id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fhorizon~stable%2Fwallaby~I076a97a6f943ab74a2db8bc5179a7db194009db4,openstack/horizon,stable/wallaby,I076a97a6f943ab74a2db8bc5179a7db194009db4,Fix app cred create without project_id for domain admins,MERGED,2022-11-04 20:58:19.000000000,2022-11-14 16:55:57.000000000,2022-11-14 16:54:49.000000000,"[{'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 35414}]","[{'number': 1, 'created': '2022-11-04 20:58:19.000000000', 'files': ['openstack_dashboard/test/unit/api/test_keystone.py', 'openstack_dashboard/api/keystone.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2f8aaa03e8ed4c2c8e3628f1f723f304b24b1f82', 'message': 'Fix app cred create without project_id for domain admins\n\nUsers with domain admin role that are not cloud admins are\nnot able to get scoped context and create an application\ncredential with project_id, so this change forces the\nscoped context in that particular case.\n\nCloses-bug: #1827120\nChange-Id: I076a97a6f943ab74a2db8bc5179a7db194009db4\n(cherry picked from commit 6eeaf9852478e25ff77c21117664ac126c5357a4)\n(cherry picked from commit 778a52e66aeab883b31db729e04944eeecfec6a2)\n(cherry picked from commit 13e821a079134a458b24593d9593e0e5318e6cd6)\n(cherry picked from commit 084ee8aaea703d99720c0cdc2751b6479dab3b2f)\n'}]",0,863629,2f8aaa03e8ed4c2c8e3628f1f723f304b24b1f82,9,4,1,14567,,,0,"Fix app cred create without project_id for domain admins

Users with domain admin role that are not cloud admins are
not able to get scoped context and create an application
credential with project_id, so this change forces the
scoped context in that particular case.

Closes-bug: #1827120
Change-Id: I076a97a6f943ab74a2db8bc5179a7db194009db4
(cherry picked from commit 6eeaf9852478e25ff77c21117664ac126c5357a4)
(cherry picked from commit 778a52e66aeab883b31db729e04944eeecfec6a2)
(cherry picked from commit 13e821a079134a458b24593d9593e0e5318e6cd6)
(cherry picked from commit 084ee8aaea703d99720c0cdc2751b6479dab3b2f)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/29/863629/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/unit/api/test_keystone.py', 'openstack_dashboard/api/keystone.py']",2,2f8aaa03e8ed4c2c8e3628f1f723f304b24b1f82,bug/1827120-stable/zed-stable/yoga-stable/xena-stable/wallaby,"def keystoneclient(request, admin=False, force_scoped=False): if (is_domain_admin(request) and not is_domain_context_specified and not force_scoped): # NOTE(ganso): users with domain admin role that are not cloud admins are # not able to get scoped context and create an application credential with # project_id, so only in this particular case we force a scoped context force_scoped = False if (request.user.project_id and request.session.get(""domain_token"") and not policy.check( ((""identity"", ""identity:update_domain""),), request)): force_scoped = True manager = keystoneclient( request, force_scoped=force_scoped).application_credentials","def keystoneclient(request, admin=False): if is_domain_admin(request) and not is_domain_context_specified: manager = keystoneclient(request).application_credentials",58,3
openstack%2Fpuppet-ovn~stable%2Fzed~Ia3112b9a219b90af718c49776da49078449f09a2,openstack/puppet-ovn,stable/zed,Ia3112b9a219b90af718c49776da49078449f09a2,Add support for ovn-ofctrl-wait-before-clear,MERGED,2022-11-08 16:04:28.000000000,2022-11-14 16:44:11.000000000,2022-11-14 16:43:09.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 16:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/5779efb52a89ce35e3251bb4742145edff87eb2b', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 2, 'created': '2022-11-09 23:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/f78bcc384e5d2b453dd51e23fa9a1d11e2ee0509', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-openstack-integration/+/863883\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 3, 'created': '2022-11-10 19:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/43b9b210179c3965f1a8f216e72dc7df3814b130', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nConflicts\n\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-openstack-integration/+/863883\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n(cherry picked from b5d38dcbd4cc8a56cc0d028f982accf23a19b15c)\n'}, {'number': 4, 'created': '2022-11-10 19:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/1e8ee799d8c8e9d033d6aa96d053c26f0d657e33', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nDepends-On: https://review.opendev.org/c/openstack/puppet-openstack-integration/+/863883\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n(cherry picked from b5d38dcbd4cc8a56cc0d028f982accf23a19b15c)\n'}, {'number': 5, 'created': '2022-11-14 03:35:16.000000000', 'files': ['spec/classes/ovn_controller_spec.rb', 'manifests/controller.pp', 'releasenotes/notes/ovn_ofctrl_wait_before_clear-c40493ce231ec38c.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/a8f8fe2cece2e20ee8c1c1b3e7d78cb3d780d6b9', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n(cherry picked from commit b5d38dcbd4cc8a56cc0d028f982accf23a19b15c)\n'}]",5,863807,a8f8fe2cece2e20ee8c1c1b3e7d78cb3d780d6b9,19,3,5,5756,,,0,"Add support for ovn-ofctrl-wait-before-clear

Support was added for this option [1] to avoid dataplane downtime
during ovn upgrades where schema changes have happened. This
adds the ability for us to configure it.

[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/

Change-Id: Ia3112b9a219b90af718c49776da49078449f09a2
(cherry picked from commit b5d38dcbd4cc8a56cc0d028f982accf23a19b15c)
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/07/863807/5 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ovn_controller_spec.rb', 'manifests/controller.pp', 'releasenotes/notes/ovn_ofctrl_wait_before_clear-c40493ce231ec38c.yaml']",3,5779efb52a89ce35e3251bb4742145edff87eb2b,ovn-ofctrl-wait-before-clear-stable/zed,"--- features: - | The new ``ovn::controller::ovn_ofctrl_wait_before_clear`` parameter has been added to resolve an issue with dataplane downtime during upgrades that involve OVN schema changes. It will delay delting and re-adding openflow rules by the configured time in ms to give ovn-controller time to handle db connection / reconnection that can happen in this case. The default of 8000ms is based on upstream OVN testing with 200k openflow rules. Since it involved a change in behavior, the upstream OVN value defaults to unset. ",,27,2
openstack%2Fironic-tempest-plugin~master~I349e4e2e3d7dcb90c25860b34d6be19b458ff584,openstack/ironic-tempest-plugin,master,I349e4e2e3d7dcb90c25860b34d6be19b458ff584,Fix typo: BaremetalIdracRedfishConfigurationMolds,MERGED,2022-11-11 09:28:42.000000000,2022-11-14 16:24:55.000000000,2022-11-14 16:23:51.000000000,"[{'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 31616}]","[{'number': 1, 'created': '2022-11-11 09:28:42.000000000', 'files': ['ironic_tempest_plugin/tests/scenario/ironic_standalone/test_cleaning.py'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/4684f915b58d2c161295100802dec7076920451f', 'message': 'Fix typo: BaremetalIdracRedfishConfigurationMolds\n\nConfiguration in the class name was mistyped.\n\nChange-Id: I349e4e2e3d7dcb90c25860b34d6be19b458ff584\n'}]",0,864253,4684f915b58d2c161295100802dec7076920451f,8,4,1,27909,,,0,"Fix typo: BaremetalIdracRedfishConfigurationMolds

Configuration in the class name was mistyped.

Change-Id: I349e4e2e3d7dcb90c25860b34d6be19b458ff584
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/53/864253/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_tempest_plugin/tests/scenario/ironic_standalone/test_cleaning.py'],1,4684f915b58d2c161295100802dec7076920451f,typo-fix,class BaremetalIdracRedfishConfigurationMolds(,class BaremetalIdracRedfishConfiguartionMolds(,1,1
openstack%2Foslo.utils~master~I8729cf180f92f43519c942e22f3b285377a5612f,openstack/oslo.utils,master,I8729cf180f92f43519c942e22f3b285377a5612f,[imageutils] Fix __str__ for QemuImgInfo,MERGED,2022-11-11 21:18:15.000000000,2022-11-14 15:51:55.000000000,2022-11-14 15:50:54.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-11 21:18:15.000000000', 'files': ['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/d49d5944824f15d00e04e1b9c7f8c3b03b440c95', 'message': ""[imageutils] Fix __str__ for QemuImgInfo\n\nCode is calling 'appened' on a list; correct this to 'append'.\n\nCloses-bug: #1996426\nChange-Id: I8729cf180f92f43519c942e22f3b285377a5612f\n""}]",1,864312,d49d5944824f15d00e04e1b9c7f8c3b03b440c95,7,2,1,5314,,,0,"[imageutils] Fix __str__ for QemuImgInfo

Code is calling 'appened' on a list; correct this to 'append'.

Closes-bug: #1996426
Change-Id: I8729cf180f92f43519c942e22f3b285377a5612f
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/12/864312/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py']",2,d49d5944824f15d00e04e1b9c7f8c3b03b440c95,bug-1996426," # test for Bug #1996426 expected_str = ""format_specific: {'data': {'foo': 'bar'}}"" self.assertIn(expected_str, str(image_info))",,4,1
openstack%2Freleases~master~Iddaaf7639cc5f3743eb20714a868afbc3ce981e3,openstack/releases,master,Iddaaf7639cc5f3743eb20714a868afbc3ce981e3,[ironic] Transition Wallaby to EM,MERGED,2022-10-21 13:00:34.000000000,2022-11-14 15:44:51.000000000,2022-11-14 15:44:51.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 15519}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-10-21 13:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b0edf1f39680f7e7cdecf451fc5fd5f8e2611e83', 'message': '[ironic] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: Iddaaf7639cc5f3743eb20714a868afbc3ce981e3\n'}, {'number': 2, 'created': '2022-10-25 17:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/de645788eff382e5d626d38c1a7c654226b81ca3', 'message': '[ironic] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: Iddaaf7639cc5f3743eb20714a868afbc3ce981e3\n'}, {'number': 3, 'created': '2022-11-04 11:21:04.000000000', 'files': ['deliverables/wallaby/python-ironicclient.yaml', 'deliverables/wallaby/sushy.yaml', 'deliverables/wallaby/networking-baremetal.yaml', 'deliverables/wallaby/ironic-inspector.yaml', 'deliverables/wallaby/networking-generic-switch.yaml', 'deliverables/wallaby/ironic-lib.yaml', 'deliverables/wallaby/ironic.yaml', 'deliverables/wallaby/sushy-cli.yaml', 'deliverables/wallaby/ironic-python-agent-builder.yaml', 'deliverables/wallaby/python-ironic-inspector-client.yaml', 'deliverables/wallaby/metalsmith.yaml', 'deliverables/wallaby/ironic-ui.yaml', 'deliverables/wallaby/bifrost.yaml', 'deliverables/wallaby/ironic-prometheus-exporter.yaml', 'deliverables/wallaby/ironic-python-agent.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1ee9b929f43441a77994e35acadd5e032ea3fbed', 'message': '[ironic] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: Iddaaf7639cc5f3743eb20714a868afbc3ce981e3\n'}]",5,862322,1ee9b929f43441a77994e35acadd5e032ea3fbed,15,7,3,17685,,,0,"[ironic] Transition Wallaby to EM

This transition the wallaby branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is November 2nd, 2022.

Change-Id: Iddaaf7639cc5f3743eb20714a868afbc3ce981e3
",git fetch https://review.opendev.org/openstack/releases refs/changes/22/862322/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/wallaby/python-ironicclient.yaml', 'deliverables/wallaby/sushy.yaml', 'deliverables/wallaby/networking-baremetal.yaml', 'deliverables/wallaby/ironic-inspector.yaml', 'deliverables/wallaby/networking-generic-switch.yaml', 'deliverables/wallaby/ironic-lib.yaml', 'deliverables/wallaby/ironic.yaml', 'deliverables/wallaby/sushy-cli.yaml', 'deliverables/wallaby/ironic-python-agent-builder.yaml', 'deliverables/wallaby/python-ironic-inspector-client.yaml', 'deliverables/wallaby/metalsmith.yaml', 'deliverables/wallaby/ironic-ui.yaml', 'deliverables/wallaby/bifrost.yaml', 'deliverables/wallaby/ironic-prometheus-exporter.yaml', 'deliverables/wallaby/ironic-python-agent.yaml']",15,b0edf1f39680f7e7cdecf451fc5fd5f8e2611e83,wallaby-em, - version: wallaby-em projects: - repo: openstack/ironic-python-agent hash: c3ad0e6a58e9d2247c6228a8bddefade1e7060b9,,60,0
openstack%2Ftripleo-ansible~master~I748a7a24aeefd8dd4f465b5ab7f5352a50e71267,openstack/tripleo-ansible,master,I748a7a24aeefd8dd4f465b5ab7f5352a50e71267,Replace deprecated PlayIterator attributes,ABANDONED,2022-10-06 03:32:01.000000000,2022-11-14 15:10:36.000000000,,"[{'_account_id': 8449}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-10-06 03:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0270760f055384b9c177378edf567c60d905413e', 'message': 'Replace deprecated PlayIterator.ITERATING_COMPLETE\n\n... to get rid of the following warning message.\n\n```\n[DEPRECATION WARNING]: PlayIterator.ITERATING_COMPLETE is deprecated,\nuse  ansible.play_iterator.IteratingStates.ITERATING_COMPLETE instead.\nThis feature  will be removed in version 2.14. Deprecation warnings can\nbe disabled by setting deprecation_warnings=False in ansible.cfg.\n```\n\nChange-Id: I748a7a24aeefd8dd4f465b5ab7f5352a50e71267\n'}, {'number': 2, 'created': '2022-10-06 04:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6976f82ff68dd25426c72cdc4517ab3fc6fde129', 'message': 'Replace deprecated PlayIterator.ITERATING_COMPLETE\n\n... to get rid of the following warning message.\n\n```\n[DEPRECATION WARNING]: PlayIterator.ITERATING_COMPLETE is deprecated,\nuse  ansible.play_iterator.IteratingStates.ITERATING_COMPLETE instead.\nThis feature  will be removed in version 2.14. Deprecation warnings can\nbe disabled by setting deprecation_warnings=False in ansible.cfg.\n```\n\nChange-Id: I748a7a24aeefd8dd4f465b5ab7f5352a50e71267\n'}, {'number': 3, 'created': '2022-10-12 01:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fec17416683aee04d11cb55e76470a2133da8e9b', 'message': 'Replace deprecated PlayIterator.ITERATING_COMPLETE\n\n... to get rid of the following warning message.\n\n```\n[DEPRECATION WARNING]: PlayIterator.ITERATING_COMPLETE is deprecated,\nuse  ansible.play_iterator.IteratingStates.ITERATING_COMPLETE instead.\nThis feature  will be removed in version 2.14. Deprecation warnings can\nbe disabled by setting deprecation_warnings=False in ansible.cfg.\n```\n\nChange-Id: I748a7a24aeefd8dd4f465b5ab7f5352a50e71267\n'}, {'number': 4, 'created': '2022-11-14 07:36:15.000000000', 'files': ['tripleo_ansible/ansible_plugins/strategy/tripleo_linear.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1e2ea56ca9cf61e2b8ef567873d5086299705900', 'message': 'Replace deprecated PlayIterator attributes\n\nITERATING_* attributes and FAILED_* attributes of PlayIterator has been\ndeprecated[1] and causes the following warning message.\n\n```\n[DEPRECATION WARNING]: PlayIterator.ITERATING_COMPLETE is deprecated,\nuse  ansible.play_iterator.IteratingStates.ITERATING_COMPLETE instead.\nThis feature  will be removed in version 2.14. Deprecation warnings can\nbe disabled by setting deprecation_warnings=False in ansible.cfg.\n```\n\n[1] https://github.com/ansible/ansible/pull/74511\n\nChange-Id: I748a7a24aeefd8dd4f465b5ab7f5352a50e71267\n'}]",1,860516,1e2ea56ca9cf61e2b8ef567873d5086299705900,13,4,4,9816,,,0,"Replace deprecated PlayIterator attributes

ITERATING_* attributes and FAILED_* attributes of PlayIterator has been
deprecated[1] and causes the following warning message.

```
[DEPRECATION WARNING]: PlayIterator.ITERATING_COMPLETE is deprecated,
use  ansible.play_iterator.IteratingStates.ITERATING_COMPLETE instead.
This feature  will be removed in version 2.14. Deprecation warnings can
be disabled by setting deprecation_warnings=False in ansible.cfg.
```

[1] https://github.com/ansible/ansible/pull/74511

Change-Id: I748a7a24aeefd8dd4f465b5ab7f5352a50e71267
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/16/860516/3 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/strategy/tripleo_linear.py'],1,0270760f055384b9c177378edf567c60d905413e,,"from ansible.play_iterator import IteratingStates if s.run_state != IteratingStates.ITERATING_COMPLETE)) # IteratingStates.ITERATING_SETUP # IteratingStates.ITERATING_TASKS # IteratingStates.ITERATING_RESCUE # IteratingStates.ITERATING_ALWAYS for state_type in [IteratingStates.ITERATING_SETUP, IteratingStates.ITERATING_TASKS, IteratingStates.ITERATING_RESCUE, IteratingStates.ITERATING_ALWAYS]:","from ansible.executor.play_iterator import PlayIterator if s.run_state != PlayIterator.ITERATING_COMPLETE)) # PlayIterator.ITERATING_SETUP # PlayIterator.ITERATING_TASKS # PlayIterator.ITERATING_RESCUE # PlayIterator.ITERATING_ALWAYS for state_type in [PlayIterator.ITERATING_SETUP, PlayIterator.ITERATING_TASKS, PlayIterator.ITERATING_RESCUE, PlayIterator.ITERATING_ALWAYS]:",10,10
openstack%2Ftripleo-ansible~master~Ifdd9a94e4153a2470662760adddc16f2635bc0c9,openstack/tripleo-ansible,master,Ifdd9a94e4153a2470662760adddc16f2635bc0c9,Handle new FieldAttributes in core Ansible,ABANDONED,2022-11-14 04:43:11.000000000,2022-11-14 15:10:03.000000000,,"[{'_account_id': 8449}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-14 04:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/58a5a52fab5bbd76bbd940ab604eff2efb9be9fa', 'message': 'Handle new FieldAttributes in core Ansible\n\nThe core ansible replaced _valid_attrs by the new FieldAttributes in\nAnsible 2.14[1]. This replaces usage of the old attribute to avoid\nfailure caused by the recent Ansible version.\n\n[1] https://github.com/ansible/ansible/pull/73908\n\nCloses-Bug: #1996482\nChange-Id: Ifdd9a94e4153a2470662760adddc16f2635bc0c9\n'}, {'number': 2, 'created': '2022-11-14 04:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a4e8a1ed2a230da5ee53792f894bec4c195602c8', 'message': 'Handle new FieldAttributes in core Ansible\n\nThe core ansible replaced _valid_attrs by the new FieldAttributes in\nAnsible 2.14[1]. This replaces usage of the old attribute to avoid\nfailure caused by the recent Ansible version.\n\n[1] https://github.com/ansible/ansible/pull/73908\n\nCloses-Bug: #1996482\nChange-Id: Ifdd9a94e4153a2470662760adddc16f2635bc0c9\n'}, {'number': 3, 'created': '2022-11-14 05:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a1de83dde8397949e5c9094e5f72b8bfd0aea818', 'message': 'Handle new FieldAttributes in core Ansible\n\nThe core ansible replaced _valid_attrs by the new FieldAttributes in\nAnsible 2.14[1]. This replaces usage of the old attribute to avoid\nfailure caused by the recent Ansible version.\n\n[1] https://github.com/ansible/ansible/pull/73908\n\nCloses-Bug: #1996482\nChange-Id: Ifdd9a94e4153a2470662760adddc16f2635bc0c9\n'}, {'number': 4, 'created': '2022-11-14 05:05:57.000000000', 'files': ['tripleo_ansible/ansible_plugins/strategy/tripleo_base.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a1c377a08d932a38953d5c974afca776a98d599b', 'message': 'Handle new FieldAttributes in core Ansible\n\nThe core ansible replaced _valid_attrs by the new FieldAttributes in\nAnsible 2.14[1]. This replaces usage of the old attribute to avoid\nfailure caused by the recent Ansible version.\n\n[1] https://github.com/ansible/ansible/pull/73908\n\nCloses-Bug: #1996482\nChange-Id: Ifdd9a94e4153a2470662760adddc16f2635bc0c9\n'}]",10,864383,a1c377a08d932a38953d5c974afca776a98d599b,17,4,4,9816,,,0,"Handle new FieldAttributes in core Ansible

The core ansible replaced _valid_attrs by the new FieldAttributes in
Ansible 2.14[1]. This replaces usage of the old attribute to avoid
failure caused by the recent Ansible version.

[1] https://github.com/ansible/ansible/pull/73908

Closes-Bug: #1996482
Change-Id: Ifdd9a94e4153a2470662760adddc16f2635bc0c9
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/83/864383/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/strategy/tripleo_base.py'],1,58a5a52fab5bbd76bbd940ab604eff2efb9be9fa,bug/1996482," def _get_task_attrs(self, task, name): # Ansible < 2.14 replaced _valid_attrs by FieldAttributes # https://github.com/ansible/ansible/pull/73908 if hasattr(task, 'fattributes'): return task.fattributes.get(name) return task._valid_attrs[name] return task.get_validated_value( 'any_errors_fatal', self._get_task_attrs('any_errors_fatal'), templar.template(task.any_errors_fatal), None)"," return task.get_validated_value('any_errors_fatal', task._valid_attrs['any_errors_fatal'], templar.template( task.any_errors_fatal), None)",12,5
openstack%2Fneutron~stable%2Fvictoria~I50f07d41428e57e6bed9be16980a6c605b7d130e,openstack/neutron,stable/victoria,I50f07d41428e57e6bed9be16980a6c605b7d130e,Allow shared net to be added on router,MERGED,2022-11-07 15:27:48.000000000,2022-11-14 15:08:26.000000000,2022-11-14 15:06:46.000000000,"[{'_account_id': 11583}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c617e484f04989a5df213aaf4cd3e786cb586c2b', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}, {'number': 2, 'created': '2022-11-08 08:51:29.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9422647e8a95069385fb539673b56d33cfd57322', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nConflicts:\n    neutron/db/l3_db.py\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)\n'}]",2,863888,9422647e8a95069385fb539673b56d33cfd57322,18,4,2,16688,,,0,"Allow shared net to be added on router

This will subnets from shared networks to be added on routers using:
$ openstack router add subnet router_id subnet_id

Without this, neutron user must use a multi-router solution, which is
not convenient at all.

Conflicts:
    neutron/db/l3_db.py

Closes-Bug: #1975603
Related-Bug: #1757482

Signed-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>
Change-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e
(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)
(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/863888/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,c617e484f04989a5df213aaf4cd3e786cb586c2b,bug/1975603,"from neutron.objects import network as network_obj # NOTE(amorin): check if network is RBAC or globaly shared # globaly shared --> disallow adding interface (see LP-1757482) # RBAC shared --> allow adding interface (see LP-1975603) elevated = context.elevated() with db_api.CONTEXT_READER.using(elevated): rbac_allowed_projects = network_obj.NetworkRBAC.get_projects( elevated, object_id=subnet['network_id'], action='access_as_shared', target_project=context.project_id) # Fail if the current project_id is NOT in the allowed # projects if context.project_id not in rbac_allowed_projects: msg = (_('Cannot add interface to router because subnet ' '%s is not owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)"," msg = (_('Cannot add interface to router because subnet %s is not ' 'owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)",40,3
openstack%2Fcharm-mysql-innodb-cluster~master~Ia2a90a0e210524ec485ce0d8493350699f8a6f7e,openstack/charm-mysql-innodb-cluster,master,Ia2a90a0e210524ec485ce0d8493350699f8a6f7e,Invoke create_databases_and_users on upgrade,MERGED,2022-09-29 21:32:15.000000000,2022-11-14 15:02:10.000000000,2022-11-14 12:18:10.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-29 21:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/8edd16a2c2f10e5ca09eb1fe27d2fab076e7b35c', 'message': ""Invoke create_databases_and_users on upgrade\n\nFix for missing allowed_units is implemented through an\ninterface code change, but the 'create_databases_and_users'\nmethod needs to be invoked to update the relation-data\nduring upgrade so the fix can be delivered.\n\nPartial-bug: #1989505\nChange-Id: Ia2a90a0e210524ec485ce0d8493350699f8a6f7e\n""}, {'number': 2, 'created': '2022-10-19 14:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/0902e4d746518722581d387be823481d5461fd23', 'message': ""Invoke create_databases_and_users on upgrade\n\nFix for missing allowed_units is implemented through an\ninterface code change, but the 'create_databases_and_users'\nmethod needs to be invoked to update the relation-data\nduring upgrade so the fix can be delivered.\n\nPartial-bug: #1989505\nChange-Id: Ia2a90a0e210524ec485ce0d8493350699f8a6f7e\n""}, {'number': 3, 'created': '2022-10-20 13:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/9cd4739e48d5a1e555c89e2179c3b7e055ba6a12', 'message': ""Invoke create_databases_and_users on upgrade\n\nFix for missing allowed_units is implemented through an\ninterface code change, but the 'create_databases_and_users'\nmethod needs to be invoked to update the relation-data\nduring upgrade so the fix can be delivered.\n\nPartial-bug: #1989505\nChange-Id: Ia2a90a0e210524ec485ce0d8493350699f8a6f7e\n""}, {'number': 4, 'created': '2022-10-20 16:22:59.000000000', 'files': ['src/reactive/mysql_innodb_cluster_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/662656055d0a55dcadf9649801300c719c47e54c', 'message': ""Invoke create_databases_and_users on upgrade\n\nFix for missing allowed_units is implemented through an\ninterface code change, but the 'create_databases_and_users'\nmethod needs to be invoked to update the relation-data\nduring upgrade so the fix can be delivered.\n\nPartial-bug: #1989505\nChange-Id: Ia2a90a0e210524ec485ce0d8493350699f8a6f7e\n""}]",13,859901,662656055d0a55dcadf9649801300c719c47e54c,36,4,4,14567,,,0,"Invoke create_databases_and_users on upgrade

Fix for missing allowed_units is implemented through an
interface code change, but the 'create_databases_and_users'
method needs to be invoked to update the relation-data
during upgrade so the fix can be delivered.

Partial-bug: #1989505
Change-Id: Ia2a90a0e210524ec485ce0d8493350699f8a6f7e
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/01/859901/1 && git format-patch -1 --stdout FETCH_HEAD,['src/reactive/mysql_innodb_cluster_handlers.py'],1,8edd16a2c2f10e5ca09eb1fe27d2fab076e7b35c,bug/1989505," if (reactive.is_flag_set( 'leadership.set.cluster-instances-clustered') and reactive.is_flag_set('db-router.available')): db_router = reactive.endpoint_from_flag(""db-router.available"") # Deliver fix for bug LP#1989505 instance.create_databases_and_users(db_router)",,6,0
openstack%2Fcharm-trilio-dm-api~stable%2F4.2~I68851c0c8541761eff6e07e8cce88575b5418606,openstack/charm-trilio-dm-api,stable/4.2,I68851c0c8541761eff6e07e8cce88575b5418606,Switch to binary builds,MERGED,2022-11-08 10:05:08.000000000,2022-11-14 14:15:45.000000000,2022-11-14 14:15:45.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 10:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-trilio-dm-api/commit/eb8cdc5eb7c0abc4e2af902605780a3cbd7c7eb9', 'message': 'Switch to binary builds\n\nChange-Id: I59ab234e73405da0d31fb9651780886d0120f8e1\n\n(cherry picked from commit 579f5374eb2494a118728b341eec9c92bac75d1c)\n(cherry picked from commit cbb28c0ee5e1ec27b4540a1bd331de4b973a83e1)\nChange-Id: I68851c0c8541761eff6e07e8cce88575b5418606\n'}, {'number': 2, 'created': '2022-11-14 10:14:35.000000000', 'files': ['osci.yaml', 'src/tests/bundles/bionic-ussuri-42.yaml', 'test-requirements.txt', 'src/tests/bundles/focal-wallaby-42.yaml', 'src/tests/bundles/focal-ussuri-42.yaml', 'src/tests/bundles/bionic-queens-42.yaml', 'requirements.txt', 'src/tests/bundles/focal-ussuri-41.yaml', 'src/wheelhouse.txt', 'charmcraft.yaml', 'src/tests/bundles/bionic-queens-41.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-trilio-dm-api/commit/116b8feecfbcfff423b12ddbbb1e39fcfc641c93', 'message': 'Switch to binary builds\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/975\n\n(cherry picked from commit 579f5374eb2494a118728b341eec9c92bac75d1c)\n(cherry picked from commit cbb28c0ee5e1ec27b4540a1bd331de4b973a83e1)\n\nChange-Id: I68851c0c8541761eff6e07e8cce88575b5418606\n'}]",0,863984,116b8feecfbcfff423b12ddbbb1e39fcfc641c93,10,3,2,12549,,,0,"Switch to binary builds

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/975

(cherry picked from commit 579f5374eb2494a118728b341eec9c92bac75d1c)
(cherry picked from commit cbb28c0ee5e1ec27b4540a1bd331de4b973a83e1)

Change-Id: I68851c0c8541761eff6e07e8cce88575b5418606
",git fetch https://review.opendev.org/openstack/charm-trilio-dm-api refs/changes/84/863984/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/bionic-ussuri-42.yaml', 'test-requirements.txt', 'src/tests/bundles/focal-wallaby-42.yaml', 'src/tests/bundles/focal-ussuri-42.yaml', 'src/tests/bundles/bionic-queens-42.yaml', 'requirements.txt', 'src/tests/bundles/focal-ussuri-41.yaml', 'src/wheelhouse.txt', 'charmcraft.yaml', 'src/tests/bundles/bionic-queens-41.yaml', 'tox.ini']",12,eb8cdc5eb7c0abc4e2af902605780a3cbd7c7eb9,binary-builds-4.2,passenv = no_proxy http_proxy https_proxy JUJU_REPOSITORY charmcraft -v pack charm-build --log-level DEBUG --use-lock-file-branches --binary-wheels-from-source -o {toxinidir}/build/builds src {posargs},"# NOTES: # * We avoid the new dependency resolver by pinning pip < 20.3, see # https://github.com/pypa/pip/issues/9187 # * Pinning dependencies requires tox >= 3.2.0, see # https://tox.readthedocs.io/en/latest/config.html#conf-requires # * It is also necessary to pin virtualenv as a newer virtualenv would still # lead to fetching the latest pip in the func* tox targets, see # https://stackoverflow.com/a/38133283 requires = pip < 20.3 virtualenv < 20.0 setuptools<50.0.0 LAYER_PATH={toxinidir}/layers INTERFACE_PATH={toxinidir}/interfacespassenv = no_proxy http_proxy https_proxy INTERFACE_PATH LAYER_PATH JUJU_REPOSITORY rename.sh charmcraft -v build {toxinidir}/rename.sh charm-build --log-level DEBUG --use-lock-file-branches -o {toxinidir}/build/builds src {posargs}",88,92
openstack%2Fcharm-trilio-wlm~master~I7035ea0afec6d7e7232c4250b68afe905a6efd67,openstack/charm-trilio-wlm,master,I7035ea0afec6d7e7232c4250b68afe905a6efd67,Add required build packages,MERGED,2022-10-28 08:58:39.000000000,2022-11-14 14:13:00.000000000,2022-11-14 14:13:00.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-28 08:58:39.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-trilio-wlm/commit/4928917afd1b94ebdf963bd660c7962c3700e7aa', 'message': 'Add required build packages\n\nBuilding the charm in LP is failing *1 due to missing packages.\n\n*1  https://launchpad.net/~openstack-charmers/charm-trilio-wlm/+charm/charm-trilio-wlm.master.latest/+build/4935/+files/buildlog_charm_ubuntu_focal_s390x_charm-trilio-wlm.master.latest_BUILDING.txt.g!z\n\nChange-Id: I7035ea0afec6d7e7232c4250b68afe905a6efd67\n'}]",1,862871,4928917afd1b94ebdf963bd660c7962c3700e7aa,9,3,1,12549,,,0,"Add required build packages

Building the charm in LP is failing *1 due to missing packages.

*1  https://launchpad.net/~openstack-charmers/charm-trilio-wlm/+charm/charm-trilio-wlm.master.latest/+build/4935/+files/buildlog_charm_ubuntu_focal_s390x_charm-trilio-wlm.master.latest_BUILDING.txt.g!z

Change-Id: I7035ea0afec6d7e7232c4250b68afe905a6efd67
",git fetch https://review.opendev.org/openstack/charm-trilio-wlm refs/changes/71/862871/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,4928917afd1b94ebdf963bd660c7962c3700e7aa,binary-builds, - libffi-dev - libssl-dev - rustc - cargo,,4,0
openstack%2Ftripleo-docs~master~I4bc8a691a75438471d36ee866f6de25e4ec7ee92,openstack/tripleo-docs,master,I4bc8a691a75438471d36ee866f6de25e4ec7ee92,Update documentation about deployment status,MERGED,2022-11-02 06:09:17.000000000,2022-11-14 14:01:16.000000000,2022-11-14 14:00:18.000000000,"[{'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-11-02 06:09:17.000000000', 'files': ['deploy-guide/source/deployment/deployment_status.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/3b584b8f4f0f6bbfdb89d0d8a3a77451856b22c8', 'message': 'Update documentation about deployment status\n\nThis change fixes the documentation explaining how to obtain deployment\nstatus.\n\n- Deployment status is now determined based on the local file, instead\n  of Heat + Mistral.\n- The workflow subcommands no longer work since Mistral was removed.\n- The openstack overcloud failures command was removed by [1].\n\n[1] 7cef22cc68d6af316ef9fbf60cb093c209c31215\n\nChange-Id: I4bc8a691a75438471d36ee866f6de25e4ec7ee92\n'}]",0,863195,3b584b8f4f0f6bbfdb89d0d8a3a77451856b22c8,9,3,1,9816,,,0,"Update documentation about deployment status

This change fixes the documentation explaining how to obtain deployment
status.

- Deployment status is now determined based on the local file, instead
  of Heat + Mistral.
- The workflow subcommands no longer work since Mistral was removed.
- The openstack overcloud failures command was removed by [1].

[1] 7cef22cc68d6af316ef9fbf60cb093c209c31215

Change-Id: I4bc8a691a75438471d36ee866f6de25e4ec7ee92
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/95/863195/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/deployment/deployment_status.rst'],1,3b584b8f4f0f6bbfdb89d0d8a3a77451856b22c8,," +------------+-------------------+ | Stack Name | Deployment Status | +------------+-------------------+ | overcloud | DEPLOY_SUCCESS | +------------+-------------------+ A different stack name can be specified with ``--stack``:: [stack@undercloud ]$ openstack overcloud status --stack my-deployment +---------------+-------------------+ | Stack Name | Deployment Status | +-----------+-----------------------+ | my-deployment | DEPLOY_SUCCESS | +---------------+-------------------+ The deployment status is stored in the YAML file, generated at ``$HOME/overcloud-deploy/<stack>/<stack>-deployment_status.yaml`` in the undercloud node."," +-----------+---------------------+---------------------+-------------------+ | Plan Name | Created | Updated | Deployment Status | +-----------+---------------------+---------------------+-------------------+ | overcloud | 2018-05-03 21:24:50 | 2018-05-03 21:27:59 | DEPLOY_SUCCESS | +-----------+---------------------+---------------------+-------------------+ A different plan name can be specified with ``--plan``:: [stack@undercloud ]$ openstack overcloud status --plan my-deployment +---------------+---------------------+---------------------+-------------------+ | Plan Name | Created | Updated | Deployment Status | +-----------+-------------------------+---------------------+-------------------+ | my-deployment | 2018-05-03 21:24:50 | 2018-05-03 21:27:59 | DEPLOY_SUCCESS | +---------------+---------------------+---------------------+-------------------+ Deployment failures can also be shown with a new command:: [stack@undercloud ]$ openstack overcloud failures --plan my-deployment .. note:: Heat CLI commands such as ``openstack stack failures list`` can still be used to show stack failures, however since Heat no longer applies software configuration, it will no longer show any errors related to configuration. Setting the status __________________ The status of the deployment will be automatically set by the API used by the Mistral workflows. However, in some cases, it may be required to manually set the status to reflect what has been done manually outside of the API. The following commands can be used to manually set the status. Set the status to ``DEPLOY_SUCCESS``:: openstack workflow execution create tripleo.deployment.v1.set_deployment_status_success Set the status to ``DEPLOYING``:: openstack workflow execution create tripleo.deployment.v1.set_deployment_status_deploying Set the status to ``DEPLOY_FAILED``:: openstack workflow execution create tripleo.deployment.v1.set_deployment_status_failed The default plan name of overcloud will be used in the above commands. It can be overridden with any of the above commands if needed:: openstack workflow execution create tripleo.deployment.v1.set_deployment_status_success '{""plan"":""my-cloud-name""}'",15,46
openstack%2Fproject-config~master~I83d53d801f7f0e27769fda7e1a606d90726f98b2,openstack/project-config,master,I83d53d801f7f0e27769fda7e1a606d90726f98b2,Add another role for Zookeeper installation,MERGED,2022-11-01 16:31:44.000000000,2022-11-14 13:59:02.000000000,2022-11-14 13:03:32.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-01 16:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a0793acd5846102c69e1c971f01bf5582e1fe027', 'message': ""Add another role for Zookeeper installation\n\nDuring PTG it was decided that we need to provide coordination service\nas part as OpenStack-Ansible deployment and decided to stop on Zookeeper\nas most feature-complete solution. With that we looked for alternative\nrole that's present under opendev umbrella, but according to\nour experience [1] of contribution to that repo it feels tought\nto try to re-use it as it's missing some aspects that we feel essential\nto have. Based on that we decided to re-write the role from scratch\nand maintain it additionally to already existing one.\n\n[1] https://review.opendev.org/q/project:+windmill/ansible-role-zookeeper+AND+owner:noonedeadpunk\n\nChange-Id: I83d53d801f7f0e27769fda7e1a606d90726f98b2\n""}, {'number': 2, 'created': '2022-11-01 16:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/032a0f446a1bdc32c53d762b0e794233005e53fc', 'message': ""Add another role for Zookeeper installation\n\nDuring PTG it was decided that we need to provide coordination service\nas part as OpenStack-Ansible deployment and decided to stop on Zookeeper\nas most feature-complete solution. With that we looked for alternative\nrole that's present under opendev umbrella, but according to\nour experience [1] of contribution to that repo it feels tought\nto try to re-use it as it's missing some aspects that we feel essential\nto have. Based on that we decided to re-write the role from scratch\nand maintain it additionally to already existing one.\n\n[1] https://review.opendev.org/q/project:+windmill/ansible-role-zookeeper+AND+owner:noonedeadpunk\n\nNeeded-By: https://review.opendev.org/c/openstack/governance/+/863161\nChange-Id: I83d53d801f7f0e27769fda7e1a606d90726f98b2\n""}, {'number': 3, 'created': '2022-11-07 14:22:23.000000000', 'files': ['zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c07db5b876295f8743637049113bb1a5d0f81560', 'message': ""Add another role for Zookeeper installation\n\nDuring PTG it was decided that we need to provide coordination service\nas part as OpenStack-Ansible deployment and decided to stop on Zookeeper\nas most feature-complete solution. With that we looked for alternative\nrole that's present under opendev umbrella, but according to\nour experience [1] of contribution to that repo it feels tought\nto try to re-use it as it's missing some aspects that we feel essential\nto have. Based on that we decided to re-write the role from scratch\nand maintain it additionally to already existing one.\n\n[1] https://review.opendev.org/q/project:+windmill/ansible-role-zookeeper+AND+owner:noonedeadpunk\n\nNeeded-By: https://review.opendev.org/c/openstack/governance/+/863161\nChange-Id: I83d53d801f7f0e27769fda7e1a606d90726f98b2\n""}]",3,863158,c07db5b876295f8743637049113bb1a5d0f81560,13,4,3,28619,,,0,"Add another role for Zookeeper installation

During PTG it was decided that we need to provide coordination service
as part as OpenStack-Ansible deployment and decided to stop on Zookeeper
as most feature-complete solution. With that we looked for alternative
role that's present under opendev umbrella, but according to
our experience [1] of contribution to that repo it feels tought
to try to re-use it as it's missing some aspects that we feel essential
to have. Based on that we decided to re-write the role from scratch
and maintain it additionally to already existing one.

[1] https://review.opendev.org/q/project:+windmill/ansible-role-zookeeper+AND+owner:noonedeadpunk

Needed-By: https://review.opendev.org/c/openstack/governance/+/863161
Change-Id: I83d53d801f7f0e27769fda7e1a606d90726f98b2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/58/863158/3 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,a0793acd5846102c69e1c971f01bf5582e1fe027,osa/zookeeper,- project: openstack/ansible-role-zookeeper description: Ansible role for Zookeeper installation groups: - openstack-ansible docimpact-group: openstack-ansible acl-config: /home/gerrit2/acls/openstack/openstack-ansible-roles.config,,6,0
openstack%2Ftripleo-docs~master~I7420904aef6e3ebf74a36f8a3c420482cde1b2d9,openstack/tripleo-docs,master,I7420904aef6e3ebf74a36f8a3c420482cde1b2d9,Node scaling now covered by baremetal_provision,MERGED,2022-10-19 23:07:05.000000000,2022-11-14 13:52:51.000000000,2022-11-14 13:51:51.000000000,"[{'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-10-19 23:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/5ac52eede68a90d5c96fb5bfbcdb52f46ec268b2', 'message': 'Node scaling now covered by baremetal_provision\n\nNode scaling with ephemeral Heat no longer works this way. Instead\nusers should follow the baremetal_provision guide on node scaling:\nhttps://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#scaling-the-overcloud\n\nChange-Id: I7420904aef6e3ebf74a36f8a3c420482cde1b2d9\n'}, {'number': 2, 'created': '2022-11-01 05:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/4191ad8c53ddc9551e849ba0272b2134565f0d50', 'message': 'Node scaling now covered by baremetal_provision\n\nNode scaling with ephemeral Heat no longer works this way. Instead\nusers should follow the baremetal_provision guide on node scaling:\nhttps://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#scaling-the-overcloud\n\nChange-Id: I7420904aef6e3ebf74a36f8a3c420482cde1b2d9\n'}, {'number': 3, 'created': '2022-11-02 05:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/f48cb7c97cb887d79a6b8b70f8f1c19cc430e905', 'message': 'Node scaling now covered by baremetal_provision\n\nNode scaling with ephemeral Heat no longer works this way. Instead\nusers should follow the baremetal_provision guide on node scaling:\nhttps://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#scaling-the-overcloud\n\nChange-Id: I7420904aef6e3ebf74a36f8a3c420482cde1b2d9\n'}, {'number': 4, 'created': '2022-11-02 05:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/5e4baceea6bffa95c8448a8cad664a654ab83415', 'message': 'Node scaling now covered by baremetal_provision\n\nNode scaling with ephemeral Heat no longer works this way. Instead\nusers should follow the baremetal_provision guide on node scaling:\nhttps://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#scaling-the-overcloud\n\nChange-Id: I7420904aef6e3ebf74a36f8a3c420482cde1b2d9\n'}, {'number': 5, 'created': '2022-11-03 02:57:39.000000000', 'files': ['deploy-guide/source/post_deployment/scale_roles.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/9bc4ab7bf8761deb517511f3c15a1679e4bb6910', 'message': 'Node scaling now covered by baremetal_provision\n\nNode scaling with ephemeral Heat no longer works this way. Instead\nusers should follow the baremetal_provision guide on node scaling:\nhttps://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#scaling-the-overcloud\n\nChange-Id: I7420904aef6e3ebf74a36f8a3c420482cde1b2d9\n'}]",0,861927,9bc4ab7bf8761deb517511f3c15a1679e4bb6910,16,3,5,30073,,,0,"Node scaling now covered by baremetal_provision

Node scaling with ephemeral Heat no longer works this way. Instead
users should follow the baremetal_provision guide on node scaling:
https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html#scaling-the-overcloud

Change-Id: I7420904aef6e3ebf74a36f8a3c420482cde1b2d9
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/27/861927/4 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/post_deployment/scale_roles.rst'],1,5ac52eede68a90d5c96fb5bfbcdb52f46ec268b2,deployment-docs,capacity should be decreased. This is now covered by the new Baremetal provisioning process. Please refer to the following document for this node scaling procedure :doc:`../provisining/_baremetal_provision`,"capacity should be decreased. To set the capacity for the compute role, first an environment file should be created:: $ cat ~/environment.yaml parameter_defaults: ComputeCount: 5 Then following command can be used to deploy it:: openstack overcloud deploy --templates [templates dir] \ -e <full environment> -e ~/environment.yaml .. note:: It is especially important to remember that you **must** include all environment files that were used to deploy the overcloud. Make sure you pass those in addition to your customization environments at the end (`environment.yaml`). .. note:: Scaling out assumes that newly added nodes has already been registered in Ironic. .. note:: When scaling down random servers of specified role will be deleted, how to delete specific nodes is described in :ref:`delete_nodes`. .. note:: The different scale parameters can be seen in the output of:: openstack help overcloud deploy",3,30
openstack%2Ftripleo-docs~master~I5f9f8961749cf9ac09b87692733c51896ba4d58f,openstack/tripleo-docs,master,I5f9f8961749cf9ac09b87692733c51896ba4d58f,Update config-download documentation,NEW,2022-11-03 02:57:39.000000000,2022-11-14 13:52:31.000000000,,"[{'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-03 02:57:39.000000000', 'files': ['deploy-guide/source/deployment/ansible_config_download.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/529c24cccdf9153bf5ec0702afafbe76381e26a3', 'message': 'Update config-download documentation\n\nThe config-download documentation is still outdated in some parts\nreferring to since removed functionality. This change removes the\nno longer relevant information, and updates include the most recent\ninformation.\n\nChange-Id: I5f9f8961749cf9ac09b87692733c51896ba4d58f\n'}]",2,863470,529c24cccdf9153bf5ec0702afafbe76381e26a3,4,2,1,30073,,,0,"Update config-download documentation

The config-download documentation is still outdated in some parts
referring to since removed functionality. This change removes the
no longer relevant information, and updates include the most recent
information.

Change-Id: I5f9f8961749cf9ac09b87692733c51896ba4d58f
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/70/863470/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/deployment/ansible_config_download.rst'],1,529c24cccdf9153bf5ec0702afafbe76381e26a3,deployment-docs,"Heat is still used to create the stack and all of the OpenStack resources. The same parameter values and environment files are passed to Heat as they were previously. During the stack creation, Heat creates any OpenStack service resources such as Nova servers and Neutron networks and ports, and then creates the software configuration data necessary to configure the overcloud via SoftwareDeployment resources.artifacts required for deployment, it does not do any of the software configuration. The data is only made available via the Heat API. Once the stack#. Create the Networks, VIPs, and provision the nodes using the baremetal provisioning workflow: :doc:`../provisioning/baremetal_provision`#. Render service data from Heat templates into relevant Ansible artifactsOn nodes that are provisioned during the ``openstack overcloud node provision`` step, the ``tripleo-admin`` user is configured for you as part of the deployment. If using pre-provisioned servers, then the user should be created prior to deployment. This user is leveraged by Ansible to connect and configure nodes during the OpenStack deployment. --stack-only # Only update the plan and stack. Skips applying the # ansible-playbook. Skips the stack and plan update.config-download with deployed-server ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ When using ``config-download`` with :doc:`deployed-server <../features/deployed_server>` (pre-provisioned nodes), a ``HostnameMap`` parameter **must** be provided. Create an environment file to define the parameter, and assign the node hostnames in the parameter value. The following example shows a sample value:: parameter_defaults: HostnameMap: overcloud-controller-0: controller-00-rack01 overcloud-controller-1: controller-01-rack02 overcloud-controller-2: controller-02-rack03 overcloud-novacompute-0: compute-00-rack01 overcloud-novacompute-1: compute-01-rack01 overcloud-novacompute-2: compute-02-rack01 Write the contents to an environment file such as ``hostnamemap.yaml``, and pass the environment as part of the deployment command with ``-e``. ``$HOME/config-download``. For the default plan name of ``overcloud`` the working $HOME/config-download/overcloudWhen using ``--stack-only``, the deployment data needs to be pulled from Heat with a separate command and ``ansible-playbook`` run manually. This enables more manual interaction and debugging.Enable tripleo-admin via SSH ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The tripleo-admin user must be `authorized on the overcloud nodes`_ for use by ``ansible-playbook``, if using the default user set by ``tripleo-ansible-inventory``. Authorizing the tripleo-admin user is done by running the ``openstack overcloud admin authorize`` command:: openstack overcloud admin authorize \ --overcloud-ssh-user heat-admin \ --overcloud-ssh-key ~/.ssh/id_rsa Alternatively, a user and key that are already authorized on the overcloud nodes can be used if that user and key are specified when running ``tripleo-ansible-inventory``. See `Generate an inventory`_. Run config-download ^^^^^^^^^^^^^^^^^^^ When using the ``--stack-only`` argument, the deployment data needs to be first downloaded from Heat. To manually download the software configuration data, use the ``openstack overcloud config download`` command:: openstack overcloud config download \ --name overcloud \ --config-dir config-download The ansible data will be generated under a directory called ``config-download`` as specified by the ``--config-dir`` CLI argument. Generate an inventory ^^^^^^^^^^^^^^^^^^^^^ To generate an inventory file to use with ``ansible-playbook`` use the ``tripleo-ansible-inventory`` command:: tripleo-ansible-inventory \ --ansible_ssh_user centos \ --static-yaml-inventory inventory.yaml The above example shows setting the ansible ssh user as ``centos``. This can be changed depending on the environment. See ``tripleo-ansible-inventory --help`` for a full list of CLI arguments and options.Once the configuration has been downloaded and the inventory generated, run ``ansible-playbook`` to configure the overcloud nodes:: -i inventory.yaml \.. admonition:: Ceph :class: ceph When config-download configures Ceph, Ansible executes ceph-ansible from within the config-download external_deploy_steps_tasks playbook. When config-download is run manually the `ssh_args` argument above will not be inherited by the second Ansible execution. To pass Ansible environment variables to this execution use a Heat environment file like the following:: parameter_defaults: CephAnsibleEnvironmentVariables: ANSIBLE_HOST_KEY_CHECKING: 'False' ANSIBLE_PRIVATE_KEY_FILE: '/home/stack/.ssh/id_rsa'``$HOME/config-download/<plan>``. .. note:: The project directory under ``$HOME/config-download/<plan>`` is only updated by ``openstack overcloud deploy`` if ``--stack-only`` is **not** used.Once the update is complete, complete the :ref:`manual-config-download` steps to create the ansible project directory. Generating overcloudrc ---------------------- In some cases, it may be required to manually generate the ``overcloudrc`` file if ``ansible-playbook`` was used manually outside of the workflow. The following command can be used to generate the ``overcloudrc`` file:: openstack overcloud credential overcloud It will generate the ``overcloudrc`` file in the current directory. The ``--directory`` option can be used to generate it in a different location. If needed, substitute the name of the deployment for overcloud. config-download with Heat SoftwareDeployment outputs ---------------------------------------------------- ``config-download`` does not support outputs on Heat SoftwareDeployment/SoftwareConfig resources. Often, ``deploy_steps_tasks`` can be used to reproduce the same behavior that would be handled by an output, by using Ansible tasks and the ``register`` keyword.","Heat is still used to create the stack, then the ansible playbooks are saved to the filesystem in a git repository. These playbook are used to deploy the openstack services and configuration to the Overcloud nodes. The same parameter values and environment files are passed to Heat as they were previously. During the stack creation, Heat simply takes the user inputs from the templates and renders the required playbooks for the deployment.deployment data necessary via SoftwareDeployment resources to perform the overcloud installation and configuration, it does not apply any of the software deployments. The data is only made available via the Heat API. Once the stack#. Create deployment plan#. Create software configuration within the Heat stack #. Create tripleo-admin ssh userThe following steps are done to create the ``tripleo-admin`` user: #. Runs a playbook to create ``tripleo-admin`` on each node. Also, gives sudo permissions to the user, as well as creates and stores a new ssh keypair for ``tripleo-admin``. The values for these cli arguments must be the same for all nodes in the overcloud deployment. ``overcloud-ssh-key`` should be the private key that corresponds with the public key specified by the Heat parameter ``KeyName`` when using Ironic deployed nodes. --stack-only # Only update the stack. Skips applying the # ansible-playbook. Skips the stack update.``$HOME/overcloud-deploy/<stack>/config-download``. For the default plan name of ``overcloud`` the working $HOME/overcloud-deploy/overcloud/config-download/overcloudPrior to running the ansible playbooks generated by config-download, it is necessary to ensure the baremetal nodes have already been provisioned. See the baremetal deployment guide first: :doc:`configure-nodes-before-deployment <./network_v2>` When running ``openstack overcloud deploy`` with the ``--stack-only`` option, this will still download the ansible content to the default directory ``$HOME/overcloud-deploy/overcloud/config-download``. But it will stop before running the ``ansible-playbook`` command.Once the baremetal nodes have been configured, and the configuration has been downloaded during the ``--stack-only`` run of ``openstack overcloud deploy``. You can then run ``ansible-playbook`` manually to configure the overcloud nodes:: -i /home/stack/config-download/overcloud/tripleo-ansible-inventory.yaml \``$HOME/overcloud-deploy/<stack-name>/config-download/<stack-name>``. ",125,41
openstack%2Fmagnum~master~Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b,openstack/magnum,master,Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b,Drop mesos driver,MERGED,2021-12-09 13:28:58.000000000,2022-11-14 13:50:50.000000000,2022-11-14 13:49:47.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 32657}]","[{'number': 1, 'created': '2021-12-09 13:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/86fe38303efb642d911486816b225fc6f4584975', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}, {'number': 2, 'created': '2021-12-09 18:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/78135a9789ee18b78bbe7b8bbde0a37e44013220', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}, {'number': 3, 'created': '2021-12-09 19:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3898163db476004dc3da21ea1203df33ff579532', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}, {'number': 4, 'created': '2022-01-31 15:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/af85d4dc119fbcc5b41c7730fab7ce02e55ea845', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}, {'number': 5, 'created': '2022-01-31 15:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/047efc0842fabfc91fa306ca9c2426453c6026a9', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}, {'number': 6, 'created': '2022-11-09 12:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c062186c71fc6b51069582ed1067156205e31217', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}, {'number': 7, 'created': '2022-11-11 12:01:52.000000000', 'files': ['magnum/drivers/mesos_ubuntu_v1/image/docker/post-install.d/60-disable-docker-service', 'magnum/drivers/mesos_ubuntu_v1/driver.py', 'magnum/drivers/mesos_ubuntu_v1/image/docker/package-installs.yaml', 'contrib/drivers/dcos_centos_v1/__init__.py', 'contrib/drivers/dcos_centos_v1/monitor.py', 'contrib/drivers/dcos_centos_v1/templates/dcosslave.yaml', 'contrib/drivers/dcos_centos_v1/image/docker/install.d/50-install-docker', 'contrib/drivers/dcos_centos_v1/template_def.py', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/configure-mesos-master.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/mesosslave.yaml', 'contrib/drivers/dcos_centos_v1/driver.py', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/write-heat-params-master.sh', 'contrib/drivers/dcos_centos_v1/templates/lb.yaml', 'magnum/tests/unit/conductor/test_monitors.py', 'magnum/drivers/mesos_ubuntu_v1/templates/mesos_slave_software_configs.yaml', 'magnum/tests/functional/mesos/__init__.py', 'contrib/drivers/dcos_centos_v1/image/dcos/extra-data.d/99-download-generate-config', 'contrib/drivers/heat/dcos_centos_template_def.py', 'magnum/drivers/mesos_ubuntu_v1/image/validate_image.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/add-proxy.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/write-heat-params.yaml', 'magnum/drivers/mesos_ubuntu_v1/version.py', 'magnum/drivers/mesos_ubuntu_v1/COPYING', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/add-ext-ca-certs.sh', 'magnum/tests/functional/common/datagen.py', 'contrib/drivers/dcos_centos_v1/image/install_imagebuild_deps.sh', 'contrib/drivers/dcos_centos_v1/version.py', 'magnum/drivers/mesos_ubuntu_v1/__init__.py', 'contrib/drivers/dcos_centos_v1/image/dcos/post-install.d/99-enable-ntp', 'contrib/drivers/dcos_centos_v1/image/docker/pre-install.d/20-configure-docker-service', 'contrib/drivers/dcos_centos_v1/image/README.md', 'contrib/drivers/dcos_centos_v1/templates/dcoscluster.yaml', 'contrib/drivers/dcos_centos_v1/image/validate_dcos_image.sh', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/post-install.d/60-disable-upstart', 'setup.cfg', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/start-services-master.sh', 'magnum/tests/functional/mesos/test_mesos_python_client.py', 'tox.ini', 'magnum/drivers/mesos_ubuntu_v1/image/Dockerfile', 'contrib/drivers/dcos_centos_v1/image/dcos/post-install.d/99-add-norgoup', 'magnum/tests/unit/drivers/test_template_definition.py', 'contrib/drivers/dcos_centos_v1/templates/secgroup.yaml', 'contrib/drivers/dcos_centos_v1/templates/dcosmaster.yaml', 'magnum/drivers/mesos_ubuntu_v1/monitor.py', 'contrib/drivers/dcos_centos_v1/image/docker/pre-install.d/10-enable-overlay', 'magnum/drivers/mesos_ubuntu_v1/templates/mesoscluster.yaml', 'contrib/drivers/dcos_centos_v1/image/docker/post-install.d/60-enable-docker-service', 'magnum/drivers/mesos_ubuntu_v1/image/install_imagebuild_deps.sh', 'magnum/drivers/mesos_ubuntu_v1/image/README.md', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/start-services-slave.sh', 'magnum/drivers/mesos_ubuntu_v1/scale_manager.py', 'requirements.txt', 'contrib/drivers/dcos_centos_v1/README.md', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/package-installs.yaml', 'magnum/drivers/mesos_ubuntu_v1/template_def.py', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/elements-deps', 'magnum/tests/unit/conductor/handlers/test_mesos_cluster_conductor.py', 'contrib/drivers/dcos_centos_v1/image/dcos/environment.d/10-dcos-install-url', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/pre-install.d/10-apt-repo', 'contrib/drivers/dcos_centos_v1/image/dcos/package-installs.yaml', 'magnum/drivers/common/templates/environments/enable_floating_ip.yaml', 'magnum/drivers/common/templates/environments/disable_floating_ip.yaml', 'magnum/drivers/mesos_ubuntu_v1/image/docker/elements-deps', 'contrib/drivers/dcos_centos_v1/scale_manager.py', 'contrib/drivers/dcos_centos_v1/templates/fragments/configure-dcos.sh', 'contrib/drivers/dcos_centos_v1/image/docker/elements-deps', 'contrib/drivers/dcos_centos_v1/templates/fragments/write-heat-params.sh', 'magnum/tests/unit/conductor/test_scale_manager.py', 'releasenotes/notes/drop_mesos_driver-pBmrJ9gAqX3EUROBS2g.yaml', 'magnum/drivers/mesos_ubuntu_v1/image/docker/pre-install.d/10-add-docker-repo', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/volume-service.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/configure-mesos-slave.sh', 'contrib/drivers/dcos_centos_v1/image/dcos/elements-deps', 'magnum/drivers/mesos_ubuntu_v1/templates/mesosmaster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d3d28594b3d2c4b2f62258b8f59812e6ccd55497', 'message': ""Drop mesos driver\n\nThe coe mesos has not been maitenaned for quite some\ntime and hasn't got much attetion from the community\nin general. As discussed in the mailing list [1] we\nare dropping for now.\n\nIn this patch, we start by removing the mesos driver\nand its test cases. This part of the code has no impact\nfor other drivers. Then we can clean up mesos references\nthat affect the API.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html\n\nConflicts:\n\tlower-constraints.txt\n\ttox.ini\n\nChange-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b\n""}]",6,821213,d3d28594b3d2c4b2f62258b8f59812e6ccd55497,28,4,7,28008,,,0,"Drop mesos driver

The coe mesos has not been maitenaned for quite some
time and hasn't got much attetion from the community
in general. As discussed in the mailing list [1] we
are dropping for now.

In this patch, we start by removing the mesos driver
and its test cases. This part of the code has no impact
for other drivers. Then we can clean up mesos references
that affect the API.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2021-December/026230.html

Conflicts:
	lower-constraints.txt
	tox.ini

Change-Id: Ied76095f1f1c57c6af93d1a6094baa6c7cc31c9b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/13/821213/6 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/mesos_ubuntu_v1/image/docker/post-install.d/60-disable-docker-service', 'magnum/drivers/mesos_ubuntu_v1/driver.py', 'magnum/drivers/mesos_ubuntu_v1/image/Dockerfile', 'magnum/drivers/mesos_ubuntu_v1/image/docker/package-installs.yaml', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/drivers/mesos_ubuntu_v1/monitor.py', 'magnum/drivers/mesos_ubuntu_v1/templates/mesoscluster.yaml', 'magnum/drivers/mesos_ubuntu_v1/image/install_imagebuild_deps.sh', 'magnum/drivers/mesos_ubuntu_v1/image/README.md', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/configure-mesos-master.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/start-services-slave.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/mesosslave.yaml', 'magnum/drivers/mesos_ubuntu_v1/scale_manager.py', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/write-heat-params-master.sh', 'magnum/tests/unit/conductor/test_monitors.py', 'magnum/drivers/mesos_ubuntu_v1/templates/mesos_slave_software_configs.yaml', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/package-installs.yaml', 'magnum/drivers/mesos_ubuntu_v1/image/validate_image.sh', 'magnum/drivers/mesos_ubuntu_v1/template_def.py', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/add-proxy.sh', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/elements-deps', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/write-heat-params.yaml', 'magnum/tests/unit/conductor/handlers/test_mesos_cluster_conductor.py', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/pre-install.d/10-apt-repo', 'magnum/drivers/mesos_ubuntu_v1/version.py', 'magnum/drivers/mesos_ubuntu_v1/image/docker/elements-deps', 'magnum/drivers/mesos_ubuntu_v1/COPYING', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/add-ext-ca-certs.sh', 'magnum/drivers/mesos_ubuntu_v1/__init__.py', 'magnum/tests/unit/conductor/test_scale_manager.py', 'releasenotes/notes/drop_mesos_driver-pBmrJ9gAqX3EUROBS2g.yaml', 'magnum/drivers/mesos_ubuntu_v1/image/docker/pre-install.d/10-add-docker-repo', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/volume-service.sh', 'magnum/drivers/mesos_ubuntu_v1/image/mesos/post-install.d/60-disable-upstart', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/configure-mesos-slave.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/fragments/start-services-master.sh', 'magnum/drivers/mesos_ubuntu_v1/templates/mesosmaster.yaml']",37,86fe38303efb642d911486816b225fc6f4584975,remove_mesos,,"heat_template_version: 2014-10-16 description: > This is a nested stack that defines a single Mesos master, This stack is included by a ResourceGroup resource in the parent template (mesoscluster.yaml). parameters: name: type: string description: server name server_image: type: string description: glance image used to boot the server master_flavor: type: string description: flavor to use when booting the server ssh_key_name: type: string description: name of ssh key to be provisioned on our server external_network: type: string description: uuid/name of a network to use for floating ip addresses fixed_network: type: string description: Network from which to allocate fixed addresses. fixed_subnet: type: string description: Subnet from which to allocate fixed addresses. secgroup_mesos_id: type: string description: ID of the security group for mesos master. api_pool_id: type: string description: ID of the load balancer pool of Marathon. openstack_ca: type: string hidden: true description: The OpenStack CA certificate to install on the node. nodes_server_group_id: type: string description: ID of the server group for kubernetes cluster nodes. resources: add_ext_ca_certs: type: OS::Heat::SoftwareConfig properties: group: script config: str_replace: template: {get_file: fragments/add-ext-ca-certs.sh} params: ""@@CACERTS_CONTENT@@"": {get_param: openstack_ca} mesos_master_init: type: OS::Heat::MultipartMime properties: parts: - config: {get_resource: add_ext_ca_certs} ###################################################################### # # Mesos master server. # # do NOT use ""_"" (underscore) in the Nova server name # it creates a mismatch between the generated Nova name and its hostname # which can lead to weird problems mesos-master: type: OS::Nova::Server properties: name: {get_param: name} image: {get_param: server_image} flavor: {get_param: master_flavor} key_name: {get_param: ssh_key_name} user_data_format: SOFTWARE_CONFIG user_data: {get_resource: mesos_master_init} networks: - port: {get_resource: mesos_master_eth0} scheduler_hints: { group: { get_param: nodes_server_group_id }} mesos_master_eth0: type: OS::Neutron::Port properties: network: {get_param: fixed_network} security_groups: - {get_param: secgroup_mesos_id} fixed_ips: - subnet: {get_param: fixed_subnet} replacement_policy: AUTO mesos_master_floating: type: OS::Neutron::FloatingIP properties: floating_network: {get_param: external_network} port_id: {get_resource: mesos_master_eth0} api_pool_member: type: Magnum::Optional::Neutron::LBaaS::PoolMember properties: pool: {get_param: api_pool_id} address: {get_attr: [mesos_master_eth0, fixed_ips, 0, ip_address]} subnet: { get_param: fixed_subnet } protocol_port: 8080 outputs: mesos_master_ip: value: {get_attr: [mesos_master_eth0, fixed_ips, 0, ip_address]} description: > This is the ""private"" address of the Mesos master node. mesos_master_external_ip: value: {get_attr: [mesos_master_floating, floating_ip_address]} description: > This is the ""public"" address of the Mesos master node. mesos_server_id: value: {get_resource: mesos-master} description: > This is the logical id of the Mesos master node. ",6,2743
openstack%2Ftripleo-docs~master~Ib508e98c35c83e295324a5900cf2325427d8158a,openstack/tripleo-docs,master,Ib508e98c35c83e295324a5900cf2325427d8158a,Removing irrelavant references to 'plan-environment.yaml',MERGED,2022-11-04 12:45:21.000000000,2022-11-14 13:48:48.000000000,2022-11-14 13:47:13.000000000,"[{'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-11-04 12:45:21.000000000', 'files': ['doc/source/install/advanced_deployment/custom.rst', 'doc/source/install/advanced_deployment/plan_export.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/a046cc707f09d30b5a100948b50977df40ade2e9', 'message': ""Removing irrelavant references to 'plan-environment.yaml'\n\nThe file and associated CLI commands were removed in wallaby\nand are therefore no longer relevant for more recent releases.\n\nInformation about the file for FFU between older releases was\nkept, as it is presumably still relevant.\n\nCloses-Bug: lp#1995702\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: Ib508e98c35c83e295324a5900cf2325427d8158a\n""}]",0,863642,a046cc707f09d30b5a100948b50977df40ade2e9,8,3,1,32926,,,0,"Removing irrelavant references to 'plan-environment.yaml'

The file and associated CLI commands were removed in wallaby
and are therefore no longer relevant for more recent releases.

Information about the file for FFU between older releases was
kept, as it is presumably still relevant.

Closes-Bug: lp#1995702

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: Ib508e98c35c83e295324a5900cf2325427d8158a
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/42/863642/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/advanced_deployment/custom.rst', 'doc/source/install/advanced_deployment/plan_export.rst']",2,a046cc707f09d30b5a100948b50977df40ade2e9,lp#1995702,,"Exporting Deployment Plans ========================== Exporting a deployment plan enables you to quickly retrieve the contents of an existing deployment plan. A deployment plan consists of the heat templates and the environment files used to deploy an overcloud, as well as the `plan-environment.yaml`_ file which holds the plan metadata. Exporting a plan can be useful if you want to use an existing plan as a starting point for further customizations (instead of starting from scratch with a fresh copy of `tripleo-heat-templates`_). Exporting a plan using the CLI ------------------------------ To export a plan using the CLI, use the following command:: $ openstack overcloud plan export <plan_name> E.g:: $ openstack overcloud plan export overcloud will export the default plan called ``overcloud``. By default, a tarball named ``overcloud.tar.gz`` containing the plan files will be created in the current directory. If you would like to use a custom file name, you can specify it using the ``--output-file`` option. Exporting a plan using the UI ----------------------------- To export a plan using the UI, navigate to the ``Plans`` page using the ``All Plans`` link from the ``Plans`` tab. Then open the kebab menu of the plan you want to export and click the ``Export`` link. This will trigger the plan export workflow and after the plan export completes you will be presented with a link to download the plan tarball. .. _`plan-environment.yaml`: https://github.com/openstack/tripleo-heat-templates/blob/master/plan-environment.yaml .. _`tripleo-heat-templates`: https://github.com/openstack/tripleo-heat-templates ",2,42
openstack%2Ftripleo-ansible~master~I16bdabe5f70a6f034028a241793f2c5bc4142d3d,openstack/tripleo-ansible,master,I16bdabe5f70a6f034028a241793f2c5bc4142d3d,Removes redundant bonds_vlans_storage nic template,NEW,2022-11-11 15:02:45.000000000,2022-11-14 13:38:43.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-11 15:02:45.000000000', 'files': ['tripleo_ansible/roles/tripleo_network_config/templates/bonds_vlans/bonds_vlans_storage.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/245e226955389631f48ac04cd2e67259485febed', 'message': 'Removes redundant bonds_vlans_storage nic template\n\nThis template is identical to bonds_vlans save for one line\nwhich is hardcoded here.\n\nChange-Id: I16bdabe5f70a6f034028a241793f2c5bc4142d3d\n'}]",1,864294,245e226955389631f48ac04cd2e67259485febed,6,2,1,19740,,,0,"Removes redundant bonds_vlans_storage nic template

This template is identical to bonds_vlans save for one line
which is hardcoded here.

Change-Id: I16bdabe5f70a6f034028a241793f2c5bc4142d3d
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/94/864294/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_network_config/templates/bonds_vlans/bonds_vlans_storage.j2'],1,245e226955389631f48ac04cd2e67259485febed,remove-redundant-template,,"--- {% set mtu_list = [ctlplane_mtu] %} {% for network in role_networks %} {{ mtu_list.append(lookup('vars', networks_lower[network] ~ '_mtu')) }} {%- endfor %} {% set min_viable_mtu = mtu_list | max %} network_config: - type: interface name: nic1 mtu: {{ ctlplane_mtu }} use_dhcp: false addresses: - ip_netmask: {{ ctlplane_ip }}/{{ ctlplane_subnet_cidr }} routes: {{ ctlplane_host_routes }} - type: ovs_bridge name: br-bond dns_servers: {{ ctlplane_dns_nameservers }} domain: {{ dns_search_domains }} members: - type: ovs_bond name: bond1 mtu: {{ min_viable_mtu }} ovs_options: {{ bond_interface_ovs_options }} members: - type: interface name: nic2 mtu: {{ min_viable_mtu }} primary: true - type: interface name: nic3 mtu: {{ min_viable_mtu }} {% for network in role_networks %} - type: vlan mtu: {{ lookup('vars', networks_lower[network] ~ '_mtu') }} vlan_id: {{ lookup('vars', networks_lower[network] ~ '_vlan_id') }} addresses: - ip_netmask: {{ lookup('vars', networks_lower[network] ~ '_ip') }}/{{ lookup('vars', networks_lower[network] ~ '_cidr') }} routes: {{ lookup('vars', networks_lower[network] ~ '_host_routes') }} {% endfor %} ",0,39
openstack%2Fneutron~master~Id9138652f5f07ef12fa682e182fe210019e8f975,openstack/neutron,master,Id9138652f5f07ef12fa682e182fe210019e8f975,Fix some pylint indentation warnings,MERGED,2022-11-09 00:48:50.000000000,2022-11-14 13:13:09.000000000,2022-11-14 13:10:49.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 22348}, {'_account_id': 34271}]","[{'number': 1, 'created': '2022-11-09 00:48:50.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py', 'neutron/plugins/ml2/managers.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_db_sync.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/drivers/mech_agent.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/eswitch_manager.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ofswitch.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/qos.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/plugins/ml2/extensions/subnet_dns_publish_fixed_ip.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1714a2b9d9e9c1aa79b9296bb76c6e59ccb617a', 'message': 'Fix some pylint indentation warnings\n\nRunning with a stricter .pylintrc generates a lot of\nC0330 warnings (hanging/continued indentation). Fix\nthe ones in neutron/plugins.\n\nTrivialfix\n\nChange-Id: Id9138652f5f07ef12fa682e182fe210019e8f975\n'}]",1,864072,b1714a2b9d9e9c1aa79b9296bb76c6e59ccb617a,12,5,1,1131,,,0,"Fix some pylint indentation warnings

Running with a stricter .pylintrc generates a lot of
C0330 warnings (hanging/continued indentation). Fix
the ones in neutron/plugins.

Trivialfix

Change-Id: Id9138652f5f07ef12fa682e182fe210019e8f975
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/864072/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/driver_context.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/maintenance.py', 'neutron/plugins/ml2/managers.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_db_sync.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/drivers/mech_agent.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/eswitch_manager.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ofswitch.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/qos.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/plugins/ml2/extensions/subnet_dns_publish_fixed_ip.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",19,b1714a2b9d9e9c1aa79b9296bb76c6e59ccb617a,pylint-c0330-plugins," cfg.CONF.ml2_type_geneve.max_header_size, OVN_MIN_GENEVE_MAX_HEADER_SIZE) 'IPv6: ""%(ipv6_opts)s""', {'port_id': port['id'], 'ipv4_opts': ipv4_opts, 'ipv6_opts': ipv6_opts}) {'port_id': port['id'], 'host': bind_host}) {ovn_const.OVN_FIP_EXT_MAC_KEY: nat['external_mac']})).execute() check_error=True) check_error=True)"," cfg.CONF.ml2_type_geneve.max_header_size, OVN_MIN_GENEVE_MAX_HEADER_SIZE) 'IPv6: ""%(ipv6_opts)s""', {'port_id': port['id'], 'ipv4_opts': ipv4_opts, 'ipv6_opts': ipv6_opts}) {'port_id': port['id'], 'host': bind_host}) {ovn_const.OVN_FIP_EXT_MAC_KEY: nat['external_mac']})).execute() check_error=True) check_error=True)",201,206
openstack%2Fneutron~master~I9311cfe5efc51552008072d84aa238e5d0c9de60,openstack/neutron,master,I9311cfe5efc51552008072d84aa238e5d0c9de60,Fix some pylint indentation warnings,MERGED,2022-11-09 00:50:23.000000000,2022-11-14 13:12:14.000000000,2022-11-14 13:10:45.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 00:50:23.000000000', 'files': ['neutron/db/l3_gateway_ip_qos.py', 'neutron/db/securitygroups_db.py', 'neutron/db/quota/models.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/db/models/subnet_service_type.py', 'neutron/db/l3_hamode_db.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/agentschedulers_db.py', 'neutron/db/data_plane_status_db.py', 'neutron/db/quota/api.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/db/allowedaddresspairs_db.py', 'neutron/db/servicetype_db.py', 'neutron/db/migration/autogen.py', 'neutron/db/ovn_revision_numbers_db.py', 'neutron/db/models/network_segment_range.py', 'neutron/db/network_ip_availability_db.py', 'neutron/db/l3_db.py', 'neutron/db/external_net_db.py', 'neutron/db/quota/driver.py', 'neutron/db/agents_db.py', 'neutron/db/db_base_plugin_common.py', 'neutron/db/extradhcpopt_db.py', 'neutron/db/extraroute_db.py', 'neutron/db/l3_dvrscheduler_db.py', 'neutron/db/l3_agentschedulers_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/55b16d7b7c5e85422c4db47ba666f2de95ef0e15', 'message': 'Fix some pylint indentation warnings\n\nRunning with a stricter .pylintrc generates a lot of\nC0330 warnings (hanging/continued indentation). Fix\nthe ones in neutron/db.\n\nTrivialfix\n\nChange-Id: I9311cfe5efc51552008072d84aa238e5d0c9de60\n'}]",1,864073,55b16d7b7c5e85422c4db47ba666f2de95ef0e15,13,4,1,1131,,,0,"Fix some pylint indentation warnings

Running with a stricter .pylintrc generates a lot of
C0330 warnings (hanging/continued indentation). Fix
the ones in neutron/db.

Trivialfix

Change-Id: I9311cfe5efc51552008072d84aa238e5d0c9de60
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/864073/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_gateway_ip_qos.py', 'neutron/db/securitygroups_db.py', 'neutron/db/quota/models.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/db/models/subnet_service_type.py', 'neutron/db/l3_hamode_db.py', 'neutron/db/l3_dvr_db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/db/agentschedulers_db.py', 'neutron/db/data_plane_status_db.py', 'neutron/db/quota/api.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/db/allowedaddresspairs_db.py', 'neutron/db/servicetype_db.py', 'neutron/db/migration/autogen.py', 'neutron/db/ovn_revision_numbers_db.py', 'neutron/db/models/network_segment_range.py', 'neutron/db/network_ip_availability_db.py', 'neutron/db/l3_db.py', 'neutron/db/external_net_db.py', 'neutron/db/quota/driver.py', 'neutron/db/agents_db.py', 'neutron/db/db_base_plugin_common.py', 'neutron/db/extradhcpopt_db.py', 'neutron/db/extraroute_db.py', 'neutron/db/l3_dvrscheduler_db.py', 'neutron/db/l3_agentschedulers_db.py']",27,55b16d7b7c5e85422c4db47ba666f2de95ef0e15,pylint-c0330-db," agent_type='L3', get_down_bindings=self.get_down_router_bindings, agent_id_attr='l3_agent_id', resource_id_attr='router_id', resource_name='router', reschedule_resource=self.reschedule_router, rescheduling_failed=l3agentscheduler.RouterReschedulingFailed) context, router_id=router_id, l3_agent_id=agent_id) context, l3_agent_id=agent_id) context, router_id=router_ids) agent_mode == constants.L3_AGENT_MODE_DVR_NO_EXTERNAL or context, agent_ids) context, _pager=pager, router_id=router_id)"," agent_type='L3', get_down_bindings=self.get_down_router_bindings, agent_id_attr='l3_agent_id', resource_id_attr='router_id', resource_name='router', reschedule_resource=self.reschedule_router, rescheduling_failed=l3agentscheduler.RouterReschedulingFailed) context, router_id=router_id, l3_agent_id=agent_id) context, l3_agent_id=agent_id) context, router_id=router_ids) agent_mode == constants.L3_AGENT_MODE_DVR_NO_EXTERNAL or context, agent_ids) context, _pager=pager, router_id=router_id)",165,165
openstack%2Fdevstack~master~I399685ed1f864f8f1ce7295ed6f83336cfccbd81,openstack/devstack,master,I399685ed1f864f8f1ce7295ed6f83336cfccbd81,[Doc] Fix Glance image size limit command,MERGED,2022-09-22 02:30:07.000000000,2022-11-14 13:11:53.000000000,2022-11-14 13:10:53.000000000,"[{'_account_id': 4393}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2022-09-22 02:30:07.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f49b435e98cd9d119179d98829241954b8d73669', 'message': ""[Doc] Fix Glance image size limit command\n\nThis commit fixes the configuration document which mentions how to\nchange Glance default image size quota at runtime because we don't have\n`openstack registered limit update` command but\n`openstack registered limit set` command[1].\n\n[1] https://docs.openstack.org/python-openstackclient/latest/cli/command-objects/registered-limit.html#registered-limit-set\n\nChange-Id: I399685ed1f864f8f1ce7295ed6f83336cfccbd81\n""}]",6,858838,f49b435e98cd9d119179d98829241954b8d73669,11,4,1,5689,,,0,"[Doc] Fix Glance image size limit command

This commit fixes the configuration document which mentions how to
change Glance default image size quota at runtime because we don't have
`openstack registered limit update` command but
`openstack registered limit set` command[1].

[1] https://docs.openstack.org/python-openstackclient/latest/cli/command-objects/registered-limit.html#registered-limit-set

Change-Id: I399685ed1f864f8f1ce7295ed6f83336cfccbd81
",git fetch https://review.opendev.org/openstack/devstack refs/changes/38/858838/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,f49b435e98cd9d119179d98829241954b8d73669,fix-typo-configuration-doc, openstack --os-cloud devstack-system-admin registered limit set \, openstack --os-cloud devstack-system-admin registered limit update \,1,1
openstack%2Ftripleo-docs~master~I3046dc0a5ea703a8db5af85191827d3f009299a8,openstack/tripleo-docs,master,I3046dc0a5ea703a8db5af85191827d3f009299a8,Scaling: reusing node index,NEW,2021-06-21 22:26:04.000000000,2022-11-14 13:11:09.000000000,,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-06-21 22:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/1ecbe3372b15a678234a8e756e99c98940d5cc41', 'message': 'Scaling: reusing node index\n\nAdding section about reusing node index during scale down/up\n\nChange-Id: I3046dc0a5ea703a8db5af85191827d3f009299a8\n'}, {'number': 2, 'created': '2021-06-21 23:25:53.000000000', 'files': ['deploy-guide/source/provisioning/baremetal_provision.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/9e6b94fe379910cc0853aeb883b13822e98970cd', 'message': 'Scaling: reusing node index\n\nAdding section about reusing node index during scale down/up\n\nChange-Id: I3046dc0a5ea703a8db5af85191827d3f009299a8\n'}]",2,797356,9e6b94fe379910cc0853aeb883b13822e98970cd,10,5,2,27419,,,0,"Scaling: reusing node index

Adding section about reusing node index during scale down/up

Change-Id: I3046dc0a5ea703a8db5af85191827d3f009299a8
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/56/797356/2 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/provisioning/baremetal_provision.rst'],1,1ecbe3372b15a678234a8e756e99c98940d5cc41,,"Reusing node index ^^^^^^^^^^^^^^^^^^ By default, TripleO will blacklist an index after a node was scaled down. There's some situations where we would like to re-use a certain node index. If we scaled down compute-1 from the overcloud stack, the stack would store the index in the ``ComputeRemovalPolicies``, for example: $ openstack stack show overcloud -f json -c parameters | \ jq -r '.parameters | [.ComputeRemovalPolicies, .ComputeRemovalPoliciesMode] | @tsv' [{""resource_list"": [1]}] append To re-use the node index 1, we would need to load this template and rerun the deployment command once: .. code-block:: yaml parameter_defaults: ComputeRemovalPolicies: '[{""resource_list"": []}]' ComputeRemovalPoliciesMode: 'update' After this, we need to set the ``ComputeRemovalPoliciesMode`` to ``append`` with this template: .. code-block:: yaml parameter_defaults: ComputeRemovalPoliciesMode: 'append' Once the deployment is completed with this ``ComputeRemovalPoliciesMode``, it can be removed from the deployment command. ",,36,0
openstack%2Fneutron-lib~master~Ie72061bdb14a9f937dd0a9067ea7e32daba899d5,openstack/neutron-lib,master,Ie72061bdb14a9f937dd0a9067ea7e32daba899d5,Add warning about mtu update and libvirt limitation,MERGED,2022-10-21 09:26:22.000000000,2022-11-14 13:06:34.000000000,2022-11-14 13:05:32.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2022-10-21 09:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/aa0b135e04a4d2e65c1a3b76c3a586a5c13db27c', 'message': 'Add warning about mtu update and libvirt limitation\n\nIt was discussed during the PTG [1].\n\n[1] https://etherpad.opendev.org/p/neutron-antelope-ptg#L336\n\nChange-Id: Ie72061bdb14a9f937dd0a9067ea7e32daba899d5\n'}, {'number': 2, 'created': '2022-10-21 09:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/b2cd6e4250567935faf0e94525f1fe3f7c490cec', 'message': 'Add warning about mtu update and libvirt limitation\n\nIt was discussed during the PTG [1].\n\n[1] https://etherpad.opendev.org/p/neutron-antelope-ptg#L336\n\nChange-Id: Ie72061bdb14a9f937dd0a9067ea7e32daba899d5\n'}, {'number': 3, 'created': '2022-11-10 19:41:33.000000000', 'files': ['api-ref/source/v2/networks.inc'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/6d3f037ea3ecb8bc1d446bf5c699636b0f7fd504', 'message': 'Add warning about mtu update and libvirt limitation\n\nIt was discussed during the PTG [1].\n\n[1] https://etherpad.opendev.org/p/neutron-antelope-ptg#L336\n\nChange-Id: Ie72061bdb14a9f937dd0a9067ea7e32daba899d5\n'}]",8,862284,6d3f037ea3ecb8bc1d446bf5c699636b0f7fd504,19,5,3,11975,,,0,"Add warning about mtu update and libvirt limitation

It was discussed during the PTG [1].

[1] https://etherpad.opendev.org/p/neutron-antelope-ptg#L336

Change-Id: Ie72061bdb14a9f937dd0a9067ea7e32daba899d5
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/84/862284/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v2/networks.inc'],1,aa0b135e04a4d2e65c1a3b76c3a586a5c13db27c,mutable-mtu,.. warning:: Due to limitation in libvirt and qemu updating ``mtu`` value for an existing network with instances plugged to it requires to do hard reboot of those instances or detach and then attach again ports from that network to the instances. ,,7,0
openstack%2Fkolla-ansible~master~Ib3dba0a3741d918a189edfa43041207a59392f07,openstack/kolla-ansible,master,Ib3dba0a3741d918a189edfa43041207a59392f07,docs: Octavia OVN provider,MERGED,2022-11-14 10:47:29.000000000,2022-11-14 13:00:58.000000000,2022-11-14 12:59:55.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}]","[{'number': 1, 'created': '2022-11-14 10:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/82a25a82281226e80c4167d267547f1c5026b7ca', 'message': 'docs: Octavia OVN provider\n\nChange-Id: Ib3dba0a3741d918a189edfa43041207a59392f07\n'}, {'number': 2, 'created': '2022-11-14 12:35:42.000000000', 'files': ['doc/source/conf.py', 'doc/source/reference/networking/octavia.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6c0c2b9850114ba05a210e291a670621f570842f', 'message': 'docs: Octavia OVN provider\n\nChange-Id: Ib3dba0a3741d918a189edfa43041207a59392f07\n'}]",5,864398,6c0c2b9850114ba05a210e291a670621f570842f,14,3,2,14826,,,0,"docs: Octavia OVN provider

Change-Id: Ib3dba0a3741d918a189edfa43041207a59392f07
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/98/864398/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/source/reference/networking/octavia.rst']",2,82a25a82281226e80c4167d267547f1c5026b7ca,,"Octavia provides load balancing as a service. This guide covers two providers: * Amphora * OVNAmphora provider ================ This section covers configuration of Octavia for the Amphora driver. See the :octavia-doc:`Octavia documentation <>` for full details. The :octavia-doc:`installation guide <install/install-ubuntu.html>` is a useful reference. ------------~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~---------------------------------------------------------------------------------------------------------~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~--------------------------------------~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~------------------~~~~~~~~~~~~~~~~~----------------------------- OVN provider ============ This section covers configuration of Octavia for the OVN driver. See the :octavia-doc:`Octavia documentation <>` and :ovn-octavia-provider-doc:`OVN Octavia provider documentation <>` for full details. To enable the OVN provider, set the following options in ``globals.yml``: .. code-block:: yaml octavia_auto_configure: ""no"" octavia_provider_drivers: ""ovn:OVN provider"" octavia_provider_agents: ""ovn""",Octavia provides load balancing as a service. This guide covers configuration of Octavia for the Amphora driver. See the :octavia-doc:`Octavia documentation <>` for full details. The :octavia-doc:`installation guide <install/install-ubuntu.html>` is a useful reference.============-----------------------------------------------------------------------------------------=========================================================================================================----------------------------------------------------======================================--------------------------------------------------------------------------------==================-----------------=============================,47,23
openstack%2Fcharm-horizon-k8s~main~I3dafeff3332202d6c91d8e477d5a40ce98131017,openstack/charm-horizon-k8s,main,I3dafeff3332202d6c91d8e477d5a40ce98131017,Clean active status for unit,MERGED,2022-11-14 11:17:57.000000000,2022-11-14 12:58:08.000000000,2022-11-14 12:17:46.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-14 11:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/3d092c2b6f55513826c890593b6bd0eb9edca718', 'message': 'Clean active status\n\nEnsure that no unit level message is set when setting the\nunit status.  This allows deployment tooling to correctly\nassess when deployment is complete.\n\nChange-Id: I3dafeff3332202d6c91d8e477d5a40ce98131017\n'}, {'number': 2, 'created': '2022-11-14 11:35:58.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/a9c0abb9bcd27a17c7d6382e561b55f7e5b5dbd1', 'message': 'Clean active status for unit\n\nEnsure that no unit level message is set when setting the\nunit status.  This allows deployment tooling to correctly\nassess when deployment is complete.\n\nProvide the URL for horizon as part of the application\nstatus message.\n\nChange-Id: I3dafeff3332202d6c91d8e477d5a40ce98131017\n'}]",0,864401,a9c0abb9bcd27a17c7d6382e561b55f7e5b5dbd1,10,3,2,935,,,0,"Clean active status for unit

Ensure that no unit level message is set when setting the
unit status.  This allows deployment tooling to correctly
assess when deployment is complete.

Provide the URL for horizon as part of the application
status message.

Change-Id: I3dafeff3332202d6c91d8e477d5a40ce98131017
",git fetch https://review.opendev.org/openstack/charm-horizon-k8s refs/changes/01/864401/2 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,3d092c2b6f55513826c890593b6bd0eb9edca718,clear-active-status," self.status.set(ops.model.ActiveStatus(""""))", self.status.set(ops.model.ActiveStatus(self.ingress_public.url)),1,1
openstack%2Fneutron~stable%2Fussuri~I50f07d41428e57e6bed9be16980a6c605b7d130e,openstack/neutron,stable/ussuri,I50f07d41428e57e6bed9be16980a6c605b7d130e,Allow shared net to be added on router,MERGED,2022-11-07 15:28:05.000000000,2022-11-14 12:52:57.000000000,2022-11-14 12:51:48.000000000,"[{'_account_id': 11583}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e77f83218f8f50c95137b90e7c0ef16dc2c5b3a4', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}, {'number': 2, 'created': '2022-11-08 08:51:51.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b52a8efb1dc2dd6cc336ea2ff1c62aab3d0e3e1', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nConflicts:\n    neutron/db/l3_db.py\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)\n'}]",2,863889,4b52a8efb1dc2dd6cc336ea2ff1c62aab3d0e3e1,12,4,2,16688,,,0,"Allow shared net to be added on router

This will subnets from shared networks to be added on routers using:
$ openstack router add subnet router_id subnet_id

Without this, neutron user must use a multi-router solution, which is
not convenient at all.

Conflicts:
    neutron/db/l3_db.py

Closes-Bug: #1975603
Related-Bug: #1757482

Signed-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>
Change-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e
(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)
(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/863889/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,e77f83218f8f50c95137b90e7c0ef16dc2c5b3a4,bug/1975603,"from neutron.objects import network as network_obj # NOTE(amorin): check if network is RBAC or globaly shared # globaly shared --> disallow adding interface (see LP-1757482) # RBAC shared --> allow adding interface (see LP-1975603) elevated = context.elevated() with db_api.CONTEXT_READER.using(elevated): rbac_allowed_projects = network_obj.NetworkRBAC.get_projects( elevated, object_id=subnet['network_id'], action='access_as_shared', target_project=context.project_id) # Fail if the current project_id is NOT in the allowed # projects if context.project_id not in rbac_allowed_projects: msg = (_('Cannot add interface to router because subnet ' '%s is not owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)"," msg = (_('Cannot add interface to router because subnet %s is not ' 'owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)",40,3
openstack%2Fneutron~stable%2Ftrain~I50f07d41428e57e6bed9be16980a6c605b7d130e,openstack/neutron,stable/train,I50f07d41428e57e6bed9be16980a6c605b7d130e,Allow shared net to be added on router,MERGED,2022-11-07 15:28:20.000000000,2022-11-14 12:49:12.000000000,2022-11-14 12:48:03.000000000,"[{'_account_id': 11583}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e57922bf7f3f2c54ba5f2c075c7eaba2fc25c82', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}, {'number': 2, 'created': '2022-11-08 08:52:05.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5c973f62e35f6fb73b13cb3f8ebde793cffd62b', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nConflicts:\n    neutron/db/l3_db.py\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)\n'}]",2,863890,f5c973f62e35f6fb73b13cb3f8ebde793cffd62b,14,4,2,16688,,,0,"Allow shared net to be added on router

This will subnets from shared networks to be added on routers using:
$ openstack router add subnet router_id subnet_id

Without this, neutron user must use a multi-router solution, which is
not convenient at all.

Conflicts:
    neutron/db/l3_db.py

Closes-Bug: #1975603
Related-Bug: #1757482

Signed-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>
Change-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e
(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)
(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/863890/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,5e57922bf7f3f2c54ba5f2c075c7eaba2fc25c82,bug/1975603,"from neutron.objects import network as network_obj # NOTE(amorin): check if network is RBAC or globaly shared # globaly shared --> disallow adding interface (see LP-1757482) # RBAC shared --> allow adding interface (see LP-1975603) elevated = context.elevated() with db_api.CONTEXT_READER.using(elevated): rbac_allowed_projects = network_obj.NetworkRBAC.get_projects( elevated, object_id=subnet['network_id'], action='access_as_shared', target_project=context.project_id) # Fail if the current project_id is NOT in the allowed # projects if context.project_id not in rbac_allowed_projects: msg = (_('Cannot add interface to router because subnet ' '%s is not owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)"," msg = (_('Cannot add interface to router because subnet %s is not ' 'owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)",40,3
openstack%2Fovn-bgp-agent~master~Iba1a110bc4495a791b9a8b74b2a062a9ef95f501,openstack/ovn-bgp-agent,master,Iba1a110bc4495a791b9a8b74b2a062a9ef95f501,Fix KeyError at add_ip_route for provider vlan networks,MERGED,2022-11-11 11:22:27.000000000,2022-11-14 12:13:31.000000000,2022-11-14 12:13:31.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2022-11-11 11:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/72ce87d765331d0ac65d9515b6d7c81b384f7208', 'message': '[WIP] Fix KeyError at add_ip_route for provider vlan networks\n\nWhen a provider-vlan network is created, the ovn_bgp_agent\nsync function will make sure that a vlan device gets created to\nproperly inject the traffic into OVN Overlay.\n\nHowever, as the sync function runs periodically (by default every\n2 mins), there is a chance that the provider vlan network was\nrecently created, and when trying to expose routes for it that\nvlan device has not been created yet, throwing a KeyError\nexception\n\nChange-Id: Iba1a110bc4495a791b9a8b74b2a062a9ef95f501\n'}, {'number': 2, 'created': '2022-11-14 07:33:55.000000000', 'files': ['ovn_bgp_agent/tests/unit/utils/test_linux_net.py', 'ovn_bgp_agent/utils/linux_net.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/28636b3b1c9c31818952c745ed67a4f3857ca93c', 'message': 'Fix KeyError at add_ip_route for provider vlan networks\n\nWhen a provider-vlan network is created, the ovn_bgp_agent\nsync function will make sure that a vlan device gets created to\nproperly inject the traffic into OVN Overlay.\n\nHowever, as the sync function runs periodically (by default every\n2 mins), there is a chance that the provider vlan network was\nrecently created, and when trying to expose routes for it that\nvlan device has not been created yet, throwing a KeyError\nexception\n\nChange-Id: Iba1a110bc4495a791b9a8b74b2a062a9ef95f501\n'}]",2,864271,28636b3b1c9c31818952c745ed67a4f3857ca93c,9,3,2,23567,,,0,"Fix KeyError at add_ip_route for provider vlan networks

When a provider-vlan network is created, the ovn_bgp_agent
sync function will make sure that a vlan device gets created to
properly inject the traffic into OVN Overlay.

However, as the sync function runs periodically (by default every
2 mins), there is a chance that the provider vlan network was
recently created, and when trying to expose routes for it that
vlan device has not been created yet, throwing a KeyError
exception

Change-Id: Iba1a110bc4495a791b9a8b74b2a062a9ef95f501
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/71/864271/1 && git format-patch -1 --stdout FETCH_HEAD,['ovn_bgp_agent/utils/linux_net.py'],1,72ce87d765331d0ac65d9515b6d7c81b384f7208,," try: oif = ndb.interfaces[oif_name]['index'] except KeyError: # Most provider network was recently created an # there has not been a sync since then, therefore # the vlan device has not yet been created # Trying to create the device and retrying ensure_vlan_device_for_network(dev, vlan) oif = ndb.interfaces[oif_name]['index']", oif = ndb.interfaces[oif_name]['index'],9,1
openstack%2Fneutron~stable%2Fwallaby~Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00,openstack/neutron,stable/wallaby,Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00,Port provisioning should retry only for VM ports,MERGED,2022-11-04 11:09:31.000000000,2022-11-14 11:48:26.000000000,2022-11-14 11:47:09.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 11:09:31.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b1379391110756cbefe942d361da7438a9aa484', 'message': ""Port provisioning should retry only for VM ports\n\nThe port provisioning method ``Ml2Plugin._port_provisioned`` creates\nan active wait to provision a port if the port is unbound since [1].\nBut this active wait should consider only VM ports in the case of\nlive migration, as described in the LP bug [2]. This wait should\nnot consider auxiliary Neutron ports or baremetal ports (we don't\nlive-migrate then).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/855257\n[2]https://bugs.launchpad.net/neutron/+bug/1988199\n\nCloses-Bug: #1991092\nChange-Id: Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00\n(cherry picked from commit 21491efd9f8ce6df98cb58c26da7896d75cb4a8b)\n""}]",1,863620,5b1379391110756cbefe942d361da7438a9aa484,12,3,1,16688,,,0,"Port provisioning should retry only for VM ports

The port provisioning method ``Ml2Plugin._port_provisioned`` creates
an active wait to provision a port if the port is unbound since [1].
But this active wait should consider only VM ports in the case of
live migration, as described in the LP bug [2]. This wait should
not consider auxiliary Neutron ports or baremetal ports (we don't
live-migrate then).

[1]https://review.opendev.org/c/openstack/neutron/+/855257
[2]https://bugs.launchpad.net/neutron/+bug/1988199

Closes-Bug: #1991092
Change-Id: Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00
(cherry picked from commit 21491efd9f8ce6df98cb58c26da7896d75cb4a8b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/863620/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,5b1379391110756cbefe942d361da7438a9aa484,bug/1991092-stable/wallaby, owner = port.device_owner if (count == MAX_PROVISIONING_TRIES or not owner.startswith(const.DEVICE_OWNER_COMPUTE_PREFIX)):, if count == MAX_PROVISIONING_TRIES:,23,2
openstack%2Fneutron~stable%2Fxena~Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00,openstack/neutron,stable/xena,Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00,Port provisioning should retry only for VM ports,MERGED,2022-11-04 11:09:15.000000000,2022-11-14 11:48:22.000000000,2022-11-14 11:47:05.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 11:09:15.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2df23ac90dda51869f24c51b30b22ae4d61c229', 'message': ""Port provisioning should retry only for VM ports\n\nThe port provisioning method ``Ml2Plugin._port_provisioned`` creates\nan active wait to provision a port if the port is unbound since [1].\nBut this active wait should consider only VM ports in the case of\nlive migration, as described in the LP bug [2]. This wait should\nnot consider auxiliary Neutron ports or baremetal ports (we don't\nlive-migrate then).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/855257\n[2]https://bugs.launchpad.net/neutron/+bug/1988199\n\nCloses-Bug: #1991092\nChange-Id: Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00\n(cherry picked from commit 21491efd9f8ce6df98cb58c26da7896d75cb4a8b)\n""}]",1,863619,a2df23ac90dda51869f24c51b30b22ae4d61c229,12,3,1,16688,,,0,"Port provisioning should retry only for VM ports

The port provisioning method ``Ml2Plugin._port_provisioned`` creates
an active wait to provision a port if the port is unbound since [1].
But this active wait should consider only VM ports in the case of
live migration, as described in the LP bug [2]. This wait should
not consider auxiliary Neutron ports or baremetal ports (we don't
live-migrate then).

[1]https://review.opendev.org/c/openstack/neutron/+/855257
[2]https://bugs.launchpad.net/neutron/+bug/1988199

Closes-Bug: #1991092
Change-Id: Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00
(cherry picked from commit 21491efd9f8ce6df98cb58c26da7896d75cb4a8b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/863619/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,a2df23ac90dda51869f24c51b30b22ae4d61c229,bug/1991092-stable/xena, owner = port.device_owner if (count == MAX_PROVISIONING_TRIES or not owner.startswith(const.DEVICE_OWNER_COMPUTE_PREFIX)):, if count == MAX_PROVISIONING_TRIES:,23,2
openstack%2Fci-log-processing~master~Ia5a86eaef48732e952e39528d980d698b72f50a3,openstack/ci-log-processing,master,Ia5a86eaef48732e952e39528d980d698b72f50a3,Change setup.cfg variables,MERGED,2022-11-14 11:00:21.000000000,2022-11-14 11:22:40.000000000,2022-11-14 11:21:48.000000000,"[{'_account_id': 6889}, {'_account_id': 8367}, {'_account_id': 9311}, {'_account_id': 20676}, {'_account_id': 22348}, {'_account_id': 30674}]","[{'number': 1, 'created': '2022-11-14 11:00:21.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ci-log-processing/commit/ce7aba29a147a01a096766fae393776cd3dd9e75', 'message': 'Change setup.cfg variables\n\nThe metadata generation is failing due improper/missing values set\nin setup.cfg file.\n\nChange-Id: Ia5a86eaef48732e952e39528d980d698b72f50a3\n'}]",0,864400,ce7aba29a147a01a096766fae393776cd3dd9e75,8,6,1,20676,,,0,"Change setup.cfg variables

The metadata generation is failing due improper/missing values set
in setup.cfg file.

Change-Id: Ia5a86eaef48732e952e39528d980d698b72f50a3
",git fetch https://review.opendev.org/openstack/ci-log-processing refs/changes/00/864400/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ce7aba29a147a01a096766fae393776cd3dd9e75,,author_email = openstack-discuss@lists.openstack.org home_page = http://docs.openstack.org/infra/ci-log-processing,author-email = openstack-discuss@lists.openstack.org home-page = http://docs.openstack.org/infra/ci-log-processing,2,2
openstack%2Fneutron~stable%2Fzed~I7cec8b53e72e7abf34012906e6adfecf079525af,openstack/neutron,stable/zed,I7cec8b53e72e7abf34012906e6adfecf079525af,Check subnet overlapping after add router interface,MERGED,2022-11-02 11:06:58.000000000,2022-11-14 11:16:55.000000000,2022-11-14 11:15:48.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 32586}]","[{'number': 1, 'created': '2022-11-02 11:06:58.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/71801fba9143b4e341037695c9a95a6ddc722766', 'message': 'Check subnet overlapping after add router interface\n\nWhen simultaneous attempts are made to add an interface\nto the same router including overlapping networks in cidrs,\nboth attempts are successful. There is a check to avoid this\noverlap but is performed when creating the network interface\nand it is done over the ports already attached to the router,\nso at this moment the check is not able to detect the\noverlapping. Furthermore, the create_port operation over the\nML2 plugin  must be executed in isolated transactions, so\ntrying to control the execution context or adding additional\nsteps to the transaction is not feasible.\n\nThis patch checks once the RouterPort is created on the\nneutron database if there is more than one overlapping port,\ntriggering in that case the exception that will remove the\nthe culprit of overlapping.\n\nCloses-Bug: #1987666\nChange-Id: I7cec8b53e72e7abf34012906e6adfecf079525af\n(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n'}]",5,863271,71801fba9143b4e341037695c9a95a6ddc722766,29,4,1,8213,,,0,"Check subnet overlapping after add router interface

When simultaneous attempts are made to add an interface
to the same router including overlapping networks in cidrs,
both attempts are successful. There is a check to avoid this
overlap but is performed when creating the network interface
and it is done over the ports already attached to the router,
so at this moment the check is not able to detect the
overlapping. Furthermore, the create_port operation over the
ML2 plugin  must be executed in isolated transactions, so
trying to control the execution context or adding additional
steps to the transaction is not feasible.

This patch checks once the RouterPort is created on the
neutron database if there is more than one overlapping port,
triggering in that case the exception that will remove the
the culprit of overlapping.

Closes-Bug: #1987666
Change-Id: I7cec8b53e72e7abf34012906e6adfecf079525af
(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/863271/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py']",3,71801fba9143b4e341037695c9a95a6ddc722766,bug/1987666-stable/zed," def test__raise_on_subnets_overlap_does_not_raise(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/24'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.2.0.0/24'}] self.db._raise_on_subnets_overlap(subnets[0], subnets[1]) def test__raise_on_subnets_overlap_raises(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/20'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.1.10.0/24'}] self.assertRaises( n_exc.BadRequest, self.db._raise_on_subnets_overlap, subnets[0], subnets[1]) def test__validate_one_router_ipv6_port_per_network(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network2', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_mix_ipv4_ipv6(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '10.1.10.0/24').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_failed(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.assertRaises( n_exc.BadRequest, self.db._validate_one_router_ipv6_port_per_network, router, new_port) @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_port_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') ipa = str(netaddr.IPNetwork(subnet['subnet']['cidr']).ip + 10) fixed_ips = [{'subnet_id': subnet['subnet']['id'], 'ip_address': ipa}] port = self.create_port( network2['network']['id'], {'fixed_ips': fixed_ips}) self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': port['port']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': self.ports[0]['port']['id']}) mock_raise_on_subnets_overlap.assert_called_once() @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_subnet_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': subnet['subnet']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': self.subnets[0]['subnet']['id']}) mock_raise_on_subnets_overlap.assert_called_once() ",,246,30
openstack%2Fmanila~stable%2Fyoga~Ic3d3d32c3f7d624846f644601ee1ca01a103882a,openstack/manila,stable/yoga,Ic3d3d32c3f7d624846f644601ee1ca01a103882a,Fix misuse of assertTrue,MERGED,2022-11-02 11:46:45.000000000,2022-11-14 11:03:51.000000000,2022-11-14 11:02:41.000000000,"[{'_account_id': 7634}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-02 11:46:45.000000000', 'files': ['manila/tests/scheduler/filters/test_json.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/74928a3afdb26205069c9cbcc0ea52cceaf560db', 'message': 'Fix misuse of assertTrue\n\nChange-Id: Ic3d3d32c3f7d624846f644601ee1ca01a103882a\nCloses-Bug: 1989250\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit c8c4989d43a317fe485ec1796fabb3f49dd6e758)\n'}]",1,863274,74928a3afdb26205069c9cbcc0ea52cceaf560db,11,3,1,35453,,,0,"Fix misuse of assertTrue

Change-Id: Ic3d3d32c3f7d624846f644601ee1ca01a103882a
Closes-Bug: 1989250
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
(cherry picked from commit c8c4989d43a317fe485ec1796fabb3f49dd6e758)
",git fetch https://review.opendev.org/openstack/manila refs/changes/74/863274/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/scheduler/filters/test_json.py', 'manila/tests/share/drivers/netapp/dataontap/cluster_mode/test_lib_base.py']",2,74928a3afdb26205069c9cbcc0ea52cceaf560db,bug/1989250, self.library._client.is_nve_supported.return_value = True self.library._client.features.FLEXVOL_ENCRYPTION = True self.assertTrue(self.library._cluster_info['nve_support'])," self.assertTrue(self.library._cluster_info['nve_support'], fake.CLUSTER_NODES)",4,3
openstack%2Fovn-bgp-agent~master~Ib7731fdc420f9a0fafdb5e75b5708863411f871c,openstack/ovn-bgp-agent,master,Ib7731fdc420f9a0fafdb5e75b5708863411f871c,Fix loadbalancer cascade deletion,MERGED,2022-11-14 08:29:15.000000000,2022-11-14 10:40:08.000000000,2022-11-14 10:40:08.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 23804}]","[{'number': 1, 'created': '2022-11-14 08:29:15.000000000', 'files': ['ovn_bgp_agent/tests/unit/drivers/openstack/watchers/test_bgp_watcher.py', 'ovn_bgp_agent/drivers/openstack/watchers/bgp_watcher.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/92abdb74dc4754503259f241e928816365b7ee24', 'message': 'Fix loadbalancer cascade deletion\n\nThe cascade deletion of loadbalancer triggers the DELETE event\nwithout informaiont about the old.datapath and was making the\nwatcher to fail (AttributeError exception).\n\nThis patch fixes it, as this information is not really needed for\nthe deletion event\n\nChange-Id: Ib7731fdc420f9a0fafdb5e75b5708863411f871c\n'}]",3,864278,92abdb74dc4754503259f241e928816365b7ee24,8,4,1,23567,,,0,"Fix loadbalancer cascade deletion

The cascade deletion of loadbalancer triggers the DELETE event
without informaiont about the old.datapath and was making the
watcher to fail (AttributeError exception).

This patch fixes it, as this information is not really needed for
the deletion event

Change-Id: Ib7731fdc420f9a0fafdb5e75b5708863411f871c
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/78/864278/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/tests/unit/drivers/openstack/watchers/test_bgp_watcher.py', 'ovn_bgp_agent/drivers/openstack/watchers/bgp_watcher.py']",2,92abdb74dc4754503259f241e928816365b7ee24,, if event == self.ROW_DELETE: match_subnets_datapaths = [ subnet_dp for subnet_dp in cr_lrp_info[ 'subnets_datapath'].values() if subnet_dp in row.datapaths] else: # old.datapath needed for members deletion on different subnet match_subnets_datapaths = [ subnet_dp for subnet_dp in cr_lrp_info[ 'subnets_datapath'].values() if (subnet_dp in row.datapaths or subnet_dp in old.datapaths)], match_subnets_datapaths = [ subnet_dp for subnet_dp in cr_lrp_info[ 'subnets_datapath'].values() if subnet_dp in row.datapaths or subnet_dp in old.datapaths],21,4
openstack%2Fcharm-horizon-k8s~main~Id1e63599618a14e7865a2159020595f433f65f70,openstack/charm-horizon-k8s,main,Id1e63599618a14e7865a2159020595f433f65f70,Ensure use of compound status in parent class,MERGED,2022-11-14 09:09:52.000000000,2022-11-14 10:38:34.000000000,2022-11-14 09:52:23.000000000,"[{'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-14 09:09:52.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/210795fe69beed58a6c89f3803fbb0d5adcfe3aa', 'message': 'Ensure use of compound status in parent class\n\nUse the compound status object from the parent class rather than\na direct set of the status from the concrete implementation in\nthis charm.\n\nChange-Id: Id1e63599618a14e7865a2159020595f433f65f70\n'}]",1,864394,210795fe69beed58a6c89f3803fbb0d5adcfe3aa,8,3,1,935,,,0,"Ensure use of compound status in parent class

Use the compound status object from the parent class rather than
a direct set of the status from the concrete implementation in
this charm.

Change-Id: Id1e63599618a14e7865a2159020595f433f65f70
",git fetch https://review.opendev.org/openstack/charm-horizon-k8s refs/changes/94/864394/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,210795fe69beed58a6c89f3803fbb0d5adcfe3aa,status-fix, self.status.set(ops.model.ActiveStatus(self.ingress_public.url)), self.unit.status = ops.model.ActiveStatus(self.ingress_public.url),1,1
openstack%2Fvenus~master~I7475fdec93262e0b9783526a90e1c706cffc00d5,openstack/venus,master,I7475fdec93262e0b9783526a90e1c706cffc00d5,Add a unit test case 'invalid_index_type'.,MERGED,2022-11-14 07:58:03.000000000,2022-11-14 10:32:58.000000000,2022-11-14 10:31:20.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2022-11-14 07:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/a045a7967733a6d314b93ae5a9309091bb013856', 'message': ""Add a unit test case 'invalid_index_type'.\n\nChange-Id: I7475fdec93262e0b9783526a90e1c706cffc00d5\n""}, {'number': 2, 'created': '2022-11-14 08:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/9e8de62f35eb26882f4c9098412a76bccccc03fd', 'message': ""Add a unit test case 'invalid_index_type'.\n\nChange-Id: I7475fdec93262e0b9783526a90e1c706cffc00d5\n""}, {'number': 3, 'created': '2022-11-14 08:14:39.000000000', 'files': ['venus/tests/unit/api/test_search_controller.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/ab0d345de37ee0749ffbfc0eb0287a45c83878df', 'message': ""Add a unit test case 'invalid_index_type'.\n\nChange-Id: I7475fdec93262e0b9783526a90e1c706cffc00d5\n""}]",2,864277,ab0d345de37ee0749ffbfc0eb0287a45c83878df,13,3,3,34375,,,0,"Add a unit test case 'invalid_index_type'.

Change-Id: I7475fdec93262e0b9783526a90e1c706cffc00d5
",git fetch https://review.opendev.org/openstack/venus refs/changes/77/864277/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/tests/unit/api/test_search_controller.py'],1,a045a7967733a6d314b93ae5a9309091bb013856,," @mock.patch('venus.modules.search.action.SearchCore.logs') def test_search_logs_invalid_index_type(self, action_logs): ret = {""code"": 0, ""msg"": ""no data, no index""} action_logs.return_value = ret req = fakes.HTTPRequest.blank('?index_type=None&?start_time=2&' '?end_time=1&?page_num=10&?page_size=10') res1 = self.controller.search_logs(req) self.assertEqual(ret, res1)",,9,0
openstack%2Fvenus~master~If07af5fe90381deb830f6ac9b5c674b2ad7a7899,openstack/venus,master,If07af5fe90381deb830f6ac9b5c674b2ad7a7899,Supplement a unit test case 'valid_index_type'.,MERGED,2022-11-14 06:31:32.000000000,2022-11-14 10:32:17.000000000,2022-11-14 10:31:19.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2022-11-14 06:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/d7920b70fcebd288b315b4897e5aaf5663d1cca3', 'message': ""Supplement a unit test case 'valid_index_type'.\n\nChange-Id: If07af5fe90381deb830f6ac9b5c674b2ad7a7899\n""}, {'number': 2, 'created': '2022-11-14 06:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/f7508b7551775a9e49fe4e66a7c41bd6b930fb66', 'message': ""Supplement a unit test case 'valid_index_type'.\n\nChange-Id: If07af5fe90381deb830f6ac9b5c674b2ad7a7899\n""}, {'number': 3, 'created': '2022-11-14 07:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/68b4aaf02f3290ce78ac540c9175ba99cda311b9', 'message': ""Supplement a unit test case 'valid_index_type'.\n\nChange-Id: If07af5fe90381deb830f6ac9b5c674b2ad7a7899\n""}, {'number': 4, 'created': '2022-11-14 08:06:31.000000000', 'files': ['venus/tests/unit/api/test_search_controller.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/9adc236bc1302596912426f3bf6af3f6521d509c', 'message': ""Supplement a unit test case 'valid_index_type'.\n\nChange-Id: If07af5fe90381deb830f6ac9b5c674b2ad7a7899\n""}]",3,864276,9adc236bc1302596912426f3bf6af3f6521d509c,16,3,4,34375,,,0,"Supplement a unit test case 'valid_index_type'.

Change-Id: If07af5fe90381deb830f6ac9b5c674b2ad7a7899
",git fetch https://review.opendev.org/openstack/venus refs/changes/76/864276/1 && git format-patch -1 --stdout FETCH_HEAD,"['main.py', 'venus/tests/unit/api/test_search_controller.py']",2,d7920b70fcebd288b315b4897e5aaf5663d1cca3,," @mock.patch('venus.modules.search.action.SearchCore.logs') def test_search_logs_valid_index_type(self, action_params): ret = {""code"": -1, ""msg"": ""invalid param""} action_params.return_value = ret req = fakes.HTTPRequest.blank('?index_type=None') res1 = self.controller.search_logs(req) self.assertEqual(ret, res1)",,24,0
openstack%2Ftripleo-ansible~master~I49d391180c9877e2a74e9ab6853a17360c72941a,openstack/tripleo-ansible,master,I49d391180c9877e2a74e9ab6853a17360c72941a,Support setting ovn-ofctrl-wait-before-clear,MERGED,2022-11-01 18:21:25.000000000,2022-11-14 10:25:30.000000000,2022-11-07 21:11:32.000000000,"[{'_account_id': 8449}, {'_account_id': 8655}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-01 18:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e67e02ecd94a67b0bdd1ca896e4f9ff50e4855a0', 'message': 'Support setting ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: I49d391180c9877e2a74e9ab6853a17360c72941a\n'}, {'number': 2, 'created': '2022-11-04 13:39:09.000000000', 'files': ['tripleo_ansible/roles/tripleo_ovn/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/567a47ef908482ee569ea6ebfd372e25e650faf1', 'message': 'Support setting ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: I49d391180c9877e2a74e9ab6853a17360c72941a\n'}]",8,863172,567a47ef908482ee569ea6ebfd372e25e650faf1,25,5,2,5756,,,0,"Support setting ovn-ofctrl-wait-before-clear

Support was added for this option [1] to avoid dataplane downtime
during ovn upgrades where schema changes have happened. This
adds the ability for us to configure it.

[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/

Change-Id: I49d391180c9877e2a74e9ab6853a17360c72941a
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/72/863172/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_ovn/defaults/main.yml'],1,e67e02ecd94a67b0bdd1ca896e4f9ff50e4855a0,ovn-ofctrl-wait-before-clear,"tripleo_ovn_ofctrl_wait_before_clear: 8000 ovn-ofctrl-wait-before-clear: ""{{ tripleo_ovn_ofctrl_wait_before_clear }}""",,2,0
openstack%2Fcharm-neutron-api~master~Idfc9158f07ac09ba9cb29b71678185489c707d79,openstack/charm-neutron-api,master,Idfc9158f07ac09ba9cb29b71678185489c707d79,Try out DPE edge charms for mysql{-router},NEW,2022-10-28 06:49:26.000000000,2022-11-14 10:14:30.000000000,,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-28 06:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/45e253cce1920d0cb2e6d0fa9cc5c3e404b09bdb', 'message': 'Try out DPE edge charms for mysql{-router}\n\nUpdate jammy-yoga bundle to see how this all hangs together.\n\nChange-Id: Idfc9158f07ac09ba9cb29b71678185489c707d79\n'}, {'number': 2, 'created': '2022-10-28 06:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/2c03e4107f805e2e58bd55046162264f5d1b7cf2', 'message': 'Try out DPE edge charms for mysql{-router}\n\nUpdate jammy-yoga bundle to see how this all hangs together.\n\nChange-Id: Idfc9158f07ac09ba9cb29b71678185489c707d79\n'}, {'number': 3, 'created': '2022-10-28 07:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/33287f9f7e6fb27009e88c0f45c85df15fbbfec4', 'message': 'Try out DPE edge charms for mysql{-router}\n\nUpdate jammy-yoga bundle to see how this all hangs together.\n\nChange-Id: Idfc9158f07ac09ba9cb29b71678185489c707d79\n'}, {'number': 4, 'created': '2022-10-28 08:06:01.000000000', 'files': ['tests/bundles/jammy-yoga.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/806bb4a7e04808ccb8ec04c887bc10c52670f9a7', 'message': 'Try out DPE edge charms for mysql{-router}\n\nUpdate jammy-yoga bundle to see how this all hangs together.\n\nChange-Id: Idfc9158f07ac09ba9cb29b71678185489c707d79\n'}]",2,862861,806bb4a7e04808ccb8ec04c887bc10c52670f9a7,12,3,4,935,,,0,"Try out DPE edge charms for mysql{-router}

Update jammy-yoga bundle to see how this all hangs together.

Change-Id: Idfc9158f07ac09ba9cb29b71678185489c707d79
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/61/862861/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/bundles/jammy-yoga.yaml'],1,45e253cce1920d0cb2e6d0fa9cc5c3e404b09bdb,try-out-dpe, channel: dpe/edge channel: dpe/edge mysql-innodb-cluster: charm: ch:mysql, channel: latest/edge channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster options: source: *openstack-origin,3,5
openstack%2Foctavia~stable%2Fxena~Icbbab19fabc90f4f4ea63a0ffdf75bb00144b745,openstack/octavia,stable/xena,Icbbab19fabc90f4f4ea63a0ffdf75bb00144b745,Change FIPS jobs to centos-9-stream,MERGED,2022-09-07 11:30:45.000000000,2022-11-14 09:59:06.000000000,2022-11-14 09:57:22.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 34429}]","[{'number': 1, 'created': '2022-09-07 11:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/876b1ad1eb9d877ffb8b39f61a4337b2cd4da433', 'message': 'Change FIPS jobs to centos-9-stream\n\nIt also fixed the missing nslookup_target variable for ansible.\n\nChange-Id: Icbbab19fabc90f4f4ea63a0ffdf75bb00144b745\n(cherry picked from commit 6d7464303ee554de2a598502486574e2a9a4e3f7)\n(cherry picked from commit ef76cbf7dec92071f04f57f117a2d852218f9071)\n'}, {'number': 2, 'created': '2022-09-14 08:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2b09022d64a4e72899b40da04fe1b753098f4ba9', 'message': 'Change FIPS jobs to centos-9-stream\n\nIt also fixed the missing nslookup_target variable for ansible.\n\nChange-Id: Icbbab19fabc90f4f4ea63a0ffdf75bb00144b745\n(cherry picked from commit 6d7464303ee554de2a598502486574e2a9a4e3f7)\n(cherry picked from commit ef76cbf7dec92071f04f57f117a2d852218f9071)\n'}, {'number': 3, 'created': '2022-10-04 15:04:14.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/980b8e79cd6261c74e79026736f9ad5fd79ce35d', 'message': 'Change FIPS jobs to centos-9-stream\n\nIt also fixed the missing nslookup_target variable for ansible.\n\nChange-Id: Icbbab19fabc90f4f4ea63a0ffdf75bb00144b745\n(cherry picked from commit 6d7464303ee554de2a598502486574e2a9a4e3f7)\n(cherry picked from commit ef76cbf7dec92071f04f57f117a2d852218f9071)\n'}]",1,856197,980b8e79cd6261c74e79026736f9ad5fd79ce35d,14,4,3,34120,,,0,"Change FIPS jobs to centos-9-stream

It also fixed the missing nslookup_target variable for ansible.

Change-Id: Icbbab19fabc90f4f4ea63a0ffdf75bb00144b745
(cherry picked from commit 6d7464303ee554de2a598502486574e2a9a4e3f7)
(cherry picked from commit ef76cbf7dec92071f04f57f117a2d852218f9071)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/97/856197/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,876b1ad1eb9d877ffb8b39f61a4337b2cd4da433,fips-compatibility-cs9-stable/yoga-stable/xena, nodeset: octavia-single-node-centos-9-stream Functional testing for a FIPS enabled Centos 9 system. nslookup_target: 'opendev.org' OCTAVIA_AMP_DISTRIBUTION_RELEASE_ID: 9-stream nodeset: octavia-single-node-centos-9-stream Functional testing for a FIPS enabled Centos 9 system nslookup_target: 'opendev.org' OCTAVIA_AMP_DISTRIBUTION_RELEASE_ID: 9-stream," nodeset: octavia-single-node-centos-8-stream Functional testing for a FIPS enabled Centos 8 system. OCTAVIA_AMP_DISTRIBUTION_RELEASE_ID: 8-stream devstack_local_conf: test-config: ""$TEMPEST_CONFIG"": validation: ssh_key_type: 'ecdsa' nodeset: octavia-single-node-centos-8-stream Functional testing for a FIPS enabled Centos 8 system OCTAVIA_AMP_DISTRIBUTION_RELEASE_ID: 8-stream devstack_local_conf: test-config: ""$TEMPEST_CONFIG"": validation: ssh_key_type: 'ecdsa'",8,16
openstack%2Fdevstack~master~I0fc6a8e66e365ac49c6c7ceb4c71c68714b9f541,openstack/devstack,master,I0fc6a8e66e365ac49c6c7ceb4c71c68714b9f541,Fix dbcounter install on Debian Bullseye,MERGED,2022-11-09 20:02:53.000000000,2022-11-14 08:41:29.000000000,2022-11-14 08:40:26.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 20:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2e135711b90efe0d13901b732757f220e6cd42d0', 'message': ""Fix dbcounter install on Debian Bullseye\n\nThe dbcounter install on Debian Bullseye is broken in a really fun way.\nThe problem is that we end up mixing pypi openssl and distro\ncryptography under pip and those two versions of libraries are not\ncompatible.\n\nThe reason this happens is that debian's pip package debundles the pip\ndeps. This splits them out into /usr/share/python-wheels and it will\nprefer distro versions of libraries over pypi installed versions of\nlibraries. But if a pypi version is installed and a distro version is\nnot then the pypi version is used. If the pypi version of library A does\nnot work with distro version of library B then debundled pip breaks.\nThis has happened with crypytography and pyOpenSSL.\n\nThis happens because urllib3 (a debundled pip dep) appears to use\npyopenssl conditionally. Novnc depends on python3-cryptography, and\nopenstack depends on cryptogrpahy from pypi ensuring we get both a\ndistro and a pypi version installed. However, pyOpenSSL is only pulled\nin from pypi via openstack deps. This leaves debundled urllib3\nattempting to use pypi pyOpenSSL with distro cryptography and that combo\nisn't valid due to an interface change.\n\nTo fix this we install python3-openssl ensuring that debundled pip will\nuse distro pyOpenSSL with distro cryptography making everything happy\nagain.\n\nChange-Id: I0fc6a8e66e365ac49c6c7ceb4c71c68714b9f541\n""}, {'number': 2, 'created': '2022-11-09 21:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8d5d9abe3cd7c526e2182dc6b9a2c05d1677870e', 'message': ""Fix dbcounter install on Debian Bullseye\n\nThe dbcounter install on Debian Bullseye is broken in a really fun way.\nThe problem is that we end up mixing pypi openssl and distro\ncryptography under pip and those two versions of libraries are not\ncompatible.\n\nThe reason this happens is that debian's pip package debundles the pip\ndeps. This splits them out into /usr/share/python-wheels and it will\nprefer distro versions of libraries over pypi installed versions of\nlibraries. But if a pypi version is installed and a distro version is\nnot then the pypi version is used. If the pypi version of library A does\nnot work with distro version of library B then debundled pip breaks.\nThis has happened with crypytography and pyOpenSSL.\n\nThis happens because urllib3 (a debundled pip dep) appears to use\npyopenssl conditionally. Novnc depends on python3-cryptography, and\nopenstack depends on cryptogrpahy from pypi ensuring we get both a\ndistro and a pypi version installed. However, pyOpenSSL is only pulled\nin from pypi via openstack deps. This leaves debundled urllib3\nattempting to use pypi pyOpenSSL with distro cryptography and that combo\nisn't valid due to an interface change.\n\nTo fix this we install python3-openssl ensuring that debundled pip will\nuse distro pyOpenSSL with distro cryptography making everything happy\nagain.\n\nChange-Id: I0fc6a8e66e365ac49c6c7ceb4c71c68714b9f541\n""}, {'number': 3, 'created': '2022-11-10 17:25:34.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/97b2a51d6beee4fd58b93027d823d6fd90f5c11f', 'message': ""Fix dbcounter install on Debian Bullseye\n\nThe dbcounter install on Debian Bullseye is broken in a really fun way.\nThe problem is that we end up mixing pypi openssl and distro\ncryptography under pip and those two versions of libraries are not\ncompatible.\n\nThe reason this happens is that debian's pip package debundles the pip\ndeps. This splits them out into /usr/share/python-wheels and it will\nprefer distro versions of libraries over pypi installed versions of\nlibraries. But if a pypi version is installed and a distro version is\nnot then the pypi version is used. If the pypi version of library A does\nnot work with distro version of library B then debundled pip breaks.\nThis has happened with crypytography and pyOpenSSL.\n\nThis happens because urllib3 (a debundled pip dep) appears to use\npyopenssl conditionally. Novnc depends on python3-cryptography, and\nopenstack depends on cryptogrpahy from pypi ensuring we get both a\ndistro and a pypi version installed. However, pyOpenSSL is only pulled\nin from pypi via openstack deps. This leaves debundled urllib3\nattempting to use pypi pyOpenSSL with distro cryptography and that combo\nisn't valid due to an interface change.\n\nTo fix this we install python3-openssl ensuring that debundled pip will\nuse distro pyOpenSSL with distro cryptography making everything happy\nagain. But we only do this when we install novnc as novnc is what pulls\nin distro cryptography in the first place. We can't simply install\npython3-openssl on all debuntu platforms because this breaks Ubuntu\nFocal in the other direction. On Ubuntu focal distro pip uses distro\npyOpenSSL when no pypi pyOpenSSl is installed (prior to keystone\ninstall) and is not compatible with pypi cryptography.\n\nHonestly, this whole intersection between distro and pypi installs of\ncryptography and pyOpenSSL could probably be made cleaner. One option\nwould be for us to always install the constraints version of both\npackages from pypi and the distro pacakges very early in the devstack\nrun. But that seems far more complicated so I'm not attempting that\nhere.\n\nChange-Id: I0fc6a8e66e365ac49c6c7ceb4c71c68714b9f541\n""}]",1,864142,97b2a51d6beee4fd58b93027d823d6fd90f5c11f,10,2,3,4146,,,0,"Fix dbcounter install on Debian Bullseye

The dbcounter install on Debian Bullseye is broken in a really fun way.
The problem is that we end up mixing pypi openssl and distro
cryptography under pip and those two versions of libraries are not
compatible.

The reason this happens is that debian's pip package debundles the pip
deps. This splits them out into /usr/share/python-wheels and it will
prefer distro versions of libraries over pypi installed versions of
libraries. But if a pypi version is installed and a distro version is
not then the pypi version is used. If the pypi version of library A does
not work with distro version of library B then debundled pip breaks.
This has happened with crypytography and pyOpenSSL.

This happens because urllib3 (a debundled pip dep) appears to use
pyopenssl conditionally. Novnc depends on python3-cryptography, and
openstack depends on cryptogrpahy from pypi ensuring we get both a
distro and a pypi version installed. However, pyOpenSSL is only pulled
in from pypi via openstack deps. This leaves debundled urllib3
attempting to use pypi pyOpenSSL with distro cryptography and that combo
isn't valid due to an interface change.

To fix this we install python3-openssl ensuring that debundled pip will
use distro pyOpenSSL with distro cryptography making everything happy
again. But we only do this when we install novnc as novnc is what pulls
in distro cryptography in the first place. We can't simply install
python3-openssl on all debuntu platforms because this breaks Ubuntu
Focal in the other direction. On Ubuntu focal distro pip uses distro
pyOpenSSL when no pypi pyOpenSSl is installed (prior to keystone
install) and is not compatible with pypi cryptography.

Honestly, this whole intersection between distro and pypi installs of
cryptography and pyOpenSSL could probably be made cleaner. One option
would be for us to always install the constraints version of both
packages from pypi and the distro pacakges very early in the devstack
run. But that seems far more complicated so I'm not attempting that
here.

Change-Id: I0fc6a8e66e365ac49c6c7ceb4c71c68714b9f541
",git fetch https://review.opendev.org/openstack/devstack refs/changes/42/864142/2 && git format-patch -1 --stdout FETCH_HEAD,['files/debs/general'],1,2e135711b90efe0d13901b732757f220e6cd42d0,fix-bullseye,"# The reason for python3-openssl is somewhat circuitous and convoluted. # Debian debundles pip's dependencies. By default this does not include # pyopenssl or cryptography. However, openstack depends on both pyopenssl # and cryptography which means they both get installed via pypi. Novnc # depends on the python3-cryptography distro package. The end results is # we get cryotography installed via both distro package and pypi and # openssl only via pypi. When pip uses debundled urllib3 it finds pypi # openssl and distro cryptography which are not compatible with each other # causing pip installs to fail. If we install python3-openssl then debundled # pip finds distro versions of both openssl and cryptography and pip works. python3-openssl",,11,0
openstack%2Ftripleo-ansible~master~If86a9843e548293084201c5ed21ebe7b68baee41,openstack/tripleo-ansible,master,If86a9843e548293084201c5ed21ebe7b68baee41,tripleo_boostrap: Fix undefined .rc attribute,ABANDONED,2022-11-14 08:17:53.000000000,2022-11-14 08:39:05.000000000,,[],"[{'number': 1, 'created': '2022-11-14 08:17:53.000000000', 'files': ['tripleo_ansible/roles/tripleo_bootstrap/tasks/packages.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/db6aac9dcdedb0a087a0f0e28b1b7d356c3aaa8e', 'message': 'tripleo_boostrap: Fix undefined .rc attribute\n\nThis change fixes the following error found in the latest CI run with\nAnsible 2.14.\n\n```\nDeploy required packages to bootstrap TripleO | standalone |\nerror={""msg"": ""The conditional check \'rpm_query_result.rc > 0\' failed.\nThe error was: error while evaluating conditional (rpm_query_result.rc\n> 0): \'dict object\' has no attribute \'rc\'. ...}\n```\n\nChange-Id: If86a9843e548293084201c5ed21ebe7b68baee41\n'}]",0,864390,db6aac9dcdedb0a087a0f0e28b1b7d356c3aaa8e,2,0,1,9816,,,0,"tripleo_boostrap: Fix undefined .rc attribute

This change fixes the following error found in the latest CI run with
Ansible 2.14.

```
Deploy required packages to bootstrap TripleO | standalone |
error={""msg"": ""The conditional check 'rpm_query_result.rc > 0' failed.
The error was: error while evaluating conditional (rpm_query_result.rc
> 0): 'dict object' has no attribute 'rc'. ...}
```

Change-Id: If86a9843e548293084201c5ed21ebe7b68baee41
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/90/864390/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_bootstrap/tasks/packages.yml'],1,db6aac9dcdedb0a087a0f0e28b1b7d356c3aaa8e,, - (rpm_query_result is not defined) or ((rpm_query_result.rc | int) > 0), - rpm_query_result.rc > 0,1,1
openstack%2Fopenstacksdk~master~I87cf7e7378b7fe6276b521be362f3e5d51427c00,openstack/openstacksdk,master,I87cf7e7378b7fe6276b521be362f3e5d51427c00,Accept queries when listing migrations,MERGED,2022-10-26 02:07:51.000000000,2022-11-14 07:49:50.000000000,2022-11-14 07:48:49.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32238}]","[{'number': 1, 'created': '2022-10-26 02:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/78a80b84f3740c1a8afb48b076c1dd05c507b5fb', 'message': 'Accept queries when listing migrations\n\nChange the migration() function in the compute proxy to accept query\nparameters as kwargs.\n\nChange-Id: I87cf7e7378b7fe6276b521be362f3e5d51427c00\n'}, {'number': 2, 'created': '2022-10-29 00:58:51.000000000', 'files': ['openstack/tests/unit/compute/v2/test_proxy.py', 'openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/19012058a3d78b490e4543cc5c71eb54386d16cf', 'message': 'Accept queries when listing migrations\n\nChange the migration() function in the compute proxy to accept query\nparameters as kwargs.\n\nChange-Id: I87cf7e7378b7fe6276b521be362f3e5d51427c00\n'}]",0,862664,19012058a3d78b490e4543cc5c71eb54386d16cf,11,3,2,35355,,,0,"Accept queries when listing migrations

Change the migration() function in the compute proxy to accept query
parameters as kwargs.

Change-Id: I87cf7e7378b7fe6276b521be362f3e5d51427c00
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/64/862664/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/compute/v2/_proxy.py'],1,78a80b84f3740c1a8afb48b076c1dd05c507b5fb,nova-gaps," def migrations(self, **query): :param kwargs query: Optional query parameters to be sent to limit the migrations being returned. return self._list(_migration.Migration, **query)", def migrations(self): return self._list(_migration.Migration),4,2
openstack%2Fglance~master~I51f07a569f35d14c3872d7f135ccead426abdf4b,openstack/glance,master,I51f07a569f35d14c3872d7f135ccead426abdf4b,"In method add_with_multihash, there has a param position error.",ABANDONED,2022-11-14 06:48:22.000000000,2022-11-14 07:11:51.000000000,,[],"[{'number': 1, 'created': '2022-11-14 06:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9bf325e71eec11cb6f4e370c1b71775f15d498b4', 'message': 'In method add_with_multihash, there has a param position error\n\nChange-Id: I51f07a569f35d14c3872d7f135ccead426abdf4b\n'}, {'number': 2, 'created': '2022-11-14 06:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a5294be720598dbf0f5d7e98de553073d39126f9', 'message': 'In method add_with_multihash, there has a param position error.\nmethod add_with_multihash is definated in glance_store/backend.py.\n\nChange-Id: I51f07a569f35d14c3872d7f135ccead426abdf4b\n'}, {'number': 3, 'created': '2022-11-14 06:54:17.000000000', 'files': ['glance/location.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1a56caea7ff91e64b64b12368ccacd0234552c16', 'message': 'In method add_with_multihash, there has a param position error.\n\nmethod add_with_multihash is definated in glance_store/backend.py.\n\nChange-Id: I51f07a569f35d14c3872d7f135ccead426abdf4b\n'}]",0,864388,1a56caea7ff91e64b64b12368ccacd0234552c16,4,0,3,33881,,,0,"In method add_with_multihash, there has a param position error.

method add_with_multihash is definated in glance_store/backend.py.

Change-Id: I51f07a569f35d14c3872d7f135ccead426abdf4b
",git fetch https://review.opendev.org/openstack/glance refs/changes/88/864388/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/location.py'],1,9bf325e71eec11cb6f4e370c1b71775f15d498b4,," store,"," store,",1,1
openstack%2Ftacker~master~I8a9e763a0ef7df07135ebfbdcc9fa104b778ee77,openstack/tacker,master,I8a9e763a0ef7df07135ebfbdcc9fa104b778ee77,CNF Deployment failed due to missing Default VIM,MERGED,2022-04-12 08:25:10.000000000,2022-11-14 06:54:14.000000000,2022-11-14 06:53:04.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}]","[{'number': 1, 'created': '2022-04-12 08:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/388ec25a8d61ee744f6ef5298e79146c94503e0c', 'message': 'CNF Deployment failed due to missing Default VIM\n\nThis patch makes kubernetes VIM as Default VIM,\nin ""ETSI NFV-SOL CNF Deployment"" Documentation.\n\nCloses-Bug: 1968680\nChange-Id: I8a9e763a0ef7df07135ebfbdcc9fa104b778ee77\n'}, {'number': 2, 'created': '2022-04-12 08:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/53734ce350b2e36685c18d45c388982bba4024fa', 'message': '[WIP]CNF Deployment failed due to missing Default VIM\n\nThis patch makes kubernetes VIM as Default VIM,\nin ""ETSI NFV-SOL CNF Deployment"" Documentation.\n\nCloses-Bug: 1968680\nChange-Id: I8a9e763a0ef7df07135ebfbdcc9fa104b778ee77\n'}, {'number': 3, 'created': '2022-10-18 08:25:17.000000000', 'files': ['doc/source/user/etsi_containerized_vnf_usage_guide.rst'], 'web_link': 'https://opendev.org/openstack/tacker/commit/594fffcc0e17e3c579f33858846ae61d2eed71f5', 'message': 'CNF Deployment failed due to missing Default VIM\n\nThis patch makes kubernetes VIM as Default VIM,\nin ""ETSI NFV-SOL CNF Deployment"" Documentation.\n\nCloses-Bug: 1968680\nChange-Id: I8a9e763a0ef7df07135ebfbdcc9fa104b778ee77\n'}]",1,837499,594fffcc0e17e3c579f33858846ae61d2eed71f5,13,4,3,34026,,,0,"CNF Deployment failed due to missing Default VIM

This patch makes kubernetes VIM as Default VIM,
in ""ETSI NFV-SOL CNF Deployment"" Documentation.

Closes-Bug: 1968680
Change-Id: I8a9e763a0ef7df07135ebfbdcc9fa104b778ee77
",git fetch https://review.opendev.org/openstack/tacker refs/changes/99/837499/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/etsi_containerized_vnf_usage_guide.rst'],1,388ec25a8d61ee744f6ef5298e79146c94503e0c,, $ openstack vim register --config-file vim-k8s.yaml test-vim-k8s --fit-width --is-default | is_default | True | | 8d8373fe-6977-49ff-83ac-7756572ed186 | test-vim-k8s | 2a505a8efb7a4569af73594bd9904834 | kubernetes | True | REACHABLE | | 8d8373fe-6977-49ff-83ac-7756572ed186 | test-vim-k8s | 2a505a8efb7a4569af73594bd9904834 | kubernetes | True | REACHABLE |, $ openstack vim register --config-file vim-k8s.yaml test-vim-k8s --fit-width | is_default | False | | 8d8373fe-6977-49ff-83ac-7756572ed186 | test-vim-k8s | 2a505a8efb7a4569af73594bd9904834 | kubernetes | False | REACHABLE | | 8d8373fe-6977-49ff-83ac-7756572ed186 | test-vim-k8s | 2a505a8efb7a4569af73594bd9904834 | kubernetes | False | REACHABLE |,4,4
openstack%2Fdevstack~master~Ia571d1dab45eb1bbb8665373d416515d3c95fb14,openstack/devstack,master,Ia571d1dab45eb1bbb8665373d416515d3c95fb14,Make debian-bullseye job non-voting,MERGED,2022-11-09 18:13:21.000000000,2022-11-14 06:50:45.000000000,2022-11-09 22:43:42.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 18:13:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a4680766515ed9317b71cfb39cd0d75dc04f3d9c', 'message': 'Make debian-bullseye job non-voting\n\nAs noted in the QA meeting this week, this job is failing due to\nsomething that seems outside of our control:\n\nhttps://meetings.opendev.org/meetings/qa/2022/qa.2022-11-08-15.00.log.html\n\nMake it non-voting until that is resolved.\n\nChange-Id: Ia571d1dab45eb1bbb8665373d416515d3c95fb14\n'}]",2,864135,a4680766515ed9317b71cfb39cd0d75dc04f3d9c,9,2,1,4393,,,0,"Make debian-bullseye job non-voting

As noted in the QA meeting this week, this job is failing due to
something that seems outside of our control:

https://meetings.opendev.org/meetings/qa/2022/qa.2022-11-08-15.00.log.html

Make it non-voting until that is resolved.

Change-Id: Ia571d1dab45eb1bbb8665373d416515d3c95fb14
",git fetch https://review.opendev.org/openstack/devstack refs/changes/35/864135/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,a4680766515ed9317b71cfb39cd0d75dc04f3d9c,debian-nv, # TODO(danms) n-v until the known issue is resolved voting: false,,2,0
openstack%2Fopenstack-ansible-galera_server~stable%2Fxena~I116ffbccfa1af8a1bfdfc2007a8c2c1f2da7d079,openstack/openstack-ansible-galera_server,stable/xena,I116ffbccfa1af8a1bfdfc2007a8c2c1f2da7d079,Bump mariadb version.,MERGED,2022-11-08 17:49:19.000000000,2022-11-14 05:31:46.000000000,2022-11-14 05:30:51.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 32238}]","[{'number': 1, 'created': '2022-11-08 17:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/1f3f5d9b3de38aa66623945fc5785c5e232069dc', 'message': 'Bump mariadb version.\n\nBump minor mariadb version to 10.6.9.\nCurrently used version(10.6.8) is affected by the bug[1] which causes\nmariabackups to be very large(they unnecesarily contain binary logs).\n\n[1] https://jira.mariadb.org/browse/MDEV-28758\n\nChange-Id: I116ffbccfa1af8a1bfdfc2007a8c2c1f2da7d079\n'}, {'number': 2, 'created': '2022-11-13 12:42:12.000000000', 'files': ['releasenotes/notes/mariadb_10.6.9_xena-0ca02752f6d72fb7.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/d65197c8696ca8dc1cbfd6af376494df56fea8ee', 'message': 'Bump mariadb version.\n\nBump minor mariadb version to 10.6.9.\nCurrently used version(10.6.8) is affected by the bug[1] which causes\nmariabackups to be very large(they unnecesarily contain binary logs).\n\n[1] https://jira.mariadb.org/browse/MDEV-28758\n\nChange-Id: I116ffbccfa1af8a1bfdfc2007a8c2c1f2da7d079\n'}]",2,864052,d65197c8696ca8dc1cbfd6af376494df56fea8ee,16,3,2,32666,,,0,"Bump mariadb version.

Bump minor mariadb version to 10.6.9.
Currently used version(10.6.8) is affected by the bug[1] which causes
mariabackups to be very large(they unnecesarily contain binary logs).

[1] https://jira.mariadb.org/browse/MDEV-28758

Change-Id: I116ffbccfa1af8a1bfdfc2007a8c2c1f2da7d079
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/52/864052/2 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,1f3f5d9b3de38aa66623945fc5785c5e232069dc,,galera_minor_version: 9,galera_minor_version: 8,1,1
openstack%2Fnova~master~I33ea5454b773c0a7fb74051f218d5473a2ae86f4,openstack/nova,master,I33ea5454b773c0a7fb74051f218d5473a2ae86f4,Remove the redundance code in HostState.update,ABANDONED,2022-11-14 03:51:08.000000000,2022-11-14 04:34:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-14 03:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/545bdbe200c711ee2c47588df38ab15c89945819', 'message': 'Remove the redundance code in HostState.update\n\nThe HostState is local variable in HostManager, So the updated is\nNone for HostState.\n\nChange-Id: I33ea5454b773c0a7fb74051f218d5473a2ae86f4\n'}, {'number': 2, 'created': '2022-11-14 03:53:18.000000000', 'files': ['nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9c5072f09cdee0944cdec2bc0d83a8891b7c667c', 'message': 'Remove the redundance code in HostState.update\n\nThe HostState is local variable in HostManager, So the updated is\nNone for HostState.\n\nChange-Id: I33ea5454b773c0a7fb74051f218d5473a2ae86f4\n'}]",0,864274,9c5072f09cdee0944cdec2bc0d83a8891b7c667c,7,1,2,31827,,,0,"Remove the redundance code in HostState.update

The HostState is local variable in HostManager, So the updated is
None for HostState.

Change-Id: I33ea5454b773c0a7fb74051f218d5473a2ae86f4
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/864274/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/host_manager.py'],1,545bdbe200c711ee2c47588df38ab15c89945819,,, if (self.updated and compute.updated_at and self.updated > compute.updated_at): return,0,3
openstack%2Ftripleo-docs~master~Ia68d3469318dd423ceb0843c39d3ac2734a5f264,openstack/tripleo-docs,master,Ia68d3469318dd423ceb0843c39d3ac2734a5f264,Fix typos in doc pages,MERGED,2022-09-20 11:18:25.000000000,2022-11-14 03:44:28.000000000,2022-11-14 03:43:22.000000000,"[{'_account_id': 7144}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-09-20 11:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/4fd65b0e2c2d32ffd36a954facaea97db9da83f4', 'message': 'Fix typos in doc pages\n\nChange-Id: Ia68d3469318dd423ceb0843c39d3ac2734a5f264\n'}, {'number': 2, 'created': '2022-09-28 15:16:58.000000000', 'files': ['deploy-guide/source/features/tolerated_failure.rst', 'deploy-guide/source/features/ovs_dpdk_config.rst', '_custom/custom.css', 'deploy-guide/source/features/deploy_cellv2_routed.rst', 'deploy-guide/source/features/ops_tools.rst', 'deploy-guide/source/deployment/overcloud.rst', 'deploy-guide/source/features/deploy_cellv2_manage_cell.rst', 'deploy-guide/source/features/vdpa_deployment.rst', 'deploy-guide/source/post_deployment/tempest/tempest.rst', 'deploy-guide/source/features/routed_spine_leaf_network.rst', 'deploy-guide/source/repositories.rst', 'doc/source/ci/chasing_promotions.rst', 'doc/source/ci/reproduce-ci.rst', 'deploy-guide/source/features/ceph_external.rst', 'deploy-guide/source/features/distributed_multibackend_storage.rst', 'deploy-guide/source/features/pre_network_config.rst', 'deploy-guide/source/post_deployment/validations/cli.rst', 'deploy-guide/source/environments/baremetal.rst', 'doc/source/ci/check_gates.rst', 'deploy-guide/source/deployment/ansible_config_download.rst', 'deploy-guide/source/features/tls-everywhere.rst', 'doc/source/developer/release.rst', 'deploy-guide/source/features/compute_nvdimm.rst', 'deploy-guide/source/features/custom_roles.rst', 'deploy-guide/source/deployment/network_v2.rst', 'deploy-guide/source/provisioning/node_states.rst', 'deploy-guide/source/features/deployed_ceph.rst', 'deploy-guide/source/features/custom_networks.rst', 'deploy-guide/source/post_deployment/delete_nodes.rst', 'deploy-guide/source/features/distributed_compute_node.rst', 'deploy-guide/source/features/deploy_cellv2_basic.rst', 'deploy-guide/source/deployment/3rd_party.rst', 'deploy-guide/source/deployment/standalone.rst', 'deploy-guide/source/features/sriov_deployment.rst', 'doc/source/developer/tripleoclient_primer.rst', 'deploy-guide/source/post_deployment/tempest/os_tempest.rst', 'doc/source/contributor/core.rst', 'deploy-guide/source/post_deployment/pre_cache_images.rst', 'deploy-guide/source/post_deployment/upgrade/fast_forward_upgrade.rst', 'deploy-guide/source/features/deployed_server.rst', 'doc/source/ci/ruck_rover_primer.rst', 'deploy-guide/source/provisioning/baremetal_provision.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/6901c3aa8aefafc7a58a12e6c47b76ebb37f3934', 'message': 'Fix typos in doc pages\n\nChange-Id: Ia68d3469318dd423ceb0843c39d3ac2734a5f264\n'}]",3,858516,6901c3aa8aefafc7a58a12e6c47b76ebb37f3934,12,7,2,20733,,,0,"Fix typos in doc pages

Change-Id: Ia68d3469318dd423ceb0843c39d3ac2734a5f264
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/16/858516/1 && git format-patch -1 --stdout FETCH_HEAD,"['deploy-guide/source/features/tolerated_failure.rst', 'deploy-guide/source/features/ovs_dpdk_config.rst', '_custom/custom.css', 'deploy-guide/source/features/deploy_cellv2_routed.rst', 'deploy-guide/source/features/ops_tools.rst', 'deploy-guide/source/deployment/overcloud.rst', 'deploy-guide/source/features/deploy_cellv2_manage_cell.rst', 'deploy-guide/source/features/vdpa_deployment.rst', 'deploy-guide/source/post_deployment/tempest/tempest.rst', 'deploy-guide/source/features/routed_spine_leaf_network.rst', 'deploy-guide/source/repositories.rst', 'doc/source/ci/chasing_promotions.rst', 'doc/source/ci/reproduce-ci.rst', 'deploy-guide/source/features/ceph_external.rst', 'deploy-guide/source/features/distributed_multibackend_storage.rst', 'deploy-guide/source/features/pre_network_config.rst', 'deploy-guide/source/post_deployment/validations/cli.rst', 'deploy-guide/source/environments/baremetal.rst', 'doc/source/ci/check_gates.rst', 'deploy-guide/source/deployment/ansible_config_download.rst', 'deploy-guide/source/features/tls-everywhere.rst', 'doc/source/developer/release.rst', 'deploy-guide/source/features/compute_nvdimm.rst', 'deploy-guide/source/features/custom_roles.rst', 'deploy-guide/source/deployment/network_v2.rst', 'deploy-guide/source/provisioning/node_states.rst', 'deploy-guide/source/features/deployed_ceph.rst', 'deploy-guide/source/features/custom_networks.rst', 'deploy-guide/source/post_deployment/delete_nodes.rst', 'deploy-guide/source/features/distributed_compute_node.rst', 'deploy-guide/source/features/deploy_cellv2_basic.rst', 'deploy-guide/source/deployment/3rd_party.rst', 'deploy-guide/source/deployment/standalone.rst', 'deploy-guide/source/features/sriov_deployment.rst', 'doc/source/developer/tripleoclient_primer.rst', 'deploy-guide/source/post_deployment/tempest/os_tempest.rst', 'doc/source/contributor/core.rst', 'deploy-guide/source/features/network_isolation.rst', 'deploy-guide/source/post_deployment/pre_cache_images.rst', 'deploy-guide/source/post_deployment/upgrade/fast_forward_upgrade.rst', 'deploy-guide/source/features/deployed_server.rst', 'doc/source/ci/ruck_rover_primer.rst', 'deploy-guide/source/provisioning/baremetal_provision.rst']",43,4fd65b0e2c2d32ffd36a954facaea97db9da83f4,typos,In the Wallaby release the baremetal provisioning was extended to also manage,In the Wallaby release the baremetal provisining was extended to also manage,76,76
openstack%2Fpuppet-openstack-integration~stable%2Fzed~Ib5e3b759d47675055b0cecc48bea4dd1b7179a91,openstack/puppet-openstack-integration,stable/zed,Ib5e3b759d47675055b0cecc48bea4dd1b7179a91,Switch to RDO Zed,MERGED,2022-11-07 15:11:09.000000000,2022-11-14 03:30:41.000000000,2022-11-14 03:30:41.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:11:09.000000000', 'files': ['manifests/repos.pp', 'configure_facts.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/deaae8b0931c400435521b51dcb381137dc70967', 'message': 'Switch to RDO Zed\n\nChange-Id: Ib5e3b759d47675055b0cecc48bea4dd1b7179a91\n'}]",1,863883,deaae8b0931c400435521b51dcb381137dc70967,7,3,1,9816,,,0,"Switch to RDO Zed

Change-Id: Ib5e3b759d47675055b0cecc48bea4dd1b7179a91
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/83/863883/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/repos.pp', 'configure_facts.sh']",2,deaae8b0931c400435521b51dcb381137dc70967,,"export DLRN_BASE=${DLRN_BASE:-${OS_NAME_VERS}-zed/puppet-passed-ci} export DLRN_DEPS_BASE=${DLRN_DEPS_BASE:-${OS_NAME_VERS}-zed/deps/latest/} export DLRN_BASE_URL=${DLRN_BASE_URL:-${OS_NAME_VERS}-zed/puppet-passed-ci/delorean.repo} export DLRN_DEPS_URL=${DLRN_DEPS_URL:-${OS_NAME_VERS}-zed/delorean-deps.repo}curl -o /tmp/delorean.repo ""${NODEPOOL_RDO_PROXY}/${OS_NAME_VERS}-zed/puppet-passed-ci/delorean.repo""curl -o /tmp/delorean-deps.repo ""${NODEPOOL_RDO_PROXY}/${OS_NAME_VERS}-zed/delorean-deps.repo""","export DLRN_BASE=${DLRN_BASE:-${OS_NAME_VERS}-master/puppet-passed-ci} export DLRN_DEPS_BASE=${DLRN_DEPS_BASE:-${OS_NAME_VERS}-master/deps/latest/} export DLRN_BASE_URL=${DLRN_BASE_URL:-${OS_NAME_VERS}-master/puppet-passed-ci/delorean.repo} export DLRN_DEPS_URL=${DLRN_DEPS_URL:-${OS_NAME_VERS}-master/delorean-deps.repo}curl -o /tmp/delorean.repo ""${NODEPOOL_RDO_PROXY}/${OS_NAME_VERS}-master/puppet-passed-ci/delorean.repo""curl -o /tmp/delorean-deps.repo ""${NODEPOOL_RDO_PROXY}/${OS_NAME_VERS}-master/delorean-deps.repo""",8,8
openstack%2Fvenus~master~Iea328d91fa8296cb24c5bdcbd851e944dc5f9b38,openstack/venus,master,Iea328d91fa8296cb24c5bdcbd851e944dc5f9b38,Fix pbr version check,MERGED,2022-10-28 12:08:56.000000000,2022-11-14 02:44:24.000000000,2022-11-14 02:42:53.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 27565}]","[{'number': 1, 'created': '2022-10-28 12:08:56.000000000', 'files': ['venus/version.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/665230ea54697fced42dfaf0ecf1c8e07b2053d4', 'message': 'Fix pbr version check\n\nCurrently pbr version check uses \'venus\' as package name, while\npython package name is openstack-venus (as per setup.cfg).\n\nThis results in following when running venus-api or venus-manager:\n\nTraceback (most recent call last):\n  File ""/var/lib/kolla/venv/lib/python3.10/site-packages/pbr/version.py"", line 475, in _get_version_from_importlib_metadata\n    distribution = importlib_metadata.distribution(self.package)\n  File ""/usr/lib/python3.10/importlib/metadata/__init__.py"", line 957, in distribution\n    return Distribution.from_name(distribution_name)\n  File ""/usr/lib/python3.10/importlib/metadata/__init__.py"", line 548, in from_name\n    raise PackageNotFoundError(name)\nimportlib.metadata.PackageNotFoundError: No package metadata was found for venus\n\nChange-Id: Iea328d91fa8296cb24c5bdcbd851e944dc5f9b38\n'}]",2,862886,665230ea54697fced42dfaf0ecf1c8e07b2053d4,8,3,1,22629,,,0,"Fix pbr version check

Currently pbr version check uses 'venus' as package name, while
python package name is openstack-venus (as per setup.cfg).

This results in following when running venus-api or venus-manager:

Traceback (most recent call last):
  File ""/var/lib/kolla/venv/lib/python3.10/site-packages/pbr/version.py"", line 475, in _get_version_from_importlib_metadata
    distribution = importlib_metadata.distribution(self.package)
  File ""/usr/lib/python3.10/importlib/metadata/__init__.py"", line 957, in distribution
    return Distribution.from_name(distribution_name)
  File ""/usr/lib/python3.10/importlib/metadata/__init__.py"", line 548, in from_name
    raise PackageNotFoundError(name)
importlib.metadata.PackageNotFoundError: No package metadata was found for venus

Change-Id: Iea328d91fa8296cb24c5bdcbd851e944dc5f9b38
",git fetch https://review.opendev.org/openstack/venus refs/changes/86/862886/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/version.py'],1,665230ea54697fced42dfaf0ecf1c8e07b2053d4,,version_info = pbr_version.VersionInfo('openstack-venus') ,version_info = pbr_version.VersionInfo('venus') ,1,1
openstack%2Fheat~master~I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9,openstack/heat,master,I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9,Imported Translations from Zanata,MERGED,2022-09-24 03:37:17.000000000,2022-11-14 02:13:18.000000000,2022-11-14 02:09:22.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-24 03:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9b49d48145ccd5321b5c6f1e3785e8bfcb6b165b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}, {'number': 2, 'created': '2022-09-29 04:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c518b4e6dc0c15a08d4345d95a05a32afb6f7b4e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}, {'number': 3, 'created': '2022-10-05 04:22:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dc315b86379f1704235af192bdd1151d06a5f8cd', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}, {'number': 4, 'created': '2022-11-04 02:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f7d165b56c180b75951d14fff3ed2bc418a23553', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}, {'number': 5, 'created': '2022-11-05 03:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a8e91a253216bb3ac7a12d980a2fea7410ed1470', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}, {'number': 6, 'created': '2022-11-10 03:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/327744ed21f23a44b02958cd440a383f97db97d0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}, {'number': 7, 'created': '2022-11-13 04:01:03.000000000', 'files': ['heat/locale/fr/LC_MESSAGES/heat.po', 'heat/locale/ja/LC_MESSAGES/heat.po', 'heat/locale/ko_KR/LC_MESSAGES/heat.po', 'heat/locale/zh_TW/LC_MESSAGES/heat.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/ru/LC_MESSAGES/heat.po', 'heat/locale/zh_CN/LC_MESSAGES/heat.po', 'heat/locale/it/LC_MESSAGES/heat.po', 'heat/locale/de/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/5451b9854bf2d6fd0f82211f29c7ff4dcf431267', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9\n'}]",0,859183,5451b9854bf2d6fd0f82211f29c7ff4dcf431267,30,2,7,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I5db9cc7f9a13db05a7d0ab0320e53bfdf4b419d9
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/859183/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/fr/LC_MESSAGES/heat.po', 'heat/locale/ja/LC_MESSAGES/heat.po', 'heat/locale/ko_KR/LC_MESSAGES/heat.po', 'heat/locale/zh_TW/LC_MESSAGES/heat.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'heat/locale/pt_BR/LC_MESSAGES/heat.po', 'heat/locale/ru/LC_MESSAGES/heat.po', 'heat/locale/zh_CN/LC_MESSAGES/heat.po', 'heat/locale/it/LC_MESSAGES/heat.po', 'heat/locale/de/LC_MESSAGES/heat.po', 'heat/locale/es/LC_MESSAGES/heat.po']",11,9b49d48145ccd5321b5c6f1e3785e8bfcb6b165b,zanata/translations,"""POT-Creation-Date: 2022-09-21 23:25+0000\n""","""POT-Creation-Date: 2022-09-06 02:55+0000\n""msgid ""Failed to create Bay '%(name)s' - %(reason)s"" msgstr ""No se ha podido crear la bahía '%(name)s' - %(reason)s"" #, python-format#, python-format msgid ""Failed to update Bay '%(name)s' - %(reason)s"" msgstr ""No se ha podido actualizar la bahía '%(name)s' - %(reason)s"" msgid ""The bay name."" msgstr ""El nombre de la bahía."" msgid ""The name or ID of the bay model."" msgstr ""El nombre o el ID del modelo de bahía."" msgid ""The node count for this bay."" msgstr ""El recuento de nodos para esta bahía."" msgid ""The number of master nodes for this bay."" msgstr ""El número de nodos mestros para esta bahía."" msgid ""Timeout for creating the bay in minutes. Set to 0 for no timeout."" msgstr """" ""Tiempo de espera para crear la bahía en minutos. Establézcalo en 0 si no "" ""desea que haya tiempo de espera."" #, python-format msgid ""Unknown status creating Bay '%(name)s' - %(reason)s"" msgstr ""Estado desconocido al crear la bahía '%(name)s' - %(reason)s"" msgid ""Unknown status updating Bay '%(name)s' - %(reason)s"" msgstr ""Estado desconocido al actualizar la bahía '%(name)s' - %(reason)s"" #, python-format",17,343
openstack%2Fvenus~master~Ieec144dac453a57680513fadb5146f3c1db4b393,openstack/venus,master,Ieec144dac453a57680513fadb5146f3c1db4b393,Add a test case to search_logs.,MERGED,2022-11-11 09:44:47.000000000,2022-11-14 01:25:50.000000000,2022-11-14 01:24:46.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2022-11-11 09:44:47.000000000', 'files': ['venus/tests/unit/api/test_search_controller.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/8abfaa3ff2b6770ef06c6c1080dc48dfad92a432', 'message': 'Add a test case to search_logs.\n\nChange-Id: Ieec144dac453a57680513fadb5146f3c1db4b393\n'}]",1,864270,8abfaa3ff2b6770ef06c6c1080dc48dfad92a432,9,3,1,34375,,,0,"Add a test case to search_logs.

Change-Id: Ieec144dac453a57680513fadb5146f3c1db4b393
",git fetch https://review.opendev.org/openstack/venus refs/changes/70/864270/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/tests/unit/api/test_search_controller.py'],1,8abfaa3ff2b6770ef06c6c1080dc48dfad92a432,," @mock.patch('venus.modules.search.action.SearchCore.logs') def test_search_logs_invalid_params(self, action_params): ret = {""code"": -1, ""msg"": ""invalid param""} action_params.return_value = ret req = fakes.HTTPRequest.blank('?start_time=None') res1 = self.controller.search_logs(req) self.assertEqual(ret, res1) req1 = fakes.HTTPRequest.blank('?end_time=None') res2 = self.controller.search_logs(req1) self.assertEqual(ret, res2) req2 = fakes.HTTPRequest.blank('?page_num=None') res3 = self.controller.search_logs(req2) self.assertEqual(ret, res3) req3 = fakes.HTTPRequest.blank('?page_size=None') res4 = self.controller.search_logs(req3) self.assertEqual(ret, res4)",,17,0
openstack%2Fvenus~master~Id9a750a6b51590ce5a896432c55c5fb8527e3a54,openstack/venus,master,Id9a750a6b51590ce5a896432c55c5fb8527e3a54,Add a test case 'valid type' to search_params.,MERGED,2022-11-11 03:12:46.000000000,2022-11-14 01:07:57.000000000,2022-11-14 01:07:06.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 27565}, {'_account_id': 31412}]","[{'number': 1, 'created': '2022-11-11 03:12:46.000000000', 'files': ['venus/tests/unit/api/test_search_controller.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/3f5cd82428974f9ba180986060c0a6884cfe17ac', 'message': ""Add a test case 'valid type' to search_params.\n\nChange-Id: Id9a750a6b51590ce5a896432c55c5fb8527e3a54\n""}]",1,863308,3f5cd82428974f9ba180986060c0a6884cfe17ac,8,4,1,34375,,,0,"Add a test case 'valid type' to search_params.

Change-Id: Id9a750a6b51590ce5a896432c55c5fb8527e3a54
",git fetch https://review.opendev.org/openstack/venus refs/changes/08/863308/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/tests/unit/api/test_search_controller.py'],1,3f5cd82428974f9ba180986060c0a6884cfe17ac,," @mock.patch('venus.modules.search.action.SearchCore.params') def test_search_params_valid_type(self, action_params): ret = {'code': 0, 'msg': 'no data, no index'} action_params.return_value = ret req = fakes.HTTPRequest.blank('?type=host_name') res1 = self.controller.search_params(req) self.assertEqual(ret, res1)",,8,0
openstack%2Fvenus~master~Icc9721e5c46afe7d98be0ec67cb446e97edeef8a,openstack/venus,master,Icc9721e5c46afe7d98be0ec67cb446e97edeef8a,Add A unit test case to search_params.,MERGED,2022-11-10 06:25:07.000000000,2022-11-14 01:06:25.000000000,2022-11-14 01:05:27.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2022-11-10 06:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/52daf8660cce551989a989c56276db4f16e721cc', 'message': 'Add A unit test case to search_params.\n\nChange-Id: Icc9721e5c46afe7d98be0ec67cb446e97edeef8a\n'}, {'number': 2, 'created': '2022-11-11 02:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/22518a2334eb25cab8397db4162d8a596479f388', 'message': 'Add A unit test case to search_params.\n\nChange-Id: Icc9721e5c46afe7d98be0ec67cb446e97edeef8a\n'}, {'number': 3, 'created': '2022-11-11 02:37:14.000000000', 'files': ['venus/tests/unit/api/test_search_controller.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/ddd8761f779659f789246cbaa5163796eee33d2f', 'message': 'Add A unit test case to search_params.\n\nChange-Id: Icc9721e5c46afe7d98be0ec67cb446e97edeef8a\n'}]",2,863306,ddd8761f779659f789246cbaa5163796eee33d2f,14,3,3,34375,,,0,"Add A unit test case to search_params.

Change-Id: Icc9721e5c46afe7d98be0ec67cb446e97edeef8a
",git fetch https://review.opendev.org/openstack/venus refs/changes/06/863306/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/tests/unit/api/test_search_controller.py'],1,52daf8660cce551989a989c56276db4f16e721cc,," @mock.patch('venus.modules.search.action.SearchCore.params') def test_search_params_invalid_type(self, action_params): ret = {'code': 0, 'msg': 'no data, no index'} action_params.return_value = ret req = fakes.HTTPRequest.blank('?type=host_name') res1 = self.controller.search_params(req) self.assertEqual(ret, res1)",,8,0
openstack%2Fvenus~master~I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8,openstack/venus,master,I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8,Add unit test for controller api,MERGED,2022-11-06 04:00:06.000000000,2022-11-14 01:04:26.000000000,2022-11-14 01:03:28.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 27565}, {'_account_id': 31412}, {'_account_id': 34375}]","[{'number': 1, 'created': '2022-11-06 04:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/a8d1c84202ff257849a676790dc2c9b2708b9e96', 'message': 'Add unit test for controller api\n\nChange-Id: I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8\n'}, {'number': 2, 'created': '2022-11-07 01:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/385a21377e30da07599cde56242e4c379325da4c', 'message': 'Add unit test for controller api\n\nChange-Id: I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8\n'}, {'number': 3, 'created': '2022-11-07 01:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/47f76584f10f97d267c1382809166dae9e4efbb8', 'message': 'Add unit test for controller api\n\nChange-Id: I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8\n'}, {'number': 4, 'created': '2022-11-10 05:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/venus/commit/3473277120ab38ed51acba6ead59b25fc92cb902', 'message': 'Add unit test for controller api\n\nChange-Id: I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8\n'}, {'number': 5, 'created': '2022-11-10 06:08:53.000000000', 'files': ['venus/tests/unit/api/test_search_controller.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/16ac2c94d92871cf59d0800d4e14b4f65a33af32', 'message': 'Add unit test for controller api\n\nChange-Id: I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8\n'}]",12,863772,16ac2c94d92871cf59d0800d4e14b4f65a33af32,15,5,5,31412,,,0,"Add unit test for controller api

Change-Id: I5424c2ec3c3b1fe4bf1bbdb4f4f6dee6578de0a8
",git fetch https://review.opendev.org/openstack/venus refs/changes/72/863772/4 && git format-patch -1 --stdout FETCH_HEAD,['venus/tests/unit/api/test_search_controller.py'],1,a8d1c84202ff257849a676790dc2c9b2708b9e96,,"# Copyright 2022 Inspur # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime import unittest from unittest import mock from venus.modules.search.action import SearchCore from venus.modules.search.search_lib import ESSearchObj from venus.modules.search.controller import SearchController from venus.api import extensions from elasticsearch import Elasticsearch from venus.tests.unit import fakes class TestSearchController(unittest.TestCase): @mock.patch('elasticsearch.Elasticsearch') def setUp(self,mock_es): mock_es.return_value=Elasticsearch() self.controller = SearchController(extensions.ExtensionManager) self.req = fakes.HTTPRequest.blank('') super(TestSearchController, self).setUp() @mock.patch('venus.modules.search.action.SearchCore.params') def test_search_params_invalid_type(self, action_params): ret = {'code': 0, 'msg': 'no data, no index'} action_params.return_value = ret req = fakes.HTTPRequest.blank('?type=host_name') res1 = self.controller.search_params(req) self.assertEqual(ret, res1) @mock.patch('venus.modules.search.action.SearchCore.params') def test_search_params_valid_type(self, action_params): pass @mock.patch('venus.modules.search.action.SearchCore.params') def test_search_params_invalid_module_name(self, action_params): pass @mock.patch('venus.modules.search.action.SearchCore.params') def test_search_params_valid_module_name(self, action_params): pass @mock.patch('venus.modules.search.action.SearchCore.log') def test_search_logs_valid_host_name(self, action_logs): pass ",,57,0
openstack%2Fos-net-config~stable%2Ftrain~Ida0c78ba7784d452165999af4dd955b0129cfdaf,openstack/os-net-config,stable/train,Ida0c78ba7784d452165999af4dd955b0129cfdaf,Mellanox NICs' ifcfg-scripts should not be removed when no CONFIG change exists,MERGED,2022-11-04 05:31:13.000000000,2022-11-12 12:56:01.000000000,2022-11-12 12:54:58.000000000,"[{'_account_id': 12398}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 05:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/239caf80fde2e13b61f0d23a103e19f829b71c97', 'message': ""Mellanox NICs' ifcfg-scripts should not be removed when no CONFIG change exists\n\nos-net-config is triggering reconfiguration/flapping of\nmellanox nics even when there are no changes in the NIC configs.\nAdded check to NOT remove ifcfg-* scripts for Mellonox NICs when\nDPDK/Bond is enabled\n\nResolves: rhbz#2131248\nChange-Id: Ida0c78ba7784d452165999af4dd955b0129cfdaf\n(cherry picked from commit e752fbac782f357f1445a609ff90e1dee6c3492d)\n""}, {'number': 2, 'created': '2022-11-08 11:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/c81a28b7b144d965c5968871aa1c544b1e6c9f76', 'message': ""Mellanox NICs' ifcfg-scripts should not be removed when no CONFIG change exists\n\nos-net-config is triggering reconfiguration/flapping of\nmellanox nics even when there are no changes in the NIC configs.\nAdded check to NOT remove ifcfg-* scripts for Mellonox NICs when\nDPDK/Bond is enabled\n\nResolves: rhbz#2131248\nChange-Id: Ida0c78ba7784d452165999af4dd955b0129cfdaf\n(cherry picked from commit e752fbac782f357f1445a609ff90e1dee6c3492d)\n""}, {'number': 3, 'created': '2022-11-08 12:21:17.000000000', 'files': ['os_net_config/impl_ifcfg.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/a598d011dcc5f1f5d3d5f610d91be40fd157c842', 'message': ""Mellanox NICs' ifcfg-scripts should not be removed when no CONFIG change exists\n\nos-net-config is triggering reconfiguration/flapping of\nmellanox nics even when there are no changes in the NIC configs.\nAdded check to NOT remove ifcfg-* scripts for Mellonox NICs when\nDPDK/Bond is enabled\n\nResolves: rhbz#2131248\nChange-Id: Ida0c78ba7784d452165999af4dd955b0129cfdaf\n(cherry picked from commit e752fbac782f357f1445a609ff90e1dee6c3492d)\n""}]",4,863587,a598d011dcc5f1f5d3d5f610d91be40fd157c842,13,4,3,33688,,,0,"Mellanox NICs' ifcfg-scripts should not be removed when no CONFIG change exists

os-net-config is triggering reconfiguration/flapping of
mellanox nics even when there are no changes in the NIC configs.
Added check to NOT remove ifcfg-* scripts for Mellonox NICs when
DPDK/Bond is enabled

Resolves: rhbz#2131248
Change-Id: Ida0c78ba7784d452165999af4dd955b0129cfdaf
(cherry picked from commit e752fbac782f357f1445a609ff90e1dee6c3492d)
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/87/863587/2 && git format-patch -1 --stdout FETCH_HEAD,['os_net_config/impl_ifcfg.py'],1,239caf80fde2e13b61f0d23a103e19f829b71c97,ifcfg_cherry_pick, logger.info('removing existing ifcfg script for intf: %s' % ifname) if not self.noop and (not common.is_mellanox_interface(ifname)): if not self.noop and (not common.is_mellanox_interface(ifname)):, if not self.noop: if not self.noop:,3,2
openstack%2Fnova~master~I5c447e630aaf1413a5eac89c2e8103506d245221,openstack/nova,master,I5c447e630aaf1413a5eac89c2e8103506d245221,Test ceph-multistore with a real image,MERGED,2022-10-10 17:55:02.000000000,2022-11-11 19:14:04.000000000,2022-11-11 19:12:15.000000000,"[{'_account_id': 4393}, {'_account_id': 8556}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-10 17:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/87d8ecaf86a04204fdb3cedf9b6a03ea80592475', 'message': 'DNM: Test ceph-multistore with a real image\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 2, 'created': '2022-10-10 19:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb9046dfb7faa950cdaff87276c0b74776b07c68', 'message': 'DNM: Test ceph-multistore with a real image\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 3, 'created': '2022-10-11 18:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bbdd1c7e2c9c177a6d15695fdc2baa2be90f79e', 'message': 'DNM: Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 4, 'created': '2022-10-11 21:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90a52efe1c196fd500f4d7cf03bda8828346fbb9', 'message': 'DNM: Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 5, 'created': '2022-10-11 22:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4a016d1edc49eacd074111e4784f7c7f65eddd7', 'message': 'DNM: Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 6, 'created': '2022-10-12 16:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bc3aae84787f5a6fb5ae5c0361e0b4cda9122ce', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 7, 'created': '2022-10-12 18:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/057ffe53a9f1b1aec49d28fe0e290a1c55cd430b', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 8, 'created': '2022-10-12 21:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fe629b348b9b37ff5c3c2e8ed6744836b0183fa', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 9, 'created': '2022-10-13 13:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb96a722f4df0d8c1a6d3c5478a01aa8e2b50f20', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 10, 'created': '2022-10-13 14:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/793bd2f0345e81088ae4f4839143ad52d200c92f', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 11, 'created': '2022-10-13 14:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8aee88464d2d8a856e55b40d986b3bb27b1ebbc8', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 12, 'created': '2022-10-13 16:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8843740779ab6bc8ded83463f046270c378e73e0', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 2G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 13, 'created': '2022-10-13 18:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1e1e5842bed5f44525a4e53f61e57109f3fdee9', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 1G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 14, 'created': '2022-11-03 17:28:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b8a1398ec33c5c97c486837f81ff4cc063b453b', 'message': 'Test ceph-multistore with a real image\n\nThis uses the devstack functionality to inflate the cirros image\nto 1G for a more realistic scenario. We also need to up the volume\nsize tempest uses for various tests to make sure we will fit.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/860976\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 15, 'created': '2022-11-07 15:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0190044f763b2fb0b7e124ab4a2dbaddd7bcb371', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 16, 'created': '2022-11-07 17:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/366d40d0749ef4b9f7ce2dd435428630a308417d', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 17, 'created': '2022-11-07 18:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5834d637301904ca095d8b3b848071e4d0b263d3', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 18, 'created': '2022-11-07 19:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6fce3f424a373088cc63583465412102328add0', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 19, 'created': '2022-11-07 22:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b758fb6d30fa42fae3d53049bd06c4d78f90d4b7', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 20, 'created': '2022-11-08 00:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9638dfa48ec3b19a0cab7aeaa0c65fd82778185a', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 21, 'created': '2022-11-08 14:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a496816d0aeec355757964915ac97661ef0e7688', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 22, 'created': '2022-11-08 14:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e1f5b00a19a924d02b98949340df920985c5e7f', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 23, 'created': '2022-11-08 17:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df191929e85459aaf8327d9adb0220c20e2765fa', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 24, 'created': '2022-11-09 16:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ddfe1bea462e2dbf380db398b4a1feab37d6486', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}, {'number': 25, 'created': '2022-11-09 19:34:10.000000000', 'files': ['playbooks/ceph/glance-copy-policy.yaml', '.zuul.yaml', 'playbooks/ceph/glance-setup.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/010983e80374ef6538c965d3db3247cda1bc6edc', 'message': 'Test ceph-multistore with a real image\n\nThis inflates the cirros image to 1G for a more realistic scenario.\nTechnically we should have been doing something like this all along,\nas the deployment guidance for ceph is to use a raw image, not a qcow2\none, so this also increases our accuracy to real-life.\n\nWe also need to up the volume size tempest uses for various tests\nto make sure we will fit.\n\nChange-Id: I5c447e630aaf1413a5eac89c2e8103506d245221\n'}]",27,860864,010983e80374ef6538c965d3db3247cda1bc6edc,149,4,25,4393,,,0,"Test ceph-multistore with a real image

This inflates the cirros image to 1G for a more realistic scenario.
Technically we should have been doing something like this all along,
as the deployment guidance for ceph is to use a raw image, not a qcow2
one, so this also increases our accuracy to real-life.

We also need to up the volume size tempest uses for various tests
to make sure we will fit.

Change-Id: I5c447e630aaf1413a5eac89c2e8103506d245221
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/860864/5 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,87d8ecaf86a04204fdb3cedf9b6a03ea80592475,glance-locations, image: http_image: https://cloud-images.ubuntu.com/jammy/20221007/jammy-server-cloudimg-amd64-disk-kvm.img,,2,0
openstack%2Fcharm-designate~master~I50693d6e85b2ce427ff184555cdfae66096f3f6c,openstack/charm-designate,master,I50693d6e85b2ce427ff184555cdfae66096f3f6c,Use the default source origin for mysql & rabbit,MERGED,2022-11-11 15:46:13.000000000,2022-11-11 19:06:02.000000000,2022-11-11 19:06:02.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-11 15:46:13.000000000', 'files': ['src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/f87d01015bebbc7758612f27082f4108ceb94a7d', 'message': ""Use the default source origin for mysql & rabbit\n\nThe functional test bundles specify that the mysql and rabbit\nservices should use the openstack-origin reference field, but this\nis not actually relevant to the rabbit/mysql charms (e.g. it doesn't\nmake sense to install rabbit from cloud:jammy-zed as rabbit is from\nthe distro).\n\nChange-Id: I50693d6e85b2ce427ff184555cdfae66096f3f6c\n""}]",1,864296,f87d01015bebbc7758612f27082f4108ceb94a7d,8,3,1,8992,,,0,"Use the default source origin for mysql & rabbit

The functional test bundles specify that the mysql and rabbit
services should use the openstack-origin reference field, but this
is not actually relevant to the rabbit/mysql charms (e.g. it doesn't
make sense to install rabbit from cloud:jammy-zed as rabbit is from
the distro).

Change-Id: I50693d6e85b2ce427ff184555cdfae66096f3f6c
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/96/864296/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml']",2,f87d01015bebbc7758612f27082f4108ceb94a7d,functional-test-sources,, options: source: *openstack-origin options: source: *openstack-origin,0,8
openstack%2Fopenstack-zuul-jobs~master~I893eaf117125e67e8b0f4387222290387885fe76,openstack/openstack-zuul-jobs,master,I893eaf117125e67e8b0f4387222290387885fe76,Use ubuntu-focal for announce-release job for stable,ABANDONED,2022-11-11 11:09:32.000000000,2022-11-11 19:04:33.000000000,,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-11 11:09:32.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/91b83d2bf9d5bd765b123b043a314a093d66f502', 'message': ""Use ubuntu-focal for announce-release job for stable\n\nThe default nodeset was changed to ubuntu-jammy recently and\nannounce-release job started to fail with that. The reason is that the\njob installs binary dependencies of the deliverables to avoid garbage\ncontent when composing the announce mail and it seems lot of projects\nhold old dependencies (mostly python2 related packages) that don't\nexist anymore under Ubuntu Jammy.\n\nTo avoid the failure, this patch pins the nodeset to ubuntu-focal for\nstable branches (only those, which are still in 'Maintained phase' as\nreleases can be made only from those).\n\nChange-Id: I893eaf117125e67e8b0f4387222290387885fe76\n""}]",0,864261,91b83d2bf9d5bd765b123b043a314a093d66f502,4,2,1,17685,,,0,"Use ubuntu-focal for announce-release job for stable

The default nodeset was changed to ubuntu-jammy recently and
announce-release job started to fail with that. The reason is that the
job installs binary dependencies of the deliverables to avoid garbage
content when composing the announce mail and it seems lot of projects
hold old dependencies (mostly python2 related packages) that don't
exist anymore under Ubuntu Jammy.

To avoid the failure, this patch pins the nodeset to ubuntu-focal for
stable branches (only those, which are still in 'Maintained phase' as
releases can be made only from those).

Change-Id: I893eaf117125e67e8b0f4387222290387885fe76
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/61/864261/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,91b83d2bf9d5bd765b123b043a314a093d66f502,, # TODO(elod.illes): this job is added to avoid announce job fails # in case a bindep is not found on default nodeset (ubuntu-jammy # currently. This can be removed as soon as every bindep is fixed # or the branches transitioned to Extended Maintenance. nodeset: ubuntu-focal pre-run: playbooks/release/pre.yaml run: playbooks/release/announce.yaml files: - ^deliverables/zed/.*\.yaml$ - ^deliverables/yoga/.*\.yaml$ - ^deliverables/xena/.*\.yaml$ - ^deliverables/wallaby/.*\.yaml$ required-projects: - openstack/releases - job: name: announce-release description: Send a release announcement after publishing a project,,18,0
openstack%2Fos-vif~stable%2Fstein~I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7,openstack/os-vif,stable/stein,I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7,Fix - os-vif fails to get the correct UpLink Representor,ABANDONED,2020-12-08 11:37:55.000000000,2022-11-11 18:39:18.000000000,,"[{'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-12-08 11:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/50a92997fbd365cbb21cc84b67e3f1d3d3b0f7de', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit b37de19c58c877f5174d76d0a4ba5ab519f464e8)\n'}, {'number': 2, 'created': '2020-12-16 08:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/3774df162ce0b44b759660648b3597426f29fea7', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit 00edcb6b639f80bd1b2efe7eb6b6ab35485ce4a7)\n'}, {'number': 3, 'created': '2021-01-05 07:46:00.000000000', 'files': ['releasenotes/notes/bug-1892132-812e6d5ce0588ebb.yaml', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/aef047a34384a055abfc15f703df59af4ec47437', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit 3c63ee065a53649c700121a7947c399f23dca95a)\n'}]",0,765974,aef047a34384a055abfc15f703df59af4ec47437,11,4,3,32296,,,0,"Fix - os-vif fails to get the correct UpLink Representor

Till kernel 5.7 PF and VF representors are exposed as virtual device.
They are not linked to its parent PCI device like how uplink
representor is linked.

Starting from kernel 5.8 due to new change [1] the PF and VF representors are
linked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails
to get the correct UpLink Representor.

This patch modifys the behviour of ""get_ifname_by_pci_address"" to
check the physical port name of the netdev in
vf_pci_addr_path/physfn/net to match the formart for the uplink ""p\d+"".

[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1

Closes-Bug: #1892132
Change-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7
(cherry picked from commit 3c63ee065a53649c700121a7947c399f23dca95a)
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/74/765974/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1892132-812e6d5ce0588ebb.yaml', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py']",3,50a92997fbd365cbb21cc84b67e3f1d3d3b0f7de,stein-ref," @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): mock__get_phys_port_name.side_effect = ([""p1""]) @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): mock__get_phys_port_name.side_effect = ([""p1s0""]) @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") def test_physical_function_interface_name_with_representors( self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): # Get the PF that matches the phys_port_name regex mock_listdir.return_value = ['enp2s0f0_0', 'enp2s0f0_1', 'enp2s0f0'] mock__get_phys_switch_id.side_effect = ( ['valid_switch', 'valid_switch', 'valid_switch']) mock__get_phys_port_name.side_effect = ([""pf0vf0"", ""pf0vf1"", ""p0""]) ifname = linux_net.get_ifname_by_pci_address( '0000:00:00.1', pf_interface=True, switchdev=True) self.assertEqual(ifname, 'enp2s0f0') @mock.patch.object(os, 'listdir') @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") def test_physical_function_interface_name_with_fallback_To_first_netdev( self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): # Try with switchdev mode to get PF but fail because there is no match # for the phys_port_name then fallback to first interface found mock_listdir.return_value = ['enp2s0f0_0', 'enp2s0f0_1', 'enp2s0f0'] mock__get_phys_switch_id.side_effect = (['valid_switch', 'valid_switch', 'valid_switch']) mock__get_phys_port_name.side_effect = ([""pf0vf0"", ""pf0vf1"", ""pf0vf2""]) ifname = linux_net.get_ifname_by_pci_address( '0000:00:00.1', pf_interface=True, switchdev=True) self.assertEqual(ifname, 'enp2s0f0_0') @mock.patch.object(os, 'listdir')"," self, mock__get_phys_switch_id, mock_listdir): @mock.patch.object(linux_net, '_get_phys_switch_id') self, mock__get_phys_switch_id, mock_listdir):",74,8
openstack%2Fos-vif~stable%2Fstein~I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76,openstack/os-vif,stable/stein,I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76,Refactor code of linux_net to more cleaner and increase performace,ABANDONED,2020-12-08 07:51:57.000000000,2022-11-11 18:39:13.000000000,,"[{'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-12-08 07:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/44abe7ee9504c698061fc56b7bd9479b07c12af6', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 76f7565b99e637d74878955a0033f35e9eb0e13f)\n'}, {'number': 2, 'created': '2020-12-09 13:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/91fe964173dc7031c8f1e500bc6796051df308ee', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 76f7565b99e637d74878955a0033f35e9eb0e13f)\n'}, {'number': 3, 'created': '2020-12-13 10:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/d0f62bfc050ffc0444ba6d738f0bb11ddf02f15c', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_linux_bridge/linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 76f7565b99e637d74878955a0033f35e9eb0e13f)\n(cherry picked from commit 167bb030f1143f37ce189673d831bd572f64d4ad)\n(cherry picked from commit a8270fd85a0edb5e5808bb5e777a63a309b5d38a)\n(cherry picked from commit aa21fd38f6a34b071859ed26a9e85894b7390a0b)\n'}, {'number': 4, 'created': '2020-12-14 13:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/0dca2c12bf5fad55e141516e99ed05a459e8e698', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_linux_bridge/linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit c3e25c7e7a871d317b82549f66721d786b51a801)\n'}, {'number': 5, 'created': '2020-12-30 13:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/6eb571075823871961a13f116bca6b6872a3a587', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_linux_bridge/linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit c3e25c7e7a871d317b82549f66721d786b51a801)\n'}, {'number': 6, 'created': '2020-12-31 10:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/fcc88fa53ebbb4a0696323798ad1f2889b4a3cd9', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_ovs/linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 17496c060c30802d0647ec4b6ee2d1fe21416620)\n'}, {'number': 7, 'created': '2021-01-05 07:42:41.000000000', 'files': ['vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/41adc262dac2c2a5647b4c08a4376ffb01731ced', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_ovs/linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit cda2a020f1ef92ebdd62c592cbad987977f240e6)\n'}]",2,765914,41adc262dac2c2a5647b4c08a4376ffb01731ced,27,4,7,32296,,,0,"Refactor code of linux_net to more cleaner and increase performace

The patch adds new functions '_get_phys_port_name' for reading physical
port name of the SR-IOV port and '_get_phys_switch_id' for reading
physical port switch ID of the SR-IOV port, in addition to refactoring
'get_representor_port' to use the new functions and decrease calls for
""_get_pf_func"" and netdevs associated with the PF will now be processed
in the loop, however it will not be matching 'phys_port_name' which
ensures the correct behaviour.

In addition to updating the unit test for linux_net and remove not
needed mocks

Conflicts:
      vif_plug_ovs/linux_net.py

Related-Bug: #1892132
Change-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76
(cherry picked from commit cda2a020f1ef92ebdd62c592cbad987977f240e6)
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/14/765914/5 && git format-patch -1 --stdout FETCH_HEAD,"['vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py']",2,44abe7ee9504c698061fc56b7bd9479b07c12af6,stein-refactor-linux-net," @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_ioerror(self, mock__get_phys_switch_id): mock__get_phys_switch_id.side_effect = ([IOError()]) @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_empty(self, mock__get_phys_switch_id): mock__get_phys_switch_id.return_value = '' @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_positive(self, mock__get_phys_switch_id): mock__get_phys_switch_id.return_value = 'pf_sw_id' @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, '_get_phys_switch_id') def test_get_representor_port(self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = (['1', ""pf0vf1"", ""pf0vf2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""2"" mock__get_phys_port_name.side_effect = ( [""p1"", ""p2"", ""VF1@PF1"", ""pf2vf1"", ""vf2@pf1"", ""pf2vf2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = ( [""p0"", ""1"", ""2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.side_effect = ( mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = ( [""p0"", ""pf0vf0"", ""pf0vf1""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_phys_port_name.side_effect = (['p0', '1', 'a']) mock__get_pf_func.return_value = ""0"" @mock.patch.object(linux_net, '_get_phys_switch_id') def test_physical_function_interface_name( self, mock__get_phys_switch_id, mock_listdir): mock__get_phys_switch_id.side_effect = ( @mock.patch.object(linux_net, '_get_phys_switch_id') def test_physical_function_interface_name_with_switchdev( self, mock__get_phys_switch_id, mock_listdir): mock__get_phys_switch_id.side_effect = ( @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test__get_phys_port_name(self, mock_isfile, mock_open): mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.return_value = 'pf0vf0' mock_isfile.return_value = True phys_port_name = linux_net._get_phys_port_name(""vf_ifname"") self.assertEqual(phys_port_name, 'pf0vf0') @mock.patch.object(os.path, 'isfile') def test__get_phys_port_name_not_found(self, mock_isfile): mock_isfile.return_value = False phys_port_name = linux_net._get_phys_port_name(""vf_ifname"") self.assertIsNone(phys_port_name) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test__get_phys_switch_id(self, mock_isfile, mock_open): mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.return_value = '66e40000039b0398' mock_isfile.return_value = True phys_port_name = linux_net._get_phys_switch_id(""ifname"") self.assertEqual(phys_port_name, '66e40000039b0398') @mock.patch.object(os.path, 'isfile') def test__get_phys_switch_id_not_found(self, mock_isfile): mock_isfile.return_value = False phys_port_name = linux_net._get_phys_switch_id(""ifname"") self.assertIsNone(phys_port_name)"," @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_ioerror(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( [IOError()]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_empty(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['']) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_positive(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id']) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") def test_get_representor_port(self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', 'pf0vf2']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False), (""0000:0a:00.0"", True)]) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_1/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_1/phys_port_name', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_2/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_2/phys_port_name', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True, True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', 'VF1@PF1', 'pf_sw_id', 'vf2@pf1', 'pf_sw_id', 'pf2vf1', 'pf_sw_id', 'pf2vf2']) # PCI IDs mocked: # PF1: 0000:0a:00.1 PF2: 0000:0a:00.2 # PF1VF1: 0000:0a:02.1 PF1VF2: 0000:0a:02.2 # PF2VF1: 0000:0a:04.1 PF2VF2: 0000:0a:04.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.1"", True), (""0000:0a:00.2"", True), (""0000:0a:02.1"", False), (""0000:0a:00.2"", True), (""0000:0a:02.2"", False), (""0000:0a:00.2"", True), (""0000:0a:04.1"", False), (""0000:0a:00.2"", True), (""0000:0a:04.2"", False), (""0000:0a:00.2"", True)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', '2']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False), (""0000:0a:00.0"", True)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', 'a']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_physical_function_inferface_name( self, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_physical_function_inferface_name_with_switchdev( self, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = (",149,187
openstack%2Fnova~stable%2Fstein~I53f3a062ce419d1142d7dd3103fab565bb105e05,openstack/nova,stable/stein,I53f3a062ce419d1142d7dd3103fab565bb105e05,Exec systemd-run without --user flag in Quobyte driver,ABANDONED,2019-05-22 12:47:17.000000000,2022-11-11 18:38:20.000000000,,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 13915}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-05-22 12:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/feff5a21aa5eda9a076397acbfd8d986eddd1a9f', 'message': 'Exec systemd-run without --user flag in Quobyte driver\n\nRemoves the --user flag from the systemd based mount command in the\nQuobyte driver. This prevents mount failures due to:\n- Older systemd releases not supporting the --user flag (e.g. CentOS)\n- Systemd versions having a bug preventing running the --scope and\n  --user flags together\n- processutils context not allowing mount to run with this flag\n(see bug referenced below for details)\n\nFurthermore the systemd detection is fixed and\nall mount and umount commands are moved to libvirt privsep.\n\nCloses-Bug: #1756823\n\nChange-Id: I53f3a062ce419d1142d7dd3103fab565bb105e05\n(cherry picked from commit 7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4)\n'}, {'number': 2, 'created': '2019-09-03 12:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed4e39853ace96296bcda89b69f2c66d0d8f5ab8', 'message': 'Exec systemd-run without --user flag in Quobyte driver\n\nRemoves the --user flag from the systemd based mount command in the\nQuobyte driver. This prevents mount failures due to:\n- Older systemd releases not supporting the --user flag (e.g. CentOS)\n- Systemd versions having a bug preventing running the --scope and\n  --user flags together\n- processutils context not allowing mount to run with this flag\n(see bug referenced below for details)\n\nFurthermore the systemd detection is fixed.\n\nCloses-Bug: #1756823\n\nChange-Id: I53f3a062ce419d1142d7dd3103fab565bb105e05\n(cherry picked from commit 7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4)\n'}, {'number': 3, 'created': '2019-09-04 11:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/584de531ac9991b9f1b7545b0d8a74f8c7d4566a', 'message': 'Exec systemd-run without --user flag in Quobyte driver\n\nRemoves the --user flag from the systemd based mount command in the\nQuobyte driver. This prevents mount failures due to:\n- Older systemd releases not supporting the --user flag (e.g. CentOS)\n- Systemd versions having a bug preventing running the --scope and\n  --user flags together\n- processutils context not allowing mount to run with this flag\n(see bug referenced below for details)\n\nFurthermore the systemd detection is fixed.\n\nNote: The privsep extension originally included in the change is\nnot part of this backport.\n\nCloses-Bug: #1756823\n\nChange-Id: I53f3a062ce419d1142d7dd3103fab565bb105e05\n(cherry picked from commit 7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4)\n'}, {'number': 4, 'created': '2019-09-23 09:09:45.000000000', 'files': ['releasenotes/notes/bug-1756823-fix-d3a999a258019c54.yaml', 'nova/virt/libvirt/volume/quobyte.py', 'nova/tests/unit/virt/libvirt/volume/test_quobyte.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/876f89abda9156ece1e8bd09e812be36d2b36c71', 'message': 'Exec systemd-run without --user flag in Quobyte driver\n\nRemoves the --user flag from the systemd based mount command in the\nQuobyte driver. This prevents mount failures due to:\n- Older systemd releases not supporting the --user flag (e.g. CentOS)\n- Systemd versions having a bug preventing running the --scope and\n  --user flags together\n- processutils context not allowing mount to run with this flag\n(see bug referenced below for details)\n\nFurthermore the systemd detection is fixed.\n\nNote: The privsep extension originally included in the change is\nnot part of this backport.\n\nCloses-Bug: #1756823\n\nChange-Id: I53f3a062ce419d1142d7dd3103fab565bb105e05\n(cherry picked from commit 7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4)\n'}]",8,660705,876f89abda9156ece1e8bd09e812be36d2b36c71,49,12,4,13915,,,0,"Exec systemd-run without --user flag in Quobyte driver

Removes the --user flag from the systemd based mount command in the
Quobyte driver. This prevents mount failures due to:
- Older systemd releases not supporting the --user flag (e.g. CentOS)
- Systemd versions having a bug preventing running the --scope and
  --user flags together
- processutils context not allowing mount to run with this flag
(see bug referenced below for details)

Furthermore the systemd detection is fixed.

Note: The privsep extension originally included in the change is
not part of this backport.

Closes-Bug: #1756823

Change-Id: I53f3a062ce419d1142d7dd3103fab565bb105e05
(cherry picked from commit 7231f7dee10fa8f9e6cead026f6a5ae3f5b15ae4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/660705/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1756823-fix-d3a999a258019c54.yaml', 'nova/virt/libvirt/volume/quobyte.py', 'nova/privsep/libvirt.py', 'nova/tests/unit/virt/libvirt/volume/test_quobyte.py']",4,feff5a21aa5eda9a076397acbfd8d986eddd1a9f,bug/1756823,"import ddtfrom nova.privsep import libvirt@ddt.ddt @ddt.data(u""starting"", u""running"", u""degraded"") @mock.patch.object(psutil.Process, ""name"", return_value=""systemd"") @mock.patch.object(processutils, ""execute"") def test_quobyte_is_systemd_ok(self, value, mock_execute, mock_proc): mock_execute.return_value = [value, ""fake stderr""] self.assertTrue(quobyte.is_systemd()) mock_execute.assert_called_once_with(""systemctl"", ""is-system-running"", check_exit_code=[0, 1]) mock_proc.assert_called_once() @mock.patch.object(psutil.Process, ""name"", return_value=""NOT_systemd"") def test_quobyte_is_systemd_not(self, mock_exists, mock_proc): self.assertFalse(quobyte.is_systemd()) mock_exists.assert_called_once_with(quobyte.SYSTEMCTL_CHECK_PATH) mock_proc.assert_called_once_with() @mock.patch.object(psutil.Process, ""name"", return_value=""NOT_systemd"") @mock.patch.object(processutils, ""execute"") def test_quobyte_is_systemd_invalid_state(self, mock_exists, mock_execute, mock_proc): mock_execute.return_value = [""FAKE_INACCEPTABLE_STATE"", ""fake stderr""] self.assertFalse(quobyte.is_systemd()) mock_exists.assert_called_once_with(quobyte.SYSTEMCTL_CHECK_PATH) mock_execute.assert_called_once_with(""systemctl"", ""is-system-running"", check_exit_code=[0, 1]) mock_proc.assert_called_once_with() @ddt.data(None, '/some/arbitrary/path') @mock.patch.object(quobyte, ""is_systemd"", return_value=False) @mock.patch.object(libvirt, ""unprivileged_qb_mount"") def test_quobyte_mount_volume_not_systemd(self, value, mock_mount, mock_ensure_tree, mock_is_sysd): quobyte.mount_volume(quobyte_volume, export_mnt_base, value) expected_commands = [mock.call(quobyte_volume, export_mnt_base, cfg_file=value)] mock_mount.assert_has_calls(expected_commands) mock_is_sysd.assert_called_once_with() @ddt.data(None, '/some/arbitrary/path') @mock.patch.object(libvirt, 'systemd_run_qb_mount') @mock.patch.object(quobyte, ""is_systemd"", return_value=True) def test_quobyte_mount_volume_systemd(self, value, mock_ensure_tree, mock_exists, mock_privsep_sysdr): quobyte.mount_volume(quobyte_volume, export_mnt_base, value) mock_exists.assert_called_once_with() mock_privsep_sysdr.assert_called_once_with(quobyte_volume, export_mnt_base, cfg_file=value) @mock.patch.object(quobyte, ""is_systemd"", return_value=False) @mock.patch.object(libvirt, 'unprivileged_qb_mount', side_effect=(processutils. ProcessExecutionError)) def test_quobyte_mount_volume_fails(self, mock_mount, mock_ensure_tree, mock_is_sysd): mock_ensure_tree.assert_called_once_with(export_mnt_base) mock_is_sysd.assert_called_once() @mock.patch.object(quobyte, ""is_systemd"", return_value=False) @mock.patch.object(libvirt, 'unprivileged_qb_umount') def test_quobyte_umount_volume_non_sysd(self, mock_lv_umount, mock_is_sysd): mock_lv_umount.assert_called_once_with(export_mnt_base) mock_is_sysd.assert_called_once() @mock.patch.object(quobyte, ""is_systemd"", return_value=True) @mock.patch.object(libvirt, 'qb_umount') def test_quobyte_umount_volume_sysd(self, mock_lv_umount, mock_exists): mnt_base = '/mnt' quobyte_volume = '192.168.1.1/volume-00001' export_mnt_base = os.path.join(mnt_base, utils.get_hash_str(quobyte_volume)) quobyte.umount_volume(export_mnt_base) mock_lv_umount.assert_called_once_with(export_mnt_base) mock_exists.assert_called_once_with() @mock.patch.object(quobyte, ""is_systemd"", return_value=True) @mock.patch.object(libvirt, 'qb_umount') mock_debug, mock_issysd): mock_issysd.assert_called_once_with() @mock.patch.object(quobyte, ""is_systemd"", return_value=True) @mock.patch.object(libvirt, 'qb_umount', side_effect=(processutils.ProcessExecutionError)) mock_exception, mock_issysd): mock_execute.assert_called_once_with(export_mnt_base) mock_issysd.assert_called_once_with()"," @mock.patch.object(fileutils, ""ensure_tree"") @mock.patch('oslo_concurrency.processutils.execute') def test_quobyte_mount_volume_not_systemd(self, mock_execute, mock_ensure_tree, mock_exists): mnt_base = '/mnt' quobyte_volume = '192.168.1.1/volume-00001' export_mnt_base = os.path.join(mnt_base, utils.get_hash_str(quobyte_volume)) quobyte.mount_volume(quobyte_volume, export_mnt_base) mock_ensure_tree.assert_called_once_with(export_mnt_base) expected_commands = [mock.call('mount.quobyte', '--disable-xattrs', quobyte_volume, export_mnt_base) ] mock_execute.assert_has_calls(expected_commands) mock_exists.assert_called_once_with("" /run/systemd/system"") @mock.patch('oslo_concurrency.processutils.execute') def test_quobyte_mount_volume_systemd(self, mock_execute, mock_ensure_tree, mock_exists): quobyte.mount_volume(quobyte_volume, export_mnt_base) expected_commands = [mock.call('systemd-run', '--scope', '--user', 'mount.quobyte', '--disable-xattrs', quobyte_volume, export_mnt_base) ] mock_execute.assert_has_calls(expected_commands) mock_exists.assert_called_once_with("" /run/systemd/system"") @mock.patch.object(os.path, ""exists"", return_value=False) @mock.patch('oslo_concurrency.processutils.execute') def test_quobyte_mount_volume_with_config(self, mock_execute, mock_ensure_tree, mock_exists): config_file_dummy = ""/etc/quobyte/dummy.conf"" quobyte.mount_volume(quobyte_volume, export_mnt_base, config_file_dummy) expected_commands = [mock.call('mount.quobyte', '--disable-xattrs', quobyte_volume, export_mnt_base, '-c', config_file_dummy) ] mock_execute.assert_has_calls(expected_commands) mock_exists.assert_called_once_with("" /run/systemd/system"") @mock.patch('oslo_concurrency.processutils.execute', side_effect=(processutils. ProcessExecutionError)) def test_quobyte_mount_volume_fails(self, mock_execute, mock_ensure_tree): @mock.patch('oslo_concurrency.processutils.execute') def test_quobyte_umount_volume(self, mock_execute): mock_execute.assert_called_once_with('umount.quobyte', export_mnt_base) @mock.patch('oslo_concurrency.processutils.execute') mock_debug): @mock.patch('oslo_concurrency.processutils.execute', side_effect=(processutils.ProcessExecutionError)) mock_exception):",160,83
openstack%2Fnova~stable%2Fstein~Iaaeae9281301f14f4ae9b43f4a06de58b699fd68,openstack/nova,stable/stein,Iaaeae9281301f14f4ae9b43f4a06de58b699fd68,Hide hypervisor id on windows guests,ABANDONED,2019-06-06 11:57:35.000000000,2022-11-11 18:38:09.000000000,,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 27961}]","[{'number': 1, 'created': '2019-06-06 11:57:35.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/config.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'releasenotes/notes/bug-1779845-8819eea6e91fb09c.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dde1e727909b6b0cefea3bc60fad086b58044329', 'message': ""Hide hypervisor id on windows guests\n\nBlueprints hide-hypervisor-id-flavor-extra-spec [1] and\nadd-kvm-hidden-feature [2] allow hiding KVM's signature for guests,\nwhich is necessary for Nvidia drivers to work in VMs with passthrough\nGPUs.  While this works well for linux guests on KVM, it doesn't work\nfor Windows guests.\n\nFor them, KVM emulates some HyperV features. With the\ncurrent implementation, KVM's signature is hidden, but HyperV's is not,\nand Nvidia drivers don't work in Windows VMs.\n\nThis change generates an extra element in the libvirt xml for Windows\nguests on KVM which obfuscates HyperV's signature too, controlled by the\nexisting image and flavor parameters (img_hide_hypervisor_id and\nhide_hypervisor_id correspondingly). The extra xml element is\n  <vendor_id state='on' value='1234567890ab'/>\nin features/hyperv.\n\n[1] https://blueprints.launchpad.net/nova/+spec/hide-hypervisor-id-flavor-extra-spec\n[2] https://blueprints.launchpad.net/nova/+spec/add-kvm-hidden-feature\n\nChange-Id: Iaaeae9281301f14f4ae9b43f4a06de58b699fd68\nCloses-Bug: 1779845\n(cherry picked from commit ca543438e183b2bd97a08ef781ddeab8303354ed)\n""}]",0,663616,dde1e727909b6b0cefea3bc60fad086b58044329,16,10,1,9373,,,0,"Hide hypervisor id on windows guests

Blueprints hide-hypervisor-id-flavor-extra-spec [1] and
add-kvm-hidden-feature [2] allow hiding KVM's signature for guests,
which is necessary for Nvidia drivers to work in VMs with passthrough
GPUs.  While this works well for linux guests on KVM, it doesn't work
for Windows guests.

For them, KVM emulates some HyperV features. With the
current implementation, KVM's signature is hidden, but HyperV's is not,
and Nvidia drivers don't work in Windows VMs.

This change generates an extra element in the libvirt xml for Windows
guests on KVM which obfuscates HyperV's signature too, controlled by the
existing image and flavor parameters (img_hide_hypervisor_id and
hide_hypervisor_id correspondingly). The extra xml element is
  <vendor_id state='on' value='1234567890ab'/>
in features/hyperv.

[1] https://blueprints.launchpad.net/nova/+spec/hide-hypervisor-id-flavor-extra-spec
[2] https://blueprints.launchpad.net/nova/+spec/add-kvm-hidden-feature

Change-Id: Iaaeae9281301f14f4ae9b43f4a06de58b699fd68
Closes-Bug: 1779845
(cherry picked from commit ca543438e183b2bd97a08ef781ddeab8303354ed)
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/663616/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/config.py', 'nova/tests/unit/virt/libvirt/test_config.py', 'releasenotes/notes/bug-1779845-8819eea6e91fb09c.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,dde1e727909b6b0cefea3bc60fad086b58044329,bug/1779845," @mock.patch.object(host.Host, 'has_min_version', new=mock.Mock(return_value=True)) def _test_get_guest_config_windows_hyperv( self, flavor=None, image_meta=None, hvid_hidden=False): if flavor is not None: instance_ref.flavor = flavor if image_meta is None: image_meta = objects.ImageMeta.from_dict(self.test_image_meta) num_features = 4 if hvid_hidden else 3 self.assertEqual(num_features, len(cfg.features)) if hvid_hidden: self.assertIsInstance(cfg.features[3], vconfig.LibvirtConfigGuestFeatureKvmHidden) self.assertEqual(hvid_hidden, cfg.features[2].vendorid_spoof) def test_get_guest_config_windows_hyperv_feature2(self): self._test_get_guest_config_windows_hyperv() def test_get_guest_config_windows_hyperv_all_hide_flv(self): # Similar to test_get_guest_config_windows_hyperv_feature2 # but also test hiding the HyperV signature with the flavor # extra_spec ""hide_hypervisor_id"" flavor_hide_id = fake_flavor.fake_flavor_obj(self.context, extra_specs={""hide_hypervisor_id"": ""true""}, expected_attrs={""extra_specs""}) # this works for kvm (the default, tested below) and qemu self.flags(virt_type='qemu', group='libvirt') self._test_get_guest_config_windows_hyperv( flavor=flavor_hide_id, hvid_hidden=True) def test_get_guest_config_windows_hyperv_all_hide_img(self): # Similar to test_get_guest_config_windows_hyperv_feature2 # but also test hiding the HyperV signature with the image # property ""img_hide_hypervisor_id"" image_meta = objects.ImageMeta.from_dict({ ""disk_format"": ""raw"", ""properties"": {""img_hide_hypervisor_id"": ""true""}}) self._test_get_guest_config_windows_hyperv( image_meta=image_meta, hvid_hidden=True) def test_get_guest_config_windows_hyperv_all_hide_flv_img(self): # Similar to test_get_guest_config_windows_hyperv_feature2 # but also test hiding the HyperV signature with both the flavor # extra_spec ""hide_hypervisor_id"" and the image property # ""img_hide_hypervisor_id"" flavor_hide_id = fake_flavor.fake_flavor_obj(self.context, extra_specs={""hide_hypervisor_id"": ""true""}, expected_attrs={""extra_specs""}) self.flags(virt_type='qemu', group='libvirt') image_meta = objects.ImageMeta.from_dict({ ""disk_format"": ""raw"", ""properties"": {""img_hide_hypervisor_id"": ""true""}}) self._test_get_guest_config_windows_hyperv( flavor=flavor_hide_id, image_meta=image_meta, hvid_hidden=True)"," @mock.patch.object(host.Host, 'has_min_version') def test_get_guest_config_windows_hyperv_feature2(self, mock_version): mock_version.return_value = True image_meta = objects.ImageMeta.from_dict(self.test_image_meta) self.assertEqual(3, len(cfg.features))",97,10
openstack%2Fnova~stable%2Fstein~I642b1e3ed6de2be4dcc19fe214f84095d2e1d31a,openstack/nova,stable/stein,I642b1e3ed6de2be4dcc19fe214f84095d2e1d31a,Silence amqp heartbeat warning,ABANDONED,2020-05-14 12:20:33.000000000,2022-11-11 18:38:04.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-05-14 12:20:33.000000000', 'files': ['nova/config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f77b645620ab1450e076cfca069695f04f603a3c', 'message': 'Silence amqp heartbeat warning\n\nWhen the nova api is executing under uWSGI or MOD_WSGI\nthe lifetime of the amqp heartbeat thread is controlled\nby the wsgi server. As a result when the nova api is run\nin this configuration we expect that the heartbeat thread\nwill be suspended and heartbeats will be missed when the wsgi\nserver suspends execution of the wsgi application.\n\nThis change adds a python logging filter to suppress\nthe reporting of heartbeat warnings as this behavior is\nexpected. Since the operator cannot do anything to address\nthe issue the warning is just noise and many operators\nand customers find it to be off-putting.\n\nChange-Id: I642b1e3ed6de2be4dcc19fe214f84095d2e1d31a\nCloses-Bug: #1825584\n(cherry picked from commit d6f664524dfa4eecbe3e16fda0fec5359faf84c6)\n(cherry picked from commit 2d98d7c6c241701d5f82cb8031fa738618ebb915)\n(cherry picked from commit bb8a5415d024f77412711da11c46e34591bf6782)\n'}]",0,728059,f77b645620ab1450e076cfca069695f04f603a3c,19,10,1,11604,,,0,"Silence amqp heartbeat warning

When the nova api is executing under uWSGI or MOD_WSGI
the lifetime of the amqp heartbeat thread is controlled
by the wsgi server. As a result when the nova api is run
in this configuration we expect that the heartbeat thread
will be suspended and heartbeats will be missed when the wsgi
server suspends execution of the wsgi application.

This change adds a python logging filter to suppress
the reporting of heartbeat warnings as this behavior is
expected. Since the operator cannot do anything to address
the issue the warning is just noise and many operators
and customers find it to be off-putting.

Change-Id: I642b1e3ed6de2be4dcc19fe214f84095d2e1d31a
Closes-Bug: #1825584
(cherry picked from commit d6f664524dfa4eecbe3e16fda0fec5359faf84c6)
(cherry picked from commit 2d98d7c6c241701d5f82cb8031fa738618ebb915)
(cherry picked from commit bb8a5415d024f77412711da11c46e34591bf6782)
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/728059/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/config.py'],1,f77b645620ab1450e076cfca069695f04f603a3c,bug/1825584,"import logging def rabbit_heartbeat_filter(log_record): # Note the type in the log message was fixed in # change Id11db4113c9b1c3add602192c1e915218704ef27 # but we handle both form to allow this to be backported # without consideration of the version of oslo.messaging used. # TODO(sean-k-mooney): remove support for typo in follow up # to allow this to be easily backported without modification. messages = [ ""Unexpected error during heartbeart thread processing"", ""Unexpected error during heartbeat thread processing""] return not any(msg in log_record.msg for msg in messages) # NOTE(sean-k-mooney): this filter addresses bug #1825584 # https://bugs.launchpad.net/nova/+bug/1825584 # eventlet monkey-patching breaks AMQP heartbeat on uWSGI rabbit_logger = logging.getLogger('oslo.messaging._drivers.impl_rabbit') rabbit_logger.addFilter(rabbit_heartbeat_filter) ",,22,0
openstack%2Fnova~stable%2Fstein~Id094dd90efde09b9a835d4492f4a92b8f8ad296e,openstack/nova,stable/stein,Id094dd90efde09b9a835d4492f4a92b8f8ad296e,Fix invalid assert_has_calls,ABANDONED,2020-09-14 10:33:09.000000000,2022-11-11 18:38:00.000000000,,"[{'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-14 10:33:09.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f80e55dd28fa48e51b079e838dc513069534d835', 'message': 'Fix invalid assert_has_calls\n\nThis is to fix the invalid assert_has_calls usage,\n""assert_has_calls = "" should be ""assert_has_calls("".\n\nChange-Id: Id094dd90efde09b9a835d4492f4a92b8f8ad296e\n(cherry picked from commit 8cb9b84f283e58841a58d5d79b15268ca5da504d)\n(cherry picked from commit 674d1cbabcf5ab2a84718cd1fc7eccaabbb59839)\n(cherry picked from commit c02a60265319281c2bf385360102c69fdccf3676)\n'}]",0,751754,f80e55dd28fa48e51b079e838dc513069534d835,5,4,1,10135,,,0,"Fix invalid assert_has_calls

This is to fix the invalid assert_has_calls usage,
""assert_has_calls = "" should be ""assert_has_calls("".

Change-Id: Id094dd90efde09b9a835d4492f4a92b8f8ad296e
(cherry picked from commit 8cb9b84f283e58841a58d5d79b15268ca5da504d)
(cherry picked from commit 674d1cbabcf5ab2a84718cd1fc7eccaabbb59839)
(cherry picked from commit c02a60265319281c2bf385360102c69fdccf3676)
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/751754/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/compute/test_compute_mgr.py'],1,f80e55dd28fa48e51b079e838dc513069534d835,," mock_remove_vol_conn.assert_has_calls([ bdm in bdms]) mock_delete_attachment.assert_has_calls([ mock.call(self.context, uuids.vol2_attach)])"," mock_remove_vol_conn.assert_has_calls = [ bdm in bdms] mock_delete_attachment.assert_has_calls = [ mock.call(self.context, uuids.vol2_attach)]",4,4
openstack%2Fnova~stable%2Fstein~Ibe236988af24a3b43508eec4efbe52a4ed05d45f,openstack/nova,stable/stein,Ibe236988af24a3b43508eec4efbe52a4ed05d45f,libvirt: Use 'writeback' QEMU cache mode when 'none' is not viable,ABANDONED,2020-08-20 13:38:52.000000000,2022-11-11 18:37:52.000000000,,"[{'_account_id': 6962}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-08-20 13:38:52.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'releasenotes/notes/writeback-cache-mode-for-guests-a7e4d2806c956164.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d0fd29330186386396893523a133c2f92efa943c', 'message': 'libvirt: Use \'writeback\' QEMU cache mode when \'none\' is not viable\n\nWhen configuring QEMU cache modes for Nova instances, we use\n\'writethrough\' when \'none\' is not available.  But that\'s not correct,\nbecause of our misunderstanding of how cache modes work.  E.g. the\nfunction disk_cachemode() in the libvirt driver assumes that\n\'writethrough\' and \'none\' cache modes have the same behaviour with\nrespect to host crash safety, which is not at all true.\n\nThe misunderstanding and complexity stems from not realizing that each\nQEMU cache mode is a shorthand to toggle *three* booleans.  Refer to the\nconvenient cache mode table in the code comment (in\nnova/virt/libvirt/driver.py).\n\nAs Kevin Wolf (thanks!), QEMU Block Layer maintainer, explains (I made\na couple of micro edits for clarity):\n\n    The thing that makes \'writethrough\' so safe against host crashes is\n    that it never keeps data in a ""write cache"", but it calls fsync()\n    after _every_ write.  This is also what makes it horribly slow.  But\n    \'cache=none\' doesn\'t do this and therefore doesn\'t provide this kind\n    of safety.  The guest OS must explicitly flush the cache in the\n    right places to make sure data is safe on the disk.  And OSes do\n    that.\n\n    So if \'cache=none\' is safe enough for you, then \'cache=writeback\'\n    should be safe enough for you, too -- because both of them have the\n    boolean \'cache.writeback=on\'.  The difference is only in\n    \'cache.direct\', but \'cache.direct=on\' only bypasses the host kernel\n    page cache and data could still sit in other caches that could be\n    present between QEMU and the disk (such as commonly a volatile write\n    cache on the disk itself).\n\nSo use \'writeback\' mode instead of the debilitatingly slow\n\'writethrough\' for cases where the O_DIRECT-based \'none\' is unsupported.\n\nDo the minimum required update to the `disk_cachemodes` config help\ntext.  (In a future patch, rewrite the cache modes documentation to fix\nconfusing fragments and outdated information.)\n\nCloses-Bug: #1818847\nChange-Id: Ibe236988af24a3b43508eec4efbe52a4ed05d45f\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\nLooks-good-to-me\'d-by: Kevin Wolf <kwolf@redhat.com>\n(cherry picked from commit b9dc86d8d646472195070022ff7ae4c372bef4ca)\n'}]",0,747163,d0fd29330186386396893523a133c2f92efa943c,8,7,1,9373,,,0,"libvirt: Use 'writeback' QEMU cache mode when 'none' is not viable

When configuring QEMU cache modes for Nova instances, we use
'writethrough' when 'none' is not available.  But that's not correct,
because of our misunderstanding of how cache modes work.  E.g. the
function disk_cachemode() in the libvirt driver assumes that
'writethrough' and 'none' cache modes have the same behaviour with
respect to host crash safety, which is not at all true.

The misunderstanding and complexity stems from not realizing that each
QEMU cache mode is a shorthand to toggle *three* booleans.  Refer to the
convenient cache mode table in the code comment (in
nova/virt/libvirt/driver.py).

As Kevin Wolf (thanks!), QEMU Block Layer maintainer, explains (I made
a couple of micro edits for clarity):

    The thing that makes 'writethrough' so safe against host crashes is
    that it never keeps data in a ""write cache"", but it calls fsync()
    after _every_ write.  This is also what makes it horribly slow.  But
    'cache=none' doesn't do this and therefore doesn't provide this kind
    of safety.  The guest OS must explicitly flush the cache in the
    right places to make sure data is safe on the disk.  And OSes do
    that.

    So if 'cache=none' is safe enough for you, then 'cache=writeback'
    should be safe enough for you, too -- because both of them have the
    boolean 'cache.writeback=on'.  The difference is only in
    'cache.direct', but 'cache.direct=on' only bypasses the host kernel
    page cache and data could still sit in other caches that could be
    present between QEMU and the disk (such as commonly a volatile write
    cache on the disk itself).

So use 'writeback' mode instead of the debilitatingly slow
'writethrough' for cases where the O_DIRECT-based 'none' is unsupported.

Do the minimum required update to the `disk_cachemodes` config help
text.  (In a future patch, rewrite the cache modes documentation to fix
confusing fragments and outdated information.)

Closes-Bug: #1818847
Change-Id: Ibe236988af24a3b43508eec4efbe52a4ed05d45f
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
Looks-good-to-me'd-by: Kevin Wolf <kwolf@redhat.com>
(cherry picked from commit b9dc86d8d646472195070022ff7ae4c372bef4ca)
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/747163/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'releasenotes/notes/writeback-cache-mode-for-guests-a7e4d2806c956164.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,d0fd29330186386396893523a133c2f92efa943c,bug/1818847-stable/stein," self.assertEqual(guest_disk.get(""cache""), ""writeback"") self.flags(disk_cachemodes=['block=writeback'], group='libvirt')"," self.assertEqual(guest_disk.get(""cache""), ""writethrough"") self.flags(disk_cachemodes=['block=writethrough'], group='libvirt')",79,29
openstack%2Fnova~stable%2Fstein~Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c,openstack/nova,stable/stein,Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c,libvirt: Log exception when unable to import rbd or rados,ABANDONED,2020-10-14 20:25:23.000000000,2022-11-11 18:37:47.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-10-14 20:25:23.000000000', 'files': ['nova/virt/libvirt/storage/rbd_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cd7a1877a40b794e62086939d94b89bf928b61e9', 'message': ""libvirt: Log exception when unable to import rbd or rados\n\nThis should help provide some context when the RbdDriver later raises a\nRuntimeError if rbd or rados hasn't been imported correctly.\n\nChange-Id: Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c\n(cherry picked from commit aa16dd09ebeb21d0b81682b0b6026de0fe4f23b7)\n(cherry picked from commit 961a355fb314975ee169cbe9ef88eb8537294253)\n(cherry picked from commit 22c86f92ce7ef86675ee8265d43b21997e0df4bc)\n(cherry picked from commit 9c58a663b7999260e1683bae6a828d118aa44fd5)\n""}]",0,758243,cd7a1877a40b794e62086939d94b89bf928b61e9,7,5,1,10135,,,0,"libvirt: Log exception when unable to import rbd or rados

This should help provide some context when the RbdDriver later raises a
RuntimeError if rbd or rados hasn't been imported correctly.

Change-Id: Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c
(cherry picked from commit aa16dd09ebeb21d0b81682b0b6026de0fe4f23b7)
(cherry picked from commit 961a355fb314975ee169cbe9ef88eb8537294253)
(cherry picked from commit 22c86f92ce7ef86675ee8265d43b21997e0df4bc)
(cherry picked from commit 9c58a663b7999260e1683bae6a828d118aa44fd5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/758243/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/storage/rbd_utils.py'],1,cd7a1877a40b794e62086939d94b89bf928b61e9,,"# NOTE(lyarwood): Log exceptions if we fail to import rbd or rados in order to # provide context later if we end up attempting to use the RbdDriver and # raising RuntimeError try: import rados except ImportError: rados = None LOG.exception( ""Unable to import the rados module, this can be ignored if Ceph is "" ""not used within this environment"") try: import rbd except ImportError: rbd = None LOG.exception( ""Unable to import the rbd module, this can be ignored if Ceph is not "" ""used within this environment"") ",try: import rados import rbd except ImportError: rados = None rbd = None ,20,7
openstack%2Fnova~stable%2Fstein~I34c68df1e6330dab1524aa0abec733610211a407,openstack/nova,stable/stein,I34c68df1e6330dab1524aa0abec733610211a407,"api: Set min, maxItems for server_group.policies field",ABANDONED,2021-01-27 16:40:46.000000000,2022-11-11 18:37:36.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 31321}]","[{'number': 1, 'created': '2021-01-27 16:40:46.000000000', 'files': ['releasenotes/notes/bug-1894966-d25c12b1320cb910.yaml', 'nova/tests/functional/regressions/test_bug_1894966.py', 'nova/api/openstack/compute/schemas/server_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/77899969c38b31b7b7623516e5ffd5b6b4a2766a', 'message': ""api: Set min, maxItems for server_group.policies field\n\nAs noted inline, the 'policies' field may be a list but it expects one\nof two items.\n\nChange-Id: I34c68df1e6330dab1524aa0abec733610211a407\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nCloses-Bug: #1894966\n(cherry picked from commit 32c43fc8017ee89d4e6cdf79086d87735a00f0c0)\n(cherry picked from commit 781210bd598c3e0ee9bd6a7db5d25688b5fc0131)\n(cherry picked from commit 1634d3f59ace0206131992e31ee2d4b64123d7e8)\n""}]",0,772721,77899969c38b31b7b7623516e5ffd5b6b4a2766a,6,3,1,9373,,,0,"api: Set min, maxItems for server_group.policies field

As noted inline, the 'policies' field may be a list but it expects one
of two items.

Change-Id: I34c68df1e6330dab1524aa0abec733610211a407
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Closes-Bug: #1894966
(cherry picked from commit 32c43fc8017ee89d4e6cdf79086d87735a00f0c0)
(cherry picked from commit 781210bd598c3e0ee9bd6a7db5d25688b5fc0131)
(cherry picked from commit 1634d3f59ace0206131992e31ee2d4b64123d7e8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/772721/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1894966-d25c12b1320cb910.yaml', 'nova/tests/functional/regressions/test_bug_1894966.py', 'nova/api/openstack/compute/schemas/server_groups.py']",3,77899969c38b31b7b7623516e5ffd5b6b4a2766a,bug/1894966-stable/stein," # enumerated values. It's changed to a single string value # in 2.64. 'items': [ { 'type': 'string', 'enum': ['anti-affinity', 'affinity'], }, ], 'minItems': 1, 'maxItems': 1,"," # enumerated values. So this is really just a single string # value, but for legacy reasons is an array. We could # probably change the type from array to string with a # microversion at some point but it's very low priority. 'items': [{ 'type': 'string', 'enum': ['anti-affinity', 'affinity']}],",22,9
openstack%2Fnova~stable%2Fstein~I72e85855f621d3a51cd58d14247abd302dcd958b,openstack/nova,stable/stein,I72e85855f621d3a51cd58d14247abd302dcd958b,tests: Add regression test for bug 1894966,ABANDONED,2021-01-27 16:38:26.000000000,2022-11-11 18:37:27.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 31321}]","[{'number': 1, 'created': '2021-01-27 16:38:26.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1894966.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd75035d688bba668cd594b213c1ed3a2516203', 'message': ""tests: Add regression test for bug 1894966\n\nYou must specify the 'policies' field. Currently, not doing so will\nresult in a HTTP 500 error code. This should be a 4xx error. Add a test\nto demonstrate the bug before we provide a fix.\n\nChanges:\n  nova/tests/functional/regressions/test_bug_1894966.py\n\nNOTE(stephenfin): Need to update 'super' call to Python 2-compatible\nvariant.\n\nChange-Id: I72e85855f621d3a51cd58d14247abd302dcd958b\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nRelated-Bug: #1894966\n(cherry picked from commit 2c66962c7a40d8ef4fab54324e06edcdec1bd716)\n(cherry picked from commit 94d24e3e8d04488abdebd4969daf98b780125297)\n(cherry picked from commit cf6db29168c4ee9a34f3b3ebdd1deae31f95f203)\n""}]",0,772720,1fd75035d688bba668cd594b213c1ed3a2516203,5,3,1,9373,,,0,"tests: Add regression test for bug 1894966

You must specify the 'policies' field. Currently, not doing so will
result in a HTTP 500 error code. This should be a 4xx error. Add a test
to demonstrate the bug before we provide a fix.

Changes:
  nova/tests/functional/regressions/test_bug_1894966.py

NOTE(stephenfin): Need to update 'super' call to Python 2-compatible
variant.

Change-Id: I72e85855f621d3a51cd58d14247abd302dcd958b
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Related-Bug: #1894966
(cherry picked from commit 2c66962c7a40d8ef4fab54324e06edcdec1bd716)
(cherry picked from commit 94d24e3e8d04488abdebd4969daf98b780125297)
(cherry picked from commit cf6db29168c4ee9a34f3b3ebdd1deae31f95f203)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/772720/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1894966.py'],1,1fd75035d688bba668cd594b213c1ed3a2516203,bug/1894966-stable/stein,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from nova import test from nova.tests import fixtures as nova_fixtures from nova.tests.functional.api import client from nova.tests.functional import integrated_helpers class TestCreateServerGroupWithEmptyPolicies( test.TestCase, integrated_helpers.InstanceHelperMixin, ): """"""Demonstrate bug #1894966. Attempt to create a server group with an invalid 'policies' field. It should fail cleanly. """""" def setUp(self): super(TestCreateServerGroupWithEmptyPolicies, self).setUp() api_fixture = self.useFixture(nova_fixtures.OSAPIFixture( api_version='v2.1')) self.api = api_fixture.api self.api.microversion = '2.63' # the last version with the bug def test_create_with_empty_policies(self): exc = self.assertRaises( client.OpenStackApiException, self.api.post_server_groups, {'name': 'test group', 'policies': []}) # FIXME(stephenfin): This should not be a 500 error self.assertEqual(500, exc.response.status_code) ",,41,0
openstack%2Fnova~stable%2Fstein~Ia2007bc63ef09931ea0197cef29d6a5614ed821a,openstack/nova,stable/stein,Ia2007bc63ef09931ea0197cef29d6a5614ed821a,libvirt: Skip encryption metadata lookups if secret already exists on host,ABANDONED,2020-12-07 09:40:04.000000000,2022-11-11 18:37:23.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-07 09:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dfca56f64cd7884b6da98db43348303d220cf25e', 'message': 'libvirt: Skip encryption metadata lookups if secret already exists on host\n\nWhen connecting an encrypted volume to a host the _attach_encryptor\nmethod will be called in order to either call a legacy os-brick\nencryptor *or* configure a libvirt secret used by libvirt and QEMU to\nnatively decrypt LUKSv1 encrypted volumes. To create this libvirt secret\nthe configured key manager will be queried to provide and then decode\nthe associated secret before this is stashed within libvirt.\n\nThis change simply skips the above when an existing libvirt secret\nassociated with the target volume is found on the host already.\n\nWhile this obviously optimises basic instance lifecycle flows such as a\nsimple power off and on it additionally resolves a more convoluted use\ncase when the ``[DEFAULT]/resume_guests_state_on_host_boot``\nconfigurable is enabled. In this case the compute service has no request\ncontext with which to query the key manager when attempting to restart\ninstances with encrypted volumes attached. As a result any attempt by\nthe compute service to restart an instance with an attached encrypted\nvolume would previously fail.\n\nCloses-Bug: #1905701\nChange-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a\n(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)\n(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)\n(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)\n(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)\n'}, {'number': 2, 'created': '2021-01-15 17:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1609634c3fd77daf9002493624b96ceac91af816', 'message': 'libvirt: Skip encryption metadata lookups if secret already exists on host\n\nWhen connecting an encrypted volume to a host the _attach_encryptor\nmethod will be called in order to either call a legacy os-brick\nencryptor *or* configure a libvirt secret used by libvirt and QEMU to\nnatively decrypt LUKSv1 encrypted volumes. To create this libvirt secret\nthe configured key manager will be queried to provide and then decode\nthe associated secret before this is stashed within libvirt.\n\nThis change simply skips the above when an existing libvirt secret\nassociated with the target volume is found on the host already.\n\nWhile this obviously optimises basic instance lifecycle flows such as a\nsimple power off and on it additionally resolves a more convoluted use\ncase when the ``[DEFAULT]/resume_guests_state_on_host_boot``\nconfigurable is enabled. In this case the compute service has no request\ncontext with which to query the key manager when attempting to restart\ninstances with encrypted volumes attached. As a result any attempt by\nthe compute service to restart an instance with an attached encrypted\nvolume would previously fail.\n\nCloses-Bug: #1905701\nChange-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a\n(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)\n(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)\n(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)\n(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)\n'}, {'number': 3, 'created': '2021-01-19 21:27:14.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug_1905701-fdc7402ffe70d104.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/21c3682bb3d5975dfa352a543b762ffab8322305', 'message': 'libvirt: Skip encryption metadata lookups if secret already exists on host\n\nWhen connecting an encrypted volume to a host the _attach_encryptor\nmethod will be called in order to either call a legacy os-brick\nencryptor *or* configure a libvirt secret used by libvirt and QEMU to\nnatively decrypt LUKSv1 encrypted volumes. To create this libvirt secret\nthe configured key manager will be queried to provide and then decode\nthe associated secret before this is stashed within libvirt.\n\nThis change simply skips the above when an existing libvirt secret\nassociated with the target volume is found on the host already.\n\nWhile this obviously optimises basic instance lifecycle flows such as a\nsimple power off and on it additionally resolves a more convoluted use\ncase when the ``[DEFAULT]/resume_guests_state_on_host_boot``\nconfigurable is enabled. In this case the compute service has no request\ncontext with which to query the key manager when attempting to restart\ninstances with encrypted volumes attached. As a result any attempt by\nthe compute service to restart an instance with an attached encrypted\nvolume would previously fail.\n\nCloses-Bug: #1905701\nChange-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a\n(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)\n(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)\n(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)\n(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)\n'}]",0,765772,21c3682bb3d5975dfa352a543b762ffab8322305,14,1,3,10135,,,0,"libvirt: Skip encryption metadata lookups if secret already exists on host

When connecting an encrypted volume to a host the _attach_encryptor
method will be called in order to either call a legacy os-brick
encryptor *or* configure a libvirt secret used by libvirt and QEMU to
natively decrypt LUKSv1 encrypted volumes. To create this libvirt secret
the configured key manager will be queried to provide and then decode
the associated secret before this is stashed within libvirt.

This change simply skips the above when an existing libvirt secret
associated with the target volume is found on the host already.

While this obviously optimises basic instance lifecycle flows such as a
simple power off and on it additionally resolves a more convoluted use
case when the ``[DEFAULT]/resume_guests_state_on_host_boot``
configurable is enabled. In this case the compute service has no request
context with which to query the key manager when attempting to restart
instances with encrypted volumes attached. As a result any attempt by
the compute service to restart an instance with an attached encrypted
volume would previously fail.

Closes-Bug: #1905701
Change-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a
(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)
(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)
(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)
(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/765772/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug_1905701-fdc7402ffe70d104.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,dfca56f64cd7884b6da98db43348303d220cf25e,bug/1905701," # Mock out find_secret so we don't skip ahead drvr._host.find_secret.return_value = None @mock.patch.object(key_manager, 'API') def test_attach_encryptor_secret_exists(self, mock_key_manager_api): connection_info = {'data': {'volume_id': uuids.volume_id}} drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) with test.nested( mock.patch.object(drvr, '_get_volume_encryption'), mock.patch.object(drvr._host, 'find_secret') ) as (mock_get_volume_encryption, mock_find_secret): drvr._attach_encryptor(self.context, connection_info, None) # Assert we called find_secret and nothing else mock_find_secret.assert_called_once_with('volume', uuids.volume_id) mock_get_volume_encryption.assert_not_called() mock_key_manager_api.assert_not_called() ",,42,1
openstack%2Fnova~stable%2Fstein~Ic5ce2580e7638a47f1ffddb4edbb503bf490504c,openstack/nova,stable/stein,Ic5ce2580e7638a47f1ffddb4edbb503bf490504c,compute: Lock by instance.uuid lock during swap_volume,ABANDONED,2020-10-19 09:06:24.000000000,2022-11-11 18:37:19.000000000,,"[{'_account_id': 10118}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-10-19 09:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65a275673bcf03a97202cc04a9bc8bb0ed60d1e3', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit a53e8471728ba934b55fd6438405f897f07293ca)\n(cherry picked from commit c6f2b873bea90df4a2c1fa3b45c6ac1bc2fac618)\n(cherry picked from commit f6a54d1a0631b478148da8b52e4b4c804ecf70f4)\n'}, {'number': 2, 'created': '2021-03-08 09:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9be0c52439f50ed0fbb9657577c227ce9bb7fc6d', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)\n(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)\n(cherry picked from commit 6540161933ec007d3de01dfc420595664781aa37)\n'}, {'number': 3, 'created': '2021-03-23 09:08:35.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3934507474582fdaf0e743beb735db79bd9ce0cd', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)\n(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)\n(cherry picked from commit fb81b16df09bedadecca9acd234ef137a427e02a)\n'}]",0,758734,3934507474582fdaf0e743beb735db79bd9ce0cd,15,4,3,10135,,,0,"compute: Lock by instance.uuid lock during swap_volume

The libvirt driver is currently the only virt driver implementing swap
volume within Nova. While libvirt itself does support moving between
multiple volumes attached to the same instance at the same time the
current logic within the libvirt driver makes a call to
virDomainGetXMLDesc that fails if there are active block jobs against
any disk attached to the domain.

This change simply uses an instance.uuid based lock in the compute layer
to serialise requests to swap_volume to avoid this from being possible.

Closes-Bug: #1896621
Change-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c
(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)
(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)
(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)
(cherry picked from commit fb81b16df09bedadecca9acd234ef137a427e02a)
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/758734/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,65a275673bcf03a97202cc04a9bc8bb0ed60d1e3,bug/1896621," """"""Replace the old volume with the new volume within the active server :param context: User request context :param old_volume_id: Original volume id :param new_volume_id: New volume id being swapped to :param instance: Instance with original_volume_id attached :param new_attachment_id: ID of the new attachment for new_volume_id """""" @utils.synchronized(instance.uuid) def _do_locked_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id): self._do_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id) _do_locked_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id) def _do_swap_volume(self, context, old_volume_id, new_volume_id, instance, new_attachment_id): """"""Replace the old volume with the new volume within the active server :param context: User request context :param old_volume_id: Original volume id :param new_volume_id: New volume id being swapped to :param instance: Instance with original_volume_id attached :param new_attachment_id: ID of the new attachment for new_volume_id """""" context = context.elevated()"," """"""Swap volume for an instance."""""" context = context.elevated() ",26,2
openstack%2Fnova~stable%2Fstein~I0e068043d8267ab91535413d950a3e154c2234f7,openstack/nova,stable/stein,I0e068043d8267ab91535413d950a3e154c2234f7,libvirt: Ignore device already in the process of unplug errors,ABANDONED,2021-05-26 09:12:43.000000000,2022-11-11 18:37:14.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-05-26 09:12:43.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1cfe6d2506329fa2ad64bfbdd700da77f5edcd50', 'message': 'libvirt: Ignore device already in the process of unplug errors\n\nAt present QEMU will raise an error to libvirt when a device_del request\nis made for a device that has already partially detached through a\nprevious request. This is outlined in more detail in the following\ndownstream Red Hat QEMU bug report:\n\nGet libvirtError ""Device XX is already in the process of unplug"" [..]\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1878659\n\nWithin Nova we can actually ignore this error and allow our existing\nretry logic to attempt again after a short wait, hopefully allowing the\noriginal request to complete removing the device from the domain.\n\nThis change does this and should result in one of the following\ndevice_del requests raising a VIR_ERR_DEVICE_MISSING error from libvirt.\n_try_detach_device should then translate that libvirt error into a\nDeviceNotFound exception which is itself then ignored by all\ndetach_device_with_retry callers and taken to mean that the device has\ndetached successfully.\n\nCloses-Bug: #1923206\nChange-Id: I0e068043d8267ab91535413d950a3e154c2234f7\n(cherry picked from commit 0a7d3794c6dc39976b4cbfe12b1688230ac895a8)\n(cherry picked from commit 972a86d61f6b6f0f3d1af549b081854e6ff016bc)\n(cherry picked from commit 4496dfe72020a9e658b04edcba90ddf7f578465f)\n(cherry picked from commit 5acc9316310028ccb3603d1ff7f0870018f834cd)\n(cherry picked from commit 1032219508e5ac0c2819b80010840eb00afe3313)\n'}]",0,793044,1cfe6d2506329fa2ad64bfbdd700da77f5edcd50,4,2,1,9373,,,0,"libvirt: Ignore device already in the process of unplug errors

At present QEMU will raise an error to libvirt when a device_del request
is made for a device that has already partially detached through a
previous request. This is outlined in more detail in the following
downstream Red Hat QEMU bug report:

Get libvirtError ""Device XX is already in the process of unplug"" [..]
https://bugzilla.redhat.com/show_bug.cgi?id=1878659

Within Nova we can actually ignore this error and allow our existing
retry logic to attempt again after a short wait, hopefully allowing the
original request to complete removing the device from the domain.

This change does this and should result in one of the following
device_del requests raising a VIR_ERR_DEVICE_MISSING error from libvirt.
_try_detach_device should then translate that libvirt error into a
DeviceNotFound exception which is itself then ignored by all
detach_device_with_retry callers and taken to mean that the device has
detached successfully.

Closes-Bug: #1923206
Change-Id: I0e068043d8267ab91535413d950a3e154c2234f7
(cherry picked from commit 0a7d3794c6dc39976b4cbfe12b1688230ac895a8)
(cherry picked from commit 972a86d61f6b6f0f3d1af549b081854e6ff016bc)
(cherry picked from commit 4496dfe72020a9e658b04edcba90ddf7f578465f)
(cherry picked from commit 5acc9316310028ccb3603d1ff7f0870018f834cd)
(cherry picked from commit 1032219508e5ac0c2819b80010840eb00afe3313)
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/793044/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py']",2,1cfe6d2506329fa2ad64bfbdd700da77f5edcd50,bug/1923206-stable/stein, # NOTE(lyarwood): https://bugzilla.redhat.com/1878659 # Ignore this known QEMU bug for the time being # allowing our retry logic to fire again and hopefully # see that the device has been removed asynchronously # by QEMU in the meantime when the next call to detach # raises VIR_ERR_DEVICE_MISSING. if 'already in the process of unplug' in errmsg: LOG.debug('Ignoring QEMU rejecting our request to ' 'detach as it is caused by a previous ' 'request still being in progress.') return,,55,1
openstack%2Fnova~stable%2Fstein~I77b28b9cc8f99b159f628f4655d85ff305a71db8,openstack/nova,stable/stein,I77b28b9cc8f99b159f628f4655d85ff305a71db8,compute: Validate a BDMs disk_bus when provided,ABANDONED,2020-08-03 20:56:56.000000000,2022-11-11 18:37:09.000000000,,"[{'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-08-03 20:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca75c5b2089286246a19ba0982c9790cacba6200', 'message': ""compute: Validate a BDMs disk_bus when provided\n\nPreviously disk_bus values were never validated and could easily end up\nbeing ignored by the underlying virt driver and hypervisor.\n\nFor example, a common mistake made by users is to request a virtio-scsi\ndisk_bus when using the libvirt virt driver. This however isn't a valid\nbus and is ignored, defaulting back to the virtio (virtio-blk) bus.\n\nThis change adds a simple validation in the compute API using the\npotential disk_bus values provided by the DiskBus field class as used\nwhen validating the hw_*_bus image properties.\n\nConflicts:\n  nova/objects/fields.py\n\nNOTE(lyarwood): Conflict as Ibf01437a051815019581ca02d1c5da25c43d09ff\nnot being present in stable/stein. As a result the comment relating to\nediting the DiskBus class from that change is squashed here for context.\n\nCloses-Bug: #1876301\nChange-Id: I77b28b9cc8f99b159f628f4655d85ff305a71db8\n(cherry picked from commit 5913bd889f9d3dfc8d154415e666c821054c229d)\n(cherry picked from commit fb31ae430a2e4f8869e77e31ea0d6a9478f6aa61)\n(cherry picked from commit b06511ca5df660d2c168bd41591b54b763f5cf0f)\n""}, {'number': 2, 'created': '2021-06-25 16:19:01.000000000', 'files': ['api-ref/source/parameters.yaml', 'nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/objects/fields.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4daae0a36b2cf59109a4d579f7a4da9bdff1d09c', 'message': ""compute: Validate a BDMs disk_bus when provided\n\nPreviously disk_bus values were never validated and could easily end up\nbeing ignored by the underlying virt driver and hypervisor.\n\nFor example, a common mistake made by users is to request a virtio-scsi\ndisk_bus when using the libvirt virt driver. This however isn't a valid\nbus and is ignored, defaulting back to the virtio (virtio-blk) bus.\n\nThis change adds a simple validation in the compute API using the\npotential disk_bus values provided by the DiskBus field class as used\nwhen validating the hw_*_bus image properties.\n\nConflicts:\n  nova/objects/fields.py\n\nNOTE(lyarwood): Conflict as Ibf01437a051815019581ca02d1c5da25c43d09ff\nnot being present in stable/stein. As a result the comment relating to\nediting the DiskBus class from that change is squashed here for context.\n\nCloses-Bug: #1876301\nChange-Id: I77b28b9cc8f99b159f628f4655d85ff305a71db8\n(cherry picked from commit 5913bd889f9d3dfc8d154415e666c821054c229d)\n(cherry picked from commit fb31ae430a2e4f8869e77e31ea0d6a9478f6aa61)\n(cherry picked from commit bbc562c572f328cc6ffa9cdbff83ae64672fe5b8)\n""}]",0,744554,4daae0a36b2cf59109a4d579f7a4da9bdff1d09c,12,6,2,10135,,,0,"compute: Validate a BDMs disk_bus when provided

Previously disk_bus values were never validated and could easily end up
being ignored by the underlying virt driver and hypervisor.

For example, a common mistake made by users is to request a virtio-scsi
disk_bus when using the libvirt virt driver. This however isn't a valid
bus and is ignored, defaulting back to the virtio (virtio-blk) bus.

This change adds a simple validation in the compute API using the
potential disk_bus values provided by the DiskBus field class as used
when validating the hw_*_bus image properties.

Conflicts:
  nova/objects/fields.py

NOTE(lyarwood): Conflict as Ibf01437a051815019581ca02d1c5da25c43d09ff
not being present in stable/stein. As a result the comment relating to
editing the DiskBus class from that change is squashed here for context.

Closes-Bug: #1876301
Change-Id: I77b28b9cc8f99b159f628f4655d85ff305a71db8
(cherry picked from commit 5913bd889f9d3dfc8d154415e666c821054c229d)
(cherry picked from commit fb31ae430a2e4f8869e77e31ea0d6a9478f6aa61)
(cherry picked from commit bbc562c572f328cc6ffa9cdbff83ae64672fe5b8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/744554/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/objects/fields.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",7,ca75c5b2089286246a19ba0982c9790cacba6200,bug/1876301," exception.InvalidBDMDiskBus,",,40,4
openstack%2Fnova~stable%2Fstein~I17357d85f845d4160cb7c7784772530a1e92af76,openstack/nova,stable/stein,I17357d85f845d4160cb7c7784772530a1e92af76,Make _rebase_with_qemu_img() generic,ABANDONED,2021-03-16 11:01:16.000000000,2022-11-11 18:37:05.000000000,,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28332}]","[{'number': 1, 'created': '2021-03-16 11:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/43cea4a744930daf3459a3bad294fe60ae135e37', 'message': 'Make _rebase_with_qemu_img() generic\n\nMove volume_delete related logic away from this method, in order to make\nit generic and usable elsewhere.\n\nChange-Id: I17357d85f845d4160cb7c7784772530a1e92af76\nRelated-Bug: #1732428\n(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)\n(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)\n(cherry picked from commit ffcb1705cbb6ddaa3fa4d8881f416f25b763b5e7)\n'}, {'number': 2, 'created': '2021-03-17 18:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d2823df1f80b7bc7cbc3cc9b185af05300a5bef', 'message': 'Make _rebase_with_qemu_img() generic\n\nMove volume_delete related logic away from this method, in order to make\nit generic and usable elsewhere.\n\nChange-Id: I17357d85f845d4160cb7c7784772530a1e92af76\nRelated-Bug: #1732428\n(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)\n(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)\n(cherry picked from commit ffcb1705cbb6ddaa3fa4d8881f416f25b763b5e7)\n'}, {'number': 3, 'created': '2021-07-19 16:40:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f62cc3bea5b814ece3e907964a31a7ea7d7e245a', 'message': 'Make _rebase_with_qemu_img() generic\n\nMove volume_delete related logic away from this method, in order to make\nit generic and usable elsewhere.\n\nNOTE(lyarwood): Conflict caused by I52fbbcac9dc386f24ee81b3321dd0d8355e01976\nlanding in stbale/ussuri.\n\nConflicts:\n  nova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I17357d85f845d4160cb7c7784772530a1e92af76\nRelated-Bug: #1732428\n(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)\n(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)\n(cherry picked from commit c61ceac5d0d0844db85791da167cf224ce360a5f)\n'}, {'number': 4, 'created': '2021-07-20 13:12:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/356d4ad4c402ac2ac99889c9e08583b87bbfd6a8', 'message': 'Make _rebase_with_qemu_img() generic\n\nMove volume_delete related logic away from this method, in order to make\nit generic and usable elsewhere.\n\nChange-Id: I17357d85f845d4160cb7c7784772530a1e92af76\nRelated-Bug: #1732428\n(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)\n(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)\n(cherry picked from commit c61ceac5d0d0844db85791da167cf224ce360a5f)\n'}]",2,780784,356d4ad4c402ac2ac99889c9e08583b87bbfd6a8,15,3,4,10135,,,0,"Make _rebase_with_qemu_img() generic

Move volume_delete related logic away from this method, in order to make
it generic and usable elsewhere.

Change-Id: I17357d85f845d4160cb7c7784772530a1e92af76
Related-Bug: #1732428
(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)
(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)
(cherry picked from commit c61ceac5d0d0844db85791da167cf224ce360a5f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/780784/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,43cea4a744930daf3459a3bad294fe60ae135e37,bug/1885528," @mock.patch('nova.virt.images.qemu_img_info', return_value=mock.Mock(file_format=""fake_fmt"")) @mock.patch('oslo_concurrency.processutils.execute') def test_rebase_with_qemu_img(self, mock_execute, mock_qemu_img_info): """"""rebasing disk image to another backing file"""""" self.drvr._rebase_with_qemu_img(""disk"", ""backing_file"") mock_qemu_img_info.assert_called_once_with(""backing_file"") mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', 'backing_file', '-F', 'fake_fmt', 'disk') # Flatten disk image when no backing file is given. mock_qemu_img_info.reset_mock() mock_execute.reset_mock() self.drvr._rebase_with_qemu_img(""disk"", None) self.assertEqual(0, mock_qemu_img_info.call_count) mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', '', 'disk') ",,37,23
openstack%2Fnova~stable%2Fstein~I58dca95251b607eaff602783fee2fc38e2421944,openstack/nova,stable/stein,I58dca95251b607eaff602783fee2fc38e2421944,Use absolute path during qemu img rebase,ABANDONED,2020-10-09 11:59:27.000000000,2022-11-11 18:37:00.000000000,,"[{'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-09 11:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/223ff0d3871fd7dffaef4dcb030d344996258b48', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 8ffa309d7ab15aaea16a446f89dafee5fea950e7)\n(cherry picked from commit 5fee316b622385951475840fd8ad1b9ad20e8d60)\n'}, {'number': 2, 'created': '2020-10-09 13:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4520c15eb41fbd12520a71ca28724ddc5066285', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit ef69c9b354814b9edfdae471a63001d91a1df348)\n(cherry picked from commit fef16847f451be9754b01c257140e48cb6ad2f52)\n(cherry picked from commit dcfb11d2737f63b78f201d8376ecbc67f52292eb)\n'}, {'number': 3, 'created': '2021-03-16 11:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80c64b455cbb646b920755eb35fa2c5fa5df81b2', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)\n'}, {'number': 4, 'created': '2021-03-17 18:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ae1a82d703170d45a8fee14cc224a3c2b7e89037', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)\n'}, {'number': 5, 'created': '2021-07-19 16:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb2a7c66ddc54156ce15f8cee68aab0afc4c6e27', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit e926ec75e29dcdf3b671811533587bba246a8c45)\n'}, {'number': 6, 'created': '2021-07-20 13:14:07.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/59d3f4e4da7f0dab5fa0936975412327e02ea034', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit e926ec75e29dcdf3b671811533587bba246a8c45)\n'}]",3,757085,59d3f4e4da7f0dab5fa0936975412327e02ea034,19,4,6,10135,,,0,"Use absolute path during qemu img rebase

During an assisted volume snapshot delete request from Cinder nova
removes the snapshot from the backing file chain. During that nova
checks the existence of such file. However in some cases (see the bug
report) the path is relative and therefore os.path.exists fails.

This patch makes sure that nova uses the volume absolute path to make
the backing file path absolute as well.

Closes-Bug #1885528

Change-Id: I58dca95251b607eaff602783fee2fc38e2421944
(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)
(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)
(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)
(cherry picked from commit e926ec75e29dcdf3b671811533587bba246a8c45)
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/757085/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,223ff0d3871fd7dffaef4dcb030d344996258b48,bug/1885528," dom_xml = """""" <domain type='kvm'> <devices> <disk type='file'> <source file='/var/lib/nova/instances/%s/disk1_file'/> <target dev='vda' bus='virtio'/> <serial>0e38683e-f0af-418f-a3f1-6b67ea0f919d</serial> </disk> <disk type='block'> <source dev='/path/to/dev/1'/> <target dev='vdb' bus='virtio' serial='1234'/> </disk> </devices> </domain>"""""" % self.inst['uuid'] dom_xml) mock_qemu_img_info.assert_called_once_with( ""/var/lib/nova/instances/%s/snap.img"" % instance.uuid) mock_execute.assert_called_once_with( 'qemu-img', 'rebase', '-b', '/var/lib/nova/instances/%s/snap.img' % instance.uuid, '-F', 'fake_fmt', '/var/lib/nova/instances/%s/disk1_file' % instance.uuid)"," self.dom_xml) mock_qemu_img_info.assert_called_once_with(""snap.img"") mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', 'snap.img', '-F', 'fake_fmt', 'disk1_file')",33,6
openstack%2Fnova~stable%2Fstein~I8296e4be9f0706fab043451b856efadbb7bd41f6,openstack/nova,stable/stein,I8296e4be9f0706fab043451b856efadbb7bd41f6,Honor [neutron]http_retries in the manual client,ABANDONED,2021-06-07 20:43:43.000000000,2022-11-11 18:36:55.000000000,,"[{'_account_id': 4690}, {'_account_id': 22348}, {'_account_id': 32155}]","[{'number': 1, 'created': '2021-06-07 20:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8389910cf4c68dddf040d30211ad1990ea442c3a', 'message': 'Honor [neutron]http_retries in the manual client\n\nChange Ifb3afb13aff7e103c2e80ade817d0e63b624604a added a nova side\nconfig option for specifying neutron client retries that maps to the\nksa connect_retries config option to provide parity with the cinder and\nglance clients that have nova side config options.\n\nThat change missed passing CONF.neutron.http_retries to the manual\nclient used for calling the port binding API. This sets the\nconnect_retries attribute on the manual ksa client so http_retries\nwill be honored.\n\nCloses-Bug: #1929886\nRelated-Bug: #1866937\n\nChange-Id: I8296e4be9f0706fab043451b856efadbb7bd41f6\n(cherry picked from commit 56eb253e9febccf721df6bca4eb851ad26cb70a6)\n(cherry picked from commit 46aa3f4ec769e948d9eb73604bf9b66f4b0230b0)\n(cherry picked from commit f20346bc00a30c914cbefb48009db776f8e00b09)\n(cherry picked from commit b96f93ed8633d6fd0725c4a11366ffbf38056e65)\n(cherry picket from commit 74e6c821fcb8f686a9b91c093b1db834b59c2856)\n'}, {'number': 2, 'created': '2021-06-08 00:27:39.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/73c9f45b9590586549ce46df8e2f15b8e3b31b44', 'message': 'Honor [neutron]http_retries in the manual client\n\nChange Ifb3afb13aff7e103c2e80ade817d0e63b624604a added a nova side\nconfig option for specifying neutron client retries that maps to the\nksa connect_retries config option to provide parity with the cinder and\nglance clients that have nova side config options.\n\nThat change missed passing CONF.neutron.http_retries to the manual\nclient used for calling the port binding API. This sets the\nconnect_retries attribute on the manual ksa client so http_retries\nwill be honored.\n\nCloses-Bug: #1929886\nRelated-Bug: #1866937\n\nChange-Id: I8296e4be9f0706fab043451b856efadbb7bd41f6\n(cherry picked from commit 56eb253e9febccf721df6bca4eb851ad26cb70a6)\n(cherry picked from commit 46aa3f4ec769e948d9eb73604bf9b66f4b0230b0)\n(cherry picked from commit f20346bc00a30c914cbefb48009db776f8e00b09)\n(cherry picked from commit b96f93ed8633d6fd0725c4a11366ffbf38056e65)\n(cherry picked from commit 74e6c821fcb8f686a9b91c093b1db834b59c2856)\n'}]",1,795138,73c9f45b9590586549ce46df8e2f15b8e3b31b44,19,3,2,9373,,,0,"Honor [neutron]http_retries in the manual client

Change Ifb3afb13aff7e103c2e80ade817d0e63b624604a added a nova side
config option for specifying neutron client retries that maps to the
ksa connect_retries config option to provide parity with the cinder and
glance clients that have nova side config options.

That change missed passing CONF.neutron.http_retries to the manual
client used for calling the port binding API. This sets the
connect_retries attribute on the manual ksa client so http_retries
will be honored.

Closes-Bug: #1929886
Related-Bug: #1866937

Change-Id: I8296e4be9f0706fab043451b856efadbb7bd41f6
(cherry picked from commit 56eb253e9febccf721df6bca4eb851ad26cb70a6)
(cherry picked from commit 46aa3f4ec769e948d9eb73604bf9b66f4b0230b0)
(cherry picked from commit f20346bc00a30c914cbefb48009db776f8e00b09)
(cherry picked from commit b96f93ed8633d6fd0725c4a11366ffbf38056e65)
(cherry picked from commit 74e6c821fcb8f686a9b91c093b1db834b59c2856)
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/795138/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,8389910cf4c68dddf040d30211ad1990ea442c3a,bug/1929886," kcl = neutronapi._get_ksa_client(my_context) self.assertEqual(retries, kcl.connect_retries)",,3,0
openstack%2Fnova~stable%2Fstein~I639dd5af7c039da546eaf9ccce56cbaaa38fa79a,openstack/nova,stable/stein,I639dd5af7c039da546eaf9ccce56cbaaa38fa79a,Add regression test for bug #1908075,ABANDONED,2021-09-21 10:51:13.000000000,2022-11-11 18:36:50.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-09-21 10:51:13.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1908075.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7ae5416299d52f34e03c095c671465f76912fd6e', 'message': 'Add regression test for bug #1908075\n\nNOTE(lyarwood): The following changes are required to allow the test to\npass on stable/train.\n\n- InstanceHelperMixin pulled in for access to a better\n  _build_minimal_create_server_request method\n- api_major_version defined in test class\n- Fake image service stubbed out directing in test class\n- A simple _create_server method is in-lined within the class\n\nRelated-Bug: #1908075\nChange-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a\n(cherry picked from commit ee3a8f02253f1f652785c07ea0be6464ab4bcc11)\n(cherry picked from commit 8e2a3dd2f08a2f0c420bc1da9c02ff6b128c06c5)\n(cherry picked from commit 92ee874947f745508bcd4636fc3f9551bde28b9e)\n'}]",0,810191,7ae5416299d52f34e03c095c671465f76912fd6e,3,2,1,9373,,,0,"Add regression test for bug #1908075

NOTE(lyarwood): The following changes are required to allow the test to
pass on stable/train.

- InstanceHelperMixin pulled in for access to a better
  _build_minimal_create_server_request method
- api_major_version defined in test class
- Fake image service stubbed out directing in test class
- A simple _create_server method is in-lined within the class

Related-Bug: #1908075
Change-Id: I639dd5af7c039da546eaf9ccce56cbaaa38fa79a
(cherry picked from commit ee3a8f02253f1f652785c07ea0be6464ab4bcc11)
(cherry picked from commit 8e2a3dd2f08a2f0c420bc1da9c02ff6b128c06c5)
(cherry picked from commit 92ee874947f745508bcd4636fc3f9551bde28b9e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/91/810191/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1908075.py'],1,7ae5416299d52f34e03c095c671465f76912fd6e,bug/1908075-stable/stein,"# Copyright 2020, Red Hat, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import nova.tests.unit.image.fake from nova.tests import fixtures as nova_fixtures from nova.tests.functional import integrated_helpers class TestVolAttachCinderReset( integrated_helpers.InstanceHelperMixin, integrated_helpers._IntegratedTestBase ): """"""Regression test for bug 1908075. This regression test aims to assert if n-api allows a non-multiattached volume to be attached to multiple instances after an admin has forcibly reset the state of the volume in Cinder. """""" api_major_version = 'v2.1' microversion = 'latest' def setUp(self): super(TestVolAttachCinderReset, self).setUp() self.cinder = self.useFixture(nova_fixtures.CinderFixture(self)) self.fake_image_service =\ nova.tests.unit.image.fake.stub_out_image_service(self) self.image_uuid = list(self.fake_image_service.images)[0] def _create_server(self, name): server = self._build_minimal_create_server_request( self.api, name, image_uuid=self.image_uuid, networks='none') server = self.api.post_server({'server': server}) return self._wait_for_state_change(self.api, server, 'ACTIVE') def test_volume_attach_after_cinder_reset_state(self): volume_id = self.cinder.IMAGE_BACKED_VOL # Launch a server and attach a volume server_a = self._create_server('server_a') self.api.post_server_volume( server_a['id'], {'volumeAttachment': {'volumeId': volume_id}} ) # reset-state of the volume within the cinder fixture, we don't model # the state of the volume within the fixture so this will have to do. del self.cinder.volume_to_attachment[volume_id] self.assertNotIn( volume_id, self.cinder.volume_ids_for_instance(server_a['id'])) # Launch a second server and attempt to attach the same volume again server_b = self._create_server('server_b') # FIXME(lyarwood): n-api shouldn't accept this request as we already # have an active bdm record for this non-multiattach volume. self.api.post_server_volume( server_b['id'], {'volumeAttachment': {'volumeId': volume_id}} ) # Assert that we have bdms within Nova still for this attachment self.assertEqual( volume_id, self.api.get_server_volumes(server_a['id'])[0].get('volumeId')) self.assertEqual( volume_id, self.api.get_server_volumes(server_b['id'])[0].get('volumeId')) # Assert that the new attachment is the only one in the fixture self.assertIn( volume_id, self.cinder.volume_ids_for_instance(server_b['id'])) def test_volume_attach_after_cinder_reset_state_multiattach_volume(self): volume_id = self.cinder.MULTIATTACH_VOL # Launch a server and attach a volume server_a = self._create_server('server_a') self.api.post_server_volume( server_a['id'], {'volumeAttachment': {'volumeId': volume_id}} ) # reset-state of the volume within the cinder fixture, we don't model # the state of the volume within the fixture so this will have to do. del self.cinder.volume_to_attachment[volume_id] self.assertNotIn( volume_id, self.cinder.volume_ids_for_instance(server_a['id'])) # Launch a second server and attempt to attach the same volume again server_b = self._create_server('server_b') # NOTE(lyarwood): Unlike non-multiattach volumes this should always be # allowed as we can have multiple active bdms for multiattached volumes self.api.post_server_volume( server_b['id'], {'volumeAttachment': {'volumeId': volume_id}} ) # Assert that we have bdms within Nova still for this attachment self.assertEqual( volume_id, self.api.get_server_volumes(server_a['id'])[0].get('volumeId')) self.assertEqual( volume_id, self.api.get_server_volumes(server_b['id'])[0].get('volumeId')) # Assert that the new attachment is the only one in the fixture self.assertIn( volume_id, self.cinder.volume_ids_for_instance(server_b['id'])) ",,122,0
openstack%2Fnova~stable%2Fstein~Idec2d31cbba497dc4b20912f3388ad2341951d23,openstack/nova,stable/stein,Idec2d31cbba497dc4b20912f3388ad2341951d23,Abort live-migration during instance_init,ABANDONED,2021-09-01 09:49:55.000000000,2022-11-11 18:36:46.000000000,,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28332}, {'_account_id': 31827}, {'_account_id': 32155}, {'_account_id': 32291}]","[{'number': 1, 'created': '2021-09-01 09:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fdaecc21830829743d6d5038d6d10bab3cc672c', 'message': 'Abort live-migration during instance_init\n\nWhen compute service restart during a live-migration,\nwe lose live-migration monitoring thread. In that case\nit is better to early abort live-migration job before resetting\nstate of instance, this will avoid API to accept further\naction while unmanaged migration process still run in background.\nIt also avoid unexpected/dangerous behavior as describe in related bug.\n\nConflicts:\n\tnova/compute/manager.py\n\nNOTE(s10): Conflict is due to Ia1b3ab0b66fdaf569f6c7a09510f208ee28725b2\nnot being in Stein\n\nChange-Id: Idec2d31cbba497dc4b20912f3388ad2341951d23\nCloses-Bug: #1753676\n(cherry picked from commit 6fa8540f2ce40aacca4fcf588a050ed26f66d24c)\n(cherry picked from commit ebcf6e4ce576285949c5a202f2d7d21dc03156ef)\n'}, {'number': 2, 'created': '2021-09-14 13:09:59.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/db23083dddbea5c2f534c26c602ca0238b73771d', 'message': 'Abort live-migration during instance_init\n\nWhen compute service restart during a live-migration,\nwe lose live-migration monitoring thread. In that case\nit is better to early abort live-migration job before resetting\nstate of instance, this will avoid API to accept further\naction while unmanaged migration process still run in background.\nIt also avoid unexpected/dangerous behavior as describe in related bug.\n\nConflicts:\n\tnova/compute/manager.py\n\nNOTE(s10): Conflict is due to Ia1b3ab0b66fdaf569f6c7a09510f208ee28725b2\nnot being in Stein\n\nChange-Id: Idec2d31cbba497dc4b20912f3388ad2341951d23\nCloses-Bug: #1753676\n(cherry picked from commit ebcf6e4ce576285949c5a202f2d7d21dc03156ef)\n(cherry picked from commit 6fa8540f2ce40aacca4fcf588a050ed26f66d24c)\n'}]",1,806881,db23083dddbea5c2f534c26c602ca0238b73771d,22,6,2,9373,,,0,"Abort live-migration during instance_init

When compute service restart during a live-migration,
we lose live-migration monitoring thread. In that case
it is better to early abort live-migration job before resetting
state of instance, this will avoid API to accept further
action while unmanaged migration process still run in background.
It also avoid unexpected/dangerous behavior as describe in related bug.

Conflicts:
	nova/compute/manager.py

NOTE(s10): Conflict is due to Ia1b3ab0b66fdaf569f6c7a09510f208ee28725b2
not being in Stein

Change-Id: Idec2d31cbba497dc4b20912f3388ad2341951d23
Closes-Bug: #1753676
(cherry picked from commit ebcf6e4ce576285949c5a202f2d7d21dc03156ef)
(cherry picked from commit 6fa8540f2ce40aacca4fcf588a050ed26f66d24c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/806881/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,8fdaecc21830829743d6d5038d6d10bab3cc672c,bug/1753676," def _reset_live_migration(self, context, instance): migration = None try: migration = objects.Migration.get_by_instance_and_status( context, instance.uuid, 'running') if migration: self.live_migration_abort(context, instance, migration.id) except Exception: LOG.exception('Failed to abort live-migration', instance=instance) finally: if migration: self._set_migration_status(migration, 'error') LOG.info('Instance found in migrating state during ' 'startup. Resetting task_state', instance=instance) instance.task_state = None instance.save(expected_task_state=[task_states.MIGRATING]) # host. Abort ongoing migration if still running and reset state. self._reset_live_migration(context, instance)"," # host, so reset the state. instance.task_state = None instance.save(expected_task_state=[task_states.MIGRATING])",34,5
openstack%2Fnova~stable%2Fstein~I48dcb7faa17fe9f8346445a1746cff5845baf358,openstack/nova,stable/stein,I48dcb7faa17fe9f8346445a1746cff5845baf358,Reproduce bug 1897528,ABANDONED,2021-11-04 12:25:22.000000000,2022-11-11 18:36:40.000000000,,"[{'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-11-04 12:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f934504bec465ddb888f3a320d66d9a966e3b81', 'message': 'Reproduce bug 1897528\n\nThe nova-compute fails to start if the hypervisor has PCI addresses\n32bit domain.\n\nChange-Id: I48dcb7faa17fe9f8346445a1746cff5845baf358\nRelated-Bug: #1897528\n(cherry picked from commit 976ac722d36439d16ea4ec1bf5037c482c89ef55)\n(cherry picked from commit 0354d4d9f47354e2b4fc0b2343c27e734fe2e494)\n(cherry picked from commit 8e9859b95c537738d97ade41a8d09670de27ef8d)\n'}, {'number': 2, 'created': '2021-11-04 12:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2199f51a59b1100720704057f0de6601632442e', 'message': 'Reproduce bug 1897528\n\nThe nova-compute fails to start if the hypervisor has PCI addresses\n32bit domain.\n\nChange-Id: I48dcb7faa17fe9f8346445a1746cff5845baf358\nRelated-Bug: #1897528\n(cherry picked from commit 976ac722d36439d16ea4ec1bf5037c482c89ef55)\n(cherry picked from commit 0354d4d9f47354e2b4fc0b2343c27e734fe2e494)\n(cherry picked from commit 8e9859b95c537738d97ade41a8d09670de27ef8d)\n(cherry picked from commit a0d3e6846c8e03ff141343c9bab9d4cbd2066dfc)\n'}, {'number': 3, 'created': '2021-11-04 12:37:33.000000000', 'files': ['nova/tests/unit/pci/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/386287b6a7d495b94115576b2c498b786e4c0628', 'message': 'Reproduce bug 1897528\n\nThe nova-compute fails to start if the hypervisor has PCI addresses\n32bit domain.\n\nChange-Id: I48dcb7faa17fe9f8346445a1746cff5845baf358\nRelated-Bug: #1897528\n(cherry picked from commit 976ac722d36439d16ea4ec1bf5037c482c89ef55)\n(cherry picked from commit 0354d4d9f47354e2b4fc0b2343c27e734fe2e494)\n(cherry picked from commit 8e9859b95c537738d97ade41a8d09670de27ef8d)\n(cherry picked from commit a0d3e6846c8e03ff141343c9bab9d4cbd2066dfc)\n'}]",0,816656,386287b6a7d495b94115576b2c498b786e4c0628,9,2,3,9373,,,0,"Reproduce bug 1897528

The nova-compute fails to start if the hypervisor has PCI addresses
32bit domain.

Change-Id: I48dcb7faa17fe9f8346445a1746cff5845baf358
Related-Bug: #1897528
(cherry picked from commit 976ac722d36439d16ea4ec1bf5037c482c89ef55)
(cherry picked from commit 0354d4d9f47354e2b4fc0b2343c27e734fe2e494)
(cherry picked from commit 8e9859b95c537738d97ade41a8d09670de27ef8d)
(cherry picked from commit a0d3e6846c8e03ff141343c9bab9d4cbd2066dfc)
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/816656/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/pci/test_manager.py'],1,2f934504bec465ddb888f3a320d66d9a966e3b81,bug/1897528,"from nova import exception def test_update_devices_from_hypervisor_resources_32bit_domain(self): self.flags( group='pci', passthrough_whitelist=[ '{""product_id"":""2032"", ""vendor_id"":""8086""}']) # There are systems where 32 bit PCI domain is used. See bug 1897528 # for example. While nova (and qemu) does not support assigning such # devices but the existence of such device in the system should not # lead to an error. fake_pci = { 'compute_node_id': 1, 'address': '10000:00:02.0', 'product_id': '2032', 'vendor_id': '8086', 'request_id': None, 'status': fields.PciDeviceStatus.AVAILABLE, 'dev_type': fields.PciDeviceType.STANDARD, 'parent_addr': None, 'numa_node': 0} fake_pci_devs = [fake_pci] fake_pci_devs_json = jsonutils.dumps(fake_pci_devs) tracker = manager.PciDevTracker(self.fake_context) # We expect that the device with 32bit PCI domain is ignored # tracker.update_devices_from_hypervisor_resources(fake_pci_devs_json) # self.assertEqual(0, len(tracker.pci_devs)) # # This is the bug 1897528 ex = self.assertRaises( exception.PciConfigInvalidWhitelist, tracker.update_devices_from_hypervisor_resources, fake_pci_devs_json) self.assertEqual( 'Invalid PCI devices Whitelist config: property domain (10000) is ' 'greater than the maximum allowable value (FFFF).', str(ex)) ",,37,0
openstack%2Fnova~stable%2Fstein~I59a0746b864610b6a314078cf5661d3d2b84b1d4,openstack/nova,stable/stein,I59a0746b864610b6a314078cf5661d3d2b84b1d4,Ignore PCI devices with 32bit domain,ABANDONED,2021-11-04 12:37:33.000000000,2022-11-11 18:36:26.000000000,,"[{'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-11-04 12:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c2c2588c629d6879db87cf75e71762d581f0c2e', 'message': 'Ignore PCI devices with 32bit domain\n\nNova and QEMU[1] supports PCI devices with a PCI address that has 16 bit\ndomain. However there are hypervisors that reports PCI addresses with\n32 bit domain. While today we cannot assign these to guests this should\nnot prevent the nova-compute service to start.\n\nThis patch changes the PCI manager to ignore such PCI devices.\n\nPlease note that this patch does not change fact that nova does not\nallow specifying PCI addresses with 32bit domain in the\n[pci]/passthrough_whitelist configuration. Such configuration is still\nrejected at nova-compute service startup.\n\nCloses-Bug: #1897528\n\n[1] https://github.com/qemu/qemu/blob/f2a1cf9180f63e88bb38ff21c169da97c3f2bad5/hw/core/qdev-properties.c#L993\n\nNOTE(s10): conflict in doc/source/admin/pci-passthrough.rst is due to\nI2ac7df7d235f0af25f5a99bc8f6abddbae2cb3af not being is Stein.\n\nChange-Id: I59a0746b864610b6a314078cf5661d3d2b84b1d4\n(cherry picked from commit 8c9d6fc8f073cde78b79ae259c9915216f5d59b0)\n(cherry picked from commit 90ffc553d7f4152a6a4a8708787150d3c3c40b03)\n(cherry picked from commit 22daca3e7f33e89b937f03a89db63cf25489e3c9)\n(cherry picked from commit f03f46ee8846571be44e6995eafcb400a0f492e5)\n'}, {'number': 2, 'created': '2021-11-04 13:20:06.000000000', 'files': ['nova/pci/manager.py', 'doc/source/admin/networking.rst', 'nova/conf/pci.py', 'nova/tests/unit/pci/test_manager.py', 'doc/source/admin/pci-passthrough.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f7c5ed9ae6cc32a9bac5bc85e6718fe41c9e41b', 'message': 'Ignore PCI devices with 32bit domain\n\nNova and QEMU[1] supports PCI devices with a PCI address that has 16 bit\ndomain. However there are hypervisors that reports PCI addresses with\n32 bit domain. While today we cannot assign these to guests this should\nnot prevent the nova-compute service to start.\n\nThis patch changes the PCI manager to ignore such PCI devices.\n\nPlease note that this patch does not change fact that nova does not\nallow specifying PCI addresses with 32bit domain in the\n[pci]/passthrough_whitelist configuration. Such configuration is still\nrejected at nova-compute service startup.\n\nCloses-Bug: #1897528\n\n[1] https://github.com/qemu/qemu/blob/f2a1cf9180f63e88bb38ff21c169da97c3f2bad5/hw/core/qdev-properties.c#L993\n\nNOTE(s10): conflict in doc/source/admin/pci-passthrough.rst is due to\nI2ac7df7d235f0af25f5a99bc8f6abddbae2cb3af not being in Stein.\n\nChange-Id: I59a0746b864610b6a314078cf5661d3d2b84b1d4\n(cherry picked from commit 8c9d6fc8f073cde78b79ae259c9915216f5d59b0)\n(cherry picked from commit 90ffc553d7f4152a6a4a8708787150d3c3c40b03)\n(cherry picked from commit 22daca3e7f33e89b937f03a89db63cf25489e3c9)\n(cherry picked from commit f03f46ee8846571be44e6995eafcb400a0f492e5)\n'}]",0,816682,1f7c5ed9ae6cc32a9bac5bc85e6718fe41c9e41b,8,2,2,9373,,,0,"Ignore PCI devices with 32bit domain

Nova and QEMU[1] supports PCI devices with a PCI address that has 16 bit
domain. However there are hypervisors that reports PCI addresses with
32 bit domain. While today we cannot assign these to guests this should
not prevent the nova-compute service to start.

This patch changes the PCI manager to ignore such PCI devices.

Please note that this patch does not change fact that nova does not
allow specifying PCI addresses with 32bit domain in the
[pci]/passthrough_whitelist configuration. Such configuration is still
rejected at nova-compute service startup.

Closes-Bug: #1897528

[1] https://github.com/qemu/qemu/blob/f2a1cf9180f63e88bb38ff21c169da97c3f2bad5/hw/core/qdev-properties.c#L993

NOTE(s10): conflict in doc/source/admin/pci-passthrough.rst is due to
I2ac7df7d235f0af25f5a99bc8f6abddbae2cb3af not being in Stein.

Change-Id: I59a0746b864610b6a314078cf5661d3d2b84b1d4
(cherry picked from commit 8c9d6fc8f073cde78b79ae259c9915216f5d59b0)
(cherry picked from commit 90ffc553d7f4152a6a4a8708787150d3c3c40b03)
(cherry picked from commit 22daca3e7f33e89b937f03a89db63cf25489e3c9)
(cherry picked from commit f03f46ee8846571be44e6995eafcb400a0f492e5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/816682/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/manager.py', 'doc/source/admin/networking.rst', 'nova/conf/pci.py', 'nova/tests/unit/pci/test_manager.py', 'doc/source/admin/pci-passthrough.rst']",5,1c2c2588c629d6879db87cf75e71762d581f0c2e,bug/1897528,.. note:: Nova only supports PCI addresses where the fields are restricted to the following maximum value: * domain - 0xFFFF * bus - 0xFF * slot - 0x1F * function - 0x7 Nova will ignore PCI devices reported by the hypervisor if the address is outside of these ranges. ,,79,16
openstack%2Fnova~stable%2Fstein~Ie36401c782f023d1d5f2623732619105dc2cfa24,openstack/nova,stable/stein,Ie36401c782f023d1d5f2623732619105dc2cfa24,Reject open redirection in the console proxy,ABANDONED,2021-07-29 22:03:00.000000000,2022-11-11 18:36:22.000000000,,"[{'_account_id': 4690}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-07-29 22:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/371a14e6b950e6177484a3fae3b54cdcf046675d', 'message': 'Reject open redirection in the console proxy\n\nOur console proxies (novnc, serial, spice) run in a websockify server\nwhose request handler inherits from the python standard\nSimpleHTTPRequestHandler. There is a known issue [1] in the\nSimpleHTTPRequestHandler which allows open redirects by way of URLs\nin the following format:\n\n  http://vncproxy.my.domain.com//example.com/%2F..\n\nwhich if visited, will redirect a user to example.com.\n\nWe can intercept a request and reject requests that pass a redirection\nURL beginning with ""//"" by implementing the\nSimpleHTTPRequestHandler.send_head() method containing the\nvulnerability to reject such requests with a 400 Bad Request.\n\nThis code is copied from a patch suggested in one of the issue comments\n[2].\n\nCloses-Bug: #1927677\n\n[1] https://bugs.python.org/issue32084\n[2] https://bugs.python.org/issue32084#msg306545\n\nConflicts:\n    nova/tests/unit/console/test_websocketproxy.py\n\nNOTE(melwitt): The conflict is because change\nI23ac1cc79482d0fabb359486a4b934463854cae5 (Allow TLS ciphers/protocols\nto be configurable for console proxies) is not in Train.\n\nChange-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24\n(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)\n(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)\n(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)\n(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)\n(cherry picked from commit 6b612c794a4a842d7ac2044c23ad15c035434170)\n'}, {'number': 2, 'created': '2021-07-29 23:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d62cadbef1147d8bab107c4cdfe2cf1d53d9a92b', 'message': 'Reject open redirection in the console proxy\n\nOur console proxies (novnc, serial, spice) run in a websockify server\nwhose request handler inherits from the python standard\nSimpleHTTPRequestHandler. There is a known issue [1] in the\nSimpleHTTPRequestHandler which allows open redirects by way of URLs\nin the following format:\n\n  http://vncproxy.my.domain.com//example.com/%2F..\n\nwhich if visited, will redirect a user to example.com.\n\nWe can intercept a request and reject requests that pass a redirection\nURL beginning with ""//"" by implementing the\nSimpleHTTPRequestHandler.send_head() method containing the\nvulnerability to reject such requests with a 400 Bad Request.\n\nThis code is copied from a patch suggested in one of the issue comments\n[2].\n\nCloses-Bug: #1927677\n\n[1] https://bugs.python.org/issue32084\n[2] https://bugs.python.org/issue32084#msg306545\n\nChange-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24\n(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)\n(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)\n(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)\n(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)\n(cherry picked from commit 6b612c794a4a842d7ac2044c23ad15c035434170)\n'}, {'number': 3, 'created': '2021-07-30 20:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d28dc537316d9b69a005f407a63c6bd6b8969bd', 'message': 'Reject open redirection in the console proxy\n\nOur console proxies (novnc, serial, spice) run in a websockify server\nwhose request handler inherits from the python standard\nSimpleHTTPRequestHandler. There is a known issue [1] in the\nSimpleHTTPRequestHandler which allows open redirects by way of URLs\nin the following format:\n\n  http://vncproxy.my.domain.com//example.com/%2F..\n\nwhich if visited, will redirect a user to example.com.\n\nWe can intercept a request and reject requests that pass a redirection\nURL beginning with ""//"" by implementing the\nSimpleHTTPRequestHandler.send_head() method containing the\nvulnerability to reject such requests with a 400 Bad Request.\n\nThis code is copied from a patch suggested in one of the issue comments\n[2].\n\nNOTE(melwitt): The unit test differences from the cherry picked change\nare due to differences in the SimpleHTTPRequestHandler in Python 2.7\n[3].\n\nCloses-Bug: #1927677\n\n[1] https://bugs.python.org/issue32084\n[2] https://bugs.python.org/issue32084#msg306545\n[3] https://github.com/python/cpython/blob/v2.7.5/Lib/SocketServer.py#L700\n\nChange-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24\n(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)\n(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)\n(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)\n(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)\n(cherry picked from commit 6b612c794a4a842d7ac2044c23ad15c035434170)\n'}, {'number': 4, 'created': '2021-07-31 01:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cae233d12b33e7ca680f3aac2f4d3b69ea633af', 'message': 'Reject open redirection in the console proxy\n\nNOTE(melwitt): This is the combination of two commits, the bug fix and\na followup change to the unit test to enable it also run on\nPython < 3.6.\n\nOur console proxies (novnc, serial, spice) run in a websockify server\nwhose request handler inherits from the python standard\nSimpleHTTPRequestHandler. There is a known issue [1] in the\nSimpleHTTPRequestHandler which allows open redirects by way of URLs\nin the following format:\n\n  http://vncproxy.my.domain.com//example.com/%2F..\n\nwhich if visited, will redirect a user to example.com.\n\nWe can intercept a request and reject requests that pass a redirection\nURL beginning with ""//"" by implementing the\nSimpleHTTPRequestHandler.send_head() method containing the\nvulnerability to reject such requests with a 400 Bad Request.\n\nThis code is copied from a patch suggested in one of the issue comments\n[2].\n\nCloses-Bug: #1927677\n\n[1] https://bugs.python.org/issue32084\n[2] https://bugs.python.org/issue32084#msg306545\n\nReduce mocking in test_reject_open_redirect for compat\n\nThis is a followup for change Ie36401c782f023d1d5f2623732619105dc2cfa24\nto reduce mocking in the unit test coverage for it.\n\nWhile backporting the bug fix, it was found to be incompatible with\nearlier versions of Python < 3.6 due to a difference in internal\nimplementation [1].\n\nThis reduces the mocking in the unit test to be more agnostic to the\ninternals of the StreamRequestHandler (ancestor of\nSimpleHTTPRequestHandler) and work across Python versions >= 2.7.\n\nRelated-Bug: #1927677\n\n[1] https://github.com/python/cpython/commit/34eeed42901666fce099947f93dfdfc05411f286\n\nChange-Id: I546d376869a992601b443fb95acf1034da2a8f36\n(cherry picked from commit 214cabe6848a1fdb4f5941d994c6cc11107fc4af)\n(cherry picked from commit 9c2f29783734cb5f9cb05a08d328c10e1d16c4f1)\n(cherry picked from commit 94e265f3ca615aa18de0081a76975019997b8709)\n(cherry picked from commit d43b88a33407b1253e7bce70f720a44f7688141f)\n\nChange-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24\n(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)\n(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)\n(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)\n(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)\n(cherry picked from commit 5cb4d618ca67e622bbae24c768f9bdf408570986)\n'}, {'number': 5, 'created': '2021-11-08 15:21:17.000000000', 'files': ['releasenotes/notes/console-proxy-reject-open-redirect-4ac0a7895acca7eb.yaml', 'nova/console/websocketproxy.py', 'nova/tests/unit/console/test_websocketproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c30711bfde264784060413953c69c122f69ac122', 'message': 'Reject open redirection in the console proxy\n\nNOTE(melwitt): This is the combination of two commits, the bug fix and\na followup change to the unit test to enable it also run on\nPython < 3.6.\n\nOur console proxies (novnc, serial, spice) run in a websockify server\nwhose request handler inherits from the python standard\nSimpleHTTPRequestHandler. There is a known issue [1] in the\nSimpleHTTPRequestHandler which allows open redirects by way of URLs\nin the following format:\n\n  http://vncproxy.my.domain.com//example.com/%2F..\n\nwhich if visited, will redirect a user to example.com.\n\nWe can intercept a request and reject requests that pass a redirection\nURL beginning with ""//"" by implementing the\nSimpleHTTPRequestHandler.send_head() method containing the\nvulnerability to reject such requests with a 400 Bad Request.\n\nThis code is copied from a patch suggested in one of the issue comments\n[2].\n\nCloses-Bug: #1927677\n\n[1] https://bugs.python.org/issue32084\n[2] https://bugs.python.org/issue32084#msg306545\n\nReduce mocking in test_reject_open_redirect for compat\n\nThis is a followup for change Ie36401c782f023d1d5f2623732619105dc2cfa24\nto reduce mocking in the unit test coverage for it.\n\nWhile backporting the bug fix, it was found to be incompatible with\nearlier versions of Python < 3.6 due to a difference in internal\nimplementation [1].\n\nThis reduces the mocking in the unit test to be more agnostic to the\ninternals of the StreamRequestHandler (ancestor of\nSimpleHTTPRequestHandler) and work across Python versions >= 2.7.\n\nRelated-Bug: #1927677\n\n[1] https://github.com/python/cpython/commit/34eeed42901666fce099947f93dfdfc05411f286\n\nChange-Id: I546d376869a992601b443fb95acf1034da2a8f36\n(cherry picked from commit 214cabe6848a1fdb4f5941d994c6cc11107fc4af)\n(cherry picked from commit 9c2f29783734cb5f9cb05a08d328c10e1d16c4f1)\n(cherry picked from commit 94e265f3ca615aa18de0081a76975019997b8709)\n(cherry picked from commit d43b88a33407b1253e7bce70f720a44f7688141f)\n\nChange-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24\n(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)\n(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)\n(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)\n(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)\n(cherry picked from commit 04d48527b62a35d912f93bc75613a6cca606df66)\n'}]",7,802935,c30711bfde264784060413953c69c122f69ac122,36,3,5,9373,,,0,"Reject open redirection in the console proxy

NOTE(melwitt): This is the combination of two commits, the bug fix and
a followup change to the unit test to enable it also run on
Python < 3.6.

Our console proxies (novnc, serial, spice) run in a websockify server
whose request handler inherits from the python standard
SimpleHTTPRequestHandler. There is a known issue [1] in the
SimpleHTTPRequestHandler which allows open redirects by way of URLs
in the following format:

  http://vncproxy.my.domain.com//example.com/%2F..

which if visited, will redirect a user to example.com.

We can intercept a request and reject requests that pass a redirection
URL beginning with ""//"" by implementing the
SimpleHTTPRequestHandler.send_head() method containing the
vulnerability to reject such requests with a 400 Bad Request.

This code is copied from a patch suggested in one of the issue comments
[2].

Closes-Bug: #1927677

[1] https://bugs.python.org/issue32084
[2] https://bugs.python.org/issue32084#msg306545

Reduce mocking in test_reject_open_redirect for compat

This is a followup for change Ie36401c782f023d1d5f2623732619105dc2cfa24
to reduce mocking in the unit test coverage for it.

While backporting the bug fix, it was found to be incompatible with
earlier versions of Python < 3.6 due to a difference in internal
implementation [1].

This reduces the mocking in the unit test to be more agnostic to the
internals of the StreamRequestHandler (ancestor of
SimpleHTTPRequestHandler) and work across Python versions >= 2.7.

Related-Bug: #1927677

[1] https://github.com/python/cpython/commit/34eeed42901666fce099947f93dfdfc05411f286

Change-Id: I546d376869a992601b443fb95acf1034da2a8f36
(cherry picked from commit 214cabe6848a1fdb4f5941d994c6cc11107fc4af)
(cherry picked from commit 9c2f29783734cb5f9cb05a08d328c10e1d16c4f1)
(cherry picked from commit 94e265f3ca615aa18de0081a76975019997b8709)
(cherry picked from commit d43b88a33407b1253e7bce70f720a44f7688141f)

Change-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24
(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)
(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)
(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)
(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)
(cherry picked from commit 04d48527b62a35d912f93bc75613a6cca606df66)
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/802935/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/console-proxy-reject-open-redirect-4ac0a7895acca7eb.yaml', 'nova/console/websocketproxy.py', 'nova/tests/unit/console/test_websocketproxy.py']",3,371a14e6b950e6177484a3fae3b54cdcf046675d,bug/1927677," def test_reject_open_redirect(self): # This will test the behavior when an attempt is made to cause an open # redirect. It should be rejected. mock_req = mock.MagicMock() mock_req.makefile().readline.side_effect = [ b'GET //example.com/%2F.. HTTP/1.1\r\n', b'' ] # Collect the response data to verify at the end. The # SimpleHTTPRequestHandler writes the response data by calling the # request socket sendall() method. self.data = b'' def fake_sendall(data): self.data += data mock_req.sendall.side_effect = fake_sendall client_addr = ('8.8.8.8', 54321) mock_server = mock.MagicMock() # This specifies that the server will be able to handle requests other # than only websockets. mock_server.only_upgrade = False # Constructing a handler will process the mock_req request passed in. websocketproxy.NovaProxyRequestHandler( mock_req, client_addr, mock_server) # Verify no redirect happens and instead a 400 Bad Request is returned. self.data = self.data.decode() self.assertIn('Error code: 400', self.data) self.assertIn('Message: URI must not start with //', self.data) ",,76,0
openstack%2Fnova~stable%2Fstein~Ie904d1513b5cf76d6d5f6877545e8eb378dd5499,openstack/nova,stable/stein,Ie904d1513b5cf76d6d5f6877545e8eb378dd5499,Add a WA flag waiting for vif-plugged event during reboot,ABANDONED,2021-11-19 16:51:28.000000000,2022-11-11 18:36:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-11-19 16:51:28.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1946729-wait-for-vif-plugged-event-during-hard-reboot-fb491f6a68370bab.yaml', '.zuul.yaml', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3afb13a205d2424022beb6a8e538da383abdd06f', 'message': 'Add a WA flag waiting for vif-plugged event during reboot\n\nThe libvirt driver power on and hard reboot destroys the domain first\nand unplugs the vifs then recreate the domain and replug the vifs.\nHowever nova does not wait for the network-vif-plugged event before\nunpause the domain. This can cause that the domain starts running and\nrequesting IP via DHCP before the networking backend finished plugging\nthe vifs.\n\nSo this patch adds a workaround config option to nova to wait for\nnetwork-vif-plugged events during hard reboot the same way as nova waits\nfor this event during new instance spawn.\n\nThis logic cannot be enabled unconditionally as not all neutron\nnetworking backend sending plug time events to wait for. Also the logic\nneeds to be vnic_type dependent as ml2/ovs and the in tree sriov backend\noften deployed together on the same compute. While ml2/ovs sends plug\ntime event the sriov backend does not send it reliably. So the\nconfiguration is not just a boolean flag but a list of vnic_types\ninstead. This way the waiting for the plug time event for a vif that is\nhandled by ml2/ovs is possible while the instance has other vifs handled\nby the sriov backend where no event can be expected.\n\nConflicts:\n      .zuul.yaml due to Ie3dc90862c895a8bd9bff4511a16254945f45478 not in\n      stable/stein\n      nova/conf/workarounds.py due to\n      I069b6b1d28eaf1eee5c7fb8d0fdef9c0c229a1bf not in stable/stein\n\nChange-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499\nCloses-Bug: #1946729\n(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)\n(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)\n(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)\n(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)\n(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)\n(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)\n'}]",0,818601,3afb13a205d2424022beb6a8e538da383abdd06f,4,1,1,9708,,,0,"Add a WA flag waiting for vif-plugged event during reboot

The libvirt driver power on and hard reboot destroys the domain first
and unplugs the vifs then recreate the domain and replug the vifs.
However nova does not wait for the network-vif-plugged event before
unpause the domain. This can cause that the domain starts running and
requesting IP via DHCP before the networking backend finished plugging
the vifs.

So this patch adds a workaround config option to nova to wait for
network-vif-plugged events during hard reboot the same way as nova waits
for this event during new instance spawn.

This logic cannot be enabled unconditionally as not all neutron
networking backend sending plug time events to wait for. Also the logic
needs to be vnic_type dependent as ml2/ovs and the in tree sriov backend
often deployed together on the same compute. While ml2/ovs sends plug
time event the sriov backend does not send it reliably. So the
configuration is not just a boolean flag but a list of vnic_types
instead. This way the waiting for the plug time event for a vif that is
handled by ml2/ovs is possible while the instance has other vifs handled
by the sriov backend where no event can be expected.

Conflicts:
      .zuul.yaml due to Ie3dc90862c895a8bd9bff4511a16254945f45478 not in
      stable/stein
      nova/conf/workarounds.py due to
      I069b6b1d28eaf1eee5c7fb8d0fdef9c0c229a1bf not in stable/stein

Change-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499
Closes-Bug: #1946729
(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)
(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)
(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)
(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)
(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)
(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/818601/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1946729-wait-for-vif-plugged-event-during-hard-reboot-fb491f6a68370bab.yaml', '.zuul.yaml', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,3afb13a205d2424022beb6a8e538da383abdd06f,bug/1946729," block_device_info=block_device_info, vifs_already_plugged=True, external_events=[]) @mock.patch('oslo_utils.fileutils.ensure_tree', new=mock.Mock()) @mock.patch('nova.virt.libvirt.LibvirtDriver.get_info') @mock.patch('nova.virt.libvirt.LibvirtDriver._create_domain_and_network') @mock.patch('nova.virt.libvirt.LibvirtDriver._get_guest_xml') @mock.patch('nova.virt.libvirt.LibvirtDriver.destroy', new=mock.Mock()) @mock.patch( 'nova.virt.libvirt.LibvirtDriver._get_all_assigned_mediated_devices', new=mock.Mock(return_value={})) def test_hard_reboot_wait_for_plug( self, mock_get_guest_xml, mock_create_domain_and_network, mock_get_info ): self.flags( group=""workarounds"", wait_for_vif_plugged_event_during_hard_reboot=[""normal""]) self.context.auth_token = None instance = objects.Instance(**self.test_instance) network_info = _fake_network_info(self, num_networks=4) network_info[0][""vnic_type""] = ""normal"" network_info[1][""vnic_type""] = ""direct"" network_info[2][""vnic_type""] = ""normal"" network_info[3][""vnic_type""] = ""direct-physical"" block_device_info = None return_values = [hardware.InstanceInfo(state=power_state.SHUTDOWN), hardware.InstanceInfo(state=power_state.RUNNING)] mock_get_info.side_effect = return_values mock_get_guest_xml.return_value = mock.sentinel.xml drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) drvr._hard_reboot( self.context, instance, network_info, block_device_info) mock_create_domain_and_network.assert_called_once_with( self.context, mock.sentinel.xml, instance, network_info, block_device_info=block_device_info, vifs_already_plugged=False, external_events=[ ('network-vif-plugged', uuids.vif1), ('network-vif-plugged', uuids.vif3), ] )"," block_device_info=block_device_info, vifs_already_plugged=True)",149,9
openstack%2Fnova~stable%2Fstein~Id2d8d72d30075200d2b07b847c4e5568599b0d3b,openstack/nova,stable/stein,Id2d8d72d30075200d2b07b847c4e5568599b0d3b,only wait for plugtime events in pre-live-migration,ABANDONED,2021-12-07 10:00:25.000000000,2022-11-11 18:36:13.000000000,,"[{'_account_id': 11604}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 31321}]","[{'number': 1, 'created': '2021-12-07 10:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f49907f20da0919b7c2f251aaca6611c4dc871f0', 'message': 'only wait for plugtime events in pre-live-migration\n\nThis change modifies _get_neutron_events_for_live_migration\nto filter the event to just the subset that will be sent\nat plug-time.\n\nCurrently neuton has a bug where by the dhcp agent\nsend a network-vif-plugged event during live migration after\nwe update the port profile with ""migrating-to:""\nthis cause a network-vif-plugged event to be sent for\nconfiguration where vif_plugging in nova/os-vif is a noop.\n\nwhen that is corrected the current logic in nova cause the migration\nto time out as its waiting for an event that will never arrive.\n\nThis change filters the set of events we wait for to just the plug\ntime events.\n\nConflicts:\n    nova/compute/manager.py\n    nova/tests/unit/compute/test_compute_mgr.py\n\nRelated-Bug: #1815989\nCloses-Bug: #1901707\nChange-Id: Id2d8d72d30075200d2b07b847c4e5568599b0d3b\n(cherry picked from commit 8b33ac064456482158b23c2a2d52f819ebb4c60e)\n(cherry picked from commit ef348c4eb3379189f290217c9351157b1ebf0adb)\n(cherry picked from commit d9c833d5a404dfa206e08c97543e80cb613b3f0b)\n(cherry picked from commit c0a36d917794fed77e75ba9ed853c01a77b540bd)\n'}, {'number': 2, 'created': '2021-12-07 13:20:48.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/network/model.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/da56c045eba7b7f53ec2962ea8b6d744b383817a', 'message': 'only wait for plugtime events in pre-live-migration\n\nThis change modifies _get_neutron_events_for_live_migration\nto filter the event to just the subset that will be sent\nat plug-time.\n\nCurrently neuton has a bug where by the dhcp agent\nsend a network-vif-plugged event during live migration after\nwe update the port profile with ""migrating-to:""\nthis cause a network-vif-plugged event to be sent for\nconfiguration where vif_plugging in nova/os-vif is a noop.\n\nwhen that is corrected the current logic in nova cause the migration\nto time out as its waiting for an event that will never arrive.\n\nThis change filters the set of events we wait for to just the plug\ntime events.\n\nConflicts:\n    nova/tests/unit/compute/test_compute_mgr.py\n\nRelated-Bug: #1815989\nCloses-Bug: #1901707\nChange-Id: Id2d8d72d30075200d2b07b847c4e5568599b0d3b\n(cherry picked from commit 8b33ac064456482158b23c2a2d52f819ebb4c60e)\n(cherry picked from commit ef348c4eb3379189f290217c9351157b1ebf0adb)\n(cherry picked from commit d9c833d5a404dfa206e08c97543e80cb613b3f0b)\n(cherry picked from commit c0a36d917794fed77e75ba9ed853c01a77b540bd)\n'}]",6,820682,da56c045eba7b7f53ec2962ea8b6d744b383817a,14,4,2,9373,,,0,"only wait for plugtime events in pre-live-migration

This change modifies _get_neutron_events_for_live_migration
to filter the event to just the subset that will be sent
at plug-time.

Currently neuton has a bug where by the dhcp agent
send a network-vif-plugged event during live migration after
we update the port profile with ""migrating-to:""
this cause a network-vif-plugged event to be sent for
configuration where vif_plugging in nova/os-vif is a noop.

when that is corrected the current logic in nova cause the migration
to time out as its waiting for an event that will never arrive.

This change filters the set of events we wait for to just the plug
time events.

Conflicts:
    nova/tests/unit/compute/test_compute_mgr.py

Related-Bug: #1815989
Closes-Bug: #1901707
Change-Id: Id2d8d72d30075200d2b07b847c4e5568599b0d3b
(cherry picked from commit 8b33ac064456482158b23c2a2d52f819ebb4c60e)
(cherry picked from commit ef348c4eb3379189f290217c9351157b1ebf0adb)
(cherry picked from commit d9c833d5a404dfa206e08c97543e80cb613b3f0b)
(cherry picked from commit c0a36d917794fed77e75ba9ed853c01a77b540bd)
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/820682/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/network/model.py', 'nova/compute/manager.py']",3,f49907f20da0919b7c2f251aaca6611c4dc871f0,bug/1901707, return (instance.get_network_info() .get_live_migration_plug_time_events())," return [('network-vif-plugged', vif['id']) for vif in instance.get_network_info()]",39,9
openstack%2Fnova~stable%2Fstein~I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527,openstack/nova,stable/stein,I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527,Gracefull recovery when attaching volume fails,ABANDONED,2022-02-18 08:44:29.000000000,2022-11-11 18:36:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-18 08:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9406c0a22f4ad821661a3dfc93f6b72c38e847e', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}, {'number': 2, 'created': '2022-02-22 08:06:17.000000000', 'files': ['releasenotes/notes/bug-1960401-504eb255253d966a.yaml', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9425ad78a95da2d8dc5309dd32867dbc0a3d21a4', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}]",0,829859,9425ad78a95da2d8dc5309dd32867dbc0a3d21a4,7,1,2,29074,,,0,"Gracefull recovery when attaching volume fails

When trying to attach a volume to an already running instance the nova-api
requests the nova-compute service to create a BlockDeviceMapping. If the
nova-api does not receive a response within `rpc_response_timeout` it will
treat the request as failed and raise an exception.

There are multiple cases where nova-compute actually already processed the
request and just the reply did not reach the nova-api in time (see bug report).
After the failed request the database will contain a BlockDeviceMapping entry
for the volume + instance combination that will never be cleaned up again.
This entry also causes the nova-api to reject all future attachments of this
volume to this instance (as it assumes it is already attached).

To work around this we check if a BlockDeviceMapping has already been created
when we see a messaging timeout. If this is the case we can safely delete it
as the compute node has already finished processing and we will no longer pick
it up.
This allows users to try the request again.

A previous fix was abandoned but without a clear reason ([1]).

[1]: https://review.opendev.org/c/openstack/nova/+/731804

Closes-Bug: 1960401
Change-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527
(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/829859/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1960401-504eb255253d966a.yaml', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",3,b9406c0a22f4ad821661a3dfc93f6b72c38e847e,," try: volume_bdm = self._create_volume_bdm( context, instance, device, volume, disk_bus=disk_bus, device_type=device_type, tag=tag) except oslo_exceptions.MessagingTimeout: # The compute node might have already created the attachment but # we never received the answer. In this case it is safe to delete # the attachment as nobody will ever pick it up again. with excutils.save_and_reraise_exception(): try: objects.BlockDeviceMapping.get_by_volume_and_instance( context, volume['id'], instance.uuid).destroy() LOG.debug(""Delete BDM after compute did not respond to "" f""attachment request for volume {volume['id']}"") except exception.VolumeBDMNotFound: LOG.debug(""BDM not found, ignoring removal. "" f""Error attaching volume {volume['id']}"")"," volume_bdm = self._create_volume_bdm( context, instance, device, volume, disk_bus=disk_bus, device_type=device_type, tag=tag)",62,3
openstack%2Fnova~stable%2Fstein~I92f35514efddcb071c7094370b79d91d34c5bc72,openstack/nova,stable/stein,I92f35514efddcb071c7094370b79d91d34c5bc72,compute: Avoid duplicate BDMs during reserve_block_device_name,ABANDONED,2021-08-06 14:27:55.000000000,2022-11-11 18:36:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-08-06 14:27:55.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1937375.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fc33fd8b7e935d8e6a690c18a0907875ac181dcf', 'message': 'compute: Avoid duplicate BDMs during reserve_block_device_name\n\nWhen attaching a volume to a running instance the nova-api validates\nthat the volume is not already attached to the instance. However\nnova-compute is responsible for actually creating the BDM entry in the\ndatabase. If sending attach requests fast enough it can be possible\nthat the same ""attach_volume"" request can be sent to nova-compute for\nthe same volume/instance combination.\n\nTo work around this we add a check in nova-compute to validate that\nthe volume has not been attached in the mean time.\n\nCloses-Bug: #1937375\nChange-Id: I92f35514efddcb071c7094370b79d91d34c5bc72\n(cherry picked from commit 2209b0007fe85d7c5439e0bfdfe2120c63898fa2)\n(cherry picked from commit 2bee83b8a980b2bd9e276b75aa74253f8c0d0a70)\n(cherry picked from commit 303c7a7c35044240f1546a5f960c1a4e6482f385)\n(cherry picked from commit deefea82efd87b001acce7cf8d0fc2915062228b)\n(cherry picked from commit 6ef97792387bf010b92da1e06beefc04d22ff5ff)\n'}]",0,803763,fc33fd8b7e935d8e6a690c18a0907875ac181dcf,5,1,1,29074,,,0,"compute: Avoid duplicate BDMs during reserve_block_device_name

When attaching a volume to a running instance the nova-api validates
that the volume is not already attached to the instance. However
nova-compute is responsible for actually creating the BDM entry in the
database. If sending attach requests fast enough it can be possible
that the same ""attach_volume"" request can be sent to nova-compute for
the same volume/instance combination.

To work around this we add a check in nova-compute to validate that
the volume has not been attached in the mean time.

Closes-Bug: #1937375
Change-Id: I92f35514efddcb071c7094370b79d91d34c5bc72
(cherry picked from commit 2209b0007fe85d7c5439e0bfdfe2120c63898fa2)
(cherry picked from commit 2bee83b8a980b2bd9e276b75aa74253f8c0d0a70)
(cherry picked from commit 303c7a7c35044240f1546a5f960c1a4e6482f385)
(cherry picked from commit deefea82efd87b001acce7cf8d0fc2915062228b)
(cherry picked from commit 6ef97792387bf010b92da1e06beefc04d22ff5ff)
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/803763/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1937375.py', 'nova/compute/manager.py']",3,fc33fd8b7e935d8e6a690c18a0907875ac181dcf,bug/1937375," # Now that we have the lock check that we haven't raced another # request and ensure there is no existing attachment if any(b for b in bdms if b.volume_id == volume_id): msg = _(""volume %s already attached"") % volume_id raise exception.InvalidVolume(reason=msg) ",,41,6
openstack%2Fnova~stable%2Fstein~I332d4f33ea6b9506cc24ac12e5c0994f208a3107,openstack/nova,stable/stein,I332d4f33ea6b9506cc24ac12e5c0994f208a3107,Add functional test for bug 1937375,ABANDONED,2021-08-06 14:27:55.000000000,2022-11-11 18:36:01.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-08-06 14:27:55.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1937375.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/975806f3995e7b09c477859aadd8a5771acd2771', 'message': 'Add functional test for bug 1937375\n\n- InstanceHelperMixin pulled in for access to a better\n  _build_minimal_create_server_request method\n- api_major_version defined in test class\n- Fake image service stubbed out directing in test class\n- A simple _create_server method is in-lined within the class\n\nRelated-Bug: #1937375\nChange-Id: I332d4f33ea6b9506cc24ac12e5c0994f208a3107\n(cherry picked from commit 2ffd9738602531e93495a1feca76bbb687c3e72c)\n(cherry picked from commit 7a9e3dcd172f187cf93f406b09f49d2ded9bd90d)\n(cherry picked from commit 68b2d5f797896768229db1cf28feb22a984daf81)\n(cherry picked from commit 2a67e8794f916af07a05c550dca01d7fca625caf)\n(cherry picked from commit 051a14674195e5d37b931d3b59366656801bc8a1)\n'}]",0,803762,975806f3995e7b09c477859aadd8a5771acd2771,4,2,1,29074,,,0,"Add functional test for bug 1937375

- InstanceHelperMixin pulled in for access to a better
  _build_minimal_create_server_request method
- api_major_version defined in test class
- Fake image service stubbed out directing in test class
- A simple _create_server method is in-lined within the class

Related-Bug: #1937375
Change-Id: I332d4f33ea6b9506cc24ac12e5c0994f208a3107
(cherry picked from commit 2ffd9738602531e93495a1feca76bbb687c3e72c)
(cherry picked from commit 7a9e3dcd172f187cf93f406b09f49d2ded9bd90d)
(cherry picked from commit 68b2d5f797896768229db1cf28feb22a984daf81)
(cherry picked from commit 2a67e8794f916af07a05c550dca01d7fca625caf)
(cherry picked from commit 051a14674195e5d37b931d3b59366656801bc8a1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/803762/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1937375.py'],1,975806f3995e7b09c477859aadd8a5771acd2771,bug/1937375,"# Copyright 2020, Red Hat, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import time import nova.tests.unit.image.fake from nova import context from nova import objects from nova.tests import fixtures as nova_fixtures from nova.tests.functional import integrated_helpers class TestDuplicateVolAttachRace( integrated_helpers.InstanceHelperMixin, integrated_helpers._IntegratedTestBase ): """"""Regression test for bug #1937375 A regression test to assert the behaviour of bug #1937375 where calls to reserve_block_device_name can race and create duplicate bdm records. As we can't recreate the race with pure API driven requests in our functional tests this instead makes duplicate calls to reserve_block_device_name during an attach to mimic the behaviour. """""" api_major_version = 'v2.1' microversion = 'latest' def setUp(self): super(TestDuplicateVolAttachRace, self).setUp() self.cinder = self.useFixture(nova_fixtures.CinderFixture(self)) self.fake_image_service =\ nova.tests.unit.image.fake.stub_out_image_service(self) self.image_uuid = list(self.fake_image_service.images)[0] def _create_server(self): server = self._build_minimal_create_server_request( self.api, 'test', image_uuid=self.image_uuid, networks='none') server = self.api.post_server({'server': server}) return self._wait_for_state_change(self.api, server, 'ACTIVE') # TODO(lyarwood): Copied from test_bug_1675570.py, move both into # _IntegratedTestBase. def _wait_for_volume_attach(self, server_id, volume_id): timeout = 0.0 server = self.api.get_server(server_id) attached_vols = [vol['id'] for vol in server['os-extended-volumes:volumes_attached']] while volume_id not in attached_vols and timeout < 10.0: time.sleep(.1) timeout += .1 server = self.api.get_server(server_id) attached_vols = [vol['id'] for vol in server['os-extended-volumes:volumes_attached']] if volume_id not in attached_vols: self.fail('Timed out waiting for volume %s to be attached to ' 'server %s. Currently attached volumes: %s' % (volume_id, server_id, attached_vols)) def test_duplicate_volume_attach_race(self): ctxt = context.get_admin_context() volume_id = self.cinder.IMAGE_BACKED_VOL server_id = self._create_server()['id'] original_reserve_name = self.compute.manager.reserve_block_device_name def wrap_reserve_block_device_name(*args, **kwargs): # We can't cause a race with duplicate API requests as functional # tests are single threaded and the first would always complete # before the second was serviced. Instead we can wrap # reserve_block_device_name on the compute manager and call it # twice to mimic two callers racing each other after the checks on # the api. original_bdm = original_reserve_name(*args, **kwargs) original_reserve_name(*args, **kwargs) return original_bdm with mock.patch.object( self.compute.manager, 'reserve_block_device_name', wrap_reserve_block_device_name ): self.api.post_server_volume( server_id, {'volumeAttachment': {'volumeId': volume_id}}) # Wait for a volume to be attached self._wait_for_volume_attach(server_id, volume_id) # Fetch all bdms for the instance to assert what we have bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( ctxt, server_id) # FIXME(lyarwood): This is bug #1937375, we now have 3 bdms for the # instance, the original root disk and two duplicate volume bdms for # the same volume attachment. self.assertEqual(3, len(bdms)) self.assertEqual(volume_id, bdms[2].volume_id) self.assertEqual(volume_id, bdms[1].volume_id) self.assertEqual('local', bdms[0].destination_type) ",,115,0
openstack%2Fnova~stable%2Fstein~Ifaa10fedcfcaa564db5524a3e648ff7548a49cd3,openstack/nova,stable/stein,Ifaa10fedcfcaa564db5524a3e648ff7548a49cd3,DNM: check CI health,ABANDONED,2022-08-23 13:12:22.000000000,2022-11-11 18:35:57.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-08-23 13:12:22.000000000', 'files': ['nova/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1e0d98d9418c74bc06cba0e9a2df079220b9f312', 'message': 'DNM: check CI health\n\nChange-Id: Ifaa10fedcfcaa564db5524a3e648ff7548a49cd3\n'}]",0,854184,1e0d98d9418c74bc06cba0e9a2df079220b9f312,4,1,1,17685,,,0,"DNM: check CI health

Change-Id: Ifaa10fedcfcaa564db5524a3e648ff7548a49cd3
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/854184/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/__init__.py'],1,1e0d98d9418c74bc06cba0e9a2df079220b9f312,,# dummy change,,1,0
openstack%2Fnova~stable%2Fstein~I95f68be76330ff09e5eabb5ef8dd9a18f5547866,openstack/nova,stable/stein,I95f68be76330ff09e5eabb5ef8dd9a18f5547866,address open redirect with 3 forward slashes,ABANDONED,2021-11-08 15:29:17.000000000,2022-11-11 18:35:53.000000000,,"[{'_account_id': 9373}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-11-08 15:29:17.000000000', 'files': ['nova/console/websocketproxy.py', 'nova/tests/unit/console/test_websocketproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/df6f8eb8c037abee7e14461eb3a541f5af83a75c', 'message': 'address open redirect with 3 forward slashes\n\nIe36401c782f023d1d5f2623732619105dc2cfa24 was intended\nto address OSSA-2021-002 (CVE-2021-3654) however after its\nrelease it was discovered that the fix only worked\nfor urls with 2 leading slashes or more then 4.\n\nThis change adresses the missing edgecase for 3 leading slashes\nand also maintian support for rejecting 2+.\n\nChange-Id: I95f68be76330ff09e5eabb5ef8dd9a18f5547866\nco-authored-by: Matteo Pozza\nCloses-Bug: #1927677\n(cherry picked from commit 6fbd0b758dcac71323f3be179b1a9d1c17a4acc5)\n(cherry picked from commit 47dad4836a26292e9d34e516e1525ecf00be127c)\n(cherry picked from commit 9588cdbfd4649ea53d60303f2d10c5d62a070a07)\n(cherry picked from commit 0997043f459ac616b594363b5b253bd0ae6ed9eb)\n(cherry picked from commit 8906552cfc2525a44251d4cf313ece61e57251eb)\n'}]",0,817037,df6f8eb8c037abee7e14461eb3a541f5af83a75c,5,3,1,17685,,,0,"address open redirect with 3 forward slashes

Ie36401c782f023d1d5f2623732619105dc2cfa24 was intended
to address OSSA-2021-002 (CVE-2021-3654) however after its
release it was discovered that the fix only worked
for urls with 2 leading slashes or more then 4.

This change adresses the missing edgecase for 3 leading slashes
and also maintian support for rejecting 2+.

Change-Id: I95f68be76330ff09e5eabb5ef8dd9a18f5547866
co-authored-by: Matteo Pozza
Closes-Bug: #1927677
(cherry picked from commit 6fbd0b758dcac71323f3be179b1a9d1c17a4acc5)
(cherry picked from commit 47dad4836a26292e9d34e516e1525ecf00be127c)
(cherry picked from commit 9588cdbfd4649ea53d60303f2d10c5d62a070a07)
(cherry picked from commit 0997043f459ac616b594363b5b253bd0ae6ed9eb)
(cherry picked from commit 8906552cfc2525a44251d4cf313ece61e57251eb)
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/817037/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/console/websocketproxy.py', 'nova/tests/unit/console/test_websocketproxy.py']",2,df6f8eb8c037abee7e14461eb3a541f5af83a75c,bug/1927677," def test_reject_open_redirect_3_slashes(self): # This will test the behavior when an attempt is made to cause an open # redirect. It should be rejected. mock_req = mock.MagicMock() mock_req.makefile().readline.side_effect = [ b'GET ///example.com/%2F.. HTTP/1.1\r\n', b'' ] client_addr = ('8.8.8.8', 54321) mock_server = mock.MagicMock() # This specifies that the server will be able to handle requests other # than only websockets. mock_server.only_upgrade = False # Constructing a handler will process the mock_req request passed in. handler = websocketproxy.NovaProxyRequestHandler( mock_req, client_addr, mock_server) # Collect the response data to verify at the end. The # SimpleHTTPRequestHandler writes the response data to a 'wfile' # attribute. output = io.BytesIO() handler.wfile = output # Process the mock_req again to do the capture. handler.do_GET() output.seek(0) result = output.readlines() # Verify no redirect happens and instead a 400 Bad Request is returned. self.assertIn('400 URI must not start with //', result[0].decode()) ",,33,6
openstack%2Fnova~stable%2Fstein~Ie3129ee395427337e9abcef2f938012608f643e1,openstack/nova,stable/stein,Ie3129ee395427337e9abcef2f938012608f643e1,Ensure MAC addresses characters are in the same case,ABANDONED,2022-09-02 11:49:57.000000000,2022-11-11 18:35:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-09-02 11:49:57.000000000', 'files': ['nova/virt/libvirt/migration.py', 'nova/tests/unit/virt/libvirt/test_migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bfe619e3d980db1e40ce2573a9df5a4b1bf53a9d', 'message': ""Ensure MAC addresses characters are in the same case\n\nCurrently neutron can report ports to have MAC addresses\nin upper case when they're created like that. In the meanwhile\nlibvirt configuration file always stores MAC in lower case\nwhich leads to KeyError while trying to retrieve migrate_vif.\n\nCloses-Bug: #1945646\nChange-Id: Ie3129ee395427337e9abcef2f938012608f643e1\n(cherry picked from commit 6a15169ed9f16672c2cde1d7f27178bb7868c41f)\n(cherry picked from commit 63a6388f6a0265f84232731aba8aec1bff3c6d18)\n(cherry picked from commit 6c3d5de659e558e8f6ee353475b54ff3ca7240ee)\n(cherry picked from commit 28d0059c1f52e51add31bff50f1f6e443c938792)\n(cherry picked from commit 184a3c976faed38907af148a533bc6e9faa410f5)\n(cherry picked from commit a5da31ec1ea1d1c7b4df146857982699ebdc328e)\n""}]",0,855553,bfe619e3d980db1e40ce2573a9df5a4b1bf53a9d,3,1,1,9373,,,0,"Ensure MAC addresses characters are in the same case

Currently neutron can report ports to have MAC addresses
in upper case when they're created like that. In the meanwhile
libvirt configuration file always stores MAC in lower case
which leads to KeyError while trying to retrieve migrate_vif.

Closes-Bug: #1945646
Change-Id: Ie3129ee395427337e9abcef2f938012608f643e1
(cherry picked from commit 6a15169ed9f16672c2cde1d7f27178bb7868c41f)
(cherry picked from commit 63a6388f6a0265f84232731aba8aec1bff3c6d18)
(cherry picked from commit 6c3d5de659e558e8f6ee353475b54ff3ca7240ee)
(cherry picked from commit 28d0059c1f52e51add31bff50f1f6e443c938792)
(cherry picked from commit 184a3c976faed38907af148a533bc6e9faa410f5)
(cherry picked from commit a5da31ec1ea1d1c7b4df146857982699ebdc328e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/855553/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/migration.py', 'nova/tests/unit/virt/libvirt/test_migration.py']",2,bfe619e3d980db1e40ce2573a9df5a4b1bf53a9d,bug/1945646-stable/train-stable/stein," self.assertIn(""ca:fe:de:ad:be:ef"", six.text_type(ex)) def test_update_vif_xml_lower_case_mac(self): """"""Tests that the vif in the migrate data is not found in the existing guest interfaces. """""" conf = vconfig.LibvirtConfigGuestInterface() conf.net_type = ""bridge"" conf.source_dev = ""qbra188171c-ea"" conf.target_dev = ""tapa188171c-ea"" conf.mac_addr = ""DE:AD:BE:EF:CA:FE"" conf.model = ""virtio"" original_xml = """"""<domain> <uuid>3de6550a-8596-4937-8046-9d862036bca5</uuid> <devices> <interface type=""bridge""> <mac address=""de:ad:be:ef:ca:fe""/> <model type=""virtio""/> <source bridge=""qbra188171c-ea""/> <target dev=""tapa188171c-ea""/> <virtualport type=""openvswitch""> <parameters interfaceid=""%s""/> </virtualport> <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/> </interface> </devices> </domain>"""""" % uuids.ovs expected_xml = """"""<domain> <uuid>3de6550a-8596-4937-8046-9d862036bca5</uuid> <devices> <interface type=""bridge""> <mac address=""DE:AD:BE:EF:CA:FE""/> <model type=""virtio""/> <source bridge=""qbra188171c-ea""/> <target dev=""tapa188171c-ea""/> <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/> </interface> </devices> </domain>"""""" self._test_update_vif_xml(conf, original_xml, expected_xml)"," self.assertIn(""CA:FE:DE:AD:BE:EF"", six.text_type(ex))",51,3
openstack%2Fnova~stable%2Fstein~I69ef8d7e5ec1aabc0beb87652fa14eba2bc72ba5,openstack/nova,stable/stein,I69ef8d7e5ec1aabc0beb87652fa14eba2bc72ba5,CI: Ironic is EOL'ing Stein; remove jobs,ABANDONED,2022-10-10 22:22:22.000000000,2022-11-11 18:35:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-10 22:22:22.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/5fdd7a0bd89b6930a2806d6b0410fcf8009eb047', 'message': ""CI: Ironic is EOL'ing Stein; remove jobs\n\nIronic is EOL'ing support for Stein; remove CI jobs related to Ironic\nstein.\n\nChange-Id: I69ef8d7e5ec1aabc0beb87652fa14eba2bc72ba5\n""}]",0,860880,5fdd7a0bd89b6930a2806d6b0410fcf8009eb047,4,1,1,10342,,,0,"CI: Ironic is EOL'ing Stein; remove jobs

Ironic is EOL'ing support for Stein; remove CI jobs related to Ironic
stein.

Change-Id: I69ef8d7e5ec1aabc0beb87652fa14eba2bc72ba5
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/860880/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5fdd7a0bd89b6930a2806d6b0410fcf8009eb047,,, - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false irrelevant-files: *dsvm-irrelevant-files - ironic-tempest-bfv: irrelevant-files: *dsvm-irrelevant-files - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode: irrelevant-files: *dsvm-irrelevant-files,0,7
openstack%2Fos-vif~stable%2Frocky~I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76,openstack/os-vif,stable/rocky,I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76,Refactor code of linux_net to more cleaner and increase performace,ABANDONED,2020-12-08 10:21:53.000000000,2022-11-11 18:34:07.000000000,,"[{'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-12-08 10:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/36f5a2101c562ac407dacf83c5bac5a7f932be75', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 76f7565b99e637d74878955a0033f35e9eb0e13f)\n'}, {'number': 2, 'created': '2020-12-14 13:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/c36d072054567bf3e730f6ea0a0f69592e230359', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_ovs/tests/unit/test_linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 0dca2c12bf5fad55e141516e99ed05a459e8e698)\n'}, {'number': 3, 'created': '2020-12-31 10:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/6d5a0ac7351e7c67196d67c0f28657cfc9baf770', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_ovs/tests/unit/test_linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit fcc88fa53ebbb4a0696323798ad1f2889b4a3cd9)\n'}, {'number': 4, 'created': '2021-01-05 08:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/237a2c1c6b9867a23e6cfff42aeaeace1d6526a1', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_ovs/tests/unit/test_linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 41adc262dac2c2a5647b4c08a4376ffb01731ced)\n'}, {'number': 5, 'created': '2021-01-05 09:58:34.000000000', 'files': ['vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/246b7178414a23e99b3329c5383c4df244724384', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nConflicts:\n      vif_plug_ovs/tests/unit/test_linux_net.py\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 41adc262dac2c2a5647b4c08a4376ffb01731ced)\n'}]",1,765962,246b7178414a23e99b3329c5383c4df244724384,17,4,5,32296,,,0,"Refactor code of linux_net to more cleaner and increase performace

The patch adds new functions '_get_phys_port_name' for reading physical
port name of the SR-IOV port and '_get_phys_switch_id' for reading
physical port switch ID of the SR-IOV port, in addition to refactoring
'get_representor_port' to use the new functions and decrease calls for
""_get_pf_func"" and netdevs associated with the PF will now be processed
in the loop, however it will not be matching 'phys_port_name' which
ensures the correct behaviour.

In addition to updating the unit test for linux_net and remove not
needed mocks

Conflicts:
      vif_plug_ovs/tests/unit/test_linux_net.py

Related-Bug: #1892132
Change-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76
(cherry picked from commit 41adc262dac2c2a5647b4c08a4376ffb01731ced)
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/62/765962/1 && git format-patch -1 --stdout FETCH_HEAD,"['vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py']",2,36f5a2101c562ac407dacf83c5bac5a7f932be75,rep-fix-rocky-backport," @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_ioerror(self, mock__get_phys_switch_id): mock__get_phys_switch_id.side_effect = ([IOError()]) @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_empty(self, mock__get_phys_switch_id): mock__get_phys_switch_id.return_value = '' @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_positive(self, mock__get_phys_switch_id): mock__get_phys_switch_id.return_value = 'pf_sw_id' @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, '_get_phys_switch_id') def test_get_representor_port(self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = (['1', ""pf0vf1"", ""pf0vf2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""2"" mock__get_phys_port_name.side_effect = ( [""p1"", ""p2"", ""VF1@PF1"", ""pf2vf1"", ""vf2@pf1"", ""pf2vf2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = ( [""p0"", ""1"", ""2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.side_effect = ( mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = ( [""p0"", ""pf0vf0"", ""pf0vf1""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_phys_port_name.side_effect = (['p0', '1', 'a']) mock__get_pf_func.return_value = ""0"" @mock.patch.object(linux_net, '_get_phys_switch_id') def test_physical_function_interface_name( self, mock__get_phys_switch_id, mock_listdir): mock__get_phys_switch_id.side_effect = ( @mock.patch.object(linux_net, '_get_phys_switch_id') def test_physical_function_interface_name_with_switchdev( self, mock__get_phys_switch_id, mock_listdir): mock__get_phys_switch_id.side_effect = ( @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test__get_phys_port_name(self, mock_isfile, mock_open): mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.return_value = 'pf0vf0' mock_isfile.return_value = True phys_port_name = linux_net._get_phys_port_name(""vf_ifname"") self.assertEqual(phys_port_name, 'pf0vf0') @mock.patch.object(os.path, 'isfile') def test__get_phys_port_name_not_found(self, mock_isfile): mock_isfile.return_value = False phys_port_name = linux_net._get_phys_port_name(""vf_ifname"") self.assertIsNone(phys_port_name) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test__get_phys_switch_id(self, mock_isfile, mock_open): mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.return_value = '66e40000039b0398' mock_isfile.return_value = True phys_port_name = linux_net._get_phys_switch_id(""ifname"") self.assertEqual(phys_port_name, '66e40000039b0398') @mock.patch.object(os.path, 'isfile') def test__get_phys_switch_id_not_found(self, mock_isfile): mock_isfile.return_value = False phys_port_name = linux_net._get_phys_switch_id(""ifname"") self.assertIsNone(phys_port_name)"," @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_ioerror(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( [IOError()]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_empty(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['']) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_positive(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id']) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") def test_get_representor_port(self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', 'pf0vf2']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False), (""0000:0a:00.0"", True)]) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_1/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_1/phys_port_name', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_2/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_2/phys_port_name', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True, True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', 'VF1@PF1', 'pf_sw_id', 'vf2@pf1', 'pf_sw_id', 'pf2vf1', 'pf_sw_id', 'pf2vf2']) # PCI IDs mocked: # PF1: 0000:0a:00.1 PF2: 0000:0a:00.2 # PF1VF1: 0000:0a:02.1 PF1VF2: 0000:0a:02.2 # PF2VF1: 0000:0a:04.1 PF2VF2: 0000:0a:04.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.1"", True), (""0000:0a:00.2"", True), (""0000:0a:02.1"", False), (""0000:0a:00.2"", True), (""0000:0a:02.2"", False), (""0000:0a:00.2"", True), (""0000:0a:04.1"", False), (""0000:0a:00.2"", True), (""0000:0a:04.2"", False), (""0000:0a:00.2"", True)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', '2']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False), (""0000:0a:00.0"", True)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', 'a']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_physical_function_inferface_name( self, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_physical_function_inferface_name_with_switchdev( self, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = (",149,187
openstack%2Fos-vif~stable%2Frocky~I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7,openstack/os-vif,stable/rocky,I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7,Fix - os-vif fails to get the correct UpLink Representor,ABANDONED,2020-12-08 11:46:36.000000000,2022-11-11 18:34:03.000000000,,"[{'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-12-08 11:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/ce7d8b68219f70cc24d7d3d95b588eb9f2706d34', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit b37de19c58c877f5174d76d0a4ba5ab519f464e8)\n'}, {'number': 2, 'created': '2020-12-16 08:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/58a3014c6e119f10d937dfb7c997414f7f00e6ef', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nConflicts:\n          vif_plug_ovs/linux_net.py\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit 3774df162ce0b44b759660648b3597426f29fea7)\n'}, {'number': 3, 'created': '2021-01-05 08:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/69ede3ed3b44cddc49bb3f8e44d3c9d48de7f009', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nConflicts:\n    vif_plug_ovs/linux_net.py\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit aef047a34384a055abfc15f703df59af4ec47437)\n'}, {'number': 4, 'created': '2021-01-05 09:58:34.000000000', 'files': ['releasenotes/notes/bug-1892132-812e6d5ce0588ebb.yaml', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/32d87ffdfb97aa7fbac3894d292762f6c70d54b5', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nConflicts:\n    vif_plug_ovs/linux_net.py\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit aef047a34384a055abfc15f703df59af4ec47437)\n'}]",0,765977,32d87ffdfb97aa7fbac3894d292762f6c70d54b5,13,4,4,32296,,,0,"Fix - os-vif fails to get the correct UpLink Representor

Till kernel 5.7 PF and VF representors are exposed as virtual device.
They are not linked to its parent PCI device like how uplink
representor is linked.

Starting from kernel 5.8 due to new change [1] the PF and VF representors are
linked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails
to get the correct UpLink Representor.

This patch modifys the behviour of ""get_ifname_by_pci_address"" to
check the physical port name of the netdev in
vf_pci_addr_path/physfn/net to match the formart for the uplink ""p\d+"".

[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1

Conflicts:
    vif_plug_ovs/linux_net.py

Closes-Bug: #1892132
Change-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7
(cherry picked from commit aef047a34384a055abfc15f703df59af4ec47437)
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/77/765977/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1892132-812e6d5ce0588ebb.yaml', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py']",3,ce7d8b68219f70cc24d7d3d95b588eb9f2706d34,rep-fix-rocky-backport," @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): mock__get_phys_port_name.side_effect = ([""p1""]) @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): mock__get_phys_port_name.side_effect = ([""p1s0""]) @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") def test_physical_function_interface_name_with_representors( self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): # Get the PF that matches the phys_port_name regex mock_listdir.return_value = ['enp2s0f0_0', 'enp2s0f0_1', 'enp2s0f0'] mock__get_phys_switch_id.side_effect = ( ['valid_switch', 'valid_switch', 'valid_switch']) mock__get_phys_port_name.side_effect = ([""pf0vf0"", ""pf0vf1"", ""p0""]) ifname = linux_net.get_ifname_by_pci_address( '0000:00:00.1', pf_interface=True, switchdev=True) self.assertEqual(ifname, 'enp2s0f0') @mock.patch.object(os, 'listdir') @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") def test_physical_function_interface_name_with_fallback_To_first_netdev( self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): # Try with switchdev mode to get PF but fail because there is no match # for the phys_port_name then fallback to first interface found mock_listdir.return_value = ['enp2s0f0_0', 'enp2s0f0_1', 'enp2s0f0'] mock__get_phys_switch_id.side_effect = (['valid_switch', 'valid_switch', 'valid_switch']) mock__get_phys_port_name.side_effect = ([""pf0vf0"", ""pf0vf1"", ""pf0vf2""]) ifname = linux_net.get_ifname_by_pci_address( '0000:00:00.1', pf_interface=True, switchdev=True) self.assertEqual(ifname, 'enp2s0f0_0') @mock.patch.object(os, 'listdir')"," self, mock__get_phys_switch_id, mock_listdir): @mock.patch.object(linux_net, '_get_phys_switch_id') self, mock__get_phys_switch_id, mock_listdir):",75,9
openstack%2Fnova~stable%2Frocky~I925513d33e4508a4c09e35553792761cdf4bb1ee,openstack/nova,stable/rocky,I925513d33e4508a4c09e35553792761cdf4bb1ee,"Instance failed to spawn: UEFINotSupported when I create instance in host with MIPS architecture, it got an error ""UEFINotSupported: UEFI is not supported""",ABANDONED,2020-07-08 11:51:15.000000000,2022-11-11 18:33:31.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 22348}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-07-08 11:51:15.000000000', 'files': ['nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c25e281ccc7b8e3e4083cae73b767b948bca2584', 'message': 'Instance failed to spawn: UEFINotSupported\nwhen I create instance in host with MIPS architecture, it got an error ""UEFINotSupported: UEFI is not supported""\n\nFixes Bug1882341\n\nChange-Id: I925513d33e4508a4c09e35553792761cdf4bb1ee\n'}]",3,739958,c25e281ccc7b8e3e4083cae73b767b948bca2584,11,6,1,32006,,,0,"Instance failed to spawn: UEFINotSupported
when I create instance in host with MIPS architecture, it got an error ""UEFINotSupported: UEFI is not supported""

Fixes Bug1882341

Change-Id: I925513d33e4508a4c09e35553792761cdf4bb1ee
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/739958/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py']",2,c25e281ccc7b8e3e4083cae73b767b948bca2584,Bug1882341," fields.Architecture.AARCH64, fields.Architecture.MIPS64, fields.Architecture.MIPS64EL] if caps.host.cpu.arch in (fields.Architecture.MIPS64, fields.Architecture.MIPS64EL): if not hw_firmware_type: hw_firmware_type = fields.FirmwareType.UEFI if caps.host.cpu.arch in (fields.Architecture.MIPS64, fields.Architecture.MIPS64EL): guest.os_loader_type = ""rom"" else: guest.os_loader_type = ""pflash"""," fields.Architecture.AARCH64] guest.os_loader_type = ""pflash""",15,3
openstack%2Fnova~stable%2Frocky~I526693dcf7ab15f836d086d173c1746e316c565a,openstack/nova,stable/rocky,I526693dcf7ab15f836d086d173c1746e316c565a,Perfect unit test of 'test_no_migrations_have_downgrade'.,ABANDONED,2020-03-31 01:40:28.000000000,2022-11-11 18:33:26.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-03-31 01:40:28.000000000', 'files': ['nova/tests/unit/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4ece9a896865ed5f0d87344407685eb930e5419e', 'message': ""Perfect unit test of 'test_no_migrations_have_downgrade'.\n\nChange-Id: I526693dcf7ab15f836d086d173c1746e316c565a\n""}]",0,716118,4ece9a896865ed5f0d87344407685eb930e5419e,6,4,1,31460,,,0,"Perfect unit test of 'test_no_migrations_have_downgrade'.

Change-Id: I526693dcf7ab15f836d086d173c1746e316c565a
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/716118/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/db/test_migrations.py'],1,4ece9a896865ed5f0d87344407685eb930e5419e,my-branch-rocky," if 'def upgrade(' in line \ and '# def upgrade(' not in line \ and ""'''def upgrade("" not in line: if 'def downgrade(' in line \ and '# def upgrade(' not in line \ and ""'''def upgrade("" not in line: helpful_msg = (""The following migrations have a downgrade which is not supported:"" ""\n\t%s"" % '\n\t'.join(sorted(includes_downgrade))+""\n\t"" ""Note: the strings 'def upgrade(' and 'def downgrade(' in the comment are also checked, \n\t"" ""and it is recommended that the useless method be removed."") self.assertFalse(includes_downgrade, helpful_msg)"," if 'def upgrade(' in line: if 'def downgrade(' in line: helpful_msg = (""The following migrations have a downgrade "" ""which is not supported:"" ""\n\t%s"" % '\n\t'.join(sorted(includes_downgrade))) self.assertFalse(includes_downgrade, helpful_msg)",11,6
openstack%2Fnova~stable%2Frocky~I0de9cc9643159c7479adf06b06633e7823020f92,openstack/nova,stable/rocky,I0de9cc9643159c7479adf06b06633e7823020f92,Force refresh instance info_cache during heal,ABANDONED,2019-08-29 14:28:42.000000000,2022-11-11 18:33:21.000000000,,"[{'_account_id': 6737}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-08-29 14:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca5867d5644fdf1c74cc786ee71876ceb8c419bd', 'message': 'Force refresh instance info_cache during heal\n\nIf the instance info_cache is corrupted somehow, like during\na host reboot and the ports aren\'t wired up properly or\na mistaken policy change in neutron results in nova resetting\nthe info_cache to an empty list, the _heal_instance_info_cache\nis meant to fix it (once the current state of the ports for\nthe instance in neutron is corrected). However, the task is\ncurrently only refreshing the cache *based* on the current contents\nof the cache, which defeats the purpose of neutron being the source\nof truth for the ports attached to the instance.\n\nThis change makes the _heal_instance_info_cache periodic task\npass a ""force_refresh"" kwarg, which defaults to False for backward\ncompatibility with other methods that refresh the cache after\noperations like attach/detach interface, and if True will make\nnova get the current state of the ports for the instance from neutron\nand fully rebuild the info_cache.\n\nTo not lose port order in info_cache this change takes original order\nfrom nova historical data that are stored as VirtualInterfaceList\nobjects. For ports that are not registered as VirtualInterfaces\nobjects it will add them at the end of port_order list. Due to this\nfor instances older than Newton another patch was introduced to fill\nmissing VirtualInterface objects in the DB [1].\n\nLong-term we should be able to refactor some of the older refresh\ncode which leverages the cache to instead use the refresh_vif_id\nkwarg so that we do targeted cache updates when we do things like\nattach and detach ports, but that\'s a change for another day.\n\n[1] https://review.openstack.org/#/c/614167\n\nCo-Authored-By: Maciej Jozefczyk <maciej.jozefczyk@corp.ovh.com>\nCloses-Bug: #1751923\n(cherry picked from commit ba44c155ce1dcefede9741722a0525820d6da2b8)\n\nChange-Id: I0de9cc9643159c7479adf06b06633e7823020f92\n'}, {'number': 2, 'created': '2019-11-27 10:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ddf51c51fa9a6845661e1d37d064003e8287da9', 'message': 'Force refresh instance info_cache during heal\n\nIf the instance info_cache is corrupted somehow, like during\na host reboot and the ports aren\'t wired up properly or\na mistaken policy change in neutron results in nova resetting\nthe info_cache to an empty list, the _heal_instance_info_cache\nis meant to fix it (once the current state of the ports for\nthe instance in neutron is corrected). However, the task is\ncurrently only refreshing the cache *based* on the current contents\nof the cache, which defeats the purpose of neutron being the source\nof truth for the ports attached to the instance.\n\nThis change makes the _heal_instance_info_cache periodic task\npass a ""force_refresh"" kwarg, which defaults to False for backward\ncompatibility with other methods that refresh the cache after\noperations like attach/detach interface, and if True will make\nnova get the current state of the ports for the instance from neutron\nand fully rebuild the info_cache.\n\nTo not lose port order in info_cache this change takes original order\nfrom nova historical data that are stored as VirtualInterfaceList\nobjects. For ports that are not registered as VirtualInterfaces\nobjects it will add them at the end of port_order list. Due to this\nfor instances older than Newton another patch was introduced to fill\nmissing VirtualInterface objects in the DB [1].\n\nLong-term we should be able to refactor some of the older refresh\ncode which leverages the cache to instead use the refresh_vif_id\nkwarg so that we do targeted cache updates when we do things like\nattach and detach ports, but that\'s a change for another day.\n\n[1] https://review.openstack.org/#/c/614167\n\nCo-Authored-By: Maciej Jozefczyk <maciej.jozefczyk@corp.ovh.com>\nCloses-Bug: #1751923\n(cherry picked from commit ba44c155ce1dcefede9741722a0525820d6da2b8)\n\nChange-Id: I0de9cc9643159c7479adf06b06633e7823020f92\n'}, {'number': 3, 'created': '2020-02-14 16:25:45.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0f5919bb5460dc872b03cbf672348b9a3ef10a30', 'message': 'Force refresh instance info_cache during heal\n\nIf the instance info_cache is corrupted somehow, like during\na host reboot and the ports aren\'t wired up properly or\na mistaken policy change in neutron results in nova resetting\nthe info_cache to an empty list, the _heal_instance_info_cache\nis meant to fix it (once the current state of the ports for\nthe instance in neutron is corrected). However, the task is\ncurrently only refreshing the cache *based* on the current contents\nof the cache, which defeats the purpose of neutron being the source\nof truth for the ports attached to the instance.\n\nThis change makes the _heal_instance_info_cache periodic task\npass a ""force_refresh"" kwarg, which defaults to False for backward\ncompatibility with other methods that refresh the cache after\noperations like attach/detach interface, and if True will make\nnova get the current state of the ports for the instance from neutron\nand fully rebuild the info_cache.\n\nTo not lose port order in info_cache this change takes original order\nfrom nova historical data that are stored as VirtualInterfaceList\nobjects. For ports that are not registered as VirtualInterfaces\nobjects it will add them at the end of port_order list. Due to this\nfor instances older than Newton another patch was introduced to fill\nmissing VirtualInterface objects in the DB [1].\n\nLong-term we should be able to refactor some of the older refresh\ncode which leverages the cache to instead use the refresh_vif_id\nkwarg so that we do targeted cache updates when we do things like\nattach and detach ports, but that\'s a change for another day.\n\n[1] https://review.openstack.org/#/c/614167\n\nCo-Authored-By: Maciej Jozefczyk <maciej.jozefczyk@corp.ovh.com>\nCloses-Bug: #1751923\n(cherry picked from commit ba44c155ce1dcefede9741722a0525820d6da2b8)\n\nChange-Id: I0de9cc9643159c7479adf06b06633e7823020f92\n'}]",0,679271,0f5919bb5460dc872b03cbf672348b9a3ef10a30,19,8,3,6737,,,0,"Force refresh instance info_cache during heal

If the instance info_cache is corrupted somehow, like during
a host reboot and the ports aren't wired up properly or
a mistaken policy change in neutron results in nova resetting
the info_cache to an empty list, the _heal_instance_info_cache
is meant to fix it (once the current state of the ports for
the instance in neutron is corrected). However, the task is
currently only refreshing the cache *based* on the current contents
of the cache, which defeats the purpose of neutron being the source
of truth for the ports attached to the instance.

This change makes the _heal_instance_info_cache periodic task
pass a ""force_refresh"" kwarg, which defaults to False for backward
compatibility with other methods that refresh the cache after
operations like attach/detach interface, and if True will make
nova get the current state of the ports for the instance from neutron
and fully rebuild the info_cache.

To not lose port order in info_cache this change takes original order
from nova historical data that are stored as VirtualInterfaceList
objects. For ports that are not registered as VirtualInterfaces
objects it will add them at the end of port_order list. Due to this
for instances older than Newton another patch was introduced to fill
missing VirtualInterface objects in the DB [1].

Long-term we should be able to refactor some of the older refresh
code which leverages the cache to instead use the refresh_vif_id
kwarg so that we do targeted cache updates when we do things like
attach and detach ports, but that's a change for another day.

[1] https://review.openstack.org/#/c/614167

Co-Authored-By: Maciej Jozefczyk <maciej.jozefczyk@corp.ovh.com>
Closes-Bug: #1751923
(cherry picked from commit ba44c155ce1dcefede9741722a0525820d6da2b8)

Change-Id: I0de9cc9643159c7479adf06b06633e7823020f92
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/679271/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py']",4,ca5867d5644fdf1c74cc786ee71876ceb8c419bd,bug/1751923," self.network_api.get_instance_nw_info( context, instance, force_refresh=True)"," self.network_api.get_instance_nw_info(context, instance)",203,11
openstack%2Fnova~stable%2Frocky~If8e689796b81592078bfdb759f8a5c08f9565144,openstack/nova,stable/rocky,If8e689796b81592078bfdb759f8a5c08f9565144,"""[stable-only]"" Removed the quoted section",ABANDONED,2020-08-04 11:32:31.000000000,2022-11-11 18:33:16.000000000,,"[{'_account_id': 4690}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 30905}]","[{'number': 1, 'created': '2020-08-04 11:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aaf073aec09d20769fa56bf832570551b496a91c', 'message': '[stable-only] Moved the quoted section\n\nmoved the quoted section from https://docs.openstack.org/nova/rocky/install/controller-install-rdo.html\nto https://docs.openstack.org/nova/rocky/install/verify.html (before no 5)\n\nChange-Id: If8e689796b81592078bfdb759f8a5c08f9565144\nCloses-Bug: #1700999\n'}, {'number': 2, 'created': '2020-08-05 16:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cccabd3fa69901510efaa305f3d76fcd389814b3', 'message': '[stable-only] Moved the quoted section\n\nmoved the quoted section from https://docs.openstack.org/nova/rocky/install/controller-install-rdo.html\nto https://docs.openstack.org/nova/rocky/install/verify.html (before no 5)\n\nChange-Id: If8e689796b81592078bfdb759f8a5c08f9565144\nCloses-Bug: #1700999\n'}, {'number': 3, 'created': '2020-08-05 16:21:00.000000000', 'files': ['doc/source/install/controller-install-rdo.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/a5d2d6f6f5299277c00ad3c1d7fc12e26e56de56', 'message': '""[stable-only]"" Removed the quoted section\n\nRemoved the quoted section from \nhttps://docs.openstack.org/nova/rocky/install/controller-install-rdo.html\n\nChange-Id: If8e689796b81592078bfdb759f8a5c08f9565144\nCloses-Bug: #1700999\n'}]",4,744681,a5d2d6f6f5299277c00ad3c1d7fc12e26e56de56,13,5,3,30905,,,0,"""[stable-only]"" Removed the quoted section

Removed the quoted section from 
https://docs.openstack.org/nova/rocky/install/controller-install-rdo.html

Change-Id: If8e689796b81592078bfdb759f8a5c08f9565144
Closes-Bug: #1700999
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/744681/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/verify.rst', 'doc/source/install/controller-install-rdo.rst']",2,aaf073aec09d20769fa56bf832570551b496a91c,,," * Due to a `packaging bug <https://bugzilla.redhat.com/show_bug.cgi?id=1430540>`_, you must enable access to the Placement API by adding the following configuration to ``/etc/httpd/conf.d/00-nova-placement-api.conf``: .. path /etc/httpd/conf.d/00-nova-placement-api.conf .. code-block:: ini <Directory /usr/bin> <IfVersion >= 2.4> Require all granted </IfVersion> <IfVersion < 2.4> Order allow,deny Allow from all </IfVersion> </Directory> * Restart the httpd service: .. code-block:: console # systemctl restart httpd ",24,24
openstack%2Fnova~stable%2Frocky~Id094dd90efde09b9a835d4492f4a92b8f8ad296e,openstack/nova,stable/rocky,Id094dd90efde09b9a835d4492f4a92b8f8ad296e,Fix invalid assert_has_calls,ABANDONED,2020-09-14 10:33:32.000000000,2022-11-11 18:32:57.000000000,,"[{'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-14 10:33:32.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7c198f6c9aa83adc85910a62fcd02293e03f597', 'message': 'Fix invalid assert_has_calls\n\nThis is to fix the invalid assert_has_calls usage,\n""assert_has_calls = "" should be ""assert_has_calls("".\n\nChange-Id: Id094dd90efde09b9a835d4492f4a92b8f8ad296e\n(cherry picked from commit 8cb9b84f283e58841a58d5d79b15268ca5da504d)\n(cherry picked from commit 674d1cbabcf5ab2a84718cd1fc7eccaabbb59839)\n(cherry picked from commit c02a60265319281c2bf385360102c69fdccf3676)\n(cherry picked from commit f80e55dd28fa48e51b079e838dc513069534d835)\n'}]",0,751755,a7c198f6c9aa83adc85910a62fcd02293e03f597,5,4,1,10135,,,0,"Fix invalid assert_has_calls

This is to fix the invalid assert_has_calls usage,
""assert_has_calls = "" should be ""assert_has_calls("".

Change-Id: Id094dd90efde09b9a835d4492f4a92b8f8ad296e
(cherry picked from commit 8cb9b84f283e58841a58d5d79b15268ca5da504d)
(cherry picked from commit 674d1cbabcf5ab2a84718cd1fc7eccaabbb59839)
(cherry picked from commit c02a60265319281c2bf385360102c69fdccf3676)
(cherry picked from commit f80e55dd28fa48e51b079e838dc513069534d835)
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/751755/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/compute/test_compute_mgr.py'],1,a7c198f6c9aa83adc85910a62fcd02293e03f597,," mock_remove_vol_conn.assert_has_calls([ bdm in bdms]) mock_delete_attachment.assert_has_calls([ mock.call(self.context, uuids.vol2_attach)])"," mock_remove_vol_conn.assert_has_calls = [ bdm in bdms] mock_delete_attachment.assert_has_calls = [ mock.call(self.context, uuids.vol2_attach)]",4,4
openstack%2Fnova~stable%2Frocky~I2c7df1bd51a7e674d75d520a38b89f971a0aa474,openstack/nova,stable/rocky,I2c7df1bd51a7e674d75d520a38b89f971a0aa474,Set instance host and drop migration under lock,ABANDONED,2020-10-07 02:38:11.000000000,2022-11-11 18:32:49.000000000,,"[{'_account_id': 4690}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 24713}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-10-07 02:38:11.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1896463.py', 'nova/utils.py', 'nova/compute/manager.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/793fb7f81eefd7a2a4e5880c5f03029fb8317e9d', 'message': 'Set instance host and drop migration under lock\n\nThe _update_available_resources periodic makes resource allocation\nadjustments while holding the COMPUTE_RESOURCE_SEMAPHORE based on the\nlist of instances assigned to the host of the resource tracker and\nbased on the migrations where the source or the target host is the host\nof the resource tracker. So if the instance.host or the migration\ncontext changes without holding the COMPUTE_RESOURCE_SEMAPHORE while\nthe _update_available_resources task is running then there will be data\ninconsistency in the resource tracker.\n\nThis patch makes sure that during evacuation the instance.host and the\nmigration context is changed while holding the semaphore.\n\nChange-Id: I2c7df1bd51a7e674d75d520a38b89f971a0aa474\nCloses-Bug: #1896463\n(cherry picked from commit 12446c168d44709df6c1735ed97ed1df2ff2e321)\n'}]",0,756421,793fb7f81eefd7a2a4e5880c5f03029fb8317e9d,8,6,1,24713,,,0,"Set instance host and drop migration under lock

The _update_available_resources periodic makes resource allocation
adjustments while holding the COMPUTE_RESOURCE_SEMAPHORE based on the
list of instances assigned to the host of the resource tracker and
based on the migrations where the source or the target host is the host
of the resource tracker. So if the instance.host or the migration
context changes without holding the COMPUTE_RESOURCE_SEMAPHORE while
the _update_available_resources task is running then there will be data
inconsistency in the resource tracker.

This patch makes sure that during evacuation the instance.host and the
migration context is changed while holding the semaphore.

Change-Id: I2c7df1bd51a7e674d75d520a38b89f971a0aa474
Closes-Bug: #1896463
(cherry picked from commit 12446c168d44709df6c1735ed97ed1df2ff2e321)
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/756421/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1896463.py', 'nova/utils.py', 'nova/compute/manager.py', 'nova/compute/resource_tracker.py']",5,793fb7f81eefd7a2a4e5880c5f03029fb8317e9d,bug/1896463," def compute_resource_semaphore(self): """"""Returns a context manager that allows locking the COMPUTE_RESOURCE_SEMAPHORE """""" return utils.lock(COMPUTE_RESOURCE_SEMAPHORE)",,211,12
openstack%2Fnova~stable%2Frocky~Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c,openstack/nova,stable/rocky,Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c,libvirt: Log exception when unable to import rbd or rados,ABANDONED,2020-10-14 20:25:39.000000000,2022-11-11 18:32:44.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-10-14 20:25:39.000000000', 'files': ['nova/virt/libvirt/storage/rbd_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f42d4c1afbf64cac295a36741d49013bd23e3205', 'message': ""libvirt: Log exception when unable to import rbd or rados\n\nThis should help provide some context when the RbdDriver later raises a\nRuntimeError if rbd or rados hasn't been imported correctly.\n\nChange-Id: Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c\n(cherry picked from commit aa16dd09ebeb21d0b81682b0b6026de0fe4f23b7)\n(cherry picked from commit 961a355fb314975ee169cbe9ef88eb8537294253)\n(cherry picked from commit 22c86f92ce7ef86675ee8265d43b21997e0df4bc)\n(cherry picked from commit 9c58a663b7999260e1683bae6a828d118aa44fd5)\n(cherry picked from commit cd7a1877a40b794e62086939d94b89bf928b61e9)\n""}]",0,758244,f42d4c1afbf64cac295a36741d49013bd23e3205,7,5,1,10135,,,0,"libvirt: Log exception when unable to import rbd or rados

This should help provide some context when the RbdDriver later raises a
RuntimeError if rbd or rados hasn't been imported correctly.

Change-Id: Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c
(cherry picked from commit aa16dd09ebeb21d0b81682b0b6026de0fe4f23b7)
(cherry picked from commit 961a355fb314975ee169cbe9ef88eb8537294253)
(cherry picked from commit 22c86f92ce7ef86675ee8265d43b21997e0df4bc)
(cherry picked from commit 9c58a663b7999260e1683bae6a828d118aa44fd5)
(cherry picked from commit cd7a1877a40b794e62086939d94b89bf928b61e9)
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/758244/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/storage/rbd_utils.py'],1,f42d4c1afbf64cac295a36741d49013bd23e3205,,"# NOTE(lyarwood): Log exceptions if we fail to import rbd or rados in order to # provide context later if we end up attempting to use the RbdDriver and # raising RuntimeError try: import rados except ImportError: rados = None LOG.exception( ""Unable to import the rados module, this can be ignored if Ceph is "" ""not used within this environment"") try: import rbd except ImportError: rbd = None LOG.exception( ""Unable to import the rbd module, this can be ignored if Ceph is not "" ""used within this environment"") ",try: import rados import rbd except ImportError: rados = None rbd = None ,20,7
openstack%2Fnova~stable%2Frocky~I0c3b9cfe96bcc3d7b6106c3e972ee9e2f79e419b,openstack/nova,stable/rocky,I0c3b9cfe96bcc3d7b6106c3e972ee9e2f79e419b,Remove deprecated nova-consoleauth reference from doc,ABANDONED,2018-10-30 01:29:25.000000000,2022-11-11 18:32:33.000000000,,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 10135}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 23561}, {'_account_id': 25314}, {'_account_id': 26515}, {'_account_id': 29165}]","[{'number': 1, 'created': '2018-10-30 01:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7547e63b0b2444d599bc709e17bc6793027e32b9', 'message': 'Remove deprecated nova-consoleauth reference from doc\n\nBecause nova-consoleauth had deprecated since version 18.0.0,\nit is better not to give reference of this service in verify operation\ndocumentation file.\n\nCloses-Bug: #1798787\nChange-Id: I0c3b9cfe96bcc3d7b6106c3e972ee9e2f79e419b\n(cherry picked from commit bc479a992d32d485291e1ec5f37ccff0db39961a)\n'}, {'number': 2, 'created': '2019-02-22 02:25:58.000000000', 'files': ['doc/source/install/verify.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/80dc320c67b13bf83b65d05f4f8ade6fa766d4dc', 'message': 'Remove deprecated nova-consoleauth reference from doc\n\nBecause nova-consoleauth had deprecated since version 18.0.0,\nit is better not to give reference of this service in verify operation\ndocumentation file.\n\nCloses-Bug: #1798787\nChange-Id: I0c3b9cfe96bcc3d7b6106c3e972ee9e2f79e419b\n(cherry picked from commit bc479a992d32d485291e1ec5f37ccff0db39961a)\n'}]",1,614055,80dc320c67b13bf83b65d05f4f8ade6fa766d4dc,19,11,2,19779,,,0,"Remove deprecated nova-consoleauth reference from doc

Because nova-consoleauth had deprecated since version 18.0.0,
it is better not to give reference of this service in verify operation
documentation file.

Closes-Bug: #1798787
Change-Id: I0c3b9cfe96bcc3d7b6106c3e972ee9e2f79e419b
(cherry picked from commit bc479a992d32d485291e1ec5f37ccff0db39961a)
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/614055/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/verify.rst'],1,7547e63b0b2444d599bc709e17bc6793027e32b9,bugfix_doc-stable/rocky, | 1 | nova-scheduler | controller | internal | enabled | up | 2016-02-09T23:11:15.000000 | | 2 | nova-conductor | controller | internal | enabled | up | 2016-02-09T23:11:16.000000 | | 3 | nova-compute | compute1 | nova | enabled | up | 2016-02-09T23:11:20.000000 |, | 1 | nova-consoleauth | controller | internal | enabled | up | 2016-02-09T23:11:15.000000 | | 2 | nova-scheduler | controller | internal | enabled | up | 2016-02-09T23:11:15.000000 | | 3 | nova-conductor | controller | internal | enabled | up | 2016-02-09T23:11:16.000000 | | 4 | nova-compute | compute1 | nova | enabled | up | 2016-02-09T23:11:20.000000 |,3,4
openstack%2Fnova~stable%2Frocky~I335113f0ec59516cb337d34b6fc9078ea202130f,openstack/nova,stable/rocky,I335113f0ec59516cb337d34b6fc9078ea202130f,Sanity check instance mapping during scheduling,ABANDONED,2020-11-16 17:50:17.000000000,2022-11-11 18:32:26.000000000,,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-11-16 17:50:17.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9b507c21aeeab876cd6a222d68f981fc923e8504', 'message': ""Sanity check instance mapping during scheduling\n\nmnaser reported a weird case where an instance was found\nin both cell0 (deleted there) and in cell1 (not deleted\nthere but in error state from a failed build). It's unclear\nhow this could happen besides some weird clustered rabbitmq\nissue where maybe the schedule and build request to conductor\nhappens twice for the same instance and one picks a host and\ntries to build and the other fails during scheduling and is\nburied in cell0.\n\nTo avoid a split brain situation like this, we add a sanity\ncheck in _bury_in_cell0 to make sure the instance mapping is\nnot pointing at a cell when we go to update it to cell0.\nSimilarly a check is added in the schedule_and_build_instances\nflow (the code is moved to a private method to make it easier\nto test).\n\nWorst case is this is unnecessary but doesn't hurt anything,\nbest case is this helps avoid split brain clustered rabbit\nissues.\n\nCloses-Bug: #1775934\n\nChange-Id: I335113f0ec59516cb337d34b6fc9078ea202130f\n(cherry picked from commit 5b552518e1abdc63fb33c633661e30e4b2fe775e)\n(cherry picked from commit efc35b1c5293c7c6c85f8cf9fd9d8cd8de71d1d5)\n(cherry picked from commit c895d3e6bca562225d70e8f81255f38970f7fcda)\n""}]",0,762899,9b507c21aeeab876cd6a222d68f981fc923e8504,9,6,1,4690,,,0,"Sanity check instance mapping during scheduling

mnaser reported a weird case where an instance was found
in both cell0 (deleted there) and in cell1 (not deleted
there but in error state from a failed build). It's unclear
how this could happen besides some weird clustered rabbitmq
issue where maybe the schedule and build request to conductor
happens twice for the same instance and one picks a host and
tries to build and the other fails during scheduling and is
buried in cell0.

To avoid a split brain situation like this, we add a sanity
check in _bury_in_cell0 to make sure the instance mapping is
not pointing at a cell when we go to update it to cell0.
Similarly a check is added in the schedule_and_build_instances
flow (the code is moved to a private method to make it easier
to test).

Worst case is this is unnecessary but doesn't hurt anything,
best case is this helps avoid split brain clustered rabbit
issues.

Closes-Bug: #1775934

Change-Id: I335113f0ec59516cb337d34b6fc9078ea202130f
(cherry picked from commit 5b552518e1abdc63fb33c633661e30e4b2fe775e)
(cherry picked from commit efc35b1c5293c7c6c85f8cf9fd9d8cd8de71d1d5)
(cherry picked from commit c895d3e6bca562225d70e8f81255f38970f7fcda)
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/762899/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",2,9b507c21aeeab876cd6a222d68f981fc923e8504,bug/1775934," inst_mapping = None try: # We don't need the cell0-targeted context here because the # instance mapping is in the API DB. inst_mapping = \ objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) except exception.InstanceMappingNotFound: # The API created the instance mapping record so it should # definitely be here. Log an error but continue to create the # instance in the cell0 database. LOG.error('While burying instance in cell0, no instance ' 'mapping was found.', instance=instance) # Perform a final sanity check that the instance is not mapped # to some other cell already because of maybe some crazy # clustered message queue weirdness. if inst_mapping and inst_mapping.cell_mapping is not None: LOG.error('When attempting to bury instance in cell0, the ' 'instance is already mapped to cell %s. Ignoring ' 'bury in cell0 attempt.', inst_mapping.cell_mapping.identity, instance=instance) continue if inst_mapping: inst_mapping.cell_mapping = cell0 inst_mapping.save() # Update mapping for instance. self._map_instance_to_cell(context, instance, cell) @staticmethod def _map_instance_to_cell(context, instance, cell): """"""Update the instance mapping to point at the given cell. During initial scheduling once a host and cell is selected in which to build the instance this method is used to update the instance mapping to point at that cell. :param context: nova auth RequestContext :param instance: Instance object being built :param cell: CellMapping representing the cell in which the instance was created and is being built. :returns: InstanceMapping object that was updated. """""" inst_mapping = objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) # Perform a final sanity check that the instance is not mapped # to some other cell already because of maybe some crazy # clustered message queue weirdness. if inst_mapping.cell_mapping is not None: LOG.error('During scheduling instance is already mapped to ' 'another cell: %s. This should not happen and is an ' 'indication of bigger problems. If you see this you ' 'should report it to the nova team. Overwriting ' 'the mapping to point at cell %s.', inst_mapping.cell_mapping.identity, cell.identity, instance=instance) inst_mapping.cell_mapping = cell inst_mapping.save() return inst_mapping "," try: # We don't need the cell0-targeted context here because the # instance mapping is in the API DB. inst_mapping = \ objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) inst_mapping.cell_mapping = cell0 inst_mapping.save() except exception.InstanceMappingNotFound: pass # Update mapping for instance. Normally this check is guarded by # a try/except but if we're here we know that a newer nova-api # handled the build process and would have created the mapping inst_mapping = objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) inst_mapping.cell_mapping = cell inst_mapping.save()",120,17
openstack%2Fnova~stable%2Frocky~I2c195df5fcf844c0587933b5b5995bdca1a3ebed,openstack/nova,stable/rocky,I2c195df5fcf844c0587933b5b5995bdca1a3ebed,Fix unplugging VIF when migrate/resize VM,ABANDONED,2020-11-24 01:37:50.000000000,2022-11-11 18:32:21.000000000,,"[{'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-24 01:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2dcc367c25825c0aa40de5e914dd58e0b3d0851a', 'message': 'Fix unplugging VIF when migrate/resize VM\n\nWhen migrating/resizing VM to destination\nhost that has VIF type difference from source VIF\ntype, it fails due to exception in unplugging\nVIF on source host after user perform a confirmation\naction.\n\nThis change unplugs the vifs in resize_instance and\nwraps the call to unplug in confirm with an try except\nblock. the call to unplug_vifs in confirm is not removed\nto support rolling upgrades but a todo is added to remove\nit after the Wallaby release.\n\nChange-Id: I2c195df5fcf844c0587933b5b5995bdca1a3ebed\nCloses-Bug: #1895220\n(cherry picked from commit 66c7f00e1d9d7c0eebe46eb4b24b2b21f7413789)\n'}, {'number': 2, 'created': '2020-11-24 01:58:09.000000000', 'files': ['releasenotes/notes/unplug-vifs-in-resize_instance-fcd98ea44e4b8725.yaml', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a4096daae8f6311495fa138aa2ccdc1d6c5e6622', 'message': 'Fix unplugging VIF when migrate/resize VM\n\nWhen migrating/resizing VM to destination\nhost that has VIF type difference from source VIF\ntype, it fails due to exception in unplugging\nVIF on source host after user perform a confirmation\naction.\n\nThis change unplugs the vifs in resize_instance and\nwraps the call to unplug in confirm with an try except\nblock. the call to unplug_vifs in confirm is not removed\nto support rolling upgrades but a todo is added to remove\nit after the Wallaby release.\n\nChange-Id: I2c195df5fcf844c0587933b5b5995bdca1a3ebed\nCloses-Bug: #1895220\n(cherry picked from commit 66c7f00e1d9d7c0eebe46eb4b24b2b21f7413789)\n'}]",1,763898,a4096daae8f6311495fa138aa2ccdc1d6c5e6622,10,2,2,28910,,,0,"Fix unplugging VIF when migrate/resize VM

When migrating/resizing VM to destination
host that has VIF type difference from source VIF
type, it fails due to exception in unplugging
VIF on source host after user perform a confirmation
action.

This change unplugs the vifs in resize_instance and
wraps the call to unplug in confirm with an try except
block. the call to unplug_vifs in confirm is not removed
to support rolling upgrades but a todo is added to remove
it after the Wallaby release.

Change-Id: I2c195df5fcf844c0587933b5b5995bdca1a3ebed
Closes-Bug: #1895220
(cherry picked from commit 66c7f00e1d9d7c0eebe46eb4b24b2b21f7413789)
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/763898/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/unplug-vifs-in-resize_instance-fcd98ea44e4b8725.yaml', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,2dcc367c25825c0aa40de5e914dd58e0b3d0851a,bug/1895220-stable/rocky,"<<<<<<< HEAD (3c7744 Follow up for cherry-pick check for merge patch)======= @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs') @mock.patch('nova.virt.libvirt.utils.save_and_migrate_vtpm_dir') @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.' '_get_instance_disk_info') >>>>>>> CHANGE (66c7f0 Fix unplugging VIF when migrate/resize VM)<<<<<<< HEAD (3c7744 Follow up for cherry-pick check for merge patch)======= mock_get_disk_info, mock_vtpm, mock_unplug_vifs, block_device_info=None, params_for_instance=None): """"""Test for nova.virt.libvirt.driver.LivirtConnection >>>>>>> CHANGE (66c7f0 Fix unplugging VIF when migrate/resize VM)<<<<<<< HEAD (3c7744 Follow up for cherry-pick check for merge patch) ======= mock_vtpm.assert_called_with( instance.uuid, mock.ANY, mock.ANY, '10.0.0.2', mock.ANY, mock.ANY) mock_unplug_vifs.assert_called_once() mock_unplug_vifs.reset_mock() >>>>>>> CHANGE (66c7f0 Fix unplugging VIF when migrate/resize VM)<<<<<<< HEAD (3c7744 Follow up for cherry-pick check for merge patch) ======= mock_vtpm.assert_called_with( instance.uuid, mock.ANY, mock.ANY, '10.0.0.1', mock.ANY, mock.ANY) mock_unplug_vifs.assert_called_once() >>>>>>> CHANGE (66c7f0 Fix unplugging VIF when migrate/resize VM) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs', new=mock.Mock()) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs', new=mock.Mock())<<<<<<< HEAD (3c7744 Follow up for cherry-pick check for merge patch)======= @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs', new=mock.Mock()) @mock.patch('nova.virt.libvirt.utils.save_and_migrate_vtpm_dir') @mock.patch('oslo_concurrency.processutils.execute') >>>>>>> CHANGE (66c7f0 Fix unplugging VIF when migrate/resize VM) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver.unplug_vifs', new=mock.Mock())<<<<<<< HEAD (3c7744 Follow up for cherry-pick check for merge patch) ======= @mock.patch('time.sleep', new=mock.Mock()) def test_cleanup_resize_not_same_host_works_when_unplug_fails(self): CONF.set_override('policy_dirs', [], group='oslo_policy') host = 'not' + CONF.host instance = self._create_instance({'host': host}) instance.old_flavor = instance.flavor instance.new_flavor = instance.flavor fake_net = _fake_network_info(self) drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) with test.nested( mock.patch('nova.compute.utils.is_volume_backed_instance', return_value=False), mock.patch.object(os.path, 'exists'), mock.patch.object(libvirt_utils, 'get_instance_path'), mock.patch.object(shutil, 'rmtree'), mock.patch.object(drvr.image_backend, 'by_name', new_callable=mock.NonCallableMock), mock.patch.object(drvr, '_undefine_domain'), mock.patch.object(drvr, 'unplug_vifs'), mock.patch('nova.virt.libvirt.driver.LOG.debug') ) as (mock_volume_backed, mock_exists, mock_get_path, mock_rmtree, mock_image_by_name, mock_undef, mock_unplug, mock_log): mock_exists.return_value = True mock_get_path.return_value = '/fake/inst' error = exception.InternalError(""fake error"") mock_unplug.side_effect = error drvr._cleanup_resize(self.context, instance, fake_net) mock_get_path.assert_called_once_with(instance) self.assertEqual(5, mock_rmtree.call_count) mock_undef.assert_called_once_with(instance) mock_unplug.assert_called_once_with(instance, fake_net) mock_log.assert_called_once_with(error, instance=instance) @mock.patch('time.sleep', new=mock.Mock()) >>>>>>> CHANGE (66c7f0 Fix unplugging VIF when migrate/resize VM)",,103,1
openstack%2Fnova~stable%2Frocky~Ia2007bc63ef09931ea0197cef29d6a5614ed821a,openstack/nova,stable/rocky,Ia2007bc63ef09931ea0197cef29d6a5614ed821a,libvirt: Skip encryption metadata lookups if secret already exists on host,ABANDONED,2020-12-07 09:40:30.000000000,2022-11-11 18:32:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-07 09:40:30.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug_1905701-fdc7402ffe70d104.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/42dbcd370202dbbcd9c339f09f3323553a5295a1', 'message': 'libvirt: Skip encryption metadata lookups if secret already exists on host\n\nWhen connecting an encrypted volume to a host the _attach_encryptor\nmethod will be called in order to either call a legacy os-brick\nencryptor *or* configure a libvirt secret used by libvirt and QEMU to\nnatively decrypt LUKSv1 encrypted volumes. To create this libvirt secret\nthe configured key manager will be queried to provide and then decode\nthe associated secret before this is stashed within libvirt.\n\nThis change simply skips the above when an existing libvirt secret\nassociated with the target volume is found on the host already.\n\nWhile this obviously optimises basic instance lifecycle flows such as a\nsimple power off and on it additionally resolves a more convoluted use\ncase when the ``[DEFAULT]/resume_guests_state_on_host_boot``\nconfigurable is enabled. In this case the compute service has no request\ncontext with which to query the key manager when attempting to restart\ninstances with encrypted volumes attached. As a result any attempt by\nthe compute service to restart an instance with an attached encrypted\nvolume would previously fail.\n\nCloses-Bug: #1905701\nChange-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a\n(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)\n(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)\n(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)\n(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)\n(cherry picked from commit dfca56f64cd7884b6da98db43348303d220cf25e)\n'}]",0,765773,42dbcd370202dbbcd9c339f09f3323553a5295a1,6,1,1,10135,,,0,"libvirt: Skip encryption metadata lookups if secret already exists on host

When connecting an encrypted volume to a host the _attach_encryptor
method will be called in order to either call a legacy os-brick
encryptor *or* configure a libvirt secret used by libvirt and QEMU to
natively decrypt LUKSv1 encrypted volumes. To create this libvirt secret
the configured key manager will be queried to provide and then decode
the associated secret before this is stashed within libvirt.

This change simply skips the above when an existing libvirt secret
associated with the target volume is found on the host already.

While this obviously optimises basic instance lifecycle flows such as a
simple power off and on it additionally resolves a more convoluted use
case when the ``[DEFAULT]/resume_guests_state_on_host_boot``
configurable is enabled. In this case the compute service has no request
context with which to query the key manager when attempting to restart
instances with encrypted volumes attached. As a result any attempt by
the compute service to restart an instance with an attached encrypted
volume would previously fail.

Closes-Bug: #1905701
Change-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a
(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)
(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)
(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)
(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)
(cherry picked from commit dfca56f64cd7884b6da98db43348303d220cf25e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/765773/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug_1905701-fdc7402ffe70d104.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,42dbcd370202dbbcd9c339f09f3323553a5295a1,bug/1905701," # Mock out find_secret so we don't skip ahead drvr._host.find_secret.return_value = None @mock.patch.object(key_manager, 'API') def test_attach_encryptor_secret_exists(self, mock_key_manager_api): connection_info = {'data': {'volume_id': uuids.volume_id}} drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) with test.nested( mock.patch.object(drvr, '_get_volume_encryption'), mock.patch.object(drvr._host, 'find_secret') ) as (mock_get_volume_encryption, mock_find_secret): drvr._attach_encryptor(self.context, connection_info, None) # Assert we called find_secret and nothing else mock_find_secret.assert_called_once_with('volume', uuids.volume_id) mock_get_volume_encryption.assert_not_called() mock_key_manager_api.assert_not_called() ",,42,1
openstack%2Fnova~stable%2Frocky~Ic5ce2580e7638a47f1ffddb4edbb503bf490504c,openstack/nova,stable/rocky,Ic5ce2580e7638a47f1ffddb4edbb503bf490504c,compute: Lock by instance.uuid lock during swap_volume,ABANDONED,2020-10-19 09:06:59.000000000,2022-11-11 18:32:09.000000000,,"[{'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-10-19 09:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17b8541982ac2930d0544f9d0f306aa093df2d16', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit a53e8471728ba934b55fd6438405f897f07293ca)\n(cherry picked from commit c6f2b873bea90df4a2c1fa3b45c6ac1bc2fac618)\n(cherry picked from commit f6a54d1a0631b478148da8b52e4b4c804ecf70f4)\n(cherry picked from commit 65a275673bcf03a97202cc04a9bc8bb0ed60d1e3)\n'}, {'number': 2, 'created': '2021-03-08 09:52:12.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8504c900edd0808770d9c4014a58a2b3b29ef6c3', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)\n(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)\n(cherry picked from commit 6540161933ec007d3de01dfc420595664781aa37)\n(cherry picked from commit 9be0c52439f50ed0fbb9657577c227ce9bb7fc6d)\n'}]",0,758735,8504c900edd0808770d9c4014a58a2b3b29ef6c3,15,3,2,10135,,,0,"compute: Lock by instance.uuid lock during swap_volume

The libvirt driver is currently the only virt driver implementing swap
volume within Nova. While libvirt itself does support moving between
multiple volumes attached to the same instance at the same time the
current logic within the libvirt driver makes a call to
virDomainGetXMLDesc that fails if there are active block jobs against
any disk attached to the domain.

This change simply uses an instance.uuid based lock in the compute layer
to serialise requests to swap_volume to avoid this from being possible.

Closes-Bug: #1896621
Change-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c
(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)
(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)
(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)
(cherry picked from commit 6540161933ec007d3de01dfc420595664781aa37)
(cherry picked from commit 9be0c52439f50ed0fbb9657577c227ce9bb7fc6d)
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/758735/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,17b8541982ac2930d0544f9d0f306aa093df2d16,bug/1896621," """"""Replace the old volume with the new volume within the active server :param context: User request context :param old_volume_id: Original volume id :param new_volume_id: New volume id being swapped to :param instance: Instance with original_volume_id attached :param new_attachment_id: ID of the new attachment for new_volume_id """""" @utils.synchronized(instance.uuid) def _do_locked_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id): self._do_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id) _do_locked_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id) def _do_swap_volume(self, context, old_volume_id, new_volume_id, instance, new_attachment_id): """"""Replace the old volume with the new volume within the active server :param context: User request context :param old_volume_id: Original volume id :param new_volume_id: New volume id being swapped to :param instance: Instance with original_volume_id attached :param new_attachment_id: ID of the new attachment for new_volume_id """""" context = context.elevated()"," """"""Swap volume for an instance."""""" context = context.elevated() ",26,2
openstack%2Fnova~stable%2Frocky~I58dca95251b607eaff602783fee2fc38e2421944,openstack/nova,stable/rocky,I58dca95251b607eaff602783fee2fc38e2421944,Use absolute path during qemu img rebase,ABANDONED,2021-03-16 11:12:32.000000000,2022-11-11 18:32:04.000000000,,"[{'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-03-16 11:12:32.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8fc3b17b124703e32d25270e3ff90974591d658f', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nNOTE(lyarwood): Conflict caused by I897999e8a4601694213f068367eae9608cdc7bbb\nnot being present in stable/rocky.\n\nConflicts:\n  nova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)\n(cherry picked from commit 80c64b455cbb646b920755eb35fa2c5fa5df81b2)\n'}]",1,780788,8fc3b17b124703e32d25270e3ff90974591d658f,4,2,1,10135,,,0,"Use absolute path during qemu img rebase

During an assisted volume snapshot delete request from Cinder nova
removes the snapshot from the backing file chain. During that nova
checks the existence of such file. However in some cases (see the bug
report) the path is relative and therefore os.path.exists fails.

This patch makes sure that nova uses the volume absolute path to make
the backing file path absolute as well.

Closes-Bug #1885528

NOTE(lyarwood): Conflict caused by I897999e8a4601694213f068367eae9608cdc7bbb
not being present in stable/rocky.

Conflicts:
  nova/tests/unit/virt/libvirt/test_driver.py

Change-Id: I58dca95251b607eaff602783fee2fc38e2421944
(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)
(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)
(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)
(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)
(cherry picked from commit 80c64b455cbb646b920755eb35fa2c5fa5df81b2)
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/780788/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,8fc3b17b124703e32d25270e3ff90974591d658f,bug/1885528," dom_xml = """""" <domain type='kvm'> <devices> <disk type='file'> <source file='/var/lib/nova/instances/%s/disk1_file'/> <target dev='vda' bus='virtio'/> <serial>0e38683e-f0af-418f-a3f1-6b67ea0f919d</serial> </disk> <disk type='block'> <source dev='/path/to/dev/1'/> <target dev='vdb' bus='virtio' serial='1234'/> </disk> </devices> </domain>"""""" % self.inst['uuid'] dom_xml) mock_qemu_img_info.assert_called_once_with( ""/var/lib/nova/instances/%s/snap.img"" % instance.uuid) mock_execute.assert_called_once_with( 'qemu-img', 'rebase', '-b', '/var/lib/nova/instances/%s/snap.img' % instance.uuid, '-F', 'fake_fmt', '/var/lib/nova/instances/%s/disk1_file' % instance.uuid)"," self.dom_xml) mock_qemu_img_info.assert_called_once_with(""snap.img"") mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', 'snap.img', '-F', 'fake_fmt', 'disk1_file')",33,6
openstack%2Fnova~stable%2Frocky~I17357d85f845d4160cb7c7784772530a1e92af76,openstack/nova,stable/rocky,I17357d85f845d4160cb7c7784772530a1e92af76,Make _rebase_with_qemu_img() generic,ABANDONED,2021-03-16 11:12:32.000000000,2022-11-11 18:31:59.000000000,,"[{'_account_id': 22348}, {'_account_id': 28332}]","[{'number': 1, 'created': '2021-03-16 11:12:32.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8a065c15a228d41e5c99a449cf53192e92a96c2d', 'message': 'Make _rebase_with_qemu_img() generic\n\nMove volume_delete related logic away from this method, in order to make\nit generic and usable elsewhere.\n\nNOTE(lyarwood): Conflicts due to I9bcc66b0dc203e08222276bced77d4409c3adcea\nand I897999e8a4601694213f068367eae9608cdc7bbb not being present in\nstable/rocky.\n\nConflicts:\n  nova/virt/libvirt/driver.py\n\nChange-Id: I17357d85f845d4160cb7c7784772530a1e92af76\nRelated-Bug: #1732428\n(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)\n(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)\n(cherry picked from commit ffcb1705cbb6ddaa3fa4d8881f416f25b763b5e7)\n(cherry picked from commit 43cea4a744930daf3459a3bad294fe60ae135e37)\n'}]",1,780787,8a065c15a228d41e5c99a449cf53192e92a96c2d,4,2,1,10135,,,0,"Make _rebase_with_qemu_img() generic

Move volume_delete related logic away from this method, in order to make
it generic and usable elsewhere.

NOTE(lyarwood): Conflicts due to I9bcc66b0dc203e08222276bced77d4409c3adcea
and I897999e8a4601694213f068367eae9608cdc7bbb not being present in
stable/rocky.

Conflicts:
  nova/virt/libvirt/driver.py

Change-Id: I17357d85f845d4160cb7c7784772530a1e92af76
Related-Bug: #1732428
(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)
(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)
(cherry picked from commit ffcb1705cbb6ddaa3fa4d8881f416f25b763b5e7)
(cherry picked from commit 43cea4a744930daf3459a3bad294fe60ae135e37)
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/780787/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,8a065c15a228d41e5c99a449cf53192e92a96c2d,bug/1885528," @mock.patch('nova.virt.images.qemu_img_info', return_value=mock.Mock(file_format=""fake_fmt"")) @mock.patch('oslo_concurrency.processutils.execute') def test_rebase_with_qemu_img(self, mock_execute, mock_qemu_img_info): """"""rebasing disk image to another backing file"""""" self.drvr._rebase_with_qemu_img(""disk"", ""backing_file"") mock_qemu_img_info.assert_called_once_with(""backing_file"") mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', 'backing_file', '-F', 'fake_fmt', 'disk') # Flatten disk image when no backing file is given. mock_qemu_img_info.reset_mock() mock_execute.reset_mock() self.drvr._rebase_with_qemu_img(""disk"", None) self.assertEqual(0, mock_qemu_img_info.call_count) mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', '', 'disk') ",,37,23
openstack%2Fnova~stable%2Frocky~I2a1a5f804ed878d80771b7bb090248da3a6d1331,openstack/nova,stable/rocky,I2a1a5f804ed878d80771b7bb090248da3a6d1331,Documentation Bug with PLacement API port,ABANDONED,2020-05-27 10:17:35.000000000,2022-11-11 18:31:48.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 31916}]","[{'number': 1, 'created': '2020-05-27 10:17:35.000000000', 'files': ['doc/source/install/controller-install-obs.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/23272f8e1b52d6acb1f3b5e4aabf9c9e1f00b9ec', 'message': 'Documentation Bug with PLacement API port\n\nIn ""Install and configure Controller node in openSUSE and SUSE Linux\nEnterprise."" Document ,the default Placement API port for controller\nnode was mentioned as ""8780"" ,but in ubuntu and RedHat related Docs\ncontain ""8778"" as default port. So modified from ""8780"" to ""8778"" to\nmaintain a consistency.\n\nChange-Id: I2a1a5f804ed878d80771b7bb090248da3a6d1331\nCloses-Bug: #1759839\n'}]",0,731141,23272f8e1b52d6acb1f3b5e4aabf9c9e1f00b9ec,8,4,1,31916,,,0,"Documentation Bug with PLacement API port

In ""Install and configure Controller node in openSUSE and SUSE Linux
Enterprise."" Document ,the default Placement API port for controller
node was mentioned as ""8780"" ,but in ubuntu and RedHat related Docs
contain ""8778"" as default port. So modified from ""8780"" to ""8778"" to
maintain a consistency.

Change-Id: I2a1a5f804ed878d80771b7bb090248da3a6d1331
Closes-Bug: #1759839
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/731141/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/controller-install-obs.rst'],1,23272f8e1b52d6acb1f3b5e4aabf9c9e1f00b9ec,, placement public http://controller:8778 | url | http://controller:8778 | placement internal http://controller:8778 | url | http://controller:8778 | placement admin http://controller:8778 | url | http://controller:8778 |, placement public http://controller:8780 | url | http://controller:8780 | placement internal http://controller:8780 | url | http://controller:8780 | placement admin http://controller:8780 | url | http://controller:8780 |,6,6
openstack%2Fnova~stable%2Frocky~I6a4252b0c12c41c233299f30ce8294fef21c7b40,openstack/nova,stable/rocky,I6a4252b0c12c41c233299f30ce8294fef21c7b40,libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event,ABANDONED,2020-03-04 13:39:38.000000000,2022-11-11 18:31:44.000000000,,"[{'_account_id': 6873}, {'_account_id': 9373}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14567}, {'_account_id': 14595}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 30498}]","[{'number': 1, 'created': '2020-03-04 13:39:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/410530bdef49913682d63f5728241dbb2473eafa', 'message': 'libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event\n\nChange Ic5cab99944df9e501ba2032eb96911c36304494d added handling for\nthe VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration\nbut failed to distinguish between the live migration actually succeeding\nor failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED\nup into the ComputeManager.handle_lifecycle_event method.\n\nAs a result, failed live migrations will inadvertantly trigger\nactivation of the port bindings on the destination host, which\ndeactivates the source host port bindings, and then\n_rollback_live_migration will delete those activated dest host port\nbindings and leave the source host port bindings deactivated.\n\nIn this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED\nevent, we attempt to get the job status to determine the course to\ntake and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,\nwhich triggers the dest host port activation, if we can determine\nthe live migration job completed successfully. Otherwise we simply\nreport the guest as paused, the same as before Ic5cab9994.\n\nConflicts:\n      nova/tests/unit/virt/libvirt/test_migration.py\n\nNOTE(elod.illes): The conflict is due to not having patch\nIfe89a705892ad96de6d5f8e68b6e4b99063a7512 in stable/rocky.\n\nChange-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40\nCloses-Bug: #1788014\n(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)\n(cherry picked from commit 27bfd0bc6233c25114504bb363402807752a7ece)\n(cherry picked from commit 6310e693039cc3b6d2808915a3b4daf7bbffb9a8)\n'}, {'number': 2, 'created': '2020-04-21 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/528d8a83adeaff2d471790729993b2a9937f1418', 'message': 'WIP: libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event\n\nChange Ic5cab99944df9e501ba2032eb96911c36304494d added handling for\nthe VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration\nbut failed to distinguish between the live migration actually succeeding\nor failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED\nup into the ComputeManager.handle_lifecycle_event method.\n\nAs a result, failed live migrations will inadvertantly trigger\nactivation of the port bindings on the destination host, which\ndeactivates the source host port bindings, and then\n_rollback_live_migration will delete those activated dest host port\nbindings and leave the source host port bindings deactivated.\n\nIn this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED\nevent, we attempt to get the job status to determine the course to\ntake and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,\nwhich triggers the dest host port activation, if we can determine\nthe live migration job completed successfully. Otherwise we simply\nreport the guest as paused, the same as before Ic5cab9994.\n\nConflicts:\n    nova/tests/unit/virt/libvirt/fakelibvirt.py\n    nova/tests/unit/virt/libvirt/test_migration.py\n    nova/virt/libvirt/host.py\n\nNOTE(elod.illes): The conflict of test_migration.py is due to not\nhaving patch Ife89a705892ad96de6d5f8e68b6e4b99063a7512 in stable/rocky.\nThe conflicts of fakelibvirt.py and host.py are due to patch\nI0981c0349f163120939c3ddb9aeac82a01ceacd0 is not present in\nstable/rocky and we cannot backport either, because the minimum libvirt\nversion is still 1.3.1 and that patch would require 3.0.0.\n\nChange-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40\nCloses-Bug: #1788014\n(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)\n(cherry picked from commit 27bfd0bc6233c25114504bb363402807752a7ece)\n(cherry picked from commit 6310e693039cc3b6d2808915a3b4daf7bbffb9a8)\n'}, {'number': 3, 'created': '2020-05-11 04:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28737e148c66474f792df7c60b4e67f6fb29d820', 'message': 'libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event\n\nChange Ic5cab99944df9e501ba2032eb96911c36304494d added handling for\nthe VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration\nbut failed to distinguish between the live migration actually succeeding\nor failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED\nup into the ComputeManager.handle_lifecycle_event method.\n\nAs a result, failed live migrations will inadvertantly trigger\nactivation of the port bindings on the destination host, which\ndeactivates the source host port bindings, and then\n_rollback_live_migration will delete those activated dest host port\nbindings and leave the source host port bindings deactivated.\n\nIn this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED\nevent, we attempt to get the job status to determine the course to\ntake and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,\nwhich triggers the dest host port activation, if we can determine\nthe live migration job completed successfully. Otherwise we simply\nreport the guest as paused, the same as before Ic5cab9994.\n\nConflicts:\n    nova/tests/unit/virt/libvirt/fakelibvirt.py\n    nova/tests/unit/virt/libvirt/test_migration.py\n    nova/virt/libvirt/host.py\n\nNOTE(elod.illes): The conflict of test_migration.py is due to not\nhaving patch Ife89a705892ad96de6d5f8e68b6e4b99063a7512 in stable/rocky.\nThe conflicts of fakelibvirt.py and host.py are due to patch\nI0981c0349f163120939c3ddb9aeac82a01ceacd0 is not present in\nstable/rocky and we cannot backport either, because the minimum libvirt\nversion is still 1.3.1 and that patch would require 3.0.0.\n\nChange-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40\nCloses-Bug: #1788014\n(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)\n(cherry picked from commit 27bfd0bc6233c25114504bb363402807752a7ece)\n(cherry picked from commit 6310e693039cc3b6d2808915a3b4daf7bbffb9a8)\n'}, {'number': 4, 'created': '2020-07-09 13:07:38.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_host.py', 'nova/virt/libvirt/host.py', 'nova/virt/libvirt/migration.py', 'nova/tests/unit/virt/libvirt/test_migration.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1b66fc9c03dbfeeb1ef3dd42b67297f995d86823', 'message': 'libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event\n\nChange Ic5cab99944df9e501ba2032eb96911c36304494d added handling for\nthe VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration\nbut failed to distinguish between the live migration actually succeeding\nor failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED\nup into the ComputeManager.handle_lifecycle_event method.\n\nAs a result, failed live migrations will inadvertantly trigger\nactivation of the port bindings on the destination host, which\ndeactivates the source host port bindings, and then\n_rollback_live_migration will delete those activated dest host port\nbindings and leave the source host port bindings deactivated.\n\nIn this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED\nevent, we attempt to get the job status to determine the course to\ntake and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,\nwhich triggers the dest host port activation, if we can determine\nthe live migration job completed successfully. Otherwise we simply\nreport the guest as paused, the same as before Ic5cab9994.\n\nConflicts:\n    nova/tests/unit/virt/libvirt/fakelibvirt.py\n    nova/tests/unit/virt/libvirt/test_migration.py\n    nova/virt/libvirt/host.py\n\nNOTE(elod.illes): The conflict of test_migration.py is due to not\nhaving patch Ife89a705892ad96de6d5f8e68b6e4b99063a7512 in stable/rocky.\nThe conflicts of fakelibvirt.py and host.py are due to patch\nI0981c0349f163120939c3ddb9aeac82a01ceacd0 is not present in\nstable/rocky and we cannot backport either, because the minimum libvirt\nversion is still 1.3.1 and that patch would require 3.0.0.\n\nChange-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40\nCloses-Bug: #1788014\n(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)\n(cherry picked from commit 27bfd0bc6233c25114504bb363402807752a7ece)\n(cherry picked from commit 6310e693039cc3b6d2808915a3b4daf7bbffb9a8)\n'}]",3,711233,1b66fc9c03dbfeeb1ef3dd42b67297f995d86823,40,12,4,17685,,,0,"libvirt: check job status for VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event

Change Ic5cab99944df9e501ba2032eb96911c36304494d added handling for
the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED event during live migration
but failed to distinguish between the live migration actually succeeding
or failing before queueing the EVENT_LIFECYCLE_MIGRATION_COMPLETED
up into the ComputeManager.handle_lifecycle_event method.

As a result, failed live migrations will inadvertantly trigger
activation of the port bindings on the destination host, which
deactivates the source host port bindings, and then
_rollback_live_migration will delete those activated dest host port
bindings and leave the source host port bindings deactivated.

In this change, if we get the VIR_DOMAIN_EVENT_SUSPENDED_MIGRATED
event, we attempt to get the job status to determine the course to
take and only queue the EVENT_LIFECYCLE_MIGRATION_COMPLETED event,
which triggers the dest host port activation, if we can determine
the live migration job completed successfully. Otherwise we simply
report the guest as paused, the same as before Ic5cab9994.

Conflicts:
    nova/tests/unit/virt/libvirt/fakelibvirt.py
    nova/tests/unit/virt/libvirt/test_migration.py
    nova/virt/libvirt/host.py

NOTE(elod.illes): The conflict of test_migration.py is due to not
having patch Ife89a705892ad96de6d5f8e68b6e4b99063a7512 in stable/rocky.
The conflicts of fakelibvirt.py and host.py are due to patch
I0981c0349f163120939c3ddb9aeac82a01ceacd0 is not present in
stable/rocky and we cannot backport either, because the minimum libvirt
version is still 1.3.1 and that patch would require 3.0.0.

Change-Id: I6a4252b0c12c41c233299f30ce8294fef21c7b40
Closes-Bug: #1788014
(cherry picked from commit aa87b9c288d316b85079e681e0df24354ec1912c)
(cherry picked from commit 27bfd0bc6233c25114504bb363402807752a7ece)
(cherry picked from commit 6310e693039cc3b6d2808915a3b4daf7bbffb9a8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/711233/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_host.py', 'nova/virt/libvirt/host.py', 'nova/virt/libvirt/migration.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/unit/virt/libvirt/test_migration.py']",5,410530bdef49913682d63f5728241dbb2473eafa,bug/1788014," @mock.patch('nova.virt.libvirt.migration.LOG', new_callable=mock.NonCallableMock) # asserts not called @mock.patch('nova.virt.libvirt.guest.Guest.is_active', return_value=True) def test_live_migration_find_type_no_logging(self, mock_active, _mock_log): self.assertEqual(fakelibvirt.VIR_DOMAIN_JOB_FAILED, migration.find_job_type(self.guest, self.instance, logging_ok=False)) ",,88,31
openstack%2Fnova~stable%2Frocky~Ie36401c782f023d1d5f2623732619105dc2cfa24,openstack/nova,stable/rocky,Ie36401c782f023d1d5f2623732619105dc2cfa24,Reject open redirection in the console proxy,ABANDONED,2021-08-02 13:39:06.000000000,2022-11-11 18:31:40.000000000,,"[{'_account_id': 4690}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-08-02 13:39:06.000000000', 'files': ['releasenotes/notes/console-proxy-reject-open-redirect-4ac0a7895acca7eb.yaml', 'nova/console/websocketproxy.py', 'nova/tests/unit/console/test_websocketproxy.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/93f271338d301af53f873c207e67b2c4239b3bc6', 'message': 'Reject open redirection in the console proxy\n\nNOTE(melwitt): This is the combination of two commits, the bug fix and\na followup change to the unit test to enable it also run on\nPython < 3.6.\n\nOur console proxies (novnc, serial, spice) run in a websockify server\nwhose request handler inherits from the python standard\nSimpleHTTPRequestHandler. There is a known issue [1] in the\nSimpleHTTPRequestHandler which allows open redirects by way of URLs\nin the following format:\n\n  http://vncproxy.my.domain.com//example.com/%2F..\n\nwhich if visited, will redirect a user to example.com.\n\nWe can intercept a request and reject requests that pass a redirection\nURL beginning with ""//"" by implementing the\nSimpleHTTPRequestHandler.send_head() method containing the\nvulnerability to reject such requests with a 400 Bad Request.\n\nThis code is copied from a patch suggested in one of the issue comments\n[2].\n\nCloses-Bug: #1927677\n\n[1] https://bugs.python.org/issue32084\n[2] https://bugs.python.org/issue32084#msg306545\n\nReduce mocking in test_reject_open_redirect for compat\n\nThis is a followup for change Ie36401c782f023d1d5f2623732619105dc2cfa24\nto reduce mocking in the unit test coverage for it.\n\nWhile backporting the bug fix, it was found to be incompatible with\nearlier versions of Python < 3.6 due to a difference in internal\nimplementation [1].\n\nThis reduces the mocking in the unit test to be more agnostic to the\ninternals of the StreamRequestHandler (ancestor of\nSimpleHTTPRequestHandler) and work across Python versions >= 2.7.\n\nRelated-Bug: #1927677\n\n[1] https://github.com/python/cpython/commit/34eeed42901666fce099947f93dfdfc05411f286\n\nChange-Id: I546d376869a992601b443fb95acf1034da2a8f36\n(cherry picked from commit 214cabe6848a1fdb4f5941d994c6cc11107fc4af)\n(cherry picked from commit 9c2f29783734cb5f9cb05a08d328c10e1d16c4f1)\n(cherry picked from commit 94e265f3ca615aa18de0081a76975019997b8709)\n(cherry picked from commit d43b88a33407b1253e7bce70f720a44f7688141f)\n\nChange-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24\n(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)\n(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)\n(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)\n(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)\n(cherry picked from commit 5cb4d618ca67e622bbae24c768f9bdf408570986)\n'}]",0,803182,93f271338d301af53f873c207e67b2c4239b3bc6,4,2,1,20312,,,0,"Reject open redirection in the console proxy

NOTE(melwitt): This is the combination of two commits, the bug fix and
a followup change to the unit test to enable it also run on
Python < 3.6.

Our console proxies (novnc, serial, spice) run in a websockify server
whose request handler inherits from the python standard
SimpleHTTPRequestHandler. There is a known issue [1] in the
SimpleHTTPRequestHandler which allows open redirects by way of URLs
in the following format:

  http://vncproxy.my.domain.com//example.com/%2F..

which if visited, will redirect a user to example.com.

We can intercept a request and reject requests that pass a redirection
URL beginning with ""//"" by implementing the
SimpleHTTPRequestHandler.send_head() method containing the
vulnerability to reject such requests with a 400 Bad Request.

This code is copied from a patch suggested in one of the issue comments
[2].

Closes-Bug: #1927677

[1] https://bugs.python.org/issue32084
[2] https://bugs.python.org/issue32084#msg306545

Reduce mocking in test_reject_open_redirect for compat

This is a followup for change Ie36401c782f023d1d5f2623732619105dc2cfa24
to reduce mocking in the unit test coverage for it.

While backporting the bug fix, it was found to be incompatible with
earlier versions of Python < 3.6 due to a difference in internal
implementation [1].

This reduces the mocking in the unit test to be more agnostic to the
internals of the StreamRequestHandler (ancestor of
SimpleHTTPRequestHandler) and work across Python versions >= 2.7.

Related-Bug: #1927677

[1] https://github.com/python/cpython/commit/34eeed42901666fce099947f93dfdfc05411f286

Change-Id: I546d376869a992601b443fb95acf1034da2a8f36
(cherry picked from commit 214cabe6848a1fdb4f5941d994c6cc11107fc4af)
(cherry picked from commit 9c2f29783734cb5f9cb05a08d328c10e1d16c4f1)
(cherry picked from commit 94e265f3ca615aa18de0081a76975019997b8709)
(cherry picked from commit d43b88a33407b1253e7bce70f720a44f7688141f)

Change-Id: Ie36401c782f023d1d5f2623732619105dc2cfa24
(cherry picked from commit 781612b33282ed298f742c85dab58a075c8b793e)
(cherry picked from commit 470925614223c8dd9b1233f54f5a96c02b2d4f70)
(cherry picked from commit 6b70350bdcf59a9712f88b6435ba2c6500133e5b)
(cherry picked from commit 719e651e6be277950632e0c2cf5cc9a018344e7b)
(cherry picked from commit 5cb4d618ca67e622bbae24c768f9bdf408570986)
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/803182/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/console-proxy-reject-open-redirect-4ac0a7895acca7eb.yaml', 'nova/console/websocketproxy.py', 'nova/tests/unit/console/test_websocketproxy.py']",3,93f271338d301af53f873c207e67b2c4239b3bc6,bug/1927677-stable/rocky,"import io def test_reject_open_redirect(self): # This will test the behavior when an attempt is made to cause an open # redirect. It should be rejected. mock_req = mock.MagicMock() mock_req.makefile().readline.side_effect = [ b'GET //example.com/%2F.. HTTP/1.1\r\n', b'' ] client_addr = ('8.8.8.8', 54321) mock_server = mock.MagicMock() # This specifies that the server will be able to handle requests other # than only websockets. mock_server.only_upgrade = False # Constructing a handler will process the mock_req request passed in. handler = websocketproxy.NovaProxyRequestHandler( mock_req, client_addr, mock_server) # Collect the response data to verify at the end. The # SimpleHTTPRequestHandler writes the response data to a 'wfile' # attribute. output = io.BytesIO() handler.wfile = output # Process the mock_req again to do the capture. handler.do_GET() output.seek(0) result = output.readlines() # Verify no redirect happens and instead a 400 Bad Request is returned. self.assertIn('400 URI must not start with //', result[0].decode()) ",,74,0
openstack%2Fnova~stable%2Frocky~I83817f7301680801beaee375825f02eda526eda1,openstack/nova,stable/rocky,I83817f7301680801beaee375825f02eda526eda1,Validate id as integer for os-aggregates,ABANDONED,2020-11-27 12:27:46.000000000,2022-11-11 18:31:35.000000000,,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 26250}]","[{'number': 1, 'created': '2020-11-27 12:27:46.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/openstack/compute/aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ad8aca7965dd7cc95e151056a74b63deecbe90a1', 'message': ""Validate id as integer for os-aggregates\n\nAccording to the api-ref, the id passed to calls in os-aggregates is\nsupposed to be an integer. No function validated this, so any value\npassed to these functions would directly reach the DB. While this is\nfine for SQLite, making a query with a string for an integer column on\nother databases like PostgreSQL results in a DBError exception and thus\na HTTP 500 instead of 400 or 404.\n\nThis commit adds validation for the id parameter the same way it's\nalready done for other endpoints.\n\nChange-Id: I83817f7301680801beaee375825f02eda526eda1\nCloses-Bug: 1865040\n(cherry picked from commit 2e70a1717f25652912886cbefa3f40e6df908c00)\n(cherry picked from commit 4653245ddcf989ebac4b964a41d881d78cf9ae2c)\n(cherry picked from commit 9448291d8f3ff6bef85d3bca4aa21c1e6036b3f1)\n""}]",0,764309,ad8aca7965dd7cc95e151056a74b63deecbe90a1,12,4,1,15334,,,0,"Validate id as integer for os-aggregates

According to the api-ref, the id passed to calls in os-aggregates is
supposed to be an integer. No function validated this, so any value
passed to these functions would directly reach the DB. While this is
fine for SQLite, making a query with a string for an integer column on
other databases like PostgreSQL results in a DBError exception and thus
a HTTP 500 instead of 400 or 404.

This commit adds validation for the id parameter the same way it's
already done for other endpoints.

Change-Id: I83817f7301680801beaee375825f02eda526eda1
Closes-Bug: 1865040
(cherry picked from commit 2e70a1717f25652912886cbefa3f40e6df908c00)
(cherry picked from commit 4653245ddcf989ebac4b964a41d881d78cf9ae2c)
(cherry picked from commit 9448291d8f3ff6bef85d3bca4aa21c1e6036b3f1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/764309/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/openstack/compute/aggregates.py']",2,ad8aca7965dd7cc95e151056a74b63deecbe90a1,bug/1865040,"from nova import utils @wsgi.expected_errors((400, 404)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) @wsgi.expected_errors((400, 404, 409)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) @wsgi.expected_errors((400, 404, 409)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) "," @wsgi.expected_errors(404) @wsgi.expected_errors((404, 409)) @wsgi.expected_errors((404, 409))",85,21
openstack%2Fnova~stable%2Frocky~I332d4f33ea6b9506cc24ac12e5c0994f208a3107,openstack/nova,stable/rocky,I332d4f33ea6b9506cc24ac12e5c0994f208a3107,Add functional test for bug 1937375,ABANDONED,2021-08-06 14:29:55.000000000,2022-11-11 18:31:32.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-08-06 14:29:55.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1937375.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9a123489f412e0e49db7cf5b36e82bbcf930ff15', 'message': 'Add functional test for bug 1937375\n\n- InstanceHelperMixin pulled in for access to a better\n  _build_minimal_create_server_request method\n- api_major_version defined in test class\n- Fake image service stubbed out directing in test class\n- A simple _create_server method is in-lined within the class\n\nRelated-Bug: #1937375\nChange-Id: I332d4f33ea6b9506cc24ac12e5c0994f208a3107\n(cherry picked from commit 2ffd9738602531e93495a1feca76bbb687c3e72c)\n(cherry picked from commit 7a9e3dcd172f187cf93f406b09f49d2ded9bd90d)\n(cherry picked from commit 68b2d5f797896768229db1cf28feb22a984daf81)\n(cherry picked from commit 2a67e8794f916af07a05c550dca01d7fca625caf)\n(cherry picked from commit 051a14674195e5d37b931d3b59366656801bc8a1)\n(cherry picked from commit 975806f3995e7b09c477859aadd8a5771acd2771)\n'}]",0,803764,9a123489f412e0e49db7cf5b36e82bbcf930ff15,3,2,1,29074,,,0,"Add functional test for bug 1937375

- InstanceHelperMixin pulled in for access to a better
  _build_minimal_create_server_request method
- api_major_version defined in test class
- Fake image service stubbed out directing in test class
- A simple _create_server method is in-lined within the class

Related-Bug: #1937375
Change-Id: I332d4f33ea6b9506cc24ac12e5c0994f208a3107
(cherry picked from commit 2ffd9738602531e93495a1feca76bbb687c3e72c)
(cherry picked from commit 7a9e3dcd172f187cf93f406b09f49d2ded9bd90d)
(cherry picked from commit 68b2d5f797896768229db1cf28feb22a984daf81)
(cherry picked from commit 2a67e8794f916af07a05c550dca01d7fca625caf)
(cherry picked from commit 051a14674195e5d37b931d3b59366656801bc8a1)
(cherry picked from commit 975806f3995e7b09c477859aadd8a5771acd2771)
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/803764/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1937375.py'],1,9a123489f412e0e49db7cf5b36e82bbcf930ff15,backport_rocky_1937375,"# Copyright 2020, Red Hat, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import time import nova.tests.unit.image.fake from nova import context from nova import objects from nova.tests import fixtures as nova_fixtures from nova.tests.functional import integrated_helpers class TestDuplicateVolAttachRace( integrated_helpers.InstanceHelperMixin, integrated_helpers._IntegratedTestBase ): """"""Regression test for bug #1937375 A regression test to assert the behaviour of bug #1937375 where calls to reserve_block_device_name can race and create duplicate bdm records. As we can't recreate the race with pure API driven requests in our functional tests this instead makes duplicate calls to reserve_block_device_name during an attach to mimic the behaviour. """""" api_major_version = 'v2.1' microversion = 'latest' def setUp(self): super(TestDuplicateVolAttachRace, self).setUp() self.cinder = self.useFixture(nova_fixtures.CinderFixture(self)) self.fake_image_service =\ nova.tests.unit.image.fake.stub_out_image_service(self) self.image_uuid = list(self.fake_image_service.images)[0] def _create_server(self): server = self._build_minimal_create_server_request( self.api, 'test', image_uuid=self.image_uuid, networks='none') server = self.api.post_server({'server': server}) return self._wait_for_state_change(self.api, server, 'ACTIVE') # TODO(lyarwood): Copied from test_bug_1675570.py, move both into # _IntegratedTestBase. def _wait_for_volume_attach(self, server_id, volume_id): timeout = 0.0 server = self.api.get_server(server_id) attached_vols = [vol['id'] for vol in server['os-extended-volumes:volumes_attached']] while volume_id not in attached_vols and timeout < 10.0: time.sleep(.1) timeout += .1 server = self.api.get_server(server_id) attached_vols = [vol['id'] for vol in server['os-extended-volumes:volumes_attached']] if volume_id not in attached_vols: self.fail('Timed out waiting for volume %s to be attached to ' 'server %s. Currently attached volumes: %s' % (volume_id, server_id, attached_vols)) def test_duplicate_volume_attach_race(self): ctxt = context.get_admin_context() volume_id = self.cinder.IMAGE_BACKED_VOL server_id = self._create_server()['id'] original_reserve_name = self.compute.manager.reserve_block_device_name def wrap_reserve_block_device_name(*args, **kwargs): # We can't cause a race with duplicate API requests as functional # tests are single threaded and the first would always complete # before the second was serviced. Instead we can wrap # reserve_block_device_name on the compute manager and call it # twice to mimic two callers racing each other after the checks on # the api. original_bdm = original_reserve_name(*args, **kwargs) original_reserve_name(*args, **kwargs) return original_bdm with mock.patch.object( self.compute.manager, 'reserve_block_device_name', wrap_reserve_block_device_name ): self.api.post_server_volume( server_id, {'volumeAttachment': {'volumeId': volume_id}}) # Wait for a volume to be attached self._wait_for_volume_attach(server_id, volume_id) # Fetch all bdms for the instance to assert what we have bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( ctxt, server_id) # FIXME(lyarwood): This is bug #1937375, we now have 3 bdms for the # instance, the original root disk and two duplicate volume bdms for # the same volume attachment. self.assertEqual(3, len(bdms)) self.assertEqual(volume_id, bdms[2].volume_id) self.assertEqual(volume_id, bdms[1].volume_id) self.assertEqual('local', bdms[0].destination_type) ",,115,0
openstack%2Fnova~stable%2Frocky~Ie62d3566230aa3e2786d129adbb2e3570b06e4c6,openstack/nova,stable/rocky,Ie62d3566230aa3e2786d129adbb2e3570b06e4c6,Prevent archiving of pci_devices records because of 'instance_uuid',ABANDONED,2020-11-02 18:16:55.000000000,2022-11-11 18:31:22.000000000,,"[{'_account_id': 10118}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-11-02 18:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03c7a3dbce76443b43ba434c4b46f4542121516f', 'message': 'Prevent archiving of pci_devices records because of \'instance_uuid\'\n\nCurrently in the archive_deleted_rows code, we will attempt to clean up\n""residue"" of deleted instance records by assuming any table with a\n\'instance_uuid\' column represents data tied to an instance\'s lifecycle\nand delete such records.\n\nThis behavior poses a problem in the case where an instance has a PCI\ndevice allocated and someone deletes the instance. The \'instance_uuid\'\ncolumn in the pci_devices table is used to track the allocation\nassociation of a PCI with an instance. There is a small time window\nduring which the instance record has been deleted but the PCI device\nhas not yet been freed from a database record perspective as PCI\ndevices are freed during the _complete_deletion method in the compute\nmanager as part of the resource tracker update call.\n\nRecords in the pci_devices table are anyway not related to the\nlifecycle of instances so they should not be considered residue to\nclean up if an instance is deleted. This adds a condition to avoid\narchiving pci_devices on the basis of an instance association.\n\nCloses-Bug: #1899541\n\nConflicts:\n    nova/db/sqlalchemy/api.py\n    nova/tests/functional/db/test_archive.py\n\nNOTE(melwitt): The conflicts are because change\nI9725f752f8aef8066f7c9705e87610cad887bf8e (refactor nova-manage\narchive_deleted_rows) and change\nId16c3d91d9ce5db9ffd125b59fffbfedf4a6843d (nova-manage db\narchive_deleted_rows is not multi-cell aware) are not in Stein.\n\nChange-Id: Ie62d3566230aa3e2786d129adbb2e3570b06e4c6\n(cherry picked from commit 1c256cf774693e2395ae8fe4a7a2f416a7aeb03a)\n(cherry picked from commit 09784db62fcd01124a101c4c69cab6e71e1ac781)\n(cherry picked from commit 79df36fecf8c8be5ae9d59397882ac844852043e)\n(cherry picked from commit e3bb6119cf2d0a503768979312aea4d10cf85cda)\n(cherry picked from commit da91b19d8be3b9cad8f713a3218a08e2d50238c8)\n'}, {'number': 2, 'created': '2020-11-02 18:19:07.000000000', 'files': ['nova/tests/functional/db/test_archive.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/661179de486e710f260e448b005e3383038337b8', 'message': 'Prevent archiving of pci_devices records because of \'instance_uuid\'\n\nCurrently in the archive_deleted_rows code, we will attempt to clean up\n""residue"" of deleted instance records by assuming any table with a\n\'instance_uuid\' column represents data tied to an instance\'s lifecycle\nand delete such records.\n\nThis behavior poses a problem in the case where an instance has a PCI\ndevice allocated and someone deletes the instance. The \'instance_uuid\'\ncolumn in the pci_devices table is used to track the allocation\nassociation of a PCI with an instance. There is a small time window\nduring which the instance record has been deleted but the PCI device\nhas not yet been freed from a database record perspective as PCI\ndevices are freed during the _complete_deletion method in the compute\nmanager as part of the resource tracker update call.\n\nRecords in the pci_devices table are anyway not related to the\nlifecycle of instances so they should not be considered residue to\nclean up if an instance is deleted. This adds a condition to avoid\narchiving pci_devices on the basis of an instance association.\n\nCloses-Bug: #1899541\n\nChange-Id: Ie62d3566230aa3e2786d129adbb2e3570b06e4c6\n(cherry picked from commit 1c256cf774693e2395ae8fe4a7a2f416a7aeb03a)\n(cherry picked from commit 09784db62fcd01124a101c4c69cab6e71e1ac781)\n(cherry picked from commit 79df36fecf8c8be5ae9d59397882ac844852043e)\n(cherry picked from commit e3bb6119cf2d0a503768979312aea4d10cf85cda)\n(cherry picked from commit da91b19d8be3b9cad8f713a3218a08e2d50238c8)\n'}]",0,760985,661179de486e710f260e448b005e3383038337b8,11,4,2,4690,,,0,"Prevent archiving of pci_devices records because of 'instance_uuid'

Currently in the archive_deleted_rows code, we will attempt to clean up
""residue"" of deleted instance records by assuming any table with a
'instance_uuid' column represents data tied to an instance's lifecycle
and delete such records.

This behavior poses a problem in the case where an instance has a PCI
device allocated and someone deletes the instance. The 'instance_uuid'
column in the pci_devices table is used to track the allocation
association of a PCI with an instance. There is a small time window
during which the instance record has been deleted but the PCI device
has not yet been freed from a database record perspective as PCI
devices are freed during the _complete_deletion method in the compute
manager as part of the resource tracker update call.

Records in the pci_devices table are anyway not related to the
lifecycle of instances so they should not be considered residue to
clean up if an instance is deleted. This adds a condition to avoid
archiving pci_devices on the basis of an instance association.

Closes-Bug: #1899541

Change-Id: Ie62d3566230aa3e2786d129adbb2e3570b06e4c6
(cherry picked from commit 1c256cf774693e2395ae8fe4a7a2f416a7aeb03a)
(cherry picked from commit 09784db62fcd01124a101c4c69cab6e71e1ac781)
(cherry picked from commit 79df36fecf8c8be5ae9d59397882ac844852043e)
(cherry picked from commit e3bb6119cf2d0a503768979312aea4d10cf85cda)
(cherry picked from commit da91b19d8be3b9cad8f713a3218a08e2d50238c8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/760985/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/db/test_archive.py', 'nova/db/sqlalchemy/api.py']",2,03c7a3dbce76443b43ba434c4b46f4542121516f,bug/1899541, if ((max_rows is None or rows_archived < max_rows) and # NOTE(melwitt): The pci_devices table uses the 'instance_uuid' # column to track the allocated association of a PCI device and its # records are not tied to the lifecycles of instance records. (tablename != 'pci_devices' and 'instance_uuid' in columns)):, if ((max_rows is None or rows_archived < max_rows) and 'instance_uuid' in columns):,21,2
openstack%2Fnova~stable%2Frocky~Ic9133f6bc14d4fe766d37a438bf52c33e89da768,openstack/nova,stable/rocky,Ic9133f6bc14d4fe766d37a438bf52c33e89da768,Improve error log when snapshot fails,ABANDONED,2021-03-25 12:01:27.000000000,2022-11-11 18:31:18.000000000,,"[{'_account_id': 7634}, {'_account_id': 17685}, {'_account_id': 21718}, {'_account_id': 22348}, {'_account_id': 26159}, {'_account_id': 32291}]","[{'number': 1, 'created': '2021-03-25 12:01:27.000000000', 'files': ['nova/exception.py', 'nova/image/glance.py', 'nova/tests/unit/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/57d340f1a336796c30677a723beccc713ae81dd0', 'message': 'Improve error log when snapshot fails\n\nIf snapshot creation via glance fails due to lack of space or over\nquota, we want to have a clearer error message.\n\nChange-Id: Ic9133f6bc14d4fe766d37a438bf52c33e89da768\nCloses-Bug: #1613770\n(cherry picked from commit 024bf10d8aec5e58111793a9652b16682eb61b7c)\n(cherry picked from commit 9e9c022bde3a3ffdf0dd87e21bf9afde0dbc1e74)\n(cherry picked from commit 446c9c56109329208193e3c9b106a0a2eb3cd9ce)\n'}]",0,782983,57d340f1a336796c30677a723beccc713ae81dd0,18,6,1,10135,,,0,"Improve error log when snapshot fails

If snapshot creation via glance fails due to lack of space or over
quota, we want to have a clearer error message.

Change-Id: Ic9133f6bc14d4fe766d37a438bf52c33e89da768
Closes-Bug: #1613770
(cherry picked from commit 024bf10d8aec5e58111793a9652b16682eb61b7c)
(cherry picked from commit 9e9c022bde3a3ffdf0dd87e21bf9afde0dbc1e74)
(cherry picked from commit 446c9c56109329208193e3c9b106a0a2eb3cd9ce)
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/782983/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/image/glance.py', 'nova/tests/unit/image/test_glance.py']",3,57d340f1a336796c30677a723beccc713ae81dd0,bug/1613770," def test_client_httpoverlimit_converts_to_imagequotaexceeded(self): in_exc = glanceclient.exc.HTTPOverLimit('123') out_exc = glance._translate_image_exception('123', in_exc) self.assertIsInstance(out_exc, exception.ImageQuotaExceeded) ",,12,0
openstack%2Fnova~stable%2Frocky~Ie904d1513b5cf76d6d5f6877545e8eb378dd5499,openstack/nova,stable/rocky,Ie904d1513b5cf76d6d5f6877545e8eb378dd5499,Add a WA flag waiting for vif-plugged event during reboot,ABANDONED,2021-11-19 16:56:33.000000000,2022-11-11 18:31:14.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-11-19 16:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3bac249a7c38bc7c10c5bbb7cc76d7e9e6eca648', 'message': 'Add a WA flag waiting for vif-plugged event during reboot\n\nThe libvirt driver power on and hard reboot destroys the domain first\nand unplugs the vifs then recreate the domain and replug the vifs.\nHowever nova does not wait for the network-vif-plugged event before\nunpause the domain. This can cause that the domain starts running and\nrequesting IP via DHCP before the networking backend finished plugging\nthe vifs.\n\nSo this patch adds a workaround config option to nova to wait for\nnetwork-vif-plugged events during hard reboot the same way as nova waits\nfor this event during new instance spawn.\n\nThis logic cannot be enabled unconditionally as not all neutron\nnetworking backend sending plug time events to wait for. Also the logic\nneeds to be vnic_type dependent as ml2/ovs and the in tree sriov backend\noften deployed together on the same compute. While ml2/ovs sends plug\ntime event the sriov backend does not send it reliably. So the\nconfiguration is not just a boolean flag but a list of vnic_types\ninstead. This way the waiting for the plug time event for a vif that is\nhandled by ml2/ovs is possible while the instance has other vifs handled\nby the sriov backend where no event can be expected.\n\nConflicts:\n      nova/conf/workarounds.py due to\n      If874f018ea996587e178219569c2903c2ee923cf not in stable/rocky\n\nThe stable/rocky specific changes:\n\n* The smart-nic vnic_type is removed from the allowed values as that\n  type is added in stein\n\nChange-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499\nCloses-Bug: #1946729\n(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)\n(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)\n(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)\n(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)\n(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)\n(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)\n(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)\n'}, {'number': 2, 'created': '2021-11-19 17:05:19.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1946729-wait-for-vif-plugged-event-during-hard-reboot-fb491f6a68370bab.yaml', '.zuul.yaml', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/75e48ce99938c9803efb15ab639b1adee9e3ebb3', 'message': 'Add a WA flag waiting for vif-plugged event during reboot\n\nThe libvirt driver power on and hard reboot destroys the domain first\nand unplugs the vifs then recreate the domain and replug the vifs.\nHowever nova does not wait for the network-vif-plugged event before\nunpause the domain. This can cause that the domain starts running and\nrequesting IP via DHCP before the networking backend finished plugging\nthe vifs.\n\nSo this patch adds a workaround config option to nova to wait for\nnetwork-vif-plugged events during hard reboot the same way as nova waits\nfor this event during new instance spawn.\n\nThis logic cannot be enabled unconditionally as not all neutron\nnetworking backend sending plug time events to wait for. Also the logic\nneeds to be vnic_type dependent as ml2/ovs and the in tree sriov backend\noften deployed together on the same compute. While ml2/ovs sends plug\ntime event the sriov backend does not send it reliably. So the\nconfiguration is not just a boolean flag but a list of vnic_types\ninstead. This way the waiting for the plug time event for a vif that is\nhandled by ml2/ovs is possible while the instance has other vifs handled\nby the sriov backend where no event can be expected.\n\nConflicts:\n      nova/conf/workarounds.py due to\n      If874f018ea996587e178219569c2903c2ee923cf not in stable/rocky\n\nThe stable/rocky specific changes:\n\n* The smart-nic vnic_type is removed from the allowed values as that\n  type is added in stein\n\nChange-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499\nCloses-Bug: #1946729\n(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)\n(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)\n(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)\n(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)\n(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)\n(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)\n(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)\n'}]",0,818604,75e48ce99938c9803efb15ab639b1adee9e3ebb3,5,1,2,9708,,,0,"Add a WA flag waiting for vif-plugged event during reboot

The libvirt driver power on and hard reboot destroys the domain first
and unplugs the vifs then recreate the domain and replug the vifs.
However nova does not wait for the network-vif-plugged event before
unpause the domain. This can cause that the domain starts running and
requesting IP via DHCP before the networking backend finished plugging
the vifs.

So this patch adds a workaround config option to nova to wait for
network-vif-plugged events during hard reboot the same way as nova waits
for this event during new instance spawn.

This logic cannot be enabled unconditionally as not all neutron
networking backend sending plug time events to wait for. Also the logic
needs to be vnic_type dependent as ml2/ovs and the in tree sriov backend
often deployed together on the same compute. While ml2/ovs sends plug
time event the sriov backend does not send it reliably. So the
configuration is not just a boolean flag but a list of vnic_types
instead. This way the waiting for the plug time event for a vif that is
handled by ml2/ovs is possible while the instance has other vifs handled
by the sriov backend where no event can be expected.

Conflicts:
      nova/conf/workarounds.py due to
      If874f018ea996587e178219569c2903c2ee923cf not in stable/rocky

The stable/rocky specific changes:

* The smart-nic vnic_type is removed from the allowed values as that
  type is added in stein

Change-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499
Closes-Bug: #1946729
(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)
(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)
(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)
(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)
(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)
(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)
(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/818604/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1946729-wait-for-vif-plugged-event-during-hard-reboot-fb491f6a68370bab.yaml', '.zuul.yaml', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,3bac249a7c38bc7c10c5bbb7cc76d7e9e6eca648,bug/1946729," block_device_info=block_device_info, vifs_already_plugged=True, external_events=[]) @mock.patch('oslo_utils.fileutils.ensure_tree', new=mock.Mock()) @mock.patch('nova.virt.libvirt.LibvirtDriver.get_info') @mock.patch('nova.virt.libvirt.LibvirtDriver._create_domain_and_network') @mock.patch('nova.virt.libvirt.LibvirtDriver._get_guest_xml') @mock.patch('nova.virt.libvirt.LibvirtDriver.destroy', new=mock.Mock()) @mock.patch( 'nova.virt.libvirt.LibvirtDriver._get_all_assigned_mediated_devices', new=mock.Mock(return_value={})) def test_hard_reboot_wait_for_plug( self, mock_get_guest_xml, mock_create_domain_and_network, mock_get_info ): self.flags( group=""workarounds"", wait_for_vif_plugged_event_during_hard_reboot=[""normal""]) self.context.auth_token = None instance = objects.Instance(**self.test_instance) network_info = _fake_network_info(self, num_networks=4) network_info[0][""vnic_type""] = ""normal"" network_info[1][""vnic_type""] = ""direct"" network_info[2][""vnic_type""] = ""normal"" network_info[3][""vnic_type""] = ""direct-physical"" block_device_info = None return_values = [hardware.InstanceInfo(state=power_state.SHUTDOWN), hardware.InstanceInfo(state=power_state.RUNNING)] mock_get_info.side_effect = return_values mock_get_guest_xml.return_value = mock.sentinel.xml drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) drvr._hard_reboot( self.context, instance, network_info, block_device_info) mock_create_domain_and_network.assert_called_once_with( self.context, mock.sentinel.xml, instance, network_info, block_device_info=block_device_info, vifs_already_plugged=False, external_events=[ ('network-vif-plugged', uuids.vif1), ('network-vif-plugged', uuids.vif3), ] )"," block_device_info=block_device_info, vifs_already_plugged=True)",148,9
openstack%2Fnova~stable%2Frocky~I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527,openstack/nova,stable/rocky,I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527,Gracefull recovery when attaching volume fails,ABANDONED,2022-02-18 08:51:39.000000000,2022-11-11 18:31:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-18 08:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00f38c8d2c789e388562bc1bd66c023a216dd525', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}, {'number': 2, 'created': '2022-02-22 08:07:06.000000000', 'files': ['releasenotes/notes/bug-1960401-504eb255253d966a.yaml', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b6933e54394cb47476f3c40227ba9367116cb374', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}]",2,829860,b6933e54394cb47476f3c40227ba9367116cb374,10,1,2,29074,,,0,"Gracefull recovery when attaching volume fails

When trying to attach a volume to an already running instance the nova-api
requests the nova-compute service to create a BlockDeviceMapping. If the
nova-api does not receive a response within `rpc_response_timeout` it will
treat the request as failed and raise an exception.

There are multiple cases where nova-compute actually already processed the
request and just the reply did not reach the nova-api in time (see bug report).
After the failed request the database will contain a BlockDeviceMapping entry
for the volume + instance combination that will never be cleaned up again.
This entry also causes the nova-api to reject all future attachments of this
volume to this instance (as it assumes it is already attached).

To work around this we check if a BlockDeviceMapping has already been created
when we see a messaging timeout. If this is the case we can safely delete it
as the compute node has already finished processing and we will no longer pick
it up.
This allows users to try the request again.

A previous fix was abandoned but without a clear reason ([1]).

[1]: https://review.opendev.org/c/openstack/nova/+/731804

Closes-Bug: 1960401
Change-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527
(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/829860/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1960401-504eb255253d966a.yaml', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",3,00f38c8d2c789e388562bc1bd66c023a216dd525,," try: volume_bdm = self._create_volume_bdm( context, instance, device, volume, disk_bus=disk_bus, device_type=device_type, tag=tag) except oslo_exceptions.MessagingTimeout: # The compute node might have already created the attachment but # we never received the answer. In this case it is safe to delete # the attachment as nobody will ever pick it up again. with excutils.save_and_reraise_exception(): try: objects.BlockDeviceMapping.get_by_volume_and_instance( context, volume['id'], instance.uuid).destroy() LOG.debug(""Delete BDM after compute did not respond to "" f""attachment request for volume {volume['id']}"") except exception.VolumeBDMNotFound: LOG.debug(""BDM not found, ignoring removal. "" f""Error attaching volume {volume['id']}"")"," volume_bdm = self._create_volume_bdm( context, instance, device, volume, disk_bus=disk_bus, device_type=device_type, tag=tag)",62,3
openstack%2Fnova~stable%2Frocky~I92f35514efddcb071c7094370b79d91d34c5bc72,openstack/nova,stable/rocky,I92f35514efddcb071c7094370b79d91d34c5bc72,compute: Avoid duplicate BDMs during reserve_block_device_name,ABANDONED,2021-08-06 14:29:55.000000000,2022-11-11 18:31:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-08-06 14:29:55.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1937375.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/273c2e8358a8c36d44c9592326a2f833082a9196', 'message': 'compute: Avoid duplicate BDMs during reserve_block_device_name\n\nWhen attaching a volume to a running instance the nova-api validates\nthat the volume is not already attached to the instance. However\nnova-compute is responsible for actually creating the BDM entry in the\ndatabase. If sending attach requests fast enough it can be possible\nthat the same ""attach_volume"" request can be sent to nova-compute for\nthe same volume/instance combination.\n\nTo work around this we add a check in nova-compute to validate that\nthe volume has not been attached in the mean time.\n\nCloses-Bug: #1937375\nChange-Id: I92f35514efddcb071c7094370b79d91d34c5bc72\n(cherry picked from commit 2209b0007fe85d7c5439e0bfdfe2120c63898fa2)\n(cherry picked from commit 2bee83b8a980b2bd9e276b75aa74253f8c0d0a70)\n(cherry picked from commit 303c7a7c35044240f1546a5f960c1a4e6482f385)\n(cherry picked from commit deefea82efd87b001acce7cf8d0fc2915062228b)\n(cherry picked from commit 6ef97792387bf010b92da1e06beefc04d22ff5ff)\n(cherry picked from commit fc33fd8b7e935d8e6a690c18a0907875ac181dcf)\n'}]",0,803765,273c2e8358a8c36d44c9592326a2f833082a9196,4,1,1,29074,,,0,"compute: Avoid duplicate BDMs during reserve_block_device_name

When attaching a volume to a running instance the nova-api validates
that the volume is not already attached to the instance. However
nova-compute is responsible for actually creating the BDM entry in the
database. If sending attach requests fast enough it can be possible
that the same ""attach_volume"" request can be sent to nova-compute for
the same volume/instance combination.

To work around this we add a check in nova-compute to validate that
the volume has not been attached in the mean time.

Closes-Bug: #1937375
Change-Id: I92f35514efddcb071c7094370b79d91d34c5bc72
(cherry picked from commit 2209b0007fe85d7c5439e0bfdfe2120c63898fa2)
(cherry picked from commit 2bee83b8a980b2bd9e276b75aa74253f8c0d0a70)
(cherry picked from commit 303c7a7c35044240f1546a5f960c1a4e6482f385)
(cherry picked from commit deefea82efd87b001acce7cf8d0fc2915062228b)
(cherry picked from commit 6ef97792387bf010b92da1e06beefc04d22ff5ff)
(cherry picked from commit fc33fd8b7e935d8e6a690c18a0907875ac181dcf)
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/803765/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1937375.py', 'nova/compute/manager.py']",3,273c2e8358a8c36d44c9592326a2f833082a9196,backport_rocky_1937375," # Now that we have the lock check that we haven't raced another # request and ensure there is no existing attachment if any(b for b in bdms if b.volume_id == volume_id): msg = _(""volume %s already attached"") % volume_id raise exception.InvalidVolume(reason=msg) ",,41,6
openstack%2Fnova~stable%2Frocky~Id3e4452883f6a3cf44ff58b39ded82e882e28c23,openstack/nova,stable/rocky,Id3e4452883f6a3cf44ff58b39ded82e882e28c23,"Move 'check-cherry-picks' test to gate, n-v check",ABANDONED,2021-08-16 09:19:21.000000000,2022-11-11 18:30:54.000000000,,"[{'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-08-16 09:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9442f36d5aa0d0d2410315d3a6681d9e3a14ec5', 'message': ""Move 'check-cherry-picks' test to gate, n-v check\n\nThis currently runs in the 'check' pipeline, as part of the pep8 job,\nwhich causes otherwise perfectly valid backports to report as failing\nCI. There's no reason a stable core shouldn't be encouraged to review\nthese patches: we simply want to prevent them *merging* before their\nparent(s). Resolve this conflict by moving the check to separate voting\njob in the 'gate' pipeline as well as a non-voting job in the 'check'\npipeline to catch more obvious issues.\n\nConflicts:\n    .zuul.yaml\n\nNOTE(elod.illes): conflict is due to multiple patches, for example\n- Iae3fcac484f060e8dbeef299d594b8ade8ab3b70 that set lower-constraints\n  job as non-voting\n- I1832da2190be5ef2b04953938860a56a43e8cddf that was added in stein and\n  is not going to be backported to rocky\n\nChange-Id: Id3e4452883f6a3cf44ff58b39ded82e882e28c23\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 98b01c9a59df4912f5a162c2c52d1f00c84d24c2)\n(cherry picked from commit fef0305abefbf165fecb883f03bce97f525a790a)\n(cherry picked from commit b7677ae08ae151858ecb0e67039e54bb3df89700)\n(cherry picked from commit 91314f7fbba312d4438fa446804f692d316512a8)\n(cherry picked from commit de94f429474713a68d5efc53677bc468f02dc112)\n(cherry picked from commit 1960b50f0d9646e12a8e8849579fab8c047885a8)\n""}, {'number': 2, 'created': '2022-08-02 11:07:07.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ce541d821633263c3f497397d9515bb2f471628', 'message': ""Move 'check-cherry-picks' test to gate, n-v check\n\nThis currently runs in the 'check' pipeline, as part of the pep8 job,\nwhich causes otherwise perfectly valid backports to report as failing\nCI. There's no reason a stable core shouldn't be encouraged to review\nthese patches: we simply want to prevent them *merging* before their\nparent(s). Resolve this conflict by moving the check to separate voting\njob in the 'gate' pipeline as well as a non-voting job in the 'check'\npipeline to catch more obvious issues.\n\nConflicts:\n    .zuul.yaml\n\nNOTE(elod.illes): conflict is due to multiple patches, for example\n- Iae3fcac484f060e8dbeef299d594b8ade8ab3b70 that set lower-constraints\n  job as non-voting, then I514f6b337ffefef90a0ce9ab0b4afd083caa277e\n  that deletes the lower-constraints job\n- I1832da2190be5ef2b04953938860a56a43e8cddf that was added in stein and\n  is not going to be backported to rocky\n\nChange-Id: Id3e4452883f6a3cf44ff58b39ded82e882e28c23\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 98b01c9a59df4912f5a162c2c52d1f00c84d24c2)\n(cherry picked from commit fef0305abefbf165fecb883f03bce97f525a790a)\n(cherry picked from commit b7677ae08ae151858ecb0e67039e54bb3df89700)\n(cherry picked from commit 91314f7fbba312d4438fa446804f692d316512a8)\n(cherry picked from commit de94f429474713a68d5efc53677bc468f02dc112)\n(cherry picked from commit 1960b50f0d9646e12a8e8849579fab8c047885a8)\n""}]",2,804654,6ce541d821633263c3f497397d9515bb2f471628,11,2,2,17685,,,0,"Move 'check-cherry-picks' test to gate, n-v check

This currently runs in the 'check' pipeline, as part of the pep8 job,
which causes otherwise perfectly valid backports to report as failing
CI. There's no reason a stable core shouldn't be encouraged to review
these patches: we simply want to prevent them *merging* before their
parent(s). Resolve this conflict by moving the check to separate voting
job in the 'gate' pipeline as well as a non-voting job in the 'check'
pipeline to catch more obvious issues.

Conflicts:
    .zuul.yaml

NOTE(elod.illes): conflict is due to multiple patches, for example
- Iae3fcac484f060e8dbeef299d594b8ade8ab3b70 that set lower-constraints
  job as non-voting, then I514f6b337ffefef90a0ce9ab0b4afd083caa277e
  that deletes the lower-constraints job
- I1832da2190be5ef2b04953938860a56a43e8cddf that was added in stein and
  is not going to be backported to rocky

Change-Id: Id3e4452883f6a3cf44ff58b39ded82e882e28c23
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
(cherry picked from commit 98b01c9a59df4912f5a162c2c52d1f00c84d24c2)
(cherry picked from commit fef0305abefbf165fecb883f03bce97f525a790a)
(cherry picked from commit b7677ae08ae151858ecb0e67039e54bb3df89700)
(cherry picked from commit 91314f7fbba312d4438fa446804f692d316512a8)
(cherry picked from commit de94f429474713a68d5efc53677bc468f02dc112)
(cherry picked from commit 1960b50f0d9646e12a8e8849579fab8c047885a8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/804654/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,e9442f36d5aa0d0d2410315d3a6681d9e3a14ec5,cherry-pick-in-gate-queue,[testenv:validate-backport] description = Determine whether a backport is ready to be merged by checking whether it has already been merged to master or more recent stable branches. deps = skipsdist = true commands = bash tools/check-cherry-picks.sh , bash tools/check-cherry-picks.sh,23,1
openstack%2Fnova~stable%2Frocky~I6f4ed6479cacc39ca803e9d96eb402e41bd291d7,openstack/nova,stable/rocky,I6f4ed6479cacc39ca803e9d96eb402e41bd291d7,CI: Ironic is EOL'ing rocky; remove jobs,ABANDONED,2022-10-10 22:20:39.000000000,2022-11-11 18:30:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-10 22:20:39.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/85711c7a9ef6f190cea08c201d6047ee3759cb85', 'message': ""CI: Ironic is EOL'ing rocky; remove jobs\n\nIronic is EOLing the rocky release. Removes Ironic jobs from nova\nfor rocky since we are retiring the branch.\n\nChange-Id: I6f4ed6479cacc39ca803e9d96eb402e41bd291d7\n""}]",0,860879,85711c7a9ef6f190cea08c201d6047ee3759cb85,4,1,1,10342,,,0,"CI: Ironic is EOL'ing rocky; remove jobs

Ironic is EOLing the rocky release. Removes Ironic jobs from nova
for rocky since we are retiring the branch.

Change-Id: I6f4ed6479cacc39ca803e9d96eb402e41bd291d7
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/860879/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,85711c7a9ef6f190cea08c201d6047ee3759cb85,,, - ironic-tempest-dsvm-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false irrelevant-files: *dsvm-irrelevant-files - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode: irrelevant-files: - ^(placement-)?api-.*$ - ^.git.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^tests-py3.txt$ - ironic-tempest-dsvm-bfv: # NOTE: Ironic boot from volume only works starting in stable/pike. irrelevant-files: - ^(placement-)?api-.*$ - ^.git.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^tests-py3.txt$,0,20
openstack%2Fos-vif~stable%2Fqueens~I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76,openstack/os-vif,stable/queens,I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76,Refactor code of linux_net to more cleaner and increase performace,ABANDONED,2020-12-08 11:17:51.000000000,2022-11-11 18:29:16.000000000,,"[{'_account_id': 2874}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-12-08 11:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/09ef8e1c512e8d35483fe94fc966e7e9c4568bb2', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 76f7565b99e637d74878955a0033f35e9eb0e13f)\n'}, {'number': 2, 'created': '2020-12-14 13:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/8ba742015b9921f8983af4f93e6f1cb968aacd38', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit c36d072054567bf3e730f6ea0a0f69592e230359)\n'}, {'number': 3, 'created': '2020-12-31 10:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/00fb0f750a6bba4ab121a237b76399c13d67e008', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 6d5a0ac7351e7c67196d67c0f28657cfc9baf770)\n'}, {'number': 4, 'created': '2021-01-06 06:53:43.000000000', 'files': ['vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/2c80fccf3fb7e34039b9e487363853b5df06e515', 'message': 'Refactor code of linux_net to more cleaner and increase performace\n\nThe patch adds new functions \'_get_phys_port_name\' for reading physical\nport name of the SR-IOV port and \'_get_phys_switch_id\' for reading\nphysical port switch ID of the SR-IOV port, in addition to refactoring\n\'get_representor_port\' to use the new functions and decrease calls for\n""_get_pf_func"" and netdevs associated with the PF will now be processed\nin the loop, however it will not be matching \'phys_port_name\' which\nensures the correct behaviour.\n\nIn addition to updating the unit test for linux_net and remove not\nneeded mocks\n\nRelated-Bug: #1892132\nChange-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76\n(cherry picked from commit 246b7178414a23e99b3329c5383c4df244724384)\n'}]",1,765941,2c80fccf3fb7e34039b9e487363853b5df06e515,15,5,4,32296,,,0,"Refactor code of linux_net to more cleaner and increase performace

The patch adds new functions '_get_phys_port_name' for reading physical
port name of the SR-IOV port and '_get_phys_switch_id' for reading
physical port switch ID of the SR-IOV port, in addition to refactoring
'get_representor_port' to use the new functions and decrease calls for
""_get_pf_func"" and netdevs associated with the PF will now be processed
in the loop, however it will not be matching 'phys_port_name' which
ensures the correct behaviour.

In addition to updating the unit test for linux_net and remove not
needed mocks

Related-Bug: #1892132
Change-Id: I3fdbea4f48cb79ebfd03a4da21e2232ccafb7a76
(cherry picked from commit 246b7178414a23e99b3329c5383c4df244724384)
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/41/765941/1 && git format-patch -1 --stdout FETCH_HEAD,"['vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py']",2,09ef8e1c512e8d35483fe94fc966e7e9c4568bb2,rep-fix-queens-backport," @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_ioerror(self, mock__get_phys_switch_id): mock__get_phys_switch_id.side_effect = ([IOError()]) @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_empty(self, mock__get_phys_switch_id): mock__get_phys_switch_id.return_value = '' @mock.patch.object(linux_net, '_get_phys_switch_id') def test_is_switchdev_positive(self, mock__get_phys_switch_id): mock__get_phys_switch_id.return_value = 'pf_sw_id' @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, '_get_phys_switch_id') def test_get_representor_port(self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = (['1', ""pf0vf1"", ""pf0vf2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""2"" mock__get_phys_port_name.side_effect = ( [""p1"", ""p2"", ""VF1@PF1"", ""pf2vf1"", ""vf2@pf1"", ""pf2vf2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = ( [""p0"", ""1"", ""2""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.side_effect = ( mock__get_pf_func.return_value = ""0"" mock__get_phys_port_name.side_effect = ( [""p0"", ""pf0vf0"", ""pf0vf1""]) @mock.patch.object(linux_net, ""_get_pf_func"") @mock.patch.object(linux_net, ""_get_phys_port_name"") @mock.patch.object(linux_net, ""_get_phys_switch_id"") self, mock__get_phys_switch_id, mock__get_phys_port_name, mock__get_pf_func, mock_listdir): mock__get_phys_switch_id.return_value = 'pf_sw_id' mock__get_phys_port_name.side_effect = (['p0', '1', 'a']) mock__get_pf_func.return_value = ""0"" @mock.patch.object(linux_net, '_get_phys_switch_id') def test_physical_function_interface_name( self, mock__get_phys_switch_id, mock_listdir): mock__get_phys_switch_id.side_effect = ( @mock.patch.object(linux_net, '_get_phys_switch_id') def test_physical_function_interface_name_with_switchdev( self, mock__get_phys_switch_id, mock_listdir): mock__get_phys_switch_id.side_effect = ( @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test__get_phys_port_name(self, mock_isfile, mock_open): mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.return_value = 'pf0vf0' mock_isfile.return_value = True phys_port_name = linux_net._get_phys_port_name(""vf_ifname"") self.assertEqual(phys_port_name, 'pf0vf0') @mock.patch.object(os.path, 'isfile') def test__get_phys_port_name_not_found(self, mock_isfile): mock_isfile.return_value = False phys_port_name = linux_net._get_phys_port_name(""vf_ifname"") self.assertIsNone(phys_port_name) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test__get_phys_switch_id(self, mock_isfile, mock_open): mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.return_value = '66e40000039b0398' mock_isfile.return_value = True phys_port_name = linux_net._get_phys_switch_id(""ifname"") self.assertEqual(phys_port_name, '66e40000039b0398') @mock.patch.object(os.path, 'isfile') def test__get_phys_switch_id_not_found(self, mock_isfile): mock_isfile.return_value = False phys_port_name = linux_net._get_phys_switch_id(""ifname"") self.assertIsNone(phys_port_name)"," @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_ioerror(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( [IOError()]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_empty(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['']) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_is_switchdev_positive(self, mock_isfile, mock_open): mock_isfile.side_effect = [True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id']) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") def test_get_representor_port(self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', 'pf0vf2']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False), (""0000:0a:00.0"", True)]) open_calls = ( [mock.call('/sys/class/net/pf_ifname/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_1/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_1/phys_port_name', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_2/phys_switch_id', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None), mock.call('/sys/class/net/rep_vf_2/phys_port_name', 'r'), mock.call().readline(), mock.call().__exit__(None, None, None)]) mock_open.assert_has_calls(open_calls) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True, True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', 'VF1@PF1', 'pf_sw_id', 'vf2@pf1', 'pf_sw_id', 'pf2vf1', 'pf_sw_id', 'pf2vf2']) # PCI IDs mocked: # PF1: 0000:0a:00.1 PF2: 0000:0a:00.2 # PF1VF1: 0000:0a:02.1 PF1VF2: 0000:0a:02.2 # PF2VF1: 0000:0a:04.1 PF2VF2: 0000:0a:04.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.1"", True), (""0000:0a:00.2"", True), (""0000:0a:02.1"", False), (""0000:0a:00.2"", True), (""0000:0a:02.2"", False), (""0000:0a:00.2"", True), (""0000:0a:04.1"", False), (""0000:0a:00.2"", True), (""0000:0a:04.2"", False), (""0000:0a:00.2"", True)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', '2']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False), (""0000:0a:00.0"", True)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') @mock.patch.object(linux_net, ""get_function_by_ifname"") self, mock_get_function_by_ifname, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( ['pf_sw_id', 'pf_sw_id', '1', 'pf_sw_id', 'a']) # PCI IDs mocked: # PF0: 0000:0a:00.0 # PF0VF1: 0000:0a:02.1 PF0VF2: 0000:0a:02.2 mock_get_function_by_ifname.side_effect = ( [(""0000:0a:00.0"", True), (""0000:0a:02.1"", False), (""0000:0a:02.2"", False)]) @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_physical_function_inferface_name( self, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = ( @mock.patch('six.moves.builtins.open') @mock.patch.object(os.path, 'isfile') def test_physical_function_inferface_name_with_switchdev( self, mock_listdir, mock_isfile, mock_open): mock_isfile.side_effect = [True, True] mock_open.return_value.__enter__ = lambda s: s readline_mock = mock_open.return_value.readline readline_mock.side_effect = (",149,187
openstack%2Fos-vif~stable%2Fqueens~I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7,openstack/os-vif,stable/queens,I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7,Fix - os-vif fails to get the correct UpLink Representor,ABANDONED,2020-12-08 11:55:42.000000000,2022-11-11 18:29:09.000000000,,"[{'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 28714}]","[{'number': 1, 'created': '2020-12-08 11:55:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/fff543aa83edfb55bf92c300436455c1b7180d43', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit b37de19c58c877f5174d76d0a4ba5ab519f464e8)\n'}, {'number': 2, 'created': '2020-12-16 09:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/a3127ab48913ac63e3f744edb69aabec46dd5dab', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit 58a3014c6e119f10d937dfb7c997414f7f00e6ef)\n'}, {'number': 3, 'created': '2021-01-06 06:53:43.000000000', 'files': ['releasenotes/notes/bug-1892132-812e6d5ce0588ebb.yaml', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/add5a0fc5ad7668721809ba3ed98b7159ebedb9a', 'message': 'Fix - os-vif fails to get the correct UpLink Representor\n\nTill kernel 5.7 PF and VF representors are exposed as virtual device.\nThey are not linked to its parent PCI device like how uplink\nrepresentor is linked.\n\nStarting from kernel 5.8 due to new change [1] the PF and VF representors are\nlinked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails\nto get the correct UpLink Representor.\n\nThis patch modifys the behviour of ""get_ifname_by_pci_address"" to\ncheck the physical port name of the netdev in\nvf_pci_addr_path/physfn/net to match the formart for the uplink ""p\\d+"".\n\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1\n\nCloses-Bug: #1892132\nChange-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7\n(cherry picked from commit 32d87ffdfb97aa7fbac3894d292762f6c70d54b5)\n'}]",0,765983,add5a0fc5ad7668721809ba3ed98b7159ebedb9a,11,4,3,32296,,,0,"Fix - os-vif fails to get the correct UpLink Representor

Till kernel 5.7 PF and VF representors are exposed as virtual device.
They are not linked to its parent PCI device like how uplink
representor is linked.

Starting from kernel 5.8 due to new change [1] the PF and VF representors are
linked to their parent PCI device, and so ""get_ifname_by_pci_address"" fails
to get the correct UpLink Representor.

This patch modifys the behviour of ""get_ifname_by_pci_address"" to
check the physical port name of the netdev in
vf_pci_addr_path/physfn/net to match the formart for the uplink ""p\d+"".

[1] https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=123f0f53dd64b67e34142485fe866a8a581f12f1

Closes-Bug: #1892132
Change-Id: I49f6ae3f0e6bfbf555c8284bfd70371ce90da0c7
(cherry picked from commit 32d87ffdfb97aa7fbac3894d292762f6c70d54b5)
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/83/765983/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1892132-812e6d5ce0588ebb.yaml', 'vif_plug_ovs/linux_net.py', 'vif_plug_ovs/tests/unit/test_linux_net.py']",3,fff543aa83edfb55bf92c300436455c1b7180d43,rep-fix-queens-backport," @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): mock__get_phys_port_name.side_effect = ([""p1""]) @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): mock__get_phys_port_name.side_effect = ([""p1s0""]) @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") def test_physical_function_interface_name_with_representors( self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): # Get the PF that matches the phys_port_name regex mock_listdir.return_value = ['enp2s0f0_0', 'enp2s0f0_1', 'enp2s0f0'] mock__get_phys_switch_id.side_effect = ( ['valid_switch', 'valid_switch', 'valid_switch']) mock__get_phys_port_name.side_effect = ([""pf0vf0"", ""pf0vf1"", ""p0""]) ifname = linux_net.get_ifname_by_pci_address( '0000:00:00.1', pf_interface=True, switchdev=True) self.assertEqual(ifname, 'enp2s0f0') @mock.patch.object(os, 'listdir') @mock.patch.object(linux_net, ""_get_phys_switch_id"") @mock.patch.object(linux_net, ""_get_phys_port_name"") def test_physical_function_interface_name_with_fallback_To_first_netdev( self, mock__get_phys_port_name, mock__get_phys_switch_id, mock_listdir): # Try with switchdev mode to get PF but fail because there is no match # for the phys_port_name then fallback to first interface found mock_listdir.return_value = ['enp2s0f0_0', 'enp2s0f0_1', 'enp2s0f0'] mock__get_phys_switch_id.side_effect = (['valid_switch', 'valid_switch', 'valid_switch']) mock__get_phys_port_name.side_effect = ([""pf0vf0"", ""pf0vf1"", ""pf0vf2""]) ifname = linux_net.get_ifname_by_pci_address( '0000:00:00.1', pf_interface=True, switchdev=True) self.assertEqual(ifname, 'enp2s0f0_0') @mock.patch.object(os, 'listdir')"," self, mock__get_phys_switch_id, mock_listdir): @mock.patch.object(linux_net, '_get_phys_switch_id') self, mock__get_phys_switch_id, mock_listdir):",75,9
openstack%2Fnova~stable%2Fqueens~I6b33fcbc4d616dcc9b126ed744846acf2b56c5af,openstack/nova,stable/queens,I6b33fcbc4d616dcc9b126ed744846acf2b56c5af,Force refresh instance info_cache during heal,ABANDONED,2019-08-29 14:37:02.000000000,2022-11-11 18:24:48.000000000,,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-08-29 14:37:02.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_virtual_interfaces.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/56d90ee3e6e93b5361c38959761c0f29ffe35924', 'message': 'Force refresh instance info_cache during heal\n\nIf the instance info_cache is corrupted somehow, like during\na host reboot and the ports aren\'t wired up properly or\na mistaken policy change in neutron results in nova resetting\nthe info_cache to an empty list, the _heal_instance_info_cache\nis meant to fix it (once the current state of the ports for\nthe instance in neutron is corrected). However, the task is\ncurrently only refreshing the cache *based* on the current contents\nof the cache, which defeats the purpose of neutron being the source\nof truth for the ports attached to the instance.\n\nThis change makes the _heal_instance_info_cache periodic task\npass a ""force_refresh"" kwarg, which defaults to False for backward\ncompatibility with other methods that refresh the cache after\noperations like attach/detach interface, and if True will make\nnova get the current state of the ports for the instance from neutron\nand fully rebuild the info_cache.\n\nTo not lose port order in info_cache this change takes original order\nfrom nova historical data that are stored as VirtualInterfaceList\nobjects. For ports that are not registered as VirtualInterfaces\nobjects it will add them at the end of port_order list. Due to this\nfor instances older than Newton another patch was introduced to fill\nmissing VirtualInterface objects in the DB [1].\n\nLong-term we should be able to refactor some of the older refresh\ncode which leverages the cache to instead use the refresh_vif_id\nkwarg so that we do targeted cache updates when we do things like\nattach and detach ports, but that\'s a change for another day.\n\n[1] https://review.openstack.org/#/c/614167\n\nAlso contains partial cherry-pick of commit 4c93003 - which deletes\nsupport for the deprectated virtual-interfaces api call that is\ndeprecated in queens - and removes unit test removed as part of that\ncommit which conflicts with this patch.\n\nCo-Authored-By: Maciej Jozefczyk <maciej.jozefczyk@corp.ovh.com>\nCloses-Bug: #1751923\n(cherry picked from commit ba44c155ce1dcefede9741722a0525820d6da2b8)\n(cherry picked from commit ca5867d5644fdf1c74cc786ee71876ceb8c419bd)\n\nChange-Id: I6b33fcbc4d616dcc9b126ed744846acf2b56c5af\n'}]",0,679274,56d90ee3e6e93b5361c38959761c0f29ffe35924,7,5,1,6737,,,0,"Force refresh instance info_cache during heal

If the instance info_cache is corrupted somehow, like during
a host reboot and the ports aren't wired up properly or
a mistaken policy change in neutron results in nova resetting
the info_cache to an empty list, the _heal_instance_info_cache
is meant to fix it (once the current state of the ports for
the instance in neutron is corrected). However, the task is
currently only refreshing the cache *based* on the current contents
of the cache, which defeats the purpose of neutron being the source
of truth for the ports attached to the instance.

This change makes the _heal_instance_info_cache periodic task
pass a ""force_refresh"" kwarg, which defaults to False for backward
compatibility with other methods that refresh the cache after
operations like attach/detach interface, and if True will make
nova get the current state of the ports for the instance from neutron
and fully rebuild the info_cache.

To not lose port order in info_cache this change takes original order
from nova historical data that are stored as VirtualInterfaceList
objects. For ports that are not registered as VirtualInterfaces
objects it will add them at the end of port_order list. Due to this
for instances older than Newton another patch was introduced to fill
missing VirtualInterface objects in the DB [1].

Long-term we should be able to refactor some of the older refresh
code which leverages the cache to instead use the refresh_vif_id
kwarg so that we do targeted cache updates when we do things like
attach and detach ports, but that's a change for another day.

[1] https://review.openstack.org/#/c/614167

Also contains partial cherry-pick of commit 4c93003 - which deletes
support for the deprectated virtual-interfaces api call that is
deprecated in queens - and removes unit test removed as part of that
commit which conflicts with this patch.

Co-Authored-By: Maciej Jozefczyk <maciej.jozefczyk@corp.ovh.com>
Closes-Bug: #1751923
(cherry picked from commit ba44c155ce1dcefede9741722a0525820d6da2b8)
(cherry picked from commit ca5867d5644fdf1c74cc786ee71876ceb8c419bd)

Change-Id: I6b33fcbc4d616dcc9b126ed744846acf2b56c5af
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/679274/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_virtual_interfaces.py', 'nova/compute/manager.py']",5,56d90ee3e6e93b5361c38959761c0f29ffe35924,bug/1751923," self.network_api.get_instance_nw_info( context, instance, force_refresh=True)"," self.network_api.get_instance_nw_info(context, instance)",203,188
openstack%2Fnova~stable%2Fqueens~Ic2b82146d28be64b363b0b8e2e8d180b515bc0a0,openstack/nova,stable/queens,Ic2b82146d28be64b363b0b8e2e8d180b515bc0a0,delete consumers which no longer have allocations,ABANDONED,2019-12-05 01:51:03.000000000,2022-11-11 18:24:43.000000000,,"[{'_account_id': 7}, {'_account_id': 4690}, {'_account_id': 9373}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-05 01:51:03.000000000', 'files': ['nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/06d36fb35190366404fd2def4b9791388e158a1a', 'message': 'delete consumers which no longer have allocations\n\nWe made the decision [1] to delete consumer records when those consumers\nno longer had any allocations referring to them (as opposed to keeping\nthose consumer records around and incrementing the consumer generation\nfor them).\n\nThis patch adds a small check within the larger\nAllocationList.create_all() and AllocationList.delete_all() DB\ntransactions that deletes consumer records when no allocation records\nremain that reference that consumer. This patch does not, however,\nattempt to clean up any ""orphaned"" consumer records that may have been\ncreated in previous calls to PUT|POST /allocations that removed the last\nremaining allocations for a consumer.\n\n[1] https://goo.gl/DpAGbW\n\nCloses-bug: #1780799\n\nConflicts:\n  nova/api/openstack/placement/objects/consumer.py\n  nova/api/openstack/placement/objects/resource_provider.py\n  nova/tests/functional/api/openstack/placement/db/test_consumer.py\n\nNOTE(melwitt): This is a heavily hand-modified backport as the\nconsumer.py and test_consumer.py files do not exist in Queens. Changes\nare applied to resource_provider.py and test_resource_provider.py\ninstead as these are the appropriate locations for this functionality in\nQueens. Other than differences to use the appropriate Queens methods\nwhere the Rocky versions did not exist, the main difference from the\noriginal change is that the seen_consumers logic needed to be changed to\nadd a seen_consumer before the \'if alloc.used == 0\' loop continuation in\norder for detection and deletion of consumers without allocations to\nwork.\n\nChange-Id: Ic2b82146d28be64b363b0b8e2e8d180b515bc0a0\n(cherry picked from commit f0f680b492c82f4f5c4163b0534dacc315b6dce5)\n'}]",0,697398,06d36fb35190366404fd2def4b9791388e158a1a,8,8,1,4690,,,0,"delete consumers which no longer have allocations

We made the decision [1] to delete consumer records when those consumers
no longer had any allocations referring to them (as opposed to keeping
those consumer records around and incrementing the consumer generation
for them).

This patch adds a small check within the larger
AllocationList.create_all() and AllocationList.delete_all() DB
transactions that deletes consumer records when no allocation records
remain that reference that consumer. This patch does not, however,
attempt to clean up any ""orphaned"" consumer records that may have been
created in previous calls to PUT|POST /allocations that removed the last
remaining allocations for a consumer.

[1] https://goo.gl/DpAGbW

Closes-bug: #1780799

Conflicts:
  nova/api/openstack/placement/objects/consumer.py
  nova/api/openstack/placement/objects/resource_provider.py
  nova/tests/functional/api/openstack/placement/db/test_consumer.py

NOTE(melwitt): This is a heavily hand-modified backport as the
consumer.py and test_consumer.py files do not exist in Queens. Changes
are applied to resource_provider.py and test_resource_provider.py
instead as these are the appropriate locations for this functionality in
Queens. Other than differences to use the appropriate Queens methods
where the Rocky versions did not exist, the main difference from the
original change is that the seen_consumers logic needed to be changed to
add a seen_consumer before the 'if alloc.used == 0' loop continuation in
order for detection and deletion of consumers without allocations to
work.

Change-Id: Ic2b82146d28be64b363b0b8e2e8d180b515bc0a0
(cherry picked from commit f0f680b492c82f4f5c4163b0534dacc315b6dce5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/697398/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py']",2,06d36fb35190366404fd2def4b9791388e158a1a,bug/1780799," class DeleteConsumerIfNoAllocsTestCase(ResourceProviderBaseCase): def _get_consumer_by_uuid(self, consumer_uuid): tbl = rp_obj._CONSUMER_TBL sel = sa.select([tbl.c.id]).where( tbl.c.uuid == consumer_uuid, ) conn = self.api_db.get_engine().connect() return conn.execute(sel).fetchone() def test_delete_consumer_if_no_allocs(self): """"""AllocationList.create_all() should attempt to delete consumers that no longer have any allocations. Due to the REST API not having any way to query for consumers directly (only via the GET /allocations/{consumer_uuid} endpoint which returns an empty dict even when no consumer record exists for the {consumer_uuid}) we need to do this functional test using only the object layer. """""" # We will use two consumers in this test, only one of which will get # all of its allocations deleted in a transaction (and we expect that # consumer record to be deleted) c1 = uuidsentinel.consumer1 c2 = uuidsentinel.consumer2 # Create some inventory that we will allocate cn1 = rp_obj.ResourceProvider( context=self.ctx, uuid=uuidsentinel.cn1, name='cn1') cn1.create() inv_dict = {'resource_class': fields.ResourceClass.VCPU, 'total': 8, 'max_unit': 8} vcpu_inv = rp_obj.Inventory(context=self.ctx, resource_provider=cn1, **inv_dict) vcpu_inv.obj_set_defaults() inv_dict = {'resource_class': fields.ResourceClass.MEMORY_MB, 'total': 2048, 'max_unit': 2048} memory_inv = rp_obj.Inventory(context=self.ctx, resource_provider=cn1, **inv_dict) memory_inv.obj_set_defaults() inv_dict = {'resource_class': fields.ResourceClass.DISK_GB, 'total': 2000, 'max_unit': 2000} disk_inv = rp_obj.Inventory(context=self.ctx, resource_provider=cn1, **inv_dict) disk_inv.obj_set_defaults() inv_list = rp_obj.InventoryList( objects=[vcpu_inv, memory_inv, disk_inv]) cn1.set_inventory(inv_list) # Now allocate some of that inventory to two different consumers allocs = [ rp_obj.Allocation( self.ctx, consumer_id=c1, resource_provider=cn1, resource_class=fields.ResourceClass.VCPU, used=1, project_id=self.ctx.project_id, user_id=self.ctx.user_id), rp_obj.Allocation( self.ctx, consumer_id=c1, resource_provider=cn1, resource_class=fields.ResourceClass.MEMORY_MB, used=512, project_id=self.ctx.project_id, user_id=self.ctx.user_id), rp_obj.Allocation( self.ctx, consumer_id=c2, resource_provider=cn1, resource_class=fields.ResourceClass.VCPU, used=1, project_id=self.ctx.project_id, user_id=self.ctx.user_id), rp_obj.Allocation( self.ctx, consumer_id=c2, resource_provider=cn1, resource_class=fields.ResourceClass.MEMORY_MB, used=512, project_id=self.ctx.project_id, user_id=self.ctx.user_id), ] alloc_list = rp_obj.AllocationList(self.ctx, objects=allocs) alloc_list.create_all() # Validate that we have consumer records for both consumers for c_uuid in (c1, c2): self.assertIsNotNone(self._get_consumer_by_uuid(c_uuid)) # OK, now ""remove"" the allocation for consumer2 by setting the used # value for both allocated resources to 0 and re-running the # AllocationList.create_all(). This should end up deleting the consumer # record for consumer2 allocs = [ rp_obj.Allocation( self.ctx, consumer_id=c2, resource_provider=cn1, resource_class=fields.ResourceClass.VCPU, used=0, project_id=self.ctx.project_id, user_id=self.ctx.user_id), rp_obj.Allocation( self.ctx, consumer_id=c2, resource_provider=cn1, resource_class=fields.ResourceClass.MEMORY_MB, used=0, project_id=self.ctx.project_id, user_id=self.ctx.user_id), ] alloc_list = rp_obj.AllocationList(self.ctx, objects=allocs) alloc_list.create_all() # consumer1 should still exist... self.assertIsNotNone(self._get_consumer_by_uuid(c1)) # but not consumer2... self.assertIsNone(self._get_consumer_by_uuid(c2)) # DELETE /allocations/{consumer_uuid} is the other place where we # delete all allocations for a consumer. Let's delete all for consumer1 # and check that the consumer record is deleted alloc_list = rp_obj.AllocationList.get_all_by_consumer_id( self.ctx, c1) alloc_list.delete_all() # consumer1 should no longer exist in the DB since we just deleted all # of its allocations self.assertIsNone(self._get_consumer_by_uuid(c1))",,151,3
openstack%2Fnova~stable%2Fqueens~Id40440cdf31b3cc32a899bfd694b537a70703e9c,openstack/nova,stable/queens,Id40440cdf31b3cc32a899bfd694b537a70703e9c,hardware: fix memory check usage for small/large pages,ABANDONED,2020-03-31 14:54:20.000000000,2022-11-11 18:24:37.000000000,,"[{'_account_id': 935}, {'_account_id': 4690}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11805}, {'_account_id': 14595}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-03-31 14:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7df327288c78cdcd9da9b53cf777dec70be2738', 'message': ""hardware: fix memory check usage for small/large pages\n\nWhen huge pages are requested, we need to examine the host cell's\nspecific huge page amounts, not the amount of physical memory\nassociated with the host NUMA node.\n\nAlso when no pagesize is requested we should consider to compute\nmemory usage based on small pages since the amount of physical memory\navailable may also include some large pages.\n\nThe unit-tests has been updated to pass correct NUMACell mempages\ninformation since the check is not done based on the pages available\non host. Also that the test 'test_host_usage_contiguous' to reflect to\ncorrect update of pages availalbes on hist based on instance usage.\n\nCloses-bug: #1734204\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>\n(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)\n(cherry picked from commit 5e69018038176a60abbb3c879ae7ac7f12b8341a)\n\nConflicts:\n nova/tests/unit/compute/test_resource_tracker.py\n nova/tests/unit/virt/test_hardware.py\n\nChange-Id: Id40440cdf31b3cc32a899bfd694b537a70703e9c\n""}, {'number': 2, 'created': '2020-03-31 19:01:11.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/tests/unit/compute/test_resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e5753eba530c1fc48477dee402553743537d4f6', 'message': ""hardware: fix memory check usage for small/large pages\n\nWhen huge pages are requested, we need to examine the host cell's\nspecific huge page amounts, not the amount of physical memory\nassociated with the host NUMA node.\n\nAlso when no pagesize is requested we should consider to compute\nmemory usage based on small pages since the amount of physical memory\navailable may also include some large pages.\n\nThe unit-tests has been updated to pass correct NUMACell mempages\ninformation since the check is not done based on the pages available\non host. Also that the test 'test_host_usage_contiguous' to reflect to\ncorrect update of pages availalbes on hist based on instance usage.\n\nCloses-bug: #1734204\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>\n(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)\n(cherry picked from commit 5e69018038176a60abbb3c879ae7ac7f12b8341a)\n\nConflicts:\n nova/tests/unit/compute/test_resource_tracker.py\n nova/tests/unit/virt/test_hardware.py\n\nChange-Id: Id40440cdf31b3cc32a899bfd694b537a70703e9c\n""}]",2,716328,2e5753eba530c1fc48477dee402553743537d4f6,17,10,2,11805,,,0,"hardware: fix memory check usage for small/large pages

When huge pages are requested, we need to examine the host cell's
specific huge page amounts, not the amount of physical memory
associated with the host NUMA node.

Also when no pagesize is requested we should consider to compute
memory usage based on small pages since the amount of physical memory
available may also include some large pages.

The unit-tests has been updated to pass correct NUMACell mempages
information since the check is not done based on the pages available
on host. Also that the test 'test_host_usage_contiguous' to reflect to
correct update of pages availalbes on hist based on instance usage.

Closes-bug: #1734204
Signed-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>
(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)
(cherry picked from commit 5e69018038176a60abbb3c879ae7ac7f12b8341a)

Conflicts:
 nova/tests/unit/compute/test_resource_tracker.py
 nova/tests/unit/virt/test_hardware.py

Change-Id: Id40440cdf31b3cc32a899bfd694b537a70703e9c
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/716328/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/tests/unit/compute/test_resource_tracker.py']",3,d7df327288c78cdcd9da9b53cf777dec70be2738,bug/1734204," '2mb*1024': objects.NUMAPagesTopology(size_kb=2048, total=1024, used=0) mempages=[_NUMA_PAGE_TOPOLOGIES['2mb*1024']], mempages=[_NUMA_PAGE_TOPOLOGIES['2mb*1024']],"," '2kb*8': objects.NUMAPagesTopology(size_kb=2, total=8, used=0) mempages=[_NUMA_PAGE_TOPOLOGIES['2kb*8']], mempages=[_NUMA_PAGE_TOPOLOGIES['2kb*8']],",222,99
openstack%2Fnova~stable%2Fqueens~I0322d872bdff68936033a6f5a54e8296a6fb3434,openstack/nova,stable/queens,I0322d872bdff68936033a6f5a54e8296a6fb3434,Block rebuild when NUMA topology changed,ABANDONED,2020-01-17 17:48:56.000000000,2022-11-11 18:24:32.000000000,,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-17 17:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/741b473bc367bc74071085cbcb31dfb61fd115a0', 'message': ""Block rebuild when NUMA topology changed\n\nIf the image change during a rebuild it's possible for the request\nNUMA topology to change. As a rebuild uses a noop claim in the\nresource tracker the NUMA topology will not be updated as part of\na rebuild.\n\nIf the NUMA constraints do not change, a rebuild will continue as normal.\nIf the new constraints conflict with the existing NUMA constraints of the\ninstance the rebuild will be rejected without altering the status of the\ninstance.\n\nThis change introduces an API check to block rebuild when the NUMA\nrequirements for the new image do not match the existing NUMA constraints.\nThis is in line with the previous check introduced to prevent the rebuild of\nvolume-backed instances which similarly are not supported.\n\nThis change adds functional tests to assert the expected behaviour of\nrebuilding NUMA instances with new images. This change also asserts that\nin place rebuilds of numa instances is currently not supported.\n\nConflicts:\n    nova/api/openstack/compute/servers.py\n    nova/tests/functional/integrated_helpers.py\n    nova/tests/functional/libvirt/test_numa_servers.py\n    nova/tests/unit/compute/test_compute_api.py\n\nNOTE(sean-k-mooney): due to the lack of\n067ac4637698021ef874904024620128c010eb6d and\nI06fad233006c7bab14749a51ffa226c3801f951b\nnova/api/openstack/compute/servers.py was modifed to\nadd excpetion handeling for the ImageNUMATopologyRebuildConflict\non rebuild and nova/tests/functional/libvirt/test_numa_servers.py\nwas modifed to mock the libvirt connection in the\nNUMAServersRebuildTests setUp function.\n\nCloses-Bug: #1763766\nPartial-implements: blueprint inplace-rebuild-of-numa-instances\nChange-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434\n(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)\n(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)\n(cherry picked from commit 061e25015a93c345e39b7b340ad166c378d072ee)\n(cherry picked from commit 62dc74b61cf87d3ed9d5e93d1c2c5182f2ae7d50)\n""}, {'number': 2, 'created': '2020-01-21 21:33:48.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/integrated_helpers.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d76b3390488a77ec875dab6a4c2d79fda03c5496', 'message': ""Block rebuild when NUMA topology changed\n\nIf the image change during a rebuild it's possible for the request\nNUMA topology to change. As a rebuild uses a noop claim in the\nresource tracker the NUMA topology will not be updated as part of\na rebuild.\n\nIf the NUMA constraints do not change, a rebuild will continue as normal.\nIf the new constraints conflict with the existing NUMA constraints of the\ninstance the rebuild will be rejected without altering the status of the\ninstance.\n\nThis change introduces an API check to block rebuild when the NUMA\nrequirements for the new image do not match the existing NUMA constraints.\nThis is in line with the previous check introduced to prevent the rebuild of\nvolume-backed instances which similarly are not supported.\n\nThis change adds functional tests to assert the expected behaviour of\nrebuilding NUMA instances with new images. This change also asserts that\nin place rebuilds of numa instances is currently not supported.\n\nConflicts:\n    nova/api/openstack/compute/servers.py\n    nova/tests/functional/integrated_helpers.py\n    nova/tests/functional/libvirt/test_numa_servers.py\n    nova/tests/unit/compute/test_compute_api.py\n\nNOTE(sean-k-mooney):\nnova/tests/functional/libvirt/test_numa_servers.py\nwas modifed to mock the libvirt connection in the\nNUMAServersRebuildTests setUp function and to do\na partial backport of I621f5111d1cccf3dc2c2ea6767ce879bc286e42b\nto provide the NUMAServersTestBase class.\n\nCloses-Bug: #1763766\nPartial-implements: blueprint inplace-rebuild-of-numa-instances\nChange-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434\n(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)\n(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)\n(cherry picked from commit 061e25015a93c345e39b7b340ad166c378d072ee)\n(cherry picked from commit 62dc74b61cf87d3ed9d5e93d1c2c5182f2ae7d50)\n""}]",2,703140,d76b3390488a77ec875dab6a4c2d79fda03c5496,13,6,2,11604,,,0,"Block rebuild when NUMA topology changed

If the image change during a rebuild it's possible for the request
NUMA topology to change. As a rebuild uses a noop claim in the
resource tracker the NUMA topology will not be updated as part of
a rebuild.

If the NUMA constraints do not change, a rebuild will continue as normal.
If the new constraints conflict with the existing NUMA constraints of the
instance the rebuild will be rejected without altering the status of the
instance.

This change introduces an API check to block rebuild when the NUMA
requirements for the new image do not match the existing NUMA constraints.
This is in line with the previous check introduced to prevent the rebuild of
volume-backed instances which similarly are not supported.

This change adds functional tests to assert the expected behaviour of
rebuilding NUMA instances with new images. This change also asserts that
in place rebuilds of numa instances is currently not supported.

Conflicts:
    nova/api/openstack/compute/servers.py
    nova/tests/functional/integrated_helpers.py
    nova/tests/functional/libvirt/test_numa_servers.py
    nova/tests/unit/compute/test_compute_api.py

NOTE(sean-k-mooney):
nova/tests/functional/libvirt/test_numa_servers.py
was modifed to mock the libvirt connection in the
NUMAServersRebuildTests setUp function and to do
a partial backport of I621f5111d1cccf3dc2c2ea6767ce879bc286e42b
to provide the NUMAServersTestBase class.

Closes-Bug: #1763766
Partial-implements: blueprint inplace-rebuild-of-numa-instances
Change-Id: I0322d872bdff68936033a6f5a54e8296a6fb3434
(cherry picked from commit 6f5358ac1992b17b7f3f99d9a32290e0d4740dae)
(cherry picked from commit 745de99063bf77704a7f0610fe9e3647257eaa50)
(cherry picked from commit 061e25015a93c345e39b7b340ad166c378d072ee)
(cherry picked from commit 62dc74b61cf87d3ed9d5e93d1c2c5182f2ae7d50)
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/703140/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/integrated_helpers.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",7,741b473bc367bc74071085cbcb31dfb61fd115a0,, # NOTE(sean-k-mooney): due to the lack of the flavor and image # properties validation I06fad233006c7bab14749a51ffa226c3801f951b # in stable/rocky we explicitly catch the NUMA rebuild conflict # instead of extending the INVALID_FLAVOR_IMAGE_EXCEPTIONS tuple # which was introduced in the stein release. except exception.ImageNUMATopologyRebuildConflict as error: raise exc.HTTPBadRequest(explanation=error.format_message()),,717,5
openstack%2Fnova~stable%2Fqueens~I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b,openstack/nova,stable/queens,I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b,FUP for in-place numa rebuild,ABANDONED,2020-01-17 17:48:56.000000000,2022-11-11 18:24:27.000000000,,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-17 17:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ac2cb8a985235e37ab482ec0980612b0e8d8c5f', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\nNOTE(sean-k-mooney): conflict was due to the use of\nNUMAHostInfo instead of HostInfo.\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)\n(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)\n(cherry picked from commit 1d6018b880158fbaf34c17c6044583d1f2ca2aa3)\n(cherry picked from commit 1919b9648ac18e2330f3e5f22aa58f271abea545)\n'}, {'number': 2, 'created': '2020-01-21 21:33:48.000000000', 'files': ['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/db625745edb3c490984dc6fed8471c0e5f81cbab', 'message': 'FUP for in-place numa rebuild\n\nThis patch addresses a number of typos and minor\nissues raised during review of [1][2]. A summary\nof the changes are corrections to typos in comments,\na correction to the exception message, an update to\nthe release note and the addition of debug logging.\n\n[1] I0322d872bdff68936033a6f5a54e8296a6fb3434\n[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\n\nRelated-Bug: #1804502\nRelated-Bug: #1763766\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\nNOTE(sean-k-mooney): conflict was due to the use of\nNUMAHostInfo instead of HostInfo.\n\nChange-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b\n(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)\n(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)\n(cherry picked from commit 1d6018b880158fbaf34c17c6044583d1f2ca2aa3)\n(cherry picked from commit 1919b9648ac18e2330f3e5f22aa58f271abea545)\n'}]",0,703142,db625745edb3c490984dc6fed8471c0e5f81cbab,11,5,2,11604,,,0,"FUP for in-place numa rebuild

This patch addresses a number of typos and minor
issues raised during review of [1][2]. A summary
of the changes are corrections to typos in comments,
a correction to the exception message, an update to
the release note and the addition of debug logging.

[1] I0322d872bdff68936033a6f5a54e8296a6fb3434
[2] I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132

Related-Bug: #1804502
Related-Bug: #1763766

Conflicts:
    nova/tests/functional/libvirt/test_numa_servers.py
NOTE(sean-k-mooney): conflict was due to the use of
NUMAHostInfo instead of HostInfo.

Change-Id: I8975e524cd5a9c7dfb065bb2dc8ceb03f1b89e7b
(cherry picked from commit f6060ab6b54261ff50b8068732f6e509619d713e)
(cherry picked from commit 48bb9a9663374936221144bb6a24688128a51146)
(cherry picked from commit 1d6018b880158fbaf34c17c6044583d1f2ca2aa3)
(cherry picked from commit 1919b9648ac18e2330f3e5f22aa58f271abea545)
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/703142/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/compute/api.py']",6,7ac2cb8a985235e37ab482ec0980612b0e8d8c5f,," return # if only one of the constraints are non-None (or 'set') then the action = ""removing"" if old_constraints else ""introducing"" LOG.debug(""NUMA rebuild validation failed. The requested image "" ""would alter the NUMA constraints by %s a NUMA "" ""topology."", action, instance=instance) # otherwise since both the old a new constraints are non none compare LOG.debug(""NUMA rebuild validation failed. The requested image "" ""conflicts with the existing NUMA constraints."", instance=instance)", :returns: True or raises on failure. # return true for easy unit testing return True # if only one of the constrains are non-None (or 'set') then the # otherwise since both the old a new constrains are non none compare # return true for easy unit testing return True ,41,36
openstack%2Fnova~stable%2Fqueens~Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c,openstack/nova,stable/queens,Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c,libvirt: Log exception when unable to import rbd or rados,ABANDONED,2020-10-14 20:28:39.000000000,2022-11-11 18:24:22.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-10-14 20:28:39.000000000', 'files': ['nova/virt/libvirt/storage/rbd_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/26e34bf802babf6d9275a313fc1f3ef826d2a362', 'message': ""libvirt: Log exception when unable to import rbd or rados\n\nThis should help provide some context when the RbdDriver later raises a\nRuntimeError if rbd or rados hasn't been imported correctly.\n\nNOTE(lyarwood): Conflict as I745b3433a447aeec819781e0ee26df6e6c70530a\nis not present on stable/queens.\n\nConflicts:\n    nova/virt/libvirt/storage/rbd_utils.py\n\nChange-Id: Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c\n(cherry picked from commit aa16dd09ebeb21d0b81682b0b6026de0fe4f23b7)\n(cherry picked from commit 961a355fb314975ee169cbe9ef88eb8537294253)\n(cherry picked from commit 22c86f92ce7ef86675ee8265d43b21997e0df4bc)\n(cherry picked from commit 9c58a663b7999260e1683bae6a828d118aa44fd5)\n(cherry picked from commit cd7a1877a40b794e62086939d94b89bf928b61e9)\n(cherry picked from commit f42d4c1afbf64cac295a36741d49013bd23e3205)\n""}]",0,758245,26e34bf802babf6d9275a313fc1f3ef826d2a362,7,5,1,10135,,,0,"libvirt: Log exception when unable to import rbd or rados

This should help provide some context when the RbdDriver later raises a
RuntimeError if rbd or rados hasn't been imported correctly.

NOTE(lyarwood): Conflict as I745b3433a447aeec819781e0ee26df6e6c70530a
is not present on stable/queens.

Conflicts:
    nova/virt/libvirt/storage/rbd_utils.py

Change-Id: Ie8bb5e5622bd37dfe8073cca12f77174e8e7d98c
(cherry picked from commit aa16dd09ebeb21d0b81682b0b6026de0fe4f23b7)
(cherry picked from commit 961a355fb314975ee169cbe9ef88eb8537294253)
(cherry picked from commit 22c86f92ce7ef86675ee8265d43b21997e0df4bc)
(cherry picked from commit 9c58a663b7999260e1683bae6a828d118aa44fd5)
(cherry picked from commit cd7a1877a40b794e62086939d94b89bf928b61e9)
(cherry picked from commit f42d4c1afbf64cac295a36741d49013bd23e3205)
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/758245/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/storage/rbd_utils.py'],1,26e34bf802babf6d9275a313fc1f3ef826d2a362,,"# NOTE(lyarwood): Log exceptions if we fail to import rbd or rados in order to # provide context later if we end up attempting to use the RbdDriver and # raising RuntimeError try: import rados except ImportError: rados = None LOG.exception( ""Unable to import the rados module, this can be ignored if Ceph is "" ""not used within this environment"") try: import rbd except ImportError: rbd = None LOG.exception( ""Unable to import the rbd module, this can be ignored if Ceph is not "" ""used within this environment"") ",try: import rados import rbd except ImportError: rados = None rbd = None ,20,7
openstack%2Fnova~stable%2Fqueens~Ie62d3566230aa3e2786d129adbb2e3570b06e4c6,openstack/nova,stable/queens,Ie62d3566230aa3e2786d129adbb2e3570b06e4c6,Prevent archiving of pci_devices records because of 'instance_uuid',ABANDONED,2020-11-02 18:22:34.000000000,2022-11-11 18:24:17.000000000,,"[{'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-11-02 18:22:34.000000000', 'files': ['nova/tests/functional/db/test_archive.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/54e8af9af15404fd81814775896db65b9b24091b', 'message': 'Prevent archiving of pci_devices records because of \'instance_uuid\'\n\nCurrently in the archive_deleted_rows code, we will attempt to clean up\n""residue"" of deleted instance records by assuming any table with a\n\'instance_uuid\' column represents data tied to an instance\'s lifecycle\nand delete such records.\n\nThis behavior poses a problem in the case where an instance has a PCI\ndevice allocated and someone deletes the instance. The \'instance_uuid\'\ncolumn in the pci_devices table is used to track the allocation\nassociation of a PCI with an instance. There is a small time window\nduring which the instance record has been deleted but the PCI device\nhas not yet been freed from a database record perspective as PCI\ndevices are freed during the _complete_deletion method in the compute\nmanager as part of the resource tracker update call.\n\nRecords in the pci_devices table are anyway not related to the\nlifecycle of instances so they should not be considered residue to\nclean up if an instance is deleted. This adds a condition to avoid\narchiving pci_devices on the basis of an instance association.\n\nCloses-Bug: #1899541\n\nConflicts:\n    nova/tests/functional/db/test_archive.py\n\nNOTE(melwitt): The conflict is because change\nI6f87cf03d49be6bfad2c5e6f0c8accf0fab4e6ee (Add simple db purge command)\nis not in Queens.\n\nChange-Id: Ie62d3566230aa3e2786d129adbb2e3570b06e4c6\n(cherry picked from commit 1c256cf774693e2395ae8fe4a7a2f416a7aeb03a)\n(cherry picked from commit 09784db62fcd01124a101c4c69cab6e71e1ac781)\n(cherry picked from commit 79df36fecf8c8be5ae9d59397882ac844852043e)\n(cherry picked from commit e3bb6119cf2d0a503768979312aea4d10cf85cda)\n(cherry picked from commit da91b19d8be3b9cad8f713a3218a08e2d50238c8)\n(cherry picked from commit 661179de486e710f260e448b005e3383038337b8)\n'}]",0,760987,54e8af9af15404fd81814775896db65b9b24091b,5,3,1,4690,,,0,"Prevent archiving of pci_devices records because of 'instance_uuid'

Currently in the archive_deleted_rows code, we will attempt to clean up
""residue"" of deleted instance records by assuming any table with a
'instance_uuid' column represents data tied to an instance's lifecycle
and delete such records.

This behavior poses a problem in the case where an instance has a PCI
device allocated and someone deletes the instance. The 'instance_uuid'
column in the pci_devices table is used to track the allocation
association of a PCI with an instance. There is a small time window
during which the instance record has been deleted but the PCI device
has not yet been freed from a database record perspective as PCI
devices are freed during the _complete_deletion method in the compute
manager as part of the resource tracker update call.

Records in the pci_devices table are anyway not related to the
lifecycle of instances so they should not be considered residue to
clean up if an instance is deleted. This adds a condition to avoid
archiving pci_devices on the basis of an instance association.

Closes-Bug: #1899541

Conflicts:
    nova/tests/functional/db/test_archive.py

NOTE(melwitt): The conflict is because change
I6f87cf03d49be6bfad2c5e6f0c8accf0fab4e6ee (Add simple db purge command)
is not in Queens.

Change-Id: Ie62d3566230aa3e2786d129adbb2e3570b06e4c6
(cherry picked from commit 1c256cf774693e2395ae8fe4a7a2f416a7aeb03a)
(cherry picked from commit 09784db62fcd01124a101c4c69cab6e71e1ac781)
(cherry picked from commit 79df36fecf8c8be5ae9d59397882ac844852043e)
(cherry picked from commit e3bb6119cf2d0a503768979312aea4d10cf85cda)
(cherry picked from commit da91b19d8be3b9cad8f713a3218a08e2d50238c8)
(cherry picked from commit 661179de486e710f260e448b005e3383038337b8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/760987/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/db/test_archive.py', 'nova/db/sqlalchemy/api.py']",2,54e8af9af15404fd81814775896db65b9b24091b,bug/1899541, if ((max_rows is None or rows_archived < max_rows) and # NOTE(melwitt): The pci_devices table uses the 'instance_uuid' # column to track the allocated association of a PCI device and its # records are not tied to the lifecycles of instance records. (tablename != 'pci_devices' and 'instance_uuid' in columns)):, if ((max_rows is None or rows_archived < max_rows) and 'instance_uuid' in columns):,21,2
openstack%2Fnova~stable%2Fqueens~I335113f0ec59516cb337d34b6fc9078ea202130f,openstack/nova,stable/queens,I335113f0ec59516cb337d34b6fc9078ea202130f,Sanity check instance mapping during scheduling,ABANDONED,2020-11-16 17:53:01.000000000,2022-11-11 18:24:12.000000000,,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-11-16 17:53:01.000000000', 'files': ['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aea214a6233cde55a830eda9f2b0f32debc519fb', 'message': ""Sanity check instance mapping during scheduling\n\nmnaser reported a weird case where an instance was found\nin both cell0 (deleted there) and in cell1 (not deleted\nthere but in error state from a failed build). It's unclear\nhow this could happen besides some weird clustered rabbitmq\nissue where maybe the schedule and build request to conductor\nhappens twice for the same instance and one picks a host and\ntries to build and the other fails during scheduling and is\nburied in cell0.\n\nTo avoid a split brain situation like this, we add a sanity\ncheck in _bury_in_cell0 to make sure the instance mapping is\nnot pointing at a cell when we go to update it to cell0.\nSimilarly a check is added in the schedule_and_build_instances\nflow (the code is moved to a private method to make it easier\nto test).\n\nWorst case is this is unnecessary but doesn't hurt anything,\nbest case is this helps avoid split brain clustered rabbit\nissues.\n\nCloses-Bug: #1775934\n\nChange-Id: I335113f0ec59516cb337d34b6fc9078ea202130f\n(cherry picked from commit 5b552518e1abdc63fb33c633661e30e4b2fe775e)\n(cherry picked from commit efc35b1c5293c7c6c85f8cf9fd9d8cd8de71d1d5)\n(cherry picked from commit c895d3e6bca562225d70e8f81255f38970f7fcda)\n(cherry picked from commit 9b507c21aeeab876cd6a222d68f981fc923e8504)\n""}]",0,762903,aea214a6233cde55a830eda9f2b0f32debc519fb,7,5,1,4690,,,0,"Sanity check instance mapping during scheduling

mnaser reported a weird case where an instance was found
in both cell0 (deleted there) and in cell1 (not deleted
there but in error state from a failed build). It's unclear
how this could happen besides some weird clustered rabbitmq
issue where maybe the schedule and build request to conductor
happens twice for the same instance and one picks a host and
tries to build and the other fails during scheduling and is
buried in cell0.

To avoid a split brain situation like this, we add a sanity
check in _bury_in_cell0 to make sure the instance mapping is
not pointing at a cell when we go to update it to cell0.
Similarly a check is added in the schedule_and_build_instances
flow (the code is moved to a private method to make it easier
to test).

Worst case is this is unnecessary but doesn't hurt anything,
best case is this helps avoid split brain clustered rabbit
issues.

Closes-Bug: #1775934

Change-Id: I335113f0ec59516cb337d34b6fc9078ea202130f
(cherry picked from commit 5b552518e1abdc63fb33c633661e30e4b2fe775e)
(cherry picked from commit efc35b1c5293c7c6c85f8cf9fd9d8cd8de71d1d5)
(cherry picked from commit c895d3e6bca562225d70e8f81255f38970f7fcda)
(cherry picked from commit 9b507c21aeeab876cd6a222d68f981fc923e8504)
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/762903/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/conductor/test_conductor.py', 'nova/conductor/manager.py']",2,aea214a6233cde55a830eda9f2b0f32debc519fb,bug/1775934," inst_mapping = None try: # We don't need the cell0-targeted context here because the # instance mapping is in the API DB. inst_mapping = \ objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) except exception.InstanceMappingNotFound: # The API created the instance mapping record so it should # definitely be here. Log an error but continue to create the # instance in the cell0 database. LOG.error('While burying instance in cell0, no instance ' 'mapping was found.', instance=instance) # Perform a final sanity check that the instance is not mapped # to some other cell already because of maybe some crazy # clustered message queue weirdness. if inst_mapping and inst_mapping.cell_mapping is not None: LOG.error('When attempting to bury instance in cell0, the ' 'instance is already mapped to cell %s. Ignoring ' 'bury in cell0 attempt.', inst_mapping.cell_mapping.identity, instance=instance) continue if inst_mapping: inst_mapping.cell_mapping = cell0 inst_mapping.save() # Update mapping for instance. self._map_instance_to_cell(context, instance, cell) @staticmethod def _map_instance_to_cell(context, instance, cell): """"""Update the instance mapping to point at the given cell. During initial scheduling once a host and cell is selected in which to build the instance this method is used to update the instance mapping to point at that cell. :param context: nova auth RequestContext :param instance: Instance object being built :param cell: CellMapping representing the cell in which the instance was created and is being built. :returns: InstanceMapping object that was updated. """""" inst_mapping = objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) # Perform a final sanity check that the instance is not mapped # to some other cell already because of maybe some crazy # clustered message queue weirdness. if inst_mapping.cell_mapping is not None: LOG.error('During scheduling instance is already mapped to ' 'another cell: %s. This should not happen and is an ' 'indication of bigger problems. If you see this you ' 'should report it to the nova team. Overwriting ' 'the mapping to point at cell %s.', inst_mapping.cell_mapping.identity, cell.identity, instance=instance) inst_mapping.cell_mapping = cell inst_mapping.save() return inst_mapping "," try: # We don't need the cell0-targeted context here because the # instance mapping is in the API DB. inst_mapping = \ objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) inst_mapping.cell_mapping = cell0 inst_mapping.save() except exception.InstanceMappingNotFound: pass # Update mapping for instance. Normally this check is guarded by # a try/except but if we're here we know that a newer nova-api # handled the build process and would have created the mapping inst_mapping = objects.InstanceMapping.get_by_instance_uuid( context, instance.uuid) inst_mapping.cell_mapping = cell inst_mapping.save()",120,17
openstack%2Fnova~stable%2Fqueens~I83817f7301680801beaee375825f02eda526eda1,openstack/nova,stable/queens,I83817f7301680801beaee375825f02eda526eda1,Validate id as integer for os-aggregates,ABANDONED,2020-11-27 12:29:00.000000000,2022-11-11 18:24:05.000000000,,"[{'_account_id': 22348}, {'_account_id': 26250}]","[{'number': 1, 'created': '2020-11-27 12:29:00.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/openstack/compute/aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3d691d948e8d2c61a76602ad18f61475c0437a09', 'message': ""Validate id as integer for os-aggregates\n\nAccording to the api-ref, the id passed to calls in os-aggregates is\nsupposed to be an integer. No function validated this, so any value\npassed to these functions would directly reach the DB. While this is\nfine for SQLite, making a query with a string for an integer column on\nother databases like PostgreSQL results in a DBError exception and thus\na HTTP 500 instead of 400 or 404.\n\nThis commit adds validation for the id parameter the same way it's\nalready done for other endpoints.\n\nChange-Id: I83817f7301680801beaee375825f02eda526eda1\nCloses-Bug: 1865040\n(cherry picked from commit 2e70a1717f25652912886cbefa3f40e6df908c00)\n(cherry picked from commit 4653245ddcf989ebac4b964a41d881d78cf9ae2c)\n(cherry picked from commit 9448291d8f3ff6bef85d3bca4aa21c1e6036b3f1)\n(cherry picked from commit ad8aca7965dd7cc95e151056a74b63deecbe90a1)\n""}]",0,764310,3d691d948e8d2c61a76602ad18f61475c0437a09,7,2,1,15334,,,0,"Validate id as integer for os-aggregates

According to the api-ref, the id passed to calls in os-aggregates is
supposed to be an integer. No function validated this, so any value
passed to these functions would directly reach the DB. While this is
fine for SQLite, making a query with a string for an integer column on
other databases like PostgreSQL results in a DBError exception and thus
a HTTP 500 instead of 400 or 404.

This commit adds validation for the id parameter the same way it's
already done for other endpoints.

Change-Id: I83817f7301680801beaee375825f02eda526eda1
Closes-Bug: 1865040
(cherry picked from commit 2e70a1717f25652912886cbefa3f40e6df908c00)
(cherry picked from commit 4653245ddcf989ebac4b964a41d881d78cf9ae2c)
(cherry picked from commit 9448291d8f3ff6bef85d3bca4aa21c1e6036b3f1)
(cherry picked from commit ad8aca7965dd7cc95e151056a74b63deecbe90a1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/764310/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/openstack/compute/aggregates.py']",2,3d691d948e8d2c61a76602ad18f61475c0437a09,bug/1865040,"from nova import utils @wsgi.expected_errors((400, 404)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) @wsgi.expected_errors((400, 404, 409)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) @wsgi.expected_errors((400, 404, 409)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) "," @wsgi.expected_errors(404) @wsgi.expected_errors((404, 409)) @wsgi.expected_errors((404, 409))",85,21
openstack%2Fnova~stable%2Fqueens~Ic5ce2580e7638a47f1ffddb4edbb503bf490504c,openstack/nova,stable/queens,Ic5ce2580e7638a47f1ffddb4edbb503bf490504c,compute: Lock by instance.uuid lock during swap_volume,ABANDONED,2020-10-19 09:07:21.000000000,2022-11-11 18:23:52.000000000,,"[{'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2020-10-19 09:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d4c5ac7cf1f001aae991fea1ef880ac2b89de88', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit a53e8471728ba934b55fd6438405f897f07293ca)\n(cherry picked from commit c6f2b873bea90df4a2c1fa3b45c6ac1bc2fac618)\n(cherry picked from commit f6a54d1a0631b478148da8b52e4b4c804ecf70f4)\n(cherry picked from commit 65a275673bcf03a97202cc04a9bc8bb0ed60d1e3)\n(cherry picked from commit 17b8541982ac2930d0544f9d0f306aa093df2d16)\n'}, {'number': 2, 'created': '2021-03-08 09:51:49.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a89f46cb3b2c8965696bc59875b75dcdb6728897', 'message': 'compute: Lock by instance.uuid lock during swap_volume\n\nThe libvirt driver is currently the only virt driver implementing swap\nvolume within Nova. While libvirt itself does support moving between\nmultiple volumes attached to the same instance at the same time the\ncurrent logic within the libvirt driver makes a call to\nvirDomainGetXMLDesc that fails if there are active block jobs against\nany disk attached to the domain.\n\nThis change simply uses an instance.uuid based lock in the compute layer\nto serialise requests to swap_volume to avoid this from being possible.\n\nCloses-Bug: #1896621\nChange-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c\n(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)\n(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)\n(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)\n(cherry picked from commit 6540161933ec007d3de01dfc420595664781aa37)\n(cherry picked from commit 9be0c52439f50ed0fbb9657577c227ce9bb7fc6d)\n(cherry picked from commit 8504c900edd0808770d9c4014a58a2b3b29ef6c3)\n'}]",0,758736,a89f46cb3b2c8965696bc59875b75dcdb6728897,8,3,2,10135,,,0,"compute: Lock by instance.uuid lock during swap_volume

The libvirt driver is currently the only virt driver implementing swap
volume within Nova. While libvirt itself does support moving between
multiple volumes attached to the same instance at the same time the
current logic within the libvirt driver makes a call to
virDomainGetXMLDesc that fails if there are active block jobs against
any disk attached to the domain.

This change simply uses an instance.uuid based lock in the compute layer
to serialise requests to swap_volume to avoid this from being possible.

Closes-Bug: #1896621
Change-Id: Ic5ce2580e7638a47f1ffddb4edbb503bf490504c
(cherry picked from commit 6cf449bdd0d4beb95cf12311e7d2f8669e625fac)
(cherry picked from commit eebf94b6540fcd16826067fac544b5a3238842a3)
(cherry picked from commit f7ba1aab5f6f76ba88d6cc63cde2ec246ee61ec5)
(cherry picked from commit 6540161933ec007d3de01dfc420595664781aa37)
(cherry picked from commit 9be0c52439f50ed0fbb9657577c227ce9bb7fc6d)
(cherry picked from commit 8504c900edd0808770d9c4014a58a2b3b29ef6c3)
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/758736/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,0d4c5ac7cf1f001aae991fea1ef880ac2b89de88,bug/1896621," """"""Replace the old volume with the new volume within the active server :param context: User request context :param old_volume_id: Original volume id :param new_volume_id: New volume id being swapped to :param instance: Instance with original_volume_id attached :param new_attachment_id: ID of the new attachment for new_volume_id """""" @utils.synchronized(instance.uuid) def _do_locked_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id): self._do_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id) _do_locked_swap_volume(context, old_volume_id, new_volume_id, instance, new_attachment_id) def _do_swap_volume(self, context, old_volume_id, new_volume_id, instance, new_attachment_id): """"""Replace the old volume with the new volume within the active server :param context: User request context :param old_volume_id: Original volume id :param new_volume_id: New volume id being swapped to :param instance: Instance with original_volume_id attached :param new_attachment_id: ID of the new attachment for new_volume_id """""" context = context.elevated()"," """"""Swap volume for an instance."""""" context = context.elevated() ",26,2
openstack%2Fnova~stable%2Fqueens~I17357d85f845d4160cb7c7784772530a1e92af76,openstack/nova,stable/queens,I17357d85f845d4160cb7c7784772530a1e92af76,Make _rebase_with_qemu_img() generic,ABANDONED,2021-03-16 11:16:56.000000000,2022-11-11 18:23:47.000000000,,"[{'_account_id': 22348}, {'_account_id': 28332}]","[{'number': 1, 'created': '2021-03-16 11:16:56.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d209a501e66a6a21eeb5a0883bb94fd1c4de2947', 'message': ""Make _rebase_with_qemu_img() generic\n\nMove volume_delete related logic away from this method, in order to make\nit generic and usable elsewhere.\n\nNOTE(lyarwood): Conflict as I9bd80adc244c64277d2d00e7d79c3002c8f9d57e\nisn't present on stable/queens.\n\nConflicts:\n  nova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I17357d85f845d4160cb7c7784772530a1e92af76\nRelated-Bug: #1732428\n(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)\n(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)\n(cherry picked from commit ffcb1705cbb6ddaa3fa4d8881f416f25b763b5e7)\n(cherry picked from commit 43cea4a744930daf3459a3bad294fe60ae135e37)\n(cherry picked from commit 8a065c15a228d41e5c99a449cf53192e92a96c2d)\n""}]",0,780789,d209a501e66a6a21eeb5a0883bb94fd1c4de2947,4,2,1,10135,,,0,"Make _rebase_with_qemu_img() generic

Move volume_delete related logic away from this method, in order to make
it generic and usable elsewhere.

NOTE(lyarwood): Conflict as I9bd80adc244c64277d2d00e7d79c3002c8f9d57e
isn't present on stable/queens.

Conflicts:
  nova/tests/unit/virt/libvirt/test_driver.py

Change-Id: I17357d85f845d4160cb7c7784772530a1e92af76
Related-Bug: #1732428
(cherry picked from commit ce2203456660083119cdbb7e73c1ad15e6e0a074)
(cherry picked from commit 2e89699c3301bf801784c637b6919752fcd3503f)
(cherry picked from commit ffcb1705cbb6ddaa3fa4d8881f416f25b763b5e7)
(cherry picked from commit 43cea4a744930daf3459a3bad294fe60ae135e37)
(cherry picked from commit 8a065c15a228d41e5c99a449cf53192e92a96c2d)
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/780789/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,d209a501e66a6a21eeb5a0883bb94fd1c4de2947,bug/1885528," @mock.patch('nova.virt.images.qemu_img_info', return_value=mock.Mock(file_format=""fake_fmt"")) @mock.patch('oslo_concurrency.processutils.execute') def test_rebase_with_qemu_img(self, mock_execute, mock_qemu_img_info): """"""rebasing disk image to another backing file"""""" self.drvr._rebase_with_qemu_img(""disk"", ""backing_file"") mock_qemu_img_info.assert_called_once_with(""backing_file"") mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', 'backing_file', '-F', 'fake_fmt', 'disk') # Flatten disk image when no backing file is given. mock_qemu_img_info.reset_mock() mock_execute.reset_mock() self.drvr._rebase_with_qemu_img(""disk"", None) self.assertEqual(0, mock_qemu_img_info.call_count) mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', '', 'disk') ",,36,23
openstack%2Fnova~stable%2Fqueens~I58dca95251b607eaff602783fee2fc38e2421944,openstack/nova,stable/queens,I58dca95251b607eaff602783fee2fc38e2421944,Use absolute path during qemu img rebase,ABANDONED,2021-03-16 11:16:56.000000000,2022-11-11 18:23:43.000000000,,"[{'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-03-16 11:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4eb390b172382ce6490fdfdc01d827059c7f7d6', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nNOTE(lyarwood): Conflict caused by I897999e8a4601694213f068367eae9608cdc7bbb\nnot being present in stable/rocky.\n\nConflicts:\n  nova/tests/unit/virt/libvirt/test_driver.py\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)\n(cherry picked from commit 80c64b455cbb646b920755eb35fa2c5fa5df81b2)\n(cherry picked from commit 8fc3b17b124703e32d25270e3ff90974591d658f)\n'}, {'number': 2, 'created': '2021-03-23 09:21:15.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f531193a33d3ac20e2bb3f1a2328d1f55ded3e33', 'message': 'Use absolute path during qemu img rebase\n\nDuring an assisted volume snapshot delete request from Cinder nova\nremoves the snapshot from the backing file chain. During that nova\nchecks the existence of such file. However in some cases (see the bug\nreport) the path is relative and therefore os.path.exists fails.\n\nThis patch makes sure that nova uses the volume absolute path to make\nthe backing file path absolute as well.\n\nCloses-Bug #1885528\n\nChange-Id: I58dca95251b607eaff602783fee2fc38e2421944\n(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)\n(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)\n(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)\n(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)\n(cherry picked from commit 80c64b455cbb646b920755eb35fa2c5fa5df81b2)\n(cherry picked from commit 8fc3b17b124703e32d25270e3ff90974591d658f)\n'}]",0,780790,f531193a33d3ac20e2bb3f1a2328d1f55ded3e33,7,2,2,10135,,,0,"Use absolute path during qemu img rebase

During an assisted volume snapshot delete request from Cinder nova
removes the snapshot from the backing file chain. During that nova
checks the existence of such file. However in some cases (see the bug
report) the path is relative and therefore os.path.exists fails.

This patch makes sure that nova uses the volume absolute path to make
the backing file path absolute as well.

Closes-Bug #1885528

Change-Id: I58dca95251b607eaff602783fee2fc38e2421944
(cherry picked from commit b9333125790682f9d60bc74fdbb12a098565e7c2)
(cherry picked from commit 831abc9f83a2d3f517030f881e7da724417fea93)
(cherry picked from commit c2044d4bd0919860aa2d49687ba9c6ef6f7d37e8)
(cherry picked from commit 351072eb0950ea4a4e573d5525ed4c5dc7d6fa30)
(cherry picked from commit 80c64b455cbb646b920755eb35fa2c5fa5df81b2)
(cherry picked from commit 8fc3b17b124703e32d25270e3ff90974591d658f)
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/780790/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,f4eb390b172382ce6490fdfdc01d827059c7f7d6,bug/1885528," dom_xml = """""" <domain type='kvm'> <devices> <disk type='file'> <source file='/var/lib/nova/instances/%s/disk1_file'/> <target dev='vda' bus='virtio'/> <serial>0e38683e-f0af-418f-a3f1-6b67ea0f919d</serial> </disk> <disk type='block'> <source dev='/path/to/dev/1'/> <target dev='vdb' bus='virtio' serial='1234'/> </disk> </devices> </domain>"""""" % self.inst['uuid'] dom_xml) mock_qemu_img_info.assert_called_once_with( ""/var/lib/nova/instances/%s/snap.img"" % instance.uuid) mock_execute.assert_called_once_with( 'qemu-img', 'rebase', '-b', '/var/lib/nova/instances/%s/snap.img' % instance.uuid, '-F', 'fake_fmt', '/var/lib/nova/instances/%s/disk1_file' % instance.uuid)"," self.dom_xml) mock_qemu_img_info.assert_called_once_with(""snap.img"") mock_execute.assert_called_once_with('qemu-img', 'rebase', '-b', 'snap.img', '-F', 'fake_fmt', 'disk1_file')",33,6
openstack%2Fnova~stable%2Fqueens~Ic9133f6bc14d4fe766d37a438bf52c33e89da768,openstack/nova,stable/queens,Ic9133f6bc14d4fe766d37a438bf52c33e89da768,Improve error log when snapshot fails,ABANDONED,2021-03-25 12:02:13.000000000,2022-11-11 18:23:38.000000000,,"[{'_account_id': 21718}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-03-25 12:02:13.000000000', 'files': ['nova/exception.py', 'nova/image/glance.py', 'nova/tests/unit/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d186a0a08cca65e06f0dfff07bc6592d3cc1c79f', 'message': 'Improve error log when snapshot fails\n\nIf snapshot creation via glance fails due to lack of space or over\nquota, we want to have a clearer error message.\n\nChange-Id: Ic9133f6bc14d4fe766d37a438bf52c33e89da768\nCloses-Bug: #1613770\n(cherry picked from commit 024bf10d8aec5e58111793a9652b16682eb61b7c)\n(cherry picked from commit 9e9c022bde3a3ffdf0dd87e21bf9afde0dbc1e74)\n(cherry picked from commit 446c9c56109329208193e3c9b106a0a2eb3cd9ce)\n(cherry picked from commit 57d340f1a336796c30677a723beccc713ae81dd0)\n'}]",0,782984,d186a0a08cca65e06f0dfff07bc6592d3cc1c79f,5,2,1,10135,,,0,"Improve error log when snapshot fails

If snapshot creation via glance fails due to lack of space or over
quota, we want to have a clearer error message.

Change-Id: Ic9133f6bc14d4fe766d37a438bf52c33e89da768
Closes-Bug: #1613770
(cherry picked from commit 024bf10d8aec5e58111793a9652b16682eb61b7c)
(cherry picked from commit 9e9c022bde3a3ffdf0dd87e21bf9afde0dbc1e74)
(cherry picked from commit 446c9c56109329208193e3c9b106a0a2eb3cd9ce)
(cherry picked from commit 57d340f1a336796c30677a723beccc713ae81dd0)
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/782984/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/image/glance.py', 'nova/tests/unit/image/test_glance.py']",3,d186a0a08cca65e06f0dfff07bc6592d3cc1c79f,bug/1613770," def test_client_httpoverlimit_converts_to_imagequotaexceeded(self): in_exc = glanceclient.exc.HTTPOverLimit('123') out_exc = glance._translate_image_exception('123', in_exc) self.assertIsInstance(out_exc, exception.ImageQuotaExceeded) ",,12,0
openstack%2Fnova~stable%2Fqueens~Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9,openstack/nova,stable/queens,Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9,Fix typo,ABANDONED,2020-09-22 09:07:37.000000000,2022-11-11 18:23:34.000000000,,"[{'_account_id': 7634}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 17685}, {'_account_id': 19779}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-22 09:07:37.000000000', 'files': ['nova/virt/hardware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f6eb83c3d671f6c88af0db8da5f346bf6933e87c', 'message': 'Fix typo\n\nChange-Id: Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n(cherry picked from commit 37593defd4c6e87d68725b021c9653ee78150f46)\n(cherry picked from commit 444d65221cc7a20a73fa38aa1ca41d7957b0198e)\n'}]",0,753261,f6eb83c3d671f6c88af0db8da5f346bf6933e87c,12,8,1,15334,,,0,"Fix typo

Change-Id: Ie698db56dfab5cdc03826c8ca0e8c60ad5f2cdc9
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
(cherry picked from commit 37593defd4c6e87d68725b021c9653ee78150f46)
(cherry picked from commit 444d65221cc7a20a73fa38aa1ca41d7957b0198e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/753261/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/hardware.py'],1,f6eb83c3d671f6c88af0db8da5f346bf6933e87c,bug/1810977," 'selected pagesize: %d', pagesize)"," 'selectionned pagesize: %d', pagesize)",1,1
openstack%2Fnova~stable%2Fqueens~I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53,openstack/nova,stable/queens,I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53,hardware: fix memory check usage for small/large pages,ABANDONED,2020-05-11 14:27:34.000000000,2022-11-11 18:23:30.000000000,,"[{'_account_id': 935}, {'_account_id': 6962}, {'_account_id': 7730}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-05-11 14:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35be74df371112a1ff0e8af001b6b35197d10def', 'message': ""hardware: fix memory check usage for small/large pages\n\nWhen huge pages are requested, we need to examine the host cell's\nspecific huge page amounts, not the amount of physical memory\nassociated with the host NUMA node.\n\nAlso when no pagesize is requested we should consider to compute\nmemory usage based on small pages since the amount of physical memory\navailable may also include some large pages.\n\nThe unit-tests has been updated to pass correct NUMACell mempages\ninformation since the check is not done based on the pages available\non host. Also that the test 'test_host_usage_contiguous' to reflect to\ncorrect update of pages availalbes on hist based on instance usage.\n\nCloses-bug: #1734204\nChange-Id: I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>\n(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)\n""}, {'number': 2, 'created': '2020-05-11 14:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fee2011a39b3b9372eec179aa570f16d6d427d2d', 'message': ""hardware: fix memory check usage for small/large pages\n\nWhen huge pages are requested, we need to examine the host cell's\nspecific huge page amounts, not the amount of physical memory\nassociated with the host NUMA node.\n\nAlso when no pagesize is requested we should consider to compute\nmemory usage based on small pages since the amount of physical memory\navailable may also include some large pages.\n\nThe unit-tests has been updated to pass correct NUMACell mempages\ninformation since the check is not done based on the pages available\non host. Also that the test 'test_host_usage_contiguous' to reflect to\ncorrect update of pages availalbes on hist based on instance usage.\n\nCloses-bug: #1734204\nChange-Id: I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>\n(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)\n""}, {'number': 3, 'created': '2020-05-12 07:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6713b4f00f75556165fe3ae7ff26fe1a5d425f35', 'message': ""hardware: fix memory check usage for small/large pages\n\nWhen huge pages are requested, we need to examine the host cell's\nspecific huge page amounts, not the amount of physical memory\nassociated with the host NUMA node.\n\nAlso when no pagesize is requested we should consider to compute\nmemory usage based on small pages since the amount of physical memory\navailable may also include some large pages.\n\nThe unit-tests has been updated to pass correct NUMACell mempages\ninformation since the check is not done based on the pages available\non host. Also that the test 'test_host_usage_contiguous' to reflect to\ncorrect update of pages availalbes on hist based on instance usage.\n\nCloses-bug: #1734204\nChange-Id: I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>\n(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)\n""}, {'number': 4, 'created': '2020-09-22 09:07:37.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/tests/unit/compute/test_resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4d57c91a0feb75a66c92f54a16dc2da0f476b98c', 'message': 'hardware: fix memory check usage for small/large pages\n\nWhen huge pages are requested, we need to examine the host cell\'s\nspecific huge page amounts, not the amount of physical memory\nassociated with the host NUMA node.\n\nAlso when no pagesize is requested we should consider to compute\nmemory usage based on small pages since the amount of physical memory\navailable may also include some large pages.\n\nThe unit-tests has been updated to pass correct NUMACell mempages\ninformation since the check is not done based on the pages available\non host. Also that the test \'test_host_usage_contiguous\' to reflect to\ncorrect update of pages availalbes on hist based on instance usage.\n\nConflicts:\n  nova/tests/unit/compute/test_resource_tracker.py\n  nova/tests/unit/virt/test_hardware.py\n\nNOTE(stephenfin): Conflicts are due to the absence of changes\nI8982ab25338969cd98621f79b7fbec8af43d12c5 (""Don\'t filter out sibling\nsets with one core"") and If6eb402428f29416ce01dfc32474248c560ae019\n(""hardware: Start accounting for networks in NUMA fitting""), plus some\nother closely related patches, all of which are too invasive to\nbackport.\n\nCloses-bug: #1734204\nChange-Id: I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>\n(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)\n(cherry picked from commit 5e69018038176a60abbb3c879ae7ac7f12b8341a)\n'}]",0,726867,4d57c91a0feb75a66c92f54a16dc2da0f476b98c,35,11,4,935,,,0,"hardware: fix memory check usage for small/large pages

When huge pages are requested, we need to examine the host cell's
specific huge page amounts, not the amount of physical memory
associated with the host NUMA node.

Also when no pagesize is requested we should consider to compute
memory usage based on small pages since the amount of physical memory
available may also include some large pages.

The unit-tests has been updated to pass correct NUMACell mempages
information since the check is not done based on the pages available
on host. Also that the test 'test_host_usage_contiguous' to reflect to
correct update of pages availalbes on hist based on instance usage.

Conflicts:
  nova/tests/unit/compute/test_resource_tracker.py
  nova/tests/unit/virt/test_hardware.py

NOTE(stephenfin): Conflicts are due to the absence of changes
I8982ab25338969cd98621f79b7fbec8af43d12c5 (""Don't filter out sibling
sets with one core"") and If6eb402428f29416ce01dfc32474248c560ae019
(""hardware: Start accounting for networks in NUMA fitting""), plus some
other closely related patches, all of which are too invasive to
backport.

Closes-bug: #1734204
Change-Id: I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53
Signed-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@redhat.com>
(cherry picked from commit 8241deee197206d5458a61884ce08e1c2c2603d9)
(cherry picked from commit 5e69018038176a60abbb3c879ae7ac7f12b8341a)
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/726867/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py', 'nova/tests/unit/compute/test_resource_tracker.py']",3,35be74df371112a1ff0e8af001b6b35197d10def,bug/1734204," '2mb*1024': objects.NUMAPagesTopology(size_kb=2048, total=1024, used=0) mempages=[_NUMA_PAGE_TOPOLOGIES['2mb*1024']], siblings=[set([1]), set([2])], pinned_cpus=set([])), mempages=[_NUMA_PAGE_TOPOLOGIES['2mb*1024']], siblings=[set([3]), set([4])], pinned_cpus=set([]))]),"," '2kb*8': objects.NUMAPagesTopology(size_kb=2, total=8, used=0) mempages=[_NUMA_PAGE_TOPOLOGIES['2kb*8']], siblings=[], pinned_cpus=set([])), mempages=[_NUMA_PAGE_TOPOLOGIES['2kb*8']], siblings=[], pinned_cpus=set([]))]),",603,74
openstack%2Fnova~stable%2Fqueens~I890b2c81cd49c1c601e9baee6a249709d0f6810e,openstack/nova,stable/queens,I890b2c81cd49c1c601e9baee6a249709d0f6810e,Fix overcommit for NUMA-based instances,ABANDONED,2020-05-11 14:34:50.000000000,2022-11-11 18:23:26.000000000,,"[{'_account_id': 935}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-05-11 14:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4f6ffec72df7b46103a1557565dfc0e84cbebd6', 'message': 'Fix overcommit for NUMA-based instances\n\nChange I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53 modified how we\nevaluated available memory for instances with a NUMA topology.\nPreviously, we used a non-pagesize aware check unless the user had\nexplicitly requested a specific pagesize. This means that for instances\nwithout pagesize requests, nova considers hugepages as available memory\nwhen deciding if a host has enough available memory for the instance.\n\nThe aforementioned change modified this so that all NUMA-based\ninstances, whether they had hugepages or not, would use the\npagesize-aware check. Unfortunately the functionality it was reusing to\ndo this was functionality previously only used for hugepages. Hugepages\ncannot be oversubscribed so we did not take oversubscription into\naccount, comparing against available memory on the host (i.e. memory not\nconsumed by other instances) rather than total memory. This is OK when\nusing hugepages but not small pages, where overcommit is OK.\n\nGiven that overcommit is already handled elsewhere in the code, we\nsimply modify the non-hugepage code path to check for available memory\nof the lowest pagesize vs. total memory.\n\nChange-Id: I890b2c81cd49c1c601e9baee6a249709d0f6810e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-Bug: #1810977\n(cherry picked from commit fd19aeafbce0fa11821b2a064bd694b078613c2f)\n'}, {'number': 2, 'created': '2020-05-12 07:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/057c8e1082cb1d68163c6945814e4d3638615599', 'message': 'Fix overcommit for NUMA-based instances\n\nChange I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53 modified how we\nevaluated available memory for instances with a NUMA topology.\nPreviously, we used a non-pagesize aware check unless the user had\nexplicitly requested a specific pagesize. This means that for instances\nwithout pagesize requests, nova considers hugepages as available memory\nwhen deciding if a host has enough available memory for the instance.\n\nThe aforementioned change modified this so that all NUMA-based\ninstances, whether they had hugepages or not, would use the\npagesize-aware check. Unfortunately the functionality it was reusing to\ndo this was functionality previously only used for hugepages. Hugepages\ncannot be oversubscribed so we did not take oversubscription into\naccount, comparing against available memory on the host (i.e. memory not\nconsumed by other instances) rather than total memory. This is OK when\nusing hugepages but not small pages, where overcommit is OK.\n\nGiven that overcommit is already handled elsewhere in the code, we\nsimply modify the non-hugepage code path to check for available memory\nof the lowest pagesize vs. total memory.\n\nChange-Id: I890b2c81cd49c1c601e9baee6a249709d0f6810e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-Bug: #1810977\n(cherry picked from commit fd19aeafbce0fa11821b2a064bd694b078613c2f)\n'}, {'number': 3, 'created': '2020-09-22 09:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/940ae21d9f8a3d60b7ff2db07af816345625b725', 'message': 'Fix overcommit for NUMA-based instances\n\nChange I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53 modified how we\nevaluated available memory for instances with a NUMA topology.\nPreviously, we used a non-pagesize aware check unless the user had\nexplicitly requested a specific pagesize. This means that for instances\nwithout pagesize requests, nova considers hugepages as available memory\nwhen deciding if a host has enough available memory for the instance.\n\nThe aforementioned change modified this so that all NUMA-based\ninstances, whether they had hugepages or not, would use the\npagesize-aware check. Unfortunately the functionality it was reusing to\ndo this was functionality previously only used for hugepages. Hugepages\ncannot be oversubscribed so we did not take oversubscription into\naccount, comparing against available memory on the host (i.e. memory not\nconsumed by other instances) rather than total memory. This is OK when\nusing hugepages but not small pages, where overcommit is OK.\n\nGiven that overcommit is already handled elsewhere in the code, we\nsimply modify the non-hugepage code path to check for available memory\nof the lowest pagesize vs. total memory.\n\nChange-Id: I890b2c81cd49c1c601e9baee6a249709d0f6810e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-Bug: #1810977\n(cherry picked from commit fd19aeafbce0fa11821b2a064bd694b078613c2f)\n(cherry picked from commit 780ccfcbdea919b196c18372d1c66bc88b4fa48c)\n'}, {'number': 4, 'created': '2020-09-22 20:06:12.000000000', 'files': ['nova/objects/numa.py', 'nova/virt/hardware.py', 'nova/tests/unit/objects/test_numa.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ff13026bf25bacc6b3b5fb842c88720354703f87', 'message': 'Fix overcommit for NUMA-based instances\n\nChange I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53 modified how we\nevaluated available memory for instances with a NUMA topology.\nPreviously, we used a non-pagesize aware check unless the user had\nexplicitly requested a specific pagesize. This means that for instances\nwithout pagesize requests, nova considers hugepages as available memory\nwhen deciding if a host has enough available memory for the instance.\n\nThe aforementioned change modified this so that all NUMA-based\ninstances, whether they had hugepages or not, would use the\npagesize-aware check. Unfortunately the functionality it was reusing to\ndo this was functionality previously only used for hugepages. Hugepages\ncannot be oversubscribed so we did not take oversubscription into\naccount, comparing against available memory on the host (i.e. memory not\nconsumed by other instances) rather than total memory. This is OK when\nusing hugepages but not small pages, where overcommit is OK.\n\nGiven that overcommit is already handled elsewhere in the code, we\nsimply modify the non-hugepage code path to check for available memory\nof the lowest pagesize vs. total memory.\n\nChange-Id: I890b2c81cd49c1c601e9baee6a249709d0f6810e\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-Bug: #1810977\n(cherry picked from commit b24ad3780bc872d1a17907909cd6bcbea7e804b3)\n(cherry picked from commit 780ccfcbdea919b196c18372d1c66bc88b4fa48c)\n'}]",0,726868,ff13026bf25bacc6b3b5fb842c88720354703f87,28,9,4,935,,,0,"Fix overcommit for NUMA-based instances

Change I5f5c621f2f0fa1bc18ee9a97d17085107a5dee53 modified how we
evaluated available memory for instances with a NUMA topology.
Previously, we used a non-pagesize aware check unless the user had
explicitly requested a specific pagesize. This means that for instances
without pagesize requests, nova considers hugepages as available memory
when deciding if a host has enough available memory for the instance.

The aforementioned change modified this so that all NUMA-based
instances, whether they had hugepages or not, would use the
pagesize-aware check. Unfortunately the functionality it was reusing to
do this was functionality previously only used for hugepages. Hugepages
cannot be oversubscribed so we did not take oversubscription into
account, comparing against available memory on the host (i.e. memory not
consumed by other instances) rather than total memory. This is OK when
using hugepages but not small pages, where overcommit is OK.

Given that overcommit is already handled elsewhere in the code, we
simply modify the non-hugepage code path to check for available memory
of the lowest pagesize vs. total memory.

Change-Id: I890b2c81cd49c1c601e9baee6a249709d0f6810e
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Closes-Bug: #1810977
(cherry picked from commit b24ad3780bc872d1a17907909cd6bcbea7e804b3)
(cherry picked from commit 780ccfcbdea919b196c18372d1c66bc88b4fa48c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/726868/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/numa.py', 'nova/virt/hardware.py', 'nova/tests/unit/objects/test_numa.py']",3,c4f6ffec72df7b46103a1557565dfc0e84cbebd6,bug/1810977," def test_can_fit_pagesize(self): # NOTE(stephenfin): '**' is Python's ""power of"" symbol self.assertTrue(cell.can_fit_pagesize(pagesize, 2 ** 20)) self.assertFalse(cell.can_fit_pagesize(pagesize, 2 ** 21)) self.assertFalse(cell.can_fit_pagesize(pagesize, 2 ** 19 + 1)) self.assertTrue(cell.can_fit_pagesize(pagesize, 2 ** 20)) self.assertTrue(cell.can_fit_pagesize(pagesize, 2 ** 20 * 2)) self.assertFalse(cell.can_fit_pagesize(pagesize, 2 ** 20 * 3)) cell.can_fit_pagesize, 12345, 2 ** 20) def test_can_fit_pagesize_oversubscription(self): """"""Validate behavior when using page oversubscription. While hugepages aren't themselves oversubscribable, we also track small pages which are. """""" # NOTE(stephenfin): '**' is Python's ""power of"" symbol cell = objects.NUMACell( id=0, cpuset=set([1, 2]), memory=1024, siblings=[set([1]), set([2])], pinned_cpus=set([]), mempages=[ # 1 GiB total, all used objects.NUMAPagesTopology( size_kb=4, total=2 ** 18, used=2 ** 18), ]) pagesize = 4 # request 2^20 KiB (so 1 GiB) self.assertTrue(cell.can_fit_pagesize( pagesize, 2 ** 20, use_free=False)) # request 2^20 + 1 KiB (so # > 1 GiB) self.assertFalse(cell.can_fit_pagesize( pagesize, 2 ** 20 + 1, use_free=False))"," def test_can_fit_hugepages(self): self.assertTrue(cell.can_fit_hugepages(pagesize, 2 ** 20)) self.assertFalse(cell.can_fit_hugepages(pagesize, 2 ** 21)) self.assertFalse(cell.can_fit_hugepages(pagesize, 2 ** 19 + 1)) self.assertTrue(cell.can_fit_hugepages(pagesize, 2 ** 20)) self.assertTrue(cell.can_fit_hugepages(pagesize, 2 ** 20 * 2)) self.assertFalse(cell.can_fit_hugepages(pagesize, 2 ** 20 * 3)) cell.can_fit_hugepages, 12345, 2 ** 20)",61,20
openstack%2Fnova~stable%2Fqueens~I2a6ccaff904c1f0759d55feeeef0ec1da32c65df,openstack/nova,stable/queens,I2a6ccaff904c1f0759d55feeeef0ec1da32c65df,Remove allocations before setting vm_status to SHELVED_OFFLOADED,ABANDONED,2021-01-22 14:32:25.000000000,2022-11-11 18:23:20.000000000,,"[{'_account_id': 6873}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-01-22 14:32:25.000000000', 'files': ['nova/tests/unit/compute/test_shelve.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6101380051cd7dbd3613bfa7358710cb14f03bee', 'message': 'Remove allocations before setting vm_status to SHELVED_OFFLOADED\n\nTempest is intermittently failing a test which does the\nfollowing:\n\n1. Create a server.\n2. Shelve offload it.\n3. Unshelve it.\n\nTempest waits for the server status to be SHELVED_OFFLOADED\nbefore unshelving the server, which goes through the\nscheduler to pick a compute node and claim resources on it.\n\nWhen shelve offloading a server, the resource allocations\nfor the instance and compute node it was on are cleared, which\nwill also delete the internal consumer record in the placement\nservice.\n\nThe race is that the allocations are removed during shelve\noffload *after* the server status changes to SHELVED_OFFLOADED.\nThis leaves a window where unshelve is going through the\nscheduler and gets the existing allocations for the instance,\nwhich are non-empty and have a consumer generation. The\nclaim_resources method in the scheduler then uses that\nconsumer generation when PUTing the allocations. That PUT\nfails because in between the GET and PUT of the allocations,\nplacement has deleted the internal consumer record. When\nPUTing the new allocations with a non-null consumer generation,\nplacement returns a 409 conflict error because for a new\nconsumer it expects the ""consumer_generation"" parameter to be\nNone.\n\nThis change handles the race by simply making sure the allocations\nare deleted (along with the related consumer record in placement)\n*before* the instance.vm_status is changed.\n\nChange-Id: I2a6ccaff904c1f0759d55feeeef0ec1da32c65df\nCloses-Bug: #1798688\n(cherry picked from commit 6369f39244558b147f7b0796269d9a86ce9b12d8)\n(cherry picked from commit 1121a59edb48fe133df14bfd4384eef04ce687a7)\n'}]",0,771986,6101380051cd7dbd3613bfa7358710cb14f03bee,10,3,1,10135,,,0,"Remove allocations before setting vm_status to SHELVED_OFFLOADED

Tempest is intermittently failing a test which does the
following:

1. Create a server.
2. Shelve offload it.
3. Unshelve it.

Tempest waits for the server status to be SHELVED_OFFLOADED
before unshelving the server, which goes through the
scheduler to pick a compute node and claim resources on it.

When shelve offloading a server, the resource allocations
for the instance and compute node it was on are cleared, which
will also delete the internal consumer record in the placement
service.

The race is that the allocations are removed during shelve
offload *after* the server status changes to SHELVED_OFFLOADED.
This leaves a window where unshelve is going through the
scheduler and gets the existing allocations for the instance,
which are non-empty and have a consumer generation. The
claim_resources method in the scheduler then uses that
consumer generation when PUTing the allocations. That PUT
fails because in between the GET and PUT of the allocations,
placement has deleted the internal consumer record. When
PUTing the new allocations with a non-null consumer generation,
placement returns a 409 conflict error because for a new
consumer it expects the ""consumer_generation"" parameter to be
None.

This change handles the race by simply making sure the allocations
are deleted (along with the related consumer record in placement)
*before* the instance.vm_status is changed.

Change-Id: I2a6ccaff904c1f0759d55feeeef0ec1da32c65df
Closes-Bug: #1798688
(cherry picked from commit 6369f39244558b147f7b0796269d9a86ce9b12d8)
(cherry picked from commit 1121a59edb48fe133df14bfd4384eef04ce687a7)
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/771986/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_shelve.py', 'nova/compute/manager.py']",2,6101380051cd7dbd3613bfa7358710cb14f03bee,bug/1798688," # Free up the resource allocations in the placement service. # This should happen *before* the vm_state is changed to # SHELVED_OFFLOADED in case client-side code is polling the API to # schedule more instances (or unshelve) once this server is offloaded. rt = self._get_resource_tracker() rt.delete_allocation_for_shelve_offloaded_instance(context, instance) "," rt = self._get_resource_tracker() rt.delete_allocation_for_shelve_offloaded_instance(context, instance) ",25,13
openstack%2Fnova~stable%2Fqueens~If9acc054100a6733f3659a15dd9fc2d462e84d64,openstack/nova,stable/queens,If9acc054100a6733f3659a15dd9fc2d462e84d64,libvirt:driver:Disallow AIO=native when 'O_DIRECT' is not available,ABANDONED,2020-09-11 11:27:47.000000000,2022-11-11 18:23:16.000000000,,"[{'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 30395}]","[{'number': 1, 'created': '2020-09-11 11:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cedb4a516932649aceccb64fc5f49b39880b2cb', 'message': ""libvirt:driver:Disallow AIO=native when 'O_DIRECT' is not available\n\nBecause of the libvirt issue[1], there is a bug[2] that if we set cache mode\nwhose write semantic is not O_DIRECT (.i.e unsafe, writeback or writethrough),\nthere will be a problem with the volume drivers\n(.i.e nova.virt.libvirt.volume.LibvirtISCSIVolumeDriver,\nnova.virt.libvirt.volume.LibvirtNFSVolumeDriver and so on), which designate\nnative io explicitly.\n\nThat problem will generate a libvirt xml for the instance,\nwhose content contains\n\n```\n...\n<disk ... >\n  <driver ... cache='unsafe/writeback/writethrough' io='native' />\n</disk>\n...\n```\nIn turn, it will fail to start the instance or attach the disk.\n\n> When qemu is configured with a block device that has aio=native set, but\n> the cache mode doesn't use O_DIRECT (i.e. isn't cache=none/directsync or any\n> unnamed mode with explicit cache.direct=on), then the raw-posix block driver\n> for local files and block devices will silently fall back to aio=threads.\n> The blockdev-add interface rejects such combinations, but qemu can't\n> change the existing legacy interfaces that libvirt uses today.\n\n[1]: https://github.com/libvirt/libvirt/commit/058384003db776c580d0e5a3016a6384e8eb7b92\n[2]: https://bugzilla.redhat.com/show_bug.cgi?id=1086704\n\nCloses-Bug: #1841363\nChange-Id: If9acc054100a6733f3659a15dd9fc2d462e84d64\n(cherry picked from commit af2405e1181d70cdf60bcd0e40b3e80f2db2e3a6)\n(cherry picked from commit 0bd58921a1fcaffcc4fac25f63434c9cab93b061)\n(cherry picked from commit d92fe4f3e69db51b7bbad52a1fe1740e37bade9a)\n(cherry picked from commit cc2f45ebb03326c757abbfaef4de3e2c1fa4ead2)\n(cherry picked from commit eea24fa9e6b14927e00f6167e011e216a0677eb5)\n""}, {'number': 2, 'created': '2021-06-24 13:49:09.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1841363-fallback-to-threaded-io-when-native-io-is-not-supported-fe56014e9648a518.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/657c1a82f9bbf3cd3ce5e8365d06cd1ff93502fd', 'message': ""libvirt:driver:Disallow AIO=native when 'O_DIRECT' is not available\n\nBecause of the libvirt issue[1], there is a bug[2] that if we set cache mode\nwhose write semantic is not O_DIRECT (.i.e unsafe, writeback or writethrough),\nthere will be a problem with the volume drivers\n(.i.e nova.virt.libvirt.volume.LibvirtISCSIVolumeDriver,\nnova.virt.libvirt.volume.LibvirtNFSVolumeDriver and so on), which designate\nnative io explicitly.\n\nThat problem will generate a libvirt xml for the instance,\nwhose content contains\n\n```\n...\n<disk ... >\n  <driver ... cache='unsafe/writeback/writethrough' io='native' />\n</disk>\n...\n```\nIn turn, it will fail to start the instance or attach the disk.\n\n> When qemu is configured with a block device that has aio=native set, but\n> the cache mode doesn't use O_DIRECT (i.e. isn't cache=none/directsync or any\n> unnamed mode with explicit cache.direct=on), then the raw-posix block driver\n> for local files and block devices will silently fall back to aio=threads.\n> The blockdev-add interface rejects such combinations, but qemu can't\n> change the existing legacy interfaces that libvirt uses today.\n\n[1]: https://github.com/libvirt/libvirt/commit/058384003db776c580d0e5a3016a6384e8eb7b92\n[2]: https://bugzilla.redhat.com/show_bug.cgi?id=1086704\n\nCloses-Bug: #1841363\nChange-Id: If9acc054100a6733f3659a15dd9fc2d462e84d64\n(cherry picked from commit af2405e1181d70cdf60bcd0e40b3e80f2db2e3a6)\n(cherry picked from commit 0bd58921a1fcaffcc4fac25f63434c9cab93b061)\n(cherry picked from commit d92fe4f3e69db51b7bbad52a1fe1740e37bade9a)\n(cherry picked from commit cc2f45ebb03326c757abbfaef4de3e2c1fa4ead2)\n(cherry picked from commit 6e6440fe97c07489ab6b70029a22fa0b9b70bc02)\n""}]",0,751249,657c1a82f9bbf3cd3ce5e8365d06cd1ff93502fd,12,7,2,10135,,,0,"libvirt:driver:Disallow AIO=native when 'O_DIRECT' is not available

Because of the libvirt issue[1], there is a bug[2] that if we set cache mode
whose write semantic is not O_DIRECT (.i.e unsafe, writeback or writethrough),
there will be a problem with the volume drivers
(.i.e nova.virt.libvirt.volume.LibvirtISCSIVolumeDriver,
nova.virt.libvirt.volume.LibvirtNFSVolumeDriver and so on), which designate
native io explicitly.

That problem will generate a libvirt xml for the instance,
whose content contains

```
...
<disk ... >
  <driver ... cache='unsafe/writeback/writethrough' io='native' />
</disk>
...
```
In turn, it will fail to start the instance or attach the disk.

> When qemu is configured with a block device that has aio=native set, but
> the cache mode doesn't use O_DIRECT (i.e. isn't cache=none/directsync or any
> unnamed mode with explicit cache.direct=on), then the raw-posix block driver
> for local files and block devices will silently fall back to aio=threads.
> The blockdev-add interface rejects such combinations, but qemu can't
> change the existing legacy interfaces that libvirt uses today.

[1]: https://github.com/libvirt/libvirt/commit/058384003db776c580d0e5a3016a6384e8eb7b92
[2]: https://bugzilla.redhat.com/show_bug.cgi?id=1086704

Closes-Bug: #1841363
Change-Id: If9acc054100a6733f3659a15dd9fc2d462e84d64
(cherry picked from commit af2405e1181d70cdf60bcd0e40b3e80f2db2e3a6)
(cherry picked from commit 0bd58921a1fcaffcc4fac25f63434c9cab93b061)
(cherry picked from commit d92fe4f3e69db51b7bbad52a1fe1740e37bade9a)
(cherry picked from commit cc2f45ebb03326c757abbfaef4de3e2c1fa4ead2)
(cherry picked from commit 6e6440fe97c07489ab6b70029a22fa0b9b70bc02)
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/751249/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1841363-fallback-to-threaded-io-when-native-io-is-not-supported-fe56014e9648a518.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,8cedb4a516932649aceccb64fc5f49b39880b2cb,bug/1841363," def _make_fake_conf(self, cache=None): if cache: self.flags(disk_cachemodes=['block=' + cache], group='libvirt') else: self.flags(group='libvirt') drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) fake_conf = FakeConfigGuestDisk() fake_conf.source_type = 'block' fake_conf.driver_io = 'native' drvr._set_cache_mode(fake_conf) return fake_conf def test_set_cache_mode_driver_io_writeback(self): """"""Tests that when conf.driver_io is 'native' and driver_cache is 'writeback', then conf.driver_io is forced to 'threads' """""" fake_conf = self._make_fake_conf('writeback') self.assertEqual('writeback', fake_conf.driver_cache) self.assertEqual('threads', fake_conf.driver_io) def test_set_cache_mode_driver_io_writethrough(self): """"""Tests that when conf.driver_io is 'native' and driver_cache is 'writethrough', then conf.driver_io is forced to 'threads' """""" fake_conf = self._make_fake_conf('writethrough') self.assertEqual('writethrough', fake_conf.driver_cache) self.assertEqual('threads', fake_conf.driver_io) def test_set_cache_mode_driver_io_unsafe(self): """"""Tests that when conf.driver_io is 'native' and driver_cache is 'unsafe', then conf.driver_io is forced to 'threads' """""" fake_conf = self._make_fake_conf('unsafe') self.assertEqual('unsafe', fake_conf.driver_cache) self.assertEqual('threads', fake_conf.driver_io) def test_without_set_cache_mode_driver_io(self): """"""Tests that when conf.driver_io is 'native' and driver_cache is not set(this is default settings), then conf.driver_io is kept as 'native' """""" fake_conf = self._make_fake_conf() self.assertIsNone(fake_conf.driver_cache) self.assertEqual('native', fake_conf.driver_io) ",,75,0
openstack%2Fnova~stable%2Fqueens~Ia2007bc63ef09931ea0197cef29d6a5614ed821a,openstack/nova,stable/queens,Ia2007bc63ef09931ea0197cef29d6a5614ed821a,libvirt: Skip encryption metadata lookups if secret already exists on host,ABANDONED,2020-12-07 09:41:03.000000000,2022-11-11 18:23:12.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-07 09:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1a783069c8c0c28e5eab46f6e5e96dd40f7d494', 'message': 'libvirt: Skip encryption metadata lookups if secret already exists on host\n\nWhen connecting an encrypted volume to a host the _attach_encryptor\nmethod will be called in order to either call a legacy os-brick\nencryptor *or* configure a libvirt secret used by libvirt and QEMU to\nnatively decrypt LUKSv1 encrypted volumes. To create this libvirt secret\nthe configured key manager will be queried to provide and then decode\nthe associated secret before this is stashed within libvirt.\n\nThis change simply skips the above when an existing libvirt secret\nassociated with the target volume is found on the host already.\n\nWhile this obviously optimises basic instance lifecycle flows such as a\nsimple power off and on it additionally resolves a more convoluted use\ncase when the ``[DEFAULT]/resume_guests_state_on_host_boot``\nconfigurable is enabled. In this case the compute service has no request\ncontext with which to query the key manager when attempting to restart\ninstances with encrypted volumes attached. As a result any attempt by\nthe compute service to restart an instance with an attached encrypted\nvolume would previously fail.\n\nCloses-Bug: #1905701\nChange-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a\n(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)\n(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)\n(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)\n(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)\n(cherry picked from commit dfca56f64cd7884b6da98db43348303d220cf25e)\n(cherry picked from commit 42dbcd370202dbbcd9c339f09f3323553a5295a1)\n'}, {'number': 2, 'created': '2021-07-27 13:15:07.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug_1905701-fdc7402ffe70d104.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3c574cc368d1be1e883394aefd06158f9638281', 'message': 'libvirt: Skip encryption metadata lookups if secret already exists on host\n\nWhen connecting an encrypted volume to a host the _attach_encryptor\nmethod will be called in order to either call a legacy os-brick\nencryptor *or* configure a libvirt secret used by libvirt and QEMU to\nnatively decrypt LUKSv1 encrypted volumes. To create this libvirt secret\nthe configured key manager will be queried to provide and then decode\nthe associated secret before this is stashed within libvirt.\n\nThis change simply skips the above when an existing libvirt secret\nassociated with the target volume is found on the host already.\n\nWhile this obviously optimises basic instance lifecycle flows such as a\nsimple power off and on it additionally resolves a more convoluted use\ncase when the ``[DEFAULT]/resume_guests_state_on_host_boot``\nconfigurable is enabled. In this case the compute service has no request\ncontext with which to query the key manager when attempting to restart\ninstances with encrypted volumes attached. As a result any attempt by\nthe compute service to restart an instance with an attached encrypted\nvolume would previously fail.\n\nCloses-Bug: #1905701\nChange-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a\n(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)\n(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)\n(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)\n(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)\n(cherry picked from commit dfca56f64cd7884b6da98db43348303d220cf25e)\n(cherry picked from commit 42dbcd370202dbbcd9c339f09f3323553a5295a1)\n'}]",0,765774,d3c574cc368d1be1e883394aefd06158f9638281,9,2,2,10135,,,0,"libvirt: Skip encryption metadata lookups if secret already exists on host

When connecting an encrypted volume to a host the _attach_encryptor
method will be called in order to either call a legacy os-brick
encryptor *or* configure a libvirt secret used by libvirt and QEMU to
natively decrypt LUKSv1 encrypted volumes. To create this libvirt secret
the configured key manager will be queried to provide and then decode
the associated secret before this is stashed within libvirt.

This change simply skips the above when an existing libvirt secret
associated with the target volume is found on the host already.

While this obviously optimises basic instance lifecycle flows such as a
simple power off and on it additionally resolves a more convoluted use
case when the ``[DEFAULT]/resume_guests_state_on_host_boot``
configurable is enabled. In this case the compute service has no request
context with which to query the key manager when attempting to restart
instances with encrypted volumes attached. As a result any attempt by
the compute service to restart an instance with an attached encrypted
volume would previously fail.

Closes-Bug: #1905701
Change-Id: Ia2007bc63ef09931ea0197cef29d6a5614ed821a
(cherry picked from commit a107a5099e86c3da80a6feeca6f840d5a3ad11b9)
(cherry picked from commit af5b87874254aeb42931e3bb4faab3a2620b6894)
(cherry picked from commit a1cb246e5d2d9ade01cc26087e361169e3aa624c)
(cherry picked from commit d47679779189e43941881c6212d6db2052a19867)
(cherry picked from commit dfca56f64cd7884b6da98db43348303d220cf25e)
(cherry picked from commit 42dbcd370202dbbcd9c339f09f3323553a5295a1)
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/765774/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug_1905701-fdc7402ffe70d104.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,e1a783069c8c0c28e5eab46f6e5e96dd40f7d494,bug/1905701," # Mock out find_secret so we don't skip ahead drvr._host.find_secret.return_value = None @mock.patch.object(key_manager, 'API') def test_attach_encryptor_secret_exists(self, mock_key_manager_api): connection_info = {'data': {'volume_id': uuids.volume_id}} drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) with test.nested( mock.patch.object(drvr, '_get_volume_encryption'), mock.patch.object(drvr._host, 'find_secret') ) as (mock_get_volume_encryption, mock_find_secret): drvr._attach_encryptor(self.context, connection_info, None) # Assert we called find_secret and nothing else mock_find_secret.assert_called_once_with('volume', uuids.volume_id) mock_get_volume_encryption.assert_not_called() mock_key_manager_api.assert_not_called() ",,42,1
openstack%2Fnova~stable%2Fqueens~I332d4f33ea6b9506cc24ac12e5c0994f208a3107,openstack/nova,stable/queens,I332d4f33ea6b9506cc24ac12e5c0994f208a3107,Add functional test for bug 1937375,ABANDONED,2021-08-06 14:30:48.000000000,2022-11-11 18:23:07.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-08-06 14:30:48.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1937375.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/87e62bdbfc3dd3ae120abb4a36b8fae8280acac2', 'message': 'Add functional test for bug 1937375\n\n- InstanceHelperMixin pulled in for access to a better\n  _build_minimal_create_server_request method\n- api_major_version defined in test class\n- Fake image service stubbed out directing in test class\n- A simple _create_server method is in-lined within the class\n\nRelated-Bug: #1937375\nChange-Id: I332d4f33ea6b9506cc24ac12e5c0994f208a3107\n(cherry picked from commit 2ffd9738602531e93495a1feca76bbb687c3e72c)\n(cherry picked from commit 7a9e3dcd172f187cf93f406b09f49d2ded9bd90d)\n(cherry picked from commit 68b2d5f797896768229db1cf28feb22a984daf81)\n(cherry picked from commit 2a67e8794f916af07a05c550dca01d7fca625caf)\n(cherry picked from commit 051a14674195e5d37b931d3b59366656801bc8a1)\n(cherry picked from commit 975806f3995e7b09c477859aadd8a5771acd2771)\n(cherry picked from commit 9a123489f412e0e49db7cf5b36e82bbcf930ff15)\n'}]",0,803766,87e62bdbfc3dd3ae120abb4a36b8fae8280acac2,3,2,1,29074,,,0,"Add functional test for bug 1937375

- InstanceHelperMixin pulled in for access to a better
  _build_minimal_create_server_request method
- api_major_version defined in test class
- Fake image service stubbed out directing in test class
- A simple _create_server method is in-lined within the class

Related-Bug: #1937375
Change-Id: I332d4f33ea6b9506cc24ac12e5c0994f208a3107
(cherry picked from commit 2ffd9738602531e93495a1feca76bbb687c3e72c)
(cherry picked from commit 7a9e3dcd172f187cf93f406b09f49d2ded9bd90d)
(cherry picked from commit 68b2d5f797896768229db1cf28feb22a984daf81)
(cherry picked from commit 2a67e8794f916af07a05c550dca01d7fca625caf)
(cherry picked from commit 051a14674195e5d37b931d3b59366656801bc8a1)
(cherry picked from commit 975806f3995e7b09c477859aadd8a5771acd2771)
(cherry picked from commit 9a123489f412e0e49db7cf5b36e82bbcf930ff15)
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/803766/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1937375.py'],1,87e62bdbfc3dd3ae120abb4a36b8fae8280acac2,backport_queens_1937375,"# Copyright 2020, Red Hat, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import time import nova.tests.unit.image.fake from nova import context from nova import objects from nova.tests import fixtures as nova_fixtures from nova.tests.functional import integrated_helpers class TestDuplicateVolAttachRace( integrated_helpers.InstanceHelperMixin, integrated_helpers._IntegratedTestBase ): """"""Regression test for bug #1937375 A regression test to assert the behaviour of bug #1937375 where calls to reserve_block_device_name can race and create duplicate bdm records. As we can't recreate the race with pure API driven requests in our functional tests this instead makes duplicate calls to reserve_block_device_name during an attach to mimic the behaviour. """""" api_major_version = 'v2.1' microversion = 'latest' def setUp(self): super(TestDuplicateVolAttachRace, self).setUp() self.cinder = self.useFixture(nova_fixtures.CinderFixture(self)) self.fake_image_service =\ nova.tests.unit.image.fake.stub_out_image_service(self) self.image_uuid = list(self.fake_image_service.images)[0] def _create_server(self): server = self._build_minimal_create_server_request( self.api, 'test', image_uuid=self.image_uuid, networks='none') server = self.api.post_server({'server': server}) return self._wait_for_state_change(self.api, server, 'ACTIVE') # TODO(lyarwood): Copied from test_bug_1675570.py, move both into # _IntegratedTestBase. def _wait_for_volume_attach(self, server_id, volume_id): timeout = 0.0 server = self.api.get_server(server_id) attached_vols = [vol['id'] for vol in server['os-extended-volumes:volumes_attached']] while volume_id not in attached_vols and timeout < 10.0: time.sleep(.1) timeout += .1 server = self.api.get_server(server_id) attached_vols = [vol['id'] for vol in server['os-extended-volumes:volumes_attached']] if volume_id not in attached_vols: self.fail('Timed out waiting for volume %s to be attached to ' 'server %s. Currently attached volumes: %s' % (volume_id, server_id, attached_vols)) def test_duplicate_volume_attach_race(self): ctxt = context.get_admin_context() volume_id = self.cinder.IMAGE_BACKED_VOL server_id = self._create_server()['id'] original_reserve_name = self.compute.manager.reserve_block_device_name def wrap_reserve_block_device_name(*args, **kwargs): # We can't cause a race with duplicate API requests as functional # tests are single threaded and the first would always complete # before the second was serviced. Instead we can wrap # reserve_block_device_name on the compute manager and call it # twice to mimic two callers racing each other after the checks on # the api. original_bdm = original_reserve_name(*args, **kwargs) original_reserve_name(*args, **kwargs) return original_bdm with mock.patch.object( self.compute.manager, 'reserve_block_device_name', wrap_reserve_block_device_name ): self.api.post_server_volume( server_id, {'volumeAttachment': {'volumeId': volume_id}}) # Wait for a volume to be attached self._wait_for_volume_attach(server_id, volume_id) # Fetch all bdms for the instance to assert what we have bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( ctxt, server_id) # FIXME(lyarwood): This is bug #1937375, we now have 3 bdms for the # instance, the original root disk and two duplicate volume bdms for # the same volume attachment. self.assertEqual(3, len(bdms)) self.assertEqual(volume_id, bdms[2].volume_id) self.assertEqual(volume_id, bdms[1].volume_id) self.assertEqual('local', bdms[0].destination_type) ",,115,0
openstack%2Fnova~stable%2Fqueens~Id3e4452883f6a3cf44ff58b39ded82e882e28c23,openstack/nova,stable/queens,Id3e4452883f6a3cf44ff58b39ded82e882e28c23,"Move 'check-cherry-picks' test to gate, n-v check",ABANDONED,2021-08-16 11:55:04.000000000,2022-11-11 18:23:03.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-08-16 11:55:04.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/2c4703d4c79820d0596b7e09a5a291099d464dac', 'message': ""Move 'check-cherry-picks' test to gate, n-v check\n\nThis currently runs in the 'check' pipeline, as part of the pep8 job,\nwhich causes otherwise perfectly valid backports to report as failing\nCI. There's no reason a stable core shouldn't be encouraged to review\nthese patches: we simply want to prevent them *merging* before their\nparent(s). Resolve this conflict by moving the check to separate voting\njob in the 'gate' pipeline as well as a non-voting job in the 'check'\npipeline to catch more obvious issues.\n\nConflicts:\n    .zuul.yaml\n\nNOTE(elod.illes): conflict is due to multiple patches, for example\n- Iae3fcac484f060e8dbeef299d594b8ade8ab3b70 was only added to rocky\n- I8630ea11c3067ed934de2ef27a63432418e98c33 was added to rocky\n\nChange-Id: Id3e4452883f6a3cf44ff58b39ded82e882e28c23\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 98b01c9a59df4912f5a162c2c52d1f00c84d24c2)\n(cherry picked from commit fef0305abefbf165fecb883f03bce97f525a790a)\n(cherry picked from commit b7677ae08ae151858ecb0e67039e54bb3df89700)\n(cherry picked from commit 91314f7fbba312d4438fa446804f692d316512a8)\n(cherry picked from commit de94f429474713a68d5efc53677bc468f02dc112)\n(cherry picked from commit 1960b50f0d9646e12a8e8849579fab8c047885a8)\n(cherry picked from commit e9442f36d5aa0d0d2410315d3a6681d9e3a14ec5)\n""}]",0,804730,2c4703d4c79820d0596b7e09a5a291099d464dac,7,2,1,17685,,,0,"Move 'check-cherry-picks' test to gate, n-v check

This currently runs in the 'check' pipeline, as part of the pep8 job,
which causes otherwise perfectly valid backports to report as failing
CI. There's no reason a stable core shouldn't be encouraged to review
these patches: we simply want to prevent them *merging* before their
parent(s). Resolve this conflict by moving the check to separate voting
job in the 'gate' pipeline as well as a non-voting job in the 'check'
pipeline to catch more obvious issues.

Conflicts:
    .zuul.yaml

NOTE(elod.illes): conflict is due to multiple patches, for example
- Iae3fcac484f060e8dbeef299d594b8ade8ab3b70 was only added to rocky
- I8630ea11c3067ed934de2ef27a63432418e98c33 was added to rocky

Change-Id: Id3e4452883f6a3cf44ff58b39ded82e882e28c23
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
(cherry picked from commit 98b01c9a59df4912f5a162c2c52d1f00c84d24c2)
(cherry picked from commit fef0305abefbf165fecb883f03bce97f525a790a)
(cherry picked from commit b7677ae08ae151858ecb0e67039e54bb3df89700)
(cherry picked from commit 91314f7fbba312d4438fa446804f692d316512a8)
(cherry picked from commit de94f429474713a68d5efc53677bc468f02dc112)
(cherry picked from commit 1960b50f0d9646e12a8e8849579fab8c047885a8)
(cherry picked from commit e9442f36d5aa0d0d2410315d3a6681d9e3a14ec5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/804730/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,2c4703d4c79820d0596b7e09a5a291099d464dac,cherry-pick-in-gate-queue,[testenv:validate-backport] description = Determine whether a backport is ready to be merged by checking whether it has already been merged to master or more recent stable branches. deps = skipsdist = true commands = bash tools/check-cherry-picks.sh , bash tools/check-cherry-picks.sh,23,1
openstack%2Fnova~stable%2Fqueens~Ie904d1513b5cf76d6d5f6877545e8eb378dd5499,openstack/nova,stable/queens,Ie904d1513b5cf76d6d5f6877545e8eb378dd5499,Add a WA flag waiting for vif-plugged event during reboot,ABANDONED,2021-11-19 17:00:04.000000000,2022-11-11 18:22:56.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-11-19 17:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5c0b48db48af48640d965c9123dcebb1233ad65', 'message': 'Add a WA flag waiting for vif-plugged event during reboot\n\nThe libvirt driver power on and hard reboot destroys the domain first\nand unplugs the vifs then recreate the domain and replug the vifs.\nHowever nova does not wait for the network-vif-plugged event before\nunpause the domain. This can cause that the domain starts running and\nrequesting IP via DHCP before the networking backend finished plugging\nthe vifs.\n\nSo this patch adds a workaround config option to nova to wait for\nnetwork-vif-plugged events during hard reboot the same way as nova waits\nfor this event during new instance spawn.\n\nThis logic cannot be enabled unconditionally as not all neutron\nnetworking backend sending plug time events to wait for. Also the logic\nneeds to be vnic_type dependent as ml2/ovs and the in tree sriov backend\noften deployed together on the same compute. While ml2/ovs sends plug\ntime event the sriov backend does not send it reliably. So the\nconfiguration is not just a boolean flag but a list of vnic_types\ninstead. This way the waiting for the plug time event for a vif that is\nhandled by ml2/ovs is possible while the instance has other vifs handled\nby the sriov backend where no event can be expected.\n\nChange-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499\nCloses-Bug: #1946729\n(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)\n(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)\n(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)\n(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)\n(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)\n(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)\n(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)\n(cherry picked from commit 3bac249a7c38bc7c10c5bbb7cc76d7e9e6eca648)\n'}, {'number': 2, 'created': '2021-11-19 17:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15e287315598e2d41882bf765ece625494e5a444', 'message': 'Add a WA flag waiting for vif-plugged event during reboot\n\nThe libvirt driver power on and hard reboot destroys the domain first\nand unplugs the vifs then recreate the domain and replug the vifs.\nHowever nova does not wait for the network-vif-plugged event before\nunpause the domain. This can cause that the domain starts running and\nrequesting IP via DHCP before the networking backend finished plugging\nthe vifs.\n\nSo this patch adds a workaround config option to nova to wait for\nnetwork-vif-plugged events during hard reboot the same way as nova waits\nfor this event during new instance spawn.\n\nThis logic cannot be enabled unconditionally as not all neutron\nnetworking backend sending plug time events to wait for. Also the logic\nneeds to be vnic_type dependent as ml2/ovs and the in tree sriov backend\noften deployed together on the same compute. While ml2/ovs sends plug\ntime event the sriov backend does not send it reliably. So the\nconfiguration is not just a boolean flag but a list of vnic_types\ninstead. This way the waiting for the plug time event for a vif that is\nhandled by ml2/ovs is possible while the instance has other vifs handled\nby the sriov backend where no event can be expected.\n\nConflicts:\n      nova/conf/workarounds.py due to\n      If874f018ea996587e178219569c2903c2ee923cf not in stable/rocky\n\nThe stable/rocky specific changes:\n\n* The smart-nic vnic_type is removed from the allowed values as that\n  type is added in stein\n\nChange-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499\nCloses-Bug: #1946729\n(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)\n(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)\n(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)\n(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)\n(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)\n(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)\n(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)\n(cherry picked from commit 75e48ce99938c9803efb15ab639b1adee9e3ebb3)\n'}, {'number': 3, 'created': '2021-11-19 17:09:58.000000000', 'files': ['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1946729-wait-for-vif-plugged-event-during-hard-reboot-fb491f6a68370bab.yaml', '.zuul.yaml', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b214f5bed0abbf265aa9e2efe2d7ce4fda955a41', 'message': 'Add a WA flag waiting for vif-plugged event during reboot\n\nThe libvirt driver power on and hard reboot destroys the domain first\nand unplugs the vifs then recreate the domain and replug the vifs.\nHowever nova does not wait for the network-vif-plugged event before\nunpause the domain. This can cause that the domain starts running and\nrequesting IP via DHCP before the networking backend finished plugging\nthe vifs.\n\nSo this patch adds a workaround config option to nova to wait for\nnetwork-vif-plugged events during hard reboot the same way as nova waits\nfor this event during new instance spawn.\n\nThis logic cannot be enabled unconditionally as not all neutron\nnetworking backend sending plug time events to wait for. Also the logic\nneeds to be vnic_type dependent as ml2/ovs and the in tree sriov backend\noften deployed together on the same compute. While ml2/ovs sends plug\ntime event the sriov backend does not send it reliably. So the\nconfiguration is not just a boolean flag but a list of vnic_types\ninstead. This way the waiting for the plug time event for a vif that is\nhandled by ml2/ovs is possible while the instance has other vifs handled\nby the sriov backend where no event can be expected.\n\nChange-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499\nCloses-Bug: #1946729\n(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)\n(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)\n(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)\n(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)\n(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)\n(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)\n(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)\n(cherry picked from commit 75e48ce99938c9803efb15ab639b1adee9e3ebb3)\n'}]",0,818605,b214f5bed0abbf265aa9e2efe2d7ce4fda955a41,6,1,3,9708,,,0,"Add a WA flag waiting for vif-plugged event during reboot

The libvirt driver power on and hard reboot destroys the domain first
and unplugs the vifs then recreate the domain and replug the vifs.
However nova does not wait for the network-vif-plugged event before
unpause the domain. This can cause that the domain starts running and
requesting IP via DHCP before the networking backend finished plugging
the vifs.

So this patch adds a workaround config option to nova to wait for
network-vif-plugged events during hard reboot the same way as nova waits
for this event during new instance spawn.

This logic cannot be enabled unconditionally as not all neutron
networking backend sending plug time events to wait for. Also the logic
needs to be vnic_type dependent as ml2/ovs and the in tree sriov backend
often deployed together on the same compute. While ml2/ovs sends plug
time event the sriov backend does not send it reliably. So the
configuration is not just a boolean flag but a list of vnic_types
instead. This way the waiting for the plug time event for a vif that is
handled by ml2/ovs is possible while the instance has other vifs handled
by the sriov backend where no event can be expected.

Change-Id: Ie904d1513b5cf76d6d5f6877545e8eb378dd5499
Closes-Bug: #1946729
(cherry picked from commit 68c970ea9915a95f9828239006559b84e4ba2581)
(cherry picked from commit 0c41bfb8c5c60f1cc930ae432e6be460ee2e97ac)
(cherry picked from commit 89c4ff5f7b45f1a5bed8b6b9b4586fceaa391bfb)
(cherry picked from commit c531fdcc192afb5af628ac567cb0ff8aa3eab052)
(cherry picked from commit 35e071470e2c5597444a7b85211a01e7fbc7c68b)
(cherry picked from commit 870d8148ef1fc0c72554f24a20aec091e69a5656)
(cherry picked from commit 3afb13a205d2424022beb6a8e538da383abdd06f)
(cherry picked from commit 75e48ce99938c9803efb15ab639b1adee9e3ebb3)
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/818605/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'releasenotes/notes/bug-1946729-wait-for-vif-plugged-event-during-hard-reboot-fb491f6a68370bab.yaml', '.zuul.yaml', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,d5c0b48db48af48640d965c9123dcebb1233ad65,bug/1946729," block_device_info=block_device_info, vifs_already_plugged=True, external_events=[]) @mock.patch('oslo_utils.fileutils.ensure_tree', new=mock.Mock()) @mock.patch('nova.virt.libvirt.LibvirtDriver.get_info') @mock.patch('nova.virt.libvirt.LibvirtDriver._create_domain_and_network') @mock.patch('nova.virt.libvirt.LibvirtDriver._get_guest_xml') @mock.patch('nova.virt.libvirt.LibvirtDriver.destroy', new=mock.Mock()) @mock.patch( 'nova.virt.libvirt.LibvirtDriver._get_all_assigned_mediated_devices', new=mock.Mock(return_value={})) def test_hard_reboot_wait_for_plug( self, mock_get_guest_xml, mock_create_domain_and_network, mock_get_info ): self.flags( group=""workarounds"", wait_for_vif_plugged_event_during_hard_reboot=[""normal""]) self.context.auth_token = None instance = objects.Instance(**self.test_instance) network_info = _fake_network_info(self, num_networks=4) network_info[0][""vnic_type""] = ""normal"" network_info[1][""vnic_type""] = ""direct"" network_info[2][""vnic_type""] = ""normal"" network_info[3][""vnic_type""] = ""direct-physical"" block_device_info = None return_values = [hardware.InstanceInfo(state=power_state.SHUTDOWN), hardware.InstanceInfo(state=power_state.RUNNING)] mock_get_info.side_effect = return_values mock_get_guest_xml.return_value = mock.sentinel.xml drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False) drvr._hard_reboot( self.context, instance, network_info, block_device_info) mock_create_domain_and_network.assert_called_once_with( self.context, mock.sentinel.xml, instance, network_info, block_device_info=block_device_info, vifs_already_plugged=False, external_events=[ ('network-vif-plugged', uuids.vif1), ('network-vif-plugged', uuids.vif3), ] )"," block_device_info=block_device_info, vifs_already_plugged=True)",148,9
openstack%2Fnova~stable%2Fqueens~I92f35514efddcb071c7094370b79d91d34c5bc72,openstack/nova,stable/queens,I92f35514efddcb071c7094370b79d91d34c5bc72,compute: Avoid duplicate BDMs during reserve_block_device_name,ABANDONED,2021-08-06 14:30:48.000000000,2022-11-11 18:22:51.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-08-06 14:30:48.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1937375.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e70b2294acf254d198e4be05d39608bdd3477f9c', 'message': 'compute: Avoid duplicate BDMs during reserve_block_device_name\n\nWhen attaching a volume to a running instance the nova-api validates\nthat the volume is not already attached to the instance. However\nnova-compute is responsible for actually creating the BDM entry in the\ndatabase. If sending attach requests fast enough it can be possible\nthat the same ""attach_volume"" request can be sent to nova-compute for\nthe same volume/instance combination.\n\nTo work around this we add a check in nova-compute to validate that\nthe volume has not been attached in the mean time.\n\nCloses-Bug: #1937375\nChange-Id: I92f35514efddcb071c7094370b79d91d34c5bc72\n(cherry picked from commit 2209b0007fe85d7c5439e0bfdfe2120c63898fa2)\n(cherry picked from commit 2bee83b8a980b2bd9e276b75aa74253f8c0d0a70)\n(cherry picked from commit 303c7a7c35044240f1546a5f960c1a4e6482f385)\n(cherry picked from commit deefea82efd87b001acce7cf8d0fc2915062228b)\n(cherry picked from commit 6ef97792387bf010b92da1e06beefc04d22ff5ff)\n(cherry picked from commit fc33fd8b7e935d8e6a690c18a0907875ac181dcf)\n(cherry picked from commit 273c2e8358a8c36d44c9592326a2f833082a9196)\n'}]",0,803767,e70b2294acf254d198e4be05d39608bdd3477f9c,4,1,1,29074,,,0,"compute: Avoid duplicate BDMs during reserve_block_device_name

When attaching a volume to a running instance the nova-api validates
that the volume is not already attached to the instance. However
nova-compute is responsible for actually creating the BDM entry in the
database. If sending attach requests fast enough it can be possible
that the same ""attach_volume"" request can be sent to nova-compute for
the same volume/instance combination.

To work around this we add a check in nova-compute to validate that
the volume has not been attached in the mean time.

Closes-Bug: #1937375
Change-Id: I92f35514efddcb071c7094370b79d91d34c5bc72
(cherry picked from commit 2209b0007fe85d7c5439e0bfdfe2120c63898fa2)
(cherry picked from commit 2bee83b8a980b2bd9e276b75aa74253f8c0d0a70)
(cherry picked from commit 303c7a7c35044240f1546a5f960c1a4e6482f385)
(cherry picked from commit deefea82efd87b001acce7cf8d0fc2915062228b)
(cherry picked from commit 6ef97792387bf010b92da1e06beefc04d22ff5ff)
(cherry picked from commit fc33fd8b7e935d8e6a690c18a0907875ac181dcf)
(cherry picked from commit 273c2e8358a8c36d44c9592326a2f833082a9196)
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/803767/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1937375.py', 'nova/compute/manager.py']",3,e70b2294acf254d198e4be05d39608bdd3477f9c,backport_queens_1937375," # Now that we have the lock check that we haven't raced another # request and ensure there is no existing attachment if any(b for b in bdms if b.volume_id == volume_id): msg = _(""volume %s already attached"") % volume_id raise exception.InvalidVolume(reason=msg) ",,41,6
openstack%2Fnova~stable%2Fqueens~I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527,openstack/nova,stable/queens,I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527,Gracefull recovery when attaching volume fails,ABANDONED,2022-02-18 08:55:13.000000000,2022-11-11 18:22:46.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-18 08:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5fcf64d82f103c77cf84344078336912a816b338', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}, {'number': 2, 'created': '2022-02-22 08:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eedb83b515ef723e9e3f2437e858137e3c666e46', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}, {'number': 3, 'created': '2022-02-22 13:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/708e92340c1e8b23021215d352ce12bcdc2c1fb9', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}, {'number': 4, 'created': '2022-02-23 15:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/009ba7873114044278e5245af89bd2dc3496423f', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nDepends-on: Ibd32d30aacae65702d0ccbdb8a02b1667ec4e8ee\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}, {'number': 5, 'created': '2022-03-21 10:54:55.000000000', 'files': ['releasenotes/notes/bug-1960401-504eb255253d966a.yaml', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2ab79946e9cd0d8897c0d14558941626a463b613', 'message': 'Gracefull recovery when attaching volume fails\n\nWhen trying to attach a volume to an already running instance the nova-api\nrequests the nova-compute service to create a BlockDeviceMapping. If the\nnova-api does not receive a response within `rpc_response_timeout` it will\ntreat the request as failed and raise an exception.\n\nThere are multiple cases where nova-compute actually already processed the\nrequest and just the reply did not reach the nova-api in time (see bug report).\nAfter the failed request the database will contain a BlockDeviceMapping entry\nfor the volume + instance combination that will never be cleaned up again.\nThis entry also causes the nova-api to reject all future attachments of this\nvolume to this instance (as it assumes it is already attached).\n\nTo work around this we check if a BlockDeviceMapping has already been created\nwhen we see a messaging timeout. If this is the case we can safely delete it\nas the compute node has already finished processing and we will no longer pick\nit up.\nThis allows users to try the request again.\n\nA previous fix was abandoned but without a clear reason ([1]).\n\n[1]: https://review.opendev.org/c/openstack/nova/+/731804\n\nCloses-Bug: 1960401\nDepends-on: Ibd32d30aacae65702d0ccbdb8a02b1667ec4e8ee\nChange-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527\n(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)\n'}]",4,829861,2ab79946e9cd0d8897c0d14558941626a463b613,19,1,5,29074,,,0,"Gracefull recovery when attaching volume fails

When trying to attach a volume to an already running instance the nova-api
requests the nova-compute service to create a BlockDeviceMapping. If the
nova-api does not receive a response within `rpc_response_timeout` it will
treat the request as failed and raise an exception.

There are multiple cases where nova-compute actually already processed the
request and just the reply did not reach the nova-api in time (see bug report).
After the failed request the database will contain a BlockDeviceMapping entry
for the volume + instance combination that will never be cleaned up again.
This entry also causes the nova-api to reject all future attachments of this
volume to this instance (as it assumes it is already attached).

To work around this we check if a BlockDeviceMapping has already been created
when we see a messaging timeout. If this is the case we can safely delete it
as the compute node has already finished processing and we will no longer pick
it up.
This allows users to try the request again.

A previous fix was abandoned but without a clear reason ([1]).

[1]: https://review.opendev.org/c/openstack/nova/+/731804

Closes-Bug: 1960401
Depends-on: Ibd32d30aacae65702d0ccbdb8a02b1667ec4e8ee
Change-Id: I17f4d7d2cb129c4ec1479cc4e5d723da75d3a527
(cherry picked from commit 9eb116b99ce32bc69c4abf8ec3b0179ef89a8860)
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/829861/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1960401-504eb255253d966a.yaml', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",3,5fcf64d82f103c77cf84344078336912a816b338,," try: volume_bdm = self._create_volume_bdm( context, instance, device, volume, disk_bus=disk_bus, device_type=device_type, tag=tag) except oslo_exceptions.MessagingTimeout: # The compute node might have already created the attachment but # we never received the answer. In this case it is safe to delete # the attachment as nobody will ever pick it up again. with excutils.save_and_reraise_exception(): try: objects.BlockDeviceMapping.get_by_volume_and_instance( context, volume['id'], instance.uuid).destroy() LOG.debug(""Delete BDM after compute did not respond to "" f""attachment request for volume {volume['id']}"") except exception.VolumeBDMNotFound: LOG.debug(""BDM not found, ignoring removal. "" f""Error attaching volume {volume['id']}"")"," volume_bdm = self._create_volume_bdm( context, instance, device, volume, disk_bus=disk_bus, device_type=device_type, tag=tag)",63,3
openstack%2Fnova~stable%2Fqueens~I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132,openstack/nova,stable/queens,I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132,Disable NUMATopologyFilter on rebuild,ABANDONED,2020-01-17 17:48:56.000000000,2022-11-11 18:22:42.000000000,,"[{'_account_id': 5948}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-17 17:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9e1264bb70ff39ee969714f8a906d8fd4817f95', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)\n(cherry picked from commit 6001bff0ff18a9712b538114f9ea57d086b4961b)\n(cherry picked from commit 4071a1aeddfa055ba643d422538c9eb6f78ed660)\n'}, {'number': 2, 'created': '2020-01-21 21:33:48.000000000', 'files': ['nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/476a9dcefa4425ee0e1beafd7fd2d9d106b9d8fd', 'message': 'Disable NUMATopologyFilter on rebuild\n\nThis change leverages the new NUMA constraint checking added in\nin I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the\nNUMATopologyFilter to be skipped on rebuild.\n\nAs the new behavior of rebuild enfroces that no changes\nto the numa constraints are allowed on rebuild we no longer\nneed to execute the NUMATopologyFilter. Previously\nthe NUMATopologyFilter would process the rebuild request\nas if it was a request to spawn a new instnace as the\nnuma_fit_instance_to_host function is not rebuild aware.\n\nAs such prior to this change a rebuild would only succeed\nif a host had enough additional capacity for a second instance\non the same host meeting the requirement of the new image and\nexisting flavor. This behavior was incorrect on two counts as\na rebuild uses a noop claim. First the resouce usage cannot\nchange so it was incorrect to require the addtional capacity\nto rebuild an instance. Secondly it was incorrect not to assert\nthe resouce usage remained the same.\n\nI0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the\nrebuild against altering the resouce usage and this change\nallows in place rebuild.\n\nThis change found a latent bug that will be adressed in a follow\nup change and updated the functional tests to note the incorrect\nbehavior.\n\nConflicts:\n    nova/tests/functional/libvirt/test_numa_servers.py\n\nChange-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132\nCloses-Bug: #1804502\nImplements: blueprint inplace-rebuild-of-numa-instances\n(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)\n(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)\n(cherry picked from commit 6001bff0ff18a9712b538114f9ea57d086b4961b)\n(cherry picked from commit 4071a1aeddfa055ba643d422538c9eb6f78ed660)\n'}]",1,703141,476a9dcefa4425ee0e1beafd7fd2d9d106b9d8fd,13,6,2,11604,,,0,"Disable NUMATopologyFilter on rebuild

This change leverages the new NUMA constraint checking added in
in I0322d872bdff68936033a6f5a54e8296a6fb3434 to allow the
NUMATopologyFilter to be skipped on rebuild.

As the new behavior of rebuild enfroces that no changes
to the numa constraints are allowed on rebuild we no longer
need to execute the NUMATopologyFilter. Previously
the NUMATopologyFilter would process the rebuild request
as if it was a request to spawn a new instnace as the
numa_fit_instance_to_host function is not rebuild aware.

As such prior to this change a rebuild would only succeed
if a host had enough additional capacity for a second instance
on the same host meeting the requirement of the new image and
existing flavor. This behavior was incorrect on two counts as
a rebuild uses a noop claim. First the resouce usage cannot
change so it was incorrect to require the addtional capacity
to rebuild an instance. Secondly it was incorrect not to assert
the resouce usage remained the same.

I0322d872bdff68936033a6f5a54e8296a6fb3434 adressed guarding the
rebuild against altering the resouce usage and this change
allows in place rebuild.

This change found a latent bug that will be adressed in a follow
up change and updated the functional tests to note the incorrect
behavior.

Conflicts:
    nova/tests/functional/libvirt/test_numa_servers.py

Change-Id: I48bccc4b9adcac3c7a3e42769c11fdeb8f6fd132
Closes-Bug: #1804502
Implements: blueprint inplace-rebuild-of-numa-instances
(cherry picked from commit 3f9411071d4c1a04ab0b68fd635597bf6959c0ca)
(cherry picked from commit 94c0362918169a1fa06aa6cf5a483e9285d7b91f)
(cherry picked from commit 6001bff0ff18a9712b538114f9ea57d086b4961b)
(cherry picked from commit 4071a1aeddfa055ba643d422538c9eb6f78ed660)
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/703141/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/numa_topology_filter.py', 'releasenotes/notes/numa-rebuild-b75f9a1966f576ea.yaml', 'nova/tests/functional/libvirt/test_numa_servers.py']",3,b9e1264bb70ff39ee969714f8a906d8fd4817f95,,"from testtools import skip # FIXME(sean-k-mooney): The logic of this test is incorrect. # The test was written to assert that we failed to rebuild # because the NUMA constraints were violated due to the attachment # of an interface from a second host NUMA node to an instance with # a NUMA topology of 1 that is affined to a different NUMA node. # Nova should reject the interface attachment if the NUMA constraints # would be violated and it should fail at that point not when the # instance is rebuilt. This is a latent bug which will be addressed # in a separate patch. @skip(""bug 1855332"") def test_attach_interface_with_network_affinity_violation(self): # FIXME(sean-k-mooney): This should raise an exception as this # interface attachment would violate the NUMA constraints. # NOTE(sean-k-mooney): the rest of the test is incorrect but # is left to show the currently broken behavior. # This should succeed as the numa constraints do not change. self._rebuild_server(server, self.image_ref_1)"," def test_rebuild_server_with_network_affinity(self): # TODO(sean-k-mooney): this should pass but i currently expect it to # fail because the NUMA topology filter does not support in place # rebuild and we have used all the resources on the compute node. self.assertRaises( client.OpenStackApiException, self._rebuild_server, server, self.image_ref_1)",37,8
openstack%2Fnova~stable%2Fqueens~I655a5f19cae6bded3b0158cd639dc45656f9b005,openstack/nova,stable/queens,I655a5f19cae6bded3b0158cd639dc45656f9b005,WIP: [stable-only] Remove grenade jobs,ABANDONED,2022-08-23 18:23:40.000000000,2022-11-11 18:22:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-08-23 18:23:40.000000000', 'files': ['playbooks/legacy/nova-grenade-live-migration/post.yaml', '.zuul.yaml', 'playbooks/legacy/nova-grenade-live-migration/run.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/7959208f73dccce3e963f08d1e6c8f2ff4615bd4', 'message': ""WIP: [stable-only] Remove grenade jobs\n\nPike transitioned to End of Life as its gate was broken, so now queens\nis the oldest branch that is still open and can be maintained (as it is\nin Extended Maintenance). This patch removes the grenade jobs as those\nwould use stable/pike as the 'from' state, which cannot be maintained\nanymore.\n\nChange-Id: I655a5f19cae6bded3b0158cd639dc45656f9b005\n""}]",0,854252,7959208f73dccce3e963f08d1e6c8f2ff4615bd4,4,1,1,17685,,,0,"WIP: [stable-only] Remove grenade jobs

Pike transitioned to End of Life as its gate was broken, so now queens
is the oldest branch that is still open and can be maintained (as it is
in Extended Maintenance). This patch removes the grenade jobs as those
would use stable/pike as the 'from' state, which cannot be maintained
anymore.

Change-Id: I655a5f19cae6bded3b0158cd639dc45656f9b005
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/854252/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/nova-grenade-live-migration/post.yaml', '.zuul.yaml', 'playbooks/legacy/nova-grenade-live-migration/run.yaml']",3,7959208f73dccce3e963f08d1e6c8f2ff4615bd4,,,"- hosts: primary name: nova-grenade-live-migration tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ https://opendev.org \ openstack/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PROJECTS=""openstack/grenade $PROJECTS"" export PYTHONUNBUFFERED=true export DEVSTACK_GATE_CONFIGDRIVE=0 export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST_NOTESTS=1 export DEVSTACK_GATE_GRENADE=pullup # By default grenade runs only smoke tests so we need to set # RUN_SMOKE to False in order to run live migration tests using # grenade export DEVSTACK_LOCAL_CONFIG=""RUN_SMOKE=False"" # LIVE_MIGRATE_BACK_AND_FORTH will tell Tempest to run a live # migration of the same instance to one compute node and then back # to the other, which is mostly only interesting for grenade since # we have mixed level computes. export DEVSTACK_LOCAL_CONFIG+=$'\n'""LIVE_MIGRATE_BACK_AND_FORTH=True"" export BRANCH_OVERRIDE=default export DEVSTACK_GATE_TOPOLOGY=""multinode"" if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi function post_test_hook { /opt/stack/new/nova/nova/tests/live_migration/hooks/run_tests.sh } export -f post_test_hook cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,165
openstack%2Fnova~stable%2Fqueens~Ideaf8a88762ce046c2f16a42deff472658a63d82,openstack/nova,stable/queens,Ideaf8a88762ce046c2f16a42deff472658a63d82,Remove Ironic jobs for queens,ABANDONED,2022-10-10 17:26:47.000000000,2022-11-11 18:22:29.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-10 17:26:47.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/2465187bc5e81ecb8b899c080de2c1fcbbd2a400', 'message': ""Remove Ironic jobs for queens\n\nRemoving jobs per\nhttps://docs.openstack.org/project-team-guide/stable-branches.html#end-of-life\nsince Ironic queens is being EOL'd.\n\nChange-Id: Ideaf8a88762ce046c2f16a42deff472658a63d82\n""}]",0,860862,2465187bc5e81ecb8b899c080de2c1fcbbd2a400,6,1,1,10342,,,0,"Remove Ironic jobs for queens

Removing jobs per
https://docs.openstack.org/project-team-guide/stable-branches.html#end-of-life
since Ironic queens is being EOL'd.

Change-Id: Ideaf8a88762ce046c2f16a42deff472658a63d82
",git fetch https://review.opendev.org/openstack/nova refs/changes/62/860862/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2465187bc5e81ecb8b899c080de2c1fcbbd2a400,,, - ironic-tempest-dsvm-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false # This irrelevant-files list should match nova-dsvm-base. # TODO(mriedem): Define a node anchor to deduplicate this. irrelevant-files: - ^(placement-)?api-.*$ - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^.git.*$ - ^doc/.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tests-py3.txt$ - ^tools/.*$ - ^tox.ini$ - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode: irrelevant-files: - ^(placement-)?api-.*$ - ^.git.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^tests-py3.txt$ - ironic-tempest-dsvm-bfv: # NOTE: Ironic boot from volume only works starting in stable/pike. irrelevant-files: - ^(placement-)?api-.*$ - ^.git.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^tests-py3.txt$,0,35
openstack%2Fneutron-lbaas~stable%2Fstein~I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0,openstack/neutron-lbaas,stable/stein,I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0,neutron-lbaas haproxy agent prevent vif unplug when failover occurs,ABANDONED,2019-06-19 12:54:50.000000000,2022-11-11 18:15:31.000000000,,"[{'_account_id': 7016}, {'_account_id': 8313}, {'_account_id': 13252}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 30381}, {'_account_id': 32291}]","[{'number': 1, 'created': '2019-06-19 12:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/28cc1c1bb9d7a713db1ad5fc9afa3e6e573c04d1', 'message': 'neutron-lbaas haproxy agent prevent vif unplug when failover occurs\n\nWhen lbaas fails over after an agent is unresponsive, the dead\nagent on coming up should not unplug the vif port, if the lbaas\nis active on other agent and when failover is configured.\n\nThis patch fixes the problem.\n\nStory: #2003672\nChange-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0\n(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)\n'}, {'number': 2, 'created': '2020-11-05 17:47:59.000000000', 'files': ['neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/0072f5d869528ca4022cb98279ef2aa3f7ca4eb1', 'message': 'neutron-lbaas haproxy agent prevent vif unplug when failover occurs\n\nWhen lbaas fails over after an agent is unresponsive, the dead\nagent on coming up should not unplug the vif port, if the lbaas\nis active on other agent and when failover is configured.\n\nThis patch fixes the problem.\n\nStory: #2003672\nChange-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0\n(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)\n'}]",0,666280,0072f5d869528ca4022cb98279ef2aa3f7ca4eb1,17,7,2,17685,,,0,"neutron-lbaas haproxy agent prevent vif unplug when failover occurs

When lbaas fails over after an agent is unresponsive, the dead
agent on coming up should not unplug the vif port, if the lbaas
is active on other agent and when failover is configured.

This patch fixes the problem.

Story: #2003672
Change-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0
(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/80/666280/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py']",4,28cc1c1bb9d7a713db1ad5fc9afa3e6e573c04d1,bug/1779194," destroy.assert_has_calls( [mock.call(i, resync=True) for i in destroyed], any_order=True) lb_id, delete_namespace=True, resync=False) lb_id, delete_namespace=True, resync=False) self.mgr.remove_orphans(resync=False) self.driver_mock.remove_orphans.assert_called_once_with( ['1', '2'], resync=False) [mock.call('1', delete_namespace=True, resync=False), mock.call('2', delete_namespace=True, resync=False)],"," destroy.assert_has_calls([mock.call(i) for i in destroyed], any_order=True) lb_id, delete_namespace=True) lb_id, delete_namespace=True) self.mgr.remove_orphans() self.driver_mock.remove_orphans.assert_called_once_with(['1', '2']) [mock.call('1', delete_namespace=True), mock.call('2', delete_namespace=True)],",29,19
openstack%2Fneutron-lbaas~stable%2Frocky~I74648fc016f490c83890568fdd482ef0fdd8fa61,openstack/neutron-lbaas,stable/rocky,I74648fc016f490c83890568fdd482ef0fdd8fa61,nlbaas2octavia: do not change SG owned by user,ABANDONED,2019-02-13 11:22:30.000000000,2022-11-11 18:14:54.000000000,,"[{'_account_id': 6469}, {'_account_id': 9008}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 13438}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-13 11:22:30.000000000', 'files': ['tools/nlbaas2octavia/nlbaas2octavia.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/eb5b6e37af98a69321d437bf9d79558a993a3d59', 'message': 'nlbaas2octavia: do not change SG owned by user\n\nWhen a user associated a VIP to his own security group, the migration\nshould not change its ownership.\n\nChange-Id: I74648fc016f490c83890568fdd482ef0fdd8fa61\n(cherry picked from commit aba049283eb6efe77c613b6641189128ba1d9f45)\n'}]",0,636596,eb5b6e37af98a69321d437bf9d79558a993a3d59,4,6,1,6579,,,0,"nlbaas2octavia: do not change SG owned by user

When a user associated a VIP to his own security group, the migration
should not change its ownership.

Change-Id: I74648fc016f490c83890568fdd482ef0fdd8fa61
(cherry picked from commit aba049283eb6efe77c613b6641189128ba1d9f45)
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/96/636596/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/nlbaas2octavia/nlbaas2octavia.py'],1,eb5b6e37af98a69321d437bf9d79558a993a3d59,," security_group = n_session.execute( ""SELECT project_id FROM securitygroups WHERE id = :id"", {'id': vip_port[2]}).fetchone() # Update security group project, only when its owner is not the # user project, which means that Octavia should own it if security_group[0] != n_lb[1]: result = n_session.execute( ""UPDATE securitygroups SET project_id = :proj_id WHERE "" ""id = :id;"", {'proj_id': CONF.migration.octavia_account_id, 'id': vip_port[2]}) if result.rowcount != 1: raise Exception(_('Unable to update VIP security group in ' 'the neutron database.'))"," result = n_session.execute( ""UPDATE securitygroups SET project_id = :proj_id WHERE "" ""id = :id;"", {'proj_id': CONF.migration.octavia_account_id, 'id': vip_port[2]}) if result.rowcount != 1: raise Exception(_('Unable to update VIP security group in the ' 'neutron database.'))",14,7
openstack%2Fneutron-lbaas~stable%2Frocky~Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404,openstack/neutron-lbaas,stable/rocky,Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404,Improve performance on get and create/update/delete requests,ABANDONED,2019-06-17 14:56:09.000000000,2022-11-11 18:14:47.000000000,,"[{'_account_id': 1131}, {'_account_id': 10273}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-06-17 14:56:09.000000000', 'files': ['neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/0b8ce159f581a35037941cc22cd9e972e9f6f048', 'message': 'Improve performance on get and create/update/delete requests\n\nThis change follows up on the previous performance improvements\nand does the same for crud requests.\nI9d67f0966561baaefb50ae97b943ff6593e194eb\nI32328c5206b9cd6fb8d8764c079f22b6ea8bfa9e\n\nWe remove from_sqlalchemy_model and the related object intermediary\nrepresentation from the get_loabalancer, get_pool, get_listener,\nget_healthmonitor, get_l7policy, get_l7policy_rule,\nget_pool_member.\n\nInstead it more directly transforms from the SQLAlchemy model to the\nrequired api dictionary format. Thus this entirely skips loading a few\nrelations that walking the intermediary object model triggered without\nthe target output needing them.\n\nThis is in particular important on calls like _get_driver_for_loadbalancer\nas it previously would load the loadbalancer and all related objects\njust to get the provider name for the loadbalancer.\n\nStory: 2004949\nTask: 29365\n\nChange-Id: Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404\n(cherry picked from commit 0295eccea62eaf89ff1785e71f45e8a21a32ad7c)\n'}]",0,665696,0b8ce159f581a35037941cc22cd9e972e9f6f048,9,5,1,29244,,,0,"Improve performance on get and create/update/delete requests

This change follows up on the previous performance improvements
and does the same for crud requests.
I9d67f0966561baaefb50ae97b943ff6593e194eb
I32328c5206b9cd6fb8d8764c079f22b6ea8bfa9e

We remove from_sqlalchemy_model and the related object intermediary
representation from the get_loabalancer, get_pool, get_listener,
get_healthmonitor, get_l7policy, get_l7policy_rule,
get_pool_member.

Instead it more directly transforms from the SQLAlchemy model to the
required api dictionary format. Thus this entirely skips loading a few
relations that walking the intermediary object model triggered without
the target output needing them.

This is in particular important on calls like _get_driver_for_loadbalancer
as it previously would load the loadbalancer and all related objects
just to get the provider name for the loadbalancer.

Story: 2004949
Task: 29365

Change-Id: Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404
(cherry picked from commit 0295eccea62eaf89ff1785e71f45e8a21a32ad7c)
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/96/665696/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py']",2,0b8ce159f581a35037941cc22cd9e972e9f6f048,635076-stable/rocky," def get_loadbalancer_as_api_dict(self, context, id): lb_db = self._get_resource(context, models.LoadBalancer, id) return lb_db.to_api_dict def get_listener_as_api_dict(self, context, id): listener_db = self._get_resource(context, models.Listener, id) return listener_db.to_api_dict def get_pool_as_api_dict(self, context, id): pool_db = self._get_resource(context, models.PoolV2, id) return pool_db.to_api_dict def get_pool_member_as_api_dict(self, context, id): member_db = self._get_resource(context, models.MemberV2, id) return member_db.to_api_dict def get_healthmonitor_as_api_dict(self, context, id): hm_db = self._get_resource(context, models.HealthMonitorV2, id) return hm_db.to_api_dict def get_l7policy_as_api_dict(self, context, id): l7policy_db = self._get_resource(context, models.L7Policy, id) return l7policy_db.to_api_dict def get_l7policy_rule_as_api_dict(self, context, id, l7policy_id): rule_db = self._get_resource(context, models.L7Rule, id) if rule_db.l7policy_id != l7policy_id: raise l7.RuleNotFoundForL7Policy( l7policy_id=l7policy_id, rule_id=id) return rule_db.to_api_dict ",,55,24
openstack%2Fneutron-lbaas~stable%2Frocky~I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0,openstack/neutron-lbaas,stable/rocky,I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0,neutron-lbaas haproxy agent prevent vif unplug when failover occurs,ABANDONED,2018-09-01 08:27:16.000000000,2022-11-11 18:14:41.000000000,,"[{'_account_id': 4187}, {'_account_id': 7016}, {'_account_id': 9008}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-01 08:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/1c3a65aad49516169ff2a81ba3b3db12cdf8f144', 'message': 'neutron-lbaas haproxy agent prevent vif unplug when failover occurs\n\nWhen lbaas fails over after an agent is unresponsive, the dead\nagent on coming up should not unplug the vif port, if the lbaas\nis active on other agent and when failover is configured.\n\nThis patch fixes the problem.\n\nChange-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0\nCloses-Bug: #1779194\n'}, {'number': 2, 'created': '2019-08-06 09:17:21.000000000', 'files': ['neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c7539a75b37bc3d3e5f93306359c50f0f01bb236', 'message': 'neutron-lbaas haproxy agent prevent vif unplug when failover occurs\n\nWhen lbaas fails over after an agent is unresponsive, the dead\nagent on coming up should not unplug the vif port, if the lbaas\nis active on other agent and when failover is configured.\n\nThis patch fixes the problem.\n\nChange-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0\nCloses-Bug: #1779194\n(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)\n'}]",0,599167,c7539a75b37bc3d3e5f93306359c50f0f01bb236,11,6,2,6593,,,0,"neutron-lbaas haproxy agent prevent vif unplug when failover occurs

When lbaas fails over after an agent is unresponsive, the dead
agent on coming up should not unplug the vif port, if the lbaas
is active on other agent and when failover is configured.

This patch fixes the problem.

Change-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0
Closes-Bug: #1779194
(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/67/599167/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py']",4,1c3a65aad49516169ff2a81ba3b3db12cdf8f144,bug/1779194-stable/rocky," destroy.assert_has_calls( [mock.call(i, resync=True) for i in destroyed], any_order=True) lb_id, delete_namespace=True, resync=False) lb_id, delete_namespace=True, resync=False) self.mgr.remove_orphans(resync=False) self.driver_mock.remove_orphans.assert_called_once_with( ['1', '2'], resync=False) [mock.call('1', delete_namespace=True, resync=False), mock.call('2', delete_namespace=True, resync=False)],"," destroy.assert_has_calls([mock.call(i) for i in destroyed], any_order=True) lb_id, delete_namespace=True) lb_id, delete_namespace=True) self.mgr.remove_orphans() self.driver_mock.remove_orphans.assert_called_once_with(['1', '2']) [mock.call('1', delete_namespace=True), mock.call('2', delete_namespace=True)],",29,19
openstack%2Fneutron-lbaas~stable%2Frocky~Ie5eff9f7733a3bcec90a8e3829036aa6d425444a,openstack/neutron-lbaas,stable/rocky,Ie5eff9f7733a3bcec90a8e3829036aa6d425444a,Unplug tap from bridge on agent recovery after failover,ABANDONED,2020-08-19 12:49:04.000000000,2022-11-11 18:14:36.000000000,,"[{'_account_id': 4187}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-08-19 12:49:04.000000000', 'files': ['neutron_lbaas/drivers/haproxy/namespace_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/177113cb6a8dcaa182d460bf76712b3d487eefc7', 'message': 'Unplug tap from bridge on agent recovery after failover\n\nWhen allow_automatic_lbaas_agent_failover is eanbled, loadbalancers\ncan somethmes fail over to other agents due to missed status reports.\nThis can lead to a situation where some loadbalancers are runing on\nmore than one agent at the same time.\n\nWhen the original agent recovers, it just kills the haproxy instance,\nbut there remains more than one tap interface with the same mac/ip\naddresses repling to arp requests. This can create problems for some\nphysical networks when the neutron network type is vlan.\n\nThis patch fixes that by also unpluging the tap interface from the\nbridge. Note the unplug_vip_port RPC is not called in this case.\n\nChange-Id: Ie5eff9f7733a3bcec90a8e3829036aa6d425444a\n'}]",0,746914,177113cb6a8dcaa182d460bf76712b3d487eefc7,5,2,1,2733,,,0,"Unplug tap from bridge on agent recovery after failover

When allow_automatic_lbaas_agent_failover is eanbled, loadbalancers
can somethmes fail over to other agents due to missed status reports.
This can lead to a situation where some loadbalancers are runing on
more than one agent at the same time.

When the original agent recovers, it just kills the haproxy instance,
but there remains more than one tap interface with the same mac/ip
addresses repling to arp requests. This can create problems for some
physical networks when the neutron network type is vlan.

This patch fixes that by also unpluging the tap interface from the
bridge. Note the unplug_vip_port RPC is not called in this case.

Change-Id: Ie5eff9f7733a3bcec90a8e3829036aa6d425444a
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/14/746914/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/drivers/haproxy/namespace_driver.py'],1,177113cb6a8dcaa182d460bf76712b3d487eefc7,bug/1779194-stable/rocky," # We don't want to call the unplug_vip_port RPC in the case where the # loadbalancer might have failed over and be runing on another agent. call_unplug_vip_port_rpc = not (resync and failover_state) if loadbalancer_id in self.deployed_loadbalancers: self.deployed_loadbalancers[loadbalancer_id].vip_port, call_unplug_vip_port_rpc=call_unplug_vip_port_rpc) def _unplug(self, namespace, port, call_unplug_vip_port_rpc=True): if call_unplug_vip_port_rpc: self.plugin_rpc.unplug_vip_port(port.id)"," # Before unplugging the port check if the LBaas # is being active and see if it is a resync # or failover is configured if (loadbalancer_id in self.deployed_loadbalancers and not (resync and failover_state)): self.deployed_loadbalancers[loadbalancer_id].vip_port) def _unplug(self, namespace, port): self.plugin_rpc.unplug_vip_port(port.id)",9,8
openstack%2Fneutron-lbaas~stable%2Fqueens~Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404,openstack/neutron-lbaas,stable/queens,Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404,Improve performance on get and create/update/delete requests,ABANDONED,2019-06-17 14:59:16.000000000,2022-11-11 18:14:02.000000000,,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 29244}]","[{'number': 1, 'created': '2019-06-17 14:59:16.000000000', 'files': ['neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ccb828ffdb2f7edf0f2d4012710147ed1b06402a', 'message': 'Improve performance on get and create/update/delete requests\n\nThis change follows up on the previous performance improvements\nand does the same for crud requests.\nI9d67f0966561baaefb50ae97b943ff6593e194eb\nI32328c5206b9cd6fb8d8764c079f22b6ea8bfa9e\n\nWe remove from_sqlalchemy_model and the related object intermediary\nrepresentation from the get_loabalancer, get_pool, get_listener,\nget_healthmonitor, get_l7policy, get_l7policy_rule,\nget_pool_member.\n\nInstead it more directly transforms from the SQLAlchemy model to the\nrequired api dictionary format. Thus this entirely skips loading a few\nrelations that walking the intermediary object model triggered without\nthe target output needing them.\n\nThis is in particular important on calls like _get_driver_for_loadbalancer\nas it previously would load the loadbalancer and all related objects\njust to get the provider name for the loadbalancer.\n\nStory: 2004949\nTask: 29365\n\nChange-Id: Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404\n(cherry picked from commit 0295eccea62eaf89ff1785e71f45e8a21a32ad7c)\n'}]",0,665700,ccb828ffdb2f7edf0f2d4012710147ed1b06402a,5,3,1,29244,,,0,"Improve performance on get and create/update/delete requests

This change follows up on the previous performance improvements
and does the same for crud requests.
I9d67f0966561baaefb50ae97b943ff6593e194eb
I32328c5206b9cd6fb8d8764c079f22b6ea8bfa9e

We remove from_sqlalchemy_model and the related object intermediary
representation from the get_loabalancer, get_pool, get_listener,
get_healthmonitor, get_l7policy, get_l7policy_rule,
get_pool_member.

Instead it more directly transforms from the SQLAlchemy model to the
required api dictionary format. Thus this entirely skips loading a few
relations that walking the intermediary object model triggered without
the target output needing them.

This is in particular important on calls like _get_driver_for_loadbalancer
as it previously would load the loadbalancer and all related objects
just to get the provider name for the loadbalancer.

Story: 2004949
Task: 29365

Change-Id: Ic268ea3cdcf809f62ba1ab3ebf8ab6d22f871404
(cherry picked from commit 0295eccea62eaf89ff1785e71f45e8a21a32ad7c)
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/00/665700/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py']",2,ccb828ffdb2f7edf0f2d4012710147ed1b06402a,635076-stable/rocky-stable/queens," def get_loadbalancer_as_api_dict(self, context, id): lb_db = self._get_resource(context, models.LoadBalancer, id) return lb_db.to_api_dict def get_listener_as_api_dict(self, context, id): listener_db = self._get_resource(context, models.Listener, id) return listener_db.to_api_dict def get_pool_as_api_dict(self, context, id): pool_db = self._get_resource(context, models.PoolV2, id) return pool_db.to_api_dict def get_pool_member_as_api_dict(self, context, id): member_db = self._get_resource(context, models.MemberV2, id) return member_db.to_api_dict def get_healthmonitor_as_api_dict(self, context, id): hm_db = self._get_resource(context, models.HealthMonitorV2, id) return hm_db.to_api_dict def get_l7policy_as_api_dict(self, context, id): l7policy_db = self._get_resource(context, models.L7Policy, id) return l7policy_db.to_api_dict def get_l7policy_rule_as_api_dict(self, context, id, l7policy_id): rule_db = self._get_resource(context, models.L7Rule, id) if rule_db.l7policy_id != l7policy_id: raise l7.RuleNotFoundForL7Policy( l7policy_id=l7policy_id, rule_id=id) return rule_db.to_api_dict ",,55,24
openstack%2Fneutron-lbaas~stable%2Fqueens~I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0,openstack/neutron-lbaas,stable/queens,I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0,neutron-lbaas haproxy agent prevent vif unplug when failover occurs,ABANDONED,2018-09-01 08:27:30.000000000,2022-11-11 18:13:46.000000000,,"[{'_account_id': 4187}, {'_account_id': 7016}, {'_account_id': 9008}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-01 08:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/5f8ec638b85522418665bb7b53ce978f42bc354a', 'message': 'neutron-lbaas haproxy agent prevent vif unplug when failover occurs\n\nWhen lbaas fails over after an agent is unresponsive, the dead\nagent on coming up should not unplug the vif port, if the lbaas\nis active on other agent and when failover is configured.\n\nThis patch fixes the problem.\n\nChange-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0\nCloses-Bug: #1779194\n'}, {'number': 2, 'created': '2019-08-06 09:18:49.000000000', 'files': ['neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/afb4737729990cd7257e569ce7b98e27229de56c', 'message': 'neutron-lbaas haproxy agent prevent vif unplug when failover occurs\n\nWhen lbaas fails over after an agent is unresponsive, the dead\nagent on coming up should not unplug the vif port, if the lbaas\nis active on other agent and when failover is configured.\n\nThis patch fixes the problem.\n\nChange-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0\nCloses-Bug: #1779194\n(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)\n'}]",0,599168,afb4737729990cd7257e569ce7b98e27229de56c,9,5,2,6593,,,0,"neutron-lbaas haproxy agent prevent vif unplug when failover occurs

When lbaas fails over after an agent is unresponsive, the dead
agent on coming up should not unplug the vif port, if the lbaas
is active on other agent and when failover is configured.

This patch fixes the problem.

Change-Id: I76c38b20eb72c1dba0a0a2a140bbe77053aa3ed0
Closes-Bug: #1779194
(cherry picked from commit 72399374b222bd4a9d192081bfab2344af27fdd3)
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/68/599168/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py']",4,5f8ec638b85522418665bb7b53ce978f42bc354a,bug/1779194-stable/queens," destroy.assert_has_calls( [mock.call(i, resync=True) for i in destroyed], any_order=True) lb_id, delete_namespace=True, resync=False) lb_id, delete_namespace=True, resync=False) self.mgr.remove_orphans(resync=False) self.driver_mock.remove_orphans.assert_called_once_with( ['1', '2'], resync=False) [mock.call('1', delete_namespace=True, resync=False), mock.call('2', delete_namespace=True, resync=False)],"," destroy.assert_has_calls([mock.call(i) for i in destroyed], any_order=True) lb_id, delete_namespace=True) lb_id, delete_namespace=True) self.mgr.remove_orphans() self.driver_mock.remove_orphans.assert_called_once_with(['1', '2']) [mock.call('1', delete_namespace=True), mock.call('2', delete_namespace=True)],",29,19
openstack%2Fmagnum~stable%2Fstein~Ie3c8dff0bad6db483b54086afed0402ef24b0b4b,openstack/magnum,stable/stein,Ie3c8dff0bad6db483b54086afed0402ef24b0b4b,Don't use OpenDev infra mirror for F29 images,ABANDONED,2021-11-02 22:00:24.000000000,2022-11-11 18:11:14.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-11-02 22:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7417d4bab8ac38cece24a97bb5a5dd9af3d96ad7', 'message': ""Don't use OpenDev infra mirror for F29 images\n\nOpenDev infra is going to remove these images from the mirrors.\nDirectly reference the upstream images.\n\nCherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96\nChange-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b\n""}, {'number': 2, 'created': '2021-11-02 22:01:17.000000000', 'files': ['magnum/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/94d81e298af1a0db51d0850981b66c501f7ec638', 'message': ""Don't use OpenDev infra mirror for F29 images\n\nOpenDev infra is going to remove these images from the mirrors.\nDirectly reference the upstream images.\n\nCherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96\nChange-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b\n""}]",0,816411,94d81e298af1a0db51d0850981b66c501f7ec638,4,1,2,7118,,,0,"Don't use OpenDev infra mirror for F29 images

OpenDev infra is going to remove these images from the mirrors.
Directly reference the upstream images.

Cherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96
Change-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/11/816411/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/contrib/gate_hook.sh'],1,7417d4bab8ac38cece24a97bb5a5dd9af3d96ad7,," export DEVSTACK_LOCAL_CONFIG+=$'\n'""MAGNUM_GUEST_IMAGE_URL='https://dl.fedoraproject.org/pub/alt/atomic/stable/Fedora-29-updates-20190820.0/AtomicHost/x86_64/images/Fedora-AtomicHost-29-20190820.0.x86_64.qcow2'""","NODEPOOL_ATOMIC_MIRROR=${NODEPOOL_FEDORA_MIRROR:-https://download.fedoraproject.org/pub/alt} export DEVSTACK_LOCAL_CONFIG+=$'\n'""MAGNUM_GUEST_IMAGE_URL='${NODEPOOL_ATOMIC_MIRROR}/atomic/stable/Fedora-29-updates-20190820.0/AtomicHost/x86_64/images/Fedora-AtomicHost-29-20190820.0.x86_64.qcow2'""",1,3
openstack%2Fmagnum~stable%2Frocky~Ie3c8dff0bad6db483b54086afed0402ef24b0b4b,openstack/magnum,stable/rocky,Ie3c8dff0bad6db483b54086afed0402ef24b0b4b,Don't use OpenDev infra mirror for F29 images,ABANDONED,2021-11-02 22:01:40.000000000,2022-11-11 18:10:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-11-02 22:01:40.000000000', 'files': ['magnum/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/167701be246dc426aee6874c7a42aeae9736ce72', 'message': ""Don't use OpenDev infra mirror for F29 images\n\nOpenDev infra is going to remove these images from the mirrors.\nDirectly reference the upstream images.\n\nCherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96\nChange-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b\n""}]",0,816412,167701be246dc426aee6874c7a42aeae9736ce72,3,1,1,7118,,,0,"Don't use OpenDev infra mirror for F29 images

OpenDev infra is going to remove these images from the mirrors.
Directly reference the upstream images.

Cherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96
Change-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/12/816412/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/contrib/gate_hook.sh'],1,167701be246dc426aee6874c7a42aeae9736ce72,," export DEVSTACK_LOCAL_CONFIG+=$'\n'""MAGNUM_GUEST_IMAGE_URL='https://dl.fedoraproject.org/pub/alt/atomic/stable/Fedora-29-updates-20190820.0/AtomicHost/x86_64/images/Fedora-AtomicHost-29-20190820.0.x86_64.qcow2'""","NODEPOOL_ATOMIC_MIRROR=${NODEPOOL_FEDORA_MIRROR:-https://download.fedoraproject.org/pub/alt} export DEVSTACK_LOCAL_CONFIG+=$'\n'""MAGNUM_GUEST_IMAGE_URL='${NODEPOOL_ATOMIC_MIRROR}/atomic/stable/Fedora-29-updates-20190820.0/AtomicHost/x86_64/images/Fedora-AtomicHost-29-20190820.0.x86_64.qcow2'""",1,3
openstack%2Fmagnum~stable%2Fqueens~Ie3c8dff0bad6db483b54086afed0402ef24b0b4b,openstack/magnum,stable/queens,Ie3c8dff0bad6db483b54086afed0402ef24b0b4b,Don't use OpenDev infra mirror for F27 images,ABANDONED,2021-11-02 22:04:33.000000000,2022-11-11 18:10:31.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-11-02 22:04:33.000000000', 'files': ['magnum/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/232694834caf57b23052b71f75c5893f01cbb20b', 'message': ""Don't use OpenDev infra mirror for F27 images\n\nOpenDev infra is going to remove these images from the mirrors.\nDirectly reference the upstream images.\n\nCherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96\nChange-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b\n""}]",0,816414,232694834caf57b23052b71f75c5893f01cbb20b,3,1,1,7118,,,0,"Don't use OpenDev infra mirror for F27 images

OpenDev infra is going to remove these images from the mirrors.
Directly reference the upstream images.

Cherry-Picked-From: cea527a6435b2dff5ee5a06815da242914103f96
Change-Id: Ie3c8dff0bad6db483b54086afed0402ef24b0b4b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/14/816414/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/contrib/gate_hook.sh'],1,232694834caf57b23052b71f75c5893f01cbb20b,," export DEVSTACK_LOCAL_CONFIG+=$'\n'""MAGNUM_GUEST_IMAGE_URL='https://ftp-stud.hs-esslingen.de/pub/Mirrors/alt.fedoraproject.org//atomic/stable/Fedora-Atomic-27-20180212.2/CloudImages/x86_64/images/Fedora-Atomic-27-20180212.2.x86_64.qcow2'""","NODEPOOL_ATOMIC_MIRROR=${NODEPOOL_FEDORA_MIRROR:-https://download.fedoraproject.org/pub/alt} export DEVSTACK_LOCAL_CONFIG+=$'\n'""MAGNUM_GUEST_IMAGE_URL='${NODEPOOL_ATOMIC_MIRROR}/atomic/stable/Fedora-Atomic-27-20180212.2/CloudImages/x86_64/images/Fedora-Atomic-27-20180212.2.x86_64.qcow2'""",1,3
openstack%2Freleases~master~I06c6488b8fb8d780dd38c5e25dfd2e4545427745,openstack/releases,master,I06c6488b8fb8d780dd38c5e25dfd2e4545427745,"[nova] Proposing EOL of Queens, Rocky and Stein",MERGED,2022-10-24 18:36:02.000000000,2022-11-11 18:01:16.000000000,2022-11-11 18:01:16.000000000,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-10-24 18:36:02.000000000', 'files': ['deliverables/rocky/os-vif.yaml', 'deliverables/queens/python-novaclient.yaml', 'deliverables/rocky/nova.yaml', 'deliverables/rocky/os-traits.yaml', 'deliverables/rocky/osc-placement.yaml', 'deliverables/stein/os-resource-classes.yaml', 'deliverables/stein/osc-placement.yaml', 'deliverables/queens/os-vif.yaml', 'deliverables/rocky/python-novaclient.yaml', 'deliverables/stein/os-traits.yaml', 'deliverables/queens/os-traits.yaml', 'deliverables/stein/python-novaclient.yaml', 'deliverables/queens/nova.yaml', 'deliverables/queens/osc-placement.yaml', 'deliverables/stein/placement.yaml', 'deliverables/stein/nova.yaml', 'deliverables/stein/os-vif.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/482006797813efe80eef6faa149da510da2cdf3b', 'message': ""[nova] Proposing EOL of Queens, Rocky and Stein\n\nThis patch transition stable/queens, stable/rocky, stable/stein\nbranches of Nova team's repositories to End of Life.\nMail was sent to ML [1] with details about the reasons.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-October/030980.html\n\nChange-Id: I06c6488b8fb8d780dd38c5e25dfd2e4545427745\n""}]",6,862520,482006797813efe80eef6faa149da510da2cdf3b,13,5,1,17685,,,0,"[nova] Proposing EOL of Queens, Rocky and Stein

This patch transition stable/queens, stable/rocky, stable/stein
branches of Nova team's repositories to End of Life.
Mail was sent to ML [1] with details about the reasons.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-October/030980.html

Change-Id: I06c6488b8fb8d780dd38c5e25dfd2e4545427745
",git fetch https://review.opendev.org/openstack/releases refs/changes/20/862520/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/rocky/os-vif.yaml', 'deliverables/queens/python-novaclient.yaml', 'deliverables/rocky/nova.yaml', 'deliverables/rocky/os-traits.yaml', 'deliverables/rocky/osc-placement.yaml', 'deliverables/stein/os-resource-classes.yaml', 'deliverables/stein/osc-placement.yaml', 'deliverables/queens/os-vif.yaml', 'deliverables/rocky/python-novaclient.yaml', 'deliverables/stein/os-traits.yaml', 'deliverables/queens/os-traits.yaml', 'deliverables/stein/python-novaclient.yaml', 'deliverables/queens/nova.yaml', 'deliverables/queens/osc-placement.yaml', 'deliverables/stein/placement.yaml', 'deliverables/stein/nova.yaml', 'deliverables/stein/os-vif.yaml']",17,482006797813efe80eef6faa149da510da2cdf3b,nova-eol-qrs, - version: stein-eol projects: - repo: openstack/os-vif hash: ec9d5430300c908ea9a1c64151eee7af522a44e7,,68,0
openstack%2Fneutron~stable%2Fvictoria~I99d27d568f66c6330f6373843d096c6ee1b4ec54,openstack/neutron,stable/victoria,I99d27d568f66c6330f6373843d096c6ee1b4ec54,Handle all portbinding attrs in case of bulk port creation,MERGED,2022-11-04 15:28:39.000000000,2022-11-11 17:54:42.000000000,2022-11-11 17:53:28.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 15:28:39.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae2d009866291857aa6ef682fb818f85a4e7e780', 'message': 'Handle all portbinding attrs in case of bulk port creation\n\nBulk port creation should honor binding:vnic_type\nand binding:profile attributes from request.\n\nCloses-Bug: #1940074\nChange-Id: I99d27d568f66c6330f6373843d096c6ee1b4ec54\n(cherry picked from commit 3640ffa0c6968a2f802a9809e4f318fb229dad7d)\n(cherry picked from commit 85126425c529fbee74ae8a9a7289e3ba28665228)\n'}]",3,863664,ae2d009866291857aa6ef682fb818f85a4e7e780,18,3,1,15554,,,0,"Handle all portbinding attrs in case of bulk port creation

Bulk port creation should honor binding:vnic_type
and binding:profile attributes from request.

Closes-Bug: #1940074
Change-Id: I99d27d568f66c6330f6373843d096c6ee1b4ec54
(cherry picked from commit 3640ffa0c6968a2f802a9809e4f318fb229dad7d)
(cherry picked from commit 85126425c529fbee74ae8a9a7289e3ba28665228)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/863664/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,ae2d009866291857aa6ef682fb818f85a4e7e780,bug/1940074, port_dict[portbindings.VNIC_TYPE] = pdata.get( portbindings.VNIC_TYPE) port_dict[portbindings.PROFILE] = pdata.get( portbindings.PROFILE),,24,0
openstack%2Ftripleo-ansible~master~Iccda95cde0e309af00ce6b918ab1acab68e548dd,openstack/tripleo-ansible,master,Iccda95cde0e309af00ce6b918ab1acab68e548dd,Don't use meta:end_play after growvols check,MERGED,2022-10-30 20:44:24.000000000,2022-11-11 17:44:08.000000000,2022-11-11 17:44:08.000000000,"[{'_account_id': 6926}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-10-30 20:44:24.000000000', 'files': ['tripleo_ansible/playbooks/cli-overcloud-node-growvols.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1678c3395ba8142e42ee1629bd1d258ffbdf4da1', 'message': ""Don't use meta:end_play after growvols check\n\nAccording to the documentation, meta: end_play will apply to all\nhosts, which is fine if every host is deploying the same image.\nHowever if there is a mixture of overcloud-full and\novercloud-hardened-uefi-full the playbook won't run correctly on some\nhosts.\n\nThis change moves to a conditional block to run as expected on each\nhost.\n\n[1] https://docs.ansible.com/ansible/latest/collections/ansible/builtin/meta_module.html\n\nChange-Id: Iccda95cde0e309af00ce6b918ab1acab68e548dd\n""}]",0,862984,1678c3395ba8142e42ee1629bd1d258ffbdf4da1,8,4,1,4571,,,0,"Don't use meta:end_play after growvols check

According to the documentation, meta: end_play will apply to all
hosts, which is fine if every host is deploying the same image.
However if there is a mixture of overcloud-full and
overcloud-hardened-uefi-full the playbook won't run correctly on some
hosts.

This change moves to a conditional block to run as expected on each
host.

[1] https://docs.ansible.com/ansible/latest/collections/ansible/builtin/meta_module.html

Change-Id: Iccda95cde0e309af00ce6b918ab1acab68e548dd
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/84/862984/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cli-overcloud-node-growvols.yaml'],1,1678c3395ba8142e42ee1629bd1d258ffbdf4da1,growvols-check," - name: Run growvols block when: find_growvols.rc == 0 block: - name: Setting growvols path set_fact: growvols_path: ""{{ find_growvols.stdout_lines[0] }}"" - name: ""Running {{ growvols_path }} {{growvols_args}}"" shell: ""{{ growvols_path }} --yes {{growvols_args}}"" become: true register: run_growvols - name: Output of growvols stdout debug: var: run_growvols.stdout"," - name: Stopping playbook when no growvols utility is found meta: end_play when: find_growvols.rc != 0 - name: Setting growvols path set_fact: growvols_path: ""{{ find_growvols.stdout_lines[0] }}"" - name: ""Running {{ growvols_path }} {{growvols_args}}"" shell: ""{{ growvols_path }} --yes {{growvols_args}}"" become: true register: run_growvols - name: Output of growvols stdout debug: var: run_growvols.stdout",13,14
openstack%2Freleases~master~I25750d216c2da28539cbc5c1d19ebc77f289475c,openstack/releases,master,I25750d216c2da28539cbc5c1d19ebc77f289475c,release-test test release,MERGED,2022-11-11 15:37:49.000000000,2022-11-11 16:58:08.000000000,2022-11-11 16:58:08.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-11 15:37:49.000000000', 'files': ['deliverables/antelope/release-test.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/0ae9b85cfc6e63bf0e05419c30187e02c1be0058', 'message': 'release-test test release\n\nThis tests the announce-release job fix that removed the bindep task\nfrom its pretask [1].\n\n[1] https://review.opendev.org/c/openstack/openstack-zuul-jobs/+/864267\n\nChange-Id: I25750d216c2da28539cbc5c1d19ebc77f289475c\n'}]",2,864295,0ae9b85cfc6e63bf0e05419c30187e02c1be0058,10,4,1,17685,,,0,"release-test test release

This tests the announce-release job fix that removed the bindep task
from its pretask [1].

[1] https://review.opendev.org/c/openstack/openstack-zuul-jobs/+/864267

Change-Id: I25750d216c2da28539cbc5c1d19ebc77f289475c
",git fetch https://review.opendev.org/openstack/releases refs/changes/95/864295/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/antelope/release-test.yaml'],1,0ae9b85cfc6e63bf0e05419c30187e02c1be0058,,releases: - version: 4.0.0 projects: - repo: openstack/release-test hash: b3938e9d2fbd3a92854e662c095aecdd21d4a82b,,5,0
openstack%2Fopenstacksdk~master~I0da8ec51ab94a094dc0e7d89aedf1830a08fd150,openstack/openstacksdk,master,I0da8ec51ab94a094dc0e7d89aedf1830a08fd150,Fix server action request generation,MERGED,2022-11-10 04:20:43.000000000,2022-11-11 16:35:38.000000000,2022-11-11 16:34:22.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-10 04:20:43.000000000', 'files': ['openstack/compute/v2/server_action.py', 'openstack/tests/unit/compute/v2/test_proxy.py', 'openstack/tests/unit/compute/v2/test_server_actions.py', 'openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0bf4d86e5a6509095c9f01def41f9b8dd928d21a', 'message': 'Fix server action request generation\n\nServer action request paths were not interpolating server_id. This\nchange marks server_id for interpolation in the ServerAction base_path,\nand uses request_id as the identifier for server actions.\n\nChange-Id: I0da8ec51ab94a094dc0e7d89aedf1830a08fd150\n'}]",1,864159,0bf4d86e5a6509095c9f01def41f9b8dd928d21a,8,2,1,35355,,,0,"Fix server action request generation

Server action request paths were not interpolating server_id. This
change marks server_id for interpolation in the ServerAction base_path,
and uses request_id as the identifier for server actions.

Change-Id: I0da8ec51ab94a094dc0e7d89aedf1830a08fd150
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/59/864159/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/compute/v2/server_action.py', 'openstack/tests/unit/compute/v2/test_proxy.py', 'openstack/tests/unit/compute/v2/test_server_actions.py', 'openstack/compute/v2/_proxy.py']",4,0bf4d86e5a6509095c9f01def41f9b8dd928d21a,nova-gaps," request_id=server_action,"," action_id=server_action,",6,6
openstack%2Fpython-glanceclient~master~I7ccc628a23c9ebdaeedcb9e6d43559f497ce9555,openstack/python-glanceclient,master,I7ccc628a23c9ebdaeedcb9e6d43559f497ce9555,schema_args: Do not generate option for read-only properties,MERGED,2022-09-20 16:09:55.000000000,2022-11-11 15:56:04.000000000,2022-11-11 15:55:05.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 19138}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-20 16:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/0ac13a4cc7a34bf4213b0f7025273dd25fe50b64', 'message': 'schema_args: Do not generate option for read-only properties\n\nThe schema_args decorator generates command line options based on the\nproperties defined in a schema. This commit makes sure read-only\nproperties are skipped during this process, since trying to modify their\nvalue would result in a Glance error.\n\nCloses-Bug: #1561828\nChange-Id: I7ccc628a23c9ebdaeedcb9e6d43559f497ce9555\n'}, {'number': 2, 'created': '2022-09-26 21:54:24.000000000', 'files': ['glanceclient/v2/shell.py', 'glanceclient/tests/unit/test_utils.py', 'glanceclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/74fa43665719ddc830999fa15bb052a87d69dd14', 'message': 'schema_args: Do not generate option for read-only properties\n\nThe schema_args decorator generates command line options based on the\nproperties defined in a schema. This commit makes sure read-only\nproperties are skipped during this process, since trying to modify their\nvalue would result in a Glance error.\n\nCloses-Bug: #1561828\nChange-Id: I7ccc628a23c9ebdaeedcb9e6d43559f497ce9555\n'}]",6,858549,74fa43665719ddc830999fa15bb052a87d69dd14,13,4,2,8122,,,0,"schema_args: Do not generate option for read-only properties

The schema_args decorator generates command line options based on the
properties defined in a schema. This commit makes sure read-only
properties are skipped during this process, since trying to modify their
value would result in a Glance error.

Closes-Bug: #1561828
Change-Id: I7ccc628a23c9ebdaeedcb9e6d43559f497ce9555
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/49/858549/2 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/tests/unit/test_utils.py', 'glanceclient/common/utils.py']",2,0ac13a4cc7a34bf4213b0f7025273dd25fe50b64,bug/1561828," if property.get('readOnly', False): continue",,10,1
openstack%2Fneutron~master~I34c44b88468f4f70e94fe7a449642d2a70d7bd05,openstack/neutron,master,I34c44b88468f4f70e94fe7a449642d2a70d7bd05,DNM Test FT timeout with oslo master,ABANDONED,2022-11-02 14:19:02.000000000,2022-11-11 15:44:57.000000000,,"[{'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-02 14:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d9195e3eae2edb790bc76fc86a214410b189830', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 2, 'created': '2022-11-02 15:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48805b4c8a93f5ab2ca0326ab9e7c8b25de52444', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n* oslo.log: removed from list, using 5.0.0\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 3, 'created': '2022-11-03 07:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f0b237ebc7d293ae7961b71943e04a1825c473f', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n* oslo.log: removed from list, using 5.0.0\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 4, 'created': '2022-11-03 09:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a4dced440ddb1518c6604ba4f32295be596d2a52', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\noslo.log: removed from list, using 5.0.0\nopenstack/oslo.db\nopenstack/oslo.log\nopenstack/oslo.messaging\nopenstack/oslo.middleware\nopenstack/oslo.policy\nopenstack/oslo.config\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 5, 'created': '2022-11-03 10:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70cc06f84c902cf4ccd88cc4b3d30710af13f33b', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\noslo.log: removed from list, using 5.0.0\nopenstack/oslo.db\nopenstack/oslo.log\nopenstack/oslo.messaging\nopenstack/oslo.middleware\nopenstack/oslo.policy\nopenstack/oslo.config\n\n(commented in this PS)\nopenstack/oslo.context\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 6, 'created': '2022-11-03 11:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8676bea4465d2b099afc39c153c1fd6f2e0df692', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 7, 'created': '2022-11-03 13:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d15a58c1f1bd3f4bd2d0ab0f2e7f755d3ca20bf', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 8, 'created': '2022-11-03 14:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8c689d0e3cfc65d5a184686b86fdaee61b72aed', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 9, 'created': '2022-11-03 15:53:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a21437bf5cf61e34f69bf769251bc5cdeda00629', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 10, 'created': '2022-11-03 17:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c9bdb49d3cc3d4e25dc06d0e24fd877a7e90742', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 11, 'created': '2022-11-03 22:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e57ccfec7a99a3ba342e2f341191e8cc70fb8f01', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 12, 'created': '2022-11-04 08:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/79639d11f95a314a43dde57b3b71b6fde9ca3c66', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 13, 'created': '2022-11-04 10:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d01e070501bb265d8a15ff3c8b09761f40b55c4', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nNOTE:\n\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 14, 'created': '2022-11-04 12:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4da80bbf63fefc53bd8088eb7be7ffa3431ddbd5', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/863324\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 15, 'created': '2022-11-07 17:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3940b11827a3dfabe37b158f379d9fcfb46687e4', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/863324\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 16, 'created': '2022-11-08 12:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f25482ff4159bcf075926e888145becbe20c026f', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/863324\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}, {'number': 17, 'created': '2022-11-08 15:46:19.000000000', 'files': ['zuul.d/base.yaml', 'zuul.d/project.yaml', 'neutron/agent/l3/keepalived_state_change.py', 'neutron/plugins/ml2/ovo_rpc.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b08cea73386735bde6702ab96d06dc8b14570823', 'message': 'DNM Test FT timeout with oslo master\n\nCI job failing: neutron-functional-with-oslo-master\n\nhttps://bugs.launchpad.net/neutron/+bug/1995091\n\nDepends-On: https://review.opendev.org/c/openstack/oslo.log/+/864018\n\nRelated-Bug: #1995091\nChange-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05\n'}]",2,863315,b08cea73386735bde6702ab96d06dc8b14570823,43,2,17,16688,,,0,"DNM Test FT timeout with oslo master

CI job failing: neutron-functional-with-oslo-master

https://bugs.launchpad.net/neutron/+bug/1995091

Depends-On: https://review.opendev.org/c/openstack/oslo.log/+/864018

Related-Bug: #1995091
Change-Id: I34c44b88468f4f70e94fe7a449642d2a70d7bd05
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/863315/5 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'tox.ini']",2,3d9195e3eae2edb790bc76fc86a214410b189830,bug/1995091, stestr run --concurrency 1 --exclude-regex (.*MySQL\.|.*PostgreSQL\.) {posargs}, stestr run --exclude-regex (.*MySQL\.|.*PostgreSQL\.) {posargs} stestr run --combine --concurrency 1 (.*MySQL\.|.*PostgreSQL\.) {posargs},8,68
openstack%2Fopenstack-zuul-jobs~master~Id3eeb168dd72e379fd8bf3fba0407ce1c1314ecb,openstack/openstack-zuul-jobs,master,Id3eeb168dd72e379fd8bf3fba0407ce1c1314ecb,Remove bindep for announce-release job,MERGED,2022-11-11 13:59:38.000000000,2022-11-11 15:12:27.000000000,2022-11-11 15:11:30.000000000,"[{'_account_id': 1004}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-11 13:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/a88af33c756b9f28c4d68b84ec802b169e9e7a0e', 'message': ""Remove bindep for announce-release job\n\nThe bindep install causes problem for announce-release and it seems\nunnecessary for this job, so let's get rid of it.\n\nChange-Id: Id3eeb168dd72e379fd8bf3fba0407ce1c1314ecb\n""}, {'number': 2, 'created': '2022-11-11 14:33:09.000000000', 'files': ['playbooks/release/pre.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/c794f36e58be1af384ae3f800cfe5b00a43f2a9a', 'message': ""Remove bindep for announce-release job\n\nThe bindep install causes problem for announce-release and it seems\nunnecessary for this job, so let's get rid of it.\n\nChange-Id: Id3eeb168dd72e379fd8bf3fba0407ce1c1314ecb\n""}]",1,864267,c794f36e58be1af384ae3f800cfe5b00a43f2a9a,12,3,2,17685,,,0,"Remove bindep for announce-release job

The bindep install causes problem for announce-release and it seems
unnecessary for this job, so let's get rid of it.

Change-Id: Id3eeb168dd72e379fd8bf3fba0407ce1c1314ecb
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/67/864267/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/release/pre.yaml'],1,a88af33c756b9f28c4d68b84ec802b169e9e7a0e,,," - role: bindep bindep_profile: test bindep_dir: ""src/{{ zuul.project.canonical_name }}"" - role: bindep bindep_profile: test bindep_dir: src/opendev.org/openstack/releases",0,6
openstack%2Fnova~master~I7077aea2abcf3cab67592879ebd1fde066bfcac5,openstack/nova,master,I7077aea2abcf3cab67592879ebd1fde066bfcac5,Correct config help message related options,MERGED,2022-11-11 10:42:40.000000000,2022-11-11 14:48:13.000000000,2022-11-11 14:47:02.000000000,"[{'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-11 10:42:40.000000000', 'files': ['nova/conf/ironic.py', 'nova/conf/libvirt.py', 'nova/conf/vmware.py', 'nova/conf/mks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ac42c43e431b2bd1089910cd52aec8552a8e9755', 'message': ""Correct config help message related options\n\nThe options list in 'Related Options:' section doesn't rendered\nas bulleted list for some params because of missing blank line.\n\nThis changes adds missing blank line wherever needed in [1].\n[1] https://docs.openstack.org/nova/latest/configuration/config.html\n\nChange-Id: I7077aea2abcf3cab67592879ebd1fde066bfcac5\n""}]",1,864259,ac42c43e431b2bd1089910cd52aec8552a8e9755,15,2,1,20733,,,0,"Correct config help message related options

The options list in 'Related Options:' section doesn't rendered
as bulleted list for some params because of missing blank line.

This changes adds missing blank line wherever needed in [1].
[1] https://docs.openstack.org/nova/latest/configuration/config.html

Change-Id: I7077aea2abcf3cab67592879ebd1fde066bfcac5
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/864259/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/ironic.py', 'nova/conf/libvirt.py', 'nova/conf/vmware.py', 'nova/conf/mks.py']",4,ac42c43e431b2bd1089910cd52aec8552a8e9755,trivial-fix,,,9,0
openstack%2Fovn-bgp-agent~master~I5c9c238649c7d970d63bacd5cfd624dda6120830,openstack/ovn-bgp-agent,master,I5c9c238649c7d970d63bacd5cfd624dda6120830,Avoid rules recreation at ensure_default_ovs_flows function,MERGED,2022-11-10 15:36:59.000000000,2022-11-11 14:05:44.000000000,2022-11-11 14:05:44.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-10 15:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/8e9e937ae7b3ccb28d9dbd2dbee339fa31c28f2b', 'message': 'Avoid rules recreation at ensure_default_ovs_flows function\n\nThere is 2 flows instead on one (one for ipv4 and one for ipv6).\nThe current code expects just one flow, therefore it is constantly\nregenerating the flows while it should not. Fixing it to account\nfor the dual stack.\n\nChange-Id: I5c9c238649c7d970d63bacd5cfd624dda6120830\n'}, {'number': 2, 'created': '2022-11-10 15:41:09.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/utils/ovs.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/utils/test_ovs.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/560673d145ebf596aa5d1b452b5f759a538ae2c9', 'message': 'Avoid rules recreation at ensure_default_ovs_flows function\n\nThere is 2 flows instead on one (one for ipv4 and one for ipv6).\nThe current code expects just one flow, therefore it is constantly\nregenerating the flows while it should not. Fixing it to account\nfor the dual stack.\n\nChange-Id: I5c9c238649c7d970d63bacd5cfd624dda6120830\n'}]",0,863307,560673d145ebf596aa5d1b452b5f759a538ae2c9,7,2,2,23567,,,0,"Avoid rules recreation at ensure_default_ovs_flows function

There is 2 flows instead on one (one for ipv4 and one for ipv6).
The current code expects just one flow, therefore it is constantly
regenerating the flows while it should not. Fixing it to account
for the dual stack.

Change-Id: I5c9c238649c7d970d63bacd5cfd624dda6120830
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/07/863307/2 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/utils/ovs.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/utils/test_ovs.py']",2,8e9e937ae7b3ccb28d9dbd2dbee339fa31c28f2b,," mock_flows.return_value = [fake_flow_0, fake_flow_1] expected_flow_filter = '{},in_port={}'.format(self.cookie_id, port_iface) expected_calls = [ mock.call('ovs-vsctl', ['list-ports', self.bridge]), mock.call('ovs-ofctl', ['del-flows', self.bridge, uneeded_flow])] self.mock_ovs_vsctl.ovs_cmd.assert_has_calls(expected_calls) self.assertEqual(len(expected_calls), self.mock_ovs_vsctl.ovs_cmd.call_count) mock_ofport.assert_called_once_with(port) expected_calls_flows = [ mock.call(self.bridge, expected_flow_filter), mock.call(self.bridge, self.cookie_id)] mock_flows.assert_has_calls(expected_calls_flows) self.assertEqual(len(expected_calls_flows), mock_flows.call_count) @mock.patch.object(ovs_utils, 'get_bridge_flows') @mock.patch.object(ovs_utils, 'get_device_port_at_ovs') def test_ensure_default_ovs_flows_no_match(self, mock_ofport, mock_flows): port = 'patch-provnet-fake-port' port_iface = '1' uneeded_port_iface = '10' fake_flow_0 = '{},ip,in_port={}'.format(self.cookie_id, port_iface) fake_flow_1 = '{},ipv6,in_port={}'.format(self.cookie_id, port_iface) uneeded_flow = '{},in_port={}'.format(self.cookie_id, uneeded_port_iface) ovn_bridge_mappings = [self.bridge] address = '172.24.200.7' self.fake_ndb.interfaces[self.bridge] = {'address': address} self.mock_ovs_vsctl.ovs_cmd.side_effect = ([port], None, None, None) mock_flows.side_effect = ([fake_flow_0], [fake_flow_0, fake_flow_1, uneeded_flow]) mock_ofport.return_value = port_iface # Invoke the method ovs_utils.ensure_default_ovs_flows(ovn_bridge_mappings, self.cookie) ",,54,16
openstack%2Fovn-bgp-agent~master~I4ac744aea51a067542f823eb1c382adc6cdccd63,openstack/ovn-bgp-agent,master,I4ac744aea51a067542f823eb1c382adc6cdccd63,Avoid KeyError exception,MERGED,2022-11-08 15:50:19.000000000,2022-11-11 13:58:00.000000000,2022-11-11 13:58:00.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2022-11-08 15:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/f3a7dc41aec35e2f33e240837cd6c06c4e9c293d', 'message': 'Avoid KeyError exception\n\nChange-Id: I4ac744aea51a067542f823eb1c382adc6cdccd63\n'}, {'number': 2, 'created': '2022-11-08 15:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/05f2f3c1c3e84bef6b9d7126aa7fbfb51c5c18b8', 'message': 'Avoid KeyError exception\n\nChange-Id: I4ac744aea51a067542f823eb1c382adc6cdccd63\n'}, {'number': 3, 'created': '2022-11-08 17:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/72432d2c71849c6a1ffb6e55884c8a2d8d1ef7a8', 'message': 'Avoid KeyError exception\n\nChange-Id: I4ac744aea51a067542f823eb1c382adc6cdccd63\n'}, {'number': 4, 'created': '2022-11-11 13:46:09.000000000', 'files': ['ovn_bgp_agent/utils/linux_net.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/19117ecffabca5bb2271deae413fd7cbb8a87a97', 'message': 'Avoid KeyError exception\n\nChange-Id: I4ac744aea51a067542f823eb1c382adc6cdccd63\n'}]",4,863302,19117ecffabca5bb2271deae413fd7cbb8a87a97,18,3,4,23567,,,0,"Avoid KeyError exception

Change-Id: I4ac744aea51a067542f823eb1c382adc6cdccd63
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/02/863302/4 && git format-patch -1 --stdout FETCH_HEAD,['ovn_bgp_agent/utils/linux_net.py'],1,f3a7dc41aec35e2f33e240837cd6c06c4e9c293d,, if route_info in ovn_routing_tables_routes.get(dev):, if route_info in ovn_routing_tables_routes[dev]:,1,1
openstack%2Ftripleo-common~master~I63def768e3a2d43dd73d7ab5ced3a779b7469f65,openstack/tripleo-common,master,I63def768e3a2d43dd73d7ab5ced3a779b7469f65,Remove python-dev from bindep,NEW,2022-11-07 10:11:01.000000000,2022-11-11 12:51:41.000000000,,"[{'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-11-07 10:11:01.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bdf5106c1e0be3c37991b504c18d724fbf8e4f0f', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I63def768e3a2d43dd73d7ab5ced3a779b7469f65\n""}]",0,863856,bdf5106c1e0be3c37991b504c18d724fbf8e4f0f,4,5,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I63def768e3a2d43dd73d7ab5ced3a779b7469f65
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/56/863856/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,bdf5106c1e0be3c37991b504c18d724fbf8e4f0f,drop-python-dev-from-bindep,,python-devel [(platform:rpm platform:base-py2)],0,1
openstack%2Fironic~master~I6d80ce88c1066cfd0467e9c887e80850b935e2fa,openstack/ironic,master,I6d80ce88c1066cfd0467e9c887e80850b935e2fa,[WIP] Use join to get node_uuid for ports,ABANDONED,2022-10-28 02:09:07.000000000,2022-11-11 12:00:03.000000000,,"[{'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2022-10-28 02:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/68527eaf2c4cc9b357ca80b6300c2560dfd69b43', 'message': '[WIP] Use join to get node_uuid for ports\n\nRemove the need for api_utils.populate_node_uuid to\nget the node_uuid for ports. Replace with join in\ndatabase api instead.\n\nChange-Id: I6d80ce88c1066cfd0467e9c887e80850b935e2fa\nStory: 2007789\nTask:  40035\n'}, {'number': 2, 'created': '2022-10-28 02:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ac6cf94448a47a34eed75273ead99d9abf3ae56', 'message': '[WIP] Use join to get node_uuid for ports\n\nRemove the need for api_utils.populate_node_uuid to\nget the node_uuid for ports. Replace with join in\ndatabase api instead.\n\nChange-Id: I6d80ce88c1066cfd0467e9c887e80850b935e2fa\nStory: 2007789\nTask:  40035\n'}, {'number': 3, 'created': '2022-10-28 03:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8530424a1391bba2059f4f72f1fb77088eef85af', 'message': '[WIP] Use join to get node_uuid for ports\n\nRemove the need for api_utils.populate_node_uuid to\nget the node_uuid for ports. Replace with join in\ndatabase api instead.\n\nChange-Id: I6d80ce88c1066cfd0467e9c887e80850b935e2fa\nStory: 2007789\nTask:  40035\n'}, {'number': 4, 'created': '2022-10-28 12:45:22.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/db/sqlalchemy/api.py', 'zuul.d/project.yaml', 'ironic/objects/port.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0fc53339f5e9a50525a4f9f1a36a2c0fc7a7b22', 'message': '[WIP] Use join to get node_uuid for ports\n\nRemove the need for api_utils.populate_node_uuid to\nget the node_uuid for ports. Replace with join in\ndatabase api instead.\n\nChange-Id: I6d80ce88c1066cfd0467e9c887e80850b935e2fa\nStory: 2007789\nTask:  40035\n'}]",9,862852,b0fc53339f5e9a50525a4f9f1a36a2c0fc7a7b22,20,2,4,24245,,,0,"[WIP] Use join to get node_uuid for ports

Remove the need for api_utils.populate_node_uuid to
get the node_uuid for ports. Replace with join in
database api instead.

Change-Id: I6d80ce88c1066cfd0467e9c887e80850b935e2fa
Story: 2007789
Task:  40035
",git fetch https://review.opendev.org/openstack/ironic refs/changes/52/862852/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/port.py', 'ironic/db/sqlalchemy/api.py', 'zuul.d/project.yaml', 'ironic/objects/port.py']",4,68527eaf2c4cc9b357ca80b6300c2560dfd69b43,story/2007789," 'node_uuid': object_fields.UUIDField(nullable=True),",,288,278
openstack%2Ftripleo-ansible~stable%2Fzed~Ie4936401c8567204029a493e5d3b77d1ce7cc5a6,openstack/tripleo-ansible,stable/zed,Ie4936401c8567204029a493e5d3b77d1ce7cc5a6,Enable --retain option for zebra daemon,MERGED,2022-11-04 15:18:13.000000000,2022-11-11 11:53:28.000000000,2022-11-11 11:53:28.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-04 15:18:13.000000000', 'files': ['tripleo_ansible/roles/tripleo_frr/templates/daemons.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/42df457825f84ca28fedd77ae25dd356e6d16d21', 'message': 'Enable --retain option for zebra daemon\n\nUsing the retain option when starting zebra allows operators to\nnot lose routes installed by zebra from the kernel when stopping\nfrr/zebra.\n\nChange-Id: Ie4936401c8567204029a493e5d3b77d1ce7cc5a6\n(cherry picked from commit 68f4fde4efcc4658ce54b3f18be751df3354743e)\n'}]",1,863624,42df457825f84ca28fedd77ae25dd356e6d16d21,11,4,1,30126,,,0,"Enable --retain option for zebra daemon

Using the retain option when starting zebra allows operators to
not lose routes installed by zebra from the kernel when stopping
frr/zebra.

Change-Id: Ie4936401c8567204029a493e5d3b77d1ce7cc5a6
(cherry picked from commit 68f4fde4efcc4658ce54b3f18be751df3354743e)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/24/863624/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_frr/templates/daemons.j2'],1,42df457825f84ca28fedd77ae25dd356e6d16d21,,"zebra_options=(""-A 127.0.0.1 -r"")","zebra_options=(""-A 127.0.0.1"")",1,1
openstack%2Fpython-tripleoclient~stable%2Fwallaby~I66d6435e41a42a9db1772eea36e41c7a5cf87d23,openstack/python-tripleoclient,stable/wallaby,I66d6435e41a42a9db1772eea36e41c7a5cf87d23,Pass undercloud inventory for running preflight validations,MERGED,2022-11-10 14:17:56.000000000,2022-11-11 11:35:25.000000000,2022-11-11 11:34:29.000000000,"[{'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 35059}]","[{'number': 1, 'created': '2022-11-10 14:17:56.000000000', 'files': ['tripleoclient/v1/undercloud_preflight.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/633ce4862404a85f41f0b239e5334592493a593b', 'message': 'Pass undercloud inventory for running preflight validations\n\nThe undercloud name is hardcoded in the preflight validations.\nThis patch generate an undercloud inventory in order to run\npreflight validations as prep step of the undercloud install.\n\nCloses-bug: #1994032\n\nChange-Id: I66d6435e41a42a9db1772eea36e41c7a5cf87d23\n(cherry picked from commit 5589eabcd776eeafd080e819b10508fa12b022c4)\n'}]",1,864208,633ce4862404a85f41f0b239e5334592493a593b,9,6,1,32926,,,0,"Pass undercloud inventory for running preflight validations

The undercloud name is hardcoded in the preflight validations.
This patch generate an undercloud inventory in order to run
preflight validations as prep step of the undercloud install.

Closes-bug: #1994032

Change-Id: I66d6435e41a42a9db1772eea36e41c7a5cf87d23
(cherry picked from commit 5589eabcd776eeafd080e819b10508fa12b022c4)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/08/864208/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/undercloud_preflight.py'],1,633ce4862404a85f41f0b239e5334592493a593b,,"from tripleo_common.inventory import TripleoInventory undercloud_hosts_file = os.path.join(constants.CLOUD_HOME_DIR, 'undercloud_ansible_hosts.yaml') undercloud_inventory = TripleoInventory() undercloud_inventory.write_static_inventory(undercloud_hosts_file) args = ['validation', 'run', '-i', undercloud_hosts_file, '--validation',"," args = ['validation', 'run', '-i', 'undercloud', '--validation',",7,1
openstack%2Fansible-collections-openstack~master~Id023d13abf5c1179044fcc611a3e509f16f10621,openstack/ansible-collections-openstack,master,Id023d13abf5c1179044fcc611a3e509f16f10621,Refactored compute_flavor module,MERGED,2022-11-07 11:42:29.000000000,2022-11-11 10:41:47.000000000,2022-11-11 10:41:47.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-07 11:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/fff8be46c53511e550876fe248ac0286274593e9', 'message': 'Refactored compute_flavor module\n\nChange-Id: Id023d13abf5c1179044fcc611a3e509f16f10621\n'}, {'number': 2, 'created': '2022-11-08 12:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/788f97f41e431d9040d8ce53e078338238dde89e', 'message': 'Refactored compute_flavor module\n\nChange-Id: Id023d13abf5c1179044fcc611a3e509f16f10621\n'}, {'number': 3, 'created': '2022-11-09 13:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/23361d8815aec805d4a43364072b24d1ec30d9e5', 'message': 'Refactored compute_flavor module\n\nChange-Id: Id023d13abf5c1179044fcc611a3e509f16f10621\n'}, {'number': 4, 'created': '2022-11-10 18:41:47.000000000', 'files': ['plugins/modules/compute_flavor.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d3c5ddd40fde9018962d700a06c2bea16459f5f3', 'message': 'Refactored compute_flavor module\n\nChange-Id: Id023d13abf5c1179044fcc611a3e509f16f10621\n'}]",9,863868,d3c5ddd40fde9018962d700a06c2bea16459f5f3,18,4,4,32962,,,0,"Refactored compute_flavor module

Change-Id: Id023d13abf5c1179044fcc611a3e509f16f10621
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/68/863868/4 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/compute_flavor.py'],1,fff8be46c53511e550876fe248ac0286274593e9,compute-flavor," extra_specs: description: - Metadata dictionary type: dict is_public: description: - Make flavor accessible to the public. type: bool name: description: - Flavor name. required: true type: str ram: description: - Amount of memory, in MB. type: int rxtx_factor: description: - RX/TX factor. type: float state: description: - Indicate desired state of the resource. - When I(state) is C(present), then I(ram), I(vcpus), and I(disk) are required. There are no default values for those parameters. choices: ['present', 'absent'] default: present type: str swap: description: - Swap space size, in MB. type: int vcpus: description: - Number of virtual CPUs. type: int disk=dict(type='int'), ephemeral=dict(type='int'), id=dict(aliases=['flavorid']), is_public=dict(type='bool'), name=dict(required=True), # required when state is 'present' ram=dict(type='int'), rxtx_factor=dict(type='float'), state=dict(default='present', choices=['absent', 'present']), swap=dict(type='int'), vcpus=dict(type='int'), id = self.params['id'] name_or_id = id if id and id != 'auto' else name flavor = self.conn.compute.find_flavor(name_or_id, get_extra_specs=True) self.exit_json(changed=self._will_change(state, flavor)) if state == 'present' and not flavor: # Create flavor flavor = self._create() self.exit_json(changed=True, flavor=flavor.to_dict(computed=False)) elif state == 'present' and flavor: # Update flavor update = self._build_update(flavor) if update: flavor = self._update(flavor, update) self.exit_json(changed=bool(update), flavor=flavor.to_dict(computed=False)) elif state == 'absent' and flavor: # Delete flavor self._delete(flavor) self.exit_json(changed=True) elif state == 'absent' and not flavor: # Do nothing self.exit_json(changed=False) def _build_update(self, flavor): return { **self._build_update_extra_specs(flavor), **self._build_update_flavor(flavor)} def _build_update_extra_specs(self, flavor): update = {} old_extra_specs = flavor['extra_specs'] new_extra_specs = self.params['extra_specs'] or {} if flavor['swap'] == '': flavor['swap'] = 0 delete_extra_specs_keys = \ set(old_extra_specs.keys()) - set(new_extra_specs.keys()) if delete_extra_specs_keys: update['delete_extra_specs_keys'] = delete_extra_specs_keys stringified = dict([(k, str(v)) for k, v in new_extra_specs.items()]) if old_extra_specs != stringified: update['create_extra_specs'] = new_extra_specs return update def _build_update_flavor(self, flavor): update = {} flavor_attributes = dict( (k, self.params[k]) for k in ['ram', 'vcpus', 'disk', 'ephemeral', 'swap', 'rxtx_factor', 'is_public'] if k in self.params and self.params[k] is not None and self.params[k] != flavor[k]) if flavor_attributes: update['flavor_attributes'] = flavor_attributes return update def _create(self): kwargs = dict((k, self.params[k]) for k in ['name', 'ram', 'vcpus', 'disk', 'ephemeral', 'swap', 'rxtx_factor', 'is_public'] if self.params[k] is not None) # Keep for backward compatibility id = self.params['id'] if id is not None and id != 'auto': kwargs['id'] = id flavor = self.conn.compute.create_flavor(**kwargs) extra_specs = self.params['extra_specs'] if extra_specs: flavor = self.conn.compute.create_flavor_extra_specs(flavor.id, extra_specs) return flavor def _delete(self, flavor): self.conn.compute.delete_flavor(flavor) def _update(self, flavor, update): flavor = self._update_flavor(flavor, update) flavor = self._update_extra_specs(flavor, update) return flavor def _update_extra_specs(self, flavor, update): if update.get('flavor_attributes'): # No need to update extra_specs since flavor will be recreated return flavor delete_extra_specs_keys = update.get('delete_extra_specs_keys') if delete_extra_specs_keys: self.conn.unset_flavor_specs(flavor.id, delete_extra_specs_keys) # Update flavor after extra_specs removal create_extra_specs = update.get('create_extra_specs') if create_extra_specs: flavor = self.conn.compute.create_flavor_extra_specs( flavor.id, create_extra_specs) return flavor def _update_flavor(self, flavor, update): flavor_attributes = update.get('flavor_attributes') if flavor_attributes: # Because only flavor descriptions are updateable, # flavor has to be recreated to ""update"" it self._delete(flavor) flavor = self._create() return flavor def _will_change(self, state, flavor): if state == 'present' and not flavor: return True elif state == 'present' and flavor: return bool(self._build_update(flavor)) elif state == 'absent' and flavor: return False else: # state == 'absent' and not flavor: return True"," state: description: - Indicate desired state of the resource. When I(state) is 'present', then I(ram), I(vcpus), and I(disk) are all required. There are no default values for those parameters. choices: ['present', 'absent'] default: present type: str name: description: - Flavor name. required: true type: str ram: description: - Amount of memory, in MB. type: int vcpus: description: - Number of virtual CPUs. type: int default: 0 default: 0 swap: description: - Swap space size, in MB. default: 0 type: int rxtx_factor: description: - RX/TX factor. default: 1.0 type: float is_public: description: - Make flavor accessible to the public. type: bool default: 'yes' extra_specs: description: - Metadata dictionary type: dict state=dict(default='present', choices=['absent', 'present']), name=dict(required=True), # required when state is 'present' ram=dict(type='int'), vcpus=dict(type='int'), disk=dict(default=0, type='int'), ephemeral=dict(default=0, type='int'), swap=dict(default=0, type='int'), rxtx_factor=dict(default=1.0, type='float'), is_public=dict(default=True, type='bool'), id=dict(aliases=['flavorid']), def _system_state_change(self, flavor, extra_specs, old_extra_specs): state = self.params['state'] if state == 'present': if not flavor: return True return self._needs_update(flavor) or extra_specs != old_extra_specs if state == 'absent' and flavor: return True return False def _needs_update(self, flavor): fields = ['ram', 'vcpus', 'disk', 'ephemeral', 'swap', 'rxtx_factor', 'is_public'] for k in fields: if self.params[k] is not None and self.params[k] != flavor[k]: return True def _build_flavor_specs_diff(self, extra_specs, old_extra_specs): new_extra_specs = dict([(k, str(v)) for k, v in extra_specs.items()]) unset_keys = set(old_extra_specs.keys()) - set(extra_specs.keys()) return new_extra_specs, unset_keys extra_specs = self.params['extra_specs'] or {} flavor = self.conn.compute.find_flavor(name, get_extra_specs=True) old_extra_specs = {} if flavor: old_extra_specs = flavor['extra_specs'] if flavor['swap'] == '': flavor['swap'] = 0 self.exit_json(changed=self._system_state_change( flavor, extra_specs, old_extra_specs)) if state == 'present': flavor_id = self.params['id'] # Keep for backward compatibility flavor_id = None if flavor_id == 'auto' else flavor_id if flavor and self._needs_update(flavor): # Because only flavor descriptions are updateable, we have to # delete and recreate a flavor to ""update"" it flavor_id = flavor['id'] self.conn.compute.delete_flavor(flavor) old_extra_specs = {} flavor = None changed = False if not flavor: flavor = self.conn.compute.create_flavor( name=name, ram=self.params['ram'], vcpus=self.params['vcpus'], disk=self.params['disk'], id=flavor_id, ephemeral=self.params['ephemeral'], swap=self.params['swap'], rxtx_factor=self.params['rxtx_factor'], is_public=self.params['is_public'] ) changed = True new_extra_specs, unset_keys = self._build_flavor_specs_diff( extra_specs, old_extra_specs) if unset_keys: self.conn.unset_flavor_specs(flavor['id'], unset_keys) if old_extra_specs != new_extra_specs: self.conn.compute.create_flavor_extra_specs( flavor['id'], extra_specs) changed = True # Have to refetch updated extra_specs self.exit_json( changed=changed, flavor=flavor.to_dict(computed=False)) elif state == 'absent': if flavor: self.conn.compute.delete_flavor(flavor) self.exit_json(changed=True) self.exit_json(changed=False)",174,127
openstack%2Fskyline-console~master~Ib3f33ad45b5630b1b7d56573399873decb8a0a70,openstack/skyline-console,master,Ib3f33ad45b5630b1b7d56573399873decb8a0a70,feature: Add translation for monitor center,ABANDONED,2022-11-11 08:53:02.000000000,2022-11-11 10:17:01.000000000,,"[{'_account_id': 22348}, {'_account_id': 28706}, {'_account_id': 30434}]","[{'number': 1, 'created': '2022-11-11 08:53:02.000000000', 'files': ['src/locales/en.json', 'src/pages/monitor/containers/OtherService/components/Memcache/index.jsx', 'src/locales/zh.json', 'skyline_console/static/main.bundle.1663167892.js', 'skyline_console/static/monitor-center.bundle.1663167892.js'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/14ff8fa12a6e38536b9005cca003379c959bb9ed', 'message': 'feature: Add translation for monitor center\n\nAdded Chinese translation for monitor center\n\nChange-Id: Ib3f33ad45b5630b1b7d56573399873decb8a0a70\n'}]",0,864251,14ff8fa12a6e38536b9005cca003379c959bb9ed,3,3,1,33689,,,0,"feature: Add translation for monitor center

Added Chinese translation for monitor center

Change-Id: Ib3f33ad45b5630b1b7d56573399873decb8a0a70
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/51/864251/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/locales/en.json', 'src/pages/monitor/containers/OtherService/components/Memcache/index.jsx', 'src/locales/zh.json', 'skyline_console/static/main.bundle.1663167892.js', 'skyline_console/static/monitor-center.bundle.1663167892.js']",5,14ff8fa12a6e38536b9005cca003379c959bb9ed,fix-i18n-monitor,"(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{1209:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.fetchPrometheus=I,a.getRequestUrl=P,a.addParams=T,a.getInterval=function(e){var t=(e||k(0))[0],a=(e||k(0))[1].diff(t,""minutes"");return M[(a>44640?3:a>1440&&a<=44640&&2)||a>60&&a<=1440&&1||a>0&&a<=60&&0||0]},a.getPromises=a.range2IntervalsDict=a.getRange=a.defaultOneHourAgo=a.baseReturnFunc=a.getXScale=a.ChartType=void 0;var m=f(r(65)),p=f(r(33)),v=f(r(27)),h=f(r(81)),g=f(r(57)),y=f(r(36)),b=f(r(91)),_=f(r(111)),x=r(569),C=f(r(119)),S=f(r(48));function D(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function w(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=D(Object(r),!0)).call(a,(function(t){(0,y.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=D(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}a.ChartType={ONELINE:""oneline"",MULTILINE:""multiline"",ONELINEDEVICES:""oneline_devices"",MULTILINEDEVICES:""multiline_devices""};a.getXScale=e=>{var t=(0,C.default)(e[1]).diff((0,C.default)(e[0]),""minutes"",!0);return w({type:""time""},N[(t>20160?4:t>10080&&t<=20160&&3)||t>1440&&t<=10080&&2||t>60&&t<=1440&&1||t>0&&t<=60&&0||0])};var E=e=>e;function I(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""range"",a=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[],r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:10;return""current""===t?S.default.skyline.query.list({query:e}):""range""===t?S.default.skyline.queryRange.list({query:e,start:(0,x.getTimestamp)(a[0]),end:(0,x.getTimestamp)(a[1]),step:r}):m.default.resolve()}function P(e,t,a,r){var n=w(w({},t),r);return a(0===(0,p.default)(n).length?e:T(e,n))}function T(e,t){var a,r,n="""";return(0,v.default)(a=(0,p.default)(t)).call(a,(e=>{var a,r;(0,b.default)(t[e])?n+=(0,h.default)(a="""".concat(e,'=~""')).call(a,t[e].join(""|""),'"",'):n+=(0,h.default)(r="""".concat(e,'=""')).call(r,t[e],'"",')})),(0,h.default)(r="""".concat(e,""{"")).call(r,n.substring(0,n.length-1),""}"")}a.baseReturnFunc=E;a.defaultOneHourAgo=()=>[(0,C.default)().subtract(1,""hours""),(0,C.default)()];var k=e=>({3:[(0,C.default)().subtract(2,""weeks""),(0,C.default)()],2:[(0,C.default)().subtract(1,""weeks""),(0,C.default)()],1:[(0,C.default)().subtract(1,""days""),(0,C.default)()],0:[(0,C.default)().subtract(1,""hours""),(0,C.default)()]}[e]||[(0,C.default)().subtract(1,""hours""),(0,C.default)()]);a.getRange=k;var N=[{formatter:e=>(0,x.getStrFromTimestamp)(e,""HH:mm:ss""),ticketCount:6},{formatter:e=>(0,x.getStrFromTimestamp)(e,""HH:mm:ss""),ticketCount:6},{formatter:e=>(0,x.getStrFromTimestamp)(e,""MM-DD HH:mm""),ticketCount:3},{formatter:e=>(0,x.getStrFromTimestamp)(e,""MM-DD HH:mm""),ticketCount:6},{formatter:e=>(0,x.getStrFromTimestamp)(e,""MM-DD HH:mm""),ticketCount:6}],M=[[{text:t(""10s""),value:10},{text:t(""1min""),value:60},{text:t(""5min""),value:300}],[{text:t(""1min""),value:60},{text:t(""5min""),value:300},{text:t(""1H""),value:3600}],[{text:t(""1H""),value:3600},{text:t(""1D""),value:86400}],[{text:t(""1D""),value:86400}]];a.range2IntervalsDict=M;a.getPromises=e=>{var t,a=(0,_.default)(METRICDICT,e);return(0,g.default)(t=a.url).call(t,((e,t)=>I(P(e,{},(a.finalFormatFunc||[])[t]||E,(a.baseParams||[])[t]||{}),""current"")))}},1221:function(e,t,a){""use strict"";var r=a(33),n=a(44),l=a(32),i=a(25),s=a(27),u=a(45),o=a(46),d=a(19),c=a(21);d(t,""__esModule"",{value:!0}),t.default=t.InstancesStore=void 0;var f,m,p=c(a(57)),v=c(a(25)),h=c(a(51)),g=c(a(71)),y=c(a(36)),b=c(a(54)),_=(c(a(72)),c(a(111))),x=c(a(53)),C=c(a(48)),S=a(34),D=c(a(1218));function w(e,t){var a=r(e);if(n){var s=n(e);t&&(s=l(s).call(s,(function(t){return i(e,t).enumerable}))),a.push.apply(a,s)}return a}function E(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)s(a=w(Object(r),!0)).call(a,(function(t){(0,y.default)(e,t,r[t])}));else if(u)o(e,u(r));else{var n;s(n=w(Object(r))).call(n,(function(t){d(e,t,i(r,t))}))}}return e}var I=(f=class extends x.default{constructor(){super(...arguments),(0,g.default)(this,""dataList"",m,this)}get client(){return C.default.trove.instances}get clientDatastore(){return C.default.trove.datastores}get clientConfigurationGroup(){return C.default.trove.configurations}get adminClient(){return C.default.trove.instancesAdmin}get mapper(){return e=>E(E({},e),{},{type:(0,_.default)(e,""datastore.type""),version:(0,_.default)(e,""datastore.version""),size:(0,_.default)(e,""volume.size"")})}detailDidFetch(e){return(0,h.default)((function*(){var t=yield D.default.fetchDetail({id:(0,_.default)(e,""flavor.id"")});return E(E({},e),{},{flavor:E(E({},e.flavor),t)})}))()}listDidFetch(e){return 0===e.length?e:(0,p.default)(e).call(e,(e=>E(E({},e),{},{project_id:e.tenant_id})))}create(e){var t=this;return(0,h.default)((function*(){return t.submitting(t.client.create(e))}))()}delete(e,t){var a=this;return(0,h.default)((function*(){var{params:r}=e;return a.client.delete(r,t)}))()}update(e,t){return this.submitting(this.client.action(e,t))}operation(e){var t=this;return(0,h.default)((function*(){var{body:a,id:r,key:n=""""}=e,l=a;return l||((l={})[n]={}),t.update(r,l)}))()}restart(e){var t=this;return(0,h.default)((function*(){var{id:a}=e;return t.operation({key:""restart"",id:a})}))()}reboot(e){var t=this;return(0,h.default)((function*(){var{id:a}=e;return t.operation({key:""reboot"",id:a})}))()}stop(e){var t=this;return(0,h.default)((function*(){var{id:a}=e;return t.submitting(t.adminClient.action(a,{stop:{}}))}))()}resizeVolume(e){var t=this;return(0,h.default)((function*(){var{id:a,size:r}=e,n={resize:{volume:{size:r}}};return t.operation({body:n,id:a})}))()}listDatastores(){var e=this;return(0,h.default)((function*(){var t=(yield e.clientDatastore.list()).datastores;e.dataList=(0,p.default)(t).call(t,e.mapper)}))()}fetchListWithoutDetail(){var e=this;return(0,h.default)((function*(){var t=(yield e.client.list())[e.listResponseKey];e.list.data=(0,p.default)(t).call(t,e.mapper)}))()}listConfigurationGroup(){var e=this;return(0,h.default)((function*(){var t=(yield e.clientConfigurationGroup.list()).configurations;e.list.data=(0,p.default)(t).call(t,e.mapper)}))()}},m=(0,b.default)(f.prototype,""dataList"",[S.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),(0,b.default)(f.prototype,""create"",[S.action],(0,v.default)(f.prototype,""create""),f.prototype),(0,b.default)(f.prototype,""delete"",[S.action],(0,v.default)(f.prototype,""delete""),f.prototype),(0,b.default)(f.prototype,""update"",[S.action],(0,v.default)(f.prototype,""update""),f.prototype),(0,b.default)(f.prototype,""operation"",[S.action],(0,v.default)(f.prototype,""operation""),f.prototype),(0,b.default)(f.prototype,""restart"",[S.action],(0,v.default)(f.prototype,""restart""),f.prototype),(0,b.default)(f.prototype,""reboot"",[S.action],(0,v.default)(f.prototype,""reboot""),f.prototype),(0,b.default)(f.prototype,""stop"",[S.action],(0,v.default)(f.prototype,""stop""),f.prototype),(0,b.default)(f.prototype,""resizeVolume"",[S.action],(0,v.default)(f.prototype,""resizeVolume""),f.prototype),(0,b.default)(f.prototype,""listDatastores"",[S.action],(0,v.default)(f.prototype,""listDatastores""),f.prototype),(0,b.default)(f.prototype,""fetchListWithoutDetail"",[S.action],(0,v.default)(f.prototype,""fetchListWithoutDetail""),f.prototype),(0,b.default)(f.prototype,""listConfigurationGroup"",[S.action],(0,v.default)(f.prototype,""listConfigurationGroup""),f.prototype),f);t.InstancesStore=I;var P=new I;t.default=P},1263:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s=i(a(580));a(337);var u=i(a(338));a(333);var o=i(a(332)),d=i(a(1273)),c=i(a(51)),f=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=x(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0)),m=(a(173),a(555),a(1209)),p=i(a(1603)),v=i(a(4039)),h=i(a(4040)),g=i(a(4041)),y=i(a(1416)),b=a(1351),_=i(a(1417));function x(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(x=function(e){return e?a:t})(e)}var C=e=>{var t,a,{renderTimeRangeSelect:r,chartConfig:n,renderNodeSelect:l,fetchNodesFunc:i,defaultNode:b,children:x,type:C}=e,[S,D,w,E]=(0,g.default)(b),[I,P,T,k]=(0,h.default)((0,m.defaultOneHourAgo)()),[N,M]=(0,v.default)(I),[L,F]=(0,f.useState)(!0),[A,O]=(0,f.useState)(!0),z=function(){var e=(0,c.default)((function*(){var e=arguments.length>0&&void 0!==arguments[0]&&arguments[0];if(F(!0),l){O(!0);var t=yield i();E(t),S&&!e||w(t[0]),e&&4!==T&&k((0,m.getRange)(T)),O(!1),F(!1)}else(0,s.default)((()=>{F(!1)}),300)}));return function(){return e.apply(this,arguments)}}(),j={interval:N,range:I,node:S};return(0,f.useEffect)((()=>{z()}),[N,I]),(0,f.useEffect)((()=>{z(!0)}),[C]),(0,f.useEffect)((()=>{F(!0),(0,s.default)((()=>{F(!1)}),300)}),[S]),f.default.createElement(""div"",{className:y.default[""base-content-container""]},f.default.createElement(_.default.Provider,{value:j},(r||l)&&f.default.createElement(o.default,{type:""default"",icon:f.default.createElement(d.default,null),onClick:()=>z(!0),className:y.default.refresh}),r&&f.default.createElement(""div"",{className:y.default.header},f.default.createElement(P,null),f.default.createElement(M,null)),l&&(A?f.default.createElement(u.default,null):f.default.createElement(D,null)),l&&A||L&&0!==(null==n||null===(t=n.chartCardList)||void 0===t?void 0:t.length)&&0!==(null==n||null===(a=n.topCardList)||void 0===a?void 0:a.length)?null:f.default.createElement(p.default,n),l&&A||L?f.default.createElement(u.default,null):x))};C.defaultProps={renderNodeSelect:!0,renderTimeRangeSelect:!0,fetchNodesFunc:b.defaultGetNodes,defaultNode:void 0};var S=C;t.default=S},1309:function(e,t,a){""use strict"";var r=a(33),n=a(44),l=a(32),i=a(25),s=a(27),u=a(45),o=a(46),d=a(19),c=a(21);d(t,""__esModule"",{value:!0}),t.baseFixToChart=y,t.handleResponses=function(e,t,a){var r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:[],n=[];return(0,m.default)(e).call(e,((e,l)=>{n.push(...b(e,t,a,r[l]))})),n},t.handleResponse=b;var f=c(a(419)),m=c(a(27)),p=c(a(1204)),v=c(a(36)),h=c(a(111));function g(e,t){var a=r(e);if(n){var s=n(e);t&&(s=l(s).call(s,(function(t){return i(e,t).enumerable}))),a.push.apply(a,s)}return a}function y(e){return{x:e[0],y:(0,f.default)((0,f.default)(e[1]).toFixed(2))}}function b(e,t,a,r){var n,{data:l}=e,c=[];return(0,m.default)(n=l.result).call(n,(e=>{var n=(0,p.default)(e)||[e.value]||[];(0,m.default)(n).call(n,(n=>{var l=function(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)s(a=g(Object(r),!0)).call(a,(function(t){(0,v.default)(e,t,r[t])}));else if(u)o(e,u(r));else{var n;s(n=g(Object(r))).call(n,(function(t){d(e,t,i(r,t))}))}}return e}({},y(n));t&&(l.type=(0,h.default)(e.metric,t)),a&&(l.device=(0,h.default)(e.metric,a)),r&&(l.type=r),c.push(l)}))})),c}},1310:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.InstancesDatabasesStore=void 0;var l,i=n(a(25)),s=n(a(51)),u=n(a(62)),o=n(a(54)),d=n(a(53)),c=n(a(48)),f=a(34),m=(l=class extends d.default{get client(){return c.default.trove.instances.databases}get isSubResource(){return!0}get responseKey(){return""database""}get paramsFunc(){return e=>{var{id:t}=e;return(0,u.default)(e,[""id""])}}create(e,t){var a=this;return(0,s.default)((function*(){return a.submitting(a.client.create(e,t))}))()}deleteDatabase(e){var t=this;return(0,s.default)((function*(){var{id:a,name:r}=e;return t.submitting(t.client.delete(a,r))}))()}},(0,o.default)(l.prototype,""create"",[f.action],(0,i.default)(l.prototype,""create""),l.prototype),(0,o.default)(l.prototype,""deleteDatabase"",[f.action],(0,i.default)(l.prototype,""deleteDatabase""),l.prototype),l);t.InstancesDatabasesStore=m;var p=new m;t.default=p},1350:function(e,t,a){var r=a(4031);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1351:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.getMysqlNodes=t.getRabbitMQNodes=t.getMemcacheNodes=t.defaultGetNodes=void 0;var l=n(a(57)),i=n(a(27)),s=n(a(102)),u=n(a(51)),o=n(a(111)),d=a(1209),c=n(a(1396)),f=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""physicalNode.systemLoad.url[0]""),""current""),{data:{result:t=[]}}=e;return 0===t.length?[{metric:{instance:""""}}]:(0,l.default)(t).call(t,(e=>({metric:{instance:e.metric.instance}})))}));return function(){return e.apply(this,arguments)}}();t.defaultGetNodes=f;var m=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""memcacheService.currentConnections.url[0]""),""current""),{data:{result:t=[]}}=e;return 0===t.length?[{metric:{instance:""""}}]:(0,l.default)(t).call(t,(e=>({metric:{instance:e.metric.instance}})))}));return function(){return e.apply(this,arguments)}}();t.getMemcacheNodes=m;var p=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""rabbitMQService.serviceStatus.url[0]""),""current""),{data:{result:t=[]}}=e;if(0===t.length)return[{metric:{instance:""""}}];var a=[];return(0,i.default)(t).call(t,(e=>{var t={metric:{instance:e.metric.instance}};(0,s.default)(a).call(a,(e=>(0,c.default)(e,t)))||a.push(t)})),a}));return function(){return e.apply(this,arguments)}}();t.getRabbitMQNodes=p;var v=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""mysqlService.runningTime.url[0]""),""current""),{data:{result:t=[]}}=e;return 0===t.length?[{metric:{instance:""""}}]:(0,l.default)(t).call(t,(e=>({metric:{instance:e.metric.instance}})))}));return function(){return e.apply(this,arguments)}}();t.getMysqlNodes=v},1352:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.cephStatusColorMap=a.cephStatusMap=a.fillEmptyMetrics=a.timestampify=a.timeAliasReg=a.isSameDay=a.stopAutoRefresh=a.startAutoRefresh=a.getColorByName=a.getZeroValues=a.getTimesData=a.getLastMonitoringData=a.getXAxisTickFormatter=a.getAreaChartOps=a.getChartData=a.getFormatTime=a.getValueByUnit=a.getSuitableValue=a.getSuitableUnit=void 0;var m=f(r(226)),p=f(r(81)),v=f(r(419)),h=f(r(27)),g=f(r(229)),y=f(r(174)),b=f(r(57)),_=f(r(1265)),x=f(r(198)),C=f(r(588)),S=f(r(620)),D=f(r(4042)),w=f(r(1299)),E=f(r(1204)),I=f(r(62)),P=f(r(36)),T=f(r(4045)),k=f(r(4047)),N=f(r(4049)),M=f(r(1532)),L=f(r(4050)),F=f(r(111)),A=f(r(131)),O=f(r(343)),z=f(r(592)),j=f(r(650)),K=f(r(91)),R=f(r(199)),U=r(334),B=r(569);function q(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function H(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=q(Object(r),!0)).call(a,(function(t){(0,P.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=q(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var V={second:{conditions:[.01,0],units:[""s"",""ms""]},cpu:{conditions:[.1,0],units:[""core"",""m""]},memory:{conditions:[1024**4,1024**3,1048576,1024,0],units:[""TiB"",""GiB"",""MiB"",""KiB"",""Bytes""]},disk:{conditions:[1e3**4,1e3**3,1e6,1e3,0],units:[""TB"",""GB"",""MB"",""KB"",""Bytes""]},throughput:{conditions:[1e3**4,1e3**3,1e6,1e3,0],units:[""TB/s"",""GB/s"",""MB/s"",""KB/s"",""B/s""]},traffic:{conditions:[1e3**4,1e3**3,1e6,1e3,0],units:[""TB/s"",""GB/s"",""MB/s"",""KB/s"",""B/s""]},bandwidth:{conditions:[131072,128,0],units:[""Mbps"",""Kbps"",""bps""]}},Q=(e,t)=>{var a,r=V[t];if((0,R.default)(r))return"""";var n=(0,K.default)(e)?e:[[0,Number(e)]],l=(0,M.default)(r.units);return(0,m.default)(a=r.conditions).call(a,((e,t)=>{var a=(0,m.default)(n).call(n,(t=>(((0,K.default)(t)?(0,F.default)(t,""[1]""):Number(t))||0)>=e));return a&&(l=r.units[t]),a})),l};a.getSuitableUnit=Q;a.getSuitableValue=function(e){var a,r=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""default"",n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0;if(!(0,O.default)(e)&&!(0,A.default)(e)||(0,j.default)(Number(e)))return n;var l=Q(e,r),i=l?"" "".concat(t(l)):"""",s=G(e,l||r);return(0,p.default)(a="""".concat(s)).call(a,i)};var G=(e,t)=>{var a=(0,v.default)(e);switch(t){default:break;case"""":case""default"":return a;case""iops"":return Math.round(a);case""%"":a*=100;break;case""m"":if((a*=1e3)<1)return 0;break;case""KiB"":a/=1024;break;case""MiB"":a/=1048576;break;case""GiB"":a/=1024**3;break;case""TiB"":a/=1024**4;break;case""Bytes"":case""B"":case""B/s"":break;case""KB"":case""KB/s"":a/=1e3;break;case""MB"":case""MB/s"":a/=1e6;break;case""GB"":case""GB/s"":a/=1e3**3;break;case""TB"":case""TB/s"":a/=1e3**4;break;case""bps"":a*=8;break;case""Kbps"":a=8*a/1024;break;case""Mbps"":a=8*a/1024/1024;break;case""ms"":a*=1e3}return 0===Number(a)?0:Number(a.toFixed(2))};a.getValueByUnit=G;var W=e=>(0,B.getStrFromTimestamp)(e).replace(/:00$/g,"""");a.getFormatTime=W;var X=e=>{var t,{type:a,unit:r,xKey:n=""time"",legend:l=[],valuesData:i=[],xFormatter:s}=e,u={};(0,h.default)(i).call(i,((e,t)=>{(0,h.default)(e).call(e,(e=>{var n=(0,g.default)((0,F.default)(e,[0],0),10),i=(0,F.default)(e,[1]),s=(0,F.default)(l,[t]);n&&!u[n]&&(u[n]=(0,y.default)(l).call(l,((e,t)=>(e[t]||(e[t]=null),e)),{})),s&&u[n]&&(u[n][s]=""-1""===i?null:G(i,(0,z.default)(r)?a:r))}))}));var o=e=>""time""===n?W(e):e;return(0,b.default)(t=(0,_.default)(u)).call(t,(e=>{var[t,a]=e;return H({[n]:(s||o)(t)},a)}))};a.getChartData=X;a.getAreaChartOps=e=>{var{type:t,title:a,unitType:r,xKey:n=""time"",legend:l=[],data:i=[],xFormatter:s}=e,u=(0,I.default)(e,[""type"",""title"",""unitType"",""xKey"",""legend"",""data"",""xFormatter""]),o=(0,K.default)(i)?i:[],d=(0,b.default)(o).call(o,(e=>(0,F.default)(e,""values"")||[])),c=r?Q((0,N.default)(d),r):u.unit,f=X({type:t,unit:c,xKey:n,legend:l,valuesData:d,xFormatter:s}),m=""time""===n?Z(f):e=>e;return H(H({},u),{},{title:a,unit:c,xAxisTickFormatter:m,data:f})};var Z=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],a=(0,b.default)(e).call(e,(e=>{var{time:t}=e;return+new Date(t)})),r=(0,k.default)(a),n=(0,T.default)(a);return n-r>864e4?e=>(0,B.getLocalTimeStr)(e,t(""Do HH:mm"")):e=>(0,B.getLocalTimeStr)(e,""HH:mm:ss"")};a.getXAxisTickFormatter=Z;a.getLastMonitoringData=e=>{var t,a={};return(0,h.default)(t=(0,_.default)(e)).call(t,(e=>{var[t,r]=e,n=(0,F.default)(r,""data.result[0].values"",[])||[],l=(0,R.default)(n)?(0,F.default)(r,""data.result[0].value"",[])||[]:(0,M.default)(n);(0,L.default)(a,""["".concat(t,""].value""),l)})),a};a.getTimesData=e=>{var t=[];return(0,h.default)(e).call(e,(e=>{var a=(0,F.default)(e,""values"")||[];(0,h.default)(a).call(a,(e=>{var a=(0,F.default)(e,""[0]"",0);(0,x.default)(t).call(t,a)||t.push(a)}))})),(0,C.default)(t).call(t)};a.getZeroValues=()=>{for(var e=[],t=(0,g.default)((0,S.default)()/1e3,10)-6e3,a=0;a<10;a++)e[a]=[t,0],t+=600;return e};a.getColorByName=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:""#fff"";return U.COLORS_MAP[e]||e};a.startAutoRefresh=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},a=H({method:""fetchData"",interval:5e3,leading:!0},t);if(e&&e[a.method]){var r=e[a.method];a.leading&&r({autoRefresh:!0}),e.timer=(0,D.default)((()=>{r({autoRefresh:!0})}),a.interval)}};a.stopAutoRefresh=e=>{e&&e.timer&&(clearInterval(e.timer),e.timer=null)};a.isSameDay=(e,t)=>Math.floor(e/864e5)===Math.floor(t/864e5);var J=/(\d+)(\w+)/;a.timeAliasReg=J;a.timestampify=e=>{var[,t=0,a]=e.match(J)||[];return Number(t)*(U.MILLISECOND_IN_TIME_UNIT[a]||0)};a.fillEmptyMetrics=(e,t)=>{var a;if(!e.times||!e.start||!e.end)return t;var r=e=>String(e).replace(/\..*$/,""""),n=Math.floor((e.end-e.start)/e.times),l=e.times+1;return(0,h.default)(a=(0,w.default)(t)).call(a,(t=>{var a=(0,F.default)(t,""data.result"");(0,R.default)(a)||(0,h.default)(a).call(a,(t=>{var a=(0,E.default)(t)||[],i=(0,y.default)(a).call(a,((e,t)=>H(H({},e),{},{[r(t[0])]:t[1]})),{});if(a.length<l){for(var s=[],u=0;u<l;u++){var o=r(e.start+u*n);s.push([o,i[o]||""0""])}t.values=s}}))})),t};var Y={0:t(""Healthy""),1:t(""Warning""),2:t(""Error"")};a.cephStatusMap=Y;a.cephStatusColorMap={0:""#379738"",1:""#FAAD14"",2:""#D93126""}},1353:function(e,t,a){var r=a(4068);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1354:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.BackupsStore=void 0;var l,i=n(a(25)),s=n(a(51)),u=n(a(54)),o=n(a(53)),d=n(a(48)),c=a(34),f=(l=class extends o.default{get client(){return d.default.trove.backups}create(e){var t=this;return(0,s.default)((function*(){return t.client.create(e)}))()}delete(e,t){var a=this;return(0,s.default)((function*(){var{params:r}=e;return a.client.delete(r,t)}))()}},(0,u.default)(l.prototype,""create"",[c.action],(0,i.default)(l.prototype,""create""),l.prototype),(0,u.default)(l.prototype,""delete"",[c.action],(0,i.default)(l.prototype,""delete""),l.prototype),l);t.BackupsStore=f;var m=new f;t.default=m},1355:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.ConfigurationsStore=void 0;var l,i=n(a(25)),s=n(a(51)),u=n(a(54)),o=n(a(53)),d=n(a(48)),c=a(34),f=(l=class extends o.default{get client(){return d.default.trove.configurations}create(e){var t=this;return(0,s.default)((function*(){return t.client.create(e)}))()}delete(e,t){var a=this;return(0,s.default)((function*(){var{params:r}=e;return a.client.delete(r,t)}))()}},(0,u.default)(l.prototype,""create"",[c.action],(0,i.default)(l.prototype,""create""),l.prototype),(0,u.default)(l.prototype,""delete"",[c.action],(0,i.default)(l.prototype,""delete""),l.prototype),l);t.ConfigurationsStore=f;var m=new f;t.default=m},1356:function(e,t,a){""use strict"";var r=a(33),n=a(44),l=a(32),i=a(25),s=a(27),u=a(45),o=a(46),d=a(19),c=a(21);d(t,""__esModule"",{value:!0}),t.default=t.InstancesUsersStore=void 0;var f,m=c(a(57)),p=c(a(32)),v=c(a(102)),h=c(a(25)),g=c(a(36)),y=c(a(51)),b=c(a(62)),_=c(a(54)),x=c(a(53)),C=c(a(48)),S=a(34);function D(e,t){var a=r(e);if(n){var s=n(e);t&&(s=l(s).call(s,(function(t){return i(e,t).enumerable}))),a.push.apply(a,s)}return a}function w(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)s(a=D(Object(r),!0)).call(a,(function(t){(0,g.default)(e,t,r[t])}));else if(u)o(e,u(r));else{var n;s(n=D(Object(r))).call(n,(function(t){d(e,t,i(r,t))}))}}return e}var E=(f=class extends x.default{get client(){return C.default.trove.instances.users}get databaseClient(){return C.default.trove.instances.databases}get instanceClient(){return C.default.trove.instances}get isSubResource(){return!0}get responseKey(){return""user""}get paramsFunc(){return e=>{var{id:t}=e;return(0,b.default)(e,[""id""])}}listDidFetch(e,t,a){var r=this;return(0,y.default)((function*(){if(0===e.length)return e;var{id:t}=a,{databases:n=[]}=yield r.databaseClient.list(t);return(0,m.default)(e).call(e,(e=>{var t,a;return w(w({},e),{},{databases:(0,m.default)(t=(0,p.default)(a=e.databases||[]).call(a,(e=>(0,v.default)(n).call(n,(t=>t.name===e.name))))).call(t,(e=>e.name))})}))}))()}create(e,t){var a=this;return(0,y.default)((function*(){return a.submitting(a.client.create(e,t))}))()}deleteUser(e){var t=this;return(0,y.default)((function*(){var{id:a,name:r}=e;return t.submitting(t.client.delete(a,r))}))()}grantDatabaseAccess(e){var t=this;return(0,y.default)((function*(){var{id:a,name:r,data:n}=e;return t.submitting(t.instanceClient.grantDatabase(a,r,n))}))()}},(0,_.default)(f.prototype,""create"",[S.action],(0,h.default)(f.prototype,""create""),f.prototype),(0,_.default)(f.prototype,""deleteUser"",[S.action],(0,h.default)(f.prototype,""deleteUser""),f.prototype),(0,_.default)(f.prototype,""grantDatabaseAccess"",[S.action],(0,h.default)(f.prototype,""grantDatabaseAccess""),f.prototype),f);t.InstancesUsersStore=E;var I=new E;t.default=I},1415:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.createFetchPrometheusClient=function(e){var{requestType:t,metricKey:a}=e,r=(0,f.default)(METRICDICT,a);return function(){var e=(0,o.default)((function*(e){var a,{params:n={},currentRange:s,interval:u}=e,o=(0,l.default)(a=r.url).call(a,((e,a)=>{var l=(r.finalFormatFunc||[])[a]||p.baseReturnFunc,i=(r.baseParams||[])[a]||{},o=(0,p.getRequestUrl)(e,n,l,i);return(0,p.fetchPrometheus)(o,t,s,u)}));return i.default.all(o)}));return function(t){return e.apply(this,arguments)}}()},t.createDataHandler=function(e){var{formatDataFn:t,typeKey:a,deviceKey:r,modifyKeys:n}=e;return e=>{var i=t(e,a,r,n),o=(0,c.default)(i),f="""",p=[];if((0,d.default)(i)&&0!==i.length&&i[0].device){var v,h=(new m.default).createView().source(i).transform({type:""partition"",groupBy:[""device""]});f=(p=(0,l.default)(v=(0,s.default)(h.rows)).call(v,(e=>(0,u.default)(e).call(e,1,e.length))))[0]}return{retData:o,device:f,devices:p}}};var l=n(a(57)),i=n(a(65)),s=n(a(33)),u=n(a(200)),o=n(a(51)),d=n(a(91)),c=n(a(4033)),f=n(a(111)),m=n(a(4034)),p=a(1209)},1416:function(e,t,a){var r=a(4035);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1417:function(e,t,a){""use strict"";a(19)(t,""__esModule"",{value:!0}),t.default=void 0;var r=a(0),n=a(1209),l=(0,r.createContext)({interval:10,range:(0,n.defaultOneHourAgo)(),node:{metric:{hostname:""""}}});t.default=l},1418:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),c(a,""policyType"",{enumerable:!0,get:function(){return v.default}}),a.InstanceStatus=void 0;var m=f(r(36)),p=r(1195),v=f(r(1300));function h(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function g(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=h(Object(r),!0)).call(a,(function(t){(0,m.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=h(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var y=g(g({},p.instanceStatus),{},{BUILD:t(""Building""),ACTIVE:t(""Active""),ERROR:t(""Error""),DELETE:t(""Delete""),MIGRATE:t(""Migrate""),RESIZE:t(""Resize""),REBOOT:t(""Reboot""),PROMOTE:t(""Promote""),EJECT:t(""Eject"")});a.InstanceStatus=y},1603:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s=i(a(57));a(1198);var u=i(a(1199));a(1196);var o=i(a(1197)),d=i(a(409)),c=i(a(62)),f=i(a(593)),m=i(a(111)),p=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=_(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0)),v=(a(173),a(1309)),h=i(a(1350)),g=i(a(1604)),y=i(a(4036)),b=i(a(1417));function _(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(_=function(e){return e?a:t})(e)}var x=e=>{var{baseTopCardProps:t,baseChartProps:a,topCardList:r,chartCardList:n}=e,l=(0,p.useContext)(b.default);return p.default.createElement(u.default,{gutter:[16,16]},0!==r.length&&p.default.createElement(o.default,{span:24},p.default.createElement(u.default,{gutter:[16,16],style:{width:""100%""}},(0,s.default)(r).call(r,(e=>{var a,r;if(e.hidden)return null;var n=(0,f.default)({},t,e),{span:i,fetchDataParams:s={}}=n,u=(0,c.default)(n,[""span"",""fetchDataParams""]),m={key:u.title};i?m.span=i:m.flex=1;var v,{params:h={}}=s,y={currentRange:l.range,interval:l.interval,params:h};if(null!==(a=l.node)&&void 0!==a&&a.metric.hostname)y.params.hostname=null===(v=l.node)||void 0===v?void 0:v.metric.hostname;else if(null!==(r=l.node)&&void 0!==r&&r.metric.instance){var b;y.params.instance=null===(b=l.node)||void 0===b?void 0:b.metric.instance}return p.default.createElement(o.default,m,p.default.createElement(g.default,(0,d.default)({},u,{fetchDataParams:y})))})))),0!==n.length&&p.default.createElement(o.default,{span:24},"" "",p.default.createElement(u.default,{gutter:[16,16]},(0,s.default)(n).call(n,(e=>{var t,r,n=(0,f.default)({},a,e),{span:i,fetchDataParams:s={}}=n,u=(0,c.default)(n,[""span"",""fetchDataParams""]),m={key:u.title};i?m.span=i:m.flex=1;var v,{params:h={}}=s,g={currentRange:l.range,interval:l.interval,params:h};if(null!==(t=l.node)&&void 0!==t&&t.metric.hostname)g.params.hostname=null===(v=l.node)||void 0===v?void 0:v.metric.hostname;else if(null!==(r=l.node)&&void 0!==r&&r.metric.instance){var b;g.params.instance=null===(b=l.node)||void 0===b?void 0:b.metric.instance}return p.default.createElement(o.default,m,p.default.createElement(y.default,(0,d.default)({},u,{fetchDataParams:g})))})))))};x.defaultProps={baseTopCardProps:{createFetchParams:{requestType:""current""},handleDataParams:{formatDataFn:v.handleResponses},renderContent:e=>{var{data:t}=e;return p.default.createElement(""div"",{className:h.default[""top-content""]},(0,m.default)(t,""[0].y"",0))}},baseChartProps:{span:12,createFetchParams:{requestType:""range""},handleDataParams:{formatDataFn:v.handleResponses},chartProps:{height:300,scale:{y:{nice:!0}}}},topCardList:[],chartCardList:[]};var C=x;t.default=C},1604:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=t.PrometheusContext=void 0,a(1229);var s=i(a(1230));a(560);var u=i(a(412)),o=i(a(51)),d=i(a(32)),c=i(a(57)),f=(a(173),function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=h(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0))),m=i(a(4032)),p=a(1415),v=i(a(1416));function h(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(h=function(e){return e?a:t})(e)}var g=(0,f.createContext)({data:[],device:"""",devices:[]});function y(e,t,a){return t&&0!==a.length?(0,d.default)(e).call(e,(e=>e.device===t)):e}t.PrometheusContext=g;var b=e=>{var{createFetchParams:t,handleDataParams:a,fetchDataParams:r,title:n,visibleHeight:l,extra:i,renderContent:h}=e,[b,_]=(0,f.useState)([]),[x,C]=(0,f.useState)([]),[S,D]=(0,f.useState)(""""),[w,E]=(0,f.useState)([]),[I,P]=(0,f.useState)(!0),T=(0,p.createFetchPrometheusClient)(t),k=(0,p.createDataHandler)(a),N={data:x,device:S,devices:w,modifyKeys:a.modifyKeys};(0,f.useEffect)((()=>{(0,o.default)((function*(){P(!0);var e=yield T(r),{retData:t,device:a,devices:n}=k(e);_(t),D(a),E(n);var l=y(t,a,n);C(l),P(!1)}))()}),[]);var M=f.default.createElement(f.default.Fragment,null,!I&&S&&0!==w.length&&f.default.createElement(u.default,{defaultValue:S,style:{width:150,marginRight:16},options:(0,c.default)(w).call(w,(e=>({label:e,value:e}))),onChange:e=>{P(!0);var t=y(b,e,w);D(e),C(t),P(!1)}}),i&&i({initData:b,chartData:x,device:S,devices:w,modifyKeys:a.modifyKeys,filterChartData:e=>{P(!0);var t=(0,d.default)(b).call(b,e);C(t),P(!1)}}));return f.default.createElement(g.Provider,{value:N},f.default.createElement(s.default,{className:v.default[""remove-extra-padding""],bodyStyle:{minHeight:l+48},title:n,extra:M,loading:I},f.default.createElement(m.default,{style:{width:""100%"",height:l}},(e=>e?f.default.createElement(g.Consumer,null,(e=>h(e))):null))))};b.defaultProps={visibleHeight:100};var _=b;t.default=_},1606:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(174)),i=n(a(36)),s=a(1295),u=n(a(0)),o=n(a(16));class d extends u.default.Component{render(){var{data:e,legendFontSize:t,legendOffsetX:a,middleFontSize:r}=this.props;return(0,s.registerShape)(""interval"",""sliceShape"",{draw(e,t){var{points:a}=e,r=[];return r.push([""M"",a[0].x,a[0].y]),r.push([""L"",a[1].x,a[1].y-.01]),r.push([""L"",a[2].x,a[2].y-.01]),r.push([""L"",a[3].x,a[3].y]),r.push(""Z""),r=this.parsePath(r),t.addShape(""path"",{attrs:{fill:e.color,path:r}})}}),u.default.createElement(s.Chart,{data:e,autoFit:!0,padding:""auto"",appendPadding:[0,20,0,0]},u.default.createElement(s.Coordinate,{type:""theta"",radius:.8,innerRadius:.75}),u.default.createElement(s.Axis,{visible:!1}),u.default.createElement(s.Tooltip,{showTitle:!1}),u.default.createElement(s.Interval,{adjust:""stack"",position:""value"",color:""type"",shape:""sliceShape""}),u.default.createElement(s.Annotation.Text,{position:[""50%"",""50%""],content:(0,l.default)(e).call(e,((e,t)=>e+t.value),0),style:{lineHeight:240,fontSize:r,fill:""#262626"",textAlign:""center""}}),u.default.createElement(s.Legend,{position:""right"",offsetX:a,itemName:{style:{fontSize:t}}}),u.default.createElement(s.Interaction,{type:""element-single-selected""}))}}t.default=d,(0,i.default)(d,""propTypes"",{data:o.default.array,legendFontSize:o.default.number,legendOffsetX:o.default.number,middleFontSize:o.default.number}),(0,i.default)(d,""defaultProps"",{legendFontSize:16,legendOffsetX:-40,middleFontSize:30})},1607:function(e,t,a){var r=a(4060);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1608:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(4075)),s=l(r(1609)),u=l(r(4080)),o=l(r(4081)),d=l(r(4082)),c=l(r(4083)),f=l(r(4084)),m={actionConfigs:{rowActions:{firstAction:i.default,moreActions:[{action:u.default},{title:t(""Database Instance Status""),actions:[o.default,d.default,c.default]},{title:t(""Configuration Update""),actions:[f.default]}]},primaryActions:[s.default],batchActions:[i.default]},actionConfigsAdmin:{rowActions:{firstAction:i.default},primaryActions:[],batchActions:[i.default]}};a.default=m},1609:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.default=a.StepCreate=void 0;var m=f(r(57)),p=f(r(65));r(1336);var v=f(r(426)),h=f(r(51)),g=f(r(36)),y=r(1193),b=r(406),_=f(r(1221)),x=f(r(407)),C=(r(173),f(r(4076))),S=f(r(4077)),D=f(r(4078)),w=f(r(4079));function E(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function I(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=E(Object(r),!0)).call(a,(function(t){(0,g.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=E(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}class P extends y.StepAction{constructor(){super(...arguments),(0,g.default)(this,""onSubmit"",(e=>{var t,{selectedRowKeys:a=[]}=e.network;return(0,m.default)(a).call(a,(e=>({""net-id"":e}))),t=[{""net-id"":a[0]}],this.store.create({instance:{datastore:{type:e.datastore_type,version:e.datastore_version},name:e.instance_name,flavorRef:e.flavor.selectedRowKeys[0],volume:{size:e.size},availability_zone:e.zone,nics:t,locality:e.locality,configuration:e.configurationGroup,databases:[{character_set:""utf8"",collate:""utf8_general_ci"",name:e.initialDatabases}],users:[{databases:[{name:e.initialDatabases}],name:e.initialAdminUser,password:e.password}]}})}))}init(){this.store=_.default,this.projectStore=x.default,this.getQuota(),this.state.isLoading=!0,this.errorMsg=""""}static allowed(){return p.default.resolve(!0)}get name(){return t(""Create Database Instance"")}get listUrl(){return this.getRoutePath(""databaseInstances"")}get hasConfirmStep(){return!1}get steps(){return[{title:t(""Details *""),component:C.default},{title:t(""Networking *""),component:S.default},{title:t(""Initialize Databases""),component:D.default},{title:t(""Advanced""),component:w.default}]}get showQuota(){return this.props.rootStore.hasAdminOnlyRole}getQuota(){var e=this;return(0,h.default)((function*(){e.showQuota&&(yield e.projectStore.fetchProjectTroveQuota(e.currentProjectId),e.setState({isLoading:!1}))}))()}get quotaInfo(){if(this.state.isLoading)return[];var{instances:e={},volumes:a={}}=this.projectStore.troveQuota||{},{left:r=0}=e||{},{data:{size:n=0}={}}=this.state,l=I(I({},e),{},{add:r?1:0,name:""instance"",title:t(""Database Instance"")}),{left:i=0}=a,s=I(I({},a),{},{add:-1===i||n<=i?n:0,name:""volumeSize"",title:t(""Database Disk (GiB)""),type:""line""});return this.checkQuota(this.state.data,this.projectStore.troveQuota),[l,s]}getQuotaMessage(e,a,r){return-1===a?"""":0===a?t(""Quota: Insufficient { name } quota to create resources."",{name:r}):e>a?t(""Insufficient {name} quota to create resources(left { quota }, input { input })."",{name:r,quota:a,input:e}):""""}checkQuota(e,a){var{instances:{left:r=0}={},volumes:{left:n=0}={}}=a||{},{size:l=0}=e||{},i=this.getQuotaMessage(1,r,t(""Database Instance"")),s=this.getQuotaMessage(l,n,t(""Database Disk (GiB)""));if(i||s){var u=i||s;this.errorMsg!==u&&v.default.error(u),this.errorMsg=u}else this.errorMsg=""""}get disableNext(){return!!this.errorMsg}get disableSubmit(){return!!this.errorMsg}}a.StepCreate=P,(0,g.default)(P,""id"",""create-database-instance""),(0,g.default)(P,""title"",t(""Create Database Instance"")),(0,g.default)(P,""path"",""/database/instances/create""),(0,g.default)(P,""policy"",""instance:create"");var T=(0,b.inject)(""rootStore"")((0,b.observer)(P));a.default=T},4028:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(413)),i=n(a(4029)),s=e=>(0,l.default)(i.default,e);t.default=s},4029:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(1212)),i=n(a(567)),s=n(a(4030)),u=n(a(4052)),o=n(a(4056)),d=n(a(4061)),c=n(a(4067)),f=""/monitor-center"",m=[{path:f,component:l.default,routes:[{path:"""".concat(f,""/overview-admin""),component:c.default,exact:!0},{path:"""".concat(f,""/physical-node-admin""),component:s.default,exact:!0},{path:"""".concat(f,""/storage-cluster-admin""),component:u.default,exact:!0},{path:"""".concat(f,""/openstack-service-admin""),component:o.default,exact:!0},{path:"""".concat(f,""/other-service-admin""),component:d.default,exact:!0},{path:""*"",component:i.default}]}];t.default=m},4030:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=a.chartCardList=a.topCardList=void 0;var i=l(r(229)),s=l(r(27)),u=l(r(419)),o=l(r(57)),d=l(r(81));r(1222);var c=l(r(1223)),f=l(r(111)),m=l(r(0)),p=l(r(119)),v=(r(173),l(r(1263))),h=r(1352),g=r(1209),y=r(161),b=l(r(1350)),_=[{title:t(""CPU Cores""),span:5,createFetchParams:{metricKey:""physicalNode.cpuCores""},renderContent:e=>m.default.createElement(""div"",{className:b.default[""top-content""]},(0,f.default)(e.data,""length"",0))},{title:t(""Total Ram""),span:5,createFetchParams:{metricKey:""physicalNode.totalMem""},renderContent:e=>m.default.createElement(""div"",{className:b.default[""top-content""]},(0,h.getSuitableValue)((0,f.default)(e.data[0],""y"",0),""memory""))},{title:t(""System Running Time""),span:5,createFetchParams:{metricKey:""physicalNode.systemRunningTime""},renderContent:e=>m.default.createElement(""div"",{className:b.default[""top-content""]},(0,y.formatUsedTime)(1e3*((0,p.default)().unix()-(0,i.default)((0,f.default)(e.data[0],""y"",(0,p.default)().unix()),10))))},{title:t(""File System Free Space""),span:9,createFetchParams:{metricKey:""physicalNode.fileSystemFreeSpace""},handleDataParams:{formatDataFn:function(){for(var e=arguments.length,t=new Array(e),a=0;a<e;a++)t[a]=arguments[a];var[r,n,l]=t,[i,o]=r,{data:{result:d}={result:[]}}=i,c=[];return(0,s.default)(d).call(d,((e,t)=>{c.push({mountpoint:(0,f.default)(e,""metric."".concat(l))+(0,f.default)(e,""metric."".concat(n)),avail:(0,u.default)((0,f.default)(e,""value[1]"",0)),total:(0,u.default)((0,f.default)(o,""data.result["".concat(t,""].value[1]""),0))})})),c},typeKey:""mountpoint"",deviceKey:""device""},renderContent:e=>{var t;return m.default.createElement(""div"",{style:{height:100,overflow:""auto""}},(0,o.default)(t=e.data||[]).call(t,((e,t)=>{var a,r=(0,y.computePercentage)(e.avail,e.total)>80?""#FAAD14"":""#1890FF"";return m.default.createElement(""div"",{key:e.mountpoint,style:{marginTop:t>0?16:0}},m.default.createElement(""div"",null,m.default.createElement(""div"",{style:{float:""left""}},e.mountpoint),m.default.createElement(""div"",{style:{float:""right""}},(0,d.default)(a="""".concat((0,y.formatSize)((0,i.default)(e.avail,10)),"" / "")).call(a,(0,y.formatSize)((0,i.default)(e.total,10))))),m.default.createElement(c.default,{style:{width:""95%""},percent:Number(((0,i.default)(e.avail,10)/(0,i.default)(e.total,10)*100).toFixed(3)),strokeColor:r}))})))}}];a.topCardList=_;var x=[{title:t(""CPU Usage(%)""),createFetchParams:{metricKey:""physicalNode.cpuUsage""},handleDataParams:{typeKey:""mode""},chartProps:{chartType:g.ChartType.MULTILINE}},{title:t(""Memory Usage""),createFetchParams:{metricKey:""physicalNode.memUsage""},handleDataParams:{modifyKeys:[t(""Used""),t(""Free"")]},chartProps:{scale:{y:{formatter:e=>(0,h.getSuitableValue)(e,""memory"",0)}},chartType:g.ChartType.MULTILINE}},{title:t(""DISK IOPS""),createFetchParams:{metricKey:""physicalNode.diskIOPS""},handleDataParams:{modifyKeys:[t(""read""),t(""write"")],deviceKey:""device""},chartProps:{chartType:g.ChartType.MULTILINEDEVICES}},{title:t(""DISK Usage(%)""),createFetchParams:{metricKey:""physicalNode.diskUsage""},handleDataParams:{typeKey:""hostname"",deviceKey:""device""},chartProps:{scale:{y:{alias:t(""DISK Usage(%)"")}},chartType:g.ChartType.ONELINEDEVICES}},{title:t(""System Load""),span:24,createFetchParams:{metricKey:""physicalNode.systemLoad""},handleDataParams:{typeKey:""__name__""},chartProps:{chartType:g.ChartType.MULTILINE}},{title:t(""Network Traffic""),span:12,createFetchParams:{metricKey:""physicalNode.networkTraffic""},handleDataParams:{modifyKeys:[t(""receive""),t(""transmit"")],deviceKey:""device""},chartProps:{chartType:g.ChartType.MULTILINEDEVICES,scale:{y:{formatter:e=>(0,h.getSuitableValue)(e,""traffic"",0)}}}},{title:t(""TCP Connections""),span:12,createFetchParams:{metricKey:""physicalNode.tcpConnections""},chartProps:{scale:{y:{alias:t(""TCP Connections"")}},chartType:g.ChartType.ONELINE}},{title:t(""Network Errors""),span:12,createFetchParams:{metricKey:""physicalNode.networkErrors""},handleDataParams:{typeKey:""__name__"",deviceKey:""device""},chartProps:{scale:{y:{alias:t(""Network Errors"")}},chartType:g.ChartType.ONELINE}},{title:t(""Network Dropped Packets""),span:12,createFetchParams:{metricKey:""physicalNode.networkDroppedPackets""},handleDataParams:{modifyKeys:[t(""receive""),t(""transmit"")],deviceKey:""device""},chartProps:{scale:{y:{alias:t(""Network Dropped Packets"")}},chartType:g.ChartType.MULTILINEDEVICES}}];a.chartCardList=x;var C={chartCardList:x,topCardList:_};a.chartConfig=C;var S=()=>m.default.createElement(v.default,{chartConfig:C});a.default=S},4031:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".styles__top-content--qpOa2 {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 120px;\n font-weight: 500;\n font-size: 24px;\n}\n"",""""]),t.locals={""top-content"":""styles__top-content--qpOa2""}},4032:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s,u=i(a(65)),o=i(a(27)),d=i(a(1400)),c=i(a(57)),f=i(a(409)),m=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=p(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0));function p(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(p=function(e){return e?a:t})(e)}var v=(0,a(406).observer)(s=class extends m.Component{constructor(e){super(e),this.state={visible:!window.IntersectionObserver},this.io=null,this.container=null}componentDidMount(){(window.IntersectionObserver?u.default.resolve():a.e(1).then(a.t.bind(null,4235,7))).then((()=>{this.io=new window.IntersectionObserver((e=>{(0,o.default)(e).call(e,(e=>{this.setState({visible:e.isIntersecting})}))}),{}),this.io.observe(this.container)}))}componentWillUnmount(){this.io&&this.io.disconnect()}render(){var e;return m.default.createElement(""div"",(0,f.default)({ref:e=>{this.container=e}},this.props),(0,d.default)(this.props.children)?(0,c.default)(e=this.props.children).call(e,(e=>e(this.state.visible))):this.props.children(this.state.visible))}})||s;t.default=v},4035:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".style__remove-extra-padding--1qIOH .ant-card-extra {\n padding: 0;\n}\n.style__remove-extra-padding--1qIOH .ant-card-head {\n border-bottom: none;\n}\n.style__remove-extra-padding--1qIOH .ant-card-body {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n}\n.style__remove-extra-padding--1qIOH .ant-card-body .ant-card-loading-content {\n width: 100%;\n}\n.style__base-content-container--2-qf6 {\n width: 100%;\n height: 100%;\n padding: 20px;\n overflow-y: scroll;\n}\n.style__base-content-container--2-qf6 .style__refresh--sME80 {\n float: left;\n}\n.style__base-content-container--2-qf6 .style__header--3xQ9T {\n margin-bottom: 16px;\n}\n"",""""]),t.locals={""remove-extra-padding"":""style__remove-extra-padding--1qIOH"",""base-content-container"":""style__base-content-container--2-qf6"",refresh:""style__refresh--sME80"",header:""style__header--3xQ9T""}},4036:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(409));r(333);var s=l(r(332));r(1317);var u=l(r(1318)),o=l(r(62)),d=l(r(593)),c=l(r(0)),f=(r(173),r(1295)),m=l(r(4037)),p=r(1209),v=r(4038),h=l(r(1604)),g=e=>{var{chartProps:a}=e;return c.default.createElement(h.default,(0,i.default)({},e,{renderContent:t=>{var r,{height:n,scale:l,chartType:i,toolTipProps:s=v.baseToolTipProps}=a,{data:u}=t;switch(l.x=(0,d.default)({},(0,p.getXScale)(e.fetchDataParams.currentRange),l.x||{}),i){case p.ChartType.ONELINE:case p.ChartType.ONELINEDEVICES:r=v.baseLineProps;break;case p.ChartType.MULTILINE:case p.ChartType.MULTILINEDEVICES:r=v.multilineProps;break;default:r=v.baseLineProps}return c.default.createElement(f.Chart,{autoFit:!0,padding:""auto"",data:u,height:n,scale:l},c.default.createElement(f.Line,r),c.default.createElement(f.Tooltip,s))},visibleHeight:e.chartProps.height,extra:()=>{var{title:n,createFetchParams:l,handleDataParams:i,fetchDataParams:d,isModal:f=!1}=e,p={},{params:v={}}=d,{instance:h,hostname:g}=v,y=(0,o.default)(v,[""instance"",""hostname""]);return v&&(h?p.instance=h:g&&(p.hostname=g)),c.default.createElement(c.default.Fragment,null,e.extra&&e.extra(),!f&&c.default.createElement(s.default,{type:""text"",icon:c.default.createElement(m.default,null),onClick:()=>{var s;u.default.info({icon:null,content:(s=r(1263).default,c.default.createElement(s,{renderNodeSelect:!1,defaultNode:{metric:p},visibleHeight:e.chartProps.height,chartConfig:{chartCardList:[{title:n,createFetchParams:l,handleDataParams:i,fetchDataParams:{params:y},chartProps:a,span:24,isModal:!0}]}})),width:1200,okText:t(""OK"")})}}))}}))};a.default=g},4038:function(e,t,a){""use strict"";a(19)(t,""__esModule"",{value:!0}),t.baseToolTipProps=t.multilineProps=t.baseLineProps=void 0;t.baseLineProps={position:""x*y""};t.multilineProps={position:""x*y"",color:""type""};t.baseToolTipProps={showCrosshairs:!0,shared:!0}},4039:function(e,a,r){""use strict"";var n=r(160),l=r(19),i=r(25),s=r(21);l(a,""__esModule"",{value:!0}),a.default=void 0;var u=s(r(57));r(560);var o=s(r(412)),d=(r(173),function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=f(t);if(a&&a.has(e))return a.get(e);var r={},n=l&&i;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=n?i(e,s):null;u&&(u.get||u.set)?l(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(r(0))),c=r(1209);function f(e){if(""function""!=typeof n)return null;var t=new n,a=new n;return(f=function(e){return e?a:t})(e)}var{Option:m}=o.default,p=e=>{var a=(0,c.getInterval)(e),[r,n]=(0,d.useState)(a[0].value),l=e=>{n(e)};(0,d.useEffect)((()=>{a=(0,c.getInterval)(e),l(a[0].value)}),[e]);return[r,()=>d.default.createElement(d.default.Fragment,null,d.default.createElement(""span"",{style:{marginLeft:20,fontSize:14,fontWeight:400,color:""rgba(0,0,0,.85)""}},t(""Time Interval: "")),d.default.createElement(o.default,{value:r,style:{width:120},onChange:l},(0,u.default)(a).call(a,(e=>d.default.createElement(m,{key:e.value,value:e.value},e.text)))))]};a.default=p},4040:function(e,a,r){""use strict"";var n=r(160),l=r(19),i=r(25),s=r(21);l(a,""__esModule"",{value:!0}),a.default=void 0,r(581);var u=s(r(423));r(1319);var o=s(r(1320)),d=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=m(t);if(a&&a.has(e))return a.get(e);var r={},n=l&&i;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=n?i(e,s):null;u&&(u.get||u.set)?l(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(r(0)),c=(r(173),s(r(119))),f=r(1209);function m(e){if(""function""!=typeof n)return null;var t=new n,a=new n;return(m=function(e){return e?a:t})(e)}var{RangePicker:p}=o.default;var v=function(e){var[a,r]=(0,d.useState)(0),[n,l]=(0,d.useState)(e),i=e=>{var t=e.target.value;r(t),l((0,f.getRange)(t))},s=e=>{r(4),l(e)};return[n,()=>d.default.createElement(u.default.Group,{value:a,onChange:i,style:{marginLeft:20}},d.default.createElement(u.default.Button,{value:0},t(""Last Hour"")),d.default.createElement(u.default.Button,{value:1},t(""Last Day"")),d.default.createElement(u.default.Button,{value:2},t(""Last 7 Days"")),d.default.createElement(u.default.Button,{value:3},t(""Last 2 Weeks"")),d.default.createElement(u.default.Button,{value:4,style:{float:""right"",padding:0}},d.default.createElement(p,{showTime:{hideDisabledOptions:!0,defaultValue:[(0,c.default)(""00:00:00"",""HH:mm:ss""),(0,c.default)(""00:00:00"",""HH:mm:ss"")]},disabledDate:g,disabledTime:h,onChange:s,value:n,bordered:!1,allowClear:!1}))),a,l]};function h(e){var t=(0,c.default)();if(t.isSame(e,""day""))return t.isSame(e,""hour"")?t.isSame(e,""minutes"")?{disabledHours:()=>y(t.hour()+1,24),disabledMinutes:()=>y(t.minute()+1,60),disabledSeconds:()=>y(t.second()+1,60)}:{disabledHours:()=>y(t.hour()+1,24),disabledMinutes:()=>y(t.minute()+1,60)}:{disabledHours:()=>y(t.hour()+1,24)}}function g(e){return e>(0,c.default)().endOf(""day"")}function y(e,t){for(var a=[],r=e;r<t;r++)a.push(r);return a}a.default=v},4041:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s=i(a(102)),u=i(a(57));a(560);var o=i(a(412)),d=i(a(111)),c=(a(173),function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=m(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0))),f=i(a(1416));function m(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(m=function(e){return e?a:t})(e)}var{Option:p}=o.default,v=e=>{var[t,a]=(0,c.useState)(e),[r,n]=(0,c.useState)([]),l=e=>{var t=i();a((0,s.default)(r).call(r,(a=>a.metric[t]===e)))};return[t,()=>{var e=i();return c.default.createElement(""div"",{className:f.default.header},c.default.createElement(""span"",{style:{color:""black"",fontSize:14,fontWeight:400}},""Node:"","" ""),c.default.createElement(o.default,{value:t.metric[e],onChange:l,style:{minWidth:150}},(0,u.default)(r).call(r,(t=>c.default.createElement(p,{key:t.metric[e],value:t.metric[e]},t.metric[e])))))},a,n];function i(){var e=""instance"";return(0,d.default)(t,""metric.hostname"",!1)&&(e=""hostname""),e}};t.default=v},4052:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(27)),s=l(r(81));r(1222);var u=l(r(1223));r(1198);var o=l(r(1199));r(1196);var d=l(r(1197)),c=l(r(111)),f=l(r(0)),m=(r(173),l(r(1263))),p=r(1352),v=l(r(1606)),h=r(1309),g=r(161),y=r(1209),b=l(r(4053)),_=l(r(4054)),x=()=>{var e=[{title:t(""Storage Cluster Status""),span:6,createFetchParams:{metricKey:""storageCluster.cephHealthStatus""},renderContent:e=>{var{data:t}=e,a=(0,c.default)(t,""y"",0);return f.default.createElement(""div"",{className:_.default[""top-content""],style:{fontSize:28,fontWeight:600,color:p.cephStatusColorMap[a]}},p.cephStatusMap[a])}},{title:""Monitors"",span:9,createFetchParams:{metricKey:""storageCluster.cephMonitorStatus""},handleDataParams:{formatDataFn:function(){var e=(0,h.handleResponses)(...arguments),t=[{type:""down"",value:0},{type:""up"",value:0}];return(0,i.default)(e).call(e,(e=>{var a=t[e.y].value+1;t[e.y].value=a})),t}},renderContent:e=>{var{data:t}=e;return f.default.createElement(""div"",null,f.default.createElement(""div"",{style:{height:120}},f.default.createElement(v.default,{data:t})))}},{title:""PGs"",span:9,createFetchParams:{metricKey:""storageCluster.cephPGS""},handleDataParams:{formatDataFn:function(){var e=(0,h.handleResponses)(...arguments);return[{type:""clean"",value:(0,c.default)(e,""[0].y"",0)},{type:""others"",value:(0,c.default)(e,""[1].y"",0)}]}},renderContent:e=>{var{data:t}=e;return f.default.createElement(""div"",null,f.default.createElement(""div"",{style:{height:120}},f.default.createElement(v.default,{data:t})))}},{title:""OSDs"",span:9,createFetchParams:{metricKey:""storageCluster.osdData""},handleDataParams:{formatDataFn:e=>{function t(e){return(0,c.default)(e,""data.result[0].value[1]"",0)}var[a,r,n,l]=e;return{inUp:t(a),inDown:t(r),outUp:t(n),outDown:t(l)}}},renderContent:e=>{var{data:a}=e;return f.default.createElement(o.default,{className:_.default.osd},f.default.createElement(d.default,{span:8}),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""Up"")),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""Down"")),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""In Cluster"")),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.inUp),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.inDown),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""Out Cluster"")),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.outUp),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.outDown))}},{title:t(""Average PGs per OSD""),span:5,createFetchParams:{metricKey:""storageCluster.avgPerOSD""}},{title:t(""Storage Cluster Usage""),span:10,createFetchParams:{metricKey:""storageCluster.storageClusterUsage""},renderContent:e=>{var a,r,n,{data:l}=e,i=(0,c.default)(l[0],""y"",0),d=(0,c.default)(l[1],""y"",0),m=(0,p.getSuitableValue)(i,""disk""),v=(0,p.getSuitableValue)(d,""disk""),h=(0,g.computePercentage)(i,d);return f.default.createElement(""div"",{className:_.default[""top-content""]},f.default.createElement(""div"",{style:{width:""100%"",height:""100%""}},f.default.createElement(o.default,{style:{justifyContent:""flex-end"",height:""50%""}},f.default.createElement(""span"",{style:{fontSize:12,marginRight:32}},(0,s.default)(a=(0,s.default)(r=(0,s.default)(n="""".concat(t(""Used""),"" "")).call(n,m,"" / "")).call(r,t(""Total""),"" "")).call(a,v))),f.default.createElement(o.default,{style:{height:""50%""}},f.default.createElement(u.default,{style:{width:""95%""},percent:h,strokeColor:h>80?""#FAAD14"":""#1890FF"",showInfo:100!==h}))))}}],a={chartCardList:[{title:t(""Storage Pool Capacity Usage""),createFetchParams:{metricKey:""storageCluster.poolCapacityUsage""},handleDataParams:{modifyKeys:[t(""used""),t(""available"")]},chartProps:{chartType:y.ChartType.MULTILINE,scale:{y:{formatter:e=>(0,p.getSuitableValue)(e,""disk"",0)}}}},{title:t(""Storage Cluster OSD Latency""),createFetchParams:{metricKey:""storageCluster.clusterOSDLatency""},handleDataParams:{modifyKeys:[""apply"",""commit""]},chartProps:{chartType:y.ChartType.MULTILINE}},{title:t(""Storage Cluster IOPS""),createFetchParams:{metricKey:""storageCluster.clusterIOPS""},handleDataParams:{modifyKeys:[t(""read""),t(""write"")]},chartProps:{chartType:y.ChartType.MULTILINE}},{title:t(""Storage Cluster Bandwidth""),createFetchParams:{metricKey:""storageCluster.clusterBandwidth""},handleDataParams:{modifyKeys:[t(""in""),t(""out"")]},chartProps:{scale:{y:{formatter:e=>(0,p.getSuitableValue)(e,""bandwidth"",0)}},chartType:y.ChartType.MULTILINE}}],topCardList:e};return f.default.createElement(m.default,{renderNodeSelect:!1,chartConfig:a},f.default.createElement(b.default,null))};a.default=x},4053:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(160),m=r(21);c(a,""__esModule"",{value:!0}),a.default=void 0;var p=m(r(27)),v=m(r(419)),h=m(r(32)),g=m(r(33)),y=m(r(57)),b=m(r(1338)),_=m(r(90)),x=m(r(229)),C=m(r(65)),S=m(r(62)),D=m(r(51)),w=m(r(36));r(1260);var E=m(r(1261)),I=m(r(111)),P=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=A(t);if(a&&a.has(e))return a.get(e);var r={},n=c&&s;for(var l in e)if(""default""!==l&&Object.prototype.hasOwnProperty.call(e,l)){var i=n?s(e,l):null;i&&(i.get||i.set)?c(r,l,i):r[l]=e[l]}r.default=e,a&&a.set(e,r);return r}(r(0)),T=(r(173),r(1415)),k=m(r(1530)),N=r(1209),M=r(161),L=m(r(429)),F=m(r(1417));function A(e){if(""function""!=typeof f)return null;var t=new f,a=new f;return(A=function(e){return e?a:t})(e)}function O(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function z(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=O(Object(r),!0)).call(a,(function(t){(0,w.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=O(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var{TabPane:j}=E.default,K=()=>{var[e,a]=(0,P.useState)({}),[r,n]=(0,P.useState)([]),[l,i]=(0,P.useState)([]),[s,u]=(0,P.useState)(""pool""),[o,d]=(0,P.useState)(!0),c=(0,P.useContext)(F.default),f=(0,T.createFetchPrometheusClient)({requestType:""current"",metricKey:""storageCluster.tabs""}),m=(0,T.createDataHandler)({modifyKeys:[""pools"",""osds""],formatDataFn:e=>{var t,a,r=[],[n,l]=e;return(0,p.default)(t=(0,I.default)(n,""data.result"",[])).call(t,(e=>{var{metric:t,value:a}=e;r.push(z(z({type:""pool""},t),{},{value:(0,v.default)(a[1])||0}))})),(0,p.default)(a=(0,I.default)(l,""data.result"",[])).call(a,(e=>{var{metric:t,value:a}=e;r.push(z(z({type:""osd""},t),{},{value:(0,v.default)(a[1])||0}))})),r}});function w(t){var a,r=(0,h.default)(t).call(t,(e=>e.type===s));(0,p.default)(a=(0,g.default)(e)).call(a,(t=>{r=(0,h.default)(r).call(r,(a=>a[t]===e[t]))})),i(r)}function M(e){return A.apply(this,arguments)}function A(){return(A=(0,D.default)((function*(e){var t,a,r=[...e],n=(0,y.default)(t=(0,I.default)(METRICDICT,""storageCluster.poolTab.url"",[])).call(t,(e=>(0,N.fetchPrometheus)(e,""current""))),l=(0,y.default)(a=(0,I.default)(METRICDICT,""storageCluster.osdTab.url"",[])).call(a,(e=>(0,N.fetchPrometheus)(e,""current"")));function i(e,t,a){var n;(0,p.default)(n=e.data.result).call(n,(e=>{var n,{metric:l,value:i}=e,s=(0,b.default)(r).call(r,(e=>e[a]===l[a]));3===t?r[s].usage=(0,v.default)((0,v.default)(i[1]).toFixed(2)):(0,_.default)(n=[""ceph_pool_objects"",""ceph_pg_total"",""ceph_pool_max_avail"",""ceph_osd_weight"",""ceph_osd_apply_latency_ms"",""ceph_osd_commit_latency_ms"",""ceph_osd_stat_bytes""]).call(n,l.__name__)>-1?r[s][l.__name__]=(0,x.default)(i[1],10):r[s][l.__name__]=i[1]}))}var s=yield C.default.all(n);(0,p.default)(s).call(s,((e,t)=>{i(e,t,""pool_id"")}));var u=yield C.default.all(l);return(0,p.default)(u).call(u,((e,t)=>{i(e,t,""ceph_daemon"")})),r}))).apply(this,arguments)}function O(){return(O=(0,D.default)((function*(){d(!0);var e=yield f({currentRange:c.range,interval:c.interval}),{retData:t}=m(e),a=yield M(t);n(a),w(a),d(!1)}))).apply(this,arguments)}(0,P.useEffect)((()=>{!function(){O.apply(this,arguments)}()}),[]),(0,P.useEffect)((()=>{w(r)}),[s,e]);var K=""pool""===s?R:U;return P.default.createElement(P.default.Fragment,null,P.default.createElement(E.default,{defaultActiveKey:""pool"",onChange:e=>{a({}),u(e)}},P.default.createElement(j,{tab:""Pools"",key:""pool""}),P.default.createElement(j,{tab:""OSDs"",key:""osd""})),P.default.createElement(k.default,{isLoading:o,resourceName:""pool""===s?t(""Pools""):t(""OSDs""),rowKey:""pool""===s?""pool_id"":""name"",columns:K,data:l,pagination:z(z({},new L.default),{},{total:l.length}),hideRefresh:!0,searchFilters:""pool""===s?[{label:t(""Pool Name""),name:""name""}]:[{label:t(""Name""),name:""ceph_daemon""}],itemActions:[],onFilterChange:e=>{var{limit:t,page:r,sortKey:n,sortOrder:l}=e,i=(0,S.default)(e,[""limit"",""page"",""sortKey"",""sortOrder""]);a(i)}}))};a.default=K;var R=[{title:t(""Pool Name""),dataIndex:""name""},{title:t(""PG Count""),dataIndex:""ceph_pg_total"",isHideable:!0},{title:t(""Object Count ""),dataIndex:""ceph_pool_objects"",isHideable:!0},{title:t(""Max Avail""),dataIndex:""ceph_pool_max_avail"",render:e=>(0,M.formatSize)(e),isHideable:!0},{title:t(""Usage""),dataIndex:""usage"",render:e=>"""".concat(e,""%""),isHideable:!0}],U=[{title:t(""Name""),dataIndex:""ceph_daemon""},{title:t(""Status""),dataIndex:""ceph_osd_up"",render:e=>""1""===e?t(""Up""):t(""Down""),isHideable:!0},{title:t(""Instance Addr""),dataIndex:""cluster_addr"",isHideable:!0},{title:t(""Weight""),dataIndex:""ceph_osd_weight"",isHideable:!0},{title:t(""Apply Latency(ms)""),dataIndex:""ceph_osd_apply_latency_ms"",isHideable:!0},{title:t(""Commit Latency(ms)""),dataIndex:""ceph_osd_commit_latency_ms"",isHideable:!0},{title:t(""Total Capacity""),dataIndex:""ceph_osd_stat_bytes"",render:e=>(0,M.formatSize)(e),isHideable:!0},{title:t(""Usage""),dataIndex:""usage"",render:e=>"""".concat((0,v.default)(e).toFixed(2),""%""),isHideable:!0}]},4054:function(e,t,a){var r=a(4055);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},4055:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__osd--2HtuM {\n height: 100%;\n color: rgba(0, 0, 0, 0.85);\n font-weight: 500;\n font-size: 16px;\n text-align: center;\n}\n.index__header--246Eo {\n padding: 20px;\n overflow: auto;\n}\n.index__header--246Eo .index__range--3UhTc .ant-radio-button-wrapper {\n color: rgba(0, 0, 0, 0.65);\n}\n.index__header--246Eo .index__range--3UhTc .ant-radio-button-wrapper-checked {\n color: #0068ff;\n}\n.index__header--246Eo .index__download--21jst {\n float: right;\n}\n.index__header--246Eo .index__download--21jst .ant-btn-icon-only {\n border-radius: 4px;\n}\n.index__my-card-row--rBTsX .index__top--3Nx2m .index__content--2R7tG {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 100%;\n font-size: 24px;\n text-align: center;\n}\n.index__my-card-row--rBTsX .index__top--3Nx2m .ant-card-bordered {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-orient: vertical;\n -webkit-box-direction: normal;\n -ms-flex-direction: column;\n flex-direction: column;\n}\n.index__my-card-row--rBTsX .index__top--3Nx2m .ant-card-bordered .ant-card-body {\n -webkit-box-flex: 1;\n -ms-flex-positive: 1;\n flex-grow: 1;\n padding-top: 0;\n overflow: hidden;\n}\n.index__my-card-row--rBTsX .ant-card-bordered {\n -webkit-box-shadow: 0 2px 20px 0 rgba(0, 0, 0, 0.09);\n box-shadow: 0 2px 20px 0 rgba(0, 0, 0, 0.09);\n}\n.index__my-card-row--rBTsX .ant-card-bordered .ant-card-head {\n border-bottom: none;\n}\n.index__outer--3mHPU {\n position: relative;\n width: 100%;\n height: 100%;\n overflow: hidden;\n font-size: 12px;\n}\n.index__outer--3mHPU .index__inner--1HrRB {\n position: absolute;\n left: 0;\n width: 100%;\n height: 100%;\n overflow-x: hidden;\n overflow-y: scroll;\n}\n.index__outer--3mHPU .index__inner--1HrRB::-webkit-scrollbar {\n display: none;\n}\n.index__top-content--2QZJv {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 120px;\n font-weight: 500;\n font-size: 24px;\n}\n.index__tabs--1be8Z .ant-tabs-tab {\n margin-right: 20px;\n border-bottom: 1px solid #f0f0f0;\n}\n.index__tabs--1be8Z .ant-tabs-nav::before {\n border-bottom: none;\n}\n.index__spin-container--2aH9q {\n width: 100%;\n min-height: 400px;\n padding: 30px 50px;\n text-align: center;\n}\n"",""""]),t.locals={osd:""index__osd--2HtuM"",header:""index__header--246Eo"",range:""index__range--3UhTc"",download:""index__download--21jst"",""my-card-row"":""index__my-card-row--rBTsX"",top:""index__top--3Nx2m"",content:""index__content--2R7tG"",outer:""index__outer--3mHPU"",inner:""index__inner--1HrRB"",""top-content"":""index__top-content--2QZJv"",tabs:""index__tabs--1be8Z"",""spin-container"":""index__spin-container--2aH9q""}},4056:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(160),m=r(21);c(a,""__esModule"",{value:!0}),a.default=a.OpenstackService=void 0;var p=m(r(562));r(333);var v=m(r(332)),h=m(r(1273)),g=m(r(51)),y=m(r(36)),b=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=w(t);if(a&&a.has(e))return a.get(e);var r={},n=c&&s;for(var l in e)if(""default""!==l&&Object.prototype.hasOwnProperty.call(e,l)){var i=n?s(e,l):null;i&&(i.get||i.set)?c(r,l,i):r[l]=e[l]}r.default=e,a&&a.set(e,r);return r}(r(0)),_=r(406),x=r(4057),C=(r(555),r(173),m(r(140))),S=m(r(4059)),D=m(r(1607));function w(e){if(""function""!=typeof f)return null;var t=new f,a=new f;return(w=function(e){return e?a:t})(e)}function E(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function I(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=E(Object(r),!0)).call(a,(function(t){(0,y.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=E(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}class P extends b.Component{constructor(e){var t;super(e),t=this,(0,y.default)(this,""getData"",(0,g.default)((function*(){yield t.store.getChartData()}))),(0,y.default)(this,""handleRefresh"",(()=>{this.getData()}));var{Store:a=x.OpenstackServiceStore}=e;this.store=new a}componentDidMount(){this.getData()}get enableCinder(){return C.default.checkEndpoint(""cinder"")}render(){var{nova_service:e,network_service:a,other_service:r,cinder_service:n}=this.store,l=[I({key:""nova_service"",title:t(""Nova Service"")},e),I({key:""network_service"",title:t(""Neutron Service"")},a),I({key:""other_service"",title:t(""Other Service"")},r)];return this.enableCinder&&(0,p.default)(l).call(l,2,0,I({key:""cinder_service"",title:t(""Cinder Service"")},n)),b.default.createElement(""div"",{className:D.default.container},b.default.createElement(v.default,{type:""default"",icon:b.default.createElement(h.default,null),onClick:this.handleRefresh}),b.default.createElement(S.default,{serviceMap:l}))}}a.OpenstackService=P;var T=(0,_.observer)(P);a.default=T},4057:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.OpenstackServiceStore=void 0;var i,s,u,o,d,c,f,m,p,v,h=l(r(65)),g=l(r(27)),y=l(r(1338)),b=l(r(51)),_=l(r(71)),x=(l(r(36)),l(r(54))),C=(l(r(72)),r(34)),S=r(1209),D=l(r(4058)),w={mysql_up:t(""Database Service""),rabbitmq_identity_info:t(""Message Queue Service""),memcached_up:t(""Cache Service"")},E=[t(""Database Service""),t(""Message Queue Service""),t(""Cache Service"")],I=(i=class extends D.default{constructor(){super(...arguments),(0,_.default)(this,""nova_service"",s,this),(0,_.default)(this,""network_service"",u,this),(0,_.default)(this,""cinder_service"",o,this),(0,_.default)(this,""other_service"",d,this),(0,_.default)(this,""getChartData"",c,this),(0,_.default)(this,""getNovaService"",f,this),(0,_.default)(this,""getNetworkService"",m,this),(0,_.default)(this,""getCinderService"",p,this),(0,_.default)(this,""getOtherService"",v,this)}},s=(0,x.default)(i.prototype,""nova_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),u=(0,x.default)(i.prototype,""network_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),o=(0,x.default)(i.prototype,""cinder_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),d=(0,x.default)(i.prototype,""other_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),c=(0,x.default)(i.prototype,""getChartData"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){var t=[e.getNovaService(),e.getNetworkService(),e.getCinderService(),e.getOtherService()];yield h.default.all(t)}))}}),f=(0,x.default)(i.prototype,""getNovaService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.nova_service,{isLoading:!0,data:[]});var t=[];try{var[a,r,n,l]=yield h.default.all((0,S.getPromises)(""openstackService.novaService"")),{data:{result:i}}=a;(0,g.default)(i).call(i,(e=>{var{metric:{service:a="""",adminState:r="""",hostname:n=""""}={}}=e;t.push({hostname:n,serviceName:a,state:""enabled""===r?""up"":""down""})}));var{data:{result:s}}=r;(0,g.default)(s).call(s,(e=>{var{metric:{service:a="""",hostname:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===a&&e.hostname===r));t[n]["""".concat(a,""24"")]=""down""}));var{data:{result:u}}=n;(0,g.default)(u).call(u,(e=>{var{metric:a,value:r}=e;t.push({serviceName:""nova_libvirt"",hostname:a.hostname,state:""enabled""===r[1]?""up"":""down""})}));var{data:{result:o}}=l;(0,g.default)(o).call(o,(e=>{var{metric:{hostname:a=""""}={}}=e,r=(0,y.default)(t).call(t,(e=>""nova_libvirt""===e.serviceName&&e.hostname===a));t[r].nova_libvirt24=""down""}))}finally{(0,C.set)(e.nova_service,{isLoading:!1,data:t})}}))}}),m=(0,x.default)(i.prototype,""getNetworkService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.network_service,{isLoading:!0,data:[]});var t=[];try{var[a,r]=yield h.default.all(S.getPromises.call(e,""openstackService.networkService"")),{data:{result:n}}=a;(0,g.default)(n).call(n,(e=>{var{metric:{service:a="""",adminState:r="""",hostname:n=""""}={}}=e;t.push({serviceName:a,hostname:n,state:r})}));var{data:{result:l}}=r;(0,g.default)(l).call(l,(e=>{var{metric:{service:a="""",hostname:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===a&&e.hostname===r));t[n]["""".concat(a,""24"")]=""down""}))}finally{(0,C.set)(e.network_service,{isLoading:!1,data:t})}}))}}),p=(0,x.default)(i.prototype,""getCinderService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.cinder_service,{isLoading:!0,data:[]});var t=[];try{var[a,r]=yield h.default.all(S.getPromises.call(e,""openstackService.cinderService"")),{data:{result:n}}=a;(0,g.default)(n).call(n,(e=>{var{metric:{service:a="""",adminState:r="""",hostname:n=""""}={}}=e;t.push({serviceName:a,hostname:n,state:""enabled""===r?""up"":""down""})}));var{data:{result:l}}=r;(0,g.default)(l).call(l,(e=>{var{metric:{service:a="""",hostname:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===a&&e.hostname===r));t[n]["""".concat(a,""24"")]=""down""}))}finally{(0,C.set)(e.cinder_service,{isLoading:!1,data:t})}}))}}),v=(0,x.default)(i.prototype,""getOtherService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.other_service,{isLoading:!0,data:[]});var t=[];try{var a=yield h.default.all(S.getPromises.call(e,""openstackService.otherService""));(0,g.default)(a).call(a,(e=>{var{data:{result:a}}=e;(0,g.default)(a).call(a,(e=>{var{metric:a,value:r}=e;t.push({serviceName:w[a.__name__],hostname:a.instance,state:""1""===r[1]?""up"":""down""})}))})),a=yield h.default.all(S.getPromises.call(e,""openstackService.otherServiceMinOverTime"")),(0,g.default)(a).call(a,((e,a)=>{var{data:{result:r}}=e;(0,g.default)(r).call(r,(e=>{var{metric:{instance:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===E[a]&&e.hostname===r));t[n]["""".concat(E[a],""24"")]=""down""}))}))}finally{(0,C.set)(e.other_service,{isLoading:!1,data:t})}}))}}),i);a.OpenstackServiceStore=I;var P=new I;a.default=P},4058:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l,i,s,u,o,d,c,f=n(a(419)),m=n(a(229)),p=n(a(33)),v=n(a(25)),h=n(a(32)),g=n(a(580)),y=n(a(51)),b=n(a(71)),_=(n(a(36)),n(a(54))),x=(n(a(72)),a(34)),C=a(1209),S=a(569),D=n(a(53)),w=(l=class extends D.default{constructor(){super(...arguments),(0,b.default)(this,""currentRange"",i,this),(0,b.default)(this,""interval"",s,this),(0,b.default)(this,""loading"",u,this),(0,b.default)(this,""handleRangePickerChange"",o,this),(0,b.default)(this,""handleIntervalChange"",d,this),(0,b.default)(this,""handleDeviceChange"",c,this)}get responseKey(){return""""}get intervals(){return(0,C.getInterval)(this.currentRange)}formatToGiB(e){return(0,f.default)(((0,m.default)(e,10)/1073741824).toFixed(2))}buildRequest(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""range"",a=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},r=0===(0,p.default)(a).length?e:(0,C.addParams)(e,a);return""current""===t?this.skylineClient.query.list({query:r}):this.skylineClient.queryRange.list({query:r,start:(0,S.getTimestamp)(this.currentRange[0]),end:(0,S.getTimestamp)(this.currentRange[1]),step:this.interval})}},i=(0,_.default)(l.prototype,""currentRange"",[x.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return(0,C.defaultOneHourAgo)()}}),s=(0,_.default)(l.prototype,""interval"",[x.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return 10}}),u=(0,_.default)(l.prototype,""loading"",[x.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return!0}}),o=(0,_.default)(l.prototype,""handleRangePickerChange"",[x.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){var t=(0,y.default)((function*(t){var a=arguments.length>1&&void 0!==arguments[1]&&arguments[1];a||(0,S.getTimestamp)(e.currentRange[0])===(0,S.getTimestamp)(t[0])&&(0,S.getTimestamp)(e.currentRange[1])===(0,S.getTimestamp)(t[1])?e.currentRange=t:(e.currentRange=t,e.interval=e.intervals[0].value),yield e.getChartData()}));return function(e){return t.apply(this,arguments)}}()}}),(0,_.default)(l.prototype,""intervals"",[x.computed],(0,v.default)(l.prototype,""intervals""),l.prototype),d=(0,_.default)(l.prototype,""handleIntervalChange"",[x.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){var t=(0,y.default)((function*(t){e.interval=t,yield e.getChartData()}));return function(e){return t.apply(this,arguments)}}()}}),c=(0,_.default)(l.prototype,""handleDeviceChange"",[x.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return(e,t)=>{var a,r=this[t];(0,x.set)(r,{isLoading:!0});var n=(0,h.default)(a=r.data).call(a,(t=>t.device===e));(0,g.default)((()=>{(0,x.set)(r,{currentDevice:e,currentShowData:n,isLoading:!1})}),200)}}}),l);t.default=w},4059:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(57));r(1394);var s=l(r(1329));r(1196);var u=l(r(1197));r(411);var o=l(r(227)),d=l(r(1522)),c=l(r(1521));r(1404);var f=l(r(1405)),m=l(r(0)),p=(r(173),r(555),l(r(1607))),{Panel:v}=f.default,h={up:m.default.createElement(c.default,{style:{fontSize:24,marginLeft:36},twoToneColor:""#52C41A""}),down:m.default.createElement(d.default,{style:{fontSize:24,marginLeft:36},twoToneColor:""#EB354D""})},g=e=>{var{serviceMap:a}=e;return m.default.createElement(f.default,{defaultActiveKey:(0,i.default)(a).call(a,(e=>e.key)),ghost:!0},(0,i.default)(a).call(a,(e=>m.default.createElement(v,{header:m.default.createElement(""span"",{className:p.default.header},e.title),key:e.key},m.default.createElement(s.default,{bordered:!0,dataSource:e.data,className:p.default.list,loading:e.isLoading,renderItem:e=>m.default.createElement(s.default.Item,{className:p.default.item},m.default.createElement(u.default,{className:p.default.title,span:6},e.engine_id?m.default.createElement(o.default,{title:e.engine_id},m.default.createElement(""span"",null,e.serviceName)):e.serviceName),m.default.createElement(u.default,{className:p.default.title,span:6},e.hostname||e.host),m.default.createElement(u.default,{className:p.default.status,span:6},m.default.createElement(""span"",null,t(""Current Status"")),h[e.state]),m.default.createElement(u.default,{className:p.default.status,span:6},m.default.createElement(""span"",null,t(""Last 24H Status""),"" ""),e["""".concat(e.serviceName,""24"")]?h[e["""".concat(e.serviceName,""24"")]]:h.up))})))))};a.default=g},4060:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__header--2Tct3 {\n color: rgba(0, 0, 0, 0.85);\n font-weight: 500;\n font-size: 16px;\n line-height: 22px;\n}\n.index__list--AK4zu {\n background-color: #fff;\n border: none;\n -webkit-box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n}\n.index__list--AK4zu .index__item--2Dqsf {\n height: 76px;\n}\n.index__list--AK4zu .index__item--2Dqsf .index__title--Tai7z {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 16px;\n}\n.index__list--AK4zu .index__item--2Dqsf .index__status--2Ke1i {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 14px;\n}\n.index__container--22t9I {\n height: 100%;\n padding: 16px;\n overflow: auto;\n}\n"",""""]),t.locals={header:""index__header--2Tct3"",list:""index__list--AK4zu"",item:""index__item--2Dqsf"",title:""index__title--Tai7z"",status:""index__status--2Ke1i"",container:""index__container--22t9I""}},4061:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=t.OtherService=void 0,a(581);var s=i(a(423)),u=i(a(36)),o=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=v(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0)),d=a(406),c=(a(173),i(a(4062))),f=i(a(4063)),m=i(a(4064)),p=i(a(4065));function v(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(v=function(e){return e?a:t})(e)}class h extends o.Component{constructor(e){super(e),(0,u.default)(this,""handleTypeChange"",(e=>{this.setState({type:e.target.value})})),(0,u.default)(this,""renderTypeSelect"",(()=>{var{type:e}=this.state;return o.default.createElement(s.default.Group,{onChange:this.handleTypeChange,value:e},o.default.createElement(s.default.Button,{value:""mysql""},""MySQL""),o.default.createElement(s.default.Button,{value:""memcache""},""Memcache""),o.default.createElement(s.default.Button,{value:""rabbitmq""},""RabbitMQ""))})),(0,u.default)(this,""renderSelectTab"",(()=>{var{type:e}=this.state,t=null;switch(e){case""mysql"":t=c.default;break;case""memcache"":t=m.default;break;case""rabbitmq"":t=f.default;break;default:t=c.default}return o.default.createElement(t,{type:e})})),this.state={type:""mysql""}}render(){return o.default.createElement(""div"",{className:p.default.container},o.default.createElement(""div"",{style:{padding:""20px 20px 0 20px""}},this.renderTypeSelect()),o.default.createElement(""div"",{className:p.default.content},this.renderSelectTab()))}}t.OtherService=h;var g=(0,d.observer)(h);t.default=g},4062:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=void 0;var i=l(r(111)),s=l(r(0)),u=l(r(1263)),o=r(1351),d=r(161),c=l(r(1350)),f=r(1209),m={topCardList:[{title:t(""Running Time""),span:6,createFetchParams:{metricKey:""mysqlService.runningTime""},renderContent:e=>{var{data:t}=e;return s.default.createElement(""div"",{className:c.default[""top-content""]},(0,d.formatUsedTime)(1e3*(0,i.default)(t,""[0].y"",0)))}},{title:t(""Connected Threads""),span:6,createFetchParams:{metricKey:""mysqlService.connectedThreads""}},{title:t(""Running Threads""),span:6,createFetchParams:{metricKey:""mysqlService.runningThreads""}},{title:t(""Slow Query""),span:6,createFetchParams:{metricKey:""mysqlService.slowQuery""}}],chartCardList:[{title:t(""Threads Activity Trends""),createFetchParams:{metricKey:""mysqlService.threadsActivityTrends_connected""},chartProps:{chartType:f.ChartType.ONELINE,scale:{y:{alias:t(""Threads Activity Trends"")}}}},{title:t(""MySQL Actions""),createFetchParams:{metricKey:""mysqlService.mysqlActions""},handleDataParams:{modifyKeys:[t(""delete""),t(""insert""),t(""update"")]},chartProps:{chartType:f.ChartType.MULTILINE,scale:{y:{alias:t(""MySQL Actions"")}}}},{title:t(""Slow Query""),createFetchParams:{metricKey:""mysqlService.slowQueryChart""},chartProps:{chartType:f.ChartType.ONELINE,scale:{y:{alias:t(""Slow Query"")}}}}]};a.chartConfig=m;a.default=e=>{var{type:t}=e;return s.default.createElement(u.default,{type:t,chartConfig:m,fetchNodesFunc:o.getMysqlNodes})}},4063:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=void 0;var i=l(r(27)),s=l(r(229));r(1198);var u=l(r(1199));r(1196);var o=l(r(1197)),d=l(r(111)),c=l(r(0)),f=(r(173),l(r(1263))),m=r(1351),p=r(1209),v=l(r(1350)),h={topCardList:[{title:t(""Server Status""),createFetchParams:{metricKey:""rabbitMQService.serviceStatus""},handleDataParams:{formatDataFn:e=>{var t={up:0,down:0},a=(0,d.default)(e[0],""data.result"",[]);return(0,i.default)(a).call(a,(e=>{1===(0,s.default)(e.value[1],10)?t.up+=1:t.down+=1})),t}},renderContent:e=>{var{data:a}=e;return c.default.createElement(""div"",{className:v.default[""top-content""]},c.default.createElement(u.default,{style:{width:""100%"",textAlign:""center""}},c.default.createElement(o.default,{span:12},a.up+t(""Up"")),c.default.createElement(o.default,{span:12},a.down+t(""Down""))))}},{title:t(""Connected Threads""),createFetchParams:{metricKey:""rabbitMQService.totalConnections""}},{title:t(""Total Queues""),createFetchParams:{metricKey:""rabbitMQService.totalQueues""}},{title:t(""Total Exchanges""),createFetchParams:{metricKey:""rabbitMQService.totalExchanges""}},{title:t(""Total Consumers""),createFetchParams:{metricKey:""rabbitMQService.totalConsumers""}}],chartCardList:[{title:t(""Published Out""),createFetchParams:{metricKey:""rabbitMQService.publishedOut""},chartProps:{chartType:p.ChartType.ONELINE,scale:{y:{alias:t(""Published Out"")}}}},{title:t(""Published In""),createFetchParams:{metricKey:""rabbitMQService.publishedIn""},chartProps:{chartType:p.ChartType.ONELINE,scale:{y:{alias:t(""Published In"")}}}},{title:t(""Channel""),createFetchParams:{metricKey:""rabbitMQService.channel""},chartProps:{chartType:p.ChartType.ONELINE,scale:{y:{alias:t(""Channel"")}}}}]};a.chartConfig=h;a.default=e=>{var{type:t}=e;return c.default.createElement(f.default,{type:t,chartConfig:h,fetchNodesFunc:m.getRabbitMQNodes})}},4064:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=void 0;var i=l(r(0)),s=l(r(1263)),u=r(1351),o=r(1209),d=r(1352),c={chartCardList:[{title:t(""Current Connections""),createFetchParams:{metricKey:""memcacheService.currentConnections""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Current Connections"")}}}},{title:t(""Total Connections""),createFetchParams:{metricKey:""memcacheService.totalConnections""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Total Connections"")}}}},{title:t(""Read and write""),createFetchParams:{metricKey:""memcacheService.readWriteBytesTotal""},handleDataParams:{modifyKeys:[t(""read""),t(""write"")]},chartProps:{chartType:o.ChartType.MULTILINE,scale:{y:{formatter:e=>(0,d.getSuitableValue)(e,""traffic"",0)}}}},{title:t(""Evictions""),createFetchParams:{metricKey:""memcacheService.evictions""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Evictions"")}}}},{title:t(""Items in Cache""),createFetchParams:{metricKey:""memcacheService.itemsInCache""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Items in Cache"")}}}}]};a.chartConfig=c;a.default=e=>{var{type:t}=e;return i.default.createElement(s.default,{type:t,chartConfig:c,fetchNodesFunc:u.getMemcacheNodes})}},4065:function(e,t,a){var r=a(4066);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},4066:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__header--2QIxy {\n color: rgba(0, 0, 0, 0.85);\n font-weight: 500;\n font-size: 16px;\n line-height: 22px;\n}\n.index__list--2MUu4 {\n background-color: #fff;\n -webkit-box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n}\n.index__list--2MUu4 .index__item--vVdTT {\n height: 76px;\n}\n.index__list--2MUu4 .index__item--vVdTT .index__title--13rNn {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 16px;\n}\n.index__list--2MUu4 .index__item--vVdTT .index__status--1Jr4w {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 14px;\n}\n.index__container--12Azg {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-orient: vertical;\n -webkit-box-direction: normal;\n -ms-flex-direction: column;\n flex-direction: column;\n height: 100%;\n}\n.index__container--12Azg .index__content--50gtm {\n -webkit-box-flex: 1;\n -ms-flex-positive: 1;\n flex-grow: 1;\n overflow: auto;\n}\n"",""""]),t.locals={header:""index__header--2QIxy"",list:""index__list--2MUu4"",item:""index__item--vVdTT"",title:""index__title--13rNn"",status:""index__status--1Jr4w"",container:""index__container--12Azg"",content:""index__content--50gtm""}},4067:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0,a(1198);var l=n(a(1199));a(1196);var i=n(a(1197)),s=n(a(0)),u=n(a(1263)),o=(a(173),n(a(1603))),d=a(1309),c=n(a(1353)),f=n(a(4069)),m=a(4070),p={renderNodeSelect:!1,renderTimeRangeSelect:!1},v=()=>s.default.createElement(u.default,p,s.default.createElement(l.default,{gutter:[16,16],className:c.default.container},s.default.createElement(i.default,{span:24},s.default.createElement(f.default,null)),s.default.createElement(i.default,{span:24},s.default.createElement(l.default,{gutter:[16,16]},s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{topCardList:m.physicalNodeLeftTopCardList})),s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{topCardList:m.physicalNodeRightTopCardList})))),s.default.createElement(i.default,{span:24},s.default.createElement(o.default,{baseTopCardProps:{span:12,createFetchParams:{requestType:""current""},handleDataParams:{formatDataFn:d.handleResponses},visibleHeight:200,renderContent:e=>s.default.createElement(""div"",{className:c.default[""top-content""]},e.data)},topCardList:m.topCardList})),s.default.createElement(i.default,{span:24},s.default.createElement(l.default,{gutter:[16,16]},s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{topCardList:m.storageLeftCardList})),s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{chartCardList:m.storageRightChartList}))))));t.default=v},4068:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__container--10N7f .index__card--3LuCF {\n height: 100%;\n padding: 16px;\n color: #000;\n background-color: #fff;\n -webkit-box-shadow: 0 0 8px 0 rgba(0, 0, 0, 0.05), 0 0 10px 0 rgba(0, 0, 0, 0.05);\n box-shadow: 0 0 8px 0 rgba(0, 0, 0, 0.05), 0 0 10px 0 rgba(0, 0, 0, 0.05);\n}\n.index__container--10N7f .index__card--3LuCF .index__tabs--1jk3S .ant-tabs-tab {\n margin-right: 20px;\n border-bottom: 1px solid #f0f0f0;\n}\n.index__container--10N7f .index__card--3LuCF .index__tabs--1jk3S .ant-tabs-nav::before {\n border-bottom: none;\n}\n.index__container--10N7f .index__alert-card-line--10YeJ {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-orient: vertical;\n -webkit-box-direction: normal;\n -ms-flex-direction: column;\n flex-direction: column;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n}\n.index__container--10N7f .index__alert-card-line--10YeJ .index__number--17oxK {\n color: #e86804;\n font-size: 36px;\n}\n.index__outer--3WpA3 {\n position: relative;\n width: 100%;\n height: 100%;\n overflow: hidden;\n font-size: 14px;\n}\n.index__outer--3WpA3 .index__inner--1jNf7 {\n position: absolute;\n left: 0;\n width: 100%;\n height: 100%;\n overflow-x: hidden;\n overflow-y: scroll;\n}\n.index__outer--3WpA3 .index__inner--1jNf7::-webkit-scrollbar {\n display: none;\n}\n.index__top-content--3X_Di {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 100px;\n font-weight: 500;\n font-size: 24px;\n}\n.index__tabs--1jk3S .ant-tabs-tab {\n margin-right: 20px;\n border-bottom: 1px solid #f0f0f0;\n}\n.index__tabs--1jk3S .ant-tabs-nav::before {\n border-bottom: none;\n}\n"",""""]),t.locals={container:""index__container--10N7f"",card:""index__card--3LuCF"",tabs:""index__tabs--1jk3S"",""alert-card-line"":""index__alert-card-line--10YeJ"",number:""index__number--17oxK"",outer:""index__outer--3WpA3"",inner:""index__inner--1jNf7"",""top-content"":""index__top-content--3X_Di""}},4069:function(e,a,r){""use strict"";var n=r(160),l=r(19),i=r(25),s=r(21);l(a,""__esModule"",{value:!0}),a.default=void 0,r(422);var u=s(r(425));r(1198);var o=s(r(1199));r(1196);var d=s(r(1197));r(337);var c=s(r(338)),f=s(r(51)),m=s(r(27)),p=s(r(174)),v=s(r(57)),h=s(r(65)),g=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=S(t);if(a&&a.has(e))return a.get(e);var r={},n=l&&i;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=n?i(e,s):null;u&&(u.get||u.set)?l(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(r(0)),y=(r(173),s(r(1353))),b=r(1309),_=s(r(119)),x=r(1415),C=r(1295);function S(e){if(""function""!=typeof n)return null;var t=new n,a=new n;return(S=function(e){return e?a:t})(e)}function D(e){var{data:a}=e;return g.default.createElement(""div"",{className:y.default.card},g.default.createElement(o.default,{justify:""space-between""},g.default.createElement(""span"",null,t(""Last week alarm trend"")),g.default.createElement(""span"",null,t(""time / 24h""))),g.default.createElement(o.default,{justify:""center"",align:""middle"",style:{height:272,paddingTop:10}},0===a.length?g.default.createElement(u.default,null):g.default.createElement(w,{data:a})))}function w(e){var{data:t}=e;return g.default.createElement(C.Chart,{padding:[10,20,50,50],autoFit:!0,data:t,scale:{count:{nice:!0}}},g.default.createElement(C.Line,{position:""date*count""}),g.default.createElement(C.Tooltip,{showCrosshairs:!0,lock:!0}))}var E=function(){var e=(0,x.createFetchPrometheusClient)({requestType:""range"",metricKey:""monitorOverview.alertInfo""}),a=(0,x.createDataHandler)({formatDataFn:(e,t,a,r)=>{var n=[];return(0,m.default)(e).call(e,((e,l)=>{n.push((0,b.handleResponse)(e,t,a,r[l]))})),n},modifyKeys:[""cpu"",""memory""]}),[r,n]=(0,g.useState)(!0),[l,i]=(0,g.useState)(0),[s,u]=(0,g.useState)(0),[C,S]=(0,g.useState)(function(){for(var e=(0,_.default)().startOf(""day""),t=[],a=6;a>=0;a--)t.push({fullDate:e.clone().subtract(a,""day"").format(""YYYY-MM-DD""),date:e.clone().subtract(a,""day"").format(""MM-DD""),count:0});return t}()),w=function(){var t=(0,f.default)((function*(t){var r=(0,_.default)(t).endOf(""day""),n=(0,_.default)(t).startOf(""day""),l=yield e({interval:15,currentRange:[n,r]}),[i,s]=a(l).retData,u=(0,p.default)(i).call(i,((e,t,a)=>a>0&&t.x-i[a-1].x>15?e+1:e),0),o=(0,p.default)(s).call(s,((e,t,a)=>a>0&&t.x-s[a-1].x>15?e+1:e),0);return{date:t,total:u+o,cpuTotal:u,memTotal:o}}));return function(e){return t.apply(this,arguments)}}(),E=function(){var e=(0,f.default)((function*(){n(!0);var e=(0,v.default)(C).call(C,(e=>{var{fullDate:t}=e;return w(t)}));try{var t=yield h.default.all(e);(0,m.default)(t).call(t,((e,a)=>{var{total:r,cpuTotal:n,memTotal:l}=e;a===t.length-1&&(i(n),u(l)),C[a].count=r}))}catch(e){}S([...C]),n(!1)}));return function(){return e.apply(this,arguments)}}();return(0,g.useEffect)((()=>{E()}),[]),r?g.default.createElement(c.default,null):g.default.createElement(o.default,{gutter:[16,16]},g.default.createElement(d.default,{flex:""1 1""},g.default.createElement(""div"",{className:y.default.card},g.default.createElement(o.default,{style:{height:""100%""}},g.default.createElement(d.default,{span:12,className:y.default[""alert-card-line""]},g.default.createElement(""div"",{className:y.default.number},l),g.default.createElement(""div"",null,t(""Today CPU usage > 80% alert""))),g.default.createElement(d.default,{span:12,className:y.default[""alert-card-line""]},g.default.createElement(""div"",{className:y.default.number},s),g.default.createElement(""div"",null,t(""Today Memory usage > 80% alert"")))))),g.default.createElement(d.default,{flex:""0 1 440px""},g.default.createElement(D,{data:C})))};a.default=E},4070:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.storageRightChartList=a.storageLeftCardList=a.topCardList=a.physicalNodeRightTopCardList=a.physicalNodeLeftTopCardList=void 0;var m=f(r(81)),p=f(r(27)),v=f(r(229)),h=f(r(419)),g=f(r(36));r(1222);var y=f(r(1223));r(1198);var b=f(r(1199)),_=f(r(111)),x=f(r(0)),C=(r(173),r(161)),S=r(1352),D=f(r(1606)),w=r(1309),E=r(1209),I=f(r(140)),P=r(4071),T=f(r(1353));function k(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function N(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=k(Object(r),!0)).call(a,(function(t){(0,g.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=k(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var M=[{title:t(""Physical CPU Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.physicalCPUUsage""},renderContent:e=>{var t,{data:a}=e,r=(0,_.default)(a[0],""y"",0),n=(0,_.default)(a[1],""y"",0);return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(r,n)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(r,"" / "")).call(t,n))))}},{title:t(""Total Ram""),span:12,createFetchParams:{metricKey:""monitorOverview.physicalMemoryUsage""},renderContent:e=>{var t,{data:a}=e,r=(0,_.default)(a[0],""y"",0),n=(0,_.default)(a[1],""y"",0),l=(0,S.getSuitableValue)(r,""memory""),i=(0,S.getSuitableValue)(n,""memory"");return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(r,n)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(l,"" / "")).call(t,i))))}},{title:t(""Physical Storage Usage""),span:24,createFetchParams:{metricKey:""monitorOverview.physicalStorageUsage""},renderContent:e=>{var a,r,n,{data:l}=e,i=(0,_.default)(l[0],""y"",0),s=(0,_.default)(l[1],""y"",0),u=(0,S.getSuitableValue)(i,""disk""),o=(0,S.getSuitableValue)(s,""disk""),d=(0,C.computePercentage)(i,s);return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",{style:{width:""100%"",height:""100%""}},x.default.createElement(b.default,{style:{justifyContent:""flex-end"",height:""50%""}},x.default.createElement(""span"",{style:{fontSize:12,marginRight:32}},(0,m.default)(a=(0,m.default)(r=(0,m.default)(n="""".concat(t(""Used""),"" "")).call(n,u,"" / "")).call(r,t(""Total""),"" "")).call(a,o))),x.default.createElement(b.default,{style:{height:""50%""}},x.default.createElement(y.default,{style:{width:""95%""},percent:d,strokeColor:d>80?""#FAAD14"":""#1890FF"",showInfo:100!==d}))))}}];a.physicalNodeLeftTopCardList=M;var L=[{visibleHeight:319,createFetchParams:{requestType:""current"",metricKey:""monitorOverview.computeNodeStatus""},handleDataParams:{formatDataFn:e=>{var t=[{type:""up"",value:0},{type:""down"",value:0}],a=(0,_.default)(e[0],""data.result"",[]);return(0,p.default)(a).call(a,(e=>{var a=""enabled""===e.metric.adminState?0:1;t[a].value+=(0,v.default)(e.value[1],10)})),t}},title:t(""Compute Node status""),renderContent:e=>{var{data:t}=e;return x.default.createElement(""div"",{style:{height:309}},x.default.createElement(D.default,{data:t}))}}];a.physicalNodeRightTopCardList=L;var F=[{title:t(""Host CPU Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostCPUUsage""},handleDataParams:{typeKey:""instance""},renderContent:P.renderTopProgress},{title:t(""Host Disk Average IOPS""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostDiskIOPS""},handleDataParams:{formatDataFn:(e,t,a,r)=>{var n=[];return(0,p.default)(e).call(e,((e,t)=>{var a;(0,p.default)(a=e.data.result||[]).call(a,(e=>{n.push({x:e.metric.instance,y:(0,h.default)((0,_.default)(e,""value[1]"",0)),type:r[t]})}))})),n},modifyKeys:[t(""read""),t(""write"")]},extra:P.renderTopColumnExtra,renderContent:P.renderTopColumnChart},{title:t(""Host Memory Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostMemoryUsage""},handleDataParams:{typeKey:""instance""},renderContent:P.renderTopProgress},{title:t(""Host Average Network IO""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostInterface""},handleDataParams:{formatDataFn:(e,t,a,r)=>{var n=[];return(0,p.default)(e).call(e,((e,t)=>{var a;(0,p.default)(a=e.data.result||[]).call(a,(e=>{n.push({x:e.metric.instance,y:(0,h.default)((0,_.default)(e,""value[1]"",0)),type:r[t]})}))})),n},modifyKeys:[t(""receive""),t(""transmit"")]},extra:P.renderTopColumnExtra,renderContent:e=>{var t=(0,P.renderTopColumnChart)(e);return x.default.cloneElement(t,N(N({},t.props),{},{scale:{y:{nice:!0,formatter:e=>(0,S.getSuitableValue)(e,""traffic"",0)}}}))}}];a.topCardList=F;var A=[{title:t(""Storage Cluster Status""),span:24,createFetchParams:{metricKey:""monitorOverview.cephHealthStatus""},renderContent:e=>{var t=(0,_.default)(e.data,""y"",0);return x.default.createElement(""div"",{className:T.default[""top-content""],style:{fontSize:28,fontWeight:600,color:S.cephStatusColorMap[t],height:65}},S.cephStatusMap[t])}},{title:t(""Storage Cluster Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.cephStorageUsage""},renderContent:e=>{var t,{data:a}=e,r=(0,_.default)(a[0],""y"",0),n=(0,_.default)(a[1],""y"",0),l=(0,S.getSuitableValue)(r,""disk""),i=(0,S.getSuitableValue)(n,""disk"");return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(r,n)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(l,"" / "")).call(t,i))))}},{title:t(""Disk allocation (GiB)""),span:12,createFetchParams:{metricKey:""monitorOverview.cephStorageAllocate""},renderContent:e=>{var t,{data:a}=e,r=(0,h.default)((0,_.default)(a[1],""y"",0).toFixed(2)),n=(0,h.default)((r-(0,_.default)(a[0],""y"",0)).toFixed(2));return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(n,r)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(n,"" GiB / "")).call(t,r,"" GiB""))))},hidden:!I.default.checkEndpoint(""cinder"")}];a.storageLeftCardList=A;var O=[{title:t(""Storage Cluster IOPS""),createFetchParams:{requestType:""range"",metricKey:""monitorOverview.cephStorageClusterIOPS""},handleDataParams:{formatDataFn:w.handleResponses,modifyKeys:[t(""read""),t(""write"")]},span:24,chartProps:{chartType:E.ChartType.MULTILINE,height:318,scale:{y:{nice:!0}}}}];a.storageRightChartList=O},4071:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.renderTopColumnChart=t.renderTopColumnExtra=t.renderTopProgress=void 0;var l=n(a(57)),i=n(a(32));a(1260);var s=n(a(1261));a(1198);var u=n(a(1199));a(1196);var o=n(a(1197));a(1222);var d=n(a(1223)),c=n(a(111)),f=n(a(0)),m=(a(173),a(1295)),p=n(a(1353));t.renderTopProgress=e=>{var{data:t}=e;return f.default.createElement(u.default,{style:{height:""100%""}},(0,l.default)(t).call(t,(e=>{var t=(0,c.default)(e,""y"",0),a=t>80?""#FAAD14"":""#1890FF"";return f.default.createElement(o.default,{span:24,key:e.type},f.default.createElement(""div"",null,e.type),f.default.createElement(d.default,{strokeColor:a,percent:t,style:{marginBottom:4},showInfo:100!==t}))})))};t.renderTopColumnExtra=e=>{var{modifyKeys:t,filterChartData:a}=e;return f.default.createElement(s.default,{className:p.default.tabs,defaultActiveKey:t[0],onChange:e=>a((t=>t.type===e))},(0,l.default)(t).call(t,(e=>f.default.createElement(s.default.TabPane,{tab:e,key:e}))))};t.renderTopColumnChart=e=>{var{data:t,modifyKeys:a}=e;return f.default.createElement(m.Chart,{autoFit:!0,data:t.length<=5?t:(0,i.default)(t).call(t,(e=>e.type===a[0])),height:198,scale:{y:{nice:!0}}},f.default.createElement(m.Interval,{position:""x*y"",size:20}))}},4072:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(413)),i=n(a(4073)),s=e=>(0,l.default)(i.default,e);t.default=s},4073:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(1212)),i=n(a(567)),s=n(a(4074)),u=n(a(1609)),o=n(a(4085)),d=n(a(4089)),c=n(a(4093)),f=n(a(4109)),m=n(a(4113)),p=""/database"",v=[{path:p,component:l.default,routes:[{path:"""".concat(p,""/instances""),component:s.default,exact:!0},{path:"""".concat(p,""/instances-admin""),component:s.default,exact:!0},{path:"""".concat(p,""/instances/create""),component:u.default,exact:!0},{path:"""".concat(p,""/backups""),component:o.default,exact:!0},{path:"""".concat(p,""/configurations""),component:d.default,exact:!0},{path:"""".concat(p,""/instances/detail/:id""),component:c.default,exact:!0},{path:"""".concat(p,""/instances-admin/detail/:id""),component:c.default,exact:!0},{path:"""".concat(p,""/backups/detail/:id""),component:m.default,exact:!0},{path:"""".concat(p,""/configurations/detail/:id""),component:f.default,exact:!0},{path:""*"",component:i.default}]}];t.default=v},4074:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Instances=void 0;var i=l(r(57)),s=l(r(0)),u=r(406),o=l(r(1194)),d=l(r(1221)),c=r(1418),f=r(161),m=l(r(1608));class p extends o.default{init(){this.store=d.default}get name(){return t(""database instances"")}get actionConfigs(){return this.isAdminPage?m.default.actionConfigsAdmin:m.default.actionConfigs}get policy(){return""instance:index""}get aliasPolicy(){return""trove:instance:index""}get searchFilters(){return[{label:t(""Name""),name:""name""},{label:t(""Version""),name:""version""},{label:t(""Status""),name:""status"",options:(0,f.getOptions)(c.InstanceStatus)}]}getColumns(){return[{title:t(""ID/Name""),dataIndex:""name"",routeName:this.getRouteName(""databaseInstanceDetail"")},{title:t(""Project ID/Name""),dataIndex:""project_name"",isHideable:!0,hidden:!this.isAdminPage},{title:t(""Datastore""),dataIndex:""type""},{title:t(""Datastore Version""),dataIndex:""version"",isHideable:!0},{title:t(""Host""),dataIndex:""ip"",render:e=>e&&e.length?s.default.createElement(s.default.Fragment,null,(0,i.default)(e).call(e,(e=>s.default.createElement(""div"",{key:e},e)))):""-"",isHideable:!0},{title:t(""Database Disk (GiB)""),dataIndex:""size"",isHideable:!0,unit:""GiB""},{title:t(""Status""),dataIndex:""status"",valueMap:c.InstanceStatus}]}}a.Instances=p;var v=(0,u.inject)(""rootStore"")((0,u.observer)(p));a.default=v},4075:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1221));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:delete""),(0,i.default)(this,""onSubmit"",(e=>u.default.delete({id:e.id})))}get id(){return""delete""}get title(){return t(""Delete"")}get actionName(){return t(""Delete"")}get isDanger(){return!0}}a.default=o},4076:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepDetails=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(32)),o=l(r(102)),d=l(r(51)),c=l(r(36)),f=l(r(0)),m=r(406),p=l(r(1201)),v=r(34),h=l(r(1221)),g=l(r(1262)),y=l(r(1275));class b extends p.default{constructor(){super(...arguments),(0,c.default)(this,""allowed"",(()=>i.default.resolve())),(0,c.default)(this,""onFlavorChange"",(e=>{this.updateContext({flavor:e})}))}init(){this.instancesStore=h.default,this.getDatastores(),this.getAvailZones()}get title(){return t(""Details *"")}get name(){return""Details""}get nameForStateUpdate(){return[""flavor"",""datastore_type""]}get defaultValue(){return{project:this.currentProjectName}}get availableZones(){var e,t;return(0,s.default)(e=(0,u.default)(t=g.default.list.data||[]).call(t,(e=>e.zoneState.available))).call(e,(e=>({value:e.zoneName,label:e.zoneName})))}getAvailZones(){return(0,d.default)((function*(){g.default.fetchListWithoutDetail()}))()}get datastores(){var e;return(0,s.default)(e=h.default.dataList||[]).call(e,(e=>({label:e.name,value:e.name,originData:(0,v.toJS)(e)})))}getDatastores(){return(0,d.default)((function*(){h.default.listDatastores()}))()}get datastoresVersion(){var e,t;if(!this.state.datastore_type)return[];var a=(0,o.default)(e=this.datastores).call(e,(e=>e.label===this.state.datastore_type));return(0,s.default)(t=a.originData.versions||[]).call(t,(e=>({label:e.name,value:e.name})))}getFlavorComponent(){return f.default.createElement(y.default,{onChange:this.onFlavorChange})}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""zone"",label:t(""Availability Zone""),type:""select"",placeholder:t(""Please select""),options:this.availableZones,required:!0},{name:""instance_name"",label:t(""Database Instance Name""),type:""input"",required:!0},{name:""size"",label:t(""Database Disk (GiB)""),type:""input-int"",min:1,placeholder:t(""Size""),required:!0,wrapperCol:{xs:{span:24},sm:{span:18}},onChange:e=>this.updateContext({size:e})},{type:""divider""},{name:""datastore_type"",label:t(""Datastore Type""),type:""select"",options:this.datastores,onChange:()=>{this.resetFormValue([""datastore_version""])},required:!0},{name:""datastore_version"",label:t(""Datastore Version""),type:""select"",options:this.datastoresVersion,required:!0},{type:""divider""},{name:""flavor"",label:t(""Database Flavor""),component:this.getFlavorComponent(),wrapperCol:{xs:{span:24},sm:{span:18}},required:!0},{name:""locality"",label:t(""Locality""),type:""select"",options:[{label:t(""Affinity""),value:""affinity""},{label:t(""Anti-Affinity""),value:""anti-affinity""}],tip:t(""Specify whether future replicated instances will be created on the same hypervisor (affinity) or on different hypervisors (anti-affinity). This value is ignored if the instance to be launched is a replica."")}]}}a.StepDetails=b;var _=(0,m.inject)(""rootStore"")((0,m.observer)(b));a.default=_},4077:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepNetworking=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=l(r(1201));class d extends o.default{constructor(){super(...arguments),(0,s.default)(this,""allowed"",(()=>i.default.resolve()))}get title(){return t(""Networking *"")}get name(){return""Networking""}get defaultValue(){return{project:this.currentProjectName}}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""network"",label:t(""Network""),type:""network-select-table"",required:!0}]}}a.StepNetworking=d;var c=(0,u.inject)(""rootStore"")((0,u.observer)(d));a.default=c},4078:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepInitializeDatabases=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=l(r(1201)),d=r(556);class c extends o.default{constructor(){super(...arguments),(0,s.default)(this,""allowed"",(()=>i.default.resolve()))}get title(){return t(""Initialize Databases"")}get name(){return""Initialize Databases""}get defaultValue(){return{project:this.currentProjectName}}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""initialDatabases"",label:t(""Initial Databases""),type:""input-name"",required:!0,maxLength:64,isDatabaseName:!0},{name:""initialAdminUser"",label:t(""Initial Admin User""),type:""input-name"",required:!0,maxLength:16,isDatabaseUserName:!0},{name:""password"",label:t(""Password""),type:""input-password"",required:!0,otherRule:(0,d.getPasswordOtherRule)(""password"")},{name:""confirmPassword"",label:t(""Confirm Password""),type:""input-password"",required:!0,dependencies:[""password""],otherRule:(0,d.getPasswordOtherRule)(""confirmPassword"")}]}}a.StepInitializeDatabases=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4079:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepAdvanced=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(51)),o=l(r(36)),d=r(406),c=l(r(1201)),f=l(r(1221));class m extends c.default{constructor(){super(...arguments),(0,o.default)(this,""allowed"",(()=>i.default.resolve()))}init(){this.getConfigurationGroups()}get title(){return t(""Initialize Databases"")}get name(){return""Initialize Databases""}get configurationGroup(){var e;return(0,s.default)(e=f.default.list.data||[]).call(e,(e=>({label:e.name,value:e.id})))}getConfigurationGroups(){return(0,u.default)((function*(){f.default.listConfigurationGroup()}))()}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""configurationGroup"",label:t(""Configuration Group""),type:""select"",options:this.configurationGroup}]}}a.StepAdvanced=m;var p=(0,d.inject)(""rootStore"")((0,d.observer)(m));a.default=p},4080:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Edit=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=r(1193),d=l(r(1221));class c extends o.ModalAction{constructor(){super(...arguments),(0,s.default)(this,""onSubmit"",(e=>{var{name:t}=e,a={instance:{name:t}},{id:r}=this.item;return d.default.patch({id:r},a)}))}static allowed(){return i.default.resolve(!0)}get formItems(){return[{name:""name"",label:t(""Name""),type:""input"",required:!0,placeholder:t(""Please input name"")}]}}a.Edit=c,(0,s.default)(c,""id"",""edit-instance""),(0,s.default)(c,""title"",t(""Edit"")),(0,s.default)(c,""buttonText"",t(""Edit"")),(0,s.default)(c,""policy"",""instance:update"");var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4081:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=r(1195),o=l(r(1221));class d extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""policy"",""instance:restart""),(0,i.default)(this,""allowedCheckFunc"",(e=>(0,u.checkStatus)([""active"",""shutoff"",""shutdown""],e))),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=e||this.item;return o.default.restart({id:t})}))}get id(){return""restart""}get title(){return t(""Restart Database Service"")}get isDanger(){return!0}get actionName(){return t(""Restart Database Service"")}get isAsyncAction(){return!0}}a.default=d},4082:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=r(1195),o=l(r(1221));class d extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""policy"",""instance:stop""),(0,i.default)(this,""allowedCheckFunc"",(e=>(0,u.checkStatus)([""active""],e))),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=e||this.item;return o.default.stop({id:t})}))}get id(){return""stop""}get title(){return t(""Stop Database Service"")}get isDanger(){return!0}get buttonText(){return t(""Stop"")}get actionName(){return t(""Stop Database Service"")}get isAsyncAction(){return!0}}a.default=d},4083:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=r(1195),o=l(r(1221));class d extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""policy"",""instance:reboot""),(0,i.default)(this,""allowedCheckFunc"",(e=>(0,u.checkStatus)([""active"",""shutoff"",""shutdown""],e))),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=e||this.item;return o.default.reboot({id:t})}))}get id(){return""reboot""}get title(){return t(""Reboot Database Instance"")}get isDanger(){return!0}get actionName(){return t(""Reboot Database Instance"")}get isAsyncAction(){return!0}}a.default=d},4084:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.default=a.ResizeVolume=void 0;var m=f(r(81)),p=f(r(65)),v=f(r(51)),h=f(r(36)),g=r(406),y=f(r(1221)),b=f(r(407)),_=r(1193),x=r(1195);function C(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function S(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=C(Object(r),!0)).call(a,(function(t){(0,h.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=C(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}class D extends _.ModalAction{constructor(){super(...arguments),(0,h.default)(this,""onSubmit"",(e=>{var{id:t}=this.item,{size:a}=e;return y.default.resizeVolume({id:t,size:a})}))}static get modalSize(){return""large""}getModalSize(){return""large""}init(){this.store=y.default,this.projectStore=b.default,this.getQuota(),this.state.isLoading=!0,this.errorMsg=""""}get isQuotaLimited(){var{volumes:{limit:e}={}}=this.projectStore.troveQuota||{};return-1!==e}get maxSize(){var{volumes:{left:e=0}={}}=this.projectStore.troveQuota||{},{size:t=0}=this.item;return e+t}isQuotaEnough(){var{size:e=0}=this.item;return!this.isQuotaLimited||this.maxSize>e}get name(){return t(""Resize Volume"")}getMinSize(){var{volume:e={}}=this.item,{size:t=1}=e;return t+1}static get disableSubmit(){var{troveQuota:e={}}=b.default;return(e=>{var{volumes:{left:t=0}={}}=e||{};return 0===t})(e)}get showQuota(){return!0}getQuota(){var e=this;return(0,v.default)((function*(){yield e.projectStore.fetchProjectTroveQuota(e.currentProjectId),e.setState({isLoading:!1})}))()}get quotaInfo(){if(this.state.isLoading)return[];var{volumes:e={}}=this.projectStore.troveQuota||{},{size:a=0}=this.state,{left:r=0}=e,{size:n=0}=this.item,l=a-n;return[S(S({},e),{},{add:-1===r||l<=r?l:0,name:""volumeSize"",title:t(""Database Disk (GiB)""),type:""ring""})]}get isAsyncAction(){return!0}get nameForStateUpdate(){return[""size""]}get defaultValue(){var{name:e,volume:t={}}=this.item;return{instance:e,size:this.getMinSize(),oldSize:t.size}}get formItems(){var e;if(this.state.isLoading)return[];if(!this.isQuotaEnough())return[{type:""label"",component:t(""Quota is not enough for extend volume."")}];var a=this.getMinSize();return[{name:""instance"",label:t(""Database Instance""),type:""label"",iconType:""instance""},{name:""oldSize"",label:t(""Current Disk (GiB)""),type:""label""},{name:""size"",label:t(""Database Disk (GiB)""),type:""slider-input"",max:this.maxSize,min:a,description:(0,m.default)(e="""".concat(a,""GiB-"")).call(e,this.maxSize,""GiB""),required:!0,display:this.isQuotaLimited},{name:""size"",label:t(""Database Disk (GiB)""),type:""input-int"",min:a,required:!0,display:!this.isQuotaLimited}]}}a.ResizeVolume=D,(0,h.default)(D,""id"",""resize-volume""),(0,h.default)(D,""title"",t(""Resize Volume"")),(0,h.default)(D,""policy"",[""trove:instance:resize_volume"",""trove:admin""]),(0,h.default)(D,""isActiveOrShutOff"",(e=>(0,x.checkStatus)([""active"",""shutoff""],e))),(0,h.default)(D,""allowed"",(e=>p.default.resolve(D.isActiveOrShutOff(e))));var w=(0,g.inject)(""rootStore"")((0,g.observer)(D));a.default=w},4085:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Backups=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=l(r(1354)),d=l(r(4086));class c extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Name""),dataIndex:""name"",routeName:this.getRouteName(""databaseBackupDetail"")},{title:t(""Description""),isHideable:!0,dataIndex:""description""}]))}init(){this.store=o.default}get name(){return t(""database backups"")}get actionConfigs(){return d.default.actionConfigs}get policy(){return""backup:index""}get searchFilters(){return[{label:t(""Name""),name:""name""}]}}a.Backups=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4086:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4087)),i=n(a(4088)),s={actionConfigs:{rowActions:{firstAction:i.default},batchActions:[i.default],primaryActions:[l.default]}};t.default=s},4087:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Create=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(51)),o=l(r(36)),d=r(1193),c=r(406),f=l(r(1221)),m=l(r(1354));class p extends d.ModalAction{constructor(){super(...arguments),(0,o.default)(this,""onSubmit"",(e=>this.store.create({backup:{description:e.description,instance:e.instance,name:e.name}})))}init(){this.store=m.default,this.getDatabaseInstance()}static get modalSize(){return""middle""}getModalSize(){return""middle""}get name(){return t(""Create Database Backup"")}static allowed(){return i.default.resolve(!0)}get listInstanceName(){var e;return(0,s.default)(e=f.default.list.data||[]).call(e,(e=>({value:e.id,label:e.name})))}getDatabaseInstance(){return(0,u.default)((function*(){yield f.default.fetchListWithoutDetail()}))()}get formItems(){return[{name:""name"",label:t(""Name""),type:""input"",required:!0},{name:""instance"",label:t(""Database Instance""),type:""select"",options:this.listInstanceName,required:!0},{name:""description"",label:t(""Description""),type:""input""}]}}a.Create=p,(0,o.default)(p,""id"",""create-database-backup""),(0,o.default)(p,""title"",t(""Create Database Backup"")),(0,o.default)(p,""policy"",""backup:create""),(0,o.default)(p,""aliasPolicy"",""trove:backup:create"");var v=(0,c.inject)(""rootStore"")((0,c.observer)(p));a.default=v},4088:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1354));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:delete""),(0,i.default)(this,""onSubmit"",(e=>u.default.delete({id:e.id})))}get id(){return""delete""}get title(){return t(""Delete Database Backup"")}get actionName(){return t(""Delete Database Backup"")}get buttonText(){return t(""Delete"")}get isDanger(){return!0}}a.default=o},4089:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Configurations=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=l(r(1355)),d=l(r(4090));class c extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Configuration Group Name""),dataIndex:""name"",routeName:this.getRouteName(""configurationsDetail"")},{title:t(""Description""),isHideable:!0,dataIndex:""description""},{title:t(""Datastore""),dataIndex:""datastore""},{title:t(""Datastore Version""),dataIndex:""datastoreVersion""}]))}init(){this.store=o.default}get name(){return t(""configurations"")}get actionConfigs(){return d.default.actionConfigs}get policy(){return""configuration:index""}get searchFilters(){return[{label:t(""Name""),name:""name""}]}}a.Configurations=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4090:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4091)),i=n(a(4092)),s={actionConfigs:{rowActions:{firstAction:i.default},batchActions:[i.default],primaryActions:[l.default]}};t.default=s},4091:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Create=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(32)),o=l(r(51)),d=l(r(36)),c=r(1193),f=r(406),m=l(r(1221)),p=l(r(1355)),v=r(34);class h extends c.ModalAction{constructor(){super(...arguments),(0,d.default)(this,""onChangeDatastoresTypeChange"",(e=>{this.setState({datastore_type:e}),this.resetFormValue([""datastore_version""])})),(0,d.default)(this,""onSubmit"",(e=>this.store.create({configuration:{description:e.description,datastore:{type:e.datastore_type,version:e.datastore_version},name:e.name,values:{connect_timeout:200}}})))}init(){this.store=p.default,this.getDatastores(),this.state.datastore_type=null}static get modalSize(){return""middle""}getModalSize(){return""middle""}get name(){return t(""Create Configurations"")}static allowed(){return i.default.resolve(!0)}getDatastores(){return(0,o.default)((function*(){yield m.default.listDatastores()}))()}get datastores(){var e;return(0,s.default)(e=m.default.dataList||[]).call(e,(e=>({label:e.name,value:e.name,originData:(0,v.toJS)(e)})))}get datastoresVersion(){var e,t;return(0,s.default)(e=(0,u.default)(t=this.datastores).call(t,(e=>e.label===this.state.datastore_type))).call(e,(e=>{var t;return(0,s.default)(t=e.originData.versions).call(t,(e=>({label:e.name,value:e.name})))}))[0]}get formItems(){return[{name:""name"",label:t(""Name""),type:""input"",required:!0},{name:""description"",label:t(""Description""),type:""input""},{name:""datastore_type"",label:t(""Datastore Type""),type:""select"",options:this.datastores,onChange:e=>{this.onChangeDatastoresTypeChange(e)},required:!0},{name:""datastore_version"",label:t(""Datastore Version""),type:""select"",options:this.datastoresVersion,required:!0}]}}a.Create=h,(0,d.default)(h,""id"",""create-configurations""),(0,d.default)(h,""title"",t(""Create Configurations"")),(0,d.default)(h,""policy"",""configuration:create"");var g=(0,f.inject)(""rootStore"")((0,f.observer)(h));a.default=g},4092:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1355));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:delete""),(0,i.default)(this,""onSubmit"",(e=>u.default.delete({id:e.id})))}get id(){return""delete""}get title(){return t(""Delete Configuration"")}get actionName(){return t(""Delete Configuration"")}get isDanger(){return!0}}a.default=o},4093:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.InstancesDetail=void 0;var i=r(406),s=l(r(1200)),u=l(r(1221)),o=r(1418),d=l(r(4094)),c=l(r(4095)),f=l(r(4100)),m=l(r(4104)),p=l(r(4106)),v=l(r(4108)),h=l(r(1608));class g extends s.default{init(){this.store=u.default}get name(){return t(""Backup Detail"")}get policy(){return""instance:detail""}get aliasPolicy(){return""trove:instance:detail""}get listUrl(){return this.getRoutePath(""databaseInstances"")}get detailInfos(){return[{title:t(""ID""),dataIndex:""id""},{title:t(""Name""),dataIndex:""name""},{title:t(""Status""),dataIndex:""status"",valueMap:o.InstanceStatus},{title:t(""Project ID""),dataIndex:""tenant_id"",hidden:!this.isAdminPage}]}get tabs(){return[{title:t(""Detail""),key:""general_info"",component:d.default},{title:t(""Users""),key:""users"",component:c.default},{title:t(""Databases""),key:""databases"",component:f.default},{title:t(""Backups""),key:""backups"",component:m.default},{title:t(""Logs""),key:""logs"",component:p.default},{title:t(""Defaults""),key:""defaults"",component:v.default}]}get actionConfigs(){return this.isAdminPage?h.default.actionConfigsAdmin:h.default.actionConfigs}}a.InstancesDetail=g;var y=(0,i.inject)(""rootStore"")((0,i.observer)(g));a.default=y},4094:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BaseDetail=void 0;var i=l(r(57)),s=l(r(0)),u=r(406),o=l(r(1202)),d=r(1418);class c extends o.default{get leftCards(){return[this.baseInfoCard,this.specsCard,this.connectionInfoCard]}get rightCards(){return[this.faultCard]}get baseInfoCard(){var e=[{label:t(""Name""),dataIndex:""name""},{label:t(""Datastore""),dataIndex:""type""},{label:t(""Datastore Version""),dataIndex:""version""},{label:t(""Status""),dataIndex:""status"",valueMap:d.InstanceStatus},{label:t(""Locality""),dataIndex:""locality"",valueMap:d.policyType}];return{title:t(""Base Info""),options:e}}get specsCard(){var e=[{label:t(""Database Flavor""),dataIndex:""flavor"",render:e=>this.getLinkRender(""flavorDetail"",e.name,{id:e.id},null)},{label:t(""Volume Size""),dataIndex:""size"",unit:""GiB""},{label:t(""Created""),dataIndex:""created"",valueRender:""toLocalTime""},{label:t(""Updated""),dataIndex:""updated"",valueRender:""toLocalTime""},{label:t(""Service Status Updated""),dataIndex:""service_status_update""}];return{title:t(""Specs""),options:e}}get connectionInfoCard(){var e=[{label:t(""Host""),dataIndex:""ip"",render:e=>e&&e.length?s.default.createElement(""span"",null,(0,i.default)(e).call(e,(e=>s.default.createElement(""div"",{key:e},e)))):""-""},{label:t(""Database Port""),dataIndex:""type"",render:e=>{switch(e){case""mysql"":return""3306"";case""mongodb"":return""27017"";case""postgresql"":return""5432""}}},{label:t(""Connection Examples""),dataIndex:""connection_examples""}];return{title:t(""Connection Information""),options:e}}get faultCard(){var e=[{label:t(""Created""),dataIndex:""created"",valueRender:""toLocalTime""},{label:t(""Message""),dataIndex:""fault.message""},{label:t(""Message Details""),dataIndex:""fault.details""}];return{title:t(""Fault""),labelCol:2,options:e}}}a.BaseDetail=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4095:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Users=void 0;var i=l(r(57)),s=l(r(36)),u=l(r(0)),o=l(r(1194)),d=r(406),c=r(1356),f=l(r(4096));class m extends o.default{constructor(){super(...arguments),(0,s.default)(this,""getColumns"",(()=>[{title:t(""User Name""),dataIndex:""name""},{title:t(""Allowed Host""),dataIndex:""host""},{title:t(""Databases""),dataIndex:""databases"",render:e=>e.length?u.default.createElement(""span"",null,(0,i.default)(e).call(e,(e=>u.default.createElement(""div"",{key:e},e)))):""-""}]))}init(){this.store=new c.InstancesUsersStore}get rowKey(){return""name""}get name(){return t(""Users"")}get actionConfigs(){return this.isAdminPage?f.default.actionConfigsAdmin:f.default.actionConfigs}get policy(){return""instance:extension:user:index""}get hideCustom(){return!0}}a.Users=m;var p=(0,d.inject)(""rootStore"")((0,d.observer)(m));a.default=p},4096:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4097)),i=n(a(4098)),s=n(a(4099)),u={actionConfigs:{rowActions:{firstAction:l.default,moreActions:[{action:s.default}]},batchActions:[l.default],primaryActions:[i.default]},actionConfigsAdmin:{rowActions:{firstAction:l.default},batchActions:[l.default],primaryActions:[]}};t.default=u},4097:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1356));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:extension:user:delete""),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=this.containerProps.detail,a=e.name||this.item.name;return u.default.deleteUser({id:t,name:a})}))}get id(){return""delete-database-user""}get title(){return t(""Delete User"")}get actionName(){return t(""Delete User"")}get isDanger(){return!0}get buttonText(){return t(""Delete"")}}a.default=o},4098:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.UserCreate=void 0;var i=l(r(57)),s=l(r(65)),u=l(r(51)),o=l(r(36)),d=r(406),c=l(r(1325)),f=l(r(1356)),m=r(1310),p=r(556);class v extends c.default{constructor(){super(...arguments),(0,o.default)(this,""onSubmit"",(e=>{var t,{id:a}=this.item;return this.store.create(a,{users:[{databases:(0,i.default)(t=e.database).call(t,(e=>({name:e}))),name:e.userName,password:e.password}]})}))}init(){var e=this;return(0,u.default)((function*(){e.store=f.default,e.databaseStore=new m.InstancesDatabasesStore,yield e.fetchDatabase()}))()}get name(){return t(""Create User"")}static allowed(){return s.default.resolve(!0)}fetchDatabase(){var{id:e}=this.item;this.databaseStore.fetchList({id:e})}get database(){var e;return(0,i.default)(e=this.databaseStore.list.data||[]).call(e,(e=>({label:e.name,value:e.name,key:e.name})))}get formItems(){return[{name:""userName"",label:t(""Name""),type:""input-name"",required:!0,isDatabaseUserName:!0,maxLength:16},{name:""database"",label:t(""Database""),type:""select"",options:this.database,mode:""multiple"",required:!0},{name:""password"",label:t(""Password""),type:""input-password"",required:!0,otherRule:(0,p.getPasswordOtherRule)(""password"")},{name:""confirmPassword"",label:t(""Confirm Password""),type:""input-password"",required:!0,dependencies:[""password""],otherRule:(0,p.getPasswordOtherRule)(""confirmPassword"")}]}}a.UserCreate=v,(0,o.default)(v,""id"",""create-user""),(0,o.default)(v,""title"",t(""Create User"")),(0,o.default)(v,""policy"",""instance:extension:user:create"");var h=(0,d.inject)(""rootStore"")((0,d.observer)(v));a.default=h},4099:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.UserDatabase=void 0;var i=l(r(57)),s=l(r(65)),u=l(r(51)),o=l(r(36)),d=r(406),c=l(r(1325)),f=l(r(1356)),m=r(1310);class p extends c.default{constructor(){super(...arguments),(0,o.default)(this,""onSubmit"",((e,t)=>{var a,{detail:{id:r}={}}=t,n={databases:(0,i.default)(a=e.database).call(a,(e=>({name:e})))};return this.store.grantDatabaseAccess({id:r,name:e.name,data:n})}))}init(){this.store=f.default,this.databaseStore=new m.InstancesDatabasesStore,this.fetchDatabase()}get name(){return t(""Grant Databases Access"")}static allowed(){return s.default.resolve(!0)}fetchDatabase(){var e=this;return(0,u.default)((function*(){var{containerProps:{detail:{id:t}={}}={}}=e.props;yield e.databaseStore.fetchList({id:t}),e.updateDefaultValue()}))()}get database(){var e;return(0,i.default)(e=this.databaseStore.list.data||[]).call(e,(e=>({label:e.name,value:e.name,key:e.name})))}get defaultValue(){var{name:e,databases:t}=this.item;return{name:e,database:t}}get formItems(){return[{name:""name"",label:t(""Name""),type:""input-name"",required:!0,disabled:!0},{name:""database"",label:t(""Database""),type:""select"",options:this.database,mode:""multiple"",required:!0,loading:this.databaseStore.list.isLoading,disabled:this.databaseStore.list.isLoading}]}}a.UserDatabase=p,(0,o.default)(p,""id"",""grant-databases-access""),(0,o.default)(p,""title"",t(""Grant Databases Access"")),(0,o.default)(p,""policy"",""instance:extension:user_access:update"");var v=(0,d.inject)(""rootStore"")((0,d.observer)(p));a.default=v},4100:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Databases=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=r(1310),d=l(r(4101));class c extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Database Name""),dataIndex:""name""}]))}init(){this.store=new o.InstancesDatabasesStore}get rowKey(){return""name""}get name(){return""Databases""}get policy(){return""instance:extension:database:index""}get actionConfigs(){return this.isAdminPage?d.default.actionConfigsAdmin:d.default.actionConfigs}get hideCustom(){return!0}}a.Databases=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4101:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4102)),i=n(a(4103)),s={actionConfigs:{rowActions:{firstAction:l.default},batchActions:[l.default],primaryActions:[i.default]},actionConfigsAdmin:{rowActions:{firstAction:l.default},batchActions:[l.default],primaryActions:[]}};t.default=s},4102:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1310));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:extension:database:delete""),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=this.containerProps.detail,a=e.name||this.item.name;return u.default.deleteDatabase({id:t,name:a})}))}get id(){return""delete-database-database""}get title(){return t(""Delete Database"")}get actionName(){return t(""Delete Database"")}get isDanger(){return!0}get buttonText(){return t(""Delete"")}}a.default=o},4103:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.DatabaseCreate=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=l(r(1325)),d=l(r(1310));class c extends o.default{constructor(){super(...arguments),(0,s.default)(this,""onSubmit"",(e=>{var{id:t}=this.item;return this.store.create(t,{databases:[{character_set:""utf8"",collate:""utf8_general_ci"",name:e.databaseName}]})}))}init(){this.store=d.default}get name(){return t(""Create Database"")}static allowed(){return i.default.resolve(!0)}get formItems(){return[{name:""databaseName"",label:t(""Name""),type:""input-name"",required:!0,isDatabaseName:!0,maxLength:64}]}}a.DatabaseCreate=c,(0,s.default)(c,""id"",""create-database""),(0,s.default)(c,""title"",t(""Create Database"")),(0,s.default)(c,""policy"",""instance:extension:database:create"");var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4104:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Backups=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=r(4105);class d extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Name""),dataIndex:""name""},{title:t(""Created""),dataIndex:""created""},{title:t(""Backup File""),dataIndex:""locationRef""},{title:t(""Incremental""),dataIndex:""incremental""},{title:t(""Status""),dataIndex:""status""}]))}init(){this.store=new o.InstanceBackupsStore}get name(){return t(""Backups"")}get policy(){return""instance:backups""}}a.Backups=d;var c=(0,u.inject)(""rootStore"")((0,u.observer)(d));a.default=c},4105:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.InstanceBackupsStore=void 0;var l=n(a(53)),i=n(a(48));class s extends l.default{get client(){return i.default.trove.instances.backups}get responseKey(){return""backup""}get isSubResource(){return!0}get paramsFunc(){return()=>{}}}t.InstanceBackupsStore=s;var u=new s;t.default=u},4106:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Logs=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=r(4107);class d extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Name""),dataIndex:""name""}]))}init(){this.store=new o.InstancesLogStore}get name(){return t(""Log"")}get policy(){return""instance:guest_log_list""}}a.Logs=d;var c=(0,u.inject)(""rootStore"")((0,u.observer)(d));a.default=c},4107:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.InstancesLogStore=void 0;var l=n(a(53)),i=n(a(48));class s extends l.default{get client(){return i.default.trove.instances.log}get responseKey(){return""logs""}get isSubResource(){return!0}get paramsFunc(){return()=>{}}}t.InstancesLogStore=s;var u=new s;t.default=u},4108:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Defaults=void 0;var i=l(r(111)),s=l(r(1202)),u=r(406);class o extends s.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Number of Nodes""),dataIndex:""node_groups"",render:e=>(0,i.default)(e,[""0"",""count""],""-"")}];return{title:t(""Defaults""),options:e}}}a.Defaults=o;var d=(0,u.inject)(""rootStore"")((0,u.observer)(o));a.default=d},4109:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.ConfigurationsDetail=void 0;var i=r(406),s=l(r(1200)),u=l(r(1355)),o=l(r(4110)),d=l(r(4111)),c=l(r(4112));class f extends s.default{init(){this.store=u.default}get name(){return""Configurations Detail""}get listUrl(){return this.getRoutePath(""configurations"")}get policy(){return""configuration:show""}get detailInfos(){return[{title:t(""Name""),dataIndex:""name""}]}get tabs(){return[{title:t(""Detail""),key:""general_info"",component:o.default},{title:t(""Values""),key:""values"",component:d.default},{title:t(""Instances""),key:""instances"",component:c.default}]}}a.ConfigurationsDetail=f;var m=(0,i.inject)(""rootStore"")((0,i.observer)(f));a.default=m},4110:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BaseDetail=void 0;var i=r(406),s=l(r(1202));class u extends s.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Name""),dataIndex:""name""},{label:t(""Description""),dataIndex:""description""},{label:t(""Datastore""),dataIndex:""datastore_name""},{label:t(""Datastore Version""),dataIndex:""datastore_version_name""},{label:t(""Created""),dataIndex:""created""},{label:t(""Updated""),dataIndex:""updated""}];return{title:t(""Base Info""),options:e}}}a.BaseDetail=u;var o=(0,i.inject)(""rootStore"")((0,i.observer)(u));a.default=o},4111:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Values=void 0;var i=l(r(1202)),s=r(406);class u extends i.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Values""),dataIndex:""values""}];return{title:t(""Defaults""),options:e}}}a.Values=u;var o=(0,s.inject)(""rootStore"")((0,s.observer)(u));a.default=o},4112:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Instances=void 0;var i=l(r(1202)),s=r(406);class u extends i.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Instances""),dataIndex:""instance_count""}];return{title:t(""Defaults""),options:e}}}a.Instances=u;var o=(0,s.inject)(""rootStore"")((0,s.observer)(u));a.default=o},4113:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BackupsDetail=void 0;var i=r(406),s=l(r(1200)),u=r(1354),o=l(r(4114));class d extends s.default{init(){this.store=new u.BackupsStore}get name(){return t(""Database Backup Detail"")}get listUrl(){return this.getRoutePath(""databaseBackups"")}get policy(){return""backup:show""}get detailInfos(){return[{title:t(""Name""),dataIndex:""name""},{title:t(""Description""),dataIndex:""description""}]}get tabs(){return[{title:t(""Detail""),key:""general_info"",component:o.default}]}}a.BackupsDetail=d;var c=(0,i.inject)(""rootStore"")((0,i.observer)(d));a.default=c},4114:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BaseDetail=void 0;var i=r(406),s=l(r(1202));class u extends s.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Datastore""),dataIndex:""datastore.type""},{label:t(""Datastore Version""),dataIndex:""datastore.version""},{label:t(""Backup File Location""),dataIndex:""locationRef""},{label:t(""Initial Volume Size""),dataIndex:""size""},{label:t(""Created""),dataIndex:""created""},{label:t(""Updated""),dataIndex:""updated""},{label:t(""Status""),dataIndex:""status""}];return{title:t(""Base Info""),options:e}}}a.BaseDetail=u;var o=(0,i.inject)(""rootStore"")((0,i.observer)(u));a.default=o}}]);","(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{1209:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.fetchPrometheus=I,a.getRequestUrl=P,a.addParams=T,a.getInterval=function(e){var t=(e||k(0))[0],a=(e||k(0))[1].diff(t,""minutes"");return M[(a>44640?3:a>1440&&a<=44640&&2)||a>60&&a<=1440&&1||a>0&&a<=60&&0||0]},a.getPromises=a.range2IntervalsDict=a.getRange=a.defaultOneHourAgo=a.baseReturnFunc=a.getXScale=a.ChartType=void 0;var m=f(r(65)),p=f(r(33)),v=f(r(27)),h=f(r(81)),g=f(r(57)),y=f(r(36)),b=f(r(91)),_=f(r(111)),x=r(569),C=f(r(119)),S=f(r(48));function D(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function w(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=D(Object(r),!0)).call(a,(function(t){(0,y.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=D(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}a.ChartType={ONELINE:""oneline"",MULTILINE:""multiline"",ONELINEDEVICES:""oneline_devices"",MULTILINEDEVICES:""multiline_devices""};a.getXScale=e=>{var t=(0,C.default)(e[1]).diff((0,C.default)(e[0]),""minutes"",!0);return w({type:""time""},N[(t>20160?4:t>10080&&t<=20160&&3)||t>1440&&t<=10080&&2||t>60&&t<=1440&&1||t>0&&t<=60&&0||0])};var E=e=>e;function I(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""range"",a=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[],r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:10;return""current""===t?S.default.skyline.query.list({query:e}):""range""===t?S.default.skyline.queryRange.list({query:e,start:(0,x.getTimestamp)(a[0]),end:(0,x.getTimestamp)(a[1]),step:r}):m.default.resolve()}function P(e,t,a,r){var n=w(w({},t),r);return a(0===(0,p.default)(n).length?e:T(e,n))}function T(e,t){var a,r,n="""";return(0,v.default)(a=(0,p.default)(t)).call(a,(e=>{var a,r;(0,b.default)(t[e])?n+=(0,h.default)(a="""".concat(e,'=~""')).call(a,t[e].join(""|""),'"",'):n+=(0,h.default)(r="""".concat(e,'=""')).call(r,t[e],'"",')})),(0,h.default)(r="""".concat(e,""{"")).call(r,n.substring(0,n.length-1),""}"")}a.baseReturnFunc=E;a.defaultOneHourAgo=()=>[(0,C.default)().subtract(1,""hours""),(0,C.default)()];var k=e=>({3:[(0,C.default)().subtract(2,""weeks""),(0,C.default)()],2:[(0,C.default)().subtract(1,""weeks""),(0,C.default)()],1:[(0,C.default)().subtract(1,""days""),(0,C.default)()],0:[(0,C.default)().subtract(1,""hours""),(0,C.default)()]}[e]||[(0,C.default)().subtract(1,""hours""),(0,C.default)()]);a.getRange=k;var N=[{formatter:e=>(0,x.getStrFromTimestamp)(e,""HH:mm:ss""),ticketCount:6},{formatter:e=>(0,x.getStrFromTimestamp)(e,""HH:mm:ss""),ticketCount:6},{formatter:e=>(0,x.getStrFromTimestamp)(e,""MM-DD HH:mm""),ticketCount:3},{formatter:e=>(0,x.getStrFromTimestamp)(e,""MM-DD HH:mm""),ticketCount:6},{formatter:e=>(0,x.getStrFromTimestamp)(e,""MM-DD HH:mm""),ticketCount:6}],M=[[{text:t(""10s""),value:10},{text:t(""1min""),value:60},{text:t(""5min""),value:300}],[{text:t(""1min""),value:60},{text:t(""5min""),value:300},{text:t(""1H""),value:3600}],[{text:t(""1H""),value:3600},{text:t(""1D""),value:86400}],[{text:t(""1D""),value:86400}]];a.range2IntervalsDict=M;a.getPromises=e=>{var t,a=(0,_.default)(METRICDICT,e);return(0,g.default)(t=a.url).call(t,((e,t)=>I(P(e,{},(a.finalFormatFunc||[])[t]||E,(a.baseParams||[])[t]||{}),""current"")))}},1221:function(e,t,a){""use strict"";var r=a(33),n=a(44),l=a(32),i=a(25),s=a(27),u=a(45),o=a(46),d=a(19),c=a(21);d(t,""__esModule"",{value:!0}),t.default=t.InstancesStore=void 0;var f,m,p=c(a(57)),v=c(a(25)),h=c(a(51)),g=c(a(71)),y=c(a(36)),b=c(a(54)),_=(c(a(72)),c(a(111))),x=c(a(53)),C=c(a(48)),S=a(34),D=c(a(1218));function w(e,t){var a=r(e);if(n){var s=n(e);t&&(s=l(s).call(s,(function(t){return i(e,t).enumerable}))),a.push.apply(a,s)}return a}function E(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)s(a=w(Object(r),!0)).call(a,(function(t){(0,y.default)(e,t,r[t])}));else if(u)o(e,u(r));else{var n;s(n=w(Object(r))).call(n,(function(t){d(e,t,i(r,t))}))}}return e}var I=(f=class extends x.default{constructor(){super(...arguments),(0,g.default)(this,""dataList"",m,this)}get client(){return C.default.trove.instances}get clientDatastore(){return C.default.trove.datastores}get clientConfigurationGroup(){return C.default.trove.configurations}get adminClient(){return C.default.trove.instancesAdmin}get mapper(){return e=>E(E({},e),{},{type:(0,_.default)(e,""datastore.type""),version:(0,_.default)(e,""datastore.version""),size:(0,_.default)(e,""volume.size"")})}detailDidFetch(e){return(0,h.default)((function*(){var t=yield D.default.fetchDetail({id:(0,_.default)(e,""flavor.id"")});return E(E({},e),{},{flavor:E(E({},e.flavor),t)})}))()}listDidFetch(e){return 0===e.length?e:(0,p.default)(e).call(e,(e=>E(E({},e),{},{project_id:e.tenant_id})))}create(e){var t=this;return(0,h.default)((function*(){return t.submitting(t.client.create(e))}))()}delete(e,t){var a=this;return(0,h.default)((function*(){var{params:r}=e;return a.client.delete(r,t)}))()}update(e,t){return this.submitting(this.client.action(e,t))}operation(e){var t=this;return(0,h.default)((function*(){var{body:a,id:r,key:n=""""}=e,l=a;return l||((l={})[n]={}),t.update(r,l)}))()}restart(e){var t=this;return(0,h.default)((function*(){var{id:a}=e;return t.operation({key:""restart"",id:a})}))()}reboot(e){var t=this;return(0,h.default)((function*(){var{id:a}=e;return t.operation({key:""reboot"",id:a})}))()}stop(e){var t=this;return(0,h.default)((function*(){var{id:a}=e;return t.submitting(t.adminClient.action(a,{stop:{}}))}))()}resizeVolume(e){var t=this;return(0,h.default)((function*(){var{id:a,size:r}=e,n={resize:{volume:{size:r}}};return t.operation({body:n,id:a})}))()}listDatastores(){var e=this;return(0,h.default)((function*(){var t=(yield e.clientDatastore.list()).datastores;e.dataList=(0,p.default)(t).call(t,e.mapper)}))()}fetchListWithoutDetail(){var e=this;return(0,h.default)((function*(){var t=(yield e.client.list())[e.listResponseKey];e.list.data=(0,p.default)(t).call(t,e.mapper)}))()}listConfigurationGroup(){var e=this;return(0,h.default)((function*(){var t=(yield e.clientConfigurationGroup.list()).configurations;e.list.data=(0,p.default)(t).call(t,e.mapper)}))()}},m=(0,b.default)(f.prototype,""dataList"",[S.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return[]}}),(0,b.default)(f.prototype,""create"",[S.action],(0,v.default)(f.prototype,""create""),f.prototype),(0,b.default)(f.prototype,""delete"",[S.action],(0,v.default)(f.prototype,""delete""),f.prototype),(0,b.default)(f.prototype,""update"",[S.action],(0,v.default)(f.prototype,""update""),f.prototype),(0,b.default)(f.prototype,""operation"",[S.action],(0,v.default)(f.prototype,""operation""),f.prototype),(0,b.default)(f.prototype,""restart"",[S.action],(0,v.default)(f.prototype,""restart""),f.prototype),(0,b.default)(f.prototype,""reboot"",[S.action],(0,v.default)(f.prototype,""reboot""),f.prototype),(0,b.default)(f.prototype,""stop"",[S.action],(0,v.default)(f.prototype,""stop""),f.prototype),(0,b.default)(f.prototype,""resizeVolume"",[S.action],(0,v.default)(f.prototype,""resizeVolume""),f.prototype),(0,b.default)(f.prototype,""listDatastores"",[S.action],(0,v.default)(f.prototype,""listDatastores""),f.prototype),(0,b.default)(f.prototype,""fetchListWithoutDetail"",[S.action],(0,v.default)(f.prototype,""fetchListWithoutDetail""),f.prototype),(0,b.default)(f.prototype,""listConfigurationGroup"",[S.action],(0,v.default)(f.prototype,""listConfigurationGroup""),f.prototype),f);t.InstancesStore=I;var P=new I;t.default=P},1263:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s=i(a(580));a(337);var u=i(a(338));a(333);var o=i(a(332)),d=i(a(1273)),c=i(a(51)),f=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=x(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0)),m=(a(173),a(555),a(1209)),p=i(a(1603)),v=i(a(4039)),h=i(a(4040)),g=i(a(4041)),y=i(a(1416)),b=a(1351),_=i(a(1417));function x(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(x=function(e){return e?a:t})(e)}var C=e=>{var t,a,{renderTimeRangeSelect:r,chartConfig:n,renderNodeSelect:l,fetchNodesFunc:i,defaultNode:b,children:x,type:C}=e,[S,D,w,E]=(0,g.default)(b),[I,P,T,k]=(0,h.default)((0,m.defaultOneHourAgo)()),[N,M]=(0,v.default)(I),[L,F]=(0,f.useState)(!0),[A,O]=(0,f.useState)(!0),z=function(){var e=(0,c.default)((function*(){var e=arguments.length>0&&void 0!==arguments[0]&&arguments[0];if(F(!0),l){O(!0);var t=yield i();E(t),S&&!e||w(t[0]),e&&4!==T&&k((0,m.getRange)(T)),O(!1),F(!1)}else(0,s.default)((()=>{F(!1)}),300)}));return function(){return e.apply(this,arguments)}}(),j={interval:N,range:I,node:S};return(0,f.useEffect)((()=>{z()}),[N,I]),(0,f.useEffect)((()=>{z(!0)}),[C]),(0,f.useEffect)((()=>{F(!0),(0,s.default)((()=>{F(!1)}),300)}),[S]),f.default.createElement(""div"",{className:y.default[""base-content-container""]},f.default.createElement(_.default.Provider,{value:j},(r||l)&&f.default.createElement(o.default,{type:""default"",icon:f.default.createElement(d.default,null),onClick:()=>z(!0),className:y.default.refresh}),r&&f.default.createElement(""div"",{className:y.default.header},f.default.createElement(P,null),f.default.createElement(M,null)),l&&(A?f.default.createElement(u.default,null):f.default.createElement(D,null)),l&&A||L&&0!==(null==n||null===(t=n.chartCardList)||void 0===t?void 0:t.length)&&0!==(null==n||null===(a=n.topCardList)||void 0===a?void 0:a.length)?null:f.default.createElement(p.default,n),l&&A||L?f.default.createElement(u.default,null):x))};C.defaultProps={renderNodeSelect:!0,renderTimeRangeSelect:!0,fetchNodesFunc:b.defaultGetNodes,defaultNode:void 0};var S=C;t.default=S},1309:function(e,t,a){""use strict"";var r=a(33),n=a(44),l=a(32),i=a(25),s=a(27),u=a(45),o=a(46),d=a(19),c=a(21);d(t,""__esModule"",{value:!0}),t.baseFixToChart=y,t.handleResponses=function(e,t,a){var r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:[],n=[];return(0,m.default)(e).call(e,((e,l)=>{n.push(...b(e,t,a,r[l]))})),n},t.handleResponse=b;var f=c(a(419)),m=c(a(27)),p=c(a(1204)),v=c(a(36)),h=c(a(111));function g(e,t){var a=r(e);if(n){var s=n(e);t&&(s=l(s).call(s,(function(t){return i(e,t).enumerable}))),a.push.apply(a,s)}return a}function y(e){return{x:e[0],y:(0,f.default)((0,f.default)(e[1]).toFixed(2))}}function b(e,t,a,r){var n,{data:l}=e,c=[];return(0,m.default)(n=l.result).call(n,(e=>{var n=(0,p.default)(e)||[e.value]||[];(0,m.default)(n).call(n,(n=>{var l=function(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)s(a=g(Object(r),!0)).call(a,(function(t){(0,v.default)(e,t,r[t])}));else if(u)o(e,u(r));else{var n;s(n=g(Object(r))).call(n,(function(t){d(e,t,i(r,t))}))}}return e}({},y(n));t&&(l.type=(0,h.default)(e.metric,t)),a&&(l.device=(0,h.default)(e.metric,a)),r&&(l.type=r),c.push(l)}))})),c}},1310:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.InstancesDatabasesStore=void 0;var l,i=n(a(25)),s=n(a(51)),u=n(a(62)),o=n(a(54)),d=n(a(53)),c=n(a(48)),f=a(34),m=(l=class extends d.default{get client(){return c.default.trove.instances.databases}get isSubResource(){return!0}get responseKey(){return""database""}get paramsFunc(){return e=>{var{id:t}=e;return(0,u.default)(e,[""id""])}}create(e,t){var a=this;return(0,s.default)((function*(){return a.submitting(a.client.create(e,t))}))()}deleteDatabase(e){var t=this;return(0,s.default)((function*(){var{id:a,name:r}=e;return t.submitting(t.client.delete(a,r))}))()}},(0,o.default)(l.prototype,""create"",[f.action],(0,i.default)(l.prototype,""create""),l.prototype),(0,o.default)(l.prototype,""deleteDatabase"",[f.action],(0,i.default)(l.prototype,""deleteDatabase""),l.prototype),l);t.InstancesDatabasesStore=m;var p=new m;t.default=p},1350:function(e,t,a){var r=a(4031);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1351:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.getMysqlNodes=t.getRabbitMQNodes=t.getMemcacheNodes=t.defaultGetNodes=void 0;var l=n(a(57)),i=n(a(27)),s=n(a(102)),u=n(a(51)),o=n(a(111)),d=a(1209),c=n(a(1396)),f=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""physicalNode.systemLoad.url[0]""),""current""),{data:{result:t=[]}}=e;return 0===t.length?[{metric:{instance:""""}}]:(0,l.default)(t).call(t,(e=>({metric:{instance:e.metric.instance}})))}));return function(){return e.apply(this,arguments)}}();t.defaultGetNodes=f;var m=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""memcacheService.currentConnections.url[0]""),""current""),{data:{result:t=[]}}=e;return 0===t.length?[{metric:{instance:""""}}]:(0,l.default)(t).call(t,(e=>({metric:{instance:e.metric.instance}})))}));return function(){return e.apply(this,arguments)}}();t.getMemcacheNodes=m;var p=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""rabbitMQService.serviceStatus.url[0]""),""current""),{data:{result:t=[]}}=e;if(0===t.length)return[{metric:{instance:""""}}];var a=[];return(0,i.default)(t).call(t,(e=>{var t={metric:{instance:e.metric.instance}};(0,s.default)(a).call(a,(e=>(0,c.default)(e,t)))||a.push(t)})),a}));return function(){return e.apply(this,arguments)}}();t.getRabbitMQNodes=p;var v=function(){var e=(0,u.default)((function*(){var e=yield(0,d.fetchPrometheus)((0,o.default)(METRICDICT,""mysqlService.runningTime.url[0]""),""current""),{data:{result:t=[]}}=e;return 0===t.length?[{metric:{instance:""""}}]:(0,l.default)(t).call(t,(e=>({metric:{instance:e.metric.instance}})))}));return function(){return e.apply(this,arguments)}}();t.getMysqlNodes=v},1352:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.cephStatusColorMap=a.cephStatusMap=a.fillEmptyMetrics=a.timestampify=a.timeAliasReg=a.isSameDay=a.stopAutoRefresh=a.startAutoRefresh=a.getColorByName=a.getZeroValues=a.getTimesData=a.getLastMonitoringData=a.getXAxisTickFormatter=a.getAreaChartOps=a.getChartData=a.getFormatTime=a.getValueByUnit=a.getSuitableValue=a.getSuitableUnit=void 0;var m=f(r(226)),p=f(r(81)),v=f(r(419)),h=f(r(27)),g=f(r(229)),y=f(r(174)),b=f(r(57)),_=f(r(1265)),x=f(r(198)),C=f(r(588)),S=f(r(620)),D=f(r(4042)),w=f(r(1299)),E=f(r(1204)),I=f(r(62)),P=f(r(36)),T=f(r(4045)),k=f(r(4047)),N=f(r(4049)),M=f(r(1532)),L=f(r(4050)),F=f(r(111)),A=f(r(131)),O=f(r(343)),z=f(r(592)),j=f(r(650)),K=f(r(91)),R=f(r(199)),U=r(334),B=r(569);function q(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function H(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=q(Object(r),!0)).call(a,(function(t){(0,P.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=q(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var V={second:{conditions:[.01,0],units:[""s"",""ms""]},cpu:{conditions:[.1,0],units:[""core"",""m""]},memory:{conditions:[1024**4,1024**3,1048576,1024,0],units:[""TiB"",""GiB"",""MiB"",""KiB"",""Bytes""]},disk:{conditions:[1e3**4,1e3**3,1e6,1e3,0],units:[""TB"",""GB"",""MB"",""KB"",""Bytes""]},throughput:{conditions:[1e3**4,1e3**3,1e6,1e3,0],units:[""TB/s"",""GB/s"",""MB/s"",""KB/s"",""B/s""]},traffic:{conditions:[1e3**4,1e3**3,1e6,1e3,0],units:[""TB/s"",""GB/s"",""MB/s"",""KB/s"",""B/s""]},bandwidth:{conditions:[131072,128,0],units:[""Mbps"",""Kbps"",""bps""]}},Q=(e,t)=>{var a,r=V[t];if((0,R.default)(r))return"""";var n=(0,K.default)(e)?e:[[0,Number(e)]],l=(0,M.default)(r.units);return(0,m.default)(a=r.conditions).call(a,((e,t)=>{var a=(0,m.default)(n).call(n,(t=>(((0,K.default)(t)?(0,F.default)(t,""[1]""):Number(t))||0)>=e));return a&&(l=r.units[t]),a})),l};a.getSuitableUnit=Q;a.getSuitableValue=function(e){var a,r=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""default"",n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0;if(!(0,O.default)(e)&&!(0,A.default)(e)||(0,j.default)(Number(e)))return n;var l=Q(e,r),i=l?"" "".concat(t(l)):"""",s=G(e,l||r);return(0,p.default)(a="""".concat(s)).call(a,i)};var G=(e,t)=>{var a=(0,v.default)(e);switch(t){default:break;case"""":case""default"":return a;case""iops"":return Math.round(a);case""%"":a*=100;break;case""m"":if((a*=1e3)<1)return 0;break;case""KiB"":a/=1024;break;case""MiB"":a/=1048576;break;case""GiB"":a/=1024**3;break;case""TiB"":a/=1024**4;break;case""Bytes"":case""B"":case""B/s"":break;case""KB"":case""KB/s"":a/=1e3;break;case""MB"":case""MB/s"":a/=1e6;break;case""GB"":case""GB/s"":a/=1e3**3;break;case""TB"":case""TB/s"":a/=1e3**4;break;case""bps"":a*=8;break;case""Kbps"":a=8*a/1024;break;case""Mbps"":a=8*a/1024/1024;break;case""ms"":a*=1e3}return 0===Number(a)?0:Number(a.toFixed(2))};a.getValueByUnit=G;var W=e=>(0,B.getStrFromTimestamp)(e).replace(/:00$/g,"""");a.getFormatTime=W;var X=e=>{var t,{type:a,unit:r,xKey:n=""time"",legend:l=[],valuesData:i=[],xFormatter:s}=e,u={};(0,h.default)(i).call(i,((e,t)=>{(0,h.default)(e).call(e,(e=>{var n=(0,g.default)((0,F.default)(e,[0],0),10),i=(0,F.default)(e,[1]),s=(0,F.default)(l,[t]);n&&!u[n]&&(u[n]=(0,y.default)(l).call(l,((e,t)=>(e[t]||(e[t]=null),e)),{})),s&&u[n]&&(u[n][s]=""-1""===i?null:G(i,(0,z.default)(r)?a:r))}))}));var o=e=>""time""===n?W(e):e;return(0,b.default)(t=(0,_.default)(u)).call(t,(e=>{var[t,a]=e;return H({[n]:(s||o)(t)},a)}))};a.getChartData=X;a.getAreaChartOps=e=>{var{type:t,title:a,unitType:r,xKey:n=""time"",legend:l=[],data:i=[],xFormatter:s}=e,u=(0,I.default)(e,[""type"",""title"",""unitType"",""xKey"",""legend"",""data"",""xFormatter""]),o=(0,K.default)(i)?i:[],d=(0,b.default)(o).call(o,(e=>(0,F.default)(e,""values"")||[])),c=r?Q((0,N.default)(d),r):u.unit,f=X({type:t,unit:c,xKey:n,legend:l,valuesData:d,xFormatter:s}),m=""time""===n?Z(f):e=>e;return H(H({},u),{},{title:a,unit:c,xAxisTickFormatter:m,data:f})};var Z=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:[],a=(0,b.default)(e).call(e,(e=>{var{time:t}=e;return+new Date(t)})),r=(0,k.default)(a),n=(0,T.default)(a);return n-r>864e4?e=>(0,B.getLocalTimeStr)(e,t(""Do HH:mm"")):e=>(0,B.getLocalTimeStr)(e,""HH:mm:ss"")};a.getXAxisTickFormatter=Z;a.getLastMonitoringData=e=>{var t,a={};return(0,h.default)(t=(0,_.default)(e)).call(t,(e=>{var[t,r]=e,n=(0,F.default)(r,""data.result[0].values"",[])||[],l=(0,R.default)(n)?(0,F.default)(r,""data.result[0].value"",[])||[]:(0,M.default)(n);(0,L.default)(a,""["".concat(t,""].value""),l)})),a};a.getTimesData=e=>{var t=[];return(0,h.default)(e).call(e,(e=>{var a=(0,F.default)(e,""values"")||[];(0,h.default)(a).call(a,(e=>{var a=(0,F.default)(e,""[0]"",0);(0,x.default)(t).call(t,a)||t.push(a)}))})),(0,C.default)(t).call(t)};a.getZeroValues=()=>{for(var e=[],t=(0,g.default)((0,S.default)()/1e3,10)-6e3,a=0;a<10;a++)e[a]=[t,0],t+=600;return e};a.getColorByName=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:""#fff"";return U.COLORS_MAP[e]||e};a.startAutoRefresh=function(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},a=H({method:""fetchData"",interval:5e3,leading:!0},t);if(e&&e[a.method]){var r=e[a.method];a.leading&&r({autoRefresh:!0}),e.timer=(0,D.default)((()=>{r({autoRefresh:!0})}),a.interval)}};a.stopAutoRefresh=e=>{e&&e.timer&&(clearInterval(e.timer),e.timer=null)};a.isSameDay=(e,t)=>Math.floor(e/864e5)===Math.floor(t/864e5);var J=/(\d+)(\w+)/;a.timeAliasReg=J;a.timestampify=e=>{var[,t=0,a]=e.match(J)||[];return Number(t)*(U.MILLISECOND_IN_TIME_UNIT[a]||0)};a.fillEmptyMetrics=(e,t)=>{var a;if(!e.times||!e.start||!e.end)return t;var r=e=>String(e).replace(/\..*$/,""""),n=Math.floor((e.end-e.start)/e.times),l=e.times+1;return(0,h.default)(a=(0,w.default)(t)).call(a,(t=>{var a=(0,F.default)(t,""data.result"");(0,R.default)(a)||(0,h.default)(a).call(a,(t=>{var a=(0,E.default)(t)||[],i=(0,y.default)(a).call(a,((e,t)=>H(H({},e),{},{[r(t[0])]:t[1]})),{});if(a.length<l){for(var s=[],u=0;u<l;u++){var o=r(e.start+u*n);s.push([o,i[o]||""0""])}t.values=s}}))})),t};var Y={0:t(""Healthy""),1:t(""Warning""),2:t(""Error"")};a.cephStatusMap=Y;a.cephStatusColorMap={0:""#379738"",1:""#FAAD14"",2:""#D93126""}},1353:function(e,t,a){var r=a(4068);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1354:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.BackupsStore=void 0;var l,i=n(a(25)),s=n(a(51)),u=n(a(54)),o=n(a(53)),d=n(a(48)),c=a(34),f=(l=class extends o.default{get client(){return d.default.trove.backups}create(e){var t=this;return(0,s.default)((function*(){return t.client.create(e)}))()}delete(e,t){var a=this;return(0,s.default)((function*(){var{params:r}=e;return a.client.delete(r,t)}))()}},(0,u.default)(l.prototype,""create"",[c.action],(0,i.default)(l.prototype,""create""),l.prototype),(0,u.default)(l.prototype,""delete"",[c.action],(0,i.default)(l.prototype,""delete""),l.prototype),l);t.BackupsStore=f;var m=new f;t.default=m},1355:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.ConfigurationsStore=void 0;var l,i=n(a(25)),s=n(a(51)),u=n(a(54)),o=n(a(53)),d=n(a(48)),c=a(34),f=(l=class extends o.default{get client(){return d.default.trove.configurations}create(e){var t=this;return(0,s.default)((function*(){return t.client.create(e)}))()}delete(e,t){var a=this;return(0,s.default)((function*(){var{params:r}=e;return a.client.delete(r,t)}))()}},(0,u.default)(l.prototype,""create"",[c.action],(0,i.default)(l.prototype,""create""),l.prototype),(0,u.default)(l.prototype,""delete"",[c.action],(0,i.default)(l.prototype,""delete""),l.prototype),l);t.ConfigurationsStore=f;var m=new f;t.default=m},1356:function(e,t,a){""use strict"";var r=a(33),n=a(44),l=a(32),i=a(25),s=a(27),u=a(45),o=a(46),d=a(19),c=a(21);d(t,""__esModule"",{value:!0}),t.default=t.InstancesUsersStore=void 0;var f,m=c(a(57)),p=c(a(32)),v=c(a(102)),h=c(a(25)),g=c(a(36)),y=c(a(51)),b=c(a(62)),_=c(a(54)),x=c(a(53)),C=c(a(48)),S=a(34);function D(e,t){var a=r(e);if(n){var s=n(e);t&&(s=l(s).call(s,(function(t){return i(e,t).enumerable}))),a.push.apply(a,s)}return a}function w(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)s(a=D(Object(r),!0)).call(a,(function(t){(0,g.default)(e,t,r[t])}));else if(u)o(e,u(r));else{var n;s(n=D(Object(r))).call(n,(function(t){d(e,t,i(r,t))}))}}return e}var E=(f=class extends x.default{get client(){return C.default.trove.instances.users}get databaseClient(){return C.default.trove.instances.databases}get instanceClient(){return C.default.trove.instances}get isSubResource(){return!0}get responseKey(){return""user""}get paramsFunc(){return e=>{var{id:t}=e;return(0,b.default)(e,[""id""])}}listDidFetch(e,t,a){var r=this;return(0,y.default)((function*(){if(0===e.length)return e;var{id:t}=a,{databases:n=[]}=yield r.databaseClient.list(t);return(0,m.default)(e).call(e,(e=>{var t,a;return w(w({},e),{},{databases:(0,m.default)(t=(0,p.default)(a=e.databases||[]).call(a,(e=>(0,v.default)(n).call(n,(t=>t.name===e.name))))).call(t,(e=>e.name))})}))}))()}create(e,t){var a=this;return(0,y.default)((function*(){return a.submitting(a.client.create(e,t))}))()}deleteUser(e){var t=this;return(0,y.default)((function*(){var{id:a,name:r}=e;return t.submitting(t.client.delete(a,r))}))()}grantDatabaseAccess(e){var t=this;return(0,y.default)((function*(){var{id:a,name:r,data:n}=e;return t.submitting(t.instanceClient.grantDatabase(a,r,n))}))()}},(0,_.default)(f.prototype,""create"",[S.action],(0,h.default)(f.prototype,""create""),f.prototype),(0,_.default)(f.prototype,""deleteUser"",[S.action],(0,h.default)(f.prototype,""deleteUser""),f.prototype),(0,_.default)(f.prototype,""grantDatabaseAccess"",[S.action],(0,h.default)(f.prototype,""grantDatabaseAccess""),f.prototype),f);t.InstancesUsersStore=E;var I=new E;t.default=I},1415:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.createFetchPrometheusClient=function(e){var{requestType:t,metricKey:a}=e,r=(0,f.default)(METRICDICT,a);return function(){var e=(0,o.default)((function*(e){var a,{params:n={},currentRange:s,interval:u}=e,o=(0,l.default)(a=r.url).call(a,((e,a)=>{var l=(r.finalFormatFunc||[])[a]||p.baseReturnFunc,i=(r.baseParams||[])[a]||{},o=(0,p.getRequestUrl)(e,n,l,i);return(0,p.fetchPrometheus)(o,t,s,u)}));return i.default.all(o)}));return function(t){return e.apply(this,arguments)}}()},t.createDataHandler=function(e){var{formatDataFn:t,typeKey:a,deviceKey:r,modifyKeys:n}=e;return e=>{var i=t(e,a,r,n),o=(0,c.default)(i),f="""",p=[];if((0,d.default)(i)&&0!==i.length&&i[0].device){var v,h=(new m.default).createView().source(i).transform({type:""partition"",groupBy:[""device""]});f=(p=(0,l.default)(v=(0,s.default)(h.rows)).call(v,(e=>(0,u.default)(e).call(e,1,e.length))))[0]}return{retData:o,device:f,devices:p}}};var l=n(a(57)),i=n(a(65)),s=n(a(33)),u=n(a(200)),o=n(a(51)),d=n(a(91)),c=n(a(4033)),f=n(a(111)),m=n(a(4034)),p=a(1209)},1416:function(e,t,a){var r=a(4035);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1417:function(e,t,a){""use strict"";a(19)(t,""__esModule"",{value:!0}),t.default=void 0;var r=a(0),n=a(1209),l=(0,r.createContext)({interval:10,range:(0,n.defaultOneHourAgo)(),node:{metric:{hostname:""""}}});t.default=l},1418:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),c(a,""policyType"",{enumerable:!0,get:function(){return v.default}}),a.InstanceStatus=void 0;var m=f(r(36)),p=r(1195),v=f(r(1300));function h(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function g(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=h(Object(r),!0)).call(a,(function(t){(0,m.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=h(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var y=g(g({},p.instanceStatus),{},{BUILD:t(""Building""),ACTIVE:t(""Active""),ERROR:t(""Error""),DELETE:t(""Delete""),MIGRATE:t(""Migrate""),RESIZE:t(""Resize""),REBOOT:t(""Reboot""),PROMOTE:t(""Promote""),EJECT:t(""Eject"")});a.InstanceStatus=y},1603:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s=i(a(57));a(1198);var u=i(a(1199));a(1196);var o=i(a(1197)),d=i(a(409)),c=i(a(62)),f=i(a(593)),m=i(a(111)),p=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=_(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0)),v=(a(173),a(1309)),h=i(a(1350)),g=i(a(1604)),y=i(a(4036)),b=i(a(1417));function _(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(_=function(e){return e?a:t})(e)}var x=e=>{var{baseTopCardProps:t,baseChartProps:a,topCardList:r,chartCardList:n}=e,l=(0,p.useContext)(b.default);return p.default.createElement(u.default,{gutter:[16,16]},0!==r.length&&p.default.createElement(o.default,{span:24},p.default.createElement(u.default,{gutter:[16,16],style:{width:""100%""}},(0,s.default)(r).call(r,(e=>{var a,r;if(e.hidden)return null;var n=(0,f.default)({},t,e),{span:i,fetchDataParams:s={}}=n,u=(0,c.default)(n,[""span"",""fetchDataParams""]),m={key:u.title};i?m.span=i:m.flex=1;var v,{params:h={}}=s,y={currentRange:l.range,interval:l.interval,params:h};if(null!==(a=l.node)&&void 0!==a&&a.metric.hostname)y.params.hostname=null===(v=l.node)||void 0===v?void 0:v.metric.hostname;else if(null!==(r=l.node)&&void 0!==r&&r.metric.instance){var b;y.params.instance=null===(b=l.node)||void 0===b?void 0:b.metric.instance}return p.default.createElement(o.default,m,p.default.createElement(g.default,(0,d.default)({},u,{fetchDataParams:y})))})))),0!==n.length&&p.default.createElement(o.default,{span:24},"" "",p.default.createElement(u.default,{gutter:[16,16]},(0,s.default)(n).call(n,(e=>{var t,r,n=(0,f.default)({},a,e),{span:i,fetchDataParams:s={}}=n,u=(0,c.default)(n,[""span"",""fetchDataParams""]),m={key:u.title};i?m.span=i:m.flex=1;var v,{params:h={}}=s,g={currentRange:l.range,interval:l.interval,params:h};if(null!==(t=l.node)&&void 0!==t&&t.metric.hostname)g.params.hostname=null===(v=l.node)||void 0===v?void 0:v.metric.hostname;else if(null!==(r=l.node)&&void 0!==r&&r.metric.instance){var b;g.params.instance=null===(b=l.node)||void 0===b?void 0:b.metric.instance}return p.default.createElement(o.default,m,p.default.createElement(y.default,(0,d.default)({},u,{fetchDataParams:g})))})))))};x.defaultProps={baseTopCardProps:{createFetchParams:{requestType:""current""},handleDataParams:{formatDataFn:v.handleResponses},renderContent:e=>{var{data:t}=e;return p.default.createElement(""div"",{className:h.default[""top-content""]},(0,m.default)(t,""[0].y"",0))}},baseChartProps:{span:12,createFetchParams:{requestType:""range""},handleDataParams:{formatDataFn:v.handleResponses},chartProps:{height:300,scale:{y:{nice:!0}}}},topCardList:[],chartCardList:[]};var C=x;t.default=C},1604:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=t.PrometheusContext=void 0,a(1229);var s=i(a(1230));a(560);var u=i(a(412)),o=i(a(51)),d=i(a(32)),c=i(a(57)),f=(a(173),function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=h(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0))),m=i(a(4032)),p=a(1415),v=i(a(1416));function h(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(h=function(e){return e?a:t})(e)}var g=(0,f.createContext)({data:[],device:"""",devices:[]});function y(e,t,a){return t&&0!==a.length?(0,d.default)(e).call(e,(e=>e.device===t)):e}t.PrometheusContext=g;var b=e=>{var{createFetchParams:t,handleDataParams:a,fetchDataParams:r,title:n,visibleHeight:l,extra:i,renderContent:h}=e,[b,_]=(0,f.useState)([]),[x,C]=(0,f.useState)([]),[S,D]=(0,f.useState)(""""),[w,E]=(0,f.useState)([]),[I,P]=(0,f.useState)(!0),T=(0,p.createFetchPrometheusClient)(t),k=(0,p.createDataHandler)(a),N={data:x,device:S,devices:w,modifyKeys:a.modifyKeys};(0,f.useEffect)((()=>{(0,o.default)((function*(){P(!0);var e=yield T(r),{retData:t,device:a,devices:n}=k(e);_(t),D(a),E(n);var l=y(t,a,n);C(l),P(!1)}))()}),[]);var M=f.default.createElement(f.default.Fragment,null,!I&&S&&0!==w.length&&f.default.createElement(u.default,{defaultValue:S,style:{width:150,marginRight:16},options:(0,c.default)(w).call(w,(e=>({label:e,value:e}))),onChange:e=>{P(!0);var t=y(b,e,w);D(e),C(t),P(!1)}}),i&&i({initData:b,chartData:x,device:S,devices:w,modifyKeys:a.modifyKeys,filterChartData:e=>{P(!0);var t=(0,d.default)(b).call(b,e);C(t),P(!1)}}));return f.default.createElement(g.Provider,{value:N},f.default.createElement(s.default,{className:v.default[""remove-extra-padding""],bodyStyle:{minHeight:l+48},title:n,extra:M,loading:I},f.default.createElement(m.default,{style:{width:""100%"",height:l}},(e=>e?f.default.createElement(g.Consumer,null,(e=>h(e))):null))))};b.defaultProps={visibleHeight:100};var _=b;t.default=_},1606:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(174)),i=n(a(36)),s=a(1295),u=n(a(0)),o=n(a(16));class d extends u.default.Component{render(){var{data:e,legendFontSize:t,legendOffsetX:a,middleFontSize:r}=this.props;return(0,s.registerShape)(""interval"",""sliceShape"",{draw(e,t){var{points:a}=e,r=[];return r.push([""M"",a[0].x,a[0].y]),r.push([""L"",a[1].x,a[1].y-.01]),r.push([""L"",a[2].x,a[2].y-.01]),r.push([""L"",a[3].x,a[3].y]),r.push(""Z""),r=this.parsePath(r),t.addShape(""path"",{attrs:{fill:e.color,path:r}})}}),u.default.createElement(s.Chart,{data:e,autoFit:!0,padding:""auto"",appendPadding:[0,20,0,0]},u.default.createElement(s.Coordinate,{type:""theta"",radius:.8,innerRadius:.75}),u.default.createElement(s.Axis,{visible:!1}),u.default.createElement(s.Tooltip,{showTitle:!1}),u.default.createElement(s.Interval,{adjust:""stack"",position:""value"",color:""type"",shape:""sliceShape""}),u.default.createElement(s.Annotation.Text,{position:[""50%"",""50%""],content:(0,l.default)(e).call(e,((e,t)=>e+t.value),0),style:{lineHeight:240,fontSize:r,fill:""#262626"",textAlign:""center""}}),u.default.createElement(s.Legend,{position:""right"",offsetX:a,itemName:{style:{fontSize:t}}}),u.default.createElement(s.Interaction,{type:""element-single-selected""}))}}t.default=d,(0,i.default)(d,""propTypes"",{data:o.default.array,legendFontSize:o.default.number,legendOffsetX:o.default.number,middleFontSize:o.default.number}),(0,i.default)(d,""defaultProps"",{legendFontSize:16,legendOffsetX:-40,middleFontSize:30})},1607:function(e,t,a){var r=a(4060);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},1608:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(4075)),s=l(r(1609)),u=l(r(4080)),o=l(r(4081)),d=l(r(4082)),c=l(r(4083)),f=l(r(4084)),m={actionConfigs:{rowActions:{firstAction:i.default,moreActions:[{action:u.default},{title:t(""Database Instance Status""),actions:[o.default,d.default,c.default]},{title:t(""Configuration Update""),actions:[f.default]}]},primaryActions:[s.default],batchActions:[i.default]},actionConfigsAdmin:{rowActions:{firstAction:i.default},primaryActions:[],batchActions:[i.default]}};a.default=m},1609:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.default=a.StepCreate=void 0;var m=f(r(57)),p=f(r(65));r(1336);var v=f(r(426)),h=f(r(51)),g=f(r(36)),y=r(1193),b=r(406),_=f(r(1221)),x=f(r(407)),C=(r(173),f(r(4076))),S=f(r(4077)),D=f(r(4078)),w=f(r(4079));function E(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function I(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=E(Object(r),!0)).call(a,(function(t){(0,g.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=E(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}class P extends y.StepAction{constructor(){super(...arguments),(0,g.default)(this,""onSubmit"",(e=>{var t,{selectedRowKeys:a=[]}=e.network;return(0,m.default)(a).call(a,(e=>({""net-id"":e}))),t=[{""net-id"":a[0]}],this.store.create({instance:{datastore:{type:e.datastore_type,version:e.datastore_version},name:e.instance_name,flavorRef:e.flavor.selectedRowKeys[0],volume:{size:e.size},availability_zone:e.zone,nics:t,locality:e.locality,configuration:e.configurationGroup,databases:[{character_set:""utf8"",collate:""utf8_general_ci"",name:e.initialDatabases}],users:[{databases:[{name:e.initialDatabases}],name:e.initialAdminUser,password:e.password}]}})}))}init(){this.store=_.default,this.projectStore=x.default,this.getQuota(),this.state.isLoading=!0,this.errorMsg=""""}static allowed(){return p.default.resolve(!0)}get name(){return t(""Create Database Instance"")}get listUrl(){return this.getRoutePath(""databaseInstances"")}get hasConfirmStep(){return!1}get steps(){return[{title:t(""Details *""),component:C.default},{title:t(""Networking *""),component:S.default},{title:t(""Initialize Databases""),component:D.default},{title:t(""Advanced""),component:w.default}]}get showQuota(){return this.props.rootStore.hasAdminOnlyRole}getQuota(){var e=this;return(0,h.default)((function*(){e.showQuota&&(yield e.projectStore.fetchProjectTroveQuota(e.currentProjectId),e.setState({isLoading:!1}))}))()}get quotaInfo(){if(this.state.isLoading)return[];var{instances:e={},volumes:a={}}=this.projectStore.troveQuota||{},{left:r=0}=e||{},{data:{size:n=0}={}}=this.state,l=I(I({},e),{},{add:r?1:0,name:""instance"",title:t(""Database Instance"")}),{left:i=0}=a,s=I(I({},a),{},{add:-1===i||n<=i?n:0,name:""volumeSize"",title:t(""Database Disk (GiB)""),type:""line""});return this.checkQuota(this.state.data,this.projectStore.troveQuota),[l,s]}getQuotaMessage(e,a,r){return-1===a?"""":0===a?t(""Quota: Insufficient { name } quota to create resources."",{name:r}):e>a?t(""Insufficient {name} quota to create resources(left { quota }, input { input })."",{name:r,quota:a,input:e}):""""}checkQuota(e,a){var{instances:{left:r=0}={},volumes:{left:n=0}={}}=a||{},{size:l=0}=e||{},i=this.getQuotaMessage(1,r,t(""Database Instance"")),s=this.getQuotaMessage(l,n,t(""Database Disk (GiB)""));if(i||s){var u=i||s;this.errorMsg!==u&&v.default.error(u),this.errorMsg=u}else this.errorMsg=""""}get disableNext(){return!!this.errorMsg}get disableSubmit(){return!!this.errorMsg}}a.StepCreate=P,(0,g.default)(P,""id"",""create-database-instance""),(0,g.default)(P,""title"",t(""Create Database Instance"")),(0,g.default)(P,""path"",""/database/instances/create""),(0,g.default)(P,""policy"",""instance:create"");var T=(0,b.inject)(""rootStore"")((0,b.observer)(P));a.default=T},4028:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(413)),i=n(a(4029)),s=e=>(0,l.default)(i.default,e);t.default=s},4029:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(1212)),i=n(a(567)),s=n(a(4030)),u=n(a(4052)),o=n(a(4056)),d=n(a(4061)),c=n(a(4067)),f=""/monitor-center"",m=[{path:f,component:l.default,routes:[{path:"""".concat(f,""/overview-admin""),component:c.default,exact:!0},{path:"""".concat(f,""/physical-node-admin""),component:s.default,exact:!0},{path:"""".concat(f,""/storage-cluster-admin""),component:u.default,exact:!0},{path:"""".concat(f,""/openstack-service-admin""),component:o.default,exact:!0},{path:"""".concat(f,""/other-service-admin""),component:d.default,exact:!0},{path:""*"",component:i.default}]}];t.default=m},4030:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=a.chartCardList=a.topCardList=void 0;var i=l(r(229)),s=l(r(27)),u=l(r(419)),o=l(r(57)),d=l(r(81));r(1222);var c=l(r(1223)),f=l(r(111)),m=l(r(0)),p=l(r(119)),v=(r(173),l(r(1263))),h=r(1352),g=r(1209),y=r(161),b=l(r(1350)),_=[{title:t(""CPU Cores""),span:5,createFetchParams:{metricKey:""physicalNode.cpuCores""},renderContent:e=>m.default.createElement(""div"",{className:b.default[""top-content""]},(0,f.default)(e.data,""length"",0))},{title:t(""Total Ram""),span:5,createFetchParams:{metricKey:""physicalNode.totalMem""},renderContent:e=>m.default.createElement(""div"",{className:b.default[""top-content""]},(0,h.getSuitableValue)((0,f.default)(e.data[0],""y"",0),""memory""))},{title:t(""System Running Time""),span:5,createFetchParams:{metricKey:""physicalNode.systemRunningTime""},renderContent:e=>m.default.createElement(""div"",{className:b.default[""top-content""]},(0,y.formatUsedTime)(1e3*((0,p.default)().unix()-(0,i.default)((0,f.default)(e.data[0],""y"",(0,p.default)().unix()),10))))},{title:t(""File System Free Space""),span:9,createFetchParams:{metricKey:""physicalNode.fileSystemFreeSpace""},handleDataParams:{formatDataFn:function(){for(var e=arguments.length,t=new Array(e),a=0;a<e;a++)t[a]=arguments[a];var[r,n,l]=t,[i,o]=r,{data:{result:d}={result:[]}}=i,c=[];return(0,s.default)(d).call(d,((e,t)=>{c.push({mountpoint:(0,f.default)(e,""metric."".concat(l))+(0,f.default)(e,""metric."".concat(n)),avail:(0,u.default)((0,f.default)(e,""value[1]"",0)),total:(0,u.default)((0,f.default)(o,""data.result["".concat(t,""].value[1]""),0))})})),c},typeKey:""mountpoint"",deviceKey:""device""},renderContent:e=>{var t;return m.default.createElement(""div"",{style:{height:100,overflow:""auto""}},(0,o.default)(t=e.data||[]).call(t,((e,t)=>{var a,r=(0,y.computePercentage)(e.avail,e.total)>80?""#FAAD14"":""#1890FF"";return m.default.createElement(""div"",{key:e.mountpoint,style:{marginTop:t>0?16:0}},m.default.createElement(""div"",null,m.default.createElement(""div"",{style:{float:""left""}},e.mountpoint),m.default.createElement(""div"",{style:{float:""right""}},(0,d.default)(a="""".concat((0,y.formatSize)((0,i.default)(e.avail,10)),"" / "")).call(a,(0,y.formatSize)((0,i.default)(e.total,10))))),m.default.createElement(c.default,{style:{width:""95%""},percent:Number(((0,i.default)(e.avail,10)/(0,i.default)(e.total,10)*100).toFixed(3)),strokeColor:r}))})))}}];a.topCardList=_;var x=[{title:t(""CPU Usage(%)""),createFetchParams:{metricKey:""physicalNode.cpuUsage""},handleDataParams:{typeKey:""mode""},chartProps:{chartType:g.ChartType.MULTILINE}},{title:t(""Memory Usage""),createFetchParams:{metricKey:""physicalNode.memUsage""},handleDataParams:{modifyKeys:[t(""Used""),t(""Free"")]},chartProps:{scale:{y:{formatter:e=>(0,h.getSuitableValue)(e,""memory"",0)}},chartType:g.ChartType.MULTILINE}},{title:t(""DISK IOPS""),createFetchParams:{metricKey:""physicalNode.diskIOPS""},handleDataParams:{modifyKeys:[t(""read""),t(""write"")],deviceKey:""device""},chartProps:{chartType:g.ChartType.MULTILINEDEVICES}},{title:t(""DISK Usage(%)""),createFetchParams:{metricKey:""physicalNode.diskUsage""},handleDataParams:{typeKey:""hostname"",deviceKey:""device""},chartProps:{scale:{y:{alias:t(""DISK Usage(%)"")}},chartType:g.ChartType.ONELINEDEVICES}},{title:t(""System Load""),span:24,createFetchParams:{metricKey:""physicalNode.systemLoad""},handleDataParams:{typeKey:""__name__""},chartProps:{chartType:g.ChartType.MULTILINE}},{title:t(""Network Traffic""),span:12,createFetchParams:{metricKey:""physicalNode.networkTraffic""},handleDataParams:{modifyKeys:[t(""receive""),t(""transmit"")],deviceKey:""device""},chartProps:{chartType:g.ChartType.MULTILINEDEVICES,scale:{y:{formatter:e=>(0,h.getSuitableValue)(e,""traffic"",0)}}}},{title:t(""TCP Connections""),span:12,createFetchParams:{metricKey:""physicalNode.tcpConnections""},chartProps:{scale:{y:{alias:t(""TCP Connections"")}},chartType:g.ChartType.ONELINE}},{title:t(""Network Errors""),span:12,createFetchParams:{metricKey:""physicalNode.networkErrors""},handleDataParams:{typeKey:""__name__"",deviceKey:""device""},chartProps:{scale:{y:{alias:t(""Network Errors"")}},chartType:g.ChartType.ONELINE}},{title:t(""Network Dropped Packets""),span:12,createFetchParams:{metricKey:""physicalNode.networkDroppedPackets""},handleDataParams:{modifyKeys:[t(""receive""),t(""transmit"")],deviceKey:""device""},chartProps:{scale:{y:{alias:t(""Network Dropped Packets"")}},chartType:g.ChartType.MULTILINEDEVICES}}];a.chartCardList=x;var C={chartCardList:x,topCardList:_};a.chartConfig=C;var S=()=>m.default.createElement(v.default,{chartConfig:C});a.default=S},4031:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".styles__top-content--qpOa2 {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 120px;\n font-weight: 500;\n font-size: 24px;\n}\n"",""""]),t.locals={""top-content"":""styles__top-content--qpOa2""}},4032:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s,u=i(a(65)),o=i(a(27)),d=i(a(1400)),c=i(a(57)),f=i(a(409)),m=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=p(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0));function p(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(p=function(e){return e?a:t})(e)}var v=(0,a(406).observer)(s=class extends m.Component{constructor(e){super(e),this.state={visible:!window.IntersectionObserver},this.io=null,this.container=null}componentDidMount(){(window.IntersectionObserver?u.default.resolve():a.e(1).then(a.t.bind(null,4235,7))).then((()=>{this.io=new window.IntersectionObserver((e=>{(0,o.default)(e).call(e,(e=>{this.setState({visible:e.isIntersecting})}))}),{}),this.io.observe(this.container)}))}componentWillUnmount(){this.io&&this.io.disconnect()}render(){var e;return m.default.createElement(""div"",(0,f.default)({ref:e=>{this.container=e}},this.props),(0,d.default)(this.props.children)?(0,c.default)(e=this.props.children).call(e,(e=>e(this.state.visible))):this.props.children(this.state.visible))}})||s;t.default=v},4035:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".style__remove-extra-padding--1qIOH .ant-card-extra {\n padding: 0;\n}\n.style__remove-extra-padding--1qIOH .ant-card-head {\n border-bottom: none;\n}\n.style__remove-extra-padding--1qIOH .ant-card-body {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n}\n.style__remove-extra-padding--1qIOH .ant-card-body .ant-card-loading-content {\n width: 100%;\n}\n.style__base-content-container--2-qf6 {\n width: 100%;\n height: 100%;\n padding: 20px;\n overflow-y: scroll;\n}\n.style__base-content-container--2-qf6 .style__refresh--sME80 {\n float: left;\n}\n.style__base-content-container--2-qf6 .style__header--3xQ9T {\n margin-bottom: 16px;\n}\n"",""""]),t.locals={""remove-extra-padding"":""style__remove-extra-padding--1qIOH"",""base-content-container"":""style__base-content-container--2-qf6"",refresh:""style__refresh--sME80"",header:""style__header--3xQ9T""}},4036:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(409));r(333);var s=l(r(332));r(1317);var u=l(r(1318)),o=l(r(62)),d=l(r(593)),c=l(r(0)),f=(r(173),r(1295)),m=l(r(4037)),p=r(1209),v=r(4038),h=l(r(1604)),g=e=>{var{chartProps:a}=e;return c.default.createElement(h.default,(0,i.default)({},e,{renderContent:t=>{var r,{height:n,scale:l,chartType:i,toolTipProps:s=v.baseToolTipProps}=a,{data:u}=t;switch(l.x=(0,d.default)({},(0,p.getXScale)(e.fetchDataParams.currentRange),l.x||{}),i){case p.ChartType.ONELINE:case p.ChartType.ONELINEDEVICES:r=v.baseLineProps;break;case p.ChartType.MULTILINE:case p.ChartType.MULTILINEDEVICES:r=v.multilineProps;break;default:r=v.baseLineProps}return c.default.createElement(f.Chart,{autoFit:!0,padding:""auto"",data:u,height:n,scale:l},c.default.createElement(f.Line,r),c.default.createElement(f.Tooltip,s))},visibleHeight:e.chartProps.height,extra:()=>{var{title:n,createFetchParams:l,handleDataParams:i,fetchDataParams:d,isModal:f=!1}=e,p={},{params:v={}}=d,{instance:h,hostname:g}=v,y=(0,o.default)(v,[""instance"",""hostname""]);return v&&(h?p.instance=h:g&&(p.hostname=g)),c.default.createElement(c.default.Fragment,null,e.extra&&e.extra(),!f&&c.default.createElement(s.default,{type:""text"",icon:c.default.createElement(m.default,null),onClick:()=>{var s;u.default.info({icon:null,content:(s=r(1263).default,c.default.createElement(s,{renderNodeSelect:!1,defaultNode:{metric:p},visibleHeight:e.chartProps.height,chartConfig:{chartCardList:[{title:n,createFetchParams:l,handleDataParams:i,fetchDataParams:{params:y},chartProps:a,span:24,isModal:!0}]}})),width:1200,okText:t(""OK"")})}}))}}))};a.default=g},4038:function(e,t,a){""use strict"";a(19)(t,""__esModule"",{value:!0}),t.baseToolTipProps=t.multilineProps=t.baseLineProps=void 0;t.baseLineProps={position:""x*y""};t.multilineProps={position:""x*y"",color:""type""};t.baseToolTipProps={showCrosshairs:!0,shared:!0}},4039:function(e,a,r){""use strict"";var n=r(160),l=r(19),i=r(25),s=r(21);l(a,""__esModule"",{value:!0}),a.default=void 0;var u=s(r(57));r(560);var o=s(r(412)),d=(r(173),function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=f(t);if(a&&a.has(e))return a.get(e);var r={},n=l&&i;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=n?i(e,s):null;u&&(u.get||u.set)?l(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(r(0))),c=r(1209);function f(e){if(""function""!=typeof n)return null;var t=new n,a=new n;return(f=function(e){return e?a:t})(e)}var{Option:m}=o.default,p=e=>{var a=(0,c.getInterval)(e),[r,n]=(0,d.useState)(a[0].value),l=e=>{n(e)};(0,d.useEffect)((()=>{a=(0,c.getInterval)(e),l(a[0].value)}),[e]);return[r,()=>d.default.createElement(d.default.Fragment,null,d.default.createElement(""span"",{style:{marginLeft:20,fontSize:14,fontWeight:400,color:""rgba(0,0,0,.85)""}},t(""Time Interval: "")),d.default.createElement(o.default,{value:r,style:{width:120},onChange:l},(0,u.default)(a).call(a,(e=>d.default.createElement(m,{key:e.value,value:e.value},e.text)))))]};a.default=p},4040:function(e,a,r){""use strict"";var n=r(160),l=r(19),i=r(25),s=r(21);l(a,""__esModule"",{value:!0}),a.default=void 0,r(581);var u=s(r(423));r(1319);var o=s(r(1320)),d=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=m(t);if(a&&a.has(e))return a.get(e);var r={},n=l&&i;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=n?i(e,s):null;u&&(u.get||u.set)?l(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(r(0)),c=(r(173),s(r(119))),f=r(1209);function m(e){if(""function""!=typeof n)return null;var t=new n,a=new n;return(m=function(e){return e?a:t})(e)}var{RangePicker:p}=o.default;var v=function(e){var[a,r]=(0,d.useState)(0),[n,l]=(0,d.useState)(e),i=e=>{var t=e.target.value;r(t),l((0,f.getRange)(t))},s=e=>{r(4),l(e)};return[n,()=>d.default.createElement(u.default.Group,{value:a,onChange:i,style:{marginLeft:20}},d.default.createElement(u.default.Button,{value:0},t(""Last Hour"")),d.default.createElement(u.default.Button,{value:1},t(""Last Day"")),d.default.createElement(u.default.Button,{value:2},t(""Last 7 Days"")),d.default.createElement(u.default.Button,{value:3},t(""Last 2 Weeks"")),d.default.createElement(u.default.Button,{value:4,style:{float:""right"",padding:0}},d.default.createElement(p,{showTime:{hideDisabledOptions:!0,defaultValue:[(0,c.default)(""00:00:00"",""HH:mm:ss""),(0,c.default)(""00:00:00"",""HH:mm:ss"")]},disabledDate:g,disabledTime:h,onChange:s,value:n,bordered:!1,allowClear:!1}))),a,l]};function h(e){var t=(0,c.default)();if(t.isSame(e,""day""))return t.isSame(e,""hour"")?t.isSame(e,""minutes"")?{disabledHours:()=>y(t.hour()+1,24),disabledMinutes:()=>y(t.minute()+1,60),disabledSeconds:()=>y(t.second()+1,60)}:{disabledHours:()=>y(t.hour()+1,24),disabledMinutes:()=>y(t.minute()+1,60)}:{disabledHours:()=>y(t.hour()+1,24)}}function g(e){return e>(0,c.default)().endOf(""day"")}function y(e,t){for(var a=[],r=e;r<t;r++)a.push(r);return a}a.default=v},4041:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=void 0;var s=i(a(102)),u=i(a(57));a(560);var o=i(a(412)),d=i(a(111)),c=(a(173),function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=m(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0))),f=i(a(1416));function m(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(m=function(e){return e?a:t})(e)}var{Option:p}=o.default,v=e=>{var[t,a]=(0,c.useState)(e),[r,n]=(0,c.useState)([]),l=e=>{var t=i();a((0,s.default)(r).call(r,(a=>a.metric[t]===e)))};return[t,()=>{var e=i();return c.default.createElement(""div"",{className:f.default.header},c.default.createElement(""span"",{style:{color:""black"",fontSize:14,fontWeight:400}},""Node:"","" ""),c.default.createElement(o.default,{value:t.metric[e],onChange:l,style:{minWidth:150}},(0,u.default)(r).call(r,(t=>c.default.createElement(p,{key:t.metric[e],value:t.metric[e]},t.metric[e])))))},a,n];function i(){var e=""instance"";return(0,d.default)(t,""metric.hostname"",!1)&&(e=""hostname""),e}};t.default=v},4052:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(27)),s=l(r(81));r(1222);var u=l(r(1223));r(1198);var o=l(r(1199));r(1196);var d=l(r(1197)),c=l(r(111)),f=l(r(0)),m=(r(173),l(r(1263))),p=r(1352),v=l(r(1606)),h=r(1309),g=r(161),y=r(1209),b=l(r(4053)),_=l(r(4054)),x=()=>{var e=[{title:t(""Storage Cluster Status""),span:6,createFetchParams:{metricKey:""storageCluster.cephHealthStatus""},renderContent:e=>{var{data:t}=e,a=(0,c.default)(t,""y"",0);return f.default.createElement(""div"",{className:_.default[""top-content""],style:{fontSize:28,fontWeight:600,color:p.cephStatusColorMap[a]}},p.cephStatusMap[a])}},{title:""Monitors"",span:9,createFetchParams:{metricKey:""storageCluster.cephMonitorStatus""},handleDataParams:{formatDataFn:function(){var e=(0,h.handleResponses)(...arguments),t=[{type:""down"",value:0},{type:""up"",value:0}];return(0,i.default)(e).call(e,(e=>{var a=t[e.y].value+1;t[e.y].value=a})),t}},renderContent:e=>{var{data:t}=e;return f.default.createElement(""div"",null,f.default.createElement(""div"",{style:{height:120}},f.default.createElement(v.default,{data:t})))}},{title:""PGs"",span:9,createFetchParams:{metricKey:""storageCluster.cephPGS""},handleDataParams:{formatDataFn:function(){var e=(0,h.handleResponses)(...arguments);return[{type:""clean"",value:(0,c.default)(e,""[0].y"",0)},{type:""others"",value:(0,c.default)(e,""[1].y"",0)}]}},renderContent:e=>{var{data:t}=e;return f.default.createElement(""div"",null,f.default.createElement(""div"",{style:{height:120}},f.default.createElement(v.default,{data:t})))}},{title:""OSDs"",span:9,createFetchParams:{metricKey:""storageCluster.osdData""},handleDataParams:{formatDataFn:e=>{function t(e){return(0,c.default)(e,""data.result[0].value[1]"",0)}var[a,r,n,l]=e;return{inUp:t(a),inDown:t(r),outUp:t(n),outDown:t(l)}}},renderContent:e=>{var{data:a}=e;return f.default.createElement(o.default,{className:_.default.osd},f.default.createElement(d.default,{span:8}),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""Up"")),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""Down"")),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""In Cluster"")),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.inUp),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.inDown),f.default.createElement(d.default,{span:8,style:{fontSize:14,opacity:.8}},t(""Out Cluster"")),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.outUp),f.default.createElement(d.default,{span:8,style:{fontSize:18}},a.outDown))}},{title:t(""Average PGs per OSD""),span:5,createFetchParams:{metricKey:""storageCluster.avgPerOSD""}},{title:t(""Storage Cluster Usage""),span:10,createFetchParams:{metricKey:""storageCluster.storageClusterUsage""},renderContent:e=>{var a,r,n,{data:l}=e,i=(0,c.default)(l[0],""y"",0),d=(0,c.default)(l[1],""y"",0),m=(0,p.getSuitableValue)(i,""disk""),v=(0,p.getSuitableValue)(d,""disk""),h=(0,g.computePercentage)(i,d);return f.default.createElement(""div"",{className:_.default[""top-content""]},f.default.createElement(""div"",{style:{width:""100%"",height:""100%""}},f.default.createElement(o.default,{style:{justifyContent:""flex-end"",height:""50%""}},f.default.createElement(""span"",{style:{fontSize:12,marginRight:32}},(0,s.default)(a=(0,s.default)(r=(0,s.default)(n="""".concat(t(""Used""),"" "")).call(n,m,"" / "")).call(r,t(""Total""),"" "")).call(a,v))),f.default.createElement(o.default,{style:{height:""50%""}},f.default.createElement(u.default,{style:{width:""95%""},percent:h,strokeColor:h>80?""#FAAD14"":""#1890FF"",showInfo:100!==h}))))}}],a={chartCardList:[{title:t(""Storage Pool Capacity Usage""),createFetchParams:{metricKey:""storageCluster.poolCapacityUsage""},handleDataParams:{modifyKeys:[t(""used""),t(""available"")]},chartProps:{chartType:y.ChartType.MULTILINE,scale:{y:{formatter:e=>(0,p.getSuitableValue)(e,""disk"",0)}}}},{title:t(""Storage Cluster OSD Latency""),createFetchParams:{metricKey:""storageCluster.clusterOSDLatency""},handleDataParams:{modifyKeys:[""apply"",""commit""]},chartProps:{chartType:y.ChartType.MULTILINE}},{title:t(""Storage Cluster IOPS""),createFetchParams:{metricKey:""storageCluster.clusterIOPS""},handleDataParams:{modifyKeys:[t(""read""),t(""write"")]},chartProps:{chartType:y.ChartType.MULTILINE}},{title:t(""Storage Cluster Bandwidth""),createFetchParams:{metricKey:""storageCluster.clusterBandwidth""},handleDataParams:{modifyKeys:[t(""in""),t(""out"")]},chartProps:{scale:{y:{formatter:e=>(0,p.getSuitableValue)(e,""bandwidth"",0)}},chartType:y.ChartType.MULTILINE}}],topCardList:e};return f.default.createElement(m.default,{renderNodeSelect:!1,chartConfig:a},f.default.createElement(b.default,null))};a.default=x},4053:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(160),m=r(21);c(a,""__esModule"",{value:!0}),a.default=void 0;var p=m(r(27)),v=m(r(419)),h=m(r(32)),g=m(r(33)),y=m(r(57)),b=m(r(1338)),_=m(r(90)),x=m(r(229)),C=m(r(65)),S=m(r(62)),D=m(r(51)),w=m(r(36));r(1260);var E=m(r(1261)),I=m(r(111)),P=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=A(t);if(a&&a.has(e))return a.get(e);var r={},n=c&&s;for(var l in e)if(""default""!==l&&Object.prototype.hasOwnProperty.call(e,l)){var i=n?s(e,l):null;i&&(i.get||i.set)?c(r,l,i):r[l]=e[l]}r.default=e,a&&a.set(e,r);return r}(r(0)),T=(r(173),r(1415)),k=m(r(1530)),N=r(1209),M=r(161),L=m(r(429)),F=m(r(1417));function A(e){if(""function""!=typeof f)return null;var t=new f,a=new f;return(A=function(e){return e?a:t})(e)}function O(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function z(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=O(Object(r),!0)).call(a,(function(t){(0,w.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=O(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var{TabPane:j}=E.default,K=()=>{var[e,a]=(0,P.useState)({}),[r,n]=(0,P.useState)([]),[l,i]=(0,P.useState)([]),[s,u]=(0,P.useState)(""pool""),[o,d]=(0,P.useState)(!0),c=(0,P.useContext)(F.default),f=(0,T.createFetchPrometheusClient)({requestType:""current"",metricKey:""storageCluster.tabs""}),m=(0,T.createDataHandler)({modifyKeys:[""pools"",""osds""],formatDataFn:e=>{var t,a,r=[],[n,l]=e;return(0,p.default)(t=(0,I.default)(n,""data.result"",[])).call(t,(e=>{var{metric:t,value:a}=e;r.push(z(z({type:""pool""},t),{},{value:(0,v.default)(a[1])||0}))})),(0,p.default)(a=(0,I.default)(l,""data.result"",[])).call(a,(e=>{var{metric:t,value:a}=e;r.push(z(z({type:""osd""},t),{},{value:(0,v.default)(a[1])||0}))})),r}});function w(t){var a,r=(0,h.default)(t).call(t,(e=>e.type===s));(0,p.default)(a=(0,g.default)(e)).call(a,(t=>{r=(0,h.default)(r).call(r,(a=>a[t]===e[t]))})),i(r)}function M(e){return A.apply(this,arguments)}function A(){return(A=(0,D.default)((function*(e){var t,a,r=[...e],n=(0,y.default)(t=(0,I.default)(METRICDICT,""storageCluster.poolTab.url"",[])).call(t,(e=>(0,N.fetchPrometheus)(e,""current""))),l=(0,y.default)(a=(0,I.default)(METRICDICT,""storageCluster.osdTab.url"",[])).call(a,(e=>(0,N.fetchPrometheus)(e,""current"")));function i(e,t,a){var n;(0,p.default)(n=e.data.result).call(n,(e=>{var n,{metric:l,value:i}=e,s=(0,b.default)(r).call(r,(e=>e[a]===l[a]));3===t?r[s].usage=(0,v.default)((0,v.default)(i[1]).toFixed(2)):(0,_.default)(n=[""ceph_pool_objects"",""ceph_pg_total"",""ceph_pool_max_avail"",""ceph_osd_weight"",""ceph_osd_apply_latency_ms"",""ceph_osd_commit_latency_ms"",""ceph_osd_stat_bytes""]).call(n,l.__name__)>-1?r[s][l.__name__]=(0,x.default)(i[1],10):r[s][l.__name__]=i[1]}))}var s=yield C.default.all(n);(0,p.default)(s).call(s,((e,t)=>{i(e,t,""pool_id"")}));var u=yield C.default.all(l);return(0,p.default)(u).call(u,((e,t)=>{i(e,t,""ceph_daemon"")})),r}))).apply(this,arguments)}function O(){return(O=(0,D.default)((function*(){d(!0);var e=yield f({currentRange:c.range,interval:c.interval}),{retData:t}=m(e),a=yield M(t);n(a),w(a),d(!1)}))).apply(this,arguments)}(0,P.useEffect)((()=>{!function(){O.apply(this,arguments)}()}),[]),(0,P.useEffect)((()=>{w(r)}),[s,e]);var K=""pool""===s?R:U;return P.default.createElement(P.default.Fragment,null,P.default.createElement(E.default,{defaultActiveKey:""pool"",onChange:e=>{a({}),u(e)}},P.default.createElement(j,{tab:""Pools"",key:""pool""}),P.default.createElement(j,{tab:""OSDs"",key:""osd""})),P.default.createElement(k.default,{isLoading:o,resourceName:""pool""===s?t(""Pools""):t(""OSDs""),rowKey:""pool""===s?""pool_id"":""name"",columns:K,data:l,pagination:z(z({},new L.default),{},{total:l.length}),hideRefresh:!0,searchFilters:""pool""===s?[{label:t(""Pool Name""),name:""name""}]:[{label:t(""Name""),name:""ceph_daemon""}],itemActions:[],onFilterChange:e=>{var{limit:t,page:r,sortKey:n,sortOrder:l}=e,i=(0,S.default)(e,[""limit"",""page"",""sortKey"",""sortOrder""]);a(i)}}))};a.default=K;var R=[{title:t(""Pool Name""),dataIndex:""name""},{title:t(""PG Count""),dataIndex:""ceph_pg_total"",isHideable:!0},{title:t(""Object Count ""),dataIndex:""ceph_pool_objects"",isHideable:!0},{title:t(""Max Avail""),dataIndex:""ceph_pool_max_avail"",render:e=>(0,M.formatSize)(e),isHideable:!0},{title:t(""Usage""),dataIndex:""usage"",render:e=>"""".concat(e,""%""),isHideable:!0}],U=[{title:t(""Name""),dataIndex:""ceph_daemon""},{title:t(""Status""),dataIndex:""ceph_osd_up"",render:e=>""1""===e?t(""Up""):t(""Down""),isHideable:!0},{title:t(""Instance Addr""),dataIndex:""cluster_addr"",isHideable:!0},{title:t(""Weight""),dataIndex:""ceph_osd_weight"",isHideable:!0},{title:t(""Apply Latency(ms)""),dataIndex:""ceph_osd_apply_latency_ms"",isHideable:!0},{title:t(""Commit Latency(ms)""),dataIndex:""ceph_osd_commit_latency_ms"",isHideable:!0},{title:t(""Total Capacity""),dataIndex:""ceph_osd_stat_bytes"",render:e=>(0,M.formatSize)(e),isHideable:!0},{title:t(""Usage""),dataIndex:""usage"",render:e=>"""".concat((0,v.default)(e).toFixed(2),""%""),isHideable:!0}]},4054:function(e,t,a){var r=a(4055);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},4055:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__osd--2HtuM {\n height: 100%;\n color: rgba(0, 0, 0, 0.85);\n font-weight: 500;\n font-size: 16px;\n text-align: center;\n}\n.index__header--246Eo {\n padding: 20px;\n overflow: auto;\n}\n.index__header--246Eo .index__range--3UhTc .ant-radio-button-wrapper {\n color: rgba(0, 0, 0, 0.65);\n}\n.index__header--246Eo .index__range--3UhTc .ant-radio-button-wrapper-checked {\n color: #0068ff;\n}\n.index__header--246Eo .index__download--21jst {\n float: right;\n}\n.index__header--246Eo .index__download--21jst .ant-btn-icon-only {\n border-radius: 4px;\n}\n.index__my-card-row--rBTsX .index__top--3Nx2m .index__content--2R7tG {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 100%;\n font-size: 24px;\n text-align: center;\n}\n.index__my-card-row--rBTsX .index__top--3Nx2m .ant-card-bordered {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-orient: vertical;\n -webkit-box-direction: normal;\n -ms-flex-direction: column;\n flex-direction: column;\n}\n.index__my-card-row--rBTsX .index__top--3Nx2m .ant-card-bordered .ant-card-body {\n -webkit-box-flex: 1;\n -ms-flex-positive: 1;\n flex-grow: 1;\n padding-top: 0;\n overflow: hidden;\n}\n.index__my-card-row--rBTsX .ant-card-bordered {\n -webkit-box-shadow: 0 2px 20px 0 rgba(0, 0, 0, 0.09);\n box-shadow: 0 2px 20px 0 rgba(0, 0, 0, 0.09);\n}\n.index__my-card-row--rBTsX .ant-card-bordered .ant-card-head {\n border-bottom: none;\n}\n.index__outer--3mHPU {\n position: relative;\n width: 100%;\n height: 100%;\n overflow: hidden;\n font-size: 12px;\n}\n.index__outer--3mHPU .index__inner--1HrRB {\n position: absolute;\n left: 0;\n width: 100%;\n height: 100%;\n overflow-x: hidden;\n overflow-y: scroll;\n}\n.index__outer--3mHPU .index__inner--1HrRB::-webkit-scrollbar {\n display: none;\n}\n.index__top-content--2QZJv {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 120px;\n font-weight: 500;\n font-size: 24px;\n}\n.index__tabs--1be8Z .ant-tabs-tab {\n margin-right: 20px;\n border-bottom: 1px solid #f0f0f0;\n}\n.index__tabs--1be8Z .ant-tabs-nav::before {\n border-bottom: none;\n}\n.index__spin-container--2aH9q {\n width: 100%;\n min-height: 400px;\n padding: 30px 50px;\n text-align: center;\n}\n"",""""]),t.locals={osd:""index__osd--2HtuM"",header:""index__header--246Eo"",range:""index__range--3UhTc"",download:""index__download--21jst"",""my-card-row"":""index__my-card-row--rBTsX"",top:""index__top--3Nx2m"",content:""index__content--2R7tG"",outer:""index__outer--3mHPU"",inner:""index__inner--1HrRB"",""top-content"":""index__top-content--2QZJv"",tabs:""index__tabs--1be8Z"",""spin-container"":""index__spin-container--2aH9q""}},4056:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(160),m=r(21);c(a,""__esModule"",{value:!0}),a.default=a.OpenstackService=void 0;var p=m(r(562));r(333);var v=m(r(332)),h=m(r(1273)),g=m(r(51)),y=m(r(36)),b=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=w(t);if(a&&a.has(e))return a.get(e);var r={},n=c&&s;for(var l in e)if(""default""!==l&&Object.prototype.hasOwnProperty.call(e,l)){var i=n?s(e,l):null;i&&(i.get||i.set)?c(r,l,i):r[l]=e[l]}r.default=e,a&&a.set(e,r);return r}(r(0)),_=r(406),x=r(4057),C=(r(555),r(173),m(r(140))),S=m(r(4059)),D=m(r(1607));function w(e){if(""function""!=typeof f)return null;var t=new f,a=new f;return(w=function(e){return e?a:t})(e)}function E(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function I(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=E(Object(r),!0)).call(a,(function(t){(0,y.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=E(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}class P extends b.Component{constructor(e){var t;super(e),t=this,(0,y.default)(this,""getData"",(0,g.default)((function*(){yield t.store.getChartData()}))),(0,y.default)(this,""handleRefresh"",(()=>{this.getData()}));var{Store:a=x.OpenstackServiceStore}=e;this.store=new a}componentDidMount(){this.getData()}get enableCinder(){return C.default.checkEndpoint(""cinder"")}render(){var{nova_service:e,network_service:a,other_service:r,cinder_service:n}=this.store,l=[I({key:""nova_service"",title:t(""Nova Service"")},e),I({key:""network_service"",title:t(""Neutron Service"")},a),I({key:""other_service"",title:t(""Other Service"")},r)];return this.enableCinder&&(0,p.default)(l).call(l,2,0,I({key:""cinder_service"",title:t(""Cinder Service"")},n)),b.default.createElement(""div"",{className:D.default.container},b.default.createElement(v.default,{type:""default"",icon:b.default.createElement(h.default,null),onClick:this.handleRefresh}),b.default.createElement(S.default,{serviceMap:l}))}}a.OpenstackService=P;var T=(0,_.observer)(P);a.default=T},4057:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.OpenstackServiceStore=void 0;var i,s,u,o,d,c,f,m,p,v,h=l(r(65)),g=l(r(27)),y=l(r(1338)),b=l(r(51)),_=l(r(71)),x=(l(r(36)),l(r(54))),C=(l(r(72)),r(34)),S=r(1209),D=l(r(4058)),w={mysql_up:t(""Database Service""),rabbitmq_identity_info:t(""Message Queue Service""),memcached_up:t(""Cache Service"")},E=[t(""Database Service""),t(""Message Queue Service""),t(""Cache Service"")],I=(i=class extends D.default{constructor(){super(...arguments),(0,_.default)(this,""nova_service"",s,this),(0,_.default)(this,""network_service"",u,this),(0,_.default)(this,""cinder_service"",o,this),(0,_.default)(this,""other_service"",d,this),(0,_.default)(this,""getChartData"",c,this),(0,_.default)(this,""getNovaService"",f,this),(0,_.default)(this,""getNetworkService"",m,this),(0,_.default)(this,""getCinderService"",p,this),(0,_.default)(this,""getOtherService"",v,this)}},s=(0,x.default)(i.prototype,""nova_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),u=(0,x.default)(i.prototype,""network_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),o=(0,x.default)(i.prototype,""cinder_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),d=(0,x.default)(i.prototype,""other_service"",[C.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return{isLoading:!1,data:[]}}}),c=(0,x.default)(i.prototype,""getChartData"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){var t=[e.getNovaService(),e.getNetworkService(),e.getCinderService(),e.getOtherService()];yield h.default.all(t)}))}}),f=(0,x.default)(i.prototype,""getNovaService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.nova_service,{isLoading:!0,data:[]});var t=[];try{var[a,r,n,l]=yield h.default.all((0,S.getPromises)(""openstackService.novaService"")),{data:{result:i}}=a;(0,g.default)(i).call(i,(e=>{var{metric:{service:a="""",adminState:r="""",hostname:n=""""}={}}=e;t.push({hostname:n,serviceName:a,state:""enabled""===r?""up"":""down""})}));var{data:{result:s}}=r;(0,g.default)(s).call(s,(e=>{var{metric:{service:a="""",hostname:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===a&&e.hostname===r));t[n]["""".concat(a,""24"")]=""down""}));var{data:{result:u}}=n;(0,g.default)(u).call(u,(e=>{var{metric:a,value:r}=e;t.push({serviceName:""nova_libvirt"",hostname:a.hostname,state:""enabled""===r[1]?""up"":""down""})}));var{data:{result:o}}=l;(0,g.default)(o).call(o,(e=>{var{metric:{hostname:a=""""}={}}=e,r=(0,y.default)(t).call(t,(e=>""nova_libvirt""===e.serviceName&&e.hostname===a));t[r].nova_libvirt24=""down""}))}finally{(0,C.set)(e.nova_service,{isLoading:!1,data:t})}}))}}),m=(0,x.default)(i.prototype,""getNetworkService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.network_service,{isLoading:!0,data:[]});var t=[];try{var[a,r]=yield h.default.all(S.getPromises.call(e,""openstackService.networkService"")),{data:{result:n}}=a;(0,g.default)(n).call(n,(e=>{var{metric:{service:a="""",adminState:r="""",hostname:n=""""}={}}=e;t.push({serviceName:a,hostname:n,state:r})}));var{data:{result:l}}=r;(0,g.default)(l).call(l,(e=>{var{metric:{service:a="""",hostname:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===a&&e.hostname===r));t[n]["""".concat(a,""24"")]=""down""}))}finally{(0,C.set)(e.network_service,{isLoading:!1,data:t})}}))}}),p=(0,x.default)(i.prototype,""getCinderService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.cinder_service,{isLoading:!0,data:[]});var t=[];try{var[a,r]=yield h.default.all(S.getPromises.call(e,""openstackService.cinderService"")),{data:{result:n}}=a;(0,g.default)(n).call(n,(e=>{var{metric:{service:a="""",adminState:r="""",hostname:n=""""}={}}=e;t.push({serviceName:a,hostname:n,state:""enabled""===r?""up"":""down""})}));var{data:{result:l}}=r;(0,g.default)(l).call(l,(e=>{var{metric:{service:a="""",hostname:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===a&&e.hostname===r));t[n]["""".concat(a,""24"")]=""down""}))}finally{(0,C.set)(e.cinder_service,{isLoading:!1,data:t})}}))}}),v=(0,x.default)(i.prototype,""getOtherService"",[C.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return(0,b.default)((function*(){(0,C.set)(e.other_service,{isLoading:!0,data:[]});var t=[];try{var a=yield h.default.all(S.getPromises.call(e,""openstackService.otherService""));(0,g.default)(a).call(a,(e=>{var{data:{result:a}}=e;(0,g.default)(a).call(a,(e=>{var{metric:a,value:r}=e;t.push({serviceName:w[a.__name__],hostname:a.instance,state:""1""===r[1]?""up"":""down""})}))})),a=yield h.default.all(S.getPromises.call(e,""openstackService.otherServiceMinOverTime"")),(0,g.default)(a).call(a,((e,a)=>{var{data:{result:r}}=e;(0,g.default)(r).call(r,(e=>{var{metric:{instance:r=""""}={}}=e,n=(0,y.default)(t).call(t,(e=>e.serviceName===E[a]&&e.hostname===r));t[n]["""".concat(E[a],""24"")]=""down""}))}))}finally{(0,C.set)(e.other_service,{isLoading:!1,data:t})}}))}}),i);a.OpenstackServiceStore=I;var P=new I;a.default=P},4058:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l,i,s,u,o,d,c,f=n(a(419)),m=n(a(229)),p=n(a(33)),v=n(a(25)),h=n(a(32)),g=n(a(580)),y=n(a(51)),b=n(a(71)),_=(n(a(36)),n(a(54))),x=(n(a(72)),a(34)),C=a(1209),S=a(569),D=n(a(53)),w=(l=class extends D.default{constructor(){super(...arguments),(0,b.default)(this,""currentRange"",i,this),(0,b.default)(this,""interval"",s,this),(0,b.default)(this,""loading"",u,this),(0,b.default)(this,""handleRangePickerChange"",o,this),(0,b.default)(this,""handleIntervalChange"",d,this),(0,b.default)(this,""handleDeviceChange"",c,this)}get responseKey(){return""""}get intervals(){return(0,C.getInterval)(this.currentRange)}formatToGiB(e){return(0,f.default)(((0,m.default)(e,10)/1073741824).toFixed(2))}buildRequest(e){var t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:""range"",a=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},r=0===(0,p.default)(a).length?e:(0,C.addParams)(e,a);return""current""===t?this.skylineClient.query.list({query:r}):this.skylineClient.queryRange.list({query:r,start:(0,S.getTimestamp)(this.currentRange[0]),end:(0,S.getTimestamp)(this.currentRange[1]),step:this.interval})}},i=(0,_.default)(l.prototype,""currentRange"",[x.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return(0,C.defaultOneHourAgo)()}}),s=(0,_.default)(l.prototype,""interval"",[x.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return 10}}),u=(0,_.default)(l.prototype,""loading"",[x.observable],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return!0}}),o=(0,_.default)(l.prototype,""handleRangePickerChange"",[x.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){var t=(0,y.default)((function*(t){var a=arguments.length>1&&void 0!==arguments[1]&&arguments[1];a||(0,S.getTimestamp)(e.currentRange[0])===(0,S.getTimestamp)(t[0])&&(0,S.getTimestamp)(e.currentRange[1])===(0,S.getTimestamp)(t[1])?e.currentRange=t:(e.currentRange=t,e.interval=e.intervals[0].value),yield e.getChartData()}));return function(e){return t.apply(this,arguments)}}()}}),(0,_.default)(l.prototype,""intervals"",[x.computed],(0,v.default)(l.prototype,""intervals""),l.prototype),d=(0,_.default)(l.prototype,""handleIntervalChange"",[x.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){var e=this;return function(){var t=(0,y.default)((function*(t){e.interval=t,yield e.getChartData()}));return function(e){return t.apply(this,arguments)}}()}}),c=(0,_.default)(l.prototype,""handleDeviceChange"",[x.action],{configurable:!0,enumerable:!0,writable:!0,initializer:function(){return(e,t)=>{var a,r=this[t];(0,x.set)(r,{isLoading:!0});var n=(0,h.default)(a=r.data).call(a,(t=>t.device===e));(0,g.default)((()=>{(0,x.set)(r,{currentDevice:e,currentShowData:n,isLoading:!1})}),200)}}}),l);t.default=w},4059:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(57));r(1394);var s=l(r(1329));r(1196);var u=l(r(1197));r(411);var o=l(r(227)),d=l(r(1522)),c=l(r(1521));r(1404);var f=l(r(1405)),m=l(r(0)),p=(r(173),r(555),l(r(1607))),{Panel:v}=f.default,h={up:m.default.createElement(c.default,{style:{fontSize:24,marginLeft:36},twoToneColor:""#52C41A""}),down:m.default.createElement(d.default,{style:{fontSize:24,marginLeft:36},twoToneColor:""#EB354D""})},g=e=>{var{serviceMap:a}=e;return m.default.createElement(f.default,{defaultActiveKey:(0,i.default)(a).call(a,(e=>e.key)),ghost:!0},(0,i.default)(a).call(a,(e=>m.default.createElement(v,{header:m.default.createElement(""span"",{className:p.default.header},e.title),key:e.key},m.default.createElement(s.default,{bordered:!0,dataSource:e.data,className:p.default.list,loading:e.isLoading,renderItem:e=>m.default.createElement(s.default.Item,{className:p.default.item},m.default.createElement(u.default,{className:p.default.title,span:6},e.engine_id?m.default.createElement(o.default,{title:e.engine_id},m.default.createElement(""span"",null,e.serviceName)):e.serviceName),m.default.createElement(u.default,{className:p.default.title,span:6},e.hostname||e.host),m.default.createElement(u.default,{className:p.default.status,span:6},m.default.createElement(""span"",null,t(""Current Status"")),h[e.state]),m.default.createElement(u.default,{className:p.default.status,span:6},m.default.createElement(""span"",null,t(""Last 24H Status""),"" ""),e["""".concat(e.serviceName,""24"")]?h[e["""".concat(e.serviceName,""24"")]]:h.up))})))))};a.default=g},4060:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__header--2Tct3 {\n color: rgba(0, 0, 0, 0.85);\n font-weight: 500;\n font-size: 16px;\n line-height: 22px;\n}\n.index__list--AK4zu {\n background-color: #fff;\n border: none;\n -webkit-box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n}\n.index__list--AK4zu .index__item--2Dqsf {\n height: 76px;\n}\n.index__list--AK4zu .index__item--2Dqsf .index__title--Tai7z {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 16px;\n}\n.index__list--AK4zu .index__item--2Dqsf .index__status--2Ke1i {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 14px;\n}\n.index__container--22t9I {\n height: 100%;\n padding: 16px;\n overflow: auto;\n}\n"",""""]),t.locals={header:""index__header--2Tct3"",list:""index__list--AK4zu"",item:""index__item--2Dqsf"",title:""index__title--Tai7z"",status:""index__status--2Ke1i"",container:""index__container--22t9I""}},4061:function(e,t,a){""use strict"";var r=a(160),n=a(19),l=a(25),i=a(21);n(t,""__esModule"",{value:!0}),t.default=t.OtherService=void 0,a(581);var s=i(a(423)),u=i(a(36)),o=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=v(t);if(a&&a.has(e))return a.get(e);var r={},i=n&&l;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=i?l(e,s):null;u&&(u.get||u.set)?n(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(a(0)),d=a(406),c=(a(173),i(a(4062))),f=i(a(4063)),m=i(a(4064)),p=i(a(4065));function v(e){if(""function""!=typeof r)return null;var t=new r,a=new r;return(v=function(e){return e?a:t})(e)}class h extends o.Component{constructor(e){super(e),(0,u.default)(this,""handleTypeChange"",(e=>{this.setState({type:e.target.value})})),(0,u.default)(this,""renderTypeSelect"",(()=>{var{type:e}=this.state;return o.default.createElement(s.default.Group,{onChange:this.handleTypeChange,value:e},o.default.createElement(s.default.Button,{value:""mysql""},""MySQL""),o.default.createElement(s.default.Button,{value:""memcache""},""Memcache""),o.default.createElement(s.default.Button,{value:""rabbitmq""},""RabbitMQ""))})),(0,u.default)(this,""renderSelectTab"",(()=>{var{type:e}=this.state,t=null;switch(e){case""mysql"":t=c.default;break;case""memcache"":t=m.default;break;case""rabbitmq"":t=f.default;break;default:t=c.default}return o.default.createElement(t,{type:e})})),this.state={type:""mysql""}}render(){return o.default.createElement(""div"",{className:p.default.container},o.default.createElement(""div"",{style:{padding:""20px 20px 0 20px""}},this.renderTypeSelect()),o.default.createElement(""div"",{className:p.default.content},this.renderSelectTab()))}}t.OtherService=h;var g=(0,d.observer)(h);t.default=g},4062:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=void 0;var i=l(r(111)),s=l(r(0)),u=l(r(1263)),o=r(1351),d=r(161),c=l(r(1350)),f=r(1209),m={topCardList:[{title:t(""Running Time""),span:6,createFetchParams:{metricKey:""mysqlService.runningTime""},renderContent:e=>{var{data:t}=e;return s.default.createElement(""div"",{className:c.default[""top-content""]},(0,d.formatUsedTime)(1e3*(0,i.default)(t,""[0].y"",0)))}},{title:t(""Connected Threads""),span:6,createFetchParams:{metricKey:""mysqlService.connectedThreads""}},{title:t(""Running Threads""),span:6,createFetchParams:{metricKey:""mysqlService.runningThreads""}},{title:t(""Slow Query""),span:6,createFetchParams:{metricKey:""mysqlService.slowQuery""}}],chartCardList:[{title:t(""Threads Activity Trends""),createFetchParams:{metricKey:""mysqlService.threadsActivityTrends_connected""},chartProps:{chartType:f.ChartType.ONELINE,scale:{y:{alias:t(""Threads Activity Trends"")}}}},{title:t(""MySQL Actions""),createFetchParams:{metricKey:""mysqlService.mysqlActions""},handleDataParams:{modifyKeys:[t(""delete""),t(""insert""),t(""update"")]},chartProps:{chartType:f.ChartType.MULTILINE,scale:{y:{alias:t(""MySQL Actions"")}}}},{title:t(""Slow Query""),createFetchParams:{metricKey:""mysqlService.slowQueryChart""},chartProps:{chartType:f.ChartType.ONELINE,scale:{y:{alias:t(""Slow Query"")}}}}]};a.chartConfig=m;a.default=e=>{var{type:t}=e;return s.default.createElement(u.default,{type:t,chartConfig:m,fetchNodesFunc:o.getMysqlNodes})}},4063:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=void 0;var i=l(r(27)),s=l(r(229));r(1198);var u=l(r(1199));r(1196);var o=l(r(1197)),d=l(r(111)),c=l(r(0)),f=(r(173),l(r(1263))),m=r(1351),p=r(1209),v=l(r(1350)),h={topCardList:[{title:t(""Server Status""),createFetchParams:{metricKey:""rabbitMQService.serviceStatus""},handleDataParams:{formatDataFn:e=>{var t={up:0,down:0},a=(0,d.default)(e[0],""data.result"",[]);return(0,i.default)(a).call(a,(e=>{1===(0,s.default)(e.value[1],10)?t.up+=1:t.down+=1})),t}},renderContent:e=>{var{data:a}=e;return c.default.createElement(""div"",{className:v.default[""top-content""]},c.default.createElement(u.default,{style:{width:""100%"",textAlign:""center""}},c.default.createElement(o.default,{span:12},a.up+t(""Up"")),c.default.createElement(o.default,{span:12},a.down+t(""Down""))))}},{title:t(""Connected Threads""),createFetchParams:{metricKey:""rabbitMQService.totalConnections""}},{title:t(""Total Queues""),createFetchParams:{metricKey:""rabbitMQService.totalQueues""}},{title:t(""Total Exchanges""),createFetchParams:{metricKey:""rabbitMQService.totalExchanges""}},{title:t(""Total Consumers""),createFetchParams:{metricKey:""rabbitMQService.totalConsumers""}}],chartCardList:[{title:t(""Published Out""),createFetchParams:{metricKey:""rabbitMQService.publishedOut""},chartProps:{chartType:p.ChartType.ONELINE,scale:{y:{alias:t(""Published Out"")}}}},{title:t(""Published In""),createFetchParams:{metricKey:""rabbitMQService.publishedIn""},chartProps:{chartType:p.ChartType.ONELINE,scale:{y:{alias:t(""Published In"")}}}},{title:t(""Channel""),createFetchParams:{metricKey:""rabbitMQService.channel""},chartProps:{chartType:p.ChartType.ONELINE,scale:{y:{alias:t(""Channel"")}}}}]};a.chartConfig=h;a.default=e=>{var{type:t}=e;return c.default.createElement(f.default,{type:t,chartConfig:h,fetchNodesFunc:m.getRabbitMQNodes})}},4064:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.chartConfig=void 0;var i=l(r(0)),s=l(r(1263)),u=r(1351),o=r(1209),d=r(1352),c={chartCardList:[{title:t(""Current Connections""),createFetchParams:{metricKey:""memcacheService.currentConnections""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Current Connections"")}}}},{title:t(""Total Connections""),createFetchParams:{metricKey:""memcacheService.totalConnections""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Total Connections"")}}}},{title:t(""Read And Write""),createFetchParams:{metricKey:""memcacheService.readWriteBytesTotal""},handleDataParams:{modifyKeys:[t(""read""),t(""write"")]},chartProps:{chartType:o.ChartType.MULTILINE,scale:{y:{formatter:e=>(0,d.getSuitableValue)(e,""traffic"",0)}}}},{title:t(""Evictions""),createFetchParams:{metricKey:""memcacheService.evictions""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Evictions"")}}}},{title:t(""Items in Cache""),createFetchParams:{metricKey:""memcacheService.itemsInCache""},chartProps:{chartType:o.ChartType.ONELINE,scale:{y:{alias:t(""Items in Cache"")}}}}]};a.chartConfig=c;a.default=e=>{var{type:t}=e;return i.default.createElement(s.default,{type:t,chartConfig:c,fetchNodesFunc:u.getMemcacheNodes})}},4065:function(e,t,a){var r=a(4066);""string""==typeof r&&(r=[[e.i,r,""""]]);var n={hmr:!0,transform:undefined,insertInto:void 0};a(75)(r,n);r.locals&&(e.exports=r.locals)},4066:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__header--2QIxy {\n color: rgba(0, 0, 0, 0.85);\n font-weight: 500;\n font-size: 16px;\n line-height: 22px;\n}\n.index__list--2MUu4 {\n background-color: #fff;\n -webkit-box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.05);\n}\n.index__list--2MUu4 .index__item--vVdTT {\n height: 76px;\n}\n.index__list--2MUu4 .index__item--vVdTT .index__title--13rNn {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 16px;\n}\n.index__list--2MUu4 .index__item--vVdTT .index__status--1Jr4w {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n color: rgba(0, 0, 0, 0.65);\n font-weight: 400;\n font-size: 14px;\n}\n.index__container--12Azg {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-orient: vertical;\n -webkit-box-direction: normal;\n -ms-flex-direction: column;\n flex-direction: column;\n height: 100%;\n}\n.index__container--12Azg .index__content--50gtm {\n -webkit-box-flex: 1;\n -ms-flex-positive: 1;\n flex-grow: 1;\n overflow: auto;\n}\n"",""""]),t.locals={header:""index__header--2QIxy"",list:""index__list--2MUu4"",item:""index__item--vVdTT"",title:""index__title--13rNn"",status:""index__status--1Jr4w"",container:""index__container--12Azg"",content:""index__content--50gtm""}},4067:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0,a(1198);var l=n(a(1199));a(1196);var i=n(a(1197)),s=n(a(0)),u=n(a(1263)),o=(a(173),n(a(1603))),d=a(1309),c=n(a(1353)),f=n(a(4069)),m=a(4070),p={renderNodeSelect:!1,renderTimeRangeSelect:!1},v=()=>s.default.createElement(u.default,p,s.default.createElement(l.default,{gutter:[16,16],className:c.default.container},s.default.createElement(i.default,{span:24},s.default.createElement(f.default,null)),s.default.createElement(i.default,{span:24},s.default.createElement(l.default,{gutter:[16,16]},s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{topCardList:m.physicalNodeLeftTopCardList})),s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{topCardList:m.physicalNodeRightTopCardList})))),s.default.createElement(i.default,{span:24},s.default.createElement(o.default,{baseTopCardProps:{span:12,createFetchParams:{requestType:""current""},handleDataParams:{formatDataFn:d.handleResponses},visibleHeight:200,renderContent:e=>s.default.createElement(""div"",{className:c.default[""top-content""]},e.data)},topCardList:m.topCardList})),s.default.createElement(i.default,{span:24},s.default.createElement(l.default,{gutter:[16,16]},s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{topCardList:m.storageLeftCardList})),s.default.createElement(i.default,{span:12},s.default.createElement(o.default,{chartCardList:m.storageRightChartList}))))));t.default=v},4068:function(e,t,a){(t=e.exports=a(74)(!1)).push([e.i,"".index__container--10N7f .index__card--3LuCF {\n height: 100%;\n padding: 16px;\n color: #000;\n background-color: #fff;\n -webkit-box-shadow: 0 0 8px 0 rgba(0, 0, 0, 0.05), 0 0 10px 0 rgba(0, 0, 0, 0.05);\n box-shadow: 0 0 8px 0 rgba(0, 0, 0, 0.05), 0 0 10px 0 rgba(0, 0, 0, 0.05);\n}\n.index__container--10N7f .index__card--3LuCF .index__tabs--1jk3S .ant-tabs-tab {\n margin-right: 20px;\n border-bottom: 1px solid #f0f0f0;\n}\n.index__container--10N7f .index__card--3LuCF .index__tabs--1jk3S .ant-tabs-nav::before {\n border-bottom: none;\n}\n.index__container--10N7f .index__alert-card-line--10YeJ {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-orient: vertical;\n -webkit-box-direction: normal;\n -ms-flex-direction: column;\n flex-direction: column;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n}\n.index__container--10N7f .index__alert-card-line--10YeJ .index__number--17oxK {\n color: #e86804;\n font-size: 36px;\n}\n.index__outer--3WpA3 {\n position: relative;\n width: 100%;\n height: 100%;\n overflow: hidden;\n font-size: 14px;\n}\n.index__outer--3WpA3 .index__inner--1jNf7 {\n position: absolute;\n left: 0;\n width: 100%;\n height: 100%;\n overflow-x: hidden;\n overflow-y: scroll;\n}\n.index__outer--3WpA3 .index__inner--1jNf7::-webkit-scrollbar {\n display: none;\n}\n.index__top-content--3X_Di {\n display: -webkit-box;\n display: -ms-flexbox;\n display: flex;\n -webkit-box-align: center;\n -ms-flex-align: center;\n align-items: center;\n -webkit-box-pack: center;\n -ms-flex-pack: center;\n justify-content: center;\n height: 100px;\n font-weight: 500;\n font-size: 24px;\n}\n.index__tabs--1jk3S .ant-tabs-tab {\n margin-right: 20px;\n border-bottom: 1px solid #f0f0f0;\n}\n.index__tabs--1jk3S .ant-tabs-nav::before {\n border-bottom: none;\n}\n"",""""]),t.locals={container:""index__container--10N7f"",card:""index__card--3LuCF"",tabs:""index__tabs--1jk3S"",""alert-card-line"":""index__alert-card-line--10YeJ"",number:""index__number--17oxK"",outer:""index__outer--3WpA3"",inner:""index__inner--1jNf7"",""top-content"":""index__top-content--3X_Di""}},4069:function(e,a,r){""use strict"";var n=r(160),l=r(19),i=r(25),s=r(21);l(a,""__esModule"",{value:!0}),a.default=void 0,r(422);var u=s(r(425));r(1198);var o=s(r(1199));r(1196);var d=s(r(1197));r(337);var c=s(r(338)),f=s(r(51)),m=s(r(27)),p=s(r(174)),v=s(r(57)),h=s(r(65)),g=function(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||""object""!=typeof e&&""function""!=typeof e)return{default:e};var a=S(t);if(a&&a.has(e))return a.get(e);var r={},n=l&&i;for(var s in e)if(""default""!==s&&Object.prototype.hasOwnProperty.call(e,s)){var u=n?i(e,s):null;u&&(u.get||u.set)?l(r,s,u):r[s]=e[s]}r.default=e,a&&a.set(e,r);return r}(r(0)),y=(r(173),s(r(1353))),b=r(1309),_=s(r(119)),x=r(1415),C=r(1295);function S(e){if(""function""!=typeof n)return null;var t=new n,a=new n;return(S=function(e){return e?a:t})(e)}function D(e){var{data:a}=e;return g.default.createElement(""div"",{className:y.default.card},g.default.createElement(o.default,{justify:""space-between""},g.default.createElement(""span"",null,t(""Last week alarm trend"")),g.default.createElement(""span"",null,t(""time / 24h""))),g.default.createElement(o.default,{justify:""center"",align:""middle"",style:{height:272,paddingTop:10}},0===a.length?g.default.createElement(u.default,null):g.default.createElement(w,{data:a})))}function w(e){var{data:t}=e;return g.default.createElement(C.Chart,{padding:[10,20,50,50],autoFit:!0,data:t,scale:{count:{nice:!0}}},g.default.createElement(C.Line,{position:""date*count""}),g.default.createElement(C.Tooltip,{showCrosshairs:!0,lock:!0}))}var E=function(){var e=(0,x.createFetchPrometheusClient)({requestType:""range"",metricKey:""monitorOverview.alertInfo""}),a=(0,x.createDataHandler)({formatDataFn:(e,t,a,r)=>{var n=[];return(0,m.default)(e).call(e,((e,l)=>{n.push((0,b.handleResponse)(e,t,a,r[l]))})),n},modifyKeys:[""cpu"",""memory""]}),[r,n]=(0,g.useState)(!0),[l,i]=(0,g.useState)(0),[s,u]=(0,g.useState)(0),[C,S]=(0,g.useState)(function(){for(var e=(0,_.default)().startOf(""day""),t=[],a=6;a>=0;a--)t.push({fullDate:e.clone().subtract(a,""day"").format(""YYYY-MM-DD""),date:e.clone().subtract(a,""day"").format(""MM-DD""),count:0});return t}()),w=function(){var t=(0,f.default)((function*(t){var r=(0,_.default)(t).endOf(""day""),n=(0,_.default)(t).startOf(""day""),l=yield e({interval:15,currentRange:[n,r]}),[i,s]=a(l).retData,u=(0,p.default)(i).call(i,((e,t,a)=>a>0&&t.x-i[a-1].x>15?e+1:e),0),o=(0,p.default)(s).call(s,((e,t,a)=>a>0&&t.x-s[a-1].x>15?e+1:e),0);return{date:t,total:u+o,cpuTotal:u,memTotal:o}}));return function(e){return t.apply(this,arguments)}}(),E=function(){var e=(0,f.default)((function*(){n(!0);var e=(0,v.default)(C).call(C,(e=>{var{fullDate:t}=e;return w(t)}));try{var t=yield h.default.all(e);(0,m.default)(t).call(t,((e,a)=>{var{total:r,cpuTotal:n,memTotal:l}=e;a===t.length-1&&(i(n),u(l)),C[a].count=r}))}catch(e){}S([...C]),n(!1)}));return function(){return e.apply(this,arguments)}}();return(0,g.useEffect)((()=>{E()}),[]),r?g.default.createElement(c.default,null):g.default.createElement(o.default,{gutter:[16,16]},g.default.createElement(d.default,{flex:""1 1""},g.default.createElement(""div"",{className:y.default.card},g.default.createElement(o.default,{style:{height:""100%""}},g.default.createElement(d.default,{span:12,className:y.default[""alert-card-line""]},g.default.createElement(""div"",{className:y.default.number},l),g.default.createElement(""div"",null,t(""Today CPU usage > 80% alert""))),g.default.createElement(d.default,{span:12,className:y.default[""alert-card-line""]},g.default.createElement(""div"",{className:y.default.number},s),g.default.createElement(""div"",null,t(""Today Memory usage > 80% alert"")))))),g.default.createElement(d.default,{flex:""0 1 440px""},g.default.createElement(D,{data:C})))};a.default=E},4070:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.storageRightChartList=a.storageLeftCardList=a.topCardList=a.physicalNodeRightTopCardList=a.physicalNodeLeftTopCardList=void 0;var m=f(r(81)),p=f(r(27)),v=f(r(229)),h=f(r(419)),g=f(r(36));r(1222);var y=f(r(1223));r(1198);var b=f(r(1199)),_=f(r(111)),x=f(r(0)),C=(r(173),r(161)),S=r(1352),D=f(r(1606)),w=r(1309),E=r(1209),I=f(r(140)),P=r(4071),T=f(r(1353));function k(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function N(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=k(Object(r),!0)).call(a,(function(t){(0,g.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=k(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}var M=[{title:t(""Physical CPU Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.physicalCPUUsage""},renderContent:e=>{var t,{data:a}=e,r=(0,_.default)(a[0],""y"",0),n=(0,_.default)(a[1],""y"",0);return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(r,n)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(r,"" / "")).call(t,n))))}},{title:t(""Total Ram""),span:12,createFetchParams:{metricKey:""monitorOverview.physicalMemoryUsage""},renderContent:e=>{var t,{data:a}=e,r=(0,_.default)(a[0],""y"",0),n=(0,_.default)(a[1],""y"",0),l=(0,S.getSuitableValue)(r,""memory""),i=(0,S.getSuitableValue)(n,""memory"");return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(r,n)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(l,"" / "")).call(t,i))))}},{title:t(""Physical Storage Usage""),span:24,createFetchParams:{metricKey:""monitorOverview.physicalStorageUsage""},renderContent:e=>{var a,r,n,{data:l}=e,i=(0,_.default)(l[0],""y"",0),s=(0,_.default)(l[1],""y"",0),u=(0,S.getSuitableValue)(i,""disk""),o=(0,S.getSuitableValue)(s,""disk""),d=(0,C.computePercentage)(i,s);return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",{style:{width:""100%"",height:""100%""}},x.default.createElement(b.default,{style:{justifyContent:""flex-end"",height:""50%""}},x.default.createElement(""span"",{style:{fontSize:12,marginRight:32}},(0,m.default)(a=(0,m.default)(r=(0,m.default)(n="""".concat(t(""Used""),"" "")).call(n,u,"" / "")).call(r,t(""Total""),"" "")).call(a,o))),x.default.createElement(b.default,{style:{height:""50%""}},x.default.createElement(y.default,{style:{width:""95%""},percent:d,strokeColor:d>80?""#FAAD14"":""#1890FF"",showInfo:100!==d}))))}}];a.physicalNodeLeftTopCardList=M;var L=[{visibleHeight:319,createFetchParams:{requestType:""current"",metricKey:""monitorOverview.computeNodeStatus""},handleDataParams:{formatDataFn:e=>{var t=[{type:""up"",value:0},{type:""down"",value:0}],a=(0,_.default)(e[0],""data.result"",[]);return(0,p.default)(a).call(a,(e=>{var a=""enabled""===e.metric.adminState?0:1;t[a].value+=(0,v.default)(e.value[1],10)})),t}},title:t(""Compute Node status""),renderContent:e=>{var{data:t}=e;return x.default.createElement(""div"",{style:{height:309}},x.default.createElement(D.default,{data:t}))}}];a.physicalNodeRightTopCardList=L;var F=[{title:t(""Host CPU Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostCPUUsage""},handleDataParams:{typeKey:""instance""},renderContent:P.renderTopProgress},{title:t(""Host Disk Average IOPS""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostDiskIOPS""},handleDataParams:{formatDataFn:(e,t,a,r)=>{var n=[];return(0,p.default)(e).call(e,((e,t)=>{var a;(0,p.default)(a=e.data.result||[]).call(a,(e=>{n.push({x:e.metric.instance,y:(0,h.default)((0,_.default)(e,""value[1]"",0)),type:r[t]})}))})),n},modifyKeys:[t(""read""),t(""write"")]},extra:P.renderTopColumnExtra,renderContent:P.renderTopColumnChart},{title:t(""Host Memory Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostMemoryUsage""},handleDataParams:{typeKey:""instance""},renderContent:P.renderTopProgress},{title:t(""Host Average Network IO""),span:12,createFetchParams:{metricKey:""monitorOverview.topHostInterface""},handleDataParams:{formatDataFn:(e,t,a,r)=>{var n=[];return(0,p.default)(e).call(e,((e,t)=>{var a;(0,p.default)(a=e.data.result||[]).call(a,(e=>{n.push({x:e.metric.instance,y:(0,h.default)((0,_.default)(e,""value[1]"",0)),type:r[t]})}))})),n},modifyKeys:[t(""receive""),t(""transmit"")]},extra:P.renderTopColumnExtra,renderContent:e=>{var t=(0,P.renderTopColumnChart)(e);return x.default.cloneElement(t,N(N({},t.props),{},{scale:{y:{nice:!0,formatter:e=>(0,S.getSuitableValue)(e,""traffic"",0)}}}))}}];a.topCardList=F;var A=[{title:t(""Storage Cluster Status""),span:24,createFetchParams:{metricKey:""monitorOverview.cephHealthStatus""},renderContent:e=>{var t=(0,_.default)(e.data,""y"",0);return x.default.createElement(""div"",{className:T.default[""top-content""],style:{fontSize:28,fontWeight:600,color:S.cephStatusColorMap[t],height:65}},S.cephStatusMap[t])}},{title:t(""Storage Cluster Usage""),span:12,createFetchParams:{metricKey:""monitorOverview.cephStorageUsage""},renderContent:e=>{var t,{data:a}=e,r=(0,_.default)(a[0],""y"",0),n=(0,_.default)(a[1],""y"",0),l=(0,S.getSuitableValue)(r,""disk""),i=(0,S.getSuitableValue)(n,""disk"");return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(r,n)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(l,"" / "")).call(t,i))))}},{title:t(""Disk allocation (GiB)""),span:12,createFetchParams:{metricKey:""monitorOverview.cephStorageAllocate""},renderContent:e=>{var t,{data:a}=e,r=(0,h.default)((0,_.default)(a[1],""y"",0).toFixed(2)),n=(0,h.default)((r-(0,_.default)(a[0],""y"",0)).toFixed(2));return x.default.createElement(""div"",{className:T.default[""top-content""]},x.default.createElement(""div"",null,x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center""}},x.default.createElement(""span"",{style:{fontSize:28,fontWeight:600}},(0,C.computePercentage)(n,r)),""%""),x.default.createElement(b.default,{style:{alignItems:""baseline"",justifyContent:""center"",fontSize:12}},(0,m.default)(t="""".concat(n,"" GiB / "")).call(t,r,"" GiB""))))},hidden:!I.default.checkEndpoint(""cinder"")}];a.storageLeftCardList=A;var O=[{title:t(""Storage Cluster IOPS""),createFetchParams:{requestType:""range"",metricKey:""monitorOverview.cephStorageClusterIOPS""},handleDataParams:{formatDataFn:w.handleResponses,modifyKeys:[t(""read""),t(""write"")]},span:24,chartProps:{chartType:E.ChartType.MULTILINE,height:318,scale:{y:{nice:!0}}}}];a.storageRightChartList=O},4071:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.renderTopColumnChart=t.renderTopColumnExtra=t.renderTopProgress=void 0;var l=n(a(57)),i=n(a(32));a(1260);var s=n(a(1261));a(1198);var u=n(a(1199));a(1196);var o=n(a(1197));a(1222);var d=n(a(1223)),c=n(a(111)),f=n(a(0)),m=(a(173),a(1295)),p=n(a(1353));t.renderTopProgress=e=>{var{data:t}=e;return f.default.createElement(u.default,{style:{height:""100%""}},(0,l.default)(t).call(t,(e=>{var t=(0,c.default)(e,""y"",0),a=t>80?""#FAAD14"":""#1890FF"";return f.default.createElement(o.default,{span:24,key:e.type},f.default.createElement(""div"",null,e.type),f.default.createElement(d.default,{strokeColor:a,percent:t,style:{marginBottom:4},showInfo:100!==t}))})))};t.renderTopColumnExtra=e=>{var{modifyKeys:t,filterChartData:a}=e;return f.default.createElement(s.default,{className:p.default.tabs,defaultActiveKey:t[0],onChange:e=>a((t=>t.type===e))},(0,l.default)(t).call(t,(e=>f.default.createElement(s.default.TabPane,{tab:e,key:e}))))};t.renderTopColumnChart=e=>{var{data:t,modifyKeys:a}=e;return f.default.createElement(m.Chart,{autoFit:!0,data:t.length<=5?t:(0,i.default)(t).call(t,(e=>e.type===a[0])),height:198,scale:{y:{nice:!0}}},f.default.createElement(m.Interval,{position:""x*y"",size:20}))}},4072:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(413)),i=n(a(4073)),s=e=>(0,l.default)(i.default,e);t.default=s},4073:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(1212)),i=n(a(567)),s=n(a(4074)),u=n(a(1609)),o=n(a(4085)),d=n(a(4089)),c=n(a(4093)),f=n(a(4109)),m=n(a(4113)),p=""/database"",v=[{path:p,component:l.default,routes:[{path:"""".concat(p,""/instances""),component:s.default,exact:!0},{path:"""".concat(p,""/instances-admin""),component:s.default,exact:!0},{path:"""".concat(p,""/instances/create""),component:u.default,exact:!0},{path:"""".concat(p,""/backups""),component:o.default,exact:!0},{path:"""".concat(p,""/configurations""),component:d.default,exact:!0},{path:"""".concat(p,""/instances/detail/:id""),component:c.default,exact:!0},{path:"""".concat(p,""/instances-admin/detail/:id""),component:c.default,exact:!0},{path:"""".concat(p,""/backups/detail/:id""),component:m.default,exact:!0},{path:"""".concat(p,""/configurations/detail/:id""),component:f.default,exact:!0},{path:""*"",component:i.default}]}];t.default=v},4074:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Instances=void 0;var i=l(r(57)),s=l(r(0)),u=r(406),o=l(r(1194)),d=l(r(1221)),c=r(1418),f=r(161),m=l(r(1608));class p extends o.default{init(){this.store=d.default}get name(){return t(""database instances"")}get actionConfigs(){return this.isAdminPage?m.default.actionConfigsAdmin:m.default.actionConfigs}get policy(){return""instance:index""}get aliasPolicy(){return""trove:instance:index""}get searchFilters(){return[{label:t(""Name""),name:""name""},{label:t(""Version""),name:""version""},{label:t(""Status""),name:""status"",options:(0,f.getOptions)(c.InstanceStatus)}]}getColumns(){return[{title:t(""ID/Name""),dataIndex:""name"",routeName:this.getRouteName(""databaseInstanceDetail"")},{title:t(""Project ID/Name""),dataIndex:""project_name"",isHideable:!0,hidden:!this.isAdminPage},{title:t(""Datastore""),dataIndex:""type""},{title:t(""Datastore Version""),dataIndex:""version"",isHideable:!0},{title:t(""Host""),dataIndex:""ip"",render:e=>e&&e.length?s.default.createElement(s.default.Fragment,null,(0,i.default)(e).call(e,(e=>s.default.createElement(""div"",{key:e},e)))):""-"",isHideable:!0},{title:t(""Database Disk (GiB)""),dataIndex:""size"",isHideable:!0,unit:""GiB""},{title:t(""Status""),dataIndex:""status"",valueMap:c.InstanceStatus}]}}a.Instances=p;var v=(0,u.inject)(""rootStore"")((0,u.observer)(p));a.default=v},4075:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1221));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:delete""),(0,i.default)(this,""onSubmit"",(e=>u.default.delete({id:e.id})))}get id(){return""delete""}get title(){return t(""Delete"")}get actionName(){return t(""Delete"")}get isDanger(){return!0}}a.default=o},4076:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepDetails=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(32)),o=l(r(102)),d=l(r(51)),c=l(r(36)),f=l(r(0)),m=r(406),p=l(r(1201)),v=r(34),h=l(r(1221)),g=l(r(1262)),y=l(r(1275));class b extends p.default{constructor(){super(...arguments),(0,c.default)(this,""allowed"",(()=>i.default.resolve())),(0,c.default)(this,""onFlavorChange"",(e=>{this.updateContext({flavor:e})}))}init(){this.instancesStore=h.default,this.getDatastores(),this.getAvailZones()}get title(){return t(""Details *"")}get name(){return""Details""}get nameForStateUpdate(){return[""flavor"",""datastore_type""]}get defaultValue(){return{project:this.currentProjectName}}get availableZones(){var e,t;return(0,s.default)(e=(0,u.default)(t=g.default.list.data||[]).call(t,(e=>e.zoneState.available))).call(e,(e=>({value:e.zoneName,label:e.zoneName})))}getAvailZones(){return(0,d.default)((function*(){g.default.fetchListWithoutDetail()}))()}get datastores(){var e;return(0,s.default)(e=h.default.dataList||[]).call(e,(e=>({label:e.name,value:e.name,originData:(0,v.toJS)(e)})))}getDatastores(){return(0,d.default)((function*(){h.default.listDatastores()}))()}get datastoresVersion(){var e,t;if(!this.state.datastore_type)return[];var a=(0,o.default)(e=this.datastores).call(e,(e=>e.label===this.state.datastore_type));return(0,s.default)(t=a.originData.versions||[]).call(t,(e=>({label:e.name,value:e.name})))}getFlavorComponent(){return f.default.createElement(y.default,{onChange:this.onFlavorChange})}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""zone"",label:t(""Availability Zone""),type:""select"",placeholder:t(""Please select""),options:this.availableZones,required:!0},{name:""instance_name"",label:t(""Database Instance Name""),type:""input"",required:!0},{name:""size"",label:t(""Database Disk (GiB)""),type:""input-int"",min:1,placeholder:t(""Size""),required:!0,wrapperCol:{xs:{span:24},sm:{span:18}},onChange:e=>this.updateContext({size:e})},{type:""divider""},{name:""datastore_type"",label:t(""Datastore Type""),type:""select"",options:this.datastores,onChange:()=>{this.resetFormValue([""datastore_version""])},required:!0},{name:""datastore_version"",label:t(""Datastore Version""),type:""select"",options:this.datastoresVersion,required:!0},{type:""divider""},{name:""flavor"",label:t(""Database Flavor""),component:this.getFlavorComponent(),wrapperCol:{xs:{span:24},sm:{span:18}},required:!0},{name:""locality"",label:t(""Locality""),type:""select"",options:[{label:t(""Affinity""),value:""affinity""},{label:t(""Anti-Affinity""),value:""anti-affinity""}],tip:t(""Specify whether future replicated instances will be created on the same hypervisor (affinity) or on different hypervisors (anti-affinity). This value is ignored if the instance to be launched is a replica."")}]}}a.StepDetails=b;var _=(0,m.inject)(""rootStore"")((0,m.observer)(b));a.default=_},4077:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepNetworking=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=l(r(1201));class d extends o.default{constructor(){super(...arguments),(0,s.default)(this,""allowed"",(()=>i.default.resolve()))}get title(){return t(""Networking *"")}get name(){return""Networking""}get defaultValue(){return{project:this.currentProjectName}}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""network"",label:t(""Network""),type:""network-select-table"",required:!0}]}}a.StepNetworking=d;var c=(0,u.inject)(""rootStore"")((0,u.observer)(d));a.default=c},4078:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepInitializeDatabases=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=l(r(1201)),d=r(556);class c extends o.default{constructor(){super(...arguments),(0,s.default)(this,""allowed"",(()=>i.default.resolve()))}get title(){return t(""Initialize Databases"")}get name(){return""Initialize Databases""}get defaultValue(){return{project:this.currentProjectName}}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""initialDatabases"",label:t(""Initial Databases""),type:""input-name"",required:!0,maxLength:64,isDatabaseName:!0},{name:""initialAdminUser"",label:t(""Initial Admin User""),type:""input-name"",required:!0,maxLength:16,isDatabaseUserName:!0},{name:""password"",label:t(""Password""),type:""input-password"",required:!0,otherRule:(0,d.getPasswordOtherRule)(""password"")},{name:""confirmPassword"",label:t(""Confirm Password""),type:""input-password"",required:!0,dependencies:[""password""],otherRule:(0,d.getPasswordOtherRule)(""confirmPassword"")}]}}a.StepInitializeDatabases=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4079:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.StepAdvanced=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(51)),o=l(r(36)),d=r(406),c=l(r(1201)),f=l(r(1221));class m extends c.default{constructor(){super(...arguments),(0,o.default)(this,""allowed"",(()=>i.default.resolve()))}init(){this.getConfigurationGroups()}get title(){return t(""Initialize Databases"")}get name(){return""Initialize Databases""}get configurationGroup(){var e;return(0,s.default)(e=f.default.list.data||[]).call(e,(e=>({label:e.name,value:e.id})))}getConfigurationGroups(){return(0,u.default)((function*(){f.default.listConfigurationGroup()}))()}get formItems(){return[{name:""project"",label:t(""Project""),type:""label""},{type:""divider""},{name:""configurationGroup"",label:t(""Configuration Group""),type:""select"",options:this.configurationGroup}]}}a.StepAdvanced=m;var p=(0,d.inject)(""rootStore"")((0,d.observer)(m));a.default=p},4080:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Edit=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=r(1193),d=l(r(1221));class c extends o.ModalAction{constructor(){super(...arguments),(0,s.default)(this,""onSubmit"",(e=>{var{name:t}=e,a={instance:{name:t}},{id:r}=this.item;return d.default.patch({id:r},a)}))}static allowed(){return i.default.resolve(!0)}get formItems(){return[{name:""name"",label:t(""Name""),type:""input"",required:!0,placeholder:t(""Please input name"")}]}}a.Edit=c,(0,s.default)(c,""id"",""edit-instance""),(0,s.default)(c,""title"",t(""Edit"")),(0,s.default)(c,""buttonText"",t(""Edit"")),(0,s.default)(c,""policy"",""instance:update"");var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4081:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=r(1195),o=l(r(1221));class d extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""policy"",""instance:restart""),(0,i.default)(this,""allowedCheckFunc"",(e=>(0,u.checkStatus)([""active"",""shutoff"",""shutdown""],e))),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=e||this.item;return o.default.restart({id:t})}))}get id(){return""restart""}get title(){return t(""Restart Database Service"")}get isDanger(){return!0}get actionName(){return t(""Restart Database Service"")}get isAsyncAction(){return!0}}a.default=d},4082:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=r(1195),o=l(r(1221));class d extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""policy"",""instance:stop""),(0,i.default)(this,""allowedCheckFunc"",(e=>(0,u.checkStatus)([""active""],e))),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=e||this.item;return o.default.stop({id:t})}))}get id(){return""stop""}get title(){return t(""Stop Database Service"")}get isDanger(){return!0}get buttonText(){return t(""Stop"")}get actionName(){return t(""Stop Database Service"")}get isAsyncAction(){return!0}}a.default=d},4083:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=r(1195),o=l(r(1221));class d extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""policy"",""instance:reboot""),(0,i.default)(this,""allowedCheckFunc"",(e=>(0,u.checkStatus)([""active"",""shutoff"",""shutdown""],e))),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=e||this.item;return o.default.reboot({id:t})}))}get id(){return""reboot""}get title(){return t(""Reboot Database Instance"")}get isDanger(){return!0}get actionName(){return t(""Reboot Database Instance"")}get isAsyncAction(){return!0}}a.default=d},4084:function(e,a,r){""use strict"";var n=r(33),l=r(44),i=r(32),s=r(25),u=r(27),o=r(45),d=r(46),c=r(19),f=r(21);c(a,""__esModule"",{value:!0}),a.default=a.ResizeVolume=void 0;var m=f(r(81)),p=f(r(65)),v=f(r(51)),h=f(r(36)),g=r(406),y=f(r(1221)),b=f(r(407)),_=r(1193),x=r(1195);function C(e,t){var a=n(e);if(l){var r=l(e);t&&(r=i(r).call(r,(function(t){return s(e,t).enumerable}))),a.push.apply(a,r)}return a}function S(e){for(var t=1;t<arguments.length;t++){var a,r=null!=arguments[t]?arguments[t]:{};if(t%2)u(a=C(Object(r),!0)).call(a,(function(t){(0,h.default)(e,t,r[t])}));else if(o)d(e,o(r));else{var n;u(n=C(Object(r))).call(n,(function(t){c(e,t,s(r,t))}))}}return e}class D extends _.ModalAction{constructor(){super(...arguments),(0,h.default)(this,""onSubmit"",(e=>{var{id:t}=this.item,{size:a}=e;return y.default.resizeVolume({id:t,size:a})}))}static get modalSize(){return""large""}getModalSize(){return""large""}init(){this.store=y.default,this.projectStore=b.default,this.getQuota(),this.state.isLoading=!0,this.errorMsg=""""}get isQuotaLimited(){var{volumes:{limit:e}={}}=this.projectStore.troveQuota||{};return-1!==e}get maxSize(){var{volumes:{left:e=0}={}}=this.projectStore.troveQuota||{},{size:t=0}=this.item;return e+t}isQuotaEnough(){var{size:e=0}=this.item;return!this.isQuotaLimited||this.maxSize>e}get name(){return t(""Resize Volume"")}getMinSize(){var{volume:e={}}=this.item,{size:t=1}=e;return t+1}static get disableSubmit(){var{troveQuota:e={}}=b.default;return(e=>{var{volumes:{left:t=0}={}}=e||{};return 0===t})(e)}get showQuota(){return!0}getQuota(){var e=this;return(0,v.default)((function*(){yield e.projectStore.fetchProjectTroveQuota(e.currentProjectId),e.setState({isLoading:!1})}))()}get quotaInfo(){if(this.state.isLoading)return[];var{volumes:e={}}=this.projectStore.troveQuota||{},{size:a=0}=this.state,{left:r=0}=e,{size:n=0}=this.item,l=a-n;return[S(S({},e),{},{add:-1===r||l<=r?l:0,name:""volumeSize"",title:t(""Database Disk (GiB)""),type:""ring""})]}get isAsyncAction(){return!0}get nameForStateUpdate(){return[""size""]}get defaultValue(){var{name:e,volume:t={}}=this.item;return{instance:e,size:this.getMinSize(),oldSize:t.size}}get formItems(){var e;if(this.state.isLoading)return[];if(!this.isQuotaEnough())return[{type:""label"",component:t(""Quota is not enough for extend volume."")}];var a=this.getMinSize();return[{name:""instance"",label:t(""Database Instance""),type:""label"",iconType:""instance""},{name:""oldSize"",label:t(""Current Disk (GiB)""),type:""label""},{name:""size"",label:t(""Database Disk (GiB)""),type:""slider-input"",max:this.maxSize,min:a,description:(0,m.default)(e="""".concat(a,""GiB-"")).call(e,this.maxSize,""GiB""),required:!0,display:this.isQuotaLimited},{name:""size"",label:t(""Database Disk (GiB)""),type:""input-int"",min:a,required:!0,display:!this.isQuotaLimited}]}}a.ResizeVolume=D,(0,h.default)(D,""id"",""resize-volume""),(0,h.default)(D,""title"",t(""Resize Volume"")),(0,h.default)(D,""policy"",[""trove:instance:resize_volume"",""trove:admin""]),(0,h.default)(D,""isActiveOrShutOff"",(e=>(0,x.checkStatus)([""active"",""shutoff""],e))),(0,h.default)(D,""allowed"",(e=>p.default.resolve(D.isActiveOrShutOff(e))));var w=(0,g.inject)(""rootStore"")((0,g.observer)(D));a.default=w},4085:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Backups=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=l(r(1354)),d=l(r(4086));class c extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Name""),dataIndex:""name"",routeName:this.getRouteName(""databaseBackupDetail"")},{title:t(""Description""),isHideable:!0,dataIndex:""description""}]))}init(){this.store=o.default}get name(){return t(""database backups"")}get actionConfigs(){return d.default.actionConfigs}get policy(){return""backup:index""}get searchFilters(){return[{label:t(""Name""),name:""name""}]}}a.Backups=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4086:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4087)),i=n(a(4088)),s={actionConfigs:{rowActions:{firstAction:i.default},batchActions:[i.default],primaryActions:[l.default]}};t.default=s},4087:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Create=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(51)),o=l(r(36)),d=r(1193),c=r(406),f=l(r(1221)),m=l(r(1354));class p extends d.ModalAction{constructor(){super(...arguments),(0,o.default)(this,""onSubmit"",(e=>this.store.create({backup:{description:e.description,instance:e.instance,name:e.name}})))}init(){this.store=m.default,this.getDatabaseInstance()}static get modalSize(){return""middle""}getModalSize(){return""middle""}get name(){return t(""Create Database Backup"")}static allowed(){return i.default.resolve(!0)}get listInstanceName(){var e;return(0,s.default)(e=f.default.list.data||[]).call(e,(e=>({value:e.id,label:e.name})))}getDatabaseInstance(){return(0,u.default)((function*(){yield f.default.fetchListWithoutDetail()}))()}get formItems(){return[{name:""name"",label:t(""Name""),type:""input"",required:!0},{name:""instance"",label:t(""Database Instance""),type:""select"",options:this.listInstanceName,required:!0},{name:""description"",label:t(""Description""),type:""input""}]}}a.Create=p,(0,o.default)(p,""id"",""create-database-backup""),(0,o.default)(p,""title"",t(""Create Database Backup"")),(0,o.default)(p,""policy"",""backup:create""),(0,o.default)(p,""aliasPolicy"",""trove:backup:create"");var v=(0,c.inject)(""rootStore"")((0,c.observer)(p));a.default=v},4088:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1354));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:delete""),(0,i.default)(this,""onSubmit"",(e=>u.default.delete({id:e.id})))}get id(){return""delete""}get title(){return t(""Delete Database Backup"")}get actionName(){return t(""Delete Database Backup"")}get buttonText(){return t(""Delete"")}get isDanger(){return!0}}a.default=o},4089:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Configurations=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=l(r(1355)),d=l(r(4090));class c extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Configuration Group Name""),dataIndex:""name"",routeName:this.getRouteName(""configurationsDetail"")},{title:t(""Description""),isHideable:!0,dataIndex:""description""},{title:t(""Datastore""),dataIndex:""datastore""},{title:t(""Datastore Version""),dataIndex:""datastoreVersion""}]))}init(){this.store=o.default}get name(){return t(""configurations"")}get actionConfigs(){return d.default.actionConfigs}get policy(){return""configuration:index""}get searchFilters(){return[{label:t(""Name""),name:""name""}]}}a.Configurations=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4090:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4091)),i=n(a(4092)),s={actionConfigs:{rowActions:{firstAction:i.default},batchActions:[i.default],primaryActions:[l.default]}};t.default=s},4091:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Create=void 0;var i=l(r(65)),s=l(r(57)),u=l(r(32)),o=l(r(51)),d=l(r(36)),c=r(1193),f=r(406),m=l(r(1221)),p=l(r(1355)),v=r(34);class h extends c.ModalAction{constructor(){super(...arguments),(0,d.default)(this,""onChangeDatastoresTypeChange"",(e=>{this.setState({datastore_type:e}),this.resetFormValue([""datastore_version""])})),(0,d.default)(this,""onSubmit"",(e=>this.store.create({configuration:{description:e.description,datastore:{type:e.datastore_type,version:e.datastore_version},name:e.name,values:{connect_timeout:200}}})))}init(){this.store=p.default,this.getDatastores(),this.state.datastore_type=null}static get modalSize(){return""middle""}getModalSize(){return""middle""}get name(){return t(""Create Configurations"")}static allowed(){return i.default.resolve(!0)}getDatastores(){return(0,o.default)((function*(){yield m.default.listDatastores()}))()}get datastores(){var e;return(0,s.default)(e=m.default.dataList||[]).call(e,(e=>({label:e.name,value:e.name,originData:(0,v.toJS)(e)})))}get datastoresVersion(){var e,t;return(0,s.default)(e=(0,u.default)(t=this.datastores).call(t,(e=>e.label===this.state.datastore_type))).call(e,(e=>{var t;return(0,s.default)(t=e.originData.versions).call(t,(e=>({label:e.name,value:e.name})))}))[0]}get formItems(){return[{name:""name"",label:t(""Name""),type:""input"",required:!0},{name:""description"",label:t(""Description""),type:""input""},{name:""datastore_type"",label:t(""Datastore Type""),type:""select"",options:this.datastores,onChange:e=>{this.onChangeDatastoresTypeChange(e)},required:!0},{name:""datastore_version"",label:t(""Datastore Version""),type:""select"",options:this.datastoresVersion,required:!0}]}}a.Create=h,(0,d.default)(h,""id"",""create-configurations""),(0,d.default)(h,""title"",t(""Create Configurations"")),(0,d.default)(h,""policy"",""configuration:create"");var g=(0,f.inject)(""rootStore"")((0,f.observer)(h));a.default=g},4092:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1355));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:delete""),(0,i.default)(this,""onSubmit"",(e=>u.default.delete({id:e.id})))}get id(){return""delete""}get title(){return t(""Delete Configuration"")}get actionName(){return t(""Delete Configuration"")}get isDanger(){return!0}}a.default=o},4093:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.InstancesDetail=void 0;var i=r(406),s=l(r(1200)),u=l(r(1221)),o=r(1418),d=l(r(4094)),c=l(r(4095)),f=l(r(4100)),m=l(r(4104)),p=l(r(4106)),v=l(r(4108)),h=l(r(1608));class g extends s.default{init(){this.store=u.default}get name(){return t(""Backup Detail"")}get policy(){return""instance:detail""}get aliasPolicy(){return""trove:instance:detail""}get listUrl(){return this.getRoutePath(""databaseInstances"")}get detailInfos(){return[{title:t(""ID""),dataIndex:""id""},{title:t(""Name""),dataIndex:""name""},{title:t(""Status""),dataIndex:""status"",valueMap:o.InstanceStatus},{title:t(""Project ID""),dataIndex:""tenant_id"",hidden:!this.isAdminPage}]}get tabs(){return[{title:t(""Detail""),key:""general_info"",component:d.default},{title:t(""Users""),key:""users"",component:c.default},{title:t(""Databases""),key:""databases"",component:f.default},{title:t(""Backups""),key:""backups"",component:m.default},{title:t(""Logs""),key:""logs"",component:p.default},{title:t(""Defaults""),key:""defaults"",component:v.default}]}get actionConfigs(){return this.isAdminPage?h.default.actionConfigsAdmin:h.default.actionConfigs}}a.InstancesDetail=g;var y=(0,i.inject)(""rootStore"")((0,i.observer)(g));a.default=y},4094:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BaseDetail=void 0;var i=l(r(57)),s=l(r(0)),u=r(406),o=l(r(1202)),d=r(1418);class c extends o.default{get leftCards(){return[this.baseInfoCard,this.specsCard,this.connectionInfoCard]}get rightCards(){return[this.faultCard]}get baseInfoCard(){var e=[{label:t(""Name""),dataIndex:""name""},{label:t(""Datastore""),dataIndex:""type""},{label:t(""Datastore Version""),dataIndex:""version""},{label:t(""Status""),dataIndex:""status"",valueMap:d.InstanceStatus},{label:t(""Locality""),dataIndex:""locality"",valueMap:d.policyType}];return{title:t(""Base Info""),options:e}}get specsCard(){var e=[{label:t(""Database Flavor""),dataIndex:""flavor"",render:e=>this.getLinkRender(""flavorDetail"",e.name,{id:e.id},null)},{label:t(""Volume Size""),dataIndex:""size"",unit:""GiB""},{label:t(""Created""),dataIndex:""created"",valueRender:""toLocalTime""},{label:t(""Updated""),dataIndex:""updated"",valueRender:""toLocalTime""},{label:t(""Service Status Updated""),dataIndex:""service_status_update""}];return{title:t(""Specs""),options:e}}get connectionInfoCard(){var e=[{label:t(""Host""),dataIndex:""ip"",render:e=>e&&e.length?s.default.createElement(""span"",null,(0,i.default)(e).call(e,(e=>s.default.createElement(""div"",{key:e},e)))):""-""},{label:t(""Database Port""),dataIndex:""type"",render:e=>{switch(e){case""mysql"":return""3306"";case""mongodb"":return""27017"";case""postgresql"":return""5432""}}},{label:t(""Connection Examples""),dataIndex:""connection_examples""}];return{title:t(""Connection Information""),options:e}}get faultCard(){var e=[{label:t(""Created""),dataIndex:""created"",valueRender:""toLocalTime""},{label:t(""Message""),dataIndex:""fault.message""},{label:t(""Message Details""),dataIndex:""fault.details""}];return{title:t(""Fault""),labelCol:2,options:e}}}a.BaseDetail=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4095:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Users=void 0;var i=l(r(57)),s=l(r(36)),u=l(r(0)),o=l(r(1194)),d=r(406),c=r(1356),f=l(r(4096));class m extends o.default{constructor(){super(...arguments),(0,s.default)(this,""getColumns"",(()=>[{title:t(""User Name""),dataIndex:""name""},{title:t(""Allowed Host""),dataIndex:""host""},{title:t(""Databases""),dataIndex:""databases"",render:e=>e.length?u.default.createElement(""span"",null,(0,i.default)(e).call(e,(e=>u.default.createElement(""div"",{key:e},e)))):""-""}]))}init(){this.store=new c.InstancesUsersStore}get rowKey(){return""name""}get name(){return t(""Users"")}get actionConfigs(){return this.isAdminPage?f.default.actionConfigsAdmin:f.default.actionConfigs}get policy(){return""instance:extension:user:index""}get hideCustom(){return!0}}a.Users=m;var p=(0,d.inject)(""rootStore"")((0,d.observer)(m));a.default=p},4096:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4097)),i=n(a(4098)),s=n(a(4099)),u={actionConfigs:{rowActions:{firstAction:l.default,moreActions:[{action:s.default}]},batchActions:[l.default],primaryActions:[i.default]},actionConfigsAdmin:{rowActions:{firstAction:l.default},batchActions:[l.default],primaryActions:[]}};t.default=u},4097:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1356));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:extension:user:delete""),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=this.containerProps.detail,a=e.name||this.item.name;return u.default.deleteUser({id:t,name:a})}))}get id(){return""delete-database-user""}get title(){return t(""Delete User"")}get actionName(){return t(""Delete User"")}get isDanger(){return!0}get buttonText(){return t(""Delete"")}}a.default=o},4098:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.UserCreate=void 0;var i=l(r(57)),s=l(r(65)),u=l(r(51)),o=l(r(36)),d=r(406),c=l(r(1325)),f=l(r(1356)),m=r(1310),p=r(556);class v extends c.default{constructor(){super(...arguments),(0,o.default)(this,""onSubmit"",(e=>{var t,{id:a}=this.item;return this.store.create(a,{users:[{databases:(0,i.default)(t=e.database).call(t,(e=>({name:e}))),name:e.userName,password:e.password}]})}))}init(){var e=this;return(0,u.default)((function*(){e.store=f.default,e.databaseStore=new m.InstancesDatabasesStore,yield e.fetchDatabase()}))()}get name(){return t(""Create User"")}static allowed(){return s.default.resolve(!0)}fetchDatabase(){var{id:e}=this.item;this.databaseStore.fetchList({id:e})}get database(){var e;return(0,i.default)(e=this.databaseStore.list.data||[]).call(e,(e=>({label:e.name,value:e.name,key:e.name})))}get formItems(){return[{name:""userName"",label:t(""Name""),type:""input-name"",required:!0,isDatabaseUserName:!0,maxLength:16},{name:""database"",label:t(""Database""),type:""select"",options:this.database,mode:""multiple"",required:!0},{name:""password"",label:t(""Password""),type:""input-password"",required:!0,otherRule:(0,p.getPasswordOtherRule)(""password"")},{name:""confirmPassword"",label:t(""Confirm Password""),type:""input-password"",required:!0,dependencies:[""password""],otherRule:(0,p.getPasswordOtherRule)(""confirmPassword"")}]}}a.UserCreate=v,(0,o.default)(v,""id"",""create-user""),(0,o.default)(v,""title"",t(""Create User"")),(0,o.default)(v,""policy"",""instance:extension:user:create"");var h=(0,d.inject)(""rootStore"")((0,d.observer)(v));a.default=h},4099:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.UserDatabase=void 0;var i=l(r(57)),s=l(r(65)),u=l(r(51)),o=l(r(36)),d=r(406),c=l(r(1325)),f=l(r(1356)),m=r(1310);class p extends c.default{constructor(){super(...arguments),(0,o.default)(this,""onSubmit"",((e,t)=>{var a,{detail:{id:r}={}}=t,n={databases:(0,i.default)(a=e.database).call(a,(e=>({name:e})))};return this.store.grantDatabaseAccess({id:r,name:e.name,data:n})}))}init(){this.store=f.default,this.databaseStore=new m.InstancesDatabasesStore,this.fetchDatabase()}get name(){return t(""Grant Databases Access"")}static allowed(){return s.default.resolve(!0)}fetchDatabase(){var e=this;return(0,u.default)((function*(){var{containerProps:{detail:{id:t}={}}={}}=e.props;yield e.databaseStore.fetchList({id:t}),e.updateDefaultValue()}))()}get database(){var e;return(0,i.default)(e=this.databaseStore.list.data||[]).call(e,(e=>({label:e.name,value:e.name,key:e.name})))}get defaultValue(){var{name:e,databases:t}=this.item;return{name:e,database:t}}get formItems(){return[{name:""name"",label:t(""Name""),type:""input-name"",required:!0,disabled:!0},{name:""database"",label:t(""Database""),type:""select"",options:this.database,mode:""multiple"",required:!0,loading:this.databaseStore.list.isLoading,disabled:this.databaseStore.list.isLoading}]}}a.UserDatabase=p,(0,o.default)(p,""id"",""grant-databases-access""),(0,o.default)(p,""title"",t(""Grant Databases Access"")),(0,o.default)(p,""policy"",""instance:extension:user_access:update"");var v=(0,d.inject)(""rootStore"")((0,d.observer)(p));a.default=v},4100:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Databases=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=r(1310),d=l(r(4101));class c extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Database Name""),dataIndex:""name""}]))}init(){this.store=new o.InstancesDatabasesStore}get rowKey(){return""name""}get name(){return""Databases""}get policy(){return""instance:extension:database:index""}get actionConfigs(){return this.isAdminPage?d.default.actionConfigsAdmin:d.default.actionConfigs}get hideCustom(){return!0}}a.Databases=c;var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4101:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=void 0;var l=n(a(4102)),i=n(a(4103)),s={actionConfigs:{rowActions:{firstAction:l.default},batchActions:[l.default],primaryActions:[i.default]},actionConfigsAdmin:{rowActions:{firstAction:l.default},batchActions:[l.default],primaryActions:[]}};t.default=s},4102:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=void 0;var i=l(r(36)),s=r(1193),u=l(r(1310));class o extends s.ConfirmAction{constructor(){super(...arguments),(0,i.default)(this,""allowedCheckFunction"",(()=>!0)),(0,i.default)(this,""policy"",""instance:extension:database:delete""),(0,i.default)(this,""onSubmit"",(e=>{var{id:t}=this.containerProps.detail,a=e.name||this.item.name;return u.default.deleteDatabase({id:t,name:a})}))}get id(){return""delete-database-database""}get title(){return t(""Delete Database"")}get actionName(){return t(""Delete Database"")}get isDanger(){return!0}get buttonText(){return t(""Delete"")}}a.default=o},4103:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.DatabaseCreate=void 0;var i=l(r(65)),s=l(r(36)),u=r(406),o=l(r(1325)),d=l(r(1310));class c extends o.default{constructor(){super(...arguments),(0,s.default)(this,""onSubmit"",(e=>{var{id:t}=this.item;return this.store.create(t,{databases:[{character_set:""utf8"",collate:""utf8_general_ci"",name:e.databaseName}]})}))}init(){this.store=d.default}get name(){return t(""Create Database"")}static allowed(){return i.default.resolve(!0)}get formItems(){return[{name:""databaseName"",label:t(""Name""),type:""input-name"",required:!0,isDatabaseName:!0,maxLength:64}]}}a.DatabaseCreate=c,(0,s.default)(c,""id"",""create-database""),(0,s.default)(c,""title"",t(""Create Database"")),(0,s.default)(c,""policy"",""instance:extension:database:create"");var f=(0,u.inject)(""rootStore"")((0,u.observer)(c));a.default=f},4104:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Backups=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=r(4105);class d extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Name""),dataIndex:""name""},{title:t(""Created""),dataIndex:""created""},{title:t(""Backup File""),dataIndex:""locationRef""},{title:t(""Incremental""),dataIndex:""incremental""},{title:t(""Status""),dataIndex:""status""}]))}init(){this.store=new o.InstanceBackupsStore}get name(){return t(""Backups"")}get policy(){return""instance:backups""}}a.Backups=d;var c=(0,u.inject)(""rootStore"")((0,u.observer)(d));a.default=c},4105:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.InstanceBackupsStore=void 0;var l=n(a(53)),i=n(a(48));class s extends l.default{get client(){return i.default.trove.instances.backups}get responseKey(){return""backup""}get isSubResource(){return!0}get paramsFunc(){return()=>{}}}t.InstanceBackupsStore=s;var u=new s;t.default=u},4106:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Logs=void 0;var i=l(r(36)),s=l(r(1194)),u=r(406),o=r(4107);class d extends s.default{constructor(){super(...arguments),(0,i.default)(this,""getColumns"",(()=>[{title:t(""Name""),dataIndex:""name""}]))}init(){this.store=new o.InstancesLogStore}get name(){return t(""Log"")}get policy(){return""instance:guest_log_list""}}a.Logs=d;var c=(0,u.inject)(""rootStore"")((0,u.observer)(d));a.default=c},4107:function(e,t,a){""use strict"";var r=a(19),n=a(21);r(t,""__esModule"",{value:!0}),t.default=t.InstancesLogStore=void 0;var l=n(a(53)),i=n(a(48));class s extends l.default{get client(){return i.default.trove.instances.log}get responseKey(){return""logs""}get isSubResource(){return!0}get paramsFunc(){return()=>{}}}t.InstancesLogStore=s;var u=new s;t.default=u},4108:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Defaults=void 0;var i=l(r(111)),s=l(r(1202)),u=r(406);class o extends s.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Number of Nodes""),dataIndex:""node_groups"",render:e=>(0,i.default)(e,[""0"",""count""],""-"")}];return{title:t(""Defaults""),options:e}}}a.Defaults=o;var d=(0,u.inject)(""rootStore"")((0,u.observer)(o));a.default=d},4109:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.ConfigurationsDetail=void 0;var i=r(406),s=l(r(1200)),u=l(r(1355)),o=l(r(4110)),d=l(r(4111)),c=l(r(4112));class f extends s.default{init(){this.store=u.default}get name(){return""Configurations Detail""}get listUrl(){return this.getRoutePath(""configurations"")}get policy(){return""configuration:show""}get detailInfos(){return[{title:t(""Name""),dataIndex:""name""}]}get tabs(){return[{title:t(""Detail""),key:""general_info"",component:o.default},{title:t(""Values""),key:""values"",component:d.default},{title:t(""Instances""),key:""instances"",component:c.default}]}}a.ConfigurationsDetail=f;var m=(0,i.inject)(""rootStore"")((0,i.observer)(f));a.default=m},4110:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BaseDetail=void 0;var i=r(406),s=l(r(1202));class u extends s.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Name""),dataIndex:""name""},{label:t(""Description""),dataIndex:""description""},{label:t(""Datastore""),dataIndex:""datastore_name""},{label:t(""Datastore Version""),dataIndex:""datastore_version_name""},{label:t(""Created""),dataIndex:""created""},{label:t(""Updated""),dataIndex:""updated""}];return{title:t(""Base Info""),options:e}}}a.BaseDetail=u;var o=(0,i.inject)(""rootStore"")((0,i.observer)(u));a.default=o},4111:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Values=void 0;var i=l(r(1202)),s=r(406);class u extends i.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Values""),dataIndex:""values""}];return{title:t(""Defaults""),options:e}}}a.Values=u;var o=(0,s.inject)(""rootStore"")((0,s.observer)(u));a.default=o},4112:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.Instances=void 0;var i=l(r(1202)),s=r(406);class u extends i.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Instances""),dataIndex:""instance_count""}];return{title:t(""Defaults""),options:e}}}a.Instances=u;var o=(0,s.inject)(""rootStore"")((0,s.observer)(u));a.default=o},4113:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BackupsDetail=void 0;var i=r(406),s=l(r(1200)),u=r(1354),o=l(r(4114));class d extends s.default{init(){this.store=new u.BackupsStore}get name(){return t(""Database Backup Detail"")}get listUrl(){return this.getRoutePath(""databaseBackups"")}get policy(){return""backup:show""}get detailInfos(){return[{title:t(""Name""),dataIndex:""name""},{title:t(""Description""),dataIndex:""description""}]}get tabs(){return[{title:t(""Detail""),key:""general_info"",component:o.default}]}}a.BackupsDetail=d;var c=(0,i.inject)(""rootStore"")((0,i.observer)(d));a.default=c},4114:function(e,a,r){""use strict"";var n=r(19),l=r(21);n(a,""__esModule"",{value:!0}),a.default=a.BaseDetail=void 0;var i=r(406),s=l(r(1202));class u extends s.default{get leftCards(){return[this.baseInfoCard]}get baseInfoCard(){var e=[{label:t(""Datastore""),dataIndex:""datastore.type""},{label:t(""Datastore Version""),dataIndex:""datastore.version""},{label:t(""Backup File Location""),dataIndex:""locationRef""},{label:t(""Initial Volume Size""),dataIndex:""size""},{label:t(""Created""),dataIndex:""created""},{label:t(""Updated""),dataIndex:""updated""},{label:t(""Status""),dataIndex:""status""}];return{title:t(""Base Info""),options:e}}}a.BaseDetail=u;var o=(0,i.inject)(""rootStore"")((0,i.observer)(u));a.default=o}}]);",27,29
openstack%2Foslo.log~master~I7371ea5e3cd27b1bd8789c17c50934cccace2ebe,openstack/oslo.log,master,I7371ea5e3cd27b1bd8789c17c50934cccace2ebe,DNM Possible fix for LP#1995514,ABANDONED,2022-11-08 15:43:33.000000000,2022-11-11 09:53:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-08 15:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/94ac2bb9e8d27332249f17714c3258fbf18f571b', 'message': 'DNM Possible fix for LP#1995514\n\nRelated-Bug: #1995514\nChange-Id: I7371ea5e3cd27b1bd8789c17c50934cccace2ebe\n'}, {'number': 2, 'created': '2022-11-10 10:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/c84c3621521949acd9a3f22df50912fc186a0c0a', 'message': 'DNM Possible fix for LP#1995514\n\nRelated-Bug: #1995514\nChange-Id: I7371ea5e3cd27b1bd8789c17c50934cccace2ebe\n'}, {'number': 3, 'created': '2022-11-10 14:17:58.000000000', 'files': ['oslo_log/log.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/8aefb30d27ed67fc3fa395f67ca44f41cba7e0a6', 'message': 'DNM Possible fix for LP#1995514\n\nRelated-Bug: #1995514\nChange-Id: I7371ea5e3cd27b1bd8789c17c50934cccace2ebe\n'}]",14,864018,8aefb30d27ed67fc3fa395f67ca44f41cba7e0a6,7,1,3,16688,,,0,"DNM Possible fix for LP#1995514

Related-Bug: #1995514
Change-Id: I7371ea5e3cd27b1bd8789c17c50934cccace2ebe
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/18/864018/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_log/log.py'],1,94ac2bb9e8d27332249f17714c3258fbf18f571b,bug/1995514, if logging.Handler.createLock != pipe_mutex.pipe_createLock: logging.threading = eventlet.green.threading logging._lock = logging.threading.RLock() logging.Handler.createLock = pipe_mutex.pipe_createLock, logging.threading = eventlet.green.threading logging._lock = logging.threading.RLock() logging.Handler.createLock = pipe_mutex.pipe_createLock,4,3
openstack%2Foslo.privsep~master~I72798f290223e77d234b1228837dd7bb1bafcc29,openstack/oslo.privsep,master,I72798f290223e77d234b1228837dd7bb1bafcc29,DNM Possible fix for LP#1995514,ABANDONED,2022-11-10 14:20:01.000000000,2022-11-11 09:53:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-10 14:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/2d85e4bc87b6f4758d49cd57b34333aba86e6e88', 'message': 'DNM Possible fix for LP#1995514\n\nDepends-On: https://review.opendev.org/c/openstack/oslo.log/+/864018\n\nRelated-Bug: #1995514\nChange-Id: I72798f290223e77d234b1228837dd7bb1bafcc29\n'}, {'number': 2, 'created': '2022-11-10 15:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/c74a74393bcad78f7843ff8ffddb76e032af58e0', 'message': 'DNM Possible fix for LP#1995514\n\nDepends-On: https://review.opendev.org/c/openstack/oslo.log/+/864018\n\nRelated-Bug: #1995514\nChange-Id: I72798f290223e77d234b1228837dd7bb1bafcc29\n'}, {'number': 3, 'created': '2022-11-10 16:49:44.000000000', 'files': ['oslo_privsep/daemon.py'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/a069b355708c481bda635d61e0a18e5e9627fcc6', 'message': 'DNM Possible fix for LP#1995514\n\nDepends-On: https://review.opendev.org/c/openstack/oslo.log/+/864018\n\nRelated-Bug: #1995514\nChange-Id: I72798f290223e77d234b1228837dd7bb1bafcc29\n'}]",0,864209,a069b355708c481bda635d61e0a18e5e9627fcc6,6,1,3,16688,,,0,"DNM Possible fix for LP#1995514

Depends-On: https://review.opendev.org/c/openstack/oslo.log/+/864018

Related-Bug: #1995514
Change-Id: I72798f290223e77d234b1228837dd7bb1bafcc29
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/09/864209/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_privsep/daemon.py'],1,2d85e4bc87b6f4758d49cd57b34333aba86e6e88,bug/1995514," logging.setup(cfg.CONF, 'privsep', fix_privsep=False) # note replace_logging call below"," logging.setup(cfg.CONF, 'privsep') # note replace_logging call below",1,1
openstack%2Fopenstack-ansible-ops~master~I5e6c42398acf70012bf879f41953d409abbd89f4,openstack/openstack-ansible-ops,master,I5e6c42398acf70012bf879f41953d409abbd89f4,Add support for apt package pinning,MERGED,2022-05-27 07:50:13.000000000,2022-11-11 09:13:16.000000000,2022-11-11 09:12:19.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2022-05-27 07:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/df7ff53798722511f4cee026588fcf797b19e437', 'message': ""Add support for apt package pinning\n\nAdds variables to pin elastic package versions to ensure they\ncan't move out of sequence. An individual variable is added\nfor journalbeat given it is withdrawn from 7.16.\n\nChange-Id: I5e6c42398acf70012bf879f41953d409abbd89f4\n""}, {'number': 2, 'created': '2022-06-06 14:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/8d26a3d1bbb5cd1f16345b5db6d39112f73b7ce9', 'message': ""Add support for apt package pinning\n\nAdds variables to pin elastic package versions to ensure they\ncan't move out of sequence. An individual variable is added\nfor journalbeat given it is withdrawn from 7.16.\n\nChange-Id: I5e6c42398acf70012bf879f41953d409abbd89f4\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-ops/+/844850\n""}, {'number': 3, 'created': '2022-10-28 09:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/28b1b478e874cd200faa89d0f99f84d9e0287e34', 'message': ""Add support for apt package pinning\n\nAdds variables to pin elastic package versions to ensure they\ncan't move out of sequence. An individual variable is added\nfor journalbeat given it is withdrawn from 7.16.\n\nChange-Id: I5e6c42398acf70012bf879f41953d409abbd89f4\n""}, {'number': 4, 'created': '2022-10-28 13:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/dfa685397a59fd01bde1058a1b2094602396d271', 'message': ""Add support for apt package pinning\n\nAdds variables to pin elastic package versions to ensure they\ncan't move out of sequence. An individual variable is added\nfor journalbeat given it is withdrawn from 7.16.\n\nChange-Id: I5e6c42398acf70012bf879f41953d409abbd89f4\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-ops/+/862915\n""}, {'number': 5, 'created': '2022-10-28 13:57:48.000000000', 'files': ['elk_metrics_7x/vars/variables.yml', 'elk_metrics_7x/ansible-role-requirements.yml', 'elk_metrics_7x/roles/elastic_repositories/meta/main.yml', 'elk_metrics_7x/roles/elastic_ilm/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/29080ab4f6cfbcb9e55cfdcab3f6e569c88e814a', 'message': ""Add support for apt package pinning\n\nAdds variables to pin elastic package versions to ensure they\ncan't move out of sequence. An individual variable is added\nfor journalbeat given it is withdrawn from 7.16.\n\nIncludes a version bump to a more recent 7.x release which is\nstill compatible with this role\n\nChange-Id: I5e6c42398acf70012bf879f41953d409abbd89f4\n""}]",6,843573,29080ab4f6cfbcb9e55cfdcab3f6e569c88e814a,21,3,5,31542,,,0,"Add support for apt package pinning

Adds variables to pin elastic package versions to ensure they
can't move out of sequence. An individual variable is added
for journalbeat given it is withdrawn from 7.16.

Includes a version bump to a more recent 7.x release which is
still compatible with this role

Change-Id: I5e6c42398acf70012bf879f41953d409abbd89f4
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/73/843573/2 && git format-patch -1 --stdout FETCH_HEAD,"['elk_metrics_7x/vars/variables.yml', 'elk_metrics_7x/ansible-role-requirements.yml', 'elk_metrics_7x/roles/elastic_repositories/meta/main.yml']",3,df7ff53798722511f4cee026588fcf797b19e437,elk-apt,dependencies: - role: apt_package_pinning,dependencies: [],35,1
openstack%2Fansible-collections-openstack~master~I6f9eef184538df4feff49dd6ed659a9b9ac1289f,openstack/ansible-collections-openstack,master,I6f9eef184538df4feff49dd6ed659a9b9ac1289f,"Refactored keystone_federation_protocol{,_info} modules",MERGED,2022-11-08 13:15:53.000000000,2022-11-11 09:00:24.000000000,2022-11-11 09:00:24.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-08 13:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/7db0e9f3ee36af9d9a9e33e5d34d1e4d4238f432', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}, {'number': 2, 'created': '2022-11-08 13:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/83e93848bbc7eee99d715723f295ec5e9aebb836', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}, {'number': 3, 'created': '2022-11-08 14:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ba4ef700ae6428011aaf29015c2ae170a99ae76b', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}, {'number': 4, 'created': '2022-11-08 19:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d7eae85454943145a486692f2cb46ebb8623469a', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}, {'number': 5, 'created': '2022-11-08 19:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8ad98808085728aaaacda699eee76f94755c402f', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}, {'number': 6, 'created': '2022-11-09 13:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/235a43d026b5eb942e6730388423b2773fc45eed', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}, {'number': 7, 'created': '2022-11-10 18:41:14.000000000', 'files': ['plugins/modules/keystone_federation_protocol.py', 'ci/roles/keystone_federation_protocol/defaults/main.yml', 'ci/roles/keystone_federation_protocol/tasks/main.yml', 'plugins/modules/keystone_federation_protocol_info.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/114bc855c00a4efd91c346a0ddb0b89aa191d26f', 'message': 'Refactored keystone_federation_protocol{,_info} modules\n\nChange-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f\n'}]",2,864003,114bc855c00a4efd91c346a0ddb0b89aa191d26f,21,4,7,32962,,,0,"Refactored keystone_federation_protocol{,_info} modules

Change-Id: I6f9eef184538df4feff49dd6ed659a9b9ac1289f
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/03/864003/6 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/keystone_federation_protocol/defaults/main.yml', 'plugins/modules/keystone_federation_protocol.py', 'ci/roles/keystone_federation_protocol/tasks/main.yml', 'plugins/modules/keystone_federation_protocol_info.py']",4,7db0e9f3ee36af9d9a9e33e5d34d1e4d4238f432,identity-federation-protocol,"DOCUMENTATION = r'''short_description: Fetch Keystone federation protocols - Fetch Keystone federation protocols. - ID or name of the federation protocol. idp: description: - ID or name of the identity provider this protocol is associated with. aliases: ['idp_id', 'idp_name']notes: - Name equals the ID of a federation protocol. - Name equals the ID of an identity provider. - ""openstacksdk""EXAMPLES = r''' - name: Fetch all federation protocols attached to an identity provider idp: example_idp - name: Fetch federation protocol by name idp: example_idp name: example_protocolRETURN = r''' protocols: description: List of federation protocol dictionaries. returned: always type: list elements: dict contains: id: description: ID of the federation protocol. returned: success type: str mapping_id: description: The definition of the federation protocol. returned: success type: str name: description: Name of the protocol. Equal to C(id). returned: success type: str idp=dict(required=True, aliases=['idp_id', 'idp_name']), def run(self): # name is id for federation protocols id = self.params['name'] # name is id for identity providers idp_id = self.params['idp'] if id: protocol = self.conn.identity.find_federation_protocol(idp_id, id) if protocol: protocols = [protocol] else: protocols = [] else: protocols = self.conn.identity.federation_protocols(idp_id) self.exit_json(changed=False, protocols=[p.to_dict(computed=False) for p in protocols])","DOCUMENTATION = '''short_description: get information about federation Protocols - Get information about federation Protocols. - The name of the Protocol. idp_id: description: - The name of the Identity Provider this Protocol is associated with. aliases: ['idp_name'] - ""openstacksdk >= 0.44""EXAMPLES = ''' - name: Describe a protocol name: example_protocol idp_id: example_idp mapping_name: example_mapping - name: Describe all protocols attached to an IDP idp_id: example_idpRETURN = ''' idp_id=dict(required=True, aliases=['idp_name']), def normalize_protocol(self, protocol): """""" Normalizes the protocol definitions so that the outputs are consistent with the parameters - ""name"" (parameter) == ""id"" (SDK) """""" if protocol is None: return None _protocol = protocol.to_dict() _protocol['name'] = protocol['id'] # As of 0.44 SDK doesn't copy the URI parameters over, so let's add them _protocol['idp_id'] = protocol['idp_id'] return _protocol def run(self): """""" Module entry point """""" name = self.params.get('name') idp = self.params.get('idp_id') if name: protocol = self.conn.identity.get_federation_protocol(idp, name) protocol = self.normalize_protocol(protocol) self.exit_json(changed=False, protocols=[protocol]) else: protocols = list(map(self.normalize_protocol, self.conn.identity.federation_protocols(idp))) self.exit_json(changed=False, protocols=protocols)",227,283
openstack%2Fnova~stable%2Fvictoria~I5540df6c7497956219c06cff6f15b51c2c8bc299,openstack/nova,stable/victoria,I5540df6c7497956219c06cff6f15b51c2c8bc299,add regression test case for bug 1978983,MERGED,2022-08-29 09:39:07.000000000,2022-11-11 08:56:22.000000000,2022-10-10 16:14:05.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-29 09:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfa293ee0079b8dc03bbbadb89fd53921fa4a1c0', 'message': 'add regression test case for bug 1978983\n\nThis change add a repoducer test for evacuating\na vm in the powering-off state\n\nRelated-Bug: #1978983\nChange-Id: I5540df6c7497956219c06cff6f15b51c2c8bc299\n(cherry picked from commit 5904c7f993ac737d68456fc05adf0aaa7a6f3018)\n(cherry picked from commit 6bd0bf00fca6ac6460d70c855eded3898cfe2401)\n(cherry picked from commit 1e0af92e17f878ce64bd16e428cb3c10904b0877)\n(cherry picked from commit b57b0eef218fd7604658842c9277aad782d11b45)\n'}, {'number': 2, 'created': '2022-08-29 10:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c2b8437427466eca29a29655f884922270db399', 'message': 'add regression test case for bug 1978983\n\nThis change add a repoducer test for evacuating\na vm in the powering-off state\n\nRelated-Bug: #1978983\nChange-Id: I5540df6c7497956219c06cff6f15b51c2c8bc299\n(cherry picked from commit 5904c7f993ac737d68456fc05adf0aaa7a6f3018)\n(cherry picked from commit 6bd0bf00fca6ac6460d70c855eded3898cfe2401)\n(cherry picked from commit 1e0af92e17f878ce64bd16e428cb3c10904b0877)\n(cherry picked from commit b57b0eef218fd7604658842c9277aad782d11b45)\n'}, {'number': 3, 'created': '2022-08-29 10:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0fd80b0f35d38a3346d458a14a8cb6671016b8f', 'message': 'add regression test case for bug 1978983\n\nThis change add a repoducer test for evacuating\na vm in the powering-off state\n\nRelated-Bug: #1978983\nChange-Id: I5540df6c7497956219c06cff6f15b51c2c8bc299\n(cherry picked from commit 5904c7f993ac737d68456fc05adf0aaa7a6f3018)\n(cherry picked from commit 6bd0bf00fca6ac6460d70c855eded3898cfe2401)\n(cherry picked from commit 1e0af92e17f878ce64bd16e428cb3c10904b0877)\n(cherry picked from commit b57b0eef218fd7604658842c9277aad782d11b45)\n'}, {'number': 4, 'created': '2022-09-06 11:22:20.000000000', 'files': ['nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/regressions/test_bug_1978983.py', 'nova/tests/functional/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b6c877377f58ccaa797af3384b199002726745ea', 'message': 'add regression test case for bug 1978983\n\nThis change add a repoducer test for evacuating\na vm in the powering-off state\n\nWhile backporting to stable/victoria\nFixed conflict in functional.integrated_helpers\n1 - Added placeholder NOT_SPECIFIED as object\n\tIts a default parameter value for _evacuate_server\n2 - Updated _evacuate_server defition\n\tto allow function to wait, until expected\n\tserver state reached\n3 - Added _start_server and _stop_server\n4 - Updated _evacuate_server arguments for test_evacuate\nas per updated _evacuate_server signature\n\nRelated-Bug: #1978983\nChange-Id: I5540df6c7497956219c06cff6f15b51c2c8bc299\n(cherry picked from commit 5904c7f993ac737d68456fc05adf0aaa7a6f3018)\n(cherry picked from commit 6bd0bf00fca6ac6460d70c855eded3898cfe2401)\n(cherry picked from commit 1e0af92e17f878ce64bd16e428cb3c10904b0877)\n(cherry picked from commit b57b0eef218fd7604658842c9277aad782d11b45)\n'}]",12,854979,b6c877377f58ccaa797af3384b199002726745ea,18,4,4,34860,,,0,"add regression test case for bug 1978983

This change add a repoducer test for evacuating
a vm in the powering-off state

While backporting to stable/victoria
Fixed conflict in functional.integrated_helpers
1 - Added placeholder NOT_SPECIFIED as object
	Its a default parameter value for _evacuate_server
2 - Updated _evacuate_server defition
	to allow function to wait, until expected
	server state reached
3 - Added _start_server and _stop_server
4 - Updated _evacuate_server arguments for test_evacuate
as per updated _evacuate_server signature

Related-Bug: #1978983
Change-Id: I5540df6c7497956219c06cff6f15b51c2c8bc299
(cherry picked from commit 5904c7f993ac737d68456fc05adf0aaa7a6f3018)
(cherry picked from commit 6bd0bf00fca6ac6460d70c855eded3898cfe2401)
(cherry picked from commit 1e0af92e17f878ce64bd16e428cb3c10904b0877)
(cherry picked from commit b57b0eef218fd7604658842c9277aad782d11b45)
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/854979/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/regressions/test_bug_1978983.py', 'nova/tests/functional/test_servers.py']",3,cfa293ee0079b8dc03bbbadb89fd53921fa4a1c0,bug/1978983," self._evacuate_server(self.server, expected_host=compute_to_evacuate.host)"," self._evacuate_server(self.server, compute_to_evacuate.host)",115,6
openstack%2Fpython-tripleoclient~master~If2a3f1d2d332a930ea9a529088b3a2ab91d50b53,openstack/python-tripleoclient,master,If2a3f1d2d332a930ea9a529088b3a2ab91d50b53,Omit empty environment files,MERGED,2022-10-17 02:14:34.000000000,2022-11-11 08:25:12.000000000,2022-11-11 08:24:14.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 8833}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-10-17 02:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/353e2b8834da004f12432e134dd734a56d640b81', 'message': 'Omit deployed-server-environment.yaml\n\n... because now the environment file is empty and tht uses the deployed\nservers by default.\n\nDepends-on: https://review.opendev.org/861547\nChange-Id: If2a3f1d2d332a930ea9a529088b3a2ab91d50b53\n'}, {'number': 2, 'created': '2022-10-20 05:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2a3d125e7a6816b47585b64936df618e9076bf71', 'message': 'Omit empty environment files\n\nThe following two environment files are now empty, after we updated\nthe default in tht to support only pre-provisioned nodes\n - deployed-server-environment.yaml\n - deployed-server-noop-ctlplane.yaml\n\nThis drops usage of these two files so that we can remove these empty\nfiles completely\n... because now the environment file is empty and tht uses the deployed\nservers by default.\n\nDepends-on: https://review.opendev.org/861547\nChange-Id: If2a3f1d2d332a930ea9a529088b3a2ab91d50b53\n'}, {'number': 3, 'created': '2022-10-20 05:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/efd6019f5a6d9e63becdf8ff696892eb38b4bbe1', 'message': 'Omit empty environment files\n\nThe following two environment files are now empty, after we updated\nthe default in tht to support only pre-provisioned nodes\n - deployed-server-environment(.j2).yaml\n - deployed-server-noop-ctlplane.yaml\n\nThis drops usage of these two files so that we can remove these empty\nfiles completely\n... because now the environment file is empty and tht uses the deployed\nservers by default.\n\nDepends-on: https://review.opendev.org/861547\nChange-Id: If2a3f1d2d332a930ea9a529088b3a2ab91d50b53\n'}, {'number': 4, 'created': '2022-10-20 05:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8787f4c2bd47318e9425fa92223da4cc71044d17', 'message': 'Omit empty environment files\n\nThe following two environment files are now empty, after we updated\nthe default in tht to support only pre-provisioned nodes\n - deployed-server-environment(.j2).yaml\n - deployed-server-noop-ctlplane.yaml\n\nThis drops usage of these two files so that we can remove these empty\nfiles completely because now the environment file is empty and tht uses\nthe deployed servers by default.\n\nDepends-on: https://review.opendev.org/861547\nChange-Id: If2a3f1d2d332a930ea9a529088b3a2ab91d50b53\n'}, {'number': 5, 'created': '2022-10-20 05:53:00.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/tripleo_deploy.py', 'tripleoclient/constants.py', 'tripleoclient/tests/v1/tripleo/test_tripleo_deploy.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/57ddfddbcae77d4f9407bbdcc1748523d02288a9', 'message': 'Omit empty environment files\n\nThe following two environment files are now empty, after we updated\nthe default in tht to support only pre-provisioned nodes\n - deployed-server-environment(.j2).yaml\n - deployed-server-noop-ctlplane.yaml\n\nThis drops usage of these two files so that we can remove these empty\nfiles completely.\n\nDepends-on: https://review.opendev.org/861547\nChange-Id: If2a3f1d2d332a930ea9a529088b3a2ab91d50b53\n'}]",4,861548,57ddfddbcae77d4f9407bbdcc1748523d02288a9,20,7,5,9816,,,0,"Omit empty environment files

The following two environment files are now empty, after we updated
the default in tht to support only pre-provisioned nodes
 - deployed-server-environment(.j2).yaml
 - deployed-server-noop-ctlplane.yaml

This drops usage of these two files so that we can remove these empty
files completely.

Depends-on: https://review.opendev.org/861547
Change-Id: If2a3f1d2d332a930ea9a529088b3a2ab91d50b53
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/48/861548/4 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/constants.py', 'tripleoclient/v1/overcloud_deploy.py']",3,353e2b8834da004f12432e134dd734a56d640b81,uc-nova-cleanup,," created_env_files.append( os.path.join( new_tht_root, constants.DEPLOYED_SERVER_ENVIRONMENT)) ",0,13
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~I28a4d173505a194c8a735e8b2e1c6f2589338730,openstack/tripleo-heat-templates,stable/wallaby,I28a4d173505a194c8a735e8b2e1c6f2589338730,Fix tls-e CA cert declaration for OVN,MERGED,2022-09-19 05:31:45.000000000,2022-11-11 08:24:11.000000000,2022-11-11 08:24:11.000000000,"[{'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-09-19 05:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5ad1d048adf28048ec3855a8a78ff910b4489045', 'message': 'Fix tls-e CA cert declaration for OVN\n\nWhen using the OVN Cluster Ansible role, we currently default to\n/etc/ipa/ca.crt. We should instead use the value defined by the\nuser in InternalTLSCAFile parameter.\n\nThis change defines the relevant Ansible variables when the role\nis called:\n  tripleo_ovn_cluster_northd_ssl_ca_cert\n  tripleo_ovn_cluster_sb_ssl_ca_cert\n  tripleo_ovn_cluster_nb_ssl_ca_cert\n\nCloses-Bug: #1989535\nChange-Id: I28a4d173505a194c8a735e8b2e1c6f2589338730\n'}, {'number': 2, 'created': '2022-09-29 00:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75fb8e51727e6381d795f0a0a92c9fe6ee8e21f5', 'message': 'Fix tls-e CA cert declaration for OVN\n\nWhen using the OVN Cluster Ansible role, we currently default to\n/etc/ipa/ca.crt. We should instead use the value defined by the\nuser in InternalTLSCAFile parameter.\n\nThis change defines the relevant Ansible variables when the role\nis called:\n  tripleo_ovn_cluster_northd_ssl_ca_cert\n  tripleo_ovn_cluster_sb_ssl_ca_cert\n  tripleo_ovn_cluster_nb_ssl_ca_cert\n\nCloses-Bug: #1989535\nResolves: rhbz#2126725\nChange-Id: I28a4d173505a194c8a735e8b2e1c6f2589338730\n'}, {'number': 3, 'created': '2022-11-02 00:48:53.000000000', 'files': ['deployment/ovn/ovn-dbs-cluster-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee45db3ef2f0c03cfa4dff0321b4a673237e1724', 'message': 'Fix tls-e CA cert declaration for OVN\n\nWhen using the OVN Cluster Ansible role, we currently default to\n/etc/ipa/ca.crt. We should instead use the value defined by the\nuser in InternalTLSCAFile parameter.\n\nThis change defines the relevant Ansible variables when the role\nis called:\n  tripleo_ovn_cluster_northd_ssl_ca_cert\n  tripleo_ovn_cluster_sb_ssl_ca_cert\n  tripleo_ovn_cluster_nb_ssl_ca_cert\n\nCloses-Bug: #1989535\nChange-Id: I28a4d173505a194c8a735e8b2e1c6f2589338730\n(cherry picked from commit 3c5d5a12fd6cb4b582d43b81cef2cb59974980a7)\n'}]",7,858039,ee45db3ef2f0c03cfa4dff0321b4a673237e1724,33,4,3,30073,,,0,"Fix tls-e CA cert declaration for OVN

When using the OVN Cluster Ansible role, we currently default to
/etc/ipa/ca.crt. We should instead use the value defined by the
user in InternalTLSCAFile parameter.

This change defines the relevant Ansible variables when the role
is called:
  tripleo_ovn_cluster_northd_ssl_ca_cert
  tripleo_ovn_cluster_sb_ssl_ca_cert
  tripleo_ovn_cluster_nb_ssl_ca_cert

Closes-Bug: #1989535
Change-Id: I28a4d173505a194c8a735e8b2e1c6f2589338730
(cherry picked from commit 3c5d5a12fd6cb4b582d43b81cef2cb59974980a7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/858039/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-dbs-cluster-ansible.yaml'],1,5ad1d048adf28048ec3855a8a78ff910b4489045,fix-ovn-tls-stable/wallaby, tripleo_ovn_cluster_northd_ssl_ca_cert: {get_param: InternalTLSCAFile} tripleo_ovn_cluster_sb_ssl_ca_cert: {get_param: InternalTLSCAFile} tripleo_ovn_cluster_nb_ssl_ca_cert: {get_param: InternalTLSCAFile},,3,0
openstack%2Fswift~master~I1ded891087907ecf95c183abadbbc974ebef4a54,openstack/swift,master,I1ded891087907ecf95c183abadbbc974ebef4a54,replicator: Use last-primary table,NEW,2022-09-26 22:39:04.000000000,2022-11-11 06:40:14.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fc9591771d1b65dcb30755b2bd930670c2e168a9', 'message': 'replicator: Use last-primary table\n\nChange-Id: I1ded891087907ecf95c183abadbbc974ebef4a54\n'}, {'number': 2, 'created': '2022-09-27 00:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6e2ec26589342fd112cd7b533cbdca4d15ea527e', 'message': 'replicator: Use last-primary table\n\nChange-Id: I1ded891087907ecf95c183abadbbc974ebef4a54\n'}, {'number': 3, 'created': '2022-11-11 00:00:32.000000000', 'files': ['swift/obj/replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4be194c5ae5bd63c73e0437e8e436951e491835f', 'message': 'replicator: Use last-primary table\n\nChange-Id: I1ded891087907ecf95c183abadbbc974ebef4a54\n'}]",11,859349,4be194c5ae5bd63c73e0437e8e436951e491835f,10,2,3,15343,,,0,"replicator: Use last-primary table

Change-Id: I1ded891087907ecf95c183abadbbc974ebef4a54
",git fetch https://review.opendev.org/openstack/swift refs/changes/49/859349/3 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/replicator.py'],1,fc9591771d1b65dcb30755b2bd930670c2e168a9,,"import osfrom swift.obj.diskfile import get_data_dir, get_part_path, get_tmp_dir, \ DiskFileRouter def get_remote_hashes(self, node, policy_index, partition, rehash=True): headers = dict(self.default_headers) headers['X-Backend-Storage-Policy-Index'] = policy_index resp = None status = None remote_hash = {} try: with Timeout(self.http_timeout): resp = http_connect( node['replication_ip'], node['replication_port'], node['device'], partition, 'REPLICATE', '' if rehash else 'hashes', headers=headers).getresponse() status = resp.status if resp.status == HTTP_OK: remote_hash = pickle.loads(resp.read()) elif resp.status == HTTP_INSUFFICIENT_STORAGE: self.logger.error( '%(replication_ip)s/%(device)s ' 'responded as unmounted', node) # Note that caller is expected to see the 507 and know to # over-replicate to a handoff else: self.logger.error( ""Invalid response %(resp)s from %(ip)s"", {'resp': resp.status, 'ip': node['replication_ip']}) except (Exception, Timeout): self.logger.exception(""Error syncing with node: %s"", node) finally: del resp return status, remote_hash # Consolidate hashes -- don't actually rehash until we know we're # not a new primary being filled, though partition_path = get_part_path( df_mgr.get_dev_path(job['device']), job['policy'], job['partition'], ) local_hash = tpool.execute( df_mgr.consolidate_hashes, partition_path) # Fan out REPLICATEs to neighbors id_to_node = {} remote_hashes = {} try: node = next(nodes) except StopIteration: self.logger.error('Ran out of handoffs while replicating ' 'partition %s of policy %d', job['partition'], int(job['policy'])) break status, hashes = self.get_remote_hashes( node, int(job['policy']), int(job['partition']), rehash=False, ) if status == HTTP_OK: id_to_node[node['id']] = node remote_hashes[node['id']] = hashes else: failure_devs_info.add((node['replication_ip'], node['device'])) if status == HTTP_INSUFFICIENT_STORAGE: # XXX: Should there be some limit to how deep into # handoffs we're willing to go? attempts_left += 1 # else, error -- maybe it'll resolve for the next cycle? # Note that some of the suffix hashes gathered at this point may be # None, because they were invalidated -- the significant thing in # this preflight check is that a node knows about a suffix at all def is_handoff(suffixes, total): if suffixes < 10: # Small enough that we should err on the side of syncing return False return (suffixes / total) < self.sync_threshold_ratio remote_suffixes = max(len(h) for h in remote_hashes.values()) if is_handoff(len(local_hash), remote_suffixes): # Wait to be filled -- otherwise we're likely to # - waste iops rehashing locally # - remove local empty dirs created by an in-progress rsync, # causing a remote rsync failure # - invalidate remote suffixes based on local partial state stats.update_deferred += 1 return # Now we can rehash locally hashed, local_hash = tpool.execute( df_mgr._get_hashes, job['device'], job['partition'], job['policy'], do_listdir=_do_listdir( int(job['partition']), self.replication_cycle)) stats.suffix_hash += hashed self.logger.update_stats('suffix.hashes', hashed) total_suffixes = max(remote_suffixes, len(local_hash)) old_hashes = {} if any(is_handoff(len(h), max(remote_suffixes, len(local_hash))) for h in remote_hashes.values()): # Talk to old primaries, merge whatever they're trying to sync for node in job['last_nodes']: if node['id'] in remote_hashes: # Doesn't count if we were going to try to replicate # to it anyway. Most likely, some disks were unmounted # and this is a tiny cluster. continue status, hashes = self.get_remote_hashes( node, int(job['policy']), int(job['partition']), rehash=False, ) if status != HTTP_OK: failure_devs_info.add((node['replication_ip'], node['device'])) continue for suffix, hsh in hashes.items(): if suffix not in old_hashes: old_hashes[suffix] = hsh elif old_hashes[suffix] != hsh: # Old primaries are out-of-sync, treat as invalid old_hashes[suffix] = None for node_id, remote_hash in remote_hashes.items(): node = id_to_node[node_id] target_devs_info.add((node['replication_ip'], node['device'])) if is_handoff(len(remote_hash), total_suffixes): # can sync whatever's not on the old primaries suffixes = [suffix for suffix, hsh in local_hash.items() if remote_hash.get(suffix, -1) != hsh and suffix not in old_hashes] else: if any(hsh is None for hsh in remote_hash.values()): # Try to rehash the remote status, hashes = self.get_remote_hashes( node, int(job['policy']), int(job['partition']), rehash=True, ) if status == HTTP_OK: remote_hash = hashes else: # can still use what we've got, anyway suffixes = [suffix for suffix, hsh in local_hash.items() if remote_hash.get(suffix, -1) != hsh] #and remote_hash.get(suffix, -1) is not None] if not suffixes: # XXX: might want to differentiate between handoff and # ""normal"" hash-matches stats.hashmatch += 1 continue # TODO: should we do a local rehash of suffixes, like current master? stats.rsync += 1 success, _junk = self.sync(node, job, suffixes) if not success: # add only remote region when replicate succeeded if success and node['region'] != job['region']: synced_remote_regions.add(node['region']) stats.suffix_sync += len(suffixes) self.logger.update_stats('suffix.syncs', len(suffixes)) part = int(partition) part_nodes = policy.object_ring.get_part_nodes(part) last_nodes = list( policy.object_ring.get_last_part_nodes(part)) last_nodes=last_nodes,","import osfrom swift.obj.diskfile import get_data_dir, get_tmp_dir, DiskFileRouter hashed, local_hash = tpool.execute( df_mgr._get_hashes, job['device'], job['partition'], job['policy'], do_listdir=_do_listdir( int(job['partition']), self.replication_cycle)) stats.suffix_hash += hashed self.logger.update_stats('suffix.hashes', hashed) # If this throws StopIteration it will be caught way below node = next(nodes) target_devs_info.add((node['replication_ip'], node['device'])) try: with Timeout(self.http_timeout): resp = http_connect( node['replication_ip'], node['replication_port'], node['device'], job['partition'], 'REPLICATE', '', headers=headers).getresponse() if resp.status == HTTP_INSUFFICIENT_STORAGE: self.logger.error( '%(replication_ip)s/%(device)s ' 'responded as unmounted', node) attempts_left += 1 continue if resp.status != HTTP_OK: self.logger.error(""Invalid response %(resp)s "" ""from %(ip)s"", {'resp': resp.status, 'ip': node['replication_ip']}) failure_devs_info.add((node['replication_ip'], node['device'])) continue remote_hash = pickle.loads(resp.read()) del resp suffixes = [suffix for suffix in local_hash if local_hash[suffix] != remote_hash.get(suffix, -1)] if not suffixes: stats.hashmatch += 1 continue hashed, recalc_hash = tpool.execute( df_mgr._get_hashes, job['device'], job['partition'], job['policy'], recalculate=suffixes) self.logger.update_stats('suffix.hashes', hashed) local_hash = recalc_hash suffixes = [suffix for suffix in local_hash if local_hash[suffix] != remote_hash.get(suffix, -1)] if not suffixes: stats.hashmatch += 1 continue stats.rsync += 1 success, _junk = self.sync(node, job, suffixes) if not success: failure_devs_info.add((node['replication_ip'], node['device'])) # add only remote region when replicate succeeded if success and node['region'] != job['region']: synced_remote_regions.add(node['region']) stats.suffix_sync += len(suffixes) self.logger.update_stats('suffix.syncs', len(suffixes)) except (Exception, Timeout): self.logger.exception(""Error syncing with node: %s"", node) except StopIteration: self.logger.error('Ran out of handoffs while replicating ' 'partition %s of policy %d', job['partition'], int(job['policy'])) part_nodes = policy.object_ring.get_part_nodes( int(partition))",176,72
openstack%2Fheat~master~I9a08b938401cd71eddd0eb80782d10392f92bf45,openstack/heat,master,I9a08b938401cd71eddd0eb80782d10392f92bf45,Retry to detach volume if nova returned error 409,MERGED,2022-10-07 11:56:39.000000000,2022-11-11 06:37:48.000000000,2022-11-11 06:36:34.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-10-07 11:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2db49160a857af40fea9d20e72cb59b62daa4af3', 'message': ""Retry to detach volume if nova returned error 409\n\nDuring volume detachment an instance can be in error state or locked.\nNova returns error 409.\nInstance can be unlocked or fixed a bit later, but heat doesn't retry to detach volume.\nThe patch makes heat to retry detachments untill stack update timeout.\n\nstory: 2010355\nChange-Id: I9a08b938401cd71eddd0eb80782d10392f92bf45\n""}, {'number': 2, 'created': '2022-10-12 12:47:11.000000000', 'files': ['heat/tests/openstack/cinder/test_volume.py', 'heat/engine/resources/volume_base.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0ea1ee087a35a43e04fcdbee2405e55dc5ef20a4', 'message': ""Retry to detach volume if nova returned error 409\n\nDuring volume detachment an instance can be in error state or locked.\nNova returns error 409.\nInstance can be unlocked or fixed a bit later, but heat doesn't retry to detach volume.\nThe patch makes heat to retry detachments untill stack update timeout.\n\nstory: 2010355\nChange-Id: I9a08b938401cd71eddd0eb80782d10392f92bf45\n""}]",3,860682,0ea1ee087a35a43e04fcdbee2405e55dc5ef20a4,14,3,2,32927,,,0,"Retry to detach volume if nova returned error 409

During volume detachment an instance can be in error state or locked.
Nova returns error 409.
Instance can be unlocked or fixed a bit later, but heat doesn't retry to detach volume.
The patch makes heat to retry detachments untill stack update timeout.

story: 2010355
Change-Id: I9a08b938401cd71eddd0eb80782d10392f92bf45
",git fetch https://review.opendev.org/openstack/heat refs/changes/82/860682/2 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/volume_base.py'],1,2db49160a857af40fea9d20e72cb59b62daa4af3,story/2010355," prg = progress.VolumeDetachProgress(server_id, vol_id, self.resource_id) prg.called = self.client_plugin('nova').detach_volume( server_id, self.resource_id) if not prg.called: prg.called = self.client_plugin('nova').detach_volume( prg.srv_id, self.resource_id) return False"," self.client_plugin('nova').detach_volume(server_id, self.resource_id) prg = progress.VolumeDetachProgress( server_id, vol_id, self.resource_id) prg.called = True",8,5
openstack%2Ftrove-dashboard~master~If633e75b8078a060fca3f450a0960368c22e698d,openstack/trove-dashboard,master,If633e75b8078a060fca3f450a0960368c22e698d,Uses network_id instead of net-id,MERGED,2022-07-19 12:40:46.000000000,2022-11-11 05:45:11.000000000,2022-11-11 05:45:11.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-07-19 12:40:46.000000000', 'files': ['trove_dashboard/content/databases/workflows/create_instance.py', 'trove_dashboard/content/databases/tests.py', 'trove_dashboard/api/trove.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/74e48f10d86d364416e91f835e1677ee9d4c43a9', 'message': ""Uses network_id instead of net-id\n\nThis PR changes the keyname in nics from `net-id` to `network_id`.\n`net-id` is deprecated[1] since Victoria and some functions don't\nwork correctly.\n\nOriginal problem:\nTrove Clusters API returns errors when processing cluster creation\nrequests from trove-dashboard because trove-dashboard submit the\nrequests using the `net-id` whereas Trove Clusters API expects\n`network_id` there.\n\n[1]: https://opendev.org/openstack/trove/commit/5590ecdce036f7a2b11ff440dfd4eb637180abcc\n\nStory: 2010148\nTask: 45792\nChange-Id: If633e75b8078a060fca3f450a0960368c22e698d\n""}]",3,850344,74e48f10d86d364416e91f835e1677ee9d4c43a9,10,2,1,31737,,,0,"Uses network_id instead of net-id

This PR changes the keyname in nics from `net-id` to `network_id`.
`net-id` is deprecated[1] since Victoria and some functions don't
work correctly.

Original problem:
Trove Clusters API returns errors when processing cluster creation
requests from trove-dashboard because trove-dashboard submit the
requests using the `net-id` whereas Trove Clusters API expects
`network_id` there.

[1]: https://opendev.org/openstack/trove/commit/5590ecdce036f7a2b11ff440dfd4eb637180abcc

Story: 2010148
Task: 45792
Change-Id: If633e75b8078a060fca3f450a0960368c22e698d
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/44/850344/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove_dashboard/content/databases/workflows/create_instance.py', 'trove_dashboard/content/databases/tests.py', 'trove_dashboard/api/trove.py']",3,74e48f10d86d364416e91f835e1677ee9d4c43a9,story/2010148," instance[""nics""] = [{""network_id"": nics}] instance[""nics""] = [{'network_id': new_instance.nics}]"," instance[""nics""] = [{""net-id"": nics}] instance[""nics""] = [{'net-id': new_instance.nics}]",7,8
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Iec8c626a4b216b66a4b320f3de0d7c4b19dd2145,openstack/tripleo-heat-templates,stable/wallaby,Iec8c626a4b216b66a4b320f3de0d7c4b19dd2145,Set tls-verify false when using insecure reg,ABANDONED,2022-11-11 00:14:56.000000000,2022-11-11 05:15:30.000000000,,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-11 00:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f4a0e7c871f064046828c514996848a35ddb3855', 'message': 'Set tls-verify false when using insecure reg\n\nWhen we are using an insecure registry, podman login\nwill fail unless we set tripleo_podman_tls_verify to false.\n\nThis change adds the variable based on the condition that\ninsecure registries are being configured.\n\nChange-Id: Iec8c626a4b216b66a4b320f3de0d7c4b19dd2145\n(cherry picked from commit 4611aef0b70de2e88e15b538d704c6e5b93b2772)\n'}, {'number': 2, 'created': '2022-11-11 00:47:15.000000000', 'files': ['deployment/podman/podman-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8d06e8f517b727bb32a4b2cf2b174e932e6f9694', 'message': 'Set tls-verify false when using insecure reg\n\nWhen we are using an insecure registry, podman login\nwill fail unless we set tripleo_podman_tls_verify to false.\n\nThis change adds the variable based on the condition that\ninsecure registries are being configured.\n\nChange-Id: Iec8c626a4b216b66a4b320f3de0d7c4b19dd2145\n(cherry picked from commit 4611aef0b70de2e88e15b538d704c6e5b93b2772)\n'}]",1,864238,8d06e8f517b727bb32a4b2cf2b174e932e6f9694,6,3,2,30073,,,0,"Set tls-verify false when using insecure reg

When we are using an insecure registry, podman login
will fail unless we set tripleo_podman_tls_verify to false.

This change adds the variable based on the condition that
insecure registries are being configured.

Change-Id: Iec8c626a4b216b66a4b320f3de0d7c4b19dd2145
(cherry picked from commit 4611aef0b70de2e88e15b538d704c6e5b93b2772)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/864238/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/podman/podman-baremetal-ansible.yaml'],1,f4a0e7c871f064046828c514996848a35ddb3855,," ansible_group_vars: tripleo_podman_tls_verify: {if: [insecure_registry_is_set, ""false"", ""true""]}",,2,0
openstack%2Fnova~master~I9e187cd9554e192c09295fc2766beb708ccc61fe,openstack/nova,master,I9e187cd9554e192c09295fc2766beb708ccc61fe,Follow up changes for ephemeral encryption,NEW,2022-08-16 08:58:22.000000000,2022-11-11 04:12:44.000000000,,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-16 08:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd35aa11e16b9ada4299d6f2846fbf5e762456c6', 'message': 'Follow up changes for ephemeral encryption\n\nThis is a follow up for the ephemeral encryption patch series that\naddresses various comments that came up during review.\n\nChange-Id: I9e187cd9554e192c09295fc2766beb708ccc61fe\n'}, {'number': 2, 'created': '2022-08-19 17:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fbc03df67043efd46fc1e4d42a5dd829e14289df', 'message': 'Follow up changes for ephemeral encryption\n\nThis is a follow up for the ephemeral encryption patch series that\naddresses various comments that came up during review.\n\nChange-Id: I9e187cd9554e192c09295fc2766beb708ccc61fe\n'}, {'number': 3, 'created': '2022-11-11 00:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/153632e352745a77c6002812f5c69c116e4baeaa', 'message': 'Follow up changes for ephemeral encryption\n\nThis is a follow up for the ephemeral encryption patch series that\naddresses various comments that came up during review.\n\nChange-Id: I9e187cd9554e192c09295fc2766beb708ccc61fe\n'}, {'number': 4, 'created': '2022-11-11 01:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3fa9ce7c388bfd1ed3c75c6228d5bad9bf00dd37', 'message': 'Follow up changes for ephemeral encryption\n\nThis is a follow up for the ephemeral encryption patch series that\naddresses various comments that came up during review.\n\nChange-Id: I9e187cd9554e192c09295fc2766beb708ccc61fe\n'}, {'number': 5, 'created': '2022-11-11 02:19:14.000000000', 'files': ['nova/virt/libvirt/blockinfo.py', 'nova/tests/unit/scheduler/test_request_filter.py', 'doc/source/reference/block-device-structs.rst', 'nova/virt/driver.py', 'nova/objects/block_device.py', 'nova/virt/libvirt/utils.py', 'nova/compute/api.py', 'nova/db/main/models.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8ae276f853fde55a3778260f3e78f297ded27af9', 'message': 'Follow up changes for ephemeral encryption\n\nThis is a follow up for the ephemeral encryption patch series that\naddresses various comments that came up during review.\n\nChange-Id: I9e187cd9554e192c09295fc2766beb708ccc61fe\n'}]",0,853254,8ae276f853fde55a3778260f3e78f297ded27af9,20,2,5,4690,,,0,"Follow up changes for ephemeral encryption

This is a follow up for the ephemeral encryption patch series that
addresses various comments that came up during review.

Change-Id: I9e187cd9554e192c09295fc2766beb708ccc61fe
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/853254/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/blockinfo.py', 'nova/tests/unit/scheduler/test_request_filter.py', 'doc/source/reference/block-device-structs.rst', 'nova/objects/block_device.py', 'nova/virt/libvirt/utils.py', 'nova/compute/api.py', 'nova/db/main/models.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",8,dd35aa11e16b9ada4299d6f2846fbf5e762456c6,specs/yoga/approved/ephemeral-encryption-libvirt," self.assertTrue( drvr.capabilities['supports_ephemeral_encryption'], ""Driver capabilities for 'supports_ephemeral_encryption' "" ""is invalid"", )"," self.assertTrue(drvr.capabilities['supports_ephemeral_encryption'], ""Driver capabilities for ' "" ""'supports_ephemeral_encryption' "" ""is invalid"")",25,20
openstack%2Fswift~master~I22cc32b701237ed3f69328e44e6eb7a3a0d094d3,openstack/swift,master,I22cc32b701237ed3f69328e44e6eb7a3a0d094d3,proxy: Use last-primaries table,NEW,2022-09-14 18:45:24.000000000,2022-11-11 01:15:31.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-09-14 18:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2b083ec8e5c411c6fe67430c63a5a168ef442949', 'message': 'proxy: Use last-primaries table\n\nChange-Id: I22cc32b701237ed3f69328e44e6eb7a3a0d094d3\n'}, {'number': 2, 'created': '2022-09-14 20:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8f94907c2cd6c35daf58235a9283d69192e03cc7', 'message': 'proxy: Use last-primaries table\n\nChange-Id: I22cc32b701237ed3f69328e44e6eb7a3a0d094d3\n'}, {'number': 3, 'created': '2022-09-26 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2f9a6b639de8f381e853e55a5141f5bb29521883', 'message': 'proxy: Use last-primaries table\n\nChange-Id: I22cc32b701237ed3f69328e44e6eb7a3a0d094d3\n'}, {'number': 4, 'created': '2022-11-11 00:00:32.000000000', 'files': ['test/unit/__init__.py', 'swift/proxy/controllers/account.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/4166a618ef601a8c84f5899ba5422437daf35cc6', 'message': 'proxy: Use last-primaries table\n\nChange-Id: I22cc32b701237ed3f69328e44e6eb7a3a0d094d3\n'}]",1,857758,4166a618ef601a8c84f5899ba5422437daf35cc6,12,1,4,15343,,,0,"proxy: Use last-primaries table

Change-Id: I22cc32b701237ed3f69328e44e6eb7a3a0d094d3
",git fetch https://review.opendev.org/openstack/swift refs/changes/58/857758/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/__init__.py', 'swift/proxy/controllers/account.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/controllers/container.py', 'swift/proxy/server.py', 'swift/proxy/controllers/base.py']",6,2b083ec8e5c411c6fe67430c63a5a168ef442949,ring-v2," policy=None, for_read=False): part_nodes, ring.get_more_nodes(partition, for_read=for_read)) node_iterator or self.app.iter_nodes( ring, part, self.logger, for_read=req.method in ('GET', 'HEAD'), )"," policy=None): part_nodes, ring.get_more_nodes(partition)) node_iterator or self.app.iter_nodes(ring, part, self.logger)",17,12
openstack%2Ftripleo-heat-templates~master~Ia2337e2f1802257f172ecf9e88995cd12ebc31d7,openstack/tripleo-heat-templates,master,Ia2337e2f1802257f172ecf9e88995cd12ebc31d7,Support setting ovn-ofctrl-wait-before-clear,MERGED,2022-11-01 18:03:20.000000000,2022-11-11 00:01:40.000000000,2022-11-11 00:01:40.000000000,"[{'_account_id': 6796}, {'_account_id': 8655}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-11-01 18:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/169c062ffd6a82163dbfe5a36f5ed1869ba940c8', 'message': 'Support setting ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nCo-Authored-By: David Hill <davidchill@hotmail.com>\nDepends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170\nChange-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7\n'}, {'number': 2, 'created': '2022-11-02 21:49:34.000000000', 'files': ['deployment/ovn/ovn-controller-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ddaa270bd160f9cc7d8689a2470636eb25c14cb4', 'message': 'Support setting ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nCo-Authored-By: David Hill <davidchill@hotmail.com>\nDepends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170\nChange-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7\n'}]",1,863171,ddaa270bd160f9cc7d8689a2470636eb25c14cb4,19,7,2,5756,,,0,"Support setting ovn-ofctrl-wait-before-clear

Support was added for this option [1] to avoid dataplane downtime
during ovn upgrades where schema changes have happened. This
adds the ability for us to configure it.

[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/

Co-Authored-By: David Hill <davidchill@hotmail.com>
Depends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170
Change-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/71/863171/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-controller-container-puppet.yaml'],1,169c062ffd6a82163dbfe5a36f5ed1869ba940c8,ovn-ofctrl-wait-before-clear, OVNOfctrlWaitBeforeClear: description: > Sets the time ovn-controller will wait on startup before clearing all openflow rules and installing the new ones. type: number default: 8000 ovn::controller::ovn_ofctrl_wait_before_clear: {get_param: OVNOfctrlWaitBeforeClear},,7,0
openstack%2Fansible-collections-openstack~master~I33fa4b3a08392feac702f45a2c47f8b04799ac0b,openstack/ansible-collections-openstack,master,I33fa4b3a08392feac702f45a2c47f8b04799ac0b,"Split project_access into {compute_flavor,volume_type}_access modules",MERGED,2022-11-04 19:10:15.000000000,2022-11-10 22:24:42.000000000,2022-11-10 22:24:42.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-04 19:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/694007fe06d6e5971d2910936e842cd97ae87b95', 'message': 'Refactored project_access module\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 2, 'created': '2022-11-05 19:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/327a18a8b14467f40a86c5eb3d2eda082b8963b1', 'message': 'Refactored project_access module\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 3, 'created': '2022-11-07 14:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e81faeb10082628f87d5d0ba3d2f61724216d1bf', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 4, 'created': '2022-11-07 19:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6b514e9cd0cbd0060d8871d296c564265312c561', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 5, 'created': '2022-11-08 09:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/36e2f2c63744f4a11c6974cea1d465cff09800fc', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 6, 'created': '2022-11-08 12:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/83e0a5702d0ee356b47a6db4727bf24a1007ced3', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 7, 'created': '2022-11-08 12:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/50ff1dbb5bfd965bddd2a0451898c9c14c5c420c', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 8, 'created': '2022-11-08 14:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cb7f631cd6e49257001526437bc40489fb3c0125', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 9, 'created': '2022-11-08 19:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6c19990473382a9a749375a1cce04222772d97b8', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 10, 'created': '2022-11-09 13:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3c872c9b92eb45dca4e7f4f9ffa97d6bed52363c', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}, {'number': 11, 'created': '2022-11-10 18:35:57.000000000', 'files': ['meta/runtime.yml', 'ci/roles/volume_type_access/tasks/main.yml', 'plugins/modules/project_access.py', 'plugins/modules/volume_type_access.py', '.zuul.yaml', 'ci/roles/compute_flavor_access/tasks/main.yml', 'plugins/modules/compute_flavor_access.py', 'ci/run-collection.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5862d91615388f27a1be4df1b0790aa8a1fb578d', 'message': 'Split project_access into {compute_flavor,volume_type}_access modules\n\nChange-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b\n'}]",5,863696,5862d91615388f27a1be4df1b0790aa8a1fb578d,38,3,11,32962,,,0,"Split project_access into {compute_flavor,volume_type}_access modules

Change-Id: I33fa4b3a08392feac702f45a2c47f8b04799ac0b
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/96/863696/2 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/project_access.py'],1,694007fe06d6e5971d2910936e842cd97ae87b95,project-access,"# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt) DOCUMENTATION = r'''short_description: Manage OpenStack access - Add or remove access to compute flavor or block-storage volume type. options: project: description: - ID or Name of project to grant. required: true type: str aliases: ['target_project_id'] resource_type: description: - The resource type required: true type: str choices: [nova_flavor, flavor, cinder_volume_type, volume_type] resource_name: description: - Name or The resource name (eg. tiny). required: true type: str choices: ['present', 'absent'] EXAMPLES = r'''RETURN = r''' resource_type=dict(required=True, choices=['nova_flavor', 'flavor', 'cinder_volume_type', 'volume_type']), changed=changed_access, resource=resource) changed=True, resource=resource)","# This module is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation, either version 3 of the License, or # (at your option) any later version. # # This software is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this software. If not, see <http://www.gnu.org/licenses/>. DOCUMENTATION = '''short_description: Manage OpenStack compute flavors access - Add or remove flavor, volume_type or other resources access from OpenStack. options: choices: ['present', 'absent'] required: false target_project_id: description: - Project id. required: true type: str resource_type: description: - The resource type (eg. nova_flavor, cinder_volume_type). required: true type: str resource_name: description: - The resource name (eg. tiny). required: true type: strEXAMPLES = '''RETURN = ''' resource_type=dict(required=True), changed=changed_access, resource=resource, id=resource_id) changed=True, resource=resource, id=resource_id)",32,39
openstack%2Fnova~master~Ib88de4f3d6dbf4a850bc76e43e3714e1de395c95,openstack/nova,master,Ib88de4f3d6dbf4a850bc76e43e3714e1de395c95,[DMN] test removal of CAP_DAC_OVERRIDE,NEW,2021-09-24 13:21:57.000000000,2022-11-10 21:44:22.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-09-24 13:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/948281d4c2e862ab6b32e3c51669471c3acd9029', 'message': '[DMN] test removal of CAP_DAC_OVERRIDE\n\nChange-Id: Ib88de4f3d6dbf4a850bc76e43e3714e1de395c95\n'}, {'number': 2, 'created': '2022-11-10 18:25:29.000000000', 'files': ['nova/privsep/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dc251be64c052e5faf74cd6cf20153116de7c22f', 'message': '[DMN] test removal of CAP_DAC_OVERRIDE\n\nChange-Id: Ib88de4f3d6dbf4a850bc76e43e3714e1de395c95\n'}]",0,810906,dc251be64c052e5faf74cd6cf20153116de7c22f,24,1,2,11604,,,0,"[DMN] test removal of CAP_DAC_OVERRIDE

Change-Id: Ib88de4f3d6dbf4a850bc76e43e3714e1de395c95
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/810906/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/privsep/__init__.py'],1,948281d4c2e862ab6b32e3c51669471c3acd9029,privsep," # capabilities.CAP_DAC_OVERRIDE,"," capabilities.CAP_DAC_OVERRIDE,",1,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I3c24f6c0b1877caca225d532e2c40cabe9095577,openstack/tripleo-heat-templates,stable/train,I3c24f6c0b1877caca225d532e2c40cabe9095577,Replace dnf by tripleo_dnf_stream for undercloud upgrade,MERGED,2022-10-26 13:07:46.000000000,2022-11-10 20:35:34.000000000,2022-11-10 20:35:34.000000000,"[{'_account_id': 6816}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}, {'_account_id': 31245}]","[{'number': 1, 'created': '2022-10-26 13:07:46.000000000', 'files': ['deployment/undercloud/undercloud-upgrade.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/49511b3be080e6d522fdd11eeba4aa552da25cb5', 'message': ""Replace dnf by tripleo_dnf_stream for undercloud upgrade\n\nDnf Ansible module doesn't only enable the stream, but\nsynchronizes the whole content. Dnf module installs\npackages which were not installed before the undercloud upgrade.\nAs a result some packages are installed in step0, and not as it\nshould be done in step3.\n\nThis patch replaces the dnf Ansible module by a custom tripleo\nmodule, tripleo_dnf_stream, which will only enable the stream\n(if the stream wasn't enabled).\n\nThis is the same change that was made for minor update workflow,\nbut for undercloud upgrade. [1]\n\n[1]https://review.opendev.org/#/q/I3fa4ccc224cf510bcc85a9c86a2b4f0d367c687f\n\nChange-Id: I3c24f6c0b1877caca225d532e2c40cabe9095577\n(cherry picked from commit 4939e19eebb7ea26462f8eb4b0e1b581adf9f3f3)\n""}]",0,862688,49511b3be080e6d522fdd11eeba4aa552da25cb5,10,8,1,33080,,,0,"Replace dnf by tripleo_dnf_stream for undercloud upgrade

Dnf Ansible module doesn't only enable the stream, but
synchronizes the whole content. Dnf module installs
packages which were not installed before the undercloud upgrade.
As a result some packages are installed in step0, and not as it
should be done in step3.

This patch replaces the dnf Ansible module by a custom tripleo
module, tripleo_dnf_stream, which will only enable the stream
(if the stream wasn't enabled).

This is the same change that was made for minor update workflow,
but for undercloud upgrade. [1]

[1]https://review.opendev.org/#/q/I3fa4ccc224cf510bcc85a9c86a2b4f0d367c687f

Change-Id: I3c24f6c0b1877caca225d532e2c40cabe9095577
(cherry picked from commit 4939e19eebb7ea26462f8eb4b0e1b581adf9f3f3)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/88/862688/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/undercloud/undercloud-upgrade.yaml'],1,49511b3be080e6d522fdd11eeba4aa552da25cb5,tripleo_dnf_stream," - name: Ensure DNF modules have the right stream enabled tripleo_dnf_stream: name: ""{{ item.module }}:{{ item.stream }}"" state: enabled"," - name: Ensure DNF modules have the right stream dnf: name: ""@{{ item.module }}:{{ item.stream }}/{{ item.profile|default('common') }}"" state: present",4,4
openstack%2Fpython-manilaclient~master~I73cde764b0c13e924776652ce4ff3c5b14decd71,openstack/python-manilaclient,master,I73cde764b0c13e924776652ce4ff3c5b14decd71,On branch bug/#1967312  Changes to be committed: Missing param check in list command,NEW,2022-11-04 14:14:04.000000000,2022-11-10 20:26:47.000000000,,"[{'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-11-04 14:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/0bc1a748dcd06c42fd3bf81940a54d718daf9570', 'message': ' On branch bug/#1967312\n Changes to be committed:\n\tmodified:   manilaclient/v2/shares.py\n\nChange-Id: I73cde764b0c13e924776652ce4ff3c5b14decd71\n'}, {'number': 2, 'created': '2022-11-10 19:14:28.000000000', 'files': ['manilaclient/v2/shares.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/1081e79dcf1eceb451c952d978a1b00f79745a36', 'message': ' On branch bug/#1967312\n Changes to be committed:\nMissing param check in list command\n\nIn the list implementation for API version 2.35 to 2.68\nwe are not sanitizing the search_opts param.\n\nERROR: If this param is not set (which is the default value)\nthis leads to ""AttributeError: \'NoneType\' object has no\nattribute \'pop\'""\n\nworkaround this problem by chenging search_opts from none to\ndictionary\n\nCloses-Bug: #1967312\n\nChange-Id: I73cde764b0c13e924776652ce4ff3c5b14decd71\n'}]",2,863652,1081e79dcf1eceb451c952d978a1b00f79745a36,5,2,2,35445,,,0," On branch bug/#1967312
 Changes to be committed:
Missing param check in list command

In the list implementation for API version 2.35 to 2.68
we are not sanitizing the search_opts param.

ERROR: If this param is not set (which is the default value)
this leads to ""AttributeError: 'NoneType' object has no
attribute 'pop'""

workaround this problem by chenging search_opts from none to
dictionary

Closes-Bug: #1967312

Change-Id: I73cde764b0c13e924776652ce4ff3c5b14decd71
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/52/863652/2 && git format-patch -1 --stdout FETCH_HEAD,['manilaclient/v2/shares.py'],1,0bc1a748dcd06c42fd3bf81940a54d718daf9570,bug/#1967312," def list(self, detailed=True, search_opts={}, # noqa"," def list(self, detailed=True, search_opts=None, # noqa",1,1
openstack%2Fpython-openstackclient~master~Ie19a24ead100dd9177669653a7a9997772ef4538,openstack/python-openstackclient,master,Ie19a24ead100dd9177669653a7a9997772ef4538,Docstring fix for CreateVolumeAttachment class,MERGED,2022-11-10 16:51:35.000000000,2022-11-10 19:41:54.000000000,2022-11-10 19:40:46.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-10 16:51:35.000000000', 'files': ['openstackclient/volume/v3/volume_attachment.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/348eb796321c8475af73b727a310c3a09f519ffa', 'message': 'Docstring fix for CreateVolumeAttachment class\n\nThe command ""volume attachment create"" has a typo in the docstring.\nThe docstring says to use ""server add volume"", but the command is\nactually ""server volume add"". This\nchange fixes the typo in the docstring.\n\nTask: 46781\nStory: 2010401\nChange-Id: Ie19a24ead100dd9177669653a7a9997772ef4538\n'}]",0,864218,348eb796321c8475af73b727a310c3a09f519ffa,7,2,1,31203,,,0,"Docstring fix for CreateVolumeAttachment class

The command ""volume attachment create"" has a typo in the docstring.
The docstring says to use ""server add volume"", but the command is
actually ""server volume add"". This
change fixes the typo in the docstring.

Task: 46781
Story: 2010401
Change-Id: Ie19a24ead100dd9177669653a7a9997772ef4538
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/18/864218/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/volume/v3/volume_attachment.py'],1,348eb796321c8475af73b727a310c3a09f519ffa,storyboard-task-46781-CreateVolumeAttachment-docstring-fix, add volume' command should be preferred., volume add' command should be preferred.,1,1
openstack%2Fpuppet-glance~stable%2Fxena~I2477d5e271b017ee12546c67f4c3f3f9be89c062,openstack/puppet-glance,stable/xena,I2477d5e271b017ee12546c67f4c3f3f9be89c062,Ensure [DEFAULT] show_multiple_locations is cleared,MERGED,2022-11-10 16:53:11.000000000,2022-11-10 19:16:46.000000000,2022-11-10 19:16:46.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-10 16:53:11.000000000', 'files': ['manifests/api.pp', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/af0063b34c8d4041e9690d658ea9f0db2e07aca0', 'message': 'Ensure [DEFAULT] show_multiple_locations is cleared\n\nThe parameter was already deprecated, but it is still required in\nsome setup (eg. to leverage in-storage copy in a deployment with Ceph\nused for cinder/glance).\n\nConsidering the parameter is still valid, this change ensures it is\nremoved by default, so that old value is properly removed from config\nfile.\n\nChange-Id: I2477d5e271b017ee12546c67f4c3f3f9be89c062\n(cherry picked from commit 5d977c750acf5276ce7fb7772436e9e74c2be001)\n(cherry picked from commit 8e7a4c46dd474b5bee8ba1b5fb1e62f5b6bf4e5e)\n'}]",0,864176,af0063b34c8d4041e9690d658ea9f0db2e07aca0,6,2,1,21129,,,0,"Ensure [DEFAULT] show_multiple_locations is cleared

The parameter was already deprecated, but it is still required in
some setup (eg. to leverage in-storage copy in a deployment with Ceph
used for cinder/glance).

Considering the parameter is still valid, this change ensures it is
removed by default, so that old value is properly removed from config
file.

Change-Id: I2477d5e271b017ee12546c67f4c3f3f9be89c062
(cherry picked from commit 5d977c750acf5276ce7fb7772436e9e74c2be001)
(cherry picked from commit 8e7a4c46dd474b5bee8ba1b5fb1e62f5b6bf4e5e)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/76/864176/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/glance_api_spec.rb']",2,af0063b34c8d4041e9690d658ea9f0db2e07aca0,," :show_multiple_locations => '<SERVICE DEFAULT>',",,4,3
openstack%2Frequirements~master~I01f040b33122a99d781cb19cb5a62ac724b4dae7,openstack/requirements,master,I01f040b33122a99d781cb19cb5a62ac724b4dae7,update constraint for stevedore to new release 4.1.1,MERGED,2022-11-10 09:15:43.000000000,2022-11-10 19:14:08.000000000,2022-11-10 19:13:08.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-10 09:15:43.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e30cda8126abcb9df7a49c5c428d461acee9ab29', 'message': 'update constraint for stevedore to new release 4.1.1\n\nmeta: version: 4.1.1\nmeta: diff-start: -\nmeta: series: antelope\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Commit: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I4f113516e2180ff358f181b04d7b1ab6a8e7631b\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I01f040b33122a99d781cb19cb5a62ac724b4dae7\n'}]",0,864191,e30cda8126abcb9df7a49c5c428d461acee9ab29,9,3,1,11131,,,0,"update constraint for stevedore to new release 4.1.1

meta: version: 4.1.1
meta: diff-start: -
meta: series: antelope
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Hervé Beraud <hberaud@redhat.com>
meta: release:Commit: Hervé Beraud <hberaud@redhat.com>
meta: release:Change-Id: I4f113516e2180ff358f181b04d7b1ab6a8e7631b
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I01f040b33122a99d781cb19cb5a62ac724b4dae7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/91/864191/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e30cda8126abcb9df7a49c5c428d461acee9ab29,new-release,stevedore===4.1.1,stevedore===4.1.0,1,1
openstack%2Ftripleo-heat-templates~master~Idf8f02e0630349b724ab1281033dfca590c17333,openstack/tripleo-heat-templates,master,Idf8f02e0630349b724ab1281033dfca590c17333,Test custom cpu_model on nested virt job,ABANDONED,2022-09-12 19:33:47.000000000,2022-11-10 18:46:09.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-09-12 19:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee9955f045639e567cd966c4f92040c8417f77ee', 'message': 'Test custom cpu_model on nested virt job\n\nChange-Id: Idf8f02e0630349b724ab1281033dfca590c17333\n'}, {'number': 2, 'created': '2022-09-13 11:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f342232386de268d5266119f51a7ce7d663db6e', 'message': 'Test custom cpu_model on nested virt job\n\nChange-Id: Idf8f02e0630349b724ab1281033dfca590c17333\n'}, {'number': 3, 'created': '2022-09-13 18:50:04.000000000', 'files': ['ci/environments/octavia-kvm.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9829348424fcc39a3355c3ea9b7cf614a5529ee4', 'message': 'Test custom cpu_model on nested virt job\n\nChange-Id: Idf8f02e0630349b724ab1281033dfca590c17333\n'}]",0,857226,9829348424fcc39a3355c3ea9b7cf614a5529ee4,11,2,3,30002,,,0,"Test custom cpu_model on nested virt job

Change-Id: Idf8f02e0630349b724ab1281033dfca590c17333
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/857226/3 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/octavia-kvm.yaml'],1,ee9955f045639e567cd966c4f92040c8417f77ee,testing_cpu_models, nova::compute::libvirt::cpu_mode: 'custom' nova::compute::libvirt::cpu_models: ['Skylake-Server'], nova::compute::libvirt::cpu_mode: 'host-passthrough',2,1
openstack%2Ftripleo-ci~master~I2cb9504b44e462cb3acf909f3fbe4483e859295e,openstack/tripleo-ci,master,I2cb9504b44e462cb3acf909f3fbe4483e859295e,DNM - Testing standalone-fips jobs,ABANDONED,2022-08-02 00:53:10.000000000,2022-11-10 18:44:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-08-02 00:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d668c38e9dced4b21d8d52bf341882490277a87c', 'message': 'DNM - Testing standalone-fips jobs\n\nChange-Id: I2cb9504b44e462cb3acf909f3fbe4483e859295e\n'}, {'number': 2, 'created': '2022-08-02 16:35:10.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2803d5f2a8776abe9d93bbe712831a35315d48fa', 'message': 'DNM - Testing standalone-fips jobs\n\nChange-Id: I2cb9504b44e462cb3acf909f3fbe4483e859295e\n'}]",0,851777,2803d5f2a8776abe9d93bbe712831a35315d48fa,7,2,2,30002,,,0,"DNM - Testing standalone-fips jobs

Change-Id: I2cb9504b44e462cb3acf909f3fbe4483e859295e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/77/851777/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,d668c38e9dced4b21d8d52bf341882490277a87c,fips_compatibility, - tripleo-ci-centos-9-standalone-fips: &cs9_vars - tripleo-ci-centos-9-scenario001-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario002-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario003-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario004-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario007-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario010-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario010-ovn-provider-standalone-fips: *cs9_vars - tripleo-ci-centos-9-scenario012-standalone-fips: *cs9_vars, - tripleo-ci-centos-9-standalone: &cs9_vars - tripleo-ci-centos-9-scenario001-standalone: &c9_scen1 <<: *c8_scen1 branches: *c9_branches dependencies: - tripleo-ci-centos-9-content-provider - tripleo-ci-centos-9-scenario002-standalone: &c9_scen2 <<: *c9_scen1 files: *scen2_files - tripleo-ci-centos-9-scenario003-standalone: &c9_scen3 <<: *c9_scen1 files: *scen3_files - tripleo-ci-centos-9-scenario004-standalone: &c9_scen4 <<: *c9_scen1 files: *scen4_files - tripleo-ci-centos-9-scenario007-standalone: &c9_scen7 <<: *c9_scen1 files: *scen7_files - tripleo-ci-centos-9-scenario010-standalone: &c9_scen10 <<: *c9_scen1 files: *scen10_files - tripleo-ci-centos-9-scenario010-ovn-provider-standalone: *c9_scen10 - tripleo-ci-centos-9-scenario012-standalone: &c9_scen12 <<: *c9_scen1 files: *scen12_files - tripleo-ci-centos-9-standalone-fips: <<: *cs9_vars voting: false # CentOS 9 jobs - tripleo-ci-centos-9-standalone: *cs9_vars - tripleo-ci-centos-9-scenario001-standalone: *c9_scen1 - tripleo-ci-centos-9-scenario002-standalone: *c9_scen2 - tripleo-ci-centos-9-scenario003-standalone: *c9_scen3 - tripleo-ci-centos-9-scenario004-standalone: *c9_scen4 - tripleo-ci-centos-9-scenario007-standalone: *c9_scen7 - tripleo-ci-centos-9-scenario010-standalone: *c9_scen10 - tripleo-ci-centos-9-scenario010-ovn-provider-standalone: *c9_scen10 - tripleo-ci-centos-9-scenario012-standalone: *c9_scen12,9,38
openstack%2Ftripleo-quickstart-extras~master~Ic921f8658c96812aad0f4e8d439821388de5a37f,openstack/tripleo-quickstart-extras,master,Ic921f8658c96812aad0f4e8d439821388de5a37f,[DNM] Adds a retry when installing packaged for freeipa,ABANDONED,2022-08-23 12:28:34.000000000,2022-11-10 18:43:37.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-08-23 12:28:34.000000000', 'files': ['roles/freeipa-setup/templates/ipa_prep.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f5797fd208ce0af2e9be400f8b027fb7329a1044', 'message': '[DNM] Adds a retry when installing packaged for freeipa\n\nTesting if a retry mitigate mirrors failure\n\nChange-Id: Ic921f8658c96812aad0f4e8d439821388de5a37f\n'}]",0,854180,f5797fd208ce0af2e9be400f8b027fb7329a1044,7,2,1,30002,,,0,"[DNM] Adds a retry when installing packaged for freeipa

Testing if a retry mitigate mirrors failure

Change-Id: Ic921f8658c96812aad0f4e8d439821388de5a37f
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/80/854180/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/freeipa-setup/templates/ipa_prep.sh.j2'],1,f5797fd208ce0af2e9be400f8b027fb7329a1044,,"function retry_command() { n=0 retries=$1 sleep_time=$2 command=$3 until [ ""$n"" -ge $retries ] do $command && break n=$((n+1)) sleep $sleep_time done } #sudo {{ ansible_pkg_mgr }} install -yq ansible-core ansible-tripleo-ipa retry_command 5 10 ""sudo dnf install -yq ansible-core ansible-tripleo-ipa""",sudo {{ ansible_pkg_mgr }} install -yq ansible-core ansible-tripleo-ipa,16,1
openstack%2Ftripleo-quickstart-extras~master~Icd168002f69130d54611d8e78faf180a5cffbd21,openstack/tripleo-quickstart-extras,master,Icd168002f69130d54611d8e78faf180a5cffbd21,DNM - Testing get latest ceph stable tag,ABANDONED,2022-04-05 15:13:17.000000000,2022-11-10 18:43:21.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-04-05 15:13:17.000000000', 'files': ['roles/set-ceph-latest-tag/README.md', 'roles/standalone/tasks/containers.yml', 'roles/set-ceph-latest-tag/defaults/main.yml', 'roles/set-ceph-latest-tag/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/785228819bbe42c3bac4827f3416358b44fa4ae5', 'message': 'DNM - Testing get latest ceph stable tag\n\nChange-Id: Icd168002f69130d54611d8e78faf180a5cffbd21\n'}]",0,836666,785228819bbe42c3bac4827f3416358b44fa4ae5,6,2,1,30002,,,0,"DNM - Testing get latest ceph stable tag

Change-Id: Icd168002f69130d54611d8e78faf180a5cffbd21
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/66/836666/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/set-ceph-latest-tag/README.md', 'roles/standalone/tasks/containers.yml', 'roles/set-ceph-latest-tag/defaults/main.yml', 'roles/set-ceph-latest-tag/tasks/main.yml']",4,785228819bbe42c3bac4827f3416358b44fa4ae5,ceph_latest_stable,"--- - name: Install skopeo and jq become: true package: name: - skopeo - jq state: present # NOTE: The latest tag is based on the last entry after sorting - name: Get latest tags using skopeo shell: >- skopeo list-tags docker://""{{ ceph_latest_tag_namespace }}/{{ ceph_latest_tag_image }}"" | jq -r '[.Tags[] | select(.|test(""{{ ceph_latest_tag_search_regex }}"")?)]|sort|last' retries: 3 register: result until: result is success - name: Set Ceph latest tag set_fact: docker_ceph_tag: ""{{ result.stdout }}"" ",,53,0
openstack%2Fmanila~master~I60d0f722c0841832c60166a6fe3f51aed6d20c61,openstack/manila,master,I60d0f722c0841832c60166a6fe3f51aed6d20c61,DNM - Testing experimental jobs,ABANDONED,2022-04-06 12:56:31.000000000,2022-11-10 18:43:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 30002}]","[{'number': 1, 'created': '2022-04-06 12:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2220ae9dd33a31c3f6325a3712f933fe2a9bd8b5', 'message': 'DNM - Testing experimental jobs\n\nChange-Id: I60d0f722c0841832c60166a6fe3f51aed6d20c61\n'}, {'number': 2, 'created': '2022-04-06 12:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/98ebb6dc88801bce90b585b79dc0e9f0982528ae', 'message': 'DNM - Testing experimental jobs\n\nChange-Id: I60d0f722c0841832c60166a6fe3f51aed6d20c61\n'}, {'number': 3, 'created': '2022-04-07 12:25:12.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/12ac96d7800c64c0eb312561ca80d92aa9061b02', 'message': 'DNM - Testing experimental jobs\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ci/+/836803\n\nChange-Id: I60d0f722c0841832c60166a6fe3f51aed6d20c61\n'}]",3,836823,12ac96d7800c64c0eb312561ca80d92aa9061b02,23,2,3,30002,,,0,"DNM - Testing experimental jobs

Depends-On: https://review.opendev.org/c/openstack/tripleo-ci/+/836803

Change-Id: I60d0f722c0841832c60166a6fe3f51aed6d20c61
",git fetch https://review.opendev.org/openstack/manila refs/changes/23/836823/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,2220ae9dd33a31c3f6325a3712f933fe2a9bd8b5,dnm_test_exp, - tripleo-ci-centos-9-scenario004-standalone,,1,0
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~I60bfa878eeaa9c7c0aab4be7220235cd84ce533a,openstack/tripleo-heat-templates,stable/wallaby,I60bfa878eeaa9c7c0aab4be7220235cd84ce533a,DNM - Testing FIPS - stable/wallaby,ABANDONED,2022-05-12 01:08:07.000000000,2022-11-10 18:43:00.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-05-12 01:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a0189b8c1bddc1f396721e29defbc99f1295749', 'message': 'DNM - Testing update prometheus registry\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/841512\nChange-Id: I60bfa878eeaa9c7c0aab4be7220235cd84ce533a\n'}, {'number': 2, 'created': '2022-05-26 17:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f8c23f981994aaf0891a9016a110f0c909770bc0', 'message': 'DNM - Testing ceph daemon registry update\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/843508\nChange-Id: I60bfa878eeaa9c7c0aab4be7220235cd84ce533a\n'}, {'number': 3, 'created': '2022-05-30 16:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7faf762e88c0010250c118c4581fe1872c15a2b6', 'message': 'DNM - Testing ceph daemon registry update - stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/843936\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/843662\n\nChange-Id: I60bfa878eeaa9c7c0aab4be7220235cd84ce533a\n'}, {'number': 4, 'created': '2022-06-01 17:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ab352a81e876266430742a191c0d24074515563b', 'message': 'DNM - Testing FIPS - stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ci/+/824479\n\nChange-Id: I60bfa878eeaa9c7c0aab4be7220235cd84ce533a\n'}, {'number': 5, 'created': '2022-06-01 18:07:45.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/668e1885b9ab9f1c513c982c36e5642d3dcc2039', 'message': 'DNM - Testing FIPS - stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ci/+/824479\n\nChange-Id: I60bfa878eeaa9c7c0aab4be7220235cd84ce533a\n'}]",2,841513,668e1885b9ab9f1c513c982c36e5642d3dcc2039,21,2,5,30002,,,0,"DNM - Testing FIPS - stable/wallaby

Depends-On: https://review.opendev.org/c/openstack/tripleo-ci/+/824479

Change-Id: I60bfa878eeaa9c7c0aab4be7220235cd84ce533a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/13/841513/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario004-standalone.yaml', 'ci/environments/scenario001-standalone.yaml']",2,5a0189b8c1bddc1f396721e29defbc99f1295749,fips-compatibility,# DNM - testing,,2,0
openstack%2Fopenstack-helm~master~I3ee56658a8ddcb95056f2893c4c5cce0ccc18804,openstack/openstack-helm,master,I3ee56658a8ddcb95056f2893c4c5cce0ccc18804,add monasca,MERGED,2021-01-19 14:16:40.000000000,2022-11-10 18:13:38.000000000,2022-11-10 18:11:55.000000000,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 30449}]","[{'number': 1, 'created': '2021-01-19 14:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d8e2fc1b5636d773a31551c86948769f757c5dfd', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 2, 'created': '2021-01-19 19:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d4695faee2bace01c6d7da2f0d5b807255690c6a', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 3, 'created': '2021-01-19 20:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/57684aee205495d8563a5b1622211288b8ae5639', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 4, 'created': '2021-01-20 13:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/44d3dea3594ac4d86ff82dc03319a6c952fd8a64', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 5, 'created': '2021-01-20 14:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0992fb13280fe41e1f4cff29a5cb36db7ea92b0b', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 6, 'created': '2021-02-05 16:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8759669b865004317be2aa698f91260f1272e015', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 7, 'created': '2021-05-31 18:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/84c8bcff166588aefc61cc747306a539e0fc1aa1', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 8, 'created': '2021-06-03 14:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d7f0d154904cc1ac5ee68150145ceeb3422113c8', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 9, 'created': '2021-06-03 14:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b047fb0fc2bce0ba50f10e2f15fe7d66ea68a572', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 10, 'created': '2021-06-03 18:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/eaa07a65ca3e06c93220fa04db8222667843efb2', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 11, 'created': '2021-06-03 19:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/066d68f06c26b3db937b55992efa23264eee9e79', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 12, 'created': '2021-06-07 15:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a1eca2e4e59fd2914659de2b698b1883f04db6b2', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 13, 'created': '2021-06-07 16:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/02d3c2af79dd5291286b50c52983948be8c5c8c0', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 14, 'created': '2021-06-07 16:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fc5da8685a0c290efdfcbbf08bde8f67c187dbc2', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 15, 'created': '2021-06-08 12:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4fd96f3134b45032a39716052663f75d7d489e0a', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 16, 'created': '2021-06-22 12:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/44e2204453e127dbefeb7687e317788f1e06de1c', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 17, 'created': '2021-06-22 17:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6dfba61acf9e7f6bd5cc7b2cb777c7ff93dee897', 'message': 'add monasca-api\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 18, 'created': '2021-06-22 18:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/427a4c8282e71d5624ac43b1772c233b54752077', 'message': 'add monasca-api(WIP)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 19, 'created': '2021-06-24 17:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5adcf6a48f0824fbb90d39bd74ec84892e6e5196', 'message': 'add monasca-api(WIP)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 20, 'created': '2021-06-25 14:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8f88de50e7c1e11c900c1fb06785ee5aa4cadbfe', 'message': 'add monasca-api(WIP)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 21, 'created': '2021-06-30 17:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4989621b937271181f57705c616c535ba8dbef9d', 'message': 'add monasca-api(WIP)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 22, 'created': '2021-06-30 18:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b7ef0bd83e95ab15c3cd69c4983f8e9770d0fadc', 'message': 'add monasca(WIP)\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 23, 'created': '2021-07-08 15:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/dd3cf9ec9eec4de3183b6e7304c558284b1e6ab7', 'message': 'add monasca(WIP)\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 24, 'created': '2021-07-12 14:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/64f5e2cbfb113ba2fe70f10468c44fd696e48d09', 'message': 'add monasca(WIP)\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 25, 'created': '2021-07-12 18:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/336d673d7112160b40420df8b0c0caa0491dfb22', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 26, 'created': '2021-07-12 18:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a9f2a2d52e13fc86fdad6f3dbe928419bb1b7fea', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 27, 'created': '2021-07-13 16:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7d8a493cb2e6239b211feab4800cdada6cd5089e', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 28, 'created': '2021-07-13 17:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bd23efed5eaa641d99af1ac9bda2e829eb9de919', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 29, 'created': '2021-07-13 18:18:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ca1cb352ec3a3b13e7f26614601faaa2801f7eef', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 30, 'created': '2021-07-13 19:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8990fa672f15328f916e19f4129f20fc26fd96f7', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 31, 'created': '2021-07-14 14:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/48a56a1b3d705b2b0eeb7eb2d160accd5bb31f8d', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 32, 'created': '2021-07-14 15:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/89fe5426fbe9c68bf196c6eafb8643e0b48b8cf9', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 33, 'created': '2021-07-14 18:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0bc29f9aab96e2f946eb72c0bd99796664f4abd5', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 34, 'created': '2021-07-15 15:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/10b8f93d02a4c656dfc7d90f38bdaf381e51bde3', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 35, 'created': '2021-07-15 19:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/167e3a2a9687fc8c63bfaa3ca4614a0f0f3e5840', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 36, 'created': '2021-07-16 09:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/16b07d54c867ca00427cc07cfed2ab657c501a12', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 37, 'created': '2021-07-20 15:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0da67b650ccbb670120a2994d99c66902f146f1f', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 38, 'created': '2021-07-21 17:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2ba63d973f51dca14f47937bb0767fcbb3c593c5', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 39, 'created': '2021-07-26 18:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/38a753c62d6ac322b7639d519683386874c18756', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 40, 'created': '2021-07-28 07:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6ddbf492a2bce462e9309557d818a46590e742f4', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 41, 'created': '2021-07-28 07:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1bb35b2cae6217a0ed44027498d6e699c1e408d3', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 42, 'created': '2021-07-28 08:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/30e8675055c3898db5c61d70c1ae3e87f7f31a07', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 43, 'created': '2021-07-28 08:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1a66704dd25c659f20c268edda3fab50a7794cd5', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 44, 'created': '2021-07-28 09:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5c58f64d5d8047a0ca55b982369e9905169100fc', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 45, 'created': '2021-07-28 11:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ad02cfdd78771e200b31a8ad8903f91f09f6f30a', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 46, 'created': '2021-07-28 19:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c440f0e335e189bffccca97b58dbc63ec41d57cb', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 47, 'created': '2021-08-05 17:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3c846b267f474a02730468b1394ecf7751cb3014', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 48, 'created': '2021-08-05 19:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e5447b0e221d39e22e439a3581c252f003239dc7', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 49, 'created': '2021-08-20 13:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1a3b8025b46ea6b446b85f0bfa6c9eb67bab2f0b', 'message': 'add monasca(WIP)\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 50, 'created': '2021-08-20 14:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a9433c172ac84819ecc54cb0cd1f1b309b2c8823', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 51, 'created': '2021-09-17 14:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/03d7a69ba3486a8f930a88be93c19139e9f2dd92', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 52, 'created': '2021-09-20 15:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9cf314a72f1f447cb8b6735ea3e54e4db38a07f3', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 53, 'created': '2021-09-20 16:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0c51c55c518cb8e399bea0a12801d818a74c5c51', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 54, 'created': '2021-09-20 16:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/447765744b28c7772d51b672ff59ba56db66ffd4', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 55, 'created': '2021-09-20 18:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f419108ab86dbce156bb958e65e7e5d08bb66ae3', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 56, 'created': '2021-09-20 18:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d69e7b6573b4b9beb83c440c8757ef9ec1454a42', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 57, 'created': '2021-09-22 11:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/60663827c1726da948f7f1aff93ee72f107fbbcd', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 58, 'created': '2021-09-22 12:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2f177dd3494c5868371d75df19b97a081d9bd1de', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 59, 'created': '2021-09-23 13:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8ef297f73e1695a95a5d84b301bd7fcdc8642a77', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 60, 'created': '2021-09-24 09:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fcb51f7b149aaa88d147c17ec9f3da985e41a351', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 61, 'created': '2021-09-24 09:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/682c93cc662ecfe165f69dd74162d2bd1e159694', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 62, 'created': '2021-09-24 10:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5d2f4348de9473a5c60f71aca34517521f3229a6', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 63, 'created': '2021-09-24 10:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c3e008a4b86cb5c6afc316d85998121f1aa619b1', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 64, 'created': '2021-09-24 13:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b994ffdfd5801a02138cbe85fd75e545e6577d9b', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 65, 'created': '2021-09-28 16:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ad775f5852af2366d96274f26087ecc89ba3013f', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 66, 'created': '2021-09-28 17:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/765c49f4946c77665de37b6792b644040f465b44', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 67, 'created': '2021-09-28 18:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8db9b5b39336656472ea4201cde7063ed54781b1', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 68, 'created': '2021-10-04 15:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/072442a0d13f9bc0cc468e684d40026866c5275e', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 69, 'created': '2021-10-08 08:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a12bfb6b49946345cefa7cd38cc2bd6b46fdba61', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 70, 'created': '2021-10-08 08:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6a1fc148e515f27cc558d58c52ed0a4cb6ed9d53', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 71, 'created': '2021-10-11 12:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9e59cbce6aa259c4825aee80d5c20891e4092b73', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 72, 'created': '2021-10-11 12:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d75aaf853fcc958fe2b0fe57cab2719ca8931467', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 73, 'created': '2021-10-11 13:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c7bbed3ecd4c4237707f7e392fe3be46cf7f75ae', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 74, 'created': '2021-10-11 16:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/777a24ea6bba11ed33aee00333cd5179a9fa6d4f', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 75, 'created': '2021-10-11 16:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/dfa6a7d3426e258ceab41875f23ddcb04727e7ab', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 76, 'created': '2021-10-11 16:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6113604960325cbd859e99d1a31acd16a85e1d8f', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 77, 'created': '2021-10-21 14:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b1f35ad797b3c25bbe671c0aacd4f31119a5cabf', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 78, 'created': '2021-11-01 09:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/14eb4e447a469fe63c40bc75ff483a01281331cc', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}, {'number': 79, 'created': '2021-11-11 14:25:13.000000000', 'files': ['monasca/templates/bin/_db-sync.sh.tpl', 'monasca/templates/job-image-repo-sync.yaml', 'monasca/values.yaml', 'monasca/templates/bin/_monasca-statsd.sh.tpl', 'monasca/values_overrides/nvidia.yaml', 'monasca/templates/job-influxdb-init.yaml', 'monasca/templates/secret-db.yaml', 'monasca/templates/bin/_monasca-persister.sh.tpl', 'monasca/templates/configmap-etc.yaml', 'monasca/values_overrides/libvirt.yaml', 'monasca/templates/daemonset-agent.yaml', 'monasca/templates/deployment-notification.yaml', 'monasca/templates/configmap-plugins-check.yaml', 'monasca/templates/configmap-plugins-detection.yaml', 'monasca/templates/bin/_monasca-agent-init.sh.tpl', 'monasca/templates/bin/_monasca-thresh.sh.tpl', 'monasca/templates/job-ks-api-service.yaml', 'monasca/templates/secret-influxdb-secret.yaml', 'monasca/Chart.yaml', 'monasca/templates/bin/_monasca-forwarder.sh.tpl', 'monasca/templates/bin/_influxdb-init.sh.tpl', 'monasca/templates/job-ks-api-endpoints.yaml', 'monasca/templates/configmap-bin.yaml', 'monasca/templates/secret-keystone.yaml', 'monasca/templates/bin/_bootstrap.sh.tpl', 'monasca/templates/deployment-persister.yaml', 'monasca/requirements.yaml', 'monasca/templates/ingress-api.yaml', 'monasca/templates/secret-ingress-tls.yaml', 'monasca/templates/service-ingress.yaml', 'monasca/templates/deployment-agent.yaml', 'monasca/templates/network_policy.yaml', 'monasca/templates/job-bootstrap.yaml', 'monasca/.helmignore', 'monasca/templates/job-db-drop.yaml', 'monasca/templates/job-db-init.yaml', 'monasca/templates/configmap-plugins-etc.yaml', 'monasca/templates/bin/_monasca-collector.sh.tpl', 'monasca/templates/job-db-sync.yaml', 'monasca/templates/service.yaml', 'monasca/templates/job-thresh-upload.yaml', 'releasenotes/notes/monasca.yaml', 'monasca/templates/bin/_monasca-api.sh.tpl', 'monasca/templates/deployment-api.yaml', 'monasca/templates/job-rabbit-init.yaml', 'monasca/templates/bin/_monasca-notification.sh.tpl', 'monasca/templates/job-ks-user.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fb16a11fef84814feb1e365df769ade4ac9f15be', 'message': 'add monasca\n\n- monasca-api\n- monasca-thresh(storm based)\n- monasca-notification\n- monasca-persister\n- monasca-agent(deployment&daemonset)\n- influxdb init\n\nChange-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804\n'}]",22,771465,fb16a11fef84814feb1e365df769ade4ac9f15be,151,4,79,31746,,,0,"add monasca

- monasca-api
- monasca-thresh(storm based)
- monasca-notification
- monasca-persister
- monasca-agent(deployment&daemonset)
- influxdb init

Change-Id: I3ee56658a8ddcb95056f2893c4c5cce0ccc18804
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/65/771465/66 && git format-patch -1 --stdout FETCH_HEAD,"['monasca-api/templates/job-image-repo-sync.yaml', 'monasca-api/templates/ingress-api.yaml', 'monasca-api/templates/configmap-etc.yaml', 'monasca-api/templates/bin/_monasca-api.sh.tpl', 'monasca-api/templates/service-ingress.yaml', 'monasca-api/Chart.yaml', 'monasca-api/templates/job-db-init.yaml', 'monasca-api/templates/secret-ingress-tls.yaml', 'monasca-api/requirements.yaml', 'monasca-api/templates/bin/_monasca-api-init.sh.tpl', 'monasca-api/templates/job-db-drop.yaml', 'monasca-api/templates/configmap-bin.yaml', 'monasca-api/templates/network_policy.yaml', 'monasca-api/templates/service.yaml', 'monasca-api/templates/secret-keystone.yaml', 'monasca-api/values.yaml', 'monasca-api/.helmignore', 'monasca-api/templates/deployment-api.yaml', 'monasca-api/templates/job-db-sync.yaml']",19,d8e2fc1b5636d773a31551c86948769f757c5dfd,,"{{/* Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} {{- if .Values.manifests.job_db_sync }} {{- $envAll := . }} {{- $mounts_monasca_db_sync := .Values.pod.mounts.monasca_db_sync.monasca_db_sync }} {{- $mounts_monasca_db_sync_init := .Values.pod.mounts.monasca_db_sync.init_container }} {{- $serviceAccountName := ""monasca-db-sync"" }} {{ tuple $envAll ""db_sync"" $serviceAccountName | include ""helm-toolkit.snippets.kubernetes_pod_rbac_serviceaccount"" }} --- apiVersion: batch/v1 kind: Job metadata: name: monasca-db-sync annotations: {{ tuple $envAll | include ""helm-toolkit.snippets.release_uuid"" }} spec: template: metadata: labels: {{ tuple $envAll ""monasca"" ""db-sync"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 8 }} annotations: {{ dict ""envAll"" $envAll ""podName"" ""monasca-db-sync"" ""containerNames"" (list ""monasca-db-sync"" ""init"" ) | include ""helm-toolkit.snippets.kubernetes_mandatory_access_control_annotation"" | indent 8 }} spec: serviceAccountName: {{ $serviceAccountName }} {{ dict ""envAll"" $envAll ""application"" ""db_sync"" | include ""helm-toolkit.snippets.kubernetes_pod_security_context"" | indent 6 }} restartPolicy: OnFailure nodeSelector: {{ .Values.labels.job.node_selector_key }}: {{ .Values.labels.job.node_selector_value }} initContainers: {{ tuple $envAll ""db_sync"" $mounts_monasca_db_sync_init | include ""helm-toolkit.snippets.kubernetes_entrypoint_init_container"" | indent 8 }} containers: - name: monasca-db-sync {{ tuple $envAll ""monasca_db_sync"" | include ""helm-toolkit.snippets.image"" | indent 10 }} {{ tuple $envAll $envAll.Values.pod.resources.jobs.db_sync | include ""helm-toolkit.snippets.kubernetes_resources"" | indent 10 }} {{ dict ""envAll"" $envAll ""application"" ""db_sync"" ""container"" ""monasca_db_sync"" | include ""helm-toolkit.snippets.kubernetes_container_security_context"" | indent 10 }} command: - /tmp/db-sync.sh volumeMounts: - name: monasca-etc mountPath: /etc/openstack-dashboard/local_settings subPath: local_settings readOnly: true - name: monasca-bin mountPath: /tmp/db-sync.sh subPath: db-sync.sh readOnly: true - name: monasca-bin mountPath: /tmp/manage.py subPath: manage.py readOnly: true {{- dict ""enabled"" $envAll.Values.manifests.certificates ""name"" $envAll.Values.endpoints.oslo_db.auth.admin.secret.tls.internal ""path"" ""/etc/mysql/certs"" | include ""helm-toolkit.snippets.tls_volume_mount"" | indent 10 }} {{ if $mounts_monasca_db_sync.volumeMounts }}{{ toYaml $mounts_monasca_db_sync.volumeMounts | indent 10 }}{{ end }} volumes: - name: monasca-etc secret: secretName: monasca-etc defaultMode: 0444 - name: monasca-bin configMap: name: monasca-bin defaultMode: 0555 {{- dict ""enabled"" $envAll.Values.manifests.certificates ""name"" $envAll.Values.endpoints.oslo_db.auth.admin.secret.tls.internal | include ""helm-toolkit.snippets.tls_volume"" | indent 6 }} {{ if $mounts_monasca_db_sync.volumes }}{{ toYaml $mounts_monasca_db_sync.volumes | indent 6 }}{{ end }} {{- end }} ",,1175,0
openstack%2Fvitrage~stable%2Fzed~Iee3c332437de989b67f7476fa09e727472ef641a,openstack/vitrage,stable/zed,Iee3c332437de989b67f7476fa09e727472ef641a,Update .gitreview for stable/zed,MERGED,2022-09-20 08:57:36.000000000,2022-11-10 17:53:48.000000000,2022-09-20 11:28:48.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-20 08:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/228360effea75d0391e937c0b966f6dcbea97914', 'message': 'Update .gitreview for stable/zed\n\nChange-Id: Iee3c332437de989b67f7476fa09e727472ef641a\n'}, {'number': 2, 'created': '2022-09-20 10:57:24.000000000', 'files': ['vitrage/storage/impl_sqlalchemy.py', '.gitreview', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/432aec7aa13b43ad34f635e3cc87a3c20011d3f1', 'message': 'Update .gitreview for stable/zed\n\nChange-Id: Iee3c332437de989b67f7476fa09e727472ef641a\n'}]",1,858499,432aec7aa13b43ad34f635e3cc87a3c20011d3f1,11,2,2,22816,,,0,"Update .gitreview for stable/zed

Change-Id: Iee3c332437de989b67f7476fa09e727472ef641a
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/99/858499/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,228360effea75d0391e937c0b966f6dcbea97914,create-zed,defaultbranch=stable/zed,,1,0
openstack%2Floci~master~I267875117d8e4f18eef0bfc21b6122fe37b02dbd,openstack/loci,master,I267875117d8e4f18eef0bfc21b6122fe37b02dbd,DNM,ABANDONED,2022-09-21 22:25:03.000000000,2022-11-10 17:53:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-09-21 22:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/7d81d6c76697c34729e745435398348976642756', 'message': 'DNM\n\ntesting gate\n\nChange-Id: I267875117d8e4f18eef0bfc21b6122fe37b02dbd\n'}, {'number': 2, 'created': '2022-09-21 22:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/3b65e23569a41c042864d0f2869f3378a2dd6b39', 'message': 'DNM\n\ntesting gate\n\nChange-Id: I267875117d8e4f18eef0bfc21b6122fe37b02dbd\n'}, {'number': 3, 'created': '2022-09-21 23:00:12.000000000', 'files': ['pydep.txt', 'Dockerfile', 'bindep.txt', 'scripts/fetch_wheels.py', 'scripts/requirements.sh', 'scripts/install_packages.sh', 'playbooks/vars.yaml', 'scripts/install.sh', 'scripts/setup_pip.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/719ef4ec90871303234990a50d5370be6bc9cdd9', 'message': 'DNM\n\ntesting gate\n\nChange-Id: I267875117d8e4f18eef0bfc21b6122fe37b02dbd\n'}]",0,858830,719ef4ec90871303234990a50d5370be6bc9cdd9,6,1,3,14119,,,0,"DNM

testing gate

Change-Id: I267875117d8e4f18eef0bfc21b6122fe37b02dbd
",git fetch https://review.opendev.org/openstack/loci refs/changes/30/858830/3 && git format-patch -1 --stdout FETCH_HEAD,"['pydep.txt', 'Dockerfile', 'bindep.txt', 'scripts/fetch_wheels.py', 'scripts/requirements.sh', 'scripts/install_packages.sh', 'playbooks/vars.yaml', 'scripts/install.sh', 'scripts/setup_pip.sh']",9,7d81d6c76697c34729e745435398348976642756,dnm_all_fixes,"VENV_SETUP_OPTS=""--symlinks"" if [[ ""$(python3 -c 'import sys; print(sys.version_info.minor);')"" -ge 9 ]]; then VENV_SETUP_OPTS=""${VENV_SETUP_OPTS} --upgrade-deps""python3 -m venv ${VENV_SETUP_OPTS} /var/lib/openstackhash -r # If python>=3.9 then we already have the latest pip and setuptools, not wheel pip install --upgrade ${PIP_ARGS} pip setuptools wheel"," if [[ ""${PYTHON3}"" == ""no"" ]]; then TMP_VIRTUALENV=""virtualenv"" else TMP_VIRTUALENV=""python3 -m virtualenv --python=python3""# This little dance allows us to install the latest pip # without get_pip.py or the python-pip package (in epel on centos) if (( $(${TMP_VIRTUALENV} --version | grep -Po '[0-9]+\.[0-9]+\.[0-9]+' | cut -d. -f1) >= 14 )); then SETUPTOOLS=""--no-setuptools"" fi if (( $(${TMP_VIRTUALENV} --version | grep -Po '[0-9]+\.[0-9]+\.[0-9]+' | cut -d. -f1) >= 20 )); then SETUPTOOLS=""--seed pip --download"" fi # virtualenv 16.4.0 fixed symlink handling. The interaction of the new # corrected behavior with legacy bugs in packaged virtualenv releases in # distributions means we need to hold on to the pip bootstrap installation # chain to preserve symlinks. As distributions upgrade their default # installations we may not need this workaround in the future PIPBOOTSTRAP=/var/lib/pipbootstrap # Create the boostrap environment so we can get pip from virtualenv ${TMP_VIRTUALENV} ${SETUPTOOLS} ${PIPBOOTSTRAP} source ${PIPBOOTSTRAP}/bin/activate # Install setuptools explicitly required for virtualenv > 20 installation pip install --upgrade setuptools # Upgrade to the latest version of virtualenv pip install --upgrade ${PIP_ARGS} virtualenv==20.7.2 # Forget the cached locations of python binaries hash -r # Create the virtualenv with the updated toolchain for openstack service virtualenv --seed pip --download /var/lib/openstack # Deactivate the old bootstrap virtualenv and switch to the new one deactivate",67,115
openstack%2Fopenstack-helm~master~I90fce0bdcc2d8806213fe4bd4d5effbe8c346450,openstack/openstack-helm,master,I90fce0bdcc2d8806213fe4bd4d5effbe8c346450,Updating nova helmrelase hooks weights (helmv3),ABANDONED,2022-09-21 16:19:32.000000000,2022-11-10 17:53:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-09-21 16:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3540fdedd4ca3344908d214114ecd8fddaab85d1', 'message': 'Updating nova helmrelase hooks weights (helmv3)\n\nThe relation of dependency for nova resources is not working\nwith helmv3 since several jobs have post-install hooks and are\ndependencies of other jobs that have no hooks.\n\nThe jobs without hooks are deployed during an installation phase\nthat is never complete since the dependency jobs are hooked to be\ndeployed on post-install phase.\n\nThis change includes helm-hooks for the boostrap and cell-setup jobs.\nThe weights will define the order each one will be deployed.\n\nSigned-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>\nChange-Id: I90fce0bdcc2d8806213fe4bd4d5effbe8c346450\n'}, {'number': 2, 'created': '2022-09-22 11:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6bc8c22e5b92595960a7947247412446b4a510f0', 'message': 'Updating nova helmrelase hooks weights (helmv3)\n\nThe relation of dependency for nova resources is not working\nwith helmv3 since several jobs have post-install hooks and are\ndependencies of other jobs that have no hooks.\n\nThe jobs without hooks are deployed during an installation phase\nthat is never complete since the dependency jobs are hooked to be\ndeployed on post-install phase.\n\nThis change includes helm-hooks for the boostrap and cell-setup jobs.\nThe weights will define the order each one will be deployed.\n\nSigned-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>\nChange-Id: I90fce0bdcc2d8806213fe4bd4d5effbe8c346450\n'}, {'number': 3, 'created': '2022-09-22 11:12:42.000000000', 'files': ['nova/templates/job-bootstrap.yaml', 'releasenotes/notes/nova.yaml', 'nova/templates/job-cell-setup.yaml', 'nova/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bba1294adc034f7a701503b6f9b660940c2de8d2', 'message': 'Updating nova helmrelase hooks weights (helmv3)\n\nThe relation of dependency for nova resources is not working\nwith helmv3 since several jobs have post-install hooks and are\ndependencies of other jobs that have no hooks.\n\nThe jobs without hooks are deployed during an installation phase\nthat is never complete since the dependency jobs are hooked to be\ndeployed on post-install phase.\n\nThis change includes helm-hooks for the boostrap and cell-setup jobs.\nThe weights will define the order each one will be deployed.\n\nSigned-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>\nChange-Id: I90fce0bdcc2d8806213fe4bd4d5effbe8c346450\n'}]",0,858770,bba1294adc034f7a701503b6f9b660940c2de8d2,6,1,3,33594,,,0,"Updating nova helmrelase hooks weights (helmv3)

The relation of dependency for nova resources is not working
with helmv3 since several jobs have post-install hooks and are
dependencies of other jobs that have no hooks.

The jobs without hooks are deployed during an installation phase
that is never complete since the dependency jobs are hooked to be
deployed on post-install phase.

This change includes helm-hooks for the boostrap and cell-setup jobs.
The weights will define the order each one will be deployed.

Signed-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>
Change-Id: I90fce0bdcc2d8806213fe4bd4d5effbe8c346450
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/70/858770/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/templates/job-bootstrap.yaml', 'releasenotes/notes/nova.yaml', 'nova/templates/job-cell-setup.yaml', 'nova/Chart.yaml']",4,3540fdedd4ca3344908d214114ecd8fddaab85d1,,version: 0.2.47,version: 0.2.46,10,1
openstack%2Fopenstack-helm~master~I3a2860f8230dfcb53b9d302ab9e557f9bd8e20a6,openstack/openstack-helm,master,I3a2860f8230dfcb53b9d302ab9e557f9bd8e20a6,Fixing cinder helmrelase hooks weights (helmv3),ABANDONED,2022-09-20 18:03:30.000000000,2022-11-10 17:53:37.000000000,,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 34350}]","[{'number': 1, 'created': '2022-09-20 18:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ef0d435e36c6bfa42b9e07c36df9ac8478ad6244', 'message': 'Fixing cinder helmrelase hooks weights (helmv3)\n\nThe relation of dependency for cinder release resources is not working\nwith helmv3 since several jobs have post-install hooks and are\ndependencies of other jobs and deployments that have no hooks.\nThe jobs/deployments without hooks are deployed during an installation\nphase that is never complete since the dependency jobs are hooked to be\ndeployed on post-install phase.\n\nThis change includes helm-hooks the api, scheduler and volume\ndeployments. The weights will define the order each one will\nbe deployed.\n\nSigned-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>\nChange-Id: I3a2860f8230dfcb53b9d302ab9e557f9bd8e20a6\n'}, {'number': 2, 'created': '2022-09-21 11:43:17.000000000', 'files': ['cinder/templates/deployment-volume.yaml', 'cinder/Chart.yaml', 'releasenotes/notes/cinder.yaml', 'cinder/templates/deployment-api.yaml', 'cinder/templates/deployment-scheduler.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e6bcfa0470568d7e7b1ff854f4fbb15a385e4a68', 'message': 'Fixing cinder helmrelase hooks weights (helmv3)\n\nThe relation of dependency for cinder release resources is not working\nwith helmv3 since several jobs have post-install hooks and are\ndependencies of other jobs and deployments that have no hooks.\nThe jobs/deployments without hooks are deployed during an installation\nphase that is never complete since the dependency jobs are hooked to be\ndeployed on post-install phase.\n\nThis change includes helm-hooks the api, scheduler and volume\ndeployments. The weights will define the order each one will\nbe deployed.\n\nSigned-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>\nChange-Id: I3a2860f8230dfcb53b9d302ab9e557f9bd8e20a6\n'}]",0,858563,e6bcfa0470568d7e7b1ff854f4fbb15a385e4a68,7,4,2,33594,,,0,"Fixing cinder helmrelase hooks weights (helmv3)

The relation of dependency for cinder release resources is not working
with helmv3 since several jobs have post-install hooks and are
dependencies of other jobs and deployments that have no hooks.
The jobs/deployments without hooks are deployed during an installation
phase that is never complete since the dependency jobs are hooked to be
deployed on post-install phase.

This change includes helm-hooks the api, scheduler and volume
deployments. The weights will define the order each one will
be deployed.

Signed-off-by: Thales Elero Cervi <thaleselero.cervi@windriver.com>
Change-Id: I3a2860f8230dfcb53b9d302ab9e557f9bd8e20a6
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/63/858563/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/templates/deployment-volume.yaml', 'cinder/templates/deployment-api.yaml', 'cinder/templates/deployment-scheduler.yaml']",3,ef0d435e36c6bfa42b9e07c36df9ac8478ad6244,,"{{- if .Values.helm3_hook }} helm.sh/hook: post-install,post-upgrade helm.sh/hook-weight: ""2"" {{- end }}",,12,0
openstack%2Floci~master~If05bdc3de2b428aa72f30698c29541cc8a835fdd,openstack/loci,master,If05bdc3de2b428aa72f30698c29541cc8a835fdd,Add monasca,ABANDONED,2021-07-01 12:44:06.000000000,2022-11-10 17:51:55.000000000,,"[{'_account_id': 1004}, {'_account_id': 8863}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-07-01 12:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/51b9d68cb65b2bb20b5319d5f8aac03d1f922f36', 'message': 'Add monasca-agent\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 2, 'created': '2021-07-13 19:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/5855015ade34e73592fea8e0da99a8bf23b71d98', 'message': 'Add monasca-agent\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 3, 'created': '2021-07-15 13:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/64746008ebb1afb95f358ccb44d3c176397eddc8', 'message': 'Add monasca-agent\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 4, 'created': '2021-07-15 15:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/333cabf63b782ca21767035a0b3f194fa97c400e', 'message': 'Add monasca\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 5, 'created': '2021-07-15 15:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/5d2ae99d9a9d808a042f0377cc8ee98f2fefc93f', 'message': 'Add monasca\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 6, 'created': '2021-07-15 15:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/7aee4d727c9b3e65cdc21e2751c743529d8946b1', 'message': 'Add monasca\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 7, 'created': '2021-07-15 15:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/8bc1eda9980ec1648ee3279245d1dbd0a1fc7296', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 8, 'created': '2021-07-20 19:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/8cb3bb51ff1432bbae0202030d0ae3a9f12de092', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 9, 'created': '2021-07-20 20:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/0076764e49491d7206e0ea0ebaf1b7cbf36872d0', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 10, 'created': '2021-07-20 20:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/b415909e2865ebb886b00cc8f307d82034164575', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 11, 'created': '2021-08-20 13:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/45ed6e5496fd20975515b44b0ce9e0834affb67b', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 12, 'created': '2021-09-24 09:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/58d1c92a18363856d0b4952864f890cb870875a5', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 13, 'created': '2021-10-21 15:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/686ec749e24e11243077edc66fb2d1511f98b38c', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 14, 'created': '2021-10-21 15:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/58be2083c9d8d8470dbc5e63955d6d154e9240b8', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 15, 'created': '2022-01-13 14:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/b98985678d9334b3e2ba5eb61c1135dd1244ce94', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 16, 'created': '2022-03-01 14:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/4e45486eef3523cdaee245657788afc35a6c0d44', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}, {'number': 17, 'created': '2022-03-02 09:24:20.000000000', 'files': ['pydep.txt', 'bindep.txt'], 'web_link': 'https://opendev.org/openstack/loci/commit/fbe68078a0f8fb529a68b7259020c10a0e6edc9b', 'message': 'Add monasca\n\n- (monasca config) profile includes packages for config database\n- (monasca metrics) profile incldues pakcages for metrics database\n- (monasca notification) profile notification specific packages\n- (monasca agent) profile includes agent specific packages\n\nChange-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd\n'}]",34,799049,fbe68078a0f8fb529a68b7259020c10a0e6edc9b,46,4,17,31746,,,0,"Add monasca

- (monasca config) profile includes packages for config database
- (monasca metrics) profile incldues pakcages for metrics database
- (monasca notification) profile notification specific packages
- (monasca agent) profile includes agent specific packages

Change-Id: If05bdc3de2b428aa72f30698c29541cc8a835fdd
",git fetch https://review.opendev.org/openstack/loci refs/changes/49/799049/17 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', '.zuul.d/monasca.yaml']",2,51b9d68cb65b2bb20b5319d5f8aac03d1f922f36,fix-zuul-job, - loci-monasca-agent - loci-monasca-agent - publish-loci-monasca-agent name: loci-monasca-agent parent: loci-base vars: project: monasca-agent required-projects: - openstack/loci - openstack/requirements - openstack/monasca-agent - job: name: publish-loci-monasca-agent parent: loci-monasca-agent post-run: playbooks/push.yaml secrets: - loci_docker_login - job:,,22,0
openstack%2Floci~master~I3f4f60756887ad07229cf522803b30d4e16463cd,openstack/loci,master,I3f4f60756887ad07229cf522803b30d4e16463cd,Remove PYTHON3 hard-coded values,ABANDONED,2021-09-29 17:36:40.000000000,2022-11-10 17:51:54.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-09-29 17:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/972712dbb67deecdbe6ab3dfceb58ab890ff0802', 'message': 'Remove PYTHON3 hard-coded values\n\nChange-Id: I3f4f60756887ad07229cf522803b30d4e16463cd\n'}, {'number': 2, 'created': '2022-04-11 20:33:56.000000000', 'files': ['Dockerfile', 'bindep.txt', 'scripts/fetch_wheels.py', 'scripts/requirements.sh', 'scripts/install_packages.sh', 'scripts/cleanup.sh', 'scripts/install.sh', 'scripts/fetch_wheels.sh', 'scripts/setup_pip.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/86e4fb05302462309102e940ed6b7cf3bc8efb80', 'message': 'Remove PYTHON3 hard-coded values\n\nChange-Id: I3f4f60756887ad07229cf522803b30d4e16463cd\n'}]",0,811757,86e4fb05302462309102e940ed6b7cf3bc8efb80,5,1,2,1004,,,0,"Remove PYTHON3 hard-coded values

Change-Id: I3f4f60756887ad07229cf522803b30d4e16463cd
",git fetch https://review.opendev.org/openstack/loci refs/changes/57/811757/2 && git format-patch -1 --stdout FETCH_HEAD,"['Dockerfile', 'scripts/requirements.sh', 'scripts/install_packages.sh', 'scripts/cleanup.sh', 'scripts/install.sh', 'scripts/fetch_wheels.sh', 'scripts/setup_pip.sh']",7,972712dbb67deecdbe6ab3dfceb58ab890ff0802,remove-py3,"TMP_VIRTUALENV=""python3 -m virtualenv --python=python3""","if [[ ""${PYTHON3}"" == ""no"" ]]; then TMP_VIRTUALENV=""virtualenv"" else TMP_VIRTUALENV=""python3 -m virtualenv --python=python3"" fi",15,67
openstack%2Fopenstack-helm~master~I5e3426bddc60321e47491cc6ea7837141a50bf2a,openstack/openstack-helm,master,I5e3426bddc60321e47491cc6ea7837141a50bf2a,Removed default policy from values file,ABANDONED,2022-01-24 07:25:41.000000000,2022-11-10 17:51:52.000000000,,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-01-24 07:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c716b17a1db4a040cb9b495dc91b0fa57c96704d', 'message': 'Removed default policy from values file\n\nAs openstack projects have implemented policy embed in code, removing the default policy hard coded in values file.\n\nChange-Id: I5e3426bddc60321e47491cc6ea7837141a50bf2a\n'}, {'number': 2, 'created': '2022-01-24 08:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bb7b506e719cae39be06c67602f5db270389b5ea', 'message': 'Removed default policy from values file\n\nAs openstack projects have implemented policy embed in code, removing the default policy hard coded in values file.\n\nChange-Id: I5e3426bddc60321e47491cc6ea7837141a50bf2a\n'}, {'number': 3, 'created': '2022-01-24 09:35:55.000000000', 'files': ['releasenotes/notes/magnum.yaml', 'releasenotes/notes/heat.yaml', 'heat/Chart.yaml', 'releasenotes/notes/neutron.yaml', 'glance/values.yaml', 'ceilometer/values.yaml', 'magnum/Chart.yaml', 'cinder/Chart.yaml', 'designate/Chart.yaml', 'releasenotes/notes/cinder.yaml', 'releasenotes/notes/mistral.yaml', 'releasenotes/notes/senlin.yaml', 'senlin/values.yaml', 'aodh/Chart.yaml', 'mistral/values.yaml', 'mistral/Chart.yaml', 'senlin/Chart.yaml', 'heat/values.yaml', 'releasenotes/notes/aodh.yaml', 'releasenotes/notes/glance.yaml', 'cinder/values.yaml', 'magnum/values.yaml', 'releasenotes/notes/placement.yaml', 'aodh/values.yaml', 'neutron/Chart.yaml', 'designate/values.yaml', 'glance/Chart.yaml', 'releasenotes/notes/ceilometer.yaml', 'placement/values.yaml', 'releasenotes/notes/designate.yaml', 'placement/Chart.yaml', 'ceilometer/Chart.yaml', 'neutron/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8d6e74960d9460443b8917eb54bc20b930909a65', 'message': 'Removed default policy from values file\n\nAs openstack projects have implemented policy embed in code, removing the default policy hard coded in values file.\n\nChange-Id: I5e3426bddc60321e47491cc6ea7837141a50bf2a\n'}]",2,826019,8d6e74960d9460443b8917eb54bc20b930909a65,10,2,3,33130,,,0,"Removed default policy from values file

As openstack projects have implemented policy embed in code, removing the default policy hard coded in values file.

Change-Id: I5e3426bddc60321e47491cc6ea7837141a50bf2a
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/19/826019/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/magnum.yaml', 'releasenotes/notes/heat.yaml', 'heat/Chart.yaml', 'releasenotes/notes/neutron.yaml', 'glance/values.yaml', 'ceilometer/values.yaml', 'magnum/Chart.yaml', 'cinder/Chart.yaml', 'designate/Chart.yaml', 'releasenotes/notes/cinder.yaml', 'releasenotes/notes/mistral.yaml', 'releasenotes/notes/senlin.yaml', 'senlin/values.yaml', 'aodh/Chart.yaml', 'mistral/values.yaml', 'mistral/Chart.yaml', 'senlin/Chart.yaml', 'heat/values.yaml', 'releasenotes/notes/aodh.yaml', 'releasenotes/notes/glance.yaml', 'cinder/values.yaml', 'magnum/values.yaml', 'releasenotes/notes/placement.yaml', 'aodh/values.yaml', 'neutron/Chart.yaml', 'designate/values.yaml', 'glance/Chart.yaml', 'releasenotes/notes/ceilometer.yaml', 'placement/values.yaml', 'releasenotes/notes/designate.yaml', 'placement/Chart.yaml', 'ceilometer/Chart.yaml', 'neutron/values.yaml']",33,c716b17a1db4a040cb9b495dc91b0fa57c96704d,remove-default-policy, policy: {}," policy: context_is_admin: role:admin owner: tenant_id:%(tenant_id)s admin_or_owner: rule:context_is_admin or rule:owner context_is_advsvc: role:advsvc admin_or_network_owner: rule:context_is_admin or tenant_id:%(network:tenant_id)s admin_owner_or_network_owner: rule:owner or rule:admin_or_network_owner admin_only: rule:context_is_admin regular_user: '' shared: field:networks:shared=True shared_subnetpools: field:subnetpools:shared=True shared_address_scopes: field:address_scopes:shared=True external: field:networks:router:external=True default: rule:admin_or_owner create_subnet: rule:admin_or_network_owner create_subnet:segment_id: rule:admin_only create_subnet:service_types: rule:admin_only get_subnet: rule:admin_or_owner or rule:shared get_subnet:segment_id: rule:admin_only update_subnet: rule:admin_or_network_owner update_subnet:service_types: rule:admin_only delete_subnet: rule:admin_or_network_owner create_subnetpool: '' create_subnetpool:shared: rule:admin_only create_subnetpool:is_default: rule:admin_only get_subnetpool: rule:admin_or_owner or rule:shared_subnetpools update_subnetpool: rule:admin_or_owner update_subnetpool:is_default: rule:admin_only delete_subnetpool: rule:admin_or_owner create_address_scope: '' create_address_scope:shared: rule:admin_only get_address_scope: rule:admin_or_owner or rule:shared_address_scopes update_address_scope: rule:admin_or_owner update_address_scope:shared: rule:admin_only delete_address_scope: rule:admin_or_owner create_network: '' get_network: rule:admin_or_owner or rule:shared or rule:external or rule:context_is_advsvc get_network:router:external: rule:regular_user get_network:segments: rule:admin_only get_network:provider:network_type: rule:admin_only get_network:provider:physical_network: rule:admin_only get_network:provider:segmentation_id: rule:admin_only get_network:queue_id: rule:admin_only get_network_ip_availabilities: rule:admin_only get_network_ip_availability: rule:admin_only create_network:shared: rule:admin_only create_network:router:external: rule:admin_only create_network:is_default: rule:admin_only create_network:segments: rule:admin_only create_network:provider:network_type: rule:admin_only create_network:provider:physical_network: rule:admin_only create_network:provider:segmentation_id: rule:admin_only update_network: rule:admin_or_owner update_network:segments: rule:admin_only update_network:shared: rule:admin_only update_network:provider:network_type: rule:admin_only update_network:provider:physical_network: rule:admin_only update_network:provider:segmentation_id: rule:admin_only update_network:router:external: rule:admin_only delete_network: rule:admin_or_owner create_segment: rule:admin_only get_segment: rule:admin_only update_segment: rule:admin_only delete_segment: rule:admin_only network_device: 'field:port:device_owner=~^network:' create_port: '' create_port:device_owner: not rule:network_device or rule:context_is_advsvc or rule:admin_or_network_owner create_port:mac_address: rule:context_is_advsvc or rule:admin_or_network_owner create_port:fixed_ips: rule:context_is_advsvc or rule:admin_or_network_owner create_port:port_security_enabled: rule:context_is_advsvc or rule:admin_or_network_owner create_port:binding:host_id: rule:admin_only create_port:binding:profile: rule:admin_only create_port:mac_learning_enabled: rule:context_is_advsvc or rule:admin_or_network_owner create_port:allowed_address_pairs: rule:admin_or_network_owner get_port: rule:context_is_advsvc or rule:admin_owner_or_network_owner get_port:queue_id: rule:admin_only get_port:binding:vif_type: rule:admin_only get_port:binding:vif_details: rule:admin_only get_port:binding:host_id: rule:admin_only get_port:binding:profile: rule:admin_only update_port: rule:admin_or_owner or rule:context_is_advsvc update_port:device_owner: not rule:network_device or rule:context_is_advsvc or rule:admin_or_network_owner update_port:mac_address: rule:admin_only or rule:context_is_advsvc update_port:fixed_ips: rule:context_is_advsvc or rule:admin_or_network_owner update_port:port_security_enabled: rule:context_is_advsvc or rule:admin_or_network_owner update_port:binding:host_id: rule:admin_only update_port:binding:profile: rule:admin_only update_port:mac_learning_enabled: rule:context_is_advsvc or rule:admin_or_network_owner update_port:allowed_address_pairs: rule:admin_or_network_owner delete_port: rule:context_is_advsvc or rule:admin_owner_or_network_owner get_router:ha: rule:admin_only create_router: rule:regular_user create_router:external_gateway_info:enable_snat: rule:admin_only create_router:distributed: rule:admin_only create_router:ha: rule:admin_only get_router: rule:admin_or_owner get_router:distributed: rule:admin_only update_router:external_gateway_info:enable_snat: rule:admin_only update_router:distributed: rule:admin_only update_router:ha: rule:admin_only delete_router: rule:admin_or_owner add_router_interface: rule:admin_or_owner remove_router_interface: rule:admin_or_owner create_router:external_gateway_info:external_fixed_ips: rule:admin_only update_router:external_gateway_info:external_fixed_ips: rule:admin_only insert_rule: rule:admin_or_owner remove_rule: rule:admin_or_owner create_qos_queue: rule:admin_only get_qos_queue: rule:admin_only update_agent: rule:admin_only delete_agent: rule:admin_only get_agent: rule:admin_only create_dhcp-network: rule:admin_only delete_dhcp-network: rule:admin_only get_dhcp-networks: rule:admin_only create_l3-router: rule:admin_only delete_l3-router: rule:admin_only get_l3-routers: rule:admin_only get_dhcp-agents: rule:admin_only get_l3-agents: rule:admin_only get_loadbalancer-agent: rule:admin_only get_loadbalancer-pools: rule:admin_only get_agent-loadbalancers: rule:admin_only get_loadbalancer-hosting-agent: rule:admin_only create_floatingip: rule:regular_user create_floatingip:floating_ip_address: rule:admin_only update_floatingip: rule:admin_or_owner delete_floatingip: rule:admin_or_owner get_floatingip: rule:admin_or_owner create_network_profile: rule:admin_only update_network_profile: rule:admin_only delete_network_profile: rule:admin_only get_network_profiles: '' get_network_profile: '' update_policy_profiles: rule:admin_only get_policy_profiles: '' get_policy_profile: '' create_metering_label: rule:admin_only delete_metering_label: rule:admin_only get_metering_label: rule:admin_only create_metering_label_rule: rule:admin_only delete_metering_label_rule: rule:admin_only get_metering_label_rule: rule:admin_only get_service_provider: rule:regular_user get_lsn: rule:admin_only create_lsn: rule:admin_only create_flavor: rule:admin_only update_flavor: rule:admin_only delete_flavor: rule:admin_only get_flavors: rule:regular_user get_flavor: rule:regular_user create_service_profile: rule:admin_only update_service_profile: rule:admin_only delete_service_profile: rule:admin_only get_service_profiles: rule:admin_only get_service_profile: rule:admin_only get_policy: rule:regular_user create_policy: rule:admin_only update_policy: rule:admin_only delete_policy: rule:admin_only get_policy_bandwidth_limit_rule: rule:regular_user create_policy_bandwidth_limit_rule: rule:admin_only delete_policy_bandwidth_limit_rule: rule:admin_only update_policy_bandwidth_limit_rule: rule:admin_only get_policy_dscp_marking_rule: rule:regular_user create_policy_dscp_marking_rule: rule:admin_only delete_policy_dscp_marking_rule: rule:admin_only update_policy_dscp_marking_rule: rule:admin_only get_rule_type: rule:regular_user get_policy_minimum_bandwidth_rule: rule:regular_user create_policy_minimum_bandwidth_rule: rule:admin_only delete_policy_minimum_bandwidth_rule: rule:admin_only update_policy_minimum_bandwidth_rule: rule:admin_only restrict_wildcard: ""(not field:rbac_policy:target_tenant=*) or rule:admin_only"" create_rbac_policy: '' create_rbac_policy:target_tenant: rule:restrict_wildcard update_rbac_policy: rule:admin_or_owner update_rbac_policy:target_tenant: rule:restrict_wildcard and rule:admin_or_owner get_rbac_policy: rule:admin_or_owner delete_rbac_policy: rule:admin_or_owner create_flavor_service_profile: rule:admin_only delete_flavor_service_profile: rule:admin_only get_flavor_service_profile: rule:regular_user get_auto_allocated_topology: rule:admin_or_owner create_trunk: rule:regular_user get_trunk: rule:admin_or_owner delete_trunk: rule:admin_or_owner get_subports: '' add_subports: rule:admin_or_owner remove_subports: rule:admin_or_owner",34,775
openstack%2Fopenstack-helm~master~I7817b08fd197e55228b55e755f1fcf7a6a27e6b3,openstack/openstack-helm,master,I7817b08fd197e55228b55e755f1fcf7a6a27e6b3,fix promisc setting in _neutron-sriov-agent-init.sh.tpl,ABANDONED,2022-01-24 09:03:53.000000000,2022-11-10 17:51:51.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-01-24 09:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f8863f03b0dc19bfd874c4dfd8cf7e66d69562dc', 'message': 'fix promisc setting in _neutron-sriov-agent-init.sh.tpl\n\nThe following note is written in the commit message [1] of the device driver.\nSo, we move this flag operation to the beginning of the script.\n\n> The vf-true-promisc-support flag cannot be toggled while any VF is in\n> promiscuous mode. This flag should be set prior to loading the iavf driver\n> or spawning VF(s).\n\n[1]: https://github.com/torvalds/linux/commit/01b5e89aab498dad5a38d04a71beca2b562d9449\n\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\nChange-Id: I7817b08fd197e55228b55e755f1fcf7a6a27e6b3\n'}, {'number': 2, 'created': '2022-01-25 02:25:07.000000000', 'files': ['neutron/Chart.yaml', 'releasenotes/notes/neutron.yaml', 'neutron/templates/bin/_neutron-sriov-agent-init.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8d5e15bfed6f86ca99edebe1180372fb4a5e7f98', 'message': 'fix promisc setting in _neutron-sriov-agent-init.sh.tpl\n\nThe following note is written in the commit message [1] of the device driver.\nSo, we move this flag operation to the beginning of the script.\n\n> The vf-true-promisc-support flag cannot be toggled while any VF is in\n> promiscuous mode. This flag should be set prior to loading the iavf driver\n> or spawning VF(s).\n\n[1]: https://github.com/torvalds/linux/commit/01b5e89aab498dad5a38d04a71beca2b562d9449\n\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\nChange-Id: I7817b08fd197e55228b55e755f1fcf7a6a27e6b3\n'}]",1,826031,8d5e15bfed6f86ca99edebe1180372fb4a5e7f98,7,1,2,31652,,,0,"fix promisc setting in _neutron-sriov-agent-init.sh.tpl

The following note is written in the commit message [1] of the device driver.
So, we move this flag operation to the beginning of the script.

> The vf-true-promisc-support flag cannot be toggled while any VF is in
> promiscuous mode. This flag should be set prior to loading the iavf driver
> or spawning VF(s).

[1]: https://github.com/torvalds/linux/commit/01b5e89aab498dad5a38d04a71beca2b562d9449

Signed-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>
Change-Id: I7817b08fd197e55228b55e755f1fcf7a6a27e6b3
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/31/826031/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/templates/bin/_neutron-sriov-agent-init.sh.tpl'],1,f8863f03b0dc19bfd874c4dfd8cf7e66d69562dc,neutron-promisc-setting-fix,"{{- if $sriov.promisc }} promisc_mode=""on"" {{- else }} promisc_mode=""off"" {{- end }} #NOTE(portdirect): get the bus that the port is on NIC_BUS=$(lshw -c network -businfo | awk '/{{ $sriov.device }}/ {print $1}') #NOTE(portdirect): get first port on the nic NIC_FIRST_PORT=$(lshw -c network -businfo | awk ""/${NIC_BUS%%.*}/ { print \$2; exit }"") #NOTE(portdirect): Enable promisc mode on the nic, by setting it for the 1st port ethtool --set-priv-flags ${NIC_FIRST_PORT} vf-true-promisc-support ${promisc_mode} "," {{- if $sriov.promisc }} promisc_mode=""on"" {{- else }} promisc_mode=""off"" {{- end }}#NOTE(portdirect): get the bus that the port is on NIC_BUS=$(lshw -c network -businfo | awk '/{{ $sriov.device }}/ {print $1}') #NOTE(portdirect): get first port on the nic NIC_FIRST_PORT=$(lshw -c network -businfo | awk ""/${NIC_BUS%%.*}/ { print \$2; exit }"") #NOTE(portdirect): Enable promisc mode on the nic, by setting it for the 1st port ethtool --set-priv-flags ${NIC_FIRST_PORT} vf-true-promisc-support ${promisc_mode}",13,12
openstack%2Fopenstack-helm~master~Ic15581d742bb11fd728208081c088c517317c3db,openstack/openstack-helm,master,Ic15581d742bb11fd728208081c088c517317c3db,Added post-install and post-upgrade hook for jobs for horizon,ABANDONED,2021-03-23 13:59:32.000000000,2022-11-10 17:51:50.000000000,,"[{'_account_id': 22348}, {'_account_id': 28008}]","[{'number': 1, 'created': '2021-03-23 13:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cdd807dce1331d59d0e46300046bc1dd2888a6d9', 'message': 'Added post-install and post-upgrade hook for jobs for horizon\n\nChart upgrading was failing due to some immutable fields are needed to upgrade before the jobs can be upgraded. For solving this issue, we\nhave added the helm.sh/hook annotations with post-install and post-upgrade values.\nAs for hook-weight annotations, we have added these to control the flow of the jobs with hook creation as the jobs are dependent. Like,\ndb-init jobs need to run before db-sync and so on.\n\nChange-Id: Ic15581d742bb11fd728208081c088c517317c3db\n'}, {'number': 2, 'created': '2021-03-29 08:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fac1bf7f1b278de789d9e1fe33abb914b0881c82', 'message': 'Added post-install and post-upgrade hook for jobs for horizon\n\nChart upgrading was failing due to some immutable fields are needed to upgrade before the jobs can be upgraded. For solving this issue, we\nhave added the helm.sh/hook annotations with post-install and post-upgrade values.\nAs for hook-weight annotations, we have added these to control the flow of the jobs with hook creation as the jobs are dependent. Like,\ndb-init jobs need to run before db-sync and so on.\n\nChange-Id: Ic15581d742bb11fd728208081c088c517317c3db\n'}, {'number': 3, 'created': '2022-01-31 08:50:12.000000000', 'files': ['horizon/templates/job-db-sync.yaml', 'horizon/Chart.yaml', 'horizon/templates/job-db-init.yaml', 'releasenotes/notes/horizon.yaml', 'horizon/templates/job-image-repo-sync.yaml', 'horizon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fb8c434b2f2d2d7c5a677a79e2872c8ccdf490d9', 'message': 'Added post-install and post-upgrade hook for jobs for horizon\n\nChart upgrading was failing due to some immutable fields are needed to upgrade before the jobs can be upgraded. For solving this issue, we\nhave added the helm.sh/hook annotations with post-install and post-upgrade values.\nAs for hook-weight annotations, we have added these to control the flow of the jobs with hook creation as the jobs are dependent. Like,\ndb-init jobs need to run before db-sync and so on.\n\nChange-Id: Ic15581d742bb11fd728208081c088c517317c3db\n'}]",0,782526,fb8c434b2f2d2d7c5a677a79e2872c8ccdf490d9,11,2,3,33130,,,0,"Added post-install and post-upgrade hook for jobs for horizon

Chart upgrading was failing due to some immutable fields are needed to upgrade before the jobs can be upgraded. For solving this issue, we
have added the helm.sh/hook annotations with post-install and post-upgrade values.
As for hook-weight annotations, we have added these to control the flow of the jobs with hook creation as the jobs are dependent. Like,
db-init jobs need to run before db-sync and so on.

Change-Id: Ic15581d742bb11fd728208081c088c517317c3db
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/26/782526/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/job-db-sync.yaml', 'horizon/Chart.yaml', 'horizon/templates/job-db-init.yaml', 'releasenotes/notes/horizon.yaml', 'horizon/templates/job-image-repo-sync.yaml']",5,cdd807dce1331d59d0e46300046bc1dd2888a6d9,horizon_annotations-patch2,"{{- define ""metadata.annotations.job.repo_sync"" }} helm.sh/hook: post-install,post-upgrade {{- end }} {{- $imageRepoSyncJob := dict ""envAll"" . ""serviceName"" ""horizon"" ""jobAnnotations"" (include ""metadata.annotations.job.repo_sync"" . | fromYaml) -}}","{{- $imageRepoSyncJob := dict ""envAll"" . ""serviceName"" ""horizon"" -}}",16,3
openstack%2Fopenstack-helm-infra~master~I45c7625f938cdf2b5172b16fb6fb614c28662fdc,openstack/openstack-helm-infra,master,I45c7625f938cdf2b5172b16fb6fb614c28662fdc,ceph-rgw: Added post-install and post-upgrade hook for jobs,ABANDONED,2022-02-01 00:09:41.000000000,2022-11-10 17:51:49.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-01 00:09:41.000000000', 'files': ['ceph-rgw/templates/job-image-repo-sync.yaml', 'ceph-rgw/Chart.yaml', 'ceph-rgw/templates/job-bootstrap.yaml', 'ceph-rgw/templates/job-ks-service.yaml', 'ceph-rgw/templates/job-ks-user.yaml', 'ceph-rgw/templates/job-rgw-placement-targets.yaml', 'ceph-rgw/templates/job-ks-endpoints.yaml', 'ceph-rgw/values.yaml', 'ceph-rgw/templates/job-rgw-storage-init.yaml', 'releasenotes/notes/ceph-rgw.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0b22599f5faa4b9e25914d528c049099acfbea99', 'message': 'ceph-rgw: Added post-install and post-upgrade hook for jobs\n\nChart upgrading was failing due to some immutable fields\nare needed to upgrade before the jobs can be upgraded. For\nsolving this issue, we have added the helm.sh/hook\nannotations with post-install and post-upgrade values.\n\nAs for hook-weight annotations, we have added these to\ncontrol the flow of the jobs with hook creation as the\njobs are dependent.\n\nChange-Id: I45c7625f938cdf2b5172b16fb6fb614c28662fdc\n'}]",0,827198,0b22599f5faa4b9e25914d528c049099acfbea99,3,1,1,1004,,,0,"ceph-rgw: Added post-install and post-upgrade hook for jobs

Chart upgrading was failing due to some immutable fields
are needed to upgrade before the jobs can be upgraded. For
solving this issue, we have added the helm.sh/hook
annotations with post-install and post-upgrade values.

As for hook-weight annotations, we have added these to
control the flow of the jobs with hook creation as the
jobs are dependent.

Change-Id: I45c7625f938cdf2b5172b16fb6fb614c28662fdc
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/98/827198/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-rgw/templates/job-image-repo-sync.yaml', 'ceph-rgw/Chart.yaml', 'ceph-rgw/templates/job-bootstrap.yaml', 'ceph-rgw/templates/job-ks-service.yaml', 'ceph-rgw/templates/job-ks-user.yaml', 'ceph-rgw/templates/job-rgw-placement-targets.yaml', 'ceph-rgw/templates/job-ks-endpoints.yaml', 'ceph-rgw/templates/job-rgw-storage-init.yaml', 'ceph-rgw/values.yaml', 'releasenotes/notes/ceph-rgw.yaml']",10,0b22599f5faa4b9e25914d528c049099acfbea99,add-rgw-jobs, - 0.1.18 Added post-install and post-upgrade hook for jobs,,49,1
openstack%2Fopenstack-helm~master~Iea82829f315ff8d269161ea657591b8fb10d91fa,openstack/openstack-helm,master,Iea82829f315ff8d269161ea657591b8fb10d91fa,Introduced helm hook for cinder bootstrap job,ABANDONED,2022-01-31 09:48:19.000000000,2022-11-10 17:51:48.000000000,,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-01-31 09:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b1219f82252652f73bb1d56b722901ae604de5e2', 'message': 'Introduced helm hook for cinder bootstrap job\n\nAdded helm hook for the cinder bootstrap job\n\nChange-Id: Iea82829f315ff8d269161ea657591b8fb10d91fa\n'}, {'number': 2, 'created': '2022-02-01 05:46:57.000000000', 'files': ['cinder/templates/job-bootstrap.yaml', 'cinder/Chart.yaml', 'cinder/templates/job-backup-storage-init.yaml', 'releasenotes/notes/cinder.yaml', 'cinder/templates/job-storage-init.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8eaea7b767d4180a908da46e98ea4ef6dafeaa77', 'message': 'Introduced helm hook for cinder bootstrap job\n\nAdded helm hook for the cinder bootstrap job, storage-init job and storage-backup-init job\n\nChange-Id: Iea82829f315ff8d269161ea657591b8fb10d91fa\n'}]",2,827005,8eaea7b767d4180a908da46e98ea4ef6dafeaa77,8,2,2,33130,,,0,"Introduced helm hook for cinder bootstrap job

Added helm hook for the cinder bootstrap job, storage-init job and storage-backup-init job

Change-Id: Iea82829f315ff8d269161ea657591b8fb10d91fa
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/05/827005/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/templates/job-bootstrap.yaml', 'cinder/Chart.yaml', 'releasenotes/notes/cinder.yaml']",3,b1219f82252652f73bb1d56b722901ae604de5e2,cinder-hook-bootstrap, - 0.2.15 Add helm hooks for cinder bootstrap job,,10,1
openstack%2Fopenstack-helm~master~Id60701c41e5eab98bc138d36bf5202a51c8d959b,openstack/openstack-helm,master,Id60701c41e5eab98bc138d36bf5202a51c8d959b,Hooks for db jobs,ABANDONED,2022-01-31 13:17:48.000000000,2022-11-10 17:51:47.000000000,,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-01-31 13:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/c7ffaa35228e672bc4c79275b3efdb0d71e6cb84', 'message': 'Hooks for db jobs\n\nAdded helm hook as an annotations for the db-sync and db-migrate job for placement.\n\nChange-Id: Id60701c41e5eab98bc138d36bf5202a51c8d959b\n'}, {'number': 2, 'created': '2022-01-31 14:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/502bc9e4cddfac9bf0282da3a999cce373c1bd18', 'message': 'Hooks for db jobs\n\nAdded helm hook as an annotations for the db-sync and db-migrate job for placement.\n\nChange-Id: Id60701c41e5eab98bc138d36bf5202a51c8d959b\n'}, {'number': 3, 'created': '2022-02-01 06:11:40.000000000', 'files': ['placement/templates/job-db-sync.yaml', 'placement/values_overrides/victoria-ubuntu_focal.yaml', 'placement/values_overrides/ussuri-ubuntu_bionic.yaml', 'releasenotes/notes/placement.yaml', 'placement/values_overrides/train-ubuntu_bionic.yaml', 'placement/Chart.yaml', 'placement/values_overrides/wallaby-ubuntu_focal.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b9eef13d891ca92c19e24d2b0cc59d45ee7074cc', 'message': 'Hooks for db jobs\n\nAdded helm hook as an annotations for the db-sync and db-migrate job for placement.\n\nRemoving the job db-migrate from values_overrides as placement migration/extraction is no longer needed for openstack release being tested.\n\nChange-Id: Id60701c41e5eab98bc138d36bf5202a51c8d959b\n'}]",2,827080,b9eef13d891ca92c19e24d2b0cc59d45ee7074cc,10,2,3,33130,,,0,"Hooks for db jobs

Added helm hook as an annotations for the db-sync and db-migrate job for placement.

Removing the job db-migrate from values_overrides as placement migration/extraction is no longer needed for openstack release being tested.

Change-Id: Id60701c41e5eab98bc138d36bf5202a51c8d959b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/80/827080/1 && git format-patch -1 --stdout FETCH_HEAD,"['placement/templates/job-db-sync.yaml', 'placement/templates/job-db-migrate.yaml', 'releasenotes/notes/placement.yaml', 'placement/Chart.yaml']",4,c7ffaa35228e672bc4c79275b3efdb0d71e6cb84,placement-annotations,version: 0.2.6,version: 0.2.5,15,1
openstack%2Fopenstack-helm~master~I7ddcfacc0fc7bb9e45d93ced31531862ea981290,openstack/openstack-helm,master,I7ddcfacc0fc7bb9e45d93ced31531862ea981290,[Rally] Remove duplicated task definition for cinder,ABANDONED,2019-10-31 11:53:24.000000000,2022-11-10 17:51:46.000000000,,"[{'_account_id': 1736}, {'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 29013}]","[{'number': 1, 'created': '2019-10-31 11:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/245565a2dc1a6f488f011faf434236bc28aa1b88', 'message': '[Rally] Remove duplicated task definition for cinder\n\nChange-Id: I7ddcfacc0fc7bb9e45d93ced31531862ea981290\n'}, {'number': 2, 'created': '2019-11-04 08:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/67de2945fbd52b99ed62af41a985bda1fb99b501', 'message': '[Rally] Remove duplicated task definition for cinder\n\n * Fix cinder task params\n\nChange-Id: I7ddcfacc0fc7bb9e45d93ced31531862ea981290\n'}, {'number': 3, 'created': '2020-02-03 15:13:55.000000000', 'files': ['rally/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/837e478baabe63233bf86d691bad7ce6ad9bcd44', 'message': '[Rally] Remove duplicated task definition for cinder\n\n * Fix cinder task params\n\nChange-Id: I7ddcfacc0fc7bb9e45d93ced31531862ea981290\n'}]",1,692348,837e478baabe63233bf86d691bad7ce6ad9bcd44,20,10,3,14525,,,0,"[Rally] Remove duplicated task definition for cinder

 * Fix cinder task params

Change-Id: I7ddcfacc0fc7bb9e45d93ced31531862ea981290
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/48/692348/3 && git format-patch -1 --stdout FETCH_HEAD,['rally/values.yaml'],1,245565a2dc1a6f488f011faf434236bc28aa1b88,(HEAD, CinderVolumes.list_types: is_public: true users_per_tenant: 3 times: 10 sla: failure_rate: max: 0," CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_volume_and_clone: size: 1 users_per_tenant: 2 times: 3 - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant CinderVolumeBackups.create_incremental_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} size: 1 context: roles: - admin users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_delete_volume_type: - args: {} context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_and_list_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 4 type: constant sla: failure_rate: max: 0 CinderVolumeTypes.create_volume_type_and_encryption_type: - args: specs: cipher: aes-xts-plain64 control_location: front-end key_size: 512 provider: LuksEncryptor context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_accept_transfer: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_attach_volume: - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: 10 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant - args: create_volume_params: availability_zone: nova flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 1 times: 5 type: constant CinderVolumes.create_and_delete_snapshot: - args: force: false context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_delete_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_and_extend_volume: - args: new_size: 2 size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant - args: new_size: max: 10 min: 6 size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_get_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 5 type: constant sla: failure_rate: max: 0 CinderVolumes.create_and_list_snapshots: - args: detailed: true force: false context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_list_volume: - args: detailed: true size: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant - args: detailed: true size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_list_volume_backups: - args: create_backup_kwargs: {} create_volume_kwargs: {} detailed: true do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_and_restore_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_and_update_volume: - args: create_volume_kwargs: {} size: 1 update_volume_kwargs: display_description: desc_updated display_name: name_updated context: users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 3 type: constant CinderVolumes.create_and_upload_volume_to_image: - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant - args: container_format: bare disk_format: raw do_delete: true force: false image: name: cirros-0.3.5-x86_64-disk.img size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_from_volume_and_delete_volume: - args: size: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant - args: size: max: 5 min: 1 context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 runner: concurrency: 2 times: 2 type: constant CinderVolumes.create_nested_snapshots_and_attach_volume: - args: nested_level: 5 size: max: 5 min: 1 context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 runner: concurrency: 1 times: 1 type: constant CinderVolumes.create_snapshot_and_attach_volume: - args: size: max: 5 min: 1 volume_type: false context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant - args: size: max: 5 min: 1 volume_type: true context: servers: flavor: name: m1.tiny image: name: cirros-0.3.5-x86_64-disk.img servers_per_tenant: 2 users: tenants: 2 users_per_tenant: 1 images: image_url: ""http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"" image_name: cirros-0.3.5-x86_64-disk.img image_type: qcow2 image_container: bare images_per_tenant: 1 runner: concurrency: 2 times: 4 type: constant CinderVolumes.create_volume: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_clone: - args: size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant - args: nested_level: 3 size: max: 5 min: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant CinderVolumes.create_volume_and_update_readonly_flag: - args: read_only: true size: 1 context: users: tenants: 2 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.create_volume_backup: - args: create_backup_kwargs: {} create_volume_kwargs: {} do_delete: true size: 1 context: roles: - member users: tenants: 1 users_per_tenant: 1 runner: concurrency: 1 times: 2 type: constant CinderVolumes.create_volume_from_snapshot: - args: do_delete: true context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 3 type: constant CinderVolumes.list_transfers: - args: detailed: true context: users: tenants: 3 users_per_tenant: 2 runner: concurrency: 2 times: 3 type: constant sla: failure_rate: max: 0 CinderVolumes.list_types: - args: is_public: true context: users: tenants: 2 users_per_tenant: 3 runner: concurrency: 2 times: 10 type: constant sla: failure_rate: max: 0 CinderVolumes.list_volumes: - args: detailed: true context: users: tenants: 1 users_per_tenant: 1 volumes: size: 1 volumes_per_tenant: 4 runner: concurrency: 1 times: 100 type: constant CinderVolumes.modify_volume_metadata: - args: {} context: users: tenants: 2 users_per_tenant: 2 volumes: size: 1 runner: concurrency: 2 times: 10 type: constant",7,8727
openstack%2Fopenstack-helm-infra~master~Ia1c56d54583017bfec891568367cfce79e2df565,openstack/openstack-helm-infra,master,Ia1c56d54583017bfec891568367cfce79e2df565,Added pgcrypto extension,ABANDONED,2022-01-10 15:32:22.000000000,2022-11-10 17:51:45.000000000,,"[{'_account_id': 22348}, {'_account_id': 28719}]","[{'number': 1, 'created': '2022-01-10 15:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/880e1cd9a91999df7e2749c33603320404f2df82', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 2, 'created': '2022-01-11 17:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/34056f1f86e4b3ca6a5458395b6d4238b6283915', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 3, 'created': '2022-01-17 17:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/634bb65f62a21ca4ae92b582f3b4b58a4f43f2af', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 4, 'created': '2022-01-17 18:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2ac05b0cc7e5dde0baf94f35e36dadd8b693eb94', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 5, 'created': '2022-01-22 18:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ecba40478a3135d1b89e5c20a683a46323e3234b', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 6, 'created': '2022-01-22 18:44:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/56afc565e0fd5373ebf52f100d7b1092a92f3aa5', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 7, 'created': '2022-02-02 18:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bc0eb64fdc15f2e61f2597b7f8aa45611e61741e', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 8, 'created': '2022-02-02 18:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/412c01afa4bc9397606c67f5103ae3386bd71c4c', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 9, 'created': '2022-02-03 13:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5e8d8f91623c5aa4c294f1fcee0cfe31a6b177b1', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 10, 'created': '2022-02-03 14:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/451ad4b15535c71d2f466a5ab07a30d621ef6279', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 11, 'created': '2022-02-21 13:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/993cb7ab3fd8f4440e258317b9eb4b52af960121', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 12, 'created': '2022-02-21 13:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a963c08aa267e8463ca3ba2e21b700a66aa1db17', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}, {'number': 13, 'created': '2022-02-21 14:31:04.000000000', 'files': ['postgresql/Chart.yaml', 'postgresql/templates/bin/_start.sh.tpl', 'releasenotes/notes/postgresql.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a8a80db998fcc5e116943ebe335344ac31035570', 'message': 'Added pgcrypto extension\n\nChange-Id: Ia1c56d54583017bfec891568367cfce79e2df565\n'}]",7,824004,a8a80db998fcc5e116943ebe335344ac31035570,27,2,13,33696,,,0,"Added pgcrypto extension

Change-Id: Ia1c56d54583017bfec891568367cfce79e2df565
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/04/824004/1 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/Chart.yaml', 'postgresql/templates/bin/_start.sh.tpl', 'releasenotes/notes/postgresql.yaml']",3,880e1cd9a91999df7e2749c33603320404f2df82,, - 0.1.12 Added pgcrypto extension,,7,1
openstack%2Fopenstack-helm-infra~master~I394fad26274bdec6a51325d28e770a853aa8bacb,openstack/openstack-helm-infra,master,I394fad26274bdec6a51325d28e770a853aa8bacb,set the pgcrypto extension on postgresql,ABANDONED,2022-02-22 19:07:15.000000000,2022-11-10 17:51:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-22 19:07:15.000000000', 'files': ['helm-toolkit/templates/scripts/_db-pg-init.sh.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b7ae4c81ccd583c19d283505c3c674013f5ac190', 'message': 'set the pgcrypto extension on postgresql\n\nChange-Id: I394fad26274bdec6a51325d28e770a853aa8bacb\n'}]",0,830512,b7ae4c81ccd583c19d283505c3c674013f5ac190,4,1,1,33696,,,0,"set the pgcrypto extension on postgresql

Change-Id: I394fad26274bdec6a51325d28e770a853aa8bacb
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/12/830512/1 && git format-patch -1 --stdout FETCH_HEAD,"['helm-toolkit/templates/scripts/_db-pg-init.sh.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml']",3,b7ae4c81ccd583c19d283505c3c674013f5ac190,, - 0.2.33 Set the pgcrypto extension on postgresql,,5,1
openstack%2Fopenstack-helm-infra~master~I355484c01951556938cc9b1503ca77e8ece03d44,openstack/openstack-helm-infra,master,I355484c01951556938cc9b1503ca77e8ece03d44,Enable the pgcrypto extension on postgresql,ABANDONED,2022-02-28 10:45:55.000000000,2022-11-10 17:51:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-28 10:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4255f795cf7c7de992189f205c9a2fa00bfbf68b', 'message': 'Enable the pgcrypto extension on postgresql\n\nChange-Id: I355484c01951556938cc9b1503ca77e8ece03d44\n'}, {'number': 2, 'created': '2022-02-28 10:47:31.000000000', 'files': ['helm-toolkit/templates/scripts/_db-pg-init.sh.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bce8afc60949f8ef59a701a1c65808cfe0796aa8', 'message': 'Enable the pgcrypto extension on postgresql\n\nChange-Id: I355484c01951556938cc9b1503ca77e8ece03d44\n'}]",0,831195,bce8afc60949f8ef59a701a1c65808cfe0796aa8,4,1,2,33696,,,0,"Enable the pgcrypto extension on postgresql

Change-Id: I355484c01951556938cc9b1503ca77e8ece03d44
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/95/831195/2 && git format-patch -1 --stdout FETCH_HEAD,"['helm-toolkit/templates/scripts/_db-pg-init.sh.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml']",3,4255f795cf7c7de992189f205c9a2fa00bfbf68b,, - 0.2.34 Set the pgcrypto extension on postgresql,,5,1
openstack%2Fopenstack-helm-infra~master~I517e6511828f342a6c00bfe7718cc689b8980a37,openstack/openstack-helm-infra,master,I517e6511828f342a6c00bfe7718cc689b8980a37,[DNM/RFC] lipstick,ABANDONED,2022-03-15 22:27:16.000000000,2022-11-10 17:51:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-03-15 22:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/636f02d923d5ebfbc1af4ce822289cea590e1e60', 'message': ""[DNM/RFC] lipstick\n\nsome stylistic cleanups...  in doing this it's clear the scope of\nthese is such we might want to rethink/revisit how this script works\nentirely and it might be better to do that in the context of having\nwell validated tests in place\n\nChange-Id: I517e6511828f342a6c00bfe7718cc689b8980a37\n""}, {'number': 2, 'created': '2022-03-16 04:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/537ffe17b3920cc7e57fafdb5dc223e59bd664f7', 'message': ""[DNM/RFC] lipstick\n\nsome stylistic cleanups...  in doing this it's clear the scope of\nthese is such we might want to rethink/revisit how this script works\nentirely and it might be better to do that in the context of having\nwell validated tests in place\n\nChange-Id: I517e6511828f342a6c00bfe7718cc689b8980a37\n""}, {'number': 3, 'created': '2022-03-16 04:50:00.000000000', 'files': ['libvirt/Chart.yaml', 'libvirt/templates/bin/_libvirt.sh.tpl', 'releasenotes/notes/libvirt.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8a1945171a8aeae34744b07405abb1c2607d34c6', 'message': ""[DNM/RFC] lipstick\n\nsome stylistic cleanups...  in doing this it's clear the scope of\nthese is such we might want to rethink/revisit how this script works\nentirely and it might be better to do that in the context of having\nwell validated tests in place\n\nChange-Id: I517e6511828f342a6c00bfe7718cc689b8980a37\n""}]",0,833934,8a1945171a8aeae34744b07405abb1c2607d34c6,6,1,3,8898,,,0,"[DNM/RFC] lipstick

some stylistic cleanups...  in doing this it's clear the scope of
these is such we might want to rethink/revisit how this script works
entirely and it might be better to do that in the context of having
well validated tests in place

Change-Id: I517e6511828f342a6c00bfe7718cc689b8980a37
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/34/833934/3 && git format-patch -1 --stdout FETCH_HEAD,['libvirt/templates/bin/_libvirt.sh.tpl'],1,636f02d923d5ebfbc1af4ce822289cea590e1e60,lipstick,"# kill any running libvirtd pkill -x libvirtd || true sleep 1 rm -f /run/libvirtd.pid if [ -d /sys/fs/cgroup/${CGROUP} ]; then CGROUPS+=""${CGROUP},"" fihp_count=""$(grep HugePages_Total /proc/meminfo | tr -cd '[:digit:]')"" echo ""INFO: Detected hugepage count of '$hp_count'. Enabling hugepage settings for libvirt/qemu."" # Enable KVM hugepages for QEMU if [ -n ""$(grep KVM_HUGEPAGES=0 /etc/default/qemu-kvm)"" ]; then sed -i 's/.*KVM_HUGEPAGES=0.*/KVM_HUGEPAGES=1/g' /etc/default/qemu-kvm else echo KVM_HUGEPAGES=1 >> /etc/default/qemu-kvm fi # Ensure that the hugepage mount location is available/mapped inside the # container. This assumes use of the default ubuntu dev-hugepages.mount # systemd unit which mounts hugepages at this location. if [ ! -d /dev/hugepages ]; then echo ""ERROR: Hugepages configured in kernel, but libvirtd container cannot access /dev/hugepages"" exit 1 fi # Kubernetes 1.10.x introduced cgroup changes that caused the container's # hugepage byte limit quota to zero out. This workaround sets that pod limit # back to the total number of hugepage bytes available to the baremetal host. if [ -d /sys/fs/cgroup/hugetlb ]; then limits=""$(ls /sys/fs/cgroup/hugetlb/{{ .Values.conf.kubernetes.cgroup }}/hugetlb.*.limit_in_bytes)"" || \ (echo ""ERROR: Failed to locate any hugetable limits. Did you set the correct cgroup in your values used for this chart?"" exit 1) for limit in $limits; do target=""/sys/fs/cgroup/hugetlb/$(dirname $(awk -F: '($2~/hugetlb/){print $3}' /proc/self/cgroup))/$(basename $limit)"" # Ensure the write target for the hugepage limit for the pod exists if [ ! -f ""$target"" ]; then echo ""ERROR: Could not find write target for hugepage limit: $target"" fi # Write hugetable limit for pod cat ""$limit"" > ""$target"" done fi # Determine OS default hugepage size to use for the hugepage write test default_hp_kb=""$(grep Hugepagesize /proc/meminfo | tr -cd '[:digit:]')"" # Attempt to write to the hugepage mount to ensure it is operational, but only # if we have at least 1 free page. num_free_pages=$(tr -cd '[:digit:]' < ""/sys/kernel/mm/hugepages/hugepages-${default_hp_kb}kB/free_hugepages"") echo ""INFO: '$num_free_pages' free hugepages of size ${default_hp_kb}kB"" if [ 0""$num_free_pages"" -gt 0 ]; then (fallocate -o0 -l ""$default_hp_kb"" /dev/hugepages/foo && rm /dev/hugepages/foo) || \ (echo ""ERROR: fallocate failed test at /dev/hugepages with size ${default_hp_kb}kB"" rm /dev/hugepages/foo exit 1) fi #NOTE(portdirect): run libvirtd as a transient unit on the host with the osh-libvirt cgroups applied. cgexec -g ${CGROUPS%,}:/osh-libvirt systemd-run --scope --slice=system libvirtd --listen & tmpsecret=$(mktemp --suffix .xml) # Wait for the libvirtd is up TIMEOUT=60 while [[ ! -f /run/libvirtd.pid ]]; do if [[ ${TIMEOUT} -gt 0 ]]; then let TIMEOUT-=1 sleep 1 else echo ""ERROR: libvirt did not start in time (pid file missing)"" exit 1 fi done # Even though we see the pid file the socket immediately (this is # needed for virsh) TIMEOUT=10 while [[ ! -e /run/libvirt/libvirt-sock ]]; do if [[ ${TIMEOUT} -gt 0 ]]; then let TIMEOUT-=1 sleep 1 else echo ""ERROR: libvirt did not start in time (socket missing)"" exit 1 fi done function create_virsh_libvirt_secret { sec_user=$1 sec_uuid=$2 sec_ceph_keyring=$3 cat > ""${tmpsecret}"" <<EOF virsh secret-define --file ""${tmpsecret}"" virsh secret-set-value --secret ""${sec_uuid}"" --base64 ""${sec_ceph_keyring}"" } if [ -z ""${CEPH_CINDER_KEYRING}"" ] ; then CEPH_CINDER_KEYRING=$(awk '/key/{print $3}' ""/etc/ceph/ceph.client.${CEPH_CINDER_USER}.keyring"") fi create_virsh_libvirt_secret ""${CEPH_CINDER_USER}"" ""${LIBVIRT_CEPH_CINDER_SECRET_UUID}"" ""${CEPH_CINDER_KEYRING}"" if [ -n ""${LIBVIRT_EXTERNAL_CEPH_CINDER_SECRET_UUID}"" ] ; then EXTERNAL_CEPH_CINDER_KEYRING=$(cat /tmp/external-ceph-client-keyring) create_virsh_libvirt_secret ""${EXTERNAL_CEPH_CINDER_USER}"" ""${LIBVIRT_EXTERNAL_CEPH_CINDER_SECRET_UUID}"" ""${EXTERNAL_CEPH_CINDER_KEYRING}"" fi # kill libvirtd ; we needed it up to load secrets kill ""$(cat /run/libvirtd.pid)"" # delay long enough for it to terminate sleep 1","{{/* Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} if [ -n ""$(cat /proc/*/comm 2>/dev/null | grep -w libvirtd)"" ]; then set +x for proc in $(ls /proc/*/comm 2>/dev/null); do if [ ""x$(cat $proc 2>/dev/null | grep -w libvirtd)"" == ""xlibvirtd"" ]; then set -x libvirtpid=$(echo $proc | cut -f 3 -d '/') echo ""WARNING: libvirtd daemon already running on host"" 1>&2 echo ""$(cat ""/proc/${libvirtpid}/status"" 2>/dev/null | grep State)"" 1>&2 kill -9 ""$libvirtpid"" || true set +x fi done set -x fi rm -f /var/run/libvirtd.pid if [ -d /sys/fs/cgroup/${CGROUP} ]; then CGROUPS+=""${CGROUP},"" fihp_count=""$(cat /proc/meminfo | grep HugePages_Total | tr -cd '[:digit:]')"" echo ""INFO: Detected hugepage count of '$hp_count'. Enabling hugepage settings for libvirt/qemu."" # Enable KVM hugepages for QEMU if [ -n ""$(grep KVM_HUGEPAGES=0 /etc/default/qemu-kvm)"" ]; then sed -i 's/.*KVM_HUGEPAGES=0.*/KVM_HUGEPAGES=1/g' /etc/default/qemu-kvm else echo KVM_HUGEPAGES=1 >> /etc/default/qemu-kvm fi # Ensure that the hugepage mount location is available/mapped inside the # container. This assumes use of the default ubuntu dev-hugepages.mount # systemd unit which mounts hugepages at this location. if [ ! -d /dev/hugepages ]; then echo ""ERROR: Hugepages configured in kernel, but libvirtd container cannot access /dev/hugepages"" exit 1 fi # Kubernetes 1.10.x introduced cgroup changes that caused the container's # hugepage byte limit quota to zero out. This workaround sets that pod limit # back to the total number of hugepage bytes available to the baremetal host. if [ -d /sys/fs/cgroup/hugetlb ]; then limits=""$(ls /sys/fs/cgroup/hugetlb/{{ .Values.conf.kubernetes.cgroup }}/hugetlb.*.limit_in_bytes)"" || \ (echo ""ERROR: Failed to locate any hugetable limits. Did you set the correct cgroup in your values used for this chart?"" exit 1) for limit in $limits; do target=""/sys/fs/cgroup/hugetlb/$(dirname $(awk -F: '($2~/hugetlb/){print $3}' /proc/self/cgroup))/$(basename $limit)"" # Ensure the write target for the hugepage limit for the pod exists if [ ! -f ""$target"" ]; then echo ""ERROR: Could not find write target for hugepage limit: $target"" fi # Write hugetable limit for pod echo ""$(cat $limit)"" > ""$target"" done fi # Determine OS default hugepage size to use for the hugepage write test default_hp_kb=""$(cat /proc/meminfo | grep Hugepagesize | tr -cd '[:digit:]')"" # Attempt to write to the hugepage mount to ensure it is operational, but only # if we have at least 1 free page. num_free_pages=""$(cat /sys/kernel/mm/hugepages/hugepages-${default_hp_kb}kB/free_hugepages | tr -cd '[:digit:]')"" echo ""INFO: '$num_free_pages' free hugepages of size ${default_hp_kb}kB"" if [ 0""$num_free_pages"" -gt 0 ]; then (fallocate -o0 -l ""$default_hp_kb"" /dev/hugepages/foo && rm /dev/hugepages/foo) || \ (echo ""ERROR: fallocate failed test at /dev/hugepages with size ${default_hp_kb}kB"" rm /dev/hugepages/foo exit 1) fi #NOTE(portdirect): run libvirtd as a transient unit on the host with the osh-libvirt cgroups applied. cgexec -g ${CGROUPS%,}:/osh-libvirt systemd-run --scope --slice=system libvirtd --listen & tmpsecret=$(mktemp --suffix .xml) if [ -n ""${LIBVIRT_EXTERNAL_CEPH_CINDER_SECRET_UUID}"" ] ; then tmpsecret2=$(mktemp --suffix .xml) fi function cleanup { rm -f ""${tmpsecret}"" if [ -n ""${LIBVIRT_EXTERNAL_CEPH_CINDER_SECRET_UUID}"" ] ; then rm -f ""${tmpsecret2}"" fi } trap cleanup EXIT # Wait for the libvirtd is up TIMEOUT=60 while [[ ! -f /var/run/libvirtd.pid ]]; do if [[ ${TIMEOUT} -gt 0 ]]; then let TIMEOUT-=1 sleep 1 else echo ""ERROR: libvirt did not start in time (pid file missing)"" exit 1 fi done # Even though we see the pid file the socket immediately (this is # needed for virsh) TIMEOUT=10 while [[ ! -e /var/run/libvirt/libvirt-sock ]]; do if [[ ${TIMEOUT} -gt 0 ]]; then let TIMEOUT-=1 sleep 1 else echo ""ERROR: libvirt did not start in time (socket missing)"" exit 1 fi done function create_virsh_libvirt_secret { sec_user=$1 sec_uuid=$2 sec_ceph_keyring=$3 cat > ${tmpsecret} <<EOF virsh secret-define --file ${tmpsecret} virsh secret-set-value --secret ""${sec_uuid}"" --base64 ""${sec_ceph_keyring}"" } if [ -z ""${CEPH_CINDER_KEYRING}"" ] ; then CEPH_CINDER_KEYRING=$(awk '/key/{print $3}' /etc/ceph/ceph.client.${CEPH_CINDER_USER}.keyring) fi create_virsh_libvirt_secret ${CEPH_CINDER_USER} ${LIBVIRT_CEPH_CINDER_SECRET_UUID} ${CEPH_CINDER_KEYRING} if [ -n ""${LIBVIRT_EXTERNAL_CEPH_CINDER_SECRET_UUID}"" ] ; then EXTERNAL_CEPH_CINDER_KEYRING=$(cat /tmp/external-ceph-client-keyring) create_virsh_libvirt_secret ${EXTERNAL_CEPH_CINDER_USER} ${LIBVIRT_EXTERNAL_CEPH_CINDER_SECRET_UUID} ${EXTERNAL_CEPH_CINDER_KEYRING} fi # kill libvirtd ; we needed it up to load secrets kill $(cat /run/libvirtd.pid) # delay long enough for it to terminate sleep 1",98,133
openstack%2Fopenstack-helm-infra~master~I3b96c688030b581d94348990b30922eced2e3047,openstack/openstack-helm-infra,master,I3b96c688030b581d94348990b30922eced2e3047,[libvirt] 'exec' to libvirtd even when using secrets,ABANDONED,2022-03-15 22:00:31.000000000,2022-11-10 17:51:42.000000000,,"[{'_account_id': 22348}, {'_account_id': 26686}]","[{'number': 1, 'created': '2022-03-15 22:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0163ce99d0034873e04ec37a05f03603c8739ce3', 'message': '[libvirt] \'exec\' to libvirtd even when using secrets\n\nwhen ""hostPid: true"" we don\'t want the entrypoint process (pid) to be\ndecoupled from libvirtd as breaks libvirtd restarting\n\nthe fix for now is\n\n  * start libvirtd\n  * inject secrets\n  * kill it\n\nthen start it again using \'exec\' so the libvirtd is the entrypoint pid\nand container lifesystem should work as expected\n\nChange-Id: I3b96c688030b581d94348990b30922eced2e3047\n'}, {'number': 2, 'created': '2022-03-16 04:45:44.000000000', 'files': ['libvirt/Chart.yaml', 'libvirt/templates/bin/_libvirt.sh.tpl', 'releasenotes/notes/libvirt.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5e4cf86d8f911e875a16d5fc5ead6760b4eb87b8', 'message': '[libvirt] \'exec\' to libvirtd even when using secrets\n\nwhen ""hostPid: true"" we don\'t want the entrypoint process (pid) to be\ndecoupled from libvirtd as breaks libvirtd restarting\n\nthe fix for now is\n\n  * start libvirtd\n  * inject secrets\n  * kill it\n\nthen start it again using \'exec\' so the libvirtd is the entrypoint pid\nand container lifesystem should work as expected\n\nChange-Id: I3b96c688030b581d94348990b30922eced2e3047\n'}]",0,833927,5e4cf86d8f911e875a16d5fc5ead6760b4eb87b8,6,2,2,8898,,,0,"[libvirt] 'exec' to libvirtd even when using secrets

when ""hostPid: true"" we don't want the entrypoint process (pid) to be
decoupled from libvirtd as breaks libvirtd restarting

the fix for now is

  * start libvirtd
  * inject secrets
  * kill it

then start it again using 'exec' so the libvirtd is the entrypoint pid
and container lifesystem should work as expected

Change-Id: I3b96c688030b581d94348990b30922eced2e3047
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/27/833927/2 && git format-patch -1 --stdout FETCH_HEAD,['libvirt/templates/bin/_libvirt.sh.tpl'],1,0163ce99d0034873e04ec37a05f03603c8739ce3,libvirt-pid-wrapper," # kill libvirtd ; we needed it up to load secrets kill $(cat /run/libvirtd.pid) # delay long enough for it to terminate sleep 1 #NOTE(portdirect): run libvirtd as a transient unit on the host with the osh-libvirt cgroups applied. exec cgexec -g ${CGROUPS%,}:/osh-libvirt systemd-run --scope --slice=system libvirtd --listen"," # rejoin libvirtd wait else #NOTE(portdirect): run libvirtd as a transient unit on the host with the osh-libvirt cgroups applied. exec cgexec -g ${CGROUPS%,}:/osh-libvirt systemd-run --scope --slice=system libvirtd --listen",7,5
openstack%2Fopenstack-helm-infra~master~Id15e97fb3b4bdcfe9565847738b4c3355ea261b8,openstack/openstack-helm-infra,master,Id15e97fb3b4bdcfe9565847738b4c3355ea261b8,[mariadb] Allow (simpler) unclustered operation.,ABANDONED,2022-03-18 03:09:14.000000000,2022-11-10 17:51:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-03-18 03:09:14.000000000', 'files': ['mariadb/README.rst', 'mariadb/values.yaml', 'mariadb/templates/bin/_readiness.sh.tpl', 'mariadb/templates/statefulset.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/79c547ee049c6c9e09c939d05c435d202af0af03', 'message': '[mariadb] Allow (simpler) unclustered operation.\n\nChange-Id: Id15e97fb3b4bdcfe9565847738b4c3355ea261b8\n'}]",0,834255,79c547ee049c6c9e09c939d05c435d202af0af03,3,1,1,8898,,,0,"[mariadb] Allow (simpler) unclustered operation.

Change-Id: Id15e97fb3b4bdcfe9565847738b4c3355ea261b8
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/55/834255/1 && git format-patch -1 --stdout FETCH_HEAD,"['mariadb/README.rst', 'mariadb/values.yaml', 'mariadb/templates/bin/_readiness.sh.tpl', 'mariadb/templates/statefulset.yaml']",4,79c547ee049c6c9e09c939d05c435d202af0af03,, {{- if le ( .Values.pod.replicas.server | int ) 1 }} # Needed when using the standard/upstream entrypoint - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: mariadb-dbadmin-password key: MYSQL_DBADMIN_PASSWORD {{- end }} {{- if gt ( .Values.pod.replicas.server | int ) 1 }} {{- end }},,46,11
openstack%2Fopenstack-helm~master~I58b9a76c994aa82c75fec825f0ea48b5b8b720c7,openstack/openstack-helm,master,I58b9a76c994aa82c75fec825f0ea48b5b8b720c7,Set wsgi daemon workers count to 1 in default,ABANDONED,2021-07-28 10:12:57.000000000,2022-11-10 17:51:39.000000000,,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 24780}]","[{'number': 1, 'created': '2021-07-28 10:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/13ae731e93603e1fafb1c43e7f3d828aa72f38b4', 'message': 'Set wsgi daemon workers count to 1 in default\n\nAs in default wsgi daemon workers count is 5, it is set to 1 so as to run one process per pod. For this approach, we will be scale the pod based on one process per pod to the required amount of replicas\n\nChange-Id: I58b9a76c994aa82c75fec825f0ea48b5b8b720c7\n'}, {'number': 2, 'created': '2021-08-03 08:10:35.000000000', 'files': ['horizon/Chart.yaml', 'releasenotes/notes/horizon.yaml', 'horizon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a42b793fdf7aeb58bfde8afadd039e8d03f09b50', 'message': 'Set wsgi daemon workers count to 1 in default\n\nAs in default wsgi daemon workers count is 5, it is set to 1 so as to run one process per pod. For this approach, we will be scale the pod based on one process per pod to the required amount of replicas and apart from this, this change is to maintain the consistency among all the modules with the worker count of 1.\n\nChange-Id: I58b9a76c994aa82c75fec825f0ea48b5b8b720c7\n'}]",0,802677,a42b793fdf7aeb58bfde8afadd039e8d03f09b50,13,4,2,33130,,,0,"Set wsgi daemon workers count to 1 in default

As in default wsgi daemon workers count is 5, it is set to 1 so as to run one process per pod. For this approach, we will be scale the pod based on one process per pod to the required amount of replicas and apart from this, this change is to maintain the consistency among all the modules with the worker count of 1.

Change-Id: I58b9a76c994aa82c75fec825f0ea48b5b8b720c7
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/77/802677/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/Chart.yaml', 'releasenotes/notes/horizon.yaml', 'horizon/values.yaml']",3,13ae731e93603e1fafb1c43e7f3d828aa72f38b4,horizon-default-workers, WSGIDaemonProcess horizon-http processes=1 threads=1 user=horizon group=horizon display-name=%{GROUP} python-path=/var/lib/kolla/venv/lib/python2.7/site-packages, WSGIDaemonProcess horizon-http processes=5 threads=1 user=horizon group=horizon display-name=%{GROUP} python-path=/var/lib/kolla/venv/lib/python2.7/site-packages,3,2
openstack%2Fopenstack-helm~master~I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd,openstack/openstack-helm,master,I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd,Update Octavia helm charts,ABANDONED,2019-11-01 09:10:10.000000000,2022-11-10 17:51:39.000000000,,"[{'_account_id': 7249}, {'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 9542}, {'_account_id': 14525}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-01 09:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5e6aecb3c97ea9603c8338adcbffdbacc90ec534', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 2, 'created': '2019-11-01 09:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6f9e8139f1551499d1e5a57864d873b8660eef03', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 3, 'created': '2019-11-01 11:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9670cfb4b6056cea83cb347300ed8f52a428a43a', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 4, 'created': '2019-11-01 11:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fb450ed0c801f50197d9ed84eed29d417df731e7', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 5, 'created': '2019-11-01 12:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0cd95d27b93d6198ea5bb16666ed7aa0f33eeb7f', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 6, 'created': '2019-11-05 11:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a80be3f331bea2440939d8c2c132c97f5a1ac7ac', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 7, 'created': '2019-11-05 11:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ecc43498692676b10b769d5e0a3b5d08c693281c', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 8, 'created': '2019-11-08 09:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/20270e13be75d6df7dda6ed970afba7b6a8b17ca', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 9, 'created': '2019-11-11 11:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8fed40631cda4818f182ea164b87be2acaedfbb2', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 10, 'created': '2019-11-21 16:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/630b60746107d3c81895cc06f9b1b5ebc7cde029', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 11, 'created': '2019-12-19 08:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/005c2c6161e6a5d2d115f166f5aec81660cf2921', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 12, 'created': '2019-12-24 12:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d63d5a12174332e8ef84cf9a620010300b59ad78', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 13, 'created': '2020-04-01 08:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b90f89c130ed3be1f7bade414a7d931d7d4adc3f', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 14, 'created': '2020-04-17 06:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a49878a18a5b559a870e1d17881e454078393779', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 15, 'created': '2020-05-20 23:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b20953f4338589281ccb8c4967f34727f3ef3976', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 16, 'created': '2020-05-21 06:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/35b94c8e05c28b82ffde3e30724af80c21733cf0', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 17, 'created': '2020-06-10 19:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7e5105e87531856bd5bf674f563922de2ba3c7b1', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 18, 'created': '2020-06-11 12:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6185c0e208457c6864ff5f9da3e75651f65d5846', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 19, 'created': '2020-11-24 04:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/23d06406d883f1ff0d86f5b4bd98d5db6e6b9c1b', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 20, 'created': '2021-01-12 08:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5c485837f0fccd568c891bcbab291d211a5db040', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 21, 'created': '2021-01-12 09:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8cd6913d4f8f8a64e2280841007e8624058f98fc', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nDepends-On: https://review.opendev.org/#/c/671727\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 22, 'created': '2021-06-08 12:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/40f8bfdff060637a1ca11684c55fee9bda35ee8e', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 23, 'created': '2021-07-08 05:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/355dbbdac06d6f1d3143c7b9003e441660c3a4ce', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 24, 'created': '2021-07-08 07:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b1bb80a84da5a89c8480db592fbc9c02642bac57', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}, {'number': 25, 'created': '2022-03-28 12:05:39.000000000', 'files': ['octavia/templates/secret-octavia-certs.yml', 'octavia/templates/bin/_octavia-housekeeping.sh.tpl', 'octavia/templates/job-create-octavia-resources.yml', 'octavia/templates/bin/_octavia-worker.sh.tpl', 'octavia/templates/bin/_octavia-health-manager.sh.tpl', 'octavia/templates/configmap-bin.yaml', 'octavia/templates/daemonset-health-manager.yaml', 'octavia/values.yaml', 'octavia/templates/bin/_octavia-health-manager-nic-init.sh.tpl', 'octavia/templates/bin/_create_octavia_resources.sh.tpl', 'octavia/Chart.yaml', 'releasenotes/notes/octavia.yaml', 'octavia/templates/deployment-housekeeping.yaml', 'octavia/templates/secret-amphora-ssh-key.yml', 'octavia/templates/deployment-worker.yaml', 'tools/deployment/developer/common/200-octavia.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/82f485e7dfb0d86b3e17711efad213f3cc9a43bb', 'message': 'Update Octavia helm charts\n\nIntroduces:\n\n* job create_octavia_resources which create all openstack resources\nrequired for starting Octavia services. it saves ids to configmap\nwhich is passed as additional config file on services start.\n* add possibility to generate certificate for amphora in charts\n* fix affinity rules for octavia-worker and octavia-housekeeping\n(run pods only on nodes where octavia-healthmanager is runnig)\n* improved generation dhclient config for o-hm0 port.\n\nChange-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd\n'}]",13,692517,82f485e7dfb0d86b3e17711efad213f3cc9a43bb,80,6,25,7249,,,0,"Update Octavia helm charts

Introduces:

* job create_octavia_resources which create all openstack resources
required for starting Octavia services. it saves ids to configmap
which is passed as additional config file on services start.
* add possibility to generate certificate for amphora in charts
* fix affinity rules for octavia-worker and octavia-housekeeping
(run pods only on nodes where octavia-healthmanager is runnig)
* improved generation dhclient config for o-hm0 port.

Change-Id: I2ec7963b54bf2a8b5ad81e14e39c5bc16a213abd
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/17/692517/21 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/templates/secret-octavia-certs.yml', 'octavia/templates/bin/_octavia-housekeeping.sh.tpl', 'octavia/templates/job-create-octavia-resources.yml', 'octavia/templates/bin/_octavia-api.sh.tpl', 'octavia/templates/bin/_octavia-worker.sh.tpl', 'octavia/templates/bin/_octavia-health-manager.sh.tpl', 'octavia/templates/configmap-bin.yaml', 'octavia/templates/daemonset-health-manager.yaml', 'octavia/values.yaml', 'octavia/templates/bin/_octavia-health-manager-nic-init.sh.tpl', 'octavia/templates/bin/_create_octavia_resources.sh.tpl', 'octavia/templates/deployment-housekeeping.yaml', 'octavia/templates/secret-amphora-ssh-key.yml', 'octavia/templates/deployment-worker.yaml']",14,5e6aecb3c97ea9603c8338adcbffdbacc90ec534,692517, podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: component operator: In values: - health_manager topologyKey: kubernetes.io/hostname - name: octavia-settings mountPath: /etc/octavia/updated_conf - name: octavia-settings configMap: name: octavia-settings defaultMode: 0444{{- end }} ,{{- end }},533,45
openstack%2Fopenstack-helm~master~I46a8a3ce38a622b99ccb409089e17bd6f78c4052,openstack/openstack-helm,master,I46a8a3ce38a622b99ccb409089e17bd6f78c4052,Set default workers to one by default,ABANDONED,2021-07-28 09:16:52.000000000,2022-11-10 17:51:38.000000000,,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2021-07-28 09:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e6537f45a4fb730e86dab684187ce208029743c6', 'message': 'Set default workers to one by default\n\nAs of now wsgi daemon has default process count 4. It has been changed to 1 so as to maintain one process per pod.\n\nChange-Id: I46a8a3ce38a622b99ccb409089e17bd6f78c4052\n'}, {'number': 2, 'created': '2021-08-03 08:19:23.000000000', 'files': ['placement/values.yaml', 'releasenotes/notes/placement.yaml', 'placement/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4dba0498011f5f30573680a651fefbfd13a517be', 'message': 'Set default workers to one by default\n\nAs of now wsgi daemon has default process count 4. It has been changed to 1 so as to maintain one process per pod and have the consistent number of the worker process 1 accross all the modules.\n\nChange-Id: I46a8a3ce38a622b99ccb409089e17bd6f78c4052\n'}]",2,802672,4dba0498011f5f30573680a651fefbfd13a517be,25,4,2,33130,,,0,"Set default workers to one by default

As of now wsgi daemon has default process count 4. It has been changed to 1 so as to maintain one process per pod and have the consistent number of the worker process 1 accross all the modules.

Change-Id: I46a8a3ce38a622b99ccb409089e17bd6f78c4052
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/72/802672/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/values.yaml', 'releasenotes/notes/placement.yaml', 'placement/Chart.yaml']",3,e6537f45a4fb730e86dab684187ce208029743c6,placement-default-workers,version: 0.2.2,version: 0.2.1,3,2
openstack%2Fopenstack-helm~master~I7103d2ae77bec442790a0bbed3aac53fe1e7641e,openstack/openstack-helm,master,I7103d2ae77bec442790a0bbed3aac53fe1e7641e,Replace deprecated Nova VNC configurations,ABANDONED,2022-01-12 20:47:35.000000000,2022-11-10 17:51:37.000000000,,"[{'_account_id': 8898}, {'_account_id': 14675}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 32349}, {'_account_id': 33390}, {'_account_id': 33594}, {'_account_id': 33987}, {'_account_id': 34255}]","[{'number': 1, 'created': '2022-01-12 20:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/20ccb7ddeb5ce5209011ab921ad54c6ad12bdfae', 'message': 'Replace deprecated Nova VNC configurations\n\nReplace deprecated opts of Nova VNC Server configurations.\n\nSigned-off-by: Iago Estrela <IagoFilipe.EstrelaBarros@windriver.com>\nChange-Id: I7103d2ae77bec442790a0bbed3aac53fe1e7641e\n'}, {'number': 2, 'created': '2022-01-24 13:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/506df43041a98099e1c17818e032dc7c43c0fe1c', 'message': 'Replace deprecated Nova VNC configurations\n\nReplace deprecated opts of Nova VNC Server configurations.\n\nSigned-off-by: Iago Estrela <IagoFilipe.EstrelaBarros@windriver.com>\nChange-Id: I7103d2ae77bec442790a0bbed3aac53fe1e7641e\n'}, {'number': 3, 'created': '2022-02-07 17:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/51624fabecfc8b3967a77db7e4404e19a64f68c1', 'message': 'Replace deprecated Nova VNC configurations\n\nReplace deprecated opts of Nova VNC Server configurations.\n\nSigned-off-by: Iago Estrela <IagoFilipe.EstrelaBarros@windriver.com>\nChange-Id: I7103d2ae77bec442790a0bbed3aac53fe1e7641e\n'}, {'number': 4, 'created': '2022-02-07 22:52:32.000000000', 'files': ['nova/templates/bin/_nova-console-proxy-init.sh.tpl', 'nova/values.yaml', 'releasenotes/notes/nova.yaml', 'nova/templates/bin/_nova-console-compute-init.sh.tpl', 'nova/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ebcfd6f77e2fb377fa24256a13bd926f19eae20f', 'message': 'Replace deprecated Nova VNC configurations\n\nReplace deprecated opts of Nova VNC Server configurations.\n\nSigned-off-by: Iago Estrela <IagoFilipe.EstrelaBarros@windriver.com>\nChange-Id: I7103d2ae77bec442790a0bbed3aac53fe1e7641e\n'}]",6,824481,ebcfd6f77e2fb377fa24256a13bd926f19eae20f,26,9,4,33410,,,0,"Replace deprecated Nova VNC configurations

Replace deprecated opts of Nova VNC Server configurations.

Signed-off-by: Iago Estrela <IagoFilipe.EstrelaBarros@windriver.com>
Change-Id: I7103d2ae77bec442790a0bbed3aac53fe1e7641e
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/81/824481/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/templates/bin/_nova-console-proxy-init.sh.tpl', 'nova/values.yaml', 'releasenotes/notes/nova.yaml', 'nova/templates/bin/_nova-console-compute-init.sh.tpl', 'nova/Chart.yaml']",5,20ccb7ddeb5ce5209011ab921ad54c6ad12bdfae,story/2009783,version: 0.2.26,version: 0.2.25,8,7
openstack%2Fopenstack-helm-infra~master~I121326722c75a8cbc25513d23f25d367eaef9deb,openstack/openstack-helm-infra,master,I121326722c75a8cbc25513d23f25d367eaef9deb,Update helm-template for subchart compatibility,ABANDONED,2022-04-25 02:59:43.000000000,2022-11-10 17:51:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-04-25 02:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/67e8463cad67b8ed7564a37450a033c610c574eb', 'message': 'Update helm-template for subchart compatibility\n\nChange-Id: I121326722c75a8cbc25513d23f25d367eaef9deb\n'}, {'number': 2, 'created': '2022-04-25 03:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ae835aa27312462a6da9231d08f0d35b24eda691', 'message': 'Update helm-template for subchart compatibility\n\nChange-Id: I121326722c75a8cbc25513d23f25d367eaef9deb\n'}, {'number': 3, 'created': '2022-04-25 03:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/94abce5bd580f2c318a833557b6b5fe190234083', 'message': 'Update helm-template for subchart compatibility\n\nChange-Id: I121326722c75a8cbc25513d23f25d367eaef9deb\n'}, {'number': 4, 'created': '2022-04-25 16:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/31cd1a792faee8996374db7faa056ccbeeca2041', 'message': 'Update helm-template for subchart compatibility\n\nChange-Id: I121326722c75a8cbc25513d23f25d367eaef9deb\n'}, {'number': 5, 'created': '2022-04-27 15:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/be9e3aa758093349cf2c0122e437c431e0b743a1', 'message': 'Update helm-template for subchart compatibility\n\nChange-Id: I121326722c75a8cbc25513d23f25d367eaef9deb\n'}, {'number': 6, 'created': '2022-05-13 19:05:50.000000000', 'files': ['helm-toolkit/templates/utils/_to_k8s_env_secret_vars.tpl', 'helm-toolkit/templates/snippets/_kubernetes_apparmor_volumes.tpl', 'helm-toolkit/templates/snippets/_kubernetes_pod_anti_affinity.tpl', 'helm-toolkit/templates/snippets/_kubernetes_apparmor_configmap.tpl', 'helm-toolkit/templates/snippets/_kubernetes_pod_rbac_roles.tpl', 'helm-toolkit/templates/snippets/_values_template_renderer.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bb79b18e1816883d2272a308301cdbd4460c994b', 'message': 'Update helm-template for subchart compatibility\n\nChange-Id: I121326722c75a8cbc25513d23f25d367eaef9deb\n'}]",1,839146,bb79b18e1816883d2272a308301cdbd4460c994b,13,1,6,32090,,,0,"Update helm-template for subchart compatibility

Change-Id: I121326722c75a8cbc25513d23f25d367eaef9deb
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/46/839146/1 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/snippets/_kubernetes_pod_rbac_roles.tpl'],1,67e8463cad67b8ed7564a37450a033c610c574eb,,{{- if ($envAll.Values.global).subchart_release_name }} {{ $releaseName = $envAll.Chart.Name }} {{- end }},,3,0
openstack%2Fopenstack-helm~master~Icba71a3946368a89a75e26d8d851443fd8afc58a,openstack/openstack-helm,master,Icba71a3946368a89a75e26d8d851443fd8afc58a,WIP enable yoga job,ABANDONED,2022-06-21 18:10:52.000000000,2022-11-10 17:51:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-06-21 18:10:52.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/99ad88871cd435cade1750647601628d07b1d414', 'message': 'WIP enable yoga job\n\nChange-Id: Icba71a3946368a89a75e26d8d851443fd8afc58a\n'}]",0,847077,99ad88871cd435cade1750647601628d07b1d414,3,1,1,28701,,,0,"WIP enable yoga job

Change-Id: Icba71a3946368a89a75e26d8d851443fd8afc58a
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/77/847077/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,99ad88871cd435cade1750647601628d07b1d414,, - openstack-helm-compute-kit-yoga-ubuntu_focal, # TODO(gagehugo): Fix and enable this job # - openstack-helm-compute-kit-yoga-ubuntu_focal,1,2
openstack%2Fopenstack-helm~master~Ib11db11d41782f9635f4ad4823fcca4065fb9fca,openstack/openstack-helm,master,Ib11db11d41782f9635f4ad4823fcca4065fb9fca,Add helm hook for bootstrap job in nova,ABANDONED,2022-07-06 10:25:54.000000000,2022-11-10 17:51:34.000000000,,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-07-06 10:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/43145c73264d31214dc7498c96b85424371755b9', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 2, 'created': '2022-07-07 06:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bec6d0a7e387aeb1e414dc9b3d72f913dee3ffd1', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 3, 'created': '2022-07-07 07:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/424e1b17b167d8ae2197b6bdf6e2bc1416586962', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 4, 'created': '2022-07-07 10:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/98e7a3417ac013d7e895d3bd910a6b919695ad85', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 5, 'created': '2022-07-08 08:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/727d35fe1f4b5d0a8f241a5bb1a5d98b7fd5843a', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 6, 'created': '2022-07-08 09:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2b5affd8d2fae6668e0a3e29f4636ef591473eb8', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 7, 'created': '2022-07-08 13:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1dd7961cd6bbd878cd848c63add50a1762ebfb3e', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}, {'number': 8, 'created': '2022-07-13 08:39:04.000000000', 'files': ['tools/deployment/component/compute-kit/compute-kit.sh', 'nova/templates/job-bootstrap.yaml', 'releasenotes/notes/nova.yaml', 'nova/templates/job-cell-setup.yaml', 'nova/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9ab1e630a50e130d1aff3ec83b4cdbabca47c862', 'message': 'Add helm hook for bootstrap job in nova\n\nChange-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca\n'}]",3,848832,9ab1e630a50e130d1aff3ec83b4cdbabca47c862,20,2,8,31746,,,0,"Add helm hook for bootstrap job in nova

Change-Id: Ib11db11d41782f9635f4ad4823fcca4065fb9fca
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/32/848832/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/templates/job-bootstrap.yaml', 'releasenotes/notes/nova.yaml', 'nova/Chart.yaml']",3,43145c73264d31214dc7498c96b85424371755b9,,version: 0.2.42,version: 0.2.41,6,1
openstack%2Fopenstack-helm~master~I2e1224af93ddef004fedcaee7a9813356377b47a,openstack/openstack-helm,master,I2e1224af93ddef004fedcaee7a9813356377b47a,add job to delete jobs before upgrading openstack,ABANDONED,2022-07-04 19:32:01.000000000,2022-11-10 17:51:33.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-07-04 19:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/326d206f5440f99ef2c76383ed17eb9c8834ea55', 'message': ""add job to delete jobs before upgrading openstack\n\nBefore this change, performing an upgrade that caused the jobs\nto need to be modified resulted in an helm upgrade error due to\ntrying to change an immutable field.\n\nNow, create a Job on pre-upgrade only to delete all successfullly\ncompleted jobs in the namespace the OpenStack Umbreall Helm\nchart is released in.\n\nThis approach was taken because\n1. Can't rely on hooks for post-install,post-upgrade to delete jobs\n   because a cyclic dependency will exist [1]\n2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted\n   before other pods' kubernetes-entrypoint sees the job completed\n\n1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4\n\nChange-Id: I2e1224af93ddef004fedcaee7a9813356377b47a\n""}, {'number': 2, 'created': '2022-07-05 14:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d4f91a05642eafb4742bd78d4fc23bcd8e07b6cf', 'message': ""add job to delete jobs before upgrading openstack\n\nBefore this change, performing an upgrade that caused the jobs\nto need to be modified resulted in an helm upgrade error due to\ntrying to change an immutable field.\n\nNow, create a Job on pre-upgrade only to delete all successfullly\ncompleted jobs in the namespace the OpenStack Umbreall Helm\nchart is released in.\n\nThis approach was taken because\n1. Can't rely on hooks for post-install,post-upgrade to delete jobs\n   because a cyclic dependency will exist [1]\n2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted\n   before other pods' kubernetes-entrypoint sees the job completed\n\n1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4\n\nChange-Id: I2e1224af93ddef004fedcaee7a9813356377b47a\n""}, {'number': 3, 'created': '2022-07-07 19:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9ac0c6c55a7a8f1798c22aafd52f1238fc1abec7', 'message': ""add job to delete jobs before upgrading openstack\n\nBefore this change, performing an upgrade that caused the jobs\nto need to be modified resulted in an helm upgrade error due to\ntrying to change an immutable field.\n\nNow, create a Job on pre-upgrade only to delete all successfullly\ncompleted jobs in the namespace the OpenStack Umbreall Helm\nchart is released in.\n\nThis approach was taken because\n1. Can't rely on hooks for post-install,post-upgrade to delete jobs\n   because a cyclic dependency will exist [1]\n2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted\n   before other pods' kubernetes-entrypoint sees the job completed\n\n1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4\n\nChange-Id: I2e1224af93ddef004fedcaee7a9813356377b47a\nDepends-On: I40798248c7778cb74e722b741cc728a84cf89b9c\n""}, {'number': 4, 'created': '2022-07-11 14:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/517c654b4a00a4dc9bd6cbc84bfe61037c6153cf', 'message': ""add job to delete jobs before upgrading openstack\n\nBefore this change, performing an upgrade that caused the jobs\nto need to be modified resulted in an helm upgrade error due to\ntrying to change an immutable field.\n\nNow, create a Job on pre-upgrade only to delete all successfullly\ncompleted jobs in the namespace the OpenStack Umbreall Helm\nchart is released in.\n\nThis approach was taken because\n1. Can't rely on hooks for post-install,post-upgrade to delete jobs\n   because a cyclic dependency will exist [1]\n2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted\n   before other pods' kubernetes-entrypoint sees the job completed\n\n1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4\n\nChange-Id: I2e1224af93ddef004fedcaee7a9813356377b47a\nDepends-On: I40798248c7778cb74e722b741cc728a84cf89b9c\n""}, {'number': 5, 'created': '2022-07-11 14:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9784ac3043a730cbc92886fb78979f65f1d82e32', 'message': ""add job to delete jobs before upgrading openstack\n\nBefore this change, performing an upgrade that caused the jobs\nto need to be modified resulted in an helm upgrade error due to\ntrying to change an immutable field.\n\nNow, create a Job on pre-upgrade only to delete all successfullly\ncompleted jobs in the namespace the OpenStack Umbreall Helm\nchart is released in.\n\nThis approach was taken because\n1. Can't rely on hooks for post-install,post-upgrade to delete jobs\n   because a cyclic dependency will exist [1]\n2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted\n   before other pods' kubernetes-entrypoint sees the job completed\n\n1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4\n\nChange-Id: I2e1224af93ddef004fedcaee7a9813356377b47a\nDepends-On: I40798248c7778cb74e722b741cc728a84cf89b9c\n""}, {'number': 6, 'created': '2022-07-27 14:03:04.000000000', 'files': ['openstack/values.yaml', 'openstack/templates/job-delete-successful-jobs.yaml', 'releasenotes/notes/openstack.yaml', 'openstack/templates/configmap-bin.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3bf4a028d472318dc26599f12122fc40d875167e', 'message': ""add job to delete jobs before upgrading openstack\n\nBefore this change, performing an upgrade that caused the jobs\nto need to be modified resulted in an helm upgrade error due to\ntrying to change an immutable field.\n\nNow, create a Job on pre-upgrade only to delete all successfullly\ncompleted jobs in the namespace the OpenStack Umbreall Helm\nchart is released in.\n\nThis approach was taken because\n1. Can't rely on hooks for post-install,post-upgrade to delete jobs\n   because a cyclic dependency will exist [1]\n2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted\n   before other pods' kubernetes-entrypoint sees the job completed\n\n1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4\n\nChange-Id: I2e1224af93ddef004fedcaee7a9813356377b47a\nDepends-On: I40798248c7778cb74e722b741cc728a84cf89b9c\n""}]",10,848668,3bf4a028d472318dc26599f12122fc40d875167e,29,1,6,28701,,,0,"add job to delete jobs before upgrading openstack

Before this change, performing an upgrade that caused the jobs
to need to be modified resulted in an helm upgrade error due to
trying to change an immutable field.

Now, create a Job on pre-upgrade only to delete all successfullly
completed jobs in the namespace the OpenStack Umbreall Helm
chart is released in.

This approach was taken because
1. Can't rely on hooks for post-install,post-upgrade to delete jobs
   because a cyclic dependency will exist [1]
2. Can't use job's ttlSecondsAfterFinished because the jobs are deleted
   before other pods' kubernetes-entrypoint sees the job completed

1 - https://opendev.org/openstack/openstack-helm/src/commit/5e19791931119e7f72fef4470eb77cf76012c214/openstack/values.yaml#L4

Change-Id: I2e1224af93ddef004fedcaee7a9813356377b47a
Depends-On: I40798248c7778cb74e722b741cc728a84cf89b9c
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/68/848668/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/values.yaml', 'openstack/templates/job-delete-successful-jobs.yaml', 'releasenotes/notes/openstack.yaml', 'openstack/templates/configmap-bin.yaml', 'openstack/Chart.yaml']",5,326d206f5440f99ef2c76383ed17eb9c8834ea55,,version: 0.1.3,version: 0.1.2,131,1
openstack%2Fopenstack-helm~master~I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c,openstack/openstack-helm,master,I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c,WIP: Add health probe for cinder volume and scheduler,ABANDONED,2022-08-19 09:37:53.000000000,2022-11-10 17:49:21.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-08-19 09:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6ca24f6c940b9fd1166fa854e380b3ee9ed13ed9', 'message': ""WIP: Add health probe for cinder volume and scheduler\n\nIt check's the RPC tcp socket status on the process and send\nmessage to service through rpc call method and expects a reply.\n\nChange-Id: I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c\n""}, {'number': 2, 'created': '2022-09-01 09:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4de2abeeb0548e2b88761cb2ca21b4e22d3e333a', 'message': ""WIP: Add health probe for cinder volume and scheduler\n\nIt check's the RPC tcp socket status on the process and send\nmessage to service through rpc call method and expects a reply.\n\nChange-Id: I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c\n""}, {'number': 3, 'created': '2022-09-01 10:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/02bc2a71f54720d8aa3cf508479794a5651e4b3c', 'message': ""WIP: Add health probe for cinder volume and scheduler\n\nIt check's the RPC tcp socket status on the process and send\nmessage to service through rpc call method and expects a reply.\n\nChange-Id: I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c\n""}, {'number': 4, 'created': '2022-09-05 13:36:51.000000000', 'files': ['cinder/templates/deployment-volume.yaml', 'cinder/templates/configmap-bin.yaml', 'cinder/templates/bin/_health-probe.py.tpl', 'cinder/values.yaml', 'cinder/Chart.yaml', 'releasenotes/notes/cinder.yaml', 'cinder/templates/deployment-scheduler.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b7c686708d6e3b5ac19461d2b67b8f6a70f28a65', 'message': ""WIP: Add health probe for cinder volume and scheduler\n\nIt check's the RPC tcp socket status on the process and send\nmessage to service through rpc call method and expects a reply.\n\nChange-Id: I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c\n""}]",0,853797,b7c686708d6e3b5ac19461d2b67b8f6a70f28a65,8,1,4,31746,,,0,"WIP: Add health probe for cinder volume and scheduler

It check's the RPC tcp socket status on the process and send
message to service through rpc call method and expects a reply.

Change-Id: I7cbcc41d3e4f9e2c2aebefe270ef316f8569d98c
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/97/853797/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/templates/deployment-volume.yaml', 'cinder/templates/configmap-bin.yaml', 'cinder/Chart.yaml', 'cinder/templates/bin/_health-probe.py.tpl', 'cinder/values.yaml', 'releasenotes/notes/cinder.yaml', 'cinder/templates/deployment-scheduler.yaml']",7,6ca24f6c940b9fd1166fa854e380b3ee9ed13ed9,,"{{- define ""cinderSchedulerLivenessProbeTemplate"" }} exec: command: - python - /tmp/health-probe.py - --config-file - /etc/cinder/cinder.conf - --service-queue-name - scheduler - --liveness-probe {{- if .Values.pod.use_fqdn.scheduler }} - --use-fqdn {{- end }} {{- end }} {{- define ""cinderSchedulerReadinessProbeTemplate"" }} exec: command: - python - /tmp/health-probe.py - --config-file - /etc/cinder/cinder.conf - --service-queue-name - scheduler {{- if .Values.pod.use_fqdn.scheduler }} - --use-fqdn {{- end }} {{- end }} {{ dict ""envAll"" $envAll ""component"" ""compute"" ""container"" ""default"" ""type"" ""liveness"" ""probeTemplate"" (include ""cinderSchedulerLivenessProbeTemplate"" $envAll | fromYaml) | include ""helm-toolkit.snippets.kubernetes_probe"" | indent 10 }} {{ dict ""envAll"" $envAll ""component"" ""compute"" ""container"" ""default"" ""type"" ""readiness"" ""probeTemplate"" (include ""cinderSchedulerReadinessProbeTemplate"" $envAll | fromYaml) | include ""helm-toolkit.snippets.kubernetes_probe"" | indent 10 }}",,299,1
openstack%2Fkayobe~stable%2Fyoga~I227c2a4fc8cec20a0e64a7f3fb4d26911aacd857,openstack/kayobe,stable/yoga,I227c2a4fc8cec20a0e64a7f3fb4d26911aacd857,Remove Venus support,MERGED,2022-11-10 13:41:42.000000000,2022-11-10 17:29:35.000000000,2022-11-10 17:28:37.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-11-10 13:41:42.000000000', 'files': ['ansible/roles/kolla-ansible/templates/overcloud-services.j2', 'etc/kayobe/kolla.yml', 'ansible/roles/kolla-ansible/templates/overcloud-components.j2', 'ansible/roles/kolla-ansible/vars/main.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/4f44c88528017b564b39953dc252fdb5365efac0', 'message': 'Remove Venus support\n\nIn the stable/yoga branch of kolla-ansible Venus has been removed,\nhence removing Venus support in Kayobe.\nSee: https://review.opendev.org/c/openstack/kolla-ansible/+/841232\n\nChange-Id: I227c2a4fc8cec20a0e64a7f3fb4d26911aacd857\n'}]",3,864203,4f44c88528017b564b39953dc252fdb5365efac0,10,3,1,35511,,,0,"Remove Venus support

In the stable/yoga branch of kolla-ansible Venus has been removed,
hence removing Venus support in Kayobe.
See: https://review.opendev.org/c/openstack/kolla-ansible/+/841232

Change-Id: I227c2a4fc8cec20a0e64a7f3fb4d26911aacd857
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/03/864203/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-ansible/templates/overcloud-services.j2', 'etc/kayobe/kolla.yml', 'ansible/roles/kolla-ansible/templates/overcloud-components.j2', 'ansible/roles/kolla-ansible/vars/main.yml']",4,4f44c88528017b564b39953dc252fdb5365efac0,,, - venus,0,11
openstack%2Fcinder~master~I46ade76474390aa58cd13c1053cac25ca2dc9d3c,openstack/cinder,master,I46ade76474390aa58cd13c1053cac25ca2dc9d3c,JovianDSS remove deprecated iscsi-target-prefix,NEW,2022-10-27 16:50:26.000000000,2022-11-10 17:04:06.000000000,,"[{'_account_id': 9236}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-27 16:50:26.000000000', 'files': ['doc/source/configuration/block-storage/drivers/open-e-joviandss-driver.rst', 'cinder/tests/unit/volume/drivers/open_e/test_rest_proxy.py', 'cinder/tests/unit/volume/drivers/open_e/test_rest.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/781c9b99124626df472d765c980336d08c27ab8a', 'message': 'JovianDSS remove deprecated iscsi-target-prefix\n\nRename iscsi-target-prefix to target-prefix in documentation section and\nunit test section\n\nImplements: blueprint joviandss-remove-deprecated-iscsi-target-prefix\nChange-Id: I46ade76474390aa58cd13c1053cac25ca2dc9d3c\n'}]",1,862831,781c9b99124626df472d765c980336d08c27ab8a,23,2,1,22312,,,0,"JovianDSS remove deprecated iscsi-target-prefix

Rename iscsi-target-prefix to target-prefix in documentation section and
unit test section

Implements: blueprint joviandss-remove-deprecated-iscsi-target-prefix
Change-Id: I46ade76474390aa58cd13c1053cac25ca2dc9d3c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/862831/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration/block-storage/drivers/open-e-joviandss-driver.rst', 'cinder/tests/unit/volume/drivers/open_e/test_rest_proxy.py', 'cinder/tests/unit/volume/drivers/open_e/test_rest.py']",3,781c9b99124626df472d765c980336d08c27ab8a,," 'target_prefix': 'iqn.2020-04.com.open-e.cinder:', tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1 tname = CONFIG_OK['target_prefix'] + UUID_1"," 'iscsi_target_prefix': 'iqn.2020-04.com.open-e.cinder:', tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1 tname = CONFIG_OK['iscsi_target_prefix'] + UUID_1",20,20
openstack%2Fpuppet-ovn~master~Ia3112b9a219b90af718c49776da49078449f09a2,openstack/puppet-ovn,master,Ia3112b9a219b90af718c49776da49078449f09a2,Add support for ovn-ofctrl-wait-before-clear,MERGED,2022-11-01 17:47:39.000000000,2022-11-10 16:45:25.000000000,2022-11-10 16:44:27.000000000,"[{'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 8297}, {'_account_id': 8655}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-11-01 17:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/51c58f5138299d9fcc272d7afd9690dd96f98070', 'message': 'Add support for ovn-ofctl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 2, 'created': '2022-11-01 17:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/ba26fdab4efb80bcc0ee1344398831e5a9a3fb03', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 3, 'created': '2022-11-01 18:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/aa1f363918ad62c6b47410c13b18b9bd97bcbeab', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 4, 'created': '2022-11-02 20:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/8b651b680f51535d8ee125c200280331bf3f5265', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 5, 'created': '2022-11-02 21:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/6873b8323907713d5a4b5d4f740ae6490e09140d', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 6, 'created': '2022-11-03 19:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/afc71fe4e281108a874e86243257db4d78c186b6', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 7, 'created': '2022-11-07 15:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/02cc4fb5ace2c167ff76d434fdd18b77c8106f36', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}, {'number': 8, 'created': '2022-11-07 15:08:45.000000000', 'files': ['spec/classes/ovn_controller_spec.rb', 'manifests/controller.pp', 'releasenotes/notes/ovn_ofctrl_wait_before_clear-c40493ce231ec38c.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/b5d38dcbd4cc8a56cc0d028f982accf23a19b15c', 'message': 'Add support for ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\nChange-Id: Ia3112b9a219b90af718c49776da49078449f09a2\n'}]",16,863170,b5d38dcbd4cc8a56cc0d028f982accf23a19b15c,42,10,8,5756,,,0,"Add support for ovn-ofctrl-wait-before-clear

Support was added for this option [1] to avoid dataplane downtime
during ovn upgrades where schema changes have happened. This
adds the ability for us to configure it.

[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/

Change-Id: Ia3112b9a219b90af718c49776da49078449f09a2
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/70/863170/8 && git format-patch -1 --stdout FETCH_HEAD,['manifests/controller.pp'],1,51c58f5138299d9fcc272d7afd9690dd96f98070,ovn-ofctrl-wait-before-clear," $manage_ovs_bridge = true, $ovn_ofctl_wait_before_clear = 8000 'external_ids:ovn-ofctl-wait-before-clear' => { 'value' => $ovn_ofctl_wait_before_clear },", $manage_ovs_bridge = true,3,1
openstack%2Fpuppet-glance~stable%2Fyoga~I2477d5e271b017ee12546c67f4c3f3f9be89c062,openstack/puppet-glance,stable/yoga,I2477d5e271b017ee12546c67f4c3f3f9be89c062,Ensure [DEFAULT] show_multiple_locations is cleared,MERGED,2022-11-04 14:06:42.000000000,2022-11-10 16:44:49.000000000,2022-11-10 16:44:49.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 14:06:42.000000000', 'files': ['manifests/api.pp', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/8e7a4c46dd474b5bee8ba1b5fb1e62f5b6bf4e5e', 'message': 'Ensure [DEFAULT] show_multiple_locations is cleared\n\nThe parameter was already deprecated, but it is still required in\nsome setup (eg. to leverage in-storage copy in a deployment with Ceph\nused for cinder/glance).\n\nConsidering the parameter is still valid, this change ensures it is\nremoved by default, so that old value is properly removed from config\nfile.\n\nChange-Id: I2477d5e271b017ee12546c67f4c3f3f9be89c062\n(cherry picked from commit 5d977c750acf5276ce7fb7772436e9e74c2be001)\n'}]",0,863623,8e7a4c46dd474b5bee8ba1b5fb1e62f5b6bf4e5e,7,3,1,21129,,,0,"Ensure [DEFAULT] show_multiple_locations is cleared

The parameter was already deprecated, but it is still required in
some setup (eg. to leverage in-storage copy in a deployment with Ceph
used for cinder/glance).

Considering the parameter is still valid, this change ensures it is
removed by default, so that old value is properly removed from config
file.

Change-Id: I2477d5e271b017ee12546c67f4c3f3f9be89c062
(cherry picked from commit 5d977c750acf5276ce7fb7772436e9e74c2be001)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/23/863623/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/glance_api_spec.rb']",2,8e7a4c46dd474b5bee8ba1b5fb1e62f5b6bf4e5e,," :show_multiple_locations => '<SERVICE DEFAULT>',",,4,3
openstack%2Fansible-collections-openstack~master~Id63e6a80d1b8e3574911016fec792f00b63f1524,openstack/ansible-collections-openstack,master,Id63e6a80d1b8e3574911016fec792f00b63f1524,Updates server_metadata for 2.0.0,MERGED,2022-11-01 20:20:01.000000000,2022-11-10 16:41:26.000000000,2022-11-10 16:41:26.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-01 20:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e1a3988e563a4b02d99e1f2b2cc02dbffaf51e23', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 2, 'created': '2022-11-03 13:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cb9267d2a7134c4025c548877e492115a29f255c', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 3, 'created': '2022-11-03 13:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/909b7374b2158eadf163f0904c36135bdc89b80f', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 4, 'created': '2022-11-07 19:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ec1cc9e0387c7be2d275ea62950cf2f9cddc5dd6', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 5, 'created': '2022-11-07 19:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c3d153988a1e0a018845488408ece6a64b47deef', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 6, 'created': '2022-11-07 22:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c4f781bca86ac7ee161fdbc3d1a3b0aa695197be', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 7, 'created': '2022-11-08 08:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/40e0a50383ea16248680b212c325fa52b7f64e5d', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 8, 'created': '2022-11-08 14:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/234db16771caa27273edc6c313c561ddcc824caf', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 9, 'created': '2022-11-08 14:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/90d0440205fc48ef984893a2fa1197678239a1b3', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 10, 'created': '2022-11-08 21:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a44944b2f5893dad1debaabf211186324565894d', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 11, 'created': '2022-11-09 02:33:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f81629093f8989f6d81e02b9f36cc2f0f0979e95', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 12, 'created': '2022-11-09 17:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6161bf5de84784d3113d51a881f8375a7697b751', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Return whole server resource instead of only metadata map\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 13, 'created': '2022-11-09 17:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ea582fadd3626382b3cb626f6907d3cd99aa0f5e', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Return whole server resource instead of only metadata map\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 14, 'created': '2022-11-09 17:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4e07747e32c2c734cc1f522026447b2562eee939', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Return whole server resource instead of only metadata map\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 15, 'created': '2022-11-10 02:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/94703298f7aa915451db0b2c0bd369c17f29312e', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Return whole server resource instead of only metadata map\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}, {'number': 16, 'created': '2022-11-10 13:04:52.000000000', 'files': ['ci/roles/server_metadata/tasks/main.yml', '.zuul.yaml', 'plugins/modules/server_metadata.py', 'ci/run-collection.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4fe73c978ab5cdc4f4f474b43658c09847eae3be', 'message': 'Updates server_metadata for 2.0.0\n\n- Switch to using proxy layer calls\n- Return whole server resource instead of only metadata map\n- Swap the name and server aliased parameters\n- Add a server_metadata test role\n- Ensure check mode returns tentatively updated metadata\n- Remove server_id return value\n\nChange-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524\n'}]",35,863178,4fe73c978ab5cdc4f4f474b43658c09847eae3be,38,4,16,34208,,,0,"Updates server_metadata for 2.0.0

- Switch to using proxy layer calls
- Return whole server resource instead of only metadata map
- Swap the name and server aliased parameters
- Add a server_metadata test role
- Ensure check mode returns tentatively updated metadata
- Remove server_id return value

Change-Id: Id63e6a80d1b8e3574911016fec792f00b63f1524
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/78/863178/12 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/server_metadata/tasks/main.yml', '.zuul.yaml', 'plugins/modules/server_metadata.py', 'ci/run-collection.yml']",4,e1a3988e563a4b02d99e1f2b2cc02dbffaf51e23,," - { role: server_metadata, tags: server_metadata }",,137,44
openstack%2Fpython-designateclient~master~Idbba68ebd3f74bde74f0b50ffcb233673dff2303,openstack/python-designateclient,master,Idbba68ebd3f74bde74f0b50ffcb233673dff2303,Include SECONDARY zones into list command output,MERGED,2022-07-12 10:20:34.000000000,2022-11-10 15:50:00.000000000,2022-11-10 15:49:02.000000000,"[{'_account_id': 5572}, {'_account_id': 7549}, {'_account_id': 11628}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-07-12 10:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/6953b5847e58779a4e9c9851cd3636c831a95a50', 'message': 'Include SECONDARY zones into list command output\n\nPRIMARY zone type is set by default, so SECONDARY\nzones were not included in the command output.\nNow all types are in output by default and specific type\ncan be passed as an argument like before\n\nRelated-Issue: PRODX-25391\nChange-Id: Idbba68ebd3f74bde74f0b50ffcb233673dff2303\n'}, {'number': 2, 'created': '2022-07-12 11:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/3db3ec3effd471ce4fe3190bc95936aa0b107b98', 'message': 'Include SECONDARY zones into list command output\n\nPRIMARY zone type is set by default, so SECONDARY\nzones were not included in the command output.\nNow all types are in output by default and specific type\ncan be passed as an argument like before\n\nCloses-Bug: #1940544\nChange-Id: Idbba68ebd3f74bde74f0b50ffcb233673dff2303\n'}, {'number': 3, 'created': '2022-07-14 06:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/315c86048382eba81b79497f67bd97fcd98f0ae2', 'message': 'Include SECONDARY zones into list command output\n\nPRIMARY zone type is set by default, so SECONDARY\nzones were not included in the command output.\nNow all types are in output by default and specific type\ncan be passed as an argument like before\n\nCloses-Bug: #1940544\nChange-Id: Idbba68ebd3f74bde74f0b50ffcb233673dff2303\n'}, {'number': 4, 'created': '2022-07-14 20:26:01.000000000', 'files': ['releasenotes/notes/bug-1940544-9ed7805341dec1ba.yaml', 'designateclient/v2/cli/zones.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/435f1e78665a03226704637a952e75c30ff2b097', 'message': 'Include SECONDARY zones into list command output\n\nPRIMARY zone type is set by default, so SECONDARY\nzones were not included in the command output.\nNow all types are in output by default and specific type\ncan be passed as an argument like before\n\nCloses-Bug: #1940544\nChange-Id: Idbba68ebd3f74bde74f0b50ffcb233673dff2303\n'}]",9,849489,435f1e78665a03226704637a952e75c30ff2b097,23,6,4,7549,,,0,"Include SECONDARY zones into list command output

PRIMARY zone type is set by default, so SECONDARY
zones were not included in the command output.
Now all types are in output by default and specific type
can be passed as an argument like before

Closes-Bug: #1940544
Change-Id: Idbba68ebd3f74bde74f0b50ffcb233673dff2303
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/89/849489/4 && git format-patch -1 --stdout FETCH_HEAD,['designateclient/v2/cli/zones.py'],1,6953b5847e58779a4e9c9851cd3636c831a95a50,bug/1940544," default=None,"," default=""PRIMARY"",",1,1
openstack%2Fpuppet-murano~master~I648ae1113f57f5cd085e8240af74a3c5750b58dc,openstack/puppet-murano,master,I648ae1113f57f5cd085e8240af74a3c5750b58dc,Fix dependencies related to openstacklib::policy,MERGED,2022-11-09 00:55:18.000000000,2022-11-10 15:44:35.000000000,2022-11-10 15:44:35.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 00:55:18.000000000', 'files': ['manifests/deps.pp'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/0a53e1d4ac6296bbaab5704dc87d34db90bf54fa', 'message': 'Fix dependencies related to openstacklib::policy\n\nSince [1] was merged, not only openstacklib::poliy::base but also\nopenstacklib::policy::default is included to manage the policy file.\nThis change ensure openstacklib::policy::default is executed after\nthe packages are installed.\n\n[1] 740d1bb822e8543535a2fccb4f2eab4b5809422c\n\nChange-Id: I648ae1113f57f5cd085e8240af74a3c5750b58dc\n'}]",0,864074,0a53e1d4ac6296bbaab5704dc87d34db90bf54fa,9,3,1,9414,,,0,"Fix dependencies related to openstacklib::policy

Since [1] was merged, not only openstacklib::poliy::base but also
openstacklib::policy::default is included to manage the policy file.
This change ensure openstacklib::policy::default is executed after
the packages are installed.

[1] 740d1bb822e8543535a2fccb4f2eab4b5809422c

Change-Id: I648ae1113f57f5cd085e8240af74a3c5750b58dc
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/74/864074/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/deps.pp'],1,0a53e1d4ac6296bbaab5704dc87d34db90bf54fa,policy-deps, -> Openstacklib::Policy<||>, -> Openstacklib::Policy::Base<||>,1,1
openstack%2Fpython-glanceclient~master~Idbf5ddc56c608588cc30616f4a0cc12c2e698b9c,openstack/python-glanceclient,master,Idbf5ddc56c608588cc30616f4a0cc12c2e698b9c,"Make ""tox -edocs"" generate the manpage",MERGED,2021-10-05 18:29:46.000000000,2022-11-10 15:42:30.000000000,2022-11-10 15:41:27.000000000,"[{'_account_id': 5202}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-10-05 18:29:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/98f4219b6e3cd51f3a6e0fba5e50aad867e59e7a', 'message': 'Make ""tox -edocs"" generate the manpage\n\nCloses-Bug: #911805\nChange-Id: Idbf5ddc56c608588cc30616f4a0cc12c2e698b9c\n'}]",2,812536,98f4219b6e3cd51f3a6e0fba5e50aad867e59e7a,9,2,1,8122,,,0,"Make ""tox -edocs"" generate the manpage

Closes-Bug: #911805
Change-Id: Idbf5ddc56c608588cc30616f4a0cc12c2e698b9c
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/36/812536/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,98f4219b6e3cd51f3a6e0fba5e50aad867e59e7a,bug/911805, sphinx-build -W -b man doc/source doc/build/man,,1,0
openstack%2Fkayobe~stable%2Fyoga~Ie9b9c49c3f382612a11a6184c30f11c57d40494d,openstack/kayobe,stable/yoga,Ie9b9c49c3f382612a11a6184c30f11c57d40494d,Add prometheus-msteams group to kayobe,MERGED,2022-11-10 11:51:15.000000000,2022-11-10 15:40:01.000000000,2022-11-10 15:39:00.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-11-10 11:51:15.000000000', 'files': ['ansible/roles/kolla-ansible/templates/overcloud-services.j2', 'releasenotes/notes/fix-add-msteams-group-to-kayobe--bfd2a5030b6955d2.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/bcf5915624d65e4209b94dd100f4cc9844753334', 'message': ""Add prometheus-msteams group to kayobe\n\nThis adds the prometheus-msteams group into\novercloud-services.j2 as it's missing and has been added\nin the yoga release to kolla-ansible.\n\nChange-Id: Ie9b9c49c3f382612a11a6184c30f11c57d40494d\n(cherry picked from commit fa40aab7ff35c3030c2cf42165c0150f2d5328c7)\n""}]",0,864173,bcf5915624d65e4209b94dd100f4cc9844753334,8,3,1,17669,,,0,"Add prometheus-msteams group to kayobe

This adds the prometheus-msteams group into
overcloud-services.j2 as it's missing and has been added
in the yoga release to kolla-ansible.

Change-Id: Ie9b9c49c3f382612a11a6184c30f11c57d40494d
(cherry picked from commit fa40aab7ff35c3030c2cf42165c0150f2d5328c7)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/73/864173/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-ansible/templates/overcloud-services.j2', 'releasenotes/notes/fix-add-msteams-group-to-kayobe--bfd2a5030b6955d2.yaml']",2,bcf5915624d65e4209b94dd100f4cc9844753334,,--- fixes: - | Adds missing Ansible group following the addition of support in Kolla Ansible for forwarding Prometheus alerts to Microsoft Teams. ,,8,0
openstack%2Fpuppet-openstack_extras~master~I1a0f00c8dcfa5ba71f32b630878cd4a2c95f35f1,openstack/puppet-openstack_extras,master,I1a0f00c8dcfa5ba71f32b630878cd4a2c95f35f1,Remove support for CentOS 8 Stream,MERGED,2022-11-09 01:01:03.000000000,2022-11-10 15:28:29.000000000,2022-11-10 15:28:29.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 01:01:03.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/ecdbf61bb32357dae977ce32541d00a901315484', 'message': 'Remove support for CentOS 8 Stream\n\n... because RDO will provide packages for only CentOS Stream 9 for Zed\nrelease. This change removes RHEL 8 as well.\n\nChange-Id: I1a0f00c8dcfa5ba71f32b630878cd4a2c95f35f1\nDepends-on: https://review.opendev.org/843503\n'}]",0,864075,ecdbf61bb32357dae977ce32541d00a901315484,7,3,1,9414,,,0,"Remove support for CentOS 8 Stream

... because RDO will provide packages for only CentOS Stream 9 for Zed
release. This change removes RHEL 8 as well.

Change-Id: I1a0f00c8dcfa5ba71f32b630878cd4a2c95f35f1
Depends-on: https://review.opendev.org/843503
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/75/864075/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,ecdbf61bb32357dae977ce32541d00a901315484,c8s,," ""8"", ""8"",",0,2
openstack%2Foctavia~master~Id328b27db1ec9c8e17bf18120259e41e75dab3b9,openstack/octavia,master,Id328b27db1ec9c8e17bf18120259e41e75dab3b9,Fix full graph loadbalancer creation if jobboard is disabled,MERGED,2022-09-28 19:08:27.000000000,2022-11-10 15:16:09.000000000,2022-11-10 15:14:45.000000000,"[{'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 31664}, {'_account_id': 34429}]","[{'number': 1, 'created': '2022-09-28 19:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/aa716d5b1bbd213074fbe148f51690b37216dc04', 'message': 'Fix full graph loadbalancer creation if jobboard is disabled\n\nThis patch fixes the creation of a full loadbalancer graph in case the\njobboard_enabled config value is False, when no ""listeners"" parameter was\npassed to the get_create_load_balancer_flow function call: use kwargs as the\nflow creation function parameters and handle ""store"" separately.\n\nStory 2010335\nTask 46462\n\nSigned-off-by: Anton Kurbatov <Anton.Kurbatov@acronis.com>\nChange-Id: Id328b27db1ec9c8e17bf18120259e41e75dab3b9\n'}, {'number': 2, 'created': '2022-09-29 07:39:01.000000000', 'files': ['octavia/tests/unit/controller/worker/v2/test_controller_worker.py', 'octavia/controller/worker/v2/controller_worker.py', 'releasenotes/notes/fix-full-graph-loadbalancer-creation-if-jobboard-is-disabled.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/216cce39c9c22831d725703f41c54b9305d65dc8', 'message': 'Fix full graph loadbalancer creation if jobboard is disabled\n\nThis patch fixes the creation of a full loadbalancer graph in case the\njobboard_enabled config value is False, when no ""listeners"" parameter was\npassed to the get_create_load_balancer_flow function call: use kwargs as the\nflow creation function parameters and handle ""store"" separately.\n\nStory 2010335\nTask 46462\n\nSigned-off-by: Anton Kurbatov <Anton.Kurbatov@acronis.com>\nChange-Id: Id328b27db1ec9c8e17bf18120259e41e75dab3b9\n'}]",4,859710,216cce39c9c22831d725703f41c54b9305d65dc8,15,4,2,28722,,,0,"Fix full graph loadbalancer creation if jobboard is disabled

This patch fixes the creation of a full loadbalancer graph in case the
jobboard_enabled config value is False, when no ""listeners"" parameter was
passed to the get_create_load_balancer_flow function call: use kwargs as the
flow creation function parameters and handle ""store"" separately.

Story 2010335
Task 46462

Signed-off-by: Anton Kurbatov <Anton.Kurbatov@acronis.com>
Change-Id: Id328b27db1ec9c8e17bf18120259e41e75dab3b9
",git fetch https://review.opendev.org/openstack/octavia refs/changes/10/859710/2 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/controller/worker/v2/test_controller_worker.py', 'octavia/controller/worker/v2/controller_worker.py', 'releasenotes/notes/fix-full-graph-loadbalancer-creation-if-jobboard-is-disabled.yaml']",3,aa716d5b1bbd213074fbe148f51690b37216dc04,story/2010335,--- fixes: - | Fix a bug when full graph of load balancer is created without listeners if jobboard_enabled=False ,,53,1
openstack%2Fnetworking-bagpipe~stable%2Fwallaby~Iceb92b157d5e875090a0dedec37c398716b89495,openstack/networking-bagpipe,stable/wallaby,Iceb92b157d5e875090a0dedec37c398716b89495,Add required project and follow pyroute2 changes,MERGED,2022-10-24 16:13:48.000000000,2022-11-10 15:14:45.000000000,2022-11-10 15:12:49.000000000,"[{'_account_id': 8313}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-24 16:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/1f44d064188d222b54cc207125cfab89af3148eb', 'message': ""Add required projects where necessary\n\nMost of the jobs needs required-projects to be added, especially in\nstable branches, where the lack of them causes gate failures.\n\nSince the templates openstack-python3-jobs-neutron and\nperiodic-stable-jobs-neutron don't contain all the necessary projects\nfor bagpipe we need to add them one by one.\n\nChange-Id: Iceb92b157d5e875090a0dedec37c398716b89495\n(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)\n(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)\n(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)\n(cherry picked from commit 39546f061193de8d46d6ca6141122f83bb18621a)\n""}, {'number': 2, 'created': '2022-10-28 15:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/abed7961d3c89e0f8c26d4bceed4fab3a58f73d7', 'message': ""Add required projects where necessary\n\nMost of the jobs needs required-projects to be added, especially in\nstable branches, where the lack of them causes gate failures.\n\nSince the templates openstack-python3-jobs-neutron and\nperiodic-stable-jobs-neutron don't contain all the necessary projects\nfor bagpipe we need to add them one by one.\n\nChange-Id: Iceb92b157d5e875090a0dedec37c398716b89495\n(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)\n(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)\n(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)\n(cherry picked from commit 39546f061193de8d46d6ca6141122f83bb18621a)\n""}, {'number': 3, 'created': '2022-11-09 17:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/a9b85a61a3aa4a32865eb79e3b2d1993f8d696d2', 'message': ""Add required projects where necessary\n\nMost of the jobs needs required-projects to be added, especially in\nstable branches, where the lack of them causes gate failures.\n\nSince the templates openstack-python3-jobs-neutron and\nperiodic-stable-jobs-neutron don't contain all the necessary projects\nfor bagpipe we need to add them one by one.\n\nChanges:\n  .zuul.yaml\n\nChange-Id: Iceb92b157d5e875090a0dedec37c398716b89495\n(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)\n(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)\n(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)\n(cherry picked from commit 39546f061193de8d46d6ca6141122f83bb18621a)\n""}, {'number': 4, 'created': '2022-11-10 10:38:34.000000000', 'files': ['networking_bagpipe/bagpipe_bgp/vpn/evpn/linux_vxlan.py', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/097de21d696c031972e6f05c8d1bbd3caff320ad', 'message': ""Add required project and follow pyroute2 changes\n\nThis is a combination of 2 commits to unblock the gate.\n\n1. Follow pyroute2 changes\n\npyroute2 recently changed its module structure (see [1]) and deprecated\nIPDB (see [2]), this patch tries to address these.\n\n[1]: https://github.com/svinota/pyroute2/discussions/786\n[2]: https://github.com/svinota/pyroute2/discussions/788\n\n(cherry picked from commit b01bc67ab803d89754f2da016761301dad353501)\n\n2. Add required projects where necessary\n\nMost of the jobs needs required-projects to be added, especially in\nstable branches, where the lack of them causes gate failures.\n\nSince the templates openstack-python3-jobs-neutron and\nperiodic-stable-jobs-neutron don't contain all the necessary projects\nfor bagpipe we need to add them one by one.\n\nChanges:\n  .zuul.yaml\n\nChange-Id: Iceb92b157d5e875090a0dedec37c398716b89495\n(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)\n(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)\n(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)\n(cherry picked from commit 39546f061193de8d46d6ca6141122f83bb18621a)\n""}]",2,862502,097de21d696c031972e6f05c8d1bbd3caff320ad,16,4,4,17685,,,0,"Add required project and follow pyroute2 changes

This is a combination of 2 commits to unblock the gate.

1. Follow pyroute2 changes

pyroute2 recently changed its module structure (see [1]) and deprecated
IPDB (see [2]), this patch tries to address these.

[1]: https://github.com/svinota/pyroute2/discussions/786
[2]: https://github.com/svinota/pyroute2/discussions/788

(cherry picked from commit b01bc67ab803d89754f2da016761301dad353501)

2. Add required projects where necessary

Most of the jobs needs required-projects to be added, especially in
stable branches, where the lack of them causes gate failures.

Since the templates openstack-python3-jobs-neutron and
periodic-stable-jobs-neutron don't contain all the necessary projects
for bagpipe we need to add them one by one.

Changes:
  .zuul.yaml

Change-Id: Iceb92b157d5e875090a0dedec37c398716b89495
(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)
(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)
(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)
(cherry picked from commit 39546f061193de8d46d6ca6141122f83bb18621a)
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/02/862502/4 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,1f44d064188d222b54cc207125cfab89af3148eb,add-bagpipe-required-projects, - openstack-tox-docs: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-py39: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-docs: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc periodic-stable: jobs: - openstack-tox-docs: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-py36: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-py38: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc,,32,0
openstack%2Fdevstack~master~I02e097fef07655ff571af9f35bf258b2ed975098,openstack/devstack,master,I02e097fef07655ff571af9f35bf258b2ed975098,"Add new service ""file_tracker""",MERGED,2022-11-02 15:46:01.000000000,2022-11-10 15:11:40.000000000,2022-11-10 15:09:43.000000000,"[{'_account_id': 4393}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2022-11-02 15:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b99fe30f34ae5e74e981fc8bb0e89ea2bde21b73', 'message': 'Add new service ""file_tracker""\n\nThis new service periodically tracks the file open in the system.\n\nChange-Id: I02e097fef07655ff571af9f35bf258b2ed975098\nCloses-Bug: #1995502\n'}, {'number': 2, 'created': '2022-11-04 14:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f136f1129983d4fde1ac6e7bedab74e74235193a', 'message': 'Add new service ""file_tracker""\n\nThis new service periodically tracks the file open in the system.\n\nCloses-Bug: #1995502\nChange-Id: I02e097fef07655ff571af9f35bf258b2ed975098\n'}, {'number': 3, 'created': '2022-11-07 08:21:49.000000000', 'files': ['.zuul.yaml', 'tools/file_tracker.sh', 'lib/dstat', 'doc/source/debugging.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d1c2bf5e7c739bc5a7eeac602b477edb9f6630c2', 'message': 'Add new service ""file_tracker""\n\nThis new service periodically tracks the file open in the system.\n\nCloses-Bug: #1995502\nChange-Id: I02e097fef07655ff571af9f35bf258b2ed975098\n'}]",14,863324,d1c2bf5e7c739bc5a7eeac602b477edb9f6630c2,24,4,3,16688,,,0,"Add new service ""file_tracker""

This new service periodically tracks the file open in the system.

Closes-Bug: #1995502
Change-Id: I02e097fef07655ff571af9f35bf258b2ed975098
",git fetch https://review.opendev.org/openstack/devstack refs/changes/24/863324/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/file_tracker.sh', 'lib/dstat', 'doc/source/debugging.rst']",3,b99fe30f34ae5e74e981fc8bb0e89ea2bde21b73,bug/1995502,file_tracker ------------ The ``file_tracker`` service periodically monitors the number of open files in the system. ,,60,0
openstack%2Ftripleo-quickstart~master~I54ff0a8669a9057dd74ae722369cd2cef65171c0,openstack/tripleo-quickstart,master,I54ff0a8669a9057dd74ae722369cd2cef65171c0,Add CloudSIG Zed config relese file,MERGED,2022-11-07 07:50:34.000000000,2022-11-10 15:08:44.000000000,2022-11-10 15:07:42.000000000,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-07 07:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/daebf6db5a7a78e55225a145ff512bcbbea03446', 'message': ""Add CloudSIG Zed config relese file\n\nIt's required to test CloudSIG Zed repos in RDO\n\nChange-Id: I54ff0a8669a9057dd74ae722369cd2cef65171c0\n""}, {'number': 2, 'created': '2022-11-07 08:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/6c1c086baec01c4a4d2eac9001d3fe6dec9c4500', 'message': ""Add CloudSIG Zed config relese file\n\nIt's required to test CloudSIG Zed repos in RDO\n\nChange-Id: I54ff0a8669a9057dd74ae722369cd2cef65171c0\n""}, {'number': 3, 'created': '2022-11-07 09:40:32.000000000', 'files': ['config/release/tripleo-ci/CentOS-9/cloudsig/zed.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/dc880cf4a1331bd6862ad6ba226932188128c546', 'message': ""Add CloudSIG Zed config relese file\n\nIt's required to test CloudSIG Zed repos in RDO\n\nChange-Id: I54ff0a8669a9057dd74ae722369cd2cef65171c0\n""}]",7,863813,dc880cf4a1331bd6862ad6ba226932188128c546,15,5,3,16312,,,0,"Add CloudSIG Zed config relese file

It's required to test CloudSIG Zed repos in RDO

Change-Id: I54ff0a8669a9057dd74ae722369cd2cef65171c0
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/13/863813/1 && git format-patch -1 --stdout FETCH_HEAD,['config/release/tripleo-ci/CentOS-9/cloudsig/zed.yml'],1,daebf6db5a7a78e55225a145ff512bcbbea03446,,"# rdoinfo configs artg_skipped_projects: - rdoinfo update_containers: false standalone_container_prep_updates: false docker_registry_host: >- {% if job is defined and job.build_container_images is defined and job.build_container_images|default(false)|bool or build_container_images|default(false)|bool -%} 127.0.0.1:5001 {%- elif job.consumer_job | default(false) | bool -%} {{ job.registry_ip_address_branch[release] }}:5001 {%- else -%} {{ job.alt_container_registry|default('quay.io') }} {%- endif -%} # name and tags devmode: true overcloud_as_undercloud: true release: yoga distro_ver: centos9 distro_deps_repo_name: deps dlrn_hash_tag: current-tripleo-rdo dlrn_hash_tag_newest: current docker_registry_namespace: ""tripleo{{ release }}"" docker_image_tag: ""cloudsig-{{ release }}"" docker_openshift_tag: v3.11.0 promote_source: current-tripleo-rdo validate_on: rdo # images overcloud_image: >- {% if whole_disk_images|bool -%} overcloud-hardened-uefi-full {%- else -%} overcloud-full {%- endif -%} overcloud_image_type: >- {% if whole_disk_images|bool -%} qcow2 {%- else -%} tar {%- endif -%} images: - name: ""{{ overcloud_image }}"" url: ""{{ overcloud_image_url }}"" type: ""{{ overcloud_image_type }}"" - name: ipa_images url: ""{{ ipa_image_url }}"" type: tar dlrn_baseurl: ""https://trunk.rdoproject.org/{{ distro_ver }}-{{ release }}"" overcloud_image_url: ""https://images.rdoproject.org/{{ distro_ver }}/{{ release }}/rdo_trunk/{{ promote_source }}/overcloud-full.tar"" ipa_image_url: ""https://images.rdoproject.org/{{ distro_ver }}/{{ release }}/rdo_trunk/{{ promote_source }}/ironic-python-agent.tar"" # NOTE(dviroel): centos-opstools repo is needed for building # collectd containers, otherwise keep the current value. enable_cs9_opstools_repo: >- {% if job is defined and job.build_container_images is defined and job.build_container_images|default(false)|bool or build_container_images|default(false)|bool -%} {{ true|bool }} {%- else -%} {{ enable_opstools_repo|default(false)|bool }} {%- endif -%} # repo setup repo_cmd_before: | sudo rm -rf /etc/yum.repos.d/delorean*; sudo rm -rf /etc/yum.repos.d/*.rpmsave; sudo rm -rf /etc/yum.repos.d/epel*; sudo dnf remove -y rdo-release centos-release-ceph-* centos-release-openstack-* centos-release-qemu-ev || true; sudo rm -rf /etc/yum.repos.d/CentOS-OpenStack-*.repo /etc/yum.repos.d/CentOS-Ceph-*.repo /etc/yum.repos.d/CentOS-QEMU-EV.repo; sudo dnf clean all; sudo dnf config-manager --disable ""*"" || true; if [ -e /etc/ci/mirror_info.sh ]; then source /etc/ci/mirror_info.sh else # Otherwise, fallback to official mirrors provided by CentOS. export NODEPOOL_CENTOS_MIRROR={{ lookup('env','NODEPOOL_CENTOS_MIRROR')|default('http://mirror.centos.org/centos', true) }} export NODEPOOL_RDO_PROXY=https://trunk.rdoproject.org fi # TODO: hack until we get https://review.opendev.org/c/zuul/zuul-jobs/+/838450 dnf config-manager --save --setopt extras-common.gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Extras-SHA512 repos: - type: package pkg_name: ""centos-release-openstack-{{ release }}"" custom_cmd: 'sudo dnf install -y --enablerepo=extras-common' - type: package pkg_name: ""centos-release-opstools"" custom_cmd: 'sudo dnf install -y --enablerepo=extras-common' # Needed for mock installation - type: generic reponame: ""delorean-{{ release }}-build-deps"" filename: ""delorean-{{ release }}-build-deps.repo"" baseurl: ""${NODEPOOL_RDO_PROXY}/{{ distro_ver }}-{{ release }}/build-deps/latest/"" # CentOS related repos - type: generic reponame: quickstart-centos-base filename: quickstart-centos-base.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/9-stream/BaseOS/x86_64/os - type: generic reponame: quickstart-centos-appstreams filename: quickstart-centos-appstreams.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/9-stream/AppStream/x86_64/os/ # centos9 the equivalent to powertools is CRB - type: generic reponame: quickstart-centos-crb filename: quickstart-centos-crb.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/9-stream/CRB/x86_64/os/ - type: generic reponame: quickstart-centos-highavailability filename: quickstart-centos-highavailability.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/9-stream/HighAvailability/x86_64/os/ repo_cmd_after: | {% if not enable_cs9_opstools_repo|default(false)|bool %}sudo dnf config-manager --save --setopt centos-opstools.enabled=0; {%endif %} sudo rpm -e epel-release || true; sudo rm -rf /etc/yum.repos.d/*.rpmsave; sudo dnf repolist; sudo dnf module list; sudo dnf clean metadata {% if repo_setup_run_update|default(true)|bool %} sudo dnf update -y {% endif %} undercloud_rpm_dependencies: >- python3-tripleoclient tripleo-operator-ansible ",,142,0
openstack%2Fmanila-specs~master~I32093c998067c06427b427bc0a66193fc94e1859,openstack/manila-specs,master,I32093c998067c06427b427bc0a66193fc94e1859,manila oversubscription enhancements,MERGED,2022-04-19 07:02:00.000000000,2022-11-10 15:00:22.000000000,2022-11-10 14:59:24.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30002}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-04-19 07:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/cbb6ba37c58fe0d46a1d1847d2f98878681024b8', 'message': 'manila oversubscription enhancements\n\nPartially-Implements: blueprint manila-oversubscription-enhancements\n\nChange-Id: I32093c998067c06427b427bc0a66193fc94e1859\n'}, {'number': 2, 'created': '2022-04-19 09:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/c15a46506b307a632a52678e67efc65a0e65dbec', 'message': 'manila oversubscription enhancements\n\nPartially-Implements: blueprint manila-oversubscription-enhancements\n\nChange-Id: I32093c998067c06427b427bc0a66193fc94e1859\n'}, {'number': 3, 'created': '2022-06-23 08:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/ee062556fa6b30655ee81663f8261acf877771e6', 'message': 'manila oversubscription enhancements\n\nPartially-Implements: blueprint manila-oversubscription-enhancements\n\nChange-Id: I32093c998067c06427b427bc0a66193fc94e1859\n'}, {'number': 4, 'created': '2022-06-28 01:39:46.000000000', 'files': ['doc/source/index.rst', 'specs/zed/manila-oversubscription-enhancements.rst'], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/53f01c08ae84ec816bfa4fb76cf5ef1aa8724056', 'message': 'manila oversubscription enhancements\n\nPartially-Implements: blueprint manila-oversubscription-enhancements\n\nChange-Id: I32093c998067c06427b427bc0a66193fc94e1859\n'}]",55,838440,53f01c08ae84ec816bfa4fb76cf5ef1aa8724056,23,5,4,30407,,,0,"manila oversubscription enhancements

Partially-Implements: blueprint manila-oversubscription-enhancements

Change-Id: I32093c998067c06427b427bc0a66193fc94e1859
",git fetch https://review.opendev.org/openstack/manila-specs refs/changes/40/838440/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/zed/manila-oversubscription-enhancements.rst']",2,cbb6ba37c58fe0d46a1d1847d2f98878681024b8,bp/manila-oversubscription-enhancements,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Manila oversubscription enhancements ==================================== https://blueprints.launchpad.net/manila/+spec/manila-oversubscription-enhancements About allocated_capacity_gb and provisioned_capacity_gb, allocated_capacity_gb is shares_gb created on a storage pool via manila. provisioned_capacity_gb is equal to the sum of allocated_capacity_gb add shares_gb_created_manually (or another manila) on the same storage pool. implies that provisioned_capacity_gb greater than or equal to allocated_capacity_gb. It is important for administrators to know these two values in order to obtain information about back-end allocated capacity. For a storage backend that supports thin provisioning,The following describes the reported capacity information. * total_capacity_gb = Total physical disk capacity of the storage pool used by Manila. * free_capacity_gb = total_capacity_gb - Used physical disk capacity of the storage pool. * provisioned_capacity_gb = Total capacity allocated by all shares(include shares created manually or other manila) in the storage pool. * allocated_capacity_gb, Total capacity allocated by all shares created by current manila. Problem Description =================== Problem One: Here's an example. Storage pool pool_A physical disk capacity is 10G. here are four shares in this pool. Share A created by openstack O_A(current manila), share size is 5G. There is a 124MB file in this share. Share B created by openstack O_A, share size is 4G. There is a 0MB file in this share. Share C created by openstack O_B, share size is 3G. There is a 400MB file in this share. Share D created manually, share size is 2G. There is a 500MB file in this share. The total physical capacity in use is 1G(124MB+0MB+400MB+500MB), the result is: total_capacity_gb = 10G free_capacity_gb = 9G provisioned_capacity_gb = 14G (5G+4G+3G+2G) allocated_capacity_gb = 9G (5G+4G, only share A and B is created by current manila) In fact, the storage back end doesn't know how many Manila services are using the storage pool or whether the administrator has manually created shares in the pool. So the allocated_capacity_gb reported by backend storage driver is not correct. only provisioned_capacity_gb reported by backend storage driver is correct. Currently, some drivers(inspur, huawei, netapp, qnap, zadara) report allocated_capacity_gb and some drivers(infinibox, hpe_3par, nexenta) report provisioned_capacity_gb, which is chaotic. Problem Two: About scheduler service supports Active/Active HA, The consume_from_share function is executed each time a share is created or extend, in this function allocated_capacity_gb and free_capacity_gb must be updated,Suppose 100 1gb shares are created, 50 of which are executed on node 1 and 30 on node 2 and 20 on node 3. Since allocated_capacity_gb is maintained in the memory of the scheduling service. As a result, the allocated_capacity_gb values of the three scheduling nodes are inconsistent. This is problematic .We need to calibrate allocated_capacity_gb periodically. Use Cases ========= * The administrator can view the capacity allocation of the back-end storage by allocated_capacity_gb and provisioned_capacity_gb. * Manila scheduler use provisioned_capacity_gb to filter and weigher back-end. Proposed Change =============== This spec proposes to: * for problem one, need to update driver code to report provisioned_capacity_gb instead of allocated_capacity_gb, that means only report provisioned_capacity_gb. * for problem two, Add a periodic task in Manila Share to periodically collect allocated_capacity_gb statistics from the database and record it in self._allocated_capacity_gb(a member variable of class ShareManager). Read self._allocated_capacity_gb and update allocated_capacity_gb in share_stats[pools] when executing _report_driver_status. Because Manila doesn't require very much real-time data for allocated_capacity_gb, Therefore, the interval of periodic tasks can be set to 5 minutes to reduce system and database pressure. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Drivers should update to report provisioned_capacity_gb instead of allocated_capacity_gb. Implementation ============== Assignee(s) ----------- Primary assignee: haixin <haix09@chinatelecom.cn> Work Items ---------- * Update Manager. * Update unittest. * Update related documents. Dependencies ============ None Testing ======= * Add the unit tests Documentation Impact ==================== The following OpenStack documentations will be updated to reflect this change: * OpenStack Contributor Guide References ========== None ",,192,0
openstack%2Fglance-specs~master~I1881a2789d16f60bb22c915dae1c27cd80685079,openstack/glance-specs,master,I1881a2789d16f60bb22c915dae1c27cd80685079,remove unicode prefix from code,MERGED,2022-08-12 14:49:34.000000000,2022-11-10 14:14:15.000000000,2022-11-10 14:12:26.000000000,"[{'_account_id': 5314}, {'_account_id': 8122}, {'_account_id': 19138}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-12 14:49:34.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/348d03c5bda815bbdc843de3142731ef6ae3732e', 'message': 'remove unicode prefix from code\n\nChange-Id: I1881a2789d16f60bb22c915dae1c27cd80685079\n'}]",3,852975,348d03c5bda815bbdc843de3142731ef6ae3732e,10,4,1,35058,,,0,"remove unicode prefix from code

Change-Id: I1881a2789d16f60bb22c915dae1c27cd80685079
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/75/852975/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,348d03c5bda815bbdc843de3142731ef6ae3732e,,"copyright = '%s, OpenStack Glance Team' % datetime.date.today().year","copyright = u'%s, OpenStack Glance Team' % datetime.date.today().year",1,1
openstack%2Fglance-specs~master~If279a3122ccf5c1d88f688025f877de2ac9d339b,openstack/glance-specs,master,If279a3122ccf5c1d88f688025f877de2ac9d339b,Fix redirects,MERGED,2022-09-19 13:15:46.000000000,2022-11-10 14:13:24.000000000,2022-11-10 14:12:17.000000000,"[{'_account_id': 8122}, {'_account_id': 9303}, {'_account_id': 19138}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-19 13:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/36d683f68bd114724562e693cd22e730efe440c6', 'message': ""Fix redirects\n\nMany redirects are not currently working because they reference\nthe '.rst' version of a file, whereas the only files available\nto the http server are the built '.html' files.\n\nChange-Id: If279a3122ccf5c1d88f688025f877de2ac9d339b\n""}, {'number': 2, 'created': '2022-09-19 13:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/8bf2e35163069ede71abca6ee5b8483d04705c14', 'message': ""Fix redirects\n\nMany redirects are not currently working because they reference\nthe '.rst' version of a file, whereas the only files available\nto the http server are the built '.html' files.\n\nChange-Id: If279a3122ccf5c1d88f688025f877de2ac9d339b\n""}, {'number': 3, 'created': '2022-09-19 14:11:26.000000000', 'files': ['doc/test/redirect-tests.txt', 'doc/source/_extra/.htaccess'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/aa8a8c70d32d905f281bb837ea9c4b8536ddf789', 'message': ""Fix redirects\n\nMany redirects are not currently working because they reference\nthe '.rst' version of a file, whereas the only files available\nto the http server are the built '.html' files.\n\nChange-Id: If279a3122ccf5c1d88f688025f877de2ac9d339b\n""}]",2,858377,aa8a8c70d32d905f281bb837ea9c4b8536ddf789,13,4,3,5314,,,0,"Fix redirects

Many redirects are not currently working because they reference
the '.rst' version of a file, whereas the only files available
to the http server are the built '.html' files.

Change-Id: If279a3122ccf5c1d88f688025f877de2ac9d339b
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/77/858377/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/_extra/.htaccess'],1,36d683f68bd114724562e693cd22e730efe440c6,fix-redirects,Redirect 301 /openstack/glance-specs/specs/queens/approved/python-glanceclient/deprecate-v1-support.html /openstack/glance-specs/specs/rocky/approved/python-glanceclient/deprecate-v1-support.htmlRedirect 301 /openstack/glance-specs/specs/rocky/approved/glance/spec-lite-deprecate-owner_is_tenant.html /openstack/glance-specs/specs/rocky/implemented/glance/spec-lite-deprecate-owner_is_tenant.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/Support-revert-pending-delete.html /openstack/glance-specs/specs/rocky/implemented/glance/Support-revert-pending-delete.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/mitigate-ossn-0075.html /openstack/glance-specs/specs/rocky/implemented/glance/mitigate-ossn-0075.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/multihash.html /openstack/glance-specs/specs/rocky/implemented/glance/multihash.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/multi-store.html /openstack/glance-specs/specs/rocky/implemented/glance/multi-store.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/operator-image-workflow.html /openstack/glance-specs/specs/rocky/implemented/glance/operator-image-workflow.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/remove-v1.html /openstack/glance-specs/specs/rocky/implemented/glance/remove-v1.html Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance_store/deprecate-store_capabilities_update_min_interval.html /openstack/glance-specs/specs/rocky/implemented/glance_store/deprecate-store_capabilities_update_min_interval.html Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/all-visibility-image-filter.html /openstack/glance-specs/specs/stein/implemented/glance/all-visibility-image-filter.html Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/windows-support.html /openstack/glance-specs/specs/stein/implemented/glance/windows-support.html Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/spec-lite-locations-with-validation-data.html /openstack/glance-specs/specs/stein/implemented/glance/spec-lite-locations-with-validation-data.html Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/spec-lite-add-description-field-to-image.html /openstack/glance-specs/specs/stein/implemented/glance/spec-lite-add-description-field-to-image.html Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/spec-lite-readding-glance-cache-manage-for-v2.html /openstack/glance-specs/specs/stein/implemented/glance/spec-lite-readding-glance-cache-manage-for-v2.html Redirect 301 /openstack/glance-specs/specs/stein/approved/python-glanceclient/spec-lite-show-store-info.html /openstack/glance-specs/specs/stein/implemented/python-glanceclient/spec-lite-show-store-info.html,Redirect 301 /openstack/glance-specs/specs/queens/approved/python-glanceclient/deprecate-v1-support.rst /openstack/glance-specs/specs/rocky/approved/python-glanceclient/deprecate-v1-support.rstRedirect 301 /openstack/glance-specs/specs/rocky/approved/glance/spec-lite-deprecate-owner_is_tenant.rst /openstack/glance-specs/specs/rocky/implemented/glance/spec-lite-deprecate-owner_is_tenant.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/Support-revert-pending-delete.rst /openstack/glance-specs/specs/rocky/implemented/glance/Support-revert-pending-delete.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/mitigate-ossn-0075.rst /openstack/glance-specs/specs/rocky/implemented/glance/mitigate-ossn-0075.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/multihash.rst /openstack/glance-specs/specs/rocky/implemented/glance/multihash.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/multi-store.rst /openstack/glance-specs/specs/rocky/implemented/glance/multi-store.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/operator-image-workflow.rst /openstack/glance-specs/specs/rocky/implemented/glance/operator-image-workflow.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance/remove-v1.rst /openstack/glance-specs/specs/rocky/implemented/glance/remove-v1.rst Redirect 301 /openstack/glance-specs/specs/rocky/approved/glance_store/deprecate-store_capabilities_update_min_interval.rst /openstack/glance-specs/specs/rocky/implemented/glance_store/deprecate-store_capabilities_update_min_interval.rst Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/all-visibility-image-filter.rst /openstack/glance-specs/specs/stein/implemented/glance/all-visibility-image-filter.rst Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/windows-support.rst /openstack/glance-specs/specs/stein/implemented/glance/windows-support.rst Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/spec-lite-locations-with-validation-data.rst /openstack/glance-specs/specs/stein/implemented/glance/spec-lite-locations-with-validation-data.rst Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/spec-lite-add-description-field-to-image.rst /openstack/glance-specs/specs/stein/implemented/glance/spec-lite-add-description-field-to-image.rst Redirect 301 /openstack/glance-specs/specs/stein/approved/glance/spec-lite-readding-glance-cache-manage-for-v2.rst /openstack/glance-specs/specs/stein/implemented/glance/spec-lite-readding-glance-cache-manage-for-v2.rst Redirect 301 /openstack/glance-specs/specs/stein/approved/python-glanceclient/spec-lite-show-store-info.rst /openstack/glance-specs/specs/stein/implemented/python-glanceclient/spec-lite-show-store-info.rst,15,15
openstack%2Fopenstacksdk~master~If8306f879361f872a1a87d589c756d9ae2435449,openstack/openstacksdk,master,If8306f879361f872a1a87d589c756d9ae2435449,Use /servers/detail endpoint in find_server proxy method,MERGED,2022-09-16 00:08:39.000000000,2022-11-10 13:57:08.000000000,2022-11-10 13:56:02.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-09-16 00:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/03d71a93f8bcaa34d5478629dc1404655511deaf', 'message': 'Use /servers/detail endpoint in find_server proxy method\n\nChange-Id: If8306f879361f872a1a87d589c756d9ae2435449\n'}, {'number': 2, 'created': '2022-09-16 04:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/49783b7adf8753207907059eaa428addb26e76d0', 'message': 'Use /servers/detail endpoint in find_server proxy method\n\nChange-Id: If8306f879361f872a1a87d589c756d9ae2435449\n'}, {'number': 3, 'created': '2022-09-29 21:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6fa752a4c4df4cb1293b37c7932f0c984ab236d9', 'message': 'Use /servers/detail endpoint in find_server proxy method\n\nCurrently, find_server will return the objects with different\nfields filled in depending on whether the term provided is an id or a\nname. This patch, in the same vein of [0], changes the find_server\nmethod so it uses the /servers/detail endpoint to find servers in the\ncase of a name being provided. This ensures that the method fills in all\nfields in every case.\n\n[0] https://review.opendev.org/c/openstack/openstacksdk/+/854293\n\nChange-Id: If8306f879361f872a1a87d589c756d9ae2435449\n'}, {'number': 4, 'created': '2022-11-01 15:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b95ab5e9f8e6a44424c71ed33290ee70e918b89c', 'message': 'Use /servers/detail endpoint in find_server proxy method\n\nCurrently, find_server will return the objects with different\nfields filled in depending on whether the term provided is an id or a\nname. This patch, in the same vein of [0], changes the find_server\nmethod so it uses the /servers/detail endpoint to find servers in the\ncase of a name being provided. This ensures that the method fills in all\nfields in every case.\n\n[0] https://review.opendev.org/c/openstack/openstacksdk/+/854293\n\nChange-Id: If8306f879361f872a1a87d589c756d9ae2435449\n'}, {'number': 5, 'created': '2022-11-01 15:56:15.000000000', 'files': ['openstack/tests/unit/cloud/test_update_server.py', 'openstack/tests/unit/cloud/test_delete_server.py', 'openstack/tests/unit/compute/v2/test_proxy.py', 'releasenotes/notes/find_server-use-details-9a22e83ec6540c98.yaml', 'openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/25ec686c5b096e7980d60079c86ff5deaa28fd8c', 'message': 'Use /servers/detail endpoint in find_server proxy method\n\nCurrently, find_server will return the objects with different\nfields filled in depending on whether the term provided is an id or a\nname. This patch, in the same vein of [0], changes the find_server\nmethod so it uses the /servers/detail endpoint to find servers in the\ncase of a name being provided. This ensures that the method fills in all\nfields in every case.\n\n[0] https://review.opendev.org/c/openstack/openstacksdk/+/854293\n\nChange-Id: If8306f879361f872a1a87d589c756d9ae2435449\n'}]",9,857987,25ec686c5b096e7980d60079c86ff5deaa28fd8c,18,3,5,34208,,,0,"Use /servers/detail endpoint in find_server proxy method

Currently, find_server will return the objects with different
fields filled in depending on whether the term provided is an id or a
name. This patch, in the same vein of [0], changes the find_server
method so it uses the /servers/detail endpoint to find servers in the
case of a name being provided. This ensures that the method fills in all
fields in every case.

[0] https://review.opendev.org/c/openstack/openstacksdk/+/854293

Change-Id: If8306f879361f872a1a87d589c756d9ae2435449
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/87/857987/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/cloud/test_update_server.py', 'openstack/tests/unit/cloud/test_delete_server.py', 'openstack/tests/unit/compute/v2/test_proxy.py', 'openstack/compute/v2/_proxy.py']",4,03d71a93f8bcaa34d5478629dc1404655511deaf,,"#user/guides/clustering/ Licensed under the Apache License, Version 2.0 (the ""License""); you may ignore_missing=ignore_missing, list_base_path='/servers/detail')","# Licensed under the Apache License, Version 2.0 (the ""License""); you may ignore_missing=ignore_missing)",17,14
openstack%2Fkolla-ansible~master~I87845ec386fda3c6582abad37ae7d8600f222000,openstack/kolla-ansible,master,I87845ec386fda3c6582abad37ae7d8600f222000,octavia: run auto_configure only when amphora is enabled,MERGED,2022-10-28 09:59:37.000000000,2022-11-10 13:35:12.000000000,2022-11-10 12:14:49.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-10-28 09:59:37.000000000', 'files': ['ansible/group_vars/all.yml', 'tests/templates/globals-default.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/587f5382de6256a736d2166f28faa604512a7183', 'message': 'octavia: run auto_configure only when amphora is enabled\n\nChange-Id: I87845ec386fda3c6582abad37ae7d8600f222000\n'}]",3,862877,587f5382de6256a736d2166f28faa604512a7183,11,3,1,22629,,,0,"octavia: run auto_configure only when amphora is enabled

Change-Id: I87845ec386fda3c6582abad37ae7d8600f222000
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/77/862877/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all.yml', 'tests/templates/globals-default.j2']",2,587f5382de6256a736d2166f28faa604512a7183,,,"octavia_auto_configure: ""no""",1,2
openstack%2Ftripleo-heat-templates~master~I0661d3b3e41f49c7eae071f7d60b752243c03037,openstack/tripleo-heat-templates,master,I0661d3b3e41f49c7eae071f7d60b752243c03037,DNM test OctaviaLogOffloadProtocol,ABANDONED,2022-06-24 15:32:53.000000000,2022-11-10 13:13:29.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-06-24 15:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5980ef36672219972f4b6e188c2678b4e19214c2', 'message': 'DNM test OctaviaLogOffloadProtocol\n\nChange-Id: I0661d3b3e41f49c7eae071f7d60b752243c03037\n'}, {'number': 2, 'created': '2022-06-27 15:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a90be8385205ebc39405549b4d0d06cd07b57bb', 'message': 'DNM test OctaviaLogOffloadProtocol\n\nChange-Id: I0661d3b3e41f49c7eae071f7d60b752243c03037\n'}, {'number': 3, 'created': '2022-06-28 12:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/877b04b1f23b86191ec4b2a30a05bcab34a51668', 'message': 'DNM test OctaviaLogOffloadProtocol\n\nChange-Id: I0661d3b3e41f49c7eae071f7d60b752243c03037\n'}, {'number': 4, 'created': '2022-07-04 14:37:47.000000000', 'files': ['ci/environments/scenario010-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3a98b83ec110dc75f791ee0fb1be3d17640531c7', 'message': 'DNM test OctaviaLogOffloadProtocol\n\nChange-Id: I0661d3b3e41f49c7eae071f7d60b752243c03037\n'}]",3,847588,3a98b83ec110dc75f791ee0fb1be3d17640531c7,23,2,4,34429,,,0,"DNM test OctaviaLogOffloadProtocol

Change-Id: I0661d3b3e41f49c7eae071f7d60b752243c03037
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/88/847588/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario010-standalone.yaml'],1,5980ef36672219972f4b6e188c2678b4e19214c2,rsyslog-tcp-offloading, OctaviaLogOffloadProtocol: tcp,,1,0
openstack%2Fpython-openstackclient~master~I1d968181eb196c6df4583c772c67ed58bc7ba585,openstack/python-openstackclient,master,I1d968181eb196c6df4583c772c67ed58bc7ba585,tests: Convert more functional tests to use 'parse_output',MERGED,2022-11-07 17:24:25.000000000,2022-11-10 13:11:23.000000000,2022-11-10 13:10:21.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-07 17:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6b42d78f71855b4c8067213114419578786bfbe2', 'message': ""tests: Convert more functional tests to use 'parse_output'\n\nChange-Id: I1d968181eb196c6df4583c772c67ed58bc7ba585\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2022-11-08 11:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/833e192c374f47961ddb667863db8205341d60e8', 'message': ""tests: Convert more functional tests to use 'parse_output'\n\nChange-Id: I1d968181eb196c6df4583c772c67ed58bc7ba585\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2022-11-08 16:48:11.000000000', 'files': ['openstackclient/tests/functional/common/test_extension.py', 'openstackclient/tests/functional/common/test_quota.py', 'openstackclient/tests/functional/common/test_args.py', 'openstackclient/tests/functional/common/test_versions.py', 'openstackclient/tests/functional/common/test_availability_zone.py', 'openstackclient/tests/functional/common/test_configuration.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/38e39b6dc14fd88318541728cb34fd8442d59e8a', 'message': ""tests: Convert more functional tests to use 'parse_output'\n\nChange-Id: I1d968181eb196c6df4583c772c67ed58bc7ba585\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,863909,38e39b6dc14fd88318541728cb34fd8442d59e8a,12,3,3,15334,,,0,"tests: Convert more functional tests to use 'parse_output'

Change-Id: I1d968181eb196c6df4583c772c67ed58bc7ba585
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/09/863909/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/functional/common/test_extension.py', 'openstackclient/tests/functional/common/test_args.py', 'openstackclient/tests/functional/common/test_quota.py', 'openstackclient/tests/functional/common/test_versions.py', 'openstackclient/tests/functional/common/test_availability_zone.py', 'openstackclient/tests/functional/volume/v3/test_transfer_request.py', 'openstackclient/tests/functional/common/test_configuration.py', 'openstackclient/tests/functional/identity/v3/test_project.py']",8,6b42d78f71855b4c8067213114419578786bfbe2,smarter-functional-tests," output = self.openstack( '--parents --children ' 'name': self.project_name}, parse_output=True, ) for attr_name in (self.PROJECT_FIELDS + ['parents', 'subtree']): self.assertIn(attr_name, output) self.assertEqual(self.project_name, output.get('name'))","import json json_output = json.loads(self.openstack( '--parents --children -f json ' 'name': self.project_name})) for attr_name in (self.PROJECT_FIELDS + ['parents', 'subtree']): self.assertIn(attr_name, json_output) self.assertEqual(self.project_name, json_output.get('name'))",141,147
openstack%2Fpython-openstackclient~master~Ic3b8958bd4fb1459a8ac3adaff216c2a26628491,openstack/python-openstackclient,master,Ic3b8958bd4fb1459a8ac3adaff216c2a26628491,tests: Move json decoding to base test class,MERGED,2022-11-07 17:24:25.000000000,2022-11-10 13:01:57.000000000,2022-11-10 13:00:50.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-07 17:24:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fbb04441d6e97518baf6c6122a6c231e6d3b83a9', 'message': 'tests: Move json decoding to base test class\n\nWe do this everywhere. Add a simple knob to simplify the pattern. Only\none use is migrated initially. The rest will be done separately.\n\nChange-Id: Ic3b8958bd4fb1459a8ac3adaff216c2a26628491\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2022-11-08 11:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c6795b3ceac52eaa0e91cbc2ede4b93ae25091e8', 'message': 'tests: Move json decoding to base test class\n\nWe do this everywhere. Add a simple knob to simplify the pattern. Only\none use is migrated initially. The rest will be done separately.\n\nChange-Id: Ic3b8958bd4fb1459a8ac3adaff216c2a26628491\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2022-11-08 16:48:11.000000000', 'files': ['openstackclient/tests/functional/base.py', 'openstackclient/tests/functional/common/test_module.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a244bb84e07617dad12dee91bbe63bdca3357b1e', 'message': 'tests: Move json decoding to base test class\n\nWe do this everywhere. Add a simple knob to simplify the pattern. Only\none use is migrated initially. The rest will be done separately.\n\nChange-Id: Ic3b8958bd4fb1459a8ac3adaff216c2a26628491\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,863908,a244bb84e07617dad12dee91bbe63bdca3357b1e,12,3,3,15334,,,0,"tests: Move json decoding to base test class

We do this everywhere. Add a simple knob to simplify the pattern. Only
one use is migrated initially. The rest will be done separately.

Change-Id: Ic3b8958bd4fb1459a8ac3adaff216c2a26628491
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/08/863908/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/functional/base.py', 'openstackclient/tests/functional/common/test_module.py']",2,fbb04441d6e97518baf6c6122a6c231e6d3b83a9,smarter-functional-tests," cmd_output = self.openstack('module list', parse_output=True) cmd_output = self.openstack('module list --all', parse_output=True) cmd_output = self.openstack('command list', parse_output=True) cmd_output = self.openstack( 'command list --group %s' % each_input, parse_output=True, )",# import json cmd_output = json.loads(self.openstack('module list -f json')) cmd_output = json.loads(self.openstack('module list --all -f json')) cmd_output = json.loads(self.openstack('command list -f json')) cmd_output = json.loads(self.openstack( 'command list --group %s -f json' % each_input )),42,30
openstack%2Fmagnum~master~I432d6d7a0fedee4596b5fd8a7849f23d93255f63,openstack/magnum,master,I432d6d7a0fedee4596b5fd8a7849f23d93255f63,Remove stdout argument from coredns log,ABANDONED,2022-11-09 10:31:48.000000000,2022-11-10 11:58:58.000000000,,"[{'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-11-09 10:31:48.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/core-dns-service.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/36555598027a06ade3f6d227693eb0f7f45ab801', 'message': ""Remove stdout argument from coredns log\n\nAccording to the documentation the first argument to log is either a\ndomain or a '.' (dot). The current setting of 'log stdout' appears to\nblackhole query logs. The default output of log is stdout so the\nargument would not be necessary.\n\nRemoving `stdout` allows coredns to send query logs to stdout.\n\nReference: https://coredns.io/plugins/log/\n\nCo-authored-by: Travis Holton <travisholton@catalystcloud.nz>\nChange-Id: I432d6d7a0fedee4596b5fd8a7849f23d93255f63\n""}]",0,864101,36555598027a06ade3f6d227693eb0f7f45ab801,4,2,1,8064,,,0,"Remove stdout argument from coredns log

According to the documentation the first argument to log is either a
domain or a '.' (dot). The current setting of 'log stdout' appears to
blackhole query logs. The default output of log is stdout so the
argument would not be necessary.

Removing `stdout` allows coredns to send query logs to stdout.

Reference: https://coredns.io/plugins/log/

Co-authored-by: Travis Holton <travisholton@catalystcloud.nz>
Change-Id: I432d6d7a0fedee4596b5fd8a7849f23d93255f63
",git fetch https://review.opendev.org/openstack/magnum refs/changes/01/864101/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/common/templates/kubernetes/fragments/core-dns-service.sh'],1,36555598027a06ade3f6d227693eb0f7f45ab801,fix-coredns-logging, log, log stdout,1,1
openstack%2Fmagnum~master~Id4726d272c6ac11c01bd027a795dc3ba624bdaec,openstack/magnum,master,Id4726d272c6ac11c01bd027a795dc3ba624bdaec,remove unicode from code,MERGED,2022-08-19 03:04:30.000000000,2022-11-10 11:17:26.000000000,2022-11-10 11:16:20.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-19 03:04:30.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/cb71864c706c3e0da85a7a14e2a8c3b4180b77f8', 'message': 'remove unicode from code\n\nChange-Id: Id4726d272c6ac11c01bd027a795dc3ba624bdaec\n'}]",0,853747,cb71864c706c3e0da85a7a14e2a8c3b4180b77f8,7,2,1,31412,,,0,"remove unicode from code

Change-Id: Id4726d272c6ac11c01bd027a795dc3ba624bdaec
",git fetch https://review.opendev.org/openstack/magnum refs/changes/47/853747/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,cb71864c706c3e0da85a7a14e2a8c3b4180b77f8,,"copyright = '2016, Magnum developers' ('index', 'MagnumReleaseNotes.tex', 'Magnum Release Notes Documentation', '2016, Magnum developers', 'manual'), ('index', 'magnumreleasenotes', 'Magnum Release Notes Documentation', ['2016, Magnum developers'], 1) ('index', 'MagnumReleaseNotes', 'Magnum Release Notes Documentation', '2016, Magnum developers', 'MagnumReleaseNotes',","copyright = u'2016, Magnum developers' ('index', 'MagnumReleaseNotes.tex', u'Magnum Release Notes Documentation', u'2016, Magnum developers', 'manual'), ('index', 'magnumreleasenotes', u'Magnum Release Notes Documentation', [u'2016, Magnum developers'], 1) ('index', 'MagnumReleaseNotes', u'Magnum Release Notes Documentation', u'2016, Magnum developers', 'MagnumReleaseNotes',",7,7
openstack%2Fpython-magnumclient~master~Ibdf2f5d6a975d91208e7f14dc027c0c4e962533f,openstack/python-magnumclient,master,Ibdf2f5d6a975d91208e7f14dc027c0c4e962533f,remove unicode from code,MERGED,2022-08-25 02:22:26.000000000,2022-11-10 11:17:09.000000000,2022-11-10 11:16:15.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-25 02:22:26.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/fa93fcf5823287d89fbac21c18afce03c2eda2b7', 'message': 'remove unicode from code\n\nChange-Id: Ibdf2f5d6a975d91208e7f14dc027c0c4e962533f\n'}]",0,854475,fa93fcf5823287d89fbac21c18afce03c2eda2b7,7,2,1,35067,,,0,"remove unicode from code

Change-Id: Ibdf2f5d6a975d91208e7f14dc027c0c4e962533f
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/75/854475/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,fa93fcf5823287d89fbac21c18afce03c2eda2b7,,"project = 'MagnumClientReleaseNotes' copyright = '2016, OpenStack Foundation' 'MagnumClient ReleaseNotes Documentation', 'OpenStack Foundation', 'manual'), 'MagnumClient ReleaseNotes Documentation', ['OpenStack Foundation'], 1) 'MagnumClient ReleaseNotes Documentation', 'OpenStack Foundation', 'MagnumClientReleaseNotes',","project = u'MagnumClientReleaseNotes' copyright = u'2016, OpenStack Foundation' u'MagnumClient ReleaseNotes Documentation', u'OpenStack Foundation', 'manual'), u'MagnumClient ReleaseNotes Documentation', [u'OpenStack Foundation'], 1) u'MagnumClient ReleaseNotes Documentation', u'OpenStack Foundation', 'MagnumClientReleaseNotes',",12,12
openstack%2Fmagnum-tempest-plugin~master~Id51cab6f2cca118d091b38ddb957dd2a5c220f5c,openstack/magnum-tempest-plugin,master,Id51cab6f2cca118d091b38ddb957dd2a5c220f5c,remove unicode prefix from code,MERGED,2022-08-24 03:02:11.000000000,2022-11-10 11:16:07.000000000,2022-11-10 11:16:07.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-24 03:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/cb94f56c99756b2393279ac90bbec2e9321868b4', 'message': 'remove unicode prefix from code\n\nChange-Id: Id51cab6f2cca118d091b38ddb957dd2a5c220f5c\n'}, {'number': 2, 'created': '2022-08-24 03:03:43.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/0982123fdbe6efcbc2b9ffa6166f6629ea2c3c12', 'message': 'remove unicode prefix from code\n\nChange-Id: Id51cab6f2cca118d091b38ddb957dd2a5c220f5c\n'}]",0,854169,0982123fdbe6efcbc2b9ffa6166f6629ea2c3c12,7,2,2,35058,,,0,"remove unicode prefix from code

Change-Id: Id51cab6f2cca118d091b38ddb957dd2a5c220f5c
",git fetch https://review.opendev.org/openstack/magnum-tempest-plugin refs/changes/69/854169/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,cb94f56c99756b2393279ac90bbec2e9321868b4,,"project = 'magnum-tempest-plugin' copyright = '2017, OpenStack Developers' '%s Documentation' % project, 'OpenStack Developers', 'manual'),","project = u'magnum-tempest-plugin' copyright = u'2017, OpenStack Developers' u'%s Documentation' % project, u'OpenStack Developers', 'manual'),",4,4
openstack%2Fmagnum-specs~master~I376f75683be5101db3f41b152bb42ae88bb56fca,openstack/magnum-specs,master,I376f75683be5101db3f41b152bb42ae88bb56fca,remove unicode prefix from code,MERGED,2022-08-24 03:12:13.000000000,2022-11-10 11:13:15.000000000,2022-11-10 11:12:19.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-24 03:12:13.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/c549fba9258999c644e47be36f24ea109f16e365', 'message': 'remove unicode prefix from code\n\nChange-Id: I376f75683be5101db3f41b152bb42ae88bb56fca\n'}]",0,854311,c549fba9258999c644e47be36f24ea109f16e365,7,2,1,35058,,,0,"remove unicode prefix from code

Change-Id: I376f75683be5101db3f41b152bb42ae88bb56fca
",git fetch https://review.opendev.org/openstack/magnum-specs refs/changes/11/854311/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,c549fba9258999c644e47be36f24ea109f16e365,,"project = 'Magnum Specs' copyright = '%s, OpenStack Containers Team' % datetime.date.today().year '%s Documentation' % project, 'OpenStack Foundation', 'manual'),","project = u'Magnum Specs' copyright = u'%s, OpenStack Containers Team' % datetime.date.today().year u'%s Documentation' % project, u'OpenStack Foundation', 'manual'),",4,4
openstack%2Fmagnum-specs~master~I136b88f5f207acd455ad5e2e262bbbfa7774fe15,openstack/magnum-specs,master,I136b88f5f207acd455ad5e2e262bbbfa7774fe15,setup.cfg: Replace dashes by underscores,MERGED,2022-08-19 02:16:56.000000000,2022-11-10 11:11:49.000000000,2022-11-10 11:10:48.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-19 02:16:56.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/8ae2d398770c2a36e01f43f233997c569840ddd2', 'message': ""setup.cfg: Replace dashes by underscores\n\nSince setuptools v54.1.0[1], the parmeters with dash have been\ndeprecated in favor of the new parameters with underscore.\n\nThis change updates the parameters accordingly to avoid the warnings\nlike the example below.\n\n  UserWarning: Usage of dash-separated 'description-file' will not be\n  supported in future versions. Please use the underscore name\n  'description_file' instead\n\n[1] https://github.com/pypa/setuptools/commit/a2e9ae4cb\n\nChange-Id: I136b88f5f207acd455ad5e2e262bbbfa7774fe15\n""}]",0,853740,8ae2d398770c2a36e01f43f233997c569840ddd2,7,2,1,31412,,,0,"setup.cfg: Replace dashes by underscores

Since setuptools v54.1.0[1], the parmeters with dash have been
deprecated in favor of the new parameters with underscore.

This change updates the parameters accordingly to avoid the warnings
like the example below.

  UserWarning: Usage of dash-separated 'description-file' will not be
  supported in future versions. Please use the underscore name
  'description_file' instead

[1] https://github.com/pypa/setuptools/commit/a2e9ae4cb

Change-Id: I136b88f5f207acd455ad5e2e262bbbfa7774fe15
",git fetch https://review.opendev.org/openstack/magnum-specs refs/changes/40/853740/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,8ae2d398770c2a36e01f43f233997c569840ddd2,,description_file =author_email = openstack-discuss@lists.openstack.org home_page = https://specs.openstack.org/openstack/magnum-specs/,description-file =author-email = openstack-discuss@lists.openstack.org home-page = https://specs.openstack.org/openstack/magnum-specs/,3,3
openstack%2Fdiskimage-builder~master~I0772a9b9c002cffb1b4bd7dc942623601f0f0b12,openstack/diskimage-builder,master,I0772a9b9c002cffb1b4bd7dc942623601f0f0b12,DNM testing the combo of the depends on,NEW,2022-10-20 19:44:17.000000000,2022-11-10 10:17:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-20 19:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5db4f9075c61d48cdc17b5f67b7a66fff141b235', 'message': 'DNM testing the combo of the depends on\n\nThis should exercise siblings handling in the image builds.\n\nDepends-On: https://review.opendev.org/c/opendev/system-config/+/862152\nDepends-On: https://review.opendev.org/c/zuul/nodepool/+/861797\nChange-Id: I0772a9b9c002cffb1b4bd7dc942623601f0f0b12\n'}, {'number': 2, 'created': '2022-10-20 22:51:38.000000000', 'files': ['diskimage_builder/elements/simple-init/post-install.d/80-simple-init', 'diskimage_builder/elements/simple-init/README.rst'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/deabcffd525730e16fc053a817b2093cbadaf401', 'message': 'DNM testing the combo of the depends on\n\nThis should exercise siblings handling in the image builds.\n\nDepends-On: https://review.opendev.org/c/opendev/system-config/+/862152\nDepends-On: https://review.opendev.org/c/zuul/nodepool/+/861797\nChange-Id: I0772a9b9c002cffb1b4bd7dc942623601f0f0b12\n'}]",2,862187,deabcffd525730e16fc053a817b2093cbadaf401,35,1,2,4146,,,0,"DNM testing the combo of the depends on

This should exercise siblings handling in the image builds.

Depends-On: https://review.opendev.org/c/opendev/system-config/+/862152
Depends-On: https://review.opendev.org/c/zuul/nodepool/+/861797
Change-Id: I0772a9b9c002cffb1b4bd7dc942623601f0f0b12
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/87/862187/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/simple-init/README.rst'],1,5db4f9075c61d48cdc17b5f67b7a66fff141b235,test-pip-wheel-nodepool-image,DNM testing changes to base docker images and want to see siblings job run. ,,3,0
openstack%2Fdevstack~master~I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8,openstack/devstack,master,I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8,Add LVM NVMe support,MERGED,2021-10-15 15:51:44.000000000,2022-11-10 10:11:00.000000000,2022-11-10 10:10:02.000000000,"[{'_account_id': 4393}, {'_account_id': 5314}, {'_account_id': 9236}, {'_account_id': 13252}, {'_account_id': 13425}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2021-10-15 15:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/344e7998258985faccfc3ceb9006dee945e3f69d', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe obsolete the CINDER_ISCSI_HELPER configuration option since we are no\nlonger limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol we'll be using Soft-RoCE and create a\ndevice on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nDepends-On: https://review.opendev.org/c/openstack/cinder/+/791929\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}, {'number': 2, 'created': '2022-02-01 16:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8456e239742bbf81d878d528f395d51112e835b7', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe obsolete the CINDER_ISCSI_HELPER configuration option since we are no\nlonger limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol we'll be using Soft-RoCE and create a\ndevice on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nDepends-On: https://review.opendev.org/c/openstack/cinder/+/791929\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}, {'number': 3, 'created': '2022-02-15 17:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/152e837363fc9ed684777a05cab6c0d1152d9aed', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe deprecate the CINDER_ISCSI_HELPER configuration option since we are\nno longer limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol devstack will be using Soft-RoCE and\ncreating a device on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nDepends-On: https://review.opendev.org/c/openstack/cinder/+/791929\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}, {'number': 4, 'created': '2022-04-01 13:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/72a21c5a02ad50db90e8582c9fc6ad7137bfbe88', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe deprecate the CINDER_ISCSI_HELPER configuration option since we are\nno longer limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol devstack will be using Soft-RoCE and\ncreating a device on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}, {'number': 5, 'created': '2022-05-26 15:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/baa888faec751284c53c7770d4747c88e8693dfd', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe deprecate the CINDER_ISCSI_HELPER configuration option since we are\nno longer limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol devstack will be using Soft-RoCE and\ncreating a device on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}, {'number': 6, 'created': '2022-07-18 18:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/78ee24302edba9409c9fbd1d51549ea7c86a04fd', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe deprecate the CINDER_ISCSI_HELPER configuration option since we are\nno longer limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol devstack will be using Soft-RoCE and\ncreating a device on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}, {'number': 7, 'created': '2022-09-13 10:53:38.000000000', 'files': ['lib/lvm', 'lib/cinder_backends/lvm', 'lib/cinder', 'lib/cinder_backends/fake_gate', 'lib/nova', 'doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/97061c9a1f2a2989e0bacb5f7cc5910c75aaeb44', 'message': ""Add LVM NVMe support\n\nThis patch adds NVMe LVM support to the existing iSCSI LVM configuration\nsupport.\n\nWe deprecate the CINDER_ISCSI_HELPER configuration option since we are\nno longer limited to iSCSI, and replace it with the CINDER_TARGET_HELPER\noption.\n\nThe patch also adds another 3 target configuration options:\n\n- CINDER_TARGET_PROTOCOL\n- CINDER_TARGET_PREFIX\n- CINDER_TARGET_PORT\n\nThese options will have different defaults based on the selected target\nhelper.  For tgtadm and lioadm they'll be iSCSI,\niqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll\nbe nvmet_rdma, nvme-subsystem-1, and 4420.\n\nBesides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to\nnvmet_tcp, and nvmet_fc.\n\nFor the RDMA transport protocol devstack will be using Soft-RoCE and\ncreating a device on top of the network interface.\n\nLVM NVMe-TCP support is added in the dependency mentioned in the footer\nand LVM NVMe-FC will be added in later patches (need os-brick and cinder\npatches) but the code here should still be valid.\n\nChange-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8\n""}]",38,814193,97061c9a1f2a2989e0bacb5f7cc5910c75aaeb44,43,8,7,9535,,,0,"Add LVM NVMe support

This patch adds NVMe LVM support to the existing iSCSI LVM configuration
support.

We deprecate the CINDER_ISCSI_HELPER configuration option since we are
no longer limited to iSCSI, and replace it with the CINDER_TARGET_HELPER
option.

The patch also adds another 3 target configuration options:

- CINDER_TARGET_PROTOCOL
- CINDER_TARGET_PREFIX
- CINDER_TARGET_PORT

These options will have different defaults based on the selected target
helper.  For tgtadm and lioadm they'll be iSCSI,
iqn.2010-10.org.openstack:, and 3260 respectively, and for nvmet they'll
be nvmet_rdma, nvme-subsystem-1, and 4420.

Besides nvmet_rdma the CINDER_TARGET_PROTOCOL option can also be set to
nvmet_tcp, and nvmet_fc.

For the RDMA transport protocol devstack will be using Soft-RoCE and
creating a device on top of the network interface.

LVM NVMe-TCP support is added in the dependency mentioned in the footer
and LVM NVMe-FC will be added in later patches (need os-brick and cinder
patches) but the code here should still be valid.

Change-Id: I6578cdc27489b34916cdeb72ba3fdf06ea9d4ad8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/93/814193/7 && git format-patch -1 --stdout FETCH_HEAD,"['files/rpms/os-brick', 'lib/cinder', 'lib/cinder_backends/fake_gate', 'lib/nova', 'files/rpms/n-cpu', 'doc/source/configuration.rst', 'files/rpms-suse/n-cpu', 'files/rpms-suse/os-brick', 'lib/lvm', 'lib/cinder_backends/lvm', 'files/debs/n-cpu', 'files/debs/os-brick']",12,344e7998258985faccfc3ceb9006dee945e3f69d,nvme,nvme-cli,,117,23
openstack%2Freleases~master~Iaf476c80eed5c71316764890b40a631e1df12758,openstack/releases,master,Iaf476c80eed5c71316764890b40a631e1df12758,Release manila-tempest-plugin,MERGED,2022-11-08 21:37:23.000000000,2022-11-10 10:03:11.000000000,2022-11-10 10:03:11.000000000,"[{'_account_id': 308}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-11-08 21:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/993f84607bb8b92cf7d07779fae3bc76f0eefb19', 'message': 'Release manila-tempest-plugin\n\nCouple of RBAC tests were included in the manila-tempest-plugin\nrepository, alongside some good fixes:\n\n$ git log --oneline --no-merges 1.10.0..256a6b0\na325504 Remove ""alt_project_share_v2_client"" client initialization\n3d2b7bb More Snapshot metadata field verification >= 2.73\n75dbca6 Add a metadata field shown on API >= 2.73\n7b2566a Add S-RBAC tests for manila\n5e559df Move skip condition under skip_checks class method\n8125ca4 Replace period to underscore\n\nChange-Id: Iaf476c80eed5c71316764890b40a631e1df12758\n'}, {'number': 2, 'created': '2022-11-09 20:14:09.000000000', 'files': ['deliverables/antelope/manila-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e79fa6217de45517a797c8c1d03a1dc23dc1deff', 'message': 'Release manila-tempest-plugin\n\nCouple of RBAC tests were included in the manila-tempest-plugin\nrepository, alongside some good fixes:\n\n$ git log --oneline --no-merges 1.10.0..121f536\n121f536 (HEAD, origin/master, origin/HEAD) [RBAC] Fix test tags\na325504 Remove ""alt_project_share_v2_client"" client initialization\n3d2b7bb More Snapshot metadata field verification >= 2.73\n75dbca6 Add a metadata field shown on API >= 2.73\n7b2566a Add S-RBAC tests for manila\n5e559df Move skip condition under skip_checks class method\n8125ca4 Replace period to underscore\n\nChange-Id: Iaf476c80eed5c71316764890b40a631e1df12758\n'}]",3,864066,e79fa6217de45517a797c8c1d03a1dc23dc1deff,13,5,2,29632,,,0,"Release manila-tempest-plugin

Couple of RBAC tests were included in the manila-tempest-plugin
repository, alongside some good fixes:

$ git log --oneline --no-merges 1.10.0..121f536
121f536 (HEAD, origin/master, origin/HEAD) [RBAC] Fix test tags
a325504 Remove ""alt_project_share_v2_client"" client initialization
3d2b7bb More Snapshot metadata field verification >= 2.73
75dbca6 Add a metadata field shown on API >= 2.73
7b2566a Add S-RBAC tests for manila
5e559df Move skip condition under skip_checks class method
8125ca4 Replace period to underscore

Change-Id: Iaf476c80eed5c71316764890b40a631e1df12758
",git fetch https://review.opendev.org/openstack/releases refs/changes/66/864066/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/antelope/manila-tempest-plugin.yaml'],1,993f84607bb8b92cf7d07779fae3bc76f0eefb19,,releases: - version: 1.11.0 projects: - repo: openstack/manila-tempest-plugin hash: 256a6b09d4ae8305de8ef9f9e1ae3498d43b4421,,5,0
openstack%2Fceilometer~master~I2f26746225a76df66e999490c0055101d325b114,openstack/ceilometer,master,I2f26746225a76df66e999490c0055101d325b114,Improve logging for Gnocchi publisher,MERGED,2022-10-28 12:04:19.000000000,2022-11-10 09:40:31.000000000,2022-11-10 09:39:35.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}, {'_account_id': 32240}]","[{'number': 1, 'created': '2022-10-28 12:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cb96d1aaea8bfcff2bf79523a61ef260ebdd7670', 'message': 'Improve logging for Gnocchi publisher\n\nChange-Id: I2f26746225a76df66e999490c0055101d325b114\n'}, {'number': 2, 'created': '2022-10-28 13:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5cbb64491bd72a627d024fb38e6a0acc90d9d23e', 'message': 'Improve logging for Gnocchi publisher\n\nChange-Id: I2f26746225a76df66e999490c0055101d325b114\n'}, {'number': 3, 'created': '2022-11-03 18:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d8eea5a952f3bbc7ac5e1ef26a179d71cd2f8d5e', 'message': 'Improve logging for Gnocchi publisher\n\nChange-Id: I2f26746225a76df66e999490c0055101d325b114\n'}, {'number': 4, 'created': '2022-11-06 19:29:58.000000000', 'files': ['ceilometer/tests/unit/publisher/test_gnocchi.py', 'ceilometer/publisher/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/060a13455cbcf759eac451c2eb923af31b08c625', 'message': 'Improve logging for Gnocchi publisher\n\nChange-Id: I2f26746225a76df66e999490c0055101d325b114\n'}]",4,862885,060a13455cbcf759eac451c2eb923af31b08c625,16,3,4,28356,,,0,"Improve logging for Gnocchi publisher

Change-Id: I2f26746225a76df66e999490c0055101d325b114
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/85/862885/4 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/publisher/gnocchi.py'],1,cb96d1aaea8bfcff2bf79523a61ef260ebdd7670,gnocchi_publisher_logs," LOG.error(""Gnocchi client exception while pushing measures [%s] "" ""for gnocchi data [%s]: [%s]."", measures, gnocchi_data, str(e)) except Exception as e: LOG.error(""Unexpected exception while pushing measures [%s] for "" ""gnocchi data [%s]: [%s]."", measures, gnocchi_data, str(e), exc_info=True) LOG.error(""Gnocchi client exception updating resource type "" ""[%s] with ID [%s] for resource data [%s]: [%s]."", resource_type, resource.get('id'), resource_extra, str(e)) except Exception as e: LOG.error(""Unexpected exception updating resource type [%s] "" ""with ID [%s] for resource data [%s]: [%s]."", resource_type, resource.get('id'), resource_extra, str(e), exc_info=True) LOG.debug(""Executing batch resource metrics measures for resource "" ""[%s] and measures [%s]."", resource_infos, measures) "," LOG.error(str(e)) except Exception as e: LOG.error(str(e), exc_info=True) LOG.error(str(e)) except Exception as e: LOG.error(str(e), exc_info=True)",17,4
openstack%2Fovn-bgp-agent~master~If6c7afb4b8ed39fd78e75af11c268d7ab84f1659,openstack/ovn-bgp-agent,master,If6c7afb4b8ed39fd78e75af11c268d7ab84f1659,Ensure only the provider network port is used,MERGED,2022-11-08 14:19:21.000000000,2022-11-10 09:36:48.000000000,2022-11-10 09:36:48.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 30126}]","[{'number': 1, 'created': '2022-11-08 14:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/0233f983d66f6d7ee7d465964c12e4ed19518651', 'message': 'Ensure only the provider network port is used\n\nThere are cases where more than one port can be attached to\nthe provider bridge (br-ex). To avoid problems with that we\nneed to ensure we only care about the ones related to the\nprovider networks (starting with patch-provnet-)\n\nChange-Id: If6c7afb4b8ed39fd78e75af11c268d7ab84f1659\n'}, {'number': 2, 'created': '2022-11-08 17:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/3bb96ded7071084866a56cf693accdfe0fbdc9dc', 'message': 'Ensure only the provider network port is used\n\nThere are cases where more than one port can be attached to\nthe provider bridge (br-ex). To avoid problems with that we\nneed to ensure we only care about the ones related to the\nprovider networks (starting with patch-provnet-)\n\nChange-Id: If6c7afb4b8ed39fd78e75af11c268d7ab84f1659\n'}, {'number': 3, 'created': '2022-11-10 09:03:56.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/utils/ovs.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/utils/test_ovs.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/6838ed4cf1bbe5e7fdb87b18a46df2faf92c6ab2', 'message': 'Ensure only the provider network port is used\n\nThere are cases where more than one port can be attached to\nthe provider bridge (br-ex). To avoid problems with that we\nneed to ensure we only care about the ones related to the\nprovider networks (starting with patch-provnet-)\n\nChange-Id: If6c7afb4b8ed39fd78e75af11c268d7ab84f1659\n'}]",1,863301,6838ed4cf1bbe5e7fdb87b18a46df2faf92c6ab2,11,4,3,23567,,,0,"Ensure only the provider network port is used

There are cases where more than one port can be attached to
the provider bridge (br-ex). To avoid problems with that we
need to ensure we only care about the ones related to the
provider networks (starting with patch-provnet-)

Change-Id: If6c7afb4b8ed39fd78e75af11c268d7ab84f1659
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/01/863301/1 && git format-patch -1 --stdout FETCH_HEAD,['ovn_bgp_agent/drivers/openstack/utils/ovs.py'],1,0233f983d66f6d7ee7d465964c12e4ed19518651,," ovs_ports = ovn_bgp_agent.privileged.ovs_vsctl.ovs_cmd( if not ovs_ports: ovs_ofport = None for ovs_port in ovs_ports.split(""\n""): if ovs_port.startswith('patch-provnet-'): ovs_ofport = get_device_port_at_ovs(ovs_port) break if not ovs_ofport: return", ovs_port = ovn_bgp_agent.privileged.ovs_vsctl.ovs_cmd( if not ovs_port: ovs_ofport = get_device_port_at_ovs(ovs_port),9,3
openstack%2Frpm-packaging~stable%2Fwallaby~Ia607a8bbe942ffb44c883128985b05a13d3e1a0a,openstack/rpm-packaging,stable/wallaby,Ia607a8bbe942ffb44c883128985b05a13d3e1a0a,[wallaby] glance 22.1.1,ABANDONED,2022-11-04 10:19:04.000000000,2022-11-10 09:35:18.000000000,,"[{'_account_id': 6593}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-04 10:19:04.000000000', 'files': ['openstack/glance/glance.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b359a49eb1b71db359f72f03d5aa42ad112d09ad', 'message': '[wallaby] glance 22.1.1\n\nChange-Id: Ia607a8bbe942ffb44c883128985b05a13d3e1a0a\n'}]",2,863631,b359a49eb1b71db359f72f03d5aa42ad112d09ad,6,3,1,28522,,,0,"[wallaby] glance 22.1.1

Change-Id: Ia607a8bbe942ffb44c883128985b05a13d3e1a0a
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/31/863631/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/glance/glance.spec.j2'],1,b359a49eb1b71db359f72f03d5aa42ad112d09ad,wallaby,{% set upstream_version = upstream_version('22.1.1') %},{% set upstream_version = upstream_version() %},1,1
openstack%2Faodh~master~Id164326115b33f2cc146bde53522e6c81d1b97ed,openstack/aodh,master,Id164326115b33f2cc146bde53522e6c81d1b97ed,remove unicode from code,NEW,2021-12-22 09:36:19.000000000,2022-11-10 09:34:25.000000000,,"[{'_account_id': 22348}, {'_account_id': 32240}]","[{'number': 1, 'created': '2021-12-22 09:36:19.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/6ffac22611fa875f67b449febc3e7ace5d545804', 'message': 'remove unicode from code\n\nChange-Id: Id164326115b33f2cc146bde53522e6c81d1b97ed\n'}]",2,822641,6ffac22611fa875f67b449febc3e7ace5d545804,4,2,1,33881,,,0,"remove unicode from code

Change-Id: Id164326115b33f2cc146bde53522e6c81d1b97ed
",git fetch https://review.opendev.org/openstack/aodh refs/changes/41/822641/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,6ffac22611fa875f67b449febc3e7ace5d545804,,"copyright = '2015, Aodh Developers' ('index', 'AodhReleaseNotes.tex', 'Aodh Release Notes Documentation', 'Aodh Developers', 'manual'), ('index', 'aodhreleasenotes', 'Aodh Release Notes Documentation', ['Aodh Developers'], 1) ('index', 'AodhReleaseNotes', 'Aodh Release Notes Documentation', 'Aodh Developers', 'AodhReleaseNotes',","copyright = u'2015, Aodh Developers' ('index', 'AodhReleaseNotes.tex', u'Aodh Release Notes Documentation', u'Aodh Developers', 'manual'), ('index', 'aodhreleasenotes', u'Aodh Release Notes Documentation', [u'Aodh Developers'], 1) ('index', 'AodhReleaseNotes', u'Aodh Release Notes Documentation', u'Aodh Developers', 'AodhReleaseNotes',",7,7
openstack%2Faodh~stable%2Fwallaby~I4f631d224404460138f4050b1b981d577b592544,openstack/aodh,stable/wallaby,I4f631d224404460138f4050b1b981d577b592544,gnocchi: Use Dynamic Aggregates API,MERGED,2022-11-08 10:26:17.000000000,2022-11-10 09:33:52.000000000,2022-11-10 09:32:45.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 10:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/9be2178bfd7de2ccf6734ea2c336ba3420093b24', 'message': 'gnocchi: Use Dynamic Aggregates API\n\nSwitch to using the Dynamic Aggregates API as the Metric Aggregation\nAPI is deprecated.\n\nWhen using the Dynamic Aggregates API, any aggregation using rates\ncan use the underlying base measures for the aggregation rather than\nthe rate, for example:\n\n    (aggregation rate:mean (metric cpu mean))\n\nThe tuple of data for each record returned via this API is encapsulated\nwith information about the aggregation used so adapt the sanitization\nfunction to deal with this and the formatting of the metrics measures\nAPI as well.\n\nChange-Id: I4f631d224404460138f4050b1b981d577b592544\nCloses-Bug: 1946793\nDepends-On: https://review.opendev.org/863284\n(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)\n(cherry picked from commit e6d55b1ea9ee852cc56002c865c9443b526f2f58)\n'}, {'number': 2, 'created': '2022-11-08 10:26:26.000000000', 'files': ['aodh/tests/unit/evaluator/test_composite.py', 'aodh/tests/unit/evaluator/test_gnocchi.py', 'aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/evaluator/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/27ee81a37acf097f572ffce1c4cd72f9987e0520', 'message': 'gnocchi: Use Dynamic Aggregates API\n\nSwitch to using the Dynamic Aggregates API as the Metric Aggregation\nAPI is deprecated.\n\nWhen using the Dynamic Aggregates API, any aggregation using rates\ncan use the underlying base measures for the aggregation rather than\nthe rate, for example:\n\n    (aggregation rate:mean (metric cpu mean))\n\nThe tuple of data for each record returned via this API is encapsulated\nwith information about the aggregation used so adapt the sanitization\nfunction to deal with this and the formatting of the metrics measures\nAPI as well.\n\nChange-Id: I4f631d224404460138f4050b1b981d577b592544\nCloses-Bug: 1946793\n(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)\n(cherry picked from commit e6d55b1ea9ee852cc56002c865c9443b526f2f58)\n'}]",1,863798,27ee81a37acf097f572ffce1c4cd72f9987e0520,10,2,2,32240,,,0,"gnocchi: Use Dynamic Aggregates API

Switch to using the Dynamic Aggregates API as the Metric Aggregation
API is deprecated.

When using the Dynamic Aggregates API, any aggregation using rates
can use the underlying base measures for the aggregation rather than
the rate, for example:

    (aggregation rate:mean (metric cpu mean))

The tuple of data for each record returned via this API is encapsulated
with information about the aggregation used so adapt the sanitization
function to deal with this and the formatting of the metrics measures
API as well.

Change-Id: I4f631d224404460138f4050b1b981d577b592544
Closes-Bug: 1946793
(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)
(cherry picked from commit e6d55b1ea9ee852cc56002c865c9443b526f2f58)
",git fetch https://review.opendev.org/openstack/aodh refs/changes/98/863798/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/tests/unit/evaluator/test_composite.py', 'aodh/tests/unit/evaluator/test_gnocchi.py', 'aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/evaluator/gnocchi.py']",5,9be2178bfd7de2ccf6734ea2c336ba3420093b24,bug/1946793-stable/xena-stable/wallaby," # NOTE(jamespage) # Dynamic Aggregates are returned in a dict struct so # check for this first. if isinstance(statistics, dict): # Pop array of measures from aggregated subdict statistics = statistics['measures']['aggregated'] _operations = [ 'aggregate', rule['aggregation_method'] ] for metric in rule['metrics']: _operations.append( [ 'metric', metric, rule['aggregation_method'].lstrip('rate:') ] ) return self._gnocchi_client.aggregates.fetch( operations=_operations, try: # FIXME(sileht): In case of a heat autoscaling stack decide to # delete an instance, the gnocchi metrics associated to this # instance will be no more updated and when the alarm will ask # for the aggregation, gnocchi will raise a 'No overlap' # exception. # So temporary set 'needed_overlap' to 0 to disable the # gnocchi checks about missing points. For more detail see: # https://bugs.launchpad.net/gnocchi/+bug/1479429 return self._gnocchi_client.aggregates.fetch( operations=[ 'aggregate', rule['aggregation_method'], [ 'metric', rule['metric'], rule['aggregation_method'].lstrip('rate:') ] ], search=json.loads(rule['query']), needed_overlap=0)"," return self._gnocchi_client.metric.aggregation( metrics=rule['metrics'], aggregation=rule['aggregation_method'], # FIXME(sileht): In case of a heat autoscaling stack decide to # delete an instance, the gnocchi metrics associated to this # instance will be no more updated and when the alarm will ask # for the aggregation, gnocchi will raise a 'No overlap' # exception. # So temporary set 'needed_overlap' to 0 to disable the # gnocchi checks about missing points. For more detail see: # https://bugs.launchpad.net/gnocchi/+bug/1479429 try: return self._gnocchi_client.metric.aggregation( metrics=rule['metric'], query=json.loads(rule['query']), aggregation=rule['aggregation_method'], needed_overlap=0, )",228,121
openstack%2Fheat-dashboard~master~I5054ea70b79a793149b21c47b9d1658b9d97c18c,openstack/heat-dashboard,master,I5054ea70b79a793149b21c47b9d1658b9d97c18c,Imported Translations from Zanata,MERGED,2022-09-24 04:41:53.000000000,2022-11-10 09:09:42.000000000,2022-11-10 09:08:29.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-09-24 04:41:53.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/c370b69f885c3098fc9215eece285fcecf13f3ad', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5054ea70b79a793149b21c47b9d1658b9d97c18c\n'}]",0,859187,c370b69f885c3098fc9215eece285fcecf13f3ad,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I5054ea70b79a793149b21c47b9d1658b9d97c18c
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/87/859187/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,c370b69f885c3098fc9215eece285fcecf13f3ad,zanata/translations,"""POT-Creation-Date: 2022-09-20 03:04+0000\n""""PO-Revision-Date: 2022-09-24 01:11+0000\n""msgid ""8.0.0.0rc1"" msgstr ""8.0.0.0rc1"" msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes""","""POT-Creation-Date: 2022-09-07 00:55+0000\n""""PO-Revision-Date: 2022-09-10 01:47+0000\n""msgid ""7.0.0-17"" msgstr ""7.0.0-17""",7,4
openstack%2Freleases~master~I2058571415ddd108141cd47761268b9b0211ff42,openstack/releases,master,I2058571415ddd108141cd47761268b9b0211ff42,Update release liaison for kolla project,MERGED,2022-11-08 12:33:51.000000000,2022-11-10 09:06:46.000000000,2022-11-10 09:06:46.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 26285}, {'_account_id': 30491}]","[{'number': 1, 'created': '2022-11-08 12:33:51.000000000', 'files': ['data/release_liaisons.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d5c201c688eba72ba4d22fa4322f1d2b6f0d4bd1', 'message': 'Update release liaison for kolla project\n\nSadly Radoslaw has had to severely reduce upstream contributions, so I\nam volunteering to replace him as contact for the kolla project.\n\nChange-Id: I2058571415ddd108141cd47761268b9b0211ff42\n'}]",1,863998,d5c201c688eba72ba4d22fa4322f1d2b6f0d4bd1,10,6,1,13252,,,0,"Update release liaison for kolla project

Sadly Radoslaw has had to severely reduce upstream contributions, so I
am volunteering to replace him as contact for the kolla project.

Change-Id: I2058571415ddd108141cd47761268b9b0211ff42
",git fetch https://review.opendev.org/openstack/releases refs/changes/98/863998/1 && git format-patch -1 --stdout FETCH_HEAD,['data/release_liaisons.yaml'],1,d5c201c688eba72ba4d22fa4322f1d2b6f0d4bd1,update-kolla-liaison, - name: 'Dr. Jens Harbott' irc: frickler email: frickler@offenerstapel.de, - name: 'Radoslaw Piliszek' irc: yoctozepto email: radoslaw.piliszek@gmail.com,3,3
openstack%2Freleases~master~I4f113516e2180ff358f181b04d7b1ab6a8e7631b,openstack/releases,master,I4f113516e2180ff358f181b04d7b1ab6a8e7631b,[antelope] release stevedore 4.1.1,MERGED,2022-11-09 09:32:49.000000000,2022-11-10 09:02:28.000000000,2022-11-10 09:02:28.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 31245}]","[{'number': 1, 'created': '2022-11-09 09:32:49.000000000', 'files': ['deliverables/antelope/stevedore.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/78e28596ef37797b659ff402166c51d104ea7a69', 'message': '[antelope] release stevedore 4.1.1\n\nChange-Id: I4f113516e2180ff358f181b04d7b1ab6a8e7631b\n'}]",1,864096,78e28596ef37797b659ff402166c51d104ea7a69,8,4,1,28522,,,0,"[antelope] release stevedore 4.1.1

Change-Id: I4f113516e2180ff358f181b04d7b1ab6a8e7631b
",git fetch https://review.opendev.org/openstack/releases refs/changes/96/864096/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/antelope/stevedore.yaml'],1,78e28596ef37797b659ff402166c51d104ea7a69,oslo-antelope, - version: 4.1.1 projects: - repo: openstack/stevedore hash: 5189992d719ad15e0e3504947895bf5ba9dc7a1d,,4,0
openstack%2Ftripleo-ansible~stable%2Ftrain~I6852de27f68f4dcf2cac44a80b3a491db1996d9f,openstack/tripleo-ansible,stable/train,I6852de27f68f4dcf2cac44a80b3a491db1996d9f,Fix molecule jobs broken with latest cryptography,ABANDONED,2022-11-09 12:28:59.000000000,2022-11-10 08:15:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-09 12:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9853ca4bb82fb01165a88dd7f60ef00e23b59bac', 'message': 'Fix molecule jobs broken with latest cryptography\n\nPin cryptography to < 37.0.0[1].\n\nAlso, changes tripleo_keystone_resources role to use\ncentos:stream9 image.\n\n[1] https://github.com/pyca/cryptography/issues/7126\n\nCloses-Bug: #1995608\nChange-Id: I6852de27f68f4dcf2cac44a80b3a491db1996d9f\n(cherry picked from commit 0e0a80a8ab56b5bd6903a8b169d058b352843f2a)\n'}, {'number': 2, 'created': '2022-11-09 12:31:12.000000000', 'files': ['tripleo_ansible/roles/tripleo-keystone-resources/molecule/default/Dockerfile.keystone', 'molecule-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9d043d43f8602b05b4dde3801bc5a9ba56f86465', 'message': 'Fix molecule jobs broken with latest cryptography\n\nPin cryptography to < 37.0.0[1].\n\nAlso, changes tripleo_keystone_resources role to use\ncentos:stream9 image.\n\n[1] https://github.com/pyca/cryptography/issues/7126\n\nCloses-Bug: #1995608\nChange-Id: I6852de27f68f4dcf2cac44a80b3a491db1996d9f\n(cherry picked from commit 0e0a80a8ab56b5bd6903a8b169d058b352843f2a)\n'}]",0,864044,9d043d43f8602b05b4dde3801bc5a9ba56f86465,5,1,2,14250,,,0,"Fix molecule jobs broken with latest cryptography

Pin cryptography to < 37.0.0[1].

Also, changes tripleo_keystone_resources role to use
centos:stream9 image.

[1] https://github.com/pyca/cryptography/issues/7126

Closes-Bug: #1995608
Change-Id: I6852de27f68f4dcf2cac44a80b3a491db1996d9f
(cherry picked from commit 0e0a80a8ab56b5bd6903a8b169d058b352843f2a)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/44/864044/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_keystone_resources/molecule/default/Dockerfile.keystone', 'molecule-requirements.txt']",2,9853ca4bb82fb01165a88dd7f60ef00e23b59bac,,"<<<<<<< HEAD (0b7c84 Merge ""Ensure the openvswitch service is enabled and deps ar)======= jinja2 cryptography<37.0.0 >>>>>>> CHANGE (0e0a80 Fix molecule jobs broken with latest cryptography)",,23,0
openstack%2Foperations-guide~master~I3e7bf7a02b188f66725a8296ce7f9394f0166f7c,openstack/operations-guide,master,I3e7bf7a02b188f66725a8296ce7f9394f0166f7c,Remove python-dev from bindep,MERGED,2022-11-07 10:03:11.000000000,2022-11-10 07:50:36.000000000,2022-11-10 07:49:37.000000000,"[{'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 10:03:11.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/8a6aaa0737009b49f7ec72bcadef652fad192fd7', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I3e7bf7a02b188f66725a8296ce7f9394f0166f7c\n""}]",0,863840,8a6aaa0737009b49f7ec72bcadef652fad192fd7,8,3,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I3e7bf7a02b188f66725a8296ce7f9394f0166f7c
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/40/863840/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,8a6aaa0737009b49f7ec72bcadef652fad192fd7,drop-python-dev-from-bindep,,python-dev [platform:dpkg] python-devel [platform:rpm],0,2
openstack%2Fcontributor-guide~master~I57a152e7ce6fc360351095cb8b20e700d71e3ad1,openstack/contributor-guide,master,I57a152e7ce6fc360351095cb8b20e700d71e3ad1,Remove python-dev from bindep,MERGED,2022-11-07 09:50:25.000000000,2022-11-10 07:49:49.000000000,2022-11-10 07:48:44.000000000,"[{'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 09:50:25.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/d5d1c7e087580c18bb1e92e4759267f6284c2819', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I57a152e7ce6fc360351095cb8b20e700d71e3ad1\n""}]",0,863827,d5d1c7e087580c18bb1e92e4759267f6284c2819,8,3,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I57a152e7ce6fc360351095cb8b20e700d71e3ad1
",git fetch https://review.opendev.org/openstack/contributor-guide refs/changes/27/863827/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,d5d1c7e087580c18bb1e92e4759267f6284c2819,drop-python-dev-from-bindep,,python-dev [platform:dpkg] python-devel [platform:rpm],0,2
openstack%2Ftacker~master~I8bce708929fa0b473bd3d6c0591ca57c4f71ec78,openstack/tacker,master,I8bce708929fa0b473bd3d6c0591ca57c4f71ec78,Imported Translations from Zanata,MERGED,2022-11-05 03:05:19.000000000,2022-11-10 05:54:04.000000000,2022-11-10 05:52:49.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}]","[{'number': 1, 'created': '2022-11-05 03:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/6811e64bf4f21de230bdc182f048d1f0d343d2e1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I8bce708929fa0b473bd3d6c0591ca57c4f71ec78\n'}, {'number': 2, 'created': '2022-11-10 04:00:00.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/tacker/commit/c1c9c907e3466195336ef65252901a1c4b07e949', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I8bce708929fa0b473bd3d6c0591ca57c4f71ec78\n'}]",0,863725,c1c9c907e3466195336ef65252901a1c4b07e949,11,4,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I8bce708929fa0b473bd3d6c0591ca57c4f71ec78
",git fetch https://review.opendev.org/openstack/tacker refs/changes/25/863725/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,6811e64bf4f21de230bdc182f048d1f0d343d2e1,zanata/translations,"""POT-Creation-Date: 2022-10-13 08:46+0000\n""""PO-Revision-Date: 2022-11-04 10:54+0000\n""msgid ""8.0.0.0rc1-12"" msgstr ""8.0.0.0rc1-12""""Adding the VNF version upgrading function to the tacker-db-manage command, "" ""which enables users to upgrade VNFs from v1 to v2 without re-instantiating "" ""it."" msgstr """" ""Adding the VNF version upgrading function to the tacker-db-manage command, "" ""which enables users to upgrade VNFs from v1 to v2 without re-instantiating "" ""it."" msgid """" ""Adds \""openid token\"" authentication strategy for Kubernetes VIM. Users can "" ""specify openid authentication parameters in the `VIM Register Request` or "" ""the `VNF Instantiate Request` to indicate tacker to use openid token for "" ""authentication."" msgstr """" ""Adds \""openid token\"" authentication strategy for Kubernetes VIM. Users can "" ""specify openid authentication parameters in the `VIM Register Request` or "" ""the `VNF Instantiate Request` to indicate Tacker to use OpenID token for "" ""authentication."" msgid """"""At the same time, the redirection when V2 calls HEAT's API is removed "" ""instead of direct call, and the subcription filter when sends notification "" ""is improved in V1 code."" msgstr """" ""At the same time, the redirection when V2 calls HEAT's API is removed "" ""instead of a direct call, and the subscription filter that sends "" ""notifications is improved in V1 code."" msgid """"""Database synchronization between Tacker and Kubernetes to enable maintainers "" ""to get status of pods from Tacker."" msgstr """" ""Database synchronisation between Tacker and Kubernetes to enable maintainers "" ""to get the status of pods from Tacker."" msgid """"msgid ""Update cirros image from 0.4.0 to 0.5.2."" msgstr ""Update Cirros image from 0.4.0 to 0.5.2."" msgid ""VNF AutoHealing triggered by FaultNotification."" msgstr ""VNF AutoHealing triggered by FaultNotification."" ","""POT-Creation-Date: 2022-10-06 01:34+0000\n""""PO-Revision-Date: 2022-10-12 01:22+0000\n""msgid ""8.0.0.0rc1-11"" msgstr ""8.0.0.0rc1-11""",46,4
openstack%2Frequirements~stable%2Fxena~Id14e3c36f7da9e6e19aec04140e56094055a7891,openstack/requirements,stable/xena,Id14e3c36f7da9e6e19aec04140e56094055a7891,update constraint for metalsmith to new release 1.5.3,MERGED,2022-11-08 21:27:24.000000000,2022-11-10 04:04:59.000000000,2022-11-10 04:04:59.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 21:27:24.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/43903b8757b8c1d45dcb97956be63581135845e0', 'message': 'update constraint for metalsmith to new release 1.5.3\n\nmeta: version: 1.5.3\nmeta: diff-start: -\nmeta: series: xena\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jay Faulkner <jay@jvf.cc>\nmeta: release:Commit: Jay Faulkner <jay@jvf.cc>\nmeta: release:Change-Id: I54b1c9429f1a007b977c4b6b6376e6c25cb52153\nmeta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: Id14e3c36f7da9e6e19aec04140e56094055a7891\n'}]",1,864065,43903b8757b8c1d45dcb97956be63581135845e0,10,2,1,11131,,,0,"update constraint for metalsmith to new release 1.5.3

meta: version: 1.5.3
meta: diff-start: -
meta: series: xena
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Jay Faulkner <jay@jvf.cc>
meta: release:Commit: Jay Faulkner <jay@jvf.cc>
meta: release:Change-Id: I54b1c9429f1a007b977c4b6b6376e6c25cb52153
meta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: Id14e3c36f7da9e6e19aec04140e56094055a7891
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/864065/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,43903b8757b8c1d45dcb97956be63581135845e0,new-release,metalsmith===1.5.3,metalsmith===1.5.2,1,1
openstack%2Fcharm-ceph-radosgw~stable%2Fpacific~I82634255ca3423fec3fc15c1e714dcb31db5da7a,openstack/charm-ceph-radosgw,stable/pacific,I82634255ca3423fec3fc15c1e714dcb31db5da7a,Enable HAProxy HTTP Health Checks,MERGED,2022-04-08 18:57:48.000000000,2022-11-10 03:27:31.000000000,2022-11-10 03:27:31.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2022-04-08 18:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/7678b74f3071cfc22f5e516b3951fbc67721b0fb', 'message': 'Enable HAProxy HTTP Health Checks\n\nCeph radosgw supports [0] the swift health check endpoint\n""/swift/healthcheck"". This change adds the haproxy\nconfiguration [1] necessary to take the response of ""GET\n/swift/healthcheck"" into account when determining the health\nof a radosgw service.\n\nFor testing, I verified that:\n- HAProxy starts and responds to requests normally with this\n  configuration.\n- Servers with status != 2xx or 3xx are removed from the\n  backend.\n- Servers that take too long to respond are also removed\n  from the backend. The default timeout value is 2s.\n\n[0] https://tracker.ceph.com/issues/11682\n[1] https://www.haproxy.com/documentation/hapee/2-0r1/onepage/#4.2-option%20httpchk\n\nCloses-Bug: 1946280\nChange-Id: I82634255ca3423fec3fc15c1e714dcb31db5da7a\n(cherry picked from commit 31a4584169c1c78e59dc505de4163d528d1cae0a)\n'}, {'number': 2, 'created': '2022-10-19 17:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/cd13d143363f28a8cb1ecbb0a50a5d8745f0b3ca', 'message': 'Enable HAProxy HTTP Health Checks\n\nCeph radosgw supports [0] the swift health check endpoint\n""/swift/healthcheck"". This change adds the haproxy\nconfiguration [1] necessary to take the response of ""GET\n/swift/healthcheck"" into account when determining the health\nof a radosgw service.\n\nFor testing, I verified that:\n- HAProxy starts and responds to requests normally with this\n  configuration.\n- Servers with status != 2xx or 3xx are removed from the\n  backend.\n- Servers that take too long to respond are also removed\n  from the backend. The default timeout value is 2s.\n\n[0] https://tracker.ceph.com/issues/11682\n[1] https://www.haproxy.com/documentation/hapee/2-0r1/onepage/#4.2-option%20httpchk\n\nCloses-Bug: 1946280\nChange-Id: I82634255ca3423fec3fc15c1e714dcb31db5da7a\n(cherry picked from commit 31a4584169c1c78e59dc505de4163d528d1cae0a)\n'}, {'number': 3, 'created': '2022-10-20 19:27:55.000000000', 'files': ['unit_tests/test_ceph_radosgw_context.py', 'test-requirements.txt', 'hooks/ceph_radosgw_context.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/3c7f468b0ca01d509566c670ab0a54a82b25f375', 'message': 'Enable HAProxy HTTP Health Checks\n\nCeph radosgw supports [0] the swift health check endpoint\n""/swift/healthcheck"". This change adds the haproxy\nconfiguration [1] necessary to take the response of ""GET\n/swift/healthcheck"" into account when determining the health\nof a radosgw service.\n\nFor testing, I verified that:\n- HAProxy starts and responds to requests normally with this\n  configuration.\n- Servers with status != 2xx or 3xx are removed from the\n  backend.\n- Servers that take too long to respond are also removed\n  from the backend. The default timeout value is 2s.\n\n[0] https://tracker.ceph.com/issues/11682\n[1] https://www.haproxy.com/documentation/hapee/2-0r1/onepage/#4.2-option%20httpchk\n\nCloses-Bug: 1946280\nChange-Id: I82634255ca3423fec3fc15c1e714dcb31db5da7a\n(cherry picked from commit 31a4584169c1c78e59dc505de4163d528d1cae0a)\n'}]",4,837065,3c7f468b0ca01d509566c670ab0a54a82b25f375,24,3,3,34275,,,0,"Enable HAProxy HTTP Health Checks

Ceph radosgw supports [0] the swift health check endpoint
""/swift/healthcheck"". This change adds the haproxy
configuration [1] necessary to take the response of ""GET
/swift/healthcheck"" into account when determining the health
of a radosgw service.

For testing, I verified that:
- HAProxy starts and responds to requests normally with this
  configuration.
- Servers with status != 2xx or 3xx are removed from the
  backend.
- Servers that take too long to respond are also removed
  from the backend. The default timeout value is 2s.

[0] https://tracker.ceph.com/issues/11682
[1] https://www.haproxy.com/documentation/hapee/2-0r1/onepage/#4.2-option%20httpchk

Closes-Bug: 1946280
Change-Id: I82634255ca3423fec3fc15c1e714dcb31db5da7a
(cherry picked from commit 31a4584169c1c78e59dc505de4163d528d1cae0a)
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/65/837065/3 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_ceph_radosgw_context.py', 'hooks/ceph_radosgw_context.py']",2,7678b74f3071cfc22f5e516b3951fbc67721b0fb,bug/1946280-stable/pacific," https, service = 'cephradosgw-server' service: [port, a_cephradosgw_api] backend_options = { service: [{ 'option': 'httpchk GET /swift/healthcheck', }] } ctxt['backend_options'] = backend_options ctxt['https'] = https() "," 'cephradosgw-server': [port, a_cephradosgw_api]",17,2
openstack%2Fcharm-ceph-radosgw~stable%2Fpacific~I38ed7b431b3454de0b332cd15a3abc02fb12b59e,openstack/charm-ceph-radosgw,stable/pacific,I38ed7b431b3454de0b332cd15a3abc02fb12b59e,charm-helpers sync,MERGED,2022-10-19 17:36:33.000000000,2022-11-10 03:24:51.000000000,2022-11-10 03:24:51.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2022-10-19 17:36:33.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/openstack_https_frontend', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/templates/openstack_https_frontend.conf', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/7da070b941df685c7f497bf55ef1cce7dd4aa8a3', 'message': 'charm-helpers sync\n\nChange-Id: I38ed7b431b3454de0b332cd15a3abc02fb12b59e\n'}]",1,861910,7da070b941df685c7f497bf55ef1cce7dd4aa8a3,8,3,1,34275,,,0,"charm-helpers sync

Change-Id: I38ed7b431b3454de0b332cd15a3abc02fb12b59e
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/10/861910/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/templates/openstack_https_frontend', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/haproxy.cfg', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/templates/openstack_https_frontend.conf', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf']",10,7da070b941df685c7f497bf55ef1cce7dd4aa8a3,pacific-charm-helpers-sync, KeepAliveTimeout 75 MaxKeepAliveRequests 1000 KeepAliveTimeout 75 MaxKeepAliveRequests 1000 KeepAliveTimeout 75 MaxKeepAliveRequests 1000,,44,2
openstack%2Ftacker~master~Id324deb36633c1c765968d96ed5659cac22411ed,openstack/tacker,master,Id324deb36633c1c765968d96ed5659cac22411ed,Stabilize sol-kubernetes-v2 job in Zuul FT,MERGED,2022-11-07 02:45:18.000000000,2022-11-10 02:41:18.000000000,2022-11-10 02:39:29.000000000,"[{'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}, {'_account_id': 34712}]","[{'number': 1, 'created': '2022-11-07 02:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b8ab03215fd2928584364549b9bb5eec6c400d3c', 'message': 'Stabilize Zuul jobs\n\nIn the kubernetes FT for v1, the following action was done to\nreduce the time to delete the resource when using helm.\n* Set ``service.type=NodePort`` in ``helmparameter`` of input\n  parameter.\n\nThis patch fixed the kuberenetes FT test for v2 in the same\nway to stabilize sol-kuberenetes-v2 job.\n\nChange-Id: Id324deb36633c1c765968d96ed5659cac22411ed\n'}, {'number': 2, 'created': '2022-11-09 01:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3fb52b424efcc53ce48ad231a765f10940fdee84', 'message': 'Stabilize sol-kubernetes-v2 job in Zuul FT\n\nIn the kubernetes FT for v1, the following action was done[1] to\nreduce the time to delete the resource when using helm.\n* Set ``service.type=NodePort`` in ``helmparameter`` of input\n  parameter.\n\nThis patch fixed the kuberenetes FT test for v2 in the same\nway to stabilize sol-kuberenetes-v2 job.\n\n[1]b313eb4420b62a86e089fa0db3b26f7a4c99ad0c\n\nChange-Id: Id324deb36633c1c765968d96ed5659cac22411ed\n'}, {'number': 3, 'created': '2022-11-09 01:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/814d748b1a671b50dbef745e54b83f804d8f53fb', 'message': 'Stabilize sol-kubernetes-v2 job in Zuul FT\n\nIn the kubernetes FT for v1, the following action was done[1] to\nreduce the time to delete the resource when using helm.\n* Set ``service.type=NodePort`` in ``helmparameter`` of input\n  parameter.\n\nThis patch fixed the kuberenetes FT test for v2 in the same\nway to stabilize sol-kuberenetes-v2 job.\n\n[1] b313eb4420b62a86e089fa0db3b26f7a4c99ad0c\n\nChange-Id: Id324deb36633c1c765968d96ed5659cac22411ed\n'}, {'number': 4, 'created': '2022-11-09 01:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ecaace643a4dddbcdcfabdd4808d76490b7b158c', 'message': 'Stabilize sol-kubernetes-v2 job in Zuul FT\n\nIn the kubernetes FT for v1, the following action was done[1] to\nreduce the time to delete the resource when using helm.\n* Set ``service.type=NodePort`` in ``helmparameter`` of input\n  parameter.\n\nThis patch fixed the kuberenetes FT test for v2 in the same\nway to stabilize sol-kuberenetes-v2 job.\n\n[1] b313eb4\n\nChange-Id: Id324deb36633c1c765968d96ed5659cac22411ed\n'}, {'number': 5, 'created': '2022-11-09 01:17:02.000000000', 'files': ['tacker/tests/functional/sol_kubernetes_v2/paramgen.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/3ae06725a5ddee20309a55e8b3d46d547032291a', 'message': 'Stabilize sol-kubernetes-v2 job in Zuul FT\n\nIn the kubernetes FT for v1, the following action was done[1] to\nreduce the time to delete the resource when using helm.\n* Set ``service.type=NodePort`` in ``helmparameter`` of input\n  parameter.\n\nThis patch fixed the kuberenetes FT test for v2 in the same\nway to stabilize sol-kuberenetes-v2 job.\n\n[1] b313eb4420b62a86e089fa0db3b26f7a4c99ad0c\n\nChange-Id: Id324deb36633c1c765968d96ed5659cac22411ed\n'}]",6,863782,3ae06725a5ddee20309a55e8b3d46d547032291a,21,4,5,34996,,,0,"Stabilize sol-kubernetes-v2 job in Zuul FT

In the kubernetes FT for v1, the following action was done[1] to
reduce the time to delete the resource when using helm.
* Set ``service.type=NodePort`` in ``helmparameter`` of input
  parameter.

This patch fixed the kuberenetes FT test for v2 in the same
way to stabilize sol-kuberenetes-v2 job.

[1] b313eb4420b62a86e089fa0db3b26f7a4c99ad0c

Change-Id: Id324deb36633c1c765968d96ed5659cac22411ed
",git fetch https://review.opendev.org/openstack/tacker refs/changes/82/863782/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/tests/functional/sol_kubernetes_v2/paramgen.py'],1,b8ab03215fd2928584364549b9bb5eec6c400d3c,stabilize-zuul-ft," ""service.port"": 8081, ""service.type"": ""NodePort"""," ""service.port"": 8081",2,1
openstack%2Frequirements~stable%2Fwallaby~I7e8837e9808b93eb0fa630fa758376d80b14b125,openstack/requirements,stable/wallaby,I7e8837e9808b93eb0fa630fa758376d80b14b125,update constraint for sushy to new release 3.7.6,MERGED,2022-11-04 10:05:15.000000000,2022-11-10 02:23:52.000000000,2022-11-10 02:23:52.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-11-04 10:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/166583666e14586dee0675475c57148da15f46a2', 'message': 'update constraint for sushy to new release 3.7.6\n\nmeta: version: 3.7.6\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jacob Anders <janders@redhat.com>\nmeta: release:Commit: Jacob Anders <janders@redhat.com>\nmeta: release:Change-Id: Ic99e361478a9504e3b7e30cb29921c5f5f7b1690\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I7e8837e9808b93eb0fa630fa758376d80b14b125\n'}, {'number': 2, 'created': '2022-11-04 14:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e540a40f74483e9136ef1c5cc55462caf65a8c57', 'message': 'update constraint for sushy to new release 3.7.6\n\nmeta: version: 3.7.6\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jacob Anders <janders@redhat.com>\nmeta: release:Commit: Jacob Anders <janders@redhat.com>\nmeta: release:Change-Id: Ic99e361478a9504e3b7e30cb29921c5f5f7b1690\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I7e8837e9808b93eb0fa630fa758376d80b14b125\n'}, {'number': 3, 'created': '2022-11-05 18:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2ca3ec2596a8935876ad337f38c971b844f0554b', 'message': 'update constraint for sushy to new release 3.7.6\n\nmeta: version: 3.7.6\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jacob Anders <janders@redhat.com>\nmeta: release:Commit: Jacob Anders <janders@redhat.com>\nmeta: release:Change-Id: Ic99e361478a9504e3b7e30cb29921c5f5f7b1690\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I7e8837e9808b93eb0fa630fa758376d80b14b125\n'}, {'number': 4, 'created': '2022-11-08 00:06:52.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b87589f0fe6d461274a544b95b1bfbb35145d17c', 'message': 'update constraint for sushy to new release 3.7.6\n\nmeta: version: 3.7.6\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jacob Anders <janders@redhat.com>\nmeta: release:Commit: Jacob Anders <janders@redhat.com>\nmeta: release:Change-Id: Ic99e361478a9504e3b7e30cb29921c5f5f7b1690\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I7e8837e9808b93eb0fa630fa758376d80b14b125\n'}]",3,863604,b87589f0fe6d461274a544b95b1bfbb35145d17c,34,5,4,11131,,,0,"update constraint for sushy to new release 3.7.6

meta: version: 3.7.6
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Jacob Anders <janders@redhat.com>
meta: release:Commit: Jacob Anders <janders@redhat.com>
meta: release:Change-Id: Ic99e361478a9504e3b7e30cb29921c5f5f7b1690
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I7e8837e9808b93eb0fa630fa758376d80b14b125
",git fetch https://review.opendev.org/openstack/requirements refs/changes/04/863604/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,166583666e14586dee0675475c57148da15f46a2,new-release,sushy===3.7.6,sushy===3.7.5,1,1
openstack%2Fopenstack-zuul-jobs~master~I02ef7fd5500cd43b3fdc210e88d133f50a93c017,openstack/openstack-zuul-jobs,master,I02ef7fd5500cd43b3fdc210e88d133f50a93c017,rpm-openafs: bump to 1.8.9pre1,MERGED,2022-11-09 23:05:29.000000000,2022-11-10 02:19:29.000000000,2022-11-10 02:15:48.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 23:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ac9b9681c905793c2f4bdefa1eb883a6b4db1694', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 2, 'created': '2022-11-09 23:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/08767aa342607bf0c8187526f29884725af44b51', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 3, 'created': '2022-11-09 23:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/cc578cc0c4f340f5fa675de04f24ad2f3ac059af', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 4, 'created': '2022-11-09 23:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/621664b1e0a3d88d45f5adc07c6353c1bd819f50', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 5, 'created': '2022-11-09 23:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ba1f99f911d6fdddbebb168d194345c9c9aed70f', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 6, 'created': '2022-11-09 23:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/6791cb85037879c931e126a3b210e3b4fb2f7036', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 7, 'created': '2022-11-10 00:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/7b9b594715e22e5b1b22e9b04fe27b229786c5c0', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 8, 'created': '2022-11-10 00:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/7de413e38e2cdcd99afb4b5f11b4c18e1b195ef4', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 9, 'created': '2022-11-10 00:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/2e2729f97cea6811eba26af679f7a461e043b613', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}, {'number': 10, 'created': '2022-11-10 00:41:43.000000000', 'files': ['roles/openafs-rpm-package-build/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/43caa50e86937d216934465b9af3e0761a16f78c', 'message': ""rpm-openafs: bump to 1.8.9pre1\n\nOpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next\navailable release.  Even though it's a pre-version, it's got to be\nbetter than cherry-picking patches.\n\nChange-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017\n""}]",4,864149,43caa50e86937d216934465b9af3e0761a16f78c,22,3,10,7118,,,0,"rpm-openafs: bump to 1.8.9pre1

OpenAFS 1.8.8.1 doesn't build on centos 9-stream, so this is the next
available release.  Even though it's a pre-version, it's got to be
better than cherry-picking patches.

Change-Id: I02ef7fd5500cd43b3fdc210e88d133f50a93c017
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/49/864149/9 && git format-patch -1 --stdout FETCH_HEAD,['roles/openafs-rpm-package-build/tasks/main.yaml'],1,ac9b9681c905793c2f4bdefa1eb883a6b4db1694,openafs-1.8.9pre1, VERSION=1.8.9pre1, VERSION=1.8.8.1,1,1
openstack%2Fpuppet-ceph~master~Id67650abda6fc4ddfeaba288dca6f9385261784b,openstack/puppet-ceph,master,Id67650abda6fc4ddfeaba288dca6f9385261784b,Remove support for CentOS 8 Stream,ABANDONED,2022-11-09 01:02:26.000000000,2022-11-10 01:21:42.000000000,,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 01:02:26.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/76499e89bc476eca52d82c05896499a0745a758e', 'message': 'Remove support for CentOS 8 Stream\n\n... because RDO will provide packages for only CentOS Stream 9 for Zed\nrelease. This change removes RHEL 8 as well.\n\nChange-Id: Id67650abda6fc4ddfeaba288dca6f9385261784b\nDepends-on: https://review.opendev.org/843503\n'}]",1,864076,76499e89bc476eca52d82c05896499a0745a758e,4,2,1,9414,,,0,"Remove support for CentOS 8 Stream

... because RDO will provide packages for only CentOS Stream 9 for Zed
release. This change removes RHEL 8 as well.

Change-Id: Id67650abda6fc4ddfeaba288dca6f9385261784b
Depends-on: https://review.opendev.org/843503
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/76/864076/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,76499e89bc476eca52d82c05896499a0745a758e,c8s," ""11"""," ""9"" ""7"", ""8"", ""7"", ""8"", ""18.04"",",1,6
openstack%2Frequirements~stable%2Fyoga~Id696f42db7f47976aaf2f42bad3ca3fd8202be27,openstack/requirements,stable/yoga,Id696f42db7f47976aaf2f42bad3ca3fd8202be27,[stable-only] Cap importlib-metadata on Python 3.7,NEW,2022-10-03 20:22:39.000000000,2022-11-09 23:18:50.000000000,,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-03 20:22:39.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/29a78542b31ba4af8eceb616c95f121d84513b93', 'message': ""[stable-only] Cap importlib-metadata on Python 3.7\n\nIn the recently released importlib-metadata 5.0.0 package a number of\nbreaking changes where made to the interface (in fact that was the only\nchange for the release removing a bunch of things tagged as deprecated).\nSince Python 3.7 depends on this library to function for querying\npackage metadata these breaking API changes cause anything using\nstevedore to fail when 5.0.0 is installed. Supporting a compatible\ninterface across multiple versions of importlib is difficult to to the\nnature of these breaking api changes. The least risky stable branch\nchange to make here is to cap the version, especially as this is a 3.7\nonly requirement this isn't a concern for master or any newer release.\nTo workaround these issues this commit sets a version cap on\nimportlib-metadata to avoid using the version which is incompatible\nwith stevedore.\n\nThe stevedore cap is being added in change\nI0db3624fcdb50eea4ff039e65456ef6e91c99c48\n\nChange-Id: Id696f42db7f47976aaf2f42bad3ca3fd8202be27\n""}]",2,860151,29a78542b31ba4af8eceb616c95f121d84513b93,7,4,1,5196,,,0,"[stable-only] Cap importlib-metadata on Python 3.7

In the recently released importlib-metadata 5.0.0 package a number of
breaking changes where made to the interface (in fact that was the only
change for the release removing a bunch of things tagged as deprecated).
Since Python 3.7 depends on this library to function for querying
package metadata these breaking API changes cause anything using
stevedore to fail when 5.0.0 is installed. Supporting a compatible
interface across multiple versions of importlib is difficult to to the
nature of these breaking api changes. The least risky stable branch
change to make here is to cap the version, especially as this is a 3.7
only requirement this isn't a concern for master or any newer release.
To workaround these issues this commit sets a version cap on
importlib-metadata to avoid using the version which is incompatible
with stevedore.

The stevedore cap is being added in change
I0db3624fcdb50eea4ff039e65456ef6e91c99c48

Change-Id: Id696f42db7f47976aaf2f42bad3ca3fd8202be27
",git fetch https://review.opendev.org/openstack/requirements refs/changes/51/860151/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,29a78542b31ba4af8eceb616c95f121d84513b93,cap-importlib-metadata,importlib-metadata<5.0.0;python_version<'3.8' # Apache-2.0,importlib-metadata;python_version<'3.8' # Apache-2.0,1,1
openstack%2Frpm-packaging~master~I6c01f15205157416846f3e4b8cf6904a0785bdb4,openstack/rpm-packaging,master,I6c01f15205157416846f3e4b8cf6904a0785bdb4,neutron: filelist fixes,MERGED,2022-11-09 15:31:07.000000000,2022-11-09 22:14:35.000000000,2022-11-09 22:14:35.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-09 15:31:07.000000000', 'files': ['openstack/neutron/neutron.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3cba00771628717f7a3966be35f8305f0effbdd9', 'message': 'neutron: filelist fixes\n\nmodules-load.d is in /usr/lib/modules-load.d on both SUSE as well as Red\nHat style distributions.\n\nChange-Id: I6c01f15205157416846f3e4b8cf6904a0785bdb4\n'}]",0,864125,3cba00771628717f7a3966be35f8305f0effbdd9,8,4,1,6593,,,0,"neutron: filelist fixes

modules-load.d is in /usr/lib/modules-load.d on both SUSE as well as Red
Hat style distributions.

Change-Id: I6c01f15205157416846f3e4b8cf6904a0785bdb4
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/25/864125/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/neutron/neutron.spec.j2'],1,3cba00771628717f7a3966be35f8305f0effbdd9,,install -D -m 644 %{SOURCE22} %{buildroot}%{_prefix}/lib/modules-load.d/openstack-neutron-linuxbridge-agent.conf install -D -m 644 %{SOURCE22} %{buildroot}%{_prefix}/lib/modules-load.d/openstack-neutron-openvswitch-agent.conf%{_bindir}/neutron-remove-duplicated-port-bindings%{_prefix}/lib/modules-load.d/openstack-neutron-linuxbridge-agent.conf%{_prefix}/lib/modules-load.d/openstack-neutron-openvswitch-agent.conf,install -D -m 644 %{SOURCE22} %{buildroot}%{_libexecdir}/modules-load.d/openstack-neutron-linuxbridge-agent.conf install -D -m 644 %{SOURCE22} %{buildroot}%{_libexecdir}/modules-load.d/openstack-neutron-openvswitch-agent.conf%{_libexecdir}/modules-load.d/openstack-neutron-linuxbridge-agent.conf%{_libexecdir}/modules-load.d/openstack-neutron-openvswitch-agent.conf,5,4
openstack%2Frpm-packaging~master~Ifbaae4c6cd5ef16e2ac5613cda90e4565f54429c,openstack/rpm-packaging,master,Ifbaae4c6cd5ef16e2ac5613cda90e4565f54429c,manila: add privsep dependency,MERGED,2022-11-09 14:27:13.000000000,2022-11-09 22:14:19.000000000,2022-11-09 22:14:19.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-09 14:27:13.000000000', 'files': ['openstack/manila/manila.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f666f89bb540c53476cd83595a9457daaec40843', 'message': 'manila: add privsep dependency\n\nWas introduced in I8457c0793d303aa7e95e0402260a788513feba77\n\nChange-Id: Ifbaae4c6cd5ef16e2ac5613cda90e4565f54429c\n'}]",0,864120,f666f89bb540c53476cd83595a9457daaec40843,8,4,1,6593,,,0,"manila: add privsep dependency

Was introduced in I8457c0793d303aa7e95e0402260a788513feba77

Change-Id: Ifbaae4c6cd5ef16e2ac5613cda90e4565f54429c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/20/864120/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/manila/manila.spec.j2'],1,f666f89bb540c53476cd83595a9457daaec40843,,BuildRequires: {{ py3('oslo.privsep') }}Requires: {{ py3('oslo.privsep') }},,2,0
openstack%2Fironic~stable%2Fzed~I2e02231d294997e824db77c998ef8d352fa69075,openstack/ironic,stable/zed,I2e02231d294997e824db77c998ef8d352fa69075,Fix the invalid glance client test,MERGED,2022-11-09 12:26:39.000000000,2022-11-09 21:06:07.000000000,2022-11-09 15:28:23.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2022-11-09 12:26:39.000000000', 'files': ['ironic/common/glance_service/image_service.py', 'ironic/common/utils.py', 'ironic/tests/unit/common/test_glance_service.py', 'ironic/conf/glance.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ff06b3d2a9568c92979334ab76d8e09ae1e6457f', 'message': ""Fix the invalid glance client test\n\nIt relied on mocking tenacity.retry, but it's executed on class\ninitialization. Depending on the ordering, it may do nothing or\nit may replace ImageService.call with a mock.\n\nInstead, add a new tenacity helper that loads an option in runtime.\nAs a nice side effect, [glance]num_retries is now mutable.\n\nChange-Id: I2e02231d294997e824db77c998ef8d352fa69075\n(cherry picked from commit cab51a9fcc022f2e4bb634277dd20e90e2dc78f7)\n""}]",0,864043,ff06b3d2a9568c92979334ab76d8e09ae1e6457f,10,2,1,10239,,,0,"Fix the invalid glance client test

It relied on mocking tenacity.retry, but it's executed on class
initialization. Depending on the ordering, it may do nothing or
it may replace ImageService.call with a mock.

Instead, add a new tenacity helper that loads an option in runtime.
As a nice side effect, [glance]num_retries is now mutable.

Change-Id: I2e02231d294997e824db77c998ef8d352fa69075
(cherry picked from commit cab51a9fcc022f2e4bb634277dd20e90e2dc78f7)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/43/864043/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/glance_service/image_service.py', 'ironic/common/utils.py', 'ironic/tests/unit/common/test_glance_service.py', 'ironic/conf/glance.py']",4,ff06b3d2a9568c92979334ab76d8e09ae1e6457f,glance-test-stable/zed," mutable=True,",,29,15
openstack%2Fopenstack-ansible~master~Ic0f58d6630e873dcee7daea861438236822d7f4e,openstack/openstack-ansible,master,Ic0f58d6630e873dcee7daea861438236822d7f4e,Improve Ceph production example,ABANDONED,2022-09-08 22:01:52.000000000,2022-11-09 20:47:34.000000000,,"[{'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2022-09-08 22:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c111f974e7db381a08d34e6ca53fa6a01e780bf1', 'message': 'Improve Ceph production example\n\nWith current ""Ceph production example"" the difference between ceph\'s\npublic and storage network is not clear.\n\nWe add Storage Network to compute nodes, but it\'s not used there.\nWe also add Storage Network to ceph-mon, but it\'s also not used there.\n\nI added few changes to make things more clear.\n\nChange-Id: Ic0f58d6630e873dcee7daea861438236822d7f4e\n'}, {'number': 2, 'created': '2022-09-08 22:04:20.000000000', 'files': ['etc/openstack_deploy/openstack_user_config.yml.prod-ceph.example', 'etc/openstack_deploy/user_variables.yml.prod-ceph.example', 'doc/source/user/ceph/full-deploy.rst', 'etc/network/interfaces.d/openstack_interface.cfg.prod.example'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2d510a4bd3c81a3cc2fd9970837c27c0810d5018', 'message': 'Improve Ceph production example\n\nWith current ""Ceph production example"" the difference between ceph\'s\npublic and storage network is not clear.\n\nWe assign Storage Network to compute nodes, but it\'s not used there.\nWe also asign Storage Network to ceph monitors, but it\'s not used there\nas well.\n\nI added few changes to make things more clear.\n\nChange-Id: Ic0f58d6630e873dcee7daea861438236822d7f4e\n'}]",1,856566,2d510a4bd3c81a3cc2fd9970837c27c0810d5018,5,2,2,32666,,,0,"Improve Ceph production example

With current ""Ceph production example"" the difference between ceph's
public and storage network is not clear.

We assign Storage Network to compute nodes, but it's not used there.
We also asign Storage Network to ceph monitors, but it's not used there
as well.

I added few changes to make things more clear.

Change-Id: Ic0f58d6630e873dcee7daea861438236822d7f4e
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/66/856566/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/openstack_deploy/openstack_user_config.yml.prod-ceph.example', 'etc/openstack_deploy/user_variables.yml.prod-ceph.example', 'doc/source/user/ceph/full-deploy.rst', 'etc/network/interfaces.d/openstack_interface.cfg.prod.example']",4,c111f974e7db381a08d34e6ca53fa6a01e780bf1,,# Only STORAGE nodes must have an IP address,# Only the COMPUTE and STORAGE nodes must have an IP address,11,4
openstack%2Fpython-cinderclient~master~I3ad8283c2a9aaac58c8d2b50fa7ac86b617e5dd3,openstack/python-cinderclient,master,I3ad8283c2a9aaac58c8d2b50fa7ac86b617e5dd3,Handle downgraded client for snapshot-create,MERGED,2022-11-08 17:01:22.000000000,2022-11-09 19:38:59.000000000,2022-11-09 19:38:00.000000000,"[{'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 17:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/c8dc1f14e5960f36881c7fb3301349abf22d82ff', 'message': ""WIP: remove redundant 'force' CLI arg definition\n\nNot sure exactly what is happening with this bug, but the only way\nI can see the 'force' argument actually get a None value is from the\nextra definition removed by this patch.\n\nChange-Id: I3ad8283c2a9aaac58c8d2b50fa7ac86b617e5dd3\nRelated-bug: #1995883\n""}, {'number': 2, 'created': '2022-11-08 20:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/9ce50f107adbbd1c4292a3365df68145adf71595', 'message': ""WIP: remove redundant 'force' CLI arg definition\n\nNot sure exactly what is happening with this bug, but the only way\nI can see the 'force' argument actually get a None value is from the\nextra definition removed by this patch.\n\nChange-Id: I3ad8283c2a9aaac58c8d2b50fa7ac86b617e5dd3\nRelated-bug: #1995883\n""}, {'number': 3, 'created': '2022-11-08 23:57:28.000000000', 'files': ['cinderclient/v3/shell.py', 'releasenotes/notes/bug-1995883-force-flag-none-3a7bb87f655bcf42.yaml', 'cinderclient/tests/unit/v3/test_shell.py', 'cinderclient/v3/volume_snapshots.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/9df653571d4da06c25222189be27e87a6da75628', 'message': 'Handle downgraded client for snapshot-create\n\nWhen a CLI user specifies --os-volume api-version 3.66, the shell\nwill execute the appropriate shell code, but if the server only\nsupports < 3.66, the client is automatically downgraded and correctly\nuses the pre-3.66 SnapshotManager.create() method.\n\nIn that case, the \'force\' parameter, which is technically not allowed\nin mv 3.66 (but which silently accepts a True value for backward\ncompatibility), will have a value of None, which the pre-3.66 code\nhappily passes to cinder as \'""force"": null\' in the request body, and\nwhich then fails the Block Storage API request-schema check.\n\nHandle this situation by detecting a None \'force\' value and setting\nit to its pre-3.66 default value of False.\n\nChange-Id: I3ad8283c2a9aaac58c8d2b50fa7ac86b617e5dd3\nCloses-bug: #1995883\n'}]",11,864027,9df653571d4da06c25222189be27e87a6da75628,18,4,3,5314,,,0,"Handle downgraded client for snapshot-create

When a CLI user specifies --os-volume api-version 3.66, the shell
will execute the appropriate shell code, but if the server only
supports < 3.66, the client is automatically downgraded and correctly
uses the pre-3.66 SnapshotManager.create() method.

In that case, the 'force' parameter, which is technically not allowed
in mv 3.66 (but which silently accepts a True value for backward
compatibility), will have a value of None, which the pre-3.66 code
happily passes to cinder as '""force"": null' in the request body, and
which then fails the Block Storage API request-schema check.

Handle this situation by detecting a None 'force' value and setting
it to its pre-3.66 default value of False.

Change-Id: I3ad8283c2a9aaac58c8d2b50fa7ac86b617e5dd3
Closes-bug: #1995883
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/27/864027/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v3/shell.py', 'cinderclient/tests/unit/v3/test_shell.py']",2,c8dc1f14e5960f36881c7fb3301349abf22d82ff,force-flag," @mock.patch('cinderclient.shell.CinderClientArgumentParser.exit') def test_snapshot_create_pre_3_66_with_naked_force( self, mock_exit): mock_exit.side_effect = Exception(""mock exit"") try: self.run_command('--os-volume-api-version 3.65 ' f'snapshot-create --force 123456') except Exception as e: # ignore the exception (it's raised to simulate an exit), # but make sure it's the exception we expect self.assertEqual('mock exit', str(e)) exit_code = mock_exit.call_args.args[0] self.assertEqual(2, exit_code) @mock.patch('cinderclient.utils.find_resource') def test_snapshot_create_pre_3_66_with_force_None( self, mock_find_vol): """"""We will let the API detect the problematic value."""""" mock_find_vol.return_value = volumes.Volume( self, {'id': '123456'}, loaded=True) snap_body_3_65 = { 'snapshot': { 'volume_id': '123456', # note: this is a string, NOT None! 'force': 'None', 'name': None, 'description': None, 'metadata': {} } } self.run_command('--os-volume-api-version 3.65 ' f'snapshot-create --force None 123456') self.assert_called_anytime('POST', '/snapshots', body=snap_body_3_65) def test_snapshot_create_3_66_with_force_None( self, mock_find_vol): mock_find_vol.return_value = volumes.Volume( self, {'id': '123456'}, loaded=True) uae = self.assertRaises(exceptions.UnsupportedAttribute, self.run_command, '--os-volume-api-version 3.66 ' f'snapshot-create --force None 123456') self.assertIn('not allowed after microversion 3.65', str(uae)) @mock.patch('cinderclient.utils.find_resource')",,46,6
openstack%2Fcinder~master~Id8f348109443a7829b5dae91c74dd03c1ea89376,openstack/cinder,master,Id8f348109443a7829b5dae91c74dd03c1ea89376,Add doc8 check to docs builds,MERGED,2022-07-21 21:42:06.000000000,2022-11-09 19:11:47.000000000,2022-11-09 19:10:27.000000000,"[{'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 35414}]","[{'number': 1, 'created': '2022-07-21 21:42:06.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4bfd1c93a5616dc3d5bb4e2a159d7158402ffbee', 'message': 'Add doc8 check to docs builds\n\nCurrently, doc8 only runs in the pep8 testenv.  Add it to the docs\ntestenv to make it easier not to submit a patch with an error.\n\nChange-Id: Id8f348109443a7829b5dae91c74dd03c1ea89376\n'}]",3,850700,4bfd1c93a5616dc3d5bb4e2a159d7158402ffbee,21,4,1,5314,,,0,"Add doc8 check to docs builds

Currently, doc8 only runs in the pep8 testenv.  Add it to the docs
testenv to make it easier not to submit a patch with an error.

Change-Id: Id8f348109443a7829b5dae91c74dd03c1ea89376
",git fetch https://review.opendev.org/openstack/cinder refs/changes/00/850700/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4bfd1c93a5616dc3d5bb4e2a159d7158402ffbee,doc8, doc8 doc8,,2,0
openstack%2Fironic~bugfix%2F21.0~I2e02231d294997e824db77c998ef8d352fa69075,openstack/ironic,bugfix/21.0,I2e02231d294997e824db77c998ef8d352fa69075,Fix the invalid glance client test,MERGED,2022-11-09 12:26:05.000000000,2022-11-09 18:52:41.000000000,2022-11-09 14:04:30.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2022-11-09 12:26:05.000000000', 'files': ['ironic/common/glance_service/image_service.py', 'ironic/common/utils.py', 'ironic/tests/unit/common/test_glance_service.py', 'ironic/conf/glance.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4de58fa80763df74672a8b6d0b73483b1e8ed3e3', 'message': ""Fix the invalid glance client test\n\nIt relied on mocking tenacity.retry, but it's executed on class\ninitialization. Depending on the ordering, it may do nothing or\nit may replace ImageService.call with a mock.\n\nInstead, add a new tenacity helper that loads an option in runtime.\nAs a nice side effect, [glance]num_retries is now mutable.\n\nChange-Id: I2e02231d294997e824db77c998ef8d352fa69075\n(cherry picked from commit cab51a9fcc022f2e4bb634277dd20e90e2dc78f7)\n""}]",0,864042,4de58fa80763df74672a8b6d0b73483b1e8ed3e3,9,2,1,10239,,,0,"Fix the invalid glance client test

It relied on mocking tenacity.retry, but it's executed on class
initialization. Depending on the ordering, it may do nothing or
it may replace ImageService.call with a mock.

Instead, add a new tenacity helper that loads an option in runtime.
As a nice side effect, [glance]num_retries is now mutable.

Change-Id: I2e02231d294997e824db77c998ef8d352fa69075
(cherry picked from commit cab51a9fcc022f2e4bb634277dd20e90e2dc78f7)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/42/864042/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/glance_service/image_service.py', 'ironic/common/utils.py', 'ironic/tests/unit/common/test_glance_service.py', 'ironic/conf/glance.py']",4,4de58fa80763df74672a8b6d0b73483b1e8ed3e3,glance-test-bugfix/21.0," mutable=True,",,29,15
openstack%2Fnetworking-bagpipe~stable%2Fxena~Iceb92b157d5e875090a0dedec37c398716b89495,openstack/networking-bagpipe,stable/xena,Iceb92b157d5e875090a0dedec37c398716b89495,Add required projects where necessary,MERGED,2022-10-21 10:02:11.000000000,2022-11-09 18:44:50.000000000,2022-11-09 18:42:55.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-21 10:02:11.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/39546f061193de8d46d6ca6141122f83bb18621a', 'message': ""Add required projects where necessary\n\nMost of the jobs needs required-projects to be added, especially in\nstable branches, where the lack of them causes gate failures.\n\nSince the templates openstack-python3-jobs-neutron and\nperiodic-stable-jobs-neutron don't contain all the necessary projects\nfor bagpipe we need to add them one by one.\n\nChanges:\n  .zuul.yaml\n\nNOTE(elod.illes): change is due to py39 job is only present in the\ncheck queue of stable/xena. No need to add in the gate queue.\n\nChange-Id: Iceb92b157d5e875090a0dedec37c398716b89495\n(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)\n(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)\n(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)\n""}]",1,862288,39546f061193de8d46d6ca6141122f83bb18621a,8,3,1,17685,,,0,"Add required projects where necessary

Most of the jobs needs required-projects to be added, especially in
stable branches, where the lack of them causes gate failures.

Since the templates openstack-python3-jobs-neutron and
periodic-stable-jobs-neutron don't contain all the necessary projects
for bagpipe we need to add them one by one.

Changes:
  .zuul.yaml

NOTE(elod.illes): change is due to py39 job is only present in the
check queue of stable/xena. No need to add in the gate queue.

Change-Id: Iceb92b157d5e875090a0dedec37c398716b89495
(cherry picked from commit 7a02ee3188a4cadba76d75ea03400b35a33c2e5f)
(cherry picked from commit 1b474c3333b25970431ade31d90a38af3f47fb7a)
(cherry picked from commit d9bd4c660ee10c8de39d4b83090aefb79933fc00)
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/88/862288/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,39546f061193de8d46d6ca6141122f83bb18621a,add-bagpipe-required-projects, - openstack-tox-docs: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-py39: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-docs: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc periodic-stable: jobs: - openstack-tox-docs: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-py36: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc - openstack-tox-py38: required-projects: - openstack/horizon - openstack/networking-bgpvpn - openstack/networking-sfc,,32,0
openstack%2Fheat~master~I1c4da88029bbf1a3cfb58f5e21da28ec2912f924,openstack/heat,master,I1c4da88029bbf1a3cfb58f5e21da28ec2912f924,Improve map_merge logging,MERGED,2022-11-03 05:47:15.000000000,2022-11-09 18:27:36.000000000,2022-11-09 18:26:10.000000000,"[{'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-03 05:47:15.000000000', 'files': ['heat/engine/hot/functions.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/56d99bf6589832e24e4b0ca53dd7eb2bb8dccd60', 'message': ""Improve map_merge logging\n\nTemplates can be complex and contain multiple instances of\nmap_merges. Debugging this can be complex, so this change\naims to improve the mapping and help users determine where\nthe problem has occured.\n\nWith this change, instead of just saying an error occured,\nwe will now return the object that the error occurred with\nand a note about it's type. This will allow for quick\nidentification of what the problem was.\n\nChange-Id: I1c4da88029bbf1a3cfb58f5e21da28ec2912f924\n""}]",7,863478,56d99bf6589832e24e4b0ca53dd7eb2bb8dccd60,20,4,1,30073,,,0,"Improve map_merge logging

Templates can be complex and contain multiple instances of
map_merges. Debugging this can be complex, so this change
aims to improve the mapping and help users determine where
the problem has occured.

With this change, instead of just saying an error occured,
we will now return the object that the error occurred with
and a note about it's type. This will allow for quick
identification of what the problem was.

Change-Id: I1c4da88029bbf1a3cfb58f5e21da28ec2912f924
",git fetch https://review.opendev.org/openstack/heat refs/changes/78/863478/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/hot/functions.py'],1,56d99bf6589832e24e4b0ca53dd7eb2bb8dccd60,map-merge-log," msg = _('Incorrect arguments: Items to merge must be maps. ' '{} is type {} instead of a dict'.format( repr(m)[:200], type(m)))", msg = _('Incorrect arguments: Items to merge must be maps.'),3,1
openstack%2Fcinder~stable%2Fyoga~Icd9dad9ad7b3ad71b3962b078e5b94670ac41c87,openstack/cinder,stable/yoga,Icd9dad9ad7b3ad71b3962b078e5b94670ac41c87,rbd: Fix snapshot delete when the source volume doesn't exist,MERGED,2022-09-20 12:32:58.000000000,2022-11-09 18:11:52.000000000,2022-11-09 18:10:28.000000000,"[{'_account_id': 4523}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-09-20 12:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/510399803831eae935f415c2046a40651c2740c1', 'message': ""rbd: Fix snapshot delete when the source volume doesn't exist\n\nCurrently snapshot delete requires access to the source volume and\nthe operation fails if the source volume doesn't exist in the backend.\nThis prevents some snapshots from being deleted when the source volume\nimage is deleted from the backend for some reason (for example, after\ncluster format).\n\nThis change makes the rbd driver to skip updating the source volume\nif it doesn't exist. A warning log is left so that operators can be\naware of any skip event.\n\nCloses-Bug: #1957073\nChange-Id: Icd9dad9ad7b3ad71b3962b078e5b94670ac41c87\n(cherry picked from commit 3ddf7ca9ea9587318b8c903e2c43b1879846d1c2)\n""}, {'number': 2, 'created': '2022-09-27 04:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1a81996e4735812b1c39a1137c00f98cd3ae7206', 'message': ""rbd: Fix snapshot delete when the source volume doesn't exist\n\nCurrently snapshot delete requires access to the source volume and\nthe operation fails if the source volume doesn't exist in the backend.\nThis prevents some snapshots from being deleted when the source volume\nimage is deleted from the backend for some reason (for example, after\ncluster format).\n\nThis change makes the rbd driver to skip updating the source volume\nif it doesn't exist. A warning log is left so that operators can be\naware of any skip event.\n\nCloses-Bug: #1957073\nChange-Id: Icd9dad9ad7b3ad71b3962b078e5b94670ac41c87\n(cherry picked from commit 3ddf7ca9ea9587318b8c903e2c43b1879846d1c2)\n""}, {'number': 3, 'created': '2022-10-17 10:21:47.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py', 'releasenotes/notes/bug-1957073-0d1307a8637a62b7.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/43fd2fadb7ce06a435967884124a69c96bb47d00', 'message': ""rbd: Fix snapshot delete when the source volume doesn't exist\n\nCurrently snapshot delete requires access to the source volume and\nthe operation fails if the source volume doesn't exist in the backend.\nThis prevents some snapshots from being deleted when the source volume\nimage is deleted from the backend for some reason (for example, after\ncluster format).\n\nThis change makes the rbd driver to skip updating the source volume\nif it doesn't exist. A warning log is left so that operators can be\naware of any skip event.\n\nThis commit also includes a squash to add a releasenote from\nI40f6eb1f104da4410d32410940824a88f7d1ec62 to reduce backporting\nworkload.\n\nCloses-Bug: #1957073\nChange-Id: Icd9dad9ad7b3ad71b3962b078e5b94670ac41c87\n(cherry picked from commit 3ddf7ca9ea9587318b8c903e2c43b1879846d1c2)\n(cherry picked from commit cf108981432d35049bf28010d3191fd9f4b82ccc)\n""}]",9,858463,43fd2fadb7ce06a435967884124a69c96bb47d00,56,4,3,9816,,,0,"rbd: Fix snapshot delete when the source volume doesn't exist

Currently snapshot delete requires access to the source volume and
the operation fails if the source volume doesn't exist in the backend.
This prevents some snapshots from being deleted when the source volume
image is deleted from the backend for some reason (for example, after
cluster format).

This change makes the rbd driver to skip updating the source volume
if it doesn't exist. A warning log is left so that operators can be
aware of any skip event.

This commit also includes a squash to add a releasenote from
I40f6eb1f104da4410d32410940824a88f7d1ec62 to reduce backporting
workload.

Closes-Bug: #1957073
Change-Id: Icd9dad9ad7b3ad71b3962b078e5b94670ac41c87
(cherry picked from commit 3ddf7ca9ea9587318b8c903e2c43b1879846d1c2)
(cherry picked from commit cf108981432d35049bf28010d3191fd9f4b82ccc)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/63/858463/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py', 'releasenotes/notes/bug-1957073-0d1307a8637a62b7.yaml']",3,510399803831eae935f415c2046a40651c2740c1,bug/1957073,--- fixes: - | RBD Driver `bug #1957073 <https://bugs.launchpad.net/cinder/+bug/1957073>`_: Snapshot delete now succeeds and skips updating the source volume image if the image does not exist in the backend. ,,55,28
openstack%2Fansible-collections-openstack~master~I1370f5bcde602f63b4763c487f027677e79c73b0,openstack/ansible-collections-openstack,master,I1370f5bcde602f63b4763c487f027677e79c73b0,Use module defaults groups in ci integration tests to reduce code bloat,MERGED,2022-11-08 10:55:05.000000000,2022-11-09 18:02:56.000000000,2022-11-09 18:02:56.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-08 10:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/67d3a83f97fd8b3cb7a9122a3f1000804a245d0d', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 2, 'created': '2022-11-08 12:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/eb9b414a7b5cea0b1dd309a57711fe3ad375a9be', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 3, 'created': '2022-11-08 12:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e114a44cc33a14b260af144bb6d243370f13c4f6', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 4, 'created': '2022-11-08 14:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b3fed4e9ed8571b5f65593134c4bfff8b9fe7695', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 5, 'created': '2022-11-08 19:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4a18ef054bf78916f9c4b029f190c5fcc4b392cd', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 6, 'created': '2022-11-08 19:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/bbe26f6065235e67b827edb2dd1f60ca00db5aab', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 7, 'created': '2022-11-08 19:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b9130b5652e255739205671cbb1a37258c6bd753', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 8, 'created': '2022-11-09 13:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3502ed1b6960a059cc956586fe41a583a6930012', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}, {'number': 9, 'created': '2022-11-09 13:37:12.000000000', 'files': ['ci/roles/keystone_idp/tasks/main.yml', 'ci/roles/quota/defaults/main.yml', 'ci/roles/keystone_mapping/tasks/main.yml', 'ci/roles/quota/tasks/main.yml', 'ci/roles/keystone_federation_protocol/tasks/main.yml', 'ci/roles/object_container/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cd002a55550f40d06bc47e7e04c096fb5df8ea01', 'message': 'Use module defaults groups in ci integration tests to reduce code bloat\n\nChange-Id: I1370f5bcde602f63b4763c487f027677e79c73b0\n'}]",0,863985,cd002a55550f40d06bc47e7e04c096fb5df8ea01,20,4,9,32962,,,0,"Use module defaults groups in ci integration tests to reduce code bloat

Change-Id: I1370f5bcde602f63b4763c487f027677e79c73b0
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/85/863985/9 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/keystone_idp/tasks/main.yml', 'ci/roles/quota/defaults/main.yml', 'ci/roles/keystone_mapping/tasks/main.yml', 'ci/roles/quota/tasks/main.yml', 'ci/roles/keystone_federation_protocol/tasks/main.yml', 'ci/roles/object_container/tasks/main.yml']",6,67d3a83f97fd8b3cb7a9122a3f1000804a245d0d,project-access, group/openstack.cloud.openstack: ignore_errors: yes , openstack.cloud.object_container: ignore_errors: yes,102,133
openstack%2Fpython-aodhclient~stable%2Fwallaby~Ia11f25fa8c36c6051a44994f2545e2b64a665593,openstack/python-aodhclient,stable/wallaby,Ia11f25fa8c36c6051a44994f2545e2b64a665593,Change aggregation method to mean,MERGED,2022-11-08 10:21:44.000000000,2022-11-09 17:59:53.000000000,2022-11-09 17:59:02.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-11-08 10:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/e67e6238a6ecc51a44255d30ee0ebd313e971cd0', 'message': 'Change aggregation method to mean\n\nCommit 231f404ad13bac69964f19b9b1bfa5a42c1f977a handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nDepends-On: https://review.opendev.org/c/openstack/aodh/+/860656\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n'}, {'number': 2, 'created': '2022-11-08 10:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/2442b7a115d2a7a2cb18b4cf8db240088d3fdf44', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nDepends-On: https://review.opendev.org/c/openstack/aodh/+/863796\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n'}, {'number': 3, 'created': '2022-11-09 06:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/578f3640ee19fb5c0512987ba39a21238113c739', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nDepends-On: https://review.opendev.org/c/openstack/aodh/+/863796\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n'}, {'number': 4, 'created': '2022-11-09 07:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/9ef520eeee806232cdb15641dc5711f068d2d78a', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nopenstack-tox-py* jobs fail due to missing ""operatorPrecedence"" attribute\nbecause of change[1] in pyparsing module. Adjust to this change by using\n""infixNotation"" in place of ""operatorPrecedence"".\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nDepends-On: https://review.opendev.org/c/openstack/aodh/+/863796\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n'}, {'number': 5, 'created': '2022-11-09 07:21:03.000000000', 'files': ['aodhclient/tests/functional/test_alarm.py', 'aodhclient/utils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/1c67e9a167b6612f45313af978eaa3c10b701621', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nopenstack-tox-py* jobs fail due to missing ""operatorPrecedence""\nattribute because of change[1] in pyparsing module. Adjust to\nthis change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nDepends-On: https://review.opendev.org/c/openstack/aodh/+/863796\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n'}]",2,863797,1c67e9a167b6612f45313af978eaa3c10b701621,18,3,5,32240,,,0,"Change aggregation method to mean

Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles
ignoring gnocchi api error when metric is not created.
However there are functional test failures when the
aggregation method is set to last for alarm type
gnocchi_aggregation_by_resources_threshold,

This fix changes the aggregration method to mean for
any create/update of alarm type
gnocchi_aggregation_by_resources_threshold.

openstack-tox-py* jobs fail due to missing ""operatorPrecedence""
attribute because of change[1] in pyparsing module. Adjust to
this change by using ""infixNotation"" in place of ""operatorPrecedence"".

[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4

Depends-On: https://review.opendev.org/c/openstack/aodh/+/863796
Change-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593
Closes-Bug: #1974682
(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)
(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)
(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/97/863797/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodhclient/tests/functional/test_alarm.py', 'tox.ini']",2,e67e6238a6ecc51a44255d30ee0ebd313e971cd0,," PYTHONWARNINGS=ignore:DEPRECATION::pip._internal.cli.base_command,ignore::UserWarning http://tarballs.openstack.org/aodh/aodh-stable-xena.tar.gz#egg=aodh[mysql]", http://tarballs.openstack.org/aodh/aodh-master.tar.gz#egg=aodh[mysql],12,11
openstack%2Fec2-api~master~I7c46a3e86f7e2fd20054e6f8ff152640f7a253ab,openstack/ec2-api,master,I7c46a3e86f7e2fd20054e6f8ff152640f7a253ab,Add some automatic steps & Fix SQL in install scripts,MERGED,2022-09-27 11:44:29.000000000,2022-11-09 17:54:55.000000000,2022-11-09 17:52:21.000000000,"[{'_account_id': 10234}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-27 11:44:29.000000000', 'files': ['tools/db/ec2api-db-setup', 'install.sh'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0ae0b9ab477c93ce2f9205ce317e91e74cee42cd', 'message': 'Add some automatic steps & Fix SQL in install scripts\n\nThis commit adds\n- select package manager in install.sh\n- retry of MySQL password\n\nfixes\n- MySQL 8 support\n- pip install MYSQL-python failure\nChange-Id: I7e9bd8b308ddc84e95e694abe806eb7630b9919c\n\nChange-Id: I7c46a3e86f7e2fd20054e6f8ff152640f7a253ab\n'}]",0,859407,0ae0b9ab477c93ce2f9205ce317e91e74cee42cd,7,2,1,35339,,,0,"Add some automatic steps & Fix SQL in install scripts

This commit adds
- select package manager in install.sh
- retry of MySQL password

fixes
- MySQL 8 support
- pip install MYSQL-python failure
Change-Id: I7e9bd8b308ddc84e95e694abe806eb7630b9919c

Change-Id: I7c46a3e86f7e2fd20054e6f8ff152640f7a253ab
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/07/859407/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/db/ec2api-db-setup', 'install.sh']",2,0ae0b9ab477c93ce2f9205ce317e91e74cee42cd,,"PACKAGE_MANAGER_SELECTED=0 while [ $PACKAGE_MANAGER_SELECTED -eq 0 ] do printf ""Enter the package manager you use <rpm|deb> "" read PACKAGE_MANAGER if [ $PACKAGE_MANAGER = ""rpm"" ] || [ $PACKAGE_MANAGER = ""deb"" ] ; then PACKAGE_MANAGER_SELECTED=1 else echo ""The package manager you entered \""${PACKAGE_MANAGER}\"" is not in <rpm|deb>"" fi done $SUDO_PREFIX tools/db/ec2api-db-setup $PACKAGE_MANAGER",$SUDO_PREFIX tools/db/ec2api-db-setup deb,43,7
openstack%2Fec2-api~master~I3103c4ecb803e784c87ed4cff5124d303620d4a5,openstack/ec2-api,master,I3103c4ecb803e784c87ed4cff5124d303620d4a5,Correct queue declaration in Zuul config,MERGED,2022-09-24 11:51:52.000000000,2022-11-09 17:54:14.000000000,2022-11-09 17:52:18.000000000,"[{'_account_id': 10234}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-24 11:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/587934174cd561e2f18adaa53a004d11ef9abca5', 'message': 'Correct queue declaration in Zuul config\n\nMove the ec2-api queue declaration from the pipeline level (where it\nis no longer valid) to the project level.\n\nhttps: //lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n\nChange-Id: I3103c4ecb803e784c87ed4cff5124d303620d4a5\n'}, {'number': 2, 'created': '2022-09-26 12:25:51.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/16b27e67ea4b5fce9e84e217bde8f07af6a7481b', 'message': 'Correct queue declaration in Zuul config\n\nMove the ec2-api queue declaration from the pipeline level (where it\nis no longer valid) to the project level.\n\nhttps: //lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n\nChange-Id: I3103c4ecb803e784c87ed4cff5124d303620d4a5\n'}]",0,859192,16b27e67ea4b5fce9e84e217bde8f07af6a7481b,9,2,2,5263,,,0,"Correct queue declaration in Zuul config

Move the ec2-api queue declaration from the pipeline level (where it
is no longer valid) to the project level.

https: //lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html

Change-Id: I3103c4ecb803e784c87ed4cff5124d303620d4a5
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/92/859192/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,587934174cd561e2f18adaa53a004d11ef9abca5,fix-queues, queue: ec2-api, queue: ec2-api,1,1
openstack%2Fec2-api~master~I7e9bd8b308ddc84e95e694abe806eb7630b9919c,openstack/ec2-api,master,I7e9bd8b308ddc84e95e694abe806eb7630b9919c,Add some automatic steps & Fix SQL in install scripts,MERGED,2022-09-27 11:40:08.000000000,2022-11-09 17:52:20.000000000,2022-11-09 17:52:20.000000000,"[{'_account_id': 10234}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-27 11:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/d98e8afd0efe9eca1dad6d7c3be9d4173b5dc297', 'message': 'Add some automatic steps & Fix SQ in install scripts\n\nChange-Id: I7e9bd8b308ddc84e95e694abe806eb7630b9919c\n'}, {'number': 2, 'created': '2022-09-27 11:42:09.000000000', 'files': ['tools/db/ec2api-db-setup', 'install.sh'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/a17f4bdcfa9b6d550df9613f1efa8501ca92d5c9', 'message': 'Add some automatic steps & Fix SQL in install scripts\n\nChange-Id: I7e9bd8b308ddc84e95e694abe806eb7630b9919c\n'}]",0,859406,a17f4bdcfa9b6d550df9613f1efa8501ca92d5c9,7,2,2,35339,,,0,"Add some automatic steps & Fix SQL in install scripts

Change-Id: I7e9bd8b308ddc84e95e694abe806eb7630b9919c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/06/859406/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/db/ec2api-db-setup', 'install.sh']",2,d98e8afd0efe9eca1dad6d7c3be9d4173b5dc297,,"PACKAGE_MANAGER_SELECTED=0 while [ $PACKAGE_MANAGER_SELECTED -eq 0 ] do printf ""Enter the package manager you use <rpm|deb> "" read PACKAGE_MANAGER if [ $PACKAGE_MANAGER = ""rpm"" ] || [ $PACKAGE_MANAGER = ""deb"" ] ; then PACKAGE_MANAGER_SELECTED=1 else echo ""The package manager you entered \""${PACKAGE_MANAGER}\"" is not in <rpm|deb>"" fi done $SUDO_PREFIX tools/db/ec2api-db-setup $PACKAGE_MANAGER",$SUDO_PREFIX tools/db/ec2api-db-setup deb,43,7
openstack%2Fec2api-tempest-plugin~master~I2fa5a56b2822a83ba63e2dc893e9d9bb3bf2c4ec,openstack/ec2api-tempest-plugin,master,I2fa5a56b2822a83ba63e2dc893e9d9bb3bf2c4ec,Add stable/zed jobs on master gate,MERGED,2022-10-16 04:03:20.000000000,2022-11-09 17:46:02.000000000,2022-11-09 17:46:02.000000000,"[{'_account_id': 10234}, {'_account_id': 22348}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-10-16 04:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2api-tempest-plugin/commit/9bddce78d06d2840ac95c4057ffb3a2b147f772a', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2fa5a56b2822a83ba63e2dc893e9d9bb3bf2c4ec\n'}, {'number': 2, 'created': '2022-11-09 15:39:30.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/ec2api-tempest-plugin/commit/205864bf25919aeaf40f790f697f6dadd88b6764', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2fa5a56b2822a83ba63e2dc893e9d9bb3bf2c4ec\n'}]",3,861521,205864bf25919aeaf40f790f697f6dadd88b6764,14,3,2,8556,,,0,"Add stable/zed jobs on master gate

As zed is released, we should add its job on master
gate to keep branchless tempest plugins compatible
to stable branch.

Ref: Tempest plugins guide for stable branch testing:
- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html

Change-Id: I2fa5a56b2822a83ba63e2dc893e9d9bb3bf2c4ec
",git fetch https://review.opendev.org/openstack/ec2api-tempest-plugin refs/changes/21/861521/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,9bddce78d06d2840ac95c4057ffb3a2b147f772a,zed-stable-job, - ec2api-tempest-plugin-functional-zed name: ec2api-tempest-plugin-functional-zed parent: ec2api-tempest-plugin-functional nodeset: openstack-single-node-focal override-checkout: stable/zed - job:,,6,0
openstack%2Fpython-tripleoclient~master~I66d6435e41a42a9db1772eea36e41c7a5cf87d23,openstack/python-tripleoclient,master,I66d6435e41a42a9db1772eea36e41c7a5cf87d23,Pass undercloud inventory for running preflight validations,MERGED,2022-11-03 16:39:17.000000000,2022-11-09 17:33:09.000000000,2022-11-09 17:32:08.000000000,"[{'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2022-11-03 16:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/291e0fee98b584701a18cc3430351ca63de0bf52', 'message': ""Pass undercloud hostname for running preflight validations\n\nThe undercloud name is hardcoded in the preflight validations.\nThis patch look for the undercloud name in the config file\nand use it in case it's specified and diffirent from the default.\nOtherwise it fallback to the default value 'undercloud'\n\nCloses-bug: #1994032\n\nChange-Id: I66d6435e41a42a9db1772eea36e41c7a5cf87d23\n""}, {'number': 2, 'created': '2022-11-03 16:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a0b5e1f2560c364c4dcfab56d60139891a08c171', 'message': ""Pass undercloud hostname for running preflight validations\n\nThe undercloud name is hardcoded in the preflight validations.\nThis patch look for the undercloud name in the config file\nand use it in case it's specified and diffirent from the default.\nOtherwise it fallback to the default value 'undercloud'\n\nCloses-bug: #1994032\n\nChange-Id: I66d6435e41a42a9db1772eea36e41c7a5cf87d23\n""}, {'number': 3, 'created': '2022-11-04 09:04:14.000000000', 'files': ['tripleoclient/v1/undercloud_preflight.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5589eabcd776eeafd080e819b10508fa12b022c4', 'message': 'Pass undercloud inventory for running preflight validations\n\nThe undercloud name is hardcoded in the preflight validations.\nThis patch generate an undercloud inventory in order to run\npreflight validations as prep step of the undercloud install.\n\nCloses-bug: #1994032\n\nChange-Id: I66d6435e41a42a9db1772eea36e41c7a5cf87d23\n'}]",6,863541,5589eabcd776eeafd080e819b10508fa12b022c4,17,4,3,16515,,,0,"Pass undercloud inventory for running preflight validations

The undercloud name is hardcoded in the preflight validations.
This patch generate an undercloud inventory in order to run
preflight validations as prep step of the undercloud install.

Closes-bug: #1994032

Change-Id: I66d6435e41a42a9db1772eea36e41c7a5cf87d23
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/41/863541/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/undercloud_preflight.py'],1,291e0fee98b584701a18cc3430351ca63de0bf52,lp/1994032,"def _run_validations(uc_hostname, upgrade=False): if not uc_hostname: uc_hostname = 'undercloud' args = ['validation', 'run', '-i', uc_hostname, '--validation', _run_validations(CONF.get('undercloud_hostname','undercloud'), upgrade)","def _run_validations(upgrade=False): args = ['validation', 'run', '-i', 'undercloud', '--validation', _run_validations(upgrade)",6,3
openstack%2Fnova~stable%2Fyoga~Ibc4bc7edf1c8d1e841c72c9188a0a62836e9f153,openstack/nova,stable/yoga,Ibc4bc7edf1c8d1e841c72c9188a0a62836e9f153,[compute] always set instance.host in post_livemigration,MERGED,2022-10-19 10:55:37.000000000,2022-11-09 17:21:07.000000000,2022-11-09 17:19:53.000000000,"[{'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 8213}, {'_account_id': 22348}, {'_account_id': 34860}, {'_account_id': 35414}]","[{'number': 1, 'created': '2022-10-19 10:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f918dd792ac3fffc32f02a269783f7ce9e4e5e81', 'message': '[compute] always set instance.host in post_livemigration\n\nThis change add a new _post_live_migration_update_host\nfunction that wraps _post_live_migration and just ensures\nthat if we exit due to an exception instance.host is set\nto the destination host.\n\nwhen we are in _post_live_migration the guest has already\nstarted running on the destination host and we cannot revert.\nSometimes admins or users will hard reboot the instance expecting\nthat to fix everything when the vm enters the error state after\nthe failed migrations. Previously this would end up recreating the\ninstance on the source node leading to possible data corruption if\nthe instance used shared storage.\n\nChange-Id: Ibc4bc7edf1c8d1e841c72c9188a0a62836e9f153\nPartial-Bug: #1628606\n(cherry picked from commit 8449b7caefa4a5c0728e11380a088525f15ad6f5)\n(cherry picked from commit c4ef8bba7e3321d1df339ee5111429e1ebf47802)\n'}, {'number': 2, 'created': '2022-10-21 07:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f377ae41a73fa9cc254e9e80cd951505a192e9bb', 'message': '[compute] always set instance.host in post_livemigration\n\nThis change add a new _post_live_migration_update_host\nfunction that wraps _post_live_migration and just ensures\nthat if we exit due to an exception instance.host is set\nto the destination host.\n\nwhen we are in _post_live_migration the guest has already\nstarted running on the destination host and we cannot revert.\nSometimes admins or users will hard reboot the instance expecting\nthat to fix everything when the vm enters the error state after\nthe failed migrations. Previously this would end up recreating the\ninstance on the source node leading to possible data corruption if\nthe instance used shared storage.\n\nChange-Id: Ibc4bc7edf1c8d1e841c72c9188a0a62836e9f153\nPartial-Bug: #1628606\n(cherry picked from commit 8449b7caefa4a5c0728e11380a088525f15ad6f5)\n(cherry picked from commit c4ef8bba7e3321d1df339ee5111429e1ebf47802)\n'}, {'number': 3, 'created': '2022-10-21 12:52:16.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/tests/functional/regressions/test_bug_1628606.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/17ae907569e45cc0f5c7da9511bb668a877b7b2e', 'message': '[compute] always set instance.host in post_livemigration\n\nThis change add a new _post_live_migration_update_host\nfunction that wraps _post_live_migration and just ensures\nthat if we exit due to an exception instance.host is set\nto the destination host.\n\nwhen we are in _post_live_migration the guest has already\nstarted running on the destination host and we cannot revert.\nSometimes admins or users will hard reboot the instance expecting\nthat to fix everything when the vm enters the error state after\nthe failed migrations. Previously this would end up recreating the\ninstance on the source node leading to possible data corruption if\nthe instance used shared storage.\n\nChange-Id: Ibc4bc7edf1c8d1e841c72c9188a0a62836e9f153\nPartial-Bug: #1628606\n(cherry picked from commit 8449b7caefa4a5c0728e11380a088525f15ad6f5)\n(cherry picked from commit 643b0c7d35752b214eee19b8d7298a19a8493f6b)\n'}]",3,861872,17ae907569e45cc0f5c7da9511bb668a877b7b2e,31,7,3,34860,,,0,"[compute] always set instance.host in post_livemigration

This change add a new _post_live_migration_update_host
function that wraps _post_live_migration and just ensures
that if we exit due to an exception instance.host is set
to the destination host.

when we are in _post_live_migration the guest has already
started running on the destination host and we cannot revert.
Sometimes admins or users will hard reboot the instance expecting
that to fix everything when the vm enters the error state after
the failed migrations. Previously this would end up recreating the
instance on the source node leading to possible data corruption if
the instance used shared storage.

Change-Id: Ibc4bc7edf1c8d1e841c72c9188a0a62836e9f153
Partial-Bug: #1628606
(cherry picked from commit 8449b7caefa4a5c0728e11380a088525f15ad6f5)
(cherry picked from commit 643b0c7d35752b214eee19b8d7298a19a8493f6b)
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/861872/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/tests/functional/regressions/test_bug_1628606.py']",3,f918dd792ac3fffc32f02a269783f7ce9e4e5e81,bug/1628606," server = self._live_migrate( self.assertEqual(self.dest.host, server['OS-EXT-SRV-ATTR:host'])"," self._live_migrate( # FIXME(amit): this should point to the dest as after migration # but does not because of bug 1628606 self.assertEqual(self.src.host, server['OS-EXT-SRV-ATTR:host'])",64,7
openstack%2Fhorizon~stable%2Fussuri~Ic61a3958461a4a939acc40d1039881e2d4c3a1cd,openstack/horizon,stable/ussuri,Ic61a3958461a4a939acc40d1039881e2d4c3a1cd,Escape unicode characters when setting logout_reason cookie,MERGED,2022-07-25 03:37:18.000000000,2022-11-09 17:06:36.000000000,2022-11-09 17:05:19.000000000,"[{'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-07-25 03:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fda93494982a4a75ef0969db03e0f9136b29ed2e', 'message': 'Escape unicode characters when setting logout_reason cookie\n\nConflicts:\n\topenstack_auth/views.py\n\nChange-Id: Ic61a3958461a4a939acc40d1039881e2d4c3a1cd\nCloses-bug: #1894801\n(cherry picked from commit e68e23937341d03be7475d71903f31a61403c1e2)\n'}, {'number': 2, 'created': '2022-07-25 03:39:20.000000000', 'files': ['horizon/templates/auth/_password_form.html', 'horizon/templates/auth/_login_form.html', 'openstack_auth/views.py', 'horizon/utils/functions.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0116e2bfe66cdd0ca86f809083ab0e21877a78d8', 'message': 'Escape unicode characters when setting logout_reason cookie\n\nConflicts:\n\topenstack_auth/views.py\n\nResolved conflict caused by 6ffeb3cabad7e311a99094b2cf2a2a266be84990,\nwhich is present stable/victoria and later.\n\nChange-Id: Ic61a3958461a4a939acc40d1039881e2d4c3a1cd\nCloses-bug: #1894801\n(cherry picked from commit e68e23937341d03be7475d71903f31a61403c1e2)\n'}]",2,850826,0116e2bfe66cdd0ca86f809083ab0e21877a78d8,14,4,2,9816,,,0,"Escape unicode characters when setting logout_reason cookie

Conflicts:
	openstack_auth/views.py

Resolved conflict caused by 6ffeb3cabad7e311a99094b2cf2a2a266be84990,
which is present stable/victoria and later.

Change-Id: Ic61a3958461a4a939acc40d1039881e2d4c3a1cd
Closes-bug: #1894801
(cherry picked from commit e68e23937341d03be7475d71903f31a61403c1e2)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/26/850826/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/auth/_password_form.html', 'horizon/templates/auth/_login_form.html', 'horizon/utils/functions.py', 'openstack_auth/views.py']",4,fda93494982a4a75ef0969db03e0f9136b29ed2e,cookie-logout-reason-encoding-stable/ussuri,"def set_logout_reason(res, msg): msg = msg.encode('unicode_escape').decode('ascii') res.set_cookie('logout_reason', msg, max_age=10) logout_reason = request.COOKIES.get( 'logout_reason', '').encode('ascii').decode('unicode_escape') logout_status = request.COOKIES.get('logout_status') 'logout_reason': logout_reason, 'logout_status': logout_status, set_logout_reason(res, msg) set_logout_reason(res, msg) set_logout_reason(res, msg) set_logout_reason(res, msg)"," res.set_cookie('logout_reason', msg, max_age=10) res.set_cookie('logout_reason', msg, max_age=10) res.set_cookie('logout_reason', msg, max_age=10) res.set_cookie('logout_reason', msg, max_age=10)",21,11
openstack%2Ftripleo-ansible~stable%2Fzed~I68a89e413b7c3eecb747386998bd36314250384b,openstack/tripleo-ansible,stable/zed,I68a89e413b7c3eecb747386998bd36314250384b,Make creating/updating users idempotent,MERGED,2022-11-09 08:19:42.000000000,2022-11-09 16:37:41.000000000,2022-11-09 16:37:41.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-09 08:19:42.000000000', 'files': ['tripleo_ansible/roles/tripleo_keystone_resources/tasks/admin.yml', 'tripleo_ansible/roles/tripleo_keystone_resources/tasks/users.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4d2ca9586fb498aee63b18d935d68a11d049b545', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n(cherry picked from commit b779d63b63735d4daa4286d8621d01e2c59de906)\n'}]",0,864033,4d2ca9586fb498aee63b18d935d68a11d049b545,8,4,1,14250,,,0,"Make creating/updating users idempotent

Similarly as in [1], updating user passwords causes auth tokens to
be revoked, which may cause service interrupution during a minor
update, or even cause a prolonged interruption in case of swift [2]

[1] https://bugs.launchpad.net/keystone/+bug/1647800
[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350

Change-Id: I68a89e413b7c3eecb747386998bd36314250384b
Related: rhbz#2097350
(cherry picked from commit b779d63b63735d4daa4286d8621d01e2c59de906)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/33/864033/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_keystone_resources/tasks/admin.yml', 'tripleo_ansible/roles/tripleo_keystone_resources/tasks/users.yml']",2,4d2ca9586fb498aee63b18d935d68a11d049b545,,"- name: ""Check password of Keystone user"" openstack.cloud.identity_user_info: name: ""{{ lookup('dict', tripleo_keystone_resources_data).value.name | default(lookup('dict', tripleo_keystone_resources_data).key) }}"" auth_type: ""v3password"" auth: auth_url: ""{{ tripleo_keystone_resources_public_endpoint }}"" username: ""{{ lookup('dict', tripleo_keystone_resources_data).value.name | default(lookup('dict', tripleo_keystone_resources_data).key) }}"" password: ""{{ lookup('dict', tripleo_keystone_resources_data).value.password }}"" user_domain_id: ""{{ lookup('dict', tripleo_keystone_resources_data).value.domain | default('default') }}"" project_name: ""{{ tripleo_keystone_resources_service_project }}"" project_domain_id: default register: tripleo_keystone_resources_user_info_results ignore_errors: true loop: ""{{ batched_tripleo_keystone_resources_data }}"" loop_control: label: ""{{ lookup('dict', tripleo_keystone_resources_data).value.name | default(lookup('dict', tripleo_keystone_resources_data).key) }}"" loop_var: tripleo_keystone_resources_data name: ""{{ lookup('dict', tripleo_keystone_resources_data.0).value.name | default(lookup('dict', tripleo_keystone_resources_data.0).key) }}"" password: ""{{ lookup('dict', tripleo_keystone_resources_data.0).value.password }}"" update_password: ""{{ tripleo_keystone_resources_data.1 is failed | ternary('always', 'on_create') }}"" email: ""{{ lookup('dict', tripleo_keystone_resources_data.0).key }}@localhost"" domain: ""{{ lookup('dict', tripleo_keystone_resources_data.0).value.domain | default('default') }}"" loop: ""{{ batched_tripleo_keystone_resources_data|zip(tripleo_keystone_resources_user_info_results.results)|list }}"" loop_control: label: ""{{ lookup('dict', tripleo_keystone_resources_data.0).value.name | default(lookup('dict', tripleo_keystone_resources_data.0).key) }}"" label: ""{{ lookup('dict', tripleo_keystone_resources_user_async_result_item.tripleo_keystone_resources_data.0).key }}"""," name: ""{{ lookup('dict', tripleo_keystone_resources_data).value.name | default(lookup('dict', tripleo_keystone_resources_data).key) }}"" password: ""{{ lookup('dict', tripleo_keystone_resources_data).value.password }}"" update_password: always email: ""{{ lookup('dict', tripleo_keystone_resources_data).key }}@localhost"" domain: ""{{ lookup('dict', tripleo_keystone_resources_data).value.domain | default('default') }}"" loop: ""{{ batched_tripleo_keystone_resources_data }}"" loop_control: label: ""{{ lookup('dict', tripleo_keystone_resources_data).value.name | default(lookup('dict', tripleo_keystone_resources_data).key) }}"" label: ""{{ lookup('dict', tripleo_keystone_resources_user_async_result_item.tripleo_keystone_resources_data).key }}""",41,9
openstack%2Fcharm-ceph-mon~stable%2Fquincy.2~Ic389c840cc4253adaddcaa50d184db6ca66cb397,openstack/charm-ceph-mon,stable/quincy.2,Ic389c840cc4253adaddcaa50d184db6ca66cb397,Work around config initialisation behaviour change,MERGED,2022-11-08 14:30:10.000000000,2022-11-09 16:07:42.000000000,2022-11-09 16:07:42.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2022-11-08 14:30:10.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/260760b1ca95cb1b5722b3e1e0f4e2534749d822', 'message': 'Work around config initialisation behaviour change\n\nThe previous (classic) version of the charm initialised a Config\nobject in the install hook and let it go out of scope. Initialise\na config object explicitly in the install and upgrade charm hooks.\n\nChange-Id: Ic389c840cc4253adaddcaa50d184db6ca66cb397\n(cherry picked from commit d76dda4f5586b752451d5a9256097a620f1aade0)\n'}]",4,863805,260760b1ca95cb1b5722b3e1e0f4e2534749d822,14,3,1,15382,,,0,"Work around config initialisation behaviour change

The previous (classic) version of the charm initialised a Config
object in the install hook and let it go out of scope. Initialise
a config object explicitly in the install and upgrade charm hooks.

Change-Id: Ic389c840cc4253adaddcaa50d184db6ca66cb397
(cherry picked from commit d76dda4f5586b752451d5a9256097a620f1aade0)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/05/863805/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,260760b1ca95cb1b5722b3e1e0f4e2534749d822,fix/persistent-config-init-stable/quincy.2," def _initialise_config(self): # The following two lines are a horrible hack to deal with the # lifecycle of a charm changing compared to the classic charm. # The previous (classic) version of the charm initialised a # Config object in the install hook and let it go out of scope. # As a result of this, the config_changed processing attempts # to upgrade Ceph from distro to the configured release when it # runs during the install or upgrade-charm hooks. c = hooks.config() c.save() def on_install(self, event): self._initialise_config() self._initialise_config()"," def on_install(self, event):",14,0
openstack%2Fansible-collections-openstack~master~I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad,openstack/ansible-collections-openstack,master,I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad,Refactored integration test of openstacksdk logging feature,MERGED,2022-11-03 14:42:28.000000000,2022-11-09 15:51:13.000000000,2022-11-09 15:51:13.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 32962}]","[{'number': 1, 'created': '2022-11-03 14:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/40253d39af2c1d616e5a3161e606803f6d42a18d', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 2, 'created': '2022-11-04 10:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d6f63e43752ee1580d57a688007750e014342e7a', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 3, 'created': '2022-11-04 12:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/134571217c6e951cbb7be858ebcf16defa2b7061', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 4, 'created': '2022-11-04 19:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/30d98dc3df0cdb48ce2ea6556890ab647ac81fac', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 5, 'created': '2022-11-05 19:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/566416697d5dc69232307863f51ac56ce2282f35', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 6, 'created': '2022-11-07 09:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d2e5ead11d6314bf175cef61fdc7c097ca3f3fc2', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 7, 'created': '2022-11-08 12:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a4e43854e8cd7e88b8e502b4f83c24d5a92b7c7d', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 8, 'created': '2022-11-09 11:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/efc97768fa14d95f24cce08788b5fe307666257b', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}, {'number': 9, 'created': '2022-11-09 13:37:12.000000000', 'files': ['ci/roles/logging/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d0ac32eefd56a5648f278902916545f71cd04f41', 'message': 'Refactored integration test of openstacksdk logging feature\n\nInstead of asserting that openstacksdk created a logging file,\nwe read the contents of that log file now. The benefit is, that\nthis integration test gives users an idea how to actually use the\nlogging feature and also read the contents of the log file.\n\nChange-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad\n'}]",0,863529,d0ac32eefd56a5648f278902916545f71cd04f41,24,3,9,32962,,,0,"Refactored integration test of openstacksdk logging feature

Instead of asserting that openstacksdk created a logging file,
we read the contents of that log file now. The benefit is, that
this integration test gives users an idea how to actually use the
logging feature and also read the contents of the log file.

Change-Id: I9e3c75dda4c1c920937c9780fbdcbe3caeb4d6ad
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/29/863529/5 && git format-patch -1 --stdout FETCH_HEAD,['ci/roles/logging/tasks/main.yaml'],1,40253d39af2c1d616e5a3161e606803f6d42a18d,project-access,"- name: Trigger flavor listing to create logs- name: Read openstacksdk's log file ansible.builtin.slurp: src: ""{{ sdk_log_file_path }}"" register: log - name: Print contents of openstacksdk's log ansible.builtin.debug: msg: ""{{ log['content'] | b64decode }}""","- name: Trigger flavor listing- name: Check log file presence ansible.builtin.stat: path: ""{{ sdk_log_file_path }}"" register: sdk_log_file - name: Assert ansible.builtin.assert: that: - ""sdk_log_file.stat.exists"" - name: Debug log file content ansible.builtin.debug: msg: ""{{ lookup('ansible.builtin.file', sdk_log_file_path) }}""",7,12
openstack%2Ftripleo-validations~stable%2Fzed~I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c,openstack/tripleo-validations,stable/zed,I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c,Remove python-dev from bindep,MERGED,2022-11-09 09:12:50.000000000,2022-11-09 15:27:12.000000000,2022-11-09 15:25:04.000000000,"[{'_account_id': 22348}, {'_account_id': 32926}]","[{'number': 1, 'created': '2022-11-09 09:12:50.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/3bf3cf3146febe4c1d9be737ff2fc01c5ebafd2c', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c\n(cherry picked from commit 12c74369d0c91a44e6604b81d65387f614e4e261)\n""}]",1,864035,3bf3cf3146febe4c1d9be737ff2fc01c5ebafd2c,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c
(cherry picked from commit 12c74369d0c91a44e6604b81d65387f614e4e261)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/35/864035/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,3bf3cf3146febe4c1d9be737ff2fc01c5ebafd2c,drop-python-dev-from-bindep-stable/zed,,python-devel [platform:rpm !platform:rhel-8 !platform:centos-8 !platform:fedora],0,1
openstack%2Ftripleo-ansible~master~I646cd49b614a9f494e77f9893521d3c070900ed5,openstack/tripleo-ansible,master,I646cd49b614a9f494e77f9893521d3c070900ed5,Move cryprography pin,MERGED,2022-11-08 14:50:59.000000000,2022-11-09 15:27:10.000000000,2022-11-09 15:25:01.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-08 14:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9d3ba0911462544b786380a8a9c9945dd5ae3596', 'message': 'WIP Testing pin removal - DO NOT MERGE\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 2, 'created': '2022-11-08 15:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/44675267422c9a979f0f93e32e636833ed55e67a', 'message': 'WIP Testing pin removal - DO NOT MERGE\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 3, 'created': '2022-11-08 16:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cce4c051850ff596e7ddd301c18b3a97091322f0', 'message': 'WIP Testing pin removal - DO NOT MERGE\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 4, 'created': '2022-11-08 16:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/968ac20af5a823a03817e635b450e5d0647ab635', 'message': 'WIP Testing pin removal - DO NOT MERGE\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 5, 'created': '2022-11-08 16:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/34f76350d4e78c93c12d0a7ec5c35ae74aa39e7e', 'message': 'WIP Testing pin removal - DO NOT MERGE\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 6, 'created': '2022-11-09 03:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/723a8bee8858b150bfdc85a5174ff9ea4fcc25d5', 'message': 'Move cryprography pin\n\nThis moves the cryptography pin to ansible-requirements.txt\nwhich is used as a constraints file[1].\n\n[1] https://opendev.org/openstack/tripleo-ansible/src/branch/master/zuul.d/playbooks/pre.yml#L42\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 7, 'created': '2022-11-09 04:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c7c2fd99beba0cee58a6568d93722a3330d48332', 'message': 'Move cryprography pin\n\nThis moves the cryptography pin to ansible-requirements.txt\nwhich is used as a constraints file[1].\n\n[1] https://opendev.org/openstack/tripleo-ansible/src/branch/master/zuul.d/playbooks/pre.yml#L42\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 8, 'created': '2022-11-09 04:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/232f4e1f401cd443b84c027a5342295ba84a51cb', 'message': 'Move cryprography pin\n\nThis moves the cryptography pin to ansible-requirements.txt\nwhich is used as a constraints file[1].\n\n[1] https://opendev.org/openstack/tripleo-ansible/src/branch/master/zuul.d/playbooks/pre.yml#L42\n\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}, {'number': 9, 'created': '2022-11-09 08:11:41.000000000', 'files': ['ansible-requirements.txt', 'zuul.d/playbooks/run-role-addition.yml', 'tripleo_ansible/roles/tripleo_keystone_resources/molecule/default/start_keystone.sh', 'tox.ini', 'molecule-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c0bc395ab494ee18e77fba608cdd40762c7b8c51', 'message': 'Move cryprography pin\n\nThis moves the cryptography pin to ansible-requirements.txt\nwhich is used as a constraints file[1].\n\n[1] https://opendev.org/openstack/tripleo-ansible/src/branch/master/zuul.d/playbooks/pre.yml#L42\n\nRelated-Bug: #1995608\nChange-Id: I646cd49b614a9f494e77f9893521d3c070900ed5\n'}]",3,864010,c0bc395ab494ee18e77fba608cdd40762c7b8c51,24,4,9,28223,,,0,"Move cryprography pin

This moves the cryptography pin to ansible-requirements.txt
which is used as a constraints file[1].

[1] https://opendev.org/openstack/tripleo-ansible/src/branch/master/zuul.d/playbooks/pre.yml#L42

Related-Bug: #1995608
Change-Id: I646cd49b614a9f494e77f9893521d3c070900ed5
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/10/864010/7 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_keystone_resources/tasks/main.yml'],1,9d3ba0911462544b786380a8a9c9945dd5ae3596,molecule/cryptography,- name: create Keystone Admin resources,- name: Create Keystone Admin resources,1,1
openstack%2Ftripleo-validations~stable%2Fwallaby~I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c,openstack/tripleo-validations,stable/wallaby,I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c,Remove python-dev from bindep,MERGED,2022-11-09 09:13:05.000000000,2022-11-09 15:26:51.000000000,2022-11-09 15:25:00.000000000,"[{'_account_id': 22348}, {'_account_id': 32926}]","[{'number': 1, 'created': '2022-11-09 09:13:05.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/7a6de0ca3d78fe0c3e77b5285b940e42003fbc34', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c\n(cherry picked from commit 12c74369d0c91a44e6604b81d65387f614e4e261)\n""}]",0,864036,7a6de0ca3d78fe0c3e77b5285b940e42003fbc34,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c
(cherry picked from commit 12c74369d0c91a44e6604b81d65387f614e4e261)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/36/864036/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,7a6de0ca3d78fe0c3e77b5285b940e42003fbc34,drop-python-dev-from-bindep-stable/zed-stable/wallaby,,python-devel [platform:rpm !platform:rhel-8 !platform:centos-8 !platform:fedora],0,1
openstack%2Freleases~master~Idb2cf9e76b5637796216484682cf4be67d16662d,openstack/releases,master,Idb2cf9e76b5637796216484682cf4be67d16662d,Move non-client library freeze to Milestone-2,ABANDONED,2022-10-19 16:01:33.000000000,2022-11-09 14:31:26.000000000,,"[{'_account_id': 308}, {'_account_id': 5314}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-19 16:01:33.000000000', 'files': ['doc/source/antelope/schedule.yaml', 'doc/source/reference/process.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/644b85af0337f8d39d3a966765da9ac74ea90219', 'message': ""Move non-client library freeze to Milestone-2\n\nIn Zed release cycle there was a late, breaking library release, which\ncaused last minute fire fighting for multiple projects. During the\n2023.1 Antelope PTG 'TC + Community leaders interaction' session this\nwas discussed [1] and PTLs agreed that one solution to this is to move\nnon-client library freeze date from week before Milestone-3 to the week\nof Milestone-2 to avoid the same problem happen in the future.\n\nThis patch adjusts the process and current cycle schedule to match\nthe discussed.\n\n[1] https://etherpad.opendev.org/p/tc-leaders-interaction-2023-1\n\nChange-Id: Idb2cf9e76b5637796216484682cf4be67d16662d\n""}]",11,861900,644b85af0337f8d39d3a966765da9ac74ea90219,13,4,1,17685,,,0,"Move non-client library freeze to Milestone-2

In Zed release cycle there was a late, breaking library release, which
caused last minute fire fighting for multiple projects. During the
2023.1 Antelope PTG 'TC + Community leaders interaction' session this
was discussed [1] and PTLs agreed that one solution to this is to move
non-client library freeze date from week before Milestone-3 to the week
of Milestone-2 to avoid the same problem happen in the future.

This patch adjusts the process and current cycle schedule to match
the discussed.

[1] https://etherpad.opendev.org/p/tc-leaders-interaction-2023-1

Change-Id: Idb2cf9e76b5637796216484682cf4be67d16662d
",git fetch https://review.opendev.org/openstack/releases refs/changes/00/861900/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/antelope/schedule.yaml', 'doc/source/reference/process.rst']",2,644b85af0337f8d39d3a966765da9ac74ea90219,nclfreeze-to-m2," Non-client library freeze: $nclfreeze Non-client library freeze: $nclfreeze This coming week is the deadline for general libraries (except client libraries): their last feature release needs to happen before ""Non-client library freeze"" on $nclfreeze. Only bugfixes releases will be allowed beyond this point. When requesting those library releases, you can also include the stable/$series branching request with the review (as an example, see the ""branches"" section here: https://opendev.org/openstack/releases/src/branch/master/deliverables/pike/os-brick.yaml#n2 Non-client library freeze: $nclfreeze#. Propose autoreleases for cycle-with-intermediary libraries (excluding client libraries) which had commits that have not been included in a release. - List them using:: ./tools/list_library_unreleased_changes.sh > /tmp/cwiff.log - Clean the generated list to keep projects names only. - Generate the patches by using ``process_auto_releases``:: ./tools/process_auto_releases.sh $SERIES $(cat /tmp/cwiff.log) .. warning:: ``process_auto_releases`` will ask you to enter a topic for the patches. Please use ``$series-final-non-client-libs`` as topic. - That patch will be used as a base to communicate with the team: if a team wants to wait for a specific patch to make it to the library, someone from the team can -1 the patch to have it held, or update that patch with a different commit SHA. .. note:: At this point, we want *all* changes in the deliverables, to ensure that we have CI configuration up to date when the stable branch is created later. - Allow the ``stable/$series`` branch to be requested with each library final release if they know they are ready. Do not require branching at this point in case of critical issues requiring another approved release past the freeze date. - Between Tuesday and Thursday, merge as soon as possible the patches that get +1 from the PTL or the release liaison. - On the Friday, merge patches that did not get any feedback from PTL or release liaison. Discuss standing -1s to see if they should be granted an exception and wait until next week. #. Process any remaining library freeze exception. It's probably a good time for teams to take stock of their client library work that needs to be completed yet. The client library freeze is coming up soon. Please plan accordingly to avoid any last minute rushes to get key functionality in."," --type library \ * General libraries (except client libraries) need to have their last feature release before Non-client library freeze ($nclfreeze). Their stable branches are cut early. Non-client library freeze: $nclfreeze (R-6 week) Non-client library freeze: $nclfreeze (R-6 week) It's probably a good time for teams to take stock of their library and client work that needs to be completed yet. The non-client library freeze is coming up, followed closely by the client lib freeze. Please plan accordingly to avoid any last minute rushes to get key functionality in. * General libraries (except client libraries) need to have their last feature release before Non-client library freeze ($nclfreeze). Their stable branches are cut early. Non-client library freeze: $nclfreeze (R-6 week) This coming week is the deadline for general libraries (except client libraries): their last feature release needs to happen before ""Non-client library freeze"" on $nclfreeze. Only bugfixes releases will be allowed beyond this point. When requesting those library releases, you can also include the stable/$series branching request with the review (as an example, see the ""branches"" section here: https://opendev.org/openstack/releases/src/branch/master/deliverables/pike/os-brick.yaml#n2 #. Propose autoreleases for cycle-with-intermediary libraries (excluding client libraries) which had commits that have not been included in a release. - List them using:: ./tools/list_library_unreleased_changes.sh > /tmp/cwiff.log - Clean the generated list to keep projects names only. - Generate the patches by using ``process_auto_releases``:: ./tools/process_auto_releases.sh $SERIES $(cat /tmp/cwiff.log) .. warning:: ``process_auto_releases`` will ask you to enter a topic for the patches. Please use ``$series-final-non-client-libs`` as topic. - That patch will be used as a base to communicate with the team: if a team wants to wait for a specific patch to make it to the library, someone from the team can -1 the patch to have it held, or update that patch with a different commit SHA. .. note:: At this point, we want *all* changes in the deliverables, to ensure that we have CI configuration up to date when the stable branch is created later. - Allow the ``stable/$series`` branch to be requested with each library final release if they know they are ready. Do not require branching at this point in case of critical issues requiring another approved release past the freeze date. - Between Tuesday and Thursday, merge as soon as possible the patches that get +1 from the PTL or the release liaison. - On the Friday, merge patches that did not get any feedback from PTL or release liaison. Discuss standing -1s to see if they should be granted an exception and wait until next week. #. Process any remaining library freeze exception. ",62,72
openstack%2Frpm-packaging~stable%2Fxena~I46e0b6d25d9f859ce730928b33df450479f7f553,openstack/rpm-packaging,stable/xena,I46e0b6d25d9f859ce730928b33df450479f7f553,[xena] metalsmith 1.5.3,MERGED,2022-11-09 11:24:21.000000000,2022-11-09 14:28:58.000000000,2022-11-09 14:28:58.000000000,"[{'_account_id': 6593}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-09 11:24:21.000000000', 'files': ['openstack/metalsmith/metalsmith.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d512d137365507b3190711d2b576ab847d45e518', 'message': '[xena] metalsmith 1.5.3\n\nChange-Id: I46e0b6d25d9f859ce730928b33df450479f7f553\n'}]",0,864104,d512d137365507b3190711d2b576ab847d45e518,7,3,1,28522,,,0,"[xena] metalsmith 1.5.3

Change-Id: I46e0b6d25d9f859ce730928b33df450479f7f553
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/04/864104/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/metalsmith/metalsmith.spec.j2'],1,d512d137365507b3190711d2b576ab847d45e518,xena,{% set upstream_version = upstream_version('1.5.3') %},{% set upstream_version = upstream_version('1.5.0') %},1,1
openstack%2Fpython-cinderclient~master~I544b7f71c66153fa54a07464aa5086ef3943ec71,openstack/python-cinderclient,master,I544b7f71c66153fa54a07464aa5086ef3943ec71,Fix passing None/null to snapshot create,ABANDONED,2022-11-07 18:57:47.000000000,2022-11-09 14:10:57.000000000,,"[{'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-11-07 18:57:47.000000000', 'files': ['cinderclient/v3/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b501f562432acf7cf777d0be83501b9a9d34b9c2', 'message': ""Fix passing None/null to snapshot create\n\nThis patch checks the force flag for snapshot create\nand if it wasn't passed in, it forces it to True for\nmicroversions >= 3.66\n\nCloses-Bug: #1995883\nChange-Id: I544b7f71c66153fa54a07464aa5086ef3943ec71\n""}]",5,863923,b501f562432acf7cf777d0be83501b9a9d34b9c2,6,2,1,5997,,,0,"Fix passing None/null to snapshot create

This patch checks the force flag for snapshot create
and if it wasn't passed in, it forces it to True for
microversions >= 3.66

Closes-Bug: #1995883
Change-Id: I544b7f71c66153fa54a07464aa5086ef3943ec71
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/23/863923/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/v3/shell.py'],1,b501f562432acf7cf777d0be83501b9a9d34b9c2,bug/1995883, if force is None: force = True," default=None,",2,1
openstack%2Fopenstack-manuals~master~I20ae9baaabe0ef7686f4be325eb96f5eceb69366,openstack/openstack-manuals,master,I20ae9baaabe0ef7686f4be325eb96f5eceb69366,Remove python-dev from bindep,MERGED,2022-11-07 10:01:42.000000000,2022-11-09 13:39:23.000000000,2022-11-09 13:06:53.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 10:01:42.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/08af189db3a31c6cb575905fb85cde778c0f6feb', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I20ae9baaabe0ef7686f4be325eb96f5eceb69366\n""}]",0,863838,08af189db3a31c6cb575905fb85cde778c0f6feb,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I20ae9baaabe0ef7686f4be325eb96f5eceb69366
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/38/863838/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,08af189db3a31c6cb575905fb85cde778c0f6feb,drop-python-dev-from-bindep,,python-dev [platform:dpkg] python-devel [platform:rpm],0,2
openstack%2Fopenstack-manuals~master~Ibe7761f6749b9f7c9e7cdde0f7964645c5a6f6a1,openstack/openstack-manuals,master,Ibe7761f6749b9f7c9e7cdde0f7964645c5a6f6a1,Imported Translations from Zanata,MERGED,2022-11-08 02:11:36.000000000,2022-11-09 13:21:20.000000000,2022-11-09 13:03:28.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 02:11:36.000000000', 'files': ['doc/common/source/locale/en_GB/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8175fbbe488678d9c74da1bc49b7e40274335b45', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ibe7761f6749b9f7c9e7cdde0f7964645c5a6f6a1\n'}]",0,863956,8175fbbe488678d9c74da1bc49b7e40274335b45,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ibe7761f6749b9f7c9e7cdde0f7964645c5a6f6a1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/56/863956/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/source/locale/en_GB/LC_MESSAGES/common.po'],1,8175fbbe488678d9c74da1bc49b7e40274335b45,zanata/translations,"""POT-Creation-Date: 2022-10-13 14:10+0000\n""""PO-Revision-Date: 2022-11-07 02:36+0000\n""msgid ""2023.1 Antelope"" msgstr ""2023.1 Antelope"" ""At the same time as OpenStack releases run out of alphabet the Technical "" ""Committee changed the `naming process <https://governance.openstack.org/tc/"" ""resolutions/20220524-release-identification-process.html>`__ to have release "" ""number and a release name as an identification code. The release number will "" ""be the primary identifier: `\""year\"".\""release count within the year\""` and "" ""the name will be used mostly for marketing purposes. The first such release "" ""will be: 2023.1 Antelope."" msgstr """" ""At the same time as OpenStack releases run out of alphabet, the Technical "" ""Committee changed the `naming process <https://governance.openstack.org/tc/"" ""resolutions/20220524-release-identification-process.html>`__ to have release "" ""number and a release name as an identification code. The release number will "" ""be the primary identifier: `\""year\"".\""release count within the year\""` and "" ""the name will be used mostly for marketing purposes. The first such release "" ""will be: 2023.1 Antelope."" msgid """"""Stein, Train, Ussuri, Victoria, Wallaby, Xena, Yoga, Zed.""""Stein, Train, Ussuri, Victoria, Wallaby, Xena, Yoga, Zed.""""The code name for the twenty seventh release of OpenStack. This release is "" ""the first release based on the new `release identification process <https://"" ""governance.openstack.org/tc/resolutions/20220524-release-identification-"" ""process.html>`__ which is formed after `\""year\"".\""release count within the "" ""year\""` and the name Antelope, a swift and gracious animal, also a type of "" ""steam locomotive."" msgstr """" ""The code name for the twenty seventh release of OpenStack. This release is "" ""the first release based on the new `release identification process <https://"" ""governance.openstack.org/tc/resolutions/20220524-release-identification-"" ""process.html>`__ which is formed after `\""year\"".\""release count within the "" ""year\""` and the name Antelope, a swift and gracious animal, also a type of "" ""steam locomotive."" msgid """"","""POT-Creation-Date: 2022-05-28 08:24+0000\n""""PO-Revision-Date: 2022-06-13 07:47+0000\n""""Stein, Train, Ussuri, Victoria, Wallaby, Xena, Yoga, and Zed.""""Stein, Train, Ussuri, Victoria, Wallaby, Xena, Yoga, and Zed.""",39,4
openstack%2Fsecurity-doc~master~I26938c5af6a34db9e67452851a0ef3ed4c5bbb0e,openstack/security-doc,master,I26938c5af6a34db9e67452851a0ef3ed4c5bbb0e,Remove python-dev from bindep,MERGED,2022-11-07 10:07:52.000000000,2022-11-09 13:02:14.000000000,2022-11-09 13:00:58.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 10:07:52.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/d6780c5d486911134fe9993d1fdceb71e75895ca', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I26938c5af6a34db9e67452851a0ef3ed4c5bbb0e\n""}]",0,863850,d6780c5d486911134fe9993d1fdceb71e75895ca,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I26938c5af6a34db9e67452851a0ef3ed4c5bbb0e
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/50/863850/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,d6780c5d486911134fe9993d1fdceb71e75895ca,drop-python-dev-from-bindep,,python-dev [platform:dpkg] python-devel [platform:rpm],0,2
openstack%2Fmagnum~master~I58b1e3280d2fbcbe354136170c22acf78642a0b1,openstack/magnum,master,I58b1e3280d2fbcbe354136170c22acf78642a0b1,Remove duplicated keys in dict,MERGED,2020-11-20 01:37:12.000000000,2022-11-09 13:00:31.000000000,2022-11-09 12:58:31.000000000,"[{'_account_id': 8064}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-11-20 01:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6bd904624c05cd5e56d4c609fc2907f9a27f7686', 'message': '[Trivial]Remove duplicated keys in dict\n\nThis is to remove duplicated keys in dict.\n\nChange-Id: I58b1e3280d2fbcbe354136170c22acf78642a0b1\n'}, {'number': 2, 'created': '2021-01-29 14:56:06.000000000', 'files': ['magnum/tests/unit/drivers/test_template_definition.py', 'magnum/tests/unit/conductor/test_monitors.py', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/826a31f8bcfb870374a11e8d10a018ff0f2e7868', 'message': 'Remove duplicated keys in dict\n\nThis is to remove duplicated keys in dict.\n\nChange-Id: I58b1e3280d2fbcbe354136170c22acf78642a0b1\n'}]",0,763490,826a31f8bcfb870374a11e8d10a018ff0f2e7868,22,4,2,20190,,,0,"Remove duplicated keys in dict

This is to remove duplicated keys in dict.

Change-Id: I58b1e3280d2fbcbe354136170c22acf78642a0b1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/90/763490/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/drivers/test_template_definition.py', 'magnum/tests/unit/conductor/test_monitors.py', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py']",3,6bd904624c05cd5e56d4c609fc2907f9a27f7686,duplicated_key,," 'flavor_id': 'flavor_id', 'master_image': 'image_id', 'minion_image': 'image_id', 'master_image': 'image_id', 'minion_image': 'image_id', 'master_image': 'image_id', 'minion_image': 'image_id',",1,10
openstack%2Fansible-collections-openstack~master~I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb,openstack/ansible-collections-openstack,master,I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb,Refactored config module,MERGED,2022-11-03 11:47:40.000000000,2022-11-09 12:34:39.000000000,2022-11-09 12:34:39.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 30396}, {'_account_id': 32962}]","[{'number': 1, 'created': '2022-11-03 11:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b936ba0a6479fb77c4b4dc6982451b58575962b6', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 2, 'created': '2022-11-03 12:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/9836ec7933e88b7d5594d65f5a09a1e620cedceb', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 3, 'created': '2022-11-04 10:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/682d56b6030ec801a38472955034caba2d904d31', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 4, 'created': '2022-11-04 12:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/25c862082bc075034025ead9c51289887ec2b8c0', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 5, 'created': '2022-11-04 19:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/dc4e15d8d97f322039336c02874ebc931f602dbd', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 6, 'created': '2022-11-05 19:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/015d1c73e0a2740f64e95f5b5713fc31be838cc8', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 7, 'created': '2022-11-07 09:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/948eabf84950db952d0599f46a7e7068c627cb94', 'message': 'Refactored config module\n\nDepends-On: https://review.opendev.org/c/openstack/bifrost/+/863816\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 8, 'created': '2022-11-07 18:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/587317ec20e5e3beaccda7d9c7300ad52c9890be', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}, {'number': 9, 'created': '2022-11-09 09:32:27.000000000', 'files': ['ci/roles/config/tasks/main.yml', '.zuul.yaml', 'ci/roles/client_config/tasks/main.yml', 'ci/run-collection.yml', 'plugins/modules/config.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d07778c24aa7aef907035f5f0e67482c56db697c', 'message': 'Refactored config module\n\nChange-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb\n'}]",6,863512,d07778c24aa7aef907035f5f0e67482c56db697c,29,4,9,32962,,,0,"Refactored config module

Change-Id: I7ba626e2ef2a108bf79cacd8d6ee0735b8a0bdeb
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/12/863512/2 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/config/tasks/main.yml', '.zuul.yaml', 'ci/roles/client_config/tasks/main.yml', 'ci/run-collection.yml', 'plugins/modules/config.py']",5,b936ba0a6479fb77c4b4dc6982451b58575962b6,config,"DOCUMENTATION = r'''author: OpenStack Ansible SIG description: - Get openstack client config data from clouds.yaml or environmentnotes: - Facts are placed in the C(openstack.clouds) variable.RETURN = r''' ansible_facts: returned: always type: dict contains: openstack: type: dict contains: clouds: description: A dict of configuration values for the CloudRegion and its services. The key for a ${config_option} for a specific ${service} should be ${service}_${config_option}. type: list elements: dict ''' EXAMPLES = r''' - name: Read configuration of all defined clouds- name: Print clouds which do not support security groups debug: msg: ""{{ item }}"" loop: ""{{ openstack.clouds | rejectattr('secgroup_source', 'none') | list }}"" - name: Read configuration of a two specific clouds - devstackfrom ansible.module_utils.basic import AnsibleModule module = AnsibleModule( argument_spec=dict( clouds=dict(type='list', default=[], elements='str'), ) ) try: for cloud in openstack.config.OpenStackConfig().get_all(): if not module.params['clouds'] \ or cloud.name in module.params['clouds']: module.exit_json(changed=False, ansible_facts=dict(openstack=dict(clouds=clouds))) except exceptions.SDKException as e:","DOCUMENTATION = '''description: - Get I(openstack) client config data from clouds.yaml or environment notes: - Facts are placed in the C(openstack.clouds) variable. required: falseauthor: OpenStack Ansible SIGEXAMPLES = ''' - name: Get list of clouds that do not support security groups- debug: var: ""{{ item }}"" with_items: ""{{ openstack.clouds | rejectattr('secgroup_source', 'none') | list }}"" - name: Get the information back just about the mordred cloudfrom ansible.module_utils.basic import AnsibleModule module = AnsibleModule(argument_spec=dict( clouds=dict(type='list', default=[], elements='str'), )) p = module.params try: config = openstack.config.OpenStackConfig() for cloud in config.get_all_clouds(): if not p['clouds'] or cloud.name in p['clouds']: module.exit_json(ansible_facts=dict(openstack=dict(clouds=clouds))) except exceptions.ConfigException as e:",56,33
openstack%2Freleases~master~Iae415fa7f3f12acfe2de89fe5814934890875f3a,openstack/releases,master,Iae415fa7f3f12acfe2de89fe5814934890875f3a,Create train-eol tag for all Designate projects,MERGED,2022-10-28 19:01:39.000000000,2022-11-09 12:32:15.000000000,2022-11-09 12:32:15.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2022-10-28 19:01:39.000000000', 'files': ['deliverables/train/python-designateclient.yaml', 'deliverables/train/designate.yaml', 'deliverables/train/designate-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e6f31d619d8c62238df9bb1ff1d07e98e37d0951', 'message': 'Create train-eol tag for all Designate projects\n\nDesignate team is no longer accepting patches to\nstable/train branch, this patch proposes to create train-eol\ntags for all Designate projects.\n\nChange-Id: Iae415fa7f3f12acfe2de89fe5814934890875f3a\n'}]",1,862956,e6f31d619d8c62238df9bb1ff1d07e98e37d0951,10,5,1,11628,,,0,"Create train-eol tag for all Designate projects

Designate team is no longer accepting patches to
stable/train branch, this patch proposes to create train-eol
tags for all Designate projects.

Change-Id: Iae415fa7f3f12acfe2de89fe5814934890875f3a
",git fetch https://review.opendev.org/openstack/releases refs/changes/56/862956/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/train/designate.yaml', 'deliverables/train/python-designateclient.yaml', 'deliverables/train/designate-dashboard.yaml']",3,e6f31d619d8c62238df9bb1ff1d07e98e37d0951,, - version: train-eol projects: - repo: openstack/designate-dashboard hash: 51a44589c2f59fca73ed8b1f3933c5d6cffae50c,,12,0
openstack%2Fmagnum~master~I79c3beebd790f2e7c787cf1c34be3c5a26cca2d0,openstack/magnum,master,I79c3beebd790f2e7c787cf1c34be3c5a26cca2d0,Make configure-agent-env.service idempotent.,MERGED,2022-09-13 13:24:47.000000000,2022-11-09 12:18:01.000000000,2022-11-09 12:16:58.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-09-13 13:24:47.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/fcct-config.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/64570c25b09a945125afc9eabcbcc53dac5673e4', 'message': ""Make configure-agent-env.service idempotent.\n\nWhen the configure-agent-env.service service is restarted it will fail\nwhen it tries to create the directory /etc/kubernetes, leaving the\nsystem 'degraded' from systemd's perspective, this change adds the '-p'\nflag to mkdir to fail silently if the directory already exists.\n\nChange-Id: I79c3beebd790f2e7c787cf1c34be3c5a26cca2d0\nRelated-Bug: #1982872\n""}]",2,857431,64570c25b09a945125afc9eabcbcc53dac5673e4,10,3,1,2424,,,0,"Make configure-agent-env.service idempotent.

When the configure-agent-env.service service is restarted it will fail
when it tries to create the directory /etc/kubernetes, leaving the
system 'degraded' from systemd's perspective, this change adds the '-p'
flag to mkdir to fail silently if the directory already exists.

Change-Id: I79c3beebd790f2e7c787cf1c34be3c5a26cca2d0
Related-Bug: #1982872
",git fetch https://review.opendev.org/openstack/magnum refs/changes/31/857431/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/k8s_fedora_coreos_v1/templates/fcct-config.yaml'],1,64570c25b09a945125afc9eabcbcc53dac5673e4,mkdir-p-etc-kubernetes, mkdir -p /etc/kubernetes/, mkdir /etc/kubernetes/,1,1
openstack%2Fneutron~stable%2Fyoga~Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00,openstack/neutron,stable/yoga,Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00,Port provisioning should retry only for VM ports,MERGED,2022-11-02 11:53:48.000000000,2022-11-09 12:17:56.000000000,2022-11-09 12:16:14.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-11-02 11:53:48.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec234e64cdb7a282bc66e5497096c5e83bec0a93', 'message': ""Port provisioning should retry only for VM ports\n\nThe port provisioning method ``Ml2Plugin._port_provisioned`` creates\nan active wait to provision a port if the port is unbound since [1].\nBut this active wait should consider only VM ports in the case of\nlive migration, as described in the LP bug [2]. This wait should\nnot consider auxiliary Neutron ports or baremetal ports (we don't\nlive-migrate then).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/855257\n[2]https://bugs.launchpad.net/neutron/+bug/1988199\n\nCloses-Bug: #1991092\nChange-Id: Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00\n(cherry picked from commit 21491efd9f8ce6df98cb58c26da7896d75cb4a8b)\n""}]",5,863279,ec234e64cdb7a282bc66e5497096c5e83bec0a93,23,4,1,35459,,,0,"Port provisioning should retry only for VM ports

The port provisioning method ``Ml2Plugin._port_provisioned`` creates
an active wait to provision a port if the port is unbound since [1].
But this active wait should consider only VM ports in the case of
live migration, as described in the LP bug [2]. This wait should
not consider auxiliary Neutron ports or baremetal ports (we don't
live-migrate then).

[1]https://review.opendev.org/c/openstack/neutron/+/855257
[2]https://bugs.launchpad.net/neutron/+bug/1988199

Closes-Bug: #1991092
Change-Id: Ic8891e2deef4bb5e72cf7d7f37b043e936adbc00
(cherry picked from commit 21491efd9f8ce6df98cb58c26da7896d75cb4a8b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/863279/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,ec234e64cdb7a282bc66e5497096c5e83bec0a93,bug/1991092-stable/yoga, owner = port.device_owner if (count == MAX_PROVISIONING_TRIES or not owner.startswith(const.DEVICE_OWNER_COMPUTE_PREFIX)):, if count == MAX_PROVISIONING_TRIES:,23,2
openstack%2Freleases~master~I1351e32979f4ff89016f8204857fb4c2bd9ba484,openstack/releases,master,I1351e32979f4ff89016f8204857fb4c2bd9ba484,Create stein-eol tag for all Designate projects,MERGED,2022-10-28 18:57:13.000000000,2022-11-09 12:16:54.000000000,2022-11-09 12:16:54.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2022-10-28 18:57:13.000000000', 'files': ['deliverables/stein/python-designateclient.yaml', 'deliverables/stein/designate.yaml', 'deliverables/stein/designate-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/8c0f6d35b2073b2ed12752ff0eca59054fe12aea', 'message': 'Create stein-eol tag for all Designate projects\n\nDesignate team is no longer accepting patches to\nstable/stein branch, this patch proposes to create stein-eol\ntags for all Designate projects.\n\nChange-Id: I1351e32979f4ff89016f8204857fb4c2bd9ba484\n'}]",2,862954,8c0f6d35b2073b2ed12752ff0eca59054fe12aea,10,5,1,11628,,,0,"Create stein-eol tag for all Designate projects

Designate team is no longer accepting patches to
stable/stein branch, this patch proposes to create stein-eol
tags for all Designate projects.

Change-Id: I1351e32979f4ff89016f8204857fb4c2bd9ba484
",git fetch https://review.opendev.org/openstack/releases refs/changes/54/862954/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/stein/python-designateclient.yaml', 'deliverables/stein/designate.yaml', 'deliverables/stein/designate-dashboard.yaml']",3,8c0f6d35b2073b2ed12752ff0eca59054fe12aea,, - version: stein-eol projects: - repo: openstack/designate-dashboard hash: a3a7a0e73b2640d3218c66da2fa19527fbbe0401,,12,0
openstack%2Fkolla-ansible~master~I9bc85d894b5bf947ac8fca505df446b99b0bb99b,openstack/kolla-ansible,master,I9bc85d894b5bf947ac8fca505df446b99b0bb99b,[ironic] Remove useless tasks,MERGED,2022-09-29 13:53:27.000000000,2022-11-09 12:09:51.000000000,2022-11-09 12:08:54.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 27339}, {'_account_id': 34533}]","[{'number': 1, 'created': '2022-09-29 13:53:27.000000000', 'files': ['ansible/roles/ironic/tasks/precheck.yml', 'ansible/roles/ironic/tasks/upgrade.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b95de04ff471bd6db1cb522a3e44d4db8b3b2811', 'message': '[ironic] Remove useless tasks\n\nThey served us well in Yoga but they are no longer needed in Zed.\nThis also avoids the early deletion of the ironic-conductor, making\nit really roll.\n\nChange-Id: I9bc85d894b5bf947ac8fca505df446b99b0bb99b\n'}]",6,859856,b95de04ff471bd6db1cb522a3e44d4db8b3b2811,14,5,1,30491,,,0,"[ironic] Remove useless tasks

They served us well in Yoga but they are no longer needed in Zed.
This also avoids the early deletion of the ironic-conductor, making
it really roll.

Change-Id: I9bc85d894b5bf947ac8fca505df446b99b0bb99b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/56/859856/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ironic/tasks/precheck.yml', 'ansible/roles/ironic/tasks/upgrade.yml']",2,b95de04ff471bd6db1cb522a3e44d4db8b3b2811,ironic-remove-useless-tasks,,"# TODO(yoctozepto): Remove this task in Zed. - name: Remove old Ironic containers become: true kolla_docker: action: ""stop_and_remove_container"" common_options: ""{{ docker_common_options }}"" name: ""{{ item }}"" with_items: # NOTE(yoctozepto): Removing conductor to avoid it # thinking that the tftp and http servers are available. - ironic_conductor - ironic_pxe - ironic_ipxe # TODO(yoctozepto): Remove this task in Zed. - name: Remove old Ironic volumes become: true kolla_docker: action: ""remove_volume"" common_options: ""{{ docker_common_options }}"" name: ""{{ item }}"" with_items: - ironic_pxe - ironic_ipxe",0,29
openstack%2Freleases~master~Ib98c7dc47b3c6ae9f92a367b352ce96b96c7c44e,openstack/releases,master,Ib98c7dc47b3c6ae9f92a367b352ce96b96c7c44e,[glance] Transition Wallaby to EM,MERGED,2022-10-21 12:59:26.000000000,2022-11-09 11:59:31.000000000,2022-11-09 11:59:31.000000000,"[{'_account_id': 17685}, {'_account_id': 19138}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-10-21 12:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/83030e8d271f6abba178bb596d94662ae88e4eef', 'message': '[glance] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: Ib98c7dc47b3c6ae9f92a367b352ce96b96c7c44e\n'}, {'number': 2, 'created': '2022-11-04 11:19:44.000000000', 'files': ['deliverables/wallaby/glance.yaml', 'deliverables/wallaby/python-glanceclient.yaml', 'deliverables/wallaby/glance-store.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/49071178d71525cf63fcd7a305f84b018d16734a', 'message': '[glance] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: Ib98c7dc47b3c6ae9f92a367b352ce96b96c7c44e\n'}]",4,862319,49071178d71525cf63fcd7a305f84b018d16734a,12,4,2,17685,,,0,"[glance] Transition Wallaby to EM

This transition the wallaby branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is November 2nd, 2022.

Change-Id: Ib98c7dc47b3c6ae9f92a367b352ce96b96c7c44e
",git fetch https://review.opendev.org/openstack/releases refs/changes/19/862319/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/wallaby/glance.yaml', 'deliverables/wallaby/python-glanceclient.yaml', 'deliverables/wallaby/glance-store.yaml']",3,83030e8d271f6abba178bb596d94662ae88e4eef,wallaby-em, - version: wallaby-em projects: - repo: openstack/glance_store hash: 5f1cee6fa90268b17c7b6f842854a3b27e44994c,,12,0
openstack%2Freleases~master~I9080e355d1af7a1d7061f6da2893b3517964065d,openstack/releases,master,I9080e355d1af7a1d7061f6da2893b3517964065d,[heat] Transition Wallaby to EM,MERGED,2022-10-21 12:59:48.000000000,2022-11-09 11:59:28.000000000,2022-11-09 11:59:28.000000000,"[{'_account_id': 9816}, {'_account_id': 12404}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-10-21 12:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/351100c4ec396de45c9c88b392e230822cfb7ca5', 'message': '[heat] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: I9080e355d1af7a1d7061f6da2893b3517964065d\n'}, {'number': 2, 'created': '2022-11-04 14:29:13.000000000', 'files': ['deliverables/wallaby/heat-translator.yaml', 'deliverables/wallaby/heat-dashboard.yaml', 'deliverables/wallaby/tosca-parser.yaml', 'deliverables/wallaby/heat.yaml', 'deliverables/wallaby/heat-agents.yaml', 'deliverables/wallaby/python-heatclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5a64623a0063c4ec552ea86d640800fb77df533c', 'message': '[heat] Transition Wallaby to EM\n\nThis transition the wallaby branch to extended maintenance.\nChanges for bugfixes and things the team deems important are\nstill encouraged, but there will no longer be official releases\noff of the branch.\n\nPlease +1 if the team is ready for us to proceed with this\ntransition, or -1 if there are any final backports currently in\nflight that we should wait for. For the latter case, please\nupdate the patch with the new commit hash after doing a final\nrelease to get those changes out so we know to proceed with the\ntransition.\n\nThe transition deadline is November 2nd, 2022.\n\nChange-Id: I9080e355d1af7a1d7061f6da2893b3517964065d\n'}]",2,862320,5a64623a0063c4ec552ea86d640800fb77df533c,10,6,2,17685,,,0,"[heat] Transition Wallaby to EM

This transition the wallaby branch to extended maintenance.
Changes for bugfixes and things the team deems important are
still encouraged, but there will no longer be official releases
off of the branch.

Please +1 if the team is ready for us to proceed with this
transition, or -1 if there are any final backports currently in
flight that we should wait for. For the latter case, please
update the patch with the new commit hash after doing a final
release to get those changes out so we know to proceed with the
transition.

The transition deadline is November 2nd, 2022.

Change-Id: I9080e355d1af7a1d7061f6da2893b3517964065d
",git fetch https://review.opendev.org/openstack/releases refs/changes/20/862320/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/wallaby/heat-translator.yaml', 'deliverables/wallaby/heat-dashboard.yaml', 'deliverables/wallaby/tosca-parser.yaml', 'deliverables/wallaby/heat.yaml', 'deliverables/wallaby/heat-agents.yaml', 'deliverables/wallaby/python-heatclient.yaml']",6,351100c4ec396de45c9c88b392e230822cfb7ca5,wallaby-em, - version: wallaby-em projects: - repo: openstack/python-heatclient hash: d16c245f5defdf811de8fe8615fa06ae6daae5b5,,24,0
openstack%2Fpython-tripleoclient~master~I2a36b93bd2bc2fea0aadab05ea3d657d47ba5d93,openstack/python-tripleoclient,master,I2a36b93bd2bc2fea0aadab05ea3d657d47ba5d93,Use VerboseFileWrapper from osc,MERGED,2022-11-08 16:26:21.000000000,2022-11-09 11:59:14.000000000,2022-11-09 11:58:12.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-11-08 16:26:21.000000000', 'files': ['tripleoclient/v1/overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/81fbe6aa6a207db050215838b265ab3fab8ed25c', 'message': ""Use VerboseFileWrapper from osc\n\nWe don't have glanceclient in requirements.\n\nCloses-Bug: #1995961\nChange-Id: I2a36b93bd2bc2fea0aadab05ea3d657d47ba5d93\n""}]",1,864023,81fbe6aa6a207db050215838b265ab3fab8ed25c,8,3,1,8833,,,0,"Use VerboseFileWrapper from osc

We don't have glanceclient in requirements.

Closes-Bug: #1995961
Change-Id: I2a36b93bd2bc2fea0aadab05ea3d657d47ba5d93
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/23/864023/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/overcloud_image.py'],1,81fbe6aa6a207db050215838b265ab3fab8ed25c,,from openstackclient.common.progressbar import VerboseFileWrapper,from glanceclient.common.progressbar import VerboseFileWrapper,1,1
openstack%2Fpython-magnumclient~master~Ib74bc35a867dd25c51de6eac2ab1e611b69d4e37,openstack/python-magnumclient,master,Ib74bc35a867dd25c51de6eac2ab1e611b69d4e37,Remove translation sections from setup.cfg,NEW,2020-05-14 17:03:35.000000000,2022-11-09 11:55:08.000000000,,"[{'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 28614}]","[{'number': 1, 'created': '2020-05-14 17:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/5c04856556eacd9b905b7dc919d76270573e340c', 'message': 'Remove translation sections from setup.cfg\n\nThese translation sections are not needed anymore, Babel can\ngenerate translation files without them.\n\nChange-Id: Ib74bc35a867dd25c51de6eac2ab1e611b69d4e37\n'}, {'number': 2, 'created': '2020-06-03 10:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/56275025e20049ee752b7c9ebe295638074262dd', 'message': 'Remove translation sections from setup.cfg\n\nThese translation sections are not needed anymore, Babel can\ngenerate translation files without them.\n\nChange-Id: Ib74bc35a867dd25c51de6eac2ab1e611b69d4e37\n'}, {'number': 3, 'created': '2022-11-09 10:52:14.000000000', 'files': ['babel.cfg'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/c30f10ffbc915f6f6a39ad2456188bb206391aee', 'message': 'Remove translation sections from setup.cfg\n\nThese translation sections are not needed anymore, Babel can\ngenerate translation files without them.\n\nConflicts:\n\tbabel.cfg\n\tsetup.cfg\n\nChange-Id: Ib74bc35a867dd25c51de6eac2ab1e611b69d4e37\n'}]",0,728147,c30f10ffbc915f6f6a39ad2456188bb206391aee,8,3,3,28614,,,0,"Remove translation sections from setup.cfg

These translation sections are not needed anymore, Babel can
generate translation files without them.

Conflicts:
	babel.cfg
	setup.cfg

Change-Id: Ib74bc35a867dd25c51de6eac2ab1e611b69d4e37
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/47/728147/3 && git format-patch -1 --stdout FETCH_HEAD,"['babel.cfg', 'setup.cfg']",2,5c04856556eacd9b905b7dc919d76270573e340c,,, [compile_catalog] directory = magnumclient/locale domain = magnumclient [update_catalog] domain = magnumclient output_dir = magnumclient/locale input_file = magnumclient/locale/magnumclient.pot [extract_messages] keywords = _ gettext ngettext l_ lazy_gettext mapping_file = babel.cfg output_file = magnumclient/locale/magnumclient.pot,0,15
openstack%2Fos-brick~master~I9ab95a274f79bbcd8a706662e9e03d0bdcb45654,openstack/os-brick,master,I9ab95a274f79bbcd8a706662e9e03d0bdcb45654,Update metadata in setup.cfg,MERGED,2022-08-29 11:20:21.000000000,2022-11-09 11:50:30.000000000,2022-11-09 11:49:30.000000000,"[{'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30396}, {'_account_id': 32029}, {'_account_id': 32238}]","[{'number': 1, 'created': '2022-08-29 11:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/fa2c896a0bd309c7bc7fb6e941dd76ab58e641b3', 'message': 'Update metadata in setup.cfg\n\nChange-Id: I9ab95a274f79bbcd8a706662e9e03d0bdcb45654\n'}, {'number': 2, 'created': '2022-09-21 11:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/de30bb8627b79745fc27ee514f7df058a1279136', 'message': 'Update metadata in setup.cfg\n\nChange-Id: I9ab95a274f79bbcd8a706662e9e03d0bdcb45654\n'}, {'number': 3, 'created': '2022-09-23 14:29:49.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/0639af4fc8d7f3abdbfe6326b778b219652af864', 'message': 'Update metadata in setup.cfg\n\nwe are using some ""aliases"" that the setuptools docs say \n""are supported for compatibility reasons"" but their use is not advised[1].\n\n[1] https://setuptools.pypa.io/en/latest/userguide/declarative_config.html#metadata\n\nmaintaining setup.cfg as per other repos[2]\n\n[2] https://review.opendev.org/c/openstack/cinder-tempest-plugin/+/828475\n\nChange-Id: I9ab95a274f79bbcd8a706662e9e03d0bdcb45654\n'}]",11,855012,0639af4fc8d7f3abdbfe6326b778b219652af864,39,9,3,30615,,,0,"Update metadata in setup.cfg

we are using some ""aliases"" that the setuptools docs say 
""are supported for compatibility reasons"" but their use is not advised[1].

[1] https://setuptools.pypa.io/en/latest/userguide/declarative_config.html#metadata

maintaining setup.cfg as per other repos[2]

[2] https://review.opendev.org/c/openstack/cinder-tempest-plugin/+/828475

Change-Id: I9ab95a274f79bbcd8a706662e9e03d0bdcb45654
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/12/855012/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fa2c896a0bd309c7bc7fb6e941dd76ab58e641b3,,description = OpenStack Cinder brick library for managing local volume attaches long_description = file: README.rsturl = https://docs.openstack.org/os-brick/classifiers =,summary = OpenStack Cinder brick library for managing local volume attaches description_file = README.rsthome_page = https://docs.openstack.org/os-brick/classifier =,4,5
openstack%2Freleases~master~Id6e01137d9c8c5b3bd93bdeaa1bf0b7900044406,openstack/releases,master,Id6e01137d9c8c5b3bd93bdeaa1bf0b7900044406,Create rocky-eol tag for all Designate projects,MERGED,2022-10-28 18:53:03.000000000,2022-11-09 11:46:34.000000000,2022-11-09 11:46:34.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2022-10-28 18:53:03.000000000', 'files': ['deliverables/rocky/python-designateclient.yaml', 'deliverables/rocky/designate-dashboard.yaml', 'deliverables/rocky/designate.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b85926715e81a9fc3d91c2161e79e7bfb02841cc', 'message': 'Create rocky-eol tag for all Designate projects\n\nDesignate team is no longer accepting patches to\nstable/rocky branch, this patch proposes to create rocky-eol\ntags for all Designate projects.\n\nChange-Id: Id6e01137d9c8c5b3bd93bdeaa1bf0b7900044406\n'}]",2,862953,b85926715e81a9fc3d91c2161e79e7bfb02841cc,10,5,1,11628,,,0,"Create rocky-eol tag for all Designate projects

Designate team is no longer accepting patches to
stable/rocky branch, this patch proposes to create rocky-eol
tags for all Designate projects.

Change-Id: Id6e01137d9c8c5b3bd93bdeaa1bf0b7900044406
",git fetch https://review.opendev.org/openstack/releases refs/changes/53/862953/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/rocky/python-designateclient.yaml', 'deliverables/rocky/designate-dashboard.yaml', 'deliverables/rocky/designate.yaml']",3,b85926715e81a9fc3d91c2161e79e7bfb02841cc,, - version: rocky-eol projects: - repo: openstack/designate hash: e4ee680f24d00b9633284c061edebaf0f62d7b3c,,12,0
openstack%2Freleases~master~I3c1c30a39bb93408648f04e310d4fc59538c1d0c,openstack/releases,master,I3c1c30a39bb93408648f04e310d4fc59538c1d0c,"[neutron-lbaas]  Transition Queens, Rocky & Stein to EOL",MERGED,2022-11-02 13:03:15.000000000,2022-11-09 11:46:32.000000000,2022-11-09 11:46:32.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29244}]","[{'number': 1, 'created': '2022-11-02 13:03:15.000000000', 'files': ['deliverables/stein/neutron-lbaas-dashboard.yaml', 'deliverables/rocky/neutron-lbaas-dashboard.yaml', 'deliverables/rocky/neutron-lbaas.yaml', 'deliverables/queens/neutron-lbaas-dashboard.yaml', 'deliverables/queens/neutron-lbaas.yaml', 'deliverables/stein/neutron-lbaas.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/09d461d87d2b6de3df3075f546bd7e5ef019879d', 'message': '[neutron-lbaas]  Transition Queens, Rocky & Stein to EOL\n\nhttps://lists.openstack.org/pipermail/openstack-discuss/2022-October/031022.html\nsimilar patch for other Networking projects:\nhttps://review.opendev.org/c/openstack/releases/+/862937\n\nChange-Id: I3c1c30a39bb93408648f04e310d4fc59538c1d0c\n'}]",2,863266,09d461d87d2b6de3df3075f546bd7e5ef019879d,13,8,1,8313,,,0,"[neutron-lbaas]  Transition Queens, Rocky & Stein to EOL

https://lists.openstack.org/pipermail/openstack-discuss/2022-October/031022.html
similar patch for other Networking projects:
https://review.opendev.org/c/openstack/releases/+/862937

Change-Id: I3c1c30a39bb93408648f04e310d4fc59538c1d0c
",git fetch https://review.opendev.org/openstack/releases refs/changes/66/863266/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/stein/neutron-lbaas-dashboard.yaml', 'deliverables/rocky/neutron-lbaas-dashboard.yaml', 'deliverables/rocky/neutron-lbaas.yaml', 'deliverables/queens/neutron-lbaas-dashboard.yaml', 'deliverables/queens/neutron-lbaas.yaml', 'deliverables/stein/neutron-lbaas.yaml']",6,09d461d87d2b6de3df3075f546bd7e5ef019879d,neutron_eol_q_r_s, - version: stein-eol projects: - repo: openstack/neutron-lbaas hash: 91ea6fb09348673023b80eb31005cb4be0e8c552,,24,0
openstack%2Freleases~master~I804b25a10465cfa3fccf1245600a2f4b813ba50a,openstack/releases,master,I804b25a10465cfa3fccf1245600a2f4b813ba50a,Add cinder specific dates for 2023.1 Antelope Schedule,MERGED,2022-10-27 13:20:14.000000000,2022-11-09 11:39:54.000000000,2022-11-09 11:39:54.000000000,"[{'_account_id': 308}, {'_account_id': 7198}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-10-27 13:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/98c868b7346da47929bc938588dbb13be51df1f4', 'message': 'Add cinder specific dates for 2023.1 Antelope Schedule\n\nChange-Id: I804b25a10465cfa3fccf1245600a2f4b813ba50a\n'}, {'number': 2, 'created': '2022-11-03 09:45:37.000000000', 'files': ['doc/source/antelope/schedule.rst', 'doc/source/antelope/schedule.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/0ffd5fdfa42d4a61f773a3763e094d4a62b72105', 'message': 'Add cinder specific dates for 2023.1 Antelope Schedule\n\nChange-Id: I804b25a10465cfa3fccf1245600a2f4b813ba50a\n'}]",6,862815,0ffd5fdfa42d4a61f773a3763e094d4a62b72105,14,5,2,27615,,,0,"Add cinder specific dates for 2023.1 Antelope Schedule

Change-Id: I804b25a10465cfa3fccf1245600a2f4b813ba50a
",git fetch https://review.opendev.org/openstack/releases refs/changes/15/862815/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/antelope/schedule.rst', 'doc/source/antelope/schedule.yaml']",2,98c868b7346da47929bc938588dbb13be51df1f4,862815, project-specific: - a-cinder-mid-cycle-ptg-1 project-specific: - a-cinder-spec-freeze project-specific: - a-cinder-driver-deadline - a-cinder-target-driver-deadline project-specific: - a-cinder-feature-checkpoint - a-cinder-mid-cycle-ptg-2 project-specific: - a-cinder-driver-features-declaration - a-cinder-os-brick-release project-specific: - a-cinder-ci-checkpoint,,113,0
openstack%2Freleases~master~I7be823475af8ef5f01cd03cc62854d0d5688c33d,openstack/releases,master,I7be823475af8ef5f01cd03cc62854d0d5688c33d,"magnum: mark queens,rocky,stein,train,ussuri as EOL",MERGED,2022-10-20 12:56:37.000000000,2022-11-09 11:39:33.000000000,2022-11-09 11:39:33.000000000,"[{'_account_id': 8064}, {'_account_id': 17685}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29759}]","[{'number': 1, 'created': '2022-10-20 12:56:37.000000000', 'files': ['deliverables/stein/magnum-ui.yaml', 'deliverables/rocky/magnum.yaml', 'deliverables/stein/magnum.yaml', 'deliverables/queens/magnum.yaml', 'deliverables/rocky/magnum-ui.yaml', 'deliverables/train/magnum-ui.yaml', 'deliverables/ussuri/magnum-ui.yaml', 'deliverables/queens/magnum-ui.yaml', 'deliverables/ussuri/magnum.yaml', 'deliverables/train/magnum.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f7d69d6633118e075d81aaddf028b16679adcddf', 'message': ""magnum: mark queens,rocky,stein,train,ussuri as EOL\n\nMagnum team does not have the capacity to backport bugfixes\nto those EM branches.\nIn addition to that, those branches don't allow users to\nprovision currently supported Kubernetes versions.\n\nqueens CI jobs have been last run on Nov2021 and failed\nrocky CI jobs have been last run on Nov2021 and failed\nstein CI jobs have been last run on Nov2021 and failed\ntrain CI jobs have been last run on Jan2022\nussuri CI jobs have been last run on Nov2021 and failed\n\nChange-Id: I7be823475af8ef5f01cd03cc62854d0d5688c33d\n""}]",3,862138,f7d69d6633118e075d81aaddf028b16679adcddf,12,6,1,22629,,,0,"magnum: mark queens,rocky,stein,train,ussuri as EOL

Magnum team does not have the capacity to backport bugfixes
to those EM branches.
In addition to that, those branches don't allow users to
provision currently supported Kubernetes versions.

queens CI jobs have been last run on Nov2021 and failed
rocky CI jobs have been last run on Nov2021 and failed
stein CI jobs have been last run on Nov2021 and failed
train CI jobs have been last run on Jan2022
ussuri CI jobs have been last run on Nov2021 and failed

Change-Id: I7be823475af8ef5f01cd03cc62854d0d5688c33d
",git fetch https://review.opendev.org/openstack/releases refs/changes/38/862138/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/stein/magnum-ui.yaml', 'deliverables/rocky/magnum.yaml', 'deliverables/stein/magnum.yaml', 'deliverables/queens/magnum.yaml', 'deliverables/rocky/magnum-ui.yaml', 'deliverables/train/magnum-ui.yaml', 'deliverables/ussuri/magnum-ui.yaml', 'deliverables/queens/magnum-ui.yaml', 'deliverables/ussuri/magnum.yaml', 'deliverables/train/magnum.yaml']",10,f7d69d6633118e075d81aaddf028b16679adcddf,, - version: train-eol projects: - repo: openstack/magnum hash: 6d3361872f584c610eec146f47f652c4132a2818,,40,0
openstack%2Fmagnum~master~I8d43a5864b5deb37be6c850115aa7edfe8ae9d30,openstack/magnum,master,I8d43a5864b5deb37be6c850115aa7edfe8ae9d30,remove unicode literal from code,MERGED,2022-08-06 12:54:27.000000000,2022-11-09 11:36:49.000000000,2022-11-09 11:35:43.000000000,"[{'_account_id': 1004}, {'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-08-06 12:54:27.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6bc060ee06fcdbf25258adb9b848907368bcf1c8', 'message': 'remove unicode literal from code\n\nChange-Id: I8d43a5864b5deb37be6c850115aa7edfe8ae9d30\n'}]",0,852346,6bc060ee06fcdbf25258adb9b848907368bcf1c8,9,4,1,35058,,,0,"remove unicode literal from code

Change-Id: I8d43a5864b5deb37be6c850115aa7edfe8ae9d30
",git fetch https://review.opendev.org/openstack/magnum refs/changes/46/852346/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,6bc060ee06fcdbf25258adb9b848907368bcf1c8,,"copyright = '2016, Magnum developers' ('index', 'MagnumReleaseNotes.tex', 'Magnum Release Notes Documentation', '2016, Magnum developers', 'manual'), ('index', 'magnumreleasenotes', 'Magnum Release Notes Documentation', ['2016, Magnum developers'], 1) ('index', 'MagnumReleaseNotes', 'Magnum Release Notes Documentation', '2016, Magnum developers', 'MagnumReleaseNotes',","copyright = u'2016, Magnum developers' ('index', 'MagnumReleaseNotes.tex', u'Magnum Release Notes Documentation', u'2016, Magnum developers', 'manual'), ('index', 'magnumreleasenotes', u'Magnum Release Notes Documentation', [u'2016, Magnum developers'], 1) ('index', 'MagnumReleaseNotes', u'Magnum Release Notes Documentation', u'2016, Magnum developers', 'MagnumReleaseNotes',",7,7
openstack%2Fpuppet-tripleo~master~I5a8e4b3598d5e5a30ec967fba504bac91c7f51ec,openstack/puppet-tripleo,master,I5a8e4b3598d5e5a30ec967fba504bac91c7f51ec,Correct TLS cert permission,MERGED,2022-06-24 14:52:06.000000000,2022-11-09 11:35:36.000000000,2022-11-09 11:35:36.000000000,"[{'_account_id': 6926}, {'_account_id': 7294}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}, {'_account_id': 30893}]","[{'number': 1, 'created': '2022-06-24 14:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/403230a92aa7b7a38b7067fb770bcb8f46210811', 'message': 'Correct TLS cert permission\n\nThis patch corrects file permission of cert directory and certificates\nfor QDR.\n\nChange-Id: I5a8e4b3598d5e5a30ec967fba504bac91c7f51ec\n'}, {'number': 2, 'created': '2022-07-04 13:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/4eb29d37f761c818be2957a27c26f758d05c83f4', 'message': 'Correct TLS cert permission\n\nThis patch corrects file permission of cert directory and certificates\nfor QDR.\n\nChange-Id: I5a8e4b3598d5e5a30ec967fba504bac91c7f51ec\n'}, {'number': 3, 'created': '2022-10-20 09:28:27.000000000', 'files': ['spec/classes/tripleo_profile_base_metrics_qdr_spec.rb', 'manifests/profile/base/metrics/qdr.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/109a62a61e06b44e4764258082cb47c57409afeb', 'message': 'Correct TLS cert permission\n\nThis patch corrects file permission of cert directory and certificates\nfor QDR.\n\nChange-Id: I5a8e4b3598d5e5a30ec967fba504bac91c7f51ec\n'}]",18,847585,109a62a61e06b44e4764258082cb47c57409afeb,29,7,3,5241,,,0,"Correct TLS cert permission

This patch corrects file permission of cert directory and certificates
for QDR.

Change-Id: I5a8e4b3598d5e5a30ec967fba504bac91c7f51ec
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/85/847585/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/tripleo_profile_base_metrics_qdr_spec.rb', 'manifests/profile/base/metrics/qdr.pp']",2,403230a92aa7b7a38b7067fb770bcb8f46210811,tls-cert-perm," mode => '0755' mode => '0644',"," mode => '0700' mode => '0600',",5,5
openstack%2Fmagnum~master~Iba762b3c1de4c0d7169299724285deba68fe7256,openstack/magnum,master,Iba762b3c1de4c0d7169299724285deba68fe7256,remove unicode literal from code,MERGED,2022-07-30 07:21:11.000000000,2022-11-09 11:34:40.000000000,2022-11-09 11:33:37.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-07-30 07:21:11.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7aae554f8b7eb473e5c9b87d31beaf7ea0e6ef22', 'message': 'remove unicode literal from code\n\nChange-Id: Iba762b3c1de4c0d7169299724285deba68fe7256\n'}]",0,851630,7aae554f8b7eb473e5c9b87d31beaf7ea0e6ef22,7,2,1,35058,,,0,"remove unicode literal from code

Change-Id: Iba762b3c1de4c0d7169299724285deba68fe7256
",git fetch https://review.opendev.org/openstack/magnum refs/changes/30/851630/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,7aae554f8b7eb473e5c9b87d31beaf7ea0e6ef22,,"copyright = '2013, OpenStack Foundation' 'magnum Documentation', 'OpenStack Foundation', 'manual'),","copyright = u'2013, OpenStack Foundation' u'magnum Documentation', u'OpenStack Foundation', 'manual'),",3,3
openstack%2Fmagnum~master~I44f80ccc97c0eeab98f1edbe4a22763732b7f4da,openstack/magnum,master,I44f80ccc97c0eeab98f1edbe4a22763732b7f4da,Fix pods stuck terminating.,MERGED,2022-09-14 05:26:39.000000000,2022-11-09 11:33:38.000000000,2022-11-09 11:32:39.000000000,"[{'_account_id': 8064}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-09-14 05:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c88131e7c3751b9b967a03b973da2099c104071a', 'message': ""Fix pods stuck terminating.\n\nIf the kubelet container is restarted on a host (during upgrades, or manually)\nthe bind mounts duplicate into /rootfs and kubelet cannot unmount these.\n\nThis leads to stuck terminating pods that must be resolved with either --force\nor restart of kubelet container.\n\nAdding 'rslave' means that when the kubelet unmounts volumes at /var/lib/kubelet/pods\nthis propogates to the host (using 'rshared'), and back into the container in /rootfs.\n\nThis bug was likely introduced when mounting of /rootfs was added[0].\n\n[0] https://opendev.org/openstack/magnum/commit/1994e9448a4d131e6305b68e49f1fdcdb5420cef\n\nChange-Id: I44f80ccc97c0eeab98f1edbe4a22763732b7f4da\n""}, {'number': 2, 'created': '2022-10-26 00:09:48.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b318560b596511b5dffcaeb965035bffa0f33c7d', 'message': ""Fix pods stuck terminating.\n\nIf the kubelet container is restarted on a host (during upgrades, or manually)\nthe bind mounts duplicate into /rootfs and kubelet cannot unmount these.\n\nThis leads to stuck terminating pods that must be resolved with either --force\nor restart of kubelet container.\n\nAdding 'rslave' means that when the kubelet unmounts volumes at /var/lib/kubelet/pods\nthis propogates to the host (using 'rshared'), and back into the container in /rootfs.\n\nThis bug was likely introduced when mounting of /rootfs was added[0].\n\n[0] https://opendev.org/openstack/magnum/commit/1994e9448a4d131e6305b68e49f1fdcdb5420cef\n\nChange-Id: I44f80ccc97c0eeab98f1edbe4a22763732b7f4da\n""}]",2,857553,b318560b596511b5dffcaeb965035bffa0f33c7d,10,4,2,14394,,,0,"Fix pods stuck terminating.

If the kubelet container is restarted on a host (during upgrades, or manually)
the bind mounts duplicate into /rootfs and kubelet cannot unmount these.

This leads to stuck terminating pods that must be resolved with either --force
or restart of kubelet container.

Adding 'rslave' means that when the kubelet unmounts volumes at /var/lib/kubelet/pods
this propogates to the host (using 'rshared'), and back into the container in /rootfs.

This bug was likely introduced when mounting of /rootfs was added[0].

[0] https://opendev.org/openstack/magnum/commit/1994e9448a4d131e6305b68e49f1fdcdb5420cef

Change-Id: I44f80ccc97c0eeab98f1edbe4a22763732b7f4da
",git fetch https://review.opendev.org/openstack/magnum refs/changes/53/857553/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh']",2,c88131e7c3751b9b967a03b973da2099c104071a,fix-stuck-terminating-pods," --volume /:/rootfs:rslave,ro \\", --volume /:/rootfs:ro \\,2,2
openstack%2Freleases~master~Ie637021e81649e84a1c6efefe967d814299dfbd6,openstack/releases,master,Ie637021e81649e84a1c6efefe967d814299dfbd6,Create queens-eol tag for all Designate projects,MERGED,2022-10-28 18:47:39.000000000,2022-11-09 11:30:16.000000000,2022-11-09 11:30:16.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2022-10-28 18:47:39.000000000', 'files': ['deliverables/queens/designate.yaml', 'deliverables/queens/designate-dashboard.yaml', 'deliverables/queens/python-designateclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5963e4ab2fdcad09de2449f0d13f3748995f9642', 'message': 'Create queens-eol tag for all Designate projects\n\nDesignate team is no longer accepting patches to\nstable/queens branch, this patch proposes to create queens-eol\ntags for all Designate projects.\n\nChange-Id: Ie637021e81649e84a1c6efefe967d814299dfbd6\n'}]",2,862951,5963e4ab2fdcad09de2449f0d13f3748995f9642,10,5,1,11628,,,0,"Create queens-eol tag for all Designate projects

Designate team is no longer accepting patches to
stable/queens branch, this patch proposes to create queens-eol
tags for all Designate projects.

Change-Id: Ie637021e81649e84a1c6efefe967d814299dfbd6
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/862951/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/queens/designate.yaml', 'deliverables/queens/designate-dashboard.yaml', 'deliverables/queens/python-designateclient.yaml']",3,5963e4ab2fdcad09de2449f0d13f3748995f9642,, - version: queens-eol projects: - repo: openstack/python-designateclient hash: 01edfe965c9951cca47404a2f123edc8383ef391,,12,0
openstack%2Fec2-api~master~I286c209a38e4271c12f47e2f3ec44da4724efbb3,openstack/ec2-api,master,I286c209a38e4271c12f47e2f3ec44da4724efbb3,increase default timeout,MERGED,2022-11-08 15:54:14.000000000,2022-11-09 11:17:49.000000000,2022-11-09 11:16:12.000000000,"[{'_account_id': 10234}, {'_account_id': 22348}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-11-08 15:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/9fe44dbc68bc6f1c46e370ba3adaf1125fcd14fb', 'message': 'raise default timeout\n\nSigned-off-by: tikitavi <rtikitavi@gmail.com>\nChange-Id: I286c209a38e4271c12f47e2f3ec44da4724efbb3\n'}, {'number': 2, 'created': '2022-11-08 16:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c8b314ea1a9d19358430d890cbac30b1429cc611', 'message': 'increase default timeout\n\nSigned-off-by: tikitavi <rtikitavi@gmail.com>\nChange-Id: I286c209a38e4271c12f47e2f3ec44da4724efbb3\n'}, {'number': 3, 'created': '2022-11-09 09:37:51.000000000', 'files': ['devstack/create_config'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/5971b2a3f7d77f6b4f6b240e4f84f2352bdee65f', 'message': 'increase default timeout\n\nSigned-off-by: tikitavi <rtikitavi@gmail.com>\nChange-Id: I286c209a38e4271c12f47e2f3ec44da4724efbb3\n'}]",0,864022,5971b2a3f7d77f6b4f6b240e4f84f2352bdee65f,11,3,3,19065,,,0,"increase default timeout

Signed-off-by: tikitavi <rtikitavi@gmail.com>
Change-Id: I286c209a38e4271c12f47e2f3ec44da4724efbb3
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/22/864022/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/create_config'],1,9fe44dbc68bc6f1c46e370ba3adaf1125fcd14fb,,"timeout=""600""","timeout=""180""",1,1
openstack%2Fec2api-tempest-plugin~master~I2cce3de5e1104decb5155a4f1d81086e9642fbf8,openstack/ec2api-tempest-plugin,master,I2cce3de5e1104decb5155a4f1d81086e9642fbf8,Pin stable branch jobs nodeset to Ubuntu Focal (20.04),MERGED,2022-10-16 02:10:00.000000000,2022-11-09 11:16:13.000000000,2022-11-09 11:16:13.000000000,"[{'_account_id': 10234}, {'_account_id': 22348}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-10-16 02:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2api-tempest-plugin/commit/803ca17701b68563d0b8fcf337338cf60f505972', 'message': 'Pin stable branch jobs nodeset to Ubuntu Focal (20.04)\n\nIn 2023.1 cycle. we are moving the default distro\nversion of Ubuntu to Jammy (22.04)[1] so we need to pin\nthe nodeset for stable branch job in master gate so that\nthey continue run on their supporting distro version which is\nUbuntu Focal since stable/victoria.\n\n[1] https://governance.openstack.org/tc/goals/selected/migrate-ci-jobs-to-ubuntu-jammy.html\n\nChange-Id: I2cce3de5e1104decb5155a4f1d81086e9642fbf8\n'}, {'number': 2, 'created': '2022-10-16 02:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2api-tempest-plugin/commit/000c2676d0f7d829bbbaffdfeebbd23e4fb5f265', 'message': 'Pin stable branch jobs nodeset to Ubuntu Focal (20.04)\n\nIn 2023.1 cycle. we are moving the default distro\nversion of Ubuntu to Jammy (22.04)[1] so we need to pin\nthe nodeset for stable branch job in master gate so that\nthey continue run on their supporting distro version which is\nUbuntu Focal since stable/victoria.\n\nAlso fixing the zuul config error.\n\n[1] https://governance.openstack.org/tc/goals/selected/migrate-ci-jobs-to-ubuntu-jammy.html\n\nChange-Id: I2cce3de5e1104decb5155a4f1d81086e9642fbf8\n'}, {'number': 3, 'created': '2022-11-08 16:08:36.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/ec2api-tempest-plugin/commit/7a23f331e52d0a7691e82708515b4460850eb55a', 'message': 'Pin stable branch jobs nodeset to Ubuntu Focal (20.04)\n\nIn 2023.1 cycle. we are moving the default distro\nversion of Ubuntu to Jammy (22.04)[1] so we need to pin\nthe nodeset for stable branch job in master gate so that\nthey continue run on their supporting distro version which is\nUbuntu Focal since stable/victoria.\n\nAlso fixing the zuul config error.\n\n[1] https://governance.openstack.org/tc/goals/selected/migrate-ci-jobs-to-ubuntu-jammy.html\n\nChange-Id: I2cce3de5e1104decb5155a4f1d81086e9642fbf8\nDepends-on: I286c209a38e4271c12f47e2f3ec44da4724efbb3\n'}]",5,861507,7a23f331e52d0a7691e82708515b4460850eb55a,20,3,3,8556,,,0,"Pin stable branch jobs nodeset to Ubuntu Focal (20.04)

In 2023.1 cycle. we are moving the default distro
version of Ubuntu to Jammy (22.04)[1] so we need to pin
the nodeset for stable branch job in master gate so that
they continue run on their supporting distro version which is
Ubuntu Focal since stable/victoria.

Also fixing the zuul config error.

[1] https://governance.openstack.org/tc/goals/selected/migrate-ci-jobs-to-ubuntu-jammy.html

Change-Id: I2cce3de5e1104decb5155a4f1d81086e9642fbf8
Depends-on: I286c209a38e4271c12f47e2f3ec44da4724efbb3
",git fetch https://review.opendev.org/openstack/ec2api-tempest-plugin refs/changes/07/861507/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,803ca17701b68563d0b8fcf337338cf60f505972,migrate-to-jammy, nodeset: openstack-single-node-focal nodeset: openstack-single-node-focal nodeset: openstack-single-node-focal,,3,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I48120976c48a8edcfdec29e651928f55ff92155a,openstack/openstack-ansible-lxc_hosts,master,I48120976c48a8edcfdec29e651928f55ff92155a,Cleanup CentOS 8 Stream,MERGED,2022-11-02 11:46:59.000000000,2022-11-09 11:04:56.000000000,2022-11-09 11:03:57.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 30396}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-11-02 11:46:59.000000000', 'files': ['vars/redhat-host.yml', 'vars/redhat-9-host.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d1fe9f7bece5ff11a1cac9b355f759bc29e62a46', 'message': 'Cleanup CentOS 8 Stream\n\nChange-Id: I48120976c48a8edcfdec29e651928f55ff92155a\n'}]",0,863259,d1fe9f7bece5ff11a1cac9b355f759bc29e62a46,9,4,1,28619,,,0,"Cleanup CentOS 8 Stream

Change-Id: I48120976c48a8edcfdec29e651928f55ff92155a
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/59/863259/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-9-host.yml', 'vars/redhat-host.yml']",2,d1fe9f7bece5ff11a1cac9b355f759bc29e62a46,osa/centos8_cleanup,"_lxc_centos_package_baseurl: ""https://download.copr.fedorainfracloud.org/results/neil/lxc4.0/centos-stream-9-$basearch/"" _lxc_centos_package_key: ""https://download.copr.fedorainfracloud.org/results/neil/lxc4.0/pubkey.gpg"" - lxc-templates-extra # requires lxc-templates","_lxc_centos_package_baseurl: ""https://download.copr.fedorainfracloud.org/results/thm/lxc3.0/epel-8-$basearch/"" _lxc_centos_package_key: ""https://download.copr.fedorainfracloud.org/results/thm/lxc3.0/pubkey.gpg"" - lxc-templates",3,52
openstack%2Fmagnum~master~I7837015c37eb58ba43ff42cc8b647c717fa1c650,openstack/magnum,master,I7837015c37eb58ba43ff42cc8b647c717fa1c650,Remove stdout argument from coredns log,MERGED,2022-10-26 03:31:48.000000000,2022-11-09 11:04:52.000000000,2022-11-09 11:03:52.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-10-26 03:31:48.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/fragments/core-dns-service.sh', 'magnum/drivers/k8s_coreos_v1/templates/fragments/enable-coredns.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e4e0843ed1001d9e462db1181ce464f9f400ecd4', 'message': ""Remove stdout argument from coredns log\n\nAccording to the documentation the first argument to log is either a\ndomain or a '.' (dot). The current setting of 'log stdout' appears to\nblackhole query logs. The default output of log is stdout so the\nargument would not be necessary.\n\nRemoving `stdout` allows coredns to send query logs to stdout.\n\nReference: https://coredns.io/plugins/log/\n\nChange-Id: I7837015c37eb58ba43ff42cc8b647c717fa1c650\n""}]",2,862667,e4e0843ed1001d9e462db1181ce464f9f400ecd4,8,3,1,35227,,,0,"Remove stdout argument from coredns log

According to the documentation the first argument to log is either a
domain or a '.' (dot). The current setting of 'log stdout' appears to
blackhole query logs. The default output of log is stdout so the
argument would not be necessary.

Removing `stdout` allows coredns to send query logs to stdout.

Reference: https://coredns.io/plugins/log/

Change-Id: I7837015c37eb58ba43ff42cc8b647c717fa1c650
",git fetch https://review.opendev.org/openstack/magnum refs/changes/67/862667/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/fragments/core-dns-service.sh', 'magnum/drivers/k8s_coreos_v1/templates/fragments/enable-coredns.yaml']",2,e4e0843ed1001d9e462db1181ce464f9f400ecd4,fix-coredns-logging, log, log stdout,2,2
openstack%2Fopenstack-ansible-openstack_hosts~master~I35a54c17d68027b9c291321834301ca7bb2fb3e7,openstack/openstack-ansible-openstack_hosts,master,I35a54c17d68027b9c291321834301ca7bb2fb3e7,Cleanup CentOS 8 Stream support,MERGED,2022-11-02 11:57:10.000000000,2022-11-09 11:03:44.000000000,2022-11-09 11:02:38.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 30396}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-11-02 11:57:10.000000000', 'files': ['vars/redhat-8.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/5936ae3f631c513b1c242530a92cadd782ef16c8', 'message': 'Cleanup CentOS 8 Stream support\n\nChange-Id: I35a54c17d68027b9c291321834301ca7bb2fb3e7\n'}]",0,863261,5936ae3f631c513b1c242530a92cadd782ef16c8,9,4,1,28619,,,0,"Cleanup CentOS 8 Stream support

Change-Id: I35a54c17d68027b9c291321834301ca7bb2fb3e7
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/61/863261/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-8.yml'],1,5936ae3f631c513b1c242530a92cadd782ef16c8,osa/centos8_cleanup,,"--- # Copyright 2016, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ## Defined required kernel openstack_host_required_kernel: 4.18.0 openstack_host_sysstat_file: /etc/sysconfig/sysstat openstack_host_sysstat_cron_file: /etc/cron.d/sysstat openstack_host_cron_template: sysstat.cron.redhat.j2 openstack_host_module_file: /etc/modules-load.d/openstack-ansible.conf openstack_host_sysstat_cron_mode: '0600' ## Kernel modules loaded on hosts openstack_host_kernel_modules: - name: 8021q - name: br_netfilter - name: dm_multipath - name: dm_snapshot - name: ebtables - name: ip6table_filter - name: ip6_tables - name: ip_tables - name: ipt_MASQUERADE - name: ipt_REJECT - name: iptable_filter - name: iptable_mangle - name: iptable_nat - name: ip_vs - name: iscsi_tcp - name: nf_conntrack - name: nf_defrag_ipv4 - name: nf_nat - name: vhost_net ## Base packages _openstack_host_distro_packages: - python3-devel - python3-six ## Bare metal base packages _openstack_host_metal_distro_packages: - cronie - curl - device-mapper-event - dstat - ebtables - git - iptables - irqbalance - kmod-libs - kmod - libselinux-python3 - lvm2 - passwd - rsync - rsyslog - sysstat - sudo - time - wget _package_repos_keys: - name: openstack-queens key: /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Cloud keyfile: ""gpg/764429E6"" - name: rdo-qemu-ev key: /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-SIG-Virtualization-RDO keyfile: ""gpg/61E8806C"" _package_list: - name: dnf-plugins-core state: present - name: epel-release state: absent - name: centos-release-storage-common state: absent - name: ca-certificates state: latest - name: centos-release-nfv-openvswitch state: ""{{ (service_install_method | default('source') == 'distro') | ternary('present', 'absent') }}"" _openstack_hosts_rdo_repo_url: ""{{ openstack_hosts_rdo_mirror_url }}/centos{{ ansible_facts['distribution_major_version'] }}-{{ openstack_distrib_code_name | lower }}/current/"" _openstack_hosts_rdo_deps_url: ""{{ openstack_hosts_rdo_mirror_url }}/centos{{ ansible_facts['distribution_major_version'] }}-{{ openstack_distrib_code_name | lower }}/deps/latest/"" _package_repos: - name: rdo-deps file: rdo-deps description: rdo-deps baseurl: ""{{ openstack_hosts_rdo_deps_url }}"" gpgcheck: no module_hotfixes: yes _openstack_ca_bundle_path: /etc/pki/tls/certs/ca-bundle.crt ",0,105
openstack%2Fmagnum-ui~stable%2Fzed~I73ac433d27bd50fee0b469375e8cd97b0d926e62,openstack/magnum-ui,stable/zed,I73ac433d27bd50fee0b469375e8cd97b0d926e62,Imported Translations from Zanata,MERGED,2022-10-06 03:49:28.000000000,2022-11-09 10:33:51.000000000,2022-11-09 10:32:38.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-10-06 03:49:28.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'magnum_ui/locale/zh_Hans/LC_MESSAGES/django.po', 'magnum_ui/locale/zh_Hans/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po', 'magnum_ui/locale/ru/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/en_GB/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/cb7a09b0d31297867f3c5513ea0d5474b25f1be5', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I73ac433d27bd50fee0b469375e8cd97b0d926e62\n'}]",0,860518,cb7a09b0d31297867f3c5513ea0d5474b25f1be5,9,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I73ac433d27bd50fee0b469375e8cd97b0d926e62
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/18/860518/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'magnum_ui/locale/zh_Hans/LC_MESSAGES/django.po', 'magnum_ui/locale/zh_Hans/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po', 'magnum_ui/locale/ru/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/en_GB/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/ru/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po']",13,cb7a09b0d31297867f3c5513ea0d5474b25f1be5,zanata/translations,,"# Gérald LONLAS <g.lonlas@gmail.com>, 2016. #zanata # JF Taltavull <jftalta@gmail.com>, 2017. #zanata # Mateusz Kowalski <mateusz.kowalski@cern.ch>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: magnum-ui\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2018-04-17 01:53+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-08-01 08:40+0000\n"" ""Last-Translator: Mateusz Kowalski <mateusz.kowalski@cern.ch>\n"" ""Language-Team: French\n"" ""Language: fr\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1)\n"" msgid ""'bay' and 'baymodel' are changed to 'cluster' and 'cluster template'."" msgstr """" ""'bay' et 'baymodel' ont été changés pour 'cluster' et 'cluster template'."" msgid ""'docker_storage_driver'"" msgstr ""'docker_storage_driver'"" msgid ""'fixed_subnet'"" msgstr ""'fixed_subnet'"" msgid ""'floating_ip_enabled'"" msgstr ""'floating_ip_enabled'"" msgid ""'master_lb_enabled'"" msgstr ""'master_lb_enabled'"" msgid ""2.2.0"" msgstr ""2.2.0"" msgid ""Bug Fixes"" msgstr ""Corrections de bugs"" msgid ""Current Series Release Notes"" msgstr ""Note de la release actuelle"" msgid ""Deprecation Notes"" msgstr ""Notes d'obsolescence"" msgid ""Magnum UI Release Notes"" msgstr ""Note de release pour Magnum UI"" msgid ""New Features"" msgstr ""Nouvelles fonctionnalités"" msgid ""Newton Series Release Notes"" msgstr ""Note de release pour Newton"" msgid ""Ocata release summary."" msgstr ""Note de release pour Ocata"" msgid ""Other Notes"" msgstr ""Autres notes"" msgid ""Switch to reno for managing release notes."" msgstr ""Commence à utiliser reno pour la gestion des notes de release"" msgid ""Upgrade Notes"" msgstr ""Notes de mises à jours"" ",9,4219
openstack%2Fcinder~master~I08f81179f4c1229aae990f4f1487831f9a9a2921,openstack/cinder,master,I08f81179f4c1229aae990f4f1487831f9a9a2921,Update metadata in setup.cfg,MERGED,2022-08-29 11:21:28.000000000,2022-11-09 10:24:01.000000000,2022-11-09 10:21:19.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 32029}, {'_account_id': 32238}]","[{'number': 1, 'created': '2022-08-29 11:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c90c572be51e69485657fe0e6b1538540bb7c6e2', 'message': 'Update metadata in setup.cfg\n\nChange-Id: I08f81179f4c1229aae990f4f1487831f9a9a2921\n'}, {'number': 2, 'created': '2022-09-23 14:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5196943176047b46f1f8d4ba7ef02a4194658abe', 'message': 'Update metadata in setup.cfg\n\nChange-Id: I08f81179f4c1229aae990f4f1487831f9a9a2921\n'}, {'number': 3, 'created': '2022-09-23 14:30:01.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b452414abde343f7d8e0415cf565a1f2aaaaf18f', 'message': 'Update metadata in setup.cfg\n\nwe are using some ""aliases"" that the setuptools docs say \n""are supported for compatibility reasons"" but their use is not advised[1].\n\n[1] https://setuptools.pypa.io/en/latest/userguide/declarative_config.html#metadata\n\nmaintaining setup.cfg as per other repos[2]\n\n[2] https://review.opendev.org/c/openstack/cinder-tempest-plugin/+/828475\n\nChange-Id: I08f81179f4c1229aae990f4f1487831f9a9a2921\n'}]",15,855013,b452414abde343f7d8e0415cf565a1f2aaaaf18f,62,10,3,30615,,,0,"Update metadata in setup.cfg

we are using some ""aliases"" that the setuptools docs say 
""are supported for compatibility reasons"" but their use is not advised[1].

[1] https://setuptools.pypa.io/en/latest/userguide/declarative_config.html#metadata

maintaining setup.cfg as per other repos[2]

[2] https://review.opendev.org/c/openstack/cinder-tempest-plugin/+/828475

Change-Id: I08f81179f4c1229aae990f4f1487831f9a9a2921
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/855013/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c90c572be51e69485657fe0e6b1538540bb7c6e2,,description = OpenStack Block Storage long_description = file: README.rsturl = https://docs.openstack.org/cinder/latest/classifiers =,summary = OpenStack Block Storage description_file = README.rsthome_page = https://docs.openstack.org/cinder/latest/classifier =,4,5
openstack%2Fglance~stable%2Fxena~If36e64b61767dc5c1df0daec2dd176fecd409926,openstack/glance,stable/xena,If36e64b61767dc5c1df0daec2dd176fecd409926,[stable-only] Remove glance-code-constants-check,MERGED,2022-11-07 21:55:38.000000000,2022-11-09 10:23:28.000000000,2022-11-09 10:21:17.000000000,"[{'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 21:55:38.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/glance/commit/3cfbb69c017ed0e2c61f267829a3b79b073832f0', 'message': ""[stable-only] Remove glance-code-constants-check\n\nThis job is only useful in the development branch; there's no\npoint in running it in the stable branches.\n\nChange-Id: If36e64b61767dc5c1df0daec2dd176fecd409926\n(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)\n(cherry picked from commit 5fbf47378e70537c73394408e69e94449aba1bec)\n""}]",1,863943,3cfbb69c017ed0e2c61f267829a3b79b073832f0,7,2,1,5314,,,0,"[stable-only] Remove glance-code-constants-check

This job is only useful in the development branch; there's no
point in running it in the stable branches.

Change-Id: If36e64b61767dc5c1df0daec2dd176fecd409926
(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)
(cherry picked from commit 5fbf47378e70537c73394408e69e94449aba1bec)
",git fetch https://review.opendev.org/openstack/glance refs/changes/43/863943/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3cfbb69c017ed0e2c61f267829a3b79b073832f0,remove-constants-check,, name: glance-code-constants-check parent: tox description: | Tests to catch when code constants have gotten out of sync. vars: tox_envlist: gateonly irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tox.ini$ - ^\.zuul\.yaml$ - job: - glance-code-constants-check,0,19
openstack%2Fcharm-specs~master~I0a6be44a0b1d79ef54be0c5905734df5b032c4c7,openstack/charm-specs,master,I0a6be44a0b1d79ef54be0c5905734df5b032c4c7,Open the Antelope Specs,MERGED,2022-11-08 13:09:12.000000000,2022-11-09 10:12:02.000000000,2022-11-09 10:11:00.000000000,"[{'_account_id': 2424}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 13:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/61fc0ae28548d0745f3287079f4dc6fce83f7eb5', 'message': 'Open the Antelope Specs\n\nOpen the Antelope cycle specs (a bit late, but better late than never).\n\nChange-Id: I0a6be44a0b1d79ef54be0c5905734df5b032c4c7\n'}, {'number': 2, 'created': '2022-11-08 13:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/238650169c1de90fe98a7f00881adae77b4b5c0d', 'message': 'Open the Antelope Specs\n\nOpen the Antelope cycle specs (a bit late, but better late than never).\n\nChange-Id: I0a6be44a0b1d79ef54be0c5905734df5b032c4c7\n'}, {'number': 3, 'created': '2022-11-08 13:54:20.000000000', 'files': ['specs/antelope/backlog/audit-middleware.rst', 'doc/source/specs/antelope/approved', 'doc/source/specs/antelope/backlog', 'specs/antelope/backlog/cinder-nimblestorage.rst', 'specs/antelope/backlog/rabbitmq-quorum-queue-support.rst', 'doc/source/specs/antelope/implemented', 'specs/antelope/backlog/release-notes-migration-to-reno.rst', 'doc/source/specs/yoga/index.rst', 'doc/source/specs/zed/approved', 'doc/source/specs/zed/implemented', 'specs/antelope/backlog/service-discovery.rst', 'specs/zed/backlog/.keep', 'specs/yoga/implemented/vtpm-support.rst', 'specs/zed/implemented/keystone-openidc.rst', 'specs/antelope/backlog/numa-live-migration.rst', 'specs/yoga/implemented/cinder-backup-swift.rst', 'specs/antelope/backlog/pausing-charms-hacluster-no-false-alerts.rst', 'doc/source/specs/zed/backlog', 'specs/antelope/backlog/cinder-solidfire.rst', 'specs/antelope/redirects', 'doc/source/specs/zed/index.rst', 'specs/antelope/backlog/swift-extended-cluster-operations.rst', 'specs/zed/redirects', 'doc/source/specs/zed/redirects', 'specs/antelope/backlog/ncc-migration-ssh-auth-sharing.rst', 'specs/antelope/implemented/.keep', 'doc/source/specs/zed/template.rst', 'specs/zed/implemented/designate-bind-service-ip.rst', 'doc/source/specs/antelope/redirects', 'doc/source/index.rst', 'specs/zed/approved/.keep', 'doc/source/specs/antelope/template.rst', 'specs/antelope/backlog/ceph-storage-action.rst', 'specs/antelope/backlog/memory-fragmentation-tuning.rst', 'doc/source/specs/antelope/index.rst', 'specs/antelope/backlog/.keep', 'specs/antelope/backlog/ovn-central-downscaling.rst', 'specs/yoga/implemented/nvidia-vgpu-support.rst', 'specs/antelope/backlog/prometheus-metrics-exporter.rst'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/9448f7ccae15fea3a7bb7332dfdbfef638e34b24', 'message': 'Open the Antelope Specs\n\nOpen the Antelope cycle specs (a bit late, but better late than never).\n\nChange-Id: I0a6be44a0b1d79ef54be0c5905734df5b032c4c7\n'}]",1,864002,9448f7ccae15fea3a7bb7332dfdbfef638e34b24,11,2,3,12549,,,0,"Open the Antelope Specs

Open the Antelope cycle specs (a bit late, but better late than never).

Change-Id: I0a6be44a0b1d79ef54be0c5905734df5b032c4c7
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/02/864002/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/antelope/approved', 'doc/source/specs/antelope/backlog', 'doc/source/specs/antelope/implemented', 'specs/antelope/approved/pausing-charms-hacluster-no-false-alerts.rst', 'specs/zed/backlog/.keep', 'specs/yoga/implemented/vtpm-support.rst', 'specs/zed/implemented/keystone-openidc.rst', 'specs/antelope/approved/cinder-nimblestorage.rst', 'specs/antelope/redirects', 'specs/antelope/approved/memory-fragmentation-tuning.rst', 'specs/antelope/approved/ovn-central-downscaling.rst', 'specs/zed/redirects', 'specs/antelope/approved/ncc-migration-ssh-auth-sharing.rst', 'specs/antelope/implemented/.keep', 'specs/zed/implemented/designate-bind-service-ip.rst', 'doc/source/specs/antelope/redirects', 'doc/source/index.rst', 'specs/antelope/approved/prometheus-metrics-exporter.rst', 'specs/antelope/approved/rabbitmq-quorum-queue-support.rst', 'specs/zed/approved/.keep', 'doc/source/specs/antelope/template.rst', 'specs/antelope/approved/cinder-solidfire.rst', 'doc/source/specs/antelope/index.rst', 'specs/antelope/backlog/.keep', 'specs/yoga/implemented/nvidia-vgpu-support.rst']",25,61fc0ae28548d0745f3287079f4dc6fce83f7eb5,charm-antelope-specs,,,164,0
openstack%2Fsushy~master~I371e4a2d294a3a87eddb230f13bca713e304f948,openstack/sushy,master,I371e4a2d294a3a87eddb230f13bca713e304f948,Increase server side retries,MERGED,2022-11-07 09:50:36.000000000,2022-11-09 10:06:42.000000000,2022-11-08 17:33:07.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 09:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/18a03dd15391b6a9e5cc265c9d4228ce9fa474f7', 'message': 'Increase server side retries\n\nThis is to take into account possible increases in time gap between\noperations from recent firmware versions, for example in Dell idrac\nseries 5.x where the time gap increased to almost 20 seconds from\nthe 10 seconds of the 4.x series, and avoid timeouts.\n\nChange-Id: I371e4a2d294a3a87eddb230f13bca713e304f948\n'}, {'number': 2, 'created': '2022-11-07 11:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/8a365426e2a3e9dd7e35d6a2d54fbe1d3fcbabca', 'message': 'Increase server side retries\n\nThis is to take into account possible increases in time gap between\noperations from recent firmware versions, for example in Dell idrac\nseries 5.x where the time gap increased to almost 20 seconds from\nthe 10 seconds of the 4.x series, and avoid timeouts.\n\nChange-Id: I371e4a2d294a3a87eddb230f13bca713e304f948\n'}, {'number': 3, 'created': '2022-11-07 11:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/c8c579b9ef4eaf8d8163be6858ba18945c15eca4', 'message': 'Increase server side retries\n\nThis is to take into account possible increases in time gap between\noperations from recent firmware versions, for example in Dell idrac\nseries 5.x where the time gap increased to almost 20 seconds from\nthe 10 seconds of the 4.x series, and avoid timeouts.\n\nChange-Id: I371e4a2d294a3a87eddb230f13bca713e304f948\n'}, {'number': 4, 'created': '2022-11-07 11:52:06.000000000', 'files': ['releasenotes/notes/increase-server-retries-5f11edde8ee0b461.yaml', 'sushy/connector.py', 'sushy/tests/unit/test_connector.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/67185bf4af21c2b844b0d8824036e73c96e344d0', 'message': 'Increase server side retries\n\nThis is to take into account possible increases in time gap between\noperations from recent firmware versions, for example in Dell idrac\nseries 5.x where the time gap increased to almost 20 seconds from\nthe 10 seconds of the 4.x series, and avoid timeouts.\n\nChange-Id: I371e4a2d294a3a87eddb230f13bca713e304f948\n'}]",5,863828,67185bf4af21c2b844b0d8824036e73c96e344d0,17,3,4,23851,,,0,"Increase server side retries

This is to take into account possible increases in time gap between
operations from recent firmware versions, for example in Dell idrac
series 5.x where the time gap increased to almost 20 seconds from
the 10 seconds of the 4.x series, and avoid timeouts.

Change-Id: I371e4a2d294a3a87eddb230f13bca713e304f948
",git fetch https://review.opendev.org/openstack/sushy refs/changes/28/863828/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/increase-server-retries-5f11edde8ee0b461.yaml', 'sushy/connector.py']",2,18a03dd15391b6a9e5cc265c9d4228ce9fa474f7,increase-retries,_SERVER_SIDE_RETRIES = 7,_SERVER_SIDE_RETRIES = 5,8,1
openstack%2Fmagnum~master~I459b421b3e9f20e2d55fc8b0c19091583bc8515f,openstack/magnum,master,I459b421b3e9f20e2d55fc8b0c19091583bc8515f,Imported Translations from Zanata,MERGED,2022-10-12 03:18:59.000000000,2022-11-09 09:56:38.000000000,2022-11-09 09:55:33.000000000,"[{'_account_id': 8064}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-12 03:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/880f6dae45a6663041bf95c30b45d83ee11fd40e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I459b421b3e9f20e2d55fc8b0c19091583bc8515f\n'}, {'number': 2, 'created': '2022-10-17 04:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4a19ea57412fb71b06a717242f0a68e5067ae70c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I459b421b3e9f20e2d55fc8b0c19091583bc8515f\n'}, {'number': 3, 'created': '2022-11-05 02:46:19.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/magnum/commit/c762071385c7cab615844a34f41ebb411700c6af', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I459b421b3e9f20e2d55fc8b0c19091583bc8515f\n'}]",0,861025,c762071385c7cab615844a34f41ebb411700c6af,11,2,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I459b421b3e9f20e2d55fc8b0c19091583bc8515f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/25/861025/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po']",2,880f6dae45a6663041bf95c30b45d83ee11fd40e,zanata/translations,,"# Gérald LONLAS <g.lonlas@gmail.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: magnum\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2021-09-06 21:22+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-10-22 04:59+0000\n"" ""Last-Translator: Gérald LONLAS <g.lonlas@gmail.com>\n"" ""Language-Team: French\n"" ""Language: fr\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1)\n"" msgid """" ""--keypair-id parameter in magnum CLI cluster-template-create has been "" ""renamed to --keypair."" msgstr """" ""Le paramètre --keypair-id dans cluster-template-create du CLI magnum a été "" ""renommé pour --keypair."" msgid ""3.0.0"" msgstr ""3.0.0"" msgid ""3.1.0"" msgstr ""3.1.0"" msgid "":ref:`genindex`"" msgstr "":ref:`genindex`"" msgid "":ref:`search`"" msgstr "":ref:`search`"" msgid ""Contents:"" msgstr ""Contenu :"" msgid ""Current Series Release Notes"" msgstr ""Note de la release actuelle"" msgid ""Deprecation Notes"" msgstr ""Notes dépréciées "" msgid ""Indices and tables"" msgstr ""Index et table des matières"" msgid ""New Features"" msgstr ""Nouvelles fonctionnalités"" msgid ""Newton Series Release Notes"" msgstr ""Note de release pour Newton"" msgid ""Security Issues"" msgstr ""Problèmes de sécurités"" msgid ""Upgrade Notes"" msgstr ""Notes de mises à jours"" msgid ""Welcome to Magnum Release Notes's documentation!"" msgstr ""Bienvenue dans la documentation de la note de Release de Magnum"" msgid ""[1] https://review.openstack.org/#/c/311476/"" msgstr ""[1] https://review.openstack.org/#/c/311476/"" ",106,68
openstack%2Fceilometer-powervm~master~I576c453e8b8099b93890317d247c919c5ef04505,openstack/ceilometer-powervm,master,I576c453e8b8099b93890317d247c919c5ef04505,Remove python-dev from bindep,NEW,2022-11-07 09:50:06.000000000,2022-11-09 09:22:20.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 09:50:06.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer-powervm/commit/c4e01ac34fa25817c602aeaade9a78eab17257f1', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I576c453e8b8099b93890317d247c919c5ef04505\n""}]",2,863826,c4e01ac34fa25817c602aeaade9a78eab17257f1,6,1,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I576c453e8b8099b93890317d247c919c5ef04505
",git fetch https://review.opendev.org/openstack/ceilometer-powervm refs/changes/26/863826/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,c4e01ac34fa25817c602aeaade9a78eab17257f1,drop-python-dev-from-bindep,,python-dev [platform:dpkg test] python-devel [platform:rpm test],0,2
openstack%2Fheat~master~Ia0df9b3468fee9382c42c8bd6a35b76ed7f2b4e5,openstack/heat,master,Ia0df9b3468fee9382c42c8bd6a35b76ed7f2b4e5,Update stestr args for inclusive language,MERGED,2022-11-09 06:11:51.000000000,2022-11-09 09:21:37.000000000,2022-11-09 09:20:23.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 06:11:51.000000000', 'files': ['devstack/upgrade/resources.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/0aa0b382519efcf128f57e884f0e83fec80f847e', 'message': 'Update stestr args for inclusive language\n\nstestr has removed whitelist / blacklist. This change updates the\ndevstack upgrade tests to ensure we use the new include-list instead.\nhttps://github.com/mtreinish/stestr/commit/9ffeb470fb4eaed484152d35411668db19a64ace\n\nChange-Id: Ia0df9b3468fee9382c42c8bd6a35b76ed7f2b4e5\n'}]",0,864082,0aa0b382519efcf128f57e884f0e83fec80f847e,9,2,1,30073,,,0,"Update stestr args for inclusive language

stestr has removed whitelist / blacklist. This change updates the
devstack upgrade tests to ensure we use the new include-list instead.
https://github.com/mtreinish/stestr/commit/9ffeb470fb4eaed484152d35411668db19a64ace

Change-Id: Ia0df9b3468fee9382c42c8bd6a35b76ed7f2b4e5
",git fetch https://review.opendev.org/openstack/heat refs/changes/82/864082/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/upgrade/resources.sh'],1,0aa0b382519efcf128f57e884f0e83fec80f847e,stestr-inclusive-lang, run --include-list $UPGRADE_TESTS, run --whitelist-file $UPGRADE_TESTS,1,1
openstack%2Fansible-collections-openstack~master~I09a133b5c4f6c71e10d274be1c70b7edcce1c83c,openstack/ansible-collections-openstack,master,I09a133b5c4f6c71e10d274be1c70b7edcce1c83c,Renamed image->image_name and flavor->flavor_name to avoid collisions,MERGED,2022-11-07 19:05:57.000000000,2022-11-09 09:09:30.000000000,2022-11-09 09:09:30.000000000,"[{'_account_id': 22348}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-07 19:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2f414cd7c46ca3a6adade5499a9ee6a4ef6f47f9', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}, {'number': 2, 'created': '2022-11-08 08:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c29b7b2b29ca15c096478cbde89c313c62be791a', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}, {'number': 3, 'created': '2022-11-08 09:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0c9e93dd64197ad814dfccb84bc19f999d6388c1', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}, {'number': 4, 'created': '2022-11-08 12:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/bcc6eab1bfa4543b1a6fb985ab6da3c137736869', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}, {'number': 5, 'created': '2022-11-08 12:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3d334146217ad34a527f9f2707083ff0c0ef2c1c', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}, {'number': 6, 'created': '2022-11-08 14:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/fc8120a2366395a3dd7573a4db3218537ea947c1', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}, {'number': 7, 'created': '2022-11-08 19:44:18.000000000', 'files': ['ci/roles/image/tasks/main.yml', 'ci/roles/server/tasks/main.yml', 'ci/roles/server/tasks/server_actions.yml', 'ci/roles/image/defaults/main.yml', 'ci/roles/volume/tasks/main.yml', 'ci/run-ansible-tests-collection.sh', 'ci/roles/server/defaults/main.yml', 'ci/roles/keystone_domain/tasks/main.yml', 'ci/roles/compute_flavor/tasks/main.yml', 'ci/roles/floating_ip/tasks/main.yml', 'ci/roles/server_volume/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a8f6dbd904033b57f41a3665d879b9adcee50d19', 'message': 'Renamed image->image_name and flavor->flavor_name to avoid collisions\n\nChange-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c\n'}]",0,863924,a8f6dbd904033b57f41a3665d879b9adcee50d19,18,3,7,32962,,,0,"Renamed image->image_name and flavor->flavor_name to avoid collisions

Change-Id: I09a133b5c4f6c71e10d274be1c70b7edcce1c83c
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/24/863924/5 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/server/tasks/main.yml', 'ci/roles/server/tasks/server_actions.yml', 'ci/run-ansible-tests-collection.sh', 'ci/roles/server/defaults/main.yml', 'ci/roles/floating_ip/tasks/main.yml']",5,2f414cd7c46ca3a6adade5499a9ee6a4ef6f47f9,ci-variable-names," image: ""{{ image_name }}"" image: ""{{ image_name }}"""," image: ""{{ image }}"" image: ""{{ image }}""",33,33
openstack%2Ftripleo-ansible~stable%2Fwallaby~Ic28add116c369979b4038ce403451dc95dc2f53d,openstack/tripleo-ansible,stable/wallaby,Ic28add116c369979b4038ce403451dc95dc2f53d,num_dpdk_interface_rx_queues support net conf schema,MERGED,2022-11-08 04:16:45.000000000,2022-11-09 08:53:28.000000000,2022-11-09 08:52:23.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2022-11-08 04:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/05394961ab42f0ace8cb1ffd55c09683f7d2785d', 'message': ""num_dpdk_interface_rx_queues support net conf schema\n\nThe network_config schema in the baremetal provision defintion\ndid not allow setting the 'num_dpdk_interface_rx_queues'.\n\nThis change adds the varaible to the schema, and adds the option\nin module: tripleo_generate_inventory_network_config. By default\nthe value is 1, which is the same default used in THT for parameter\nNumDpdkInterfaceRxQueues.\n\nCloses-Bug: #1989593\nChange-Id: Ic28add116c369979b4038ce403451dc95dc2f53d\n""}, {'number': 2, 'created': '2022-11-08 08:30:31.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_generate_inventory_network_config.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py', 'releasenotes/notes/net-conf-schema-num_dpdk_interface_rx_queues-4a37e4fc3957ed9a.yaml', 'tripleo_ansible/tests/modules/test_tripleo_generate_inventory_network_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4b6c2e017c9ce408b6b421c1e6f9b6a073c8b96e', 'message': ""num_dpdk_interface_rx_queues support net conf schema\n\nThe network_config schema in the baremetal provision defintion\ndid not allow setting the 'num_dpdk_interface_rx_queues'.\n\nThis change adds the varaible to the schema, and adds the option\nin module: tripleo_generate_inventory_network_config. By default\nthe value is 1, which is the same default used in THT for parameter\nNumDpdkInterfaceRxQueues.\n\nCloses-Bug: #1989593\nChange-Id: Ic28add116c369979b4038ce403451dc95dc2f53d\n(cherry picked from commit c3315623fe23864ce34e63ae364c7a2d200679a4)\n""}]",1,863794,4b6c2e017c9ce408b6b421c1e6f9b6a073c8b96e,16,3,2,30073,,,0,"num_dpdk_interface_rx_queues support net conf schema

The network_config schema in the baremetal provision defintion
did not allow setting the 'num_dpdk_interface_rx_queues'.

This change adds the varaible to the schema, and adds the option
in module: tripleo_generate_inventory_network_config. By default
the value is 1, which is the same default used in THT for parameter
NumDpdkInterfaceRxQueues.

Closes-Bug: #1989593
Change-Id: Ic28add116c369979b4038ce403451dc95dc2f53d
(cherry picked from commit c3315623fe23864ce34e63ae364c7a2d200679a4)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/94/863794/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_generate_inventory_network_config.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py', 'releasenotes/notes/net-conf-schema-num_dpdk_interface_rx_queues-4a37e4fc3957ed9a.yaml', 'tripleo_ansible/tests/modules/test_tripleo_generate_inventory_network_config.py']",4,05394961ab42f0ace8cb1ffd55c09683f7d2785d,bug/1989593-stable/zed-stable/wallaby," 'num_dpdk_interface_rx_queues': 1, 'num_dpdk_interface_rx_queues': 1,",,14,0
openstack%2Ftripleo-quickstart-extras~master~Ibe18cf6737bab7903c7cf40d3bdf8797c21639f5,openstack/tripleo-quickstart-extras,master,Ibe18cf6737bab7903c7cf40d3bdf8797c21639f5,Set tempest_test_whitelist properly,ABANDONED,2021-01-11 14:10:38.000000000,2022-11-09 08:40:39.000000000,,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-11 14:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a3c6e903feaad387725e4d5a423efc41ff7675d1', 'message': 'Set tempest_test_whitelist properly\n\nThis patch sets the default tests to run in both check/gate jobs as well\nas periodic jobs\n\nChange-Id: Ibe18cf6737bab7903c7cf40d3bdf8797c21639f5\n'}, {'number': 2, 'created': '2021-01-11 20:32:31.000000000', 'files': ['playbooks/tasks/tempest.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d827ad51d1f3e4cd25e8a1ac8bb106abcce96cd1', 'message': ""Set tempest_test_whitelist properly\n\nMoving the tempest_test_whitelist variable to tempest.yml instead of\nhaving it on featureset file. With this move, it is possible to\noverwrite it, while in featureset file isn't possible.\n\nThe patch that remove it from featureset is in [1]\n\n[1] - https://review.opendev.org/c/openstack/tripleo-quickstart/+/770127\n\nChange-Id: Ibe18cf6737bab7903c7cf40d3bdf8797c21639f5\n""}]",2,770126,d827ad51d1f3e4cd25e8a1ac8bb106abcce96cd1,8,3,2,8367,,,0,"Set tempest_test_whitelist properly

Moving the tempest_test_whitelist variable to tempest.yml instead of
having it on featureset file. With this move, it is possible to
overwrite it, while in featureset file isn't possible.

The patch that remove it from featureset is in [1]

[1] - https://review.opendev.org/c/openstack/tripleo-quickstart/+/770127

Change-Id: Ibe18cf6737bab7903c7cf40d3bdf8797c21639f5
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/26/770126/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tasks/tempest.yml'],1,a3c6e903feaad387725e4d5a423efc41ff7675d1,skiplist-fix, - name: Set default list of allowed set_fact: tempest_test_whitelist: - 'tempest.scenario.test_minimum_basic.TestMinimumBasicScenario' - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps' - 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern' when: tempest_test_whitelist is undefined - name: Set tempest periodic regex set_fact: tempest_test_whitelist: - smoke when: (('periodic' in zuul.pipeline and not job.force_non_periodic|default(false)|bool) or (job.force_periodic|default(false)|bool)) and not tempest_run_skipped | default(false) | bool ,,14,0
openstack%2Ftripleo-quickstart~master~I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8,openstack/tripleo-quickstart,master,I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8,Remove tempest_test_whitelist variable,ABANDONED,2021-01-11 14:11:50.000000000,2022-11-09 08:40:21.000000000,,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-01-11 14:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7c3889c2c9605c3ea2ca143cfcdf26a3e6b0c105', 'message': 'Remove tempest_test_whitelist variable\n\nHaving this set here, it means it cannot be overwritten in periodic\njobs, and so, this will be set in the tempest.yml task under\ntripleo-quickstart-extras\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/770126\nChange-Id: I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8\n'}, {'number': 2, 'created': '2021-01-11 15:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e699e521c8581face3ede66ab998ad1bb82e5036', 'message': 'Remove tempest_test_whitelist variable\n\nHaving this set here, it means it cannot be overwritten in periodic\njobs, and so, this will be set in the tempest.yml task under\ntripleo-quickstart-extras\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/770126\nChange-Id: I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8\n'}, {'number': 3, 'created': '2021-01-11 15:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3e75bbcdf7dea273cfc32faf922b3793d85507d3', 'message': 'Remove tempest_test_whitelist variable\n\nHaving this set here, it means it cannot be overwritten in periodic\njobs, and so, this will be set in the tempest.yml task under\ntripleo-quickstart-extras\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/770126\nChange-Id: I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8\n'}, {'number': 4, 'created': '2021-01-12 09:35:14.000000000', 'files': ['config/general_config/featureset052.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/72b46c7845b99eeda3830eb951970e2afc8fca67', 'message': 'Remove tempest_test_whitelist variable\n\nHaving this set here, it means it cannot be overwritten in periodic\njobs, and so, this will be set in the tempest.yml task under\ntripleo-quickstart-extras\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/770126\nChange-Id: I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8\n'}]",1,770127,72b46c7845b99eeda3830eb951970e2afc8fca67,16,3,4,8367,,,0,"Remove tempest_test_whitelist variable

Having this set here, it means it cannot be overwritten in periodic
jobs, and so, this will be set in the tempest.yml task under
tripleo-quickstart-extras

Depends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/770126
Change-Id: I5328e74ff36362a5cfbbf6e6e867cdffc4fc9ab8
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/27/770127/4 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset052.yml'],1,7c3889c2c9605c3ea2ca143cfcdf26a3e6b0c105,skiplist,,tempest_whitelist: - 'tempest.scenario.test_minimum_basic.TestMinimumBasicScenario' - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps' - 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern' tempest_periodic_regex: - 'smoke' tempest_test_whitelist: >- {% if (('periodic' in zuul.pipeline and not job.force_non_periodic|default(false)|bool) or (job.force_periodic|default(false)|bool)) and not tempest_run_skipped | default(false) | bool -%} {{ tempest_periodic_regex }} {%- else -%} {{ tempest_whitelist }} {%- endif -%} ,0,15
openstack%2Ftripleo-quickstart-extras~master~I85293ea74b0c823e4295f3cabe8f4b1f91f492b6,openstack/tripleo-quickstart-extras,master,I85293ea74b0c823e4295f3cabe8f4b1f91f492b6,Set retry_image option in tempestconf,ABANDONED,2021-03-22 19:38:26.000000000,2022-11-09 08:40:06.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-03-22 19:38:26.000000000', 'files': ['playbooks/tasks/tempest.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f198e312eab2ff3e33e4eaa952b473b5a1081418', 'message': 'Set retry_image option in tempestconf\n\nThis is an option in tempestconf to enable it to try different sources\nfor cirros image. If one of the sources fail, it will try from a\ndifferent one. This built a safe plan when one of the sources of the\ncirros image is offline.\n\nChange-Id: I85293ea74b0c823e4295f3cabe8f4b1f91f492b6\n'}]",0,782321,f198e312eab2ff3e33e4eaa952b473b5a1081418,4,2,1,8367,,,0,"Set retry_image option in tempestconf

This is an option in tempestconf to enable it to try different sources
for cirros image. If one of the sources fail, it will try from a
different one. This built a safe plan when one of the sources of the
cirros image is offline.

Change-Id: I85293ea74b0c823e4295f3cabe8f4b1f91f492b6
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/21/782321/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tasks/tempest.yml'],1,f198e312eab2ff3e33e4eaa952b473b5a1081418,set-retry-image, - name: Set cirros image facts for periodic # This option is to enable tempestconf to download the cirros image # from a different source if it doesn't find the local one retry_image: true, - name: set cirros image facts for periodic,4,1
openstack%2Ftripleo-quickstart-extras~master~I2f91e9fea92a948b8ccc001c1091370741e51e81,openstack/tripleo-quickstart-extras,master,I2f91e9fea92a948b8ccc001c1091370741e51e81,Add list_skipped_installer on tempest skiplist,ABANDONED,2021-05-04 19:42:26.000000000,2022-11-09 08:39:16.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-05-04 19:42:26.000000000', 'files': ['playbooks/tasks/tempest.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6cfa66c91b99ca4f03e2777169f2ead7adcd1dae', 'message': 'Add list_skipped_installer on tempest skiplist\n\nThis patch adds the installer option to filter tests on the skiplist.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-tempest-skiplist/+/789625\nChange-Id: I2f91e9fea92a948b8ccc001c1091370741e51e81\n'}]",0,789626,6cfa66c91b99ca4f03e2777169f2ead7adcd1dae,4,2,1,8367,,,0,"Add list_skipped_installer on tempest skiplist

This patch adds the installer option to filter tests on the skiplist.

Depends-On: https://review.opendev.org/c/openstack/openstack-tempest-skiplist/+/789625
Change-Id: I2f91e9fea92a948b8ccc001c1091370741e51e81
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/26/789626/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tasks/tempest.yml'],1,6cfa66c91b99ca4f03e2777169f2ead7adcd1dae,skiplist-installer," list_skipped_release: ""{{ release }}"" list_skipped_installer: ""{{ (osp_release is defined) | ternary('osp', 'tripleo') }}"""," list_skipped_release: ""{{ (osp_release is defined) | ternary(osp_release, release) }}""",2,1
openstack%2Fansible-role-collect-logs~master~If264037d6bcfe8bf9b8ae1a51f0c0af15c7bcf8f,openstack/ansible-role-collect-logs,master,If264037d6bcfe8bf9b8ae1a51f0c0af15c7bcf8f,DNM - Dummy patch to test molecule,ABANDONED,2021-09-17 07:44:01.000000000,2022-11-09 08:38:06.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-09-17 07:44:01.000000000', 'files': ['plugins/modules/sova.py'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/66a92a41e8d5f992627157cf5f9f5c8f6a55b18d', 'message': 'DNM - Dummy patch to test molecule\n\nChange-Id: If264037d6bcfe8bf9b8ae1a51f0c0af15c7bcf8f\n'}]",0,809535,66a92a41e8d5f992627157cf5f9f5c8f6a55b18d,4,2,1,8367,,,0,"DNM - Dummy patch to test molecule

Change-Id: If264037d6bcfe8bf9b8ae1a51f0c0af15c7bcf8f
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/35/809535/1 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/sova.py'],1,66a92a41e8d5f992627157cf5f9f5c8f6a55b18d,dnm-test, # dummy patch,,1,0
openstack%2Fansible-role-collect-logs~master~I74fc9f4d2a2746a8d222a2696c634c2d09355fb9,openstack/ansible-role-collect-logs,master,I74fc9f4d2a2746a8d222a2696c634c2d09355fb9,Add openstack-health url to failed file,ABANDONED,2021-09-13 08:06:05.000000000,2022-11-09 08:37:51.000000000,,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 32458}]","[{'number': 1, 'created': '2021-09-13 08:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/53b1c32cbf27eb2e5b1dacaeb8961b397db202f9', 'message': 'Add openstack-health url to failed file\n\nIn order to make it easy for developers to check the status of a\nparticualr failure, this patch adds in to the failed reasons file the\nurl pointing to openstack-health for the particular failure.\nRight now as default, we are using the url health.sbarnea.com, but we\nwill change it in the future to a tripleo url.\n\nChange-Id: I74fc9f4d2a2746a8d222a2696c634c2d09355fb9\n'}, {'number': 2, 'created': '2021-09-13 12:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/c106ce93afcfc4d93dea645e836675e5adde0142', 'message': 'Add openstack-health url to failed file\n\nIn order to make it easy for developers to check the status of a\nparticualr failure, this patch adds in to the failed reasons file the\nurl pointing to openstack-health for the particular failure.\nRight now as default, we are using the url health.sbarnea.com, but we\nwill change it in the future to a tripleo url.\n\nChange-Id: I74fc9f4d2a2746a8d222a2696c634c2d09355fb9\n'}, {'number': 3, 'created': '2021-09-13 13:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/806a88eee7bb634162f4f55a0e9b5c9e326eff89', 'message': 'Add openstack-health url to failed file\n\nIn order to make it easy for developers to check the status of a\nparticualr failure, this patch adds in to the failed reasons file the\nurl pointing to openstack-health for the particular failure.\nRight now as default, we are using the url health.sbarnea.com, but we\nwill change it in the future to a tripleo url.\n\nChange-Id: I74fc9f4d2a2746a8d222a2696c634c2d09355fb9\n'}, {'number': 4, 'created': '2021-09-14 07:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/5bbc0727b6a3211e05cb7b7ce28602e139d61107', 'message': 'Add openstack-health url to failed file\n\nIn order to make it easy for developers to check the status of a\nparticualr failure, this patch adds in to the failed reasons file the\nurl pointing to openstack-health for the particular failure.\nRight now as default, we are using the url health.sbarnea.com, but we\nwill change it in the future to a tripleo url.\n\nChange-Id: I74fc9f4d2a2746a8d222a2696c634c2d09355fb9\n'}, {'number': 5, 'created': '2021-09-14 08:11:34.000000000', 'files': ['plugins/modules/sova.py'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/cb705aea754b4d7130242d3f063adf4f52dbacb8', 'message': 'Add openstack-health url to failed file\n\nIn order to make it easy for developers to check the status of a\nparticualr failure, this patch adds in to the failed reasons file the\nurl pointing to openstack-health for the particular failure.\nRight now as default, we are using the url health.sbarnea.com, but we\nwill change it in the future to a tripleo url.\n\nChange-Id: I74fc9f4d2a2746a8d222a2696c634c2d09355fb9\n'}]",3,808603,cb705aea754b4d7130242d3f063adf4f52dbacb8,15,5,5,8367,,,0,"Add openstack-health url to failed file

In order to make it easy for developers to check the status of a
particualr failure, this patch adds in to the failed reasons file the
url pointing to openstack-health for the particular failure.
Right now as default, we are using the url health.sbarnea.com, but we
will change it in the future to a tripleo url.

Change-Id: I74fc9f4d2a2746a8d222a2696c634c2d09355fb9
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/03/808603/2 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/sova.py'],1,53b1c32cbf27eb2e5b1dacaeb8961b397db202f9,health-anchor," health: description: - URL of the openstack-health required: False type: string health: https://health.openstack.org/ health=dict(type=""string"", default=""http://health.sbarnea.com/""), messages, tags, ids = [], [], [] _ids, msgs = parse(file_, PATTERNS[name]) found = [i for i in PATTERNS[name] if i[""id""] in _ids] ids += _ids f.write(""Reason: "" + reason + ""\n"" for _id in ids: f.write(module.params[""health""] + ""#"" + _id) for _id in ids: f.write(module.params[""health""] + ""#"" + _id)"," messages, tags = [], [] ids, msgs = parse(file_, PATTERNS[name]) found = [i for i in PATTERNS[name] if i[""id""] in ids] f.write(""Reason: "" + reason + ""\n"")",17,4
openstack%2Ftripleo-quickstart-extras~master~I1f6ad405b86c4b0efaeff0108c11cab5f1b8e8d8,openstack/tripleo-quickstart-extras,master,I1f6ad405b86c4b0efaeff0108c11cab5f1b8e8d8,DNM - Testing upgrade,ABANDONED,2021-11-17 00:08:19.000000000,2022-11-09 08:37:32.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2021-11-17 00:08:19.000000000', 'files': ['roles/build-test-packages/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/282157a7e8778d43bc40d39280382fba09b80193', 'message': 'DNM - Testing upgrade\n\nChange-Id: I1f6ad405b86c4b0efaeff0108c11cab5f1b8e8d8\n'}]",0,818181,282157a7e8778d43bc40d39280382fba09b80193,6,2,1,8367,,,0,"DNM - Testing upgrade

Change-Id: I1f6ad405b86c4b0efaeff0108c11cab5f1b8e8d8
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/81/818181/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/build-test-packages/tasks/main.yml'],1,282157a7e8778d43bc40d39280382fba09b80193,dnm, # - (item.branch == zuul.override_checkout | default(zuul.branch)) or (osp_release is defined and osp_release in item.branch), - (item.branch == zuul.override_checkout | default(zuul.branch)) or (osp_release is defined and osp_release in item.branch),1,1
openstack%2Fopenstack-tempest-skiplist~master~I68fcb4953ffb67a777285c53081b289fb68dc7fe,openstack/openstack-tempest-skiplist,master,I68fcb4953ffb67a777285c53081b289fb68dc7fe,This test is failing to connect to metadata service,ABANDONED,2022-03-18 15:16:29.000000000,2022-11-09 08:37:15.000000000,,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 31075}]","[{'number': 1, 'created': '2022-03-18 15:16:29.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/38f5560ce1957089ce24a56af4c2309abe5aafdd', 'message': 'This test is failing to connect to metadata service\n\nChange-Id: I68fcb4953ffb67a777285c53081b289fb68dc7fe\nRelated-Bug: #1965546\n'}]",2,834330,38f5560ce1957089ce24a56af4c2309abe5aafdd,4,5,1,8367,,,0,"This test is failing to connect to metadata service

Change-Id: I68fcb4953ffb67a777285c53081b289fb68dc7fe
Related-Bug: #1965546
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/30/834330/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,38f5560ce1957089ce24a56af4c2309abe5aafdd,bug/1965546, - test: 'tempest.scenario.test_server_basic_ops.TestServerBasicOps.test_server_basic_ops' deployment: - 'overcloud' releases: - name: 'master' reason: 'Failing to connect to metadata service' lp: 'https://bugs.launchpad.net/tripleo/+bug/1965546' jobs: - periodic-tripleo-ci-centos-9-standalone-full-tempest-scenario-master,,9,0
openstack%2Fopenstack-tempest-skiplist~master~I998c36c81a92452d44eb870f66e91ff963baf7db,openstack/openstack-tempest-skiplist,master,I998c36c81a92452d44eb870f66e91ff963baf7db,Adding featureset001 groups,ABANDONED,2022-05-04 12:14:15.000000000,2022-11-09 08:36:57.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-05-04 12:14:15.000000000', 'files': ['roles/validate-tempest/vars/tempest_allow.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/becc3c0154c16cd65693d06ffd06c0ddd7e2edaa', 'message': 'Adding featureset001 groups\n\nThis patch add featureset001 groups splited in:\n\nfeatureset001_periodic_cni:\n* tempest.api.compute\n* tempest.api.network\n* tempest.api.identity\n\nfeatureset001_periodic_ovi:\n* tempest.api.object_storage\n* tempest.api.volume\n* tempest.api.image\n\nTo make easier to split featureset001 job in two, reducing so the\nresources required  to run all these tests in one single job\n\nChange-Id: I998c36c81a92452d44eb870f66e91ff963baf7db\n'}]",0,840444,becc3c0154c16cd65693d06ffd06c0ddd7e2edaa,3,1,1,8367,,,0,"Adding featureset001 groups

This patch add featureset001 groups splited in:

featureset001_periodic_cni:
* tempest.api.compute
* tempest.api.network
* tempest.api.identity

featureset001_periodic_ovi:
* tempest.api.object_storage
* tempest.api.volume
* tempest.api.image

To make easier to split featureset001 job in two, reducing so the
resources required  to run all these tests in one single job

Change-Id: I998c36c81a92452d44eb870f66e91ff963baf7db
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/44/840444/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_allow.yml'],1,becc3c0154c16cd65693d06ffd06c0ddd7e2edaa,scenario001, - name: featureset001_periodic_cni tests: - 'tempest.api.compute' - 'tempest.api.network' - 'tempest.api.identity' - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps' releases: - all - name: featureset001_periodic_ovi tests: - 'tempest.api.object_storage' - 'tempest.api.volume' - 'tempest.api.image' - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps' releases: - all,,16,0
openstack%2Ftripleo-quickstart-extras~master~I9029fd21de00df67c1a4d664a2393cdb8a7e9e51,openstack/tripleo-quickstart-extras,master,I9029fd21de00df67c1a4d664a2393cdb8a7e9e51,DNM - Testing patch,ABANDONED,2022-06-21 11:57:37.000000000,2022-11-09 08:36:40.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-06-21 11:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0e1276478131ff151bb07a368e33661a1f7540f2', 'message': 'DNM - Testing patch\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/846530\nChange-Id: I9029fd21de00df67c1a4d664a2393cdb8a7e9e51\n'}, {'number': 2, 'created': '2022-06-21 12:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7da9d47504f8bca51fd4b7926bfbeb8fb1dbb115', 'message': 'DNM - Testing patch\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/846530\nChange-Id: I9029fd21de00df67c1a4d664a2393cdb8a7e9e51\n'}, {'number': 3, 'created': '2022-06-23 11:22:24.000000000', 'files': ['roles/standalone/tasks/main.yml', 'roles/standalone/tasks/ceph-install.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e3c4f754f69137c722b2a2b17b259ef6d90d6689', 'message': 'DNM - Testing patch\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/847323\nChange-Id: I9029fd21de00df67c1a4d664a2393cdb8a7e9e51\n'}]",0,847010,e3c4f754f69137c722b2a2b17b259ef6d90d6689,14,2,3,8367,,,0,"DNM - Testing patch

Depends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/847323
Change-Id: I9029fd21de00df67c1a4d664a2393cdb8a7e9e51
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/10/847010/3 && git format-patch -1 --stdout FETCH_HEAD,['roles/standalone/tasks/main.yml'],1,0e1276478131ff151bb07a368e33661a1f7540f2,dnm-test,# What a day!,,1,0
openstack%2Ftripleo-ci~master~I7c4d5c8a8306bb528628b47e3d8518576ced4667,openstack/tripleo-ci,master,I7c4d5c8a8306bb528628b47e3d8518576ced4667,Add tempest option for ceph scenario004 job,ABANDONED,2022-07-26 15:52:03.000000000,2022-11-09 08:36:31.000000000,,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-07-26 15:52:03.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/13eea5e602b3cb92636f9009ec787fc35f5c3c40', 'message': 'Add tempest option for ceph scenario004 job\n\nTempest needs to be configured to use sha1 for\nobjects temp url hashes, until rgw gets support for\nsha256 as now expect by tempest by default.\n\nChange-Id: I7c4d5c8a8306bb528628b47e3d8518576ced4667\n'}]",1,851044,13eea5e602b3cb92636f9009ec787fc35f5c3c40,5,3,1,8367,,,0,"Add tempest option for ceph scenario004 job

Tempest needs to be configured to use sha1 for
objects temp url hashes, until rgw gets support for
sha256 as now expect by tempest by default.

Change-Id: I7c4d5c8a8306bb528628b47e3d8518576ced4667
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/44/851044/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,13eea5e602b3cb92636f9009ec787fc35f5c3c40,ceph-option, 'object_storage_feature_enabled.tempurl_digest_hashlib': 'sha1',,1,0
openstack%2Fopenstack-tempest-skiplist~master~I4b0361b47bfb780e249037f5bb9e037c5afe17d1,openstack/openstack-tempest-skiplist,master,I4b0361b47bfb780e249037f5bb9e037c5afe17d1,Adding designate tempest test to skiplist,ABANDONED,2022-10-31 13:29:12.000000000,2022-11-09 08:35:55.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-31 13:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/2707a7ba7c6097e1ecde9127755b7e797e6f4ff1', 'message': 'Adding designate tempest test to skiplist\n\nTests are failing due the lack of a dns nameserver in tempest config\nfile. Skipping while checking the best option to fix the problem.\n\nChange-Id: I4b0361b47bfb780e249037f5bb9e037c5afe17d1\n'}, {'number': 2, 'created': '2022-10-31 14:42:01.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/9fcc2ab17560f0c1c391d041fba3d6641e10e4eb', 'message': 'Adding designate tempest test to skiplist\n\nTests are failing due the lack of a dns nameserver in tempest config\nfile. Skipping while checking the best option to fix the problem.\n\nChange-Id: I4b0361b47bfb780e249037f5bb9e037c5afe17d1\n'}]",0,863059,9fcc2ab17560f0c1c391d041fba3d6641e10e4eb,5,1,2,8367,,,0,"Adding designate tempest test to skiplist

Tests are failing due the lack of a dns nameserver in tempest config
file. Skipping while checking the best option to fix the problem.

Change-Id: I4b0361b47bfb780e249037f5bb9e037c5afe17d1
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/59/863059/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,2707a7ba7c6097e1ecde9127755b7e797e6f4ff1,bug/1995169, - test: 'designate_tempest_plugin.tests.api.v2.test_recordset' deployment: - 'overcloud' releases: - name: master reason: Nameservers list cannot be empty lp: https://bugs.launchpad.net/tripleo/+bug/1995169 jobs: - periodic-tripleo-ci-centos-9-scenario003-standalone-master - test: 'designate_tempest_plugin.tests.api.v2.test_zones' deployment: - 'overcloud' releases: - name: master reason: Nameservers list cannot be empty lp: https://bugs.launchpad.net/tripleo/+bug/1995169 jobs: - periodic-tripleo-ci-centos-9-scenario003-standalone-master,,18,0
openstack%2Ftripleo-quickstart-extras~master~I0bdaa9416f68b9642a78471c0893d12fd6ca1951,openstack/tripleo-quickstart-extras,master,I0bdaa9416f68b9642a78471c0893d12fd6ca1951,Remove pingtest from tripleo-quickstart-extras,ABANDONED,2022-09-29 11:53:32.000000000,2022-11-09 08:34:14.000000000,,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-09-29 11:53:32.000000000', 'files': ['roles/validate-simple/README.md', 'roles/validate-simple/defaults/main.yml', 'roles/validate-simple/templates/overcloud-validate.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a580a5a8e70fee377e5dcdee38a03e64d19d7799', 'message': 'Remove pingtest from tripleo-quickstart-extras\n\nPingtest is no longer supported but is still being executed in some of\nour jobs. Removing it to avoid future issues.\n\nChange-Id: I0bdaa9416f68b9642a78471c0893d12fd6ca1951\n'}]",3,859835,a580a5a8e70fee377e5dcdee38a03e64d19d7799,5,3,1,8367,,,0,"Remove pingtest from tripleo-quickstart-extras

Pingtest is no longer supported but is still being executed in some of
our jobs. Removing it to avoid future issues.

Change-Id: I0bdaa9416f68b9642a78471c0893d12fd6ca1951
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/35/859835/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/validate-simple/README.md', 'roles/validate-simple/defaults/main.yml', 'roles/validate-simple/templates/overcloud-validate.sh.j2']",3,a580a5a8e70fee377e5dcdee38a03e64d19d7799,pingtest,,"## * Create cleanup env function for heat ## :: function cleanup { openstack stack delete --yes {{ validate_stack_name }} if [[ $({{ working_dir }}/wait_for -w 300 -d 30 -s ""Stack not found"" -- ""openstack stack show {{ validate_stack_name }}"") ]]; then echo ""openstack stack delete"" else if [[ $(openstack stack list | grep {{ validate_stack_name }} | grep -i failed) ]]; then openstack stack delete --yes {{ validate_stack_name }} fi fi openstack image list | awk '/pingtest/ {print $2}' | while read IMAGEID; do openstack image delete $IMAGEID; done neutron net-delete {{ public_net_name }} } {% if not skip_pingtest_cleanup %} # trap on exit #nodocs trap cleanup EXIT #nodocs {% endif %} {% if generate_pingtest_subunit|bool %} # Install dependencies for generate_subunit #nodocs sudo yum install -y python-os-testr ## * Start measuring time of test ## :: TEST_START=$(date +%s) {% endif %} {% if generate_pingtest_subunit|bool %} generate-subunit $TEST_START $(( $(date +%s) - TEST_START)) success pingtest > {{ working_dir }}/pingtest.subunit {% endif %}{% if generate_pingtest_subunit|bool %} generate-subunit $TEST_START $(( $(date +%s) - TEST_START)) fail pingtest > {{ working_dir }}/pingtest.subunit {% endif %}",0,40
openstack%2Ftripleo-ansible~master~I668f91d4c3a541720918c56d6f1a5e23aa269024,openstack/tripleo-ansible,master,I668f91d4c3a541720918c56d6f1a5e23aa269024,Remove upper-constraint for role-addition job,ABANDONED,2022-11-08 14:33:48.000000000,2022-11-09 08:10:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-08 14:33:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8c2f921f0cd9200cf0a936becd26d89b5dccc870', 'message': 'Remove cryptography pinning\n\nChange-Id: I668f91d4c3a541720918c56d6f1a5e23aa269024\nRelated-Bug: #1995608\n'}, {'number': 2, 'created': '2022-11-08 15:10:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0a2ed6c0a962372b425bcdc3b418115916286dcf', 'message': ""Remove upper-constraint for role-addition job\n\nWith the cryptography issue, we can't remove the pinning (tried it,\nfailed) - and since now the upper-contraint is pushing for the newer lib\n(38.0.0), it leads to a depdency issue.\n\nRelated-Bug: #1995608\nChange-Id: I668f91d4c3a541720918c56d6f1a5e23aa269024\n""}]",0,864009,0a2ed6c0a962372b425bcdc3b418115916286dcf,6,1,2,28223,,,0,"Remove upper-constraint for role-addition job

With the cryptography issue, we can't remove the pinning (tried it,
failed) - and since now the upper-contraint is pushing for the newer lib
(38.0.0), it leads to a depdency issue.

Related-Bug: #1995608
Change-Id: I668f91d4c3a541720918c56d6f1a5e23aa269024
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/09/864009/1 && git format-patch -1 --stdout FETCH_HEAD,['molecule-requirements.txt'],1,8c2f921f0cd9200cf0a936becd26d89b5dccc870,molecule/cryptography,,cryptography<37.0.0,0,1
openstack%2Fopenstack-tempest-skiplist~master~Ie9340cb51f9bafbb3f39a5d45a571f9c1ef4adef,openstack/openstack-tempest-skiplist,master,Ie9340cb51f9bafbb3f39a5d45a571f9c1ef4adef,Added allowed group featureset067,MERGED,2022-11-07 08:03:24.000000000,2022-11-09 07:56:23.000000000,2022-11-09 07:55:27.000000000,"[{'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 08:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/0b9641751edbed7bd40f882ccf28cb1b1f1dbadf', 'message': 'Added allowed group featureset067\n\nChange-Id: Ie9340cb51f9bafbb3f39a5d45a571f9c1ef4adef\n'}, {'number': 2, 'created': '2022-11-08 14:26:01.000000000', 'files': ['roles/validate-tempest/vars/tempest_allow.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/473fed6e0032151e81ab9ab4264427deb27177c4', 'message': 'Added allowed group featureset067\n\nChange-Id: Ie9340cb51f9bafbb3f39a5d45a571f9c1ef4adef\n'}]",5,863814,473fed6e0032151e81ab9ab4264427deb27177c4,14,3,2,22954,,,0,"Added allowed group featureset067

Change-Id: Ie9340cb51f9bafbb3f39a5d45a571f9c1ef4adef
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/14/863814/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_allow.yml'],1,0b9641751edbed7bd40f882ccf28cb1b1f1dbadf,standalone_ffu, - name: featureset067 tests: - 'tempest.scenario.test_minimum_basic.TestMinimumBasicScenario' - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps' - 'tempest.scenario.test_volume_boot_pattern.TestVolumeBootPattern' releases: - wallaby,,7,0
openstack%2Fopenstack-ansible~master~Ief2588fec57f65a6662a08f05e18b07bcff6b3c2,openstack/openstack-ansible,master,Ief2588fec57f65a6662a08f05e18b07bcff6b3c2,Imported Translations from Zanata,MERGED,2022-11-07 03:06:25.000000000,2022-11-09 07:40:12.000000000,2022-11-09 07:38:58.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-11-07 03:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a69dba4030a5d46335860e75f1e7b05ac6516914', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ief2588fec57f65a6662a08f05e18b07bcff6b3c2\n'}, {'number': 2, 'created': '2022-11-09 02:24:08.000000000', 'files': ['doc/source/locale/ru/LC_MESSAGES/doc.po', 'doc/source/locale/id/LC_MESSAGES/doc-reference.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/es/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc-reference.po', 'doc/source/locale/id/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-admin.po', 'doc/source/locale/fr/LC_MESSAGES/doc.po'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bfa8f192cc221cbb399e65d791e7d13eeee78753', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ief2588fec57f65a6662a08f05e18b07bcff6b3c2\n'}]",0,863784,bfa8f192cc221cbb399e65d791e7d13eeee78753,10,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ief2588fec57f65a6662a08f05e18b07bcff6b3c2
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/84/863784/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/locale/id/LC_MESSAGES/doc-reference.po', 'doc/source/locale/de/LC_MESSAGES/doc-reference.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-admin.po']",3,a69dba4030a5d46335860e75f1e7b05ac6516914,zanata/translations,"""Project-Id-Version: openstack-ansible 25.1.0.dev103\n""""POT-Creation-Date: 2022-10-31 17:20+0000\n""""PO-Revision-Date: 2022-11-07 02:47+0000\n""msgid ""(* because we need to include containers in the limit)"" msgstr ""(* because we need to include containers in the limit)"" msgid ""Clearing out stale information"" msgstr ""Clearing out stale information"" msgid ""Deploying Infrastructure Hosts"" msgstr ""Deploying Infrastructure Hosts"" msgid ""Disable HAProxy back ends (optional)"" msgstr ""Disable HAProxy back ends (optional)"" msgid ""Drain RabbitMQ connections (optional)"" msgstr ""Drain RabbitMQ connections (optional)"" msgid """" ""During the upgrade process, some OpenStack services cannot be deployed by "" ""using Ansible's '--limit'. As such, it will be necessary to deploy some "" ""services to mixed operating system versions at the same time."" msgstr """" ""During the upgrade process, some OpenStack services cannot be deployed by "" ""using Ansible's '--limit'. As such, it will be necessary to deploy some "" ""services to mixed operating system versions at the same time."" msgid """" ""Everything should be sync'ed and in order now. You can take your primary "" ""Galera from MAINT to READY"" msgstr """" ""Everything should be sync'ed and in order now. You can take your primary "" ""Galera from MAINT to READY"" msgid """" ""Everything should now be in a working state and we can finish it off with"" msgstr """" ""Everything should now be in a working state and we can finish it off with"" msgid ""If it IS a 'primary', do these steps"" msgstr ""If it IS a 'primary', do these steps"" msgid """" ""If you wish to minimise error states in HAProxy, services on hosts which are "" ""being reinstalled can be set in maintenance mode (MAINT)."" msgstr """" ""If you wish to minimise error states in HAProxy, services on hosts which are "" ""being reinstalled can be set in maintenance mode (MAINT)."" ""In order to cleanly hand over connections from one member of the RabbitMQ "" ""cluster to another, the instance being reinstalled should be drained. This "" ""can be achieved by running the following from the instance to be reinstalled "" ""and waiting for the RabbitMQ admin interface to indicate that socket "" ""descriptors have reduced to zero."" msgstr """" ""In order to cleanly hand over connections from one member of the RabbitMQ "" ""cluster to another, the instance being reinstalled should be drained. This "" ""can be achieved by running the following from the instance to be reinstalled "" ""and waiting for the RabbitMQ admin interface to indicate that socket "" ""descriptors have reduced to zero."" msgid """"""In the same way as OpenStack Ansible major (and some minor) upgrades, there "" ""will be brief interruptions to the entire Galera and RabbitMQ clusters "" ""during the upgrade which will result in brief service interruptions."" msgstr """" ""In the same way as OpenStack Ansible major (and some minor) upgrades, there "" ""will be brief interruptions to the entire Galera and RabbitMQ clusters "" ""during the upgrade which will result in brief service interruptions."" msgid """"msgid ""Keystone"" msgstr ""Keystone"" ""Note that at this point, the Ansible role will have taken the primary Galera "" ""out of MAINT in HAProxy. You may wish to temporarily put it back into MAINT "" ""until you are sure it is working correctly."" msgstr """" ""Note that at this point, the Ansible role will have taken the primary Galera "" ""out of MAINT in HAProxy. You may wish to temporarily put it back into MAINT "" ""until you are sure it is working correctly."" msgid """"msgid ""RabbitMQ"" msgstr ""RabbitMQ"" msgid ""Removing stale ansible-facts"" msgstr ""Removing stale ansible-facts"" msgid ""Repo Server"" msgstr ""Repo Server"" msgid ""Temporarily set your primary Galera in MAINT in HAProxy"" msgstr ""Temporarily set your primary Galera in MAINT in HAProxy"" ""The RabbitMQ primary will also be in a cluster of it's own. You will need to "" ""fix this by running these commands on the primary."" msgstr """" ""The RabbitMQ primary will also be in a cluster of its own. You will need to "" ""fix this by running these commands on the primary."" msgid """" ""The SSH certificate authority must be updated for the upgraded release "" ""version. SSH certificates are used for nova live migration and keystone "" ""credential synchonrisation in the new release. This step ensures that the "" ""required CA is generated and available for other playbooks."" msgstr """" ""The SSH certificate authority must be updated for the upgraded release "" ""version. SSH certificates are used for nova live migration and keystone "" ""credential synchronisation in the new release. This step ensures that the "" ""required CA is generated and available for other playbooks."" msgid """"msgid ""The following services are known to lack support for '--limit':"" msgstr ""The following services are known to lack support for '--limit':"" msgid """" ""Update user_variables to set overrides for the location of any existing "" ""Ocatavia certificates."" msgstr """" ""Update user_variables to set overrides for the location of any existing "" ""Octavia certificates."" msgid ""Warnings"" msgstr ""Warnings"" msgid ""We can move on to RabbitMQ primary"" msgstr ""We can move on to RabbitMQ primary"" ""When taking down 'memcached' instances for upgrades you may encounter "" ""performance issues with the APIs."" msgstr """" ""When taking down 'memcached' instances for upgrades you may encounter "" ""performance issues with the APIs."" msgid """"msgid """" ""You'll now have mariadb running, but it's not synced info from the non-"" ""primaries. To fix this we ssh to the primary Galera, and restart the mariadb."" ""service and verify everything is in order."" msgstr """" ""You'll now have MariaDB running, but it's not synced info from the non-"" ""primaries. To fix this we ssh to the primary Galera, and restart the mariadb."" ""service and verify everything is in order."" ","""Project-Id-Version: openstack-ansible 25.1.0.dev68\n""""POT-Creation-Date: 2022-09-12 14:13+0000\n""""PO-Revision-Date: 2022-09-10 01:59+0000\n""",149,31
openstack%2Fkolla~master~Ie3b4e4461dbfe35808250a929b3e95f880242aed,openstack/kolla,master,Ie3b4e4461dbfe35808250a929b3e95f880242aed,Update stable release generation doc,MERGED,2022-11-04 10:28:25.000000000,2022-11-09 07:08:02.000000000,2022-11-09 07:07:02.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2022-11-04 10:28:25.000000000', 'files': ['doc/source/contributor/release-management.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/83c1879877b86a8782166c3e01b547e29a123b8e', 'message': ""Update stable release generation doc\n\nWallaby has been moved to EM state, so it will receive no more releases.\nAlso, being optimistic, zed is already being added to the list of stable\nbranches, so we don't forget it when we actually cut that branch.\n\nAdd a small note about this being referenced once per month in regular\nKolla meetings. Also update the example link to a patch that actually\nmatches the description.\n\nChange-Id: Ie3b4e4461dbfe35808250a929b3e95f880242aed\n""}]",1,863633,83c1879877b86a8782166c3e01b547e29a123b8e,7,2,1,13252,,,0,"Update stable release generation doc

Wallaby has been moved to EM state, so it will receive no more releases.
Also, being optimistic, zed is already being added to the list of stable
branches, so we don't forget it when we actually cut that branch.

Add a small note about this being referenced once per month in regular
Kolla meetings. Also update the example link to a patch that actually
matches the description.

Change-Id: Ie3b4e4461dbfe35808250a929b3e95f880242aed
",git fetch https://review.opendev.org/openstack/kolla refs/changes/33/863633/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/release-management.rst'],1,83c1879877b86a8782166c3e01b547e29a123b8e,update-stable-release-docs,than once every 45 days. We try to make one release per month by having a recurring topic for that in the first Kolla meeting each month. for rel in xena yoga zed; do for rel in yoga zed; do tox -e venv -- new-release $rel ansible-collection-kolla feature done * example release patch: https://review.opendev.org/c/openstack/releases/+/860521,than once every 45 days. for rel in wallaby xena yoga; do * example release patch (kolla): https://review.opendev.org/650411 * example release patch (kolla-ansible): https://review.opendev.org/650412,7,5
openstack%2Fkolla~master~I4f153a619eb57a75ebdb1aba4b71e422b30d74fe,openstack/kolla,master,I4f153a619eb57a75ebdb1aba4b71e422b30d74fe,docs: when reno is required,MERGED,2022-10-20 12:07:45.000000000,2022-11-09 06:49:57.000000000,2022-11-09 06:48:56.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 27339}, {'_account_id': 32761}, {'_account_id': 34533}]","[{'number': 1, 'created': '2022-10-20 12:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9de3dff45e671a23114f54a33d6ef114ab7751f2', 'message': 'docs: when reno is required\n\nIn Zed PTG we decided to limit the amount of release notes\nthis change adds the criteria when reno is required to the docs\n\n[1]: https://etherpad.opendev.org/p/kolla-zed-ptg#L149\n\nChange-Id: I4f153a619eb57a75ebdb1aba4b71e422b30d74fe\n'}, {'number': 2, 'created': '2022-10-28 06:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e382e4f7c7008f723d2b65fafc100f9bf30519e0', 'message': 'docs: when reno is required\n\nIn Zed PTG we decided to limit the amount of release notes\nthis change adds the criteria when reno is required to the docs\n\n[1]: https://etherpad.opendev.org/p/kolla-zed-ptg#L149\n\nChange-Id: I4f153a619eb57a75ebdb1aba4b71e422b30d74fe\n'}, {'number': 3, 'created': '2022-10-28 06:12:06.000000000', 'files': ['doc/source/contributor/release-notes.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/397a9a33e86dbf235d9c888f237ce6377e4828de', 'message': 'docs: when reno is required\n\nIn Zed PTG we decided to limit the amount of release notes\nthis change adds the criteria when reno is required to the docs\n\n[1]: https://etherpad.opendev.org/p/kolla-zed-ptg#L149\n\nChange-Id: I4f153a619eb57a75ebdb1aba4b71e422b30d74fe\n'}]",7,862106,397a9a33e86dbf235d9c888f237ce6377e4828de,16,7,3,22629,,,0,"docs: when reno is required

In Zed PTG we decided to limit the amount of release notes
this change adds the criteria when reno is required to the docs

[1]: https://etherpad.opendev.org/p/kolla-zed-ptg#L149

Change-Id: I4f153a619eb57a75ebdb1aba4b71e422b30d74fe
",git fetch https://review.opendev.org/openstack/kolla refs/changes/06/862106/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/release-notes.rst'],1,9de3dff45e671a23114f54a33d6ef114ab7751f2,,When a release note is required: - ``feature`` - best included with docs change (if separate from the code) - ``user impacting`` - to improve visibility of the change for users ,,5,0
openstack%2Fneutron~master~I7c03bac9c6e8dd074325f511e555c10fec8e77fc,openstack/neutron,master,I7c03bac9c6e8dd074325f511e555c10fec8e77fc,test: fix docstring validation function,MERGED,2022-11-07 12:21:17.000000000,2022-11-09 05:02:51.000000000,2022-11-07 16:24:24.000000000,"[{'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 12:21:17.000000000', 'files': ['neutron/tests/functional/db/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/609ebd950421e14153df6e05a51aab73d99144e2', 'message': 'test: fix docstring validation function\n\nFor some reason in Python even if using getattr with None and as\ndefault value a string for the type __doc__ will return None.\n\n>>> type(getattr(None, ""__doc__"", """"))\n<class \'NoneType\'>\n\nThe error reported was:\n\nft1.1: neutron.tests.functional.db.test_migrations.TestModelsMigrationsMySQL.test_branchestesttools.testresult.real._StringException: Traceback (most recent call last):\n  File ""/home/zuul/src/opendev.org/openstack/neutron/neutron/tests/base.py"", line 182, in func\n    return f(self, *args, **kwargs)\n  File ""/home/zuul/src/opendev.org/openstack/neutron/neutron/tests/functional/db/test_migrations.py"", line 302, in test_branches\n    find_migration_exceptions()\n  File ""/home/zuul/src/opendev.org/openstack/neutron/neutron/tests/functional/db/test_migrations.py"", line 253, in find_migration_exceptions\n    if len(explanation) < 1:\nTypeError: object of type \'NoneType\' has no len()\n\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@industrialdiscipline.com>\nChange-Id: I7c03bac9c6e8dd074325f511e555c10fec8e77fc\n'}]",0,863870,609ebd950421e14153df6e05a51aab73d99144e2,10,4,1,7730,,,0,"test: fix docstring validation function

For some reason in Python even if using getattr with None and as
default value a string for the type __doc__ will return None.

>>> type(getattr(None, ""__doc__"", """"))
<class 'NoneType'>

The error reported was:

ft1.1: neutron.tests.functional.db.test_migrations.TestModelsMigrationsMySQL.test_branchestesttools.testresult.real._StringException: Traceback (most recent call last):
  File ""/home/zuul/src/opendev.org/openstack/neutron/neutron/tests/base.py"", line 182, in func
    return f(self, *args, **kwargs)
  File ""/home/zuul/src/opendev.org/openstack/neutron/neutron/tests/functional/db/test_migrations.py"", line 302, in test_branches
    find_migration_exceptions()
  File ""/home/zuul/src/opendev.org/openstack/neutron/neutron/tests/functional/db/test_migrations.py"", line 253, in find_migration_exceptions
    if len(explanation) < 1:
TypeError: object of type 'NoneType' has no len()

Signed-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@industrialdiscipline.com>
Change-Id: I7c03bac9c6e8dd074325f511e555c10fec8e77fc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/863870/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/db/test_migrations.py'],1,609ebd950421e14153df6e05a51aab73d99144e2,, if not explanation:, if len(explanation) < 1:,1,1
openstack%2Ftripleo-heat-templates~master~I47782e418ee92741c23193244c1fa1c660206024,openstack/tripleo-heat-templates,master,I47782e418ee92741c23193244c1fa1c660206024,Add handling for OVN Multi-RHEL,ABANDONED,2022-06-30 02:41:32.000000000,2022-11-09 04:39:04.000000000,,"[{'_account_id': 6681}, {'_account_id': 8297}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 34271}]","[{'number': 1, 'created': '2022-06-30 02:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6237f9cda2070bfa3d9ec736e3d3e35890467885', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\ndepends-on: https://review.opendev.org/c/openstack/tripleo-ansible/+/845653/\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 2, 'created': '2022-06-30 03:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/617a843badae778f8d4f92b65f22ee1a3fa1fc4f', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\ndepends-on: https://review.opendev.org/c/openstack/tripleo-ansible/+/845653/\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 3, 'created': '2022-06-30 03:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c9155a29bc1877eb37b61acff18c51b54f4c3eb6', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\ndepends-on: https://review.opendev.org/c/openstack/tripleo-ansible/+/845653/\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 4, 'created': '2022-06-30 12:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c089b7efd9d551f3eb4d02abe1976dbbfb22a2be', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\ndepends-on: https://review.opendev.org/c/openstack/tripleo-ansible/+/845653/\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 5, 'created': '2022-06-30 12:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/62d1f6f2e5ad4a41515b4131a3d9a8e322036555', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\ndepends-on: https://review.opendev.org/c/openstack/tripleo-ansible/+/845653/\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 6, 'created': '2022-07-06 01:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7e515685d46b6c82ab8f0368e02eb1b899043520', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\ndepends-on: https://review.opendev.org/c/openstack/tripleo-ansible/+/845653/\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 7, 'created': '2022-07-06 08:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f49f71ad0d8c0cfd73d271b119a531e681706f7', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 8, 'created': '2022-07-06 09:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f84708b9fced097add790c117f768a4a212302e', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\n'}, {'number': 9, 'created': '2022-07-07 17:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f73bdace1dfbffbbe7148413c48a8f6d9cc966f2', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 10, 'created': '2022-07-07 17:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6cf81debc9302ef0176ce9048d98abca961e141e', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 11, 'created': '2022-07-18 04:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87705f7058901185187c285ef127421e9bb9dfbe', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameter:\nContainerOvnControllerImages\n\nThis parameter accepts a dictionary like:\nContainerOvnControllerImages: {""8"": ""rhel8-image-url"", ""9"":\n""rhel9-image-url""}\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 12, 'created': '2022-07-18 05:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f2acb3457acc04580d86550483dce5353d1f37b7', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 13, 'created': '2022-07-18 06:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0dc93383ee8521473070e12f934e1fa365312d96', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 14, 'created': '2022-07-18 07:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8285cfd887444e833f800d18b16a858e42b5e0ba', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 15, 'created': '2022-07-18 12:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/53845b32a4fb6bb1855af950356935d5b3ad50d3', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe then use tripleo-ansible to select the correct image from the URL.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n'}, {'number': 16, 'created': '2022-07-19 02:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9e0309ea81db81de1335989940be18135d8d1bb', 'message': ""Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe set each of these images as a key/value pair in the\nContainerOvnControllerImage and ContainerOvnControllerConfigImage\nvalues like so:\n\n        ContainerOvnControllerImage:\n          '9': {get_param: ContainerOvnControllerImage9}\n          '8': {get_param: ContainerOvnControllerImage8}\n        ContainerOvnControllerConfigImage:\n          '9': {get_param: ContainerOvnControllerConfigImage9}\n          '8': {get_param: ContainerOvnControllerConfigImage8}\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n""}, {'number': 17, 'created': '2022-07-19 04:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/367b705ecf17bc8e731b3c9ba7ca3f84d35f8f22', 'message': ""Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe set each of these images as a key/value pair in the\nContainerOvnControllerImage and ContainerOvnControllerConfigImage\nvalues like so:\n\n        ContainerOvnControllerImage:\n          '9': {get_param: ContainerOvnControllerImage9}\n          '8': {get_param: ContainerOvnControllerImage8}\n        ContainerOvnControllerConfigImage:\n          '9': {get_param: ContainerOvnControllerConfigImage9}\n          '8': {get_param: ContainerOvnControllerConfigImage8}\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n""}, {'number': 18, 'created': '2022-07-19 04:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d17b7ed99a895a9a01b5860a5a4970395942fcf9', 'message': ""Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe set each of these images as a key/value pair in the\nContainerOvnControllerImage and ContainerOvnControllerConfigImage\nvalues like so:\n\n        ContainerOvnControllerImage:\n          '9': {get_param: ContainerOvnControllerImage9}\n          '8': {get_param: ContainerOvnControllerImage8}\n        ContainerOvnControllerConfigImage:\n          '9': {get_param: ContainerOvnControllerConfigImage9}\n          '8': {get_param: ContainerOvnControllerConfigImage8}\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n""}, {'number': 19, 'created': '2022-07-19 05:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8ab36de4a9de119f0c1501f74f74b9883ac4ae37', 'message': ""Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerImage9\nContainerOvnControllerConfigImage8\nContainerOvnControllerConfigImage9\n\nWe set each of these images as a key/value pair in the\nContainerOvnControllerImage and ContainerOvnControllerConfigImage\nvalues like so:\n\n        ContainerOvnControllerImage:\n          '9': {get_param: ContainerOvnControllerImage9}\n          '8': {get_param: ContainerOvnControllerImage8}\n        ContainerOvnControllerConfigImage:\n          '9': {get_param: ContainerOvnControllerConfigImage9}\n          '8': {get_param: ContainerOvnControllerConfigImage8}\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-heat-templates/+/848960\n""}, {'number': 20, 'created': '2022-07-19 12:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca616e2cbc8be5c9c2b5197cb195aee64cac3ed7', 'message': ""Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerConfigImage8\n\nWe set each of these images as a key/value pair in the\nOvnControllerImages and OvnControllerConfigImages\nvalues like so:\n\n        OvnControllerImages:\n          'default': {get_param: ContainerOvnControllerImage}\n          '8': {get_param: ContainerOvnControllerImage8}\n        OvnControllerConfigImages:\n          'default': {get_param: ContainerOvnControllerConfigImage}\n          '8': {get_param: ContainerOvnControllerConfigImage8}\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n""}, {'number': 21, 'created': '2022-07-19 12:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/90f9615265f120e9e6a06079db7940381a44ff25', 'message': ""Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change adds a new parameters:\nContainerOvnControllerImage8\nContainerOvnControllerConfigImage8\n\nWe set each of these images as a key/value pair in the\nOvnControllerImages and OvnControllerConfigImages\nvalues like so:\n\n        OvnControllerImages:\n          'default': {get_param: ContainerOvnControllerImage}\n          '8': {get_param: ContainerOvnControllerImage8}\n        OvnControllerConfigImages:\n          'default': {get_param: ContainerOvnControllerConfigImage}\n          '8': {get_param: ContainerOvnControllerConfigImage8}\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n""}, {'number': 22, 'created': '2022-07-27 23:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4c2654515772dc81c0e24efca3eac3c0ed3deaf8', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change modifys the ContainerOvnControllerimage\nand ContainerOvnControllerConfigImage parameters to\nallow for a dictionary instead of a string. Then we\ntemplate out the docker_config to selectively use\nthe correct image based on the Host OS.\n\nThese values are generated as key/value pairs during\nContainer Image Prepare step provided by this change:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/850131\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n'}, {'number': 23, 'created': '2022-08-07 23:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3f70b4c3db05a3574eb7f1e28de12553d691b8f3', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change modifys the ContainerOvnControllerimage\nand ContainerOvnControllerConfigImage parameters to\nallow for a dictionary instead of a string. Then we\ntemplate out the docker_config to selectively use\nthe correct image based on the Host OS.\n\nThese values are generated as key/value pairs during\nContainer Image Prepare step provided by this change:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/850131\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n'}, {'number': 24, 'created': '2022-08-22 01:43:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e665b0157be16caebae5e110d10294d7188b1bd2', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change modifys the ContainerOvnControllerimage\nand ContainerOvnControllerConfigImage parameters to\nallow for a dictionary instead of a string. Then we\ntemplate out the docker_config to selectively use\nthe correct image based on the Host OS.\n\nThese values are generated as key/value pairs during\nContainer Image Prepare step provided by this change:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/850131\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n'}, {'number': 25, 'created': '2022-08-22 01:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2e218638d71224df08dd6b0b33a3a60fdb026cd4', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change modifys the ContainerOvnControllerimage\nand ContainerOvnControllerConfigImage parameters to\nallow for a dictionary instead of a string. Then we\ntemplate out the docker_config to selectively use\nthe correct image based on the Host OS.\n\nThese values are generated as key/value pairs during\nContainer Image Prepare step provided by this change:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/850131\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n'}, {'number': 26, 'created': '2022-08-22 02:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b1873cefa982b37346c6c731dae5cefe7f584ea', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change modifys the ContainerOvnControllerimage\nand ContainerOvnControllerConfigImage parameters to\nallow for a dictionary instead of a string. Then we\ntemplate out the docker_config to selectively use\nthe correct image based on the Host OS.\n\nThese values are generated as key/value pairs during\nContainer Image Prepare step provided by this change:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/850131\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n'}, {'number': 27, 'created': '2022-08-22 04:44:51.000000000', 'files': ['deployment/ovn/ovn-controller-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3df0afe0c301d4cbda3aa36d31389065f3eda7f5', 'message': 'Add handling for OVN Multi-RHEL\n\nIn a Multi-RHEL environment, we need to selectively\nchoose the correct container image to match the host\nOS. This change modifys the ContainerOvnControllerimage\nand ContainerOvnControllerConfigImage parameters to\nallow for a dictionary instead of a string. Then we\ntemplate out the docker_config to selectively use\nthe correct image based on the Host OS.\n\nThese values are generated as key/value pairs during\nContainer Image Prepare step provided by this change:\nhttps://review.opendev.org/c/openstack/tripleo-common/+/850131\n\nWe then use tripleo-ansible to select the correct image for the node\nbased on the OS of the specific node.\n\nChange-Id: I47782e418ee92741c23193244c1fa1c660206024\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131\n'}]",55,848208,3df0afe0c301d4cbda3aa36d31389065f3eda7f5,101,7,27,30073,,,0,"Add handling for OVN Multi-RHEL

In a Multi-RHEL environment, we need to selectively
choose the correct container image to match the host
OS. This change modifys the ContainerOvnControllerimage
and ContainerOvnControllerConfigImage parameters to
allow for a dictionary instead of a string. Then we
template out the docker_config to selectively use
the correct image based on the Host OS.

These values are generated as key/value pairs during
Container Image Prepare step provided by this change:
https://review.opendev.org/c/openstack/tripleo-common/+/850131

We then use tripleo-ansible to select the correct image for the node
based on the OS of the specific node.

Change-Id: I47782e418ee92741c23193244c1fa1c660206024
Depends-On: https://review.opendev.org/c/openstack/tripleo-common/+/850131
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/848208/25 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml']",2,6237f9cda2070bfa3d9ec736e3d3e35890467885,multi-rhel, ansible_group_vars: tripleo_enable_dvr: {get_param: NeutronEnableDVR},,33,1
openstack%2Ffreezer-web-ui~master~Idfb87da968f303a2b86d658c2231b9ea14ba5dd6,openstack/freezer-web-ui,master,Idfb87da968f303a2b86d658c2231b9ea14ba5dd6,Switch to 2023.1 Python3 unit tests and generic template name,NEW,2022-09-13 12:16:04.000000000,2022-11-09 04:15:56.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-13 12:16:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/8bc6df364ab1e927e5b258d879349781bd48f8dd', 'message': 'Switch to 2023.1 Python3 unit tests and generic template name\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope. Also,\nupdating the template name to generic one.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: Idfb87da968f303a2b86d658c2231b9ea14ba5dd6\n'}]",2,857354,8bc6df364ab1e927e5b258d879349781bd48f8dd,6,2,1,22816,,,0,"Switch to 2023.1 Python3 unit tests and generic template name

This is an automatically generated patch to ensure unit testing
is in place for all the of the tested runtimes for antelope. Also,
updating the template name to generic one.

See also the PTI in governance [1].

[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html

Change-Id: Idfb87da968f303a2b86d658c2231b9ea14ba5dd6
",git fetch https://review.opendev.org/openstack/freezer-web-ui refs/changes/54/857354/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,8bc6df364ab1e927e5b258d879349781bd48f8dd,add-antelope-python-jobtemplates, - openstack-python3-jobs, - openstack-python3-zed-jobs,1,1
openstack%2Ffreezer-web-ui~stable%2Fzed~Ifc3af6480b494a62c5f774b8892646b76599b949,openstack/freezer-web-ui,stable/zed,Ifc3af6480b494a62c5f774b8892646b76599b949,Imported Translations from Zanata,NEW,2022-10-06 03:28:39.000000000,2022-11-09 03:35:27.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-10-06 03:28:39.000000000', 'files': ['disaster_recovery/locale/zh_Hans/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/0f3929834901fcf3cb1fd39fac8c3f6f95b75b3b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ifc3af6480b494a62c5f774b8892646b76599b949\n'}]",0,860515,0f3929834901fcf3cb1fd39fac8c3f6f95b75b3b,3,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ifc3af6480b494a62c5f774b8892646b76599b949
",git fetch https://review.opendev.org/openstack/freezer-web-ui refs/changes/15/860515/1 && git format-patch -1 --stdout FETCH_HEAD,['disaster_recovery/locale/zh_Hans/LC_MESSAGES/django.po'],1,0f3929834901fcf3cb1fd39fac8c3f6f95b75b3b,zanata/translations,"# Jimmy Li <ljzljm@163.com>, 2021. #zanata""POT-Creation-Date: 2022-05-09 01:26+0000\n""""PO-Revision-Date: 2021-09-10 01:08+0000\n"" ""Last-Translator: Jimmy Li <ljzljm@163.com>\n""msgid ""Advanced configuration"" msgstr ""高级配置"" msgid ""Container Name or Path"" msgstr ""容器名称或路径"" msgid ""Days"" msgstr ""日"" msgid ""Delete Backup"" msgid_plural ""Delete Backups"" msgstr[0] ""删除备份"" msgid ""Delete Job File"" msgid_plural ""Delete Job Files"" msgstr[0] ""删除任务文件"" msgid ""Delete Session"" msgid_plural ""Delete Sessions"" msgstr[0] ""删除Session"" msgid ""Delete backups is not recoverable."" msgstr ""删除备份是不可恢复的。"" msgid ""Deleted Backup"" msgid_plural ""Deleted Backups"" msgstr[0] ""已删除的备份"" msgid ""Deleted Job File"" msgid_plural ""Deleted Job Files"" msgstr[0] ""已删除的任务文件"" msgid ""Hours"" msgstr ""小时"" msgid ""Job"" msgstr ""任务"" msgid ""Minutes"" msgstr ""分"" msgid ""Nova network ID *"" msgstr ""Nova 网络ID *"" msgid ""Please choose a interval unit"" msgstr ""请选择间隔单位"" msgid ""Seconds"" msgstr ""秒"" msgid ""Weeks"" msgstr ""周"" msgid ""nova"" msgstr ""nova"" msgid ""rsync"" msgstr ""rsync"" msgid ""tar"" msgstr ""tar"" ","""POT-Creation-Date: 2021-02-17 01:26+0000\n""""PO-Revision-Date: 2016-09-05 03:42+0000\n"" ""Last-Translator: howard lee <howard@mail.ustc.edu.cn>\n""",66,3
openstack%2Fneutron~master~Ic131cd49307471982b8bd09f823809261d246c0d,openstack/neutron,master,Ic131cd49307471982b8bd09f823809261d246c0d,Fix some pylint indentation warnings,MERGED,2022-11-04 17:29:55.000000000,2022-11-09 00:54:17.000000000,2022-11-07 12:28:02.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 17:29:55.000000000', 'files': ['neutron/scheduler/l3_ovn_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f77c7c9584caa4e7dd14099f5566a3411bc2e2ed', 'message': 'Fix some pylint indentation warnings\n\nRunning with a stricter .pylintrc generates a lot of\nC0330 warnings (hanging/continued indentation). Fix\nthe ones in neutron/scheduler.\n\nTrivialfix\n\nChange-Id: Ic131cd49307471982b8bd09f823809261d246c0d\n'}]",0,863674,f77c7c9584caa4e7dd14099f5566a3411bc2e2ed,10,4,1,1131,,,0,"Fix some pylint indentation warnings

Running with a stricter .pylintrc generates a lot of
C0330 warnings (hanging/continued indentation). Fix
the ones in neutron/scheduler.

Trivialfix

Change-Id: Ic131cd49307471982b8bd09f823809261d246c0d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/863674/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/scheduler/l3_ovn_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py']",2,f77c7c9584caa4e7dd14099f5566a3411bc2e2ed,pylint-c0330-scheduler," context, dhcp_agent_id=agent_id, network_id=network_id, binding_index=binding_index).create() plugin, context, network)"," context, dhcp_agent_id=agent_id, network_id=network_id, binding_index=binding_index).create() plugin, context, network)",7,6
openstack%2Fneutron~master~I168f836b665ec852c03a03e815cb4134ac36879a,openstack/neutron,master,I168f836b665ec852c03a03e815cb4134ac36879a,Refactor generate address pools by cidr,ABANDONED,2022-10-21 04:21:24.000000000,2022-11-08 23:32:46.000000000,,"[{'_account_id': 8313}, {'_account_id': 22348}, {'_account_id': 33543}]","[{'number': 1, 'created': '2022-10-21 04:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/57e5e13b7cf4a7a87aa141e7cb8aca2eb1bbbc37', 'message': 'Refactor generate address pools by cidr\n\nChange-Id: I168f836b665ec852c03a03e815cb4134ac36879a\n'}, {'number': 2, 'created': '2022-10-24 14:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff8c0c54a5a2a5fdf68c7602261502df0158a54d', 'message': 'Refactor generate address pools by cidr\n\nChange-Id: I168f836b665ec852c03a03e815cb4134ac36879a\n'}, {'number': 3, 'created': '2022-10-28 02:52:43.000000000', 'files': ['neutron/ipam/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/848db1464b42229c4afbf0ba3d6f676a69d4ae91', 'message': 'Refactor generate address pools by cidr\n\nChange-Id: I168f836b665ec852c03a03e815cb4134ac36879a\n'}]",6,862217,848db1464b42229c4afbf0ba3d6f676a69d4ae91,30,3,3,33543,,,0,"Refactor generate address pools by cidr

Change-Id: I168f836b665ec852c03a03e815cb4134ac36879a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/862217/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/ipam/utils.py'],1,57e5e13b7cf4a7a87aa141e7cb8aca2eb1bbbc37,," hosts = list(net.iter_hosts()) ipset = netaddr.IPSet(netaddr.IPRange(hosts[0], hosts[-1]))"," if ip_version == constants.IP_VERSION_4: if net.prefixlen <= 30: first_ip = first + 1 # last address is broadcast in v4 last_ip = last - (ip_version == 4) else: first_ip = first last_ip = last else: # IPv6 case first_ip = first + 1 last_ip = last ipset = netaddr.IPSet(netaddr.IPRange(first_ip, last_ip))",2,12
openstack%2Fopenstack-ansible~master~I758ba683c150ec0c2ab1903f3ff5304e5264a368,openstack/openstack-ansible,master,I758ba683c150ec0c2ab1903f3ff5304e5264a368,Switch master branch to track stable/zed,MERGED,2022-10-06 11:21:49.000000000,2022-11-08 22:46:07.000000000,2022-11-08 22:44:41.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-06 11:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/734d31663c2cf5b3a8737b32e46dfb9f82c79ee5', 'message': 'Switch master branch to track stable/zed\n\nSince stable/zed has been released, we need to track this branch\nwhen deploying services to ensure our code does work with the release.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_nova/+/860540\nChange-Id: I758ba683c150ec0c2ab1903f3ff5304e5264a368\n'}, {'number': 2, 'created': '2022-10-25 08:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ac337e37ddb0972ca3b0cc72ed5e24d2fa680130', 'message': 'Switch master branch to track stable/zed\n\nSince stable/zed has been released, we need to track this branch\nwhen deploying services to ensure our code does work with the release.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_nova/+/860540\nChange-Id: I758ba683c150ec0c2ab1903f3ff5304e5264a368\n'}, {'number': 3, 'created': '2022-10-25 08:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8aed0fbfbb98fcc8b4510e41e2783ddcb46ea393', 'message': 'Switch master branch to track stable/zed\n\nSince stable/zed has been released, we need to track this branch\nwhen deploying services to ensure our code does work with the release.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_nova/+/860540\nChange-Id: I758ba683c150ec0c2ab1903f3ff5304e5264a368\n'}, {'number': 4, 'created': '2022-10-25 11:02:24.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bc6378ba3f144f94bcca0ca061b67e6bd9c12773', 'message': 'Switch master branch to track stable/zed\n\nSince stable/zed has been released, we need to track this branch\nwhen deploying services to ensure our code does work with the release.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_nova/+/860540\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_neutron/+/862594\nChange-Id: I758ba683c150ec0c2ab1903f3ff5304e5264a368\n'}]",3,860549,bc6378ba3f144f94bcca0ca061b67e6bd9c12773,19,3,4,28619,,,0,"Switch master branch to track stable/zed

Since stable/zed has been released, we need to track this branch
when deploying services to ensure our code does work with the release.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_nova/+/860540
Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-os_neutron/+/862594
Change-Id: I758ba683c150ec0c2ab1903f3ff5304e5264a368
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/49/860549/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml']",4,734d31663c2cf5b3a8737b32e46dfb9f82c79ee5,,### HEAD as of 06.10.2022 ###tempest_git_install_branch: f1d0e395e95d3502a9c3904ce56520d116e6bf48tempest_plugin_barbican_git_install_branch: a32eaf0dd8a4cd1825f69b97dc7ac51519ec07d7tempest_plugin_cinder_git_install_branch: 89823d9868a58da23bbc0c8d9020b0adaafda32btempest_plugin_designate_git_install_branch: 6c251b44c57f8d08d45468ef00a5c4d53a9c923btempest_plugin_heat_git_install_branch: 4196ac5992b5e63ac97dd0f990278c37b17d6c6etempest_plugin_ironic_git_install_branch: a2c26c6ddf0c764d2cffca16f8597fe5a9084050tempest_plugin_keystone_git_install_branch: 7f43a203803248854f8213c91ae61c04d33d57f3tempest_plugin_magnum_git_install_branch: 462da994612a2fb49067a62e3fa640871d492fb3tempest_plugin_manila_git_install_branch: e344e37d62caf65da9b8e1ba7a6bc925cfded7fctempest_plugin_neutron_git_install_branch: 3ff8300038266f851b2abbb2c9498357fb6a76cftempest_plugin_novajoin_git_install_branch: 0df7e1c6b58ba108fcd38a0b5ea4e4f45e87a05dtempest_plugin_octavia_git_install_branch: 031ecca5132c8491e55d93a9ff88c670fccd7983tempest_plugin_senlin_git_install_branch: e4829f056c58c162ca8bc78f0bca998bfee64e43tempest_plugin_telemetry_git_install_branch: 60633b244fb4500115965e30a0e512ffaf256a6ctempest_plugin_zun_git_install_branch: e8be4c7b08dd79da12d7c8962fb94c8f2ec4bc09rally_openstack_git_install_branch: ba45f16ef1245757a9e275df5cfa28b8dd954016,### HEAD as of 23.06.2022 ###tempest_git_install_branch: 7559bb649e11377c8cba4e7a6129025a7d3d5d06tempest_plugin_barbican_git_install_branch: 11c8cfae0ce85b874ab055e685accba85f460fdatempest_plugin_cinder_git_install_branch: 141dace60e5e4d14bf39b65872a4c9db63ba8df4tempest_plugin_designate_git_install_branch: 6d5e0a1406070667f97718e98dfe21dbc95b3d98tempest_plugin_heat_git_install_branch: ba43685c131d6387779ed35f5bf61fc86667a728tempest_plugin_ironic_git_install_branch: 3af6253bc96ba1897feb0a88e60bddd0097d05fftempest_plugin_keystone_git_install_branch: 4eff632695fe79a5d78f400dca3ceab663c83788tempest_plugin_magnum_git_install_branch: 70d8e4551409c712f4a1e523566951da72e1871ctempest_plugin_manila_git_install_branch: b31d6efb21cfec92fed899a1eec1cb5de30c737btempest_plugin_neutron_git_install_branch: 318ec127c548d4f3cba1ceb9edb11c5d250b1786tempest_plugin_novajoin_git_install_branch: b2e548518a8893562ed111fe66f5937603f5ec5dtempest_plugin_octavia_git_install_branch: 1aeccba999a15e2e71feb520c233dd19299e6905tempest_plugin_senlin_git_install_branch: 7a8121fc5f51f17f9f56a7d73739ed4378ba264ftempest_plugin_telemetry_git_install_branch: e5ef4e7c6eeeada174452da9be5f56fa1dcc22a9tempest_plugin_zun_git_install_branch: c6b830885c15ed40e9e5436c88c72d32e754beaerally_openstack_git_install_branch: 3984f97c1c9fd0695bab123da81323e83abac3a3,125,125
openstack%2Fmanila-tempest-plugin~master~I34bed8ac06aad666fe1d4c8eb79e005716970bf0,openstack/manila-tempest-plugin,master,I34bed8ac06aad666fe1d4c8eb79e005716970bf0,[RBAC] Fix test tags,MERGED,2022-11-02 11:00:27.000000000,2022-11-08 22:01:08.000000000,2022-11-08 22:01:08.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-11-02 11:00:27.000000000', 'files': ['manila_tempest_tests/tests/rbac/test_shares.py', 'manila_tempest_tests/tests/rbac/test_share_types.py', 'manila_tempest_tests/tests/rbac/test_snapshots.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/121f536ac32649fdc9f13dca681ab3fd69e725e8', 'message': '[RBAC] Fix test tags\n\nThere are a number of tests whose direction is\nnot marked correctly.\n\nChange-Id: I34bed8ac06aad666fe1d4c8eb79e005716970bf0\n'}]",2,863253,121f536ac32649fdc9f13dca681ab3fd69e725e8,10,3,1,19262,,,0,"[RBAC] Fix test tags

There are a number of tests whose direction is
not marked correctly.

Change-Id: I34bed8ac06aad666fe1d4c8eb79e005716970bf0
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/53/863253/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila_tempest_tests/tests/rbac/test_shares.py', 'manila_tempest_tests/tests/rbac/test_share_types.py', 'manila_tempest_tests/tests/rbac/test_snapshots.py']",3,121f536ac32649fdc9f13dca681ab3fd69e725e8,secure-rbac," @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_POSITIVE, base.TAG_API_WITH_BACKEND)"," @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND) @tc.attr(base.TAG_NEGATIVE, base.TAG_API_WITH_BACKEND)",10,10
openstack%2Fproject-config~master~Iab38df6386ce5219a52787fda5e64a8faab23a06,openstack/project-config,master,Iab38df6386ce5219a52787fda5e64a8faab23a06,Skip existing remote artifacts during PyPI upload,MERGED,2022-11-08 15:45:57.000000000,2022-11-08 21:02:06.000000000,2022-11-08 21:02:06.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 15:45:57.000000000', 'files': ['playbooks/publish/pypi.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1ea6374489e2cb4c7e776b8110f99f8d1d5ff766', 'message': 'Skip existing remote artifacts during PyPI upload\n\nIn order to be able to safely re-enqueue tags which previously\nfailed release jobs after successfully uploading at least some\nartifacts to PyPI, instruct twine to treat ""file already exists""\nresponses as benign and ignore them, proceeding to upload any others\nwhich aren\'t yet there.\n\nDepends-On: https://review.opendev.org/864004\nChange-Id: Iab38df6386ce5219a52787fda5e64a8faab23a06\n'}]",0,864019,1ea6374489e2cb4c7e776b8110f99f8d1d5ff766,8,4,1,5263,,,0,"Skip existing remote artifacts during PyPI upload

In order to be able to safely re-enqueue tags which previously
failed release jobs after successfully uploading at least some
artifacts to PyPI, instruct twine to treat ""file already exists""
responses as benign and ignore them, proceeding to upload any others
which aren't yet there.

Depends-On: https://review.opendev.org/864004
Change-Id: Iab38df6386ce5219a52787fda5e64a8faab23a06
",git fetch https://review.opendev.org/openstack/project-config refs/changes/19/864019/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/publish/pypi.yaml'],1,1ea6374489e2cb4c7e776b8110f99f8d1d5ff766,twine-upload, pypi_twine_skip_existing: true,,1,0
openstack%2Fopenstack-helm~master~I4e0eb544d0fec83a2d57fbd3f892f8f93207495b,openstack/openstack-helm,master,I4e0eb544d0fec83a2d57fbd3f892f8f93207495b,Imported Translations from Zanata,MERGED,2022-11-07 03:45:26.000000000,2022-11-08 20:36:18.000000000,2022-11-08 20:34:57.000000000,"[{'_account_id': 1004}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 03:45:26.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'doc/source/locale/id/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc.po'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e187023ffed12af67d6a50f0edafcb5ab1598fd6', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4e0eb544d0fec83a2d57fbd3f892f8f93207495b\n'}]",0,863786,e187023ffed12af67d6a50f0edafcb5ab1598fd6,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4e0eb544d0fec83a2d57fbd3f892f8f93207495b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/86/863786/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'doc/source/locale/id/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc.po']",5,e187023ffed12af67d6a50f0edafcb5ab1598fd6,zanata/translations,"""Project-Id-Version: openstack-helm 0.1.1.dev3879\n""""POT-Creation-Date: 2022-10-24 20:45+0000\n""","""Project-Id-Version: openstack-helm 0.1.1.dev3462\n""""POT-Creation-Date: 2021-06-22 20:22+0000\n""""Please review our `documentation <https://docs.openstack.org/openstack-helm/"" ""latest/>`_. For quick installation, evaluation, and convenience, we have a "" ""kubeadm based all-in-one solution that runs in a Docker container. The "" ""Kubeadm-AIO set up can be found `here <https://docs.openstack.org/openstack-"" ""helm/latest/install/developer/index.html>`_."" msgstr """" ""Bitte lesen Sie unsere `Dokumentation <https://docs.openstack.org/openstack-"" ""helm/latest/>`_. Für schnelle Installation, Evaluierung und Komfort haben "" ""wir eine kubeadm-basierte All-in-One-Lösung, die in einem Docker-Container "" ""ausgeführt wird. Das Kubeadm-AIO-Setup finden Sie hier <https://docs."" ""openstack.org/openstack-helm/latest/install/developer/index.html>`_."" msgid """"",549,62
openstack%2Fansible-collections-openstack~master~I70fc744f786a9de654592c97188af48ddbe8751d,openstack/ansible-collections-openstack,master,I70fc744f786a9de654592c97188af48ddbe8751d,"Refactored volume_snapshot{,_info} modules",MERGED,2022-11-03 10:30:22.000000000,2022-11-08 20:11:20.000000000,2022-11-08 20:11:20.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 32962}]","[{'number': 1, 'created': '2022-11-03 10:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d83a830a044c939450cc680e1a4cfcad7de193ca', 'message': 'Refactored volume_snapshot{,_info} modules\n\nChange-Id: I70fc744f786a9de654592c97188af48ddbe8751d\n'}, {'number': 2, 'created': '2022-11-04 10:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/fb1fa7786581ff7ef75087570511d483ec4b53a8', 'message': 'Refactored volume_snapshot{,_info} modules\n\nChange-Id: I70fc744f786a9de654592c97188af48ddbe8751d\n'}, {'number': 3, 'created': '2022-11-04 12:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/1df8c3975e92f6ed1d0d7de90bdc8f605a848e51', 'message': 'Refactored volume_snapshot{,_info} modules\n\nChange-Id: I70fc744f786a9de654592c97188af48ddbe8751d\n'}, {'number': 4, 'created': '2022-11-04 19:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4b17cab7bb29c42643c355e66a808412c4ce40be', 'message': 'Refactored volume_snapshot{,_info} modules\n\nChange-Id: I70fc744f786a9de654592c97188af48ddbe8751d\n'}, {'number': 5, 'created': '2022-11-05 19:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f1e43fba3549fbefdf2702fc92047218f1aafa9f', 'message': 'Refactored volume_snapshot{,_info} modules\n\nChange-Id: I70fc744f786a9de654592c97188af48ddbe8751d\n'}, {'number': 6, 'created': '2022-11-08 12:49:11.000000000', 'files': ['ci/roles/volume_snapshot/defaults/main.yml', 'ci/roles/volume/tasks/main.yml', 'plugins/modules/volume_snapshot.py', 'plugins/modules/volume_snapshot_info.py', '.zuul.yaml', 'ci/roles/volume_snapshot/tasks/main.yml', 'ci/run-collection.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b3c2e8f1ce9f04565ed7259cd966567d62c911af', 'message': 'Refactored volume_snapshot{,_info} modules\n\nChange-Id: I70fc744f786a9de654592c97188af48ddbe8751d\n'}]",5,863498,b3c2e8f1ce9f04565ed7259cd966567d62c911af,18,3,6,32962,,,0,"Refactored volume_snapshot{,_info} modules

Change-Id: I70fc744f786a9de654592c97188af48ddbe8751d
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/98/863498/3 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/volume_snapshot/defaults/main.yml', 'ci/roles/volume/tasks/main.yml', 'plugins/modules/volume_snapshot.py', 'plugins/modules/volume_snapshot_info.py', '.zuul.yaml', 'ci/roles/volume_snapshot/tasks/main.yml', 'ci/run-collection.yml']",7,d83a830a044c939450cc680e1a4cfcad7de193ca,volume_snapshot," - { role: volume_snapshot, tags: volume_snapshot }",,326,197
openstack%2Fopenstack-ansible~stable%2Fyoga~I3c1151449afe545780f98c01afa9fc6948f685a4,openstack/openstack-ansible,stable/yoga,I3c1151449afe545780f98c01afa9fc6948f685a4,Switch Ceph for Ubuntu Jammy to distro,MERGED,2022-10-31 15:09:29.000000000,2022-11-08 20:06:05.000000000,2022-11-08 20:04:48.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-31 15:09:29.000000000', 'files': ['releasenotes/notes/jammy_ceph_experimental-7783ead1c07fe0ed.yaml', 'inventory/group_vars/all/ceph.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dedac9f7b3ee18bf0d24d1c7d20258e2bd99e4be', 'message': 'Switch Ceph for Ubuntu Jammy to distro\n\nUbuntu Jammy repository is not available on download.ceph.com but\nwe still want/need to test out ceph deployment one way or another.\nSo instead of failing installation we install distro-provided ceph.\n\nChange-Id: I3c1151449afe545780f98c01afa9fc6948f685a4\n(cherry picked from commit b3a25cdca2907f06e870d0f2f3811b72dc4ae324)\n'}]",0,862994,dedac9f7b3ee18bf0d24d1c7d20258e2bd99e4be,8,3,1,28619,,,0,"Switch Ceph for Ubuntu Jammy to distro

Ubuntu Jammy repository is not available on download.ceph.com but
we still want/need to test out ceph deployment one way or another.
So instead of failing installation we install distro-provided ceph.

Change-Id: I3c1151449afe545780f98c01afa9fc6948f685a4
(cherry picked from commit b3a25cdca2907f06e870d0f2f3811b72dc4ae324)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/862994/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/jammy_ceph_experimental-7783ead1c07fe0ed.yaml', 'inventory/group_vars/all/ceph.yml']",2,dedac9f7b3ee18bf0d24d1c7d20258e2bd99e4be,,"ceph_origin: ""{{ (ansible_facts['distribution'] | lower == 'ubuntu' and ansible_facts['distribution_version'] | lower == '22.04') | ternary('distro', 'repository') }}"" ceph_pkg_source: ""{{ (ansible_facts['distribution'] | lower == 'ubuntu' and ansible_facts['distribution_version'] | lower == '22.04') | ternary('distro', 'ceph') }}""",ceph_origin: repository,10,1
openstack%2Fpython-openstackclient~master~I76efeccec04937c3a68108e2654872e00fadcec4,openstack/python-openstackclient,master,I76efeccec04937c3a68108e2654872e00fadcec4,zuul: Remove nova-network tests,MERGED,2022-11-07 16:45:16.000000000,2022-11-08 19:50:40.000000000,2022-11-08 19:48:42.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-07 16:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/17d0082655b1737b2db9261e6f78540068ab8be8', 'message': ""zuul: Remove nova-network tests\n\nnova-network has been removed from nova for a very long time now and\nwe've no way to test it in CI save for installing old versions of\nOpenStack. We don't care about this enough to do that, so just remove\nthe thing.\n\nIn the vein of things that have been removed, we also remove\nconfiguration that was supposed to enable cinder's v1 API but doesn't\nsince the related knob was removed over 5 years ago [1].\n\n[1] https://github.com/openstack/cinder/commit/3e91de956e1947a7014709010b99df380242ac74\n\nChange-Id: I76efeccec04937c3a68108e2654872e00fadcec4\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2022-11-08 10:20:41.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1d71479a4cea2a90eb2f244864fbcc665ed9484f', 'message': ""zuul: Remove nova-network tests\n\nnova-network has been removed from nova for a very long time now and\nwe've no way to test it in CI save for installing old versions of\nOpenStack. We don't care about this enough to do that, so just remove\nthe thing.\n\nIn the vein of things that have been removed, we also remove\nconfiguration that was supposed to enable cinder's v1 API but doesn't\nsince the related knob was removed over 5 years ago [1].\n\n[1] https://github.com/openstack/cinder/commit/3e91de956e1947a7014709010b99df380242ac74\n\nChange-Id: I76efeccec04937c3a68108e2654872e00fadcec4\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",1,863897,1d71479a4cea2a90eb2f244864fbcc665ed9484f,10,3,2,15334,,,0,"zuul: Remove nova-network tests

nova-network has been removed from nova for a very long time now and
we've no way to test it in CI save for installing old versions of
OpenStack. We don't care about this enough to do that, so just remove
the thing.

In the vein of things that have been removed, we also remove
configuration that was supposed to enable cinder's v1 API but doesn't
since the related knob was removed over 5 years ago [1].

[1] https://github.com/openstack/cinder/commit/3e91de956e1947a7014709010b99df380242ac74

Change-Id: I76efeccec04937c3a68108e2654872e00fadcec4
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/97/863897/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,17d0082655b1737b2db9261e6f78540068ab8be8,trivial,," devstack_local_conf: post-config: $CINDER_CONF: DEFAULT: # NOTE(dtroyer): OSC needs to support Volume v1 for a while yet so re-enable enable_v1_api: true name: osc-functional-devstack-n-net parent: osc-functional-devstack-base timeout: 7800 vars: devstack_localrc: FLAT_INTERFACE: br_flat PUBLIC_INTERFACE: br_pub devstack_services: n-cell: true n-net: true neutron: false neutron-segments: false q-agt: false q-dhcp: false q-l3: false q-meta: false q-metering: false q-qos: false q-svc: false tox_envlist: functional - job: # This is insufficient, but leaving it here as a reminder of what may # someday be all we need to make this work # disable_python3_package swift # - osc-functional-devstack-n-net: # voting: false # # The job testing nova-network no longer works before Pike, and # # should be disabled until the New Way of testing against old clouds # # is ready and backported # branches: ^(?!stable/(newton|ocata)).*$",0,37
openstack%2Fopenstack-ansible~stable%2Fwallaby~I25851b97abceb7bf3a17819982c26b95dd4998f3,openstack/openstack-ansible,stable/wallaby,I25851b97abceb7bf3a17819982c26b95dd4998f3,Bump OpenStack-Ansible Wallaby,MERGED,2022-10-17 11:49:47.000000000,2022-11-08 19:49:48.000000000,2022-11-08 19:48:21.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-17 11:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6a422cffb684b7dd0e0a9d40a236781341d5f1ba', 'message': 'Bump OpenStack-Ansible Wallaby\n\nChange-Id: I25851b97abceb7bf3a17819982c26b95dd4998f3\n'}, {'number': 2, 'created': '2022-10-24 15:21:00.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/777f4ab421c75b6def8f26e08eb42c07c1b3e4a0', 'message': 'Bump OpenStack-Ansible Wallaby\n\nChange-Id: I25851b97abceb7bf3a17819982c26b95dd4998f3\n'}]",3,861601,777f4ab421c75b6def8f26e08eb42c07c1b3e4a0,16,3,2,28619,,,0,"Bump OpenStack-Ansible Wallaby

Change-Id: I25851b97abceb7bf3a17819982c26b95dd4998f3
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/01/861601/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,6a422cffb684b7dd0e0a9d40a236781341d5f1ba,,### HEAD as of 17.10.2022 ### version: b5e0cb2331e75c7e6dbfb3cc40857951aef70212 shallow_since: '2022-10-11' version: 43aac1b156ace3690583d96c319c74d51ec14ce2 shallow_since: '2022-10-09',### HEAD as of 28.09.2022 ### version: 2ccc59fa13c9834344d9c040cfa818b7d16f6800 shallow_since: '2022-09-27' version: 1ae6284951b6aef0b2f5fb3d87f0d1a322d16e9b shallow_since: '2022-09-26',24,24
openstack%2Ftripleo-validations~master~I1d91cd980921420095105205a8deaf36cee7c571,openstack/tripleo-validations,master,I1d91cd980921420095105205a8deaf36cee7c571,Add sysctl validation for undercloud preflight checks,MERGED,2022-10-13 13:37:23.000000000,2022-11-08 19:33:04.000000000,2022-11-08 19:32:03.000000000,"[{'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 28223}, {'_account_id': 32926}]","[{'number': 1, 'created': '2022-10-13 13:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/e5721d8143c9189933720f78c42ac6edf44cd23c', 'message': 'Add sysctl validation for undercloud preflight checks\n\nChange-Id: I1d91cd980921420095105205a8deaf36cee7c571\n'}, {'number': 2, 'created': '2022-10-13 13:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/2026c10776452955c4d9d944ecdc7a6327520bd3', 'message': 'Add sysctl validation for undercloud preflight checks\n\nChange-Id: I1d91cd980921420095105205a8deaf36cee7c571\n'}, {'number': 3, 'created': '2022-10-13 13:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/1da95d19a180268b16605f1bbbb9ea753e654daf', 'message': 'Add sysctl validation for undercloud preflight checks\n\nChange-Id: I1d91cd980921420095105205a8deaf36cee7c571\n'}, {'number': 4, 'created': '2022-10-13 15:04:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/719f19fa74f02f6c29e77a0824fe74c28a717adf', 'message': 'Add sysctl validation for undercloud preflight checks\n\nChange-Id: I1d91cd980921420095105205a8deaf36cee7c571\n'}, {'number': 5, 'created': '2022-10-13 20:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/100bfc61d60b391c913ca522685d9c4d8db70674', 'message': 'Add sysctl validation for undercloud preflight checks\n\nChange-Id: I1d91cd980921420095105205a8deaf36cee7c571\n'}, {'number': 6, 'created': '2022-10-18 14:55:27.000000000', 'files': ['doc/source/roles/role-undercloud_sysctl.rst', 'roles/undercloud_sysctl/defaults/main.yaml', 'playbooks/undercloud-sysctl.yaml', 'roles/undercloud_sysctl/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/f5e786a4b94892b178bd63e6d9663a07c0fd655f', 'message': 'Add sysctl validation for undercloud preflight checks\n\nChange-Id: I1d91cd980921420095105205a8deaf36cee7c571\n'}]",4,861179,f5e786a4b94892b178bd63e6d9663a07c0fd655f,22,4,6,16515,,,0,"Add sysctl validation for undercloud preflight checks

Change-Id: I1d91cd980921420095105205a8deaf36cee7c571
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/79/861179/5 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/undercloud_sysctl.yaml', 'roles/undercloud_sysctl/defaults/main.yaml', 'roles/undercloud_sysctl/tasks/main.yaml']",3,e5721d8143c9189933720f78c42ac6edf44cd23c,sysctl,"--- # Copyright 2020 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. - name: Check if ipv6 is enabled become: true register: stat_result stat: path: /proc/net/if_inet6 - name: Set ipv6 option if enabled set_fact: undercloud_sysctl_options: ""{{ undercloud_sysctl_options + [undercloud_sysctl_ipv6_option] }}"" when: stat_result.stat.exists - name: Check sysctl options become: true register: option_result stat: path: ""/proc/sys/{{ item | replace('.', '/') }}"" loop: ""{{ undercloud_sysctl_options }}"" - name: Set missing options set_fact: missing_options: ""{{ missing_options + [item.invocation.module_args.path] }}"" when: not item.stat.exists loop: ""{{ option_result.results }}"" - name: Clear missing options for fail message set_fact: fail_options: ""{{ missing_options | join(', ') | replace('/proc/sys/', '') | replace('/', '.') }}"" - name: Fail if some options are missing fail: msg: | Required sysctl options are not available. Check that your kernel is up to date. Missing: {{ fail_options }} when: fail_options ",,81,0
openstack%2Ftempest~master~I7ef97019a9db973749fa81875cfb9e5e837e6bea,openstack/tempest,master,I7ef97019a9db973749fa81875cfb9e5e837e6bea,Fix server id reference in _rebuild_server_and_check(),MERGED,2022-10-27 14:14:39.000000000,2022-11-08 19:24:14.000000000,2022-11-08 19:22:56.000000000,"[{'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2022-10-27 14:14:39.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5928eeb68c95dab9bccda787dc2fd9ba052f3f25', 'message': ""Fix server id reference in _rebuild_server_and_check()\n\nReference to server id is broken now because\nServerActionsTestJSON(self) object has no attribute 'server'.\n\nserver attribute is passed as a method's argument.\n\nChange-Id: I7ef97019a9db973749fa81875cfb9e5e837e6bea\n""}]",3,862823,5928eeb68c95dab9bccda787dc2fd9ba052f3f25,13,2,1,32666,,,0,"Fix server id reference in _rebuild_server_and_check()

Reference to server id is broken now because
ServerActionsTestJSON(self) object has no attribute 'server'.

server attribute is passed as a method's argument.

Change-Id: I7ef97019a9db973749fa81875cfb9e5e837e6bea
",git fetch https://review.opendev.org/openstack/tempest refs/changes/23/862823/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_actions.py'],1,5928eeb68c95dab9bccda787dc2fd9ba052f3f25,," waiters.wait_for_server_status(self.client, server['id'],"," waiters.wait_for_server_status(self.client, self.server['id'],",1,1
openstack%2Floci~master~I4e7d8c81d3793d4d3b85b450ded673ad122dc266,openstack/loci,master,I4e7d8c81d3793d4d3b85b450ded673ad122dc266,Add cryptography back for placement,MERGED,2022-11-08 16:50:27.000000000,2022-11-08 19:23:02.000000000,2022-11-08 19:23:02.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 33519}]","[{'number': 1, 'created': '2022-11-08 16:50:27.000000000', 'files': ['pydep.txt'], 'web_link': 'https://opendev.org/openstack/loci/commit/7dd55124c3d4a1368d027575332eb0e045b426ce', 'message': 'Add cryptography back for placement\n\nThe compute-kit jobs are currently failing in osh-images due to\nplacement not having cryptography available. At this time the\nplacement project does not specify cryptography in their\nrequirements, so in the meantime this change adds it back but\nspecifically for the placement project.\n\nChange-Id: I4e7d8c81d3793d4d3b85b450ded673ad122dc266\n'}]",1,864025,7dd55124c3d4a1368d027575332eb0e045b426ce,12,3,1,21420,,,0,"Add cryptography back for placement

The compute-kit jobs are currently failing in osh-images due to
placement not having cryptography available. At this time the
placement project does not specify cryptography in their
requirements, so in the meantime this change adds it back but
specifically for the placement project.

Change-Id: I4e7d8c81d3793d4d3b85b450ded673ad122dc266
",git fetch https://review.opendev.org/openstack/loci refs/changes/25/864025/1 && git format-patch -1 --stdout FETCH_HEAD,['pydep.txt'],1,7dd55124c3d4a1368d027575332eb0e045b426ce,cryptography,cryptography [placement],,1,0
openstack%2Ftripleo-validations~master~I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c,openstack/tripleo-validations,master,I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c,Remove python-dev from bindep,MERGED,2022-11-07 10:11:57.000000000,2022-11-08 18:36:38.000000000,2022-11-08 18:35:34.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 32926}]","[{'number': 1, 'created': '2022-11-07 10:11:57.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/12c74369d0c91a44e6604b81d65387f614e4e261', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c\n""}]",0,863858,12c74369d0c91a44e6604b81d65387f614e4e261,8,4,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I7c54768c6d9cda14ecb4a4d52361dcfdb267fe6c
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/58/863858/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,12c74369d0c91a44e6604b81d65387f614e4e261,drop-python-dev-from-bindep,,python-devel [platform:rpm !platform:rhel-8 !platform:centos-8 !platform:fedora],0,1
openstack%2Ftripleo-ansible~master~I68a89e413b7c3eecb747386998bd36314250384b,openstack/tripleo-ansible,master,I68a89e413b7c3eecb747386998bd36314250384b,Make creating/updating users idempotent,MERGED,2022-10-21 14:43:34.000000000,2022-11-08 18:35:38.000000000,2022-11-08 18:35:38.000000000,"[{'_account_id': 7144}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 9914}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-10-21 14:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d05c23dade68c079a4bc3924fad3766005003a1b', 'message': '[WiP] Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 2, 'created': '2022-10-24 10:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a7be35b5b3d26fc5f859485ff6ef5b878147c607', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 3, 'created': '2022-10-24 12:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/44c5fc2927c5df1287178720f7e1e6b9c76ff990', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 4, 'created': '2022-10-24 15:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/63228a69a0f4dee495c47fae7001fb177b3edba6', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 5, 'created': '2022-10-25 08:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4a730fbb4cff92efe0917f19ad37734549867cfe', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 6, 'created': '2022-10-28 09:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/5c6f71ed434ba6287ce67a55bc24ac4a8ef24701', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 7, 'created': '2022-10-28 13:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e9a5e6446c381d2dad31209488926b2cdc4c289b', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 8, 'created': '2022-11-02 08:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d9a9ac081cf081290f967cdab746475e243ce847', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 9, 'created': '2022-11-03 08:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/13aa342a4a843e7faa545b0d59ba4dfecb2cde53', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 10, 'created': '2022-11-03 12:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/41f1c200ab121642d567e9fa57fdd5656e962601', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}, {'number': 11, 'created': '2022-11-04 14:36:34.000000000', 'files': ['tripleo_ansible/roles/tripleo_keystone_resources/tasks/admin.yml', 'tripleo_ansible/roles/tripleo_keystone_resources/tasks/users.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b779d63b63735d4daa4286d8621d01e2c59de906', 'message': 'Make creating/updating users idempotent\n\nSimilarly as in [1], updating user passwords causes auth tokens to\nbe revoked, which may cause service interrupution during a minor\nupdate, or even cause a prolonged interruption in case of swift [2]\n\n[1] https://bugs.launchpad.net/keystone/+bug/1647800\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350\n\nChange-Id: I68a89e413b7c3eecb747386998bd36314250384b\nRelated: rhbz#2097350\n'}]",10,862372,b779d63b63735d4daa4286d8621d01e2c59de906,48,8,11,14250,,,0,"Make creating/updating users idempotent

Similarly as in [1], updating user passwords causes auth tokens to
be revoked, which may cause service interrupution during a minor
update, or even cause a prolonged interruption in case of swift [2]

[1] https://bugs.launchpad.net/keystone/+bug/1647800
[2] https://bugzilla.redhat.com/show_bug.cgi?id=2097350

Change-Id: I68a89e413b7c3eecb747386998bd36314250384b
Related: rhbz#2097350
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/72/862372/11 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_keystone_resources/tasks/admin.yml'],1,d05c23dade68c079a4bc3924fad3766005003a1b,,"- name: Check admin password openstack.cloud.identity_user_info: auth_type: ""v3password"" auth: auth_url: ""{{ tripleo_keystone_resources_public_endpoint }}"" username: admin password: ""{{ tripleo_keystone_resources_admin_password }}"" project_name: admin user_domain_name: Default project_domain_name: Default register: user_info_result failed_when: False update_password: ""{{ user_info_result.rc | default(False) | ternary('on_create', 'always') }}"" when: user_info_result.rc is defined", update_password: always,15,1
openstack%2Fvalidations-common~master~I5d57b97f510fde6b50eb3aeda5febcd6ef70f994,openstack/validations-common,master,I5d57b97f510fde6b50eb3aeda5febcd6ef70f994,Remove python-dev from bindep,MERGED,2022-11-07 10:12:14.000000000,2022-11-08 18:35:36.000000000,2022-11-08 18:35:36.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 32926}]","[{'number': 1, 'created': '2022-11-07 10:12:14.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/e83a48d501aabf7741fa042fce89656592e1c041', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I5d57b97f510fde6b50eb3aeda5febcd6ef70f994\n""}]",0,863859,e83a48d501aabf7741fa042fce89656592e1c041,7,4,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I5d57b97f510fde6b50eb3aeda5febcd6ef70f994
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/59/863859/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,e83a48d501aabf7741fa042fce89656592e1c041,drop-python-dev-from-bindep,,python-devel [platform:rpm !platform:rhel-8 !platform:centos-8 !platform:fedora],0,1
openstack%2Fopenstacksdk~master~I759c486d2bd553ed95d97e7b92703ee399821fd2,openstack/openstacksdk,master,I759c486d2bd553ed95d97e7b92703ee399821fd2,compute: Add functional tests for volume attachments,MERGED,2021-12-20 13:00:06.000000000,2022-11-08 18:12:37.000000000,2022-11-08 18:11:17.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2021-12-20 13:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3f6382fb17c8e3b464b184cfa34182674bcd52fc', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2021-12-20 15:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0f1ba6f64ee91ccf388c0b515f24ae02a668a691', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2021-12-20 17:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3c1586c448634e0f8ed027c744f4f202c504b5d3', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 4, 'created': '2021-12-21 13:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e57d66dc6cc33729b205400e5664223467e9da91', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 5, 'created': '2021-12-21 17:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/87bf9fc7b50deef1c9f9c9eafb2369c84a962e4c', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 6, 'created': '2022-09-07 16:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/91f983fec8cdb93cf6bb50730df4b54814ad1d47', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 7, 'created': '2022-09-08 11:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f87cf669e6a233c8544554873e3fdb27238212f2', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 8, 'created': '2022-09-28 13:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7aa871bf0c683eaa0187cf885fe19f45a80b7bf1', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 9, 'created': '2022-09-30 10:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8d251e34e0d37676eea68f222a53f4c58dc00257', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 10, 'created': '2022-10-11 15:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eaa6de3988fc004a8718281fcd18781f2ee6486b', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 11, 'created': '2022-10-18 12:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1a781395eec6e72205d62e9f3acb8ab6f3c604df', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 12, 'created': '2022-10-26 12:10:10.000000000', 'files': ['openstack/tests/functional/compute/v2/test_volume_attachment.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d3e798920790449731d764147e1d368c8b3d269c', 'message': 'compute: Add functional tests for volume attachments\n\nThese provide a sort of documentation and prevent us regressing in the\nfuture.\n\nChange-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",11,822314,d3e798920790449731d764147e1d368c8b3d269c,33,3,12,15334,,,0,"compute: Add functional tests for volume attachments

These provide a sort of documentation and prevent us regressing in the
future.

Change-Id: I759c486d2bd553ed95d97e7b92703ee399821fd2
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/14/822314/12 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/compute/v2/test_volume_attachment.py'],1,3f6382fb17c8e3b464b184cfa34182674bcd52fc,compute-gaps,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack.block_storage.v3 import volume as volume_ from openstack.compute.v2 import server as server_ from openstack.compute.v2 import volume_attachment as volume_attachment_ from openstack.tests.functional import base from openstack.tests.functional.compute import base as ft_base class TestServerVolumeAttachment(ft_base.BaseComputeTest): def setUp(self): super().setUp() self.server_name = self.getUniqueString() flavor = self.conn.compute.find_flavor( base.FLAVOR_NAME, ignore_missing=False, ) image = self.conn.compute.find_image( base.IMAGE_NAME, ignore_missing=False, ) # create the server and volume volume = self.conn.create_volume(1) server = self.conn.compute.create_server( name=self.server_name, flavor_id=flavor.id, image_id=image.id, networks='none', ) self.conn.compute.wait_for_server(server, wait=self._wait_for_timeout) self.conn.volume.wait_for_status( volume, status='available' wait=self._wait_for_timeout, ) assert isinstance(server, server_.Server) self.assertEqual(self.server_name, server.name) assert isinstance(volume, volume_.Volume) self.server = server self.volume = volume def test_volume_attachment(self): # create the volume attachment volume_attachment = self.conn.compute.create_volume_attachment( server, volume, ) self.assertIsInstance( volume_attachment, volume_attachment_.VolumeAttachment, ) self.conn.volume.wait_for_status( volume, status='in-use', wait=self._wait_for_timeout, ) # list all attached volume attachments (there should only be one) volume_attachments = self.conn.compute.volume_attachments(self.server) self.assertEqual(1, len(volume_attachments)) self.assertIsInstance( volume_attachments[0], volume_attachment_.VolumeAttachment, ) # update the volume attachment volume_attachment = self.conn.compute.update_volume_attachment( self.server, self.volume, delete_on_termination=True, ) self.assertIsInstance( volume_attachment, volume_attachment_.VolumeAttachment, ) # retrieve details of the (updated) volume attachment volume_attachment = self.conn.compute.get_volume_attachment( self.server, self.volume, ) self.assertIsInstance( volume_attachment, volume_attachment_.VolumeAttachment, ) self.assertTrue(volume_attachment.delete_on_termination) # delete the volume attachment result = self.conn.compute.delete_volume_attachment( self.server, self.volume, ignore_missing=False, ) self.assertIsNone(result) def tearDown(self): # we delete the server before the volume in case it's still attached # somehow self.conn.compute.delete_server(self.server.id) self.conn.compute.wait_for_delete( self.server, wait=self._wait_for_timeout, ) self.conn.volume.delete_volume(self.volume.id) self.conn.compute.wait_for_delete( self.volume, wait=self._wait_for_timeout, ) super().tearDown() ",,131,0
openstack%2Fopenstack-helm~master~I818a3a79faa631ec1b7de625f2113c6f19610760,openstack/openstack-helm,master,I818a3a79faa631ec1b7de625f2113c6f19610760,Remove train and ussuri overrides,MERGED,2022-10-20 04:42:54.000000000,2022-11-08 18:05:07.000000000,2022-11-08 18:03:56.000000000,"[{'_account_id': 8898}, {'_account_id': 18250}, {'_account_id': 22348}, {'_account_id': 33519}]","[{'number': 1, 'created': '2022-10-20 04:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/79b2e025dc8ea1b81767e9782be4735fc14d2145', 'message': 'Remove train and ussuri overrides\n\nWe dropped train support a long time ago now, and our latest efforts\nare to drop ussuri/bionic images. This change removes any leftover\ntrain overrides as well as any ussuri overrides. This also changes\nany image defaults to use wallaby.\n\nDepends-on: https://review.opendev.org/c/openstack/openstack-helm/+/861933\nChange-Id: I818a3a79faa631ec1b7de625f2113c6f19610760\n'}, {'number': 2, 'created': '2022-10-22 04:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8358b0ae585fe0aae9c99e53ae9955f691c79deb', 'message': 'Remove train and ussuri overrides\n\nWe dropped train support a long time ago now, and our latest efforts\nare to drop ussuri/bionic images. This change removes any leftover\ntrain overrides as well as any ussuri overrides. This also changes\nany image defaults to use wallaby.\n\nDepends-on: https://review.opendev.org/c/openstack/openstack-helm/+/861933\nChange-Id: I818a3a79faa631ec1b7de625f2113c6f19610760\n'}, {'number': 3, 'created': '2022-10-24 21:01:09.000000000', 'files': ['heat/Chart.yaml', 'openstack/values_overrides/heat/ussuri-ubuntu_bionic.yaml', 'horizon/Chart.yaml', 'openstack/values_overrides/glance/train-ubuntu_bionic.yaml', 'releasenotes/notes/neutron.yaml', 'keystone/values_overrides/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/placement/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/nova/train-ubuntu_bionic.yaml', 'heat/values_overrides/train-ubuntu_bionic.yaml', 'barbican/values_overrides/ussuri-ubuntu_bionic.yaml', 'cinder/Chart.yaml', 'releasenotes/notes/cinder.yaml', 'openstack/values_overrides/nova/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/neutron/train-ubuntu_bionic.yaml', 'barbican/values.yaml', 'placement/values_overrides/ussuri-ubuntu_bionic.yaml', 'releasenotes/notes/placement.yaml', 'neutron/Chart.yaml', 'nova/Chart.yaml', 'openstack/values_overrides/horizon/ussuri-ubuntu_bionic.yaml', 'glance/Chart.yaml', 'nova/values.yaml', 'nova/values_overrides/train-ubuntu_bionic.yaml', 'placement/Chart.yaml', 'openstack/values_overrides/heat/train-ubuntu_bionic.yaml', 'keystone/values_overrides/train-ubuntu_bionic.yaml', 'keystone/Chart.yaml', 'neutron/values_overrides/train-ubuntu_bionic.yaml', 'openstack/Chart.yaml', 'releasenotes/notes/openstack.yaml', 'glance/values_overrides/ussuri-ubuntu_bionic.yaml', 'releasenotes/notes/heat.yaml', 'cinder/values_overrides/ussuri-ubuntu_bionic.yaml', 'horizon/values_overrides/ussuri-ubuntu_bionic.yaml', 'nova/values_overrides/ussuri-ubuntu_bionic.yaml', 'cinder/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/glance/ussuri-ubuntu_bionic.yaml', 'barbican/values_overrides/train-ubuntu_bionic.yaml', 'barbican/Chart.yaml', 'releasenotes/notes/nova.yaml', 'glance/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/horizon/train-ubuntu_bionic.yaml', 'horizon/values_overrides/train-ubuntu_bionic.yaml', 'heat/values_overrides/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/keystone/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/neutron/ussuri-ubuntu_bionic.yaml', 'releasenotes/notes/glance.yaml', 'cinder/values.yaml', 'neutron/values_overrides/ussuri-ubuntu_bionic.yaml', 'releasenotes/notes/keystone.yaml', 'releasenotes/notes/horizon.yaml', 'releasenotes/notes/barbican.yaml', 'openstack/values_overrides/keystone/train-ubuntu_bionic.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5ffefb60c1836cc62abe669de72a79b79974f859', 'message': 'Remove train and ussuri overrides\n\nWe dropped train support a long time ago now, and our latest efforts\nare to drop ussuri/bionic images. This change removes any leftover\ntrain overrides as well as any ussuri overrides. This also changes\nany image defaults to use wallaby.\n\nChange-Id: I818a3a79faa631ec1b7de625f2113c6f19610760\n'}]",0,861934,5ffefb60c1836cc62abe669de72a79b79974f859,17,4,3,21420,,,0,"Remove train and ussuri overrides

We dropped train support a long time ago now, and our latest efforts
are to drop ussuri/bionic images. This change removes any leftover
train overrides as well as any ussuri overrides. This also changes
any image defaults to use wallaby.

Change-Id: I818a3a79faa631ec1b7de625f2113c6f19610760
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/34/861934/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/values_overrides/ussuri-ubuntu_bionic.yaml', 'cinder/values_overrides/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/heat/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/glance/train-ubuntu_bionic.yaml', 'horizon/values_overrides/ussuri-ubuntu_bionic.yaml', 'nova/values_overrides/ussuri-ubuntu_bionic.yaml', 'cinder/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/glance/ussuri-ubuntu_bionic.yaml', 'keystone/values_overrides/ussuri-ubuntu_bionic.yaml', 'barbican/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/placement/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/nova/train-ubuntu_bionic.yaml', 'heat/values_overrides/train-ubuntu_bionic.yaml', 'barbican/values_overrides/ussuri-ubuntu_bionic.yaml', 'glance/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/horizon/train-ubuntu_bionic.yaml', 'openstack/values_overrides/nova/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/neutron/train-ubuntu_bionic.yaml', 'horizon/values_overrides/train-ubuntu_bionic.yaml', 'heat/values_overrides/ussuri-ubuntu_bionic.yaml', 'barbican/values.yaml', 'openstack/values_overrides/keystone/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/neutron/ussuri-ubuntu_bionic.yaml', 'cinder/values.yaml', 'neutron/values_overrides/ussuri-ubuntu_bionic.yaml', 'placement/values_overrides/ussuri-ubuntu_bionic.yaml', 'placement/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/horizon/ussuri-ubuntu_bionic.yaml', 'openstack/values_overrides/keystone/train-ubuntu_bionic.yaml', 'nova/values.yaml', 'nova/values_overrides/train-ubuntu_bionic.yaml', 'openstack/values_overrides/heat/train-ubuntu_bionic.yaml', 'keystone/values_overrides/train-ubuntu_bionic.yaml', 'neutron/values_overrides/train-ubuntu_bionic.yaml']",34,79b2e025dc8ea1b81767e9782be4735fc14d2145,rm-train-ussuri,,"--- images: tags: bootstrap: ""docker.io/openstackhelm/heat:train-ubuntu_bionic"" db_init: ""docker.io/openstackhelm/heat:train-ubuntu_bionic"" db_drop: ""docker.io/openstackhelm/heat:train-ubuntu_bionic"" ks_user: ""docker.io/openstackhelm/heat:train-ubuntu_bionic"" ks_service: ""docker.io/openstackhelm/heat:train-ubuntu_bionic"" ks_endpoints: ""docker.io/openstackhelm/heat:train-ubuntu_bionic"" neutron_db_sync: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_dhcp: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_l3: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_l2gw: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_linuxbridge_agent: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_metadata: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_openvswitch_agent: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_server: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_rpc_server: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_bagpipe_bgp: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" neutron_netns_cleanup_cron: ""docker.io/openstackhelm/neutron:train-ubuntu_bionic"" ... ",44,584
openstack%2Fopenstack-ansible~master~I23402d0f706fcfb7f6316398e0bf022e9c5ea951,openstack/openstack-ansible,master,I23402d0f706fcfb7f6316398e0bf022e9c5ea951,Add release note about used ansible and ceph versions,MERGED,2022-10-19 13:26:24.000000000,2022-11-08 17:47:01.000000000,2022-11-08 17:43:19.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-19 13:26:24.000000000', 'files': ['releasenotes/notes/zed_ansible_ceph_versions-52f90c4e2340e3c2.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c2a6a86346463cf62707704837c7d626ff0792ef', 'message': 'Add release note about used ansible and ceph versions\n\nChange-Id: I23402d0f706fcfb7f6316398e0bf022e9c5ea951\n'}]",0,861889,c2a6a86346463cf62707704837c7d626ff0792ef,8,3,1,28619,,,0,"Add release note about used ansible and ceph versions

Change-Id: I23402d0f706fcfb7f6316398e0bf022e9c5ea951
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/89/861889/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/zed_ansible_ceph_versions-52f90c4e2340e3c2.yaml'],1,c2a6a86346463cf62707704837c7d626ff0792ef,,--- features: - | Default ``ansible-core`` version has been switched to 2.13 series - | ``ceph-ansible`` version has been switched to v7 series - | Default ceph version has been switched to Quincy ,,8,0
openstack%2Fopenstack-ansible~master~I91c5e130348f4080cf947cb1097f78da6a34bfb4,openstack/openstack-ansible,master,I91c5e130348f4080cf947cb1097f78da6a34bfb4,Make Ubuntu Jammy voting,MERGED,2022-10-28 08:33:10.000000000,2022-11-08 17:45:43.000000000,2022-11-08 17:43:06.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-28 08:33:10.000000000', 'files': ['zuul.d/project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c93a42c29761d0631820c214ffbad285f641be4b', 'message': 'Make Ubuntu Jammy voting\n\nWe are moving Ubuntu 22.04 support out of experimental state\nwhich means that Jammy should be voting now. With that we are also\nreplacing focal jobs with jammy in gates to save CI resources.\n\nChange-Id: I91c5e130348f4080cf947cb1097f78da6a34bfb4\n'}]",1,862869,c93a42c29761d0631820c214ffbad285f641be4b,10,3,1,28619,,,0,"Make Ubuntu Jammy voting

We are moving Ubuntu 22.04 support out of experimental state
which means that Jammy should be voting now. With that we are also
replacing focal jobs with jammy in gates to save CI resources.

Change-Id: I91c5e130348f4080cf947cb1097f78da6a34bfb4
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/69/862869/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project-templates.yaml'],1,c93a42c29761d0631820c214ffbad285f641be4b,, - openstack-ansible-deploy-aio_lxc-ubuntu-jammy - openstack-ansible-deploy-aio_lxc-ubuntu-jammy - openstack-ansible-deploy-aio_lxc-ubuntu-jammy - openstack-ansible-deploy-infra_lxc-ubuntu-jammy - openstack-ansible-deploy-infra_lxc-ubuntu-jammy - openstack-ansible-deploy-infra_lxc-ubuntu-jammy - openstack-ansible-deploy-hosts_lxc-ubuntu-jammy - openstack-ansible-deploy-hosts_lxc-ubuntu-jammy - openstack-ansible-deploy-hosts_lxc-ubuntu-jammy - openstack-ansible-deploy-hosts_metal-ubuntu-jammy - openstack-ansible-deploy-hosts_metal-ubuntu-jammy - openstack-ansible-deploy-hosts_metal-ubuntu-jammy - openstack-ansible-deploy-aio_metal-ubuntu-jammy - openstack-ansible-deploy-aio_metal-ubuntu-jammy - openstack-ansible-deploy-aio_telemetry_metal-ubuntu-jammy - openstack-ansible-deploy-aio_telemetry_metal-ubuntu-jammy - openstack-ansible-deploy-aio_nfs-ubuntu-jammy - openstack-ansible-deploy-aio_nfs-ubuntu-jammy - openstack-ansible-deploy-aio_ceph-ubuntu-jammy, - openstack-ansible-deploy-aio_lxc-ubuntu-jammy: voting: false - openstack-ansible-deploy-aio_lxc-ubuntu-focal - openstack-ansible-deploy-aio_lxc-ubuntu-focal - openstack-ansible-deploy-infra_lxc-ubuntu-jammy: voting: false - openstack-ansible-deploy-infra_lxc-ubuntu-focal - openstack-ansible-deploy-infra_lxc-ubuntu-focal - openstack-ansible-deploy-hosts_lxc-ubuntu-jammy: voting: false - openstack-ansible-deploy-hosts_lxc-ubuntu-focal - openstack-ansible-deploy-hosts_lxc-ubuntu-focal - openstack-ansible-deploy-hosts_metal-ubuntu-jammy: voting: false - openstack-ansible-deploy-hosts_metal-ubuntu-focal - openstack-ansible-deploy-hosts_metal-ubuntu-focal - openstack-ansible-deploy-aio_metal-ubuntu-jammy: voting: false - openstack-ansible-deploy-aio_metal-ubuntu-focal - openstack-ansible-deploy-aio_telemetry_metal-ubuntu-jammy: voting: false - openstack-ansible-deploy-aio_telemetry_metal-ubuntu-focal - openstack-ansible-deploy-aio_nfs-ubuntu-jammy: voting: false - openstack-ansible-deploy-aio_nfs-ubuntu-focal - openstack-ansible-deploy-aio_ceph-ubuntu-jammy: voting: false,19,27
openstack%2Fopenstack-ansible~master~I17f4ebf686f323c045e462f74d3f6ed943a3134d,openstack/openstack-ansible,master,I17f4ebf686f323c045e462f74d3f6ed943a3134d,Mark Zaqar as deprecated in role matrix,MERGED,2022-10-19 12:45:39.000000000,2022-11-08 17:43:16.000000000,2022-11-08 17:43:16.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-19 12:45:39.000000000', 'files': ['doc/source/contributor/role-maturity-matrix.html'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cd5d8fce19e7ad746acfcae44ba699d5ccc4ffde', 'message': 'Mark Zaqar as deprecated in role matrix\n\nChange-Id: I17f4ebf686f323c045e462f74d3f6ed943a3134d\n'}]",0,861884,cd5d8fce19e7ad746acfcae44ba699d5ccc4ffde,7,3,1,28619,,,0,"Mark Zaqar as deprecated in role matrix

Change-Id: I17f4ebf686f323c045e462f74d3f6ed943a3134d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/84/861884/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/role-maturity-matrix.html'],1,cd5d8fce19e7ad746acfcae44ba699d5ccc4ffde,, </tr> <tr > <td>os_zaqar</td> <td>Queens</td> <td>Train</td>, <td>os_zaqar</td> <td>Queens</td> <td>Complete</td> <td>✘</td> <td>✔</td> <td>✘</td> </tr> <tr >,5,8
openstack%2Fopenstack-ansible~master~Ia5cfdbc3cbe57647a209ca71693589e4f070cd83,openstack/openstack-ansible,master,Ia5cfdbc3cbe57647a209ca71693589e4f070cd83,[doc] Mark Ocata/Pike/Queens as EOL,MERGED,2022-10-21 09:03:42.000000000,2022-11-08 17:43:12.000000000,2022-11-08 17:43:12.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-21 09:03:42.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a35b30879536f2a4ce7a02355cec26c4ccbc11c1', 'message': '[doc] Mark Ocata/Pike/Queens as EOL\n\nChange-Id: Ia5cfdbc3cbe57647a209ca71693589e4f070cd83\n'}]",0,862283,a35b30879536f2a4ce7a02355cec26c4ccbc11c1,7,3,1,28619,,,0,"[doc] Mark Ocata/Pike/Queens as EOL

Change-Id: Ia5cfdbc3cbe57647a209ca71693589e4f070cd83
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/83/862283/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,a35b30879536f2a4ce7a02355cec26c4ccbc11c1,,Queens: EOL (end-of-life) ~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack-Ansible's Queens series was EOL'd on 19 October 2022.Pike: EOL (end-of-life) ~~~~~~~~~~~~~~~~~~~~~~~ OpenStack-Ansible's Pike series was EOL'd on 17 June 2022.Ocata: EOL (end-of-life) ~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack-Ansible's Ocata series was EOL'd on 21 December 2022.,Queens: Extended Maintenance ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack-Ansible's Queens series was first released with the 17.0.0 tag on 14 March 2018.Pike: Extended Maintenance ~~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack-Ansible's Pike series was first released with the 16.0.0 tag on 14 September 2017.Ocata: Extended Maintenance ~~~~~~~~~~~~~~~~~~~~~~~~~~~ OpenStack-Ansible's Ocata series was first released with the 15.0.0 tag on 8 March 2017.,9,12
openstack%2Fopenstack-ansible~master~I3a53949870fa9eb8d659370029c9805fd7f3f2c5,openstack/openstack-ansible,master,I3a53949870fa9eb8d659370029c9805fd7f3f2c5,[doc] Mark Victoria as EM,MERGED,2022-10-21 08:58:00.000000000,2022-11-08 17:43:09.000000000,2022-11-08 17:43:09.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-21 08:58:00.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/700965439ae99522f596ba79b85e0a227ce00226', 'message': '[doc] Mark Victoria as EM\n\nChange-Id: I3a53949870fa9eb8d659370029c9805fd7f3f2c5\n'}]",0,862281,700965439ae99522f596ba79b85e0a227ce00226,7,3,1,28619,,,0,"[doc] Mark Victoria as EM

Change-Id: I3a53949870fa9eb8d659370029c9805fd7f3f2c5
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/862281/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,700965439ae99522f596ba79b85e0a227ce00226,,Victoria: Extended Maintenance ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~,Victoria: Maintained ~~~~~~~~~~~~~~~~~~~~,2,2
openstack%2Frequirements~stable%2Fyoga~I605717824159f878df252e4c6d9bdd7af2f113df,openstack/requirements,stable/yoga,I605717824159f878df252e4c6d9bdd7af2f113df,Remove python-dev from bindep,MERGED,2022-11-08 13:35:08.000000000,2022-11-08 17:30:54.000000000,2022-11-08 17:30:54.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 13:35:08.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d063325fc859cf22b30ffa31f495e15014d5d086', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I605717824159f878df252e4c6d9bdd7af2f113df\n(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)\n""}]",0,863800,d063325fc859cf22b30ffa31f495e15014d5d086,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I605717824159f878df252e4c6d9bdd7af2f113df
(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/00/863800/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,d063325fc859cf22b30ffa31f495e15014d5d086,drop-python-dev-from-bindep-stable/zed-stable/yoga,,python-devel [platform:rpm !platform:centos-8],0,1
openstack%2Frequirements~stable%2Fxena~I605717824159f878df252e4c6d9bdd7af2f113df,openstack/requirements,stable/xena,I605717824159f878df252e4c6d9bdd7af2f113df,Remove python-dev from bindep,MERGED,2022-11-08 13:35:21.000000000,2022-11-08 17:30:52.000000000,2022-11-08 17:30:52.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 13:35:21.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fb75f9f0671351060c1cf64fd5af9b6783f6708d', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I605717824159f878df252e4c6d9bdd7af2f113df\n(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)\n""}]",0,863801,fb75f9f0671351060c1cf64fd5af9b6783f6708d,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I605717824159f878df252e4c6d9bdd7af2f113df
(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/01/863801/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,fb75f9f0671351060c1cf64fd5af9b6783f6708d,drop-python-dev-from-bindep-stable/zed-stable/yoga-stable/xena,,python-devel [platform:rpm !platform:centos-8],0,1
openstack%2Frequirements~stable%2Fwallaby~I605717824159f878df252e4c6d9bdd7af2f113df,openstack/requirements,stable/wallaby,I605717824159f878df252e4c6d9bdd7af2f113df,Remove python-dev from bindep,MERGED,2022-11-08 13:35:39.000000000,2022-11-08 17:30:49.000000000,2022-11-08 17:30:49.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 13:35:39.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/85e8e81562a31fc35718c908afd2c1cdc17c2e64', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I605717824159f878df252e4c6d9bdd7af2f113df\n(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)\n""}]",0,863802,85e8e81562a31fc35718c908afd2c1cdc17c2e64,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I605717824159f878df252e4c6d9bdd7af2f113df
(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/02/863802/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,85e8e81562a31fc35718c908afd2c1cdc17c2e64,drop-python-dev-from-bindep-stable/zed-stable/yoga-stable/xena-stable/wallaby,,python-devel [platform:rpm !platform:centos-8],0,1
openstack%2Frequirements~stable%2Fzed~I605717824159f878df252e4c6d9bdd7af2f113df,openstack/requirements,stable/zed,I605717824159f878df252e4c6d9bdd7af2f113df,Remove python-dev from bindep,MERGED,2022-11-08 13:34:36.000000000,2022-11-08 17:28:55.000000000,2022-11-08 17:28:55.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 13:34:36.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d73cd33e4307241066cbd281971b8ab7428ff235', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I605717824159f878df252e4c6d9bdd7af2f113df\n(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)\n""}]",0,863799,d73cd33e4307241066cbd281971b8ab7428ff235,7,2,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I605717824159f878df252e4c6d9bdd7af2f113df
(cherry picked from commit 90b48934f4f018cf6e04dcd42731731346422b03)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/863799/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,d73cd33e4307241066cbd281971b8ab7428ff235,drop-python-dev-from-bindep-stable/zed,,python-devel [platform:rpm !platform:centos-8],0,1
openstack%2Fvalidations-libs~master~I89be9dea4a1d7d7c3d8d1910adddbc111defa55a,openstack/validations-libs,master,I89be9dea4a1d7d7c3d8d1910adddbc111defa55a,Remove python-dev from bindep,MERGED,2022-11-07 10:12:32.000000000,2022-11-08 17:26:12.000000000,2022-11-08 17:26:12.000000000,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 32926}, {'_account_id': 35199}]","[{'number': 1, 'created': '2022-11-07 10:12:32.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/5fb5a02716c3243e9e64ce1c670e635893bd85b2', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I89be9dea4a1d7d7c3d8d1910adddbc111defa55a\n""}]",1,863860,5fb5a02716c3243e9e64ce1c670e635893bd85b2,9,5,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I89be9dea4a1d7d7c3d8d1910adddbc111defa55a
",git fetch https://review.opendev.org/openstack/validations-libs refs/changes/60/863860/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,5fb5a02716c3243e9e64ce1c670e635893bd85b2,drop-python-dev-from-bindep,,python-devel [platform:rpm !platform:rhel-8 !platform:centos-8],0,1
openstack%2Fopenstack-helm-infra~master~I05a959b4678852699b7b5531cd8303e15662b372,openstack/openstack-helm-infra,master,I05a959b4678852699b7b5531cd8303e15662b372,Fix resource name in role of ingress chart,MERGED,2022-10-30 18:01:11.000000000,2022-11-08 17:25:16.000000000,2022-11-08 17:24:10.000000000,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-30 18:01:11.000000000', 'files': ['ingress/Chart.yaml', 'ingress/templates/deployment-ingress.yaml', 'releasenotes/notes/ingress.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4a224320d86367f2a1b5bc3f2810cf11c1366c1d', 'message': 'Fix resource name in role of ingress chart\n\nChange-Id: I05a959b4678852699b7b5531cd8303e15662b372\n'}]",0,862982,4a224320d86367f2a1b5bc3f2810cf11c1366c1d,8,3,1,34293,,,0,"Fix resource name in role of ingress chart

Change-Id: I05a959b4678852699b7b5531cd8303e15662b372
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/82/862982/1 && git format-patch -1 --stdout FETCH_HEAD,"['ingress/Chart.yaml', 'ingress/templates/deployment-ingress.yaml', 'releasenotes/notes/ingress.yaml']",3,4a224320d86367f2a1b5bc3f2810cf11c1366c1d,, - 0.2.11 Fix resource name in the role,,3,2
openstack%2Fopenstack-ansible-os_neutron~master~If4d4250528e39ba4c9f11713088fc2412ab9e5db,openstack/openstack-ansible-os_neutron,master,If4d4250528e39ba4c9f11713088fc2412ab9e5db,Enable experimental execution of LXB if required,MERGED,2022-10-25 11:02:04.000000000,2022-11-08 17:10:39.000000000,2022-11-08 17:09:31.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-25 11:02:04.000000000', 'files': ['templates/neutron.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/1a0077705f16c4132e0ab96fdf2aa038c54a9bbd', 'message': ""Enable experimental execution of LXB if required\n\nIn cases when neutron_plugin_type is set to ml2.lxb we should explicitly\nenable execution of LXB since it's experimental faeature starting Zed.\n\nChange-Id: If4d4250528e39ba4c9f11713088fc2412ab9e5db\n""}]",2,862594,1a0077705f16c4132e0ab96fdf2aa038c54a9bbd,12,3,1,28619,,,0,"Enable experimental execution of LXB if required

In cases when neutron_plugin_type is set to ml2.lxb we should explicitly
enable execution of LXB since it's experimental faeature starting Zed.

Change-Id: If4d4250528e39ba4c9f11713088fc2412ab9e5db
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/94/862594/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/neutron.conf.j2'],1,1a0077705f16c4132e0ab96fdf2aa038c54a9bbd,, {% if neutron_plugin_type == 'ml2.lxb' %} [experimental] linuxbridge = True {% endif %} ,,6,0
openstack%2Fopenstack-ansible-openstack_hosts~master~I2a8a91aaa535044966619706734d3ad07714d671,openstack/openstack-ansible-openstack_hosts,master,I2a8a91aaa535044966619706734d3ad07714d671,Switch codename to Zed,MERGED,2022-10-06 11:22:47.000000000,2022-11-08 17:02:43.000000000,2022-11-08 17:01:39.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-06 11:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/d705b889849d91acd9faf9acca1c53eeb3a9afa9', 'message': 'Switch codename to Zed\n\nChange-Id: I2a8a91aaa535044966619706734d3ad07714d671\n'}, {'number': 2, 'created': '2022-10-24 07:56:43.000000000', 'files': ['vars/ubuntu-22.04.yml', 'vars/ubuntu-20.04.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/eb042cb2c3343111a586a83f25b07bfd9c82c3c7', 'message': 'Switch codename to Zed\n\nChange-Id: I2a8a91aaa535044966619706734d3ad07714d671\n'}]",0,860551,eb042cb2c3343111a586a83f25b07bfd9c82c3c7,11,3,2,28619,,,0,"Switch codename to Zed

Change-Id: I2a8a91aaa535044966619706734d3ad07714d671
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/51/860551/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,d705b889849d91acd9faf9acca1c53eeb3a9afa9,,"openstack_distrib_code_name: ""Zed""","openstack_distrib_code_name: ""Yoga""",1,1
openstack%2Fheat~master~I1d3666b2cef54c2dcdf54217d65ad05b74dfceec,openstack/heat,master,I1d3666b2cef54c2dcdf54217d65ad05b74dfceec,Implement RouterInterface deletion checking,NEW,2022-11-08 15:34:20.000000000,2022-11-08 16:50:45.000000000,,"[{'_account_id': 9542}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 15:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3533e381ca4e3cc35ba1aac4b6050a986049d396', 'message': 'Implement RouterInterface deletion checking\n\nTo address async nature of resource deletion we\nneed to make handle_delete compatible with resource deletion API.\n\nCloses-Issue: PROD-32237\nChange-Id: I1d3666b2cef54c2dcdf54217d65ad05b74dfceec\n'}, {'number': 2, 'created': '2022-11-08 15:38:42.000000000', 'files': ['heat/engine/clients/progress.py', 'heat/engine/resources/openstack/neutron/router.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2018e46319d9ccce507e1cb5184edf2aeba4234d', 'message': 'Implement RouterInterface deletion checking\n\nTo address async nature of resource deletion we\nneed to make handle_delete compatible with resource deletion API.\n\nCloses-Issue: PROD-32237\nChange-Id: I1d3666b2cef54c2dcdf54217d65ad05b74dfceec\n'}]",8,864016,2018e46319d9ccce507e1cb5184edf2aeba4234d,6,2,2,35392,,,0,"Implement RouterInterface deletion checking

To address async nature of resource deletion we
need to make handle_delete compatible with resource deletion API.

Closes-Issue: PROD-32237
Change-Id: I1d3666b2cef54c2dcdf54217d65ad05b74dfceec
",git fetch https://review.opendev.org/openstack/heat refs/changes/16/864016/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/progress.py', 'heat/engine/resources/openstack/neutron/router.py']",2,3533e381ca4e3cc35ba1aac4b6050a986049d396,improve_handle_delete_router_interface,"from heat.engine import ( attributes, constraints, properties, support, translation, ) from heat.engine.clients import progress from heat.engine.resources.openstack.neutron import ( neutron, subnet, ) from oslo_log import log as logging LOG = logging.getLogger(__name__) check = None if not self.resource_id: return check tokens = self.resource_id.replace(""="", "":"").split("":"") if len(tokens) == 2: # compatible with old data tokens.insert(1, ""subnet_id"") check = progress.RouterInterfaceRemoveProgress(router_id, key, value) with self.client_plugin().ignore_conflict_and_not_found: check.called = self.client().remove_interface_router( router_id, {key: value} ) return check def check_delete_complete(self, check: ""progress.RouterInterfaceRemoveProgress""): if check is None: return True if not check.called: with self.client_plugin().ignore_not_found: check.called = self.client().remove_interface_router( check.router_id, {check.key: check.value} ) return False else: with self.client_plugin().ignore_not_found: return not self.client().list_ports( **{""id"": check.called.get(""port_id"")} ).get(""ports"")","from heat.engine import attributes from heat.engine import constraints from heat.engine import properties from heat.engine.resources.openstack.neutron import neutron from heat.engine.resources.openstack.neutron import subnet from heat.engine import support from heat.engine import translation if not self.resource_id: return tokens = self.resource_id.replace('=', ':').split(':') if len(tokens) == 2: # compatible with old data tokens.insert(1, 'subnet_id') with self.client_plugin().ignore_not_found: self.client().remove_interface_router( router_id, {key: value})",53,15
openstack%2Fneutron~stable%2Fwallaby~I50f07d41428e57e6bed9be16980a6c605b7d130e,openstack/neutron,stable/wallaby,I50f07d41428e57e6bed9be16980a6c605b7d130e,Allow shared net to be added on router,MERGED,2022-11-07 15:27:28.000000000,2022-11-08 16:45:27.000000000,2022-11-08 16:44:17.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24b05f6773735a18c8a2b080e22261a84c647f4c', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}, {'number': 2, 'created': '2022-11-08 08:51:04.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/caba9ec406e54d7f44147fbf01c524f8c1d567de', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nConflicts:\n    neutron/db/l3_db.py\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)\n'}]",1,863887,caba9ec406e54d7f44147fbf01c524f8c1d567de,13,3,2,16688,,,0,"Allow shared net to be added on router

This will subnets from shared networks to be added on routers using:
$ openstack router add subnet router_id subnet_id

Without this, neutron user must use a multi-router solution, which is
not convenient at all.

Conflicts:
    neutron/db/l3_db.py

Closes-Bug: #1975603
Related-Bug: #1757482

Signed-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>
Change-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e
(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)
(cherry picked from commit 05569382481fadb05cc69449b19364647a8c4cdb)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/87/863887/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,24b05f6773735a18c8a2b080e22261a84c647f4c,bug/1975603,"from neutron.objects import network as network_obj # NOTE(amorin): check if network is RBAC or globaly shared # globaly shared --> disallow adding interface (see LP-1757482) # RBAC shared --> allow adding interface (see LP-1975603) elevated = context.elevated() with db_api.CONTEXT_READER.using(elevated): rbac_allowed_projects = network_obj.NetworkRBAC.get_projects( elevated, object_id=subnet['network_id'], action='access_as_shared', target_project=context.project_id) # Fail if the current project_id is NOT in the allowed # projects if context.project_id not in rbac_allowed_projects: msg = (_('Cannot add interface to router because subnet ' '%s is not owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)"," msg = (_('Cannot add interface to router because subnet %s is not ' 'owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)",40,3
openstack%2Fopenstack-ansible-os_tacker~master~I70264ef5ffd6ebb851e4d3c4c86c28ea222f7139,openstack/openstack-ansible-os_tacker,master,I70264ef5ffd6ebb851e4d3c4c86c28ea222f7139,Add deployment of tacker-scheduler,MERGED,2022-10-19 10:52:13.000000000,2022-11-08 16:37:16.000000000,2022-11-08 16:36:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2022-10-19 10:52:13.000000000', 'files': ['tasks/main.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tacker/commit/a2800f0d284eaf0b1749dc761d3ecb388fed3bfd', 'message': ""Add deployment of tacker-scheduler\n\nThere's a long-standing bug from 2017 that tacker requires scheduler\nservice to run. However it seemed no real interest to tacker among OSA\nusers. Nevertheless it's better late then never fixing it.\n\nChange-Id: I70264ef5ffd6ebb851e4d3c4c86c28ea222f7139\nCloses-Bug: #1710874\n""}]",0,861870,a2800f0d284eaf0b1749dc761d3ecb388fed3bfd,10,4,1,28619,,,0,"Add deployment of tacker-scheduler

There's a long-standing bug from 2017 that tacker requires scheduler
service to run. However it seemed no real interest to tacker among OSA
users. Nevertheless it's better late then never fixing it.

Change-Id: I70264ef5ffd6ebb851e4d3c4c86c28ea222f7139
Closes-Bug: #1710874
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tacker refs/changes/70/861870/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'defaults/main.yml']",2,a2800f0d284eaf0b1749dc761d3ecb388fed3bfd,,"tacker_conductor_program_name: tacker-conductortacker_services: tacker-server: group: tacker_server service_name: ""{{ tacker_service_name }}"" enabled: yes state: started execstarts: ""{{ tacker_bin }}/{{ tacker_program_name }} {{ tacker_config_options|default('') }}"" config_overrides: ""{{ tacker_init_config_overrides }}"" tacker-conductor: group: tacker_server service_name: ""{{ tacker_conductor_program_name }}"" enabled: yes execstarts: ""{{ tacker_bin }}/{{ tacker_conductor_program_name }} {{ tacker_conductor_config_options|default('') }}"" config_overrides: ""{{ tacker_conductor_init_config_overrides }}"" tacker_conductor_config_options: ""{{ tacker_config_options }}""tacker_conductor_init_config_overrides: {}",,19,6
openstack%2Fneutron~stable%2Fxena~I50f07d41428e57e6bed9be16980a6c605b7d130e,openstack/neutron,stable/xena,I50f07d41428e57e6bed9be16980a6c605b7d130e,Allow shared net to be added on router,MERGED,2022-11-07 15:27:10.000000000,2022-11-08 16:27:51.000000000,2022-11-08 16:26:11.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3851230889daa003a0b93eacde397df4e2968d6e', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}, {'number': 2, 'created': '2022-11-08 08:50:28.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/05569382481fadb05cc69449b19364647a8c4cdb', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nConflicts:\n    neutron/db/l3_db.py\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}]",3,863886,05569382481fadb05cc69449b19364647a8c4cdb,13,3,2,16688,,,0,"Allow shared net to be added on router

This will subnets from shared networks to be added on routers using:
$ openstack router add subnet router_id subnet_id

Without this, neutron user must use a multi-router solution, which is
not convenient at all.

Conflicts:
    neutron/db/l3_db.py

Closes-Bug: #1975603
Related-Bug: #1757482

Signed-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>
Change-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e
(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/863886/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,3851230889daa003a0b93eacde397df4e2968d6e,bug/1975603,"from neutron.objects import network as network_obj # NOTE(amorin): check if network is RBAC or globaly shared # globaly shared --> disallow adding interface (see LP-1757482) # RBAC shared --> allow adding interface (see LP-1975603) elevated = context.elevated() with db_api.CONTEXT_READER.using(elevated): rbac_allowed_projects = network_obj.NetworkRBAC.get_projects( elevated, object_id=subnet['network_id'], action='access_as_shared', target_project=context.project_id) # Fail if the current project_id is NOT in the allowed # projects if context.project_id not in rbac_allowed_projects: msg = (_('Cannot add interface to router because subnet ' '%s is not owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)"," msg = (_('Cannot add interface to router because subnet %s is not ' 'owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)",40,3
openstack%2Fneutron~stable%2Fwallaby~I99d27d568f66c6330f6373843d096c6ee1b4ec54,openstack/neutron,stable/wallaby,I99d27d568f66c6330f6373843d096c6ee1b4ec54,Handle all portbinding attrs in case of bulk port creation,MERGED,2022-11-04 15:27:32.000000000,2022-11-08 16:27:45.000000000,2022-11-08 16:26:01.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 15:27:32.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/85126425c529fbee74ae8a9a7289e3ba28665228', 'message': 'Handle all portbinding attrs in case of bulk port creation\n\nBulk port creation should honor binding:vnic_type\nand binding:profile attributes from request.\n\nCloses-Bug: #1940074\nChange-Id: I99d27d568f66c6330f6373843d096c6ee1b4ec54\n(cherry picked from commit 3640ffa0c6968a2f802a9809e4f318fb229dad7d)\n'}]",1,863663,85126425c529fbee74ae8a9a7289e3ba28665228,9,3,1,15554,,,0,"Handle all portbinding attrs in case of bulk port creation

Bulk port creation should honor binding:vnic_type
and binding:profile attributes from request.

Closes-Bug: #1940074
Change-Id: I99d27d568f66c6330f6373843d096c6ee1b4ec54
(cherry picked from commit 3640ffa0c6968a2f802a9809e4f318fb229dad7d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/863663/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,85126425c529fbee74ae8a9a7289e3ba28665228,bug/1940074, port_dict[portbindings.VNIC_TYPE] = pdata.get( portbindings.VNIC_TYPE) port_dict[portbindings.PROFILE] = pdata.get( portbindings.PROFILE),,24,0
openstack%2Fneutron~stable%2Fyoga~I50f07d41428e57e6bed9be16980a6c605b7d130e,openstack/neutron,stable/yoga,I50f07d41428e57e6bed9be16980a6c605b7d130e,Allow shared net to be added on router,MERGED,2022-11-07 15:26:51.000000000,2022-11-08 16:27:43.000000000,2022-11-08 16:26:07.000000000,"[{'_account_id': 8313}, {'_account_id': 11583}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 15:26:51.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d34760ae5bd0d574f80e1a51b9a7d261451ca83', 'message': 'Allow shared net to be added on router\n\nThis will subnets from shared networks to be added on routers using:\n$ openstack router add subnet router_id subnet_id\n\nWithout this, neutron user must use a multi-router solution, which is\nnot convenient at all.\n\nCloses-Bug: #1975603\nRelated-Bug: #1757482\n\nSigned-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>\nChange-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e\n(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)\n'}]",2,863885,1d34760ae5bd0d574f80e1a51b9a7d261451ca83,10,4,1,16688,,,0,"Allow shared net to be added on router

This will subnets from shared networks to be added on routers using:
$ openstack router add subnet router_id subnet_id

Without this, neutron user must use a multi-router solution, which is
not convenient at all.

Closes-Bug: #1975603
Related-Bug: #1757482

Signed-off-by: Arnaud Morin <arnaud.morin@ovhcloud.com>
Change-Id: I50f07d41428e57e6bed9be16980a6c605b7d130e
(cherry picked from commit 8619c104b886517266f5b7ae7d19816aa5764dc0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/863885/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/extensions/test_l3.py', 'neutron/db/l3_db.py']",2,1d34760ae5bd0d574f80e1a51b9a7d261451ca83,bug/1975603,"from neutron.objects import network as network_obj # NOTE(amorin): check if network is RBAC or globaly shared # globaly shared --> disallow adding interface (see LP-1757482) # RBAC shared --> allow adding interface (see LP-1975603) elevated = context.elevated() with db_api.CONTEXT_READER.using(elevated): rbac_allowed_projects = network_obj.NetworkRBAC.get_projects( elevated, object_id=subnet['network_id'], action='access_as_shared', target_project=context.project_id) # Fail if the current project_id is NOT in the allowed # projects if context.project_id not in rbac_allowed_projects: msg = (_('Cannot add interface to router because subnet ' '%s is not owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)"," msg = (_('Cannot add interface to router because subnet %s is not ' 'owned by project making the request') % subnet_id) raise n_exc.BadRequest(resource='router', msg=msg)",40,3
openstack%2Fmanila~stable%2Fxena~If28d97a9916ce56d7f7bf93274f5618eee01c209,openstack/manila,stable/xena,If28d97a9916ce56d7f7bf93274f5618eee01c209,Check project permissions for share replicas,MERGED,2022-07-05 19:07:17.000000000,2022-11-08 16:08:40.000000000,2022-11-08 16:07:20.000000000,"[{'_account_id': 6413}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-07-05 19:07:17.000000000', 'files': ['manila/db/sqlalchemy/api.py', 'releasenotes/notes/bug-1922243-fix-project-only-replica-listing-f5f2b95ef14c3ded.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/6cc760e0a301051dcf6fc4bd8a3a36640584538d', 'message': 'Check project permissions for share replicas\n\nFixed the issue of returning more share replicas than we should\nbe in a project context. Derived project id from parent share in\nthe share replicas listing query in non-admin share replicas\nlisting request scenarios.\n\nChange-Id: If28d97a9916ce56d7f7bf93274f5618eee01c209\nCloses-Bug: #1922243\nDepends-On: I69c31a33c1aad8edae2d90ad6101da1be650be85\n(cherry picked from commit 6484de925119ffb3614921b59045a958a404d43d)\n(cherry picked from commit 886c2258528a8cd2ad2d8a68634a265a257f8c7d)\n'}]",2,848720,6cc760e0a301051dcf6fc4bd8a3a36640584538d,12,3,1,16643,,,0,"Check project permissions for share replicas

Fixed the issue of returning more share replicas than we should
be in a project context. Derived project id from parent share in
the share replicas listing query in non-admin share replicas
listing request scenarios.

Change-Id: If28d97a9916ce56d7f7bf93274f5618eee01c209
Closes-Bug: #1922243
Depends-On: I69c31a33c1aad8edae2d90ad6101da1be650be85
(cherry picked from commit 6484de925119ffb3614921b59045a958a404d43d)
(cherry picked from commit 886c2258528a8cd2ad2d8a68634a265a257f8c7d)
",git fetch https://review.opendev.org/openstack/manila refs/changes/20/848720/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/sqlalchemy/api.py', 'releasenotes/notes/bug-1922243-fix-project-only-replica-listing-f5f2b95ef14c3ded.yaml']",2,6cc760e0a301051dcf6fc4bd8a3a36640584538d,bug/1922243,"--- fixes: - | Fixed an issue that caused Manila to return all projects' share replicas even when the user was not an administrator. Now, when the user is not an administrator, only the replicas in the project perspective are going to be displayed. For more details, please refer to `Launchpad Bug #1922243 <https://bugs.launchpad.net/manila/+bug/1922243>`_ ",,14,0
openstack%2Fmanila~stable%2Fyoga~Icbfabb3bc0f608ebdd0784337db0921cc7763c53,openstack/manila,stable/yoga,Icbfabb3bc0f608ebdd0784337db0921cc7763c53,Fix DriverFilter/GoodnessWeigher string evaluations,MERGED,2022-09-14 05:29:12.000000000,2022-11-08 16:08:38.000000000,2022-11-08 16:07:18.000000000,"[{'_account_id': 6413}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-09-14 05:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8649204d6f260859c020bc418711750da1eff40e', 'message': 'Fix DriverFilter/GoodnessWeigher string evaluations\n\nWhen trying to compare two values that are non-numeric using the driver\nfilter, the filter function will give an error. This is not desirable as\nit might be interesting to support comparatives with non-numeric values\nprovided by the filter objects (share, host, etc). For example, the\nfollowing formula failed before the fix:\n\nfilter_function = \'(share.project_id == ""bb212f09317a4f4a8952ef3f729c2551"")\'\n\nCopied from cinder https://opendev.org/openstack/cinder/commit/87a7e80a2cbc4c8abcf4394242a02fcc5140e44b\n\nCloses-Bug: #1975715\nChange-Id: Icbfabb3bc0f608ebdd0784337db0921cc7763c53\n(cherry picked from commit a2ebe1eb9a54e15f842cdd85d32212f497e21c02)\n'}, {'number': 2, 'created': '2022-09-22 15:27:57.000000000', 'files': ['manila/tests/scheduler/evaluator/test_evaluator.py', 'manila/scheduler/evaluator/evaluator.py', 'releasenotes/notes/bug-1975715-fix-driverfilter-string-evaluations-3886a68d4d7fa3a1.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/1c021168b85cdb39681581cca87f664cab59c93e', 'message': 'Fix DriverFilter/GoodnessWeigher string evaluations\n\nWhen trying to compare two values that are non-numeric using the driver\nfilter, the filter function will give an error. This is not desirable as\nit might be interesting to support comparatives with non-numeric values\nprovided by the filter objects (share, host, etc). For example, the\nfollowing formula failed before the fix:\n\nfilter_function = \'(share.project_id == ""bb212f09317a4f4a8952ef3f729c2551"")\'\n\nCopied from cinder https://opendev.org/openstack/cinder/commit/87a7e80a2cbc4c8abcf4394242a02fcc5140e44b\n\nCloses-Bug: #1975715\nChange-Id: Icbfabb3bc0f608ebdd0784337db0921cc7763c53\n(cherry picked from commit a2ebe1eb9a54e15f842cdd85d32212f497e21c02)\n'}]",2,857474,1c021168b85cdb39681581cca87f664cab59c93e,17,3,2,16643,,,0,"Fix DriverFilter/GoodnessWeigher string evaluations

When trying to compare two values that are non-numeric using the driver
filter, the filter function will give an error. This is not desirable as
it might be interesting to support comparatives with non-numeric values
provided by the filter objects (share, host, etc). For example, the
following formula failed before the fix:

filter_function = '(share.project_id == ""bb212f09317a4f4a8952ef3f729c2551"")'

Copied from cinder https://opendev.org/openstack/cinder/commit/87a7e80a2cbc4c8abcf4394242a02fcc5140e44b

Closes-Bug: #1975715
Change-Id: Icbfabb3bc0f608ebdd0784337db0921cc7763c53
(cherry picked from commit a2ebe1eb9a54e15f842cdd85d32212f497e21c02)
",git fetch https://review.opendev.org/openstack/manila refs/changes/74/857474/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/scheduler/evaluator/test_evaluator.py', 'manila/scheduler/evaluator/evaluator.py', 'releasenotes/notes/bug-1975715-fix-driverfilter-string-evaluations-3886a68d4d7fa3a1.yaml']",3,8649204d6f260859c020bc418711750da1eff40e,bug/1975715,"--- fixes: - | Goodness_function expects integer or float else raise parseException. This causes example such as ""(share.share_proto == 'CIFS') ? 100 : 50"" to fail during evaluation. Fix it by adding support of string evalution. ",,17,9
openstack%2Fcharm-ceph-osd~master~I59bf4e41f1f56c6bda2352b5613289ff73113342,openstack/charm-ceph-osd,master,I59bf4e41f1f56c6bda2352b5613289ff73113342,Enable users to start/stop Crimson OSD's,MERGED,2022-09-05 20:15:25.000000000,2022-11-08 15:50:26.000000000,2022-11-08 15:08:26.000000000,"[{'_account_id': 15382}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-05 20:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/b716ff0a73d4a98fb82d9be8c434dd77add75b98', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset adds 2 new actions: {start/stop}-crimson-osd, which\nallow users to use Crimson as the (experimental) implementation\nfor Ceph OSD's.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 2, 'created': '2022-09-05 22:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/a9ac0a85e8c91c28d8e702b0a4b97ec4a85dd726', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset adds 2 new actions: {start/stop}-crimson-osd, which\nallow users to use Crimson as the (experimental) implementation\nfor Ceph OSD's.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 3, 'created': '2022-09-08 23:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/c750f26c63898d56f16ce181b9e869ef389a79a8', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset adds 2 new actions: {start/stop}-crimson-osd, which\nallow users to use Crimson as the (experimental) implementation\nfor Ceph OSD's.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 4, 'created': '2022-09-09 00:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/b4f08eb5033e522aedc4a4a27a8c907bb48d347e', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset adds 2 new actions: {start/stop}-crimson-osd, which\nallow users to use Crimson as the (experimental) implementation\nfor Ceph OSD's.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 5, 'created': '2022-09-20 21:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/553ddab661bf61ba6b7ff5be93d1ffb24b5350c0', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 6, 'created': '2022-09-20 23:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/433327c11f83f206b1a854542cf59bba87a5f5a3', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 7, 'created': '2022-09-21 23:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/6944d083be27cdb128b5b1ea99a811a9dad3722c', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 8, 'created': '2022-09-22 23:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/1e145c9499d7a42171eab8b50a447546cd5e2113', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 9, 'created': '2022-09-23 17:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/cc66d2d484d76b37d994040296ff665482ef10c4', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 10, 'created': '2022-10-11 17:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/f10cf8aca88774d9bf905a5d1d8816509956884d', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 11, 'created': '2022-10-11 18:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/c9a1c5511579c1d9cb51f74217f16834f3c0e221', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 12, 'created': '2022-10-18 21:11:57.000000000', 'files': ['files/systemd/crimson-osd@.service', 'unit_tests/test_actions_add_disk.py', 'actions/add_disk.py', 'tox.ini', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/dbe3ee52bcccc1afec40def2234d4a78d1272d61', 'message': ""Enable users to start/stop Crimson OSD's\n\nThis patchset modifies the add-disk action so that it now\ncan optionally start a Crimson OSD daemon.\n\nChange-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342\nDepends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}]",44,855982,dbe3ee52bcccc1afec40def2234d4a78d1272d61,67,4,12,33717,,,0,"Enable users to start/stop Crimson OSD's

This patchset modifies the add-disk action so that it now
can optionally start a Crimson OSD daemon.

Change-Id: I59bf4e41f1f56c6bda2352b5613289ff73113342
Depends-On: If58bde4d5445ed5de420abc007db6bf8b8e43269
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/82/855982/12 && git format-patch -1 --stdout FETCH_HEAD,"['actions/start_crimson_osd.py', 'actions/use-crimson-osd', 'unit_tests/test_actions_use_crimson_osd.py', 'actions/start-crimson-osd', 'actions/stop-crimson-osd', 'actions.yaml']",6,b716ff0a73d4a98fb82d9be8c434dd77add75b98,,"start-crimson-osd: description: | Use the experimental Crimson OSD implementation for a set of OSD's. Use with care, as Crimson cannot be considered production-ready yet. params: osds: type: string description: Comma-separated list of OSD's for which to use Crimson. i-really-mean-it: type: boolean description: Must be toggled to enable actually performing this action required: - osds - i-really-mean-it stop-crimson-osd: description: Stop the specified OSD ids, which must be running with Crimson. params: osds: type: string description: Comma-separated list of OSD IDs to stop required: - osds",,215,0
openstack%2Fansible-collections-openstack~master~I3a7a0b0567ac24fb9433352fdc99022bf366fc6a,openstack/ansible-collections-openstack,master,I3a7a0b0567ac24fb9433352fdc99022bf366fc6a,Fixed check mode,MERGED,2022-11-08 12:48:26.000000000,2022-11-08 15:13:13.000000000,2022-11-08 15:13:13.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-08 12:48:26.000000000', 'files': ['plugins/modules/port.py', 'plugins/modules/volume_backup.py', 'plugins/modules/baremetal_node.py', 'plugins/modules/server.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8c889f8eb35e8a4161e5419114f114d35b84020e', 'message': 'Fixed check mode\n\nChange-Id: I3a7a0b0567ac24fb9433352fdc99022bf366fc6a\n'}]",0,864001,8c889f8eb35e8a4161e5419114f114d35b84020e,9,5,1,32962,,,0,"Fixed check mode

Change-Id: I3a7a0b0567ac24fb9433352fdc99022bf366fc6a
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/01/864001/1 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/port.py', 'plugins/modules/volume_backup.py', 'plugins/modules/baremetal_node.py', 'plugins/modules/server.py']",4,8c889f8eb35e8a4161e5419114f114d35b84020e,check-mode, return True return False, return False return True,8,8
openstack%2Fosc-lib~master~I4b91180749f947d2a6874b76fb5d429829d8a658,openstack/osc-lib,master,I4b91180749f947d2a6874b76fb5d429829d8a658,WIP Add support for deferred plugin loading,NEW,2020-06-13 14:45:46.000000000,2022-11-08 14:58:26.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-06-13 14:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/f982bee3037315da7db7a779abeb5c6ce9ffef71', 'message': 'Defer plugin loading\n\nDepends-On: https://review.opendev.org/733961\nChange-Id: I4b91180749f947d2a6874b76fb5d429829d8a658\n'}, {'number': 2, 'created': '2020-06-15 15:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/4f0c5dafc22f618f1e5fd61fa7a46fe94fa83f55', 'message': 'WIP Add support for deferred plugin loading\n\nSupport was added in cliff to allow builtings to be\nused without loading plugins and then to only load\nplugins on demand. Plumb that through here.\n\nThis is going to need a cliff release and a min bump.\n\nDepends-On: https://review.opendev.org/733961\nChange-Id: I4b91180749f947d2a6874b76fb5d429829d8a658\n'}, {'number': 3, 'created': '2022-11-07 16:27:12.000000000', 'files': ['releasenotes/notes/support-deferred-plugin-loading-9cfa55473213dd5f.yaml', 'osc_lib/shell.py'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/cafd38216bacae2257da511d6ec00b81b7bffdf8', 'message': 'WIP Add support for deferred plugin loading\n\nSupport was added in cliff to allow builtings to be\nused without loading plugins and then to only load\nplugins on demand. Plumb that through here.\n\nThis is going to need a cliff release and a min bump.\n\nDepends-On: https://review.opendev.org/733961\nChange-Id: I4b91180749f947d2a6874b76fb5d429829d8a658\n'}]",2,735430,cafd38216bacae2257da511d6ec00b81b7bffdf8,10,1,3,2,,,0,"WIP Add support for deferred plugin loading

Support was added in cliff to allow builtings to be
used without loading plugins and then to only load
plugins on demand. Plumb that through here.

This is going to need a cliff release and a min bump.

Depends-On: https://review.opendev.org/733961
Change-Id: I4b91180749f947d2a6874b76fb5d429829d8a658
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/30/735430/2 && git format-patch -1 --stdout FETCH_HEAD,['osc_lib/shell.py'],1,f982bee3037315da7db7a779abeb5c6ce9ffef71,osc-plugin-optimize," load_plugins=False, load_plugins=load_plugins, if self.load_plugins: self._load_plugins()", self._load_plugins(),4,1
openstack%2Fcharms.ceph~master~If58bde4d5445ed5de420abc007db6bf8b8e43269,openstack/charms.ceph,master,If58bde4d5445ed5de420abc007db6bf8b8e43269,Consider crimson-osds as well,MERGED,2022-09-05 19:15:46.000000000,2022-11-08 14:48:05.000000000,2022-11-08 14:48:05.000000000,"[{'_account_id': 20634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-05 19:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/3ea29fc35d1400f0476f82cd4d74c5b101a357fa', 'message': ""Consider crimson-osds as well\n\nThis patchset modifies the 'get_running_osds' function so that\nit also considers crimson-osds as valid OSD's.\n\nChange-Id: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}, {'number': 2, 'created': '2022-10-19 20:09:54.000000000', 'files': ['charms_ceph/utils.py', 'unit_tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/84adacf5c8015465e715d628d258c3616d3c60bf', 'message': ""Consider crimson-osds as well\n\nThis patchset modifies the 'get_running_osds' function so that\nit also considers crimson-osds as valid OSD's. In addition, it\nalso modifies the 'get_local_osd_ids' to _not_ include Crimson\nOSDs so that unsupported functionality doesn't make some hooks\nfail in the ceph-osd charm.\n\nChange-Id: If58bde4d5445ed5de420abc007db6bf8b8e43269\n""}]",0,855978,84adacf5c8015465e715d628d258c3616d3c60bf,8,2,2,33717,,,0,"Consider crimson-osds as well

This patchset modifies the 'get_running_osds' function so that
it also considers crimson-osds as valid OSD's. In addition, it
also modifies the 'get_local_osd_ids' to _not_ include Crimson
OSDs so that unsupported functionality doesn't make some hooks
fail in the ceph-osd charm.

Change-Id: If58bde4d5445ed5de420abc007db6bf8b8e43269
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/78/855978/1 && git format-patch -1 --stdout FETCH_HEAD,['charms_ceph/utils.py'],1,3ea29fc35d1400f0476f82cd4d74c5b101a357fa,crimson-osds," cmd = ['pgrep', 'ceph-osd|crimson-osd']"," cmd = ['pgrep', 'ceph-osd']",1,1
openstack%2Fcharms.ceph~master~I62e5cff169ea1ed2c5707156f5eb035206fbd410,openstack/charms.ceph,master,I62e5cff169ea1ed2c5707156f5eb035206fbd410,Add helpers for removing an OSD,ABANDONED,2020-01-31 07:18:27.000000000,2022-11-08 14:44:48.000000000,,"[{'_account_id': 20634}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-31 07:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/fb27bd4779f0a8524bde179128d80543793867a0', 'message': 'Add helpers for removing an OSD\n\nChange-Id: I62e5cff169ea1ed2c5707156f5eb035206fbd410\n'}, {'number': 2, 'created': '2020-01-31 08:05:23.000000000', 'files': ['unit_tests/test_utils.py', 'ceph/utils.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/6cccbbb73eee0627a74aa6e321d453beb8799bf9', 'message': 'Add helpers for removing an OSD\n\nChange-Id: I62e5cff169ea1ed2c5707156f5eb035206fbd410\n'}]",0,705164,6cccbbb73eee0627a74aa6e321d453beb8799bf9,6,2,2,20634,,,0,"Add helpers for removing an OSD

Change-Id: I62e5cff169ea1ed2c5707156f5eb035206fbd410
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/64/705164/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph/utils.py'],1,fb27bd4779f0a8524bde179128d80543793867a0,bug/1629679," service_pause, def remove_osds(ignore_errors=False): """"""Remove OSDs on this machine from the CRUSH map and auth."""""" reweight_all_to_zero(ignore_errors=ignore_errors) osd_out_all() purge_all_osds() def purge_osd(osd_id): luminous_or_later = cmp_pkgrevno('ceph-common', '12.0.0') >= 0 # failure_domain changed in luminous if luminous_or_later: try: log(""Purging OSD {}"".format(osd_id)) subprocess.check_call([""ceph"", ""--id"", ""osd-upgrade"", ""osd"", ""purge"", str(osd_id), ""--yes-i-really-mean-it""]) except subprocess.CalledProcessError as e: log(e) raise else: return old_purge(osd_id) def old_purge(osd_id): """"""Pre-luminous, we have to manually purge the OSD."""""" commands = [ [ ""ceph"", ""--id"", ""osd-upgrade"", ""osd"", ""crush"", ""remove"", ""osd.{}"".format(osd_id) ], [ ""ceph"", ""--id"", ""osd-upgrade"", ""auth"", ""del"", ""osd.{}"".format(osd_id) ], [ ""ceph"", ""--id"", ""osd-upgrade"", ""osd"", ""rm"", ""{}"".format(osd_id) ], ] for command in commands: try: log(""Calling {}"".format(command)) subprocess.check_call(command) except subprocess.CalledProcessError as e: log(e) raise def purge_all_osds(ignore_errors=False): for osd_id in get_local_osd_ids(): try: purge_osd(osd_id) except subprocess.CalledProcessError: if not ignore_errors: raise def osd_out(osd_id): try: log('running ceph osd out {}'.format(osd_id)) subprocess.check_call(['ceph', '--id', 'osd-upgrade', 'osd', 'out', str(osd_id)]) return True except subprocess.CalledProcessError as e: log(e) raise def osd_out_all(ignore_errors=False): for osd_id in get_local_osd_ids(): try: osd_out(osd_id) except subprocess.CalledProcessError: if not ignore_errors: raise def reweight_all_to_zero(ignore_errors=False): """"""Reweight all OSDs on this machien to 0."""""" for osd_id in get_local_osd_ids(): try: reweight_osd(osd_id, ""0"") except subprocess.CalledProcessError: if not ignore_errors: raise def disable(): """"""Stop the ceph-osd process from running and disable on restarts."""""" if systemd(): for osd_id in get_local_osd_ids(): service_name = 'ceph-osd@{}'.format(osd_id) service_pause(service_name) else: service_name = 'ceph-osd-all' service_pause(service_name)",,101,0
openstack%2Ftripleo-ansible~stable%2Fzed~Ic28add116c369979b4038ce403451dc95dc2f53d,openstack/tripleo-ansible,stable/zed,Ic28add116c369979b4038ce403451dc95dc2f53d,num_dpdk_interface_rx_queues support net conf schema,MERGED,2022-11-08 04:16:30.000000000,2022-11-08 14:38:13.000000000,2022-11-08 14:37:10.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2022-11-08 04:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/9c5c3c327e68ecf308f3e9ade06c1b48caa22ab0', 'message': ""num_dpdk_interface_rx_queues support net conf schema\n\nThe network_config schema in the baremetal provision defintion\ndid not allow setting the 'num_dpdk_interface_rx_queues'.\n\nThis change adds the varaible to the schema, and adds the option\nin module: tripleo_generate_inventory_network_config. By default\nthe value is 1, which is the same default used in THT for parameter\nNumDpdkInterfaceRxQueues.\n\nCloses-Bug: #1989593\nChange-Id: Ic28add116c369979b4038ce403451dc95dc2f53d\n""}, {'number': 2, 'created': '2022-11-08 08:29:03.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_generate_inventory_network_config.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py', 'releasenotes/notes/net-conf-schema-num_dpdk_interface_rx_queues-4a37e4fc3957ed9a.yaml', 'tripleo_ansible/tests/modules/test_tripleo_generate_inventory_network_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f7088db68d62ad8c43c53dd239f83ea3b3576a2d', 'message': ""num_dpdk_interface_rx_queues support net conf schema\n\nThe network_config schema in the baremetal provision defintion\ndid not allow setting the 'num_dpdk_interface_rx_queues'.\n\nThis change adds the varaible to the schema, and adds the option\nin module: tripleo_generate_inventory_network_config. By default\nthe value is 1, which is the same default used in THT for parameter\nNumDpdkInterfaceRxQueues.\n\nCloses-Bug: #1989593\nChange-Id: Ic28add116c369979b4038ce403451dc95dc2f53d\n(cherry picked from commit c3315623fe23864ce34e63ae364c7a2d200679a4)\n""}]",3,863793,f7088db68d62ad8c43c53dd239f83ea3b3576a2d,16,3,2,30073,,,0,"num_dpdk_interface_rx_queues support net conf schema

The network_config schema in the baremetal provision defintion
did not allow setting the 'num_dpdk_interface_rx_queues'.

This change adds the varaible to the schema, and adds the option
in module: tripleo_generate_inventory_network_config. By default
the value is 1, which is the same default used in THT for parameter
NumDpdkInterfaceRxQueues.

Closes-Bug: #1989593
Change-Id: Ic28add116c369979b4038ce403451dc95dc2f53d
(cherry picked from commit c3315623fe23864ce34e63ae364c7a2d200679a4)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/93/863793/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_generate_inventory_network_config.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py', 'releasenotes/notes/net-conf-schema-num_dpdk_interface_rx_queues-4a37e4fc3957ed9a.yaml', 'tripleo_ansible/tests/modules/test_tripleo_generate_inventory_network_config.py']",4,9c5c3c327e68ecf308f3e9ade06c1b48caa22ab0,bug/1989593-stable/zed," 'num_dpdk_interface_rx_queues': 1, 'num_dpdk_interface_rx_queues': 1,",,14,0
openstack%2Fcharm-ceph-mon~stable%2Fquincy~Ic389c840cc4253adaddcaa50d184db6ca66cb397,openstack/charm-ceph-mon,stable/quincy,Ic389c840cc4253adaddcaa50d184db6ca66cb397,Work around config initialisation behaviour change,ABANDONED,2022-11-08 14:23:02.000000000,2022-11-08 14:30:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-08 14:23:02.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/b6763c6ec793a39ee99f2ae2a7c86f9c239566a2', 'message': 'Work around config initialisation behaviour change\n\nThe previous (classic) version of the charm initialised a Config\nobject in the install hook and let it go out of scope. Initialise\na config object explicitly in the install and upgrade charm hooks.\n\nChange-Id: Ic389c840cc4253adaddcaa50d184db6ca66cb397\n'}]",0,863804,b6763c6ec793a39ee99f2ae2a7c86f9c239566a2,3,1,1,15382,,,0,"Work around config initialisation behaviour change

The previous (classic) version of the charm initialised a Config
object in the install hook and let it go out of scope. Initialise
a config object explicitly in the install and upgrade charm hooks.

Change-Id: Ic389c840cc4253adaddcaa50d184db6ca66cb397
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/04/863804/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,b6763c6ec793a39ee99f2ae2a7c86f9c239566a2,fix/persistent-config-init-stable/quincy,"<<<<<<< HEAD (a2b6b1 Resync charms.ceph) ======= #! /usr/bin/python3 import logging from ops.main import main import ceph_status import ceph_mds import charms.operator_libs_linux.v0.apt as apt import charms.operator_libs_linux.v1.systemd as systemd from ops.charm import CharmEvents from ops.framework import EventBase, EventSource import ops_openstack.core import charms_ceph.utils as ceph from charms_ceph.broker import ( process_requests ) import ceph_hooks as hooks import ceph_client import ceph_metrics import ops_actions logger = logging.getLogger(__name__) class NotifyClientEvent(EventBase): def __init__(self, handle): super().__init__(handle) class CephCharmEvents(CharmEvents): """"""Custom charm events."""""" notify_clients = EventSource(NotifyClientEvent) class CephMonCharm(ops_openstack.core.OSBaseCharm): release = 'quincy' PACKAGES = [ 'ceph', 'gdisk', 'radosgw', 'lvm2', 'parted', 'smartmontools', ] on = CephCharmEvents() # General charm control callbacks. # TODO: Figure out how to do hardening in an operator-framework # world def _initialise_config(self): # The following two lines are a horrible hack to deal with the # lifecycle of a charm changing compared to the classic charm. # The previous (classic) version of the charm initialised a # Config object in the install hook and let it go out of scope. # As a result of this, the config_changed processing attempts # to upgrade Ceph from distro to the configured release when it # runs during the install or upgrade-charm hooks. c = hooks.config() c.save() def on_install(self, event): self._initialise_config() self.install_pkgs() rm_packages = ceph.determine_packages_to_remove() if rm_packages: apt.remove_package(packages=rm_packages, fatal=True) try: # we defer and explicitly run `ceph-create-keys` from # add_keyring_to_ceph() as part of bootstrap process # LP: #1719436. systemd.service_pause('ceph-create-keys') except systemd.SystemdError: pass def on_config(self, event): if hooks.config_changed(): self.on.notify_clients.emit() def on_pre_series_upgrade(self, event): hooks.pre_series_upgrade() def on_upgrade(self, event): self._initialise_config() self.metrics_endpoint.update_alert_rules() hooks.upgrade_charm() self.on.notify_clients.emit() def on_post_series_upgrade(self, event): hooks.post_series_upgrade() # Relations. def on_mon_relation_joined(self, event): hooks.mon_relation_joined() def on_bootstrap_source_relation_changed(self, event): if hooks.bootstrap_source_relation_changed(): self.on.notify_clients.emit() def on_prometheus_relation_joined_or_changed(self, event): hooks.prometheus_relation() def on_prometheus_relation_departed(self, event): hooks.prometheus_left() def on_mon_relation(self, event): if hooks.mon_relation(): self.on.notify_clients.emit() def on_osd_relation(self, event): hooks.osd_relation() self.on.notify_clients.emit() def on_dashboard_relation_joined(self, event): hooks.dashboard_relation() def on_radosgw_relation(self, event): hooks.radosgw_relation() def on_rbd_mirror_relation(self, event): if hooks.rbd_mirror_relation(): self.on.notify_clients.emit() def on_admin_relation(self, event): hooks.admin_relation_joined() def on_nrpe_relation(self, event): hooks.update_nrpe_config() def on_commit(self, _event): self.ceph_status.assess_status() # Actions. def _observe_action(self, on_action, callable): def _make_method(fn): return lambda _, event: fn(event) method_name = 'on_' + str(on_action.event_kind) method = _make_method(callable) # In addition to being a method, the action callbacks _must_ have # the same '__name__' as their attribute name (this is how lookups # work in the operator framework world). method.__name__ = method_name inst = type(self) setattr(inst, method_name, method) self.framework.observe(on_action, getattr(self, method_name)) def is_blocked_insecure_cmr(self): remote_block = False remote_unit_name = hooks.remote_unit() if remote_unit_name and hooks.is_cmr_unit(remote_unit_name): remote_block = not self.config['permit-insecure-cmr'] return remote_block def notify_clients(self, _event): self.clients.notify_all() self.mds.notify_all() for relation in self.model.relations['admin']: hooks.admin_relation_joined(str(relation.id)) def __init__(self, *args): super().__init__(*args) self._stored.is_started = True if self.is_blocked_insecure_cmr(): logging.error( ""Not running hook, CMR detected and not supported"") return fw = self.framework self.clients = ceph_client.CephClientProvides(self) self.metrics_endpoint = ceph_metrics.CephMetricsEndpointProvider(self) self.ceph_status = ceph_status.StatusAssessor(self) self.mds = ceph_mds.CephMdsProvides(self) self._observe_action(self.on.change_osd_weight_action, ops_actions.change_osd_weight.change_osd_weight) self._observe_action(self.on.copy_pool_action, ops_actions.copy_pool.copy_pool) self._observe_action(self.on.create_crush_rule_action, ops_actions.create_crush_rule.create_crush_rule) self._observe_action( self.on.create_erasure_profile_action, ops_actions.create_erasure_profile.create_erasure_profile_action) self._observe_action(self.on.get_health_action, ops_actions.get_health.get_health_action) self._observe_action(self.on.get_erasure_profile_action, ops_actions.get_erasure_profile.erasure_profile) fw.observe(self.on.install, self.on_install) fw.observe(self.on.config_changed, self.on_config) fw.observe(self.on.pre_series_upgrade, self.on_pre_series_upgrade) fw.observe(self.on.upgrade_charm, self.on_upgrade) fw.observe(self.on.post_series_upgrade, self.on_post_series_upgrade) fw.observe(self.on.mon_relation_joined, self.on_mon_relation_joined) fw.observe(self.on.bootstrap_source_relation_changed, self.on_bootstrap_source_relation_changed) fw.observe(self.on.prometheus_relation_joined, self.on_prometheus_relation_joined_or_changed) fw.observe(self.on.prometheus_relation_changed, self.on_prometheus_relation_joined_or_changed) fw.observe(self.on.prometheus_relation_departed, self.on_prometheus_relation_departed) for key in ('mon_relation_departed', 'mon_relation_changed', 'leader_settings_changed', 'bootstrap_source_relation_departed'): fw.observe(getattr(self.on, key), self.on_mon_relation) fw.observe(self.on.osd_relation_joined, self.on_osd_relation) fw.observe(self.on.osd_relation_changed, self.on_osd_relation) fw.observe(self.on.dashboard_relation_joined, self.on_dashboard_relation_joined) fw.observe(self.on.radosgw_relation_changed, self.on_radosgw_relation) fw.observe(self.on.radosgw_relation_joined, self.on_radosgw_relation) fw.observe(self.on.rbd_mirror_relation_changed, self.on_rbd_mirror_relation) fw.observe(self.on.rbd_mirror_relation_joined, self.on_rbd_mirror_relation) fw.observe(self.on.admin_relation_changed, self.on_admin_relation) fw.observe(self.on.admin_relation_joined, self.on_admin_relation) fw.observe(self.on.nrpe_external_master_relation_joined, self.on_nrpe_relation) fw.observe(self.on.nrpe_external_master_relation_changed, self.on_nrpe_relation) fw.observe(self.on.notify_clients, self.notify_clients) def ready_for_service(self): return hooks.ready_for_service() def process_broker_request(self, broker_req_id, requests, recurse=True): broker_result = process_requests(requests) if hooks.relation_ids('rbd-mirror'): # NOTE(fnordahl): juju relation level data candidate # notify mons to flag that the other mon units should update # their ``rbd-mirror`` relations with information about new # pools. logger.debug('Notifying peers after processing broker' 'request {}.'.format(broker_req_id)) hooks.notify_mons() # notify_rbd_mirrors is the only case where this is False if recurse: # update ``rbd-mirror`` relations for this unit with # information about new pools. logger.debug( 'Notifying this units rbd-mirror relations after ' 'processing broker request {}.'.format(broker_req_id)) hooks.notify_rbd_mirrors() return broker_result if __name__ == '__main__': main(CephMonCharm) >>>>>>> CHANGE (d76dda Work around config initialisation behaviour change) ",,278,0
openstack%2Fcharm-ceph-mon~master~Ic389c840cc4253adaddcaa50d184db6ca66cb397,openstack/charm-ceph-mon,master,Ic389c840cc4253adaddcaa50d184db6ca66cb397,Work around config initialisation behaviour change,MERGED,2022-11-02 13:40:20.000000000,2022-11-08 14:27:48.000000000,2022-11-08 14:27:48.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-02 13:40:20.000000000', 'files': ['src/charm.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/d76dda4f5586b752451d5a9256097a620f1aade0', 'message': 'Work around config initialisation behaviour change\n\nThe previous (classic) version of the charm initialised a Config\nobject in the install hook and let it go out of scope. Initialise\na config object explicitly in the install and upgrade charm hooks.\n\nChange-Id: Ic389c840cc4253adaddcaa50d184db6ca66cb397\n'}]",0,863269,d76dda4f5586b752451d5a9256097a620f1aade0,7,3,1,15382,,,0,"Work around config initialisation behaviour change

The previous (classic) version of the charm initialised a Config
object in the install hook and let it go out of scope. Initialise
a config object explicitly in the install and upgrade charm hooks.

Change-Id: Ic389c840cc4253adaddcaa50d184db6ca66cb397
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/69/863269/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,d76dda4f5586b752451d5a9256097a620f1aade0,fix/persistent-config-init," def _initialise_config(self): # The following two lines are a horrible hack to deal with the # lifecycle of a charm changing compared to the classic charm. # The previous (classic) version of the charm initialised a # Config object in the install hook and let it go out of scope. # As a result of this, the config_changed processing attempts # to upgrade Ceph from distro to the configured release when it # runs during the install or upgrade-charm hooks. c = hooks.config() c.save() def on_install(self, event): self._initialise_config() self._initialise_config()"," def on_install(self, event):",14,0
openstack%2Faodh~stable%2Fwallaby~Ief75ccdc0fe5c6a197fc05bc481a5be096447558,openstack/aodh,stable/wallaby,Ief75ccdc0fe5c6a197fc05bc481a5be096447558,Ignore Gnocchi API error when the metric is not yet created,MERGED,2022-11-08 10:14:58.000000000,2022-11-08 14:08:14.000000000,2022-11-08 14:07:03.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-08 10:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/7806ec923c5afe97c1daab6ccd0cc135e1b64076', 'message': 'Ignore Gnocchi API error when the metric is not yet created\n\nChange 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8 replaced usage of\nmetric aggregate API by Dynamic aggregate API.\n\nHowever the Dynamic aggregate API returns a different response code\n(not 404, but 400) in Gnocchi <= 4.4 and this is causing the direct API\nerror when the metric associated with the aggregation does not exist.\n\nThis change adds 400 to the ignored response codes so that Aodh api\ndoes not return error even when the associated metric is not yet\ncreated in Gnocchi.\n\nDepends-On: https://review.opendev.org/c/openstack/telemetry-tempest-plugin/+/853829\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/854807\n\nCloses-Bug: #1974682\nChange-Id: Ief75ccdc0fe5c6a197fc05bc481a5be096447558\n(cherry picked from commit 214be56b3865d4d5bc30eaf0cb4b56bde9577f8c)\n(cherry picked from commit 2ad64b04e858565fb830ba207841b70edf5ff347)\n(cherry picked from commit 231f404ad13bac69964f19b9b1bfa5a42c1f977a)\n'}, {'number': 2, 'created': '2022-11-08 10:15:29.000000000', 'files': ['aodh/api/controllers/v2/alarm_rules/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/8454cac06a654bb1e4eea20e6a36417796a94d82', 'message': 'Ignore Gnocchi API error when the metric is not yet created\n\nChange 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8 replaced usage of\nmetric aggregate API by Dynamic aggregate API.\n\nHowever the Dynamic aggregate API returns a different response code\n(not 404, but 400) in Gnocchi <= 4.4 and this is causing the direct API\nerror when the metric associated with the aggregation does not exist.\n\nThis change adds 400 to the ignored response codes so that Aodh api\ndoes not return error even when the associated metric is not yet\ncreated in Gnocchi.\n\nDepends-On: https://review.opendev.org/c/openstack/telemetry-tempest-plugin/+/853829\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/855344\n\nCloses-Bug: #1974682\nChange-Id: Ief75ccdc0fe5c6a197fc05bc481a5be096447558\n(cherry picked from commit 214be56b3865d4d5bc30eaf0cb4b56bde9577f8c)\n(cherry picked from commit 2ad64b04e858565fb830ba207841b70edf5ff347)\n(cherry picked from commit 231f404ad13bac69964f19b9b1bfa5a42c1f977a)\n'}]",1,863796,8454cac06a654bb1e4eea20e6a36417796a94d82,8,2,2,32240,,,0,"Ignore Gnocchi API error when the metric is not yet created

Change 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8 replaced usage of
metric aggregate API by Dynamic aggregate API.

However the Dynamic aggregate API returns a different response code
(not 404, but 400) in Gnocchi <= 4.4 and this is causing the direct API
error when the metric associated with the aggregation does not exist.

This change adds 400 to the ignored response codes so that Aodh api
does not return error even when the associated metric is not yet
created in Gnocchi.

Depends-On: https://review.opendev.org/c/openstack/telemetry-tempest-plugin/+/853829
Depends-On: https://review.opendev.org/c/openstack/devstack/+/855344

Closes-Bug: #1974682
Change-Id: Ief75ccdc0fe5c6a197fc05bc481a5be096447558
(cherry picked from commit 214be56b3865d4d5bc30eaf0cb4b56bde9577f8c)
(cherry picked from commit 2ad64b04e858565fb830ba207841b70edf5ff347)
(cherry picked from commit 231f404ad13bac69964f19b9b1bfa5a42c1f977a)
",git fetch https://review.opendev.org/openstack/aodh refs/changes/96/863796/1 && git format-patch -1 --stdout FETCH_HEAD,['aodh/api/controllers/v2/alarm_rules/gnocchi.py'],1,7806ec923c5afe97c1daab6ccd0cc135e1b64076,bug/1974682-stable/yoga-stable/xena-stable/wallaby," # doesn't exists yet, it doesn't matter. return if e.code == 400 and 'Metrics not found' in e.message[""cause""]: # NOTE(tkajinam): Gnocchi<4.5 returns 400 instead of 404"," # doesn't exists yet, it doesn't matter",4,1
openstack%2Fcinder~stable%2Fyoga~Id1e40fd42b88c63dbbba2aaae77c40660ddac4c7,openstack/cinder,stable/yoga,Id1e40fd42b88c63dbbba2aaae77c40660ddac4c7,NFS: Fix generic revert to snapshot flow,MERGED,2022-09-29 12:20:32.000000000,2022-11-08 14:06:04.000000000,2022-10-29 14:41:25.000000000,"[{'_account_id': 5314}, {'_account_id': 13671}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30396}]","[{'number': 1, 'created': '2022-09-29 12:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1dc950b826acdab740cbcfbe119c0c31a9833a07', 'message': ""NFS: Fix generic revert to snapshot flow\n\nWhile reverting to a snapshot with generic flow, we create a\ntemporary volume from snapshot and copy data from temporary to the\noriginal volume.\nWhile creating this temporary volume, the snapshot is in 'restoring'\nstate whereas the remotefs driver only accepts 'available' and\n'backing-up' states for this operation.\nThis patch adds the 'restoring' state to the list of acceptable states.\n\nCloses-Bug: 1946059\n\nChange-Id: Id1e40fd42b88c63dbbba2aaae77c40660ddac4c7\n(cherry picked from commit 862edca0deb366ea980485359216fea020a03c9e)\n""}, {'number': 2, 'created': '2022-10-28 20:08:37.000000000', 'files': ['cinder/tests/unit/volume/drivers/test_nfs.py', 'releasenotes/notes/fix-nfs-revert-to-snap-adc04204b3661d66.yaml', 'cinder/volume/drivers/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a3c8857ee30205a2f0d0302728b3bcd4db8419fc', 'message': ""NFS: Fix generic revert to snapshot flow\n\nWhile reverting to a snapshot with generic flow, we create a\ntemporary volume from snapshot and copy data from temporary to the\noriginal volume.\nWhile creating this temporary volume, the snapshot is in 'restoring'\nstate whereas the remotefs driver only accepts 'available' and\n'backing-up' states for this operation.\nThis patch adds the 'restoring' state to the list of acceptable states.\n\nCloses-Bug: 1946059\n\nChange-Id: Id1e40fd42b88c63dbbba2aaae77c40660ddac4c7\n(cherry picked from commit 862edca0deb366ea980485359216fea020a03c9e)\n""}]",6,859839,a3c8857ee30205a2f0d0302728b3bcd4db8419fc,46,5,2,10459,,,0,"NFS: Fix generic revert to snapshot flow

While reverting to a snapshot with generic flow, we create a
temporary volume from snapshot and copy data from temporary to the
original volume.
While creating this temporary volume, the snapshot is in 'restoring'
state whereas the remotefs driver only accepts 'available' and
'backing-up' states for this operation.
This patch adds the 'restoring' state to the list of acceptable states.

Closes-Bug: 1946059

Change-Id: Id1e40fd42b88c63dbbba2aaae77c40660ddac4c7
(cherry picked from commit 862edca0deb366ea980485359216fea020a03c9e)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/39/859839/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/test_nfs.py', 'releasenotes/notes/fix-nfs-revert-to-snap-adc04204b3661d66.yaml', 'cinder/volume/drivers/remotefs.py']",3,1dc950b826acdab740cbcfbe119c0c31a9833a07,bug/1946059," acceptable_states = ['available', 'backing-up', 'restoring']"," acceptable_states = ['available', 'backing-up']",11,3
openstack%2Fpython-troveclient~master~Ia836b341b287f4f2ca5e9c9690e3c83b89015445,openstack/python-troveclient,master,Ia836b341b287f4f2ca5e9c9690e3c83b89015445,Update master for stable/zed,MERGED,2022-09-09 15:15:27.000000000,2022-11-08 13:59:34.000000000,2022-11-08 13:58:32.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-09-09 15:15:27.000000000', 'files': ['releasenotes/source/zed.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/e8b2534e0d1e37347a57504d1419c9f17515b38e', 'message': 'Update master for stable/zed\n\nAdd file to the reno documentation build to show release notes for\nstable/zed.\n\nUse pbr instruction to increment the minor version number\nautomatically so that master versions are higher than the versions on\nstable/zed.\n\nSem-Ver: feature\nChange-Id: Ia836b341b287f4f2ca5e9c9690e3c83b89015445\n'}]",1,856817,e8b2534e0d1e37347a57504d1419c9f17515b38e,8,3,1,22816,,,0,"Update master for stable/zed

Add file to the reno documentation build to show release notes for
stable/zed.

Use pbr instruction to increment the minor version number
automatically so that master versions are higher than the versions on
stable/zed.

Sem-Ver: feature
Change-Id: Ia836b341b287f4f2ca5e9c9690e3c83b89015445
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/17/856817/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/zed.rst', 'releasenotes/source/index.rst']",2,e8b2534e0d1e37347a57504d1419c9f17515b38e,reno-zed, zed,,7,0
openstack%2Fceilometer~stable%2Fxena~I9b34ac062d45b2b839dc9d6e0cdce696185890e4,openstack/ceilometer,stable/xena,I9b34ac062d45b2b839dc9d6e0cdce696185890e4,Remove lingering queue declaration,MERGED,2022-11-02 13:14:47.000000000,2022-11-08 13:45:53.000000000,2022-11-07 18:09:00.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-02 13:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/02491a5ed1c5b0395ed496c6ef69777923a8ce6a', 'message': 'Remove lingering queue declaration\n\nfrom .zuul.yaml file.\n\nChange-Id: I9b34ac062d45b2b839dc9d6e0cdce696185890e4\n(cherry picked from commit 7e545b0fd9fd4a393d9e2af30f9fc370b20078c0)\n(cherry picked from commit 142cb0b6e6f6fa85634c5176c84ab15d6511fa89)\n'}, {'number': 2, 'created': '2022-11-03 05:53:45.000000000', 'files': ['.zuul.yaml', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0b2a9e31a2a1a29053ddaf545c986e169a0aefb7', 'message': 'Remove lingering queue declaration\n\nfrom .zuul.yaml file.\n\nChange-Id: I9b34ac062d45b2b839dc9d6e0cdce696185890e4\n(cherry picked from commit 7e545b0fd9fd4a393d9e2af30f9fc370b20078c0)\n(cherry picked from commit 142cb0b6e6f6fa85634c5176c84ab15d6511fa89)\n'}]",5,863284,0b2a9e31a2a1a29053ddaf545c986e169a0aefb7,14,2,2,4264,,,0,"Remove lingering queue declaration

from .zuul.yaml file.

Change-Id: I9b34ac062d45b2b839dc9d6e0cdce696185890e4
(cherry picked from commit 7e545b0fd9fd4a393d9e2af30f9fc370b20078c0)
(cherry picked from commit 142cb0b6e6f6fa85634c5176c84ab15d6511fa89)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/84/863284/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,02491a5ed1c5b0395ed496c6ef69777923a8ce6a,zuul_queue-stable/zed-stable/yoga-stable/xena,, queue: telemetry,0,1
openstack%2Frelease-test~master~Ief3fe84f1764590ea6952e68f238db7daab2e9f7,openstack/release-test,master,Ief3fe84f1764590ea6952e68f238db7daab2e9f7,Remove python-dev from bindep,MERGED,2022-11-07 10:05:01.000000000,2022-11-08 13:32:25.000000000,2022-11-08 13:32:25.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 10:05:01.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/release-test/commit/7ce20180e1d9642cd4d0affda5dc9fb2d8b25a08', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: Ief3fe84f1764590ea6952e68f238db7daab2e9f7\n""}]",1,863845,7ce20180e1d9642cd4d0affda5dc9fb2d8b25a08,7,3,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: Ief3fe84f1764590ea6952e68f238db7daab2e9f7
",git fetch https://review.opendev.org/openstack/release-test refs/changes/45/863845/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,7ce20180e1d9642cd4d0affda5dc9fb2d8b25a08,drop-python-dev-from-bindep,,python-dev [platform:dpkg] python-devel [platform:rpm],0,2
openstack%2Fneutron~master~I76ee72269f08b9e4f4a97240bd7b4dcdd21dba04,openstack/neutron,master,I76ee72269f08b9e4f4a97240bd7b4dcdd21dba04,[POC] Remove unnecessary chains and rules in the L3 agent,ABANDONED,2022-11-08 11:29:30.000000000,2022-11-08 12:41:43.000000000,,[],"[{'number': 1, 'created': '2022-11-08 11:29:30.000000000', 'files': ['neutron/agent/l3/router_info.py', 'neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2cff6d8b605dd36de8e5d8a79e5c28b334a42099', 'message': '[POC] Remove unnecessary chains and rules in the L3 agent\n\nRelated to nft migration\n\nChange-Id: I76ee72269f08b9e4f4a97240bd7b4dcdd21dba04\n'}]",0,863992,2cff6d8b605dd36de8e5d8a79e5c28b334a42099,2,0,1,16688,,,0,"[POC] Remove unnecessary chains and rules in the L3 agent

Related to nft migration

Change-Id: I76ee72269f08b9e4f4a97240bd7b4dcdd21dba04
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/863992/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/router_info.py', 'neutron/agent/linux/iptables_manager.py']",2,2cff6d8b605dd36de8e5d8a79e5c28b334a42099,ntf_migration," table_chain_to_skip = [ ('filter', 'FORWARD'), ('filter', 'OUTPUT'), ] if (table, chain) in table_chain_to_skip: continue ",,9,2
openstack%2Fneutron~master~Iac1d4c4004e1348ced388ee4dd44711f0e27bcc2,openstack/neutron,master,Iac1d4c4004e1348ced388ee4dd44711f0e27bcc2,Use --exclude-regex in tox.ini,MERGED,2022-11-07 23:43:24.000000000,2022-11-08 12:20:05.000000000,2022-11-08 12:18:43.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 32029}]","[{'number': 1, 'created': '2022-11-07 23:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b41c1d1cc845d845d9fc781c243dda5502c2a179', 'message': 'Use --exclude-regex in tox.ini\n\n--black-regex has been deprecated and using it can sometimes\ncause failures in the fulltest job.\n\nChange-Id: Iac1d4c4004e1348ced388ee4dd44711f0e27bcc2\nCloses-bug: #1995901\n'}, {'number': 2, 'created': '2022-11-07 23:46:45.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e2a0ac058305dd16d6dedb883d305cd162f5fe4', 'message': 'Use --exclude-regex in tox.ini\n\n--black-regex has been deprecated and using it can sometimes\ncause failures in the fullstack job.\n\nChange-Id: Iac1d4c4004e1348ced388ee4dd44711f0e27bcc2\nCloses-bug: #1995901\n'}]",1,863950,9e2a0ac058305dd16d6dedb883d305cd162f5fe4,12,5,2,1131,,,0,"Use --exclude-regex in tox.ini

--black-regex has been deprecated and using it can sometimes
cause failures in the fullstack job.

Change-Id: Iac1d4c4004e1348ced388ee4dd44711f0e27bcc2
Closes-bug: #1995901
",git fetch https://review.opendev.org/openstack/neutron refs/changes/50/863950/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b41c1d1cc845d845d9fc781c243dda5502c2a179,bug/1995901, stestr run --concurrency 2 --exclude-regex neutron.tests.fullstack.test_securitygroup.TestSecurityGroupsSameNetwork.test_securitygroup {posargs}, stestr run --concurrency 2 --black-regex neutron.tests.fullstack.test_securitygroup.TestSecurityGroupsSameNetwork.test_securitygroup {posargs},1,1
openstack%2Fpuppet-ironic~stable%2Fwallaby~I9b3db7f1749479c6581ada34117a31729572ecb9,openstack/puppet-ironic,stable/wallaby,I9b3db7f1749479c6581ada34117a31729572ecb9,Debian/Ubuntu: Do not use the ironic-inspector-dnsmasq service,MERGED,2022-10-24 01:27:30.000000000,2022-11-08 12:17:02.000000000,2022-11-08 12:17:02.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-24 01:27:30.000000000', 'files': ['spec/classes/ironic_inspector_spec.rb', 'manifests/inspector.pp', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/68c3891f8905ec383c44accad6b2204067ec80f7', 'message': 'Debian/Ubuntu: Do not use the ironic-inspector-dnsmasq service\n\n... because the service is not available in these distributions.\n\nChange-Id: I9b3db7f1749479c6581ada34117a31729572ecb9\n(cherry picked from commit 0d75b5366385e06c64138e49f2ea408cfc987006)\n(cherry picked from commit 45d292e0a0224dfe0ccf81bf840a100a72325df0)\n(cherry picked from commit 6048343bd149034c97c32a492d2aa6c8c550a524)\n'}]",1,862238,68c3891f8905ec383c44accad6b2204067ec80f7,13,3,1,9816,,,0,"Debian/Ubuntu: Do not use the ironic-inspector-dnsmasq service

... because the service is not available in these distributions.

Change-Id: I9b3db7f1749479c6581ada34117a31729572ecb9
(cherry picked from commit 0d75b5366385e06c64138e49f2ea408cfc987006)
(cherry picked from commit 45d292e0a0224dfe0ccf81bf840a100a72325df0)
(cherry picked from commit 6048343bd149034c97c32a492d2aa6c8c550a524)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/38/862238/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ironic_inspector_spec.rb', 'manifests/inspector.pp', 'manifests/params.pp']",3,68c3891f8905ec383c44accad6b2204067ec80f7,debian-ironic-inspector-stable/wallaby, $inspector_dnsmasq_service = false, # it seems like there is not currently a builtin dnsmasq in the debian packaging # https://packages.debian.org/source/experimental/ironic-inspector # this should be changed to whatever debian will use for dnsmasq $inspector_dnsmasq_service = 'ironic-inspector-dnsmasq',19,16
openstack%2Fpuppet-swift~master~I6da122c569e7a66a1933b7483fb8cf68a40dd94f,openstack/puppet-swift,master,I6da122c569e7a66a1933b7483fb8cf68a40dd94f,Restrict access to the mount base directory,MERGED,2022-10-20 02:11:16.000000000,2022-11-08 12:07:23.000000000,2022-11-08 12:07:23.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 29759}]","[{'number': 1, 'created': '2022-10-20 02:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/52fc70da378b309e8c18f4a4dea369e09ff7ebb2', 'message': 'Restrict access to the mount base directory\n\nThe swift processes does not require write access to the mount base\ndirectory (which is usually /srv/node), thus the directory can be owned\nby root. This is more consistent with the current installation guide\nof Swift.\n\nChange-Id: I6da122c569e7a66a1933b7483fb8cf68a40dd94f\n'}, {'number': 2, 'created': '2022-10-20 04:09:11.000000000', 'files': ['manifests/storage/disk.pp', 'manifests/storage/xfs.pp', 'manifests/storage/loopback.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/911919e5a5fca9bd1f8fe67f66aad51cf899822b', 'message': 'Restrict access to the mount base directory\n\nThe swift processes does not require write access to the mount base\ndirectory (which is usually /srv/node), thus the directory can be owned\nby root. This is more consistent with the current installation guide\nof Swift.\n\nChange-Id: I6da122c569e7a66a1933b7483fb8cf68a40dd94f\n'}]",1,861932,911919e5a5fca9bd1f8fe67f66aad51cf899822b,14,4,2,9816,,,0,"Restrict access to the mount base directory

The swift processes does not require write access to the mount base
directory (which is usually /srv/node), thus the directory can be owned
by root. This is more consistent with the current installation guide
of Swift.

Change-Id: I6da122c569e7a66a1933b7483fb8cf68a40dd94f
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/32/861932/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/disk.pp', 'manifests/storage/xfs.pp', 'manifests/storage/loopback.pp']",3,52fc70da378b309e8c18f4a4dea369e09ff7ebb2,," owner => 'root' group => 'root',"," owner => $::swift::params::user, group => $::swift::params::group,",6,6
openstack%2Fpuppet-ironic~stable%2Fwallaby~Ibd0fe69f2a2d0defb648d06e8098712f84de45e6,openstack/puppet-ironic,stable/wallaby,Ibd0fe69f2a2d0defb648d06e8098712f84de45e6,Debian/Ubuntu: The staging driver package is not available,MERGED,2022-10-24 01:28:33.000000000,2022-11-08 11:49:00.000000000,2022-11-08 11:49:00.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-24 01:28:33.000000000', 'files': ['manifests/drivers/staging.pp', 'spec/classes/ironic_drivers_staging_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/d15f9a3e8c892bbcaf41093711646039beadba6f', 'message': 'Debian/Ubuntu: The staging driver package is not available\n\n... so the deployment should fail the user explicitly requires it.\n\nChange-Id: Ibd0fe69f2a2d0defb648d06e8098712f84de45e6\n(cherry picked from commit a92e08ecc243fab588b813eda06a218d7495b172)\n(cherry picked from commit 1e2207a73339041e4fa412515edb9286ea681501)\n(cherry picked from commit b12fcfe24191b05153336556646ecda1cedc43d3)\n'}]",1,862239,d15f9a3e8c892bbcaf41093711646039beadba6f,13,3,1,9816,,,0,"Debian/Ubuntu: The staging driver package is not available

... so the deployment should fail the user explicitly requires it.

Change-Id: Ibd0fe69f2a2d0defb648d06e8098712f84de45e6
(cherry picked from commit a92e08ecc243fab588b813eda06a218d7495b172)
(cherry picked from commit 1e2207a73339041e4fa412515edb9286ea681501)
(cherry picked from commit b12fcfe24191b05153336556646ecda1cedc43d3)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/39/862239/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/drivers/staging.pp', 'spec/classes/ironic_drivers_staging_spec.rb']",2,d15f9a3e8c892bbcaf41093711646039beadba6f,debian-ironic-inspector-stable/wallaby, on_supported_os({ :supported_os => OSDefaults.get_supported_os if facts[:osfamily] == 'RedHat' it_configures 'ironic-staging-drivers' end," # TODO: use OSDefaults.get_supported_os when ironic-staging-drivers is # packaged for Debian and Ubuntu on_supported_os({ :supported_os => [ { 'operatingsystem' => 'CentOS', 'operatingsystemrelease' => [ '7' ] } ] it_configures 'ironic-staging-drivers'",12,10
openstack%2Fpython-openstackclient~master~I7b4f7e5c3769a813bd8b2b9cd6090c6fe501e13d,openstack/python-openstackclient,master,I7b4f7e5c3769a813bd8b2b9cd6090c6fe501e13d,"compute: Add '--no-network', '--auto-network' flags",MERGED,2022-10-26 10:32:55.000000000,2022-11-08 10:49:47.000000000,2022-11-08 10:48:36.000000000,"[{'_account_id': 1131}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-10-26 10:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f2f569cdaf55a45f2831020a1bf5a6349e7130a0', 'message': ""compute: Add '--no-network', '--auto-network' flags\n\nThese are aliases for '--nic none' and '--nic auto', respectively.\n\nChange-Id: I7b4f7e5c3769a813bd8b2b9cd6090c6fe501e13d\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2022-10-26 14:13:30.000000000', 'files': ['openstackclient/tests/unit/compute/v2/test_server.py', 'releasenotes/notes/auto-no-network-options-f4ddb2bb7544d2f5.yaml', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a7975c42003d7df2af91154007435cd5f8560f24', 'message': ""compute: Add '--no-network', '--auto-network' flags\n\nThese are aliases for '--nic none' and '--nic auto', respectively.\n\nChange-Id: I7b4f7e5c3769a813bd8b2b9cd6090c6fe501e13d\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",2,862680,a7975c42003d7df2af91154007435cd5f8560f24,12,3,2,15334,,,0,"compute: Add '--no-network', '--auto-network' flags

These are aliases for '--nic none' and '--nic auto', respectively.

Change-Id: I7b4f7e5c3769a813bd8b2b9cd6090c6fe501e13d
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/80/862680/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/compute/v2/test_server.py', 'releasenotes/notes/auto-no-network-options-f4ddb2bb7544d2f5.yaml', 'openstackclient/compute/v2/server.py']",3,f2f569cdaf55a45f2831020a1bf5a6349e7130a0,no-network-option," 'Tag for the attached interface ' '(supported by --os-compute-api-version 2.49 or later)'class NoneNICAction(argparse.Action): def __init__(self, option_strings, dest, help=None): super().__init__( option_strings=option_strings, dest=dest, nargs=0, default=[], required=False, help=help, ) def __call__(self, parser, namespace, values, option_string=None): # Make sure we have an empty dict rather than None if getattr(namespace, self.dest, None) is None: setattr(namespace, self.dest, []) getattr(namespace, self.dest).append('none') class AutoNICAction(argparse.Action): def __init__(self, option_strings, dest, help=None): super().__init__( option_strings=option_strings, dest=dest, nargs=0, default=[], required=False, help=help, ) def __call__(self, parser, namespace, values, option_string=None): # Make sure we have an empty dict rather than None if getattr(namespace, self.dest, None) is None: setattr(namespace, self.dest, []) getattr(namespace, self.dest).append('auto') option_strings=option_strings, dest=dest, nargs=None, const=None, default=[], type=None, choices=None, required=False, help=help, metavar=metavar, k, sep, v = kv_str.partition('=') metavar='<network>', ""For more advanced use cases, refer to the '--nic' parameter."" metavar='<port>', '--no-network', dest='nics', action=NoneNICAction, help=_( ""Do not attach a network to the server. "" ""This is a wrapper for the '--nic none' option that provides "" ""a simple syntax for disabling network connectivity for a new "" ""server. "" ""For more advanced use cases, refer to the '--nic' parameter. "" ""(supported by --os-compute-api-version 2.37 or above)"" ), ) parser.add_argument( '--auto-network', dest='nics', action=AutoNICAction, help=_( ""Automatically allocate a network to the server. "" ""This is the default network allocation policy. "" ""This is a wrapper for the '--nic none' option that provides "" ""a simple syntax for disabling network connectivity for a new "" ""server. "" ""For more advanced use cases, refer to the '--nic' parameter. "" ""(supported by --os-compute-api-version 2.37 or above)"" ), ) parser.add_argument( action=NICAction, # NOTE(RuiChen): Add '\n' to the end of line to improve formatting; # see cliff's _SmartHelpFormatter for more details."," ""Tag for the attached interface. "" ""(Supported by API versions '2.49' - '2.latest')""# TODO(stephenfin): Replace with 'MultiKeyValueAction' when we no longer # support '--nic=auto' and '--nic=none' nargs=None, const=None, default=None, type=None, choices=None, required=False, option_strings=option_strings, dest=dest, nargs=nargs, const=const, default=default, type=type, choices=choices, required=required, help=help, metavar=metavar, k, sep, v = kv_str.partition(""="") metavar=""<network>"", default=[], # NOTE(RuiChen): Add '\n' to the end of line to improve formatting; # see cliff's _SmartHelpFormatter for more details. ""For more advanced use cases, refer to the '--nic' "" ""parameter."" metavar=""<port>"", default=[], action=NICAction, default=[],",136,38
openstack%2Fos-net-config~stable%2Ftrain~Ifd674efb349e0c3156606c8fce72a176f8d05b0f,openstack/os-net-config,stable/train,Ifd674efb349e0c3156606c8fce72a176f8d05b0f,zuul: Declare queue at top level,MERGED,2022-11-04 07:20:34.000000000,2022-11-08 10:48:41.000000000,2022-11-08 10:46:57.000000000,"[{'_account_id': 12398}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 07:20:34.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/a5190badd405dd333efac204194a5cc296ace1f2', 'message': 'zuul: Declare queue at top level\n\nZuul deprecated declaring shared queues at a pipeline level with\nrelease 4.1.0. This updates the job definition to use the top level\ndeclaration instead.\n\nChange-Id: Ifd674efb349e0c3156606c8fce72a176f8d05b0f\n(cherry picked from commit 84f11c7468db316c2ce93beedb81059bdf14e483)\n'}]",0,863591,a5190badd405dd333efac204194a5cc296ace1f2,8,4,1,33688,,,0,"zuul: Declare queue at top level

Zuul deprecated declaring shared queues at a pipeline level with
release 4.1.0. This updates the job definition to use the top level
declaration instead.

Change-Id: Ifd674efb349e0c3156606c8fce72a176f8d05b0f
(cherry picked from commit 84f11c7468db316c2ce93beedb81059bdf14e483)
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/91/863591/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,a5190badd405dd333efac204194a5cc296ace1f2,zuul/queue, queue: tripleo jobs: - openstack-tox-pep8, queue: tripleo,3,1
openstack%2Fpython-openstackclient~master~Iaf9a75da418c64b304a14f15dd0fce267785c4a4,openstack/python-openstackclient,master,Iaf9a75da418c64b304a14f15dd0fce267785c4a4,zuul: Enable Swift tests,ABANDONED,2022-11-07 16:45:16.000000000,2022-11-08 10:21:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 16:45:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/dd5dff47a5f7198a58ab21600c686bff70e8ed86', 'message': ""zuul: Enable Swift tests\n\nIt's now ready for Python 3.\n\nChange-Id: Iaf9a75da418c64b304a14f15dd0fce267785c4a4\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,863899,dd5dff47a5f7198a58ab21600c686bff70e8ed86,3,1,1,15334,,,0,"zuul: Enable Swift tests

It's now ready for Python 3.

Change-Id: Iaf9a75da418c64b304a14f15dd0fce267785c4a4
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/99/863899/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,dd5dff47a5f7198a58ab21600c686bff70e8ed86,trivial,," DISABLED_PYTHON3_PACKAGES: swift devstack_services: # Swift is not ready for python3 yet: At a minimum keystonemiddleware needs # to be installed in the py2 env, there are probably other things too... s-account: false s-container: false s-object: false s-proxy: false # As swift is not available for this job, c-bak service won't be functional. # The backup related tests can be handled by other jobs having swift enabled. # The backup service along with swift services can be enabled once swift is # compatible with py3 c-bak: false",0,13
openstack%2Fpython-openstackclient~master~I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5,openstack/python-openstackclient,master,I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5,WIP Use deferred plugin loading,NEW,2020-06-13 14:46:03.000000000,2022-11-08 10:16:31.000000000,,"[{'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-06-13 14:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6b4d44f642d8e72dfe490a600f1e6a1e440b7d83', 'message': 'Defer plugin loading\n\nDepends-On: https://review.opendev.org/735430\nChange-Id: I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5\n'}, {'number': 2, 'created': '2020-06-13 15:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/44503c7c6f20317cb8019e8c0667a7753732f4a5', 'message': 'Defer plugin loading\n\nDepends-On: https://review.opendev.org/735430\nChange-Id: I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5\n'}, {'number': 3, 'created': '2020-06-15 15:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ddc6705790d865fb250f56d0010b231dca4e0476', 'message': ""WIP Use deferred plugin loading\n\ncliff and osc-lib support using builtins without loading\nplugins, and only loading plugins if the builtins can't\ndo the job. Use that support.\n\nThis is going to need an osc-lib release and min bump.\n\nDepends-On: https://review.opendev.org/735430\nChange-Id: I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5\n""}, {'number': 4, 'created': '2022-11-07 16:28:00.000000000', 'files': ['examples/osc-lib.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py', 'releasenotes/notes/use-deferred-plugin-8afeedeff01b8cc2.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/561f06935f0aa4d1bc2e5192133bcec3a863ff06', 'message': ""WIP Use deferred plugin loading\n\ncliff and osc-lib support using builtins without loading\nplugins, and only loading plugins if the builtins can't\ndo the job. Use that support.\n\nThis is going to need an osc-lib release and min bump.\n\nDepends-On: https://review.opendev.org/735430\nChange-Id: I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5\n""}]",4,735431,561f06935f0aa4d1bc2e5192133bcec3a863ff06,11,2,4,2,,,0,"WIP Use deferred plugin loading

cliff and osc-lib support using builtins without loading
plugins, and only loading plugins if the builtins can't
do the job. Use that support.

This is going to need an osc-lib release and min bump.

Depends-On: https://review.opendev.org/735430
Change-Id: I0247ae0b1e2d9ad89e97ae3f667cec23e7cac7f5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/31/735431/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/osc-lib.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py']",3,6b4d44f642d8e72dfe490a600f1e6a1e440b7d83,osc-plugin-optimize,"def get_plugin_modules(_plugin_modules=[]): if _plugin_modules: return _plugin_modules for mod in 'openstack.cli.base', 'openstack.cli.extension': _plugin_modules.extend(get_plugin_modules(mod)) return _plugin_modules","PLUGIN_MODULES = [] # Get list of base plugin modules PLUGIN_MODULES = get_plugin_modules( 'openstack.cli.base', ) # Append list of external plugin modules PLUGIN_MODULES.extend(get_plugin_modules( 'openstack.cli.extension', ))",14,14
openstack%2Fhorizon~stable%2Fzed~I6a665552aa316e063059e74a3caf19f1573043ae,openstack/horizon,stable/zed,I6a665552aa316e063059e74a3caf19f1573043ae,Imported Translations from Zanata,MERGED,2022-11-08 03:00:44.000000000,2022-11-08 08:56:18.000000000,2022-11-08 08:55:12.000000000,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-11-08 03:00:44.000000000', 'files': ['openstack_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a6f4500504217bec529dd67e8471bc9300605e72', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I6a665552aa316e063059e74a3caf19f1573043ae\n'}]",0,863959,a6f4500504217bec529dd67e8471bc9300605e72,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I6a665552aa316e063059e74a3caf19f1573043ae
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/863959/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'],1,a6f4500504217bec529dd67e8471bc9300605e72,zanata/translations,"""POT-Creation-Date: 2022-10-18 04:15+0000\n""""PO-Revision-Date: 2022-11-07 02:54+0000\n""msgid ""Browse..."" msgstr ""Browse..."" ","""POT-Creation-Date: 2022-09-30 06:37+0000\n""""PO-Revision-Date: 2022-09-05 10:28+0000\n""",5,2
openstack%2Fcliff~master~Ibd0e054142be05fd285e29b7ad325901a9627c5a,openstack/cliff,master,Ibd0e054142be05fd285e29b7ad325901a9627c5a,Load plugins in the interactive mode,NEW,2022-11-07 17:23:00.000000000,2022-11-08 08:49:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 17:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/662bc7dce449f46cf3c87f0092002e510c6f2e24', 'message': 'Load plugins in the interactive mode\n\nIn the interactive mode it is not sufficient to simply load plugins. It\niss required to load them, rebuild parser, reparse args with new\nplugins. Without that plugin clients may fail to initialize properly.\n\nChange-Id: Ibd0e054142be05fd285e29b7ad325901a9627c5a\n'}, {'number': 2, 'created': '2022-11-07 17:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/e25f5ca3aba53836aaf88e6dde40b2044b72d292', 'message': 'Load plugins in the interactive mode\n\nIn the interactive mode it is not sufficient to simply load plugins. It\niss required to load them, rebuild parser, reparse args with new\nplugins. Without that plugin clients may fail to initialize properly.\n\nChange-Id: Ibd0e054142be05fd285e29b7ad325901a9627c5a\n'}, {'number': 3, 'created': '2022-11-08 07:08:38.000000000', 'files': ['cliff/app.py'], 'web_link': 'https://opendev.org/openstack/cliff/commit/ac38459d6cac3f1fc768087ce57cf6b90e4f571a', 'message': 'Load plugins in the interactive mode\n\nIn the interactive mode it is not sufficient to simply load plugins. It\niss required to load them, rebuild parser, reparse args with new\nplugins. Without that plugin clients may fail to initialize properly.\n\nChange-Id: Ibd0e054142be05fd285e29b7ad325901a9627c5a\n'}]",0,863907,ac38459d6cac3f1fc768087ce57cf6b90e4f571a,5,1,3,27900,,,0,"Load plugins in the interactive mode

In the interactive mode it is not sufficient to simply load plugins. It
iss required to load them, rebuild parser, reparse args with new
plugins. Without that plugin clients may fail to initialize properly.

Change-Id: Ibd0e054142be05fd285e29b7ad325901a9627c5a
",git fetch https://review.opendev.org/openstack/cliff refs/changes/07/863907/3 && git format-patch -1 --stdout FETCH_HEAD,['cliff/app.py'],1,662bc7dce449f46cf3c87f0092002e510c6f2e24,osc-plugin-optimize,"cliff/app.py if self.interactive_mode: # For interactive mode we need to load all plugins self.load_plugins = True # Rebuild parser to be able to reparse options with all plugins self.parser = self.build_option_parser( self._description, self._version) # Run plugin loading for command manager and reparse self.command_manager.load_command_plugins() self.options, remainder = self.parser.parse_known_args(argv) ", self.command_manager.load_command_plugins(),11,1
openstack%2Fcliff~master~Id370dc35f1d56816b132a570694270e2bed235a4,openstack/cliff,master,Id370dc35f1d56816b132a570694270e2bed235a4,Add load_plugins option,NEW,2020-06-06 13:04:44.000000000,2022-11-08 08:43:16.000000000,,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-06-06 13:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/e245c0187496ac228321cd356216db4ab92501a1', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 2, 'created': '2020-06-06 14:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/f67770c100f5664b38d244f3bc3101de6e342e6a', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 3, 'created': '2020-06-06 17:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/c3bc1e914eac1285d3aead22b72150a588684ece', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 4, 'created': '2020-06-06 17:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/61d35d17d020c91efbf20445cd81f89acf4f2568', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 5, 'created': '2020-06-06 19:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/ddcb3094bde77a557da8a83380930ad27725aa88', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 6, 'created': '2020-06-07 14:40:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/b0de0ef2c69770ad8fe0182de3bd5abb9480d441', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 7, 'created': '2020-06-07 16:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/338f1c81d806f8eff02815fe9225aacd8d9ca621', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 8, 'created': '2020-06-08 15:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/45d08a2a7d6d117218864d7e515391ceaceb41ae', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/734095\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 9, 'created': '2020-06-08 16:20:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/2e471eea162d120b53cc251667706d2e463a1192', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/734095\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 10, 'created': '2020-06-12 16:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/49fee13df8e76a1fae73b0fc130ee804727a2fd7', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/735372\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 11, 'created': '2020-06-12 18:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/277cc46f49794d32862f794bdd9aa875fffd88b9', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/735372\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 12, 'created': '2020-06-12 21:41:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/74c25ad8a7cd4c5ca51d559a64004b44d78f12c1', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/735372\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 13, 'created': '2020-06-12 21:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/603665127ea95aaf1dcb6d5bd319fac989d99277', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/735372\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 14, 'created': '2020-06-13 14:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/a7a7dc55f9d29eeac7c7f816de2489e1be18b0d6', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to App and CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/735372\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 15, 'created': '2020-06-14 13:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/71cedd6a208f7c4ad6f8ac2385a364409ca582ae', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to App and CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nDepends-On: https://review.opendev.org/735372\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 16, 'created': '2020-06-15 15:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/2395ac5fd9536c403669e82cffdf2ff26d258bf5', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to App and CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange the sort order in a unit test so that we can have consistent\nbehavior across python versions.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 17, 'created': '2022-11-07 16:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/ca11fe185c40e877eddb1d59fac6f609fa3c60cb', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to App and CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange the sort order in a unit test so that we can have consistent\nbehavior across python versions.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 18, 'created': '2022-11-08 06:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/b66739261cad8df93da0b59289eb90aad8fecff8', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to App and CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange the sort order in a unit test so that we can have consistent\nbehavior across python versions.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}, {'number': 19, 'created': '2022-11-08 07:07:33.000000000', 'files': ['cliff/tests/test_commandmanager.py', 'cliff/exception.py', 'cliff/app.py', 'cliff/commandmanager.py', 'releasenotes/notes/load-plugins-option-0990d69ec68d82cf.yaml'], 'web_link': 'https://opendev.org/openstack/cliff/commit/5079a9239fd6c709aed4976a7519c6b8607637b9', 'message': ""Add load_plugins option\n\nScanning entrypoints is costly with the cost increasing relative\nto the number of python libraries installed on a system. In OSC\nthis means that we're paying a cost on every command invocation\neven for running commands that are being provided by OSC itself\nand not a plugin.\n\nAdd a new load_plugins option to App and CommandManager controlling\nwhether plugins are loaded on instantiation. load_plugins defaults\nto True, which retains the exisitng behavior. If load_plugins\nis set to False, the entrypoints scan will only be done if a command\ndoes not match from a set of builtins. This allows optimizing builtins\nto avoid the entrypoint cost and to only pay it for commands\nactually provided by external plugins.\n\nChange the sort order in a unit test so that we can have consistent\nbehavior across python versions.\n\nChange-Id: Id370dc35f1d56816b132a570694270e2bed235a4\n""}]",3,733961,5079a9239fd6c709aed4976a7519c6b8607637b9,40,2,19,2,,,0,"Add load_plugins option

Scanning entrypoints is costly with the cost increasing relative
to the number of python libraries installed on a system. In OSC
this means that we're paying a cost on every command invocation
even for running commands that are being provided by OSC itself
and not a plugin.

Add a new load_plugins option to App and CommandManager controlling
whether plugins are loaded on instantiation. load_plugins defaults
to True, which retains the exisitng behavior. If load_plugins
is set to False, the entrypoints scan will only be done if a command
does not match from a set of builtins. This allows optimizing builtins
to avoid the entrypoint cost and to only pay it for commands
actually provided by external plugins.

Change the sort order in a unit test so that we can have consistent
behavior across python versions.

Change-Id: Id370dc35f1d56816b132a570694270e2bed235a4
",git fetch https://review.opendev.org/openstack/cliff refs/changes/61/733961/6 && git format-patch -1 --stdout FETCH_HEAD,"['cliff/commandmanager.py', 'releasenotes/notes/load-plugins-option-0990d69ec68d82cf.yaml']",2,e245c0187496ac228321cd356216db4ab92501a1,osc-plugin-optimize,"--- features: - | Added new ``load_plugins`` option to ``CommandManager`` controlling whether plugins are loaded on instantiation. ``load_plugins`` defaults to ``True``, which retains the exisitng behavior. If ``load_plugins`` is set to ``False``, the entrypoints scan will only be done if a command does not match from a set of builtins. This allows optimizing builtins to avoid the entrypoint cost. ",,21,2
openstack%2Fvirtualbmc~master~I295bf25056f66c29649620ce8420382c4a151c1d,openstack/virtualbmc,master,I295bf25056f66c29649620ce8420382c4a151c1d,remove python-dev from bindep,MERGED,2022-11-07 09:35:37.000000000,2022-11-08 08:42:58.000000000,2022-11-08 08:42:00.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2022-11-07 09:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/cd9143353ec34d605ee91700dc65281b338bbc0a', 'message': 'remove python-dev from bindep\n\nChange-Id: I295bf25056f66c29649620ce8420382c4a151c1d\n'}, {'number': 2, 'created': '2022-11-07 09:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/2d7d18a135389297e4edb6de113116081c0d9cd9', 'message': 'remove python-dev from bindep\n\nIt is no longer supported by jammy.\n\nChange-Id: I295bf25056f66c29649620ce8420382c4a151c1d\n'}, {'number': 3, 'created': '2022-11-07 09:37:45.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/virtualbmc/commit/75f69f859a3ead7e5333abb9e9d19a78a70e7a82', 'message': ""remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I295bf25056f66c29649620ce8420382c4a151c1d\n""}]",0,863818,75f69f859a3ead7e5333abb9e9d19a78a70e7a82,10,3,3,28522,,,0,"remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I295bf25056f66c29649620ce8420382c4a151c1d
",git fetch https://review.opendev.org/openstack/virtualbmc refs/changes/18/863818/2 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,cd9143353ec34d605ee91700dc65281b338bbc0a,drop-python-dev-from-bindep,,python-dev [platform:dpkg test compile]python-devel [platform:rpm test compile],0,2
openstack%2Fpuppet-swift~master~Ie32d7cd12680ffb6e350a1f25309e92b7df698b2,openstack/puppet-swift,master,Ie32d7cd12680ffb6e350a1f25309e92b7df698b2,Fix python-ceilometermiddleware -> python3-ceilometermiddleware,NEW,2022-10-21 12:39:30.000000000,2022-11-08 08:25:18.000000000,,"[{'_account_id': 9816}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-21 12:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/65dc2bcab18d6122089c10065481942de97ee28e', 'message': ""Fix python-ceilometermiddleware -> python3-ceilometermiddleware\n\nThere's a ::swift::params for it, but it's not in use. As a result,\nthis breaks the install of ceilometermiddleware. Let's use it.\n\nChange-Id: Ie32d7cd12680ffb6e350a1f25309e92b7df698b2\n""}, {'number': 2, 'created': '2022-11-03 13:55:01.000000000', 'files': ['manifests/proxy/ceilometer.pp', 'spec/classes/swift_proxy_ceilometer_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/71bc4e1d2c4965886ecf9b15846849d901a59d0b', 'message': ""Fix python-ceilometermiddleware -> python3-ceilometermiddleware\n\nThere's a ::swift::params for it, but it's not in use. As a result,\nthis breaks the install of ceilometermiddleware. Let's use it.\n\nChange-Id: Ie32d7cd12680ffb6e350a1f25309e92b7df698b2\n""}]",4,862300,71bc4e1d2c4965886ecf9b15846849d901a59d0b,7,3,2,6476,,,0,"Fix python-ceilometermiddleware -> python3-ceilometermiddleware

There's a ::swift::params for it, but it's not in use. As a result,
this breaks the install of ceilometermiddleware. Let's use it.

Change-Id: Ie32d7cd12680ffb6e350a1f25309e92b7df698b2
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/00/862300/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/proxy/ceilometer.pp', 'spec/classes/swift_proxy_ceilometer_spec.rb']",2,65dc2bcab18d6122089c10065481942de97ee28e,ceilometermiddleware, it { is_expected.to contain_package('python3-ceilometermiddleware').with(, it { is_expected.to contain_package('python-ceilometermiddleware').with(,4,3
openstack%2Fcliff~master~I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9,openstack/cliff,master,I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9,Add method to load builtins by string,NEW,2020-06-14 13:59:10.000000000,2022-11-08 08:19:53.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-06-14 13:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/39ec00b48b2f2491b8564edb33aacb0711f868bb', 'message': 'Add method to load builtins by string\n\nTo make it easy to keep a list of builtins and then to load them,\nallow passing builtins by name similar to how they work in setup.cfg.\n\nChange-Id: I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9\n'}, {'number': 2, 'created': '2020-06-15 15:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/6bf788c9620c9e7481941945d6e3bd09d028d1a2', 'message': 'Add method to load builtins by string\n\nTo make it easy to keep a list of builtins and then to load them,\nallow passing builtins by name similar to how they work in setup.cfg.\n\nChange-Id: I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9\n'}, {'number': 3, 'created': '2022-11-07 16:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/676c963107ad3bb29f1b78fd3016a9d96fa12129', 'message': 'Add method to load builtins by string\n\nTo make it easy to keep a list of builtins and then to load them,\nallow passing builtins by name similar to how they work in setup.cfg.\n\nChange-Id: I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9\n'}, {'number': 4, 'created': '2022-11-07 16:26:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cliff/commit/aa813ed335d995a43c5de53206623398f1fb3f61', 'message': 'Add method to load builtins by string\n\nTo make it easy to keep a list of builtins and then to load them,\nallow passing builtins by name similar to how they work in setup.cfg.\n\nChange-Id: I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9\n'}, {'number': 5, 'created': '2022-11-08 07:07:33.000000000', 'files': ['cliff/commandmanager.py'], 'web_link': 'https://opendev.org/openstack/cliff/commit/800a6c287e059fa72dc5a912fcefca8f46869931', 'message': 'Add method to load builtins by string\n\nTo make it easy to keep a list of builtins and then to load them,\nallow passing builtins by name similar to how they work in setup.cfg.\n\nChange-Id: I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9\n'}]",1,735465,800a6c287e059fa72dc5a912fcefca8f46869931,11,1,5,2,,,0,"Add method to load builtins by string

To make it easy to keep a list of builtins and then to load them,
allow passing builtins by name similar to how they work in setup.cfg.

Change-Id: I0d5d5c56a447e990b2fe72ff7fa220ac19c1dae9
",git fetch https://review.opendev.org/openstack/cliff refs/changes/65/735465/1 && git format-patch -1 --stdout FETCH_HEAD,['cliff/commandmanager.py'],1,39ec00b48b2f2491b8564edb33aacb0711f868bb,osc-plugin-optimize,"import importlibimport sys def add_command_by_name(self, name, command_class_name, group=None): mod_str, class_str = command_class_name.split(':') importlib.import_module(mod_str) cliff_app_class = getattr(sys.modules[mod_str], class_str) self.add_command(name, cliff_app_class, group) ",,8,0
openstack%2Ftripleo-ansible~master~Ic28add116c369979b4038ce403451dc95dc2f53d,openstack/tripleo-ansible,master,Ic28add116c369979b4038ce403451dc95dc2f53d,num_dpdk_interface_rx_queues support net conf schema,MERGED,2022-09-14 15:37:27.000000000,2022-11-08 07:24:21.000000000,2022-11-08 07:23:12.000000000,"[{'_account_id': 4571}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-09-14 15:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c297137a09fc126581f85cb8af9c3bd2f4ddf16b', 'message': ""num_dpdk_interface_rx_queues support net conf schema\n\nThe network_config schema in the baremetal provision defintion\ndid not allow setting the 'num_dpdk_interface_rx_queues'.\n\nThis change adds the varaible to the schema, and adds the option\nin module: tripleo_generate_inventory_network_config. By default\nthe value is 1, which is the same default used in THT for parameter\nNumDpdkInterfaceRxQueues.\n\nCloses-Bug: #1989593\nChange-Id: Ic28add116c369979b4038ce403451dc95dc2f53d\n""}, {'number': 2, 'created': '2022-09-14 17:49:14.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_generate_inventory_network_config.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py', 'releasenotes/notes/net-conf-schema-num_dpdk_interface_rx_queues-4a37e4fc3957ed9a.yaml', 'tripleo_ansible/tests/modules/test_tripleo_generate_inventory_network_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c3315623fe23864ce34e63ae364c7a2d200679a4', 'message': ""num_dpdk_interface_rx_queues support net conf schema\n\nThe network_config schema in the baremetal provision defintion\ndid not allow setting the 'num_dpdk_interface_rx_queues'.\n\nThis change adds the varaible to the schema, and adds the option\nin module: tripleo_generate_inventory_network_config. By default\nthe value is 1, which is the same default used in THT for parameter\nNumDpdkInterfaceRxQueues.\n\nCloses-Bug: #1989593\nChange-Id: Ic28add116c369979b4038ce403451dc95dc2f53d\n""}]",0,857731,c3315623fe23864ce34e63ae364c7a2d200679a4,11,6,2,24245,,,0,"num_dpdk_interface_rx_queues support net conf schema

The network_config schema in the baremetal provision defintion
did not allow setting the 'num_dpdk_interface_rx_queues'.

This change adds the varaible to the schema, and adds the option
in module: tripleo_generate_inventory_network_config. By default
the value is 1, which is the same default used in THT for parameter
NumDpdkInterfaceRxQueues.

Closes-Bug: #1989593
Change-Id: Ic28add116c369979b4038ce403451dc95dc2f53d
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/31/857731/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_generate_inventory_network_config.py', 'tripleo_ansible/ansible_plugins/module_utils/baremetal_deploy.py', 'releasenotes/notes/net-conf-schema-num_dpdk_interface_rx_queues-4a37e4fc3957ed9a.yaml', 'tripleo_ansible/tests/modules/test_tripleo_generate_inventory_network_config.py']",4,c297137a09fc126581f85cb8af9c3bd2f4ddf16b,bug/1989593," 'num_dpdk_interface_rx_queues': 1, 'num_dpdk_interface_rx_queues': 1,",,15,0
openstack%2Faodh~master~I4d0f15e9315776c98e0f077893152f7865570b6d,openstack/aodh,master,I4d0f15e9315776c98e0f077893152f7865570b6d,Update python testing classifier,NEW,2021-12-21 09:25:06.000000000,2022-11-08 07:12:52.000000000,,"[{'_account_id': 22348}, {'_account_id': 32102}]","[{'number': 1, 'created': '2021-12-21 09:25:06.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/aodh/commit/8420354f6e9c09a0024b67cdb99404e7df7d34ad', 'message': 'Update python testing classifier\n\nChange-Id: I4d0f15e9315776c98e0f077893152f7865570b6d\n'}]",2,822441,8420354f6e9c09a0024b67cdb99404e7df7d34ad,4,2,1,33881,,,0,"Update python testing classifier

Change-Id: I4d0f15e9315776c98e0f077893152f7865570b6d
",git fetch https://review.opendev.org/openstack/aodh refs/changes/41/822441/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,8420354f6e9c09a0024b67cdb99404e7df7d34ad,, Programming Language :: Python :: 3.9,,1,0
openstack%2Fkolla-ansible~master~I071bbbe0d8f1fef084eb47fb6d16da53f0f2f97a,openstack/kolla-ansible,master,I071bbbe0d8f1fef084eb47fb6d16da53f0f2f97a,fix deploy keystone missing parameter keystone_admin_url,ABANDONED,2022-11-04 08:23:05.000000000,2022-11-08 06:22:20.000000000,,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 08:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cd43e6fbf5fa25876b159271f0c5a550078f148f', 'message': 'fix deploy keystone sissing parameter keystone_admin_url\n\nChange-Id: I071bbbe0d8f1fef084eb47fb6d16da53f0f2f97a\n'}, {'number': 2, 'created': '2022-11-04 08:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/be02419fd307ddf5d57543ff6069d468d6160642', 'message': 'fix deploy keystone missing parameter keystone_admin_url\n\nChange-Id: I071bbbe0d8f1fef084eb47fb6d16da53f0f2f97a\n'}, {'number': 3, 'created': '2022-11-07 03:55:57.000000000', 'files': ['ansible/roles/keystone/tasks/register.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b65d15c45daac2359970f869ef875fde06e91b16', 'message': 'fix deploy keystone missing parameter keystone_admin_url\n\nkolla_keystone_bootstrap script 8 parameters are required by default\n\nCloses-Bug: #1995823\n\nChange-Id: I071bbbe0d8f1fef084eb47fb6d16da53f0f2f97a\n'}]",3,863596,b65d15c45daac2359970f869ef875fde06e91b16,13,2,3,32029,,,0,"fix deploy keystone missing parameter keystone_admin_url

kolla_keystone_bootstrap script 8 parameters are required by default

Closes-Bug: #1995823

Change-Id: I071bbbe0d8f1fef084eb47fb6d16da53f0f2f97a
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/96/863596/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/keystone/tasks/register.yml'],1,cd43e6fbf5fa25876b159271f0c5a550078f148f,, admin {{ keystone_admin_url }} {{ keystone_internal_url }} {{ keystone_public_url }} {{ item }}, admin {{ keystone_internal_url }} {{ keystone_public_url }} {{ item }},1,1
openstack%2Frequirements~master~Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9,openstack/requirements,master,Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9,Drop unbuildable package from global-requirements,MERGED,2021-10-10 18:33:09.000000000,2022-11-08 04:19:49.000000000,2022-11-08 04:18:43.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 18551}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-10-10 18:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/0d642c4e95d9781c61467618adcf79caaf53a175', 'message': 'DNM: Show failed builds and dependents\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n'}, {'number': 2, 'created': '2021-10-11 11:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/70d4f4c2017ace49531e13e26c26439e19033f0e', 'message': 'DNM: Show failed builds and dependents\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n'}, {'number': 3, 'created': '2022-03-26 20:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fa3404a488ef7a048465e14fc2f32da85aac2fba', 'message': 'DNM: Show failed builds and dependents\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n'}, {'number': 4, 'created': '2022-06-15 16:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9cc60598c1ed31763b6b532f11223a204ce85df0', 'message': 'DNM: Show failed builds and dependents\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n'}, {'number': 5, 'created': '2022-08-02 07:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3d4cb3ea1d63a5a9a53ccf9a460dcae5ba0bfa02', 'message': 'DNM: Show failed builds and dependents\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n'}, {'number': 6, 'created': '2022-08-27 16:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7ce475cdb704b00d42a63da7bc68faf69d823dd3', 'message': 'DNM: Show failed builds and dependents\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n'}, {'number': 7, 'created': '2022-10-13 22:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/52f8bc1663c6c24d2e99bf556c4ebf2bd00fd7f3', 'message': ""Drop unbuildable packages from global-requirements\n\nThese are no longer buildable on a modern python3 environment, the only\nthing that they didn't show up as gate failures so far is that we are\nrunning on the opendev CI with a set of cached wheel builds, where\nversions of these packages were built with an older setup some time age\nwhen things still worked. This will no longer be the case when switching\nto python3.10. There also seem to be no current users of these packages\nanymore. Affected are:\n\n- anyjson\n- pystache\n- suds-jurko\n\nSee [0] for a test build without the wheel cache in use.\n\n[0] https://review.opendev.org/813292\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n""}, {'number': 8, 'created': '2022-10-29 09:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4a6feab55122b81d85815074377bde04ee303641', 'message': ""Drop unbuildable package from global-requirements\n\nsuds-jurko is no longer buildable on a modern python3 environment, the only\nreason that this didn't show up as gate failures so far is that we are\nrunning on the opendev CI with a set of cached wheel builds, where\nversions of this package were built with an older setup some time age\nwhen things still worked. This will no longer be the case when switching\nto python3.10.\n\nSee [0] for a test build without the wheel cache in use.\n\n[0] https://review.opendev.org/813292\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n""}, {'number': 9, 'created': '2022-11-05 16:44:37.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c18003ff3c0f7b7e33ae274115a679490f84b7ea', 'message': ""Drop unbuildable package from global-requirements\n\nsuds-jurko is no longer buildable on a modern python3 environment, the only\nreason that this didn't show up as gate failures so far is that we are\nrunning on the opendev CI with a set of cached wheel builds, where\nversions of this package were built with an older setup some time age\nwhen things still worked. This will no longer be the case when switching\nto python3.10.\n\nSee [0] for a test build without the wheel cache in use.\n\n[0] https://review.opendev.org/813292\n\nChange-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9\n""}]",8,813302,c18003ff3c0f7b7e33ae274115a679490f84b7ea,31,4,9,13252,,,0,"Drop unbuildable package from global-requirements

suds-jurko is no longer buildable on a modern python3 environment, the only
reason that this didn't show up as gate failures so far is that we are
running on the opendev CI with a set of cached wheel builds, where
versions of this package were built with an older setup some time age
when things still worked. This will no longer be the case when switching
to python3.10.

See [0] for a test build without the wheel cache in use.

[0] https://review.opendev.org/813292

Change-Id: Ic9b4200ad98879c9d2bd4c0544ba9f1f3fb412f9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/02/813302/8 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,0d642c4e95d9781c61467618adcf79caaf53a175,drop-unbuildable,#pystache===0.5.4#suds-jurko===0.6#os-net-config===15.0.0 needs anyjson#anyjson===0.3.3#funcparserlib===0.3.6#oslo.vmware===3.9.1 needs suds-jurko#os-collect-config===13.0.1 needs anyjson,pystache===0.5.4suds-jurko===0.6os-net-config===15.0.0anyjson===0.3.3funcparserlib===0.3.6oslo.vmware===3.9.1os-collect-config===13.0.1,7,7
openstack%2Frequirements~stable%2Fwallaby~I41e55c57b1d1829319674d223c6cabce081d9674,openstack/requirements,stable/wallaby,I41e55c57b1d1829319674d223c6cabce081d9674,update constraint for os_vif to new release 2.4.1,MERGED,2022-11-04 15:25:04.000000000,2022-11-08 03:34:23.000000000,2022-11-08 03:34:23.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 15:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/63b78b39436ada08fa02460648276d9a241bb7ac', 'message': 'update constraint for os_vif to new release 2.4.1\n\nmeta: version: 2.4.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Sean Mooney <work@seanmooney.info>\nmeta: release:Commit: sean mooney <smooney@redhat.com>\nmeta: release:Change-Id: Idadd35aa4a51314661f2fe72c0a3594be3106249\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Workflow+1: Elod Illes <elod.illes@est.tech>\nChange-Id: I41e55c57b1d1829319674d223c6cabce081d9674\n'}, {'number': 2, 'created': '2022-11-04 15:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d294bdafa8202e033528f78fb38b0f0478eb81c8', 'message': 'update constraint for os_vif to new release 2.4.1\n\nmeta: version: 2.4.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Sean Mooney <work@seanmooney.info>\nmeta: release:Commit: sean mooney <smooney@redhat.com>\nmeta: release:Change-Id: Idadd35aa4a51314661f2fe72c0a3594be3106249\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Workflow+1: Elod Illes <elod.illes@est.tech>\nChange-Id: I41e55c57b1d1829319674d223c6cabce081d9674\n'}, {'number': 3, 'created': '2022-11-05 18:03:46.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b9abd25f2d2d55c02929e7760ca093e5467af0f3', 'message': 'update constraint for os_vif to new release 2.4.1\n\nmeta: version: 2.4.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Sean Mooney <work@seanmooney.info>\nmeta: release:Commit: sean mooney <smooney@redhat.com>\nmeta: release:Change-Id: Idadd35aa4a51314661f2fe72c0a3594be3106249\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Workflow+1: Elod Illes <elod.illes@est.tech>\nChange-Id: I41e55c57b1d1829319674d223c6cabce081d9674\n'}]",1,863662,b9abd25f2d2d55c02929e7760ca093e5467af0f3,19,3,3,11131,,,0,"update constraint for os_vif to new release 2.4.1

meta: version: 2.4.1
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Sean Mooney <work@seanmooney.info>
meta: release:Commit: sean mooney <smooney@redhat.com>
meta: release:Change-Id: Idadd35aa4a51314661f2fe72c0a3594be3106249
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Workflow+1: Elod Illes <elod.illes@est.tech>
Change-Id: I41e55c57b1d1829319674d223c6cabce081d9674
",git fetch https://review.opendev.org/openstack/requirements refs/changes/62/863662/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,63b78b39436ada08fa02460648276d9a241bb7ac,new-release,os-vif===2.4.1,os-vif===2.4.0,1,1
openstack%2Fwatcher-tempest-plugin~master~I6e71dbd45ec97e65d51c26de092af0da7dd1dea0,openstack/watcher-tempest-plugin,master,I6e71dbd45ec97e65d51c26de092af0da7dd1dea0,Add stable/zed jobs on master gate,MERGED,2022-10-16 04:02:41.000000000,2022-11-08 02:15:08.000000000,2022-11-08 02:15:08.000000000,"[{'_account_id': 22348}, {'_account_id': 28748}]","[{'number': 1, 'created': '2022-10-16 04:02:41.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/watcher-tempest-plugin/commit/01ab036562b346bf2a558d96308c7e2d24f65f57', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nAlso fixing the zuul config error.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I6e71dbd45ec97e65d51c26de092af0da7dd1dea0\n'}]",1,861517,01ab036562b346bf2a558d96308c7e2d24f65f57,6,2,1,8556,,,0,"Add stable/zed jobs on master gate

As zed is released, we should add its job on master
gate to keep branchless tempest plugins compatible
to stable branch.

Also fixing the zuul config error.

Ref: Tempest plugins guide for stable branch testing:
- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html

Change-Id: I6e71dbd45ec97e65d51c26de092af0da7dd1dea0
",git fetch https://review.opendev.org/openstack/watcher-tempest-plugin refs/changes/17/861517/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,01ab036562b346bf2a558d96308c7e2d24f65f57,zed-stable-job, queue: watcher - watcher-tempest-functional-zed name: watcher-tempest-functional-zed parent: watcher-tempest-functional nodeset: openstack-single-node-focal override-checkout: stable/zed - job:, queue: watcher,8,1
openstack%2Fnova~stable%2Fyoga~I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19,openstack/nova,stable/yoga,I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19,Adds a repoducer for post live migration fail,MERGED,2022-10-19 10:55:37.000000000,2022-11-08 01:35:57.000000000,2022-11-08 01:34:50.000000000,"[{'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2022-10-19 10:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8760e1d27d6fe5e1a000a848a647fcc94705fe61', 'message': 'Adds a repoducer for post live migration fail\n\nAdds a regression test or repoducer for post live migration\nfail at destination, the possible casue can be fail to get\ninstance network info or  block device info\n\nRelated-Bug: #1628606\nChange-Id: I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19\n(cherry picked from commit a20baeca1f5ebb0dfe9607335a6986e9ed0e1725)\n(cherry picked from commit b4a62650f3b298df2f6f5b9f4402f27c4121f2b8)\n'}, {'number': 2, 'created': '2022-10-21 07:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/41e92f59673fffc3df05d0ac94da9ff9b19d939c', 'message': 'Adds a repoducer for post live migration fail\n\nAdds a regression test or repoducer for post live migration\nfail at destination, the possible casue can be fail to get\ninstance network info or  block device info\n\nconflict and new changes:\nadds getting server after _live_migrate in reproducer test (missed in\nmain commit)\nadds return server from _live_migrate in _integrated_helpers\n\nRelated-Bug: #1628606\nChange-Id: I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19\n(cherry picked from commit a20baeca1f5ebb0dfe9607335a6986e9ed0e1725)\n(cherry picked from commit b4a62650f3b298df2f6f5b9f4402f27c4121f2b8)\n'}, {'number': 3, 'created': '2022-10-21 09:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f9f4b4caf8c8c73b1aab2f15cf45ba340e62e09', 'message': 'Adds a repoducer for post live migration fail\n\nAdds a regression test or repoducer for post live migration\nfail at destination, the possible casue can be fail to get\ninstance network info or  block device info\n\nchanges:\nadds return server from _live_migrate in _integrated_helpers\n\nRelated-Bug: #1628606\nChange-Id: I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19\n(cherry picked from commit a20baeca1f5ebb0dfe9607335a6986e9ed0e1725)\n(cherry picked from commit b4a62650f3b298df2f6f5b9f4402f27c4121f2b8)\n'}, {'number': 4, 'created': '2022-10-21 12:52:16.000000000', 'files': ['nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/regressions/test_bug_1628606.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/71e5a1dbcc22aeaa798d3d06ce392cf73364b8db', 'message': 'Adds a repoducer for post live migration fail\n\nAdds a regression test or repoducer for post live migration\nfail at destination, the possible casue can be fail to get\ninstance network info or  block device info\n\nchanges:\nadds return server from _live_migrate in _integrated_helpers\n\nRelated-Bug: #1628606\nChange-Id: I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19\n(cherry picked from commit a20baeca1f5ebb0dfe9607335a6986e9ed0e1725)\n(cherry picked from commit 74a618a8118642c9fd32c4e0d502d12ac826affe)\n'}]",1,861871,71e5a1dbcc22aeaa798d3d06ce392cf73364b8db,23,4,4,34860,,,0,"Adds a repoducer for post live migration fail

Adds a regression test or repoducer for post live migration
fail at destination, the possible casue can be fail to get
instance network info or  block device info

changes:
adds return server from _live_migrate in _integrated_helpers

Related-Bug: #1628606
Change-Id: I48dbe0aae8a3943fdde69cda1bd663d70ea0eb19
(cherry picked from commit a20baeca1f5ebb0dfe9607335a6986e9ed0e1725)
(cherry picked from commit 74a618a8118642c9fd32c4e0d502d12ac826affe)
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/861871/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1628606.py'],1,8760e1d27d6fe5e1a000a848a647fcc94705fe61,bug/1628606,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import test from nova.tests import fixtures as nova_fixtures from nova.tests.functional.api import client from nova.tests.functional import fixtures as func_fixtures from nova.tests.functional import integrated_helpers from unittest import mock class PostLiveMigrationFail( test.TestCase, integrated_helpers.InstanceHelperMixin): """"""Regression test for bug 1628606 """""" def setUp(self): super().setUp() self.useFixture(nova_fixtures.NeutronFixture(self)) self.glance = self.useFixture(nova_fixtures.GlanceFixture(self)) self.useFixture(func_fixtures.PlacementFixture()) self.useFixture(nova_fixtures.HostNameWeigherFixture()) self.start_service('conductor') self.start_service('scheduler') api_fixture = self.useFixture(nova_fixtures.OSAPIFixture( api_version='v2.1')) self.api = api_fixture.admin_api self.api.microversion = 'latest' self.src = self._start_compute(host='host1') self.dest = self._start_compute(host='host2') @mock.patch( 'nova.compute.manager.ComputeManager' '._post_live_migration_remove_source_vol_connections') def test_post_live_migration(self, mock_migration): server = self._create_server(networks=[]) self.assertEqual(self.src.host, server['OS-EXT-SRV-ATTR:host']) error = client.OpenStackApiException( ""Failed to remove source vol connection post live migration"") mock_migration.side_effect = error self._live_migrate( server, migration_expected_state='error', server_expected_state='ERROR') # FIXME(amit): this should point to the dest as after migration # but does not because of bug 1628606 self.assertEqual(self.src.host, server['OS-EXT-SRV-ATTR:host']) ",,61,0
openstack%2Frequirements~stable%2Fzed~I1ebf6bf72883556fcc3cb22e591d7cbd3926c236,openstack/requirements,stable/zed,I1ebf6bf72883556fcc3cb22e591d7cbd3926c236,update constraint for python-manilaclient to new release 4.1.1,MERGED,2022-11-02 08:09:37.000000000,2022-11-08 01:34:45.000000000,2022-11-08 01:34:45.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 08:09:37.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6989b43d6eec953f6c7087b00862e3696f3d82bd', 'message': 'update constraint for python-manilaclient to new release 4.1.1\n\nmeta: version: 4.1.1\nmeta: diff-start: -\nmeta: series: zed\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: silvacarloss <ces.eduardo98@gmail.com>\nmeta: release:Commit: silvacarloss <ces.eduardo98@gmail.com>\nmeta: release:Change-Id: Ie9f228ce04dd07dba6405041d8d37d7683deaeff\nmeta: release:Code-Review+1: Goutham Pacha Ravi <gouthampravi@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Workflow+1: Elod Illes <elod.illes@est.tech>\nChange-Id: I1ebf6bf72883556fcc3cb22e591d7cbd3926c236\n'}]",3,863199,6989b43d6eec953f6c7087b00862e3696f3d82bd,14,3,1,11131,,,0,"update constraint for python-manilaclient to new release 4.1.1

meta: version: 4.1.1
meta: diff-start: -
meta: series: zed
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: silvacarloss <ces.eduardo98@gmail.com>
meta: release:Commit: silvacarloss <ces.eduardo98@gmail.com>
meta: release:Change-Id: Ie9f228ce04dd07dba6405041d8d37d7683deaeff
meta: release:Code-Review+1: Goutham Pacha Ravi <gouthampravi@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Workflow+1: Elod Illes <elod.illes@est.tech>
Change-Id: I1ebf6bf72883556fcc3cb22e591d7cbd3926c236
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/863199/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,6989b43d6eec953f6c7087b00862e3696f3d82bd,new-release,python-manilaclient===4.1.1,python-manilaclient===4.1.0,1,1
openstack%2Frequirements~master~I2bc4b2e1e7f05e415564207ba4ca51626a091a39,openstack/requirements,master,I2bc4b2e1e7f05e415564207ba4ca51626a091a39,update constraint for tripleo-common to new release 17.0.0,MERGED,2022-11-02 16:38:33.000000000,2022-11-08 00:12:52.000000000,2022-11-08 00:11:55.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 16:38:33.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2c995e3cbc229b4b6caf4f116c0cad97bd37b3e4', 'message': 'update constraint for tripleo-common to new release 17.0.0\n\nmeta: version: 17.0.0\nmeta: diff-start: -\nmeta: series: independent\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: rabi <ramishra@redhat.com>\nmeta: release:Commit: rabi <ramishra@redhat.com>\nmeta: release:Change-Id: Id6fa1b598ee430a6b496cf4f315e5fb3e7a2df4a\nmeta: release:Code-Review+1: Takashi Kajinami <tkajinam@redhat.com>\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+1: Jiri Podivin <jpodivin@redhat.com>\nmeta: release:Code-Review+1: mbu <mat.bultel@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Ronelle Landy <rlandy@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I2bc4b2e1e7f05e415564207ba4ca51626a091a39\n'}]",2,863415,2c995e3cbc229b4b6caf4f116c0cad97bd37b3e4,10,3,1,11131,,,0,"update constraint for tripleo-common to new release 17.0.0

meta: version: 17.0.0
meta: diff-start: -
meta: series: independent
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: rabi <ramishra@redhat.com>
meta: release:Commit: rabi <ramishra@redhat.com>
meta: release:Change-Id: Id6fa1b598ee430a6b496cf4f315e5fb3e7a2df4a
meta: release:Code-Review+1: Takashi Kajinami <tkajinam@redhat.com>
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+1: Jiri Podivin <jpodivin@redhat.com>
meta: release:Code-Review+1: mbu <mat.bultel@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Ronelle Landy <rlandy@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I2bc4b2e1e7f05e415564207ba4ca51626a091a39
",git fetch https://review.opendev.org/openstack/requirements refs/changes/15/863415/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2c995e3cbc229b4b6caf4f116c0cad97bd37b3e4,new-release,tripleo-common===17.0.0,tripleo-common===16.4.0,1,1
openstack%2Frequirements~master~Icc3ca2c341cd4e828f2940a57ef84c3a97f82557,openstack/requirements,master,Icc3ca2c341cd4e828f2940a57ef84c3a97f82557,update constraint for validations-libs to new release 1.8.0,MERGED,2022-11-02 16:47:18.000000000,2022-11-07 23:48:12.000000000,2022-11-07 23:46:32.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 16:47:18.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5ce9b0145ab6750c0159452e0a85c109d4a136ba', 'message': 'update constraint for validations-libs to new release 1.8.0\n\nmeta: version: 1.8.0\nmeta: diff-start: -\nmeta: series: independent\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: rabi <ramishra@redhat.com>\nmeta: release:Commit: rabi <ramishra@redhat.com>\nmeta: release:Change-Id: Id6fa1b598ee430a6b496cf4f315e5fb3e7a2df4a\nmeta: release:Code-Review+1: Takashi Kajinami <tkajinam@redhat.com>\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+1: Jiri Podivin <jpodivin@redhat.com>\nmeta: release:Code-Review+1: mbu <mat.bultel@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Ronelle Landy <rlandy@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Icc3ca2c341cd4e828f2940a57ef84c3a97f82557\n'}]",3,863417,5ce9b0145ab6750c0159452e0a85c109d4a136ba,13,3,1,11131,,,0,"update constraint for validations-libs to new release 1.8.0

meta: version: 1.8.0
meta: diff-start: -
meta: series: independent
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: rabi <ramishra@redhat.com>
meta: release:Commit: rabi <ramishra@redhat.com>
meta: release:Change-Id: Id6fa1b598ee430a6b496cf4f315e5fb3e7a2df4a
meta: release:Code-Review+1: Takashi Kajinami <tkajinam@redhat.com>
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+1: Jiri Podivin <jpodivin@redhat.com>
meta: release:Code-Review+1: mbu <mat.bultel@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Ronelle Landy <rlandy@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Icc3ca2c341cd4e828f2940a57ef84c3a97f82557
",git fetch https://review.opendev.org/openstack/requirements refs/changes/17/863417/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5ce9b0145ab6750c0159452e0a85c109d4a136ba,new-release,validations-libs===1.8.0,validations-libs===1.7.1,1,1
openstack%2Frequirements~master~I88e20e222992464ac225353cfa27ced5a11c4177,openstack/requirements,master,I88e20e222992464ac225353cfa27ced5a11c4177,update constraint for os-net-config to new release 16.0.0,MERGED,2022-11-02 16:29:57.000000000,2022-11-07 23:47:32.000000000,2022-11-07 23:46:29.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 16:29:57.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a08c466163e9ffc1dc046d51929e0dab0b61c749', 'message': 'update constraint for os-net-config to new release 16.0.0\n\nmeta: version: 16.0.0\nmeta: diff-start: -\nmeta: series: independent\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: rabi <ramishra@redhat.com>\nmeta: release:Commit: rabi <ramishra@redhat.com>\nmeta: release:Change-Id: Id6fa1b598ee430a6b496cf4f315e5fb3e7a2df4a\nmeta: release:Code-Review+1: Takashi Kajinami <tkajinam@redhat.com>\nmeta: release:Code-Review+1: Marios Andreou <marios@redhat.com>\nmeta: release:Code-Review+1: Jiri Podivin <jpodivin@redhat.com>\nmeta: release:Code-Review+1: mbu <mat.bultel@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Ronelle Landy <rlandy@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I88e20e222992464ac225353cfa27ced5a11c4177\n'}]",2,863407,a08c466163e9ffc1dc046d51929e0dab0b61c749,10,3,1,11131,,,0,"update constraint for os-net-config to new release 16.0.0

meta: version: 16.0.0
meta: diff-start: -
meta: series: independent
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: rabi <ramishra@redhat.com>
meta: release:Commit: rabi <ramishra@redhat.com>
meta: release:Change-Id: Id6fa1b598ee430a6b496cf4f315e5fb3e7a2df4a
meta: release:Code-Review+1: Takashi Kajinami <tkajinam@redhat.com>
meta: release:Code-Review+1: Marios Andreou <marios@redhat.com>
meta: release:Code-Review+1: Jiri Podivin <jpodivin@redhat.com>
meta: release:Code-Review+1: mbu <mat.bultel@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Ronelle Landy <rlandy@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I88e20e222992464ac225353cfa27ced5a11c4177
",git fetch https://review.opendev.org/openstack/requirements refs/changes/07/863407/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a08c466163e9ffc1dc046d51929e0dab0b61c749,new-release,os-net-config===16.0.0,os-net-config===15.2.0,1,1
openstack%2Fswift~master~Ibe67b1a485350967e37809ba8575a33eba56ee97,openstack/swift,master,Ibe67b1a485350967e37809ba8575a33eba56ee97,Mark rolling-upgrade job non-voting,MERGED,2022-11-07 20:25:42.000000000,2022-11-07 23:32:44.000000000,2022-11-07 23:30:45.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 20:25:42.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/d1b2bbdcf0421691c0e45bf51084622c8f474116', 'message': ""Mark rolling-upgrade job non-voting\n\nUpstream CPython broke our HTTP parsing; while we can fix our own\nHttpProtocol, previous tags won't have the fix (naturally).\n\nSee also: https://github.com/python/cpython/commit/4abab6b603dd38bec1168e9a37c40a48ec89508e\n\nChange-Id: Ibe67b1a485350967e37809ba8575a33eba56ee97\nRelated-Change: https://review.opendev.org/c/openstack/swift/+/863441\n""}]",1,863929,d1b2bbdcf0421691c0e45bf51084622c8f474116,8,2,1,15343,,,0,"Mark rolling-upgrade job non-voting

Upstream CPython broke our HTTP parsing; while we can fix our own
HttpProtocol, previous tags won't have the fix (naturally).

See also: https://github.com/python/cpython/commit/4abab6b603dd38bec1168e9a37c40a48ec89508e

Change-Id: Ibe67b1a485350967e37809ba8575a33eba56ee97
Related-Change: https://review.opendev.org/c/openstack/swift/+/863441
",git fetch https://review.opendev.org/openstack/swift refs/changes/29/863929/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d1b2bbdcf0421691c0e45bf51084622c8f474116,, voting: false, - swift-multinode-rolling-upgrade: irrelevant-files: *functest-irrelevant-files,1,2
openstack%2Frequirements~stable%2Fzed~Ie36e4cc68c6fb5e28793ad38b094e3bcb936abe9,openstack/requirements,stable/zed,Ie36e4cc68c6fb5e28793ad38b094e3bcb936abe9,update constraint for sushy to new release 4.3.1,MERGED,2022-11-07 11:07:40.000000000,2022-11-07 23:30:42.000000000,2022-11-07 23:30:42.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-07 11:07:40.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d007026c132884c4ed4e9dff659d2dc08914cd19', 'message': 'update constraint for sushy to new release 4.3.1\n\nmeta: version: 4.3.1\nmeta: diff-start: -\nmeta: series: zed\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jacob Anders <janders@redhat.com>\nmeta: release:Commit: Jacob Anders <janders@redhat.com>\nmeta: release:Change-Id: I5ecfc2cb2de6fbf468e9981b2767c85ab263e90d\nmeta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>\nmeta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ie36e4cc68c6fb5e28793ad38b094e3bcb936abe9\n'}]",2,863866,d007026c132884c4ed4e9dff659d2dc08914cd19,13,3,1,11131,,,0,"update constraint for sushy to new release 4.3.1

meta: version: 4.3.1
meta: diff-start: -
meta: series: zed
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Jacob Anders <janders@redhat.com>
meta: release:Commit: Jacob Anders <janders@redhat.com>
meta: release:Change-Id: I5ecfc2cb2de6fbf468e9981b2767c85ab263e90d
meta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>
meta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Ie36e4cc68c6fb5e28793ad38b094e3bcb936abe9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/66/863866/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d007026c132884c4ed4e9dff659d2dc08914cd19,new-release,sushy===4.3.1,sushy===4.3.0,1,1
openstack%2Frequirements~stable%2Fwallaby~Ief9acf6d570444002e1a8e0f6879cb925cd37790,openstack/requirements,stable/wallaby,Ief9acf6d570444002e1a8e0f6879cb925cd37790,update constraint for os-brick to new release 4.3.4,MERGED,2022-11-03 11:34:09.000000000,2022-11-07 23:29:15.000000000,2022-11-07 23:29:15.000000000,"[{'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-03 11:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/bd6d236dc6ef2d6ab15dc2b1fb8fe147afbceb31', 'message': 'update constraint for os-brick to new release 4.3.4\n\nmeta: version: 4.3.4\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Jon Bernard <jobernar@redhat.com>\nmeta: release:Commit: Jon Bernard <jobernar@redhat.com>\nmeta: release:Change-Id: I7d3501a9cd2453e545826d158223dcd1bddeda7a\nmeta: release:Code-Review+1: Rajat Dhasmana <rajatdhasmana@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ief9acf6d570444002e1a8e0f6879cb925cd37790\n'}, {'number': 2, 'created': '2022-11-04 14:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2e61942ceb1e48ffea31ed859bd7cc4b5161914b', 'message': 'update constraint for os-brick to new release 4.3.4\n\nmeta: version: 4.3.4\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Jon Bernard <jobernar@redhat.com>\nmeta: release:Commit: Jon Bernard <jobernar@redhat.com>\nmeta: release:Change-Id: I7d3501a9cd2453e545826d158223dcd1bddeda7a\nmeta: release:Code-Review+1: Rajat Dhasmana <rajatdhasmana@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ief9acf6d570444002e1a8e0f6879cb925cd37790\n'}, {'number': 3, 'created': '2022-11-05 18:03:01.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6cadd874e2214443609d9efb10cfa4c4d0cd32d1', 'message': 'update constraint for os-brick to new release 4.3.4\n\nmeta: version: 4.3.4\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Jon Bernard <jobernar@redhat.com>\nmeta: release:Commit: Jon Bernard <jobernar@redhat.com>\nmeta: release:Change-Id: I7d3501a9cd2453e545826d158223dcd1bddeda7a\nmeta: release:Code-Review+1: Rajat Dhasmana <rajatdhasmana@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ief9acf6d570444002e1a8e0f6879cb925cd37790\n'}]",2,863511,6cadd874e2214443609d9efb10cfa4c4d0cd32d1,22,5,3,11131,,,0,"update constraint for os-brick to new release 4.3.4

meta: version: 4.3.4
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Jon Bernard <jobernar@redhat.com>
meta: release:Commit: Jon Bernard <jobernar@redhat.com>
meta: release:Change-Id: I7d3501a9cd2453e545826d158223dcd1bddeda7a
meta: release:Code-Review+1: Rajat Dhasmana <rajatdhasmana@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Ief9acf6d570444002e1a8e0f6879cb925cd37790
",git fetch https://review.opendev.org/openstack/requirements refs/changes/11/863511/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,bd6d236dc6ef2d6ab15dc2b1fb8fe147afbceb31,new-release,os-brick===4.3.4,os-brick===4.3.3,1,1
openstack%2Fpython-openstackclient~master~Iab5232858e4a67e356680d169a885875d574c3cc,openstack/python-openstackclient,master,Iab5232858e4a67e356680d169a885875d574c3cc,Run swift in -tips job,MERGED,2022-09-20 18:24:45.000000000,2022-11-07 22:55:02.000000000,2022-11-07 22:53:03.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-09-20 18:24:45.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/28ac0141b56b8c0943fb29733c1fd6c000856b17', 'message': 'Run swift in -tips job\n\nSince there is only py3 left, swift has learned to live with it, so we\nmight as well test it.\n\nChange-Id: Iab5232858e4a67e356680d169a885875d574c3cc\n'}]",2,858568,28ac0141b56b8c0943fb29733c1fd6c000856b17,13,3,1,13252,,,0,"Run swift in -tips job

Since there is only py3 left, swift has learned to live with it, so we
might as well test it.

Change-Id: Iab5232858e4a67e356680d169a885875d574c3cc
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/68/858568/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,28ac0141b56b8c0943fb29733c1fd6c000856b17,,," # This is insufficient, but leaving it here as a reminder of what may # someday be all we need to make this work # disable_python3_package swift DISABLED_PYTHON3_PACKAGES: swift devstack_services: # Swift is not ready for python3 yet: At a minimum keystonemiddleware needs # to be installed in the py2 env, there are probably other things too... s-account: false s-container: false s-object: false s-proxy: false # As swift is not available for this job, c-bak service won't be functional. # The backup related tests can be handled by other jobs having swift enabled. # The backup service along with swift services can be enabled once swift is # compatible with py3 c-bak: false",0,16
openstack%2Frequirements~master~Ia4b554d5acb1e4586b3d058908cec53d46243dc9,openstack/requirements,master,Ia4b554d5acb1e4586b3d058908cec53d46243dc9,Bump pytest version to the latest version to avoid py usage.,MERGED,2022-11-07 16:01:10.000000000,2022-11-07 22:53:57.000000000,2022-11-07 22:53:00.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 32927}]","[{'number': 1, 'created': '2022-11-07 16:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7672eb21a615db1629d6072306d2bc6633149862', 'message': '[DNM] Test pytest latest version for horizon\n\nChange-Id: Ia4b554d5acb1e4586b3d058908cec53d46243dc9\n'}, {'number': 2, 'created': '2022-11-07 16:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/5c85eea0ad73b644f9ab80908c31bf304c4920fc', 'message': ""Bump\xa0pytest version to the latest version to avoid py usage.\n\npytest old version may use 'py' which has some CVE [1].\nSo it is advised\xa0to use pytest latest version 7.2.0\nwhich completely\xa0removes usage of py. Also, pytest-html\nversion is bumped to the latest version 3.2.0 to include\n[2] fix. The next step will be updating the pytest version\nin the horizon and any other places.\n\n[1]\xa0https://nvd.nist.gov/vuln/detail/CVE-2022-42969\n[2]\xa0https://github.com/pytest-dev/pytest/issues/10428\n\nCo-Authored-By: mitya-eremeev-2 <mitossvyaz@mail.ru>\nChange-Id: Ia4b554d5acb1e4586b3d058908cec53d46243dc9\n""}, {'number': 3, 'created': '2022-11-07 18:04:15.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5053de6c19be69d4b088d4825dd4d7748e2a900d', 'message': ""Bump\xa0pytest version to the latest version to avoid py usage.\n\npytest old version may use 'py' which has some CVE [1].\nSo it is advised\xa0to use pytest latest version 7.2.0\nwhich completely\xa0removes usage of py. Also, pytest-html\nversion is bumped to the latest version 3.2.0 to include\n[2] fix. The next step will be updating the pytest version\nin the horizon and any other places.\n\n[1]\xa0https://nvd.nist.gov/vuln/detail/CVE-2022-42969\n[2]\xa0https://github.com/pytest-dev/pytest/issues/10428\n\nCo-Authored-By: mitya-eremeev-2 <mitossvyaz@mail.ru>\nChange-Id: Ia4b554d5acb1e4586b3d058908cec53d46243dc9\n""}]",1,863893,5053de6c19be69d4b088d4825dd4d7748e2a900d,14,3,3,29313,,,0,"Bump pytest version to the latest version to avoid py usage.

pytest old version may use 'py' which has some CVE [1].
So it is advised to use pytest latest version 7.2.0
which completely removes usage of py. Also, pytest-html
version is bumped to the latest version 3.2.0 to include
[2] fix. The next step will be updating the pytest version
in the horizon and any other places.

[1] https://nvd.nist.gov/vuln/detail/CVE-2022-42969
[2] https://github.com/pytest-dev/pytest/issues/10428

Co-Authored-By: mitya-eremeev-2 <mitossvyaz@mail.ru>
Change-Id: Ia4b554d5acb1e4586b3d058908cec53d46243dc9
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/863893/3 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,7672eb21a615db1629d6072306d2bc6633149862,,pytest===7.2.0pytest-html===3.2.0,pytest===7.1.2pytest-html===3.1.1,2,2
openstack%2Frequirements~stable%2Fyoga~I2aedda59b2408d41cd099ac8ded4bf9d6cf5a401,openstack/requirements,stable/yoga,I2aedda59b2408d41cd099ac8ded4bf9d6cf5a401,update constraint for metalsmith to new release 1.6.3,MERGED,2022-11-07 14:22:05.000000000,2022-11-07 22:52:56.000000000,2022-11-07 22:52:56.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 14:22:05.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e82f982344d23297fab1e2489fda7b7438c4b5ea', 'message': 'update constraint for metalsmith to new release 1.6.3\n\nmeta: version: 1.6.3\nmeta: diff-start: -\nmeta: series: yoga\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jay Faulkner <jay@jvf.cc>\nmeta: release:Commit: Jay Faulkner <jay@jvf.cc>\nmeta: release:Change-Id: I1678bc2cbf67190670e8b8dad8953c273d4db078\nmeta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I2aedda59b2408d41cd099ac8ded4bf9d6cf5a401\n'}]",1,863882,e82f982344d23297fab1e2489fda7b7438c4b5ea,7,2,1,11131,,,0,"update constraint for metalsmith to new release 1.6.3

meta: version: 1.6.3
meta: diff-start: -
meta: series: yoga
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Jay Faulkner <jay@jvf.cc>
meta: release:Commit: Jay Faulkner <jay@jvf.cc>
meta: release:Change-Id: I1678bc2cbf67190670e8b8dad8953c273d4db078
meta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I2aedda59b2408d41cd099ac8ded4bf9d6cf5a401
",git fetch https://review.opendev.org/openstack/requirements refs/changes/82/863882/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e82f982344d23297fab1e2489fda7b7438c4b5ea,new-release,metalsmith===1.6.3,metalsmith===1.6.2,1,1
openstack%2Fcharm-trilio-dm-api~master~I80ebe8f49e1cb0e5c4c345caaac6f85743418d3d,openstack/charm-trilio-dm-api,master,I80ebe8f49e1cb0e5c4c345caaac6f85743418d3d,Add required build packages,MERGED,2022-10-28 13:09:33.000000000,2022-11-07 22:41:22.000000000,2022-11-07 22:41:22.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-28 13:09:33.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-trilio-dm-api/commit/cbb28c0ee5e1ec27b4540a1bd331de4b973a83e1', 'message': 'Add required build packages\n\nChange-Id: I80ebe8f49e1cb0e5c4c345caaac6f85743418d3d\n'}]",4,862888,cbb28c0ee5e1ec27b4540a1bd331de4b973a83e1,12,3,1,12549,,,0,"Add required build packages

Change-Id: I80ebe8f49e1cb0e5c4c345caaac6f85743418d3d
",git fetch https://review.opendev.org/openstack/charm-trilio-dm-api refs/changes/88/862888/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,cbb28c0ee5e1ec27b4540a1bd331de4b973a83e1,binary-build-pkgs, - libffi-dev - libssl-dev - rustc - cargo,,4,0
openstack%2Fcharm-trilio-data-mover~master~Icc221196efa8f02302499626af2a788537520387,openstack/charm-trilio-data-mover,master,Icc221196efa8f02302499626af2a788537520387,Add required build packages,MERGED,2022-10-28 13:09:50.000000000,2022-11-07 22:35:42.000000000,2022-11-07 22:35:42.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-28 13:09:50.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-trilio-data-mover/commit/92b3c383aee810664a5ebb7bd882350af0485ca4', 'message': 'Add required build packages\n\nChange-Id: Icc221196efa8f02302499626af2a788537520387\n'}]",3,862889,92b3c383aee810664a5ebb7bd882350af0485ca4,11,3,1,12549,,,0,"Add required build packages

Change-Id: Icc221196efa8f02302499626af2a788537520387
",git fetch https://review.opendev.org/openstack/charm-trilio-data-mover refs/changes/89/862889/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,92b3c383aee810664a5ebb7bd882350af0485ca4,binary-build-pkgs, - libffi-dev - libssl-dev - rustc - cargo,,4,0
openstack%2Fcharm-trilio-horizon-plugin~master~Ibdeef2c73048793719bcc2d2c7367732a40177f8,openstack/charm-trilio-horizon-plugin,master,Ibdeef2c73048793719bcc2d2c7367732a40177f8,Add required build packages,MERGED,2022-10-28 13:10:13.000000000,2022-11-07 22:27:58.000000000,2022-11-07 22:27:58.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-28 13:10:13.000000000', 'files': ['charmcraft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-trilio-horizon-plugin/commit/6e14aa25b130f53b73abee0ec4fa44257195b2e8', 'message': 'Add required build packages\n\nChange-Id: Ibdeef2c73048793719bcc2d2c7367732a40177f8\n'}]",1,862910,6e14aa25b130f53b73abee0ec4fa44257195b2e8,7,3,1,12549,,,0,"Add required build packages

Change-Id: Ibdeef2c73048793719bcc2d2c7367732a40177f8
",git fetch https://review.opendev.org/openstack/charm-trilio-horizon-plugin refs/changes/10/862910/1 && git format-patch -1 --stdout FETCH_HEAD,['charmcraft.yaml'],1,6e14aa25b130f53b73abee0ec4fa44257195b2e8,binary-build-pkgs, - libffi-dev - libssl-dev - rustc - cargo,,4,0
openstack%2Fglance~stable%2Fyoga~If36e64b61767dc5c1df0daec2dd176fecd409926,openstack/glance,stable/yoga,If36e64b61767dc5c1df0daec2dd176fecd409926,[stable-only] Remove glance-code-constants-check,MERGED,2022-11-04 12:05:23.000000000,2022-11-07 22:16:00.000000000,2022-11-07 22:13:21.000000000,"[{'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 12:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/635d3354efd4a65ef95ff8d5d9002c780fde1cdf', 'message': ""[stable-only] Remove glance-code-constants-check\n\nThis job is only useful in the development branch; there's no\npoint in running it in the stable branches.\n\nChange-Id: If36e64b61767dc5c1df0daec2dd176fecd409926\n""}, {'number': 2, 'created': '2022-11-07 18:06:15.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/glance/commit/5fbf47378e70537c73394408e69e94449aba1bec', 'message': ""[stable-only] Remove glance-code-constants-check\n\nThis job is only useful in the development branch; there's no\npoint in running it in the stable branches.\n\nChange-Id: If36e64b61767dc5c1df0daec2dd176fecd409926\n(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)\n""}]",3,863622,5fbf47378e70537c73394408e69e94449aba1bec,11,2,2,5314,,,0,"[stable-only] Remove glance-code-constants-check

This job is only useful in the development branch; there's no
point in running it in the stable branches.

Change-Id: If36e64b61767dc5c1df0daec2dd176fecd409926
(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)
",git fetch https://review.opendev.org/openstack/glance refs/changes/22/863622/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,635d3354efd4a65ef95ff8d5d9002c780fde1cdf,remove-constants-check-stable/yoga,, name: glance-code-constants-check parent: tox description: | Tests to catch when code constants have gotten out of sync. vars: tox_envlist: gateonly irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tox.ini$ - ^\.zuul\.yaml$ - job: - glance-code-constants-check,0,19
openstack%2Fswift~master~I6d8d5af68884b08e22fd8a332f366a0b81acb7ed,openstack/swift,master,I6d8d5af68884b08e22fd8a332f366a0b81acb7ed,tests: Tolerate NoSuchBucket errors when cleaning up,MERGED,2022-11-04 16:40:06.000000000,2022-11-07 22:15:16.000000000,2022-11-07 22:13:18.000000000,"[{'_account_id': 1179}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 16:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8829baec6673bd04d8e4066fb954a13781415187', 'message': ""tests: Tolerate NoSuchBucket errors when cleaning up\n\nSometimes we'll get back a 503 on the initial attempt, though the delete\nsucceeded on the backend. Then when the client automatically retries, it\ngets back a 404.\n\nChange-Id: I6d8d5af68884b08e22fd8a332f366a0b81acb7ed\n""}, {'number': 2, 'created': '2022-11-07 19:41:15.000000000', 'files': ['test/s3api/__init__.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/162847d15141d1948ca45190166c7160bd6931c5', 'message': ""tests: Tolerate NoSuchBucket errors when cleaning up\n\nSometimes we'll get back a 503 on the initial attempt, though the delete\nsucceeded on the backend. Then when the client automatically retries, it\ngets back a 404.\n\nChange-Id: I6d8d5af68884b08e22fd8a332f366a0b81acb7ed\n""}]",2,863670,162847d15141d1948ca45190166c7160bd6931c5,13,2,2,15343,,,0,"tests: Tolerate NoSuchBucket errors when cleaning up

Sometimes we'll get back a 503 on the initial attempt, though the delete
succeeded on the backend. Then when the client automatically retries, it
gets back a 404.

Change-Id: I6d8d5af68884b08e22fd8a332f366a0b81acb7ed
",git fetch https://review.opendev.org/openstack/swift refs/changes/70/863670/2 && git format-patch -1 --stdout FETCH_HEAD,['test/s3api/__init__.py'],1,8829baec6673bd04d8e4066fb954a13781415187,," if 'NoSuchBucket' not in str(e): if 'BucketNotEmpty' not in str(e): raise # Something's gone sideways. Try harder client.put_bucket_versioning( Bucket=bucket_name, VersioningConfiguration={'Status': 'Suspended'}) while True: cls._remove_all_object_versions_from_bucket( client, bucket_name) # also try some version-unaware operations... for key in client.list_objects(Bucket=bucket_name).get( 'Contents', []): client.delete_object(Bucket=bucket_name, Key=key['Key']) # *then* try again try: client.delete_bucket(Bucket=bucket_name) except ClientError as e: if 'NoSuchBucket' in str(e): break if 'BucketNotEmpty' not in str(e): raise if time.time() > timeout: raise Exception('Timeout clearing %r' % bucket_name) time.sleep(backoff) backoff *= 2 else: break"," if 'BucketNotEmpty' not in str(e): raise # Something's gone sideways. Try harder client.put_bucket_versioning( Bucket=bucket_name, VersioningConfiguration={'Status': 'Suspended'}) while True: cls._remove_all_object_versions_from_bucket( client, bucket_name) # also try some version-unaware operations... for key in client.list_objects(Bucket=bucket_name).get( 'Contents', []): client.delete_object(Bucket=bucket_name, Key=key['Key']) # *then* try again try: client.delete_bucket(Bucket=bucket_name) except ClientError as e: if 'BucketNotEmpty' not in str(e): raise if time.time() > timeout: raise Exception('Timeout clearing %r' % bucket_name) time.sleep(backoff) backoff *= 2 else: break",30,25
openstack%2Frequirements~stable%2Fwallaby~I18619fa00562de101f8c0fbb61bc065911bbfe08,openstack/requirements,stable/wallaby,I18619fa00562de101f8c0fbb61bc065911bbfe08,update constraint for python-neutronclient to new release 7.3.1,MERGED,2022-11-02 15:56:10.000000000,2022-11-07 22:13:15.000000000,2022-11-07 22:13:15.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 15:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7ed2142f5aa2172f1b2d387e4bec5ef0e833f590', 'message': 'update constraint for python-neutronclient to new release 7.3.1\n\nmeta: version: 7.3.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I18619fa00562de101f8c0fbb61bc065911bbfe08\n'}, {'number': 2, 'created': '2022-11-04 14:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/0ddb7926e6d133352b87d70024203eddd7ddb846', 'message': 'update constraint for python-neutronclient to new release 7.3.1\n\nmeta: version: 7.3.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I18619fa00562de101f8c0fbb61bc065911bbfe08\n'}, {'number': 3, 'created': '2022-11-05 18:03:18.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b2f3c5864620ad6594e4327dce73a3faaf1b499b', 'message': 'update constraint for python-neutronclient to new release 7.3.1\n\nmeta: version: 7.3.1\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I18619fa00562de101f8c0fbb61bc065911bbfe08\n'}]",0,863328,b2f3c5864620ad6594e4327dce73a3faaf1b499b,15,4,3,11131,,,0,"update constraint for python-neutronclient to new release 7.3.1

meta: version: 7.3.1
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
meta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
meta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327
meta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>
meta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>
meta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>
meta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I18619fa00562de101f8c0fbb61bc065911bbfe08
",git fetch https://review.opendev.org/openstack/requirements refs/changes/28/863328/3 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,7ed2142f5aa2172f1b2d387e4bec5ef0e833f590,new-release,python-neutronclient===7.3.1,python-neutronclient===7.3.0,1,1
openstack%2Fswift~master~Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4,openstack/swift,master,Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4,WIP proxy: add rate control in response to backend 529s,NEW,2022-10-17 17:33:41.000000000,2022-11-07 21:59:09.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-17 17:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5c9d9c217a328bcabcd1e3724c0fdad227d25c48', 'message': ""WIP proxy: add rate control in response to backend 529s\n\nTODO: update conf samples & deployment guide.\n\nDifferentiate the proxy server's behavior in response to a backend 529\nby counting them separately from other 5xx responses. A separate\ninstance of ErrorLimiter is used to count 529s and make a node\nunavailable for a suppresion interval if a suppression limit is\nexceeded. The rate control can be configured using two new config\noptions:\n\n    rate_control_suppression_limit\n    rate_control_suppression_limit\n\nChange-Id: Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4\n""}, {'number': 2, 'created': '2022-10-21 14:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7583dba81a8054b0b24972e1b33c01739587c67a', 'message': ""WIP proxy: add rate control in response to backend 529s\n\nTODO: update conf samples & deployment guide.\n\nDifferentiate the proxy server's behavior in response to a backend 529\nby counting them separately from other 5xx responses. A separate\ninstance of ErrorLimiter is used to count 529s and make a node\nunavailable for a suppresion interval if a suppression limit is\nexceeded. The rate control can be configured using two new config\noptions:\n\n    rate_control_suppression_limit\n    rate_control_suppression_limit\n\nChange-Id: Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4\n""}, {'number': 3, 'created': '2022-10-25 16:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/63291d90603a1a3103afe450906e52947478f473', 'message': ""WIP proxy: add rate control in response to backend 529s\n\nTODO: update conf samples & deployment guide.\n\nDifferentiate the proxy server's behavior in response to a backend 529\nby counting them separately from other 5xx responses. A separate\ninstance of ErrorLimiter is used to count 529s and make a node\nunavailable for a suppresion interval if a suppression limit is\nexceeded. The rate control can be configured using two new config\noptions:\n\n    rate_control_suppression_limit\n    rate_control_suppression_limit\n\nChange-Id: Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4\n""}, {'number': 4, 'created': '2022-10-25 18:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/13c00d3d46ec50d6219e0434c8b3c35eeccfa6ce', 'message': ""WIP proxy: add rate control in response to backend 529s\n\nTODO: update conf samples & deployment guide.\n\nDifferentiate the proxy server's behavior in response to a backend 529\nby counting them separately from other 5xx responses. A separate\ninstance of ErrorLimiter is used to count 529s and make a node\nunavailable for a suppresion interval if a suppression limit is\nexceeded. The rate control can be configured using two new config\noptions:\n\n    rate_control_suppression_limit\n    rate_control_suppression_limit\n\nChange-Id: Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4\n""}, {'number': 5, 'created': '2022-11-07 20:44:53.000000000', 'files': ['test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/proxy/controllers/test_container.py', 'swift/common/http.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/828d01624a2e4df02cc28d5d7047b4f615ba82bf', 'message': ""WIP proxy: add rate control in response to backend 529s\n\nTODO: update conf samples & deployment guide.\n\nDifferentiate the proxy server's behavior in response to a backend 529\nby counting them separately from other 5xx responses. A separate\ninstance of ErrorLimiter is used to count 529s and make a node\nunavailable for a suppresion interval if a suppression limit is\nexceeded. The rate control can be configured using two new config\noptions:\n\n    rate_control_suppression_limit\n    rate_control_suppression_limit\n\nChange-Id: Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4\n""}]",4,861653,828d01624a2e4df02cc28d5d7047b4f615ba82bf,16,1,5,7847,,,0,"WIP proxy: add rate control in response to backend 529s

TODO: update conf samples & deployment guide.

Differentiate the proxy server's behavior in response to a backend 529
by counting them separately from other 5xx responses. A separate
instance of ErrorLimiter is used to count 529s and make a node
unavailable for a suppresion interval if a suppression limit is
exceeded. The rate control can be configured using two new config
options:

    rate_control_suppression_limit
    rate_control_suppression_limit

Change-Id: Idf1a0aca58a2090b8259fb98aaf37e27c7b82bf4
",git fetch https://review.opendev.org/openstack/swift refs/changes/53/861653/3 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/test_server.py', 'test/unit/proxy/controllers/test_obj.py', 'test/unit/proxy/controllers/test_container.py', 'swift/common/http.py', 'swift/proxy/controllers/obj.py', 'swift/proxy/server.py', 'swift/proxy/controllers/base.py']",7,5c9d9c217a328bcabcd1e3724c0fdad227d25c48,p-proxy-529, if self.app.is_node_available(node): if self.app.is_node_available(node): if self.app.is_node_available(node): if self.app.is_node_available(node):, if not self.app.error_limited(node): if not self.app.error_limited(node): if not self.app.error_limited(node): if not self.app.error_limited(node):,287,36
openstack%2Ftripleo-ansible~master~I7538def60e4fd3a7187ede0e1f5ada1b0c460f65,openstack/tripleo-ansible,master,I7538def60e4fd3a7187ede0e1f5ada1b0c460f65,Add podman_socket role,MERGED,2022-09-15 09:41:02.000000000,2022-11-07 21:50:25.000000000,2022-11-07 21:50:25.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-09-15 09:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/19f9adac7cf2f638a81a436bf9758a89bf371df7', 'message': 'Add podma_socket role\n\nThis patch adds a role for creating podman socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 2, 'created': '2022-09-15 11:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d70702242f4e02bd9c8e4761342c14318d41dfad', 'message': 'Add podma_socket role\n\nThis patch adds a role for creating podman socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 3, 'created': '2022-09-16 11:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/06db75a60b8d49af80e8a7236bc7bcad520676f4', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 4, 'created': '2022-10-11 22:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f8043542d5730ed968bb2b2b9e05bd052fdc9144', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 5, 'created': '2022-10-13 12:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/74cd5fa482378e82c0746547e0f11ca60a9d4d14', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman TCP socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nTCP socket is used in favor of unix one due to socket creation instability\nwhen used with syystemd (more info in [1]).\n\n[1] https://github.com/containers/podman/issues/12493\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 6, 'created': '2022-10-17 09:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/af5cc5e92ccbe362e35a6b719216ddb8a541d72e', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman TCP socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nTCP socket is used in favor of unix one due to socket creation instability\nwhen used with syystemd (more info in [1]).\n\n[1] https://github.com/containers/podman/issues/12493\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 7, 'created': '2022-10-19 12:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/60f3c6179c84678d50bc15fb94f568a6be78311a', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 8, 'created': '2022-10-27 12:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b70bf65ccb2a9ffce2b51976381bfdb53cf2e30d', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 9, 'created': '2022-11-03 10:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6ceec1edf5b791ed07139b4bb00f53f10693c70c', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nAdds runc dependency to pass molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 10, 'created': '2022-11-03 10:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a6a2de16681deab0a704cc57d59c1575ef20a80f', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nAdds runc dependency to pass molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 11, 'created': '2022-11-03 13:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cb3d6295de6e8b54a9762fae08eac56869978f7b', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 12, 'created': '2022-11-03 15:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0a6d79e04fac46c1eac5a3621c4d4dcbfda4076c', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 13, 'created': '2022-11-03 16:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e3a5581b2dd4a7a29052d6e498de7133d118b0da', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 14, 'created': '2022-11-03 16:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2a5b7bf4e7031c28ac9702476125c91d0faef7bf', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 15, 'created': '2022-11-03 19:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1380fda649a4917fcdbdcfbc9de0cc1fac0878d9', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 16, 'created': '2022-11-04 11:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/67f9215af7fd462062304a206570e0552b48090a', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}, {'number': 17, 'created': '2022-11-04 11:55:38.000000000', 'files': ['tripleo_ansible/roles/tripleo_podman/molecule/login/prepare.yml', 'tripleo_ansible/roles/tripleo_podman/defaults/main.yml', 'tripleo_ansible/roles/tripleo_podman/meta/main.yml', 'tripleo_ansible/roles/tripleo_podman/templates/podman.service.j2', 'tripleo_ansible/roles/tripleo_podman/tasks/tripleo_podman_rsyslog_cleanup.yml', 'tripleo_ansible/roles/tripleo_podman/molecule/install/prepare.yml', 'tripleo_ansible/roles/tripleo_podman/tasks/tripleo_podman_service.yml', 'tripleo_ansible/roles/tripleo_podman/molecule/default/prepare.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4fd0e5a9aea67751a457fa82bb7331744f428259', 'message': 'Add podman_socket role\n\nThis patch adds a role for creating podman unix socket for TripleO purposes.\nIt will be used during collectd deployments since collectd-sensubility\nrequires accessing podman via the socket.\n\nFixes molecule tests for tripleo_podman role.\n\nChange-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65\n'}]",22,857855,4fd0e5a9aea67751a457fa82bb7331744f428259,74,4,17,5241,,,0,"Add podman_socket role

This patch adds a role for creating podman unix socket for TripleO purposes.
It will be used during collectd deployments since collectd-sensubility
requires accessing podman via the socket.

Fixes molecule tests for tripleo_podman role.

Change-Id: I7538def60e4fd3a7187ede0e1f5ada1b0c460f65
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/55/857855/16 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_podman/defaults/main.yml', 'tripleo_ansible/roles/tripleo_podman/templates/podman.service.j2', 'tripleo_ansible/roles/tripleo_podman/templates/podman.socket.j2', 'tripleo_ansible/roles/tripleo_podman/tasks/tripleo_podman_socket.yml']",4,19f9adac7cf2f638a81a436bf9758a89bf371df7,user-podman-socket,"--- # Copyright 2022 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. - name: Ensure podman socket directory exists become: true ansible.builtin.file: path: ""{{ tripleo_podman_socket_path | dirname }}"" state: directory mode: 0700 - name: Create required systemd unit files for podman socket become: true ansible.builtin.template: src: ""{{ item.source }}"" dest: ""{{ item.destination }}"" mode: 0644 with_items: - destination: ""/usr/lib/systemd/system/{{ tripleo_podman_service_unit_name }}"" source: podman.service.j2 - destination: ""/usr/lib/systemd/system/{{ tripleo_podman_socket_unit_name }}"" source: podman.socket.j2 - name: Enable podman socket unit ansible.builtin.service: name: ""{{ tripleo_podman_socket_unit_name }}"" state: started enabled: true - name: Enable podman service unit ansible.builtin.service: name: ""{{ tripleo_podman_service_unit_name }}"" state: started enabled: true - name: Reload systemctl ansible.builtin.systemd: daemon_reload: true ",,84,0
openstack%2Fnova~master~I75cb6d0fdf17c0fd9a7f8b5d0d3677dec9c4a7d7,openstack/nova,master,I75cb6d0fdf17c0fd9a7f8b5d0d3677dec9c4a7d7,DNM: Testing cinder devstack change,ABANDONED,2022-11-07 19:19:11.000000000,2022-11-07 21:18:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 19:19:11.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b05074946c237e500728b44ffb885aeb59496591', 'message': 'DNM: Testing cinder devstack change\n\nChange-Id: I75cb6d0fdf17c0fd9a7f8b5d0d3677dec9c4a7d7\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/814193\n'}]",1,863925,b05074946c237e500728b44ffb885aeb59496591,5,1,1,4393,,,0,"DNM: Testing cinder devstack change

Change-Id: I75cb6d0fdf17c0fd9a7f8b5d0d3677dec9c4a7d7
Depends-On: https://review.opendev.org/c/openstack/devstack/+/814193
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/863925/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,b05074946c237e500728b44ffb885aeb59496591,test-cinder-target-thing,"# unless required by applicable law or agreed to in writing, software","# Unless required by applicable law or agreed to in writing, software",1,1
openstack%2Fglance~master~Id75b1506ff8cfc873e2bf6cbf51b73e671cd58d4,openstack/glance,master,Id75b1506ff8cfc873e2bf6cbf51b73e671cd58d4,DNM: Test cinder target devstack change,ABANDONED,2022-11-07 19:20:02.000000000,2022-11-07 21:18:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 19:20:02.000000000', 'files': ['glance/api/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/495a6b73236e65c6db86576f50a0d89fc6755087', 'message': 'DNM: Test cinder target devstack change\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/814193\nChange-Id: Id75b1506ff8cfc873e2bf6cbf51b73e671cd58d4\n'}]",1,863926,495a6b73236e65c6db86576f50a0d89fc6755087,3,1,1,4393,,,0,"DNM: Test cinder target devstack change

Depends-On: https://review.opendev.org/c/openstack/devstack/+/814193
Change-Id: Id75b1506ff8cfc873e2bf6cbf51b73e671cd58d4
",git fetch https://review.opendev.org/openstack/glance refs/changes/26/863926/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/__init__.py'],1,495a6b73236e65c6db86576f50a0d89fc6755087,test-cinder-target-thing,"# unless required by applicable law or agreed to in writing, software","# Unless required by applicable law or agreed to in writing, software",1,1
openstack%2Fansible-collections-openstack~master~I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2,openstack/ansible-collections-openstack,master,I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2,"Refactored volume_backup{,_info} modules",MERGED,2022-11-03 09:27:36.000000000,2022-11-07 21:15:42.000000000,2022-11-07 21:15:42.000000000,"[{'_account_id': 22348}, {'_account_id': 32962}, {'_account_id': 34208}]","[{'number': 1, 'created': '2022-11-03 09:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2e6dbe6ef3b71fb41f420e2600e0ccc0a96f3141', 'message': 'Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 2, 'created': '2022-11-03 09:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b164c3c12550a56964883dc539e30d6665a12b92', 'message': 'Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 3, 'created': '2022-11-03 10:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c2bb0a521114eee5a9614c933b8b9737195ea10f', 'message': 'Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 4, 'created': '2022-11-03 14:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/1b84ed30c9d93a590cdf903af1f83cc35e53f23c', 'message': '[DNM] Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 5, 'created': '2022-11-03 20:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cb5a0d68ca2909b054d2c68154ae4e64eee26d7e', 'message': '[DNM] Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 6, 'created': '2022-11-04 10:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/923327e843ba6d7fa4e149be90205c1d3d407f07', 'message': 'Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 7, 'created': '2022-11-04 12:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f4b6d63bd80c1749039a02d161ba49cc69caa3d3', 'message': 'Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}, {'number': 8, 'created': '2022-11-04 19:06:57.000000000', 'files': ['ci/roles/volume/tasks/main.yml', 'plugins/modules/volume_backup.py', '.zuul.yaml', 'ci/run-collection.yml', 'plugins/modules/volume_backup_info.py', 'ci/roles/volume_backup/defaults/main.yml', 'ci/roles/volume_backup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/764a8bff64fca8353371c15c4c14dc9752829db2', 'message': 'Refactored volume_backup{,_info} modules\n\nChange-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2\n'}]",0,863486,764a8bff64fca8353371c15c4c14dc9752829db2,19,3,8,32962,,,0,"Refactored volume_backup{,_info} modules

Change-Id: I523fd25a11f8f39a346afc17ae1e3a4dfcb8bae2
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/86/863486/4 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/volume/tasks/main.yml', 'plugins/modules/volume_backup.py', '.zuul.yaml', 'ci/run-collection.yml', 'plugins/modules/volume_backup_info.py', 'ci/roles/volume_backup/defaults/main.yml', 'ci/roles/volume_backup/tasks/main.yml']",7,2e6dbe6ef3b71fb41f420e2600e0ccc0a96f3141,volume_backup,"--- - name: Get existing backups openstack.cloud.volume_backup_info: cloud: ""{{ cloud }}"" register: info - name: Assert volume_backup_info assert: that: - info.volume_backups|length == 0 - name: Get non-existing backup openstack.cloud.volume_backup_info: cloud: ""{{ cloud }}"" name: non-existing-backup register: info - name: Assert volume_backup_info assert: that: - info.volume_backups|length == 0 - name: Create volume openstack.cloud.volume: cloud: ""{{ cloud }}"" state: present size: 1 name: ansible_volume register: volume - name: Create volume backup openstack.cloud.volume_backup: cloud: ""{{ cloud }}"" state: present name: ansible_volume_backup volume: ansible_volume metadata: key1: value1 key2: value2 register: backup - name: Assert volume_backup assert: that: - backup.volume_backup.name == ""ansible_volume_backup"" - backup.volume_backup.volume_id == volume.volume.id - backup.volume_backup.metadata.keys()|sort == ['key1', 'key2'] - backup.volume_backup.metadata['key1'] == 'value1' - backup.volume_backup.metadata['key2'] == 'value2' - name: Assert return values of volume_backup module assert: that: # allow new fields to be introduced but prevent fields from being removed - expected_fields|difference(info.volume_backup.keys())|length == 0 - name: Get backup info openstack.cloud.volume_backup_info: cloud: ""{{ cloud }}"" name: ansible_volume_backup register: info - name: Assert volume_backup_info assert: that: - info.volume_backups|length == 1 - info.volume_backups[0].id == backup.backup.id - info.volume_backups[0].volume_id == volume.volume.id - name: Assert return values of volume_info module assert: that: # allow new fields to be introduced but prevent fields from being removed - expected_fields|difference(info.volumes[0].keys())|length == 0 - name: Delete volume backup openstack.cloud.volume_backup: cloud: ""{{ cloud }}"" name: ansible_volume_backup wait: false state: absent - name: Delete volume openstack.cloud.volume: cloud: ""{{ cloud }}"" state: absent name: ansible_volume ",,363,197
openstack%2Fhorizon~master~I7549373c9ebba0a618708924d4fce6c464639dec,openstack/horizon,master,I7549373c9ebba0a618708924d4fce6c464639dec,[CVE-2022-42969] Py is not used by pytest anymore,ABANDONED,2022-10-31 19:39:28.000000000,2022-11-07 20:23:24.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-10-31 19:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3bd51118e6a1e268cd5ea234861f0c81ad89c8e4', 'message': ""[CVE-2022-42969] pytest 7.2.0 doesn't use py\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nBut pytest_html explicitly uses py and we must specify it\nin test requirements in Horizon.\n\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n""}, {'number': 2, 'created': '2022-11-02 11:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/84963de8d1af6546b54387fc140f78422a3a52c2', 'message': ""[CVE-2022-42969] pytest 7.2.0 doesn't use py\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nBut pytest_html explicitly uses py and we must specify it\nin test requirements in Horizon.\n\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n""}, {'number': 3, 'created': '2022-11-02 11:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/649073bad5bd8042d832f40570f9ade407299457', 'message': ""[CVE-2022-42969] Don't use py.\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nhttps://review.opendev.org/c/openstack/requirements/+/863083\npytest_html uses py too. We figured out that pytest_html is not used,\nso we removed it.\n\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n""}, {'number': 4, 'created': '2022-11-07 11:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bbd53d119852416467329fbd3f6e15d8d2eac639', 'message': ""[CVE-2022-42969] Don't use py.\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nhttps://review.opendev.org/c/openstack/requirements/+/863083\npytest_html uses py too. We figured out that pytest_html is not used,\nso we removed it.\n\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n""}, {'number': 5, 'created': '2022-11-07 11:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4d003f8d92f63cc0fb2d0b367cd7056e96447b06', 'message': ""[CVE-2022-42969] Don't use py.\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nhttps://review.opendev.org/c/openstack/requirements/+/863083\npytest_html uses py too. We figured out that pytest_html is not used,\nso we removed it.\n\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n""}, {'number': 6, 'created': '2022-11-07 16:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/38bd81fb8e9d9f08b24b91d807e20ca52e78e287', 'message': ""[CVE-2022-42969] Don't use py.\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nhttps://review.opendev.org/c/openstack/requirements/+/863083\npytest_html uses py too. We figured out that pytest_html is not used,\nso we removed it.\n\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n""}, {'number': 7, 'created': '2022-11-07 16:17:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/eba977c1e66de195d4364366bbe46c55d7ba72f0', 'message': '[CVE-2022-42969] Py is not used by pytest anymore\n\nPackage Py has CVE and its maintainers advice do not use it.\nPy is mostly used in pytest.\nPytest 7.2.0 completely stops to use py.\nSo we bump pytest version in upper constraints in order\ndo not use py under the hood.\nhttps://review.opendev.org/c/openstack/requirements/+/863083\npytest_html uses py too. Now we cannot stop using of py.\npytest breaks the use of py if py is not installed before pytest.\nTherefore, we explicitly specify the py package before pytest.\n\nDepends-On: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\nStory: 2010389\nChange-Id: I7549373c9ebba0a618708924d4fce6c464639dec\n'}]",11,863101,eba977c1e66de195d4364366bbe46c55d7ba72f0,18,3,7,32927,,,0,"[CVE-2022-42969] Py is not used by pytest anymore

Package Py has CVE and its maintainers advice do not use it.
Py is mostly used in pytest.
Pytest 7.2.0 completely stops to use py.
So we bump pytest version in upper constraints in order
do not use py under the hood.
https://review.opendev.org/c/openstack/requirements/+/863083
pytest_html uses py too. Now we cannot stop using of py.
pytest breaks the use of py if py is not installed before pytest.
Therefore, we explicitly specify the py package before pytest.

Depends-On: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2
Story: 2010389
Change-Id: I7549373c9ebba0a618708924d4fce6c464639dec
",git fetch https://review.opendev.org/openstack/horizon refs/changes/01/863101/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,3bd51118e6a1e268cd5ea234861f0c81ad89c8e4,story/2010389,py>=1.11.0 # MIT,,1,0
openstack%2Frequirements~stable%2Fwallaby~Idf1607d358817ea8b198382a2762cc6d288801fa,openstack/requirements,stable/wallaby,Idf1607d358817ea8b198382a2762cc6d288801fa,update constraint for horizon to new release 19.4.0,MERGED,2022-11-04 09:20:49.000000000,2022-11-07 20:17:39.000000000,2022-11-07 20:17:39.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 09:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/eafb02f1bca8e4bdbc9c225d044da8af9016ab9b', 'message': 'update constraint for horizon to new release 19.4.0\n\nmeta: version: 19.4.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: manchandavishal <manchandavishal143@gmail.com>\nmeta: release:Commit: Vishal Manchanda <manchandavishal143@gmail.com>\nmeta: release:Change-Id: I1765bab313faf4593ffa142966adb94d09960303\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Idf1607d358817ea8b198382a2762cc6d288801fa\n'}, {'number': 2, 'created': '2022-11-04 14:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/761e5320fd585df129c6bc82c2967c3969002b49', 'message': 'update constraint for horizon to new release 19.4.0\n\nmeta: version: 19.4.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: manchandavishal <manchandavishal143@gmail.com>\nmeta: release:Commit: Vishal Manchanda <manchandavishal143@gmail.com>\nmeta: release:Change-Id: I1765bab313faf4593ffa142966adb94d09960303\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Idf1607d358817ea8b198382a2762cc6d288801fa\n'}, {'number': 3, 'created': '2022-11-05 18:02:45.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7218638384d1fdea75a5c635419d0243f6d5ab6b', 'message': 'update constraint for horizon to new release 19.4.0\n\nmeta: version: 19.4.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: manchandavishal <manchandavishal143@gmail.com>\nmeta: release:Commit: Vishal Manchanda <manchandavishal143@gmail.com>\nmeta: release:Change-Id: I1765bab313faf4593ffa142966adb94d09960303\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Idf1607d358817ea8b198382a2762cc6d288801fa\n'}]",0,863601,7218638384d1fdea75a5c635419d0243f6d5ab6b,15,3,3,11131,,,0,"update constraint for horizon to new release 19.4.0

meta: version: 19.4.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: manchandavishal <manchandavishal143@gmail.com>
meta: release:Commit: Vishal Manchanda <manchandavishal143@gmail.com>
meta: release:Change-Id: I1765bab313faf4593ffa142966adb94d09960303
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Idf1607d358817ea8b198382a2762cc6d288801fa
",git fetch https://review.opendev.org/openstack/requirements refs/changes/01/863601/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,eafb02f1bca8e4bdbc9c225d044da8af9016ab9b,new-release,horizon===19.4.0,horizon===19.3.0,1,1
openstack%2Frequirements~stable%2Fwallaby~Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1,openstack/requirements,stable/wallaby,Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1,Raise upper diskimage-builder===3.24.0,MERGED,2022-10-25 21:58:28.000000000,2022-11-07 20:17:36.000000000,2022-11-07 20:17:36.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-25 21:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d25185940345a0fbba97864eb4d25a8010b91536', 'message': 'Raise upper diskimage-builder===3.24.0\n\ndiskimage-builder is branchless and has minimal pip dependencies, so\nit is desirable to run the latest even on stable branches.\n\nThis sets the same version currently on master.\n\nChange-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1\n(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)\n(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)\n'}, {'number': 2, 'created': '2022-11-04 14:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d5230970389dc3783e402d96804780c25a899deb', 'message': 'Raise upper diskimage-builder===3.24.0\n\ndiskimage-builder is branchless and has minimal pip dependencies, so\nit is desirable to run the latest even on stable branches.\n\nThis sets the same version currently on master.\n\nChange-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1\n(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)\n(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)\n'}, {'number': 3, 'created': '2022-11-05 18:03:25.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0f9160ec72e85789681af9721aafac4dfbe3cbab', 'message': 'Raise upper diskimage-builder===3.24.0\n\ndiskimage-builder is branchless and has minimal pip dependencies, so\nit is desirable to run the latest even on stable branches.\n\nThis sets the same version currently on master.\n\nChange-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1\n(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)\n(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)\n'}]",1,862650,0f9160ec72e85789681af9721aafac4dfbe3cbab,15,3,3,4571,,,0,"Raise upper diskimage-builder===3.24.0

diskimage-builder is branchless and has minimal pip dependencies, so
it is desirable to run the latest even on stable branches.

This sets the same version currently on master.

Change-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1
(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)
(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/50/862650/3 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d25185940345a0fbba97864eb4d25a8010b91536,wallaby/dib-upper,diskimage-builder===3.24.0,diskimage-builder===3.20.3,1,1
openstack%2Frequirements~stable%2Fwallaby~I00a33212c6f507e2b9316d254b6c39a2454cd30b,openstack/requirements,stable/wallaby,I00a33212c6f507e2b9316d254b6c39a2454cd30b,update constraint for ovsdbapp to new release 1.9.4,MERGED,2022-11-02 15:56:13.000000000,2022-11-07 20:02:38.000000000,2022-11-07 20:02:38.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 15:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d39253c83c11162c22e6a808a326c22ccad17ff2', 'message': 'update constraint for ovsdbapp to new release 1.9.4\n\nmeta: version: 1.9.4\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I00a33212c6f507e2b9316d254b6c39a2454cd30b\n'}, {'number': 2, 'created': '2022-11-04 14:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1387e7dd64974bfa9d0be51c726d99e5b4fb3115', 'message': 'update constraint for ovsdbapp to new release 1.9.4\n\nmeta: version: 1.9.4\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I00a33212c6f507e2b9316d254b6c39a2454cd30b\n'}, {'number': 3, 'created': '2022-11-05 18:03:13.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3ad0203c6009111a046afef353ecec93be6c3b58', 'message': 'update constraint for ovsdbapp to new release 1.9.4\n\nmeta: version: 1.9.4\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I00a33212c6f507e2b9316d254b6c39a2454cd30b\n'}]",1,863329,3ad0203c6009111a046afef353ecec93be6c3b58,16,4,3,11131,,,0,"update constraint for ovsdbapp to new release 1.9.4

meta: version: 1.9.4
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
meta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
meta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327
meta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>
meta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>
meta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>
meta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I00a33212c6f507e2b9316d254b6c39a2454cd30b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/29/863329/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d39253c83c11162c22e6a808a326c22ccad17ff2,new-release,ovsdbapp===1.9.4,ovsdbapp===1.9.3,1,1
openstack%2Frequirements~stable%2Fwallaby~I481979a4fc135483b3400f323f3928d31beb5026,openstack/requirements,stable/wallaby,I481979a4fc135483b3400f323f3928d31beb5026,update constraint for neutron to new release 18.6.0,MERGED,2022-11-02 15:56:44.000000000,2022-11-07 20:02:35.000000000,2022-11-07 20:02:35.000000000,"[{'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-02 15:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/43591f880018c61e8f605f59cd1164d026a73d2b', 'message': 'update constraint for neutron to new release 18.6.0\n\nmeta: version: 18.6.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I481979a4fc135483b3400f323f3928d31beb5026\n'}, {'number': 2, 'created': '2022-11-04 14:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/57ac452c45feecf29c02a5c63273402cac66f242', 'message': 'update constraint for neutron to new release 18.6.0\n\nmeta: version: 18.6.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I481979a4fc135483b3400f323f3928d31beb5026\n'}, {'number': 3, 'created': '2022-11-05 18:03:07.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9627ae39ef6887faa739f552934529a594cb2b20', 'message': 'update constraint for neutron to new release 18.6.0\n\nmeta: version: 18.6.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\nmeta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>\nmeta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I481979a4fc135483b3400f323f3928d31beb5026\n'}]",2,863370,9627ae39ef6887faa739f552934529a594cb2b20,19,4,3,11131,,,0,"update constraint for neutron to new release 18.6.0

meta: version: 18.6.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
meta: release:Commit: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
meta: release:Change-Id: I3fa42a3e32b431c5fee0fae381d914af121c8327
meta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+1: Luis Tomas Bolivar <ltomasbo@redhat.com>
meta: release:Code-Review+1: Terry Wilson <twilson@redhat.com>
meta: release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>
meta: release:Code-Review+1: Dr. Jens Harbott <frickler@offenerstapel.de>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I481979a4fc135483b3400f323f3928d31beb5026
",git fetch https://review.opendev.org/openstack/requirements refs/changes/70/863370/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,43591f880018c61e8f605f59cd1164d026a73d2b,new-release,neutron===18.6.0,neutron===18.5.0,1,1
openstack%2Fmanila~stable%2Ftrain~I0e75dc2285d26c45f2811d7050976b7474863a77,openstack/manila,stable/train,I0e75dc2285d26c45f2811d7050976b7474863a77,Fix stable/train CI jobs,MERGED,2022-06-24 17:41:42.000000000,2022-11-07 19:38:33.000000000,2022-11-07 19:36:19.000000000,"[{'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30002}]","[{'number': 1, 'created': '2022-06-24 17:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/573e7cf5173b932120de65f43d7f57cca6241d97', 'message': 'Define queues at project level\n\nDefining queues at project.pipeline level was deprecated in release\n4.1.0 of Zuul [1] and support for it will (probably) be dropped in\nrelease 7.0.0. [2][3]\n\nThis change is a stable/train only patch since newer branches use\nlayout.yaml inside zuul.d dir to declare project check/gate jobs.\nSee topic [4] for more info related to this change.\n\n[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes\n[2] https://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n[3] https://lists.zuul-ci.org/pipermail/zuul-discuss/2022-May/001801.html\n[4] https://review.opendev.org/q/topic:fix-queue-config\n\nCo-Authored-By: Eduardo Santos <eduardo.experimental@gmail.com>\nChange-Id: I0e75dc2285d26c45f2811d7050976b7474863a77\nSigned-off-by: Douglas Viroel <dviroel@redhat.com>\n'}, {'number': 2, 'created': '2022-11-03 18:20:07.000000000', 'files': ['contrib/ci/post_test_hook.sh', '.zuul.yaml', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/manila/commit/8a6487ffd6427b172acd29675a10f05014700245', 'message': ""Fix stable/train CI jobs\n\nThis is a combination of two cherry-picks\nto ensure CI runs and does so with constraints\nthat are unfortunately required on this\nbranch.\n\n1) Define queues at project level\n\nDefining queues at project.pipeline level was deprecated in release\n4.1.0 of Zuul [1] and support for it will (probably) be dropped in\nrelease 7.0.0. [2][3]\n\nThis change is a stable/train only patch since newer branches use\nlayout.yaml inside zuul.d dir to declare project check/gate jobs.\nSee topic [4] for more info related to this change.\n\n[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes\n[2] https://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html\n[3] https://lists.zuul-ci.org/pipermail/zuul-discuss/2022-May/001801.html\n[4] https://review.opendev.org/q/topic:fix-queue-config\n\n2) Pin tempest plugin and scenario test image\n\nOriginal Change-Id: Ic7213030dd433b765d5a815d8a31aee01b09da1c\n\nTempest is pinned to a 26.1.0 on this stable\nbranch [5]. manila-tempest-plugin in Zed requires a newer\ntempest release [6] than this one. So, pin\nmanila-tempest-plugin as well to a version that can still\nwork with the pinned version of tempest.\n\nAlso, manila's test image (built from manila-image-elements)\nis based off of Ubuntu 22.04 (Jammy Jellyfish) in the Zed\nrelease; we don't need that image to be used to test this\nstable branch and we could use an older version (based on\nUbuntu 20.04 - Focal Fossa) that requires less memory/CPU [7]\n\n[5] https://review.opendev.org/c/openstack/devstack/+/838051\n[6] https://review.opendev.org/c/openstack/manila-tempest-plugin/+/849995\n[7] https://review.opendev.org/c/openstack/manila-tempest-plugin/+/846061\n\nCo-Authored-By: Eduardo Santos <eduardo.experimental@gmail.com>\nChange-Id: I0e75dc2285d26c45f2811d7050976b7474863a77\nSigned-off-by: Douglas Viroel <dviroel@redhat.com>\n""}]",3,847595,8a6487ffd6427b172acd29675a10f05014700245,18,3,2,30002,,,0,"Fix stable/train CI jobs

This is a combination of two cherry-picks
to ensure CI runs and does so with constraints
that are unfortunately required on this
branch.

1) Define queues at project level

Defining queues at project.pipeline level was deprecated in release
4.1.0 of Zuul [1] and support for it will (probably) be dropped in
release 7.0.0. [2][3]

This change is a stable/train only patch since newer branches use
layout.yaml inside zuul.d dir to declare project check/gate jobs.
See topic [4] for more info related to this change.

[1] https://zuul-ci.org/docs/zuul/latest/releasenotes.html#relnotes-4-1-0-deprecation-notes
[2] https://lists.openstack.org/pipermail/openstack-discuss/2022-May/028603.html
[3] https://lists.zuul-ci.org/pipermail/zuul-discuss/2022-May/001801.html
[4] https://review.opendev.org/q/topic:fix-queue-config

2) Pin tempest plugin and scenario test image

Original Change-Id: Ic7213030dd433b765d5a815d8a31aee01b09da1c

Tempest is pinned to a 26.1.0 on this stable
branch [5]. manila-tempest-plugin in Zed requires a newer
tempest release [6] than this one. So, pin
manila-tempest-plugin as well to a version that can still
work with the pinned version of tempest.

Also, manila's test image (built from manila-image-elements)
is based off of Ubuntu 22.04 (Jammy Jellyfish) in the Zed
release; we don't need that image to be used to test this
stable branch and we could use an older version (based on
Ubuntu 20.04 - Focal Fossa) that requires less memory/CPU [7]

[5] https://review.opendev.org/c/openstack/devstack/+/838051
[6] https://review.opendev.org/c/openstack/manila-tempest-plugin/+/849995
[7] https://review.opendev.org/c/openstack/manila-tempest-plugin/+/846061

Co-Authored-By: Eduardo Santos <eduardo.experimental@gmail.com>
Change-Id: I0e75dc2285d26c45f2811d7050976b7474863a77
Signed-off-by: Douglas Viroel <dviroel@redhat.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/95/847595/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,573e7cf5173b932120de65f43d7f57cca6241d97,fix-ci, queue: manila, queue: manila,1,1
openstack%2Fkayobe~master~Icc13737b5e04be84a01e0be7c90a5e6b1a0cefa8,openstack/kayobe,master,Icc13737b5e04be84a01e0be7c90a5e6b1a0cefa8,Adds missing variables to ssh.yml,MERGED,2022-09-08 10:59:41.000000000,2022-11-07 19:22:59.000000000,2022-11-07 19:21:31.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25600}]","[{'number': 1, 'created': '2022-09-08 10:59:41.000000000', 'files': ['etc/kayobe/ssh.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/a7affb3a5eef1536d6df7587abc09e68064b1845', 'message': 'Adds missing variables to ssh.yml\n\nTrivialFix\n\nChange-Id: Icc13737b5e04be84a01e0be7c90a5e6b1a0cefa8\n'}]",0,856470,a7affb3a5eef1536d6df7587abc09e68064b1845,9,4,1,28048,,,0,"Adds missing variables to ssh.yml

TrivialFix

Change-Id: Icc13737b5e04be84a01e0be7c90a5e6b1a0cefa8
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/70/856470/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/ssh.yml'],1,a7affb3a5eef1536d6df7587abc09e68064b1845,,"# Type of SSH key. Default is ""rsa"". #ssh_key_type: ",,3,0
openstack%2Fkayobe~master~I845df2682ee32d0622d49cbcc5fa82a4e2873435,openstack/kayobe,master,I845df2682ee32d0622d49cbcc5fa82a4e2873435,Adds missing variables to seed-vm.yml,MERGED,2022-09-08 10:57:17.000000000,2022-11-07 19:17:22.000000000,2022-11-07 19:15:36.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25600}]","[{'number': 1, 'created': '2022-09-08 10:57:17.000000000', 'files': ['etc/kayobe/seed-vm.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/5b578b9793fe69e6ea03d2650ebc574603e79bae', 'message': 'Adds missing variables to seed-vm.yml\n\nTrivialFix\n\nChange-Id: I845df2682ee32d0622d49cbcc5fa82a4e2873435\n'}]",0,856469,5b578b9793fe69e6ea03d2650ebc574603e79bae,9,4,1,28048,,,0,"Adds missing variables to seed-vm.yml

TrivialFix

Change-Id: I845df2682ee32d0622d49cbcc5fa82a4e2873435
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/69/856469/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/seed-vm.yml'],1,5b578b9793fe69e6ea03d2650ebc574603e79bae,,# Root volume. #seed_vm_root_volume: # Data volume. #seed_vm_data_volume: ,,6,0
openstack%2Fkayobe~master~I8129b2a6793ea36bb296ef8337a5461f73d6e557,openstack/kayobe,master,I8129b2a6793ea36bb296ef8337a5461f73d6e557,Adds missing sasl options to compute.yml,MERGED,2022-09-08 09:51:52.000000000,2022-11-07 19:16:37.000000000,2022-11-07 19:15:30.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25600}]","[{'number': 1, 'created': '2022-09-08 09:51:52.000000000', 'files': ['etc/kayobe/compute.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/a4e9d5124ce3179451e977a529e6f6744f20dae5', 'message': 'Adds missing sasl options to compute.yml\n\nTrivialFix\n\nChange-Id: I8129b2a6793ea36bb296ef8337a5461f73d6e557\n'}]",0,856454,a4e9d5124ce3179451e977a529e6f6744f20dae5,9,4,1,28048,,,0,"Adds missing sasl options to compute.yml

TrivialFix

Change-Id: I8129b2a6793ea36bb296ef8337a5461f73d6e557
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/54/856454/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/compute.yml'],1,a4e9d5124ce3179451e977a529e6f6744f20dae5,,# Whether to enable libvirt SASL authentication. Default is true. #compute_libvirt_enable_sasl: true # libvirt SASL password. Default is unset. #compute_libvirt_sasl_password: ,,6,0
openstack%2Fkayobe~master~Id18613fdf12b27374846fdbbac451c99deff2233,openstack/kayobe,master,Id18613fdf12b27374846fdbbac451c99deff2233,Add missing variables from neutron.yml,MERGED,2022-09-08 10:49:56.000000000,2022-11-07 19:15:33.000000000,2022-11-07 19:15:33.000000000,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25600}]","[{'number': 1, 'created': '2022-09-08 10:49:56.000000000', 'files': ['etc/kayobe/neutron.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/7c9e738046f6a8dd6e77e7e75c84869debeb7443', 'message': 'Add missing variables from neutron.yml\n\nChange-Id: Id18613fdf12b27374846fdbbac451c99deff2233\n'}]",0,856464,7c9e738046f6a8dd6e77e7e75c84869debeb7443,8,4,1,28048,,,0,"Add missing variables from neutron.yml

Change-Id: Id18613fdf12b27374846fdbbac451c99deff2233
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/64/856464/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/neutron.yml'],1,7c9e738046f6a8dd6e77e7e75c84869debeb7443,,# List of Ansible hosts whose switch interfaces are to be configured as tagged # members of all networks managed by the genericswitch ML2 mechanism driver. # These hosts will be matched against the description fields in the # switch_interface_config variable for each switch to determine which # interfaces should be configured. #kolla_neutron_ml2_generic_switch_trunk_port_hosts: ,,7,0
openstack%2Fneutron~stable%2Ftrain~I7cec8b53e72e7abf34012906e6adfecf079525af,openstack/neutron,stable/train,I7cec8b53e72e7abf34012906e6adfecf079525af,Check subnet overlapping after add router interface,ABANDONED,2022-11-07 10:19:43.000000000,2022-11-07 18:39:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 10:19:43.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/90018ef2b78035ce2fdd4cd12794011b0f636be3', 'message': 'Check subnet overlapping after add router interface\n\nWhen simultaneous attempts are made to add an interface\nto the same router including overlapping networks in cidrs,\nboth attempts are successful. There is a check to avoid this\noverlap but is performed when creating the network interface\nand it is done over the ports already attached to the router,\nso at this moment the check is not able to detect the\noverlapping. Furthermore, the create_port operation over the\nML2 plugin  must be executed in isolated transactions, so\ntrying to control the execution context or adding additional\nsteps to the transaction is not feasible.\n\nThis patch checks once the RouterPort is created on the\nneutron database if there is more than one overlapping port,\ntriggering in that case the exception that will remove the\nthe culprit of overlapping.\n\nConflicts:\n      neutron/db/l3_db.py\n(manually cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n\nCloses-Bug: #1987666\nChange-Id: I7cec8b53e72e7abf34012906e6adfecf079525af\n(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n'}]",2,863862,90018ef2b78035ce2fdd4cd12794011b0f636be3,3,1,1,34451,,,0,"Check subnet overlapping after add router interface

When simultaneous attempts are made to add an interface
to the same router including overlapping networks in cidrs,
both attempts are successful. There is a check to avoid this
overlap but is performed when creating the network interface
and it is done over the ports already attached to the router,
so at this moment the check is not able to detect the
overlapping. Furthermore, the create_port operation over the
ML2 plugin  must be executed in isolated transactions, so
trying to control the execution context or adding additional
steps to the transaction is not feasible.

This patch checks once the RouterPort is created on the
neutron database if there is more than one overlapping port,
triggering in that case the exception that will remove the
the culprit of overlapping.

Conflicts:
      neutron/db/l3_db.py
(manually cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)

Closes-Bug: #1987666
Change-Id: I7cec8b53e72e7abf34012906e6adfecf079525af
(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/863862/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py']",3,90018ef2b78035ce2fdd4cd12794011b0f636be3,,"from neutron.db import models_v2 def test__raise_on_subnets_overlap_does_not_raise(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/24'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.2.0.0/24'}] self.db._raise_on_subnets_overlap(subnets[0], subnets[1]) def test__raise_on_subnets_overlap_raises(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/20'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.1.10.0/24'}] self.assertRaises( n_exc.BadRequest, self.db._raise_on_subnets_overlap, subnets[0], subnets[1]) def test__validate_one_router_ipv6_port_per_network(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network2', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_mix_ipv4_ipv6(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '10.1.10.0/24').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_failed(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.assertRaises( n_exc.BadRequest, self.db._validate_one_router_ipv6_port_per_network, router, new_port) @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_port_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') ipa = str(netaddr.IPNetwork(subnet['subnet']['cidr']).ip + 10) fixed_ips = [{'subnet_id': subnet['subnet']['id'], 'ip_address': ipa}] port = self.create_port( network2['network']['id'], {'fixed_ips': fixed_ips}) self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': port['port']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': self.ports[0]['port']['id']}) mock_raise_on_subnets_overlap.assert_called_once() @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_subnet_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': subnet['subnet']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': self.subnets[0]['subnet']['id']}) mock_raise_on_subnets_overlap.assert_called_once() ",,247,30
openstack%2Fneutron~stable%2Fussuri~I7cec8b53e72e7abf34012906e6adfecf079525af,openstack/neutron,stable/ussuri,I7cec8b53e72e7abf34012906e6adfecf079525af,Check subnet overlapping after add router interface,ABANDONED,2022-11-07 10:20:53.000000000,2022-11-07 18:39:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 10:20:53.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d11c3cf76944dbc5fc065633402b04659484b15', 'message': 'Check subnet overlapping after add router interface\n\nWhen simultaneous attempts are made to add an interface\nto the same router including overlapping networks in cidrs,\nboth attempts are successful. There is a check to avoid this\noverlap but is performed when creating the network interface\nand it is done over the ports already attached to the router,\nso at this moment the check is not able to detect the\noverlapping. Furthermore, the create_port operation over the\nML2 plugin  must be executed in isolated transactions, so\ntrying to control the execution context or adding additional\nsteps to the transaction is not feasible.\n\nThis patch checks once the RouterPort is created on the\nneutron database if there is more than one overlapping port,\ntriggering in that case the exception that will remove the\nthe culprit of overlapping.\n\nConflicts:\n      neutron/db/l3_db.py\n(manually cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n\nCloses-Bug: #1987666\nChange-Id: I7cec8b53e72e7abf34012906e6adfecf079525af\n(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n'}]",0,863863,2d11c3cf76944dbc5fc065633402b04659484b15,3,1,1,34451,,,0,"Check subnet overlapping after add router interface

When simultaneous attempts are made to add an interface
to the same router including overlapping networks in cidrs,
both attempts are successful. There is a check to avoid this
overlap but is performed when creating the network interface
and it is done over the ports already attached to the router,
so at this moment the check is not able to detect the
overlapping. Furthermore, the create_port operation over the
ML2 plugin  must be executed in isolated transactions, so
trying to control the execution context or adding additional
steps to the transaction is not feasible.

This patch checks once the RouterPort is created on the
neutron database if there is more than one overlapping port,
triggering in that case the exception that will remove the
the culprit of overlapping.

Conflicts:
      neutron/db/l3_db.py
(manually cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)

Closes-Bug: #1987666
Change-Id: I7cec8b53e72e7abf34012906e6adfecf079525af
(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/863863/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py']",3,2d11c3cf76944dbc5fc065633402b04659484b15,,"from neutron.db import models_v2 def test__raise_on_subnets_overlap_does_not_raise(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/24'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.2.0.0/24'}] self.db._raise_on_subnets_overlap(subnets[0], subnets[1]) def test__raise_on_subnets_overlap_raises(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/20'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.1.10.0/24'}] self.assertRaises( n_exc.BadRequest, self.db._raise_on_subnets_overlap, subnets[0], subnets[1]) def test__validate_one_router_ipv6_port_per_network(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network2', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_mix_ipv4_ipv6(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '10.1.10.0/24').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_failed(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.assertRaises( n_exc.BadRequest, self.db._validate_one_router_ipv6_port_per_network, router, new_port) @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_port_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') ipa = str(netaddr.IPNetwork(subnet['subnet']['cidr']).ip + 10) fixed_ips = [{'subnet_id': subnet['subnet']['id'], 'ip_address': ipa}] port = self.create_port( network2['network']['id'], {'fixed_ips': fixed_ips}) self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': port['port']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': self.ports[0]['port']['id']}) mock_raise_on_subnets_overlap.assert_called_once() @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_subnet_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': subnet['subnet']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': self.subnets[0]['subnet']['id']}) mock_raise_on_subnets_overlap.assert_called_once() ",,247,30
openstack%2Fneutron~stable%2Fvictoria~I7cec8b53e72e7abf34012906e6adfecf079525af,openstack/neutron,stable/victoria,I7cec8b53e72e7abf34012906e6adfecf079525af,Check subnet overlapping after add router interface,ABANDONED,2022-11-07 10:15:40.000000000,2022-11-07 18:39:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-07 10:15:40.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5f6479633214ed8759061f5df582d9c163acbaf', 'message': 'Check subnet overlapping after add router interface\n\nWhen simultaneous attempts are made to add an interface\nto the same router including overlapping networks in cidrs,\nboth attempts are successful. There is a check to avoid this\noverlap but is performed when creating the network interface\nand it is done over the ports already attached to the router,\nso at this moment the check is not able to detect the\noverlapping. Furthermore, the create_port operation over the\nML2 plugin  must be executed in isolated transactions, so\ntrying to control the execution context or adding additional\nsteps to the transaction is not feasible.\n\nThis patch checks once the RouterPort is created on the\nneutron database if there is more than one overlapping port,\ntriggering in that case the exception that will remove the\nthe culprit of overlapping.\n\nConflicts:\n      neutron/db/l3_db.py\n(manually cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n\nCloses-Bug: #1987666\nChange-Id: I7cec8b53e72e7abf34012906e6adfecf079525af\n(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)\n'}]",0,863861,c5f6479633214ed8759061f5df582d9c163acbaf,3,1,1,34451,,,0,"Check subnet overlapping after add router interface

When simultaneous attempts are made to add an interface
to the same router including overlapping networks in cidrs,
both attempts are successful. There is a check to avoid this
overlap but is performed when creating the network interface
and it is done over the ports already attached to the router,
so at this moment the check is not able to detect the
overlapping. Furthermore, the create_port operation over the
ML2 plugin  must be executed in isolated transactions, so
trying to control the execution context or adding additional
steps to the transaction is not feasible.

This patch checks once the RouterPort is created on the
neutron database if there is more than one overlapping port,
triggering in that case the exception that will remove the
the culprit of overlapping.

Conflicts:
      neutron/db/l3_db.py
(manually cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)

Closes-Bug: #1987666
Change-Id: I7cec8b53e72e7abf34012906e6adfecf079525af
(cherry picked from commit 1abb77d7a63cde2aa9640351f663870c14430919)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/863861/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/fullstack/test_l3_agent.py', 'neutron/tests/unit/db/test_l3_db.py']",3,c5f6479633214ed8759061f5df582d9c163acbaf,,"from neutron.db import models_v2 def test__raise_on_subnets_overlap_does_not_raise(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/24'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.2.0.0/24'}] self.db._raise_on_subnets_overlap(subnets[0], subnets[1]) def test__raise_on_subnets_overlap_raises(self): subnets = [ {'id': uuidutils.generate_uuid(), 'cidr': '10.1.0.0/20'}, {'id': uuidutils.generate_uuid(), 'cidr': '10.1.10.0/24'}] self.assertRaises( n_exc.BadRequest, self.db._raise_on_subnets_overlap, subnets[0], subnets[1]) def test__validate_one_router_ipv6_port_per_network(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network2', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_mix_ipv4_ipv6(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '10.1.10.0/24').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.db._validate_one_router_ipv6_port_per_network( router, new_port) def test__validate_one_router_ipv6_port_per_network_failed(self): port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 1), subnet_id='foo_subnet')]) rports = [l3_models.RouterPort(router_id='foo_router', port=port)] router = l3_models.Router( id='foo_router', attached_ports=rports, route_list=[], gw_port_id=None) new_port = models_v2.Port( id=uuidutils.generate_uuid(), network_id='foo_network', fixed_ips=[models_v2.IPAllocation( ip_address=str(netaddr.IPNetwork( '2001:db8::/32').ip + 2), subnet_id='foo_subnet')]) self.assertRaises( n_exc.BadRequest, self.db._validate_one_router_ipv6_port_per_network, router, new_port) @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_port_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') ipa = str(netaddr.IPNetwork(subnet['subnet']['cidr']).ip + 10) fixed_ips = [{'subnet_id': subnet['subnet']['id'], 'ip_address': ipa}] port = self.create_port( network2['network']['id'], {'fixed_ips': fixed_ips}) self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': port['port']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': self.ports[0]['port']['id']}) mock_raise_on_subnets_overlap.assert_called_once() @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_raise_on_subnets_overlap') def test_add_router_interface_by_subnet_overlap_detected( self, mock_raise_on_subnets_overlap, mock_check_dup): # NOTE(froyo): On a normal behaviour this overlapping would be detected # by _check_for_dup_router_subnets, in order to evalue the code # implemented to cover the race condition when two ports are added # simultaneously using colliding cidrs we need to ""fake"" this method # to overpass it and check we achieve the code part that cover the case mock_check_dup.return_value = True network2 = self.create_network('network2') subnet = self.create_subnet(network2, '1.1.1.1', '1.1.1.0/24') self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': subnet['subnet']['id']}) mock_raise_on_subnets_overlap.assert_not_called() self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'subnet_id': self.subnets[0]['subnet']['id']}) mock_raise_on_subnets_overlap.assert_called_once() ",,247,30
openstack%2Faodh~stable%2Fxena~I4f631d224404460138f4050b1b981d577b592544,openstack/aodh,stable/xena,I4f631d224404460138f4050b1b981d577b592544,gnocchi: Use Dynamic Aggregates API,MERGED,2022-04-08 03:41:20.000000000,2022-11-07 18:31:14.000000000,2022-11-07 18:30:11.000000000,"[{'_account_id': 4264}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-04-08 03:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/9d95ddec6cbe680c79f19d1c013d5db360e4303e', 'message': 'gnocchi: Use Dynamic Aggregates API\n\nSwitch to using the Dynamic Aggregates API as the Metric Aggregation\nAPI is deprecated.\n\nWhen using the Dynamic Aggregates API, any aggregation using rates\ncan use the underlying base measures for the aggregation rather than\nthe rate, for example:\n\n    (aggregation rate:mean (metric cpu mean))\n\nThe tuple of data for each record returned via this API is encapsulated\nwith information about the aggregation used so adapt the sanitization\nfunction to deal with this and the formatting of the metrics measures\nAPI as well.\n\nChange-Id: I4f631d224404460138f4050b1b981d577b592544\nCloses-Bug: 1946793\n(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)\n'}, {'number': 2, 'created': '2022-10-31 06:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/508ca6001fd34821ca4dce7b6da4cf45fcd4ca26', 'message': 'gnocchi: Use Dynamic Aggregates API\n\nSwitch to using the Dynamic Aggregates API as the Metric Aggregation\nAPI is deprecated.\n\nWhen using the Dynamic Aggregates API, any aggregation using rates\ncan use the underlying base measures for the aggregation rather than\nthe rate, for example:\n\n    (aggregation rate:mean (metric cpu mean))\n\nThe tuple of data for each record returned via this API is encapsulated\nwith information about the aggregation used so adapt the sanitization\nfunction to deal with this and the formatting of the metrics measures\nAPI as well.\n\nChange-Id: I4f631d224404460138f4050b1b981d577b592544\nCloses-Bug: 1946793\n(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)\n'}, {'number': 3, 'created': '2022-11-07 15:38:36.000000000', 'files': ['aodh/tests/unit/evaluator/test_composite.py', 'aodh/tests/unit/evaluator/test_gnocchi.py', 'aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/evaluator/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/e6d55b1ea9ee852cc56002c865c9443b526f2f58', 'message': 'gnocchi: Use Dynamic Aggregates API\n\nSwitch to using the Dynamic Aggregates API as the Metric Aggregation\nAPI is deprecated.\n\nWhen using the Dynamic Aggregates API, any aggregation using rates\ncan use the underlying base measures for the aggregation rather than\nthe rate, for example:\n\n    (aggregation rate:mean (metric cpu mean))\n\nThe tuple of data for each record returned via this API is encapsulated\nwith information about the aggregation used so adapt the sanitization\nfunction to deal with this and the formatting of the metrics measures\nAPI as well.\n\nChange-Id: I4f631d224404460138f4050b1b981d577b592544\nCloses-Bug: 1946793\nDepends-On: https://review.opendev.org/863284\n(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)\n'}]",25,837053,e6d55b1ea9ee852cc56002c865c9443b526f2f58,44,3,3,10366,,,0,"gnocchi: Use Dynamic Aggregates API

Switch to using the Dynamic Aggregates API as the Metric Aggregation
API is deprecated.

When using the Dynamic Aggregates API, any aggregation using rates
can use the underlying base measures for the aggregation rather than
the rate, for example:

    (aggregation rate:mean (metric cpu mean))

The tuple of data for each record returned via this API is encapsulated
with information about the aggregation used so adapt the sanitization
function to deal with this and the formatting of the metrics measures
API as well.

Change-Id: I4f631d224404460138f4050b1b981d577b592544
Closes-Bug: 1946793
Depends-On: https://review.opendev.org/863284
(cherry picked from commit 74eadfbd58359b7ebe9e1e40ae6b6ff245146bb8)
",git fetch https://review.opendev.org/openstack/aodh refs/changes/53/837053/2 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/tests/unit/evaluator/test_composite.py', 'aodh/tests/unit/evaluator/test_gnocchi.py', 'aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/evaluator/gnocchi.py']",5,9d95ddec6cbe680c79f19d1c013d5db360e4303e,bug/1946793-stable/xena," # NOTE(jamespage) # Dynamic Aggregates are returned in a dict struct so # check for this first. if isinstance(statistics, dict): # Pop array of measures from aggregated subdict statistics = statistics['measures']['aggregated'] _operations = [ 'aggregate', rule['aggregation_method'] ] for metric in rule['metrics']: _operations.append( [ 'metric', metric, rule['aggregation_method'].lstrip('rate:') ] ) return self._gnocchi_client.aggregates.fetch( operations=_operations, try: # FIXME(sileht): In case of a heat autoscaling stack decide to # delete an instance, the gnocchi metrics associated to this # instance will be no more updated and when the alarm will ask # for the aggregation, gnocchi will raise a 'No overlap' # exception. # So temporary set 'needed_overlap' to 0 to disable the # gnocchi checks about missing points. For more detail see: # https://bugs.launchpad.net/gnocchi/+bug/1479429 return self._gnocchi_client.aggregates.fetch( operations=[ 'aggregate', rule['aggregation_method'], [ 'metric', rule['metric'], rule['aggregation_method'].lstrip('rate:') ] ], search=json.loads(rule['query']), needed_overlap=0)"," return self._gnocchi_client.metric.aggregation( metrics=rule['metrics'], aggregation=rule['aggregation_method'], # FIXME(sileht): In case of a heat autoscaling stack decide to # delete an instance, the gnocchi metrics associated to this # instance will be no more updated and when the alarm will ask # for the aggregation, gnocchi will raise a 'No overlap' # exception. # So temporary set 'needed_overlap' to 0 to disable the # gnocchi checks about missing points. For more detail see: # https://bugs.launchpad.net/gnocchi/+bug/1479429 try: return self._gnocchi_client.metric.aggregation( metrics=rule['metric'], query=json.loads(rule['query']), aggregation=rule['aggregation_method'], needed_overlap=0, )",228,121
openstack%2Fbifrost~master~I9938e45fe39841f109ab4b4d102bf802d9b938ab,openstack/bifrost,master,I9938e45fe39841f109ab4b4d102bf802d9b938ab,Adapt role bifrost-cloud-config to Ansible OpenStack Col. >=2.0.0,MERGED,2022-11-07 09:11:39.000000000,2022-11-07 18:20:13.000000000,2022-11-07 18:19:01.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 09:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/a32ac20e7929fffed0b9637e290b525c25481b21', 'message': 'Adapt role bifrost-cloud-config to Ansible OpenStack Col. >=2.0.0\n\nChange-Id: I9938e45fe39841f109ab4b4d102bf802d9b938ab\n'}, {'number': 2, 'created': '2022-11-07 12:41:27.000000000', 'files': ['playbooks/roles/bifrost-cloud-config/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/540749ef93d9a29fa354bbb5474302a43ee2050c', 'message': 'Adapt role bifrost-cloud-config to Ansible OpenStack Col. >=2.0.0\n\nChange-Id: I9938e45fe39841f109ab4b4d102bf802d9b938ab\n'}]",1,863816,540749ef93d9a29fa354bbb5474302a43ee2050c,11,3,2,32962,,,0,"Adapt role bifrost-cloud-config to Ansible OpenStack Col. >=2.0.0

Change-Id: I9938e45fe39841f109ab4b4d102bf802d9b938ab
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/16/863816/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-cloud-config/tasks/main.yml'],1,a32ac20e7929fffed0b9637e290b525c25481b21,openstack-cloud-config," register: config - name: ""Set openstack_cloud if possible on Ansible OpenStack collection <2.0.0"" when: config.ansible_facts.openstack.clouds | default([]) | length > 0 openstack_cloud: ""{{ config.ansible_facts.openstack.clouds[0] }}"" no_log: yes - name: ""Set openstack_cloud if possible on Ansible OpenStack collection >=2.0.0"" when: clouds in config set_fact: # TODO(dtantsur): support looking up by cloud_name openstack_cloud: ""{{ config.clouds[0].config }}"""," - name: ""Set openstack_cloud if possible"" openstack_cloud: ""{{ openstack.clouds[0] }}"" when: - openstack is defined - openstack.clouds | length > 0",11,5
openstack%2Fdevstack-gate~master~Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3,openstack/devstack-gate,master,Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3,Support an IPv6 underlay network,ABANDONED,2016-07-15 19:07:28.000000000,2022-11-07 18:19:25.000000000,,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 4146}, {'_account_id': 10459}, {'_account_id': 17120}, {'_account_id': 22348}]","[{'number': 1, 'created': '2016-07-15 19:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/99aec71a5f314cb34578003702562acde72ebd33', 'message': '[WIP] Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 2, 'created': '2016-10-03 20:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c68b9bb6b5742c9891a7aa8e4b55d5a4d0167cdb', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 3, 'created': '2016-10-03 22:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/8c5e4c51d1b7d61f88463e4692a2e0ba0c9b15d7', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 4, 'created': '2016-10-03 23:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/357674032d246c6d27ab1d1ead811496bcb21697', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 5, 'created': '2016-10-04 01:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c35db565c23f567af4d334fd726cfeaf8c5d8a69', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 6, 'created': '2016-10-04 02:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/602b3e20498ed1af274eb9e95db13804eed47723', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 7, 'created': '2016-10-04 03:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/4f4709da1d2158094667f41dfc3fb309205074b6', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 8, 'created': '2017-02-07 02:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/2aa10daa61b993474d458718d767079392bc8c09', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 9, 'created': '2017-02-15 02:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/359afed219448ad2c1bec0802fe8adbd3cb22118', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 10, 'created': '2017-03-03 18:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/56331cb39b7196b2fa1832771f0cb961995a1951', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 11, 'created': '2017-03-03 21:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ecda37b81bb81cc54c19d0ba964fa5d10bba19a5', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 12, 'created': '2017-03-03 22:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f7ccb5d2052429b8b67d228635ac8cda4353ed8d', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 13, 'created': '2017-06-16 14:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e7feef94b4a181ee1fc6e7841ff6f6d44f7f7318', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the MTU accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 14, 'created': '2017-10-02 20:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/1c4d01212a756c50ed1a5aa450989d7199bd3310', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 15, 'created': '2018-06-28 17:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e6e2ed3ba7cd66415896016789e736d87e5f466e', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 16, 'created': '2018-06-28 17:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/e8822e39b960cd945be7af20aa4932f93f0d2a03', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 17, 'created': '2019-03-15 17:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/52d7740d155b3c1077c240e67d324093a0119974', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 18, 'created': '2019-07-12 18:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/716c63471845ce6eac252e62f58cc7fd74b24127', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}, {'number': 19, 'created': '2020-11-04 21:51:14.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/3c9dc019b65aff7c09c786f22b289d7c6046cc06', 'message': 'Support an IPv6 underlay network\n\nIf the tunnel endpoints for the underlay network are IPv6\naddresses, decrease the mtu accordingly.\n\nChange-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3\n'}]",13,343041,3c9dc019b65aff7c09c786f22b289d7c6046cc06,74,6,19,1131,,,0,"Support an IPv6 underlay network

If the tunnel endpoints for the underlay network are IPv6
addresses, decrease the mtu accordingly.

Change-Id: Iaef2cd5a6bd396714141ce5e9dbdebe238e6b2b3
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/41/343041/6 && git format-patch -1 --stdout FETCH_HEAD,"['devstack-vm-gate.sh', 'functions.sh']",2,99aec71a5f314cb34578003702562acde72ebd33,ipv6-underlay, local mtu=1500 local tunnel_overhead=$1 local bridge_name=$2 local host_ip=$3 local set_ips=$4 local offset=$5 local pub_addr_prefix=$6 local pub_addr_mask=$7 mtu=$((mtu - tunnel_overhead)), local mtu=1450 local bridge_name=$1 local host_ip=$2 local set_ips=$3 local offset=$4 local pub_addr_prefix=$5 local pub_addr_mask=$6,30,12
openstack%2Foctavia-tempest-plugin~master~Id4830b80dd5deead6c97d1c4302e01810c7dbb34,openstack/octavia-tempest-plugin,master,Id4830b80dd5deead6c97d1c4302e01810c7dbb34,Remove duplicate operating status check,ABANDONED,2021-01-21 21:41:29.000000000,2022-11-07 18:16:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2021-01-21 21:41:29.000000000', 'files': ['octavia_tempest_plugin/tests/api/v2/test_pool.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/e914a5efc38ff4e5d0fb5a461a2a237a855f3735', 'message': 'Remove duplicate operating status check\n\nThere are two checks for operating status in\n_test_pool_CRUD(), remove the duplicate but move\nthe comments to make clear what is expected.\n\nChange-Id: Id4830b80dd5deead6c97d1c4302e01810c7dbb34\n'}]",0,771887,e914a5efc38ff4e5d0fb5a461a2a237a855f3735,3,1,1,1131,,,0,"Remove duplicate operating status check

There are two checks for operating status in
_test_pool_CRUD(), remove the duplicate but move
the comments to make clear what is expected.

Change-Id: Id4830b80dd5deead6c97d1c4302e01810c7dbb34
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/87/771887/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_tempest_plugin/tests/api/v2/test_pool.py'],1,e914a5efc38ff4e5d0fb5a461a2a237a855f3735,dup-oper-status, # Operating status for a pool without members will be: # ONLINE if it is attached to a listener and is a live test # OFFLINE if it is just on the LB directly or is in noop mode," # Operating status for a pool without members will be: if (listener_protocol is not None and not CONF.load_balancer.test_with_noop): # ONLINE if it is attached to a listener and is a live test self.assertEqual(const.ONLINE, pool[const.OPERATING_STATUS]) else: # OFFLINE if it is just on the LB directly or is in noop mode self.assertEqual(const.OFFLINE, pool[const.OPERATING_STATUS])",3,8
openstack%2Frequirements~stable%2Fvictoria~Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1,openstack/requirements,stable/victoria,Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1,Raise upper diskimage-builder===3.24.0,MERGED,2022-10-25 22:02:43.000000000,2022-11-07 18:16:16.000000000,2022-11-07 18:16:16.000000000,"[{'_account_id': 11655}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-25 22:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a9ddc96e3a369f410607105a207860f4cc35b20a', 'message': 'Raise upper diskimage-builder===3.24.0\n\ndiskimage-builder is branchless and has minimal pip dependencies, so\nit is desirable to run the latest even on stable branches.\n\nThis sets the same version currently on master.\n\nThis change also fixes broken victoria jobs which fetch centos images,\nthe centos filename format changed and diskimage-builder-3.4.0\nswitches to the new format.\n\nChange-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1\n(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)\n(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)\n(cherry picked from commit d25185940345a0fbba97864eb4d25a8010b91536)\n'}, {'number': 2, 'created': '2022-11-04 17:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4f95a4a0beb86c90e66cacbc4f5862bbe42f1323', 'message': 'Raise upper diskimage-builder===3.24.0\n\ndiskimage-builder is branchless and has minimal pip dependencies, so\nit is desirable to run the latest even on stable branches.\n\nThis sets the same version currently on master.\n\nThis change also fixes broken victoria jobs which fetch centos images,\nthe centos filename format changed and diskimage-builder-3.4.0\nswitches to the new format.\n\nChange-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1\n(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)\n(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)\n(cherry picked from commit d25185940345a0fbba97864eb4d25a8010b91536)\n'}, {'number': 3, 'created': '2022-11-05 18:00:58.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f831f100967cce8a06d9664ed77d3e3a9eb06e54', 'message': 'Raise upper diskimage-builder===3.24.0\n\ndiskimage-builder is branchless and has minimal pip dependencies, so\nit is desirable to run the latest even on stable branches.\n\nThis sets the same version currently on master.\n\nThis change also fixes broken victoria jobs which fetch centos images,\nthe centos filename format changed and diskimage-builder-3.4.0\nswitches to the new format.\n\nChange-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1\n(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)\n(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)\n(cherry picked from commit d25185940345a0fbba97864eb4d25a8010b91536)\n'}]",2,862651,f831f100967cce8a06d9664ed77d3e3a9eb06e54,16,4,3,4571,,,0,"Raise upper diskimage-builder===3.24.0

diskimage-builder is branchless and has minimal pip dependencies, so
it is desirable to run the latest even on stable branches.

This sets the same version currently on master.

This change also fixes broken victoria jobs which fetch centos images,
the centos filename format changed and diskimage-builder-3.4.0
switches to the new format.

Change-Id: Ie08ab9685e5b73934186af8ec1cd5c6af2d1abb1
(cherry picked from commit 9365ac59772c5a0bdc3c908d864e910f3a806f8b)
(cherry picked from commit 1c1f63ae5b0db5fc335af3eb896fb0bb413d4060)
(cherry picked from commit d25185940345a0fbba97864eb4d25a8010b91536)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/51/862651/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a9ddc96e3a369f410607105a207860f4cc35b20a,,diskimage-builder===3.24.0,diskimage-builder===3.2.1,1,1
openstack%2Foctavia~master~If5bff05f65c6b231c23bfcffa584da3cc346d77b,openstack/octavia,master,If5bff05f65c6b231c23bfcffa584da3cc346d77b,Stop configuring install_command in tox.,ABANDONED,2020-01-23 19:11:45.000000000,2022-11-07 18:15:40.000000000,,"[{'_account_id': 1131}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-23 19:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/559d2d754eb02ff8921228a199010f294459b44c', 'message': ""Stop configuring install_command in tox.\n\nCurrently, we are overriding 'install_command' to use 'pip'. This is\nconsidered poor behavior and 'python -m pip' should be used instead:\n\nhttps://snarky.ca/why-you-should-use-python-m-pip/\n\nIt turns out that this is the the default value provided by tox:\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nSo we can remove the line and simply use the default value.\n\nChange-Id: If5bff05f65c6b231c23bfcffa584da3cc346d77b\n""}, {'number': 2, 'created': '2020-10-14 18:11:28.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/octavia/commit/272c226cd966cbb57e41d351881c256a839f09da', 'message': ""Stop configuring install_command in tox.\n\nCurrently, we are overriding 'install_command' to use 'pip'. This is\nconsidered poor behavior and 'python -m pip' should be used instead:\n\nhttps://snarky.ca/why-you-should-use-python-m-pip/\n\nIt turns out that this is the the default value provided by tox:\n\nhttps://tox.readthedocs.io/en/latest/config.html#conf-install_command\n\nSo we can remove the line and simply use the default value.\n\nChange-Id: If5bff05f65c6b231c23bfcffa584da3cc346d77b\n""}]",4,704053,272c226cd966cbb57e41d351881c256a839f09da,9,3,2,1131,,,0,"Stop configuring install_command in tox.

Currently, we are overriding 'install_command' to use 'pip'. This is
considered poor behavior and 'python -m pip' should be used instead:

https://snarky.ca/why-you-should-use-python-m-pip/

It turns out that this is the the default value provided by tox:

https://tox.readthedocs.io/en/latest/config.html#conf-install_command

So we can remove the line and simply use the default value.

Change-Id: If5bff05f65c6b231c23bfcffa584da3cc346d77b
",git fetch https://review.opendev.org/openstack/octavia refs/changes/53/704053/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,559d2d754eb02ff8921228a199010f294459b44c,stop_configuring_install_command,minversion = 3.2.0,minversion = 2.5.0install_command = pip install {opts} {packages},1,3
openstack%2Fnetworking-ovn~stable%2Ftrain~I2517f83d0de3dc8c4a7a153756f45974934df6bd,openstack/networking-ovn,stable/train,I2517f83d0de3dc8c4a7a153756f45974934df6bd,"Revert ""Make networking-ovn-octavia-v2-dsvm-scenario non-voting""",ABANDONED,2021-06-16 18:41:35.000000000,2022-11-07 18:14:02.000000000,,"[{'_account_id': 4694}, {'_account_id': 6773}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-06-16 18:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/503da3683bcba1b05b45d6b5fe3f8cc30fab17f0', 'message': 'Revert ""Make networking-ovn-octavia-v2-dsvm-scenario non-voting""\n\nThis reverts commit 3cb95f094f0706795d1b68ff836ab357594309e0.\n\nReason for revert: Tempest patches have merged that should make job pass now.\n\nChange-Id: I2517f83d0de3dc8c4a7a153756f45974934df6bd\n'}, {'number': 2, 'created': '2021-06-16 18:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4eac60c8af132e6122a8b500c596f124a35879bf', 'message': 'Revert ""Make networking-ovn-octavia-v2-dsvm-scenario non-voting""\n\nThis reverts commit 3cb95f094f0706795d1b68ff836ab357594309e0.\n\nReason for revert: Tempest patches have merged that should make job pass now.\n\nChange-Id: I2517f83d0de3dc8c4a7a153756f45974934df6bd\n'}, {'number': 3, 'created': '2021-06-22 01:45:50.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/91db72b523d92b9545b225d25c752cc02f7f6c2e', 'message': 'Revert ""Make networking-ovn-octavia-v2-dsvm-scenario non-voting""\n\nThis reverts commit 3cb95f094f0706795d1b68ff836ab357594309e0.\n\nReason for revert: Tempest patches have merged that should make job pass now.\n\nChange-Id: I2517f83d0de3dc8c4a7a153756f45974934df6bd\n'}]",0,796660,91db72b523d92b9545b225d25c752cc02f7f6c2e,23,5,3,1131,,,0,"Revert ""Make networking-ovn-octavia-v2-dsvm-scenario non-voting""

This reverts commit 3cb95f094f0706795d1b68ff836ab357594309e0.

Reason for revert: Tempest patches have merged that should make job pass now.

Change-Id: I2517f83d0de3dc8c4a7a153756f45974934df6bd
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/60/796660/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,503da3683bcba1b05b45d6b5fe3f8cc30fab17f0,, - networking-ovn-octavia-v2-dsvm-scenario - networking-ovn-octavia-v2-dsvm-scenario, - networking-ovn-octavia-v2-dsvm-scenario: voting: false,2,2
openstack%2Fpython-openstackclient~master~Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f,openstack/python-openstackclient,master,Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f,Register base commands as builtins,NEW,2020-06-13 15:41:47.000000000,2022-11-07 17:51:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-06-13 15:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fc4da2db7e90155c4e7214bfe588c1a8308b36fc', 'message': 'Register base commands as builtins\n\nChange-Id: Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f\n'}, {'number': 2, 'created': '2020-06-14 14:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a3c16da7a1d7873572ad14f3d3e1146522118346', 'message': ""Register base commands as builtins\n\nAdd 'help commands' as an alias for command list. --help\nis no longer going to show all of the plugin commands.\n\nChange-Id: Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f\n""}, {'number': 3, 'created': '2020-06-15 15:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c8679d33d2ec2ef297dd357ca648f950a11d612c', 'message': ""Register base commands as builtins\n\nAdd 'help commands' as an alias for command list. --help\nis no longer going to show all of the plugin commands.\n\nChange-Id: Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f\n""}, {'number': 4, 'created': '2020-06-15 19:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7447a23de4ef2a54ab922d791173a2d3eeec7c07', 'message': ""Register base commands as builtins\n\nAdd 'help commands' as an alias for command list. --help\nis no longer going to show all of the plugin commands.\n\nDepends-On: https://review.opendev.org/735465\nChange-Id: Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f\n""}, {'number': 5, 'created': '2022-11-07 16:51:00.000000000', 'files': ['openstackclient/common/module.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d3889e3abd51abdb237e1a54c0a76faeac893832', 'message': ""Register base commands as builtins\n\nAdd 'help commands' as an alias for command list. --help\nis no longer going to show all of the plugin commands.\n\nDepends-On: https://review.opendev.org/735465\nChange-Id: Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f\n""}]",441,735434,d3889e3abd51abdb237e1a54c0a76faeac893832,11,2,5,2,,,0,"Register base commands as builtins

Add 'help commands' as an alias for command list. --help
is no longer going to show all of the plugin commands.

Depends-On: https://review.opendev.org/735465
Change-Id: Id31139b99d45c37c98aa5e0689eb9bbb78e23c8f
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/34/735434/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/shell.py', 'setup.cfg']",2,fc4da2db7e90155c4e7214bfe588c1a8308b36fc,osc-plugin-optimize,,openstack.cli = command_list = openstackclient.common.module:ListCommand module_list = openstackclient.common.module:ListModule openstack.common = availability_zone_list = openstackclient.common.availability_zone:ListAvailabilityZone configuration_show = openstackclient.common.configuration:ShowConfiguration extension_list = openstackclient.common.extension:ListExtension extension_show = openstackclient.common.extension:ShowExtension limits_show = openstackclient.common.limits:ShowLimits project_purge = openstackclient.common.project_purge:ProjectPurge quota_list = openstackclient.common.quota:ListQuota quota_set = openstackclient.common.quota:SetQuota quota_show = openstackclient.common.quota:ShowQuota versions_show = openstackclient.common.versions:ShowVersions ,37,20
openstack%2Frequirements~master~I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f,openstack/requirements,master,I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f,Updated from generate-constraints,MERGED,2022-09-03 08:18:17.000000000,2022-11-07 17:06:34.000000000,2022-11-07 17:05:31.000000000,"[{'_account_id': 12898}, {'_account_id': 13252}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-03 08:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f6490a6e892d64129845286829e0ebe73fb145a6', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 2, 'created': '2022-09-10 08:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/548ed592289fbe6af6ed8fc388ee42706c7805bc', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 3, 'created': '2022-09-11 11:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/351e2466defaa52532514f65dd6c58ad3da42e07', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 4, 'created': '2022-09-17 08:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2ffea23af182ff94a1e789d6c1ae01793429284d', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 5, 'created': '2022-09-24 08:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/423fe4acee8acddb055d75f30f28f7d830d1d1d5', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 6, 'created': '2022-10-01 08:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/8e888f11d60ee1470a7b1fc74504907b5029bd9f', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 7, 'created': '2022-10-08 08:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/bf2f822175dba9680c979b18ebd061af03cc1923', 'message': 'Updated from generate-constraints\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 8, 'created': '2022-10-12 05:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/15ececd0c578da67db3fc9667144a9ff698081fa', 'message': 'Updated from generate-constraints\n\nAmended to exclude the current blockers from [0]\n\n[0] https://etherpad.opendev.org/p/requirements-blockers\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 9, 'created': '2022-10-12 10:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/0b79e0311237f74f4590a61e7ed6c7e44caaf517', 'message': 'Updated from generate-constraints\n\nAmended to exclude the current blockers from [0], dropped pins specific\nto python3.8.\n\n[0] https://etherpad.opendev.org/p/requirements-blockers\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 10, 'created': '2022-10-12 13:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/75fb5c8547dd6b50caf3cf0b225165693a353a9e', 'message': 'Updated from generate-constraints\n\nAmended to exclude the current blockers from [0], dropped pins specific\nto python3.8.\n\n[0] https://etherpad.opendev.org/p/requirements-blockers\n\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 11, 'created': '2022-10-20 05:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c13b23553524455354b3fd87fd50dc8f0d6b9755', 'message': 'Updated from generate-constraints\n\nAmended to exclude the current blockers from [0], dropped pins specific\nto python3.8.\n\n[0] https://etherpad.opendev.org/p/requirements-blockers\n\nDepends-On: https://review.opendev.org/c/openstack/barbican/+/861594\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 12, 'created': '2022-10-24 04:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e94338a88f674083d4cccb38232270063fecc525', 'message': 'Updated from generate-constraints\n\nAmended to exclude the current blockers from [0], dropped pins specific\nto python3.8.\n\n[0] https://etherpad.opendev.org/p/requirements-blockers\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/861956\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}, {'number': 13, 'created': '2022-10-31 14:00:42.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f4f272786ddb77ddce64ac4f8bb2f8f7f6fb5ea0', 'message': 'Updated from generate-constraints\n\nAmended to exclude the current blockers from [0], dropped pins specific\nto python3.8.\n\n[0] https://etherpad.opendev.org/p/requirements-blockers\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/863029\nChange-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f\n'}]",10,855711,f4f272786ddb77ddce64ac4f8bb2f8f7f6fb5ea0,65,4,13,11131,,,0,"Updated from generate-constraints

Amended to exclude the current blockers from [0], dropped pins specific
to python3.8.

[0] https://etherpad.opendev.org/p/requirements-blockers

Depends-On: https://review.opendev.org/c/openstack/ironic/+/863029
Change-Id: I6ec5a3e7a3626d1fcfdc9f2034c765e617e2057f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/11/855711/13 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,f6490a6e892d64129845286829e0ebe73fb145a6,constraints-edited,pytest===7.1.3grpcio===1.48.1sniffio===1.3.0Mako===1.2.2google-api-core===2.10.0types-paramiko===2.11.4jaraco.classes===3.2.2doc8===1.0.0prettytable===3.4.1cryptography===37.0.4requests-mock===1.10.0pkg_resources===0.0.0libvirt-python===8.7.0docutils===0.19dogtag-pki===11.2.1boto3===1.24.66keyring===23.9.0keystonemiddleware===10.1.0edgegrid-python===1.3.0sympy===1.11.1more-itertools===8.14.0Sphinx===5.1.1botocore===1.27.66oslo.db===12.1.0jsonschema===4.15.0python-heatclient===3.1.0virtualenv===20.16.4,pytest===7.1.2grpcio===1.47.0sniffio===1.2.0Mako===1.2.1google-api-core===2.8.2types-paramiko===2.11.3doc8===0.11.2prettytable===3.3.0cryptography===36.0.2requests-mock===1.9.3libvirt-python===8.6.0docutils===0.17.1dogtag-pki===10.7.4.1boto3===1.24.61keyring===23.8.2keystonemiddleware===10.0.1edgegrid-python===1.2.1python-nss===1.0.1sympy===1.11Sphinx===4.5.0botocore===1.27.61oslo.db===12.0.0jsonschema===4.14.0python-heatclient===3.0.0virtualenv===20.16.3,27,25
openstack%2Frequirements~master~If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2,openstack/requirements,master,If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2,[CVE-2022-42969] Reduce usage of package py,ABANDONED,2022-10-31 15:49:53.000000000,2022-11-07 16:51:09.000000000,,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-31 15:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/05ab3bb16390e3724920c095a4ccc907fd29d9d8', 'message': '[CVE-2022-42969] Do not use package py\n\nSome weird CVE was found in package py.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\n\nStory: 2010389\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n'}, {'number': 2, 'created': '2022-10-31 19:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6d5a7df3edb59a0435cf795700d71faf2500280f', 'message': '[CVE-2022-42969] Do not use package py\n\nSome weird CVE was found in package py.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n'}, {'number': 3, 'created': '2022-11-07 13:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/49e1d4adc969691a2b848ce9846d79c00885bc1f', 'message': '[CVE-2022-42969] Do not use package py\n\nSome weird CVE was found in package py.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n'}, {'number': 4, 'created': '2022-11-07 15:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/47d7373f06db4043c9c9fc532cb323675c744df1', 'message': '[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n'}, {'number': 5, 'created': '2022-11-07 15:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/de26a97a363dc7a8c958a8d8d552ba397620cc10', 'message': ""[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nMaintainers support py in maintenance mode.\nSo it's better do not use it.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n""}, {'number': 6, 'created': '2022-11-07 15:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/e4b6ec861d53209bbc001df9deff97e7e20a914b', 'message': ""[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nMaintainers support py in maintenance mode.\nSo it's better do not use it.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n""}, {'number': 7, 'created': '2022-11-07 16:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a7740be1c4f85a3078dfb02970a4fd07ea65108a', 'message': ""[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nMaintainers support py in maintenance mode.\nSo it's better do not use it.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n""}, {'number': 8, 'created': '2022-11-07 16:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ee88d26ec00493212359c5de877846998abcc9f7', 'message': ""[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nMaintainers support py in maintenance mode.\nSo it's better do not use it.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nDepends-On: I7549373c9ebba0a618708924d4fce6c464639dec\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n""}, {'number': 9, 'created': '2022-11-07 16:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/b7d29ccb32130c81de635c695ac341dba35d31c8', 'message': ""[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nMaintainers support py in maintenance mode.\nSo it's better do not use it.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n""}, {'number': 10, 'created': '2022-11-07 16:27:08.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7790b3478a660b811bde8c346c44b2f57cd32069', 'message': ""[CVE-2022-42969] Reduce usage of package py\n\nSome weird CVE was found in package py.\nMaintainers support py in maintenance mode.\nSo it's better do not use it.\nPytest does not use py since 7.2.0.\nSo we upgrade pytest.\nHorizon uses py and requires that\npy is set in requirements.\n\nStory: 2010389\nChange-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2\n""}]",4,863083,7790b3478a660b811bde8c346c44b2f57cd32069,23,2,10,32927,,,0,"[CVE-2022-42969] Reduce usage of package py

Some weird CVE was found in package py.
Maintainers support py in maintenance mode.
So it's better do not use it.
Pytest does not use py since 7.2.0.
So we upgrade pytest.
Horizon uses py and requires that
py is set in requirements.

Story: 2010389
Change-Id: If16d88a54d7b86f4afb7ad24df00f5f12ba69cd2
",git fetch https://review.opendev.org/openstack/requirements refs/changes/83/863083/9 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,05ab3bb16390e3724920c095a4ccc907fd29d9d8,,pytest===7.2.0,pytest===7.1.2,1,1
openstack%2Fswift~master~Ic52d7af1e34550b9ea5f74108eff9c3412248573,openstack/swift,master,Ic52d7af1e34550b9ea5f74108eff9c3412248573,Break out config validation from run_wsgi,ABANDONED,2022-03-25 11:31:12.000000000,2022-11-07 16:35:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-03-25 11:31:12.000000000', 'files': ['swift/common/utils.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f0773c34fbd5be8493f0ccd3d35022c46a742709', 'message': 'Break out config validation from run_wsgi\n\nMove config validation and app pre-load to a separate function to make\nit very obvious where validation should be done.\n\nChange-Id: Ic52d7af1e34550b9ea5f74108eff9c3412248573\n'}]",1,835208,f0773c34fbd5be8493f0ccd3d35022c46a742709,5,1,1,7847,,,0,"Break out config validation from run_wsgi

Move config validation and app pre-load to a separate function to make
it very obvious where validation should be done.

Change-Id: Ic52d7af1e34550b9ea5f74108eff9c3412248573
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/835208/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'swift/common/wsgi.py', 'test/unit/common/test_wsgi.py']",3,f0773c34fbd5be8493f0ccd3d35022c46a742709,safe-reload," def test_run_server_bad_bind_port(self): calls = defaultdict(lambda: 0) logger = debug_logger() def _initrp(conf_file, app_section, *args, **kwargs): calls['_initrp'] += 1 return ( {'__file__': 'test', 'workers': 0, 'bind_port': 'bad'}, logger, 'log_name') def _loadapp(uri, name=None, **kwargs): calls['_loadapp'] += 1 with mock.patch.object(wsgi, '_initrp', _initrp), \ mock.patch.object(wsgi, 'get_socket'), \ mock.patch.object(wsgi, 'drop_privileges'), \ mock.patch.object(wsgi, 'loadapp', _loadapp), \ mock.patch.object(wsgi, 'capture_stdio'), \ mock.patch.object(wsgi, 'run_server'): rc = wsgi.run_wsgi('conf_file', 'app_section') self.assertEqual(calls['_initrp'], 1) self.assertEqual(calls['_loadapp'], 0) self.assertEqual(rc, 1) self.assertEqual( [""bind_port wasn't properly set in the config file. "" ""It must be explicitly set to a valid port number.""], logger.get_lines_for_level('error') ) ",,64,26
openstack%2Frequirements~master~I605717824159f878df252e4c6d9bdd7af2f113df,openstack/requirements,master,I605717824159f878df252e4c6d9bdd7af2f113df,Remove python-dev from bindep,MERGED,2022-11-07 10:06:06.000000000,2022-11-07 16:25:37.000000000,2022-11-07 16:24:20.000000000,"[{'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 10:06:06.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/90b48934f4f018cf6e04dcd42731731346422b03', 'message': ""Remove python-dev from bindep\n\nIt is no longer supported by jammy and lead us to the following errors with the announce-release job.\n\n```\nNo package matching 'python-dev' is available\n```\n\nChange-Id: I605717824159f878df252e4c6d9bdd7af2f113df\n""}]",0,863847,90b48934f4f018cf6e04dcd42731731346422b03,9,3,1,28522,,,0,"Remove python-dev from bindep

It is no longer supported by jammy and lead us to the following errors with the announce-release job.

```
No package matching 'python-dev' is available
```

Change-Id: I605717824159f878df252e4c6d9bdd7af2f113df
",git fetch https://review.opendev.org/openstack/requirements refs/changes/47/863847/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,90b48934f4f018cf6e04dcd42731731346422b03,drop-python-dev-from-bindep,,python-devel [platform:rpm !platform:centos-8],0,1
openstack%2Fdesignate-tempest-plugin~master~If40574da1704c66c9e26692f7fd3a705029cba19,openstack/designate-tempest-plugin,master,If40574da1704c66c9e26692f7fd3a705029cba19,Fix checking of the [dns].nameservers value,ABANDONED,2022-11-07 16:23:17.000000000,2022-11-07 16:23:53.000000000,,[],"[{'number': 1, 'created': '2022-11-07 16:23:17.000000000', 'files': ['designate_tempest_plugin/services/dns/query/query_client.py', 'designate_tempest_plugin/tests/api/v2/test_zone_tasks.py', 'designate_tempest_plugin/common/waiters.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/f7975798ab274fca6e1a8999855654e3a080eea2', 'message': 'Fix checking of the [dns].nameservers value\n\nThis patch [1] introduced checking whether the CONF.dns.nameservers\nis empty. If the CONF.dns.nameservers value is empty then the\ninitialization of the QueryClient fails. This change makes the majority\nof designate-tempest-plugin tests fail even tests that do not use the\nQueryClient.\n\nThis patch introduces three changes:\n\n1) ValueError is raised only when the query() function is called so\n   that only tests that actually use the query() function fail.\n\n2) wait_for_query() function is fixed so that it never succeeds when the\n   CONF.dns.nameservers value is empty.\n\n3) Skip tests that rely upon [dns].nameserver value.\n\n[1] https://review.opendev.org/c/openstack/designate-tempest-plugin/+/860116\nChange-Id: Iedd151b2e47ed62adc168a97cb6021ccb47abb0f\n\nChange-Id: If40574da1704c66c9e26692f7fd3a705029cba19\n'}]",0,863895,f7975798ab274fca6e1a8999855654e3a080eea2,2,0,1,30674,,,0,"Fix checking of the [dns].nameservers value

This patch [1] introduced checking whether the CONF.dns.nameservers
is empty. If the CONF.dns.nameservers value is empty then the
initialization of the QueryClient fails. This change makes the majority
of designate-tempest-plugin tests fail even tests that do not use the
QueryClient.

This patch introduces three changes:

1) ValueError is raised only when the query() function is called so
   that only tests that actually use the query() function fail.

2) wait_for_query() function is fixed so that it never succeeds when the
   CONF.dns.nameservers value is empty.

3) Skip tests that rely upon [dns].nameserver value.

[1] https://review.opendev.org/c/openstack/designate-tempest-plugin/+/860116
Change-Id: Iedd151b2e47ed62adc168a97cb6021ccb47abb0f

Change-Id: If40574da1704c66c9e26692f7fd3a705029cba19
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/95/863895/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate_tempest_plugin/services/dns/query/query_client.py', 'designate_tempest_plugin/tests/api/v2/test_zone_tasks.py', 'designate_tempest_plugin/common/waiters.py']",3,f7975798ab274fca6e1a8999855654e3a080eea2,fix/QueryClient, if all_answers_good:, if not client.nameservers or all_answers_good:,11,8
openstack%2Frequirements~stable%2Fyoga~Ibf8537952325fdf796fb430bc9edc1cd8e6e206f,openstack/requirements,stable/yoga,Ibf8537952325fdf796fb430bc9edc1cd8e6e206f,update constraint for sushy to new release 4.1.3,MERGED,2022-11-07 11:07:04.000000000,2022-11-07 16:11:39.000000000,2022-11-07 16:11:39.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-11-07 11:07:04.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a8ae49c4f948c906e68a85b5dc040276fcbd82c6', 'message': 'update constraint for sushy to new release 4.1.3\n\nmeta: version: 4.1.3\nmeta: diff-start: -\nmeta: series: yoga\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jacob Anders <janders@redhat.com>\nmeta: release:Commit: Jacob Anders <janders@redhat.com>\nmeta: release:Change-Id: Ib3ffbeb9cd8457e4936aa2bcc6bad2bda518ea30\nmeta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ibf8537952325fdf796fb430bc9edc1cd8e6e206f\n'}]",0,863865,a8ae49c4f948c906e68a85b5dc040276fcbd82c6,8,3,1,11131,,,0,"update constraint for sushy to new release 4.1.3

meta: version: 4.1.3
meta: diff-start: -
meta: series: yoga
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Jacob Anders <janders@redhat.com>
meta: release:Commit: Jacob Anders <janders@redhat.com>
meta: release:Change-Id: Ib3ffbeb9cd8457e4936aa2bcc6bad2bda518ea30
meta: release:Code-Review+1: Riccardo Pittau <elfosardo@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Ibf8537952325fdf796fb430bc9edc1cd8e6e206f
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/863865/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a8ae49c4f948c906e68a85b5dc040276fcbd82c6,new-release,sushy===4.1.3,sushy===4.1.2,1,1
openstack%2Fcharm-nova-cloud-controller~master~Ic868213c6bb42bc2a28ad25a2f7344a28ab9f04d,openstack/charm-nova-cloud-controller,master,Ic868213c6bb42bc2a28ad25a2f7344a28ab9f04d,ch-sync: IndentityServiceContext app data fixes,MERGED,2022-11-03 14:48:03.000000000,2022-11-07 15:53:15.000000000,2022-11-07 15:53:15.000000000,"[{'_account_id': 2424}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-03 14:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/d18e3389dbf04e2927223cbecb6d1facac385f67', 'message': ""ch-sync: IndentityServiceContext app data fixes\n\nThe IdentityServiceContext was recently updated to add the application\ndata bag. Unfortunately, they keystone charm uses both the regular\nrelation data primarily, but the updates for endpoints are on both the\napplication database and the regular relation data. The\nIdentityServiceContext used the app data bag exclusively if there were\nany keys available, which leads to it ignoring the existing relation\ndata entirely; this results in 'identity relation not ready' with\nmissing data items.\n\ncharm-helpers is patched at [1] to solve the issue and this is a\ncharm-helpers sync that includes that patch.  This changes the\nfunctionality of the IdentityServiceContext so that it preferentially\nselects keys from the application data bag unless they are None, in\nwhich case it tries for those keys on the existing relation data. e.g.\nit will stitch the two relations together with the app data bag taking\npriority. This allows the nova-cloud-controller charm to correctly\naccess the identity relation data and form a complete context.\n\n[1] https://github.com/juju/charm-helpers/pull/746\n\nChange-Id: Ic868213c6bb42bc2a28ad25a2f7344a28ab9f04d\n""}, {'number': 2, 'created': '2022-11-03 14:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/d965fbf9375aa1dabcab3f674cc2007494bb605e', 'message': ""ch-sync: IndentityServiceContext app data fixes\n\nThe IdentityServiceContext was recently updated to add the application\ndata bag. Unfortunately, they keystone charm uses both the regular\nrelation data primarily, but the updates for endpoints are on both the\napplication database and the regular relation data. The\nIdentityServiceContext used the app data bag exclusively if there were\nany keys available, which leads to it ignoring the existing relation\ndata entirely; this results in 'identity relation not ready' with\nmissing data items.\n\ncharm-helpers is patched at [1] to solve the issue and this is a\ncharm-helpers sync that includes that patch.  This changes the\nfunctionality of the IdentityServiceContext so that it preferentially\nselects keys from the application data bag unless they are None, in\nwhich case it tries for those keys on the existing relation data. e.g.\nit will stitch the two relations together with the app data bag taking\npriority. This allows the nova-cloud-controller charm to correctly\naccess the identity relation data and form a complete context.\n\n[1] https://github.com/juju/charm-helpers/pull/746\n\nChange-Id: Ic868213c6bb42bc2a28ad25a2f7344a28ab9f04d\n""}, {'number': 3, 'created': '2022-11-03 15:03:00.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/ssh_migrations.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/storage/linux/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/core/unitdata.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/1d06b80c8dfb5ce4aa5fa74ac444d6af961053b0', 'message': ""ch-sync: IndentityServiceContext app data fixes\n\nThe IdentityServiceContext was recently updated to add the application\ndata bag. Unfortunately, they keystone charm uses both the regular\nrelation data primarily, but the updates for endpoints are on both the\napplication database and the regular relation data. The\nIdentityServiceContext used the app data bag exclusively if there were\nany keys available, which leads to it ignoring the existing relation\ndata entirely; this results in 'identity relation not ready' with\nmissing data items.\n\ncharm-helpers is patched at [1] to solve the issue and this is a\ncharm-helpers sync that includes that patch.  This changes the\nfunctionality of the IdentityServiceContext so that it preferentially\nselects keys from the application data bag unless they are None, in\nwhich case it tries for those keys on the existing relation data. e.g.\nit will stitch the two relations together with the app data bag taking\npriority. This allows the nova-cloud-controller charm to correctly\naccess the identity relation data and form a complete context.\n\n[1] https://github.com/juju/charm-helpers/pull/746\n\nChange-Id: Ic868213c6bb42bc2a28ad25a2f7344a28ab9f04d\n""}]",0,863531,1d06b80c8dfb5ce4aa5fa74ac444d6af961053b0,11,4,3,20870,,,0,"ch-sync: IndentityServiceContext app data fixes

The IdentityServiceContext was recently updated to add the application
data bag. Unfortunately, they keystone charm uses both the regular
relation data primarily, but the updates for endpoints are on both the
application database and the regular relation data. The
IdentityServiceContext used the app data bag exclusively if there were
any keys available, which leads to it ignoring the existing relation
data entirely; this results in 'identity relation not ready' with
missing data items.

charm-helpers is patched at [1] to solve the issue and this is a
charm-helpers sync that includes that patch.  This changes the
functionality of the IdentityServiceContext so that it preferentially
selects keys from the application data bag unless they are None, in
which case it tries for those keys on the existing relation data. e.g.
it will stitch the two relations together with the app data bag taking
priority. This allows the nova-cloud-controller charm to correctly
access the identity relation data and form a complete context.

[1] https://github.com/juju/charm-helpers/pull/746

Change-Id: Ic868213c6bb42bc2a28ad25a2f7344a28ab9f04d
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/31/863531/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/ssh_migrations.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charm-helpers-hooks.yaml', 'charmhelpers/contrib/storage/linux/utils.py', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/core/unitdata.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py']",15,d18e3389dbf04e2927223cbecb6d1facac385f67,bug/fix-app-data-identity-context, return not (bool(result)), return not(bool(result)),256,55
openstack%2Fcharm-nova-cloud-controller~stable%2Fzed~If2d3922eb11cf1b7270eea2c7784928388140978,openstack/charm-nova-cloud-controller,stable/zed,If2d3922eb11cf1b7270eea2c7784928388140978,Updates for zed stable branch creation,MERGED,2022-10-14 16:08:34.000000000,2022-11-07 15:53:14.000000000,2022-11-07 15:53:14.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-14 16:08:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/bc0ac5ff62087deb38eb156fea11dff6c78833a1', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: If2d3922eb11cf1b7270eea2c7784928388140978\n'}, {'number': 2, 'created': '2022-10-22 16:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/3f46eac4404253c569e8a0c5a1b8f0d54615cc7b', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: If2d3922eb11cf1b7270eea2c7784928388140978\n'}, {'number': 3, 'created': '2022-11-04 08:48:07.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/ssh_migrations.py', '.gitreview', 'test-requirements.txt', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charm-helpers-hooks.yaml', 'tests/bundles/jammy-zed.yaml', 'charmhelpers/contrib/storage/linux/utils.py', 'tests/bundles/kinetic-zed.yaml', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'tests/bundles/jammy-yoga.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/8d76e1fe90056858d4d5e4b5bf1e8780419da090', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n- also sync in charm-helpers #747 IdentityServiceContext app data bag\n  fixes.\n\nChange-Id: If2d3922eb11cf1b7270eea2c7784928388140978\n'}]",7,861442,8d76e1fe90056858d4d5e4b5bf1e8780419da090,24,3,3,20870,,,0,"Updates for zed stable branch creation

- Set default branch for git review/gerrit to stable/zed
- Switch tests to stable.
- Switch to using stable charm-helpers branch.
- Switch to using stable charm.openstack branch.
- Switch to using stable zaza, zaza-openstack-tests
  branch
- (reactive charms) Add build.lock file
- (classic charms) make sync
- (reactive: not reactive plugin): lock charm-tools < 3.1
- (reactive: with reactive plugin): lock charm snap to 3.x/stable
- also sync in charm-helpers #747 IdentityServiceContext app data bag
  fixes.

Change-Id: If2d3922eb11cf1b7270eea2c7784928388140978
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/42/861442/3 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/ssh_migrations.py', '.gitreview', 'test-requirements.txt', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charm-helpers-hooks.yaml', 'tests/bundles/jammy-zed.yaml', 'charmhelpers/contrib/storage/linux/utils.py', 'tests/bundles/kinetic-zed.yaml', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/contrib/openstack/templates/haproxy.cfg', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/network/ip.py', 'tests/bundles/jammy-yoga.yaml']",18,bc0ac5ff62087deb38eb156fea11dff6c78833a1,zed-stable-updates, channel: 8.0/edge channel: 8.0/edge channel: 8.0/edge channel: 8.0/edge channel: 8.0/edge channel: 8.0/edge channel: 8.0/edge channel: 3.9/edge channel: zed/edge channel: zed/edge channel: zed/edge channel: zed/edge channel: zed/edge channel: zed/edge channel: zed/edge, channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge,251,74
openstack%2Fcharm-nova-cloud-controller~stable%2Fussuri~Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,openstack/charm-nova-cloud-controller,stable/ussuri,Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,Fix SQLite locking issue on unit tests,MERGED,2022-11-04 09:12:45.000000000,2022-11-07 15:53:12.000000000,2022-11-07 15:53:12.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 09:12:45.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/eb14dba8fdaf9ce7533f48730bf3d3f8ce134c6a', 'message': 'Fix SQLite locking issue on unit tests\n\nstestr runs tests in parallel and this can cause issues with locking\nwhen SQLite is not mocked out properly and gets used in a test.  This\npatch just switches Storage to use :memory: so that locking does not\noccur.\n\nCloses-Bug: #1908282\nChange-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd\n(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)\n'}]",0,863617,eb14dba8fdaf9ce7533f48730bf3d3f8ce134c6a,7,3,1,2424,,,0,"Fix SQLite locking issue on unit tests

stestr runs tests in parallel and this can cause issues with locking
when SQLite is not mocked out properly and gets used in a test.  This
patch just switches Storage to use :memory: so that locking does not
occur.

Closes-Bug: #1908282
Change-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd
(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/17/863617/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py']",5,eb14dba8fdaf9ce7533f48730bf3d3f8ce134c6a,,import charmhelpers.core.unitdata @classmethod def setUpClass(cls): super().setUpClass() charmhelpers.core.unitdata._KV = ( charmhelpers.core.unitdata.Storage(':memory:')) ,,64,0
openstack%2Ftrove~master~Ie056126951947984aa1942f1e1d8ccf54905fd6d,openstack/trove,master,Ie056126951947984aa1942f1e1d8ccf54905fd6d,Update metadata in setup.cfg,NEW,2022-10-30 06:42:26.000000000,2022-11-07 15:52:55.000000000,,"[{'_account_id': 5572}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-30 06:42:26.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove/commit/fcba5c024e6849c8cbf71f0068ed567b3eeac21c', 'message': 'Update metadata in setup.cfg\n\nwe are using some ""aliases"" that the setuptools docs say\n""are supported for compatibility reasons"" but their use is not advised[1].\n\n[1] https://setuptools.pypa.io/en/latest/userguide/declarative_config.html#metadata\n\nChange-Id: Ie056126951947984aa1942f1e1d8ccf54905fd6d\n'}]",1,862979,fcba5c024e6849c8cbf71f0068ed567b3eeac21c,4,2,1,32029,,,0,"Update metadata in setup.cfg

we are using some ""aliases"" that the setuptools docs say
""are supported for compatibility reasons"" but their use is not advised[1].

[1] https://setuptools.pypa.io/en/latest/userguide/declarative_config.html#metadata

Change-Id: Ie056126951947984aa1942f1e1d8ccf54905fd6d
",git fetch https://review.opendev.org/openstack/trove refs/changes/79/862979/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fcba5c024e6849c8cbf71f0068ed567b3eeac21c,setup,description = OpenStack DBaaS long_description = file: README.rsturl = https://docs.openstack.org/trove/latest/classifiers =,summary = OpenStack DBaaS description_file = README.rsthome_page = https://docs.openstack.org/trove/latest/classifier =,4,5
openstack%2Fcharm-nova-cloud-controller~stable%2Fvictoria~Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,openstack/charm-nova-cloud-controller,stable/victoria,Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,Fix SQLite locking issue on unit tests,MERGED,2022-11-04 09:11:42.000000000,2022-11-07 15:52:23.000000000,2022-11-07 15:52:23.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 09:11:42.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/1358a613340bf05ad0c209d92e5f1ea942980402', 'message': 'Fix SQLite locking issue on unit tests\n\nstestr runs tests in parallel and this can cause issues with locking\nwhen SQLite is not mocked out properly and gets used in a test.  This\npatch just switches Storage to use :memory: so that locking does not\noccur.\n\nCloses-Bug: #1908282\nChange-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd\n(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)\n'}]",0,863616,1358a613340bf05ad0c209d92e5f1ea942980402,7,3,1,2424,,,0,"Fix SQLite locking issue on unit tests

stestr runs tests in parallel and this can cause issues with locking
when SQLite is not mocked out properly and gets used in a test.  This
patch just switches Storage to use :memory: so that locking does not
occur.

Closes-Bug: #1908282
Change-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd
(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/16/863616/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py']",5,1358a613340bf05ad0c209d92e5f1ea942980402,,import charmhelpers.core.unitdata @classmethod def setUpClass(cls): super().setUpClass() charmhelpers.core.unitdata._KV = ( charmhelpers.core.unitdata.Storage(':memory:')) ,,64,0
openstack%2Fcharm-nova-cloud-controller~stable%2Fwallaby~Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,openstack/charm-nova-cloud-controller,stable/wallaby,Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,Fix SQLite locking issue on unit tests,MERGED,2022-11-04 09:10:54.000000000,2022-11-07 15:52:21.000000000,2022-11-07 15:52:21.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 09:10:54.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/7d544a69ae92a99b7a2a90fa1d07f83e1d8363f9', 'message': 'Fix SQLite locking issue on unit tests\n\nstestr runs tests in parallel and this can cause issues with locking\nwhen SQLite is not mocked out properly and gets used in a test.  This\npatch just switches Storage to use :memory: so that locking does not\noccur.\n\nCloses-Bug: #1908282\nChange-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd\n(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)\n'}]",0,863615,7d544a69ae92a99b7a2a90fa1d07f83e1d8363f9,7,3,1,2424,,,0,"Fix SQLite locking issue on unit tests

stestr runs tests in parallel and this can cause issues with locking
when SQLite is not mocked out properly and gets used in a test.  This
patch just switches Storage to use :memory: so that locking does not
occur.

Closes-Bug: #1908282
Change-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd
(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/15/863615/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py']",5,7d544a69ae92a99b7a2a90fa1d07f83e1d8363f9,,import charmhelpers.core.unitdata @classmethod def setUpClass(cls): super().setUpClass() charmhelpers.core.unitdata._KV = ( charmhelpers.core.unitdata.Storage(':memory:')) ,,64,0
openstack%2Fcharm-nova-cloud-controller~stable%2Fxena~Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,openstack/charm-nova-cloud-controller,stable/xena,Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd,Fix SQLite locking issue on unit tests,MERGED,2022-11-04 09:09:56.000000000,2022-11-07 15:52:19.000000000,2022-11-07 15:52:19.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-04 09:09:56.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/3e3bd32d74ed77fea9b4e14c0d3ab5c15bb91c27', 'message': 'Fix SQLite locking issue on unit tests\n\nstestr runs tests in parallel and this can cause issues with locking\nwhen SQLite is not mocked out properly and gets used in a test.  This\npatch just switches Storage to use :memory: so that locking does not\noccur.\n\nCloses-Bug: #1908282\nChange-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd\n(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)\n'}]",1,863614,3e3bd32d74ed77fea9b4e14c0d3ab5c15bb91c27,9,3,1,2424,,,0,"Fix SQLite locking issue on unit tests

stestr runs tests in parallel and this can cause issues with locking
when SQLite is not mocked out properly and gets used in a test.  This
patch just switches Storage to use :memory: so that locking does not
occur.

Closes-Bug: #1908282
Change-Id: Iaa1c7b78dee498e0cc6dc6fccf12e74f22225ecd
(cherry picked from commit 36ef217bc620bebe4475dbb1453d3c82ac5b9d73)
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/14/863614/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_hooks.py', 'unit_tests/test_actions.py', 'unit_tests/test_nova_cc_utils.py', 'unit_tests/test_actions_openstack_upgrade.py', 'unit_tests/test_nova_cc_contexts.py']",5,3e3bd32d74ed77fea9b4e14c0d3ab5c15bb91c27,,import charmhelpers.core.unitdata @classmethod def setUpClass(cls): super().setUpClass() charmhelpers.core.unitdata._KV = ( charmhelpers.core.unitdata.Storage(':memory:')) ,,64,0
