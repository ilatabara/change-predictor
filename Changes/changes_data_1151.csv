id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ffuel-ostf~master~I93b72d24e54dde31c9dd608c98be857aa9a65657,openstack/fuel-ostf,master,I93b72d24e54dde31c9dd608c98be857aa9a65657,Add error catching to the cleanup method for Heat tests,MERGED,2015-06-09 11:58:48.000000000,2015-06-11 15:29:26.000000000,2015-06-11 15:27:07.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7227}, {'_account_id': 7428}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 12200}, {'_account_id': 13420}, {'_account_id': 13919}, {'_account_id': 13962}, {'_account_id': 14691}]","[{'number': 1, 'created': '2015-06-09 11:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/45ee7129ce800e9e38e2ef2a6c1216960560a404', 'message': ""Add error catching to the cleanup method of heat tests\n\nIf tests fails on some step it calls cleanup method that tries to\ndelete created stack, but in case if there is some problem in it\nuser won't see errors in FUEL web, that's why error catching was added.\n\nChange-Id: I93b72d24e54dde31c9dd608c98be857aa9a65657\nCloses-Bug: #1463339\n""}, {'number': 2, 'created': '2015-06-09 13:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/0a0ec547ce488a584d4a644e6d720bc61f8ffa3e', 'message': ""Add error catching to the cleanup method of heat tests\n\nIf tests fails on some step it calls cleanup method that tries to\ndelete created stack, but in case if there is some problem in it\nuser won't see errors in FUEL web, that's why error catching was added.\n\nChange-Id: I93b72d24e54dde31c9dd608c98be857aa9a65657\nCloses-Bug: #1463339\n""}, {'number': 3, 'created': '2015-06-11 09:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/875511f54202defbceac34c7846829b981ae21c8', 'message': ""Add error catching to the cleanup method of heat tests\n\nIf the test fails on some step it calls cleanup method that tries\nto delete the created stack, but in case if there is some problem\nin it user won't see errors in FUEL web, that's why error catching\nwas added.\n\nCloses-Bug: #1463339\n\nChange-Id: I93b72d24e54dde31c9dd608c98be857aa9a65657\n""}, {'number': 4, 'created': '2015-06-11 10:00:33.000000000', 'files': ['fuel_health/tests/platform_tests/test_heat.py', 'fuel_health/heatmanager.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/7d0cc3920a4961827c2acd4fb85b661e167e5ab7', 'message': ""Add error catching to the cleanup method for Heat tests\n\nIf the test fails on some step it calls cleanup method that tries\nto delete the created stack, but in case if there is some problem\nin it user won't see errors in FUEL web, that's why error catching\nwas added.\n\nCloses-Bug: #1463339\n\nChange-Id: I93b72d24e54dde31c9dd608c98be857aa9a65657\n""}]",0,189672,7d0cc3920a4961827c2acd4fb85b661e167e5ab7,33,12,4,8592,,,0,"Add error catching to the cleanup method for Heat tests

If the test fails on some step it calls cleanup method that tries
to delete the created stack, but in case if there is some problem
in it user won't see errors in FUEL web, that's why error catching
was added.

Closes-Bug: #1463339

Change-Id: I93b72d24e54dde31c9dd608c98be857aa9a65657
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/72/189672/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_health/tests/platform_tests/test_heat.py', 'fuel_health/heatmanager.py']",2,45ee7129ce800e9e38e2ef2a6c1216960560a404,bug/1463339," try: self.heat_client.stacks.delete(stack.id) except: self.fail(""Cleanup: Failed to delete stack '%s'"" % stack_name)", self.heat_client.stacks.delete(stack.id),5,2
openstack%2Fpython-glanceclient~master~Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85,openstack/python-glanceclient,master,Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85,Make glanceclient accept a session object,MERGED,2014-12-16 06:45:38.000000000,2015-06-11 15:25:28.000000000,2015-06-11 15:25:26.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 1916}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 7191}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-12-16 06:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5ccab0232b62cbe5c72f232f7f945539aa35ddd9', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 2, 'created': '2015-03-20 10:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8d1ce1f16769bd819566fd91cf6fe6fdf2935d93', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 3, 'created': '2015-04-07 01:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b0480329194ffb7c4956907c660498e0abcad9fb', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 4, 'created': '2015-04-08 02:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/9ccbdd15261c3d10e7b9539f3888da05bbfefda0', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 5, 'created': '2015-04-15 01:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1f3f3d8eddbd1c4882ba751fa83b8c435d8502b4', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 6, 'created': '2015-04-16 05:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/bec1a4b177a15b872d33e8368f7d660380a82f1c', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 7, 'created': '2015-04-28 18:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/ec3747e87d156822f8ff389c9b7446209f82e360', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 8, 'created': '2015-05-27 03:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/a9e15f4ae4991ce5ac4c1f44e0521d8c1e475502', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 9, 'created': '2015-06-03 23:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/cbe95ce1cd5c60fda2239c1c4e8351371b21ef06', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 10, 'created': '2015-06-09 03:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/1c781add8d2fe65bc7623ae88f17575381909155', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 11, 'created': '2015-06-09 21:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/dde859389c3062361eddcbe93386cbb7a8b1d73c', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 12, 'created': '2015-06-10 12:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/e89ae3fdec76873392985710882eb0a9638d4a9e', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}, {'number': 13, 'created': '2015-06-11 13:11:56.000000000', 'files': ['glanceclient/tests/unit/test_http.py', 'glanceclient/v1/client.py', 'test-requirements.txt', 'glanceclient/common/http.py', 'glanceclient/v2/client.py', 'glanceclient/client.py', 'glanceclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5ce9c7dc964be0b3e8f9f273169b77ada85cd8ec', 'message': 'Make glanceclient accept a session object\n\nTo make this work we create a different HTTPClient that extends the\nbasic keystoneclient Adapter. The Adapter is a standard set of\nparameters that all clients should know how to use like region_name and\nuser_agent. We extend this with the glance specific response\nmanipulation like loading and sending iterables.\n\nImplements: bp session-objects\nChange-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85\n'}]",26,141994,5ce9c7dc964be0b3e8f9f273169b77ada85cd8ec,65,7,13,7191,,,0,"Make glanceclient accept a session object

To make this work we create a different HTTPClient that extends the
basic keystoneclient Adapter. The Adapter is a standard set of
parameters that all clients should know how to use like region_name and
user_agent. We extend this with the glance specific response
manipulation like loading and sending iterables.

Implements: bp session-objects
Change-Id: Ie8eb4bbf7d1a037099a6d4b272cab70525fbfc85
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/94/141994/8 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/v1/client.py', 'test-requirements.txt', 'glanceclient/common/http.py', 'glanceclient/v2/client.py', 'tests/test_http.py', 'glanceclient/client.py']",6,5ccab0232b62cbe5c72f232f7f945539aa35ddd9,bp/session-objects,"def Client(version=None, endpoint=None, session=None, *args, **kwargs): if session and endpoint: msg = (""You cannot provide an endpoint URL with the session. The "" ""endpoint will be retrieved from the auth plugin's catalog"") elif not session: if version is not None: warnings.warn((""`version` keyword is being deprecated. Please pass"" "" the version as part of the URL. "" ""http://$HOST:$PORT/v$VERSION_NUMBER""), DeprecationWarning) endpoint, url_version = utils.strip_version(endpoint) if not url_version and not version: msg = (""Please provide either the version or an url with the form "" ""http://$HOST:$PORT/v$VERSION_NUMBER"") raise RuntimeError(msg) version = int(version or url_version) return client_class(endpoint, *args, session=session, **kwargs)","def Client(version=None, endpoint=None, *args, **kwargs): if version is not None: warnings.warn((""`version` keyword is being deprecated. Please pass the"" "" version as part of the URL. "" ""http://$HOST:$PORT/v$VERSION_NUMBER""), DeprecationWarning) endpoint, url_version = utils.strip_version(endpoint) if not url_version and not version: msg = (""Please provide either the version or an url with the form "" ""http://$HOST:$PORT/v$VERSION_NUMBER"") version = int(version or url_version) return client_class(endpoint, *args, **kwargs)",132,27
openstack%2Fsolum~master~I686a7c4bc4b52145f351238b62bf7ac0036693b6,openstack/solum,master,I686a7c4bc4b52145f351238b62bf7ac0036693b6,Adds app resource,ABANDONED,2015-06-10 20:57:43.000000000,2015-06-11 15:22:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-10 20:57:43.000000000', 'files': ['solum/objects/sqlalchemy/migration/alembic_migrations/versions/40df542e345_create_app_table.py', 'solum/api/controllers/v1/app.py', 'solum/objects/app.py', 'examples/apps/cherrypy.yaml', 'solum/tests/fakes.py', 'solum/api/controllers/v1/datamodel/app.py', 'solum/tests/api/controllers/v1/test_app.py', 'solum/objects/sqlalchemy/app.py', 'solum/tests/api/handlers/test_app.py', 'solum/api/handlers/app_handler.py', 'solum/tests/objects/test_app.py', 'solum/api/controllers/v1/root.py', 'solum/objects/sqlalchemy/__init__.py', 'solum/api/controllers/v1/plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/f10ac30028ad6f36e4e8af062729da9af737db17', 'message': 'Adds app resource\n\nCreates app table\nExposes app resource Create, Index, Get, Patch, and Delete\nAdds example yaml file in examples/apps/cherrypy.yaml\n\nChange-Id: I686a7c4bc4b52145f351238b62bf7ac0036693b6\n'}]",0,190348,f10ac30028ad6f36e4e8af062729da9af737db17,3,1,1,1375,,,0,"Adds app resource

Creates app table
Exposes app resource Create, Index, Get, Patch, and Delete
Adds example yaml file in examples/apps/cherrypy.yaml

Change-Id: I686a7c4bc4b52145f351238b62bf7ac0036693b6
",git fetch https://review.opendev.org/openstack/solum refs/changes/48/190348/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/objects/sqlalchemy/migration/alembic_migrations/versions/40df542e345_create_app_table.py', 'solum/api/controllers/v1/app.py', 'solum/objects/app.py', 'examples/apps/cherrypy.yaml', 'solum/tests/fakes.py', 'solum/api/controllers/v1/datamodel/app.py', 'solum/tests/api/controllers/v1/test_app.py', 'solum/objects/sqlalchemy/app.py', 'solum/tests/api/handlers/test_app.py', 'solum/api/handlers/app_handler.py', 'solum/tests/objects/test_app.py', 'solum/api/controllers/v1/root.py', 'solum/objects/sqlalchemy/__init__.py', 'solum/api/controllers/v1/plan.py']",14,f10ac30028ad6f36e4e8af062729da9af737db17,app-resource, raise exception.BadRequest(reason='No data.') raise exception.BadRequest(reason='No data.'), raise exception.BadRequest raise exception.BadRequest,748,4
openstack%2Ftripleo-ci~master~I668938cb66cd14094a9b81e4c70db5eabf381101,openstack/tripleo-ci,master,I668938cb66cd14094a9b81e4c70db5eabf381101,Revert nova swap and ephemeral BDMs patch fix,MERGED,2015-06-11 13:03:13.000000000,2015-06-11 15:15:03.000000000,2015-06-11 15:15:03.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-06-11 13:03:13.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5a0b7171a7586509dafa2f8d1027098d1b4c39cc', 'message': 'Revert nova swap and ephemeral BDMs patch fix\n\nWe think this might be causing the ephemeral partition not to show up.\n\nChange-Id: I668938cb66cd14094a9b81e4c70db5eabf381101\n'}]",0,190629,5a0b7171a7586509dafa2f8d1027098d1b4c39cc,8,3,1,360,,,0,"Revert nova swap and ephemeral BDMs patch fix

We think this might be causing the ephemeral partition not to show up.

Change-Id: I668938cb66cd14094a9b81e4c70db5eabf381101
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/29/190629/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,5a0b7171a7586509dafa2f8d1027098d1b4c39cc,nova_ephemeral_revert,#https://review.openstack.org/#/c/190622/ temprevert nova 7f8128f87f5a2fa93c857295fb7e4163986eda25 1464239 ,,3,0
openstack%2Foslo-incubator~stable%2Fjuno~I0721616ff1210028e73cacda8e07ac14276f4946,openstack/oslo-incubator,stable/juno,I0721616ff1210028e73cacda8e07ac14276f4946,Updated from global requirements,MERGED,2015-04-22 12:46:52.000000000,2015-06-11 15:08:49.000000000,2015-06-11 15:08:47.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7293}]","[{'number': 1, 'created': '2015-04-22 12:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/03cd8ac73bb8ec066bd0c440a06a8cef2b20f467', 'message': 'Updated from global requirements\n\nChange-Id: I0721616ff1210028e73cacda8e07ac14276f4946\n'}, {'number': 2, 'created': '2015-05-14 22:34:17.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b89783b42bf119abfa098dd785ce577415a32c59', 'message': 'Updated from global requirements\n\nChange-Id: I0721616ff1210028e73cacda8e07ac14276f4946\n'}]",0,176280,b89783b42bf119abfa098dd785ce577415a32c59,12,3,2,11131,,,0,"Updated from global requirements

Change-Id: I0721616ff1210028e73cacda8e07ac14276f4946
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/80/176280/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,03cd8ac73bb8ec066bd0c440a06a8cef2b20f467,openstack/requirements,"stevedore>=1.0.0,<=1.3.0 # Apache-2.0","stevedore>=1.0.0,<=1.2.0 # Apache-2.0",2,2
openstack%2Foslo-incubator~master~I201f15daa718cf3e2984bf44edde5b843d30eb66,openstack/oslo-incubator,master,I201f15daa718cf3e2984bf44edde5b843d30eb66,Updated from global requirements,MERGED,2015-06-11 00:47:40.000000000,2015-06-11 15:05:09.000000000,2015-06-11 15:05:08.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-11 00:47:40.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/de819ff5fab57f8a94cfdfee61da0a961f56bc7b', 'message': 'Updated from global requirements\n\nChange-Id: I201f15daa718cf3e2984bf44edde5b843d30eb66\n'}]",0,190430,de819ff5fab57f8a94cfdfee61da0a961f56bc7b,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I201f15daa718cf3e2984bf44edde5b843d30eb66
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/30/190430/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,de819ff5fab57f8a94cfdfee61da0a961f56bc7b,openstack/requirements,stevedore>=1.5.0 # Apache-2.0,stevedore>=1.3.0 # Apache-2.0,1,1
openstack%2Fopenstacksdk~master~I99d34acc044486c4661e198da6dc97e4eea99cf1,openstack/openstacksdk,master,I99d34acc044486c4661e198da6dc97e4eea99cf1,Add fucntional tests for servers,ABANDONED,2015-06-11 15:02:00.000000000,2015-06-11 15:03:23.000000000,,[],"[{'number': 1, 'created': '2015-06-11 15:02:00.000000000', 'files': ['openstack/tests/functional/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/20378a2abd4cdb48725b9bbc84bbee5b1aec48c7', 'message': 'Add fucntional tests for servers\n\nChange-Id: I99d34acc044486c4661e198da6dc97e4eea99cf1\n'}]",0,190679,20378a2abd4cdb48725b9bbc84bbee5b1aec48c7,2,0,1,8736,,,0,"Add fucntional tests for servers

Change-Id: I99d34acc044486c4661e198da6dc97e4eea99cf1
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/79/190679/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/compute/v2/test_server.py'],1,20378a2abd4cdb48725b9bbc84bbee5b1aec48c7,ostestr,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from openstack.compute.v2 import server from openstack.tests.functional import base class TestServer(base.BaseFunctionalTest): NAME = uuid.uuid4().hex ID = None @classmethod def setUpClass(cls): super(TestServer, cls).setUpClass() # TODO(thowe): These values should be able to be set in clouds.yaml flavor = '4' image = 'cirros-0.3.4-x86_64-uec' netid = '' if netid: args = {'networks': [{""uuid"": netid}]} else: args = {} sot = cls.conn.compute.create_server( name=cls.NAME, flavor=flavor, image=image, **args) assert isinstance(sot, server.Server) cls.assertIs(cls.NAME, sot.name) cls.ID = sot.id @classmethod def tearDownClass(cls): sot = cls.conn.compute.delete_server(cls.ID) cls.assertIs(None, sot) def test_find(self): sot = self.conn.compute.find_server(self.NAME) self.assertEqual(self.ID, sot.id) def test_get(self): sot = self.conn.compute.get_server(self.ID) self.assertEqual(self.NAME, sot.name) self.assertEqual(self.ID, sot.id) def test_list(self): names = [o.name for o in self.conn.compute.servers()] self.assertIn(self.NAME, names) ",,57,0
openstack%2Foslo-cookiecutter~master~Id4d0f9673d1fa38f19260bd8576c03e5855cd01d,openstack/oslo-cookiecutter,master,Id4d0f9673d1fa38f19260bd8576c03e5855cd01d,Include examples in openstack-common.conf,MERGED,2015-06-09 15:42:47.000000000,2015-06-11 14:59:05.000000000,2015-06-11 14:59:04.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-09 15:42:47.000000000', 'files': ['oslo.{{cookiecutter.module_name}}/openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/oslo-cookiecutter/commit/07fa3fad30d507e4336cda2b4452a7ab28987cdd', 'message': ""Include examples in openstack-common.conf\n\nAdds some commented out examples to openstack-common.conf so users\ndon't have to go look up the syntax somewhere else.\n\nChange-Id: Id4d0f9673d1fa38f19260bd8576c03e5855cd01d\n""}]",0,189780,07fa3fad30d507e4336cda2b4452a7ab28987cdd,7,3,1,6928,,,0,"Include examples in openstack-common.conf

Adds some commented out examples to openstack-common.conf so users
don't have to go look up the syntax somewhere else.

Change-Id: Id4d0f9673d1fa38f19260bd8576c03e5855cd01d
",git fetch https://review.opendev.org/openstack/oslo-cookiecutter refs/changes/80/189780/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo.{{cookiecutter.module_name}}/openstack-common.conf'],1,07fa3fad30d507e4336cda2b4452a7ab28987cdd,examples,# The list of scripts and modules to copy from oslo-incubator # For example: # script=tools/with_venv.sh # module=service,,4,0
openstack%2Fcinder~master~I76a736bd12372cff6c7fb3936b0eeb520a96ba08,openstack/cinder,master,I76a736bd12372cff6c7fb3936b0eeb520a96ba08,Merge tag '2015.1.0',MERGED,2015-04-30 23:25:26.000000000,2015-06-11 14:49:22.000000000,2015-06-10 01:37:25.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5263}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2015-04-30 23:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b3b86be19158a076795015f089f0a0707cb88226', 'message': ""Merge tag '2015.1.0'\n\nCinder 2015.1.0\n\nChange-Id: I76a736bd12372cff6c7fb3936b0eeb520a96ba08\n""}, {'number': 2, 'created': '2015-06-09 17:40:13.000000000', 'files': ['cinder/locale/cinder.pot', 'requirements.txt', '.gitreview', 'cinder/locale/cinder-log-error.pot', 'cinder/locale/cinder-log-info.pot', 'cinder/tests/api/contrib/test_quotas.py', 'cinder/locale/cinder-log-warning.pot', 'cinder/tests/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cabe7c1a1d5b35e58fc4ed34b12fcccd4416835e', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I76a736bd12372cff6c7fb3936b0eeb520a96ba08\n""}]",0,179287,cabe7c1a1d5b35e58fc4ed34b12fcccd4416835e,48,25,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I76a736bd12372cff6c7fb3936b0eeb520a96ba08
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/179287/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/locale/cinder.pot', 'requirements.txt', '.gitreview', 'cinder/locale/cinder-log-error.pot', 'cinder/locale/cinder-log-info.pot', 'cinder/tests/api/contrib/test_quotas.py', 'cinder/locale/cinder-log-warning.pot', 'cinder/tests/image/test_glance.py']",8,b3b86be19158a076795015f089f0a0707cb88226,merge/release-tag,,"<<<<<<< HEAD (b45528 Merge ""Add retry to lvm delete"") ======= # Copyright 2011 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime import glanceclient.exc import mock from oslo_config import cfg from cinder import context from cinder import exception from cinder.image import glance from cinder import test from cinder.tests.glance import stubs as glance_stubs CONF = cfg.CONF class NullWriter(object): """"""Used to test ImageService.get which takes a writer object."""""" def write(self, *arg, **kwargs): pass class TestGlanceSerializer(test.TestCase): def test_serialize(self): metadata = {'name': 'image1', 'is_public': True, 'foo': 'bar', 'properties': { 'prop1': 'propvalue1', 'mappings': [ {'virtual': 'aaa', 'device': 'bbb'}, {'virtual': 'xxx', 'device': 'yyy'}], 'block_device_mapping': [ {'virtual_device': 'fake', 'device_name': '/dev/fake'}, {'virtual_device': 'ephemeral0', 'device_name': '/dev/fake0'}]}} converted_expected = { 'name': 'image1', 'is_public': True, 'foo': 'bar', 'properties': { 'prop1': 'propvalue1', 'mappings': '[{""device"": ""bbb"", ""virtual"": ""aaa""}, ' '{""device"": ""yyy"", ""virtual"": ""xxx""}]', 'block_device_mapping': '[{""virtual_device"": ""fake"", ""device_name"": ""/dev/fake""}, ' '{""virtual_device"": ""ephemeral0"", ' '""device_name"": ""/dev/fake0""}]'}} converted = glance._convert_to_string(metadata) self.assertEqual(converted, converted_expected) self.assertEqual(glance._convert_from_string(converted), metadata) class TestGlanceImageService(test.TestCase): """"""Tests the Glance image service. At a high level, the translations involved are: 1. Glance -> ImageService - This is needed so we can support multiple ImageServices (Glance, Local, etc) 2. ImageService -> API - This is needed so we can support multple APIs (OpenStack, EC2) """""" NOW_GLANCE_OLD_FORMAT = ""2010-10-11T10:30:22"" NOW_GLANCE_FORMAT = ""2010-10-11T10:30:22.000000"" class tzinfo(datetime.tzinfo): @staticmethod def utcoffset(*args, **kwargs): return datetime.timedelta() NOW_DATETIME = datetime.datetime(2010, 10, 11, 10, 30, 22, tzinfo=tzinfo()) def setUp(self): super(TestGlanceImageService, self).setUp() client = glance_stubs.StubGlanceClient() self.service = self._create_image_service(client) self.context = context.RequestContext('fake', 'fake', auth_token=True) self.stubs.Set(glance.time, 'sleep', lambda s: None) def _create_image_service(self, client): def _fake_create_glance_client(context, netloc, use_ssl, version): return client self.stubs.Set(glance, '_create_glance_client', _fake_create_glance_client) client_wrapper = glance.GlanceClientWrapper('fake', 'fake_host', 9292) return glance.GlanceImageService(client=client_wrapper) @staticmethod def _make_fixture(**kwargs): fixture = {'name': None, 'properties': {}, 'status': None, 'is_public': None} fixture.update(kwargs) return fixture def _make_datetime_fixture(self): return self._make_fixture(created_at=self.NOW_GLANCE_FORMAT, updated_at=self.NOW_GLANCE_FORMAT, deleted_at=self.NOW_GLANCE_FORMAT) def test_create_with_instance_id(self): """"""Ensure instance_id is persisted as an image-property."""""" fixture = {'name': 'test image', 'is_public': False, 'properties': {'instance_id': '42', 'user_id': 'fake'}} image_id = self.service.create(self.context, fixture)['id'] image_meta = self.service.show(self.context, image_id) expected = { 'id': image_id, 'name': 'test image', 'is_public': False, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {'instance_id': '42', 'user_id': 'fake'}, 'owner': None, } self.assertDictMatch(image_meta, expected) image_metas = self.service.detail(self.context) self.assertDictMatch(image_metas[0], expected) def test_create_without_instance_id(self): """"""Test Creating images without instance_id. Ensure we can create an image without having to specify an instance_id. Public images are an example of an image not tied to an instance. """""" fixture = {'name': 'test image', 'is_public': False} image_id = self.service.create(self.context, fixture)['id'] expected = { 'id': image_id, 'name': 'test image', 'is_public': False, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {}, 'owner': None, } actual = self.service.show(self.context, image_id) self.assertDictMatch(actual, expected) def test_create(self): fixture = self._make_fixture(name='test image') num_images = len(self.service.detail(self.context)) image_id = self.service.create(self.context, fixture)['id'] self.assertIsNotNone(image_id) self.assertEqual(num_images + 1, len(self.service.detail(self.context))) def test_create_and_show_non_existing_image(self): fixture = self._make_fixture(name='test image') image_id = self.service.create(self.context, fixture)['id'] self.assertIsNotNone(image_id) self.assertRaises(exception.ImageNotFound, self.service.show, self.context, 'bad image id') def test_detail_private_image(self): fixture = self._make_fixture(name='test image') fixture['is_public'] = False properties = {'owner_id': 'proj1'} fixture['properties'] = properties self.service.create(self.context, fixture)['id'] proj = self.context.project_id self.context.project_id = 'proj1' image_metas = self.service.detail(self.context) self.context.project_id = proj self.assertEqual(1, len(image_metas)) self.assertEqual(image_metas[0]['name'], 'test image') self.assertEqual(image_metas[0]['is_public'], False) def test_detail_marker(self): fixtures = [] ids = [] for i in range(10): fixture = self._make_fixture(name='TestImage %d' % (i)) fixtures.append(fixture) ids.append(self.service.create(self.context, fixture)['id']) image_metas = self.service.detail(self.context, marker=ids[1]) self.assertEqual(len(image_metas), 8) i = 2 for meta in image_metas: expected = { 'id': ids[i], 'status': None, 'is_public': None, 'name': 'TestImage %d' % (i), 'properties': {}, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'owner': None, } self.assertDictMatch(meta, expected) i = i + 1 def test_detail_limit(self): fixtures = [] ids = [] for i in range(10): fixture = self._make_fixture(name='TestImage %d' % (i)) fixtures.append(fixture) ids.append(self.service.create(self.context, fixture)['id']) image_metas = self.service.detail(self.context, limit=5) self.assertEqual(len(image_metas), 5) def test_detail_default_limit(self): fixtures = [] ids = [] for i in range(10): fixture = self._make_fixture(name='TestImage %d' % (i)) fixtures.append(fixture) ids.append(self.service.create(self.context, fixture)['id']) image_metas = self.service.detail(self.context) for i, meta in enumerate(image_metas): self.assertEqual(meta['name'], 'TestImage %d' % (i)) def test_detail_marker_and_limit(self): fixtures = [] ids = [] for i in range(10): fixture = self._make_fixture(name='TestImage %d' % (i)) fixtures.append(fixture) ids.append(self.service.create(self.context, fixture)['id']) image_metas = self.service.detail(self.context, marker=ids[3], limit=5) self.assertEqual(len(image_metas), 5) i = 4 for meta in image_metas: expected = { 'id': ids[i], 'status': None, 'is_public': None, 'name': 'TestImage %d' % (i), 'properties': {}, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'owner': None, } self.assertDictMatch(meta, expected) i = i + 1 def test_detail_invalid_marker(self): fixtures = [] ids = [] for i in range(10): fixture = self._make_fixture(name='TestImage %d' % (i)) fixtures.append(fixture) ids.append(self.service.create(self.context, fixture)['id']) self.assertRaises(exception.Invalid, self.service.detail, self.context, marker='invalidmarker') def test_update(self): fixture = self._make_fixture(name='test image') image = self.service.create(self.context, fixture) image_id = image['id'] fixture['name'] = 'new image name' self.service.update(self.context, image_id, fixture) new_image_data = self.service.show(self.context, image_id) self.assertEqual('new image name', new_image_data['name']) def test_delete(self): fixture1 = self._make_fixture(name='test image 1') fixture2 = self._make_fixture(name='test image 2') fixtures = [fixture1, fixture2] num_images = len(self.service.detail(self.context)) self.assertEqual(0, num_images) ids = [] for fixture in fixtures: new_id = self.service.create(self.context, fixture)['id'] ids.append(new_id) num_images = len(self.service.detail(self.context)) self.assertEqual(2, num_images) self.service.delete(self.context, ids[0]) num_images = len(self.service.detail(self.context)) self.assertEqual(1, num_images) def test_show_passes_through_to_client(self): fixture = self._make_fixture(name='image1', is_public=True) image_id = self.service.create(self.context, fixture)['id'] image_meta = self.service.show(self.context, image_id) expected = { 'id': image_id, 'name': 'image1', 'is_public': True, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {}, 'owner': None, } self.assertEqual(image_meta, expected) def test_show_raises_when_no_authtoken_in_the_context(self): fixture = self._make_fixture(name='image1', is_public=False, properties={'one': 'two'}) image_id = self.service.create(self.context, fixture)['id'] self.context.auth_token = False self.assertRaises(exception.ImageNotFound, self.service.show, self.context, image_id) def test_detail_passes_through_to_client(self): fixture = self._make_fixture(name='image10', is_public=True) image_id = self.service.create(self.context, fixture)['id'] image_metas = self.service.detail(self.context) expected = [ { 'id': image_id, 'name': 'image10', 'is_public': True, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {}, 'owner': None, }, ] self.assertEqual(image_metas, expected) def test_show_makes_datetimes(self): fixture = self._make_datetime_fixture() image_id = self.service.create(self.context, fixture)['id'] image_meta = self.service.show(self.context, image_id) self.assertEqual(image_meta['created_at'], self.NOW_DATETIME) self.assertEqual(image_meta['updated_at'], self.NOW_DATETIME) def test_detail_makes_datetimes(self): fixture = self._make_datetime_fixture() self.service.create(self.context, fixture) image_meta = self.service.detail(self.context)[0] self.assertEqual(image_meta['created_at'], self.NOW_DATETIME) self.assertEqual(image_meta['updated_at'], self.NOW_DATETIME) def test_download_with_retries(self): tries = [0] class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that fails the first time, then succeeds."""""" def get(self, image_id): if tries[0] == 0: tries[0] = 1 raise glanceclient.exc.ServiceUnavailable('') else: return {} client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter writer = NullWriter() # When retries are disabled, we should get an exception self.flags(glance_num_retries=0) self.assertRaises(exception.GlanceConnectionFailed, service.download, self.context, image_id, writer) # Now lets enable retries. No exception should happen now. tries = [0] self.flags(glance_num_retries=1) service.download(self.context, image_id, writer) def test_client_forbidden_converts_to_imagenotauthed(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a Forbidden exception."""""" def get(self, image_id): raise glanceclient.exc.Forbidden(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter writer = NullWriter() self.assertRaises(exception.ImageNotAuthorized, service.download, self.context, image_id, writer) def test_client_httpforbidden_converts_to_imagenotauthed(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a HTTPForbidden exception."""""" def get(self, image_id): raise glanceclient.exc.HTTPForbidden(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter writer = NullWriter() self.assertRaises(exception.ImageNotAuthorized, service.download, self.context, image_id, writer) def test_client_notfound_converts_to_imagenotfound(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a NotFound exception."""""" def get(self, image_id): raise glanceclient.exc.NotFound(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter writer = NullWriter() self.assertRaises(exception.ImageNotFound, service.download, self.context, image_id, writer) def test_client_httpnotfound_converts_to_imagenotfound(self): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that raises a HTTPNotFound exception."""""" def get(self, image_id): raise glanceclient.exc.HTTPNotFound(image_id) client = MyGlanceStubClient() service = self._create_image_service(client) image_id = 1 # doesn't matter writer = NullWriter() self.assertRaises(exception.ImageNotFound, service.download, self.context, image_id, writer) def test_glance_client_image_id(self): fixture = self._make_fixture(name='test image') image_id = self.service.create(self.context, fixture)['id'] (_service, same_id) = glance.get_remote_image_service(self.context, image_id) self.assertEqual(same_id, image_id) def test_glance_client_image_ref(self): fixture = self._make_fixture(name='test image') image_id = self.service.create(self.context, fixture)['id'] image_url = 'http://something-less-likely/%s' % image_id (service, same_id) = glance.get_remote_image_service(self.context, image_url) self.assertEqual(same_id, image_id) self.assertEqual(service._client.netloc, 'something-less-likely') for ipv6_url in ('[::1]', '::1', '[::1]:444'): image_url = 'http://%s/%s' % (ipv6_url, image_id) (service, same_id) = glance.get_remote_image_service(self.context, image_url) self.assertEqual(same_id, image_id) self.assertEqual(service._client.netloc, ipv6_url) def test_extracting_missing_attributes(self): """"""Verify behavior from glance objects that are missing attributes This fakes the image class and is missing the checksum and name attribute as the client would return if they're not set in the database. Regression test for bug #1308058. """""" class MyFakeGlanceImage(glance_stubs.FakeImage): def __init__(self, metadata): IMAGE_ATTRIBUTES = ['size', 'disk_format', 'owner', 'container_format', 'id', 'created_at', 'updated_at', 'deleted', 'status', 'min_disk', 'min_ram', 'is_public'] raw = dict.fromkeys(IMAGE_ATTRIBUTES) raw.update(metadata) self.__dict__['raw'] = raw metadata = { 'id': 1, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, } image = MyFakeGlanceImage(metadata) actual = glance._extract_attributes(image) expected = { 'id': 1, 'name': None, 'is_public': None, 'size': None, 'min_disk': None, 'min_ram': None, 'disk_format': None, 'container_format': None, 'checksum': None, 'created_at': self.NOW_DATETIME, 'updated_at': self.NOW_DATETIME, 'deleted_at': None, 'deleted': None, 'status': None, 'properties': {}, 'owner': None, } self.assertEqual(actual, expected) @mock.patch('cinder.image.glance.CONF') def test_extracting_v2_boot_properties(self, config): config.glance_api_version = 2 attributes = ['size', 'disk_format', 'owner', 'container_format', 'checksum', 'id', 'name', 'created_at', 'updated_at', 'deleted', 'status', 'min_disk', 'min_ram', 'is_public'] metadata = { 'id': 1, 'size': 2, 'min_disk': 2, 'min_ram': 2, 'kernel_id': 'foo', 'ramdisk_id': 'bar', } class FakeSchema(object): def __init__(self, base): self.base = base def is_base_property(self, key): if key in self.base: return True else: return False image = glance_stubs.FakeImage(metadata) client = glance_stubs.StubGlanceClient() service = self._create_image_service(client) service._image_schema = FakeSchema(attributes) actual = service._translate_from_glance(image) expected = { 'id': 1, 'name': None, 'is_public': None, 'size': 2, 'min_disk': 2, 'min_ram': 2, 'disk_format': None, 'container_format': None, 'checksum': None, 'deleted': None, 'deleted_at': None, 'status': None, 'properties': {'kernel_id': 'foo', 'ramdisk_id': 'bar'}, 'owner': None, 'created_at': None, 'updated_at': None } self.assertEqual(expected, actual) class TestGlanceClientVersion(test.TestCase): """"""Tests the version of the glance client generated."""""" @mock.patch('cinder.image.glance.glanceclient.Client') def test_glance_version_by_flag(self, _mockglanceclient): """"""Test glance version set by flag is honoured."""""" glance.GlanceClientWrapper('fake', 'fake_host', 9292) self.assertEqual('1', _mockglanceclient.call_args[0][0]) self.flags(glance_api_version=2) glance.GlanceClientWrapper('fake', 'fake_host', 9292) self.assertEqual('2', _mockglanceclient.call_args[0][0]) CONF.reset() @mock.patch('cinder.image.glance.glanceclient.Client') def test_glance_version_by_arg(self, _mockglanceclient): """"""Test glance version set by arg to GlanceClientWrapper"""""" glance.GlanceClientWrapper('fake', 'fake_host', 9292, version=1) self.assertEqual('1', _mockglanceclient.call_args[0][0]) glance.GlanceClientWrapper('fake', 'fake_host', 9292, version=2) self.assertEqual('2', _mockglanceclient.call_args[0][0]) def _create_failing_glance_client(info): class MyGlanceStubClient(glance_stubs.StubGlanceClient): """"""A client that fails the first time, then succeeds."""""" def get(self, image_id): info['num_calls'] += 1 if info['num_calls'] == 1: raise glanceclient.exc.ServiceUnavailable('') return {} return MyGlanceStubClient() class TestGlanceImageServiceClient(test.TestCase): def setUp(self): super(TestGlanceImageServiceClient, self).setUp() self.context = context.RequestContext('fake', 'fake', auth_token=True) self.stubs.Set(glance.time, 'sleep', lambda s: None) def test_create_glance_client(self): self.flags(auth_strategy='keystone') self.flags(glance_request_timeout=60) class MyGlanceStubClient(object): def __init__(inst, version, *args, **kwargs): self.assertEqual('1', version) self.assertEqual(""http://fake_host:9292"", args[0]) self.assertTrue(kwargs['token']) self.assertEqual(60, kwargs['timeout']) self.stubs.Set(glance.glanceclient, 'Client', MyGlanceStubClient) client = glance._create_glance_client(self.context, 'fake_host:9292', False) self.assertIsInstance(client, MyGlanceStubClient) def test_create_glance_client_auth_strategy_is_not_keystone(self): self.flags(auth_strategy='noauth') self.flags(glance_request_timeout=60) class MyGlanceStubClient(object): def __init__(inst, version, *args, **kwargs): self.assertEqual('1', version) self.assertEqual('http://fake_host:9292', args[0]) self.assertNotIn('token', kwargs) self.assertEqual(60, kwargs['timeout']) self.stubs.Set(glance.glanceclient, 'Client', MyGlanceStubClient) client = glance._create_glance_client(self.context, 'fake_host:9292', False) self.assertIsInstance(client, MyGlanceStubClient) def test_create_glance_client_glance_request_default_timeout(self): self.flags(auth_strategy='keystone') self.flags(glance_request_timeout=None) class MyGlanceStubClient(object): def __init__(inst, version, *args, **kwargs): self.assertEqual(""1"", version) self.assertEqual(""http://fake_host:9292"", args[0]) self.assertTrue(kwargs['token']) self.assertNotIn('timeout', kwargs) self.stubs.Set(glance.glanceclient, 'Client', MyGlanceStubClient) client = glance._create_glance_client(self.context, 'fake_host:9292', False) self.assertIsInstance(client, MyGlanceStubClient) >>>>>>> BRANCH (5987bb Add external genconfig calls) ",752,2538
openstack%2Ftelemetry-specs~master~I9d75b2e332c25c8968fbe010212e87cbaa8977cb,openstack/telemetry-specs,master,I9d75b2e332c25c8968fbe010212e87cbaa8977cb,remove pagination effort,MERGED,2015-06-11 03:48:28.000000000,2015-06-11 14:49:20.000000000,2015-06-11 14:49:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-06-11 03:48:28.000000000', 'files': ['specs/liberty/ceilometer-pagination.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/cd9ea1c2cbe91ded939cf4a2aaef3e2fa3632207', 'message': 'remove pagination effort\n\nChange-Id: I9d75b2e332c25c8968fbe010212e87cbaa8977cb\n'}]",0,190471,cd9ea1c2cbe91ded939cf4a2aaef3e2fa3632207,7,3,1,6537,,,0,"remove pagination effort

Change-Id: I9d75b2e332c25c8968fbe010212e87cbaa8977cb
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/71/190471/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/ceilometer-pagination.rst'],1,cd9ea1c2cbe91ded939cf4a2aaef3e2fa3632207,remove-pagination,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== Support paginate for all resource list APIs =========================================== https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-events-pagination This blueprint adds support to the generic resource listing call for limit marker, and sort_dir(sorted by timestamp) and groupby(especially by event types) filters, allowing users of the API to retrieve a subset of resources or provide a grouping return. Problem description =================== It is now highly probable that a event-list call could end up attempting to return hundreds of events. The event-list API with no pagination is not easy to use, and may return 500 error if the response is too large. Actually, there is already a blueprint[2] for pagination of ceilometer APIs proposed by Fengqian Gao<fengqian.gao@intel.com>. The blueprint has finished some works, but didn't finish all the proposed goals. Since the assignee is no longer working on OpenStack anymore, I would like to continue the uncompleted items of the blueprint and add the alarm/resource/meter/sample pagination as the proposed changes to this spec. Proposed change =============== 1. We should support event pagination with limit and marker query parameters. Additionally, we should allow users specifying the sort_dir('asc' or 'desc') of the return events, and support the groupby filter of listing events. - limit: the number of events to list - marker: the message_id of the last item in the previous page - sort_dir: the direction of the sorting, 'asc' or 'desc', 'desc' as default - sort_key: the key of the sorting, such as ""generated"" of event. 2. In storage layer, for alarm and event feature has dedicated storage implementation, so this blueprint will propose to construct pagination query, marker query, sort query methods base on different storage backends (sqlalchemy, mongodb, hbase, db2) and different data model(alarm data, event data, metering data), this will continue the implemented parts by Fengqian Gao. 3. To continue the works blueprint[2] has proposed, this blueprint will also propose implement alarm/resource/meter/sample pagination of in ceilometer, like the event pagination mentioned above. There is a mail thread that has discussed the implementation of this blueprint[3]. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- A example of Restful API of event pagination:: GET /v2/events?limit=2&sort_key=generated&sort_dir=dsc Response: 200 OK RESP BODY: [{ ""traits"": [{ ""type"": ""string"", ""name"": ""state"", ""value"": ""active"" },...], ""generated"": ""2014-10-12T10:00:13.800050"", ""message_id"": ""ad39e927-e68e-48ef-9a05-281298dc142a"", ""event_type"": ""compute.instance.delete.start"" }, { ""traits"": [{ ""type"": ""string"", ""name"": ""state"", ""value"": ""active"" },...], ""generated"": ""2014-10-12T10:00:13.357174"", ""message_id"": ""bf13223c-0d61-4759-8e9a-dc754da833eb"", ""event_type"": ""compute.instance.update"" }] Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: liusheng<liusheng@huawei.com> Other contributors: ZhiQiang Fan<aji.zqfan@gmail.com> fengqian-gao<fengqian.gao@intel.com> Ongoing maintainer: liusheng<liusheng@huawei.com> Work Items ---------- - Implement pagination/marker/sort query base on the implementation in oslo: *oslo.db.utils:paginate_query* for alarm/event/metering/resource - Complete pagination/marker/sort query to continue the completed parts(by Fengqian Gao) in impl_mongodb - Implement the pagination/marker query constructor methods in impl_db2 - Implement pagination/marker/sort query for alarm/event/metering/resource in impl_db2 (continue the Fengqian Gao's works) - Implement the pagination/marker/sort query constructor methods in impl_hbase - Implement pagination/marker/sort query for alarm/event/metering/resource in impl_hbase - Implement the API pagination/marker/sort query support for alarm/event/resource/meter/sample Future lifecycle ================ None Dependencies ============ None Testing ======= Add tempest api tests and scenario tests to exercise pagination in ceilometer Documentation Impact ==================== Update the relevant documentation about this api change References ========== [1] https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-events-pagination [2] https://blueprints.launchpad.net/ceilometer/+spec/paginate-db-search [3] http://lists.openstack.org/pipermail/openstack-dev/2014-January/024687.html [4] https://review.openstack.org/#/c/128418/ ",0,198
openstack%2Fneutron~master~I6738ff6b73bd0b943cec32f14ccb8946ba28d2e3,openstack/neutron,master,I6738ff6b73bd0b943cec32f14ccb8946ba28d2e3,Correct indentation in neutron.api.v2.attributes,MERGED,2015-06-10 20:29:23.000000000,2015-06-11 14:48:10.000000000,2015-06-11 04:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 6524}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-10 20:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8e41639f65415f884fc54971bb9914f3f32361b', 'message': 'Correct indentation in neutron.api.v2.attributes\n\nThis change corrects subnetpool resource definition indentation in\nneutron.api.v2.attributes.\n\nChange-Id: I6738ff6b73bd0b943cec32f14ccb8946ba28d2e3\n'}, {'number': 2, 'created': '2015-06-10 20:41:52.000000000', 'files': ['neutron/api/v2/attributes.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c8a19ba4032f98ecbffe53c4e731587550ded96', 'message': 'Correct indentation in neutron.api.v2.attributes\n\nThis change corrects subnetpool resource definition indentation in\nneutron.api.v2.attributes.\n\nChange-Id: I6738ff6b73bd0b943cec32f14ccb8946ba28d2e3\n'}]",0,190339,9c8a19ba4032f98ecbffe53c4e731587550ded96,33,19,2,8124,,,0,"Correct indentation in neutron.api.v2.attributes

This change corrects subnetpool resource definition indentation in
neutron.api.v2.attributes.

Change-Id: I6738ff6b73bd0b943cec32f14ccb8946ba28d2e3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/190339/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/v2/attributes.py'],1,e8e41639f65415f884fc54971bb9914f3f32361b,bug/1404093," 'allow_put': True, 'validate': {'type:non_negative': None}, 'convert_to': convert_to_int, 'default': ATTR_NOT_SPECIFIED, 'is_visible': True}, 'allow_put': True, 'default': ATTR_NOT_SPECIFIED, 'validate': {'type:non_negative': None}, 'convert_to': convert_to_int, 'is_visible': True}, 'allow_put': True, 'default': ATTR_NOT_SPECIFIED, 'validate': {'type:non_negative': None}, 'convert_to': convert_to_int, 'is_visible': True},"," 'allow_put': True, 'validate': {'type:non_negative': None}, 'convert_to': convert_to_int, 'default': ATTR_NOT_SPECIFIED, 'is_visible': True}, 'allow_put': True, 'default': ATTR_NOT_SPECIFIED, 'validate': {'type:non_negative': None}, 'convert_to': convert_to_int, 'is_visible': True}, 'allow_put': True, 'default': ATTR_NOT_SPECIFIED, 'validate': {'type:non_negative': None}, 'convert_to': convert_to_int, 'is_visible': True},",15,15
openstack%2Fcinder~master~I16744c997f71f3680b2e12aaee8631f0e6b6b3d5,openstack/cinder,master,I16744c997f71f3680b2e12aaee8631f0e6b6b3d5,Merge tag '2014.2',MERGED,2014-10-16 13:26:04.000000000,2015-06-11 14:44:54.000000000,2015-06-10 05:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 5263}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2014-10-16 13:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7427d8c6e35a6ed9ffff911a6353a79afc82c3c', 'message': ""Merge tag '2014.2'\n\nCinder 2014.2\n\nChange-Id: I16744c997f71f3680b2e12aaee8631f0e6b6b3d5\n""}, {'number': 2, 'created': '2015-06-09 16:33:49.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/test_netapp_eseries_iscsi.py', 'cinder/tests/test_vmware_volumeops.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/tests/test_image_utils.py', 'cinder/tests/test_volume.py', 'cinder/tests/test_zfssa.py', 'cinder/locale/cinder.pot', 'cinder/volume/drivers/glusterfs.py', 'requirements.txt', 'cinder/tests/test_smbfs.py', 'cinder/volume/drivers/vmware/error_util.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/smbfs.py', 'cinder/tests/brick/test_brick_connector.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/brick/initiator/connector.py', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/eqlx.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/tests/volume/drivers/netapp/test_iscsi.py', 'cinder/openstack/common/processutils.py', 'cinder/tests/test_storwize_svc.py', 'cinder/volume/utils.py', 'cinder/image/image_utils.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/test_vmware_vmdk.py', 'cinder/tests/test_volume_utils.py', 'cinder/utils.py', 'cinder/volume/drivers/remotefs.py', 'cinder/volume/drivers/zfssa/zfssaiscsi.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/66494f54112fdfa135b3974c75aa388c8d1fb49e', 'message': ""Merge tag '2014.2'\n\nThis is a null-merge of the 2014.2 release tag back into the\nmaster branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I16744c997f71f3680b2e12aaee8631f0e6b6b3d5\n""}]",0,128920,66494f54112fdfa135b3974c75aa388c8d1fb49e,45,23,2,11131,,,0,"Merge tag '2014.2'

This is a null-merge of the 2014.2 release tag back into the
master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I16744c997f71f3680b2e12aaee8631f0e6b6b3d5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/128920/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/locale/cinder.pot', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/iscsi.py', 'cinder/tests/test_storwize_svc.py']",4,d7427d8c6e35a6ed9ffff911a6353a79afc82c3c,merge/release-tag,,"<<<<<<< HEAD (89ba69 Merge ""Fix display name change during backup restore"")======= >>>>>>> BRANCH (be3d46 Fix LVM iSCSI driver tgtadm CHAP authentication)",3,597
openstack%2Foperations-guide~master~Ifc371a830650e2a6a99f6e3dbcac003079afaf67,openstack/operations-guide,master,Ifc371a830650e2a6a99f6e3dbcac003079afaf67,Updated from openstack-manuals,MERGED,2015-06-11 10:43:12.000000000,2015-06-11 14:44:45.000000000,2015-06-11 14:44:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 10:43:12.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/1625a4e39233bea77aa22350a3826f001ee5e3b5', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ifc371a830650e2a6a99f6e3dbcac003079afaf67\n'}]",0,190573,1625a4e39233bea77aa22350a3826f001ee5e3b5,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ifc371a830650e2a6a99f6e3dbcac003079afaf67
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/73/190573/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,1625a4e39233bea77aa22350a3826f001ee5e3b5,openstack/openstack-manuals," into an address that is easier to remember. For example, translating"," into an address that is easier to remember For example, translating",1,1
openstack%2Fapi-site~master~I449c76903258d39c00342c137630b2055bbbe79b,openstack/api-site,master,I449c76903258d39c00342c137630b2055bbbe79b,Updated from openstack-manuals,MERGED,2015-06-11 10:43:03.000000000,2015-06-11 14:41:29.000000000,2015-06-11 14:41:27.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 10:43:03.000000000', 'files': ['firstapp/source/imported/glossary.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/d6805ec89d275143b1e042ad06dba637cf231948', 'message': 'Updated from openstack-manuals\n\nChange-Id: I449c76903258d39c00342c137630b2055bbbe79b\n'}]",0,190572,d6805ec89d275143b1e042ad06dba637cf231948,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I449c76903258d39c00342c137630b2055bbbe79b
",git fetch https://review.opendev.org/openstack/api-site refs/changes/72/190572/1 && git format-patch -1 --stdout FETCH_HEAD,['firstapp/source/imported/glossary.rst'],1,d6805ec89d275143b1e042ad06dba637cf231948,openstack/openstack-manuals," into an address that is easier to remember. For example, translating"," into an address that is easier to remember For example, translating",1,1
openstack%2Fswift~master~Ie637ed3458c7ff56c26834bca73203ed55604d74,openstack/swift,master,Ie637ed3458c7ff56c26834bca73203ed55604d74,Add six requirement,MERGED,2015-06-08 22:23:35.000000000,2015-06-11 14:38:12.000000000,2015-06-11 14:38:10.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 6968}, {'_account_id': 9107}, {'_account_id': 12193}, {'_account_id': 14867}, {'_account_id': 16206}]","[{'number': 1, 'created': '2015-06-08 22:23:35.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/swift/commit/5ad369c1cb0f480b164a5b5e7eb194081835c266', 'message': 'Add six requirement\n\nThe six module is needed to add Python 3 support to Swift.\n\nChange-Id: Ie637ed3458c7ff56c26834bca73203ed55604d74\n'}]",0,189495,5ad369c1cb0f480b164a5b5e7eb194081835c266,20,7,1,9107,,,0,"Add six requirement

The six module is needed to add Python 3 support to Swift.

Change-Id: Ie637ed3458c7ff56c26834bca73203ed55604d74
",git fetch https://review.opendev.org/openstack/swift refs/changes/95/189495/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5ad369c1cb0f480b164a5b5e7eb194081835c266,py3,six>=1.9.0,,1,0
openstack%2Ffuel-web~stable%2F6.1~I58dd0ebd6de610448bf297d0bd97c6a334f6abc0,openstack/fuel-web,stable/6.1,I58dd0ebd6de610448bf297d0bd97c6a334f6abc0,Do not run mongo checks for old releases,MERGED,2015-06-11 14:10:52.000000000,2015-06-11 14:37:06.000000000,2015-06-11 14:37:06.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-06-11 14:10:52.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/objects/release.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e42b7db476b0ace256d09d95d49b184d555095b4', 'message': ""Do not run mongo checks for old releases\n\nIn Fuel releases before 6.1 we didn't have 'external mongo' feature,\nand therefore running mongo checks is invalid operation.\n\nCloses-Bug: #1463880\n\nChange-Id: I58dd0ebd6de610448bf297d0bd97c6a334f6abc0\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}]",0,190648,e42b7db476b0ace256d09d95d49b184d555095b4,12,6,1,10391,,,0,"Do not run mongo checks for old releases

In Fuel releases before 6.1 we didn't have 'external mongo' feature,
and therefore running mongo checks is invalid operation.

Closes-Bug: #1463880

Change-Id: I58dd0ebd6de610448bf297d0bd97c6a334f6abc0
Signed-off-by: Igor Kalnitsky <igor@kalnitsky.org>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/48/190648/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/objects/release.py']",4,e42b7db476b0ace256d09d95d49b184d555095b4,," def is_external_mongo_enabled(cls, instance): """"""Check if external mongo is available for release :param instance: a Release instance :returns: boolean """""" return (StrictVersion(instance.fuel_version) >= StrictVersion(consts.FUEL_EXTERNAL_MONGO)) @classmethod",,55,1
openstack%2Ffuel-web~stable%2F6.1~I449d23cf5e563b9de386beb249437bbf98db47f3,openstack/fuel-web,stable/6.1,I449d23cf5e563b9de386beb249437bbf98db47f3,Pin upper bound of python-cinderclient version,MERGED,2015-06-11 14:16:19.000000000,2015-06-11 14:33:13.000000000,2015-06-11 14:33:11.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-06-11 14:16:19.000000000', 'files': ['nailgun/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b6fb731cb66922a0f1aa800543cfee4d17492e07', 'message': 'Pin upper bound of python-cinderclient version\n\npython-cinderclient > 1.2.1 require python-keystoneclinet 1.6 when we install\n1.4 due to fix problem with pbr version caused by keystonemiddleware\nWe could require higher versiona of keystonemiddleware (>=1.5) but it\nwould be much higher than the version we have in repos (1.2) for 6.1\n\nChange-Id: I449d23cf5e563b9de386beb249437bbf98db47f3\nCloses-Bug: #1464132\n(cherry picked from commit 9f6004fac838a42cab281094e2a574bb5dfe5295)\n'}]",0,190654,b6fb731cb66922a0f1aa800543cfee4d17492e07,12,9,1,12200,,,0,"Pin upper bound of python-cinderclient version

python-cinderclient > 1.2.1 require python-keystoneclinet 1.6 when we install
1.4 due to fix problem with pbr version caused by keystonemiddleware
We could require higher versiona of keystonemiddleware (>=1.5) but it
would be much higher than the version we have in repos (1.2) for 6.1

Change-Id: I449d23cf5e563b9de386beb249437bbf98db47f3
Closes-Bug: #1464132
(cherry picked from commit 9f6004fac838a42cab281094e2a574bb5dfe5295)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/54/190654/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/requirements.txt'],1,b6fb731cb66922a0f1aa800543cfee4d17492e07,,"python-cinderclient>=1.0.7,<=1.2.1",python-cinderclient>=1.0.7,1,1
openstack%2Ffuel-web~master~I449d23cf5e563b9de386beb249437bbf98db47f3,openstack/fuel-web,master,I449d23cf5e563b9de386beb249437bbf98db47f3,Pin upper bound of python-cinderclient version,MERGED,2015-06-11 08:23:45.000000000,2015-06-11 14:30:36.000000000,2015-06-11 14:13:00.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2015-06-11 08:23:45.000000000', 'files': ['nailgun/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9f6004fac838a42cab281094e2a574bb5dfe5295', 'message': 'Pin upper bound of python-cinderclient version\n\npython-cinderclient > 1.2.1 require python-keystoneclinet 1.6 when we install\n1.4 due to fix problem with pbr version caused by keystonemiddleware\nWe could require higher versiona of keystonemiddleware (>=1.5) but it\nwould be much higher than the version we have in repos (1.2) for 6.1\n\nChange-Id: I449d23cf5e563b9de386beb249437bbf98db47f3\nCloses-Bug: #1464132\n'}]",0,190541,9f6004fac838a42cab281094e2a574bb5dfe5295,14,9,1,12200,,,0,"Pin upper bound of python-cinderclient version

python-cinderclient > 1.2.1 require python-keystoneclinet 1.6 when we install
1.4 due to fix problem with pbr version caused by keystonemiddleware
We could require higher versiona of keystonemiddleware (>=1.5) but it
would be much higher than the version we have in repos (1.2) for 6.1

Change-Id: I449d23cf5e563b9de386beb249437bbf98db47f3
Closes-Bug: #1464132
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/41/190541/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/requirements.txt'],1,9f6004fac838a42cab281094e2a574bb5dfe5295,bug/1464132,"python-cinderclient>=1.0.7,<=1.2.1",python-cinderclient>=1.0.7,1,1
openstack%2Fxstatic-jasmine~master~I4d3f7ae430fad38891927e44084941058e6bcccf,openstack/xstatic-jasmine,master,I4d3f7ae430fad38891927e44084941058e6bcccf,Adding LICENSE file,MERGED,2015-06-08 21:55:36.000000000,2015-06-11 14:29:46.000000000,2015-06-11 14:29:45.000000000,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 12826}, {'_account_id': 14124}]","[{'number': 1, 'created': '2015-06-08 21:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/xstatic-jasmine/commit/7773235cf0c3c87825c79410ce2090395b36b729', 'message': 'Adding LICENSE file.\n\nChange-Id: I4d3f7ae430fad38891927e44084941058e6bcccf\n'}, {'number': 2, 'created': '2015-06-08 21:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/xstatic-jasmine/commit/3f60ec92ac8da7d2d7005d779896f68dd81210fb', 'message': 'Adding LICENSE file.\n\nChange-Id: I4d3f7ae430fad38891927e44084941058e6bcccf\n'}, {'number': 3, 'created': '2015-06-08 21:58:18.000000000', 'files': ['LICENSE'], 'web_link': 'https://opendev.org/openstack/xstatic-jasmine/commit/53fdc7e4c8408d8c9e09a95808f12e964925f547', 'message': 'Adding LICENSE file\n\nChange-Id: I4d3f7ae430fad38891927e44084941058e6bcccf\n'}]",0,189485,53fdc7e4c8408d8c9e09a95808f12e964925f547,10,4,3,9659,,,0,"Adding LICENSE file

Change-Id: I4d3f7ae430fad38891927e44084941058e6bcccf
",git fetch https://review.opendev.org/openstack/xstatic-jasmine refs/changes/85/189485/3 && git format-patch -1 --stdout FETCH_HEAD,['LICENSE'],1,7773235cf0c3c87825c79410ce2090395b36b729,add_license,"Copyright (c) 2008-2014 Pivotal Labs Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ",,20,0
openstack%2Fkeystone~master~Ic7591accee78637bef2413def75dbe6a9888495d,openstack/keystone,master,Ic7591accee78637bef2413def75dbe6a9888495d,install_venv_common no longer in oslo-incubator,ABANDONED,2015-06-07 14:08:29.000000000,2015-06-11 14:22:47.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7725}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-06-07 14:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a38f0069d6a03d23dcd5eab11f068ddf640e7c6d', 'message': 'cleanup openstack-common.conf\n\nChange-Id: Ic7591accee78637bef2413def75dbe6a9888495d\n'}, {'number': 2, 'created': '2015-06-08 11:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/264ba632779dde32707d69e18b013af206252974', 'message': 'Remove unnecessary install_venv_common.py\n\nChange-Id: Ic7591accee78637bef2413def75dbe6a9888495d\n'}, {'number': 3, 'created': '2015-06-10 11:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/884b239f915a16d3d07f343a0a859c818fac1de1', 'message': 'install_venv_common no longer in oslo-incubator\n\nRemove reference to the file as it is no longer in the oslo-incubator\nrepo.\n\nChange-Id: Ic7591accee78637bef2413def75dbe6a9888495d\n'}, {'number': 4, 'created': '2015-06-10 11:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a9fc3f4e63a9cda3fe17df942697f2c12eb2e86a', 'message': 'install_venv_common no longer in oslo-incubator\n\nRemove reference to the file as it is no longer in the oslo-incubator\nrepo.\n\nChange-Id: Ic7591accee78637bef2413def75dbe6a9888495d\n'}, {'number': 5, 'created': '2015-06-10 12:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a96e5ac87f8295810395bac22893a479c238bae4', 'message': 'install_venv_common no longer in oslo-incubator\n\nRemove reference to the file as it is no longer in the oslo-incubator\nrepo.\n\nChange-Id: Ic7591accee78637bef2413def75dbe6a9888495d\n'}, {'number': 6, 'created': '2015-06-11 10:22:32.000000000', 'files': ['openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/keystone/commit/12d9547cabb25aac8b73fea50710b00f525062f1', 'message': 'install_venv_common no longer in oslo-incubator\n\nRemove reference to the file as it is no longer in the oslo-incubator\nrepo. Note that the file still exists in keystone, but just advertising\nthe fact that a future sync will not refresh the file as it is no longer\npresent in oslo-incubator and imply keystone owns the file now.\n\nChange-Id: Ic7591accee78637bef2413def75dbe6a9888495d'}]",0,189111,12d9547cabb25aac8b73fea50710b00f525062f1,16,4,6,5638,,,0,"install_venv_common no longer in oslo-incubator

Remove reference to the file as it is no longer in the oslo-incubator
repo. Note that the file still exists in keystone, but just advertising
the fact that a future sync will not refresh the file as it is no longer
present in oslo-incubator and imply keystone owns the file now.

Change-Id: Ic7591accee78637bef2413def75dbe6a9888495d",git fetch https://review.opendev.org/openstack/keystone refs/changes/11/189111/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-common.conf'],1,a38f0069d6a03d23dcd5eab11f068ddf640e7c6d,,,module=versionutilsscript=tools/install_venv_common.py,0,2
openstack%2Ffuel-web~master~I58dd0ebd6de610448bf297d0bd97c6a334f6abc0,openstack/fuel-web,master,I58dd0ebd6de610448bf297d0bd97c6a334f6abc0,Do not run mongo checks for old releases,MERGED,2015-06-10 16:43:42.000000000,2015-06-11 14:22:39.000000000,2015-06-11 14:10:46.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-06-10 16:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/88adf8257133cf99e138a09f2f73328277d2ecb5', 'message': ""Do not run mongo checks for old releases\n\nIn Fuel releases before 6.1 we didn't have 'external mongo' feature,\nand therefore we shouldn't run mongo checks for envs based on these\nreleases.\n\nCloses-Bug: #1463880\n\nChange-Id: I58dd0ebd6de610448bf297d0bd97c6a334f6abc0\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 2, 'created': '2015-06-11 08:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5284fd2cc1dd030558da84962d9e0bf0f86965a4', 'message': ""Do not run mongo checks for old releases\n\nIn Fuel releases before 6.1 we didn't have 'external mongo' feature,\nand therefore running mongo checks is invalid operation.\n\nCloses-Bug: #1463880\n\nChange-Id: I58dd0ebd6de610448bf297d0bd97c6a334f6abc0\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 3, 'created': '2015-06-11 09:50:43.000000000', 'files': ['nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/objects/release.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e191012ee67bceed80acd114e440f51f15534dc8', 'message': ""Do not run mongo checks for old releases\n\nIn Fuel releases before 6.1 we didn't have 'external mongo' feature,\nand therefore running mongo checks is invalid operation.\n\nCloses-Bug: #1463880\n\nChange-Id: I58dd0ebd6de610448bf297d0bd97c6a334f6abc0\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}]",3,190252,e191012ee67bceed80acd114e440f51f15534dc8,31,9,3,10391,,,0,"Do not run mongo checks for old releases

In Fuel releases before 6.1 we didn't have 'external mongo' feature,
and therefore running mongo checks is invalid operation.

Closes-Bug: #1463880

Change-Id: I58dd0ebd6de610448bf297d0bd97c6a334f6abc0
Signed-off-by: Igor Kalnitsky <igor@kalnitsky.org>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/52/190252/3 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/task/task.py'],1,88adf8257133cf99e138a09f2f73328277d2ecb5,do-not-check-mongo-for-old-envs," attributes = objects.Attributes.merged_attrs( task.cluster.attributes) # we're not interested in checks for release where we didn't # have external mongo feature if 'external_mongo' not in attributes: components = attributes.get(""additional_components"", None) if (components and components[""ceilometer""][""value""] and components[""mongo""][""value""] and len(objects.Cluster.get_nodes_by_role( task.cluster, 'mongo')) > 0): raise errors.ExtMongoCheckerError if (components and components[""ceilometer""][""value""] and not components[""mongo""][""value""] and len(objects.Cluster.get_nodes_by_role( task.cluster, 'mongo')) == 0): raise errors.MongoNodesCheckError"," components = objects.Attributes.merged_attrs( task.cluster.attributes).get(""additional_components"", None) if (components and components[""ceilometer""][""value""] and components[""mongo""][""value""] and len(objects.Cluster.get_nodes_by_role( task.cluster, 'mongo')) > 0): raise errors.ExtMongoCheckerError if (components and components[""ceilometer""][""value""] and not components[""mongo""][""value""] and len(objects.Cluster.get_nodes_by_role( task.cluster, 'mongo')) == 0): raise errors.MongoNodesCheckError",17,12
openstack%2Fpython-saharaclient~master~I95e54da58339753bc6ce65a6ba710ebae98d3130,openstack/python-saharaclient,master,I95e54da58339753bc6ce65a6ba710ebae98d3130,"Another gate test, test env in pretty_tox.sh",ABANDONED,2015-06-11 01:41:03.000000000,2015-06-11 14:21:13.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}]","[{'number': 1, 'created': '2015-06-11 01:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/0cc7f5c93e1e8daf4e9bc15bc09bd8750375c80f', 'message': 'Another gate test, test env in pretty_tox.sh\n\nChange-Id: I95e54da58339753bc6ce65a6ba710ebae98d3130\n'}, {'number': 2, 'created': '2015-06-11 13:47:50.000000000', 'files': ['tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/46f0432e1bfcf6bdd091240af267fb1d1c8f10c5', 'message': 'Another gate test, test env in pretty_tox.sh\n\nChange-Id: I95e54da58339753bc6ce65a6ba710ebae98d3130\n'}]",0,190451,46f0432e1bfcf6bdd091240af267fb1d1c8f10c5,5,2,2,8091,,,0,"Another gate test, test env in pretty_tox.sh

Change-Id: I95e54da58339753bc6ce65a6ba710ebae98d3130
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/51/190451/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/pretty_tox.sh'],1,0cc7f5c93e1e8daf4e9bc15bc09bd8750375c80f,test2,"echo ""in pretty_tox.sh"" echo $OS_USERNAME",,2,0
openstack%2Fpython-saharaclient~master~Iae7754b431ab70970a2570a825113d524cf6cf49,openstack/python-saharaclient,master,Iae7754b431ab70970a2570a825113d524cf6cf49,"Test, env seems to be missing in pretty_tox.sh",ABANDONED,2015-06-10 21:08:52.000000000,2015-06-11 14:20:55.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7745}, {'_account_id': 8091}]","[{'number': 1, 'created': '2015-06-10 21:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/47e8cace0359fa93a71be29b5f610a55097061a7', 'message': 'Silly test, starting point for finding errors\n\nChange-Id: Iae7754b431ab70970a2570a825113d524cf6cf49\n'}, {'number': 2, 'created': '2015-06-11 01:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/7b677a4f78b2530597b321202f0e2ee7cb2c2347', 'message': 'Silly test, starting point for finding errors\n\nChange-Id: Iae7754b431ab70970a2570a825113d524cf6cf49\n'}, {'number': 3, 'created': '2015-06-11 13:15:07.000000000', 'files': ['tox.ini', 'tools/pretty_tox.sh', 'saharaclient/tests/functional/hooks/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/64bc9f5b2b46304b63af4214a9efbdc1387952c3', 'message': 'Test, env seems to be missing in pretty_tox.sh\n\n(do not merge)\n\nChange-Id: Iae7754b431ab70970a2570a825113d524cf6cf49\n'}]",0,190351,64bc9f5b2b46304b63af4214a9efbdc1387952c3,15,4,3,8091,,,0,"Test, env seems to be missing in pretty_tox.sh

(do not merge)

Change-Id: Iae7754b431ab70970a2570a825113d524cf6cf49
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/51/190351/3 && git format-patch -1 --stdout FETCH_HEAD,['saharaclient/tests/functional/hooks/post_test_hook.sh'],1,47e8cace0359fa93a71be29b5f610a55097061a7,test,echo $OS_USERNAME echo $OS_PASSWORD echo $OS_TENANT_NAME echo $OS_AUTH_URL,,4,0
openstack%2Fneutron~master~I71aeb8f1e5fc5f3e330e593a463858dd65e6093b,openstack/neutron,master,I71aeb8f1e5fc5f3e330e593a463858dd65e6093b,Fix typos in docs,MERGED,2015-06-09 00:33:10.000000000,2015-06-11 14:15:12.000000000,2015-06-09 10:33:03.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12955}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15752}, {'_account_id': 15922}, {'_account_id': 16707}]","[{'number': 1, 'created': '2015-06-09 00:33:10.000000000', 'files': ['doc/source/devref/callbacks.rst', 'doc/source/devref/contribute.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0bbfc090bb25f1e05b98f0ad70c18209b87ed6b', 'message': 'Fix typos in docs\n\nChange-Id: I71aeb8f1e5fc5f3e330e593a463858dd65e6093b\n'}]",0,189513,d0bbfc090bb25f1e05b98f0ad70c18209b87ed6b,29,26,1,6610,,,0,"Fix typos in docs

Change-Id: I71aeb8f1e5fc5f3e330e593a463858dd65e6093b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/189513/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/callbacks.rst', 'doc/source/devref/contribute.rst']",2,d0bbfc090bb25f1e05b98f0ad70c18209b87ed6b,, Absence of an entry for an existing plugin or driver means no active effort, Absense of an entry for an existing plugin or driver means no active effort,2,2
openstack%2Fironic-inspector~master~I5b00a71e86a5a57111c25b0e16c662107074c21f,openstack/ironic-inspector,master,I5b00a71e86a5a57111c25b0e16c662107074c21f,Rework processing hook interface for 2.0.0,MERGED,2015-06-08 15:45:27.000000000,2015-06-11 14:05:40.000000000,2015-06-11 14:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 7882}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-06-08 15:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/54e5d23b01c0f855e0caa614a1d1bc6beebb4af2', 'message': 'Rework processing hook interface for 2.0.0\n\nThis is a backward incompatible change of hooks interfaces.\nThe goal is to make these interfaces easier extensible, and to give\nhooks access to NodeInfo instance.\n\nChange-Id: I5b00a71e86a5a57111c25b0e16c662107074c21f\nImplements: blueprint plugin-interface-v2\n'}, {'number': 2, 'created': '2015-06-09 13:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/1e71c369b8c0b286dcc9aae62e5c3f41ffbf5c5f', 'message': 'Rework processing hook interface for 2.0.0\n\nThis is a backward incompatible change of hooks interfaces.\nThe goal is to make these interfaces easier extensible, and to give\nhooks access to NodeInfo instance.\n\nChange-Id: I5b00a71e86a5a57111c25b0e16c662107074c21f\nImplements: blueprint plugin-interface-v2\n'}, {'number': 3, 'created': '2015-06-10 16:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/f0cfd310ec75e0ec3b48699ba79bec3e847042dc', 'message': 'Rework processing hook interface for 2.0.0\n\nThis is a backward incompatible change of hooks interfaces.\nThe goal is to make these interfaces easier extensible, and to give\nhooks access to NodeInfo instance.\n\nChange-Id: I5b00a71e86a5a57111c25b0e16c662107074c21f\nImplements: blueprint plugin-interface-v2\n'}, {'number': 4, 'created': '2015-06-11 13:48:09.000000000', 'files': ['ironic_inspector/test/base.py', 'ironic_inspector/plugins/edeploy.py', 'ironic_inspector/process.py', 'ironic_inspector/test/test_plugins_root_device_hint.py', 'ironic_inspector/plugins/standard.py', 'ironic_inspector/plugins/root_device_hint.py', 'ironic_inspector/test/test_plugins_edeploy.py', 'ironic_inspector/plugins/base.py', 'ironic_inspector/plugins/example.py', 'ironic_inspector/test/test_main.py', 'ironic_inspector/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/ff44040d2cd8af117f03a933b1edf06e058f2912', 'message': 'Rework processing hook interface for 2.0.0\n\nThis is a backward incompatible change of hooks interfaces.\nThe goal is to make these interfaces easier extensible, and to give\nhooks access to NodeInfo instance.\n\nChange-Id: I5b00a71e86a5a57111c25b0e16c662107074c21f\nImplements: blueprint plugin-interface-v2\n'}]",2,189346,ff44040d2cd8af117f03a933b1edf06e058f2912,17,4,4,10239,,,0,"Rework processing hook interface for 2.0.0

This is a backward incompatible change of hooks interfaces.
The goal is to make these interfaces easier extensible, and to give
hooks access to NodeInfo instance.

Change-Id: I5b00a71e86a5a57111c25b0e16c662107074c21f
Implements: blueprint plugin-interface-v2
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/46/189346/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/plugins/edeploy.py', 'ironic_inspector/process.py', 'ironic_inspector/plugins/standard.py', 'ironic_inspector/plugins/root_device_hint.py', 'ironic_inspector/plugins/base.py', 'ironic_inspector/plugins/example.py']",6,54e5d23b01c0f855e0caa614a1d1bc6beebb4af2,bug/1464184," def before_processing(self, introspection_data, **kwargs): def before_update(self, introspection_data, node_info, node_patches, ports_patches, **kwargs): LOG.debug('before_update: %s (node %s)', introspection_data, node_info.uuid)"," def before_processing(self, introspection_data): def before_update(self, node, ports, introspection_data): LOG.debug('before_update: %s (node %s)', introspection_data, node.uuid)",70,66
openstack%2Fmagnum~master~I23a12caa8651d5ae076b78d899905c96f3f8d61e,openstack/magnum,master,I23a12caa8651d5ae076b78d899905c96f3f8d61e,Cloud driver is not needed,MERGED,2015-06-11 06:15:56.000000000,2015-06-11 14:03:24.000000000,2015-06-11 14:03:22.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 10206}, {'_account_id': 11208}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-06-11 06:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8234262b2055c34cdf9c97958ee0a9d6515d252a', 'message': ""Cloud driver is not needed\n\nAt this time, we have a cloud driver for nova, but it isn't used by anywhere.\n\nChange-Id: I23a12caa8651d5ae076b78d899905c96f3f8d61e\nCloses-Bug: #1464109\n""}, {'number': 2, 'created': '2015-06-11 07:06:40.000000000', 'files': ['magnum/base.py', 'magnum/cloud/__init__.py', 'magnum/cloud/nova_driver.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e93831b96e5326e6d79848a42895ba4bf7703947', 'message': ""Cloud driver is not needed\n\nAt this time, we have a cloud driver for nova, but it isn't used by anywhere.\n\nChange-Id: I23a12caa8651d5ae076b78d899905c96f3f8d61e\nCloses-Bug: #1464109\n""}]",0,190499,e93831b96e5326e6d79848a42895ba4bf7703947,14,8,2,12385,,,0,"Cloud driver is not needed

At this time, we have a cloud driver for nova, but it isn't used by anywhere.

Change-Id: I23a12caa8651d5ae076b78d899905c96f3f8d61e
Closes-Bug: #1464109
",git fetch https://review.opendev.org/openstack/magnum refs/changes/99/190499/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/cloud/__init__.py', 'magnum/cloud/nova_driver.py']",2,8234262b2055c34cdf9c97958ee0a9d6515d252a,bug/1464109,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from magnum import base KEYSTONE_URL = ""https://example.com:5000/v2.0/"" class NovaBayBase(base.BayBase): pass class NovaBayFactory(NovaBayBase): def __init__(self): pass def list(self): self.nova.servers.list() def create(self, pod_definition=None): pass def get_pod(self, pod_id): return NovaBay(pod_id) class NovaBay(NovaBayBase): def __init__(self, pod_id): self.pod_id = pod_id def destroy(self): pass def stop(self): pass ",0,45
openstack%2Fpython-novaclient~master~Ia88b022d86505c2d7baa920fafbbfbaee04e4e58,openstack/python-novaclient,master,Ia88b022d86505c2d7baa920fafbbfbaee04e4e58,Add help message for secgroup-add/del-default-rule,MERGED,2015-06-08 11:05:38.000000000,2015-06-11 13:56:49.000000000,2015-06-11 13:56:48.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 4690}, {'_account_id': 13525}]","[{'number': 1, 'created': '2015-06-08 11:05:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0c8d44744e7a6633da3e26a503ace9c536a28e06', 'message': ""Add help message for secgroup-add/del-default-rule\n\nAdd help message about only work with the nova-network backend, not neutron\nfor 'secgroup-add-default-rule' and 'secgroup-delete-default-rule'.\n\nChange-Id: Ia88b022d86505c2d7baa920fafbbfbaee04e4e58\nCloses-Bug: #1419739\n""}, {'number': 2, 'created': '2015-06-10 13:51:11.000000000', 'files': ['novaclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/89a4ca828bda834252d5f682e753cae81fd57df7', 'message': ""Add help message for secgroup-add/del-default-rule\n\nAdd help message about only work with the nova-network backend, not neutron\nfor 'secgroup-add-default-rule' and 'secgroup-delete-default-rule'.\n\nChange-Id: Ia88b022d86505c2d7baa920fafbbfbaee04e4e58\nCloses-Bug: #1419739\n""}]",4,189263,89a4ca828bda834252d5f682e753cae81fd57df7,11,5,2,13525,,,0,"Add help message for secgroup-add/del-default-rule

Add help message about only work with the nova-network backend, not neutron
for 'secgroup-add-default-rule' and 'secgroup-delete-default-rule'.

Change-Id: Ia88b022d86505c2d7baa920fafbbfbaee04e4e58
Closes-Bug: #1419739
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/63/189263/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/v2/shell.py'],1,0c8d44744e7a6633da3e26a503ace9c536a28e06,bug/1419739," security group for new tenants. Only work with the nova-network backend, not neutron. 'default' security group for new tenants. Only work with the nova-network backend, not neutron.", security group for new tenants. 'default' security group for new tenants.,4,2
openstack%2Ffuel-web~master~I71e0255820edef4725208db777bf5e0bf8d3958c,openstack/fuel-web,master,I71e0255820edef4725208db777bf5e0bf8d3958c,IBP: /boot on small hard drive if possible,MERGED,2015-06-09 13:00:37.000000000,2015-06-11 13:54:40.000000000,2015-06-11 13:40:47.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6677}, {'_account_id': 8003}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11827}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-06-09 13:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7431900ee77365474361de9795d280f52650de77', 'message': 'IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T),\nso we need to avoid placing /boot on such drives if it is\npossible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n'}, {'number': 2, 'created': '2015-06-09 17:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aa336486b3923ba53af61073af8597f0fdf15639', 'message': 'IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T),\nso we need to avoid placing /boot on such drives if it is\npossible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n'}, {'number': 3, 'created': '2015-06-10 07:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/013fc065406f9f7cc3178fdf4801847044c415a2', 'message': ""IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T)\ndue to firmware bugs, so we'd better avoid placing\n/boot on such drives if it is possible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n""}, {'number': 4, 'created': '2015-06-10 15:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4468e2bf527e5bc4735f19d53af24d02363818b5', 'message': ""IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T)\ndue to firmware bugs, so we'd better avoid placing\n/boot on such drives if it is possible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n""}, {'number': 5, 'created': '2015-06-10 15:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dcd29d9d958a5ff0062e8e3ed532ee1ec92d6113', 'message': ""IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T)\ndue to firmware bugs, so we'd better avoid placing\n/boot on such drives if it is possible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n""}, {'number': 6, 'created': '2015-06-10 15:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6b7b9954c4a10bb59428dbdbb7fa1558aa9170f1', 'message': ""IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T)\ndue to firmware bugs, so we'd better avoid placing\n/boot on such drives if it is possible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n""}, {'number': 7, 'created': '2015-06-11 11:01:39.000000000', 'files': ['fuel_agent/fuel_agent/drivers/nailgun.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/059831145c657a5eaba563b18652351a459de566', 'message': ""IBP: /boot on small hard drive if possible\n\nOn some hardware GRUB can not see huge hard drives (>2T)\ndue to firmware bugs, so we'd better avoid placing\n/boot on such drives if it is possible.\n\nChange-Id: I71e0255820edef4725208db777bf5e0bf8d3958c\nPartial-Bug: #1461126\n""}]",19,189698,059831145c657a5eaba563b18652351a459de566,75,9,7,3009,,,0,"IBP: /boot on small hard drive if possible

On some hardware GRUB can not see huge hard drives (>2T)
due to firmware bugs, so we'd better avoid placing
/boot on such drives if it is possible.

Change-Id: I71e0255820edef4725208db777bf5e0bf8d3958c
Partial-Bug: #1461126
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/98/189698/4 && git format-patch -1 --stdout FETCH_HEAD,['fuel_agent/fuel_agent/drivers/nailgun.py'],1,7431900ee77365474361de9795d280f52650de77,bug/1461126," def small_ks_disks(self, maxsize=2097152): return [d for d in self.ks_disks if d['size'] <= maxsize] @property if volume.get('mount') != '/boot': if volume.get('mount') == '/boot' \ and not self._boot_partition_done: # NOTE(kozhukalov): On some hardware GRUB is not able # to see disks larger than 2T, so we need to avoid # placing /boot on such huge disks if it is possible. if disk in self.small_ks_disks \ or not self.small_ks_disks: LOG.debug('Adding partition on disk %s: size=%s', disk['name'], volume['size']) prt = parted.add_partition(size=volume['size']) LOG.debug('Partition name: %s', prt.name) self._boot_partition_done = True", if volume.get('mount') != '/boot' \ or not self._boot_partition_done: if volume.get('mount') == '/boot': self._boot_partition_done = True,18,4
openstack%2Fnova~master~I41d6af52ffed924d35ac255625488f40f7989a0a,openstack/nova,master,I41d6af52ffed924d35ac255625488f40f7989a0a,virt: convert VFS API to use nova.virt.image.model,MERGED,2014-10-30 13:22:08.000000000,2015-06-11 13:49:35.000000000,2015-06-11 13:49:32.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 8802}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12898}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2014-10-30 13:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/720fc756d8ae462793aecfceef81cdb40bd248c0', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 2, 'created': '2014-10-30 17:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2d90f870a4b28484436c822793d42114ee2e8f1', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 3, 'created': '2014-11-13 09:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52c4d36158689e5baaec59d2ee8aec43dfec4d03', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 4, 'created': '2014-11-18 12:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bceb5c77d5988d6da22cca89b8d07c316bd51c5', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 5, 'created': '2014-11-20 15:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15f2377a69f1b4cea7f3fa78ab2e063f27d3222f', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 6, 'created': '2014-11-20 15:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0327bf1bf7c11d66d4091a19de445487ed05e61a', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 7, 'created': '2014-12-02 15:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/041f86309bc93156ea484dc4a8934cbec9e1a4de', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 8, 'created': '2014-12-08 17:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1649af3b378914c7ddb204577da4cf696db0b7a5', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 9, 'created': '2014-12-09 10:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d79ebdd09aac9b6fd4d550b9843a530b3d36af57', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 10, 'created': '2014-12-16 11:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf615fc4615b3c244b3654ba0841ff8ec936ba94', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 11, 'created': '2014-12-18 10:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1eaba319314773d5e812a00cc689ae992b7b47c', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 12, 'created': '2014-12-19 11:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52a0fce59b3d4de3a25a169db147922df26b1f34', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 13, 'created': '2015-01-12 12:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a6a48e19b71062752ddbd7739efea2432903184', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 14, 'created': '2015-01-13 11:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd2cd134ba6c1a32cab6066b0c322c5bbca82b36', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 15, 'created': '2015-01-19 12:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc70a23382dbe7ecf640357e341f3125b8d174df', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 16, 'created': '2015-01-26 11:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c298e890d3ba513cfa1ae2a9d9aa2389f3ec61b9', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 17, 'created': '2015-01-26 15:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9138209f8ab03e6c144a3ebf804d129b6c3903e1', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 18, 'created': '2015-01-27 11:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afacdbd3f6fee037e6ba84613ef369921a5c0852', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 19, 'created': '2015-01-28 12:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9438a54ad96a88c9d4609ddb595333e4e7742011', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 20, 'created': '2015-02-03 10:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/456f5c9b2f9eb6fc18213d47ebca35a536f9ef2c', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 21, 'created': '2015-02-16 10:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71e6518fad338b5ce04c216a0bd29762e7547dfa', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 22, 'created': '2015-04-30 11:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8cdbc767fb40358dc0e45a285c4a6460c1ec61ec', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 23, 'created': '2015-05-14 10:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/060a7d554c029045b662d2b836aba57415daab49', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 24, 'created': '2015-05-18 10:19:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/891f277c8b431bc2366a6bac2fdc1fd2e61e2c81', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 25, 'created': '2015-05-26 16:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/611e408acb06d73302a76009c8629114f6f5a1bc', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 26, 'created': '2015-06-02 14:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/05ac612b77f310f2cc11052040aeed3f26176f4b', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}, {'number': 27, 'created': '2015-06-04 13:04:14.000000000', 'files': ['nova/tests/unit/virt/disk/vfs/fakeguestfs.py', 'nova/hacking/checks.py', 'nova/virt/xenapi/vm_utils.py', 'nova/virt/disk/vfs/localfs.py', 'nova/tests/unit/virt/disk/vfs/test_guestfs.py', 'nova/virt/disk/vfs/api.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py', 'nova/virt/disk/vfs/guestfs.py', 'nova/tests/unit/virt/disk/test_inject.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/356e0651a676e3c43983a6f2848a79975f609f34', 'message': 'virt: convert VFS API to use nova.virt.image.model\n\nConvert the nova.virt.disk.vfs classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\nThis enables the libguestfs impl to now support the\nconfiguration of RBD images.\n\nRelated-Bug: #1257674\nChange-Id: I41d6af52ffed924d35ac255625488f40f7989a0a\n'}]",15,132022,356e0651a676e3c43983a6f2848a79975f609f34,226,20,27,1779,,,0,"virt: convert VFS API to use nova.virt.image.model

Convert the nova.virt.disk.vfs classes to use the
nova.virt.image.model classes instead of manually
passing a filename and image format as parameters.
This enables the libguestfs impl to now support the
configuration of RBD images.

Related-Bug: #1257674
Change-Id: I41d6af52ffed924d35ac255625488f40f7989a0a
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/132022/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/disk/test_inject.py', 'nova/hacking/checks.py', 'nova/tests/virt/disk/vfs/test_localfs.py', 'nova/virt/xenapi/vm_utils.py', 'nova/tests/virt/disk/vfs/fakeguestfs.py', 'nova/virt/disk/vfs/localfs.py', 'nova/virt/disk/vfs/api.py', 'nova/tests/virt/disk/vfs/test_guestfs.py', 'nova/virt/disk/vfs/guestfs.py', 'nova/virt/disk/api.py']",10,720fc756d8ae462793aecfceef81cdb40bd248c0,bug/1257674," """"""Check whether we can resize contained file system. :param image: the local file path :param use_cow: whether the image is in qcow2 format """""" fs = vfs.VFS.instance_for_image( imgmodel.LocalFileImage(image, imgmodel.FORMAT_QCOW2), None) :param image: the local file path :param key: the SSH public key to inject :param net: the network configuration to inject :param metadata: the user metadata to inject :param admin_password: the root password to set :param files: the files to copy into the image :param partition: the partition number to access :param use_cow: whether the image is in qcow2 format :param mandatory: the list of parameters which must not fail to inject fmt = imgmodel.FORMAT_RAW if use_cow: fmt = imgmodel.FORMAT_QCOW2 try: fs = vfs.VFS.instance_for_image( imgmodel.LocalFileImage(image, fmt), partition)"," """"""Check whether we can resize contained file system."""""" fs = vfs.VFS.instance_for_image(image, 'qcow2', None) fmt = ""raw"" if use_cow: fmt = ""qcow2"" try: fs = vfs.VFS.instance_for_image(image, fmt, partition)",244,104
openstack%2Ffuel-library~stable%2F6.1~Ie31272df37b1e8373745d5e4b7ce4a66cf020cc2,openstack/fuel-library,stable/6.1,Ie31272df37b1e8373745d5e4b7ce4a66cf020cc2,DO NOT MERGE: Test commit,ABANDONED,2015-06-11 10:50:23.000000000,2015-06-11 13:48:33.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-06-11 10:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/11ee2bad08fde6274855076bfc5c3382faf0c4a9', 'message': 'DO NOT MERGE: Test commit\n\nChange-Id: Ie31272df37b1e8373745d5e4b7ce4a66cf020cc2\n'}, {'number': 2, 'created': '2015-06-11 11:06:43.000000000', 'files': ['test_file'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bc8868ebf0107a5172cee1b6b384b59400f610f4', 'message': 'DO NOT MERGE: Test commit\n\nFuel-CI: disable\n\nChange-Id: Ie31272df37b1e8373745d5e4b7ce4a66cf020cc2'}]",0,190577,bc8868ebf0107a5172cee1b6b384b59400f610f4,20,2,2,9977,,,0,"DO NOT MERGE: Test commit

Fuel-CI: disable

Change-Id: Ie31272df37b1e8373745d5e4b7ce4a66cf020cc2",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/77/190577/1 && git format-patch -1 --stdout FETCH_HEAD,['test_file'],1,11ee2bad08fde6274855076bfc5c3382faf0c4a9,,,,0,0
openstack%2Ffuel-library~master~I402bb49f02eacf64b77652a528892e9c80e859e1,openstack/fuel-library,master,I402bb49f02eacf64b77652a528892e9c80e859e1,DO NOT MERGE: Test commit,ABANDONED,2015-06-11 10:10:39.000000000,2015-06-11 13:48:22.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-06-11 10:10:39.000000000', 'files': ['test_file'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/77e2dccf8aff45ebf445092754e89b43ce625959', 'message': 'DO NOT MERGE: Test commit\n\nChange-Id: I402bb49f02eacf64b77652a528892e9c80e859e1\n'}]",0,190564,77e2dccf8aff45ebf445092754e89b43ce625959,16,3,1,9977,,,0,"DO NOT MERGE: Test commit

Change-Id: I402bb49f02eacf64b77652a528892e9c80e859e1
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/64/190564/1 && git format-patch -1 --stdout FETCH_HEAD,['test_file'],1,77e2dccf8aff45ebf445092754e89b43ce625959,test,,,0,0
openstack%2Ffuel-web~master~I0b7ed0f67b9882fff9d3d66d956fac0fac309361,openstack/fuel-web,master,I0b7ed0f67b9882fff9d3d66d956fac0fac309361,Screen data loading moved to fetchData method,MERGED,2015-02-11 10:19:06.000000000,2015-06-11 13:44:18.000000000,2015-06-11 13:32:26.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-02-11 10:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/92e324e612e4d40b6e5b4e406bec798eee7a1fad', 'message': 'Moves screen data loading to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 2, 'created': '2015-02-11 12:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aafba7aec41735d44150f1e751a4905235b4fc4c', 'message': 'Moves screen data loading to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 3, 'created': '2015-02-12 08:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0e5296f92a72380d40387c47147ca6bfa90170fc', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 4, 'created': '2015-02-12 13:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c039208fe73b57c18e6a36721738bb070d38ab8d', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 5, 'created': '2015-02-18 09:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/43e6e585d51d6bb185467e87b01daa8e1907f49f', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 6, 'created': '2015-02-18 09:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9c6357de03506f44d4f30f1081c9d25ea4ef6d85', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 7, 'created': '2015-02-18 13:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ce4bb78ea7d6c048912f1a19d6db9b28c8993684', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 8, 'created': '2015-03-13 10:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b4e03116cf28a60102aae0288a96e979b9085ceb', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 9, 'created': '2015-03-13 12:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/741437d2d85734bb05fe22dbe6b07447e4bd4e7d', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 10, 'created': '2015-03-13 15:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e4bca3186f190a7eb24c1e8596470718a0c41377', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 11, 'created': '2015-03-18 18:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/49fec04bc3cb2ff64a2125283e86242fda01043b', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 12, 'created': '2015-06-04 13:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a69a2271fa941778173cffa8f83d470f2884cf86', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 13, 'created': '2015-06-09 12:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4c9d7ca94e9ddf8aa687088ba361586426ab21b6', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 14, 'created': '2015-06-09 13:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/cbef1943a4e36ff1c4fb3b58b76bcba2e03609aa', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 15, 'created': '2015-06-10 08:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/57dec287ac46cb9acf0e3246a95152eddbb4606f', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 16, 'created': '2015-06-11 09:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3c97092489317aa4d695b62cbefeb9c1f3b98e17', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 17, 'created': '2015-06-11 09:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/667ba2bffda15f8737b12d8e47e4564d59d2a5c4', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}, {'number': 18, 'created': '2015-06-11 13:14:13.000000000', 'files': ['nailgun/static/views/cluster_page_tabs/nodes_tab.jsx', 'nailgun/static/views/cluster_page.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_nodes_screen.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/add_nodes_screen.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.jsx', 'nailgun/static/views/controls.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d8995ebeb05d982069c56dd6cadb6121c8fa9a95', 'message': 'Screen data loading moved to fetchData method\n\nRelated to blueprint react-router\n\nChange-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361\n'}]",18,154811,d8995ebeb05d982069c56dd6cadb6121c8fa9a95,129,7,18,8766,,,0,"Screen data loading moved to fetchData method

Related to blueprint react-router

Change-Id: I0b7ed0f67b9882fff9d3d66d956fac0fac309361
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/11/154811/10 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/cluster_nodes_screen.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_nodes_screen.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/add_nodes_screen.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.jsx']",5,92e324e612e4d40b6e5b4e406bec798eee7a1fad,bp/react-router," locked={locked} <div> {this.props.mode != 'list' && <RolePanel {...this.props} selectedNodeIds={this.state.selectedNodeIds} />} <NodeList {...this.props} nodes={this.props.nodes.models} grouping={this.state.grouping} filter={this.state.filter} locked={locked} selectedNodeIds={this.state.selectedNodeIds} selectNodes={this.selectNodes} // FIXME: one more role limits hack roleLimitation={(this.props.cluster.get('mode') == 'multi-node' && _.contains(assignedRoles, 'controller')) || _.contains(assignedRoles, 'zabbix-server')} /> </div>"," loading: this.props.mode == 'add', shouldDataBeFetched: function() { return !this.state.loading; }, var clusterId = this.props.mode == 'add' ? '' : this.props.cluster.id; this.props.nodes.fetch = function(options) { return this.constructor.__super__.fetch.call(this, _.extend({data: {cluster_id: clusterId}}, options)); }; if (this.props.mode == 'edit') { var ids = this.props.nodes.pluck('id'); this.props.nodes.parse = function(response) { return _.filter(response, function(node) {return _.contains(ids, node.id);}); }; } componentDidMount: function() { if (this.props.mode == 'add') { $.when(this.props.nodes.fetch(), this.props.cluster.get('settings').fetch({cache: true})).always(_.bind(function() { this.setState({loading: false}); this.scheduleDataFetch(); }, this)); } }, locked={locked || this.state.loading} {this.state.loading ? <controls.ProgressBar /> : <div> {this.props.mode != 'list' && <RolePanel {...this.props} selectedNodeIds={this.state.selectedNodeIds} />} <NodeList {...this.props} nodes={this.props.nodes.models} grouping={this.state.grouping} filter={this.state.filter} locked={locked} selectedNodeIds={this.state.selectedNodeIds} selectNodes={this.selectNodes} // FIXME: one more role limits hack roleLimitation={(this.props.cluster.get('mode') == 'multi-node' && _.contains(assignedRoles, 'controller')) || _.contains(assignedRoles, 'zabbix-server')} /> </div> }",76,85
openstack%2Fnetworking-ovn~master~I3771140880cb6eaafea2606268813effa3d4004a,openstack/networking-ovn,master,I3771140880cb6eaafea2606268813effa3d4004a,Document ideas for supporting provider networks,ABANDONED,2015-06-04 17:17:00.000000000,2015-06-11 13:41:36.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5756}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-04 17:17:00.000000000', 'files': ['doc/source/design/provider_networks.rst', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/68d221044760923b9ac18f2d658768adc235a421', 'message': ""Document ideas for supporting provider networks\n\nWe do not currently have a way to support Neutorn provider networks in\nOVN.  I'd like to propose a way forward so I started writing up a\nproposal.  I'm putting this up for review here to get initial feedback\nfrom other Neutorn developers that this seems to make sense.  Once\nthe proposal seems baked enough, I'll post it to the ovs-dev mailing\nlist for discussion there.\n\nChange-Id: I3771140880cb6eaafea2606268813effa3d4004a\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n""}]",7,188519,68d221044760923b9ac18f2d658768adc235a421,11,7,1,1561,,,0,"Document ideas for supporting provider networks

We do not currently have a way to support Neutorn provider networks in
OVN.  I'd like to propose a way forward so I started writing up a
proposal.  I'm putting this up for review here to get initial feedback
from other Neutorn developers that this seems to make sense.  Once
the proposal seems baked enough, I'll post it to the ovs-dev mailing
list for discussion there.

Change-Id: I3771140880cb6eaafea2606268813effa3d4004a
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/19/188519/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/design/provider_networks.rst', 'doc/source/index.rst']",2,68d221044760923b9ac18f2d658768adc235a421,provider-networks, design/provider_networks,,111,0
openstack%2Fnetworking-ovn~master~I84b0d0073c1f8553300510eb7dee873eb47a5cb5,openstack/networking-ovn,master,I84b0d0073c1f8553300510eb7dee873eb47a5cb5,Updated from global requirements,MERGED,2015-06-09 20:06:09.000000000,2015-06-11 13:39:49.000000000,2015-06-11 13:39:48.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-09 20:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5db1f5209bf7aea790e9ac45ee904148daebff68', 'message': 'Updated from global requirements\n\nChange-Id: I84b0d0073c1f8553300510eb7dee873eb47a5cb5\n'}, {'number': 2, 'created': '2015-06-11 12:41:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/bfd5c0cbf4f1d1026fdc33497389f61eb9f5c1b2', 'message': 'Updated from global requirements\n\nChange-Id: I84b0d0073c1f8553300510eb7dee873eb47a5cb5\n'}]",0,189916,bfd5c0cbf4f1d1026fdc33497389f61eb9f5c1b2,9,3,2,11131,,,0,"Updated from global requirements

Change-Id: I84b0d0073c1f8553300510eb7dee873eb47a5cb5
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/16/189916/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5db1f5209bf7aea790e9ac45ee904148daebff68,openstack/requirements,oslo.concurrency>=2.0.0 # Apache-2.0,oslo.concurrency>=1.8.0 # Apache-2.0,1,1
openstack%2Fhorizon~master~Iec9f40612c193da02c9efc1c37a51e8845fc36fb,openstack/horizon,master,Iec9f40612c193da02c9efc1c37a51e8845fc36fb,JSCS cleanup - dashboard/cloud-services/,ABANDONED,2015-06-11 06:44:34.000000000,2015-06-11 13:37:58.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12826}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-06-11 06:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bf86cdc31dce6d11d49f71a8f39e163e36f67804', 'message': ""JSCS cleanup - launch-instance/cloud-services/\n\nFollowing John Papa's style guide.\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors launch-instance/cloud-services/.\n\nChange-Id: Iec9f40612c193da02c9efc1c37a51e8845fc36fb\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 2, 'created': '2015-06-11 06:46:41.000000000', 'files': ['openstack_dashboard/static/dashboard/cloud-services/cloud-services.spec.js', 'openstack_dashboard/static/dashboard/cloud-services/cloud-services.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9838e2bba02f17440b6d58b4811e39f9af6f71cf', 'message': ""JSCS cleanup - dashboard/cloud-services/\n\nFollowing John Papa's style guide.\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors dashboard/cloud-services/.\n\nChange-Id: Iec9f40612c193da02c9efc1c37a51e8845fc36fb\nPartially-Implements: blueprint jscs-cleanup\n""}]",0,190508,9838e2bba02f17440b6d58b4811e39f9af6f71cf,6,5,2,13805,,,0,"JSCS cleanup - dashboard/cloud-services/

Following John Papa's style guide.
https://github.com/johnpapa/angular-styleguide,
this patch refactors dashboard/cloud-services/.

Change-Id: Iec9f40612c193da02c9efc1c37a51e8845fc36fb
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/08/190508/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/cloud-services/cloud-services.spec.js', 'openstack_dashboard/static/dashboard/cloud-services/cloud-services.js']",2,bf86cdc31dce6d11d49f71a8f39e163e36f67804,bp/jscs-cleanup, var fromJson = angular.fromJson; var isArray = angular.isArray;," var fromJson = angular.fromJson, isArray = angular.isArray;",12,12
openstack%2Fneutron-specs~master~I952b1456882319ce655d7f09039cfe924217e747,openstack/neutron-specs,master,I952b1456882319ce655d7f09039cfe924217e747,Implement floating IPs using stateless NAT,MERGED,2014-12-01 22:55:40.000000000,2015-06-11 13:34:51.000000000,2015-06-11 13:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 7141}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 7921}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9820}, {'_account_id': 10980}, {'_account_id': 11279}, {'_account_id': 13734}]","[{'number': 1, 'created': '2014-12-01 22:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f88eb7b7435244bc62d987418bd0b1387bed2583', 'message': 'Implement floating IPs using stateless NAT\n\nChange-Id: I952b1456882319ce655d7f09039cfe924217e747\n'}, {'number': 2, 'created': '2014-12-03 18:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/71862db178145ba6fdb4855f072d915eade5e020', 'message': 'Implement floating IPs using stateless NAT\n\nChange-Id: I952b1456882319ce655d7f09039cfe924217e747\n'}, {'number': 3, 'created': '2014-12-08 15:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/80548d623b781a8017de102140d3582837cd5224', 'message': 'Implement floating IPs using stateless NAT\n\nChange-Id: I952b1456882319ce655d7f09039cfe924217e747\n'}, {'number': 4, 'created': '2014-12-09 19:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5072afe64547b595713876e517634db795cc1847', 'message': 'Implement floating IPs using stateless NAT\n\nChange-Id: I952b1456882319ce655d7f09039cfe924217e747\n'}, {'number': 5, 'created': '2015-04-01 18:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/13dd2e59e5ddf647608c5d7d5b9de47cf3125a50', 'message': 'Implement floating IPs using stateless NAT\n\nChange-Id: I952b1456882319ce655d7f09039cfe924217e747\n'}, {'number': 6, 'created': '2015-04-29 22:21:17.000000000', 'files': ['specs/liberty/stateless-floatingips.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b07787676f6c1c2db4f7ab2a0e73c026c6ed9859', 'message': 'Implement floating IPs using stateless NAT\n\nChange-Id: I952b1456882319ce655d7f09039cfe924217e747\n'}]",64,138201,b07787676f6c1c2db4f7ab2a0e73c026c6ed9859,73,18,6,7448,,,0,"Implement floating IPs using stateless NAT

Change-Id: I952b1456882319ce655d7f09039cfe924217e747
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/01/138201/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/stateless-floatingips.rst'],1,f88eb7b7435244bc62d987418bd0b1387bed2583,bp/stateless-floatingips,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================== Stateless Floating IPs ====================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/stateless-floatingips :Author: Carl Baldwin <carl.baldwin@hp.com> :Copyright: 2014 Hewlett-Packard Development Company, L.P. In the current implementation, conntrack is not useful for floating ips. There is no reason for it except that there did not seem to be another way. If we could implement floating ips in a stateless way that didn't touch conntrack then this could be both a performance improvement and a security improvement. Problem Description =================== Floating IPs are just one to one mappings of private and floater IPs so all that needs to happen is a stateless swapping of IP addresses. However, the current implementation uses SNAT and DNAT targets in the iptables nat table. These targets depend on conntrack to identify packets traversing in both directions which are part of the established connection. Tracking these connections takes processor and memory resources. As the number of connections through a network node increases, the end-user may experience connectivity issues unless conntrack is tuned up to handle them. How to tune conntrack is out of the scope of this blueprint. The point is that it is needed with the current Neutron and really shouldn't be. There would not be any need to tune it if it were not used. Proposed Change =============== The iptables raw table was introduced to give a way to skip conntrack for certain packets. From the iptables man page [#]_ :: This table is used mainly for configuring exemptions from connection tracking in combination with the NOTRACK target. It registers at the netfilter hooks with higher priority and is thus called before ip_conntrack, or any other IP tables. .. [#] http://ipset.netfilter.org/iptables.man.html The NOTRACK target will allow bypassing conntrack for packets associated with the floating IP. However, it does not accomplish the actual rewriting of addresses. The SNAT, DNAT, and MASQUERADE are not useful because they are meant to work with conntrack and stateful NAT. We need something to perform stateless address translation. The Xtables-addons project [#]_ has an implementation for performing stateless NAT in the iptables raw table. From the manpage [#]_ we can see that the RAWDNAT and RAWSNAT can easily be used to perform address translation:: -t raw -A PREROUTING -i lan0 -d 212.201.100.135 -j RAWDNAT --to-destination 199.181.132.250 -t rawpost -A POSTROUTING -o lan0 -s 199.181.132.250 -j RAWSNAT --to-source 212.201.100.135 The above is a generic example, the floating IPs will be applied with matching rules similar to the SNAT and DNAT rules being used today. .. [#] http://netfilter.org/projects/xtables-addons/index.html .. [#] http://manpages.ubuntu.com/manpages/karmic/man8/xtables-addons.8.html There is one aspect of stateless NAT that is more difficult than staleful NAT. It is that a rule must be configured for both directions of packet flow. This is because there is no such thing as a connection with stateless rules and therefore you can't think of the connection as inherently having a direction. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- There was a security note released recently related to a bug [#]_ in Neutron where established connections through floating ips would continue to work after the floating ip was disassociated from a private IP address. This bug as fixed in Juno by explicitly calling conntrack to delete the connections. This adds complexity to the L3 agent which can be removed when stateless floating IPs have been fully implemented. .. [#] https://bugs.launchpad.net/neutron/+bug/1334926 .. [#] https://review.openstack.org/#/c/124375/ Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ As stated above, there will be no need to tune conntrack to handle a high volume of connections by either increasing the size of the connection table or decreasing the timeout to clean out stale entries. The entries are not needed. Conntrack will not be invoked to inspect packets through the floating IP addresses. This change will result in more packets being matched in the iptables raw tables. Since this table's rules are checked before conntrack, every packet will be checked against the new rules in the PREROUTING and POSTROUTING chains of the raw and rawpost tables respectively. I expect that the performance savings from bypassing conntrack IPv6 Impact ----------- Since IPv6 does not have a floating IP implementation in Neutron, there is no effect. Other Deployer Impact --------------------- Deployers will be required to install xtable-addons before this feature can be used. I have not fully assessed the availability of this package in all distributions. I suspect that some distributions may not package it. For this reason, I may need to make this an optional feature that is turned off by default. Developer Impact ---------------- None Community Impact ---------------- Performance and security impact Alternatives ------------ The kernel once had stateless nat built in to the routing rules feature [#]_. This was removed (or deprecated) long ago and so it is not viable:: --> ip rule add nat 205.254.211.17 from 192.168.100.17 Warning: route NAT is deprecated --> ip route add nat 205.254.211.17 via 192.168.100.17 RTNETLINK answers: Invalid argument .. [#] http://linux-ip.net/html/nat-stateless.html Stateless nat can apparently be accomplished using tc [#]_. I chose to pursue the RAWSNAT and RAWDNAT method because it is more familiar to the community which does not -- as a whole -- have expertise with tc. .. [#] http://www.linuxalgorithm.com/2898840/ Implementation ============== Assignee(s) ----------- Primary assignee: none yet Other assignees: `carl-baldwin <https://launchpad.net/~carl-baldwin>`_ Work Items ---------- #. Assess the availability of the xtables-addons package #. Implement it. Dependencies ============ Depends on xtable-addons package. Testing ======= Full unit test coverage will be add or maintained for the parts of code that need to be touched to implement this new feature. Existing higher-level will be sufficient since this blueprint does not change the nature of floating ips from an external observer's point of view. If we need to support this new feature as an optional one with the default off then we may need to assess whether it needs to be enabled in CI tests. At the least, a patch to enable the feature will be used to run tests. Tempest Tests ------------- Existing Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== The dependency on xtable-addons will be documented for deployers. If the feature is enabled with a configuration option then that will need to be documented too. User Documentation ------------------ None Developer Documentation ----------------------- None References ========== See inline references throughout the document. ",,248,0
openstack%2Foslo.messaging~master~I95c7c2b87735dae3e98ad401d05cf382022c1199,openstack/oslo.messaging,master,I95c7c2b87735dae3e98ad401d05cf382022c1199,Updated from global requirements,MERGED,2015-06-09 20:04:24.000000000,2015-06-11 13:27:40.000000000,2015-06-11 13:27:39.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-06-09 20:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b032966c2508dd96fe619a809de407e9b7e48287', 'message': 'Updated from global requirements\n\nChange-Id: I95c7c2b87735dae3e98ad401d05cf382022c1199\n'}, {'number': 2, 'created': '2015-06-10 21:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4b9992bbd954c61fa4eeb953cce909ede3feef7a', 'message': 'Updated from global requirements\n\nChange-Id: I95c7c2b87735dae3e98ad401d05cf382022c1199\n'}, {'number': 3, 'created': '2015-06-11 00:47:50.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2f14ca162f182d04af9e29cc8f7184f974d45e4d', 'message': 'Updated from global requirements\n\nChange-Id: I95c7c2b87735dae3e98ad401d05cf382022c1199\n'}]",0,189911,2f14ca162f182d04af9e29cc8f7184f974d45e4d,11,2,3,11131,,,0,"Updated from global requirements

Change-Id: I95c7c2b87735dae3e98ad401d05cf382022c1199
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/11/189911/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,b032966c2508dd96fe619a809de407e9b7e48287,openstack/requirements,"oslo.middleware>=1.2.0,!=2.0.0 # Apache-2.0",oslo.middleware>=1.2.0 # Apache-2.0,2,2
openstack%2Fnova-specs~master~Idc104f70820e2796aa0d093118e7e7fe15318986,openstack/nova-specs,master,Idc104f70820e2796aa0d093118e7e7fe15318986,Cells instance migration,MERGED,2014-11-21 21:07:36.000000000,2015-06-11 13:23:15.000000000,2015-06-11 13:23:14.000000000,"[{'_account_id': 3}, {'_account_id': 136}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 2033}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6687}, {'_account_id': 7166}, {'_account_id': 9420}, {'_account_id': 12548}, {'_account_id': 12898}, {'_account_id': 13530}]","[{'number': 1, 'created': '2014-11-21 21:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bdadd2c67e95566894af9f7ad05feaf023ca47f0', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 2, 'created': '2014-11-24 19:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/69776894c77b123340f67e4e4791dc6453b76f5a', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 3, 'created': '2015-01-13 15:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5877b16e82b9bee579d65f5ff21c1348b1e25699', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 4, 'created': '2015-01-14 14:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/825246f4b27df276289a4b123c750162f7e2e065', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 5, 'created': '2015-01-15 19:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8452d65138f826f14a266f6b55688144f33dfef0', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 6, 'created': '2015-03-25 13:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/11ddfe7108a1696a7a1bff8c503d6d3a0f1fc137', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 7, 'created': '2015-04-01 20:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bb2e668707fd2a08332152098f37daa98911f367', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}, {'number': 8, 'created': '2015-06-09 14:52:31.000000000', 'files': ['specs/liberty/approved/cells-instance-migration.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7431b51b06f173b8965f00df0aa44b55984f43fb', 'message': 'Cells instance migration\n\nSpec for migrating data into the instance_mapping table used for\ntracking which instance is in which cell.\n\nbp cells-instance-migration\n\nChange-Id: Idc104f70820e2796aa0d093118e7e7fe15318986\n'}]",34,136490,7431b51b06f173b8965f00df0aa44b55984f43fb,53,15,8,5441,,,0,"Cells instance migration

Spec for migrating data into the instance_mapping table used for
tracking which instance is in which cell.

bp cells-instance-migration

Change-Id: Idc104f70820e2796aa0d093118e7e7fe15318986
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/90/136490/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/cells-instance-migration.rst'],1,bdadd2c67e95566894af9f7ad05feaf023ca47f0,bp/cells-instance-migration,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Cells instance migration ========================================== https://blueprints.launchpad.net/nova/+spec/cells-instance-migration Now that there's a table to map instances to cells it needs to be populated with data on instances that exist prior to its creation and usage. Problem description =================== When Nova is partitioned into cells, the compute api needs to know which cell to communicate with for a particular instance. Instances that exist from before this mapping was maintained need to have their location added to the table. Use Cases ---------- * Operators want to partition their deployments into cells for scaling, failure domain, and buildout reasons. When partitioned, we need a lookup table to know which partition an instance is in. That lookup table needs to be populated with information on instances that exist prior to its creation. Project Priority ----------------- Cells v2 has been made a project priority for Kilo. Proposed change =============== The 'instance_mapping' table will be populated with data on which cell an instance lives in. There are two cases to consider: In a deployment not using cellsv1 a new v2 cell should be added and then all instances can be mapped to that cell. In a deployment using cellsv1 new v2 cells should be created with the same names as the current cells and then instances can be mapped to the new cells one at a time. And there are two methods we can use to populate this data. If a v2 cell is configured and we can match an instance to that cell then we can create the mapping as the instance is accessed through its pre cells v2 method. Additionally a new nova-manage command will be added to do an manual migration at any time. Alternatives ------------ We could continue to use the nova-cells model in place today. The downsides of this have been discussed in the etherpad link in the references section. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ On its own this change does not introduce a performance impact. When it's used by later specs it does introduce another database lookup for many actions within Nova. For example a 'nova show <uuid>' will require Nova to look up the database that an instance is in before it can query it for instance data. This can be optimized later with a memcached cache of this mapping. Other deployer impact --------------------- Deployers will be provided with a new nova-manage command to trigger the creation of the mappings. This should be run once for a deployment not currently using cells, and once in each cell for a deployment currently using cells. This migration can be run at any time but should be run a final time before switching over to using cells v2. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: alaski Other contributors: None Work Items ---------- * Add database migration for 'instance_mapping' table. Dependencies ============ https://blueprints.launchpad.net/nova/+spec/cells-instance-mapping Testing ======= Since this is designed to be an internal re-architecting of Nova with no user visible changes the current suite of Tempest or functional tests should suffice. At some point we will want to look at how to test multiple cells or potentially exposing the concept of a cell in the API and we will tackle testing requirements then. Documentation Impact ==================== Documentation on the new nova-manage command will need to be written. References ========== ``https://etherpad.openstack.org/p/kilo-nova-cells`` ",,158,0
openstack%2Fopenstacksdk~master~I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c,openstack/openstacksdk,master,I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c,Updated from global requirements,MERGED,2015-06-04 20:15:21.000000000,2015-06-11 13:22:39.000000000,2015-06-11 13:22:38.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-04 20:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e08252e8c1f2ebdcb9a54076be77c11673385c28', 'message': 'Updated from global requirements\n\nChange-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c\n'}, {'number': 2, 'created': '2015-06-08 21:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/db09dad50f871ce50e475aebd175df51f682811d', 'message': 'Updated from global requirements\n\nChange-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c\n'}, {'number': 3, 'created': '2015-06-09 20:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8cd5aab9e6c9e0f3640a2f932d4e764805e31468', 'message': 'Updated from global requirements\n\nChange-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c\n'}, {'number': 4, 'created': '2015-06-10 21:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5074450e6e3c2164a24b15032d867a92cefa83ca', 'message': 'Updated from global requirements\n\nChange-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c\n'}, {'number': 5, 'created': '2015-06-11 00:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3d118c5d1ce6d5787c05c89ee375fd3803b7aa00', 'message': 'Updated from global requirements\n\nChange-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c\n'}, {'number': 6, 'created': '2015-06-11 12:41:44.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/503546612d0fa8788f1e36f1282726d07e4a4f89', 'message': 'Updated from global requirements\n\nChange-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c\n'}]",0,188571,503546612d0fa8788f1e36f1282726d07e4a4f89,19,3,6,11131,,,0,"Updated from global requirements

Change-Id: I4bb0cbe9fb81bbc1e3fd86d19cca74356780630c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/71/188571/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e08252e8c1f2ebdcb9a54076be77c11673385c28,openstack/requirements,os-client-config>=1.2.0,os-client-config,1,1
openstack%2Ftripleo-puppet-elements~master~I8b7adff6f05f864115071c51810b41efad887584,openstack/tripleo-puppet-elements,master,I8b7adff6f05f864115071c51810b41efad887584,Install fence agents on the controller image,MERGED,2015-05-26 13:48:03.000000000,2015-06-11 13:22:31.000000000,2015-06-11 13:22:30.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-05-26 13:48:03.000000000', 'files': ['elements/overcloud-controller/pkg-map', 'elements/overcloud-controller/install.d/package-installs-overcloud-controller'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/d1b75d2df3e7bcefc618af696fa75c9e50f8b4e1', 'message': 'Install fence agents on the controller image\n\nInstalls fence-agents-all, and also fence-virt package to provide\nfence_xvm.\n\nChange-Id: I8b7adff6f05f864115071c51810b41efad887584\n'}]",0,185597,d1b75d2df3e7bcefc618af696fa75c9e50f8b4e1,12,5,1,8042,,,0,"Install fence agents on the controller image

Installs fence-agents-all, and also fence-virt package to provide
fence_xvm.

Change-Id: I8b7adff6f05f864115071c51810b41efad887584
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/97/185597/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/overcloud-controller/pkg-map', 'elements/overcloud-controller/install.d/package-installs-overcloud-controller']",2,d1b75d2df3e7bcefc618af696fa75c9e50f8b4e1,fencing,fence_agents_package fence_virt_package,,4,0
openstack%2Fpuppet-neutron~master~I4824c09e6af4a800b5ac0c22bf5daea99452bd7e,openstack/puppet-neutron,master,I4824c09e6af4a800b5ac0c22bf5daea99452bd7e,Fix support for auth_uri setting in neutron provider,MERGED,2015-05-12 16:16:34.000000000,2015-06-11 13:18:18.000000000,2015-06-09 15:29:18.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-05-12 16:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5236df5d2e267f23974b234b8b5b5c79e8852c04', 'message': 'Fix support for auth_uri setting in neutron provider\n\nChange-Id: I4824c09e6af4a800b5ac0c22bf5daea99452bd7e\n'}, {'number': 2, 'created': '2015-05-13 12:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5c565b4e23df798c030284a303653208687b1877', 'message': 'Fix support for auth_uri setting in neutron provider\n\nChange-Id: I4824c09e6af4a800b5ac0c22bf5daea99452bd7e\n'}, {'number': 3, 'created': '2015-05-14 11:46:36.000000000', 'files': ['lib/puppet/provider/neutron.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/6fb01efe21669a1a2408ca7aba0efc421cb51bd9', 'message': ""Fix support for auth_uri setting in neutron provider\n\nNeutron provider still uses auth_port and auth_host config\noptions even though those are now deprecated and won't be set\nif someone chooses to use auth_uri. This commit adds support\nfor auth_uri and keeps the provider backwards compatible.\n\n\nChange-Id: I4824c09e6af4a800b5ac0c22bf5daea99452bd7e\n""}]",0,182374,6fb01efe21669a1a2408ca7aba0efc421cb51bd9,21,4,3,11166,,,0,"Fix support for auth_uri setting in neutron provider

Neutron provider still uses auth_port and auth_host config
options even though those are now deprecated and won't be set
if someone chooses to use auth_uri. This commit adds support
for auth_uri and keeps the provider backwards compatible.


Change-Id: I4824c09e6af4a800b5ac0c22bf5daea99452bd7e
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/74/182374/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/neutron.rb'],1,5236df5d2e267f23974b234b8b5b5c79e8852c04,," auth_keys = ['admin_tenant_name', 'admin_user', 'admin_password'] deprecated_auth_url = ['auth_host', 'auth_port', 'auth_protocol'] auth_keys.all?{|k| !conf['keystone_authtoken'][k].nil?} and ( deprecated_auth_url.all?{|k| !conf['keystone_authtoken'][k].nil?} or !conf['keystone_authtoken']['auth_uri'].nil? ) if !conf['keystone_authtoken']['auth_uri'].nil? creds['auth_uri'] = conf['keystone_authtoken']['auth_uri'] else q = conf['keystone_authtoken'] creds['auth_uri'] = ""#{q['auth_protocol']}://#{q['auth_host']}:#{q['auth_port']}/v2.0/"" end ""#{q['auth_uri']}"".strip"," auth_keys = ['auth_host', 'auth_port', 'auth_protocol', 'admin_tenant_name', 'admin_user', 'admin_password'] auth_keys.all?{|k| !conf['keystone_authtoken'][k].nil?} ""#{q['auth_protocol']}://#{q['auth_host']}:#{q['auth_port']}/v2.0/""",12,4
openstack%2Ffuel-devops~master~I0e6ec4ea84d0d8da315cc5296f8d46c495120bca,openstack/fuel-devops,master,I0e6ec4ea84d0d8da315cc5296f8d46c495120bca,Cleanup in running pep8 tests,MERGED,2015-06-03 08:18:13.000000000,2015-06-11 13:18:10.000000000,2015-06-11 13:18:10.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-06-03 08:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a435d21e14d0213cd772b989ceec6ecdeba3de17', 'message': 'Cleanup in running pep8 tests\n\nNew hacking (0.10.1)\nUpdated flake8 ignores\nrun_tests.sh will call tox\n\nChange-Id: I0e6ec4ea84d0d8da315cc5296f8d46c495120bca\n'}, {'number': 2, 'created': '2015-06-08 07:57:13.000000000', 'files': ['run_tests.sh', 'tox.ini', 'devops/helpers/scancodes.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/17f8a1462769917b8945457e236786738e9ba5eb', 'message': 'Cleanup in running pep8 tests\n\nNew hacking (0.10.1)\nUpdated flake8 ignores\nrun_tests.sh will call tox\n\nPartial-Bug: #1462906\nChange-Id: I0e6ec4ea84d0d8da315cc5296f8d46c495120bca\n'}]",1,187902,17f8a1462769917b8945457e236786738e9ba5eb,15,7,2,12200,,,0,"Cleanup in running pep8 tests

New hacking (0.10.1)
Updated flake8 ignores
run_tests.sh will call tox

Partial-Bug: #1462906
Change-Id: I0e6ec4ea84d0d8da315cc5296f8d46c495120bca
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/02/187902/2 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini', 'devops/helpers/scancodes.py']",3,a435d21e14d0213cd772b989ceec6ecdeba3de17,enable_test, return scancodes , return scancodes,12,9
openstack%2Ffuel-devops~master~Ica5910774c8196cb24709939c708c3df20ba2708,openstack/fuel-devops,master,Ica5910774c8196cb24709939c708c3df20ba2708,Update .gitignore,MERGED,2015-06-03 10:26:22.000000000,2015-06-11 13:16:23.000000000,2015-06-11 13:16:23.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11082}, {'_account_id': 11969}, {'_account_id': 12200}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-06-03 10:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/93a8998b2b9a1366a53ba1d8dd68839daa902129', 'message': 'Update .gitignore\n\nChange-Id: Ica5910774c8196cb24709939c708c3df20ba2708\n'}, {'number': 2, 'created': '2015-06-08 07:47:15.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/d11e64c64fd7a49a74ed867935b3b418ef54587b', 'message': 'Update .gitignore\n\nCloses-Bug: #1462900\n\nChange-Id: Ica5910774c8196cb24709939c708c3df20ba2708\n'}]",2,187938,d11e64c64fd7a49a74ed867935b3b418ef54587b,17,9,2,12200,,,0,"Update .gitignore

Closes-Bug: #1462900

Change-Id: Ica5910774c8196cb24709939c708c3df20ba2708
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/38/187938/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,93a8998b2b9a1366a53ba1d8dd68839daa902129,gitignore,"# Byte-compiled / optimized / DLL files __pycache__/ *.py[cod] # C extensions *.so # Distribution / packaging .Python env/ build/ develop-eggs/ dist/ downloads/ eggs/ lib/ lib64/ parts/ sdist/ var/ *.egg-info/ .installed.cfg *.egg # PyInstaller # Usually these files are written by a python script from a template # before PyInstaller builds the exe, so as to inject date/other infos into it. *.manifest *.spec # Installer logs pip-log.txt pip-delete-this-directory.txt # Unit test / coverage reports htmlcov/ .tox/ .coverage .cache nosetests.xml coverage.xml # Translations *.mo *.pot # Django stuff: *.log # Sphinx documentation docs/_build/ # PyBuilder target/ # OtherMANIFEST",build dist MANIFEST*.pyc.tox,57,5
openstack%2Fdevstack-gate~master~I557e9d7d35239b9336b6d90f037f14cdf2585f76,openstack/devstack-gate,master,I557e9d7d35239b9336b6d90f037f14cdf2585f76,"Revert ""Revert ""only force off KEYSTONE_USE_WSGI up until kilo""""",MERGED,2015-06-11 10:49:25.000000000,2015-06-11 13:11:20.000000000,2015-06-11 13:11:18.000000000,"[{'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-06-11 10:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/76311742561237419424fce218d86b0d39e6819a', 'message': 'Revert ""Revert ""only force off KEYSTONE_USE_WSGI up until kilo""""\n\nThis reverts commit ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda.\n\nChange-Id: I557e9d7d35239b9336b6d90f037f14cdf2585f76\n'}, {'number': 2, 'created': '2015-06-11 10:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/b8e313cbe4a3f5cccd73484ad1771a43ffd5d695', 'message': 'Revert ""Revert ""only force off KEYSTONE_USE_WSGI up until kilo""""\n\nThis reverts commit ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda.\n\nThis was never the correct fix, it just masked the root problem. This\ncorrectly was setting the variables but there was a bug in grenade that made this not do the right thing on stable/kilo because of a missing \nsource include.\n\nThat\'s where it should have been fixed.\n\nRelated-Bug: #1456835\n\nChange-Id: I557e9d7d35239b9336b6d90f037f14cdf2585f76'}, {'number': 3, 'created': '2015-06-11 10:57:09.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/0ad1d662e3b52d52a4236722bd0bdf2bcaf47f98', 'message': 'Revert ""Revert ""only force off KEYSTONE_USE_WSGI up until kilo""""\n\nThis reverts commit ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda.\n\nThis was never the correct fix, it just masked the root problem. This\ncorrectly was setting the variables but there was a bug in grenade that\nmade this not do the right thing on stable/kilo because of a missing \nsource include.\n\nThat\'s where it should have been fixed.\n\nRelated-Bug: #1456835\n\nChange-Id: I557e9d7d35239b9336b6d90f037f14cdf2585f76'}]",0,190576,0ad1d662e3b52d52a4236722bd0bdf2bcaf47f98,7,2,3,2750,,,0,"Revert ""Revert ""only force off KEYSTONE_USE_WSGI up until kilo""""

This reverts commit ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda.

This was never the correct fix, it just masked the root problem. This
correctly was setting the variables but there was a bug in grenade that
made this not do the right thing on stable/kilo because of a missing 
source include.

That's where it should have been fixed.

Related-Bug: #1456835

Change-Id: I557e9d7d35239b9336b6d90f037f14cdf2585f76",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/76/190576/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,76311742561237419424fce218d86b0d39e6819a,stable_kilo," case $GRENADE_BASE_BRANCH in ""stable/icehouse"") ;& ""stable/juno"") echo ""KEYSTONE_USE_MOD_WSGI=False"" >> ""$localrc_file"" ;; esac"," echo ""KEYSTONE_USE_MOD_WSGI=False"" >> ""$localrc_file""",7,1
openstack%2Ffuel-library~stable%2F6.1~I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a,openstack/fuel-library,stable/6.1,I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a,Set value for 'pool_maxsize' in keystone,MERGED,2015-06-09 16:49:47.000000000,2015-06-11 13:10:41.000000000,2015-06-11 09:49:26.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10068}, {'_account_id': 11090}, {'_account_id': 13055}, {'_account_id': 14168}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-06-09 16:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/54cccc8fb8b5264004f083fb38e1ddc411eb5422', 'message': ' Set new keystone value for\n section: [memcache] parameter: ""pool_maxsize"" to 100\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\nCloses-Bug:#1455099\n'}, {'number': 2, 'created': '2015-06-09 16:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/73c1557c922fede4652ca17d3540e5162d4f9503', 'message': ' Set new keystone value for\n section: [memcache] parameter: ""pool_maxsize"" to 100\n\nCloses-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n'}, {'number': 3, 'created': '2015-06-10 08:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b97ef9ff1d05815c60dcdab501800141f3589820', 'message': "" Set value for 'pool_maxsize' in keystone\n\n Set  new parameter 'pool_maxsize' for memcache.\n Default value was set to 100 to fix an issue\n with getting token from keystone after 10 sec timeout.\n\n Closes-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n""}, {'number': 4, 'created': '2015-06-10 08:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8878d5997a4ccc51efdb8aee53e86e767c9263be', 'message': "" Set value for 'pool_maxsize' in keystone\n\n Set  new parameter 'pool_maxsize' for memcache.\n Default value was set to 100 to fix an issue with\n getting token from keystone after 10 sec timeout.\n\n Closes-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n""}, {'number': 5, 'created': '2015-06-10 10:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f1b5c85244b6fc97c0ba1e6871ae2df78e274595', 'message': "" Set value for 'pool_maxsize' in keystone\n\n Set  new parameter 'pool_maxsize' for memcache.\n Default value was set to 100 to fix an issue with\n getting token from keystone after 10 sec timeout.\n\n Closes-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n""}, {'number': 6, 'created': '2015-06-10 10:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f11c6551cd8ce2ec928ae2c98b0ebe28d496f6ec', 'message': "" Set value for 'pool_maxsize' in keystone\n\n Set  new parameter 'pool_maxsize' for memcache.\n Default value was set to 100 to fix an issue with\n getting token from keystone after 10 sec timeout.\n\n Closes-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n""}, {'number': 7, 'created': '2015-06-10 10:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/14ea9a2665a76dd1822edec0143319e1c5ea38b3', 'message': "" Set value for 'pool_maxsize' in keystone\n\n Set  new parameter 'pool_maxsize' for memcache.\n Default value was set to 100 to fix an issue with\n getting token from keystone after 10 sec timeout.\n\n Closes-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n""}, {'number': 8, 'created': '2015-06-10 11:00:39.000000000', 'files': ['deployment/puppet/openstack/manifests/keystone.pp', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2a91007bfb0058a113cc1733360944cffba5987d', 'message': "" Set value for 'pool_maxsize' in keystone\n\n Set  new parameter 'pool_maxsize' for memcache.\n Default value was set to 100 to fix an issue with\n getting token from keystone after 10 sec timeout.\n\n Closes-Bug:#1455099\n\nChange-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a\n""}]",1,189811,2a91007bfb0058a113cc1733360944cffba5987d,71,11,8,14007,,,0," Set value for 'pool_maxsize' in keystone

 Set  new parameter 'pool_maxsize' for memcache.
 Default value was set to 100 to fix an issue with
 getting token from keystone after 10 sec timeout.

 Closes-Bug:#1455099

Change-Id: I0dd9b572d3b78c3d30cbfb4e000a457fd69d5e3a
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/11/189811/8 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/keystone.pp', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp']",2,54cccc8fb8b5264004f083fb38e1ddc411eb5422,6.1,"$memcache_pool_maxsize = 100 memcache_pool_maxsize => $memcache_pool_maxsize,",,5,0
openstack%2Fhorizon~master~I66b83a695046610aa44c9efdf44895fcd977e62b,openstack/horizon,master,I66b83a695046610aa44c9efdf44895fcd977e62b,JSCS Cleanup - style guide cleanup for toast,MERGED,2015-06-09 01:28:32.000000000,2015-06-11 13:06:09.000000000,2015-06-11 13:06:06.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10881}, {'_account_id': 11881}, {'_account_id': 13785}, {'_account_id': 13805}, {'_account_id': 14307}]","[{'number': 1, 'created': '2015-06-09 01:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ef00d4987265e8a16264cfb9e2ecd45604b7bf6f', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 2, 'created': '2015-06-09 01:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aa7530f21e7d5f7530e78314a651e9b3c5e7ddb1', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 3, 'created': '2015-06-09 17:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b5ee550b7da928152013ce587e95b44abb509534', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 4, 'created': '2015-06-09 18:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ffe94a98495f0f7d7527e6ec7752b5a24432c1dd', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 5, 'created': '2015-06-10 01:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4d68ea3348244bedd6c165649d1735949b9cbf9a', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 6, 'created': '2015-06-10 01:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4f199e67d2cfde7ef8b15f30f419060cba75e8f6', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 7, 'created': '2015-06-10 22:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7169dd8121f1ee4a86a812468391030413441439', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 8, 'created': '2015-06-10 22:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ddc195ed877aa9bca0d79f0119145339ffcc778f', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}, {'number': 9, 'created': '2015-06-11 00:58:23.000000000', 'files': ['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/toast/toast.directive.js', 'horizon/static/framework/widgets/toast/toast.module.js', 'horizon/static/framework/widgets/toast/toast.html', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/karma.conf.js', 'horizon/static/framework/widgets/toast/toast.factory.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3137401f24b43de6ecbf1f3c09c6a8c6e12e9298', 'message': ""JSCS Cleanup - style guide cleanup for toast\n\nFollowing John Papa's style guide\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors the Angular code for 'toast' module.\n\nChange-Id: I66b83a695046610aa44c9efdf44895fcd977e62b\nPartially-Implements: blueprint jscs-cleanup\n""}]",9,189524,3137401f24b43de6ecbf1f3c09c6a8c6e12e9298,31,9,9,9622,,,0,"JSCS Cleanup - style guide cleanup for toast

Following John Papa's style guide
https://github.com/johnpapa/angular-styleguide,
this patch refactors the Angular code for 'toast' module.

Change-Id: I66b83a695046610aa44c9efdf44895fcd977e62b
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/24/189524/7 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/toast/toast.directive.js', 'horizon/static/framework/widgets/toast/toast.module.js', 'horizon/templates/horizon/_scripts.html', 'horizon/test/jasmine/jasmine_tests.py', 'horizon/karma.conf.js', 'horizon/static/framework/widgets/toast/toast.factory.js']",7,ef00d4987265e8a16264cfb9e2ecd45604b7bf6f,bp/jscs-cleanup,"/* * Copyright 2015 IBM Corp. * * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function() { 'use_strict'; /** * @ngdoc service * @name toastService * * @description * This service can be used to display user messages, toasts, in Horizon. * To create a new toast, inject the 'horizon.framework.widgets.toast.service' module into your * current module. Then, use the service methods. * * For example to add a 'success' message: * toastService.add('success', 'User successfully created.'); * * All actions (add, clearAll, etc.) taken on the data are automatically * sync-ed with the HTML. */ angular .module('horizon.framework.widgets.toast') .factory('horizon.framework.widgets.toast.service', toastService); function toastService() { var toasts = []; var service = { types: {}, add: add, close: close, get: get, clearAll: clearAll, clearErrors: clearErrors, clearSuccesses: clearSuccesses }; /** * There are 5 types of toasts, which are based off Bootstrap alerts. */ service.types = { danger: gettext('Danger'), warning: gettext('Warning'), info: gettext('Info'), success: gettext('Success'), error: gettext('Error') }; return service; /////////////////////// /** * Helper method used to remove all the toasts matching the 'type' * passed in. */ function clear(type) { for (var i = toasts.length - 1; i >= 0; i--) { if (toasts[i].type === type) { toasts.splice(i, 1); } } } /** * Create a toast object and push it to the toasts array. */ function add(type, msg) { var toast = { type: type === 'error' ? 'danger' : type, typeMsg: this.types[type], msg: msg, close: function(index) { toasts.splice(index, 1); } }; toasts.push(toast); }; /** * Remove a single toast. */ function close(index) { toasts.splice(index, 1); }; /** * Return all toasts. */ function get() { return toasts; }; /** * Remove all toasts. */ function clearAll() { toasts = []; }; /** * Remove all toasts of type 'danger.' */ function clearErrors() { clear('danger'); }; /** * Remove all toasts of type 'success.' */ function clearSuccesses() { clear('success'); }; } })(); ",,230,164
openstack%2Ffuel-library~master~Iac5076532e25295f6d9abbb9e9c1b4213931d1da,openstack/fuel-library,master,Iac5076532e25295f6d9abbb9e9c1b4213931d1da,Fixed issue with keystone memcache,MERGED,2015-06-10 16:20:32.000000000,2015-06-11 13:05:50.000000000,2015-06-11 12:52:21.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11090}, {'_account_id': 13055}, {'_account_id': 13478}, {'_account_id': 13962}, {'_account_id': 14691}, {'_account_id': 14774}, {'_account_id': 16044}]","[{'number': 1, 'created': '2015-06-10 16:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/29368e472b98b314745b280e0f233ede0f8b5eb7', 'message': ""Fixed issue with keystone memcache\n\nWith the default value for the 'dead_timeout' recovery\nof keystone memcache service can take more than 3 minutes.\nThis parameter allows to degrease this timeout to 20-30 seconds.\n\nChange-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da\nCloses-Bug: #1461036\n""}, {'number': 2, 'created': '2015-06-10 16:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cbf5f770ba4b3f75b6a52e6e774381426a424fcd', 'message': ""Fixed issue with keystone memcache\n\nWith the default value for the 'dead_timeout' recovery\nof keystone memcache service can take more than 3 minutes.\nThis parameter allows to reduce this timeout to 20-30 seconds.\n\nChange-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da\nCloses-Bug: #1461036\n""}, {'number': 3, 'created': '2015-06-11 10:08:40.000000000', 'files': ['deployment/puppet/openstack/manifests/keystone.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8f461c226471bd6dc6122387b92f0fc226465773', 'message': ""Fixed issue with keystone memcache\n\nWith the default value for the 'dead_timeout' recovery\nof keystone memcache service can take more than 3 minutes.\nThis parameter allows to reduce this timeout to 20-30 seconds.\n\nChange-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da\nCloses-Bug: #1461036\n""}]",0,190248,8f461c226471bd6dc6122387b92f0fc226465773,61,13,3,7227,,,0,"Fixed issue with keystone memcache

With the default value for the 'dead_timeout' recovery
of keystone memcache service can take more than 3 minutes.
This parameter allows to reduce this timeout to 20-30 seconds.

Change-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da
Closes-Bug: #1461036
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/48/190248/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/keystone.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb']",2,29368e472b98b314745b280e0f233ede0f8b5eb7,bug/1461036, should contain_keystone_config('memcache/dead_retry').with(:value => '30'),,2,0
openstack%2Ffuel-library~stable%2F6.1~Iac5076532e25295f6d9abbb9e9c1b4213931d1da,openstack/fuel-library,stable/6.1,Iac5076532e25295f6d9abbb9e9c1b4213931d1da,Fixed issue with keystone memcache,MERGED,2015-06-10 16:26:07.000000000,2015-06-11 12:57:08.000000000,2015-06-11 12:57:07.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 11090}, {'_account_id': 13055}, {'_account_id': 13478}, {'_account_id': 13962}, {'_account_id': 14510}, {'_account_id': 14691}]","[{'number': 1, 'created': '2015-06-10 16:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9501893fc0e3df87386184ba0d768fe749ec9150', 'message': ""Fixed issue with keystone memcache\n\nWith the default value for the 'dead_timeout' recovery\nof keystone memcache service can take more than 3 minutes.\nThis parameter allows to degrease this timeout to 20-30 seconds.\n\nChange-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da\nCloses-Bug: #1461036\n""}, {'number': 2, 'created': '2015-06-10 16:27:46.000000000', 'files': ['deployment/puppet/openstack/manifests/keystone.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bf1382cfacc85bfc58cb49f98ce4ce13fa01d651', 'message': ""Fixed issue with keystone memcache\n\nWith the default value for the 'dead_timeout' recovery\nof keystone memcache service can take more than 3 minutes.\nThis parameter allows to reduce this timeout to 20-30 seconds.\n\nChange-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da\nCloses-Bug: #1461036\n""}]",0,190249,bf1382cfacc85bfc58cb49f98ce4ce13fa01d651,25,13,2,7227,,,0,"Fixed issue with keystone memcache

With the default value for the 'dead_timeout' recovery
of keystone memcache service can take more than 3 minutes.
This parameter allows to reduce this timeout to 20-30 seconds.

Change-Id: Iac5076532e25295f6d9abbb9e9c1b4213931d1da
Closes-Bug: #1461036
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/49/190249/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/keystone.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb']",2,9501893fc0e3df87386184ba0d768fe749ec9150,bug/1461036, should contain_keystone_config('memcache/dead_retry').with(:value => '30'),,2,0
openstack%2Ftempest~master~I0fbc02a2bc8badbb1792870c34495b913572af0a,openstack/tempest,master,I0fbc02a2bc8badbb1792870c34495b913572af0a,Fix L3AgentSchedulerTestJSON failure for dvr routers,MERGED,2015-06-04 23:47:26.000000000,2015-06-11 12:54:20.000000000,2015-06-11 12:54:18.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-04 23:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a6b9a18bacc1f4a1aec2f95f397f41f7886d04a5', 'message': 'Fix L3AgentSchedulerTestJSON failure for dvr routers\n\nIn L3AgentSchedulerTestJSON test class, the resource\nsetup method has special handling for the dvr routers,\nsince DVR Routers require a valid subnet with port for\nthe routers to be scheduled.\n\nBut in the case of Non-DVR Routers this was not required.\n\nThe resource cleanup method was missing in this test class.\nBut the Super class resource cleanup method was not aware\nabout the DVR Router and existence of the router owned ports\nand hence was trying to delete the port before it removed\nthe router.\n\nThis patch fixes the problem by creaing a resource cleanup\nmethod in L3AgentSchedulerTestJSON and cleans up the\ninterface and subnet added for the DVR Router.\n\nChange-Id: I0fbc02a2bc8badbb1792870c34495b913572af0a\nCloses-Bug: #1462150\n'}, {'number': 2, 'created': '2015-06-05 00:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b1e39d3cfbc2621dd9b1fd5bd83025ec5503fabf', 'message': 'Fix L3AgentSchedulerTestJSON failure for dvr routers\n\nIn L3AgentSchedulerTestJSON test class, the resource\nsetup method has special handling for the dvr routers,\nsince DVR Routers require a valid subnet with port for\nthe routers to be scheduled.\n\nBut in the case of Non-DVR Routers this was not required.\n\nThe resource cleanup method was missing in this test class.\nBut the Super class resource cleanup method was not aware\nabout the DVR Router and existence of the router owned ports\nand hence was trying to delete the port before it removed\nthe router.\n\nThis patch fixes the problem by creaing a resource cleanup\nmethod in L3AgentSchedulerTestJSON and cleans up the\ninterface and subnet added for the DVR Router.\n\nChange-Id: I0fbc02a2bc8badbb1792870c34495b913572af0a\nCloses-Bug: #1462150\n'}, {'number': 3, 'created': '2015-06-05 00:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/36d9e6632cafad44ccb5667fe339b9536f1760c6', 'message': 'Fix L3AgentSchedulerTestJSON failure for dvr routers\n\nIn L3AgentSchedulerTestJSON test class, the resource\nsetup method has special handling for the dvr routers,\nsince DVR Routers require a valid subnet with port for\nthe routers to be scheduled.\n\nBut in the case of Non-DVR Routers this was not required.\n\nThe resource cleanup method was missing in this test class.\nBut the Super class resource cleanup method was not aware\nabout the DVR Router and existence of the router owned ports\nand hence was trying to delete the port before it removed\nthe router.\n\nThis patch fixes the problem by creaing a resource cleanup\nmethod in L3AgentSchedulerTestJSON and cleans up the\ninterface and subnet added for the DVR Router.\n\nChange-Id: I0fbc02a2bc8badbb1792870c34495b913572af0a\nCloses-Bug: #1462150\n'}, {'number': 4, 'created': '2015-06-05 00:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ebe65e3e7e1bf980d0d26580b49b8697e5d5546d', 'message': 'Fix L3AgentSchedulerTestJSON failure for dvr routers\n\nIn L3AgentSchedulerTestJSON test class, the resource\nsetup method has special handling for the dvr routers,\nsince DVR Routers require a valid subnet with port for\nthe routers to be scheduled.\n\nBut in the case of Non-DVR Routers this was not required.\n\nThe resource cleanup method was missing in this test class.\nBut the Super class resource cleanup method was not aware\nabout the DVR Router and existence of the router owned ports\nand hence was trying to delete the port before it removed\nthe router.\n\nThis patch fixes the problem by creaing a resource cleanup\nmethod in L3AgentSchedulerTestJSON and cleans up the\ninterface and subnet added for the DVR Router.\n\nChange-Id: I0fbc02a2bc8badbb1792870c34495b913572af0a\nCloses-Bug: #1462150\n'}, {'number': 5, 'created': '2015-06-08 17:01:54.000000000', 'files': ['tempest/api/network/admin/test_l3_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae82c97f8b5968750be89dd96e216dcf085cb671', 'message': 'Fix L3AgentSchedulerTestJSON failure for dvr routers\n\nIn L3AgentSchedulerTestJSON test class, the resource\nsetup method has special handling for the dvr routers,\nsince DVR Routers require a valid subnet with port for\nthe routers to be scheduled.\n\nBut in the case of Non-DVR Routers this was not required.\n\nThe resource cleanup method was missing in this test class.\nBut the Super class resource cleanup method was not aware\nabout the DVR Router and existence of the router owned ports\nand hence was trying to delete the port before it removed\nthe router.\n\nThis patch fixes the problem by creaing a resource cleanup\nmethod in L3AgentSchedulerTestJSON and cleans up the\ninterface and subnet added for the DVR Router.\n\nChange-Id: I0fbc02a2bc8badbb1792870c34495b913572af0a\nCloses-Bug: #1462150\n'}]",13,188630,ae82c97f8b5968750be89dd96e216dcf085cb671,32,7,5,7016,,,0,"Fix L3AgentSchedulerTestJSON failure for dvr routers

In L3AgentSchedulerTestJSON test class, the resource
setup method has special handling for the dvr routers,
since DVR Routers require a valid subnet with port for
the routers to be scheduled.

But in the case of Non-DVR Routers this was not required.

The resource cleanup method was missing in this test class.
But the Super class resource cleanup method was not aware
about the DVR Router and existence of the router owned ports
and hence was trying to delete the port before it removed
the router.

This patch fixes the problem by creaing a resource cleanup
method in L3AgentSchedulerTestJSON and cleans up the
interface and subnet added for the DVR Router.

Change-Id: I0fbc02a2bc8badbb1792870c34495b913572af0a
Closes-Bug: #1462150
",git fetch https://review.opendev.org/openstack/tempest refs/changes/30/188630/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/admin/test_l3_agent_scheduler.py'],1,a6b9a18bacc1f4a1aec2f95f397f41f7886d04a5,bug/1462150," @classmethod def resource_cleanup(cls): if test.is_extension_enabled('dvr', 'network'): is_dvr_router = cls.admin_client.show_router( cls.router['id'])['router'].get('distributed', False) if is_dvr_router: cls.client.remove_router_interface_with_port_id( cls.router['id'], cls.port['id']) cls.client.delete_subnet(cls.subnet['id']) super(L3AgentSchedulerTestJSON, cls).resource_setup() ",,11,0
openstack%2Ftripleo-incubator~master~Ia5c59e3867bb1df9efee8288e4b78e96c5554246,openstack/tripleo-incubator,master,Ia5c59e3867bb1df9efee8288e4b78e96c5554246,Get only VM's with the full name matching,ABANDONED,2015-03-19 11:29:36.000000000,2015-06-11 12:48:00.000000000,,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-03-19 11:29:36.000000000', 'files': ['scripts/get-vm-mac'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/8b333ad2f9b3903fdfef723197fdae1d2d270228', 'message': ""Get only VM's with the full name matching\n\nget-vm-mac would grep for a VM for example with the name 'instack'\nand also VM's named 'instack.old' or 'backup-instack' would match.\nThis patch ensures only fully matching names are matched.\n\nChange-Id: Ia5c59e3867bb1df9efee8288e4b78e96c5554246\n""}]",0,165782,8b333ad2f9b3903fdfef723197fdae1d2d270228,9,6,1,11997,,,0,"Get only VM's with the full name matching

get-vm-mac would grep for a VM for example with the name 'instack'
and also VM's named 'instack.old' or 'backup-instack' would match.
This patch ensures only fully matching names are matched.

Change-Id: Ia5c59e3867bb1df9efee8288e4b78e96c5554246
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/82/165782/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/get-vm-mac'],1,8b333ad2f9b3903fdfef723197fdae1d2d270228,get-full-match,"vms=$(sudo virsh list --all | grep "" $VMNAME "" | awk '{ print $2 }')",vms=$(sudo virsh list --all | grep $VMNAME | awk '{ print $2 }'),1,1
openstack%2Fcinder~master~I303a8f7e5c2113103de4658f0c5137a7e060fe83,openstack/cinder,master,I303a8f7e5c2113103de4658f0c5137a7e060fe83,Remove oslo-incubator copy of middleware,ABANDONED,2015-06-09 10:21:50.000000000,2015-06-11 12:44:05.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12369}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16676}]","[{'number': 1, 'created': '2015-06-09 10:21:50.000000000', 'files': ['cinder/openstack/common/middleware/__init__.py', 'cinder/openstack/common/middleware/catch_errors.py', 'cinder/openstack/common/middleware/request_id.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dcb0e81bbeab9e0a4e04f37b0be7c339eeb5be7f', 'message': ""Remove oslo-incubator copy of middleware\n\nWe have moved away from openstack/common/middleware modules\nto the oslo_middlware library. Let's cleanup the remaining files,\nleft here to not breaking grenade in the gate.\n\nChange-Id: I303a8f7e5c2113103de4658f0c5137a7e060fe83\n""}]",0,189638,dcb0e81bbeab9e0a4e04f37b0be7c339eeb5be7f,26,26,1,13636,,,0,"Remove oslo-incubator copy of middleware

We have moved away from openstack/common/middleware modules
to the oslo_middlware library. Let's cleanup the remaining files,
left here to not breaking grenade in the gate.

Change-Id: I303a8f7e5c2113103de4658f0c5137a7e060fe83
",git fetch https://review.opendev.org/openstack/cinder refs/changes/38/189638/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/openstack/common/middleware/__init__.py', 'cinder/openstack/common/middleware/catch_errors.py', 'cinder/openstack/common/middleware/request_id.py']",3,dcb0e81bbeab9e0a4e04f37b0be7c339eeb5be7f,oslo-middlware,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Compatibility shim for Kilo, while operators migrate to oslo.middleware."""""" from oslo_middleware import request_id from cinder.openstack.common import versionutils ENV_REQUEST_ID = 'openstack.request_id' HTTP_RESP_HEADER_REQUEST_ID = 'x-openstack-request-id' @versionutils.deprecated(as_of=versionutils.deprecated.KILO, in_favor_of='oslo_middleware.RequestId') class RequestIdMiddleware(request_id.RequestId): pass ",0,50
openstack%2Fneutron~stable%2Fkilo~I26dc5ce9e46c74423358aa8a9559bc6c7cbdf85e,openstack/neutron,stable/kilo,I26dc5ce9e46c74423358aa8a9559bc6c7cbdf85e,Support BP:ipv6-router in Neutron HA Router,MERGED,2015-06-02 08:54:57.000000000,2015-06-11 12:43:22.000000000,2015-06-09 20:12:51.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10153}, {'_account_id': 10257}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-02 08:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50eaf93605bb9f01ff6f750d774374e3753f3496', 'message': 'Support BP:ipv6-router in Neutron HA Router\n\nblueprint ipv6-router (ChangeID:Iaefa95f788053ded9fc9c7ff6845c3030c6fd6df),\nsupports an IPv6 Router where the router gateway port has no subnet.\n\nThe BP implements the following. If an external network (without any subnet)\nis attached to the Neutron router, it reads the ipv6_gateway config parameter\n(LLA of upstream router) from l3_agent.ini file and adds a default route that\npoints to this LLA.  If the ipv6_gateway config value is not configured, it\nwould configure the gateway interface to accept router advts from upstream\nrouter to build the default route.\n\nFor an HA router, we would have to configure keepalived to perform this\noperation. This patch extends the functionality to an HA router.\n\nConflicts:\n        neutron/agent/l3/ha_router.py\n        neutron/tests/unit/agent/l3/test_agent.py\n\nImplements: blueprint ipv6-router\nChange-Id: I26dc5ce9e46c74423358aa8a9559bc6c7cbdf85e\n(cherry picked from commit 89489d2720c80c3465e36dad566aa835215fb92e)\n'}, {'number': 2, 'created': '2015-06-04 02:19:41.000000000', 'files': ['neutron/agent/linux/interface.py', 'neutron/agent/l3/ha_router.py', 'neutron/agent/l3/router_info.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/tests/functional/agent/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eec77c1872bba05ff9cf94e383a72c8abd6a17a6', 'message': 'Support BP:ipv6-router in Neutron HA Router\n\nblueprint ipv6-router (ChangeID:Iaefa95f788053ded9fc9c7ff6845c3030c6fd6df),\nsupports an IPv6 Router where the router gateway port has no subnet.\n\nThe BP implements the following. If an external network (without any subnet)\nis attached to the Neutron router, it reads the ipv6_gateway config parameter\n(LLA of upstream router) from l3_agent.ini file and adds a default route that\npoints to this LLA.  If the ipv6_gateway config value is not configured, it\nwould configure the gateway interface to accept router advts from upstream\nrouter to build the default route. For an HA router, we would have to\nconfigure keepalived to perform this operation. \n\nThis patch is a bug fix for the broken feature in kilo.\n\nConflicts:\n        neutron/agent/l3/ha_router.py\n        neutron/tests/unit/agent/l3/test_agent.py\n\nImplements: blueprint ipv6-router\nChange-Id: I26dc5ce9e46c74423358aa8a9559bc6c7cbdf85e\n(cherry picked from commit 89489d2720c80c3465e36dad566aa835215fb92e)\n'}]",0,187500,eec77c1872bba05ff9cf94e383a72c8abd6a17a6,54,23,2,10257,,,0,"Support BP:ipv6-router in Neutron HA Router

blueprint ipv6-router (ChangeID:Iaefa95f788053ded9fc9c7ff6845c3030c6fd6df),
supports an IPv6 Router where the router gateway port has no subnet.

The BP implements the following. If an external network (without any subnet)
is attached to the Neutron router, it reads the ipv6_gateway config parameter
(LLA of upstream router) from l3_agent.ini file and adds a default route that
points to this LLA.  If the ipv6_gateway config value is not configured, it
would configure the gateway interface to accept router advts from upstream
router to build the default route. For an HA router, we would have to
configure keepalived to perform this operation. 

This patch is a bug fix for the broken feature in kilo.

Conflicts:
        neutron/agent/l3/ha_router.py
        neutron/tests/unit/agent/l3/test_agent.py

Implements: blueprint ipv6-router
Change-Id: I26dc5ce9e46c74423358aa8a9559bc6c7cbdf85e
(cherry picked from commit 89489d2720c80c3465e36dad566aa835215fb92e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/187500/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/ha_router.py', 'neutron/agent/linux/interface.py', 'neutron/agent/l3/router_info.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/tests/functional/agent/test_l3_agent.py']",5,50eaf93605bb9f01ff6f750d774374e3753f3496,bp/ipv6-router," self.agent.conf.set_override('ipv6_gateway', 'fe80::f816:3eff:fe2e:1') def test_ipv6_ha_router_lifecycle_with_no_gw_subnet(self): self.agent.conf.set_override('ipv6_gateway', 'fe80::f816:3eff:fe2e:1') self._router_lifecycle(enable_ha=True, ip_version=6, v6_ext_gw_with_sub=False) def test_ipv6_ha_router_lifecycle_with_no_gw_subnet_for_router_advts(self): # Verify that router gw interface is configured to receive Router # Advts from upstream router when no external gateway is configured. self._router_lifecycle(enable_ha=True, dual_stack=True, v6_ext_gw_with_sub=False) # Verify router gateway interface is configured to receive Router Advts # when IPv6 is enabled and no IPv6 gateway is configured. if router.use_ipv6 and not v6_ext_gw_with_sub: if not self.agent.conf.ipv6_gateway: external_port = router.get_ex_gw_port() external_device_name = router.get_external_device_name( external_port['id']) ip_wrapper = ip_lib.IPWrapper(namespace=router.ns_name) ra_state = ip_wrapper.netns.execute(['sysctl', '-b', 'net.ipv6.conf.%s.accept_ra' % external_device_name]) self.assertEqual('2', ra_state) "," if not v6_ext_gw_with_sub: self.agent.conf.set_override('ipv6_gateway', 'fe80::f816:3eff:fe2e:1')",46,17
openstack%2Fhorizon~master~Iac87e41edd797c2a8318dcaceefe0651bd22dd61,openstack/horizon,master,Iac87e41edd797c2a8318dcaceefe0651bd22dd61,Extends .jscsrc to ignore 3rd party files,MERGED,2015-06-10 11:36:27.000000000,2015-06-11 12:38:00.000000000,2015-06-11 12:37:58.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 7665}, {'_account_id': 9981}, {'_account_id': 10881}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-06-10 11:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b19e48021dd365a1cf8865d85e861e58de45f37d', 'message': 'Extends .jscsrc\n\nAdds a few files that should be skipped to the .jscsrc, since they are\nbeyond our control (external libs, generated coverage reports etc.)\n\nThis also reduces the error count to around 2k\n\nCloses-Bug: 1463791\nChange-Id: Iac87e41edd797c2a8318dcaceefe0651bd22dd61\n'}, {'number': 2, 'created': '2015-06-11 02:50:33.000000000', 'files': ['.jscsrc'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fda1062195ecb0ff38d71cff8b2d3304043059c2', 'message': 'Extends .jscsrc to ignore 3rd party files\n\nAdds a few files that should be skipped to the .jscsrc, since they are\nbeyond our control (external libs, generated coverage reports etc.)\n\nThis also reduces the error count to around 2k\n\nCloses-Bug: 1463791\nChange-Id: Iac87e41edd797c2a8318dcaceefe0651bd22dd61'}]",1,190131,fda1062195ecb0ff38d71cff8b2d3304043059c2,17,8,2,12826,,,0,"Extends .jscsrc to ignore 3rd party files

Adds a few files that should be skipped to the .jscsrc, since they are
beyond our control (external libs, generated coverage reports etc.)

This also reduces the error count to around 2k

Closes-Bug: 1463791
Change-Id: Iac87e41edd797c2a8318dcaceefe0651bd22dd61",git fetch https://review.opendev.org/openstack/horizon refs/changes/31/190131/1 && git format-patch -1 --stdout FETCH_HEAD,['.jscsrc'],1,b19e48021dd365a1cf8865d85e861e58de45f37d,bug/1463791," "".venv/**"", ""bower_components/**"", ""horizon/.coverage-karma/**"", ""lib/**"", ""openstack_dashboard/.coverage-karma/**""} "," ""bower_components/**""}",6,2
openstack%2Fzaqar~master~Ic5b95fdfa8949e85ca8601d39137cc4e4dcbb4cd,openstack/zaqar,master,Ic5b95fdfa8949e85ca8601d39137cc4e4dcbb4cd,Merge tag '2015.1.0',MERGED,2015-05-01 00:14:13.000000000,2015-06-11 12:36:37.000000000,2015-06-11 12:36:34.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6159}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-05-01 00:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7dcb1941cfd95cde61301f459163afe157fc9214', 'message': ""Merge tag '2015.1.0'\n\nZaqar 2015.1.0\n\nChange-Id: Ic5b95fdfa8949e85ca8601d39137cc4e4dcbb4cd\n""}, {'number': 2, 'created': '2015-06-09 17:31:43.000000000', 'files': ['zaqar/locale/fr/LC_MESSAGES/zaqar-log-error.po', 'requirements.txt', '.gitreview', 'zaqar/locale/pt_BR/LC_MESSAGES/zaqar.po', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/25c06960b6a234788207efe5d5253d9edb678e05', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: Ic5b95fdfa8949e85ca8601d39137cc4e4dcbb4cd\n""}]",0,179306,25c06960b6a234788207efe5d5253d9edb678e05,11,4,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: Ic5b95fdfa8949e85ca8601d39137cc4e4dcbb4cd
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/06/179306/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/locale/fr/LC_MESSAGES/zaqar-log-error.po', 'requirements.txt', '.gitreview', 'zaqar/locale/pt_BR/LC_MESSAGES/zaqar.po', 'requirements-py3.txt']",5,7dcb1941cfd95cde61301f459163afe157fc9214,merge/release-tag,keystonemiddleware>=1.5.0,"keystonemiddleware>=1.5.0,<1.6.0",621,39
openstack%2Fproject-config~master~I9d35206cdb95093b62544ca150431c54c4887e4e,openstack/project-config,master,I9d35206cdb95093b62544ca150431c54c4887e4e,Adding #openstack-searchlight IRC channel,MERGED,2015-06-10 15:42:59.000000000,2015-06-11 12:33:41.000000000,2015-06-11 12:33:39.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 11356}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-10 15:42:59.000000000', 'files': ['accessbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/55a53ba653c95cd403ff7e0f75e6ec7f87afd067', 'message': 'Adding #openstack-searchlight IRC channel\n\nChange-Id: I9d35206cdb95093b62544ca150431c54c4887e4e\n'}]",0,190235,55a53ba653c95cd403ff7e0f75e6ec7f87afd067,15,7,1,5623,,,0,"Adding #openstack-searchlight IRC channel

Change-Id: I9d35206cdb95093b62544ca150431c54c4887e4e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/35/190235/1 && git format-patch -1 --stdout FETCH_HEAD,['accessbot/channels.yaml'],1,55a53ba653c95cd403ff7e0f75e6ec7f87afd067,, - name: openstack-searchlight,,1,0
openstack%2Ffuel-web~stable%2F6.1~Ie3849befd85797e27655afc9483c4648954a8eaf,openstack/fuel-web,stable/6.1,Ie3849befd85797e27655afc9483c4648954a8eaf,Tests commit. Trigger CI for stable/6.1,ABANDONED,2015-06-08 15:43:39.000000000,2015-06-11 12:32:11.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-06-08 15:43:39.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9a243e570ef4b35db69524136e54ee68be788348', 'message': 'Tests commit. Trigger CI for stable/6.1\n\nChange-Id: Ie3849befd85797e27655afc9483c4648954a8eaf\n'}]",0,189345,9a243e570ef4b35db69524136e54ee68be788348,6,2,1,13505,,,0,"Tests commit. Trigger CI for stable/6.1

Change-Id: Ie3849befd85797e27655afc9483c4648954a8eaf
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/45/189345/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,9a243e570ef4b35db69524136e54ee68be788348,,,,1,0
openstack%2Frequirements~master~I8e478b5b2be9b125390556ec945e0e38e8b71937,openstack/requirements,master,I8e478b5b2be9b125390556ec945e0e38e8b71937,Formatting nits in update.py.,MERGED,2015-06-11 07:18:48.000000000,2015-06-11 12:31:39.000000000,2015-06-11 12:31:36.000000000,"[{'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-06-11 07:18:48.000000000', 'files': ['update.py'], 'web_link': 'https://opendev.org/openstack/requirements/commit/08c2efe6cb09de644b85f04fabe8e441354920f5', 'message': 'Formatting nits in update.py.\n\nNothing semantic, just making it more pleasing on mine eyes.\n\nChange-Id: I8e478b5b2be9b125390556ec945e0e38e8b71937\n'}]",0,190522,08c2efe6cb09de644b85f04fabe8e441354920f5,6,2,1,4190,,,0,"Formatting nits in update.py.

Nothing semantic, just making it more pleasing on mine eyes.

Change-Id: I8e478b5b2be9b125390556ec945e0e38e8b71937
",git fetch https://review.opendev.org/openstack/requirements refs/changes/22/190522/1 && git format-patch -1 --stdout FETCH_HEAD,['update.py'],1,08c2efe6cb09de644b85f04fabe8e441354920f5,,"""""""","r""""""",1,5
openstack%2Fneutron~master~I73854f9863f44621ae0d89c5dc4893ccc16d07e4,openstack/neutron,master,I73854f9863f44621ae0d89c5dc4893ccc16d07e4,Ensure non-overlapping cidrs in subnetpools without galera,MERGED,2015-05-04 21:59:05.000000000,2015-06-11 12:25:27.000000000,2015-06-11 12:25:25.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 841}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9555}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11816}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14258}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-05-04 21:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d3f3ca4227f59f46622dc7c54df83484dccb896', 'message': ""Ensure non-overlapping cidrs in subnetpools\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\nClose-Bug: #1451576\nClose-Bug: #1451558\n""}, {'number': 2, 'created': '2015-05-04 22:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be3462162d5c9fd3f94543e0197e0deee88135fc', 'message': ""Ensure non-overlapping cidrs in subnetpools\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\nClose-Bug: #1451576\nClose-Bug: #1451558\n""}, {'number': 3, 'created': '2015-05-05 08:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4988501fd11aab32d1e62b893fbe4e4f0c39d024', 'message': ""Ensure non-overlapping cidrs in subnetpools\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\nClose-Bug: #1451576\nClose-Bug: #1451558\n""}, {'number': 4, 'created': '2015-05-09 19:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8cbfa31e60d5d202da4fa89f942fb17704f52fea', 'message': ""Ensure non-overlapping cidrs in subnetpools without galera\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\nBut this change does not ensure non-overlapping cidrs in subnetpools\nwith galera because galera doesn't support SELECT FOR UPDATE locks. A\nfollow-up change will (try to?) remove locks from subnet allocation[1]\nin order to ensure non-overlapping cidrs in subnetpools also with galera.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nCloses-Bug: #1451558\nPartial-Bug: #1451576\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\n""}, {'number': 5, 'created': '2015-05-12 11:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cfef35109e0fa77980a0d005acfad96e9fcc9fa9', 'message': ""Ensure non-overlapping cidrs in subnetpools without galera\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\nBut this change does not ensure non-overlapping cidrs in subnetpools\nwith galera because galera doesn't support SELECT FOR UPDATE locks. A\nfollow-up change will (try to?) remove locks from subnet allocation[1]\nin order to ensure non-overlapping cidrs in subnetpools also with galera.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nCloses-Bug: #1451558\nPartial-Bug: #1451576\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\n""}, {'number': 6, 'created': '2015-05-15 16:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/94e4c177f1408ad592c74998ffb9fbccb9745b21', 'message': ""Ensure non-overlapping cidrs in subnetpools without galera\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\nBut this change does not ensure non-overlapping cidrs in subnetpools\nwith galera because galera doesn't support SELECT FOR UPDATE locks. A\nfollow-up change will (try to?) remove locks from subnet allocation[1]\nin order to ensure non-overlapping cidrs in subnetpools also with galera.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nCloses-Bug: #1451558\nPartial-Bug: #1451576\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\n""}, {'number': 7, 'created': '2015-05-25 14:10:02.000000000', 'files': ['neutron/ipam/subnet_alloc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3682e3391f188845d0c7f382f0ccd4b38db3904e', 'message': ""Ensure non-overlapping cidrs in subnetpools without galera\n\n_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool\n(with mysql/postgresql at least). It ensures we don't allocate a cidr\noverlapping with existent cidrs but nothing disallows a concurrent\nsubnet allocation to create a subnet in the same subnetpool.\n\nThis change replaces the lock on subnetpool subnets by a lock on the\nsubnetpool itself. It disallows to allocate concurrently 2 subnets in\nthe same subnetpool and ensure non-overlapping cidrs in the same\nsubnetpool.\n\nMoreover this change solves a trouble with postgresql which disallows\nto lock an empty select with an outer join: it happens on first subnet\nallocation in a subnetpool when no specific cidr is provided. Moving\nthe lock ensures the lock is done on a non-empty select.\n\nBut this change does not ensure non-overlapping cidrs in subnetpools\nwith galera because galera doesn't support SELECT FOR UPDATE locks. A\nfollow-up change will (try to?) remove locks from subnet allocation[1]\nin order to ensure non-overlapping cidrs in subnetpools also with galera.\n\n[1] in neutron.ipam.subnet_alloc.SubnetAllocator\n\nCloses-Bug: #1451558\nPartial-Bug: #1451576\nChange-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4\n""}]",24,179955,3682e3391f188845d0c7f382f0ccd4b38db3904e,209,40,7,8124,,,0,"Ensure non-overlapping cidrs in subnetpools without galera

_get_allocated_cidrs[1] locks only allocated subnets in a subnetpool
(with mysql/postgresql at least). It ensures we don't allocate a cidr
overlapping with existent cidrs but nothing disallows a concurrent
subnet allocation to create a subnet in the same subnetpool.

This change replaces the lock on subnetpool subnets by a lock on the
subnetpool itself. It disallows to allocate concurrently 2 subnets in
the same subnetpool and ensure non-overlapping cidrs in the same
subnetpool.

Moreover this change solves a trouble with postgresql which disallows
to lock an empty select with an outer join: it happens on first subnet
allocation in a subnetpool when no specific cidr is provided. Moving
the lock ensures the lock is done on a non-empty select.

But this change does not ensure non-overlapping cidrs in subnetpools
with galera because galera doesn't support SELECT FOR UPDATE locks. A
follow-up change will (try to?) remove locks from subnet allocation[1]
in order to ensure non-overlapping cidrs in subnetpools also with galera.

[1] in neutron.ipam.subnet_alloc.SubnetAllocator

Closes-Bug: #1451558
Partial-Bug: #1451576
Change-Id: I73854f9863f44621ae0d89c5dc4893ccc16d07e4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/179955/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron/ipam/subnet_alloc.py'],1,7d3f3ca4227f59f46622dc7c54df83484dccb896,bug/1451576," def _lock_subnetpool(self, session): """"""Lock subnetpool associated row. This method disallows to allocate concurrently 2 subnets in the same subnetpool, it's required to ensure non-overlapping cidrs in the same subnetpool. """""" (session.query(models_v2.SubnetPool.id). filter_by(id=self._subnetpool['id']). with_lockmode('update').first()) def _get_allocated_cidrs(self, session): query = session.query(models_v2.Subnet) self._lock_subnetpool(session) self._lock_subnetpool(session)"," def _get_allocated_cidrs(self, session): query = session.query( models_v2.Subnet).with_lockmode('update')",14,2
openstack%2Fproject-config~master~Ied13da46118027bea05be7a40b62be01e9fd4cea,openstack/project-config,master,Ied13da46118027bea05be7a40b62be01e9fd4cea,Adds rtfd post-hooks to all akanda projects,MERGED,2015-06-05 20:20:05.000000000,2015-06-11 12:24:42.000000000,2015-06-11 12:24:41.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-05 20:20:05.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0bda16aad3a4a55b2a3f822a977100f6b60a4350', 'message': 'Adds rtfd post-hooks to all akanda projects\n\nAdds readthedocs post hooks to the akanda jobs to trigger\npost-merge doc builds.\n\nChange-Id: Ied13da46118027bea05be7a40b62be01e9fd4cea\n'}]",0,188909,0bda16aad3a4a55b2a3f822a977100f6b60a4350,7,3,1,1420,,,0,"Adds rtfd post-hooks to all akanda projects

Adds readthedocs post hooks to the akanda jobs to trigger
post-merge doc builds.

Change-Id: Ied13da46118027bea05be7a40b62be01e9fd4cea
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/188909/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,0bda16aad3a4a55b2a3f822a977100f6b60a4350,akanda_docs, - name: docs-on-rtfd - name: docs-on-rtfd - name: docs-on-rtfd - name: docs-on-rtfd - name: docs-on-rtfd - name: docs-on-rtfd,,19,0
openstack%2Fproject-config~master~I7913794de51bf7a862dbb835d4368fc6ab5cde5b,openstack/project-config,master,I7913794de51bf7a862dbb835d4368fc6ab5cde5b,oslo.vmware non-voting bandit job,MERGED,2015-06-11 02:09:39.000000000,2015-06-11 12:22:45.000000000,2015-06-11 12:22:42.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 9172}]","[{'number': 1, 'created': '2015-06-11 02:09:39.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/879a646428f1646be2bf1d1b55e30f3f7507f0eb', 'message': 'oslo.vmware non-voting bandit job\n\nThis adds a non-voting bandit job for oslo.vmware.  The oslo.vmware\nproject already has a tox environment for bandit, just need the\ninfra to run this job as part of the gate of the master branch.\n\nChange-Id: I7913794de51bf7a862dbb835d4368fc6ab5cde5b\n'}]",0,190457,879a646428f1646be2bf1d1b55e30f3f7507f0eb,7,8,1,8119,,,0,"oslo.vmware non-voting bandit job

This adds a non-voting bandit job for oslo.vmware.  The oslo.vmware
project already has a tox environment for bandit, just need the
infra to run this job as part of the gate of the master branch.

Change-Id: I7913794de51bf7a862dbb835d4368fc6ab5cde5b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/57/190457/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,879a646428f1646be2bf1d1b55e30f3f7507f0eb,bandit, - name: gate-oslo.vmware-tox-bandit branch: ^(?!stable/(icehouse|juno|kilo)).*$ voting: false - gate-oslo.vmware-tox-bandit,,7,0
openstack%2Fopenstack-manuals~master~I653c12c3e895111d08ecf8fef017e82fca2f909d,openstack/openstack-manuals,master,I653c12c3e895111d08ecf8fef017e82fca2f909d,Dashboard system requirements for the install guide,MERGED,2015-06-03 03:22:56.000000000,2015-06-11 12:10:33.000000000,2015-06-11 12:10:31.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 9515}, {'_account_id': 10897}, {'_account_id': 12686}, {'_account_id': 14396}]","[{'number': 1, 'created': '2015-06-03 03:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/87e3aa9e8770348326b83f2f523b8bef91bc58d1', 'message': 'Update system requirements in install guide for Debian 7\n\nUpdating information on where the dashboard service is installed,\nand adding additional information to clarify system requirements -\npython versions and sending ip addresses to users.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: none\nCloses-Bug: #1426451\n'}, {'number': 2, 'created': '2015-06-03 06:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4b9c93996ec006ba9d13b0045d315ee430a12d6b', 'message': 'Update Dashboard system requirements in install guide for Debian 7\n\nRemoving the system requirements section, and moving any\nimportant information into the introduction and concluding paragraps\nof the Horizon chapter.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: none\nPartial-Bug: #1426451\n'}, {'number': 3, 'created': '2015-06-09 04:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b6a71f6f5e5a98b156d3e60e3d3e9fa2d1b9e7c0', 'message': 'Dashboard system requirements for Debian 7 install\n\nBecause horizon is deployed on the controller node from Juno onwards, this\npatch removes the system requirements section, which has documentation\nfor deploying horizon on a server other than the controller node.\n\nIt moves any important information from the system requirements chapter to the\nintroduction and concluding paragraphs of the Horizon chapter, and specifies\nthat these are Debian requirements.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: juno kilo\nCloses-Bug: #1426451\n'}, {'number': 4, 'created': '2015-06-11 02:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/60a343441035430a1072c929e2da0c4ebbc21108', 'message': 'Dashboard system requirements for Debian 7 install\n\nBecause horizon is deployed on the controller node from Juno onwards, this\npatch removes the system requirements section, which has documentation\nfor deploying horizon on a server other than the controller node.\n\nIt moves any important information from the system requirements chapter to the\nintroduction and concluding paragraphs of the Horizon chapter, and specifies\nthat these are Debian requirements.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: juno kilo\nCloses-Bug: #1426451\n'}, {'number': 5, 'created': '2015-06-11 03:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b4f7d5469cfe16cb5603f5f9ed3db4f790157980', 'message': 'Dashboard system requirements for Debian 7 install\n\nBecause horizon is deployed on the controller node from Juno onwards, this\npatch removes the system requirements section, which has documentation\nfor deploying horizon on a server other than the controller node.\n\nIt moves any important information from the system requirements chapter to the\nintroduction and concluding paragraphs of the Horizon chapter, and specifies\nthat these are Debian requirements.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: juno kilo\nCloses-Bug: #1426451\n'}, {'number': 6, 'created': '2015-06-11 03:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ecb50918b6bba17d9017b5f0896dbd4b85a92e5a', 'message': 'Dashboard system requirements for Debian 7 install\n\nBecause horizon is deployed on the controller node from Juno onwards, this\npatch removes the system requirements section, which has documentation\nfor deploying horizon on a server other than the controller node.\n\nIt moves any important information from the system requirements chapter to the\nintroduction and concluding paragraphs of the Horizon chapter, and specifies\nthat these are Debian requirements.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: juno kilo\nCloses-Bug: #1426451\n'}, {'number': 7, 'created': '2015-06-11 04:27:47.000000000', 'files': ['doc/install-guide/section_dashboard-install.xml', 'doc/install-guide/section_dashboard-system-reqs.xml', 'doc/install-guide/ch_horizon.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b33b598a993a3db4b47ec121d21b0d5eeb56b39e', 'message': 'Dashboard system requirements for the install guide\n\nBecause horizon is deployed on the controller node from Juno and Kilo onwards, this\npatch removes the system requirements section, which has documentation\nfor deploying horizon on a server other than the controller node.\n\nIt moves any important information from the system requirements chapter to the\nintroduction and concluding paragraphs of the Horizon chapter.\n\nChange-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d\nbackport: juno kilo\nCloses-Bug: #1426451\n'}]",10,187850,b33b598a993a3db4b47ec121d21b0d5eeb56b39e,30,7,7,10897,,,0,"Dashboard system requirements for the install guide

Because horizon is deployed on the controller node from Juno and Kilo onwards, this
patch removes the system requirements section, which has documentation
for deploying horizon on a server other than the controller node.

It moves any important information from the system requirements chapter to the
introduction and concluding paragraphs of the Horizon chapter.

Change-Id: I653c12c3e895111d08ecf8fef017e82fca2f909d
backport: juno kilo
Closes-Bug: #1426451
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/50/187850/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_dashboard-system-reqs.xml'],1,87e3aa9e8770348326b83f2f523b8bef91bc58d1,bug1426451/joseph-r-email," <para>Python 2.6 or 2.7. Django, and must run on any system, including Mac OS X. Installation prerequisites <para>Install and configure the dashboard on the compute node following the directions in <xref linkend=""install_dashboard""/>.</para> <para>Point the IP Address to a Domain Name, redirecting IP requests, instead of issuing users with the IP address in case ssl certificates cause identification problems between local machines and servers.</para>"," <para>Python 2.7. Django. The Python version should run on any system, including Mac OS X. Installation prerequisites <para>Then, install and configure the dashboard on a node that can contact the Identity Service.</para>",9,5
openstack%2Fcinder~stable%2Fkilo~Ie184725ea9d83d676612ec82ea56013c0f15eed4,openstack/cinder,stable/kilo,Ie184725ea9d83d676612ec82ea56013c0f15eed4,Follow i18n guidelines in LIO target,ABANDONED,2015-06-02 16:33:14.000000000,2015-06-11 11:45:43.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9171}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12285}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2015-06-02 16:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3c3f755ffab66245b59cba2c091245e2ab0f1903', 'message': 'Follow i18n guidelines in LIO target\n\nIn LIO target some logging instances do not follow i18n guidelines\nrelated to delayed string interpolation.\n\nChange-Id: Ie184725ea9d83d676612ec82ea56013c0f15eed4\n(cherry picked from commit 948d6d87e8f09bbc3696cb0efec00f235b6cf799)\n'}, {'number': 2, 'created': '2015-06-05 08:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3eccbf0b5233c53aafd52da24be70babff8274c2', 'message': 'Follow i18n guidelines in LIO target\n\nIn LIO target some logging instances do not follow i18n guidelines\nrelated to delayed string interpolation.\n\nChange-Id: Ie184725ea9d83d676612ec82ea56013c0f15eed4\n(cherry picked from commit 948d6d87e8f09bbc3696cb0efec00f235b6cf799)\n'}, {'number': 3, 'created': '2015-06-08 08:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb5ed91752f19ad486451389b92c58c7c11bdf46', 'message': 'Follow i18n guidelines in LIO target\n\nIn LIO target some logging instances do not follow i18n guidelines\nrelated to delayed string interpolation.\n\nChange-Id: Ie184725ea9d83d676612ec82ea56013c0f15eed4\n(cherry picked from commit 948d6d87e8f09bbc3696cb0efec00f235b6cf799)\n'}, {'number': 4, 'created': '2015-06-08 13:53:20.000000000', 'files': ['cinder/volume/targets/lio.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e622569cc5c8b768e1a9c2d433f298de04c5f9ec', 'message': 'Follow i18n guidelines in LIO target\n\nIn LIO target some logging instances do not follow i18n guidelines\nrelated to delayed string interpolation.\n\nChange-Id: Ie184725ea9d83d676612ec82ea56013c0f15eed4\n(cherry picked from commit 948d6d87e8f09bbc3696cb0efec00f235b6cf799)\n'}]",0,187665,e622569cc5c8b768e1a9c2d433f298de04c5f9ec,76,28,4,9535,,,0,"Follow i18n guidelines in LIO target

In LIO target some logging instances do not follow i18n guidelines
related to delayed string interpolation.

Change-Id: Ie184725ea9d83d676612ec82ea56013c0f15eed4
(cherry picked from commit 948d6d87e8f09bbc3696cb0efec00f235b6cf799)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/187665/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/targets/lio.py'],1,3c3f755ffab66245b59cba2c091245e2ab0f1903,bug/1460692," LOG.info(_LI('Creating iscsi_target for volume: %s'), vol_id) except putils.ProcessExecutionError: LOG.exception(_LE(""Failed to create iscsi target for volume "" ""id:%s.""), vol_id) ""id:%s.""), vol_id) LOG.info(_LI('Removing iscsi_target: %s'), vol_id) except putils.ProcessExecutionError: LOG.exception(_LE(""Failed to remove iscsi target for volume "" ""id:%s.""), vol_id) LOG.exception(_LE(""Failed to add initiator iqn %s to target""), connector['initiator']) except putils.ProcessExecutionError: LOG.exception(_LE(""Failed to delete initiator iqn %s to target.""), connector['initiator'])"," LOG.info(_LI('Creating iscsi_target for volume: %s') % vol_id) except putils.ProcessExecutionError as e: LOG.error(_LE(""Failed to create iscsi target for volume "" ""id:%s."") % vol_id) LOG.error(_LE(""%s"") % e) ""id:%s."") % vol_id) LOG.info(_LI('Removing iscsi_target: %s') % vol_id) except putils.ProcessExecutionError as e: LOG.error(_LE(""Failed to remove iscsi target for volume "" ""id:%s."") % vol_id) LOG.error(_LE(""%s"") % e) LOG.error(_LE(""Failed to add initiator iqn %s to target"") % connector['initiator']) except putils.ProcessExecutionError as e: LOG.error(_LE(""Failed to delete initiator iqn %(initiator)s to "" ""target. Error: %(error)s""), {'initiator': connector['initiator'], 'error': e})",14,17
openstack%2Fcinder~stable%2Fkilo~Id28968735eca27c4c4e5892e14d06aece02b06f5,openstack/cinder,stable/kilo,Id28968735eca27c4c4e5892e14d06aece02b06f5,Log command failure details before raising ISCSITargetDetachFailed,ABANDONED,2015-06-02 16:33:14.000000000,2015-06-11 11:45:20.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10263}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2015-06-02 16:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/765c07a98490204e117231af323aa52d659f0643', 'message': 'Log command failure details before raising ISCSITargetDetachFailed\n\nIn the case that there is some useful information in the\nProcessExecutionError (like stderr) when trying to terminate the\nconnection in the lio target, also log the error.\n\nRelated-Bug: #1450658\n\nChange-Id: Id28968735eca27c4c4e5892e14d06aece02b06f5\n(cherry picked from commit b9f3967c1d048674e5ea53e8a9f539030ff043ef)\n'}, {'number': 2, 'created': '2015-06-05 08:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1360e61dce1a24af79a9d0af323e0792719ee879', 'message': 'Log command failure details before raising ISCSITargetDetachFailed\n\nIn the case that there is some useful information in the\nProcessExecutionError (like stderr) when trying to terminate the\nconnection in the lio target, also log the error.\n\nRelated-Bug: #1450658\n\nChange-Id: Id28968735eca27c4c4e5892e14d06aece02b06f5\n(cherry picked from commit b9f3967c1d048674e5ea53e8a9f539030ff043ef)\n'}, {'number': 3, 'created': '2015-06-08 08:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8b142cfedfbdaac930ce8d038776a3992fac25fb', 'message': 'Log command failure details before raising ISCSITargetDetachFailed\n\nIn the case that there is some useful information in the\nProcessExecutionError (like stderr) when trying to terminate the\nconnection in the lio target, also log the error.\n\nRelated-Bug: #1450658\n\nChange-Id: Id28968735eca27c4c4e5892e14d06aece02b06f5\n(cherry picked from commit b9f3967c1d048674e5ea53e8a9f539030ff043ef)\n'}, {'number': 4, 'created': '2015-06-08 13:53:20.000000000', 'files': ['cinder/volume/targets/lio.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ec26ded7e1ac83bc4853e111251dba249585358e', 'message': 'Log command failure details before raising ISCSITargetDetachFailed\n\nIn the case that there is some useful information in the\nProcessExecutionError (like stderr) when trying to terminate the\nconnection in the lio target, also log the error.\n\nRelated-Bug: #1450658\n\nChange-Id: Id28968735eca27c4c4e5892e14d06aece02b06f5\n(cherry picked from commit b9f3967c1d048674e5ea53e8a9f539030ff043ef)\n'}]",3,187664,ec26ded7e1ac83bc4853e111251dba249585358e,83,30,4,9535,,,0,"Log command failure details before raising ISCSITargetDetachFailed

In the case that there is some useful information in the
ProcessExecutionError (like stderr) when trying to terminate the
connection in the lio target, also log the error.

Related-Bug: #1450658

Change-Id: Id28968735eca27c4c4e5892e14d06aece02b06f5
(cherry picked from commit b9f3967c1d048674e5ea53e8a9f539030ff043ef)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/64/187664/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/targets/lio.py'],1,765c07a98490204e117231af323aa52d659f0643,bug/1460692," except putils.ProcessExecutionError as e: LOG.error(_LE(""Failed to delete initiator iqn %(initiator)s to "" ""target. Error: %(error)s""), {'initiator': connector['initiator'], 'error': e})"," except putils.ProcessExecutionError: LOG.error(_LE(""Failed to delete initiator iqn %s to target."") % connector['initiator'])",4,3
openstack%2Fcinder~stable%2Fkilo~I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a,openstack/cinder,stable/kilo,I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a,Targets test refactoring,ABANDONED,2015-06-02 16:33:14.000000000,2015-06-11 11:45:06.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9171}, {'_account_id': 9176}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10263}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12285}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2015-06-02 16:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d5c52e691097fdb397f13da466b3c5b3c79eef4', 'message': ""Targets test refactoring\n\nThe unit tests for iser inherit from the tgtAdm, it means that any\ntime run tests for iser, tgtAdm tests run too. This chache add\nTargetFixture to tests, it allows to decouple tests and delete\nduplicated code.\n\nOther changes:\n -  deleted  __init__ in test's classes; __init__ may work as a\nreplacement for setUp, but  setUp should be used instead because\nit is part of the protocol for writing tests. It also has a\ncounterpart, tearDown, which __init__ does no;\n - replaced stubs to mock.\n\nChange-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a\nCloses-Bug: #1420009\n(cherry picked from commit bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d)\n""}, {'number': 2, 'created': '2015-06-05 08:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/29a10c5b496f54fdee1d3810b3ce511a5594e7e3', 'message': ""Targets test refactoring\n\nThe unit tests for iser inherit from the tgtAdm, it means that any\ntime run tests for iser, tgtAdm tests run too. This chache add\nTargetFixture to tests, it allows to decouple tests and delete\nduplicated code.\n\nOther changes:\n -  deleted  __init__ in test's classes; __init__ may work as a\nreplacement for setUp, but  setUp should be used instead because\nit is part of the protocol for writing tests. It also has a\ncounterpart, tearDown, which __init__ does no;\n - replaced stubs to mock.\n\nChange-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a\nCloses-Bug: #1420009\n(cherry picked from commit bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d)\n""}, {'number': 3, 'created': '2015-06-08 08:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/04ba65e3b55c68d2c4ea7f5a1e7723cd6950a0ba', 'message': ""Targets test refactoring\n\nThe unit tests for iser inherit from the tgtAdm, it means that any\ntime run tests for iser, tgtAdm tests run too. This chache add\nTargetFixture to tests, it allows to decouple tests and delete\nduplicated code.\n\nOther changes:\n -  deleted  __init__ in test's classes; __init__ may work as a\nreplacement for setUp, but  setUp should be used instead because\nit is part of the protocol for writing tests. It also has a\ncounterpart, tearDown, which __init__ does no;\n - replaced stubs to mock.\n\nChange-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a\nCloses-Bug: #1420009\n(cherry picked from commit bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d)\n""}, {'number': 4, 'created': '2015-06-08 13:53:20.000000000', 'files': ['cinder/tests/unit/targets/test_lio_driver.py', 'cinder/tests/unit/targets/test_scst_driver.py', 'cinder/tests/unit/targets/targets_fixture.py', 'cinder/tests/unit/targets/test_cxt_driver.py', 'cinder/tests/unit/targets/test_base_iscsi_driver.py', 'cinder/tests/unit/targets/test_iet_driver.py', 'cinder/tests/unit/targets/test_iser_driver.py', 'cinder/tests/unit/targets/test_tgt_driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b009c4361f33039a654951e8bceb85978593df31', 'message': ""Targets test refactoring\n\nThe unit tests for iser inherit from the tgtAdm, it means that any\ntime run tests for iser, tgtAdm tests run too. This chache add\nTargetFixture to tests, it allows to decouple tests and delete\nduplicated code.\n\nOther changes:\n -  deleted  __init__ in test's classes; __init__ may work as a\nreplacement for setUp, but  setUp should be used instead because\nit is part of the protocol for writing tests. It also has a\ncounterpart, tearDown, which __init__ does no;\n - replaced stubs to mock.\n\nChange-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a\nCloses-Bug: #1420009\n(cherry picked from commit bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d)\n""}]",0,187663,b009c4361f33039a654951e8bceb85978593df31,79,34,4,9535,,,0,"Targets test refactoring

The unit tests for iser inherit from the tgtAdm, it means that any
time run tests for iser, tgtAdm tests run too. This chache add
TargetFixture to tests, it allows to decouple tests and delete
duplicated code.

Other changes:
 -  deleted  __init__ in test's classes; __init__ may work as a
replacement for setUp, but  setUp should be used instead because
it is part of the protocol for writing tests. It also has a
counterpart, tearDown, which __init__ does no;
 - replaced stubs to mock.

Change-Id: I8aa9f756efb0b4fc4a3a0ea960c6f2d8e20ec18a
Closes-Bug: #1420009
(cherry picked from commit bdd0ff6c685855a47034cdfa0cdfa50a4d153a1d)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/63/187663/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/targets/test_lio_driver.py', 'cinder/tests/unit/targets/test_scst_driver.py', 'cinder/tests/unit/targets/targets_fixture.py', 'cinder/tests/unit/targets/test_cxt_driver.py', 'cinder/tests/unit/targets/test_base_iscsi_driver.py', 'cinder/tests/unit/targets/test_iet_driver.py', 'cinder/tests/unit/targets/test_iser_driver.py', 'cinder/tests/unit/targets/test_tgt_driver.py']",8,3d5c52e691097fdb397f13da466b3c5b3c79eef4,bug/1460692,"from cinder.tests.unit.targets import targets_fixture as tfclass TestTgtAdmDriver(tf.TargetDriverFixture): with mock.patch('cinder.utils.execute', return_value=(self.fake_iscsi_scan, None)): self.assertEqual('1', self.target._get_target( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45')) with mock.patch('cinder.utils.execute', return_value=(self.fake_iscsi_scan, None)): self.assertTrue(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) with mock.patch('cinder.utils.execute', return_value=(bad_scan, None)): self.assertFalse(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) @mock.patch('cinder.utils.execute') def test_recreate_backing_lun(self, mock_execute, mock_sleep): self.target._recreate_backing_lun(self.test_vol, '1', self.test_vol, self.test_vol.split(':')[1]), self.target._get_target_chap_auth(ctxt, self.test_vol)) ctxt, self.test_vol) ctxt, self.test_vol) with mock.patch('cinder.utils.execute', return_value=('', '')),\ mock.patch.object(self.target, '_get_target', side_effect=lambda x: 1),\ mock.patch.object(self.target, '_verify_backing_lun', side_effect=lambda x, y: True): self.assertEqual( self.target.create_iscsi_target( self.test_vol, 1, 0, self.fake_volumes_dir)) with mock.patch.object(self.target, '_get_target', side_effect=lambda x: 1),\ mock.patch.object(self.target, '_verify_backing_lun', side_effect=lambda x, y: True),\ mock.patch('cinder.utils.execute', _fake_execute): self.assertEqual( self.target.create_iscsi_target( self.test_vol, 1, 0, self.fake_volumes_dir)) @mock.patch('cinder.utils.execute') @mock.patch('cinder.utils.execute') @mock.patch('cinder.utils.execute') calls = [mock.call('tgt-admin', '--force', '--delete', self.iscsi_target_prefix + self.testvol['name'], mock.call('tgt-admin', '--delete', self.iscsi_target_prefix + self.testvol['name'], expected_result = {'location': '10.9.8.7:3260,1 ' + self.iscsi_target_prefix + self.testvol['name'] + ' 1', 'QZJbisG9AL954FNF4D P68eE7u9eFqDGexd28DQ'} with mock.patch('cinder.utils.execute', return_value=('', '')),\ mock.patch.object(self.target, '_get_target', side_effect=lambda x: 1),\ mock.patch.object(self.target, '_verify_backing_lun', side_effect=lambda x, y: True),\ mock.patch.object(self.target, '_get_target_chap_auth', side_effect=lambda x, y: None) as m_chap,\ mock.patch.object(vutils, 'generate_username', side_effect=lambda: 'QZJbisG9AL954FNF4D'),\ mock.patch.object(vutils, 'generate_password', side_effect=lambda: 'P68eE7u9eFqDGexd28DQ'): ctxt = context.get_admin_context() self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) m_chap.side_effect = lambda x, y: ('otzLy2UYbYfnP4zXLG5z', '234Zweo38VGBBvrpK9nt') expected_result['auth'] = ('CHAP ' 'otzLy2UYbYfnP4zXLG5z ' '234Zweo38VGBBvrpK9nt') self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) self.iscsi_target_prefix + self.testvol['name'],","import tempfilefrom oslo_utils import timeutilsfrom cinder import testfrom cinder.volume import configuration as confclass TestTgtAdmDriver(test.TestCase): self.configuration = conf.Configuration(None) self.configuration.append_config_values = mock.Mock(return_value=0) self.configuration.iscsi_ip_address = '10.9.8.7' self.fake_volumes_dir = tempfile.mkdtemp() self.iscsi_target_prefix = 'iqn.2010-10.org.openstack:' self.fake_project_id = 'ed2c1fd4-5fc0-11e4-aa15-123b93f75cba' self.fake_volume_id = '83c2e877-feed-46be-8435-77884fe55b45' self.stubs.Set(self.configuration, 'safe_get', self.fake_safe_get) self.testvol =\ {'project_id': self.fake_project_id, 'name': 'volume-%s' % self.fake_volume_id, 'size': 1, 'id': self.fake_volume_id, 'volume_type_id': None, 'provider_location': '10.9.8.7:3260 ' 'iqn.2010-10.org.openstack:' 'volume-%s 0' % self.fake_volume_id, 'provider_auth': 'CHAP stack-1-a60e2611875f40199931f2' 'c76370d66b 2FE0CQ8J196R', 'provider_geometry': '512 512', 'created_at': timeutils.utcnow(), 'host': 'fake_host@lvm#lvm'} self.expected_iscsi_properties = \ {'auth_method': 'CHAP', 'auth_password': '2FE0CQ8J196R', 'auth_username': 'stack-1-a60e2611875f40199931f2c76370d66b', 'encrypted': False, 'logical_block_size': '512', 'physical_block_size': '512', 'target_discovered': False, 'target_iqn': 'iqn.2010-10.org.openstack:volume-%s' % self.fake_volume_id, 'target_lun': 0, 'target_portal': '10.9.8.7:3260', 'volume_id': self.fake_volume_id} def fake_safe_get(self, value): if value == 'volumes_dir': return self.fake_volumes_dir elif value == 'iscsi_protocol': return self.configuration.iscsi_protocol elif value == 'iscsi_target_prefix': return self.iscsi_target_prefix def _fake_execute(*args, **kwargs): return self.fake_iscsi_scan, None self.stubs.Set(utils, 'execute', _fake_execute) self.assertEqual('1', self.target._get_target('iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45')) def _fake_execute(*args, **kwargs): return self.fake_iscsi_scan, None self.stubs.Set(utils, 'execute', _fake_execute) self.assertTrue(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) def _fake_execute_bad_lun(*args, **kwargs): return bad_scan, None self.stubs.Set(utils, 'execute', _fake_execute_bad_lun) self.assertFalse(self.target._verify_backing_lun( 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-' '8435-77884fe55b45', '1')) @mock.patch.object(utils, 'execute') def test_recreate_backing_lun(self, mock_execute, mock_sleep): test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.target._recreate_backing_lun(test_vol, '1', test_vol, test_vol =\ 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' test_vol.split(':')[1]), self.target._get_target_chap_auth(ctxt, test_vol)) test_vol =\ 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' ctxt, test_vol) ctxt, test_vol) def _fake_execute(*args, **kwargs): return '', '' self.stubs.Set(utils, 'execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.assertEqual( 1, self.target.create_iscsi_target( test_vol, 0, self.fake_volumes_dir)) self.stubs.Set(utils, 'execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' self.assertEqual( 1, self.target.create_iscsi_target( test_vol, 0, self.fake_volumes_dir)) @mock.patch.object(utils, 'execute') @mock.patch.object(utils, 'execute') @mock.patch.object(utils, 'execute') test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' calls = [mock.call('tgt-admin', '--force', '--delete', test_vol, mock.call('tgt-admin', '--delete', test_vol, def _fake_execute(*args, **kwargs): return '', '' self.stubs.Set(utils, 'execute', _fake_execute) self.stubs.Set(self.target, '_get_target', lambda x: 1) self.stubs.Set(self.target, '_verify_backing_lun', lambda x, y: True) self.stubs.Set(self.target, '_get_target_chap_auth', lambda x, y: None) self.stubs.Set(vutils, 'generate_username', lambda: 'QZJbisGmn9AL954FNF4D') self.stubs.Set(vutils, 'generate_password', lambda: 'P68eE7u9eFqDGexd28DQ') expected_result = {'location': '10.9.8.7:3260,1 ' 'iqn.2010-10.org.openstack:' 'volume-83c2e877-feed-46be-8435-77884fe55b45 1', 'QZJbisGmn9AL954FNF4D P68eE7u9eFqDGexd28DQ'} ctxt = context.get_admin_context() self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) self.stubs.Set(self.target, '_get_target_chap_auth', lambda x, y: ('otzLy2UYbYfnP4zXLG5z', '234Zweo38VGBBvrpK9nt')) expected_result['auth'] = ('CHAP ' 'otzLy2UYbYfnP4zXLG5z 234Zweo38VGBBvrpK9nt') self.assertEqual(expected_result, self.target.create_export(ctxt, self.testvol, self.fake_volumes_dir)) test_vol = 'iqn.2010-10.org.openstack:'\ 'volume-83c2e877-feed-46be-8435-77884fe55b45' test_vol,",320,614
openstack%2Fcinder~stable%2Fkilo~I63b0f89474b3c139bdb89589abd85319d2aa61ec,openstack/cinder,stable/kilo,I63b0f89474b3c139bdb89589abd85319d2aa61ec,Move unit tests into dedicated directory,ABANDONED,2015-06-02 16:33:14.000000000,2015-06-11 11:44:54.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2243}, {'_account_id': 6873}, {'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12285}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2015-06-02 16:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/16c1282f7caec71eba229c4c1ed29748b0492e3f', 'message': ""Move unit tests into dedicated directory\n\nThis patch moves all of the existing cinder/tests into\ncinder unit tests.  This is being done to make way for\nthe addition of cinder/tests/functional.\n\nYes, this is going to cause significant pain with\nany changes that haven't merged behind it in terms\nof rebase, but there's no real alternative.  We have\nto rip the band-aid off at some point, and early in L\nseems like a great time to do it.\n\nConflicts:\n\tcinder/tests/unit/api/contrib/test_qos_specs_manage.py\n\nChange-Id: I63b0f89474b3c139bdb89589abd85319d2aa61ec\n(cherry picked from commit cbcbc90cf64d91a33b7bcfb826c59d4b69697486)\n""}, {'number': 2, 'created': '2015-06-05 08:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5e21fc7f9161d93bad3eab442357bcecd82aad8d', 'message': ""Move unit tests into dedicated directory\n\nThis patch moves all of the existing cinder/tests into\ncinder unit tests.  This is being done to make way for\nthe addition of cinder/tests/functional.\n\nYes, this is going to cause significant pain with\nany changes that haven't merged behind it in terms\nof rebase, but there's no real alternative.  We have\nto rip the band-aid off at some point, and early in L\nseems like a great time to do it.\n\nConflicts:\n\tcinder/tests/unit/api/contrib/test_qos_specs_manage.py\n\nChange-Id: I63b0f89474b3c139bdb89589abd85319d2aa61ec\n(cherry picked from commit cbcbc90cf64d91a33b7bcfb826c59d4b69697486)\n""}, {'number': 3, 'created': '2015-06-08 08:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b5c1e0cc68cced1c032b276c89a384f2190ff72c', 'message': ""Move unit tests into dedicated directory\n\nThis patch moves all of the existing cinder/tests into\ncinder unit tests.  This is being done to make way for\nthe addition of cinder/tests/functional.\n\nYes, this is going to cause significant pain with\nany changes that haven't merged behind it in terms\nof rebase, but there's no real alternative.  We have\nto rip the band-aid off at some point, and early in L\nseems like a great time to do it.\n\nConflicts:\n\tcinder/tests/unit/api/contrib/test_qos_specs_manage.py\n\nChange-Id: I63b0f89474b3c139bdb89589abd85319d2aa61ec\n(cherry picked from commit cbcbc90cf64d91a33b7bcfb826c59d4b69697486)\n""}, {'number': 4, 'created': '2015-06-08 13:53:20.000000000', 'files': ['cinder/tests/unit/test_db_api.py', 'cinder/tests/unit/api/contrib/test_volume_transfer.py', 'cinder/tests/unit/fake_hp_lefthand_client.py', 'cinder/tests/unit/utils.py', 'cinder/tests/unit/cast_as_call.py', 'cinder/tests/unit/monkey_patch_example/example_b.py', 'cinder/tests/unit/api/contrib/test_extended_snapshot_attributes.py', 'cinder/tests/unit/api/contrib/test_snapshot_actions.py', 'cinder/tests/unit/test_v6000_common.py', 'cinder/tests/unit/scheduler/test_allocated_capacity_weigher.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_api.py', 'cinder/tests/unit/backup/fake_swift_client2.py', 'cinder/tests/unit/test_volume_rpcapi.py', 'cinder/tests/unit/scheduler/test_rpcapi.py', 'cinder/tests/unit/api/v1/__init__.py', 'cinder/tests/unit/test_replication.py', 'cinder/tests/unit/windows/test_vhdutils.py', 'cinder/tests/unit/test_nfs.py', 'cinder/tests/unit/api/contrib/test_volume_migration_status_attribute.py', 'cinder/tests/unit/targets/test_iser_driver.py', 'cinder/tests/unit/test_prophetstor_dpl.py', 'cinder/tests/unit/test_hitachi_hbsd_horcm_fc.py', 'cinder/tests/unit/test_vmware_volumeops.py', 'cinder/tests/unit/api/contrib/test_scheduler_hints.py', 'cinder/tests/unit/test_openvstorage.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/tests/unit/image/__init__.py', 'cinder/tests/unit/test_smbfs.py', 'cinder/tests/unit/test_test.py', 'cinder/tests/unit/brick/test_brick_connector.py', 'cinder/tests/unit/api/v2/__init__.py', 'cinder/tests/unit/api/v2/test_snapshot_metadata.py', 'cinder/tests/unit/compute/__init__.py', 'cinder/tests/unit/zonemanager/test_cisco_lookup_service.py', 'cinder/test.py', 'cinder/tests/unit/api/v1/test_volumes.py', 'cinder/tests/unit/scheduler/test_volume_number_weigher.py', 'cinder/tests/unit/var/certificate.crt', 'cinder/tests/unit/test_v6000_fcp.py', 'cinder/tests/unit/test_volume_configuration.py', 'cinder/tests/unit/windows/test_windows_remotefs.py', 'cinder/tests/unit/api/contrib/test_volume_manage.py', 'cinder/tests/unit/test_exception.py', 'cinder/tests/unit/brick/test_brick_exception.py', 'cinder/tests/unit/test_evaluator.py', 'cinder/tests/unit/test_volume_glance_metadata.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_7mode.py', 'cinder/tests/unit/test_ibm_xiv_ds8k.py', 'cinder/tests/unit/integrated/api/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/test_common.py', 'cinder/tests/unit/db/fakes.py', 'cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/tests/unit/test_hplefthand.py', 'cinder/tests/unit/test_dellsc.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/tests/unit/integrated/test_extensions.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_client.py', 'cinder/tests/unit/api/contrib/test_volume_encryption_metadata.py', 'cinder/tests/unit/glance/stubs.py', 'cinder/tests/unit/keymgr/test_barbican.py', 'cinder/tests/unit/test_rbd.py', 'cinder/tests/unit/fake_driver.py', 'cinder/tests/unit/api/contrib/test_cgsnapshots.py', 'cinder/tests/unit/api/extensions/foxinsocks.py', 'cinder/tests/unit/backup/fake_service_with_verify.py', 'cinder/tests/unit/integrated/api/client.py', 'cinder/tests/unit/zonemanager/test_brcd_lookup_service.py', 'cinder/tests/unit/test_xio.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_base.py', 'cinder/tests/unit/windows/test_windows_utils.py', 'cinder/tests/unit/brick/test_brick_lvm.py', 'cinder/tests/unit/volume/__init__.py', 'cinder/tests/unit/image/test_glance.py', 'cinder/tests/unit/scheduler/test_scheduler_options.py', 'cinder/tests/unit/api/contrib/test_volume_type_encryption.py', 'cinder/tests/unit/keymgr/test_mock_key_mgr.py', 'cinder/tests/unit/test_hp3par.py', 'cinder/tests/unit/api/v2/test_types.py', 'cinder/tests/unit/test_vmware_vmdk.py', 'cinder/tests/unit/keymgr/__init__.py', 'cinder/tests/unit/zonemanager/test_cisco_fc_san_lookup_service.py', 'cinder/tests/unit/targets/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/fakes.py', 'cinder/tests/unit/keymgr/fake.py', 'cinder/tests/unit/test_volume_types_extra_specs.py', 'cinder/tests/unit/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/tests/unit/test_huawei_drivers_compatibility.py', 'cinder/tests/unit/db/test_transfers.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/tests/unit/db/test_qos_specs.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/test_quota.py', 'cinder/tests/unit/volume/drivers/netapp/test_utils.py', 'cinder/tests/unit/api/contrib/test_services.py', 'cinder/tests/unit/test_hitachi_hbsd_snm2_iscsi.py', 'cinder/tests/unit/test_hitachi_hbsd_snm2_fc.py', 'cinder/tests/unit/windows/db_fakes.py', 'cinder/tests/unit/test_pure.py', 'cinder/tests/unit/test_backup_ceph.py', 'cinder/tests/unit/targets/test_lio_driver.py', 'cinder/tests/unit/api/contrib/test_quotas_classes.py', 'cinder/tests/unit/integrated/test_login.py', 'cinder/tests/unit/volume/drivers/netapp/__init__.py', 'cinder/tests/unit/windows/test_smbfs.py', 'cinder/tests/unit/fake_utils.py', 'cinder/tests/unit/test_solidfire.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py', 'cinder/tests/unit/scheduler/test_host_filters.py', 'cinder/tests/__init__.py', 'cinder/tests/unit/api/v1/stubs.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_iscsi.py', 'cinder/tests/unit/policy.json', 'cinder/tests/unit/test_hds_hnas_backend.py', 'cinder/tests/unit/fake_notifier.py', 'cinder/tests/unit/test_block_device.py', 'cinder/tests/unit/zonemanager/test_volume_driver.py', 'cinder/tests/unit/api/contrib/test_volume_type_access.py', 'cinder/tests/unit/api/test_wsgi.py', 'cinder/tests/unit/scheduler/test_goodness_weigher.py', 'cinder/tests/unit/api/test_xmlutil.py', 'cinder/tests/unit/api/v1/test_limits.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/tests/unit/test_zfssa.py', 'cinder/tests/unit/test_image_utils.py', 'cinder/tests/unit/test_scality.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/keymgr/test_not_implemented_key_mgr.py', 'cinder/tests/unit/test_hds_iscsi.py', 'cinder/tests/unit/api/v1/test_volume_metadata.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/fakes.py', 'cinder/tests/unit/fake_vmem_client.py', 'cinder/tests/unit/targets/test_scst_driver.py', 'cinder/tests/unit/test_v6000_iscsi.py', 'cinder/tests/unit/api/middleware/test_auth.py', 'cinder/tests/unit/integrated/integrated_helpers.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode.py', 'cinder/tests/unit/windows/__init__.py', 'cinder/tests/unit/test_qos_specs.py', 'cinder/tests/unit/api/contrib/test_availability_zones.py', 'cinder/tests/unit/api/contrib/test_hosts.py', 'cinder/tests/unit/zonemanager/test_brcd_fc_zone_client_cli.py', 'cinder/tests/unit/monkey_patch_example/example_a.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/tests/unit/integrated/test_xml.py', 'cinder/tests/unit/scheduler/test_host_manager.py', 'cinder/tests/unit/__init__.py', 'cinder/tests/unit/test_hds.py', 'cinder/tests/unit/api/test_common.py', 'cinder/tests/unit/targets/test_tgt_driver.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/backup/fake_swift_client.py', 'cinder/tests/unit/test_backup_driver_base.py', 'cinder/tests/unit/test_ibm_flashsystem.py', 'cinder/tests/unit/db/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_utils.py', 'cinder/tests/unit/targets/test_cxt_driver.py', 'cinder/tests/unit/keymgr/test_conf_key_mgr.py', 'cinder/tests/unit/test_api.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/image/fake.py', 'cinder/tests/unit/targets/test_iet_driver.py', 'cinder/tests/unit/brick/fake_lvm.py', 'cinder/tests/unit/test_quobyte.py', 'cinder/tests/unit/test_dellfc.py', 'cinder/tests/unit/test_misc.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/api/test_extensions.py', 'cinder/tests/unit/test_emc_xtremio.py', 'cinder/tests/unit/test_volume_throttling.py', 'cinder/tests/unit/test_dellscapi.py', 'cinder/tests/unit/backup/fake_service.py', 'cinder/tests/unit/test_conf.py', 'cinder/tests/unit/keymgr/mock_key_mgr.py', 'cinder/tests/unit/glance/__init__.py', 'cinder/tests/unit/conf_fixture.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/runtime_conf.py', 'cinder/tests/unit/api/v1/test_types.py', 'cinder/tests/unit/api/test_versions.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/api/contrib/test_quotas.py', 'cinder/tests/unit/backup/drivers/__init__.py', 'cinder/tests/unit/test_nimble.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/fake_hp_client_exceptions.py', 'cinder/tests/unit/api/v1/test_snapshots.py', 'cinder/tests/unit/scheduler/fakes.py', 'cinder/tests/unit/scheduler/test_filter_scheduler.py', 'cinder/tests/unit/api/contrib/test_used_limits.py', 'cinder/tests/unit/test_netapp_eseries_iscsi.py', 'cinder/tests/unit/api/openstack/__init__.py', 'cinder/tests/unit/volume/drivers/datera.py', 'cinder/tests/unit/backup/__init__.py', 'cinder/tests/unit/declare_conf.py', 'cinder/tests/unit/scheduler/test_chance_weigher.py', 'cinder/tests/unit/test_sheepdog.py', 'cinder/tests/unit/api/openstack/test_wsgi.py', 'cinder/tests/unit/api/v2/test_limits.py', 'cinder/hacking/checks.py', 'cinder/tests/unit/api/fakes.py', 'cinder/tests/unit/api/contrib/test_volume_image_metadata.py', 'cinder/tests/unit/brick/test_brick_linuxscsi.py', 'cinder/tests/unit/test_eqlx.py', 'cinder/tests/unit/zonemanager/test_fc_zone_manager.py', 'cinder/tests/unit/api/contrib/test_admin_actions.py', 'cinder/tests/unit/xenapi/__init__.py', 'cinder/tests/unit/test_wsgi.py', 'cinder/tests/unit/api/common.py', 'cinder/tests/unit/monkey_patch_example/__init__.py', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/test_create_volume_flow.py', 'cinder/tests/unit/volume/drivers/__init__.py', 'cinder/tests/unit/keymgr/test_key_mgr.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_cmode.py', 'cinder/tests/unit/api/contrib/test_scheduler_stats.py', 'cinder/tests/unit/api/test_router.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/tests/unit/test_ibmnas.py', 'cinder/tests/unit/var/ca.crt', 'cinder/tests/unit/test_san.py', 'cinder/tests/unit/test_remotefs.py', 'cinder/tests/unit/objects/test_fields.py', 'cinder/tests/unit/integrated/__init__.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/api/__init__.py', 'cinder/tests/unit/test_vmware_datastore.py', 'cinder/tests/unit/api/contrib/test_types_extra_specs.py', 'cinder/tests/unit/api/v2/stubs.py', 'cinder/tests/unit/zonemanager/test_cisco_fc_zone_client_cli.py', 'cinder/tests/unit/test_hacking.py', 'cinder/tests/unit/zonemanager/test_brcd_fc_san_lookup_service.py', 'cinder/tests/unit/api/middleware/__init__.py', 'cinder/tests/unit/db/test_name_id.py', 'cinder/tests/unit/compute/test_nova.py', 'cinder/tests/unit/test_netapp.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_cmode.py', 'cinder/tests/unit/keymgr/test_key.py', 'cinder/tests/unit/test_gpfs.py', 'cinder/tests/unit/test_emc_vmax.py', 'cinder/tests/unit/test_cmd.py', 'cinder/tests/unit/test_huawei_18000.py', 'cinder/tests/unit/api/contrib/test_volume_replication.py', 'cinder/tests/unit/api/contrib/test_volume_tenant_attribute.py', 'cinder/tests/unit/objects/__init__.py', 'cinder/tests/unit/test_glusterfs.py', 'cinder/tests/unit/db/test_finish_migration.py', 'cinder/tests/unit/var/privatekey.key', 'cinder/tests/unit/test_test_utils.py', 'cinder/tests/unit/windows/test_windows.py', 'cinder/tests/unit/test_srb.py', 'cinder/tests/unit/api/contrib/test_consistencygroups.py', 'cinder/tests/unit/targets/test_base_iscsi_driver.py', 'cinder/tests/unit/test_volume.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_7mode.py', 'cinder/tests/unit/api/contrib/test_qos_specs_manage.py', 'cinder/tests/unit/scheduler/__init__.py', 'cinder/tests/unit/test_backup_swift.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/__init__.py', 'cinder/tests/unit/test_netapp_ssc.py', 'cinder/tests/unit/fake_hp_3par_client.py', 'cinder/tests/unit/api/extensions/__init__.py', 'cinder/tests/unit/db/test_purge.py', 'cinder/tests/unit/test_api_urlmap.py', 'cinder/tests/unit/brick/test_brick_linuxfc.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/__init__.py', 'cinder/tests/unit/brick/__init__.py', 'cinder/tests/unit/test_context.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/brick/test_brick_remotefs.py', 'cinder/tests/unit/zonemanager/test_cisco_fc_zone_driver.py', 'cinder/tests/unit/zonemanager/__init__.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/api/contrib/__init__.py', 'cinder/tests/unit/test_backup.py', 'cinder/tests/unit/integrated/test_volumes.py', 'cinder/tests/unit/test_backup_tsm.py', 'cinder/tests/unit/test_netapp_nfs.py', 'cinder/tests/unit/api/contrib/test_volume_unmanage.py', 'cinder/tests/unit/test_hds_nfs.py', 'cinder/tests/unit/api/v2/test_snapshots.py', 'cinder/tests/unit/api/contrib/test_types_manage.py', 'cinder/tests/unit/api/middleware/test_faults.py', 'cinder/tests/unit/test_cloudbyte.py', 'cinder/tests/unit/test_utils.py', 'cinder/tests/unit/test_service.py', 'cinder/tests/unit/test_migrations.py', 'cinder/tests/unit/scheduler/test_capacity_weigher.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f4b7d827d6a728e72152dcce2e19be5d727b30f', 'message': ""Move unit tests into dedicated directory\n\nThis patch moves all of the existing cinder/tests into\ncinder unit tests.  This is being done to make way for\nthe addition of cinder/tests/functional.\n\nYes, this is going to cause significant pain with\nany changes that haven't merged behind it in terms\nof rebase, but there's no real alternative.  We have\nto rip the band-aid off at some point, and early in L\nseems like a great time to do it.\n\nConflicts:\n\tcinder/tests/unit/api/contrib/test_qos_specs_manage.py\n\nChange-Id: I63b0f89474b3c139bdb89589abd85319d2aa61ec\n(cherry picked from commit cbcbc90cf64d91a33b7bcfb826c59d4b69697486)\n""}]",0,187662,7f4b7d827d6a728e72152dcce2e19be5d727b30f,69,29,4,9535,,,0,"Move unit tests into dedicated directory

This patch moves all of the existing cinder/tests into
cinder unit tests.  This is being done to make way for
the addition of cinder/tests/functional.

Yes, this is going to cause significant pain with
any changes that haven't merged behind it in terms
of rebase, but there's no real alternative.  We have
to rip the band-aid off at some point, and early in L
seems like a great time to do it.

Conflicts:
	cinder/tests/unit/api/contrib/test_qos_specs_manage.py

Change-Id: I63b0f89474b3c139bdb89589abd85319d2aa61ec
(cherry picked from commit cbcbc90cf64d91a33b7bcfb826c59d4b69697486)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/187662/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_db_api.py', 'cinder/tests/unit/api/contrib/test_volume_transfer.py', 'cinder/tests/unit/fake_hp_lefthand_client.py', 'cinder/tests/unit/utils.py', 'cinder/tests/unit/cast_as_call.py', 'cinder/tests/unit/monkey_patch_example/example_b.py', 'cinder/tests/unit/api/contrib/test_extended_snapshot_attributes.py', 'cinder/tests/unit/api/contrib/test_snapshot_actions.py', 'cinder/tests/unit/test_v6000_common.py', 'cinder/tests/unit/scheduler/test_allocated_capacity_weigher.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_api.py', 'cinder/tests/unit/backup/fake_swift_client2.py', 'cinder/tests/unit/test_volume_rpcapi.py', 'cinder/tests/unit/scheduler/test_rpcapi.py', 'cinder/tests/unit/api/v1/__init__.py', 'cinder/tests/unit/test_replication.py', 'cinder/tests/unit/windows/test_vhdutils.py', 'cinder/tests/unit/test_nfs.py', 'cinder/tests/unit/api/contrib/test_volume_migration_status_attribute.py', 'cinder/tests/unit/targets/test_iser_driver.py', 'cinder/tests/unit/test_prophetstor_dpl.py', 'cinder/tests/unit/test_hitachi_hbsd_horcm_fc.py', 'cinder/tests/unit/test_vmware_volumeops.py', 'cinder/tests/unit/api/contrib/test_scheduler_hints.py', 'cinder/tests/unit/test_openvstorage.py', 'cinder/tests/unit/test_volume_types.py', 'cinder/tests/unit/image/__init__.py', 'cinder/tests/unit/test_smbfs.py', 'cinder/tests/unit/test_test.py', 'cinder/tests/unit/brick/test_brick_connector.py', 'cinder/tests/unit/api/v2/__init__.py', 'cinder/tests/unit/api/v2/test_snapshot_metadata.py', 'cinder/tests/unit/compute/__init__.py', 'cinder/tests/unit/zonemanager/test_cisco_lookup_service.py', 'cinder/test.py', 'cinder/tests/unit/api/v1/test_volumes.py', 'cinder/tests/unit/scheduler/test_volume_number_weigher.py', 'cinder/tests/unit/var/certificate.crt', 'cinder/tests/unit/test_v6000_fcp.py', 'cinder/tests/unit/test_volume_configuration.py', 'cinder/tests/unit/windows/test_windows_remotefs.py', 'cinder/tests/unit/api/contrib/test_volume_manage.py', 'cinder/tests/unit/test_exception.py', 'cinder/tests/unit/brick/test_brick_exception.py', 'cinder/tests/unit/test_evaluator.py', 'cinder/tests/unit/test_volume_glance_metadata.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_7mode.py', 'cinder/tests/unit/test_ibm_xiv_ds8k.py', 'cinder/tests/unit/integrated/api/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/test_common.py', 'cinder/tests/unit/db/fakes.py', 'cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/tests/unit/test_hplefthand.py', 'cinder/tests/unit/test_dellsc.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/tests/unit/integrated/test_extensions.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_client.py', 'cinder/tests/unit/api/contrib/test_volume_encryption_metadata.py', 'cinder/tests/unit/glance/stubs.py', 'cinder/tests/unit/keymgr/test_barbican.py', 'cinder/tests/unit/test_rbd.py', 'cinder/tests/unit/fake_driver.py', 'cinder/tests/unit/api/contrib/test_cgsnapshots.py', 'cinder/tests/unit/api/extensions/foxinsocks.py', 'cinder/tests/unit/backup/fake_service_with_verify.py', 'cinder/tests/unit/integrated/api/client.py', 'cinder/tests/unit/zonemanager/test_brcd_lookup_service.py', 'cinder/tests/unit/test_xio.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_base.py', 'cinder/tests/unit/windows/test_windows_utils.py', 'cinder/tests/unit/brick/test_brick_lvm.py', 'cinder/tests/unit/volume/__init__.py', 'cinder/tests/unit/image/test_glance.py', 'cinder/tests/unit/scheduler/test_scheduler_options.py', 'cinder/tests/unit/api/contrib/test_volume_type_encryption.py', 'cinder/tests/unit/keymgr/test_mock_key_mgr.py', 'cinder/tests/unit/test_hp3par.py', 'cinder/tests/unit/api/v2/test_types.py', 'cinder/tests/unit/test_vmware_vmdk.py', 'cinder/tests/unit/keymgr/__init__.py', 'cinder/tests/unit/zonemanager/test_cisco_fc_san_lookup_service.py', 'cinder/tests/unit/targets/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/fakes.py', 'cinder/tests/unit/keymgr/fake.py', 'cinder/tests/unit/test_volume_types_extra_specs.py', 'cinder/tests/unit/zonemanager/test_brcd_fc_zone_driver.py', 'cinder/tests/unit/test_huawei_drivers_compatibility.py', 'cinder/tests/unit/db/test_transfers.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/tests/unit/db/test_qos_specs.py', 'cinder/tests/unit/api/contrib/test_volume_host_attribute.py', 'cinder/tests/unit/test_quota.py', 'cinder/tests/unit/volume/drivers/netapp/test_utils.py', 'cinder/tests/unit/api/contrib/test_services.py', 'cinder/tests/unit/test_hitachi_hbsd_snm2_iscsi.py', 'cinder/tests/unit/test_hitachi_hbsd_snm2_fc.py', 'cinder/tests/unit/windows/db_fakes.py', 'cinder/tests/unit/test_pure.py', 'cinder/tests/unit/test_backup_ceph.py', 'cinder/tests/unit/targets/test_lio_driver.py', 'cinder/tests/unit/api/contrib/test_quotas_classes.py', 'cinder/tests/unit/integrated/test_login.py', 'cinder/tests/unit/volume/drivers/netapp/__init__.py', 'cinder/tests/unit/windows/test_smbfs.py', 'cinder/tests/unit/fake_utils.py', 'cinder/tests/unit/test_solidfire.py', 'cinder/tests/unit/api/v1/test_snapshot_metadata.py', 'cinder/tests/unit/scheduler/test_host_filters.py', 'cinder/tests/__init__.py', 'cinder/tests/unit/api/v1/stubs.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_iscsi.py', 'cinder/tests/unit/policy.json', 'cinder/tests/unit/test_hds_hnas_backend.py', 'cinder/tests/unit/fake_notifier.py', 'cinder/tests/unit/test_block_device.py', 'cinder/tests/unit/zonemanager/test_volume_driver.py', 'cinder/tests/unit/api/contrib/test_volume_type_access.py', 'cinder/tests/unit/api/test_wsgi.py', 'cinder/tests/unit/scheduler/test_goodness_weigher.py', 'cinder/tests/unit/api/test_xmlutil.py', 'cinder/tests/unit/api/v1/test_limits.py', 'cinder/tests/unit/api/contrib/test_volume_actions.py', 'cinder/tests/unit/test_zfssa.py', 'cinder/tests/unit/test_image_utils.py', 'cinder/tests/unit/test_scality.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/keymgr/test_not_implemented_key_mgr.py', 'cinder/tests/unit/test_hds_iscsi.py', 'cinder/tests/unit/api/v1/test_volume_metadata.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/fakes.py', 'cinder/tests/unit/fake_vmem_client.py', 'cinder/tests/unit/targets/test_scst_driver.py', 'cinder/tests/unit/test_v6000_iscsi.py', 'cinder/tests/unit/api/middleware/test_auth.py', 'cinder/tests/unit/integrated/integrated_helpers.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode.py', 'cinder/tests/unit/windows/__init__.py', 'cinder/tests/unit/test_qos_specs.py', 'cinder/tests/unit/api/contrib/test_availability_zones.py', 'cinder/tests/unit/api/contrib/test_hosts.py', 'cinder/tests/unit/zonemanager/test_brcd_fc_zone_client_cli.py', 'cinder/tests/unit/monkey_patch_example/example_a.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/tests/unit/integrated/test_xml.py', 'cinder/tests/unit/scheduler/test_host_manager.py', 'cinder/tests/unit/__init__.py', 'cinder/tests/unit/test_hds.py', 'cinder/tests/unit/api/test_common.py', 'cinder/tests/unit/targets/test_tgt_driver.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/tests/unit/backup/fake_swift_client.py', 'cinder/tests/unit/test_backup_driver_base.py', 'cinder/tests/unit/test_ibm_flashsystem.py', 'cinder/tests/unit/db/__init__.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/test_utils.py', 'cinder/tests/unit/targets/test_cxt_driver.py', 'cinder/tests/unit/keymgr/test_conf_key_mgr.py', 'cinder/tests/unit/test_api.py', 'cinder/tests/unit/api/v2/test_volume_metadata.py', 'cinder/tests/unit/image/fake.py', 'cinder/tests/unit/targets/test_iet_driver.py', 'cinder/tests/unit/brick/fake_lvm.py', 'cinder/tests/unit/test_quobyte.py', 'cinder/tests/unit/test_dellfc.py', 'cinder/tests/unit/test_misc.py', 'cinder/tests/unit/test_volume_utils.py', 'cinder/tests/unit/test_volume_transfer.py', 'cinder/tests/unit/api/test_extensions.py', 'cinder/tests/unit/test_emc_xtremio.py', 'cinder/tests/unit/test_volume_throttling.py', 'cinder/tests/unit/test_dellscapi.py', 'cinder/tests/unit/backup/fake_service.py', 'cinder/tests/unit/test_conf.py', 'cinder/tests/unit/keymgr/mock_key_mgr.py', 'cinder/tests/unit/glance/__init__.py', 'cinder/tests/unit/conf_fixture.py', 'cinder/tests/unit/scheduler/test_scheduler.py', 'cinder/tests/unit/runtime_conf.py', 'cinder/tests/unit/api/v1/test_types.py', 'cinder/tests/unit/api/test_versions.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/api/contrib/test_quotas.py', 'cinder/tests/unit/backup/drivers/__init__.py', 'cinder/tests/unit/test_nimble.py', 'cinder/tests/unit/objects/test_volume.py', 'cinder/tests/unit/fake_hp_client_exceptions.py', 'cinder/tests/unit/api/v1/test_snapshots.py', 'cinder/tests/unit/scheduler/fakes.py', 'cinder/tests/unit/scheduler/test_filter_scheduler.py', 'cinder/tests/unit/api/contrib/test_used_limits.py', 'cinder/tests/unit/test_netapp_eseries_iscsi.py', 'cinder/tests/unit/api/openstack/__init__.py', 'cinder/tests/unit/volume/drivers/datera.py', 'cinder/tests/unit/backup/__init__.py', 'cinder/tests/unit/declare_conf.py', 'cinder/tests/unit/scheduler/test_chance_weigher.py', 'cinder/tests/unit/test_sheepdog.py', 'cinder/tests/unit/api/openstack/test_wsgi.py', 'cinder/tests/unit/api/v2/test_limits.py', 'cinder/hacking/checks.py', 'cinder/tests/unit/api/fakes.py', 'cinder/tests/unit/api/contrib/test_volume_image_metadata.py', 'cinder/tests/unit/brick/test_brick_linuxscsi.py', 'cinder/tests/unit/test_eqlx.py', 'cinder/tests/unit/zonemanager/test_fc_zone_manager.py', 'cinder/tests/unit/api/contrib/test_admin_actions.py', 'cinder/tests/unit/xenapi/__init__.py', 'cinder/tests/unit/test_wsgi.py', 'cinder/tests/unit/api/common.py', 'cinder/tests/unit/monkey_patch_example/__init__.py', 'cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/test_create_volume_flow.py', 'cinder/tests/unit/volume/drivers/__init__.py', 'cinder/tests/unit/keymgr/test_key_mgr.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_cmode.py', 'cinder/tests/unit/api/contrib/test_scheduler_stats.py', 'cinder/tests/unit/api/test_router.py', 'cinder/tests/unit/objects/test_objects.py', 'cinder/tests/unit/test_ibmnas.py', 'cinder/tests/unit/var/ca.crt', 'cinder/tests/unit/test_san.py', 'cinder/tests/unit/test_remotefs.py', 'cinder/tests/unit/objects/test_fields.py', 'cinder/tests/unit/integrated/__init__.py', 'cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'cinder/tests/unit/api/__init__.py', 'cinder/tests/unit/test_vmware_datastore.py', 'cinder/tests/unit/api/contrib/test_types_extra_specs.py', 'cinder/tests/unit/api/v2/stubs.py', 'cinder/tests/unit/zonemanager/test_cisco_fc_zone_client_cli.py', 'cinder/tests/unit/test_hacking.py', 'cinder/tests/unit/zonemanager/test_brcd_fc_san_lookup_service.py', 'cinder/tests/unit/api/middleware/__init__.py', 'cinder/tests/unit/db/test_name_id.py', 'cinder/tests/unit/compute/test_nova.py', 'cinder/tests/unit/test_netapp.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_cmode.py', 'cinder/tests/unit/keymgr/test_key.py', 'cinder/tests/unit/test_gpfs.py', 'cinder/tests/unit/test_emc_vmax.py', 'cinder/tests/unit/test_cmd.py', 'cinder/tests/unit/test_huawei_18000.py', 'cinder/tests/unit/api/contrib/test_volume_replication.py', 'cinder/tests/unit/api/contrib/test_volume_tenant_attribute.py', 'cinder/tests/unit/objects/__init__.py', 'cinder/tests/unit/test_glusterfs.py', 'cinder/tests/unit/db/test_finish_migration.py', 'cinder/tests/unit/var/privatekey.key', 'cinder/tests/unit/test_test_utils.py', 'cinder/tests/unit/windows/test_windows.py', 'cinder/tests/unit/test_srb.py', 'cinder/tests/unit/api/contrib/test_consistencygroups.py', 'cinder/tests/unit/targets/test_base_iscsi_driver.py', 'cinder/tests/unit/test_volume.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_7mode.py', 'cinder/tests/unit/api/contrib/test_qos_specs_manage.py', 'cinder/tests/unit/scheduler/__init__.py', 'cinder/tests/unit/test_backup_swift.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/__init__.py', 'cinder/tests/unit/test_netapp_ssc.py', 'cinder/tests/unit/fake_hp_3par_client.py', 'cinder/tests/unit/api/extensions/__init__.py', 'cinder/tests/unit/db/test_purge.py', 'cinder/tests/unit/test_api_urlmap.py', 'cinder/tests/unit/brick/test_brick_linuxfc.py', 'cinder/tests/unit/volume/drivers/netapp/eseries/__init__.py', 'cinder/tests/unit/brick/__init__.py', 'cinder/tests/unit/test_context.py', 'cinder/tests/unit/api/v2/test_volumes.py', 'cinder/tests/unit/brick/test_brick_remotefs.py', 'cinder/tests/unit/zonemanager/test_cisco_fc_zone_driver.py', 'cinder/tests/unit/zonemanager/__init__.py', 'cinder/tests/unit/fake_volume.py', 'cinder/tests/unit/api/contrib/__init__.py', 'cinder/tests/unit/test_backup.py', 'cinder/tests/unit/integrated/test_volumes.py', 'cinder/tests/unit/test_backup_tsm.py', 'cinder/tests/unit/test_netapp_nfs.py', 'cinder/tests/unit/api/contrib/test_volume_unmanage.py', 'cinder/tests/unit/test_hds_nfs.py', 'cinder/tests/unit/api/v2/test_snapshots.py', 'cinder/tests/unit/api/contrib/test_types_manage.py', 'cinder/tests/unit/api/middleware/test_faults.py', 'cinder/tests/unit/test_cloudbyte.py', 'cinder/tests/unit/test_utils.py', 'cinder/tests/unit/test_service.py', 'cinder/tests/unit/test_migrations.py', 'cinder/tests/unit/scheduler/test_capacity_weigher.py']",289,16c1282f7caec71eba229c4c1ed29748b0492e3f,bug/1460692,from cinder.tests.unit.scheduler import fakes,from cinder.tests.scheduler import fakes,274,263
openstack%2Fgrenade~stable%2Fkilo~I4b2542e6ff2bc11a51c1fa15f1cf8836872ea089,openstack/grenade,stable/kilo,I4b2542e6ff2bc11a51c1fa15f1cf8836872ea089,Include missing source so keystone can shut down in kilo,ABANDONED,2015-06-11 10:59:59.000000000,2015-06-11 11:38:16.000000000,,[],"[{'number': 1, 'created': '2015-06-11 10:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/332d2ca89beb7bfd052cd4f4904b5028f484c296', 'message': ""Include missing source so keystone can shut down in kilo\n\nKeystone couldn't shut down in WSGI mode because we were missing a\nsource of the lib/apache file. That was preventing kilo backports from\nlanding, this should fix that issue.\n\nChange-Id: I4b2542e6ff2bc11a51c1fa15f1cf8836872ea089\nCloses-Bug: #1456835\n""}, {'number': 2, 'created': '2015-06-11 11:00:52.000000000', 'files': ['projects/10_keystone/shutdown.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/f9e49785171f3f70e680adbc11d1beeb5dfd387f', 'message': ""Include missing source so keystone can shut down in kilo\n\nKeystone couldn't shut down in WSGI mode because we were missing a\nsource of the lib/apache file. That was preventing kilo backports from\nlanding, this should fix that issue.\n\nDepends-On: I557e9d7d35239b9336b6d90f037f14cdf2585f76\n(devstack-gate change to revert to old correct behavior)\n\nChange-Id: I4b2542e6ff2bc11a51c1fa15f1cf8836872ea089\nCloses-Bug: #1456835\n""}]",0,190581,f9e49785171f3f70e680adbc11d1beeb5dfd387f,3,0,2,2750,,,0,"Include missing source so keystone can shut down in kilo

Keystone couldn't shut down in WSGI mode because we were missing a
source of the lib/apache file. That was preventing kilo backports from
landing, this should fix that issue.

Depends-On: I557e9d7d35239b9336b6d90f037f14cdf2585f76
(devstack-gate change to revert to old correct behavior)

Change-Id: I4b2542e6ff2bc11a51c1fa15f1cf8836872ea089
Closes-Bug: #1456835
",git fetch https://review.opendev.org/openstack/grenade refs/changes/81/190581/2 && git format-patch -1 --stdout FETCH_HEAD,['projects/10_keystone/shutdown.sh'],1,332d2ca89beb7bfd052cd4f4904b5028f484c296,,source $BASE_DEVSTACK_DIR/lib/apache,,1,0
openstack%2Fnova~master~I0756700c8a8d1baa34eaa7c568ffea97365c5845,openstack/nova,master,I0756700c8a8d1baa34eaa7c568ffea97365c5845,Fix formatting issue of rest_api_version_history,ABANDONED,2015-06-11 10:16:13.000000000,2015-06-11 11:36:10.000000000,,"[{'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 13252}, {'_account_id': 15286}]","[{'number': 1, 'created': '2015-06-11 10:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8151f19f0a8a3a90712892a0794473f0a59f2f7e', 'message': 'Fix formatting issue of rest_api_version_history\n\nVery small change to fix a formatting issue of a paragraph in the\nrest_api_version_history file.\n\nChange-Id: I0756700c8a8d1baa34eaa7c568ffea97365c5845\n'}, {'number': 2, 'created': '2015-06-11 10:20:08.000000000', 'files': ['nova/api/openstack/rest_api_version_history.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/a0d11aa12e5c855cd176f507ff8bf38fcd975ab9', 'message': 'Fix formatting issue of rest_api_version_history\n\nVery small change to fix a formatting issue of a paragraph in the\nrest_api_version_history file.\n\nChange-Id: I0756700c8a8d1baa34eaa7c568ffea97365c5845\n'}]",0,190567,a0d11aa12e5c855cd176f507ff8bf38fcd975ab9,8,4,2,1865,,,0,"Fix formatting issue of rest_api_version_history

Very small change to fix a formatting issue of a paragraph in the
rest_api_version_history file.

Change-Id: I0756700c8a8d1baa34eaa7c568ffea97365c5845
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/190567/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/rest_api_version_history.rst'],1,8151f19f0a8a3a90712892a0794473f0a59f2f7e,fix_rst_formatting,2.4 ---,- **2.4**,2,1
openstack%2Fheat~master~I5e09e2c797701483d0a85d33fad37f8481458f8c,openstack/heat,master,I5e09e2c797701483d0a85d33fad37f8481458f8c,Add unit test case for Keystone client plug-in for group,MERGED,2015-06-09 09:15:16.000000000,2015-06-11 11:33:00.000000000,2015-06-11 11:20:31.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9751}, {'_account_id': 10487}]","[{'number': 1, 'created': '2015-06-09 09:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0dbb69c61c212dbb22167c8bb785c1ec17d6bf1b', 'message': 'Add unit test case for Keystone client plugin for group\n\nAdds required unit test cases for the keystone group\nin the keystone client plugin\n\nChange-Id: I5e09e2c797701483d0a85d33fad37f8481458f8c\nCloses-bug: #1463267\n'}, {'number': 2, 'created': '2015-06-09 10:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9662186af4b299433031c2c8291e2a670b9603a2', 'message': 'Add unit test case for Keystone client plugin for group\n\nAdds required unit test cases for the keystone group\nin the keystone client plugin\n\nChange-Id: I5e09e2c797701483d0a85d33fad37f8481458f8c\nCloses-bug: #1463267\n'}, {'number': 3, 'created': '2015-06-10 11:45:21.000000000', 'files': ['heat/tests/keystone/test_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/030d1ae654a79721a012d29e12421ae360386da6', 'message': 'Add unit test case for Keystone client plug-in for group\n\nAdds required unit test cases for the keystone group\nin the keystone client plug-in\n\nCloses-Bug: #1463267\n\nChange-Id: I5e09e2c797701483d0a85d33fad37f8481458f8c\n'}]",0,189607,030d1ae654a79721a012d29e12421ae360386da6,22,6,3,10487,,,0,"Add unit test case for Keystone client plug-in for group

Adds required unit test cases for the keystone group
in the keystone client plug-in

Closes-Bug: #1463267

Change-Id: I5e09e2c797701483d0a85d33fad37f8481458f8c
",git fetch https://review.opendev.org/openstack/heat refs/changes/07/189607/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/keystone/test_client.py'],1,0dbb69c61c212dbb22167c8bb785c1ec17d6bf1b,bug/1463267-keystone-client-plugin-tests," class KeystoneClientPluginGroupTest(common.HeatTestCase): sample_uuid = '477e8273-60a7-4c41-b683-fdb0bc7cd152' sample_name = 'sample_group' def _get_mock_group(self): group = mock.MagicMock() group.id = self.sample_uuid group.name = self.sample_name return group def setUp(self): super(KeystoneClientPluginGroupTest, self).setUp() self._client = mock.MagicMock() self._client.client = mock.MagicMock() self._client.client.groups = mock.MagicMock() @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_group_id(self, client_keystone): self._client.client.groups.get.return_value = (self ._get_mock_group()) client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_group_id(self.sample_uuid)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_group_id_with_name(self, client_keystone): self._client.client.groups.get.side_effect = (keystone_exceptions .NotFound) self._client.client.groups.list.return_value = [ self._get_mock_group() ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_group_id(self.sample_name)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_group_id_not_found(self, client_keystone): self._client.client.groups.get.side_effect = (keystone_exceptions .NotFound) self._client.client.groups.list.return_value = [ ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) ex = self.assertRaises(exception.EntityNotFound, client_plugin.get_group_id, self.sample_name) msg = (""The KeystoneGroup (%(name)s) could not be found."" % {'name': self.sample_name}) self.assertEqual(msg, six.text_type(ex))",,66,0
openstack%2Fneutron~master~Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5,openstack/neutron,master,Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5,Moving out the cisco n1kv section to stackforge,MERGED,2015-04-08 01:17:25.000000000,2015-06-11 11:30:34.000000000,2015-06-11 03:11:52.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7018}, {'_account_id': 8940}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12749}, {'_account_id': 12955}, {'_account_id': 14027}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-08 01:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39e6c1e5772d24a4b1e8642f270b2a1505c4f648', 'message': 'N1Kv: Make neutron-VSM sync interval configurable\n\nCurrently, the sync interval between consecutive VSM-neutron syncs for\nCisco Nexus 1000V cannot be configured.\n\nChange-Id: Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5\nCloses-Bug: #1441400\n'}, {'number': 2, 'created': '2015-04-08 01:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bca0c61049ead6397099fdbbdc439902061672b2', 'message': 'N1Kv: Make neutron-VSM sync interval configurable\n\nCurrently, the sync interval between consecutive VSM-neutron syncs for\nCisco Nexus 1000V is not user configurable.\n\nChange-Id: Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5\nCloses-Bug: #1441400\n'}, {'number': 3, 'created': '2015-06-01 18:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0259ab43eae4cef0fcaf8121a808130cd75e876', 'message': ""Moving out the cisco n1kv section to stackforge\n\nSince most of the n1kv plugin code resides in stackforge/networking-cisco\nrepo, it's best to move the n1kv section there\n\nChange-Id: Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5\nCloses-Bug: #1441400\n""}, {'number': 4, 'created': '2015-06-02 18:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1eb3a9628f56472a249a69da27a43ccd5274e738', 'message': ""Moving out the cisco n1kv section to stackforge\n\nSince most of the n1kv plugin code resides in stackforge/networking-cisco\nrepo, it's best to move the n1kv section there\n\nChange-Id: Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5\nDepends-on: Ia26b504a4135b12f003a89e3f19ff650e0d271a4\nCloses-Bug: #1441400\n""}, {'number': 5, 'created': '2015-06-10 18:07:36.000000000', 'files': ['etc/neutron/plugins/ml2/ml2_conf_cisco.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c34ce7c9845cc56f981e0ee8714d1f9345df5852', 'message': ""Moving out the cisco n1kv section to stackforge\n\nSince most of the n1kv plugin code resides in stackforge/networking-cisco\nrepo, it's best to move the n1kv section there\n\nChange-Id: Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5\nCloses-Bug: #1441400\n""}]",6,171451,c34ce7c9845cc56f981e0ee8714d1f9345df5852,111,35,5,12749,,,0,"Moving out the cisco n1kv section to stackforge

Since most of the n1kv plugin code resides in stackforge/networking-cisco
repo, it's best to move the n1kv section there

Change-Id: Ic1388980dea0d27dfa5e84869f1f20cc9bff78e5
Closes-Bug: #1441400
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/171451/5 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/plugins/ml2/ml2_conf_cisco.ini'],1,39e6c1e5772d24a4b1e8642f270b2a1505c4f648,bug/1441400,# (IntOpt) Time duration in seconds between consecutive neutron-VSM syncs # sync_interval = 300 ,,3,0
openstack%2Fpython-manilaclient~master~I51a4aa7d66cf24ec89cd2c87c9ce902b919ba4b1,openstack/python-manilaclient,master,I51a4aa7d66cf24ec89cd2c87c9ce902b919ba4b1,Fix configuration for tox 2.0.x,MERGED,2015-05-13 17:04:50.000000000,2015-06-11 11:27:09.000000000,2015-05-14 17:31:37.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-05-13 17:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/677caa26970188ec9fc9d84d25337010b02f4d28', 'message': ""Fix tox configuration\n\nGate jobs started failing with following error:\n\ntox.ConfigError: ConfigError: substitution key 'envbindir' not found\n\nSo, replace substitution key 'envbindir' with 'envdir' with suffix '/bin'.\n\nChange-Id: I51a4aa7d66cf24ec89cd2c87c9ce902b919ba4b1\n""}, {'number': 2, 'created': '2015-05-14 12:41:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/095c81eb1e17f8d5b8c1c903d67792fdc4abbe9f', 'message': ""Fix configuration for tox 2.0.x\n\nUsing latest tox 2.0.x our tox jobs fail with following error:\n\ntox.ConfigError: ConfigError: substitution key 'envbindir' not found\n\nSo, replace substitution key 'envbindir' with 'envdir' with suffix '/bin'.\n\nChange-Id: I51a4aa7d66cf24ec89cd2c87c9ce902b919ba4b1\nCloses-Bug: #1455066\n""}]",0,182759,095c81eb1e17f8d5b8c1c903d67792fdc4abbe9f,27,8,2,8851,,,0,"Fix configuration for tox 2.0.x

Using latest tox 2.0.x our tox jobs fail with following error:

tox.ConfigError: ConfigError: substitution key 'envbindir' not found

So, replace substitution key 'envbindir' with 'envdir' with suffix '/bin'.

Change-Id: I51a4aa7d66cf24ec89cd2c87c9ce902b919ba4b1
Closes-Bug: #1455066
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/59/182759/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,677caa26970188ec9fc9d84d25337010b02f4d28,bug/1455066, OS_MANILA_EXEC_DIR = {envdir}/bin {envdir}/bin/python setup.py install {envdir}/bin/python setup.py testr --testr-args='{posargs}' {envdir}/bin/python setup.py install {envdir}/bin/oslo-config-generator --config-file etc/oslo-config-generator/manilaclient.conf, OS_MANILA_EXEC_DIR = {envbindir} {envbindir}/python setup.py install {envbindir}/python setup.py testr --testr-args='{posargs}' {envbindir}/python setup.py install {envbindir}/oslo-config-generator --config-file etc/oslo-config-generator/manilaclient.conf,5,5
openstack%2Fproject-config~master~I28ba0cb0a064e1a08b47578ead9ec1a2e2768ca3,openstack/project-config,master,I28ba0cb0a064e1a08b47578ead9ec1a2e2768ca3,Add libjerasure dev packages on workers,MERGED,2015-06-08 21:23:39.000000000,2015-06-11 11:26:57.000000000,2015-06-11 11:26:56.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-08 21:23:39.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/90bc7f14a82d72e05752117207d820b96402229b', 'message': ""Add libjerasure dev packages on workers\n\nWithout libjerasure-dev and its declared dependency, libjerasure2,\npyeclib doesn't build extensions needed to support Swift's Python\n2.7 unit test jobs. Update the bindep fallback if the corresponding\nchange is merged to the openstack_project Puppet manifest.\n\nChange-Id: I28ba0cb0a064e1a08b47578ead9ec1a2e2768ca3\nDepends-On: Ia8ea54a8dc3350d17abc4ff33fe03fd937e0a068\n""}]",0,189471,90bc7f14a82d72e05752117207d820b96402229b,13,4,1,5263,,,0,"Add libjerasure dev packages on workers

Without libjerasure-dev and its declared dependency, libjerasure2,
pyeclib doesn't build extensions needed to support Swift's Python
2.7 unit test jobs. Update the bindep fallback if the corresponding
change is merged to the openstack_project Puppet manifest.

Change-Id: I28ba0cb0a064e1a08b47578ead9ec1a2e2768ca3
Depends-On: Ia8ea54a8dc3350d17abc4ff33fe03fd937e0a068
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/189471/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,90bc7f14a82d72e05752117207d820b96402229b,pyeclib-jerasure,libjerasure-dev [platform:ubuntu-trusty],,1,0
openstack%2Ftempest~master~I3e0d06c7654ad30c42e435a19106c6633144c9b5,openstack/tempest,master,I3e0d06c7654ad30c42e435a19106c6633144c9b5,Provides a sample resourcefile for Javelin,MERGED,2015-05-13 13:38:14.000000000,2015-06-11 11:25:40.000000000,2015-06-11 11:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 7872}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-13 13:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/43697420299c660229c8517f54042ac8d53a116f', 'message': 'Provides a sample resourcefile for Javelin\n\nIntroducing a sample file in etc/ similar to the existing ones for\ntempest.conf or accounts.yaml. This file can be used as a concrete\nexample of how to use Javelin.\n\nCurrently some resources are missing from the file (like volumes,\nrouters, and more importantly servers) and could be added in a later\ncommit.\n\nChange-Id: I3e0d06c7654ad30c42e435a19106c6633144c9b5\n'}, {'number': 2, 'created': '2015-06-05 12:56:01.000000000', 'files': ['etc/javelin-resources.yaml.sample'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b9c52dee27ba83146a84fc61ed389000952cbb00', 'message': 'Provides a sample resourcefile for Javelin\n\nIntroducing a sample file in etc/ similar to the existing ones for\ntempest.conf or accounts.yaml. This file can be used as a concrete\nexample of how to use Javelin.\n\nCurrently some resources are missing from the file (like volumes,\nrouters, and more importantly servers) and could be added in a later\ncommit.\n\nChange-Id: I3e0d06c7654ad30c42e435a19106c6633144c9b5\n'}]",0,182671,b9c52dee27ba83146a84fc61ed389000952cbb00,16,7,2,7020,,,0,"Provides a sample resourcefile for Javelin

Introducing a sample file in etc/ similar to the existing ones for
tempest.conf or accounts.yaml. This file can be used as a concrete
example of how to use Javelin.

Currently some resources are missing from the file (like volumes,
routers, and more importantly servers) and could be added in a later
commit.

Change-Id: I3e0d06c7654ad30c42e435a19106c6633144c9b5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/182671/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/resourcefile.yaml.sample'],1,43697420299c660229c8517f54042ac8d53a116f,javelin_resourcefile,tenants: - javelin - discuss users: - name: javelin pass: gungnir tenant: javelin - name: javelin2 pass: gungnir2 tenant: discuss secgroups: - name: secgroup1 owner: javelin description: SecurityGroup1 rules: - 'icmp -1 -1 0.0.0.0/0' - 'tcp 22 22 0.0.0.0/0' - name: secgroup2 owner: javelin2 description: SecurityGroup2 rules: - 'tcp 80 80 0.0.0.0/0' images: - name: cirros1 owner: javelin imgdir: images file: cirros.img container_format: bare disk_format: qcow2 - name: cirros2 owner: javelin2 imgdir: files/images/cirros-0.3.2-x86_64-uec file: cirros-0.3.2-x86_64-blank.img container_format: ami disk_format: ami aki: cirros-0.3.2-x86_64-vmlinuz ari: cirros-0.3.2-x86_64-initrd networks: - name: network1 owner: javelin - name: network2 owner: javelin2 subnets: - name: net1-subnet1 range: 10.1.0.0/24 network: network1 owner: javelin - name: net2-subnet2 range: 192.168.1.0/24 network: network2 owner: javelin2 objects: - container: container1 name: object1 owner: javelin file: /etc/hosts swift_role: Member telemetry: true,,65,0
openstack%2Ftempest~master~I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4,openstack/tempest,master,I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4,Add keystone v2.0 and v3 api discovery checks,MERGED,2015-03-09 18:27:11.000000000,2015-06-11 11:23:55.000000000,2015-06-11 11:23:53.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6578}, {'_account_id': 6683}, {'_account_id': 6890}, {'_account_id': 7020}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 8367}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 14345}, {'_account_id': 14687}]","[{'number': 1, 'created': '2015-03-09 18:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/344381aa424ad3d5465d808778ad31c5ab7bd076', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 2, 'created': '2015-03-09 20:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/48fe798b71f6c76d74c1af46e9eac443ac06d922', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 3, 'created': '2015-03-13 12:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b3a77af93a6a95dfb308feb0d7f1d12a3648c75b', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 4, 'created': '2015-03-13 16:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8808f841fe463a942c908f8c2a76c7b7ce5bd2c9', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 5, 'created': '2015-03-13 16:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/53872973b123cfa0289c4cdb7f074c660f8429ff', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 6, 'created': '2015-03-23 13:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4ac1430ab0fbcf5c46c7aefd443789e909e18cbf', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 7, 'created': '2015-04-20 12:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0b8981ffdc1005615a2c3fb931eceed99e3e8908', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}, {'number': 8, 'created': '2015-05-12 13:29:28.000000000', 'files': ['tempest/api/identity/v2/test_api_discovery.py', 'tempest/services/identity/v2/json/identity_client.py', 'tempest/api/identity/v3/test_api_discovery.py', 'tempest/services/identity/v3/json/identity_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8135405db9062871b6a6efaae54f027afcd4b192', 'message': 'Add keystone v2.0 and v3 api discovery checks\n\nKeystone documentation is quite strict about\nfield media-types and status, therefore they\nmust be validated. Remaining fields are\nchecked only for their presence in response.\n\nChange-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4\n'}]",2,162710,8135405db9062871b6a6efaae54f027afcd4b192,45,14,8,14345,,,0,"Add keystone v2.0 and v3 api discovery checks

Keystone documentation is quite strict about
field media-types and status, therefore they
must be validated. Remaining fields are
checked only for their presence in response.

Change-Id: I76f50bc1cf5581b35adca410bb7f5d4ec9aecbf4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/10/162710/8 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/v2/json/identity_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/api/identity/admin/v3/test_api_discovery.py', 'tempest/api/identity/admin/v2/test_api_discovery.py']",4,344381aa424ad3d5465d808778ad31c5ab7bd076,keystone_api_checks,"# Copyright 2011 OpenStack Foundation. # Copyright 2012, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.api.identity import base from tempest import test class TestApiDiscovery(base.BaseIdentityV2AdminTest): """"""Tests for API discovery features."""""" @test.attr(type='smoke') def test_api_version_resources(self): descr = self.client.get_api_details() expected_resources = ('id', 'links', 'media-types', 'status', 'updated') for res in expected_resources: self.assertIn(res, descr) @test.attr(type='smoke') def test_api_media_types(self): descr = self.client.get_api_details() # Get MIME type bases and descriptions media_types = [(media_type['base'], media_type['type']) for media_type in descr['media-types']] # These are supported for API version 2 supported_types = [('application/json', 'application/vnd.openstack.identity-v2.0+json'), ('application/xml', 'application/vnd.openstack.identity-v2.0+xml')] # Check if supported types exists in response body for s_type in supported_types: self.assertIn(s_type, media_types) def test_api_version_statuses(self): descr = self.client.get_api_details() status = descr['status'].lower() supported_statuses = ['current', 'stable', 'experimental', 'supported', 'deprecated'] self.assertIn(status, supported_statuses) ",,136,0
openstack%2Frally~master~I95d5a00c9e423ff38bcf3ed0497d9a2bdbfc22b0,openstack/rally,master,I95d5a00c9e423ff38bcf3ed0497d9a2bdbfc22b0,Add base benchmark for Manila list shares operation,ABANDONED,2015-06-11 10:59:21.000000000,2015-06-11 11:21:03.000000000,,[{'_account_id': 14817}],"[{'number': 1, 'created': '2015-06-11 10:59:21.000000000', 'files': ['rally-jobs/rally-manila.yaml', 'samples/tasks/scenarios/manila/list-shares.yaml', 'rally/consts.py', 'rally/plugins/openstack/scenarios/manila/shares.py', 'tests/unit/plugins/openstack/scenarios/manila/test_shares.py', 'rally-jobs/rally-manila-no-ss.yaml', 'samples/tasks/scenarios/manila/list-shares.json', 'rally/osclients.py', 'rally/plugins/openstack/scenarios/manila/utils.py', 'requirements.txt', 'tests/unit/test_osclients.py', 'tests/unit/plugins/openstack/scenarios/manila/test_utils.py', 'rally/plugins/openstack/scenarios/manila/__init__.py', 'tests/unit/plugins/openstack/scenarios/manila/__init__.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/d23377f8a3db0f01387dc41e8e879046b7f7b465', 'message': ""Add base benchmark for Manila list shares operation\n\nList of changes:\n- Added general support of Manila project.\n- Added support of 'list' operation for shares.\n- Added benchmark for listing of shares.\n- Added two different manila jobs scripts that will be used for two\ndifferent Manila installtions. Current benchmark is used without changes in\nboth installations.\n\nChange-Id: I95d5a00c9e423ff38bcf3ed0497d9a2bdbfc22b0\n""}]",0,190580,d23377f8a3db0f01387dc41e8e879046b7f7b465,3,1,1,8851,,,0,"Add base benchmark for Manila list shares operation

List of changes:
- Added general support of Manila project.
- Added support of 'list' operation for shares.
- Added benchmark for listing of shares.
- Added two different manila jobs scripts that will be used for two
different Manila installtions. Current benchmark is used without changes in
both installations.

Change-Id: I95d5a00c9e423ff38bcf3ed0497d9a2bdbfc22b0
",git fetch https://review.opendev.org/openstack/rally refs/changes/80/190580/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/rally-manila.yaml', 'samples/tasks/scenarios/manila/list-shares.yaml', 'rally/consts.py', 'rally/plugins/openstack/scenarios/manila/shares.py', 'tests/unit/plugins/openstack/scenarios/manila/test_shares.py', 'rally-jobs/rally-manila-no-ss.yaml', 'samples/tasks/scenarios/manila/list-shares.json', 'rally/osclients.py', 'rally/plugins/openstack/scenarios/manila/utils.py', 'requirements.txt', 'tests/unit/test_osclients.py', 'tests/unit/plugins/openstack/scenarios/manila/test_utils.py', 'rally/plugins/openstack/scenarios/manila/__init__.py', 'tests/unit/plugins/openstack/scenarios/manila/__init__.py']",14,d23377f8a3db0f01387dc41e8e879046b7f7b465,,,,276,0
openstack%2Fkeystone~master~Iebdfe86721204a550a74a00c46d661d903a4a141,openstack/keystone,master,Iebdfe86721204a550a74a00c46d661d903a4a141,Add validity check of 'expires_at' in trust creation,MERGED,2015-06-04 09:15:58.000000000,2015-06-11 11:20:27.000000000,2015-06-11 11:20:24.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8290}]","[{'number': 1, 'created': '2015-06-04 09:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3dd9afde935cec892efb9edb8a06a61277e0053', 'message': 'Add Validity check of \'expires_at\' in trust creation\n\nIt is meaningless that creating a trust with expiration older than now.\nThis change add the validity check of ""expires_at"" when creating a trust.\n\nChange-Id: Iebdfe86721204a550a74a00c46d661d903a4a141\nCloses-Bug: 1456069\n'}, {'number': 2, 'created': '2015-06-04 09:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/56f3ba175f355baba714f1b822be4432f782266c', 'message': 'Add validity check of \'expires_at\' in trust creation\n\nIt is meaningless that creating a trust with expiration older than now.\nThis change add the validity check of ""expires_at"" when creating a trust.\n\nChange-Id: Iebdfe86721204a550a74a00c46d661d903a4a141\nCloses-Bug: 1456069\n'}, {'number': 3, 'created': '2015-06-04 11:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/808abb9d5765cb262c0175a334ef43b68e578a62', 'message': 'Add validity check of \'expires_at\' in trust creation\n\nIt is meaningless that creating a trust with expiration older than now.\nThis change add the validity check of ""expires_at"" when creating a trust.\n\nChange-Id: Iebdfe86721204a550a74a00c46d661d903a4a141\nCloses-Bug: 1456069\n'}, {'number': 4, 'created': '2015-06-05 02:47:25.000000000', 'files': ['keystone/tests/unit/test_v3_auth.py', 'keystone/trust/controllers.py', 'keystone/exception.py', 'keystone/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/345d5a9f1914308ff894180dbc3b732f3860bf2b', 'message': 'Add validity check of \'expires_at\' in trust creation\n\nIt is meaningless that creating a trust with expiration older than now.\nThis change add the validity check of ""expires_at"" when creating a trust.\n\nChange-Id: Iebdfe86721204a550a74a00c46d661d903a4a141\nCloses-Bug: 1456069\n'}]",2,188315,345d5a9f1914308ff894180dbc3b732f3860bf2b,15,5,4,8290,,,0,"Add validity check of 'expires_at' in trust creation

It is meaningless that creating a trust with expiration older than now.
This change add the validity check of ""expires_at"" when creating a trust.

Change-Id: Iebdfe86721204a550a74a00c46d661d903a4a141
Closes-Bug: 1456069
",git fetch https://review.opendev.org/openstack/keystone refs/changes/15/188315/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/trust/controllers.py', 'keystone/exception.py', 'keystone/tests/unit/test_auth.py']",3,c3dd9afde935cec892efb9edb8a06a61277e0053,bug/1456069," def test_create_trust_expires_older_than_now(self): self.assertRaises(exception.ValidationExpirationError, self.create_trust, self.sample_data, self.trustor['name'], expires_at=""2010-06-04T08:44:31.999999Z"") ",,19,1
openstack%2Fsecurity-doc~master~I7857c978781010e429f4e6ee00e9558411e243d6,openstack/security-doc,master,I7857c978781010e429f4e6ee00e9558411e243d6,Updated from openstack-manuals,MERGED,2015-06-11 02:11:21.000000000,2015-06-11 11:07:48.000000000,2015-06-11 11:07:47.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-11 02:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/d5a21af243085e1a4b54daf8f06cce1b1526726e', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7857c978781010e429f4e6ee00e9558411e243d6\n'}, {'number': 2, 'created': '2015-06-11 08:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/d8a56befc15af79d8ac04a389d2dc2a7691de663', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7857c978781010e429f4e6ee00e9558411e243d6\n'}, {'number': 3, 'created': '2015-06-11 10:43:16.000000000', 'files': ['glossary/glossary-terms.xml', 'glossary/locale/ja.po', 'glossary/locale/zh_CN.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/ab268942da979e8e17965ef3708757f60172f010', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7857c978781010e429f4e6ee00e9558411e243d6\n'}]",0,190461,ab268942da979e8e17965ef3708757f60172f010,10,2,3,11131,,,0,"Updated from openstack-manuals

Change-Id: I7857c978781010e429f4e6ee00e9558411e243d6
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/61/190461/3 && git format-patch -1 --stdout FETCH_HEAD,['glossary/glossary-terms.xml'],1,d5a21af243085e1a4b54daf8f06cce1b1526726e,openstack/openstack-manuals," /etc/passwd, OpenLDAP, OpenStack Identity, and so on.</para> Identity service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity service, the worker process that service.</para> service.</para> service.</para> <para>The Identity service component that provides authentication <para>The Identity component that provides high-level <para>The storage method used by the Identity service catalog service authentication with the Identity service.</para> <para>An Identity service that lists API endpoints that are available to a user after authentication with the Identity service.</para> of the cloud; talks to services, such as Identity authentication, Object Storage, and node/storage workers through a <para>An Identity service token that is not associated with a specific opposed to using the Identity service.</para> service (glance).</para> <para>Alternative term for an Identity service catalog.</para> of Identity service, this is a call that is specific to the Identity and Compute. Requires Redis.</para> <para>The Identity service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity, <para>Alternative term for the Identity service API.</para> <primary>Identity</primary> <para>The source used by Identity service to retrieve user <glossterm>Identity</glossterm> <primary>Identity</primary> authentication system. The project name of Identity is <glossterm>Identity service API</glossterm> <primary>Identity service</primary> <secondary>Identity service API</secondary> <para>The API used to access the OpenStack Identity service provided <primary>Identity</primary> service.</para> service.</para> service.</para> service.</para> a password and a private key. Currently not supported in Identity.</para> Identity.</para> <para>Component of Identity that provides a rule-management service.</para> that typically shares only the Identity (keystone) with other both Identity and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity service role.</para> <para>An Identity service API access token that is associated with a service that implements delayed delete.</para> service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity service catalog.</para> Identity service catalog.</para> <para>An Identity service feature that enables services, such as securely with the Identity service.</para> Identity.</para> <para>An Identity service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity service. <para>An Identity service component that manages and validates tokens <para>Alternative term for an Identity service default token.</para> <para>In Identity, each user is associated with one or more service.</para> service.</para> service.</para>"," /etc/passwd, OpenLDAP, OpenStack Identity Service, and so on.</para> Identity Service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity Service, the worker process that Service.</para> Service.</para> Service.</para> <para>The Identity Service component that provides authentication <para>The Identity Service component that provides high-level <para>The storage method used by the Identity Service catalog service authentication with the Identity Service.</para> <para>An Identity Service that lists API endpoints that are available to a user after authentication with the Identity Service.</para> of the cloud; talks to services, such as Identity Service authentication, Object Storage, and node/storage workers through a <para>An Identity Service token that is not associated with a specific opposed to using the Identity Service.</para> Service (glance).</para> <para>Alternative term for an Identity Service catalog.</para> of Identity Service, this is a call that is specific to the Identity Service and Compute. Requires Redis.</para> <para>The Identity Service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity Service, <para>Alternative term for the Identity Service API.</para> <primary>Identity Service</primary> <para>The source used by Identity Service to retrieve user <glossterm>Identity Service</glossterm> <primary>Identity Service</primary> authentication system. The project name of the Identity Service is <glossterm>Identity Service API</glossterm> <primary>Identity Service</primary> <secondary>Identity Service API</secondary> <para>The API used to access the OpenStack Identity Service provided <primary>Identity Service</primary> Service.</para> Service.</para> Service.</para> Service.</para> a password and a private key. Currently not supported in Identity Service.</para> Identity Service.</para> <para>Component of Identity Service that provides a rule-management Service.</para> that typically shares only the Identity Service (keystone) with other both Identity Service and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity Service role.</para> <para>An Identity Service API access token that is associated with a Service that implements delayed delete.</para> Service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity Service catalog.</para> Identity Service catalog.</para> <para>An Identity Service feature that enables services, such as securely with the Identity Service.</para> Identity Service.</para> <para>An Identity Service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity Service. <para>An Identity Service component that manages and validates tokens <para>Alternative term for an Identity Service default token.</para> <para>In Identity Service, each user is associated with one or more Service.</para> Service.</para> Service.</para>",61,61
openstack%2Fha-guide~master~I506134d9bd9afea249db4664db9f8e1c90b8fa16,openstack/ha-guide,master,I506134d9bd9afea249db4664db9f8e1c90b8fa16,Updated from openstack-manuals,MERGED,2015-06-11 02:11:12.000000000,2015-06-11 11:01:07.000000000,2015-06-11 11:01:06.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-11 02:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/6dfe43b5c0e7ddd73d3873215205b0327cb3b73f', 'message': 'Updated from openstack-manuals\n\nChange-Id: I506134d9bd9afea249db4664db9f8e1c90b8fa16\n'}, {'number': 2, 'created': '2015-06-11 08:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/07359ef66e0d4c6fafb6ca429bb2a3397cc3ecfd', 'message': 'Updated from openstack-manuals\n\nChange-Id: I506134d9bd9afea249db4664db9f8e1c90b8fa16\n'}, {'number': 3, 'created': '2015-06-11 10:43:06.000000000', 'files': ['doc/ha-guide/source/imported/glossary.rst', 'doc/glossary/locale/zh_CN.po', 'doc/glossary/locale/ja.po', 'doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/95e70e77e20858b7d272bfdbdd2dd5b273ca44f6', 'message': 'Updated from openstack-manuals\n\nChange-Id: I506134d9bd9afea249db4664db9f8e1c90b8fa16\n'}]",0,190459,95e70e77e20858b7d272bfdbdd2dd5b273ca44f6,10,2,3,11131,,,0,"Updated from openstack-manuals

Change-Id: I506134d9bd9afea249db4664db9f8e1c90b8fa16
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/59/190459/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/imported/glossary.rst', 'doc/glossary/glossary-terms.xml']",2,6dfe43b5c0e7ddd73d3873215205b0327cb3b73f,openstack/openstack-manuals," /etc/passwd, OpenLDAP, OpenStack Identity, and so on.</para> Identity service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity service, the worker process that service.</para> service.</para> service.</para> <para>The Identity service component that provides authentication <para>The Identity component that provides high-level <para>The storage method used by the Identity service catalog service authentication with the Identity service.</para> <para>An Identity service that lists API endpoints that are available to a user after authentication with the Identity service.</para> of the cloud; talks to services, such as Identity authentication, Object Storage, and node/storage workers through a <para>An Identity service token that is not associated with a specific opposed to using the Identity service.</para> service (glance).</para> <para>Alternative term for an Identity service catalog.</para> of Identity service, this is a call that is specific to the Identity and Compute. Requires Redis.</para> <para>The Identity service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity, <para>Alternative term for the Identity service API.</para> <primary>Identity</primary> <para>The source used by Identity service to retrieve user <glossterm>Identity</glossterm> <primary>Identity</primary> authentication system. The project name of Identity is <glossterm>Identity service API</glossterm> <primary>Identity service</primary> <secondary>Identity service API</secondary> <para>The API used to access the OpenStack Identity service provided <primary>Identity</primary> service.</para> service.</para> service.</para> service.</para> a password and a private key. Currently not supported in Identity.</para> Identity.</para> <para>Component of Identity that provides a rule-management service.</para> that typically shares only the Identity (keystone) with other both Identity and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity service role.</para> <para>An Identity service API access token that is associated with a service that implements delayed delete.</para> service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity service catalog.</para> Identity service catalog.</para> <para>An Identity service feature that enables services, such as securely with the Identity service.</para> Identity.</para> <para>An Identity service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity service. <para>An Identity service component that manages and validates tokens <para>Alternative term for an Identity service default token.</para> <para>In Identity, each user is associated with one or more service.</para> service.</para> service.</para>"," /etc/passwd, OpenLDAP, OpenStack Identity Service, and so on.</para> Identity Service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity Service, the worker process that Service.</para> Service.</para> Service.</para> <para>The Identity Service component that provides authentication <para>The Identity Service component that provides high-level <para>The storage method used by the Identity Service catalog service authentication with the Identity Service.</para> <para>An Identity Service that lists API endpoints that are available to a user after authentication with the Identity Service.</para> of the cloud; talks to services, such as Identity Service authentication, Object Storage, and node/storage workers through a <para>An Identity Service token that is not associated with a specific opposed to using the Identity Service.</para> Service (glance).</para> <para>Alternative term for an Identity Service catalog.</para> of Identity Service, this is a call that is specific to the Identity Service and Compute. Requires Redis.</para> <para>The Identity Service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity Service, <para>Alternative term for the Identity Service API.</para> <primary>Identity Service</primary> <para>The source used by Identity Service to retrieve user <glossterm>Identity Service</glossterm> <primary>Identity Service</primary> authentication system. The project name of the Identity Service is <glossterm>Identity Service API</glossterm> <primary>Identity Service</primary> <secondary>Identity Service API</secondary> <para>The API used to access the OpenStack Identity Service provided <primary>Identity Service</primary> Service.</para> Service.</para> Service.</para> Service.</para> a password and a private key. Currently not supported in Identity Service.</para> Identity Service.</para> <para>Component of Identity Service that provides a rule-management Service.</para> that typically shares only the Identity Service (keystone) with other both Identity Service and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity Service role.</para> <para>An Identity Service API access token that is associated with a Service that implements delayed delete.</para> Service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity Service catalog.</para> Identity Service catalog.</para> <para>An Identity Service feature that enables services, such as securely with the Identity Service.</para> Identity Service.</para> <para>An Identity Service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity Service. <para>An Identity Service component that manages and validates tokens <para>Alternative term for an Identity Service default token.</para> <para>In Identity Service, each user is associated with one or more Service.</para> Service.</para> Service.</para>",117,117
openstack%2Fproject-config~master~I6c7e053fd03825a6da27919229a517aac6d80e8b,openstack/project-config,master,I6c7e053fd03825a6da27919229a517aac6d80e8b,Import mox3 library,MERGED,2015-06-10 20:09:30.000000000,2015-06-11 10:59:32.000000000,2015-06-11 10:59:31.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 2813}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6316}, {'_account_id': 6601}, {'_account_id': 6928}, {'_account_id': 7491}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-10 20:09:30.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/acls/openstack/mox3.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4280312a8cd316605a0253f82afbedffb6a04727', 'message': 'Import mox3 library\n\nThe mox3 library was a fork of mox created by the community, and left a\nbit stagnant. It is now causing some issues with dependencies, and so we\nwould like to bring it into the Oslo program to clean it up and create\nanother release.\n\nChange-Id: I6c7e053fd03825a6da27919229a517aac6d80e8b\n'}]",0,190330,4280312a8cd316605a0253f82afbedffb6a04727,17,13,1,2472,,,0,"Import mox3 library

The mox3 library was a fork of mox created by the community, and left a
bit stagnant. It is now causing some issues with dependencies, and so we
would like to bring it into the Oslo program to clean it up and create
another release.

Change-Id: I6c7e053fd03825a6da27919229a517aac6d80e8b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/30/190330/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/acls/openstack/mox3.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,4280312a8cd316605a0253f82afbedffb6a04727,import-mox3, - name: openstack/mox3 template: - name: merge-check - name: python-jobs - name: python26-jobs - name: python3-jobs - name: openstack-server-publish-jobs - name: check-requirements - name: publish-to-pypi - name: lib-forward-testing ,,48,0
openstack%2Fmurano~master~I4382215df1bcf81aea60e29039de548bcfe5a356,openstack/murano,master,I4382215df1bcf81aea60e29039de548bcfe5a356,Clean-up openstack.common,MERGED,2015-06-05 16:43:38.000000000,2015-06-11 10:52:54.000000000,2015-06-11 10:52:53.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-05 16:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/837075cda8a148061939dc4d091835c350763b41', 'message': 'Clean-up openstack.common\n\n* Unused module was removed\n* Existing modules were updated\n\nNext patch will remove all locations of openstack.common.log usage\n\nChange-Id: I4382215df1bcf81aea60e29039de548bcfe5a356\n'}, {'number': 2, 'created': '2015-06-05 16:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/3477660cead920c925d1a779bc6aea37c8f29cb2', 'message': 'Clean-up openstack.common\n\n* Unused module was removed\n* Existing modules were updated\n* Readme file was added\n\nNext patch will remove all locations of openstack.common.log usage\n\nChange-Id: I4382215df1bcf81aea60e29039de548bcfe5a356\n'}, {'number': 3, 'created': '2015-06-08 12:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/03576fbd0ab8e57da3add92d82f77aa5cd7cdb44', 'message': 'Clean-up openstack.common\n\n* Unused module was removed\n* Existing modules were updated\n* Readme file was added\n* Exceptions classes, used from unsupported exceptions from\n  oslo-incubator are moved to murano.common\n* Orginize imports to the correct order in files, where the order were modified\n\nNext patch will remove all locations of openstack.common.log usage\n\nChange-Id: I4382215df1bcf81aea60e29039de548bcfe5a356\n'}, {'number': 4, 'created': '2015-06-08 13:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/06c9a64f683ab8fab99e67f100a730ec2c674a84', 'message': 'Clean-up openstack.common\n\n* Unused module was removed\n* Existing modules were updated\n* Readme file was added\n* Exceptions classes, used from unsupported exceptions from\n  oslo-incubator are moved to murano.common\n* Orginize imports to the correct order in files, where the order were modified\n\nNext patch will remove all locations of openstack.common.log usage\n\nChange-Id: I4382215df1bcf81aea60e29039de548bcfe5a356\n'}, {'number': 5, 'created': '2015-06-10 12:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/d41598570a9b41d03613564efaf1d28da0541b12', 'message': 'Clean-up openstack.common\n\n* Unused module was removed\n* Existing modules were updated\n* Readme file was added\n* Exceptions classes, used from unsupported exceptions from\n  oslo-incubator are moved to murano.common\n* Orginize imports to the correct order in files, where the order were modified\n\nNext patch will remove all locations of openstack.common.log usage\n\nChange-Id: I4382215df1bcf81aea60e29039de548bcfe5a356\n'}, {'number': 6, 'created': '2015-06-10 14:28:57.000000000', 'files': ['murano/openstack/common/eventlet_backdoor.py', 'murano/openstack/common/threadgroup.py', 'murano/openstack/common/sslutils.py', 'murano/api/v1/catalog.py', 'murano/openstack/common/README.rst', 'murano/common/exceptions.py', 'murano/openstack/common/loopingcall.py', 'murano/openstack/common/fileutils.py', 'murano/openstack/common/lockutils.py', 'murano/openstack/common/processutils.py', 'murano/openstack/common/exception.py', 'murano/openstack/common/systemd.py', 'openstack-common.conf', 'murano/common/wsgi.py', 'murano/openstack/common/service.py', 'murano/packages/exceptions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/cb2d5d0caaea86332b3604768541e7c59be7efa1', 'message': 'Clean-up openstack.common\n\n* Unused module was removed\n* Existing modules were updated\n* Readme file was added\n* Exceptions classes, used from unsupported exceptions from\n  oslo-incubator are moved to murano.common\n* Orginize imports to the correct order in files, where the order were modified\n\nNext patch will remove all locations of openstack.common.log usage\n\nChange-Id: I4382215df1bcf81aea60e29039de548bcfe5a356\n'}]",16,188848,cb2d5d0caaea86332b3604768541e7c59be7efa1,48,9,6,7549,,,0,"Clean-up openstack.common

* Unused module was removed
* Existing modules were updated
* Readme file was added
* Exceptions classes, used from unsupported exceptions from
  oslo-incubator are moved to murano.common
* Orginize imports to the correct order in files, where the order were modified

Next patch will remove all locations of openstack.common.log usage

Change-Id: I4382215df1bcf81aea60e29039de548bcfe5a356
",git fetch https://review.opendev.org/openstack/murano refs/changes/48/188848/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/openstack/common/eventlet_backdoor.py', 'murano/openstack/common/lockutils.py', 'murano/openstack/common/threadgroup.py', 'murano/openstack/common/sslutils.py', 'murano/openstack/common/processutils.py', 'murano/openstack/common/systemd.py', 'openstack-common.conf', 'murano/openstack/common/loopingcall.py', 'murano/openstack/common/service.py', 'murano/openstack/common/fileutils.py']",10,837075cda8a148061939dc4d091835c350763b41,update-openstack-common,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import logging import os import tempfile from oslo_utils import excutils LOG = logging.getLogger(__name__) _FILE_CACHE = {} def ensure_tree(path): """"""Create a directory (and any ancestor directories required) :param path: Directory to create """""" try: os.makedirs(path) except OSError as exc: if exc.errno == errno.EEXIST: if not os.path.isdir(path): raise else: raise def read_cached_file(filename, force_reload=False): """"""Read from a file if it has been modified. :param force_reload: Whether to reload the file. :returns: A tuple with a boolean specifying if the data is fresh or not. """""" global _FILE_CACHE if force_reload: delete_cached_file(filename) reloaded = False mtime = os.path.getmtime(filename) cache_info = _FILE_CACHE.setdefault(filename, {}) if not cache_info or mtime > cache_info.get('mtime', 0): LOG.debug(""Reloading cached file %s"" % filename) with open(filename) as fap: cache_info['data'] = fap.read() cache_info['mtime'] = mtime reloaded = True return (reloaded, cache_info['data']) def delete_cached_file(filename): """"""Delete cached file if present. :param filename: filename to delete """""" global _FILE_CACHE if filename in _FILE_CACHE: del _FILE_CACHE[filename] def delete_if_exists(path, remove=os.unlink): """"""Delete a file, but ignore file not found error. :param path: File to delete :param remove: Optional function to remove passed path """""" try: remove(path) except OSError as e: if e.errno != errno.ENOENT: raise @contextlib.contextmanager def remove_path_on_error(path, remove=delete_if_exists): """"""Protect code that wants to operate on PATH atomically. Any exception will cause PATH to be removed. :param path: File to work with :param remove: Optional function to remove passed path """""" try: yield except Exception: with excutils.save_and_reraise_exception(): remove(path) def file_open(*args, **kwargs): """"""Open file see built-in open() documentation for more details Note: The reason this is kept in a separate module is to easily be able to provide a stub module that doesn't alter system state at all (for unit tests) """""" return open(*args, **kwargs) def write_to_tempfile(content, path=None, suffix='', prefix='tmp'): """"""Create temporary file or use existing file. This util is needed for creating temporary file with specified content, suffix and prefix. If path is not None, it will be used for writing content. If the path doesn't exist it'll be created. :param content: content for temporary file. :param path: same as parameter 'dir' for mkstemp :param suffix: same as parameter 'suffix' for mkstemp :param prefix: same as parameter 'prefix' for mkstemp For example: it can be used in database tests for creating configuration files. """""" if path: ensure_tree(path) (fd, path) = tempfile.mkstemp(suffix=suffix, dir=path, prefix=prefix) try: os.write(fd, content) finally: os.close(fd) return path ",47,827
openstack%2Fdevstack-gate~master~I670d8be337eb7326828aa142765c14600e5024cc,openstack/devstack-gate,master,I670d8be337eb7326828aa142765c14600e5024cc,"Revert ""only force off KEYSTONE_USE_WSGI up until kilo""",MERGED,2015-05-22 17:04:34.000000000,2015-06-11 10:49:25.000000000,2015-05-26 15:56:25.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6873}, {'_account_id': 6876}, {'_account_id': 7198}, {'_account_id': 9003}]","[{'number': 1, 'created': '2015-05-22 17:04:34.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda', 'message': 'Revert ""only force off KEYSTONE_USE_WSGI up until kilo""\n\nThis reverts commit 0911c9f3de347b6cb70e15bb2d6f0b969374f906\n\nThis is breaking grenade jobs on stable/kilo changes.\n\nChange-Id: I670d8be337eb7326828aa142765c14600e5024cc\nCloses-Bug: #1456835\n'}]",1,185073,ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda,12,8,1,6873,,,0,"Revert ""only force off KEYSTONE_USE_WSGI up until kilo""

This reverts commit 0911c9f3de347b6cb70e15bb2d6f0b969374f906

This is breaking grenade jobs on stable/kilo changes.

Change-Id: I670d8be337eb7326828aa142765c14600e5024cc
Closes-Bug: #1456835
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/73/185073/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,ccbfaa83ac82f14a9d7d9cc658d2899d41fc9dda,stable_kilo," echo ""KEYSTONE_USE_MOD_WSGI=False"" >> ""$localrc_file"""," case $GRENADE_BASE_BRANCH in ""stable/icehouse"") ;& ""stable/juno"") echo ""KEYSTONE_USE_MOD_WSGI=False"" >> ""$localrc_file"" ;; esac",1,7
openstack%2Fopenstack-manuals~master~I4006f966a652ee8134b2959dff7deef4586034fe,openstack/openstack-manuals,master,I4006f966a652ee8134b2959dff7deef4586034fe,[glossary] Add a missing dot character,MERGED,2015-06-11 10:18:53.000000000,2015-06-11 10:40:09.000000000,2015-06-11 10:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-11 10:18:53.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/30c53894c51349bca8a51c501c43210ee8d5f408', 'message': '[glossary] Add a missing dot character\n\nChange-Id: I4006f966a652ee8134b2959dff7deef4586034fe\nCloses-Bug: 1464202\n'}]",0,190568,30c53894c51349bca8a51c501c43210ee8d5f408,6,2,1,10497,,,0,"[glossary] Add a missing dot character

Change-Id: I4006f966a652ee8134b2959dff7deef4586034fe
Closes-Bug: 1464202
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/190568/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,30c53894c51349bca8a51c501c43210ee8d5f408,bug/1464202," into an address that is easier to remember. For example, translating"," into an address that is easier to remember For example, translating",1,1
openstack%2Fneutron~master~I38bac101106f890e198ba8ae22c324e26c288d77,openstack/neutron,master,I38bac101106f890e198ba8ae22c324e26c288d77,Moving out the cisco n1kv section to stackforge,ABANDONED,2015-06-10 18:04:35.000000000,2015-06-11 10:22:35.000000000,,"[{'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-06-10 18:04:35.000000000', 'files': ['etc/neutron/plugins/ml2/ml2_conf_cisco.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc9a828c1e35b6ace8a2a871bf78f0fca9381123', 'message': ""Moving out the cisco n1kv section to stackforge\n\nSince most of the n1kv plugin code resides in stackforge/networking-cisco\nrepo, it's best to move the n1kv section there\n\nChange-Id: I38bac101106f890e198ba8ae22c324e26c288d77\nCloses-Bug: #1441400\n""}]",0,190284,bc9a828c1e35b6ace8a2a871bf78f0fca9381123,10,8,1,12749,,,0,"Moving out the cisco n1kv section to stackforge

Since most of the n1kv plugin code resides in stackforge/networking-cisco
repo, it's best to move the n1kv section there

Change-Id: I38bac101106f890e198ba8ae22c324e26c288d77
Closes-Bug: #1441400
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/190284/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/plugins/ml2/ml2_conf_cisco.ini'],1,bc9a828c1e35b6ace8a2a871bf78f0fca9381123,bug/1441400,," [ml2_cisco_n1kv] # (StrOpt) Name of the policy profile to be associated with a port when no # policy profile is specified during port creates. # default_policy_profile = default-pp # (StrOpt) Name of the VLAN network profile to be associated with a network. # default_vlan_network_profile = default-vlan-np # (StrOpt) Name of the VXLAN network profile to be associated with a network. # default_vxlan_network_profile = default-vxlan-np # (IntOpt) Time in seconds for which the plugin polls the VSM for updates in # policy profiles. # poll_duration = 60 # (IntOpt) Timeout duration in seconds for the http request # http_timeout = 15 # (BoolOpt) Specify whether tenants are restricted from accessing all the # policy profiles. # Default value: False, indicating all tenants can access all policy profiles. # # restrict_policy_profiles = False # Describe Cisco N1KV VSM connectivity # In this section you can specify connectivity details in order for plugin # to connect to N1KV Virtual Supervisor Module (VSM). # # n1kv_vsm_ips =<vsm1_ip>,<vsm2_ip>,.... # username = <username> # password = <password> # # An example would be: # n1kv_vsm_ips = 1.1.1.1,1.1.1.2 # username = user # password = password ",0,39
openstack%2Fceilometer~master~Ic0ce45d957ed969f771469c4a4c4faf2f91406e8,openstack/ceilometer,master,Ic0ce45d957ed969f771469c4a4c4faf2f91406e8,API design for configuration via data store,ABANDONED,2015-02-12 15:13:22.000000000,2015-06-11 10:21:43.000000000,,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 7052}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-02-12 15:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f9e4f481fcac7c95d4392d5c8d741a13df149d11', 'message': '[WIP] API design for configuration via data store\n\nwork in progress\n\nChange-Id: Ic0ce45d957ed969f771469c4a4c4faf2f91406e8\nPartially-Implements: blueprint ceilometer-configuration-via-data-store\n'}, {'number': 2, 'created': '2015-02-16 15:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5b5d57bc823934fb3f37dafdd64f8a447580097f', 'message': 'API design for configuration via data store\n\nthis patch adds in API two  API requests:\n\nGET /v2/meta/pipelines\n    Return all pipeline configuration items\n    Parameters: q - Filter rules for items to be returned\n    Return type: list(configuration)\n\nPUT /v2/meta/pipelines\n    Create a new pipeline configuration item with a user-defined id\n    Parameters: data(configuration) - a configuration within the\n    request body\n\nChange-Id: Ic0ce45d957ed969f771469c4a4c4faf2f91406e8\nPartially-Implements: blueprint ceilometer-configuration-via-data-store\n'}, {'number': 3, 'created': '2015-02-20 12:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ba0f9a663d1be1e7ea1bbeac43542a0955393ffa', 'message': 'API design for configuration via data store\n\nthis patch adds in API two new requests:\n\nGET /v2/meta/pipelines\n    Return all pipeline configuration items\n    Parameters: q - Filter rules for items to be returned\n    Return type: configuration\n\nPUT /v2/meta/pipelines\n    Create a new pipeline configuration item with a user-defined id\n    Parameters: data(configuration) - a configuration within the\n    request body\n\nAPIImpact:\nDocImpact:\n\nChange-Id: Ic0ce45d957ed969f771469c4a4c4faf2f91406e8\nPartially-Implements: blueprint ceilometer-configuration-via-data-store\n'}, {'number': 4, 'created': '2015-03-06 15:27:05.000000000', 'files': ['ceilometer/api/controllers/v2/meta.py', 'ceilometer/tests/api/v2/test_configuration_scenarios.py', 'ceilometer/api/controllers/v2/root.py', 'ceilometer/api/app.py', 'ceilometer/api/hooks.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/68cf0e7accb6dbf0ce77992f1fbcbe5640244493', 'message': 'API design for configuration via data store\n\nthis patch adds in API two new requests:\n\nGET /v2/meta/pipelines\n    Return all pipeline configuration items\n    Parameters: q - Filter rules for items to be returned\n    Return type: configuration\n\nPUT /v2/meta/pipelines\n    Create a new pipeline configuration item with a user-defined id\n    Parameters: data(configuration) - a configuration within the\n    request body\n\nAPIImpact:\nDocImpact:\n\nChange-Id: Ic0ce45d957ed969f771469c4a4c4faf2f91406e8\nPartially-Implements: blueprint ceilometer-configuration-via-data-store\n'}]",15,155345,68cf0e7accb6dbf0ce77992f1fbcbe5640244493,20,5,4,10987,,,0,"API design for configuration via data store

this patch adds in API two new requests:

GET /v2/meta/pipelines
    Return all pipeline configuration items
    Parameters: q - Filter rules for items to be returned
    Return type: configuration

PUT /v2/meta/pipelines
    Create a new pipeline configuration item with a user-defined id
    Parameters: data(configuration) - a configuration within the
    request body

APIImpact:
DocImpact:

Change-Id: Ic0ce45d957ed969f771469c4a4c4faf2f91406e8
Partially-Implements: blueprint ceilometer-configuration-via-data-store
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/45/155345/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/api/v2/test_list_pipeline_scenarios.py', 'ceilometer/api/controllers/v2/meta.py', 'ceilometer/api/controllers/v2/root.py', 'ceilometer/api/app.py', 'ceilometer/api/hooks.py']",5,f9e4f481fcac7c95d4392d5c8d741a13df149d11,bp/ceilometer-configuration-via-data-store," def __init__(self, conn, event_conn, alarm_conn, pipeline_conn): self.pipeline_storage_connection = pipeline_conn state.request.pipeline_storage_conn = self.pipeline_storage_connection"," def __init__(self, conn, event_conn, alarm_conn):",285,2
openstack%2Fironic~master~Ia18335278da4c25240e537d53687658fe4fbaa6a,openstack/ironic,master,Ia18335278da4c25240e537d53687658fe4fbaa6a,Sync with latest oslo-incubator,MERGED,2015-06-07 14:07:40.000000000,2015-06-11 10:15:46.000000000,2015-06-11 10:15:44.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 13362}]","[{'number': 1, 'created': '2015-06-07 14:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cd961fd4c80e9d498d9bb99290bcd493a7407d17', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: Ia18335278da4c25240e537d53687658fe4fbaa6a\n'}, {'number': 2, 'created': '2015-06-10 11:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3dd9fdfa2eb3ee9bebcc5ac038e461204c2da5a2', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest oslo-incubator code\n\nChange-Id: Ia18335278da4c25240e537d53687658fe4fbaa6a'}, {'number': 3, 'created': '2015-06-10 11:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e99476c5b41a30ee683b6e512e3b15292e741ae0', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest oslo-incubator code\n\nChange-Id: Ia18335278da4c25240e537d53687658fe4fbaa6a'}, {'number': 4, 'created': '2015-06-10 15:31:33.000000000', 'files': ['ironic/openstack/common/loopingcall.py', 'ironic/openstack/common/periodic_task.py', 'ironic/openstack/common/eventlet_backdoor.py', 'ironic/openstack/common/service.py', 'openstack-common.conf', 'tools/install_venv_common.py', 'ironic/openstack/common/fileutils.py', 'ironic/openstack/common/threadgroup.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/133c83180de213a51836d7f03b9861e14b0a5507', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest oslo-incubator code\n\nChange-Id: Ia18335278da4c25240e537d53687658fe4fbaa6a\n'}]",3,189110,133c83180de213a51836d7f03b9861e14b0a5507,32,8,4,5638,,,0,"Sync with latest oslo-incubator

Periodic sync with latest oslo-incubator code

Change-Id: Ia18335278da4c25240e537d53687658fe4fbaa6a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/189110/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/openstack/common/loopingcall.py', 'ironic/openstack/common/periodic_task.py', 'ironic/openstack/common/eventlet_backdoor.py', 'ironic/openstack/common/service.py', 'openstack-common.conf', 'ironic/openstack/common/fileutils.py', 'ironic/openstack/common/threadgroup.py']",7,cd961fd4c80e9d498d9bb99290bcd493a7407d17,,from ironic.openstack.common._i18n import _LE except Exception: LOG.exception(_LE('Error stopping thread.')) except Exception: LOG.exception(_LE('Error stopping timer.')) except Exception: LOG.exception(_LE('Error waiting on ThreadGroup.')), except Exception as ex: LOG.exception(ex) except Exception as ex: LOG.exception(ex) except Exception as ex: LOG.exception(ex),22,37
openstack%2Fpython-cinderclient~master~I06ae26e7e6420847b4013e490479b4c5b8c343e7,openstack/python-cinderclient,master,I06ae26e7e6420847b4013e490479b4c5b8c343e7,Add test for cinder list-extension command output,ABANDONED,2015-06-08 13:49:18.000000000,2015-06-11 10:11:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 14305}]","[{'number': 1, 'created': '2015-06-08 13:49:18.000000000', 'files': ['cinderclient/tests/functional/test_readonly_cli.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/610209de78d33c6ddd781baa4c48f07fab423e8a', 'message': 'Add test for cinder list-extension command output\n\nChange-Id: I06ae26e7e6420847b4013e490479b4c5b8c343e7\n'}]",1,189300,610209de78d33c6ddd781baa4c48f07fab423e8a,7,3,1,14614,,,0,"Add test for cinder list-extension command output

Change-Id: I06ae26e7e6420847b4013e490479b4c5b8c343e7
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/00/189300/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/tests/functional/test_readonly_cli.py'],1,610209de78d33c6ddd781baa4c48f07fab423e8a,," def test_list_extensions(self): list_extensions = self.cinder('list-extensions') self.assertTableHeaders(list_extensions, ['Name', 'Summary', 'Alias', 'Updated'])",,4,0
openstack%2Fneutron~master~Id1275c51e9adb865a3da9f0db007f3092b55b140,openstack/neutron,master,Id1275c51e9adb865a3da9f0db007f3092b55b140,Remove useless pass from methods in type_tunnel.py,MERGED,2015-06-10 16:46:47.000000000,2015-06-11 10:01:56.000000000,2015-06-11 04:27:26.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-10 16:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/153acc425e480a9c402597e04921d9950afcd250', 'message': 'Remove useless pass from methods in type_tunnel.py\n\nThe pass is useless because there is a docstring in the methods.\nIn generally considered as uncovered by coverage tool.\n\nChange-Id: Id1275c51e9adb865a3da9f0db007f3092b55b140\n'}, {'number': 2, 'created': '2015-06-10 17:20:24.000000000', 'files': ['neutron/plugins/ml2/drivers/type_tunnel.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca63dfd0f39c7d691247c146b7529937c5804c9e', 'message': 'Remove useless pass from methods in type_tunnel.py\n\nThe pass is useless because there is a docstring in the methods.\nGenerally considered as uncovered by coverage tool.\n\nChange-Id: Id1275c51e9adb865a3da9f0db007f3092b55b140\n'}]",1,190256,ca63dfd0f39c7d691247c146b7529937c5804c9e,41,22,2,10370,,,0,"Remove useless pass from methods in type_tunnel.py

The pass is useless because there is a docstring in the methods.
Generally considered as uncovered by coverage tool.

Change-Id: Id1275c51e9adb865a3da9f0db007f3092b55b140
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/190256/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/type_tunnel.py'],1,153acc425e480a9c402597e04921d9950afcd250,remove_pass,, pass pass pass pass pass,0,5
openstack%2Fnova~master~I66206c62536eae9819754fc0ba7c9b7f3a8ed3c6,openstack/nova,master,I66206c62536eae9819754fc0ba7c9b7f3a8ed3c6,VMware: use vCenter instead of VC,MERGED,2015-06-09 08:34:37.000000000,2015-06-11 09:58:27.000000000,2015-06-11 09:58:24.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8119}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-09 08:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df23b8f541066c89370161b8ea539fa162252c3c', 'message': 'VMware: use vCenter instead of VC\n\nIn review https://review.openstack.org/#/c/183711/ it was\nsuggested to use vCenter instead of VC.\n\nTrivialFix\n\nChange-Id: I66206c62536eae9819754fc0ba7c9b7f3a8ed3c6\n'}, {'number': 2, 'created': '2015-06-10 19:26:37.000000000', 'files': ['nova/virt/vmwareapi/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5a058a125acfb065f06a2740a2aea44a901bc334', 'message': 'VMware: use vCenter instead of VC\n\nIn review https://review.openstack.org/#/c/183711/ it was\nsuggested to use vCenter instead of VC.\n\nTrivialFix\n\nChange-Id: I66206c62536eae9819754fc0ba7c9b7f3a8ed3c6\n'}]",2,189593,5a058a125acfb065f06a2740a2aea44a901bc334,23,12,2,1653,,,0,"VMware: use vCenter instead of VC

In review https://review.openstack.org/#/c/183711/ it was
suggested to use vCenter instead of VC.

TrivialFix

Change-Id: I66206c62536eae9819754fc0ba7c9b7f3a8ed3c6
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/189593/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/driver.py'],1,df23b8f541066c89370161b8ea539fa162252c3c,veesee," help='Hostname or IP address for connection to VMware ' 'vCenter host.'), help='Port for connection to VMware vCenter host.'), help='Username for connection to VMware vCenter host.'), help='Password for connection to VMware vCenter host.', LOG.warning(_LW('Running Nova with a VMware vCenter version less ' 'than %(version)s is deprecated. The required ' 'minimum version of vCenter will be raised to ' '%(version)s in the 2016.1 release.'),"," help='Hostname or IP address for connection to VMware VC ' 'host.'), help='Port for connection to VMware VC host.'), help='Username for connection to VMware VC host.'), help='Password for connection to VMware VC host.', LOG.warning(_LW('Running Nova with a VMware VC version less than ' '%(version)s is deprecated. The required minimum ' 'version of VC will be raised to %(version)s ' 'in the 2016.1 release.'),",9,9
openstack%2Fpython-keystoneclient~feature%2Fkeystoneauth_integration~Ib127ef5fc582f53df9a781aa260e3134848f724e,openstack/python-keystoneclient,feature/keystoneauth_integration,Ib127ef5fc582f53df9a781aa260e3134848f724e,Add dependency on keystoneauth,MERGED,2015-05-27 23:34:44.000000000,2015-06-11 09:54:18.000000000,2015-06-11 09:54:17.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 7191}, {'_account_id': 8978}]","[{'number': 1, 'created': '2015-05-27 23:34:44.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/c565dfc1bcdae30293f250b4394737ee21f2fe5b', 'message': 'Add dependency on keystoneauth\n\nDepend on the current master of keystoneauth so we can iterate changes\nquickly.\n\nChange-Id: Ib127ef5fc582f53df9a781aa260e3134848f724e\n'}]",0,186226,c565dfc1bcdae30293f250b4394737ee21f2fe5b,9,4,1,7191,,,0,"Add dependency on keystoneauth

Depend on the current master of keystoneauth so we can iterate changes
quickly.

Change-Id: Ib127ef5fc582f53df9a781aa260e3134848f724e
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/26/186226/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c565dfc1bcdae30293f250b4394737ee21f2fe5b,186220,-e git+https://git.openstack.org/openstack/keystoneauth#egg=keystoneauth,,1,0
openstack%2Fmurano~master~Ic6fb75a0610c23e8920e4c2aca54876bc2dec2e0,openstack/murano,master,Ic6fb75a0610c23e8920e4c2aca54876bc2dec2e0,[Murano Docs] Add importing an app package HowTo,MERGED,2015-06-10 14:18:55.000000000,2015-06-11 09:44:26.000000000,2015-06-11 09:44:25.000000000,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-10 14:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c11a91a7077e3a5aab11ef7014631d86b3ffe159', 'message': '[Murano Docs] Add importing an app package HowTo\n\nThis patch adds a HowTo instruction on importing an application package:\n- from a zip file\n- from murano applications repository\n- from bundles of applications\nAlso adds a ""figures"" folder with necessary for this HowTo screenshots inside.\n\nChange-Id: Ic6fb75a0610c23e8920e4c2aca54876bc2dec2e0\n'}, {'number': 2, 'created': '2015-06-10 14:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/57f7a3cc13034630803b7295558964b4900b5e7c', 'message': '[Murano Docs] Add importing an app package HowTo\n\nThis patch adds a HowTo instruction on importing an application package:\n- from a zip file\n- from murano applications repository\n- from bundles of applications\nAlso adds a ""figures"" folder with necessary for this HowTo screenshots\n inside.\nRemoves the ""From a local bundle of applications"" section as it refers\n to CLI.\nChange-Id: Ic6fb75a0610c23e8920e4c2aca54876bc2dec2e0\n'}, {'number': 3, 'created': '2015-06-10 16:11:46.000000000', 'files': ['doc/source/draft/enduser-guide/figures/repository.png', 'doc/source/draft/enduser-guide/manage_applications.rst', 'doc/source/draft/enduser-guide/figures/bundle_name.png', 'doc/source/draft/enduser-guide/figures/import_bundle.png', 'doc/source/draft/enduser-guide/figures/import_package.png', 'doc/source/draft/enduser-guide/figures/browse_zip_file.png'], 'web_link': 'https://opendev.org/openstack/murano/commit/2cb5c185ad11603f62541a93600c4c15d88b9dd0', 'message': '[Murano Docs] Add importing an app package HowTo\n\nThis patch adds a HowTo instruction on importing an application package:\n- from a zip file\n- from murano applications repository\n- from bundles of applications\nAlso adds a ""figures"" folder with necessary for this HowTo screenshots\n inside.\nRemoves the ""From a local bundle of applications"" section as it refers\n to CLI.\nChange-Id: Ic6fb75a0610c23e8920e4c2aca54876bc2dec2e0\n'}]",0,190202,2cb5c185ad11603f62541a93600c4c15d88b9dd0,18,6,3,14947,,,0,"[Murano Docs] Add importing an app package HowTo

This patch adds a HowTo instruction on importing an application package:
- from a zip file
- from murano applications repository
- from bundles of applications
Also adds a ""figures"" folder with necessary for this HowTo screenshots
 inside.
Removes the ""From a local bundle of applications"" section as it refers
 to CLI.
Change-Id: Ic6fb75a0610c23e8920e4c2aca54876bc2dec2e0
",git fetch https://review.opendev.org/openstack/murano refs/changes/02/190202/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/draft/enduser-guide/figures/repository.png', 'doc/source/draft/enduser-guide/manage_applications.rst', 'doc/source/draft/enduser-guide/figures/bundle_name.png', 'doc/source/draft/enduser-guide/figures/import_bundle.png', 'doc/source/draft/enduser-guide/figures/import_package.png', 'doc/source/draft/enduser-guide/figures/browse_zip_file.png']",6,c11a91a7077e3a5aab11ef7014631d86b3ffe159,app_package_import,,,79,2
openstack%2Fhorizon~master~Ifa53fde6e0c4119a092e657fc07627ffb68dd248,openstack/horizon,master,Ifa53fde6e0c4119a092e657fc07627ffb68dd248,JSCS cleanup - Angular framework widgets (partial2),MERGED,2015-06-02 20:28:48.000000000,2015-06-11 09:43:51.000000000,2015-06-11 09:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9622}, {'_account_id': 11881}, {'_account_id': 13785}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-06-02 20:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fee23b2e3ac11ac935305a370a95fe3cf00847d6', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 2, 'created': '2015-06-02 21:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/06a91ddc4ed45d961df7ec7c72a69dd084f72996', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 3, 'created': '2015-06-03 16:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b59d768c128343e2dc73af6890af8d90eda6fd97', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 4, 'created': '2015-06-03 16:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/80071727123599db1704df957f720585a4358a12', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 5, 'created': '2015-06-05 15:18:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9d46c02cbd1fbfa98fec9f80b8d5cdda682a9c22', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 6, 'created': '2015-06-06 01:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/18d6dc0015429e4df0f750d4a6afa228b9bccc24', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 7, 'created': '2015-06-08 15:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/452517d2a44de06a6781b70761bf4085ce72e161', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 8, 'created': '2015-06-09 01:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3c230cfd851f2a1eef215e882e26bf4537d0ba19', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 9, 'created': '2015-06-09 19:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2134f284f77ca2d64fdf150a2bc1a4490892b56a', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 10, 'created': '2015-06-10 01:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/409b330cf42dba808e250f6908916271a320fbe8', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 11, 'created': '2015-06-10 21:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c47d4a9993a356ae4a15c9c8fdf94fb7332e55b6', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}, {'number': 12, 'created': '2015-06-10 22:54:05.000000000', 'files': ['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/wizard/wizard.js', 'horizon/static/framework/widgets/wizard/wizard.spec.js', 'horizon/static/framework/widgets/table/basic-table.spec.js', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.js', 'horizon/static/framework/widgets/table/basic-table.js', 'horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/table/table.spec.js', 'horizon/static/framework/widgets/modal/modal.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.js', 'horizon/static/framework/widgets/table/table.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/985680d60dd4a203ebdcfeb9f8b798c72da21f2e', 'message': 'JSCS cleanup - Angular framework widgets (partial2)\n\nWe need to do cleanup before we can enable JSCS globally\n(https://review.openstack.org/#/c/185725/).\n\nWidgets included: modal, modal-wait-spinner, table, toast,\ntransfer-table, wizard\n\nChange-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248\nPartially-Implements: blueprint jscs-cleanup\n'}]",15,187758,985680d60dd4a203ebdcfeb9f8b798c72da21f2e,39,6,12,11881,,,0,"JSCS cleanup - Angular framework widgets (partial2)

We need to do cleanup before we can enable JSCS globally
(https://review.openstack.org/#/c/185725/).

Widgets included: modal, modal-wait-spinner, table, toast,
transfer-table, wizard

Change-Id: Ifa53fde6e0c4119a092e657fc07627ffb68dd248
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/187758/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/widgets/toast/toast.spec.js', 'horizon/static/framework/widgets/wizard/wizard.js', 'horizon/static/framework/widgets/wizard/wizard.spec.js', 'horizon/static/framework/widgets/table/basic-table.spec.js', 'horizon/static/framework/widgets/modal-wait-spinner/modal-wait-spinner.js', 'horizon/static/framework/widgets/table/basic-table.js', 'horizon/static/framework/widgets/toast/toast.js', 'horizon/static/framework/widgets/table/table.spec.js', 'horizon/static/framework/widgets/modal/modal.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.js', 'horizon/static/framework/widgets/table/table.js', 'horizon/static/framework/widgets/transfer-table/transfer-table.spec.js']",12,fee23b2e3ac11ac935305a370a95fe3cf00847d6,bp/jscs-cleanup," var items = [1, 2, 3]; // jscs:disable maximumLineLength // jscs:enable maximumLineLength // jscs:disable maximumLineLength // jscs:enable maximumLineLength"," var items = [1,2,3];",153,141
openstack%2Foslo.messaging~master~Ied61de2c5606ed8180b6d4c4bcfe2b7130eeb0e1,openstack/oslo.messaging,master,Ied61de2c5606ed8180b6d4c4bcfe2b7130eeb0e1,TEST,ABANDONED,2015-06-11 06:04:29.000000000,2015-06-11 09:43:21.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-11 06:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/0ec2d14f7deb5e95f160d12f1cdccd83a8710c81', 'message': 'TEST\n\nChange-Id: Ied61de2c5606ed8180b6d4c4bcfe2b7130eeb0e1\n'}, {'number': 2, 'created': '2015-06-11 06:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/543c858ead8423cc978f388832d176dd96953d44', 'message': 'TEST\n\nChange-Id: Ied61de2c5606ed8180b6d4c4bcfe2b7130eeb0e1\n'}, {'number': 3, 'created': '2015-06-11 07:07:08.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/048836097c0e22e3da84e9b2ea404b678d7f3c17', 'message': 'TEST\n\nChange-Id: Ied61de2c5606ed8180b6d4c4bcfe2b7130eeb0e1\n'}]",0,190495,048836097c0e22e3da84e9b2ea404b678d7f3c17,6,1,3,2813,,,0,"TEST

Change-Id: Ied61de2c5606ed8180b6d4c4bcfe2b7130eeb0e1
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/95/190495/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0ec2d14f7deb5e95f160d12f1cdccd83a8710c81,,commands = {toxinidir}/setup-test-env-rabbit.sh python setup.py test --coverage --coverage-package-name=oslo_messaging --testr-args='{posargs}',commands = python setup.py test --coverage --coverage-package-name=oslo_messaging --testr-args='{posargs}',1,2
openstack%2Ffuel-web~master~I1baa32c9a517bf58ab050232c36a61dd53132280,openstack/fuel-web,master,I1baa32c9a517bf58ab050232c36a61dd53132280,Fixes management panel for deploying environment,MERGED,2015-02-10 10:01:17.000000000,2015-06-11 09:38:29.000000000,2015-06-11 09:26:36.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-02-10 10:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2083e5e0666213267466ccc4890024654274f8dc', 'message': 'Fixes management panel for deploying environment\n\nCloses-Bug: #1420202\n\nChange-Id: I1baa32c9a517bf58ab050232c36a61dd53132280\n'}, {'number': 2, 'created': '2015-03-06 14:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c633341b48d5979798a0bc04c462b5df7db94ba7', 'message': 'Fixes management panel for deploying environment\n\nCloses-Bug: #1420202\n\nChange-Id: I1baa32c9a517bf58ab050232c36a61dd53132280\n'}, {'number': 3, 'created': '2015-06-04 12:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c1964e98df72eeee13c252c3c1e12f24acdb6055', 'message': 'Fixes management panel for deploying environment\n\nCloses-Bug: #1420202\n\nChange-Id: I1baa32c9a517bf58ab050232c36a61dd53132280\n'}, {'number': 4, 'created': '2015-06-10 07:43:22.000000000', 'files': ['nailgun/static/views/cluster_page_tabs/nodes_tab.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.jsx', 'nailgun/static/views/dialogs.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c2808a4da6f02012e3b655c1e7bbeb45d230e235', 'message': 'Fixes management panel for deploying environment\n\nCloses-Bug: #1420202\n\nChange-Id: I1baa32c9a517bf58ab050232c36a61dd53132280\n'}]",0,154396,c2808a4da6f02012e3b655c1e7bbeb45d230e235,37,7,4,8766,,,0,"Fixes management panel for deploying environment

Closes-Bug: #1420202

Change-Id: I1baa32c9a517bf58ab050232c36a61dd53132280
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/96/154396/3 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/node_list_screen.jsx'],1,2083e5e0666213267466ccc4890024654274f8dc,bug/1420202," disabled={!this.props.nodes.length} disabled={!this.props.nodes.length} disabled={this.props.locked} isNodeSelectable = node.isSelectable() && !this.state.actionInProgress, disabled = this.props.locked || !isNodeSelectable, disabled={!isNodeSelectable}"," disabled={this.props.locked || !this.props.nodes.length} disabled={this.props.locked || !this.props.nodes.length} disabled = this.props.locked || !node.isSelectable() || this.state.actionInProgress, disabled={disabled}",6,4
openstack%2Fnova~master~Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5,openstack/nova,master,Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5,Add config option to override url for versions,ABANDONED,2015-03-02 09:04:36.000000000,2015-06-11 09:23:51.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5638}, {'_account_id': 5754}, {'_account_id': 6732}, {'_account_id': 8119}, {'_account_id': 8290}, {'_account_id': 8976}, {'_account_id': 9008}, {'_account_id': 9459}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14619}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-02 09:04:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f24da3291e7b40a22fd65fcef10369eefc2d0118', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when cinder api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 2, 'created': '2015-03-03 01:27:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/117e9059d80a5756bf9307f41744547ecccde221', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when cinder api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 3, 'created': '2015-03-03 03:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e48757fbe8b568de443f26bfa4c1b6dbaeddfcd', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when cinder api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 4, 'created': '2015-04-13 05:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26752e34032d0c025c6b777edf01850d4b1bc617', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 5, 'created': '2015-04-14 02:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a8883dae07b5f360d4f462aee0bd3f4771a2f4c', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 6, 'created': '2015-04-14 05:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0792e7cfd402cba21b0674a85aeb07228e06ff61', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 7, 'created': '2015-04-21 02:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75e4ec3ffea118b9df8a3fe0666fdd251d1b5d14', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 8, 'created': '2015-04-21 06:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c9194eacef35b93fb6e3db4b18f7952cf01bb81', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 9, 'created': '2015-05-12 03:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfcca3dda8c271765495bbddf31261eb9a1245ab', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}, {'number': 10, 'created': '2015-05-29 04:03:27.000000000', 'files': ['nova/tests/unit/test_versions.py', 'nova/api/openstack/compute/views/versions.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6ceb2694c95204b386619a6b0d2cff6ec8179d87', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when nova api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5\nCloses-Bug: #1384379\n'}]",12,160266,6ceb2694c95204b386619a6b0d2cff6ec8179d87,86,21,10,8976,,,0,"Add config option to override url for versions

The versions url returns the wrong data when nova api is behind
a proxy. This adds a new config option so it can be set properly.

DocImpact

Change-Id: Ifdda22506fe6518a8835f8df5b6a3b406d5f17a5
Closes-Bug: #1384379
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/160266/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_versions.py', 'nova/api/openstack/compute/views/versions.py']",2,f24da3291e7b40a22fd65fcef10369eefc2d0118,bug/1384379,"from oslo_config import cfg versions_opts = [ cfg.StrOpt('public_endpoint', default=None, help=""Public url to use for versions endpoint. The default "" ""is None, which will use the request's host_url "" ""attribute to populate the URL base. If Nova is "" ""operating behind a proxy, you will want to change "" ""this to represent the proxy's URL.""), ] CONF = cfg.CONF CONF.register_opts(versions_opts) def get_view_builder(req): base_url = CONF.public_endpoint or req.application_url",def get_view_builder(req): base_url = req.application_url,75,2
openstack%2Fheat~master~I231c83aae025b1b3c42e05eb6752c321d3fee5a6,openstack/heat,master,I231c83aae025b1b3c42e05eb6752c321d3fee5a6,Add config option to override url for versions,ABANDONED,2015-03-02 09:06:27.000000000,2015-06-11 09:23:31.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6732}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8976}, {'_account_id': 9459}, {'_account_id': 9751}, {'_account_id': 10487}, {'_account_id': 12000}, {'_account_id': 12606}]","[{'number': 1, 'created': '2015-03-02 09:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f8239c8dc090de33678451c689539b2a677dcd0e', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when glance api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 2, 'created': '2015-03-03 01:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3524993e90cc1f4564f5ce760ccf259b663eddd7', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when glance api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 3, 'created': '2015-03-03 02:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51c40862d0df79814524a34d3b42852f06116479', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when glance api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 4, 'created': '2015-03-04 03:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/af52c402f51ff0b83cad49a86d9f57ba29767fda', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when glance api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 5, 'created': '2015-03-06 04:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5c73ac86ee79d813a8980de2ef6c5ce28dc84682', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when glance api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 6, 'created': '2015-03-20 03:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa963faf42cfa9d8e0e4f6cdd73b909d045fa71b', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when heat api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 7, 'created': '2015-03-20 03:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4ed4b145efae81c97d1a610c681b00f7527cad32', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when heat api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 8, 'created': '2015-04-14 04:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/abeb7d96355358f12d5a282ac094b0d4aec41c96', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when heat api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}, {'number': 9, 'created': '2015-05-05 06:09:18.000000000', 'files': ['heat/tests/test_version_negotiation_middleware.py', 'heat/api/openstack/versions.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9abab62c50fbf058abe00b112f7248e2fb208ea9', 'message': 'Add config option to override url for versions\n\nThe versions url returns the wrong data when heat api is behind\na proxy. This adds a new config option so it can be set properly.\n\nDocImpact\n\nChange-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6\nCloses-Bug: #1384379\n'}]",19,160267,9abab62c50fbf058abe00b112f7248e2fb208ea9,54,13,9,8976,,,0,"Add config option to override url for versions

The versions url returns the wrong data when heat api is behind
a proxy. This adds a new config option so it can be set properly.

DocImpact

Change-Id: I231c83aae025b1b3c42e05eb6752c321d3fee5a6
Closes-Bug: #1384379
",git fetch https://review.opendev.org/openstack/heat refs/changes/67/160267/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_version_negotiation_middleware.py', 'heat/api/openstack/versions.py']",2,f8239c8dc090de33678451c689539b2a677dcd0e,bug/1384379,"from oslo.config import cfgversions_opts = [ cfg.StrOpt('public_endpoint', default=None, help=""Public url to use for versions endpoint. The default "" ""is None, which will use the request's host_url "" ""attribute to populate the URL base. If Heat is "" ""operating behind a proxy, you will want to change "" ""this to represent the proxy's URL.""), ] CONF = cfg.CONF CONF.register_opts(versions_opts) def index(self, req): url = CONF.public_endpoint or req.host_url return ""%s/v1/"" % url @webob.dec.wsgify def __call__(self, req): return self.index(req)"," @webob.dec.wsgify def __call__(self, req): return ""%s/v1/"" % req.host_url",66,3
openstack%2Foperations-guide~master~I8457699ad12a9f727839750f495647a10c58df8e,openstack/operations-guide,master,I8457699ad12a9f727839750f495647a10c58df8e,Updated from openstack-manuals,MERGED,2015-06-11 08:22:27.000000000,2015-06-11 09:23:00.000000000,2015-06-11 09:22:59.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 08:22:27.000000000', 'files': ['doc/glossary/locale/zh_CN.po', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/e8bbb35e1b6057802bb7250ad3f1860855499d82', 'message': 'Updated from openstack-manuals\n\nChange-Id: I8457699ad12a9f727839750f495647a10c58df8e\n'}]",0,190540,e8bbb35e1b6057802bb7250ad3f1860855499d82,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I8457699ad12a9f727839750f495647a10c58df8e
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/40/190540/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/glossary/locale/zh_CN.po', 'doc/glossary/locale/ja.po']",2,e8bbb35e1b6057802bb7250ad3f1860855499d82,openstack/openstack-manuals,"""POT-Creation-Date: 2015-06-11 02:28+0000\n"" ""PO-Revision-Date: 2015-06-11 05:25+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""""A collection of servers that can share IPs with other members of the group. "" ""Any server in a group can share one or more public IPs with any other server "" ""in the group. With the exception of the first server in a shared IP group, "" ""servers must be launched into shared IP groups. A server may be a member of "" ""only one shared IP group."" msgstr """" ""グループの他のメンバーと IP を共有できるサーバー群。グループ内のサーバーは、"" ""そのグループ内の他のサーバーと 1 つ以上のパブリック IP を共有できる。共有 IP "" ""グループにおける 1 番目のサーバーを除き、サーバーは共有 IP グループの中で起動"" ""する必要があります。サーバーは、共有 IP グループ 1 つだけのメンバーになれま"" ""す。"" msgid """"msgid """" ""A discrete OpenStack environment with dedicated API endpoints that typically "" ""shares only the Identity (keystone) with other regions."" msgstr """" ""専用の API エンドポイントを持つ、分離した OpenStack 環境。一般的に Identity "" ""(keystone) のみを他のリージョンと共有する。"" ""A domain within a parent domain. Subdomains cannot be registered. Subdomains "" ""enable you to delegate domains. Subdomains can themselves have subdomains, "" ""so third-level, fourth-level, fifth-level, and deeper levels of nesting are "" ""possible."" msgstr """" ""親ドメイン内のドメイン。サブドメインは登録できない。サブドメインによりドメイ"" ""ンを委譲できる。サブドメインは、サブドメインを持てるので、第 3 階層、第 4 階"" ""層、第 5 階層と深い階層構造にできる。"" msgid """"""A grouped release of projects related to OpenStack that came out in the fall "" ""of 2011, the fourth release of OpenStack. It included Compute (nova 2011.3), "" ""Object Storage (swift 1.4.3), and the Image service (glance)."" msgstr """" ""2011年秋に登場した OpenStack 関連プロジェクトのリリース。Compute (nova "" ""2011.3), Object Storage (swift 1.4.3), Image service (glance) が含まれる。"" msgid """" ""A high availability system design approach and associated service "" ""implementation ensures that a prearranged level of operational performance "" ""will be met during a contractual measurement period. High availability "" ""systems seeks to minimize system downtime and data loss."" msgstr """" ""高可用性システムの設計手法および関連サービスの実装により、契約された測定期間"" ""中、合意された運用レベルを満たします。高可用性システムは、システムの停止時間"" ""とデータ損失を最小化しようとします。"" msgid """"""with the Identity service.""msgid ""A list of VM images that are available through Image service."" msgstr ""Image service 経由で利用可能な仮想マシンイメージの一覧。""""A list of tenants that can access a given VM image within Image service.""""Image service 内で指定した仮想マシンイメージにアクセスできるテナントの一覧。""msgid ""Alphanumeric ID assigned to each Identity service role."" msgstr ""各 Identity service ロールに割り当てられる英数 ID。""""service, this is a call that is specific to the implementation, such as """"API 拡張やプラグインの別名。Identity service では、OpenID のサポートの追加な""msgid ""Alternative term for an Identity service catalog.""msgid ""Alternative term for an Identity service default token."" msgstr ""Identity service デフォルトトークンの別名。""msgid ""Alternative term for the Identity service API."" msgstr ""Identity service API の別名。"" msgid ""Alternative term for the Identity service catalog.""""An Identity service API access token that is associated with a specific ""msgstr ""特定のテナントに関連付けられた Identity service API アクセストークン。""""An Identity service API endpoint that is associated with one or more tenants.""""1 つ以上のテナントと関連付けられた Identity service API エンドポイント。""""An Identity service component that manages and validates tokens after a user """"ユーザーやテナントが認証された後、トークンを管理し、検証する Identity のコン"" ""ポーネント。""""An Identity service feature that enables services, such as Compute, to """"An Identity service that lists API endpoints that are available to a user "" ""after authentication with the Identity service.""""An Identity service token that is not associated with a specific tenant and """"create, modify, and audit. Do not confuse with OpenStack Identity service, """"An OpenStack service, such as Compute, Object Storage, or Image service. """"Compute、Object Storage、Image service などの OpenStack のサービス。ユーザー""""the Identity service.""""An easy method to create a local LDAP directory for testing Identity and "" ""Compute. Requires Redis.""""An official OpenStack project. Currently consists of Compute (nova), Object "" ""Storage (swift), Image service (glance), Identity (keystone), Dashboard "" ""(horizon), Networking (neutron), and Block Storage (cinder), the Telemetry "" ""module (ceilometer), Orchestration module (heat), Database service (trove), "" ""Bare Metal service (ironic), Data processing service (sahara). However, this "" ""definition is changing based on community discussions about the \""Big Tent\""."" msgstr """" ""OpenStack の公式プロジェクト。現在、 Compute (nova), Object Storage (swift), "" ""Image service (glance), Identity (keystone), Dashboard (horizon), Networking "" ""(neutron), and Block Storage (cinder), the Telemetry module (ceilometer), "" ""Orchestration module (heat), Database service (trove), Bare Metal service "" ""(ironic), Data processing service (sahara) がある。しかしながら、この定義は"" ""「Big Tent」に関するコミュニティーの議論に基づき変更されてきている。"" msgid ""An open source LDAP server. Supported by both Compute and Identity.""""and a private key. Currently not supported in Identity.""""では現在サポートされていない。""msgid ""Both a VM container format and disk format. Supported by Image service.""""仮想マシンのコンテナー形式とディスク形式の両方。Image service によりサポート""""Component of Identity that provides a rule-management interface and a rule-"" ""based authorization engine.""""ルール管理インターフェースやルールベースの認可エンジンを提供する Identity の"" ""コンポーネント。""msgid ""Element of RabbitMQ that provides a response to an incoming MQ message."" msgstr ""送信されてきた MQ メッセージに応答する RabbitMQ の要素。"" msgid ""Identity service API"" msgstr ""Identity service API"" ""In Identity, each user is associated with one or more tenants, and in "" ""Compute can be associated with roles, projects, or both.""""Identity では、各ユーザーが 1 つ以上のテナントに関連付けられます。Compute で"" ""は、ロール、プロジェクトに関連付けられます。""""In the context of the Identity service, the worker process that provides ""msgstr ""Identity の領域で、管理 API へのアクセスを提供するワーカープロセス。""msgid ""One of the VM image disk formats supported by Image service.""""Image service によりサポートされる、仮想マシンイメージディスク形式の 1 つ。""msgid """" ""Open vSwitch is a production quality, multilayer virtual switch licensed "" ""under the open source Apache 2.0 license. It is designed to enable massive "" ""network automation through programmatic extension, while still supporting "" ""standard management interfaces and protocols (for example NetFlow, sFlow, "" ""SPAN, RSPAN, CLI, LACP, 802.1ag)."" msgstr """" ""Open vSwitch は、商用品質、複数階層の仮想スイッチ。オープンソースの Apache "" ""2.0 license に基づき許諾される。標準的な管理インターフェースやプロトコルと使"" ""用ながら、プログラム拡張により大規模なネットワーク自動化を実現できるよう設計"" ""されている (例えば、NetFlow、sFlow、SPAN、RSPAN、CLI、LACP、802.1ag)。"" ""OpenStack is a cloud operating system that controls large pools of compute, "" ""storage, and networking resources throughout a data center, all managed "" ""through a dashboard that gives administrators control while empowering their "" ""users to provision resources through a web interface. OpenStack is an open "" ""source project licensed under the Apache License 2.0."" msgstr """" ""OpenStack は、データセンター全体のコンピュートリソース、ストレージリソース、"" ""ネットワークリソースの大規模なプールを制御する、クラウドオペレーティングシス"" ""テム。管理者はすべてダッシュボードから制御できる。ユーザーは Web インター"" ""フェースからリソースを配備できる。Apache License 2.0 に基づき許諾されるオープ"" ""ンソースのプロジェクト。"" msgid """" ""OpenStack project that produces a set of Python libraries containing code "" ""shared by OpenStack projects."" msgstr """" ""OpenStack プロジェクトに共有されるコードを含む Python ライブラリー群を作成す"" ""る OpenStack プロジェクト。"" msgid """"msgid """" ""OpenStack project that provides a key-value store for applications running "" ""in an OpenStack cloud. The code name for the project is magnetoDB."" msgstr """" ""OpenStack 上のアプリケーションにキーバリューストアを提供する OpenStack プロ"" ""ジェクト。このプロジェクトのコード名は magnetoDB。"" ""Principal communications protocol in the internet protocol suite for "" ""relaying datagrams across network boundaries."" msgstr """" ""ネットワーク境界を越えてデータグラムを中継するための、インターネットプロトコ"" ""ルにおける中心的な通信プロトコル。"" msgid """"""Provides a predefined list of actions that the user can perform, such as "" ""start or stop VMs, reset passwords, and so on. Supported in both Identity "" ""and Compute and can be configured using the horizon dashboard."" msgstr """" ""仮想マシンの起動や停止、パスワードの初期化など、ユーザーが実行できる操作の事"" ""前定義済み一覧を提供する。Identity と Compute においてサポートされる。ダッ"" ""シュボードを使用して設定できる。"" msgid """"msgid ""Specifies the authentication source used by Image service or Identity.""""Term used in the OSI network architecture for the data link layer. The data "" ""link layer is responsible for media access control, flow control and "" ""detecting and possibly correcting errors that may occur in the physical "" ""layer."" msgstr """" ""OSI ネットワークアーキテクチャーにおけるデータリンク層に使用される用語。デー"" ""タリンク層は、メディアアクセス制御、フロー制御、物理層で発生する可能性のある"" ""エラー検知、できる限りエラー訂正に責任を持つ。"" msgid """" ""Term used in the OSI network architecture for the network layer. The network "" ""layer is responsible for packet forwarding including routing from one node "" ""to another."" msgstr """" ""OSI ネットワークアーキテクチャーにおけるネットワーク層に使用される用語。ネッ"" ""トワーク層は、パケット転送、あるノードから別のノードへのルーティングに責任を"" ""持つ。"" msgid """"""The API used to access the OpenStack Identity service provided through """"The Compute direct exchanges, fanout exchanges, and topic exchanges use this "" ""key to determine how to process a message; processing varies depending on "" ""exchange type."" msgstr """" ""Compute の直接交換、ファンアウト交換、トピック交換は、このキーを使用して、"" ""メッセージを処理する方法を判断する。処理内容は交換形式に応じて変化する。"" msgid """"msgid ""The Identity component that provides high-level authorization services."" msgstr ""高レベルの認可サービスを提供する Identity のコンポーネント。"" msgid ""The Identity service component that provides authentication services."" msgstr ""認証サービスを提供する Identity のコンポーネント。""""The Identity service endpoint template that contains services available to """"OpenLDAP, OpenStack Identity, and so on.""""name of Identity is keystone.""msgid """" ""The OpenStack core project that provides eventually consistent and redundant "" ""storage and retrieval of fixed digital content. The project name of "" ""OpenStack Object Storage is swift."" msgstr """" ""結果整合性（eventually consistent）、ストレージ冗長化、静的デジタルコンテンツ"" ""取得、といった機能を提供する、OpenStack のコアプロジェクト。OpenStack Object "" ""Storage のプロジェクト名は swift。"" msgid """" ""The cooperative threading model used by Python; reduces race conditions and "" ""only context switches when specific library calls are made. Each OpenStack "" ""service is its own thread."" msgstr """" ""Python により使用される協調スレッドモデル。特定のライブラリーコールが発行され"" ""るときの競合状態とコンテキストスイッチを減らす。各 OpenStack サービスは自身の"" ""スレッドである。"" ""The primary load balancing configuration object. Specifies the virtual IP "" ""address and port where client traffic is received. Also defines other "" ""details such as the load balancing method to be used, protocol, and so on. "" ""This entity is sometimes known in load-balancing products as a virtual "" ""server, vserver, or listener."" msgstr """" ""主たる負荷分散の設定オブジェクト。クライアント通信を受け付ける仮想 IP とポー"" ""トを指定する。使用する負荷分散方式、プロトコルなどの詳細も定義する。このエン"" ""ティティは、virtual server、vserver、listener のような負荷分散製品においても"" ""知られている。"" msgid """"""The source used by Identity service to retrieve user information; an """"The storage method used by the Identity service catalog service to store and """"Unique ID assigned to each service that is available in the Identity service """"Unique ID assigned to each tenant within the Identity service. The project """"Identity 内で各テナントに割り当てられる一意な ID。プロジェクト ID は、テナン"" ""ト ID に対応付けられる。""""Unique numeric ID associated with each user in Identity, conceptually "" ""similar to a Linux or LDAP UID.""""Identity で各ユーザーと関連付けられた一意な数値 ID。概念として、Linux や "" ""LDAP の UID を同じ。""","""POT-Creation-Date: 2015-06-10 05:08+0000\n"" ""PO-Revision-Date: 2015-06-10 05:38+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""""with the Identity Service.""msgid ""A list of VM images that are available through Image Service."" msgstr ""Image Service 経由で利用可能な仮想マシンイメージの一覧。""""A list of tenants that can access a given VM image within Image Service.""""Image Service 内で指定した仮想マシンイメージにアクセスできるテナントの一覧。""msgid ""Alphanumeric ID assigned to each Identity Service role."" msgstr ""各 Identity Service ロールに割り当てられる英数 ID。""""Service, this is a call that is specific to the implementation, such as """"API 拡張やプラグインの別名。Identity Service では、OpenID のサポートの追加な""msgid ""Alternative term for an Identity Service catalog.""msgid ""Alternative term for an Identity Service default token."" msgstr ""Identity Service デフォルトトークンの別名。""msgid ""Alternative term for the Identity Service API."" msgstr ""Identity サービス API の別名。"" msgid ""Alternative term for the Identity Service catalog.""""An Identity Service API access token that is associated with a specific ""msgstr ""特定のテナントに関連付けられた Identity Service API アクセストークン。""""An Identity Service API endpoint that is associated with one or more tenants.""""1 つ以上のテナントと関連付けられた Identity Service API エンドポイント。""""An Identity Service component that manages and validates tokens after a user """"ユーザーやテナントが認証された後、トークンを管理し、検証する Identity "" ""Service のコンポーネント。""""An Identity Service feature that enables services, such as Compute, to """"An Identity Service that lists API endpoints that are available to a user "" ""after authentication with the Identity Service.""""An Identity Service token that is not associated with a specific tenant and """"create, modify, and audit. Do not confuse with OpenStack Identity Service, """"An OpenStack service, such as Compute, Object Storage, or Image Service. """"Compute、Object Storage、Image Service などの OpenStack のサービス。ユーザー""""the Identity Service.""""An easy method to create a local LDAP directory for testing Identity Service "" ""and Compute. Requires Redis.""""An open source LDAP server. Supported by both Compute and Identity Service.""""An option within Compute that enables administrators to create and manage "" ""users through the <literal>nova-manage</literal> command as opposed to using "" ""the Identity Service."" msgstr """" ""管理者が、Identity を使用する代わりに、<literal>nova-manage</literal> コマン"" ""ド経由でユーザーを作成および管理できる、Compute 内のオプション。"" msgid """"""and a private key. Currently not supported in Identity Service.""""Service では現在サポートされていない。""msgid ""Both a VM container format and disk format. Supported by Image Service.""""仮想マシンのコンテナー形式とディスク形式の両方。Image Service によりサポート""""Checks for and deletes unused VMs; the component of Image Service that "" ""implements delayed delete."" msgstr """" ""未使用の仮想マシンを確認し、削除する。遅延削除を実装する、Image Service のコ"" ""ンポーネント。"" msgid """"""Collection of Compute components that represent the global state of the "" ""cloud; talks to services, such as Identity Service authentication, Object "" ""Storage, and node/storage workers through a queue."" msgstr """" ""クラウドの全体状況を表す Compute コンポーネント群。キュー経由で、Identity の"" ""認証、Object Storage、ノード/ストレージワーカーなどのサービスと通信する。"" msgid """"""Component of Identity Service that provides a rule-management interface and "" ""a rule-based authorization engine.""""ルール管理インターフェースやルールベースの認可エンジンを提供する Identity "" ""Service のコンポーネント。""msgid ""Identity Service"" msgstr ""Identity サービス"" msgid ""Identity Service API"" msgstr ""Identity サービス API"" ""In Identity Service, each user is associated with one or more tenants, and "" ""in Compute can be associated with roles, projects, or both.""""Identity Service では、各ユーザーが 1 つ以上のテナントに関連付けられます。"" ""Compute では、ロール、プロジェクトに関連付けられます。""""In the context of the Identity Service, the worker process that provides ""msgstr """" ""Identity Service の領域で、管理 API へのアクセスを提供するワーカープロセス。""msgid ""One of the VM image disk formats supported by Image Service.""""Image Service によりサポートされる、仮想マシンイメージディスク形式の 1 つ。""msgid """" ""Specifies the authentication source used by Image service or Identity "" ""Service.""""The API used to access the OpenStack Identity Service provided through ""msgid ""The Identity Service component that provides authentication services."" msgstr ""認証サービスを提供する Identity Service のコンポーネント。""""The Identity Service component that provides high-level authorization "" ""services."" msgstr ""高レベルの認可サービスを提供する Identity Service コンポーネント。"" msgid """" ""The Identity Service endpoint template that contains services available to """"OpenLDAP, OpenStack Identity Service, and so on.""""name of the Identity Service is keystone.""""The source used by Identity Service to retrieve user information; an """"The storage method used by the Identity Service catalog service to store and """"Unique ID assigned to each service that is available in the Identity Service """"Unique ID assigned to each tenant within the Identity Service. The project """"Identity Service 内で各テナントに割り当てられる一意な ID。プロジェクト ID "" ""は、テナント ID に対応付けられる。""""Unique numeric ID associated with each user in Identity Service, "" ""conceptually similar to a Linux or LDAP UID.""""Identity Service で各ユーザーと関連付けられた一意な数値 ID。概念として、"" ""Linux や LDAP の UID を同じ。""",257,132
openstack%2Fnova~master~Id113e52985aca06afe415223a6ccf7f9a9930ae6,openstack/nova,master,Id113e52985aca06afe415223a6ccf7f9a9930ae6,Fixed some misspellings,MERGED,2015-04-14 02:33:57.000000000,2015-06-11 09:18:27.000000000,2015-06-11 09:18:23.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 4491}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6167}, {'_account_id': 6802}, {'_account_id': 7634}, {'_account_id': 7730}, {'_account_id': 8119}, {'_account_id': 8247}, {'_account_id': 8276}, {'_account_id': 8290}, {'_account_id': 8556}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-14 02:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f85ee86a66dea6ba5144de5731d66aa4137f0526', 'message': 'Fixed some misspellings\n\nChange-Id: Id113e52985aca06afe415223a6ccf7f9a9930ae6\nCloses-Bug: #1443731\n'}, {'number': 2, 'created': '2015-04-14 03:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/466640b2197da7fe91d404c97930843c8468cc60', 'message': 'Fixed some misspellings\n\nChange-Id: Id113e52985aca06afe415223a6ccf7f9a9930ae6\nCloses-Bug: #1443731\n'}, {'number': 3, 'created': '2015-06-10 02:29:38.000000000', 'files': ['nova/tests/functional/wsgi/test_flavor_manage.py', 'nova/tests/unit/compute/test_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c83303d5b18d5edf25f79467b8cefc9c901b3ae', 'message': 'Fixed some misspellings\n\nChange-Id: Id113e52985aca06afe415223a6ccf7f9a9930ae6\nCloses-Bug: #1443731\n'}]",10,173153,0c83303d5b18d5edf25f79467b8cefc9c901b3ae,45,19,3,4491,,,0,"Fixed some misspellings

Change-Id: Id113e52985aca06afe415223a6ccf7f9a9930ae6
Closes-Bug: #1443731
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/173153/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_objects.py', 'nova/tests/functional/wsgi/test_flavor_manage.py', 'nova/tests/unit/console/test_websocketproxy.py', 'nova/tests/unit/compute/test_tracker.py']",4,f85ee86a66dea6ba5144de5731d66aa4137f0526,bug/1443731, # NOTE(pmurray): no initial values are calculated before the initial, # NOTE(pmurray): no intial values are calculated before the initial,4,4
openstack%2Fnova~master~I2f4646f0938f92882850f294a97114ecbc920b20,openstack/nova,master,I2f4646f0938f92882850f294a97114ecbc920b20,ec2: clean up in test_cinder_cloud,MERGED,2015-03-10 12:06:35.000000000,2015-06-11 09:17:58.000000000,2015-06-11 09:17:55.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 6167}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}]","[{'number': 1, 'created': '2015-03-10 12:06:35.000000000', 'files': ['nova/tests/unit/api/ec2/test_cinder_cloud.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d5e10543a640cc8e5fd227c129176fbaf211f982', 'message': 'ec2: clean up in test_cinder_cloud\n\n_fake_bdm_get() is never been called in this unit\ntest case. remove it.\n\nChange-Id: I2f4646f0938f92882850f294a97114ecbc920b20\n'}]",0,162974,d5e10543a640cc8e5fd227c129176fbaf211f982,14,9,1,12175,,,0,"ec2: clean up in test_cinder_cloud

_fake_bdm_get() is never been called in this unit
test case. remove it.

Change-Id: I2f4646f0938f92882850f294a97114ecbc920b20
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/162974/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/ec2/test_cinder_cloud.py'],1,d5e10543a640cc8e5fd227c129176fbaf211f982,clean_up_cinder_cloud_testing,," @staticmethod def _fake_bdm_get(ctxt, id): return [{'volume_id': 87654321, 'snapshot_id': None, 'no_device': None, 'virtual_name': None, 'delete_on_termination': True, 'device_name': '/dev/sdh'}, {'volume_id': None, 'snapshot_id': 98765432, 'no_device': None, 'virtual_name': None, 'delete_on_termination': True, 'device_name': '/dev/sdi'}, {'volume_id': None, 'snapshot_id': None, 'no_device': True, 'virtual_name': None, 'delete_on_termination': None, 'device_name': None}, {'volume_id': None, 'snapshot_id': None, 'no_device': None, 'virtual_name': 'ephemeral0', 'delete_on_termination': None, 'device_name': '/dev/sdb'}, {'volume_id': None, 'snapshot_id': None, 'no_device': None, 'virtual_name': 'swap', 'delete_on_termination': None, 'device_name': '/dev/sdc'}, {'volume_id': None, 'snapshot_id': None, 'no_device': None, 'virtual_name': 'ephemeral1', 'delete_on_termination': None, 'device_name': '/dev/sdd'}, {'volume_id': None, 'snapshot_id': None, 'no_device': None, 'virtual_name': 'ephemeral2', 'delete_on_termination': None, 'device_name': '/dev/sd3'}, ]",0,46
openstack%2Fswift-specs~master~If9b258427f422be31ef14b35c54844bbd290bdb0,openstack/swift-specs,master,If9b258427f422be31ef14b35c54844bbd290bdb0,Add event notification spec,MERGED,2015-05-07 09:46:46.000000000,2015-06-11 09:16:58.000000000,2015-06-11 09:16:55.000000000,"[{'_account_id': 3}, {'_account_id': 4608}, {'_account_id': 5600}, {'_account_id': 6968}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 8542}, {'_account_id': 12193}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-05-07 09:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/55e09bd66fe744e2a080d7a2e83f5bf9a9372e1e', 'message': 'Add event notification spec\n\nChange-Id: If9b258427f422be31ef14b35c54844bbd290bdb0\n'}, {'number': 2, 'created': '2015-05-07 12:58:20.000000000', 'files': ['specs/in_progress/notifications.rst'], 'web_link': 'https://opendev.org/openstack/swift-specs/commit/9a9f429f93af267e701a3d9f38881a55391e339e', 'message': 'Add event notification spec\n\nChange-Id: If9b258427f422be31ef14b35c54844bbd290bdb0\n'}]",8,180914,9a9f429f93af267e701a3d9f38881a55391e339e,17,9,2,6968,,,0,"Add event notification spec

Change-Id: If9b258427f422be31ef14b35c54844bbd290bdb0
",git fetch https://review.opendev.org/openstack/swift-specs refs/changes/14/180914/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/in_progress/notifications.rst'],1,55e09bd66fe744e2a080d7a2e83f5bf9a9372e1e,notifications,":: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ============================================== Send notifications on PUT/POST/DELETE requests ============================================== Swift should be able to send out notifications if new objects are uploaded, metadata has been changed or data has been deleted. Problem Description =================== Currently there is no way to detect changes in a given container except listing it's contents and comparing timestamps. This makes it difficult and slow in case there are a lot of objects stored, and it is not very efficient at all. Some external services might be interested when an object got uploaded, updated or deleted; for example to store the metadata in an external database for searching or to trigger specific events like computing on object data. Proposed Change =============== A new middleware should be added that can be configured to run inside the proxy server pipeline. Alternatives ------------ Another option might be to analyze logfiles and parsing them, aggregating data into notifications per account and sending batches of updates to an external service. However, performance is most likely worse since there is a lot of string parsing involved, and a central logging service might be required to send notifications in order. Implementation ============== Sending out notifications should happen when an object got modified. That means every successful object change (PUT, POST, DELETE) should trigger an action and send out an event notification. It should be configurable on either an account or container level that notifications should be sent; this leaves it up to the user to decide where they end up and if a possible performance impact is acceptable. An implementation should be developed as an additional middleware inside the Swift proxy, and make use of existing queuing implementations within OpenStack, namely Zaqar (https://wiki.openstack.org/wiki/Zaqar). It needs to be discussed if metadata that is stored along the object should be included in the notification or not; if there is a lot of metadata the notifications are getting quite large. A possible trade off might be a threshold for included metadata, for example only the first X bytes. Or send no metadata at all, but only the account/container/objectname. Assignee(s) ----------- Primary assignee: cschwede Work Items ---------- Develop middleware for the Swift proxy server including functional tests. Update Swift functional test VMs to include Zaqar service for testing. Repositories ------------ None Servers ------- Functional tests require either a running Zaqar service on the testing VM, or a dummy implementation that acts like a Zaqar queue. DNS Entries ----------- None Documentation ------------- Add documentation for new middleware Security -------- Does this introduce any additional security risks, or are there security-related considerations which should be discussed? Testing ------- Unit and functional testing shall be included in a patch. Dependencies ============ - python-zaqarclient: https://github.com/openstack/python-zaqarclient - zaqar service running on the gate (inside the VM) ",,107,0
openstack%2Fnova~master~I7270e06622131af1565f748f69aa3497ca7ef4d2,openstack/nova,master,I7270e06622131af1565f748f69aa3497ca7ef4d2,Overwrite NovaException message,MERGED,2015-04-24 07:50:18.000000000,2015-06-11 09:14:19.000000000,2015-06-11 09:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 14819}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-24 07:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6725a6b810cde5e4284cb7e9677c8e8141dc36c6', 'message': 'Overwrite NovaException message\n\nI see nova reports DeprecationWarning message when using exception.message.\n\nDeprecationWarning: BaseException.message has been deprecated as of Python 2.6\n\nThis can be fixed by overwrite message in our Nova base Exception.\n\nCloses-Bug: #447946\nChange-Id: I7270e06622131af1565f748f69aa3497ca7ef4d2\n'}, {'number': 2, 'created': '2015-04-24 12:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d637f537937506c4a79b8e5e3ce995d561c4c7f', 'message': 'Overwrite NovaException message\n\nI see nova reports DeprecationWarning message when using exception.message.\n\nDeprecationWarning: BaseException.message has been deprecated as of Python 2.6\n\nThis can be fixed by overwrite message in our Nova base Exception.\n\nCloses-Bug: #1447946\nChange-Id: I7270e06622131af1565f748f69aa3497ca7ef4d2\n'}, {'number': 3, 'created': '2015-05-12 06:51:45.000000000', 'files': ['nova/exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/731719d4a05c12adb75cf075f769ef26e7b81ef2', 'message': 'Overwrite NovaException message\n\nI see nova reports DeprecationWarning message when using exception.message.\n\nDeprecationWarning: BaseException.message has been deprecated as of Python 2.6\n\nThis can be fixed by overwrite message in our Nova base Exception.\n\nCloses-Bug: #1447946\nChange-Id: I7270e06622131af1565f748f69aa3497ca7ef4d2\n'}]",2,177105,731719d4a05c12adb75cf075f769ef26e7b81ef2,32,13,3,12175,,,0,"Overwrite NovaException message

I see nova reports DeprecationWarning message when using exception.message.

DeprecationWarning: BaseException.message has been deprecated as of Python 2.6

This can be fixed by overwrite message in our Nova base Exception.

Closes-Bug: #1447946
Change-Id: I7270e06622131af1565f748f69aa3497ca7ef4d2
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/177105/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/exception.py'],1,6725a6b810cde5e4284cb7e9677c8e8141dc36c6,exception_message, self.message = message,,1,0
openstack%2Fmagnum~master~Ie53af7c511b436459c9bb35e34f32ec2f3cef4f6,openstack/magnum,master,Ie53af7c511b436459c9bb35e34f32ec2f3cef4f6,Remove major version checking,MERGED,2015-06-11 07:04:47.000000000,2015-06-11 09:13:31.000000000,2015-06-11 09:13:30.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 10206}, {'_account_id': 11189}]","[{'number': 1, 'created': '2015-06-11 07:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1141c1548fbd76ae17a89bbf385eddf88427541e', 'message': 'Remove major version checking\n\nChecking major version is useless, because major version is checked by\ncontroller itself.\n\nChange-Id: Ie53af7c511b436459c9bb35e34f32ec2f3cef4f6\nCloses-Bug: #1464113\n'}, {'number': 2, 'created': '2015-06-11 07:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6eaddac5c898a77200a7b3e5691174fb7db5a2d4', 'message': 'Remove major version checking\n\nChecking major version is useless, because major version is checked by\ncontroller itself.\n\nChange-Id: Ie53af7c511b436459c9bb35e34f32ec2f3cef4f6\nCloses-Bug: #1464113\n'}, {'number': 3, 'created': '2015-06-11 07:27:48.000000000', 'files': ['magnum/tests/unit/api/controllers/test_base.py', 'magnum/api/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/75d489323e06f3ada178d8ef6ab97a259a2927ae', 'message': 'Remove major version checking\n\nRaising NotAcceptable is useless if major version is different, because major\nversion is checked by controller itself.\n\nChange-Id: Ie53af7c511b436459c9bb35e34f32ec2f3cef4f6\nCloses-Bug: #1464113\n'}]",0,190513,75d489323e06f3ada178d8ef6ab97a259a2927ae,10,4,3,12385,,,0,"Remove major version checking

Raising NotAcceptable is useless if major version is different, because major
version is checked by controller itself.

Change-Id: Ie53af7c511b436459c9bb35e34f32ec2f3cef4f6
Closes-Bug: #1464113
",git fetch https://review.opendev.org/openstack/magnum refs/changes/13/190513/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/api/controllers/test_base.py', 'magnum/api/controllers/base.py']",2,1141c1548fbd76ae17a89bbf385eddf88427541e,bug/1464113, if (a.major < b.major): return True if (a.major > b.major): return True,from magnum.common.exception import NotAcceptable if a.major != b.major: raise NotAcceptable() if a.major != b.major: raise NotAcceptable() ,82,7
openstack%2Fkeystone~master~I92be4856a0fbe22651409099cb740ed99724eae1,openstack/keystone,master,I92be4856a0fbe22651409099cb740ed99724eae1,Imported Translations from Transifex,MERGED,2015-05-28 06:07:38.000000000,2015-06-11 09:03:21.000000000,2015-06-11 09:03:19.000000000,"[{'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2015-05-28 06:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/53f723121a923b168d4ca636a7449cbe6f0ebab5', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 2, 'created': '2015-05-29 06:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/eb5aabb89e830c2291c8349d423435620c38cba9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 3, 'created': '2015-05-30 06:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b570aaecc753d439b68123fe2c6ea811a1fbc103', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 4, 'created': '2015-06-01 06:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/45944bb4fc95b0a2c40c924d36d989a490f1156c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 5, 'created': '2015-06-02 06:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7689173c6ca9d75221a3b700c80b841e43e59c11', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 6, 'created': '2015-06-03 06:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a9d833304d7ebccf440c3f82b142b86f180b1c2d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 7, 'created': '2015-06-04 06:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4cdc48634c34eddaefaf28f88ebd75fb72c9694c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 8, 'created': '2015-06-05 06:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fe6108c1748fa502c8dd9a5cf99afd409e9446fa', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 9, 'created': '2015-06-06 06:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/31a1d52a874cc7a2b0d01639f6e96b6c7b6f32df', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 10, 'created': '2015-06-07 06:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0a39b5c9caa000dfcf3e1be6eade7fe64a9e1ddd', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 11, 'created': '2015-06-08 06:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a05bf9318a759981bc628de5d524e267c60a4093', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 12, 'created': '2015-06-09 06:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4c6e89c29bf73a0be3a95767e9fc0d2327e60859', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 13, 'created': '2015-06-10 06:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e2be877a1512dc5a9081acb93734e0a9888ffb85', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}, {'number': 14, 'created': '2015-06-11 06:04:53.000000000', 'files': ['keystone/locale/de/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/fr/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/keystone-log-info.pot', 'keystone/locale/fr/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/keystone.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/keystone-log-warning.pot', 'keystone/locale/keystone-log-error.pot', 'keystone/locale/vi_VN/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/fr/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-info.po'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cc02f994f9ecbacfa2c8d4324eda60b435bce9b3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I92be4856a0fbe22651409099cb740ed99724eae1\n'}]",0,186279,cc02f994f9ecbacfa2c8d4324eda60b435bce9b3,33,2,14,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I92be4856a0fbe22651409099cb740ed99724eae1
",git fetch https://review.opendev.org/openstack/keystone refs/changes/79/186279/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/locale/de/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/fr/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/fr/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/keystone.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/keystone-log-warning.pot', 'keystone/locale/keystone-log-error.pot', 'keystone/locale/vi_VN/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/fr/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-info.po']",19,53f723121a923b168d4ca636a7449cbe6f0ebab5,transifex/translations,"""POT-Creation-Date: 2015-05-28 06:07+0000\n""msgid ""Caught %s, stopping children"" msgstr ""Caught %s, stopping children""msgid ""Child caught %s, exiting"" msgstr ""Child caught %s, exiting""msgid ""Eventlet backdoor listening on %(port)s for process %(pid)d"" msgstr ""Eventlet backdoor listening on %(port)s for process %(pid)d"" msgid ""Forking too fast, sleeping"" msgstr ""Forking too fast, sleeping"" msgid ""Parent process has died unexpectedly, exiting"" msgstr ""Parent process has died unexpectedly, exiting"" #, python-format msgid ""Started child %d"" msgstr ""Started child %d"" #, python-format msgid ""Starting %d workers"" msgstr ""Starting %d workers"" #, python-format msgid ""Waiting on %d children to exit"" msgstr ""Waiting on %d children to exit""","""POT-Creation-Date: 2015-05-15 06:07+0000\n""msgid ""Eventlet backdoor listening on %(port)s for process %(pid)d"" msgstr ""Eventlet backdoor listening on %(port)s for process %(pid)d"" #, python-formatmsgid ""Parent process has died unexpectedly, exiting"" msgstr ""Parent process has died unexpectedly, exiting"" msgid ""Child caught %s, exiting"" msgstr ""Child caught %s, exiting"" msgid ""Forking too fast, sleeping"" msgstr ""Forking too fast, sleeping"" #, python-format msgid ""Started child %d"" msgstr ""Started child %d"" #, python-format msgid ""Starting %d workers"" msgstr ""Starting %d workers""msgid ""Caught %s, stopping children"" msgstr ""Caught %s, stopping children""msgid ""Waiting on %d children to exit"" msgstr ""Waiting on %d children to exit""",1123,1132
openstack%2Ffuel-web~master~I5b19884a3f1a2ed253b67bcf3583e99739c716e1,openstack/fuel-web,master,I5b19884a3f1a2ed253b67bcf3583e99739c716e1,[React] Edit node disks screen,MERGED,2015-01-12 15:15:21.000000000,2015-06-11 08:59:34.000000000,2015-06-11 08:46:42.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-01-12 15:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d671b3b7201c02a3e21645b2244ce316600c3c29', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 2, 'created': '2015-01-16 15:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6701c68bdc04fac0c9b76b78d0b149caeb81431f', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 3, 'created': '2015-02-12 14:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/299963f65c4549668c606475088d12af75ff0691', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 4, 'created': '2015-02-16 15:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/77b80c26953ae76405479466b1d8846b4fc0cbcb', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 5, 'created': '2015-05-05 11:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5eb94fec3acb17995ab738629d0b90f77911c387', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 6, 'created': '2015-05-08 16:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/65fb2d58a1fa987aa27c581292f094d75b27f127', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 7, 'created': '2015-05-12 07:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a1cfe4e4e8e43806d7b3fd013327d16593470959', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 8, 'created': '2015-05-15 15:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f4c33a76dddc03348c73231b7f2e64f66358d4d9', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 9, 'created': '2015-05-20 16:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1824f4fbf091aa58b0929b1d8156027cb58d99b9', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 10, 'created': '2015-05-21 16:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/64db56c809bbfd1e0b3b81bd912432c8aabbaba7', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 11, 'created': '2015-05-22 12:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/102fdebedd488f95e51826226a26685ca187428e', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 12, 'created': '2015-05-22 13:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3aa12e76c2ac26475e8c3044b3009ad0b1171b51', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 13, 'created': '2015-05-22 14:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6f0be60c53096140d6935e6e196e1922d5bcec67', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 14, 'created': '2015-05-25 12:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c75874e0a0e5b04995a15f496be0321cd4ccafc1', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 15, 'created': '2015-05-29 09:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9f86b19359489ee908188505f4968e33f5a2a0e9', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 16, 'created': '2015-06-04 12:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8239595a6d2a0c3a7ed43db88e49241af148ace1', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}, {'number': 17, 'created': '2015-06-09 16:09:26.000000000', 'files': ['nailgun/static/views/cluster_page_tabs/nodes_tab.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_node_interfaces_screen.jsx', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.jsx', 'nailgun/static/templates/cluster/volume_style.html', 'nailgun/static/styles/main.less', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/screen.js', 'nailgun/static/translations/core.json', 'nailgun/static/views/controls.jsx', 'nailgun/static/component_mixins.jsx', 'nailgun/static/templates/cluster/edit_node_disks.html', 'nailgun/ui_tests/test_node_disk.js', 'nailgun/static/templates/cluster/node_disk.html', 'nailgun/static/templates/cluster/node_interface.html', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.js', 'nailgun/static/views/cluster_page_tabs/nodes_tab_screens/edit_node_screen.js', 'nailgun/static/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4244eb13e34a736c172c25591f724f158cbdbd78', 'message': '[React] Edit node disks screen\n\nRelated to blueprint backbone-to-react\n\nChange-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1\n'}]",217,146491,4244eb13e34a736c172c25591f724f158cbdbd78,134,7,17,9730,,,0,"[React] Edit node disks screen

Related to blueprint backbone-to-react

Change-Id: I5b19884a3f1a2ed253b67bcf3583e99739c716e1
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/91/146491/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/nodes_tab.js', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.jsx', 'nailgun/static/js/views/cluster_page_tabs/nodes_tab_screens/edit_node_disks_screen.js']",3,d671b3b7201c02a3e21645b2244ce316600c3c29,bp/backbone-to-react," 'text!templates/cluster/volume_style.html',sfsf"," 'text!templates/cluster/volume_style.html',",294,2
openstack%2Ffuel-web~master~Id0c4f0a8cd42cd583f98ad7347264821071f875f,openstack/fuel-web,master,Id0c4f0a8cd42cd583f98ad7347264821071f875f,Language chooser control show full names of languages,MERGED,2015-06-10 12:45:58.000000000,2015-06-11 08:53:28.000000000,2015-06-11 08:41:26.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-06-10 12:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f1672f4a61920ff0d2302539b04fb6a2a5379272', 'message': 'Language chooser control show full names of languages\n\nCloses-Bug:#1443922\n\nChange-Id: Id0c4f0a8cd42cd583f98ad7347264821071f875f\n'}, {'number': 2, 'created': '2015-06-10 14:09:11.000000000', 'files': ['nailgun/static/styles/main.less', 'nailgun/static/i18n.js', 'nailgun/static/translations/core.json', 'nailgun/static/views/layout.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fe959450adc8a685dedcbed4bb9f95e4a74a7e35', 'message': 'Language chooser control show full names of languages\n\nCloses-Bug:#1443922\n\nChange-Id: Id0c4f0a8cd42cd583f98ad7347264821071f875f\n'}]",2,190161,fe959450adc8a685dedcbed4bb9f95e4a74a7e35,19,7,2,9730,,,0,"Language chooser control show full names of languages

Closes-Bug:#1443922

Change-Id: Id0c4f0a8cd42cd583f98ad7347264821071f875f
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/61/190161/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/styles/main.less', 'nailgun/static/i18n.js', 'nailgun/static/translations/core.json', 'nailgun/static/views/layout.jsx']",4,f1672f4a61920ff0d2302539b04fb6a2a5379272,bug/1443922, {i18n.getLanguageName(locale)}, {i18n.getLocaleName(locale)},9,2
openstack%2Fopenstack-manuals~master~I86a8032c32a52fb912b392f72b978ce157c31653,openstack/openstack-manuals,master,I86a8032c32a52fb912b392f72b978ce157c31653,Convert ch_blockstorage.xml to RST,MERGED,2015-06-10 12:28:00.000000000,2015-06-11 08:46:09.000000000,2015-06-11 08:46:08.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 14396}, {'_account_id': 14947}, {'_account_id': 14962}, {'_account_id': 15293}]","[{'number': 1, 'created': '2015-06-10 12:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f72c460cc7790e4cb2c10e9d6c6a8fff14d8883f', 'message': 'Convert ch_blockstorage.xml to RST\n\nThis patch converts ch_blockstorage.xml to blockstorage.rst\n\nChange-Id: I86a8032c32a52fb912b392f72b978ce157c31653\nImplements: blueprint reorganise-user-guides\n'}, {'number': 2, 'created': '2015-06-10 12:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a4da47449147819b3f2fdf5c6196723cc4d5428', 'message': 'Convert ch_blockstorage.xml to RST\n\nThis patch converts ch_blockstorage.xml to blockstorage.rst\n\nChange-Id: I86a8032c32a52fb912b392f72b978ce157c31653\nImplements: blueprint reorganise-user-guides\n'}, {'number': 3, 'created': '2015-06-10 15:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e90e7131e42ca9d867ad8dfcce922880f19c9254', 'message': 'Convert ch_blockstorage.xml to RST\n\nThis patch converts ch_blockstorage.xml to blockstorage.rst\nAlso changes Storage Area Network (SAN) to Network Attached\n Storage (NAS), and ISCSI to iSCSI.\n\nChange-Id: I86a8032c32a52fb912b392f72b978ce157c31653\nImplements: blueprint reorganise-user-guides\n'}, {'number': 4, 'created': '2015-06-10 16:15:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b56b85bd1d99b0cf363244b783af191661087e8f', 'message': 'Convert ch_blockstorage.xml to RST\n\nThis patch converts ch_blockstorage.xml to blockstorage.rst\nAlso changes Storage Area Network (SAN) to Network Attached\n Storage (NAS), and ISCSI to iSCSI.\n\nChange-Id: I86a8032c32a52fb912b392f72b978ce157c31653\nImplements: blueprint reorganise-user-guides\n'}, {'number': 5, 'created': '2015-06-11 08:26:00.000000000', 'files': ['doc/admin-guide-cloud-rst/source/blockstorage.rst', 'doc/admin-guide-cloud-rst/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9cb0d900b55a8ba9c31f38710544979e6cec46db', 'message': 'Convert ch_blockstorage.xml to RST\n\nThis patch converts ch_blockstorage.xml to blockstorage.rst\nAlso changes Storage Area Network (SAN) to Network Attached\n Storage (NAS), and ISCSI to iSCSI.\n\nChange-Id: I86a8032c32a52fb912b392f72b978ce157c31653\nImplements: blueprint reorganise-user-guides\n'}]",2,190151,9cb0d900b55a8ba9c31f38710544979e6cec46db,20,8,5,14947,,,0,"Convert ch_blockstorage.xml to RST

This patch converts ch_blockstorage.xml to blockstorage.rst
Also changes Storage Area Network (SAN) to Network Attached
 Storage (NAS), and ISCSI to iSCSI.

Change-Id: I86a8032c32a52fb912b392f72b978ce157c31653
Implements: blueprint reorganise-user-guides
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/190151/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud-rst/source/blockstorage.rst', 'doc/admin-guide-cloud-rst/source/index.rst']",2,f72c460cc7790e4cb2c10e9d6c6a8fff14d8883f,bp/reorganise-user-guides, blockstorage.rst,,145,0
openstack%2Fkolla~master~I3d25ac47ed1f60cb23cf9f528119366a5e31d434,openstack/kolla,master,I3d25ac47ed1f60cb23cf9f528119366a5e31d434,Documentation improvements and minor fixups,ABANDONED,2015-06-05 11:03:04.000000000,2015-06-11 08:40:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 14027}, {'_account_id': 15697}, {'_account_id': 16520}]","[{'number': 1, 'created': '2015-06-05 11:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/829ec754c32ac9579c22eea5f1e6d8a5513e278c', 'message': 'Documentation improvements and minor fixups\n\n* Move the Ansible README under the docs/ dir to make it more visible\nto people browsing the docs.\n\n* Add a paragraph explaining the provided inventory files.\n\n* Add note to ensure user updates the koalla_directory var to match\n  their environment.\n\n* Add paragraph on some basic requirements for those using Vagrant.\n\n* Add missing command for pip requirements when installing compose.\n\n* Add recommendation to avoid the statically linked docker binary if\n  possible (I had kernel incompatibilities when trying this)\n\nMinor:\n* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""\n\n* Fix some typos\n\nChange-Id: I3d25ac47ed1f60cb23cf9f528119366a5e31d434\n'}, {'number': 2, 'created': '2015-06-08 08:59:39.000000000', 'files': ['docs/ansible-deployment.md', 'docs/dev-quickstart.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/fb66053f09e07b69ed4377698df9a1637c04c5c4', 'message': 'Documentation improvements and minor fixups\n\n* Move the Ansible README under the docs/ dir to make it more visible\nto people browsing the docs.\n\n* Add a paragraph explaining the provided inventory files.\n\n* Add note to ensure user updates the koalla_directory var to match\n  their environment.\n\n* Add paragraph on some basic requirements for those using Vagrant.\n\n* Add missing command for pip requirements when installing compose.\n\n* Add recommendation to avoid the statically linked docker binary if\n  possible (I had kernel incompatibilities when trying this)\n\nMinor:\n* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""\n\n* Fix some typos\n\nChange-Id: I3d25ac47ed1f60cb23cf9f528119366a5e31d434\n'}]",12,188742,fb66053f09e07b69ed4377698df9a1637c04c5c4,22,7,2,1390,,,0,"Documentation improvements and minor fixups

* Move the Ansible README under the docs/ dir to make it more visible
to people browsing the docs.

* Add a paragraph explaining the provided inventory files.

* Add note to ensure user updates the koalla_directory var to match
  their environment.

* Add paragraph on some basic requirements for those using Vagrant.

* Add missing command for pip requirements when installing compose.

* Add recommendation to avoid the statically linked docker binary if
  possible (I had kernel incompatibilities when trying this)

Minor:
* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""

* Fix some typos

Change-Id: I3d25ac47ed1f60cb23cf9f528119366a5e31d434
",git fetch https://review.opendev.org/openstack/kolla refs/changes/42/188742/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/ansible-deployment.md', 'docs/dev-quickstart.md']",2,829ec754c32ac9579c22eea5f1e6d8a5513e278c,doc-fixups,"A [Vagrant][] environment can be very useful for testing out Kolla. If you choose this method, ensure you allocate at least 8192 MB of memory, and approx 10GB of hard disk space for the box. [Vagrant]: https://www.vagrantup.com/ sudo pip install -r requirements.txtIt is recommended that use the 1.6.0 packages that are provided by your [distro][], however, if these are unavailable, you can try the Docker 1.6.0 binary provided by Docker Inc.: sudo yum install python-keystoneclient python-glanceclient \ python-novaclient python-heatclient python-neutronclientThis environment will start up the OpenStack services listed in the[distro]: https://docs.docker.com/installation/ example with an Intel driver, the interface is enp1s0. The interface nameThe `start` command to Kolla is responsible for starting the containers","Next, download and run the Docker 1.6.0 binary provided by Docker Inc.: sudo yum install python-keystoneclient python-glanceclient \ python-novaclient python-heatclient python-neutronclientThis environment will start up the openstack services listed in theexmaple with an Intel driver, the interface is enp1s0. The interface nameThe `start` command to kolla is responsible for starting the containers",29,12
openstack%2Fgrenade~master~I0c2d79800f001ebc3120d12d739c7fbb6a609a5a,openstack/grenade,master,I0c2d79800f001ebc3120d12d739c7fbb6a609a5a,Modify cinder api-paste.ini file on Kilo upgrade,ABANDONED,2015-03-05 10:54:19.000000000,2015-06-11 08:40:19.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 7198}, {'_account_id': 13636}]","[{'number': 1, 'created': '2015-03-05 10:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/b4cc7b65358a602f1fa9b66dad57f88605ca7e81', 'message': 'Modify cinder api-paste.ini file on Kilo upgrade\n\nThis change will allow upgdate cinder to modify the cinder\napi-paste.ini file to use oslo.middleware instead of\nopenstack.common.middleware.\n\nChange-Id: I0c2d79800f001ebc3120d12d739c7fbb6a609a5a\nDepends-On: I43f4ebfc3f30d064236d570638d2dda09af4fbe9\n'}, {'number': 2, 'created': '2015-03-05 16:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/1e7f4ebf5f25a09e52f1f471cecebb46fb649ee6', 'message': 'Modify cinder api-paste.ini file on Kilo upgrade\n\nThis change will allow upgdate cinder to modify the cinder\napi-paste.ini file to use oslo.middleware instead of\nopenstack.common.middleware.\n\nThis change is required to enable Cinder moving from the\nold oslo-incubator based middleware to the oslo.middleware\nlibrary.\n\nChange-Id: I0c2d79800f001ebc3120d12d739c7fbb6a609a5a\nDepends-On: I43f4ebfc3f30d064236d570638d2dda09af4fbe9\n'}, {'number': 3, 'created': '2015-03-05 17:48:02.000000000', 'files': ['from-juno/upgrade-cinder'], 'web_link': 'https://opendev.org/openstack/grenade/commit/22fe3704a2a87982721078055cef3bd111e5756b', 'message': 'Modify cinder api-paste.ini file on Kilo upgrade\n\nThis change will allow upgdate cinder to modify the cinder\napi-paste.ini file to use oslo.middleware instead of\nopenstack.common.middleware.\n\nThis change is required to enable Cinder moving from the\nold oslo-incubator based middleware to the oslo.middleware\nlibrary.\n\nDocumentation has been add in the Kilo Release Notes.\n\nhttps://wiki.openstack.org/wiki/ReleaseNotes/Kilo#Upgrade_Notes_7\n\nChange-Id: I0c2d79800f001ebc3120d12d739c7fbb6a609a5a\nDepends-On: I43f4ebfc3f30d064236d570638d2dda09af4fbe9\n'}]",1,161677,22fe3704a2a87982721078055cef3bd111e5756b,16,6,3,13636,,,0,"Modify cinder api-paste.ini file on Kilo upgrade

This change will allow upgdate cinder to modify the cinder
api-paste.ini file to use oslo.middleware instead of
openstack.common.middleware.

This change is required to enable Cinder moving from the
old oslo-incubator based middleware to the oslo.middleware
library.

Documentation has been add in the Kilo Release Notes.

https://wiki.openstack.org/wiki/ReleaseNotes/Kilo#Upgrade_Notes_7

Change-Id: I0c2d79800f001ebc3120d12d739c7fbb6a609a5a
Depends-On: I43f4ebfc3f30d064236d570638d2dda09af4fbe9
",git fetch https://review.opendev.org/openstack/grenade refs/changes/77/161677/1 && git format-patch -1 --stdout FETCH_HEAD,['from-juno/upgrade-cinder'],1,b4cc7b65358a602f1fa9b66dad57f88605ca7e81,cinder,#!/usr/bin/env bash # ``upgrade-cinder`` function configure_cinder_upgrade { XTRACE=$(set +o | grep xtrace) set -o xtrace sed -i 's/cinder.openstack.common.middleware/oslo.middleware/g' $CINDER_API_PASTE_INI sed -i 's/RequestIdMiddleware/RequestId/g' $CINDER_API_PASTE_INI ## reset to previous state $XTRACE } ,,15,0
openstack%2Fironic~master~If13c6b8d3f3abec12748f903227cdb553f8ee9f1,openstack/ironic,master,If13c6b8d3f3abec12748f903227cdb553f8ee9f1,Install guide reflects changes on master branch,MERGED,2015-06-08 15:01:35.000000000,2015-06-11 08:36:01.000000000,2015-06-11 08:35:58.000000000,"[{'_account_id': 3}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11680}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-06-08 15:01:35.000000000', 'files': ['doc/source/deploy/install-guide.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0c80cae0f9d0cec26984e602436a7ca65b0a3a76', 'message': 'Install guide reflects changes on master branch\n\nThis updates the install guide so that it reflects the changes we\nare doing on master branch for the Liberty release, instead of for\nthe Kilo release.\n\nChange-Id: If13c6b8d3f3abec12748f903227cdb553f8ee9f1\n'}]",0,189327,0c80cae0f9d0cec26984e602436a7ca65b0a3a76,12,6,1,6618,,,0,"Install guide reflects changes on master branch

This updates the install guide so that it reflects the changes we
are doing on master branch for the Liberty release, instead of for
the Kilo release.

Change-Id: If13c6b8d3f3abec12748f903227cdb553f8ee9f1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/27/189327/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deploy/install-guide.rst'],1,0c80cae0f9d0cec26984e602436a7ca65b0a3a76,install-doc,This document pertains to the current code (on master branch) of OpenStack Ironic and should be accurate for the Kilo (2015.1) release of OpenStack Ironic. Usersyou review all the `available options <https://git.openstack.org/cgit/openstack/ironic/tree/etc/ironic/ironic.conf.sample>`_,This document pertains to the Kilo (2015.1) release of OpenStack Ironic. Usersyou review all the `available options <http://docs.openstack.org/kilo/config-reference/content/ch_configuring-openstack-bare-metal.html>`_,3,2
openstack%2Fhorizon~master~I75259ef5d6715a077366b21fd42eb86834937b5d,openstack/horizon,master,I75259ef5d6715a077366b21fd42eb86834937b5d,Change 'Update Metadata' to specific name in modal header,MERGED,2015-06-05 09:24:03.000000000,2015-06-11 08:35:48.000000000,2015-06-11 08:35:46.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 16628}]","[{'number': 1, 'created': '2015-06-05 09:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f4659d4ce8b6c767bc4e6f3994d19cde39bd79d', 'message': ""Change 'Update Metadata' to specific name in modal header\n\nIn some update metadata modal, use 'Update {{specific name}}\n Metadata' much better than Update Metadata.\n\nChange-Id: I75259ef5d6715a077366b21fd42eb86834937b5d\nCloses-bug:#1462161\n""}, {'number': 2, 'created': '2015-06-08 00:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f038fa43c09ffbe392c499a8dceadc47ee25e996', 'message': ""Change 'Update Metadata' to specific name in modal header\n\nIn some update metadata modal, use 'Update {{specific name}}\n Metadata' much better than Update Metadata.\n\nChange-Id: I75259ef5d6715a077366b21fd42eb86834937b5d\nCloses-bug:#1462161\n""}, {'number': 3, 'created': '2015-06-10 15:31:15.000000000', 'files': ['openstack_dashboard/dashboards/admin/flavors/templates/flavors/_update_metadata.html', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/_update_metadata.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/63acde9643f8ad73446ae62ba440144ce4a40293', 'message': ""Change 'Update Metadata' to specific name in modal header\n\nIn some update metadata modal, use 'Update {{specific name}}\n Metadata' much better than Update Metadata.\n\nChange-Id: I75259ef5d6715a077366b21fd42eb86834937b5d\nCloses-bug:#1462161\n""}]",0,188713,63acde9643f8ad73446ae62ba440144ce4a40293,12,4,3,9961,,,0,"Change 'Update Metadata' to specific name in modal header

In some update metadata modal, use 'Update {{specific name}}
 Metadata' much better than Update Metadata.

Change-Id: I75259ef5d6715a077366b21fd42eb86834937b5d
Closes-bug:#1462161
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/188713/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/flavors/templates/flavors/_update_metadata.html', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/_update_metadata.html']",2,6f4659d4ce8b6c767bc4e6f3994d19cde39bd79d,fix-bug/1462161,"{% block modal-header %}{% trans ""Update Aggregate Metadata"" %}{% endblock %}","{% block modal-header %}{% trans ""Update Metadata"" %}{% endblock %}",2,2
openstack%2Fironic~master~I195f9142110540efa0951b5914e41de92804dc04,openstack/ironic,master,I195f9142110540efa0951b5914e41de92804dc04,Updated from global requirements,MERGED,2015-06-10 21:21:40.000000000,2015-06-11 08:35:44.000000000,2015-06-11 08:35:42.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-06-10 21:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4ce118261e7583d1e01ff65d475823057fd36e06', 'message': 'Updated from global requirements\n\nChange-Id: I195f9142110540efa0951b5914e41de92804dc04\n'}, {'number': 2, 'created': '2015-06-10 23:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9db63611fb4309ef331bed2d71943a3f92dd084', 'message': 'Updated from global requirements\n\nChange-Id: I195f9142110540efa0951b5914e41de92804dc04\n'}, {'number': 3, 'created': '2015-06-11 00:42:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b1f76e25ac858a7c43a2588aac748397fdc1293d', 'message': 'Updated from global requirements\n\nChange-Id: I195f9142110540efa0951b5914e41de92804dc04\n'}]",0,190357,b1f76e25ac858a7c43a2588aac748397fdc1293d,19,4,3,11131,,,0,"Updated from global requirements

Change-Id: I195f9142110540efa0951b5914e41de92804dc04
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/190357/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4ce118261e7583d1e01ff65d475823057fd36e06,openstack/requirements,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,1,1
openstack%2Fnova~master~Idb74d1900377f28c8c02a916a17a76215f142e3e,openstack/nova,master,Idb74d1900377f28c8c02a916a17a76215f142e3e,libvirt: introduce method to get domain XML,MERGED,2015-06-08 14:05:39.000000000,2015-06-11 08:35:20.000000000,2015-06-11 08:35:17.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8276}, {'_account_id': 8802}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-08 14:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6492f470b6b023b5fca84a474b92a189124c4aeb', 'message': 'libvirt: introduce method to get domain XML\n\nAdds method get_xml_desc to the Guest object and updates\nthe libvirt driver code to use it.\n\nChange-Id: Idb74d1900377f28c8c02a916a17a76215f142e3e\n'}, {'number': 2, 'created': '2015-06-09 15:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f807798cb73dbdc46c5fbd0176b0e149b820652', 'message': 'libvirt: introduce method to get domain XML\n\nAdds method get_xml_desc to the Guest object and updates\nthe libvirt driver code to use it.\n\nChange-Id: Idb74d1900377f28c8c02a916a17a76215f142e3e\n'}, {'number': 3, 'created': '2015-06-10 14:39:28.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a63e394ebbf7fd439cf4f8126c17278e94bbb6d1', 'message': 'libvirt: introduce method to get domain XML\n\nAdds method get_xml_desc to the Guest object and updates\nthe libvirt driver code to use it.\n\nChange-Id: Idb74d1900377f28c8c02a916a17a76215f142e3e\n'}]",0,189307,a63e394ebbf7fd439cf4f8126c17278e94bbb6d1,39,13,3,7730,,,0,"libvirt: introduce method to get domain XML

Adds method get_xml_desc to the Guest object and updates
the libvirt driver code to use it.

Change-Id: Idb74d1900377f28c8c02a916a17a76215f142e3e
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/189307/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,6492f470b6b023b5fca84a474b92a189124c4aeb,refactor-libvirt," def XMLDesc(self, flags): def XMLDesc(self, flags): def XMLDesc(self, flags): def XMLDesc(self, flags): vdmock.XMLDesc(flags=fakelibvirt.VIR_DOMAIN_XML_MIGRATABLE).AndReturn( vdmock.XMLDesc(flags=fakelibvirt.VIR_DOMAIN_XML_MIGRATABLE ).AndReturn(FakeVirtDomain().XMLDesc(flags=0)) vdmock.XMLDesc(flags=fakelibvirt.VIR_DOMAIN_XML_MIGRATABLE).AndReturn( FakeVirtDomain().XMLDesc(flags=0)) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) vdmock.XMLDesc(flags=0).AndReturn(dummyxml) flags=(fakelibvirt.VIR_DOMAIN_XML_INACTIVE | fakelibvirt.VIR_DOMAIN_XML_SECURE)) mock_dom.XMLDesc.assert_called_once_with(flags=( fakelibvirt.VIR_DOMAIN_XML_SECURE)) def XMLDesc(self, flags): domain.XMLDesc(flags=0).AndReturn(self.dom_xml) domain.XMLDesc(flags=0).AndReturn(self.dom_xml) domain.XMLDesc(flags=0).AndReturn(self.dom_xml) domain.XMLDesc(flags=0).AndReturn(self.dom_xml) domain.XMLDesc(flags=0).AndReturn(self.dom_xml) domain.XMLDesc(flags=0).AndReturn(self.dom_xml) def XMLDesc(self, flags): domain.XMLDesc(flags=0).AndReturn(self.dom_netdisk_xml) def XMLDesc(self, flags): domain.XMLDesc(flags=0).AndReturn(self.dom_netdisk_xml) def XMLDesc(self, flags): domain.XMLDesc(flags=0).AndReturn(self.dom_netdisk_xml) def XMLDesc(self, flags): domain.XMLDesc(flags=0).AndReturn(self.dom_netdisk_xml)"," def XMLDesc(self, *args): def XMLDesc(self, *args): def XMLDesc(self, flag): def XMLDesc(self, flag): vdmock.XMLDesc(fakelibvirt.VIR_DOMAIN_XML_MIGRATABLE).AndReturn( vdmock.XMLDesc(fakelibvirt.VIR_DOMAIN_XML_MIGRATABLE).AndReturn( FakeVirtDomain().XMLDesc(0)) vdmock.XMLDesc(fakelibvirt.VIR_DOMAIN_XML_MIGRATABLE).AndReturn( FakeVirtDomain().XMLDesc(0)) vdmock.XMLDesc(0).AndReturn(dummyxml) vdmock.XMLDesc(0).AndReturn(dummyxml) vdmock.XMLDesc(0).AndReturn(dummyxml) vdmock.XMLDesc(0).AndReturn(dummyxml) vdmock.XMLDesc(0).AndReturn(dummyxml) vdmock.XMLDesc(0).AndReturn(dummyxml) vdmock.XMLDesc(0).AndReturn(dummyxml) fakelibvirt.VIR_DOMAIN_XML_INACTIVE | fakelibvirt.VIR_DOMAIN_XML_SECURE) mock_dom.XMLDesc.assert_called_once_with( fakelibvirt.VIR_DOMAIN_XML_SECURE) def XMLDesc(self, *args): domain.XMLDesc(0).AndReturn(self.dom_xml) domain.XMLDesc(0).AndReturn(self.dom_xml) domain.XMLDesc(0).AndReturn(self.dom_xml) domain.XMLDesc(0).AndReturn(self.dom_xml) domain.XMLDesc(0).AndReturn(self.dom_xml) domain.XMLDesc(0).AndReturn(self.dom_xml) def XMLDesc(self, *args): domain.XMLDesc(0).AndReturn(self.dom_netdisk_xml) def XMLDesc(self, *args): domain.XMLDesc(0).AndReturn(self.dom_netdisk_xml) def XMLDesc(self, *args): domain.XMLDesc(0).AndReturn(self.dom_netdisk_xml) def XMLDesc(self, *args): domain.XMLDesc(0).AndReturn(self.dom_netdisk_xml)",126,74
openstack%2Fnova~master~Ie39d3feba654c487abdd300687e9a243c84ab5cf,openstack/nova,master,Ie39d3feba654c487abdd300687e9a243c84ab5cf,libvirt: introduce method detach_device to Guest object,MERGED,2015-06-05 13:02:18.000000000,2015-06-11 08:34:56.000000000,2015-06-11 08:34:52.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8276}, {'_account_id': 8802}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-05 13:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca42ea6a5c48e98363279671eb17c3f3e4a1714f', 'message': 'libvirt: introduce method detach_device to Guest object\n\nAdds method detach_device to the Guest object and updates the\nlibvirt driver code to use it.\nAlso updates methods _detach_pci_devices and\n_detach_sriov_ports to use a Guest object.\n\nChange-Id: Ie39d3feba654c487abdd300687e9a243c84ab5cf\n'}, {'number': 2, 'created': '2015-06-05 13:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4bc83adc0d6240e57d4531b1f7b5daabb098980', 'message': 'libvirt: introduce method detach_device to Guest object\n\nAdds method detach_device to the Guest object and updates the\nlibvirt driver code to use it.\nAlso updates methods _detach_pci_devices and\n_detach_sriov_ports to use a Guest object.\n\nChange-Id: Ie39d3feba654c487abdd300687e9a243c84ab5cf\n'}, {'number': 3, 'created': '2015-06-08 08:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90f5c6bd565ebd1236a64c29bf052f5e74b0b3dd', 'message': 'libvirt: introduce method detach_device to Guest object\n\nAdds method detach_device to the Guest object and updates the\nlibvirt driver code to use it.\nAlso updates methods _detach_pci_devices and\n_detach_sriov_ports to use a Guest object.\n\nChange-Id: Ie39d3feba654c487abdd300687e9a243c84ab5cf\n'}, {'number': 4, 'created': '2015-06-09 15:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b44b570b8167cae2cfc5a2af1cf070685611ae1', 'message': 'libvirt: introduce method detach_device to Guest object\n\nAdds method detach_device to the Guest object and updates the\nlibvirt driver code to use it.\nAlso updates methods _detach_pci_devices and\n_detach_sriov_ports to use a Guest object.\n\nChange-Id: Ie39d3feba654c487abdd300687e9a243c84ab5cf\n'}, {'number': 5, 'created': '2015-06-10 14:39:28.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py', 'nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/63649ece28a779ecc3ada6b08e70cde548a4e3c8', 'message': 'libvirt: introduce method detach_device to Guest object\n\nAdds method detach_device to the Guest object and updates the\nlibvirt driver code to use it.\nAlso updates methods _detach_pci_devices and\n_detach_sriov_ports to use a Guest object.\n\nChange-Id: Ie39d3feba654c487abdd300687e9a243c84ab5cf\n'}]",0,188765,63649ece28a779ecc3ada6b08e70cde548a4e3c8,48,12,5,7730,,,0,"libvirt: introduce method detach_device to Guest object

Adds method detach_device to the Guest object and updates the
libvirt driver code to use it.
Also updates methods _detach_pci_devices and
_detach_sriov_ports to use a Guest object.

Change-Id: Ie39d3feba654c487abdd300687e9a243c84ab5cf
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/188765/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_guest.py', 'nova/virt/libvirt/guest.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,ca42ea6a5c48e98363279671eb17c3f3e4a1714f,refactor-libvirt," def detachDeviceFlags(self, xml, flags): guest = libvirt_guest.Guest(FakeDomain()) drvr._detach_pci_devices(guest, pci_devices) def detachDeviceFlags(self, xml, flags): guest = libvirt_guest.Guest(FakeDomain()) drvr._detach_pci_devices, guest, pci_devices)"""""", flags=flags) guest = libvirt_guest.Guest(domain) drvr._detach_sriov_ports(self.context, instance, guest)"," def detachDeviceFlags(self, xml, flag): drvr._detach_pci_devices(FakeDomain(), pci_devices) def detachDeviceFlags(self, xml, flag): drvr._detach_pci_devices, FakeDomain(), pci_devices)"""""", flags) drvr._detach_sriov_ports(self.context, instance, domain)",92,50
openstack%2Fpython-openstackclient~master~I3fa8f29edb3fc430d453bd0fc835312c0c8401f4,openstack/python-openstackclient,master,I3fa8f29edb3fc430d453bd0fc835312c0c8401f4,Skip trying to set project_domain_id if not using password,MERGED,2015-06-11 06:45:17.000000000,2015-06-11 08:19:38.000000000,2015-06-11 08:19:37.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-06-11 06:45:17.000000000', 'files': ['openstackclient/common/clientmanager.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aac0d588bd83b51cd2f4b36b22741497fb39d79f', 'message': 'Skip trying to set project_domain_id if not using password\n\nThis is already fine for user_domain_id, and needs to be replicated\nfor project_domain_id. Also added more logging.\n\nChange-Id: I3fa8f29edb3fc430d453bd0fc835312c0c8401f4\n'}]",1,190509,aac0d588bd83b51cd2f4b36b22741497fb39d79f,7,2,1,6482,,,0,"Skip trying to set project_domain_id if not using password

This is already fine for user_domain_id, and needs to be replicated
for project_domain_id. Also added more logging.

Change-Id: I3fa8f29edb3fc430d453bd0fc835312c0c8401f4
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/09/190509/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/common/clientmanager.py'],1,aac0d588bd83b51cd2f4b36b22741497fb39d79f,fix, self.auth_plugin_name.endswith('password') and LOG.debug('Using parameters %s' % self._auth_params),,2,0
openstack%2Fopenstack-manuals~master~Ic8bb5271613cacad7d495abe59b99c786f8f8756,openstack/openstack-manuals,master,Ic8bb5271613cacad7d495abe59b99c786f8f8756,Imported Translations from Transifex,MERGED,2015-06-11 06:16:13.000000000,2015-06-11 08:19:30.000000000,2015-06-11 08:19:29.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 06:16:13.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/user-guide-admin/source/locale/user-guide-admin.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/glossary/locale/de.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/user-guide-admin.po', 'doc/install-guide/locale/vi_VN.po', 'doc/networking-guide/source/locale/networking-guide.pot', 'doc/glossary/locale/zh_CN.po', 'doc/common/locale/ja.po', 'doc/glossary/locale/es.po', 'doc/glossary/locale/glossary.pot', 'doc/glossary/locale/fr.po', 'doc/install-guide/locale/pt_BR.po', 'doc/glossary/locale/vi_VN.po', 'doc/glossary/locale/ko_KR.po', 'doc/user-guide/source/locale/user-guide.pot', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a2fef6abd69611d5142b97b7c8fa142b2ddb0781', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ic8bb5271613cacad7d495abe59b99c786f8f8756\n'}]",0,190500,a2fef6abd69611d5142b97b7c8fa142b2ddb0781,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ic8bb5271613cacad7d495abe59b99c786f8f8756
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/00/190500/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/user-guide-admin/source/locale/user-guide-admin.pot', 'doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/glossary/locale/de.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/user-guide-admin.po', 'doc/install-guide/locale/vi_VN.po', 'doc/networking-guide/source/locale/networking-guide.pot', 'doc/glossary/locale/zh_CN.po', 'doc/common/locale/ja.po', 'doc/glossary/locale/es.po', 'doc/glossary/locale/glossary.pot', 'doc/glossary/locale/fr.po', 'doc/install-guide/locale/pt_BR.po', 'doc/glossary/locale/vi_VN.po', 'doc/glossary/locale/ko_KR.po', 'doc/user-guide/source/locale/user-guide.pot', 'doc/glossary/locale/ja.po']",18,a2fef6abd69611d5142b97b7c8fa142b2ddb0781,transifex/translations,"""POT-Creation-Date: 2015-06-11 02:28+0000\n"" ""PO-Revision-Date: 2015-06-11 05:25+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""""A collection of servers that can share IPs with other members of the group. "" ""Any server in a group can share one or more public IPs with any other server "" ""in the group. With the exception of the first server in a shared IP group, "" ""servers must be launched into shared IP groups. A server may be a member of "" ""only one shared IP group."" msgstr """" ""グループの他のメンバーと IP を共有できるサーバー群。グループ内のサーバーは、"" ""そのグループ内の他のサーバーと 1 つ以上のパブリック IP を共有できる。共有 IP "" ""グループにおける 1 番目のサーバーを除き、サーバーは共有 IP グループの中で起動"" ""する必要があります。サーバーは、共有 IP グループ 1 つだけのメンバーになれま"" ""す。"" msgid """"msgid """" ""A discrete OpenStack environment with dedicated API endpoints that typically "" ""shares only the Identity (keystone) with other regions."" msgstr """" ""専用の API エンドポイントを持つ、分離した OpenStack 環境。一般的に Identity "" ""(keystone) のみを他のリージョンと共有する。"" ""A domain within a parent domain. Subdomains cannot be registered. Subdomains "" ""enable you to delegate domains. Subdomains can themselves have subdomains, "" ""so third-level, fourth-level, fifth-level, and deeper levels of nesting are "" ""possible."" msgstr """" ""親ドメイン内のドメイン。サブドメインは登録できない。サブドメインによりドメイ"" ""ンを委譲できる。サブドメインは、サブドメインを持てるので、第 3 階層、第 4 階"" ""層、第 5 階層と深い階層構造にできる。"" msgid """"""A grouped release of projects related to OpenStack that came out in the fall "" ""of 2011, the fourth release of OpenStack. It included Compute (nova 2011.3), "" ""Object Storage (swift 1.4.3), and the Image service (glance)."" msgstr """" ""2011年秋に登場した OpenStack 関連プロジェクトのリリース。Compute (nova "" ""2011.3), Object Storage (swift 1.4.3), Image service (glance) が含まれる。"" msgid """" ""A high availability system design approach and associated service "" ""implementation ensures that a prearranged level of operational performance "" ""will be met during a contractual measurement period. High availability "" ""systems seeks to minimize system downtime and data loss."" msgstr """" ""高可用性システムの設計手法および関連サービスの実装により、契約された測定期間"" ""中、合意された運用レベルを満たします。高可用性システムは、システムの停止時間"" ""とデータ損失を最小化しようとします。"" msgid """"""with the Identity service.""msgid ""A list of VM images that are available through Image service."" msgstr ""Image service 経由で利用可能な仮想マシンイメージの一覧。""""A list of tenants that can access a given VM image within Image service.""""Image service 内で指定した仮想マシンイメージにアクセスできるテナントの一覧。""msgid ""Alphanumeric ID assigned to each Identity service role."" msgstr ""各 Identity service ロールに割り当てられる英数 ID。""""service, this is a call that is specific to the implementation, such as """"API 拡張やプラグインの別名。Identity service では、OpenID のサポートの追加な""msgid ""Alternative term for an Identity service catalog.""msgid ""Alternative term for an Identity service default token."" msgstr ""Identity service デフォルトトークンの別名。""msgid ""Alternative term for the Identity service API."" msgstr ""Identity service API の別名。"" msgid ""Alternative term for the Identity service catalog.""""An Identity service API access token that is associated with a specific ""msgstr ""特定のテナントに関連付けられた Identity service API アクセストークン。""""An Identity service API endpoint that is associated with one or more tenants.""""1 つ以上のテナントと関連付けられた Identity service API エンドポイント。""""An Identity service component that manages and validates tokens after a user """"ユーザーやテナントが認証された後、トークンを管理し、検証する Identity のコン"" ""ポーネント。""""An Identity service feature that enables services, such as Compute, to """"An Identity service that lists API endpoints that are available to a user "" ""after authentication with the Identity service.""""An Identity service token that is not associated with a specific tenant and """"create, modify, and audit. Do not confuse with OpenStack Identity service, """"An OpenStack service, such as Compute, Object Storage, or Image service. """"Compute、Object Storage、Image service などの OpenStack のサービス。ユーザー""""the Identity service.""""An easy method to create a local LDAP directory for testing Identity and "" ""Compute. Requires Redis.""""An official OpenStack project. Currently consists of Compute (nova), Object "" ""Storage (swift), Image service (glance), Identity (keystone), Dashboard "" ""(horizon), Networking (neutron), and Block Storage (cinder), the Telemetry "" ""module (ceilometer), Orchestration module (heat), Database service (trove), "" ""Bare Metal service (ironic), Data processing service (sahara). However, this "" ""definition is changing based on community discussions about the \""Big Tent\""."" msgstr """" ""OpenStack の公式プロジェクト。現在、 Compute (nova), Object Storage (swift), "" ""Image service (glance), Identity (keystone), Dashboard (horizon), Networking "" ""(neutron), and Block Storage (cinder), the Telemetry module (ceilometer), "" ""Orchestration module (heat), Database service (trove), Bare Metal service "" ""(ironic), Data processing service (sahara) がある。しかしながら、この定義は"" ""「Big Tent」に関するコミュニティーの議論に基づき変更されてきている。"" msgid ""An open source LDAP server. Supported by both Compute and Identity.""""and a private key. Currently not supported in Identity.""""では現在サポートされていない。""msgid ""Both a VM container format and disk format. Supported by Image service.""""仮想マシンのコンテナー形式とディスク形式の両方。Image service によりサポート""""Component of Identity that provides a rule-management interface and a rule-"" ""based authorization engine.""""ルール管理インターフェースやルールベースの認可エンジンを提供する Identity の"" ""コンポーネント。""msgid ""Element of RabbitMQ that provides a response to an incoming MQ message."" msgstr ""送信されてきた MQ メッセージに応答する RabbitMQ の要素。"" msgid ""Identity service API"" msgstr ""Identity service API"" ""In Identity, each user is associated with one or more tenants, and in "" ""Compute can be associated with roles, projects, or both.""""Identity では、各ユーザーが 1 つ以上のテナントに関連付けられます。Compute で"" ""は、ロール、プロジェクトに関連付けられます。""""In the context of the Identity service, the worker process that provides ""msgstr ""Identity の領域で、管理 API へのアクセスを提供するワーカープロセス。""msgid ""One of the VM image disk formats supported by Image service.""""Image service によりサポートされる、仮想マシンイメージディスク形式の 1 つ。""msgid """" ""Open vSwitch is a production quality, multilayer virtual switch licensed "" ""under the open source Apache 2.0 license. It is designed to enable massive "" ""network automation through programmatic extension, while still supporting "" ""standard management interfaces and protocols (for example NetFlow, sFlow, "" ""SPAN, RSPAN, CLI, LACP, 802.1ag)."" msgstr """" ""Open vSwitch は、商用品質、複数階層の仮想スイッチ。オープンソースの Apache "" ""2.0 license に基づき許諾される。標準的な管理インターフェースやプロトコルと使"" ""用ながら、プログラム拡張により大規模なネットワーク自動化を実現できるよう設計"" ""されている (例えば、NetFlow、sFlow、SPAN、RSPAN、CLI、LACP、802.1ag)。"" ""OpenStack is a cloud operating system that controls large pools of compute, "" ""storage, and networking resources throughout a data center, all managed "" ""through a dashboard that gives administrators control while empowering their "" ""users to provision resources through a web interface. OpenStack is an open "" ""source project licensed under the Apache License 2.0."" msgstr """" ""OpenStack は、データセンター全体のコンピュートリソース、ストレージリソース、"" ""ネットワークリソースの大規模なプールを制御する、クラウドオペレーティングシス"" ""テム。管理者はすべてダッシュボードから制御できる。ユーザーは Web インター"" ""フェースからリソースを配備できる。Apache License 2.0 に基づき許諾されるオープ"" ""ンソースのプロジェクト。"" msgid """" ""OpenStack project that produces a set of Python libraries containing code "" ""shared by OpenStack projects."" msgstr """" ""OpenStack プロジェクトに共有されるコードを含む Python ライブラリー群を作成す"" ""る OpenStack プロジェクト。"" msgid """"msgid """" ""OpenStack project that provides a key-value store for applications running "" ""in an OpenStack cloud. The code name for the project is magnetoDB."" msgstr """" ""OpenStack 上のアプリケーションにキーバリューストアを提供する OpenStack プロ"" ""ジェクト。このプロジェクトのコード名は magnetoDB。"" ""Principal communications protocol in the internet protocol suite for "" ""relaying datagrams across network boundaries."" msgstr """" ""ネットワーク境界を越えてデータグラムを中継するための、インターネットプロトコ"" ""ルにおける中心的な通信プロトコル。"" msgid """"""Provides a predefined list of actions that the user can perform, such as "" ""start or stop VMs, reset passwords, and so on. Supported in both Identity "" ""and Compute and can be configured using the horizon dashboard."" msgstr """" ""仮想マシンの起動や停止、パスワードの初期化など、ユーザーが実行できる操作の事"" ""前定義済み一覧を提供する。Identity と Compute においてサポートされる。ダッ"" ""シュボードを使用して設定できる。"" msgid """"msgid ""Specifies the authentication source used by Image service or Identity.""""Term used in the OSI network architecture for the data link layer. The data "" ""link layer is responsible for media access control, flow control and "" ""detecting and possibly correcting errors that may occur in the physical "" ""layer."" msgstr """" ""OSI ネットワークアーキテクチャーにおけるデータリンク層に使用される用語。デー"" ""タリンク層は、メディアアクセス制御、フロー制御、物理層で発生する可能性のある"" ""エラー検知、できる限りエラー訂正に責任を持つ。"" msgid """" ""Term used in the OSI network architecture for the network layer. The network "" ""layer is responsible for packet forwarding including routing from one node "" ""to another."" msgstr """" ""OSI ネットワークアーキテクチャーにおけるネットワーク層に使用される用語。ネッ"" ""トワーク層は、パケット転送、あるノードから別のノードへのルーティングに責任を"" ""持つ。"" msgid """"""The API used to access the OpenStack Identity service provided through """"The Compute direct exchanges, fanout exchanges, and topic exchanges use this "" ""key to determine how to process a message; processing varies depending on "" ""exchange type."" msgstr """" ""Compute の直接交換、ファンアウト交換、トピック交換は、このキーを使用して、"" ""メッセージを処理する方法を判断する。処理内容は交換形式に応じて変化する。"" msgid """"msgid ""The Identity component that provides high-level authorization services."" msgstr ""高レベルの認可サービスを提供する Identity のコンポーネント。"" msgid ""The Identity service component that provides authentication services."" msgstr ""認証サービスを提供する Identity のコンポーネント。""""The Identity service endpoint template that contains services available to """"OpenLDAP, OpenStack Identity, and so on.""""name of Identity is keystone.""msgid """" ""The OpenStack core project that provides eventually consistent and redundant "" ""storage and retrieval of fixed digital content. The project name of "" ""OpenStack Object Storage is swift."" msgstr """" ""結果整合性（eventually consistent）、ストレージ冗長化、静的デジタルコンテンツ"" ""取得、といった機能を提供する、OpenStack のコアプロジェクト。OpenStack Object "" ""Storage のプロジェクト名は swift。"" msgid """" ""The cooperative threading model used by Python; reduces race conditions and "" ""only context switches when specific library calls are made. Each OpenStack "" ""service is its own thread."" msgstr """" ""Python により使用される協調スレッドモデル。特定のライブラリーコールが発行され"" ""るときの競合状態とコンテキストスイッチを減らす。各 OpenStack サービスは自身の"" ""スレッドである。"" ""The primary load balancing configuration object. Specifies the virtual IP "" ""address and port where client traffic is received. Also defines other "" ""details such as the load balancing method to be used, protocol, and so on. "" ""This entity is sometimes known in load-balancing products as a virtual "" ""server, vserver, or listener."" msgstr """" ""主たる負荷分散の設定オブジェクト。クライアント通信を受け付ける仮想 IP とポー"" ""トを指定する。使用する負荷分散方式、プロトコルなどの詳細も定義する。このエン"" ""ティティは、virtual server、vserver、listener のような負荷分散製品においても"" ""知られている。"" msgid """"""The source used by Identity service to retrieve user information; an """"The storage method used by the Identity service catalog service to store and """"Unique ID assigned to each service that is available in the Identity service """"Unique ID assigned to each tenant within the Identity service. The project """"Identity 内で各テナントに割り当てられる一意な ID。プロジェクト ID は、テナン"" ""ト ID に対応付けられる。""""Unique numeric ID associated with each user in Identity, conceptually "" ""similar to a Linux or LDAP UID.""""Identity で各ユーザーと関連付けられた一意な数値 ID。概念として、Linux や "" ""LDAP の UID を同じ。""","""POT-Creation-Date: 2015-06-10 05:08+0000\n"" ""PO-Revision-Date: 2015-06-10 05:38+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""""with the Identity Service.""msgid ""A list of VM images that are available through Image Service."" msgstr ""Image Service 経由で利用可能な仮想マシンイメージの一覧。""""A list of tenants that can access a given VM image within Image Service.""""Image Service 内で指定した仮想マシンイメージにアクセスできるテナントの一覧。""msgid ""Alphanumeric ID assigned to each Identity Service role."" msgstr ""各 Identity Service ロールに割り当てられる英数 ID。""""Service, this is a call that is specific to the implementation, such as """"API 拡張やプラグインの別名。Identity Service では、OpenID のサポートの追加な""msgid ""Alternative term for an Identity Service catalog.""msgid ""Alternative term for an Identity Service default token."" msgstr ""Identity Service デフォルトトークンの別名。""msgid ""Alternative term for the Identity Service API."" msgstr ""Identity サービス API の別名。"" msgid ""Alternative term for the Identity Service catalog.""""An Identity Service API access token that is associated with a specific ""msgstr ""特定のテナントに関連付けられた Identity Service API アクセストークン。""""An Identity Service API endpoint that is associated with one or more tenants.""""1 つ以上のテナントと関連付けられた Identity Service API エンドポイント。""""An Identity Service component that manages and validates tokens after a user """"ユーザーやテナントが認証された後、トークンを管理し、検証する Identity "" ""Service のコンポーネント。""""An Identity Service feature that enables services, such as Compute, to """"An Identity Service that lists API endpoints that are available to a user "" ""after authentication with the Identity Service.""""An Identity Service token that is not associated with a specific tenant and """"create, modify, and audit. Do not confuse with OpenStack Identity Service, """"An OpenStack service, such as Compute, Object Storage, or Image Service. """"Compute、Object Storage、Image Service などの OpenStack のサービス。ユーザー""""the Identity Service.""""An easy method to create a local LDAP directory for testing Identity Service "" ""and Compute. Requires Redis.""""An open source LDAP server. Supported by both Compute and Identity Service.""""An option within Compute that enables administrators to create and manage "" ""users through the <literal>nova-manage</literal> command as opposed to using "" ""the Identity Service."" msgstr """" ""管理者が、Identity を使用する代わりに、<literal>nova-manage</literal> コマン"" ""ド経由でユーザーを作成および管理できる、Compute 内のオプション。"" msgid """"""and a private key. Currently not supported in Identity Service.""""Service では現在サポートされていない。""msgid ""Both a VM container format and disk format. Supported by Image Service.""""仮想マシンのコンテナー形式とディスク形式の両方。Image Service によりサポート""""Checks for and deletes unused VMs; the component of Image Service that "" ""implements delayed delete."" msgstr """" ""未使用の仮想マシンを確認し、削除する。遅延削除を実装する、Image Service のコ"" ""ンポーネント。"" msgid """"""Collection of Compute components that represent the global state of the "" ""cloud; talks to services, such as Identity Service authentication, Object "" ""Storage, and node/storage workers through a queue."" msgstr """" ""クラウドの全体状況を表す Compute コンポーネント群。キュー経由で、Identity の"" ""認証、Object Storage、ノード/ストレージワーカーなどのサービスと通信する。"" msgid """"""Component of Identity Service that provides a rule-management interface and "" ""a rule-based authorization engine.""""ルール管理インターフェースやルールベースの認可エンジンを提供する Identity "" ""Service のコンポーネント。""msgid ""Identity Service"" msgstr ""Identity サービス"" msgid ""Identity Service API"" msgstr ""Identity サービス API"" ""In Identity Service, each user is associated with one or more tenants, and "" ""in Compute can be associated with roles, projects, or both.""""Identity Service では、各ユーザーが 1 つ以上のテナントに関連付けられます。"" ""Compute では、ロール、プロジェクトに関連付けられます。""""In the context of the Identity Service, the worker process that provides ""msgstr """" ""Identity Service の領域で、管理 API へのアクセスを提供するワーカープロセス。""msgid ""One of the VM image disk formats supported by Image Service.""""Image Service によりサポートされる、仮想マシンイメージディスク形式の 1 つ。""msgid """" ""Specifies the authentication source used by Image service or Identity "" ""Service.""""The API used to access the OpenStack Identity Service provided through ""msgid ""The Identity Service component that provides authentication services."" msgstr ""認証サービスを提供する Identity Service のコンポーネント。""""The Identity Service component that provides high-level authorization "" ""services."" msgstr ""高レベルの認可サービスを提供する Identity Service コンポーネント。"" msgid """" ""The Identity Service endpoint template that contains services available to """"OpenLDAP, OpenStack Identity Service, and so on.""""name of the Identity Service is keystone.""""The source used by Identity Service to retrieve user information; an """"The storage method used by the Identity Service catalog service to store and """"Unique ID assigned to each service that is available in the Identity Service """"Unique ID assigned to each tenant within the Identity Service. The project """"Identity Service 内で各テナントに割り当てられる一意な ID。プロジェクト ID "" ""は、テナント ID に対応付けられる。""""Unique numeric ID associated with each user in Identity Service, "" ""conceptually similar to a Linux or LDAP UID.""""Identity Service で各ユーザーと関連付けられた一意な数値 ID。概念として、"" ""Linux や LDAP の UID を同じ。""",8695,1110
openstack%2Fapi-site~master~I319f6af16b0f353b2a2c2460bce17f570e33142c,openstack/api-site,master,I319f6af16b0f353b2a2c2460bce17f570e33142c,Imported Translations from Transifex,MERGED,2015-06-11 06:03:40.000000000,2015-06-11 08:09:27.000000000,2015-06-11 08:09:26.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 06:03:40.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-quick-start/locale/pt_BR.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/cc2ec4015e2d3dd1376ad815d87c142e06fe9a2b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I319f6af16b0f353b2a2c2460bce17f570e33142c\n'}]",0,190494,cc2ec4015e2d3dd1376ad815d87c142e06fe9a2b,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I319f6af16b0f353b2a2c2460bce17f570e33142c
",git fetch https://review.opendev.org/openstack/api-site refs/changes/94/190494/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/locale/api-ref.pot', 'api-quick-start/locale/pt_BR.po']",2,cc2ec4015e2d3dd1376ad815d87c142e06fe9a2b,transifex/translations,"# Andre Campos Bezerra <andrecbezerra@gmail.com>, 2015""POT-Creation-Date: 2015-06-11 02:24+0000\n"" ""PO-Revision-Date: 2015-06-10 17:55+0000\n"" ""Last-Translator: Andre Campos Bezerra <andrecbezerra@gmail.com>\n""msgid ""Bad Request"" msgstr ""Falha em requisição"" msgid """" ""Request an authentication token from the Identity endpoint that your cloud "" ""administrator gave you. Send a payload of credentials in the request:"" msgstr """" ""Solicite um token de autenticação do endpoint de Identidade que o seu "" ""administrador de nuvem lhe deu. Envie a carga de credenciais na requisição:"" ","""POT-Creation-Date: 2015-05-26 14:28+0000\n"" ""PO-Revision-Date: 2015-05-21 10:44+0000\n"" ""Last-Translator: Guteemebrg Nunes <gutemhc@gmail.com>\n""",156,125
openstack%2Fnova~master~Ied7d47363d0489bca3cf2c711217e1a3b7d24a03,openstack/nova,master,Ied7d47363d0489bca3cf2c711217e1a3b7d24a03,"fix ""down"" nova-compute service spuriously marked as ""up""",MERGED,2015-03-10 15:54:59.000000000,2015-06-11 08:04:04.000000000,2015-06-11 08:04:01.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6450}, {'_account_id': 6802}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8412}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-10 15:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fa6d300b8bb94a365799286845f8d473589059e', 'message': 'Fix nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: There are broken unit tests still, but I wanted to get the\nbasic concept out for comments while I work on tidying it up.\n\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 2, 'created': '2015-03-10 18:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78af24105634212cf06341d3e7eb68c2af5718a6', 'message': 'Fix nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with _do_compute_node() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 3, 'created': '2015-03-11 14:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e693e229b0df07929b3cb319e31fa79ab05b2226', 'message': 'Fix nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with _do_compute_node() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 4, 'created': '2015-03-11 20:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b9022b483a06b02f16b9bae37f92933dca1f210', 'message': 'Fix nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with _do_compute_node() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 5, 'created': '2015-03-12 19:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0617f0fbe8dbeb2b0decfd02e856fc36241b291', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with _do_compute_node() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 6, 'created': '2015-03-12 20:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bfc5e89d061bdb7aba74f0160baa0af53ee6cc9', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with _do_compute_node() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 7, 'created': '2015-03-13 06:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fbd16a78b1677d5b3bc5b7e4ab845eacb1290224', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with obj_load_attr() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 8, 'created': '2015-03-13 18:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33d3d0845360796db13c5052569834d130dc0243', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with obj_load_attr() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 9, 'created': '2015-03-17 16:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57cb4213819f5e29f1f674c363ba394b15bb5151', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with obj_load_attr() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 10, 'created': '2015-03-21 05:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e26f10973729d5e90764c3d691b3cdc8b86d3683', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with obj_load_attr() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 11, 'created': '2015-03-23 22:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2170354153ddf01fd0d448becec99154886833c', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""update_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node.\n\nThe fix is to add a new field to explicitly track when the service\nsends in a status report and use that if available when testing\nwhether the service is up.\n\nNOTE: I feel like what I\'ve done with obj_load_attr() and\n_from_db_object() is a bit of a hack, but it lets me avoid modifying\nmany of the unit tests and I think it might help when upgrading.\nThoughts?\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 12, 'created': '2015-03-26 22:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c464548cf09925c3536606ba861128162551d759', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nWe also add a new conductor API call to explicitly report state.\nThis will update the ""last_updated_at"" field using the current\ntime as seen by nova-conductor.  This should minimize any issues\nwith compute node time not being in sync.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 13, 'created': '2015-03-27 16:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7a2d29f658ca101e4abf70b047dba3b1b404713', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 14, 'created': '2015-03-27 20:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/086e221facf37bf056ef17b18662d05d6c95ac09', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 15, 'created': '2015-03-28 03:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c4ca22061d3cbb8024b4ebab9fca78d254662c3', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 16, 'created': '2015-03-30 14:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1447f38d1e133879d0b28cb88c6e30cea2ccc306', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 17, 'created': '2015-04-10 23:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c9cf06ff6508e30bb3a3dceba58d9964a2f3b41', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 18, 'created': '2015-04-13 14:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86785819c175e7094ebf310a63bc38c335b31435', 'message': 'Fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 19, 'created': '2015-05-01 00:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/412d57d3f1f972e5380fa8faebd2cfbd0b08ef7e', 'message': 'ix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 20, 'created': '2015-05-01 03:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e02c2431c7afe9ab85865fd9c91dee06c553e277', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 21, 'created': '2015-05-01 03:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7966a225eac4c2b892c54f285c0f66c6db24c1b0', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 22, 'created': '2015-05-15 20:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7b7d77cbef87ab5edb293b23ffeb4e802a1e6e9', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 23, 'created': '2015-05-16 06:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a40df87fd7428942364a1f3073abc55c9763ae5', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by setting the service as ""down"" or ""up"", thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nThis does mean that ""nova service-list"" could show the service as\n""down"" even if it shows a recent ""updated_at"", but that could\nhappen for the other backends already.\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 24, 'created': '2015-05-21 07:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47cc6da3cdc3d787adccea990540c8626c14a7f2', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by disabling or enabling the service, thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nDocImpact\nThis commit will cause a behaviour change for the DB servicegroup\ndriver.  It will mean that enabling/disabling the service will\ncause the ""updated_at"" field to change (as before) but that will\nno longer be tied to the ""up/down"" status of the service. So\n""nova service-list"" could show the service as ""down"" even if it\nshows a recent ""updated_at"".  (But this could happen for the other\nservicegroup drivers already.)\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 25, 'created': '2015-06-10 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/861ddc4b186b59ec7008dcf4bd7b9929567b915d', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by disabling or enabling the service, thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nDocImpact\nThis commit will cause a behaviour change for the DB servicegroup\ndriver.  It will mean that enabling/disabling the service will\ncause the ""updated_at"" field to change (as before) but that will\nno longer be tied to the ""up/down"" status of the service. So\n""nova service-list"" could show the service as ""down"" even if it\nshows a recent ""updated_at"".  (But this could happen for the other\nservicegroup drivers already.)\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}, {'number': 26, 'created': '2015-06-10 19:18:19.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/294_add_service_heartbeat.py', 'nova/tests/unit/objects/test_objects.py', 'nova/db/sqlalchemy/models.py', 'nova/tests/unit/db/test_migrations.py', 'nova/servicegroup/drivers/db.py', 'nova/tests/unit/servicegroup/test_db_servicegroup.py', 'nova/objects/service.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/tests/unit/objects/test_service.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b9bae02af2168ad64d3b3d28c97c3853cee73272', 'message': 'fix ""down"" nova-compute service spuriously marked as ""up""\n\nCurrently we use the auto-updated ""updated_at"" field to determine\nwhether a service is ""up"".  An end-user can cause the ""updated_at""\nfield to be updated by disabling or enabling the service, thus\npotentially causing a service that is unavailable to be detected\nas ""up"".  This could result in the scheduler trying to assign\ninstances to an unavailable compute node, or in the system\nmistakenly preventing evacuation of an instance.\n\nThe fix is to add a new field to explicitly track the timestamp of\nthe last time the service sent in a status report and use that if\navailable when testing whether the service is up.\n\nDocImpact\nThis commit will cause a behaviour change for the DB servicegroup\ndriver.  It will mean that enabling/disabling the service will\ncause the ""updated_at"" field to change (as before) but that will\nno longer be tied to the ""up/down"" status of the service. So\n""nova service-list"" could show the service as ""down"" even if it\nshows a recent ""updated_at"".  (But this could happen for the other\nservicegroup drivers already.)\n\nCloses-Bug: #1420848\nChange-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03\n'}]",74,163060,b9bae02af2168ad64d3b3d28c97c3853cee73272,235,21,26,8768,,,0,"fix ""down"" nova-compute service spuriously marked as ""up""

Currently we use the auto-updated ""updated_at"" field to determine
whether a service is ""up"".  An end-user can cause the ""updated_at""
field to be updated by disabling or enabling the service, thus
potentially causing a service that is unavailable to be detected
as ""up"".  This could result in the scheduler trying to assign
instances to an unavailable compute node, or in the system
mistakenly preventing evacuation of an instance.

The fix is to add a new field to explicitly track the timestamp of
the last time the service sent in a status report and use that if
available when testing whether the service is up.

DocImpact
This commit will cause a behaviour change for the DB servicegroup
driver.  It will mean that enabling/disabling the service will
cause the ""updated_at"" field to change (as before) but that will
no longer be tied to the ""up/down"" status of the service. So
""nova service-list"" could show the service as ""down"" even if it
shows a recent ""updated_at"".  (But this could happen for the other
servicegroup drivers already.)

Closes-Bug: #1420848
Change-Id: Ied7d47363d0489bca3cf2c711217e1a3b7d24a03
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/163060/21 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/models.py', 'nova/tests/unit/db/test_migrations.py', 'nova/servicegroup/drivers/db.py', 'nova/tests/unit/servicegroup/test_db_servicegroup.py', 'nova/objects/service.py', 'nova/conductor/manager.py', 'nova/db/sqlalchemy/migrate_repo/versions/278_add_service_heartbeat.py']",7,4fa6d300b8bb94a365799286845f8d473589059e,bug/1420848,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from sqlalchemy import MetaData, Table, Column, DateTime BASE_TABLE_NAME = 'services' NEW_COLUMN_NAME = 'reported_at' def upgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine for prefix in ('', 'shadow_'): table = Table(prefix + BASE_TABLE_NAME, meta, autoload=True) new_column = Column(NEW_COLUMN_NAME, DateTime, nullable=True) if not hasattr(table.c, NEW_COLUMN_NAME): table.create_column(new_column) def downgrade(migrate_engine): meta = MetaData() meta.bind = migrate_engine for prefix in ('', 'shadow_'): table = Table(prefix + BASE_TABLE_NAME, meta, autoload=True) if hasattr(table.c, NEW_COLUMN_NAME): getattr(table.c, NEW_COLUMN_NAME).drop() ",,83,5
openstack%2Fnova-specs~master~Iba0d82e7c16eb4cfd5903ddb013c2b61bf22005f,openstack/nova-specs,master,Iba0d82e7c16eb4cfd5903ddb013c2b61bf22005f,"Expose ""last_seen_up"" when listing services",ABANDONED,2015-03-30 21:21:54.000000000,2015-06-11 07:57:05.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 8768}]","[{'number': 1, 'created': '2015-03-30 21:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ec824c49e928c7f9079b4bc229d10ddced07a192', 'message': 'Expose ""last_seen_up"" when listing services\n\nAssuming something like https://review.openstack.org/163060 gets merged, this\nblueprint simply covers adding the ""last_seen_up"" field as a property in the\nresponse to issuing a GET on /v2/{tenant-id}/os-services. The rationale for\ndoing this is that it\'s possible we could end up with a recent ""updated_at""\ntimestamp, but the service is considered as ""down"". Without exposing\n""last_seen_up"" the end-user can\'t tell why the service is considered ""down"".\n\nIf the value of ""last_seen_up"" is None, then we will set the value in the\nproperty to ""-"" to indicate that there was no meaningful information present.\n\nIt\'s a simple change, but since it\'s an API change a spec is needed.\n\nAPIImpact\n\nChange-Id: Iba0d82e7c16eb4cfd5903ddb013c2b61bf22005f\n'}, {'number': 2, 'created': '2015-04-11 00:25:52.000000000', 'files': ['specs/liberty/approved/expose-last-seen-up-listing-services.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/02d3dca7acf2532323f6ce3931c7191fee2bddd3', 'message': 'Expose ""last_seen_up"" when listing services\n\nAssuming something like https://review.openstack.org/163060 gets merged, this\nblueprint simply covers adding the ""last_seen_up"" field as a property in the\nresponse to issuing a GET on /v2/{tenant-id}/os-services. The rationale for\ndoing this is that it\'s possible we could end up with a recent ""updated_at""\ntimestamp, but the service is considered as ""down"". Without exposing\n""last_seen_up"" the end-user can\'t tell why the service is considered ""down"".\n\nIf the value of ""last_seen_up"" is None, then we will set the value in the\nproperty to ""-"" to indicate that there was no meaningful information present.\n\nIt\'s a simple change, but since it\'s an API change a spec is needed.\n\nAPIImpact\n\nImplements blueprint expose-last-seen-up-listing-services\n\nChange-Id: Iba0d82e7c16eb4cfd5903ddb013c2b61bf22005f\n'}]",2,169093,02d3dca7acf2532323f6ce3931c7191fee2bddd3,9,6,2,8768,,,0,"Expose ""last_seen_up"" when listing services

Assuming something like https://review.openstack.org/163060 gets merged, this
blueprint simply covers adding the ""last_seen_up"" field as a property in the
response to issuing a GET on /v2/{tenant-id}/os-services. The rationale for
doing this is that it's possible we could end up with a recent ""updated_at""
timestamp, but the service is considered as ""down"". Without exposing
""last_seen_up"" the end-user can't tell why the service is considered ""down"".

If the value of ""last_seen_up"" is None, then we will set the value in the
property to ""-"" to indicate that there was no meaningful information present.

It's a simple change, but since it's an API change a spec is needed.

APIImpact

Implements blueprint expose-last-seen-up-listing-services

Change-Id: Iba0d82e7c16eb4cfd5903ddb013c2b61bf22005f
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/93/169093/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/approved/expose-last-seen-up-listing-services.rst'],1,ec824c49e928c7f9079b4bc229d10ddced07a192,bp/simply,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Expose ""last_seen_up"" when listing services ============================================ https://blueprints.launchpad.net/nova/+spec/expose-last-seen-up-listing-services Assuming something like https://review.openstack.org/163060 gets merged, this blueprint simply covers adding the ""last_seen_up"" field as a property in the response to issuing a GET on /v2/{tenant-id}/os-services. The rationale for doing this is that it's possible we could end up with a recent ""updated_at"" timestamp, but the service is considered as ""down"". Without exposing ""last_seen_up"" the end-user can't tell why the service is considered ""down"". If the value of ""last_seen_up"" is None, then we will set the value in the property to ""-"" to indicate that there was no meaningful information present. It's a simple change, but since it's an API change a spec is needed. Problem description =================== Use Cases ---------- Bug #1420848 points out that the existing is_up() routine for the servicegroup DB driver is not reliable. (Someone disabling/enabling the service will cause it to be detected as ""up"" for some time. In response,git commit https://review.openstack.org/163060 proposes a new ""last_seen_up"" field in the service DB model, to be used by the servicegroup DB driver to track when the service reported itself as up (as opposed to when the DB row was updated, which could happen due to other reasons). Assuming something like that gets merged, then for the servicegroup DB driver the ""updated_at"" field in the output of doing a GET on /v2/{tenant-id}/os-services no longer has any real relevance as to whether or not the service is considered ""up"". Instead, it would be useful to report the ""last_seen_up"" field. Project Priority ----------------- Not a priority in liberty. Proposed change =============== The 2.4 microversion will be claimed and used to add the ""last_seen_up"" (or equivalent, if https://review.openstack.org/163060 gets modified) property to the response to a GET on /v2/{tenant-id}/os-services. If the value of ""last_seen_up"" is None, then we will set the value in the property to ""-"" to indicate that there was no meaningful information present. Alternatives ------------ If the servicegroup DB driver is being used we could override the existing ""updated_at"" field and report the ""last_seen_up"" timestamp in it. This would change the precise meaning of the field. Instead of ""the DB row was updated at this time"" it would mean ""the service reported its state at this time"". Alternately, in addition to adding the ""last_seen_up"" field we could remove the ""updated_at"" field at the same time since it is no longer meaningful for the servicegroup DB driver and never was meaningful for the other servicegroup drivers. Data model impact ----------------- None REST API impact --------------- Sample API for getting the service listing. The first service has been created but has not yet reported its state. This is also what it would look like if using a servicegroup driver other than the DB driver. (For now at least.) GET: /v2/{tenant-id}/os-services JSON Response:: { ""services"": [ { ""binary"": ""nova-scheduler"", ""disabled_reason"": null, ""host"": ""host2"", ""id"": 3, ""last_seen_up"": ""-"", ""state"": ""down"", ""status"": ""enabled"", ""updated_at"": ""2012-09-19T06:55:34.000000"", ""zone"": ""internal"" }, { ""binary"": ""nova-compute"", ""disabled_reason"": ""test4"", ""host"": ""host2"", ""id"": 4, ""last_seen_up"": ""2012-09-18T08:03:38.000000"", ""state"": ""down"", ""status"": ""disabled"", ""updated_at"": ""2012-09-18T08:03:38.000000"", ""zone"": ""nova"" } ] } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- python-novaclient will be updated to add the ""last_seen_up"" column when displaying the results of the ""nova service-list"" command. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: cbf123 Work Items ---------- * Basically already implemented under https://review.openstack.org/168418 but since it means an API change was told it needed a spec. Dependencies ============ * Assumes that something like https://review.openstack.org/163060 has been merged. Testing ======= Unit tests will be provided. Documentation Impact ==================== New property in the GET response as documented above. New column in python-novaclient as documented above. References ========== None ",,192,0
openstack%2Fnova-specs~master~Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1,openstack/nova-specs,master,Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1,Make fitler to support force_hosts/force_nodes,ABANDONED,2015-04-09 03:22:32.000000000,2015-06-11 07:56:48.000000000,,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 782}, {'_account_id': 6062}, {'_account_id': 11530}]","[{'number': 1, 'created': '2015-04-09 03:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c72455fe8c119b02717166b8acfeca369d414447', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 2, 'created': '2015-04-09 03:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/33b1ea978e592b3d4bde62a1ef8ca197ca41f5d6', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 3, 'created': '2015-04-09 03:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/af53a23b8fbb82e5a767d026490dd98590aa48b8', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 4, 'created': '2015-04-09 04:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/52de77a97536fc620606404eac35697f09946584', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 5, 'created': '2015-04-09 06:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5264ba9a9724fd945bf87376dda503b928c2009a', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 6, 'created': '2015-04-10 01:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3ca17f69b06c3962d6484fb667465fa4e09f050a', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 7, 'created': '2015-04-10 03:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/aa12da5ab0a5ccece7f9f8fa3c23937e7c1c25e5', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}, {'number': 8, 'created': '2015-04-10 07:13:44.000000000', 'files': ['specs/liberty/approved/filter-support-force-hosts.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f87cd64494a773adc715d44d5f997e3152c484c8', 'message': 'Make fitler to support force_hosts/force_nodes\n\nAdd an attribute for each filter and make some filters be executed\neven if the force_hosts/force_nodes options are set.\n\nChange-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1\nImplements: blueprint verifiable-force-hosts\n'}]",6,171917,f87cd64494a773adc715d44d5f997e3152c484c8,22,5,8,11530,,,0,"Make fitler to support force_hosts/force_nodes

Add an attribute for each filter and make some filters be executed
even if the force_hosts/force_nodes options are set.

Change-Id: Ibab41ffa1dcb74af5f914a0f5481cfffb13eb8d1
Implements: blueprint verifiable-force-hosts
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/17/171917/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/liberty/approved/filter-support-force-hosts.rst', 'specs/liberty/approved/liberty-template.rst']",2,c72455fe8c119b02717166b8acfeca369d414447,bp/verifiable-force-hosts,,../../liberty-template.rst,139,1
openstack%2Fhorizon~master~Idf96d43c8a6648b49f272caca93d15ea218f680c,openstack/horizon,master,Idf96d43c8a6648b49f272caca93d15ea218f680c,Imported Translations from Transifex,MERGED,2015-06-11 06:21:46.000000000,2015-06-11 07:56:32.000000000,2015-06-11 07:56:31.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-06-11 06:21:46.000000000', 'files': ['openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/729c36c38176ee122cc58d6db4b5d165e5b35cc3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Idf96d43c8a6648b49f272caca93d15ea218f680c\n'}]",0,190501,729c36c38176ee122cc58d6db4b5d165e5b35cc3,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Idf96d43c8a6648b49f272caca93d15ea218f680c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/01/190501/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'horizon/locale/ja/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po']",4,729c36c38176ee122cc58d6db4b5d165e5b35cc3,transifex/translations,"""POT-Creation-Date: 2015-06-11 01:21-0500\n""#: dashboards/project/firewalls/tables.py:307 #: dashboards/project/firewalls/tables.py:355#: dashboards/project/firewalls/tables.py:364#: dashboards/project/instances/templates/instances/_detail_overview.html:116#: dashboards/project/firewalls/tables.py:292#: dashboards/project/instances/views.py:396#: dashboards/project/stacks/forms.py:63#: dashboards/project/firewalls/tables.py:309 #: dashboards/project/firewalls/tables.py:357#: dashboards/project/instances/templates/instances/_detail_overview.html:121#: dashboards/project/firewalls/tables.py:370#: dashboards/project/firewalls/tables.py:289 #: dashboards/project/firewalls/tables.py:313 #: dashboards/project/firewalls/tables.py:319 #: dashboards/project/firewalls/tables.py:367#: dashboards/project/instances/templates/instances/_detail_overview.html:146#: dashboards/project/stacks/forms.py:62#: dashboards/project/stacks/forms.py:64#: dashboards/project/instances/views.py:410#: dashboards/project/instances/views.py:421#: dashboards/project/firewalls/tables.py:316#: dashboards/project/firewalls/tables.py:360#: dashboards/project/firewalls/tables.py:375#: dashboards/project/firewalls/tables.py:296#: dashboards/project/firewalls/tables.py:300 #: dashboards/project/firewalls/tables.py:311#: dashboards/project/firewalls/tables.py:324#: dashboards/project/firewalls/tables.py:333#: dashboards/project/firewalls/tables.py:335#: dashboards/project/firewalls/tables.py:337#: dashboards/project/firewalls/tables.py:339#: dashboards/project/firewalls/tables.py:341#: dashboards/project/firewalls/tables.py:343#: dashboards/project/firewalls/tables.py:345#: dashboards/project/firewalls/tables.py:347#: dashboards/project/firewalls/tables.py:350#: dashboards/project/firewalls/tables.py:351#: dashboards/project/firewalls/tables.py:362#: dashboards/project/firewalls/tables.py:389#: dashboards/project/instances/views.py:407#: dashboards/project/instances/views.py:440 #: dashboards/project/instances/views.py:442#: dashboards/project/instances/views.py:460 #: dashboards/project/instances/views.py:462#: dashboards/project/instances/templates/instances/_detail_overview.html:124#: dashboards/project/instances/templates/instances/_detail_overview.html:134#: dashboards/project/instances/templates/instances/_detail_overview.html:138#: dashboards/project/instances/templates/instances/_detail_overview.html:141#: dashboards/project/instances/templates/instances/_detail_overview.html:147#: dashboards/project/instances/views.py:321#: dashboards/project/instances/views.py:342#: dashboards/project/instances/views.py:351#: dashboards/project/instances/views.py:360#: dashboards/project/instances/views.py:368#: dashboards/project/stacks/forms.py:190#: dashboards/project/instances/workflows/create_instance.py:889 msgid ""Unable to retrieve extensions information"" msgstr """" #: dashboards/project/instances/workflows/create_instance.py:953#: dashboards/project/instances/workflows/create_instance.py:963#: dashboards/project/stacks/forms.py:57#: dashboards/project/stacks/forms.py:58#: dashboards/project/stacks/forms.py:66#: dashboards/project/stacks/forms.py:73 dashboards/project/stacks/forms.py:75#: dashboards/project/stacks/forms.py:76#: dashboards/project/stacks/forms.py:83 dashboards/project/stacks/forms.py:85#: dashboards/project/stacks/forms.py:86#: dashboards/project/stacks/forms.py:93 dashboards/project/stacks/forms.py:95#: dashboards/project/stacks/forms.py:96#: dashboards/project/stacks/forms.py:102#: dashboards/project/stacks/forms.py:110 #: dashboards/project/stacks/forms.py:112#: dashboards/project/stacks/forms.py:113#: dashboards/project/stacks/forms.py:120 #: dashboards/project/stacks/forms.py:122#: dashboards/project/stacks/forms.py:123#: dashboards/project/stacks/forms.py:135#: dashboards/project/stacks/forms.py:136#: dashboards/project/stacks/forms.py:198#: dashboards/project/stacks/forms.py:205#: dashboards/project/stacks/forms.py:230#: dashboards/project/stacks/forms.py:231#: dashboards/project/stacks/forms.py:232 #: dashboards/project/stacks/forms.py:407#: dashboards/project/stacks/forms.py:234 #: dashboards/project/stacks/forms.py:265 #: dashboards/project/stacks/forms.py:410#: dashboards/project/stacks/forms.py:241#: dashboards/project/stacks/forms.py:242#: dashboards/project/stacks/forms.py:250#: dashboards/project/stacks/forms.py:266#: dashboards/project/stacks/forms.py:269#: dashboards/project/stacks/forms.py:274#: dashboards/project/stacks/forms.py:275#: dashboards/project/stacks/forms.py:277#: dashboards/project/stacks/forms.py:278#: dashboards/project/stacks/forms.py:291#: dashboards/project/stacks/forms.py:292#: dashboards/project/stacks/forms.py:384#: dashboards/project/stacks/forms.py:404#: dashboards/project/stacks/forms.py:439#: dashboards/project/stacks/forms.py:448","""POT-Creation-Date: 2015-06-09 01:18-0500\n""#: dashboards/project/firewalls/tables.py:304 #: dashboards/project/firewalls/tables.py:346#: dashboards/project/firewalls/tables.py:355#: dashboards/project/instances/templates/instances/_detail_overview.html:117#: dashboards/project/firewalls/tables.py:289#: dashboards/project/instances/views.py:392#: dashboards/project/stacks/forms.py:62#: dashboards/project/firewalls/tables.py:306 #: dashboards/project/firewalls/tables.py:348#: dashboards/project/instances/templates/instances/_detail_overview.html:122#: dashboards/project/firewalls/tables.py:358#: dashboards/project/instances/templates/instances/_detail_overview.html:147#: dashboards/project/stacks/forms.py:61#: dashboards/project/stacks/forms.py:63#: dashboards/project/instances/views.py:406#: dashboards/project/instances/views.py:417#: dashboards/project/firewalls/tables.py:310#: dashboards/project/firewalls/tables.py:351#: dashboards/project/firewalls/tables.py:363#: dashboards/project/firewalls/tables.py:293#: dashboards/project/firewalls/tables.py:297 #: dashboards/project/firewalls/tables.py:308#: dashboards/project/firewalls/tables.py:315#: dashboards/project/firewalls/tables.py:324#: dashboards/project/firewalls/tables.py:326#: dashboards/project/firewalls/tables.py:328#: dashboards/project/firewalls/tables.py:330#: dashboards/project/firewalls/tables.py:332#: dashboards/project/firewalls/tables.py:334#: dashboards/project/firewalls/tables.py:336#: dashboards/project/firewalls/tables.py:338#: dashboards/project/firewalls/tables.py:341#: dashboards/project/firewalls/tables.py:342#: dashboards/project/firewalls/tables.py:353#: dashboards/project/firewalls/tables.py:377#: dashboards/project/instances/views.py:403#: dashboards/project/instances/views.py:436 #: dashboards/project/instances/views.py:438#: dashboards/project/instances/views.py:456 #: dashboards/project/instances/views.py:458#: dashboards/project/instances/templates/instances/_detail_overview.html:125#: dashboards/project/instances/templates/instances/_detail_overview.html:135#: dashboards/project/instances/templates/instances/_detail_overview.html:139#: dashboards/project/instances/templates/instances/_detail_overview.html:142#: dashboards/project/instances/templates/instances/_detail_overview.html:148#: dashboards/project/instances/views.py:317#: dashboards/project/instances/views.py:338#: dashboards/project/instances/views.py:347#: dashboards/project/instances/views.py:356#: dashboards/project/instances/views.py:364#: dashboards/project/stacks/forms.py:189#: dashboards/project/instances/workflows/create_instance.py:930#: dashboards/project/instances/workflows/create_instance.py:940#: dashboards/project/stacks/forms.py:56#: dashboards/project/stacks/forms.py:57#: dashboards/project/stacks/forms.py:65#: dashboards/project/stacks/forms.py:72 dashboards/project/stacks/forms.py:74#: dashboards/project/stacks/forms.py:75#: dashboards/project/stacks/forms.py:82 dashboards/project/stacks/forms.py:84#: dashboards/project/stacks/forms.py:85#: dashboards/project/stacks/forms.py:92 dashboards/project/stacks/forms.py:94#: dashboards/project/stacks/forms.py:95#: dashboards/project/stacks/forms.py:101#: dashboards/project/stacks/forms.py:109 #: dashboards/project/stacks/forms.py:111#: dashboards/project/stacks/forms.py:112#: dashboards/project/stacks/forms.py:119 #: dashboards/project/stacks/forms.py:121#: dashboards/project/stacks/forms.py:122#: dashboards/project/stacks/forms.py:134#: dashboards/project/stacks/forms.py:135#: dashboards/project/stacks/forms.py:197#: dashboards/project/stacks/forms.py:204#: dashboards/project/stacks/forms.py:229#: dashboards/project/stacks/forms.py:230#: dashboards/project/stacks/forms.py:231 #: dashboards/project/stacks/forms.py:406#: dashboards/project/stacks/forms.py:233 #: dashboards/project/stacks/forms.py:264 #: dashboards/project/stacks/forms.py:409#: dashboards/project/stacks/forms.py:240#: dashboards/project/stacks/forms.py:241#: dashboards/project/stacks/forms.py:249#: dashboards/project/stacks/forms.py:265#: dashboards/project/stacks/forms.py:268#: dashboards/project/stacks/forms.py:273#: dashboards/project/stacks/forms.py:274#: dashboards/project/stacks/forms.py:276#: dashboards/project/stacks/forms.py:277#: dashboards/project/stacks/forms.py:290#: dashboards/project/stacks/forms.py:291#: dashboards/project/stacks/forms.py:383#: dashboards/project/stacks/forms.py:403#: dashboards/project/stacks/forms.py:438#: dashboards/project/stacks/forms.py:447",560,104
openstack%2Fnova-specs~master~Ia9006dc721f27a0cd85ad3e1e667222880a61a50,openstack/nova-specs,master,Ia9006dc721f27a0cd85ad3e1e667222880a61a50,Virt driver to support cpu features,ABANDONED,2015-04-03 08:53:00.000000000,2015-06-11 07:56:19.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 4573}, {'_account_id': 4992}, {'_account_id': 5511}, {'_account_id': 5754}, {'_account_id': 7730}, {'_account_id': 12175}]","[{'number': 1, 'created': '2015-04-03 08:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/57d40a6c75fefdd11f4b6b588eb7df69b5299e1a', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 2, 'created': '2015-04-03 09:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3192f8b4f01934a6e587958f6d2dcc101785a17c', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 3, 'created': '2015-04-03 09:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/647389152186fe79263a548cae22bd11aaacf58e', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 4, 'created': '2015-04-03 14:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/53f1316400d0f2a7d445756e7bf168f108d876d5', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 5, 'created': '2015-04-03 15:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cd469d0c8a7d07194bfa3e8005cf245c3b0d1d9b', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 6, 'created': '2015-04-03 23:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8e0711e9013f2cd80c853d67bc909a84d7f19acb', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 7, 'created': '2015-04-08 08:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/63843435a0c6490c4da7a055d4c07ab7dae23486', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}, {'number': 8, 'created': '2015-04-21 05:28:22.000000000', 'files': ['specs/liberty/approved/virt-driver-cpu-features.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e0232f419e3840ac538e64c70f9398a176b83757', 'message': 'Virt driver to support cpu features\n\nThis blueprint is going to implement more flexible way to custom\nguest cpu features.\n\nimplement blueprint virt-driver-cpu-features\n\nThis is separated from blueprint: more-image-properties\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>\n\nChange-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50\n'}]",46,170396,e0232f419e3840ac538e64c70f9398a176b83757,33,9,8,5754,,,0,"Virt driver to support cpu features

This blueprint is going to implement more flexible way to custom
guest cpu features.

implement blueprint virt-driver-cpu-features

This is separated from blueprint: more-image-properties

Co-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>
Co-Authored-By: Jiang, Yunhong <yunhong.jiang@intel.com>

Change-Id: Ia9006dc721f27a0cd85ad3e1e667222880a61a50
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/96/170396/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/approved/virt-driver-cpu-features.rst'],1,57d40a6c75fefdd11f4b6b588eb7df69b5299e1a,bp/virt-driver-cpu-model,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Virt driver cpu feature for guest VCPU ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/more-image-properties This feature aims to improve libvirt driver to enable user define what kind of cpu feature enable to the guest. Problem description =================== Currently in Nova, instance can be scheduled to a host which support specific cpu feature by add parameter ""capabilities:cpu_info:features"" in the flavor extra_specs and enable ComputeCapabilitiesFilter in the Nova Scheduler. But there still have some problem: * An image may required a specific CPU capability such as Intel AES-NI instruction set support. But current there isn't any support for this. * When instance didn't want some features, ComputeCapabilitiesFilter will schedule instance to a host without those features. This may lead to resource can't be utilized effective. Actually instance can be scheduled to host which support those features and just hide those features to the guest. * When instance request some cpu features, ComputeCapabilitiesFilter will schedule instance to a host with those features. But actually which kind of cpu model exposed to guest is controlled by options cpu_mode and cpu_model. If the operator configure host to expose lower level cpu model than the instance request by option cpu_mode and cpu_model, then finally although the host support those features, but those feature didn't expose to the guest. Use Cases ---------- * An image required a specific CPU capability. When flavor allow same capability, nova should boot the instance on the host which support capability, and that capability expose to the guest. * An image or flavor required disable specific CPU capability. The nova should ensure the guest can't see that capability. * Keep ComputeCapabilitiesFilter's behavior as before. Project Priority ----------------- Does this blueprint fit under one of the :ref:`kilo-priorities`? If so which one and how? Proposed change =============== The flavor extra specs and image properties will be enhanced to support new parameters: * hw:cpu_features=sse4.2:required,ase:disabled,... The instance boot without above parameter, the Nova behavior is same as currently. The instance will be scheduled to host satisfied other requirement. The cpu features exposed to the guest is defined by options 'cpu_mode' and 'cpu_model' on the host which the instance running on. 'hw:cpu_features' is used to specify the instance requirement on the cpu features. 'hw:cpu_features' accept a list of 'feature_name:option' which split by ','. The feature name feature string name which can be identify by hypervisor. The option's valid value are: * 'required': The feature must be able to expose to the guest. The host scheduled on must support this feature. * 'disabled': The feature will not expose the guest. The host which scheduled on will can support or didn't support this feature, but finally the feature will not expose to the user. * 'optional': The feature is optional. +------------------+----------------------------+-----------+ | FLAVOR_POLICY | IMAGE_POLICY | RESULT | +==================+============================+===========+ | Require | Require | Require | +------------------+----------------------------+-----------+ | Require | Optional | Require | +------------------+----------------------------+-----------+ | Require | Disable | Exception | +------------------+----------------------------+-----------+ | Require | Not Specified | Require | +------------------+----------------------------+-----------+ | Optional | Require | Require | +------------------+----------------------------+-----------+ | Optional | Optional | Optional | +------------------+----------------------------+-----------+ | Optional | Not Specified | Optional | +------------------+----------------------------+-----------+ | Optional | Disable | Disable | +------------------+----------------------------+-----------+ | Disable | Require/Optional | Exception | +------------------+----------------------------+-----------+ | Disable | Disable | Disable | +------------------+----------------------------+-----------+ | Disable | Not Specified | Disable | +------------------+----------------------------+-----------+ | Not Specified | Require/Optional | Exception | +------------------+----------------------------+-----------+ | Not Specified | Disable | Disable | +------------------+----------------------------+-----------+ The nova scheduler should depend on the cpu features which calculated from flavor and image to schedule instance. But there are two options which effect the host capability. It is CONF.libvirt.cpu_mode and CONF.libvirt.cpu_model. The scheduler behavior. The behavior is as below: * cpu_mode=host-model|host-passthrough: This is default value. The scheduler will depend on host capability to schedule the instance. * cpu_mode=custom: With this value, the cpu_model will specific a cpu model the operator want the guest run. The host need report this custom model. The scheduler will try to search the required cpu features from this custom model. * cpu_mode=none: What the cpu model is for guest is totally depend on the libvirt implementation. So the scheduler will not schedule any instance with cpu features requirement to it. Alternativee ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Data model impact ----------------- Turn the cpu_info to nova object VirtCPUModel is part of work in blueprint resource-objects: https://blueprints.launchpad.net/openstack/?searchtext=resource-objects For implement those requirement. There is a little different between guest cpu object and host cpu object. There is generic object to describe the cpu capabilities: :: class CPUModel: fields = { 'arch': fields.EnumField(nullable=True, valid_values=arch.ALL), 'vendor': fields.StringField(nullable=True), 'topology': fields.ObjectField('VirtCPUTopology', nullable=True), 'features': fields.ListOfObjectsField(""VirtCPUFeature"", default=[]), 'model': fields.StringField(nullable=True), } For the host cpu info, the model should be looks like this: :: class HostCPUModel: fields = { 'mode' = fields.EnumField(nullable=True, valid_values=cpumodel.ALL_CPUMODES), 'model' = fields.ObjectField('VirtCPUTopology', CPUModel) 'supported_cpu_model': obj_fields.ListOfObjectsField( 'InstanceNUMACell', nullable=True) } * mode: The value is CONF.libvirt.cpu_mode. Scheduler will depend on this to decide how to match cpu feature reqirement. * model: This is the host capabilities which report from hypervisor. * supported_model: This value is only valid when mode is 'custom'. When the mode is custom, the supported_cpu_model store all the cpu_model info which the hypervisor supported. :: class VirtCPUModel: fields = { 'model' = fields.ObjectField('CPUModel') } There is only one field 'model' which used to store the guest cpu capabilites. But think about we can support pre-instance model in the future, so we need to add new fields into this object. REST API impact --------------- Currently the hypervisor API will return the cpu info, but the info is json-string. This isn't good because the data model may changed in the future. So this blueprint proposes to add new field 'cpu_model' for the hypervisor API. The cpu_model field's value is totally match to the HostCPUModel's structure. :: { 'cpu_model': { 'mode': 'custom', 'model': { 'arch': 'x86_64', 'vendor': 'Intel', 'model': 'Nehalm', 'topology': { 'sockets': 2, 'cores': 2, 'threads': 2, } features: ['aes', 'sse4.2', ...], } 'supported_cpu_model': [ { 'arch': 'x86_64', 'vendor': 'Intel', 'model': 'Penryn', 'topology': { 'sockets': 2, 'cores': 2, 'threads': 2, } features: ['aes', 'sse4.1', ...], } ] } } This new fields will added by micro-version. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ There will be more process for validate user request and doing the scheduling. Also hypervisor will report more cpu info to the scheduler that incease some loads. But that should be acceptable. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Alex Xu <hejie.xu@intel.com> Other contributors: Jiang, Yunhong <yunhong.jiang@intel.com> Bhandaru, Malini K <malini.k.bhandaru@intel.com> Work Items ---------- TODO... Dependencies ============ There is a little overlap with blueprint resource-objects: https://blueprints.launchpad.net/openstack/?searchtext=resource-objects To implement this blueprint, need convert to cpu info to nova object. Testing ======= The unitest and functional tests should be added. Documentation Impact ==================== The document should be updated to reflect the new image properties supported. References ========== None ",,303,0
openstack%2Fnova~master~Ia05231202cc7c23374ca95dcf2fbcc84fef75279,openstack/nova,master,Ia05231202cc7c23374ca95dcf2fbcc84fef75279,don't leave glance with open file descriptor on error,ABANDONED,2015-06-03 21:13:09.000000000,2015-06-11 07:55:36.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4190}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-03 21:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/945d72c6181a2cf808de9f9401b93c28f15b3a59', 'message': ""don't leave glance with open file descriptor on error\n\nIf we run into a problem writing the image file (full filesystem\nfor example) the current code will leave glance stuck with an\nopen file descriptor.  This prevents the image file from being\ndeleted.  glance will eventually time out and release it, but\nthis takes hours.\n\nThe fix is to continue to iterate over the rest of the\nimage_chunks even if we can't actually do anything with them.\nThis allows glance to close the file right away.\n\nChange-Id: Ia05231202cc7c23374ca95dcf2fbcc84fef75279\nCloses-Bug: #1461678\n""}, {'number': 2, 'created': '2015-06-11 06:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f7f3e6cb9541f0400b2b917771bb2d000742ad9', 'message': ""don't leave glance with open file descriptor on error\n\nIf we run into a problem writing the image file (full filesystem\nfor example) the current code can leave glance stuck with an\nopen file descriptor.  This prevents the image file from being\ndeleted.\n\nIt appears that the problem is due to nova-compute holding open\nthe HTTP connection to glance-api, which in turn holds open the\nfile descriptor.\n\nThe fix is to explicitly delete the iterator.  This results in\nthe HTTP socket being shut down, which in turn results in the\nfile descriptor being closed.\n\nChange-Id: Ia05231202cc7c23374ca95dcf2fbcc84fef75279\nCloses-Bug: #1461678\n""}, {'number': 3, 'created': '2015-06-11 06:47:57.000000000', 'files': ['nova/image/glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/afd099864648c8bdf4bb20b51169fffa19d6320d', 'message': ""don't leave glance with open file descriptor on error\n\nIf we run into a problem writing the image file (full filesystem\nfor example) the current code can leave glance stuck with an\nopen file descriptor.  This prevents the image file from being\ndeleted.\n\nIt appears that the problem is due to nova-compute holding open\nthe HTTP connection to glance-api, which in turn holds open the\nfile descriptor.\n\nThe fix is to explicitly delete the iterator.  This results in\nthe HTTP socket being shut down, which in turn results in the\nfile descriptor being closed.\n\nChange-Id: Ia05231202cc7c23374ca95dcf2fbcc84fef75279\nCloses-Bug: #1461678\nCo-Authored-By: Robert Collins <rbtcollins@hp.com>\n""}]",5,188179,afd099864648c8bdf4bb20b51169fffa19d6320d,21,12,3,8768,,,0,"don't leave glance with open file descriptor on error

If we run into a problem writing the image file (full filesystem
for example) the current code can leave glance stuck with an
open file descriptor.  This prevents the image file from being
deleted.

It appears that the problem is due to nova-compute holding open
the HTTP connection to glance-api, which in turn holds open the
file descriptor.

The fix is to explicitly delete the iterator.  This results in
the HTTP socket being shut down, which in turn results in the
file descriptor being closed.

Change-Id: Ia05231202cc7c23374ca95dcf2fbcc84fef75279
Closes-Bug: #1461678
Co-Authored-By: Robert Collins <rbtcollins@hp.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/188179/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/image/glance.py'],1,945d72c6181a2cf808de9f9401b93c28f15b3a59,bug/1461678," # We need to iterate over all the image chunks here even if we run # into an error, otherwise glance will be stuck with an open file # descriptor. exc = None try: if not exc: data.write(chunk) except IOError as exc: pass if exc: raise exc", data.write(chunk),11,1
openstack%2Fhorizon~master~Ic6540fed142ef5b2f6fa9eeec0fe2c6eee629ed0,openstack/horizon,master,Ic6540fed142ef5b2f6fa9eeec0fe2c6eee629ed0,JSCS cleanup - launch-instance/,ABANDONED,2015-06-11 06:35:05.000000000,2015-06-11 07:53:40.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-06-11 06:35:05.000000000', 'files': ['openstack_dashboard/static/dashboard/launch-instance/keypair/keypair.js', 'openstack_dashboard/static/dashboard/launch-instance/network/network.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.model.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/security-groups/security-groups.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7f2dd22865427438b0a9a05144f04e4ceb319887', 'message': ""JSCS cleanup - launch-instance/\n\nFollowing John Papa's style guide.\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors launch-instance/* except for source,\nflavor and configuration.\n\nChange-Id: Ic6540fed142ef5b2f6fa9eeec0fe2c6eee629ed0\nPartially-Implements: blueprint jscs-cleanup\n""}]",0,190505,7f2dd22865427438b0a9a05144f04e4ceb319887,4,4,1,13805,,,0,"JSCS cleanup - launch-instance/

Following John Papa's style guide.
https://github.com/johnpapa/angular-styleguide,
this patch refactors launch-instance/* except for source,
flavor and configuration.

Change-Id: Ic6540fed142ef5b2f6fa9eeec0fe2c6eee629ed0
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/05/190505/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/launch-instance/keypair/keypair.js', 'openstack_dashboard/static/dashboard/launch-instance/network/network.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.model.js', 'openstack_dashboard/static/dashboard/launch-instance/launch-instance.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/security-groups/security-groups.js']",5,7f2dd22865427438b0a9a05144f04e4ceb319887,bp/jscs-cleanup," /** /** gettext('If a security group is not associated with an instance before it is launched, then you will have very limited access to the instance after it is deployed. You will only be able to access the instance from a VNC console.')"," /** /** gettext('If a security group is not associated with an instance before it is launched, then you will have very limited access to the instance after it is deployed. You will only be able to access the instance from a VNC console.'),",43,41
openstack%2Fhorizon~master~I98f5a8fdba199a6e6ee3ca39918804ac6751fe4c,openstack/horizon,master,I98f5a8fdba199a6e6ee3ca39918804ac6751fe4c,JSCS cleanup - launch-instance/source/,ABANDONED,2015-06-11 06:11:35.000000000,2015-06-11 07:53:25.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-06-11 06:11:35.000000000', 'files': ['openstack_dashboard/static/dashboard/launch-instance/source/source.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/cd131b3cb03a5fc61d395de86234cca321f38f6a', 'message': ""JSCS cleanup - launch-instance/source/\n\nFollowing John Papa's style guide.\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors launch-instance/source/\n\nChange-Id: I98f5a8fdba199a6e6ee3ca39918804ac6751fe4c\nPartially-Implements: blueprint jscs-cleanup\n""}]",0,190498,cd131b3cb03a5fc61d395de86234cca321f38f6a,4,4,1,13805,,,0,"JSCS cleanup - launch-instance/source/

Following John Papa's style guide.
https://github.com/johnpapa/angular-styleguide,
this patch refactors launch-instance/source/

Change-Id: I98f5a8fdba199a6e6ee3ca39918804ac6751fe4c
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/98/190498/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/launch-instance/source/source.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/source/source.js']",2,cd131b3cb03a5fc61d395de86234cca321f38f6a,bp/jscs-cleanup," $scope.tableBodyCells = []; var maxTotalInstances = 1; // Must has default value > 0 var totalInstancesUsed = 0; var instanceCount = $scope.model.newInstanceSpec.instance_count || 1; var added = instanceCount; var source; for (var i = 0, len = sources.length; i < len; i++) {"," $scope.tableBodyCells= []; var maxTotalInstances = 1, // Must has default value > 0 totalInstancesUsed = 0; var instance_count = $scope.model.newInstanceSpec.instance_count || 1; var added = instance_count; var i = 0, len = sources.length, source; for (; i < len; i++) {",10,13
openstack%2Fhorizon~master~I424b6303d4f14246af8181f8c1875e35b5433ac7,openstack/horizon,master,I424b6303d4f14246af8181f8c1875e35b5433ac7,JSCS cleanup - launch-instance/flavor/,ABANDONED,2015-06-11 05:58:27.000000000,2015-06-11 07:53:02.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-06-11 05:58:27.000000000', 'files': ['openstack_dashboard/static/dashboard/launch-instance/flavor/flavor.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5dea78b652f4e4c6c84a24a3cd2afdcc147882af', 'message': ""JSCS cleanup - launch-instance/flavor/\n\nFollowing John Papa's style guide.\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors launch-instance/flavor/\n\nChange-Id: I424b6303d4f14246af8181f8c1875e35b5433ac7\nPartially-Implements: blueprint jscs-cleanup\n""}]",0,190489,5dea78b652f4e4c6c84a24a3cd2afdcc147882af,4,4,1,13805,,,0,"JSCS cleanup - launch-instance/flavor/

Following John Papa's style guide.
https://github.com/johnpapa/angular-styleguide,
this patch refactors launch-instance/flavor/

Change-Id: I424b6303d4f14246af8181f8c1875e35b5433ac7
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/89/190489/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/launch-instance/flavor/flavor.js'],1,5dea78b652f4e4c6c84a24a3cd2afdcc147882af,bp/jscs-cleanup," $scope.$watchCollection(function () { }, function (newValue, oldValue, scope) { var ctrl = scope.selectFlavorCtrl; ctrl.flavors = newValue; ctrl.updateFlavorFacades(); $scope.$watchCollection(function () { this.getErrors = function (flavor) { var messages = {}; var source = this.source; var instanceCount = this.instanceCount;"," $scope.$watchCollection(function() { },function (newValue, oldValue, scope) { var ctrl = scope.selectFlavorCtrl; ctrl.flavors = newValue; ctrl.updateFlavorFacades(); $scope.$watchCollection(function() { this.getErrors = function(flavor) { var messages = {}, source = this.source, instanceCount = this.instanceCount;",10,11
openstack%2Fhorizon~master~I8b7370949ec16cc45f2d6c9f56e9dc3cd5a25ec6,openstack/horizon,master,I8b7370949ec16cc45f2d6c9f56e9dc3cd5a25ec6,JSCS cleanup - launch-instance/configuration/,ABANDONED,2015-06-11 05:48:20.000000000,2015-06-11 07:52:33.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-06-11 05:48:20.000000000', 'files': ['openstack_dashboard/static/dashboard/launch-instance/configuration/load-edit.js', 'openstack_dashboard/static/dashboard/launch-instance/configuration/configuration.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/configuration/configuration.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0063463e1b25ea98d44551906563285972a4df99', 'message': ""JSCS cleanup - launch-instance/configuration/\n\nFollowing John Papa's style guide.\nhttps://github.com/johnpapa/angular-styleguide,\nthis patch refactors launch-instance/configuration/\n\nChange-Id: I8b7370949ec16cc45f2d6c9f56e9dc3cd5a25ec6\nPartially-Implements: blueprint jscs-cleanup\n""}]",0,190488,0063463e1b25ea98d44551906563285972a4df99,4,4,1,13805,,,0,"JSCS cleanup - launch-instance/configuration/

Following John Papa's style guide.
https://github.com/johnpapa/angular-styleguide,
this patch refactors launch-instance/configuration/

Change-Id: I8b7370949ec16cc45f2d6c9f56e9dc3cd5a25ec6
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/88/190488/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/launch-instance/configuration/load-edit.js', 'openstack_dashboard/static/dashboard/launch-instance/configuration/configuration.spec.js', 'openstack_dashboard/static/dashboard/launch-instance/configuration/configuration.js']",3,0063463e1b25ea98d44551906563285972a4df99,bp/jscs-cleanup, var MAX_SCRIPT_SIZE = 16 * 1024; var DEFAULT_CONFIG_DRIVE = false; var DEFAULT_USER_DATA = ''; var DEFAULT_DISK_CONFIG = 'AUTO'; var config = this; var newInstanceSpec = $scope.model.newInstanceSpec;," var MAX_SCRIPT_SIZE = 16 * 1024, DEFAULT_CONFIG_DRIVE = false, DEFAULT_USER_DATA = '', DEFAULT_DISK_CONFIG = 'AUTO'; var config = this, newInstanceSpec = $scope.model.newInstanceSpec;",9,9
openstack%2Fproject-config~master~If5b510783d530e36adf225fd02bd3a6e704a715c,openstack/project-config,master,If5b510783d530e36adf225fd02bd3a6e704a715c,oslo.msg: don't use devstack for rabbit func tests,ABANDONED,2015-06-10 13:21:14.000000000,2015-06-11 07:14:26.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6159}]","[{'number': 1, 'created': '2015-06-10 13:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ddfbe200e2d6727f111422ec7f647249ca7595aa', 'message': ""oslo.msg: don't use devstack for rabbit func tests\n\nThe oslo.messaging functional tests suite currently relies on devstack\nsetup to setup rabbit/qpid/zmq.\n\nThis is a bit overkill and a change in devstack can break our jobs,\nso we want to remove this dependencies.\n\nThe tox target of the rabbit functional tests job have been rabbit enhanced to\nnot depends on devstack,\n\nThis change add a job the run it on a non devstack vm.\n\nWhen this new job will be validated, the old one will be removed.\n\nDepends-On: 036de8b9be2e3a34378da15b3d4252e6f5885696\nChange-Id: If5b510783d530e36adf225fd02bd3a6e704a715c\n""}, {'number': 2, 'created': '2015-06-10 13:24:12.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/35f556197fe7df449d946b76e033f10b84ab86d6', 'message': ""oslo.msg: don't use devstack for rabbit func tests\n\nThe oslo.messaging functional tests suite currently relies on devstack\nsetup to setup rabbit/qpid/zmq.\n\nThis is a bit overkill and a change in devstack can break our jobs,\nso we want to remove this dependencies.\n\nThe tox target of the rabbit functional tests job have been rabbit enhanced to\nnot depends on devstack,\n\nThis change add a job the run it on a non devstack vm.\n\nWhen this new job will be validated, the old one will be removed.\n\nDepends-On: I27eb2c1d3d0ca67aa361c83e41372138e03d9bdd\nChange-Id: If5b510783d530e36adf225fd02bd3a6e704a715c\n""}]",0,190186,35f556197fe7df449d946b76e033f10b84ab86d6,4,3,2,2813,,,0,"oslo.msg: don't use devstack for rabbit func tests

The oslo.messaging functional tests suite currently relies on devstack
setup to setup rabbit/qpid/zmq.

This is a bit overkill and a change in devstack can break our jobs,
so we want to remove this dependencies.

The tox target of the rabbit functional tests job have been rabbit enhanced to
not depends on devstack,

This change add a job the run it on a non devstack vm.

When this new job will be validated, the old one will be removed.

Depends-On: I27eb2c1d3d0ca67aa361c83e41372138e03d9bdd
Change-Id: If5b510783d530e36adf225fd02bd3a6e704a715c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/190186/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,ddfbe200e2d6727f111422ec7f647249ca7595aa,, - name: gate-oslo.messaging-tox-py27-func-rabbit branch: ^(?!stable/(icehouse|juno)).*$ voting: false - gate-oslo.messaging-tox-py27-func-rabbit,,8,0
openstack%2Fnetworking-ovn~master~I334c93803408908a6df29d2a7a0a20c8facb34ab,openstack/networking-ovn,master,I334c93803408908a6df29d2a7a0a20c8facb34ab,Fix import in l3 plugin stub,MERGED,2015-06-10 20:17:31.000000000,2015-06-11 07:05:53.000000000,2015-06-11 07:05:51.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4395}]","[{'number': 1, 'created': '2015-06-10 20:17:31.000000000', 'files': ['networking_ovn/l3/l3_ovn.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5d5e4b80e2e9f1668a806f8df379829a7a11282e', 'message': 'Fix import in l3 plugin stub\n\nUpdate this code to reflect a recent change in Neutron so the tests\nstill pass.\n\nChange-Id: I334c93803408908a6df29d2a7a0a20c8facb34ab\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",0,190332,5d5e4b80e2e9f1668a806f8df379829a7a11282e,7,3,1,1561,,,0,"Fix import in l3 plugin stub

Update this code to reflect a recent change in Neutron so the tests
still pass.

Change-Id: I334c93803408908a6df29d2a7a0a20c8facb34ab
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/32/190332/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/l3/l3_ovn.py'],1,5d5e4b80e2e9f1668a806f8df379829a7a11282e,devstack,"from neutron.db import common_db_mixinclass OVNL3RouterPlugin(common_db_mixin.CommonDbMixin,","from neutron.db import db_base_plugin_v2class OVNL3RouterPlugin(db_base_plugin_v2.common_db_mixin.CommonDbMixin,",2,2
openstack%2Fpython-glanceclient~master~Ie124fc47fec8219401e9d0d1b3f17394af30089e,openstack/python-glanceclient,master,Ie124fc47fec8219401e9d0d1b3f17394af30089e,Change schema type of `additionalProperties` in unittests,ABANDONED,2015-03-17 13:29:26.000000000,2015-06-11 06:47:04.000000000,,"[{'_account_id': 3}, {'_account_id': 7575}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-03-17 13:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/fa543e537ea65f33ce79502e7921fba0a819a69e', 'message': ""WIP: Fix schema type of `additionalProperties` in unittests\n\nRight now the `additionalProperties` field in image schema in unittests\nhas type set to 'string'. It's invalid behaviour, because additional\nproperties can contain null values as well, so we are changing it to\nsupport ['string', 'null'].\n\nAdditionally new test has been added to cover nullable property.\n\nChange-Id: Ie124fc47fec8219401e9d0d1b3f17394af30089e\nCloses-Bug: 1419823\n""}, {'number': 2, 'created': '2015-03-18 11:12:24.000000000', 'files': ['tests/v2/test_images.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/c42d3b0e29d3d617ffa57a980ad4f75e04e8d1fc', 'message': ""Change schema type of `additionalProperties` in unittests\n\nRight now the `additionalProperties` field in image schema in unittests\nhas type set to 'string'. It's invalid behaviour, because additional\nproperties can contain null values as well, so we are changing it to\nsupport ['null', 'string'] types.\n\nAdditionally new test has been added to cover nullable property.\n\nChange-Id: Ie124fc47fec8219401e9d0d1b3f17394af30089e\nPartial-Bug: 1419823\n""}]",0,165066,c42d3b0e29d3d617ffa57a980ad4f75e04e8d1fc,8,3,2,13161,,,0,"Change schema type of `additionalProperties` in unittests

Right now the `additionalProperties` field in image schema in unittests
has type set to 'string'. It's invalid behaviour, because additional
properties can contain null values as well, so we are changing it to
support ['null', 'string'] types.

Additionally new test has been added to cover nullable property.

Change-Id: Ie124fc47fec8219401e9d0d1b3f17394af30089e
Partial-Bug: 1419823
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/66/165066/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/v2/test_images.py'],1,fa543e537ea65f33ce79502e7921fba0a819a69e,bug/1419823," 'additionalProperties': {'type': ['string', 'null']} '/v2/images/8e25757f-054c-454c-b6ca-d1e89c44e6d6': { 'GET': ( {}, { 'id': '8e25757f-054c-454c-b6ca-d1e89c44e6d6', 'name': 'image-6', 'description': None, }, ), 'PATCH': ( {}, '', ), }, 'additionalProperties': {'type': ['string', 'null']} def test_get_image_custom_property_none(self): image = self.controller.get('8e25757f-054c-454c-b6ca-d1e89c44e6d6') self.assertEqual('8e25757f-054c-454c-b6ca-d1e89c44e6d6', image.id) self.assertEqual('image-6', image.name) self.assertEqual(None, image.description) "," 'additionalProperties': {'type': 'string'}, 'additionalProperties': {'type': 'string'},",22,2
openstack%2Fkeystoneauth-saml2~master~I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6,openstack/keystoneauth-saml2,master,I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6,Refactor SAML2 auth plugins,MERGED,2015-04-23 13:55:59.000000000,2015-06-11 06:14:28.000000000,2015-06-11 06:14:27.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2015-04-23 13:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/eb6b4486c8e1d39f31f9bb8a773147e3ff9027e5', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.contrib.auth.v3.federation.FederatedBaseAuth`` class\n\nAlso, new parameter ``protocol`` is added.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 2, 'created': '2015-04-23 13:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/a0e5de843a3718f35ad51047899fede3b8ff80c7', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.contrib.auth.v3.federation.FederatedBaseAuth`` class\n\nAlso, new parameter ``protocol`` is added.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 3, 'created': '2015-04-23 14:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/bbdee9aa2b1dad5774ed2519ed7a8241a24d4350', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.contrib.auth.v3.federation.FederatedBaseAuth`` class\n\nAlso, new parameter ``protocol`` is added.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 4, 'created': '2015-04-23 15:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/e25423bda42395aa3c181c9be30e190d1c5bd72b', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.contrib.auth.v3.federation.FederatedBaseAuth`` class\n\nAlso, new parameter ``protocol`` is added.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 5, 'created': '2015-04-23 15:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/cfd4d23e6922d8ece83a6ecd31912d7ce16cf8a1', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.contrib.auth.v3.federation.FederatedBaseAuth`` class\n\nNew parameter ``protocol`` is added and its default value is deprecated.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 6, 'created': '2015-04-24 13:12:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/41f8d37cf4550726efde6870eb2151ecf2b44373', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.contrib.auth.v3.federation.FederatedBaseAuth`` class\n\nNew parameter ``protocol`` is added and its default value is deprecated.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 7, 'created': '2015-04-27 11:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/ac427afa1717b9005930b8d4e9f51f8cb1af0226', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.auth.identity.v3.federation.FederationBaseAuth`` class.\nAlso, a small typo in the docstring is fixed.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 8, 'created': '2015-04-29 13:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/3e85892106ab363628ca8976a769fc70b83786b8', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.auth.identity.v3.federation.FederationBaseAuth`` class.\nAlso, a small typo in the docstring is fixed.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 9, 'created': '2015-05-21 23:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/93974311f5e5a3327fe488f17b06aec853d7bd87', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.auth.identity.v3.federation.FederationBaseAuth`` class.\nAlso, a small typo in the docstring is fixed.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 10, 'created': '2015-05-29 17:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/7d5ed894a5d8630446c1fcac3f0490c1ca99207e', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.auth.identity.v3.federation.FederationBaseAuth`` class.\nAlso, a small typo in the docstring is fixed.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 11, 'created': '2015-06-02 08:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/7d0fc3f1caa39d68cd2ac68a503e00da66e4f3e3', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.auth.identity.v3.federated.FederatedBaseAuth`` class.\nAlso, a small typo in the docstring is fixed.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}, {'number': 12, 'created': '2015-06-02 08:44:31.000000000', 'files': ['keystoneclient_saml2/v3/saml2.py', 'setup.cfg', 'keystoneclient_saml2/tests/test_auth_saml2.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/2259789d6b767b5a1d228b9456c5a2fd8baab7bd', 'message': 'Refactor SAML2 auth plugins\n\nThis patch refactors saml2 authentication plugins and inherits from\n``keystoneclient.auth.identity.v3.federated.FederatedBaseAuth`` class.\nAlso, a small typo in the docstring is fixed.\n\nChange-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6\nPartially-Implements: bp refactor-federated-plugins\n'}]",7,176746,2259789d6b767b5a1d228b9456c5a2fd8baab7bd,35,14,12,8978,,,0,"Refactor SAML2 auth plugins

This patch refactors saml2 authentication plugins and inherits from
``keystoneclient.auth.identity.v3.federated.FederatedBaseAuth`` class.
Also, a small typo in the docstring is fixed.

Change-Id: I16a89183c7f900851bbf3f5e1a7e9d98340a9ea6
Partially-Implements: bp refactor-federated-plugins
",git fetch https://review.opendev.org/openstack/keystoneauth-saml2 refs/changes/46/176746/4 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient_federation/v3/saml2.py'],1,eb6b4486c8e1d39f31f9bb8a773147e3ff9027e5,bp/refactor-federated-plugins,"from keystoneclient.i18n import _from keystoneclient_federation.v3 import federation class _BaseSAMLPlugin(federation.FederatedAuthPlugin): def __init__(self, auth_url, identity_provider, identity_provider_url, username, password, protocol, **kwargs): """"""Class constructor accepting following parameters: :param auth_url: URL of the Identity Service :type auth_url: string :param identity_provider: name of the Identity Provider the client will authenticate against. This parameter will be used to build a dynamic URL used to obtain unscoped OpenStack token. :type identity_provider: string :param identity_provider_url: An Identity Provider URL, where the SAML2 authn request will be sent. :type identity_provider_url: string :param username: User's login :type username: string :param password: User's password :type password: string :param protocol: Protocol to be used in for the authentication. The name must be equal to one configured at the keystone sp side. This value is used for building dynamic authentication URL. Typical value would be: saml2 :type protocol: string """""" super(_BaseSAMLPlugin, self).__init__( auth_url=auth_url, identity_provider=identity_provider, identity_provider_url=identity_provider_url, protocol=protocol, **kwargs) self.username = username self.password = password @classmethod def get_options(cls): options = super(_BaseSAMLPlugin, cls).get_options() options.extend([ cfg.StrOpt('user-name', dest='username', help='Username', deprecated_name='username'), cfg.StrOpt('password', help='Password') ]) return options @property def scoped_token_plugin(self): """"""Return class that should be used for scoping the token."""""" return Saml2ScopedToken class Saml2TokenAuthMethod(v3.AuthMethod):class Saml2Token(_BaseSAMLPlugin): :param protocol: Protocol to be used in for the authentication. The name must be equal to one configured at the keystone sp side. This value is used for building dynamic authentication URL. Typical value would be: saml2 :type protocol: string _auth_method_class = Saml2TokenAuthMethod username, password, protocol, **kwargs): """"""Class constructor accepting following parameters: :param auth_url: URL of the Identity Service :type auth_url: string :param identity_provider: name of the Identity Provider the client will authenticate against. This parameter will be used to build a dynamic URL used to obtain unscoped OpenStack token. :type identity_provider: string :param identity_provider_url: An Identity Provider URL, where the SAML2 authn request will be sent. :type identity_provider_url: string :param username: User's login :type username: string :param password: User's password :type password: string :param protocol: Protocol to be used in for the authentication. The name must be equal to one configured at the keystone sp side. This value is used for building dynamic authentication URL. Typical value would be: saml2 :type protocol: string """""" super(Saml2Token, self).__init__( auth_url=auth_url, identity_provider=identity_provider, identity_provider_url=identity_provider_url, username=username, password=password, protocol=protocol, **kwargs) def get_unscoped_auth_ref(self, session): The federated authentication consists of: Provider). It's crucial to include HTTP headers indicating we are expecting SOAP message in return. Service Provider should respond with such SOAP message. This step is handed by a method ``Saml2Token_send_service_provider_request()``. ``Saml2Token_send_idp_saml2_authn_request(session)`` ``Saml2Token_send_service_provider_saml2_authn_response()`` :returns: AccessInfo :rtype: :py:class:`keystoneclient.access.AccessInfo` token = self.authenticated_response.headers['X-Subject-Token'] token_json = self.authenticated_response.json()['token'] class ADFSToken(_BaseSAMLPlugin): """"""Authentication plugin for Microsoft ADFS2.0 IdPs."""""" _auth_method_class = Saml2TokenAuthMethod service_provider_endpoint, username, password, protocol, **kwargs): """"""Constructor for ``ADFSToken``. :param auth_url: URL of the Identity Service :type auth_url: string :param identity_provider: name of the Identity Provider the client will authenticate against. This parameter will be used to build a dynamic URL used to obtain unscoped OpenStack token. :type identity_provider: string :param identity_provider_url: An Identity Provider URL, where the SAML2 authentication request will be sent. :type identity_provider_url: string :param service_provider_endpoint: Endpoint where an assertion is being sent, for instance: ``https://host.domain/Shibboleth.sso/ADFS`` :type service_provider_endpoint: string :param username: User's login :type username: string :param password: User's password :type password: string """""" super(ADFSToken, self).__init__( auth_url=auth_url, identity_provider=identity_provider, identity_provider_url=identity_provider_url, username=username, password=password, protocol=protocol) options = super(ADFSToken, cls).get_options() def get_unscoped_auth_ref(self, session, *kwargs): This is a multistep process: build a etree.XML object filling certain attributes with proper user credentials, created/expires dates (ticket is be valid for 120 seconds as currently we don't handle reusing ADFS issued security tokens). prepare a request addressed for the Service Provider endpoint. This also includes changing namespaces in the XML document. Step handled by ``ADFSToken._prepare_sp_request()`` method. the server will respond with HTTP 301 code which should be ignored as the 'location' header doesn't contain protected area. The goal of this operation is fetching the session cookie which later allows for accessing protected URL endpoints. Step handed by ``ADFSToken._send_assertion_to_service_provider()`` method. accessed and an unscoped token can be retrieved. Step handled by ``ADFSToken._access_service_provider()`` method. :param session: a session object to send out HTTP requests. :returns: AccessInfo :rtype: :py:class:`keystoneclient.access.AccessInfo` token = self.authenticated_response.headers['X-Subject-Token'] token_json = self.authenticated_response.json()['token']","from keystoneclient_federation.i18n import _ class _BaseSAMLPlugin(v3.AuthConstructor): PROTOCOL = 'saml2' @property def token_url(self): """"""Return full URL where authorization data is sent."""""" values = { 'host': self.auth_url.rstrip('/'), 'identity_provider': self.identity_provider, 'protocol': self.PROTOCOL } url = (""%(host)s/OS-FEDERATION/identity_providers/"" ""%(identity_provider)s/protocols/%(protocol)s/auth"") url = url % values return url @classmethod def get_options(cls): options = super(_BaseSAMLPlugin, cls).get_options() options.extend([ cfg.StrOpt('identity-provider', help=""Identity Provider's name""), cfg.StrOpt('identity-provider-url', help=""Identity Provider's URL""), cfg.StrOpt('user-name', dest='username', help='Username', deprecated_name='username'), cfg.StrOpt('password', help='Password') ]) return options class Saml2UnscopedTokenAuthMethod(v3.AuthMethod):class Saml2UnscopedToken(_BaseSAMLPlugin): _auth_method_class = Saml2UnscopedTokenAuthMethod username, password, **kwargs): super(Saml2UnscopedToken, self).__init__(auth_url=auth_url, **kwargs) self.identity_provider = identity_provider self.identity_provider_url = identity_provider_url self.username, self.password = username, password def _get_unscoped_token(self, session): The federated authentication consists of:: Provider). Client utilizes URL:: ``/v3/OS-FEDERATION/identity_providers/{identity_provider}/ protocols/saml2/auth``. It's crucial to include HTTP headers indicating we are expecting SOAP message in return. Service Provider should respond with such SOAP message. This step is handed by a method ``Saml2UnscopedToken_send_service_provider_request()`` ``Saml2UnscopedToken_send_idp_saml2_authn_request(session)`` ``Saml2UnscopedToken_send_service_provider_saml2_authn_response()`` :returns: (token, token_json) return (self.authenticated_response.headers['X-Subject-Token'], self.authenticated_response.json()['token']) def get_auth_ref(self, session, **kwargs): """"""Authenticate via SAML2 protocol and retrieve unscoped token. This is a multi-step process where a client does federated authn receives an unscoped token. Federated authentication utilizing SAML2 Enhanced Client or Proxy extension. See ``Saml2UnscopedToken_get_unscoped_token()`` for more information on that step. Upon successful authentication and assertion mapping an unscoped token is returned and stored within the plugin object for further use. :param session : a session object to send out HTTP requests. :type session: keystoneclient.session.Session :return: an object with scoped token's id and unscoped token json included. :rtype: :py:class:`keystoneclient.access.AccessInfoV3` """""" token, token_json = self._get_unscoped_token(session)class ADFSUnscopedToken(_BaseSAMLPlugin): """"""Authentication plugin for Microsoft ADFS2.0 IdPs. :param auth_url: URL of the Identity Service :type auth_url: string :param identity_provider: name of the Identity Provider the client will authenticate against. This parameter will be used to build a dynamic URL used to obtain unscoped OpenStack token. :type identity_provider: string :param identity_provider_url: An Identity Provider URL, where the SAML2 authentication request will be sent. :type identity_provider_url: string :param service_provider_endpoint: Endpoint where an assertion is being sent, for instance: ``https://host.domain/Shibboleth.sso/ADFS`` :type service_provider_endpoint: string :param username: User's login :type username: string :param password: User's password :type password: string """""" _auth_method_class = Saml2UnscopedTokenAuthMethod service_provider_endpoint, username, password, **kwargs): super(ADFSUnscopedToken, self).__init__(auth_url=auth_url, **kwargs) self.identity_provider = identity_provider self.identity_provider_url = identity_provider_url self.username, self.password = username, password options = super(ADFSUnscopedToken, cls).get_options() def _get_unscoped_token(self, session, *kwargs): This is a multistep process:: build a etree.XML object filling certain attributes with proper user credentials, created/expires dates (ticket is be valid for 120 seconds as currently we don't handle reusing ADFS issued security tokens) . Step handled by ``ADFSUnscopedToken._prepare_adfs_request()`` method. ``ADFSUnscopedToken._get_adfs_security_token()`` method. prepare a request addressed for the Service Provider endpoint. This also includes changing namespaces in the XML document. Step handled by ``ADFSUnscopedToken._prepare_sp_request()`` method. the server will respond with HTTP 301 code which should be ignored as the 'location' header doesn't contain protected area. The goal of this operation is fetching the session cookie which later allows for accessing protected URL endpoints. Step handed by ``ADFSUnscopedToken._send_assertion_to_service_provider()`` method. accessed and an unscoped token can be retrieved. Step handled by ``ADFSUnscopedToken._access_service_provider()`` method. :param session : a session object to send out HTTP requests. :returns: (Unscoped federated token, token JSON body) return (self.authenticated_response.headers['X-Subject-Token'], self.authenticated_response.json()['token']) def get_auth_ref(self, session, **kwargs): token, token_json = self._get_unscoped_token(session) def __init__(self, auth_url, token, **kwargs): super(Saml2ScopedToken, self).__init__(auth_url, token, **kwargs) if not (self.project_id or self.domain_id): raise exceptions.ValidationError( _('Neither project nor domain specified'))",174,138
openstack%2Fneutron~master~I90326479e908042fec9ecb25fa19a8dd5b15e7d8,openstack/neutron,master,I90326479e908042fec9ecb25fa19a8dd5b15e7d8,Consume oslo.policy,MERGED,2015-04-23 12:28:12.000000000,2015-06-11 06:04:13.000000000,2015-06-11 06:04:10.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 7634}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9820}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11343}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-23 12:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2467bd230fc4b22eb63d2b0835ee5a176fe90ee8', 'message': ""Consume oslo.policy\n\nSome non intrusive changes to tests are needed, so that we don't rely on\nlibrary symbols that are now private (f.e. parse_rule).\n\nNote: referred oslo.policy commit is not really enough, we will also\nneed to release a new library version with the change included, and\nupdate both global and neutron requirements to require the new version.\n\nDepends-On: I6ee9f8f7fcea3ddb2c52b5d58dfce3dd328c9131\nChange-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8\n""}, {'number': 2, 'created': '2015-06-04 15:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92d52945aab5327d65af44bfff0fc5cecbbf9a73', 'message': ""Consume oslo.policy\n\nSome non intrusive changes to tests are needed, so that we don't rely on\nlibrary symbols that are now private (f.e. parse_rule).\n\nChange-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8\n""}, {'number': 3, 'created': '2015-06-04 15:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/90bcb2e214cf010070b7adb07d3428a0b9f10001', 'message': ""Consume oslo.policy\n\nSome non intrusive changes to tests are needed, so that we don't rely on\nlibrary symbols that are now private (f.e. parse_rule).\n\nCloses-Bug: #1458945\nChange-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8\n""}, {'number': 4, 'created': '2015-06-05 15:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e839415d6caf7ef27ec6ff61a7462bf9024128c', 'message': ""Consume oslo.policy\n\nSome non intrusive changes to tests are needed, so that we don't rely on\nlibrary symbols that are now private (f.e. parse_rule).\n\nChange-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8\n""}, {'number': 5, 'created': '2015-06-08 11:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/521518c5cfbdc8b716c365995de4c338ecfdb035', 'message': ""Consume oslo.policy\n\nSome non intrusive changes to tests are needed, so that we don't rely on\nlibrary symbols that are now private (f.e. parse_rule).\n\nCloses-Bug: #1458945\nChange-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8\n""}, {'number': 6, 'created': '2015-06-09 17:07:13.000000000', 'files': ['neutron/tests/unit/api/v2/test_base.py', 'requirements.txt', 'neutron/api/v2/base.py', 'neutron/tests/unit/test_policy.py', 'neutron/api/v2/resource.py', 'openstack-common.conf', 'neutron/policy.py', 'neutron/openstack/common/policy.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9143ce10e422bd17c4817dfe08163879e0e5a4ca', 'message': ""Consume oslo.policy\n\nSome non intrusive changes to tests are needed, so that we don't rely on\nlibrary symbols that are now private (f.e. parse_rule).\n\nCloses-Bug: #1458945\nChange-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8\n""}]",1,176711,9143ce10e422bd17c4817dfe08163879e0e5a4ca,147,40,6,9656,,,0,"Consume oslo.policy

Some non intrusive changes to tests are needed, so that we don't rely on
library symbols that are now private (f.e. parse_rule).

Closes-Bug: #1458945
Change-Id: I90326479e908042fec9ecb25fa19a8dd5b15e7d8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/176711/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/v2/test_base.py', 'requirements.txt', 'neutron/api/v2/base.py', 'neutron/tests/unit/test_policy.py', 'neutron/api/v2/resource.py', 'openstack-common.conf', 'neutron/policy.py', 'neutron/openstack/common/policy.py']",8,2467bd230fc4b22eb63d2b0835ee5a176fe90ee8,policy,,"# -*- coding: utf-8 -*- # # Copyright (c) 2012 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Common Policy Engine Implementation Policies can be expressed in one of two forms: A list of lists, or a string written in the new policy language. In the list-of-lists representation, each check inside the innermost list is combined as with an ""and"" conjunction--for that check to pass, all the specified checks must pass. These innermost lists are then combined as with an ""or"" conjunction. As an example, take the following rule, expressed in the list-of-lists representation:: [[""role:admin""], [""project_id:%(project_id)s"", ""role:projectadmin""]] This is the original way of expressing policies, but there now exists a new way: the policy language. In the policy language, each check is specified the same way as in the list-of-lists representation: a simple ""a:b"" pair that is matched to the correct class to perform that check:: +===========================================================================+ | TYPE | SYNTAX | +===========================================================================+ |User's Role | role:admin | +---------------------------------------------------------------------------+ |Rules already defined on policy | rule:admin_required | +---------------------------------------------------------------------------+ |Against URL's¹ | http://my-url.org/check | +---------------------------------------------------------------------------+ |User attributes² | project_id:%(target.project.id)s | +---------------------------------------------------------------------------+ |Strings | <variable>:'xpto2035abc' | | | 'myproject':<variable> | +---------------------------------------------------------------------------+ | | project_id:xpto2035abc | |Literals | domain_id:20 | | | True:%(user.enabled)s | +===========================================================================+ ¹URL checking must return 'True' to be valid ²User attributes (obtained through the token): user_id, domain_id or project_id Conjunction operators are available, allowing for more expressiveness in crafting policies. So, in the policy language, the previous check in list-of-lists becomes:: role:admin or (project_id:%(project_id)s and role:projectadmin) The policy language also has the ""not"" operator, allowing a richer policy rule:: project_id:%(project_id)s and not role:dunce Attributes sent along with API calls can be used by the policy engine (on the right side of the expression), by using the following syntax:: <some_value>:%(user.id)s Contextual attributes of objects identified by their IDs are loaded from the database. They are also available to the policy engine and can be checked through the `target` keyword:: <some_value>:%(target.role.name)s Finally, two special policy checks should be mentioned; the policy check ""@"" will always accept an access, and the policy check ""!"" will always reject an access. (Note that if a rule is either the empty list (""[]"") or the empty string, this is equivalent to the ""@"" policy check.) Of these, the ""!"" policy check is probably the most useful, as it allows particular rules to be explicitly disabled. """""" import abc import ast import copy import logging import os import re from oslo_config import cfg from oslo_serialization import jsonutils import six import six.moves.urllib.parse as urlparse import six.moves.urllib.request as urlrequest from neutron.openstack.common import fileutils from neutron.openstack.common._i18n import _, _LE policy_opts = [ cfg.StrOpt('policy_file', default='policy.json', help=_('The JSON file that defines policies.')), cfg.StrOpt('policy_default_rule', default='default', help=_('Default rule. Enforced when a requested rule is not ' 'found.')), cfg.MultiStrOpt('policy_dirs', default=['policy.d'], help=_('Directories where policy configuration files are ' 'stored. They can be relative to any directory ' 'in the search path defined by the config_dir ' 'option, or absolute paths. The file defined by ' 'policy_file must exist for these directories to ' 'be searched. Missing or empty directories are ' 'ignored.')), ] CONF = cfg.CONF CONF.register_opts(policy_opts) LOG = logging.getLogger(__name__) _checks = {} def list_opts(): """"""Entry point for oslo-config-generator."""""" return [(None, copy.deepcopy(policy_opts))] class PolicyNotAuthorized(Exception): def __init__(self, rule): msg = _(""Policy doesn't allow %s to be performed."") % rule super(PolicyNotAuthorized, self).__init__(msg) class Rules(dict): """"""A store for rules. Handles the default_rule setting directly."""""" @classmethod def load_json(cls, data, default_rule=None): """"""Allow loading of JSON rule data."""""" # Suck in the JSON data and parse the rules rules = dict((k, parse_rule(v)) for k, v in jsonutils.loads(data).items()) return cls(rules, default_rule) def __init__(self, rules=None, default_rule=None): """"""Initialize the Rules store."""""" super(Rules, self).__init__(rules or {}) self.default_rule = default_rule def __missing__(self, key): """"""Implements the default rule handling."""""" if isinstance(self.default_rule, dict): raise KeyError(key) # If the default rule isn't actually defined, do something # reasonably intelligent if not self.default_rule: raise KeyError(key) if isinstance(self.default_rule, BaseCheck): return self.default_rule # We need to check this or we can get infinite recursion if self.default_rule not in self: raise KeyError(key) elif isinstance(self.default_rule, six.string_types): return self[self.default_rule] def __str__(self): """"""Dumps a string representation of the rules."""""" # Start by building the canonical strings for the rules out_rules = {} for key, value in self.items(): # Use empty string for singleton TrueCheck instances if isinstance(value, TrueCheck): out_rules[key] = '' else: out_rules[key] = str(value) # Dump a pretty-printed JSON representation return jsonutils.dumps(out_rules, indent=4) class Enforcer(object): """"""Responsible for loading and enforcing rules. :param policy_file: Custom policy file to use, if none is specified, `CONF.policy_file` will be used. :param rules: Default dictionary / Rules to use. It will be considered just in the first instantiation. If `load_rules(True)`, `clear()` or `set_rules(True)` is called this will be overwritten. :param default_rule: Default rule to use, CONF.default_rule will be used if none is specified. :param use_conf: Whether to load rules from cache or config file. :param overwrite: Whether to overwrite existing rules when reload rules from config file. """""" def __init__(self, policy_file=None, rules=None, default_rule=None, use_conf=True, overwrite=True): self.default_rule = default_rule or CONF.policy_default_rule self.rules = Rules(rules, self.default_rule) self.policy_path = None self.policy_file = policy_file or CONF.policy_file self.use_conf = use_conf self.overwrite = overwrite def set_rules(self, rules, overwrite=True, use_conf=False): """"""Create a new Rules object based on the provided dict of rules. :param rules: New rules to use. It should be an instance of dict. :param overwrite: Whether to overwrite current rules or update them with the new rules. :param use_conf: Whether to reload rules from cache or config file. """""" if not isinstance(rules, dict): raise TypeError(_(""Rules must be an instance of dict or Rules, "" ""got %s instead"") % type(rules)) self.use_conf = use_conf if overwrite: self.rules = Rules(rules, self.default_rule) else: self.rules.update(rules) def clear(self): """"""Clears Enforcer rules, policy's cache and policy's path."""""" self.set_rules({}) fileutils.delete_cached_file(self.policy_path) self.default_rule = None self.policy_path = None def load_rules(self, force_reload=False): """"""Loads policy_path's rules. Policy file is cached and will be reloaded if modified. :param force_reload: Whether to reload rules from config file. """""" if force_reload: self.use_conf = force_reload if self.use_conf: if not self.policy_path: self.policy_path = self._get_policy_path(self.policy_file) self._load_policy_file(self.policy_path, force_reload, overwrite=self.overwrite) for path in CONF.policy_dirs: try: path = self._get_policy_path(path) except cfg.ConfigFilesNotFoundError: continue self._walk_through_policy_directory(path, self._load_policy_file, force_reload, False) @staticmethod def _walk_through_policy_directory(path, func, *args): # We do not iterate over sub-directories. policy_files = next(os.walk(path))[2] policy_files.sort() for policy_file in [p for p in policy_files if not p.startswith('.')]: func(os.path.join(path, policy_file), *args) def _load_policy_file(self, path, force_reload, overwrite=True): reloaded, data = fileutils.read_cached_file( path, force_reload=force_reload) if reloaded or not self.rules or not overwrite: rules = Rules.load_json(data, self.default_rule) self.set_rules(rules, overwrite=overwrite, use_conf=True) LOG.debug(""Reloaded policy file: %(path)s"", {'path': path}) def _get_policy_path(self, path): """"""Locate the policy json data file/path. :param path: It's value can be a full path or related path. When full path specified, this function just returns the full path. When related path specified, this function will search configuration directories to find one that exists. :returns: The policy path :raises: ConfigFilesNotFoundError if the file/path couldn't be located. """""" policy_path = CONF.find_file(path) if policy_path: return policy_path raise cfg.ConfigFilesNotFoundError((path,)) def enforce(self, rule, target, creds, do_raise=False, exc=None, *args, **kwargs): """"""Checks authorization of a rule against the target and credentials. :param rule: A string or BaseCheck instance specifying the rule to evaluate. :param target: As much information about the object being operated on as possible, as a dictionary. :param creds: As much information about the user performing the action as possible, as a dictionary. :param do_raise: Whether to raise an exception or not if check fails. :param exc: Class of the exception to raise if the check fails. Any remaining arguments passed to enforce() (both positional and keyword arguments) will be passed to the exception class. If not specified, PolicyNotAuthorized will be used. :return: Returns False if the policy does not allow the action and exc is not provided; otherwise, returns a value that evaluates to True. Note: for rules using the ""case"" expression, this True value will be the specified string from the expression. """""" self.load_rules() # Allow the rule to be a Check tree if isinstance(rule, BaseCheck): result = rule(target, creds, self) elif not self.rules: # No rules to reference means we're going to fail closed result = False else: try: # Evaluate the rule result = self.rules[rule](target, creds, self) except KeyError: LOG.debug(""Rule [%s] doesn't exist"" % rule) # If the rule doesn't exist, fail closed result = False # If it is False, raise the exception if requested if do_raise and not result: if exc: raise exc(*args, **kwargs) raise PolicyNotAuthorized(rule) return result @six.add_metaclass(abc.ABCMeta) class BaseCheck(object): """"""Abstract base class for Check classes."""""" @abc.abstractmethod def __str__(self): """"""String representation of the Check tree rooted at this node."""""" pass @abc.abstractmethod def __call__(self, target, cred, enforcer): """"""Triggers if instance of the class is called. Performs the check. Returns False to reject the access or a true value (not necessary True) to accept the access. """""" pass class FalseCheck(BaseCheck): """"""A policy check that always returns False (disallow)."""""" def __str__(self): """"""Return a string representation of this check."""""" return ""!"" def __call__(self, target, cred, enforcer): """"""Check the policy."""""" return False class TrueCheck(BaseCheck): """"""A policy check that always returns True (allow)."""""" def __str__(self): """"""Return a string representation of this check."""""" return ""@"" def __call__(self, target, cred, enforcer): """"""Check the policy."""""" return True class Check(BaseCheck): """"""A base class to allow for user-defined policy checks."""""" def __init__(self, kind, match): """"""Initiates Check instance. :param kind: The kind of the check, i.e., the field before the ':'. :param match: The match of the check, i.e., the field after the ':'. """""" self.kind = kind self.match = match def __str__(self): """"""Return a string representation of this check."""""" return ""%s:%s"" % (self.kind, self.match) class NotCheck(BaseCheck): """"""Implements the ""not"" logical operator. A policy check that inverts the result of another policy check. """""" def __init__(self, rule): """"""Initialize the 'not' check. :param rule: The rule to negate. Must be a Check. """""" self.rule = rule def __str__(self): """"""Return a string representation of this check."""""" return ""not %s"" % self.rule def __call__(self, target, cred, enforcer): """"""Check the policy. Returns the logical inverse of the wrapped check. """""" return not self.rule(target, cred, enforcer) class AndCheck(BaseCheck): """"""Implements the ""and"" logical operator. A policy check that requires that a list of other checks all return True. """""" def __init__(self, rules): """"""Initialize the 'and' check. :param rules: A list of rules that will be tested. """""" self.rules = rules def __str__(self): """"""Return a string representation of this check."""""" return ""(%s)"" % ' and '.join(str(r) for r in self.rules) def __call__(self, target, cred, enforcer): """"""Check the policy. Requires that all rules accept in order to return True. """""" for rule in self.rules: if not rule(target, cred, enforcer): return False return True def add_check(self, rule): """"""Adds rule to be tested. Allows addition of another rule to the list of rules that will be tested. Returns the AndCheck object for convenience. """""" self.rules.append(rule) return self class OrCheck(BaseCheck): """"""Implements the ""or"" operator. A policy check that requires that at least one of a list of other checks returns True. """""" def __init__(self, rules): """"""Initialize the 'or' check. :param rules: A list of rules that will be tested. """""" self.rules = rules def __str__(self): """"""Return a string representation of this check."""""" return ""(%s)"" % ' or '.join(str(r) for r in self.rules) def __call__(self, target, cred, enforcer): """"""Check the policy. Requires that at least one rule accept in order to return True. """""" for rule in self.rules: if rule(target, cred, enforcer): return True return False def add_check(self, rule): """"""Adds rule to be tested. Allows addition of another rule to the list of rules that will be tested. Returns the OrCheck object for convenience. """""" self.rules.append(rule) return self def _parse_check(rule): """"""Parse a single base check rule into an appropriate Check object."""""" # Handle the special checks if rule == '!': return FalseCheck() elif rule == '@': return TrueCheck() try: kind, match = rule.split(':', 1) except Exception: LOG.exception(_LE(""Failed to understand rule %s"") % rule) # If the rule is invalid, we'll fail closed return FalseCheck() # Find what implements the check if kind in _checks: return _checks[kind](kind, match) elif None in _checks: return _checks[None](kind, match) else: LOG.error(_LE(""No handler for matches of kind %s"") % kind) return FalseCheck() def _parse_list_rule(rule): """"""Translates the old list-of-lists syntax into a tree of Check objects. Provided for backwards compatibility. """""" # Empty rule defaults to True if not rule: return TrueCheck() # Outer list is joined by ""or""; inner list by ""and"" or_list = [] for inner_rule in rule: # Elide empty inner lists if not inner_rule: continue # Handle bare strings if isinstance(inner_rule, six.string_types): inner_rule = [inner_rule] # Parse the inner rules into Check objects and_list = [_parse_check(r) for r in inner_rule] # Append the appropriate check to the or_list if len(and_list) == 1: or_list.append(and_list[0]) else: or_list.append(AndCheck(and_list)) # If we have only one check, omit the ""or"" if not or_list: return FalseCheck() elif len(or_list) == 1: return or_list[0] return OrCheck(or_list) # Used for tokenizing the policy language _tokenize_re = re.compile(r'\s+') def _parse_tokenize(rule): """"""Tokenizer for the policy language. Most of the single-character tokens are specified in the _tokenize_re; however, parentheses need to be handled specially, because they can appear inside a check string. Thankfully, those parentheses that appear inside a check string can never occur at the very beginning or end (""%(variable)s"" is the correct syntax). """""" for tok in _tokenize_re.split(rule): # Skip empty tokens if not tok or tok.isspace(): continue # Handle leading parens on the token clean = tok.lstrip('(') for i in range(len(tok) - len(clean)): yield '(', '(' # If it was only parentheses, continue if not clean: continue else: tok = clean # Handle trailing parens on the token clean = tok.rstrip(')') trail = len(tok) - len(clean) # Yield the cleaned token lowered = clean.lower() if lowered in ('and', 'or', 'not'): # Special tokens yield lowered, clean elif clean: # Not a special token, but not composed solely of ')' if len(tok) >= 2 and ((tok[0], tok[-1]) in [('""', '""'), (""'"", ""'"")]): # It's a quoted string yield 'string', tok[1:-1] else: yield 'check', _parse_check(clean) # Yield the trailing parens for i in range(trail): yield ')', ')' class ParseStateMeta(type): """"""Metaclass for the ParseState class. Facilitates identifying reduction methods. """""" def __new__(mcs, name, bases, cls_dict): """"""Create the class. Injects the 'reducers' list, a list of tuples matching token sequences to the names of the corresponding reduction methods. """""" reducers = [] for key, value in cls_dict.items(): if not hasattr(value, 'reducers'): continue for reduction in value.reducers: reducers.append((reduction, key)) cls_dict['reducers'] = reducers return super(ParseStateMeta, mcs).__new__(mcs, name, bases, cls_dict) def reducer(*tokens): """"""Decorator for reduction methods. Arguments are a sequence of tokens, in order, which should trigger running this reduction method. """""" def decorator(func): # Make sure we have a list of reducer sequences if not hasattr(func, 'reducers'): func.reducers = [] # Add the tokens to the list of reducer sequences func.reducers.append(list(tokens)) return func return decorator @six.add_metaclass(ParseStateMeta) class ParseState(object): """"""Implement the core of parsing the policy language. Uses a greedy reduction algorithm to reduce a sequence of tokens into a single terminal, the value of which will be the root of the Check tree. Note: error reporting is rather lacking. The best we can get with this parser formulation is an overall ""parse failed"" error. Fortunately, the policy language is simple enough that this shouldn't be that big a problem. """""" def __init__(self): """"""Initialize the ParseState."""""" self.tokens = [] self.values = [] def reduce(self): """"""Perform a greedy reduction of the token stream. If a reducer method matches, it will be executed, then the reduce() method will be called recursively to search for any more possible reductions. """""" for reduction, methname in self.reducers: if (len(self.tokens) >= len(reduction) and self.tokens[-len(reduction):] == reduction): # Get the reduction method meth = getattr(self, methname) # Reduce the token stream results = meth(*self.values[-len(reduction):]) # Update the tokens and values self.tokens[-len(reduction):] = [r[0] for r in results] self.values[-len(reduction):] = [r[1] for r in results] # Check for any more reductions return self.reduce() def shift(self, tok, value): """"""Adds one more token to the state. Calls reduce()."""""" self.tokens.append(tok) self.values.append(value) # Do a greedy reduce... self.reduce() @property def result(self): """"""Obtain the final result of the parse. Raises ValueError if the parse failed to reduce to a single result. """""" if len(self.values) != 1: raise ValueError(""Could not parse rule"") return self.values[0] @reducer('(', 'check', ')') @reducer('(', 'and_expr', ')') @reducer('(', 'or_expr', ')') def _wrap_check(self, _p1, check, _p2): """"""Turn parenthesized expressions into a 'check' token."""""" return [('check', check)] @reducer('check', 'and', 'check') def _make_and_expr(self, check1, _and, check2): """"""Create an 'and_expr'. Join two checks by the 'and' operator. """""" return [('and_expr', AndCheck([check1, check2]))] @reducer('and_expr', 'and', 'check') def _extend_and_expr(self, and_expr, _and, check): """"""Extend an 'and_expr' by adding one more check."""""" return [('and_expr', and_expr.add_check(check))] @reducer('check', 'or', 'check') def _make_or_expr(self, check1, _or, check2): """"""Create an 'or_expr'. Join two checks by the 'or' operator. """""" return [('or_expr', OrCheck([check1, check2]))] @reducer('or_expr', 'or', 'check') def _extend_or_expr(self, or_expr, _or, check): """"""Extend an 'or_expr' by adding one more check."""""" return [('or_expr', or_expr.add_check(check))] @reducer('not', 'check') def _make_not_expr(self, _not, check): """"""Invert the result of another check."""""" return [('check', NotCheck(check))] def _parse_text_rule(rule): """"""Parses policy to the tree. Translates a policy written in the policy language into a tree of Check objects. """""" # Empty rule means always accept if not rule: return TrueCheck() # Parse the token stream state = ParseState() for tok, value in _parse_tokenize(rule): state.shift(tok, value) try: return state.result except ValueError: # Couldn't parse the rule LOG.exception(_LE(""Failed to understand rule %s"") % rule) # Fail closed return FalseCheck() def parse_rule(rule): """"""Parses a policy rule into a tree of Check objects."""""" # If the rule is a string, it's in the policy language if isinstance(rule, six.string_types): return _parse_text_rule(rule) return _parse_list_rule(rule) def register(name, func=None): """"""Register a function or Check class as a policy check. :param name: Gives the name of the check type, e.g., 'rule', 'role', etc. If name is None, a default check type will be registered. :param func: If given, provides the function or class to register. If not given, returns a function taking one argument to specify the function or class to register, allowing use as a decorator. """""" # Perform the actual decoration by registering the function or # class. Returns the function or class for compliance with the # decorator interface. def decorator(func): _checks[name] = func return func # If the function or class is given, do the registration if func: return decorator(func) return decorator @register(""rule"") class RuleCheck(Check): def __call__(self, target, creds, enforcer): """"""Recursively checks credentials based on the defined rules."""""" try: return enforcer.rules[self.match](target, creds, enforcer) except KeyError: # We don't have any matching rule; fail closed return False @register(""role"") class RoleCheck(Check): def __call__(self, target, creds, enforcer): """"""Check that there is a matching role in the cred dict."""""" return self.match.lower() in [x.lower() for x in creds['roles']] @register('http') class HttpCheck(Check): def __call__(self, target, creds, enforcer): """"""Check http: rules by calling to a remote server. This example implementation simply verifies that the response is exactly 'True'. """""" url = ('http:' + self.match) % target # Convert instances of object() in target temporarily to # empty dict to avoid circular reference detection # errors in jsonutils.dumps(). temp_target = copy.deepcopy(target) for key in target.keys(): element = target.get(key) if type(element) is object: temp_target[key] = {} data = {'target': jsonutils.dumps(temp_target), 'credentials': jsonutils.dumps(creds)} post_data = urlparse.urlencode(data) f = urlrequest.urlopen(url, post_data) return f.read() == ""True"" @register(None) class GenericCheck(Check): def __call__(self, target, creds, enforcer): """"""Check an individual match. Matches look like: tenant:%(tenant_id)s role:compute:admin True:%(user.enabled)s 'Member':%(role.name)s """""" try: match = self.match % target except KeyError: # While doing GenericCheck if key not # present in Target return false return False try: # Try to interpret self.kind as a literal leftval = ast.literal_eval(self.kind) except ValueError: try: kind_parts = self.kind.split('.') leftval = creds for kind_part in kind_parts: leftval = leftval[kind_part] except KeyError: return False return match == six.text_type(leftval) ",76,1035
openstack%2Foslo.concurrency~master~I9dc5573004a6ee3648ab64b2fefe769c69ae8fbc,openstack/oslo.concurrency,master,I9dc5573004a6ee3648ab64b2fefe769c69ae8fbc,Updated from global requirements,MERGED,2015-06-10 23:49:28.000000000,2015-06-11 05:53:33.000000000,2015-06-11 05:53:32.000000000,"[{'_account_id': 3}, {'_account_id': 708}]","[{'number': 1, 'created': '2015-06-10 23:49:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/d6b9ed2def6eff75c9462e4d493b2b5edbbd9ee2', 'message': 'Updated from global requirements\n\nChange-Id: I9dc5573004a6ee3648ab64b2fefe769c69ae8fbc\n'}]",0,190410,d6b9ed2def6eff75c9462e4d493b2b5edbbd9ee2,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I9dc5573004a6ee3648ab64b2fefe769c69ae8fbc
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/10/190410/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d6b9ed2def6eff75c9462e4d493b2b5edbbd9ee2,openstack/requirements,fasteners>=0.5 # Apache-2.0,fasteners>=0.5 # Apache-2.0,1,1
openstack%2Fmagnum~master~I64d1b13cdc7c86a007b200bf2e2547216a66eefc,openstack/magnum,master,I64d1b13cdc7c86a007b200bf2e2547216a66eefc,Refactor magnum functional test to add Kubernetes API test,MERGED,2015-06-09 10:18:14.000000000,2015-06-11 05:44:18.000000000,2015-06-11 05:44:17.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 8143}, {'_account_id': 10206}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-06-09 10:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e5b7768dac1707e106147b6d568d34f106bc1139', 'message': 'Refactor magnum functional test to add Kubernetes API test\n\nTo test Kubernetes API, we need bay created and as already in\nmagnum functional test, we were creating bay. So this patch\nrefactors the code to seperate methods for each operation. So\nthat it can be used at other places.\n\nChange-Id: I64d1b13cdc7c86a007b200bf2e2547216a66eefc\nPartial-bug: #1460236\n'}, {'number': 2, 'created': '2015-06-10 12:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/16fbaee93db193115e50cb4ddb0900afce5cce54', 'message': 'Refactor magnum functional test to add Kubernetes API test\n\nTo test Kubernetes API, we need bay created and as already in\nmagnum functional test, we were creating bay. So this patch\nrefactors the code to seperate methods for each operation. So\nthat it can be used at other places.\n\nChange-Id: I64d1b13cdc7c86a007b200bf2e2547216a66eefc\nPartial-bug: #1460236\n'}, {'number': 3, 'created': '2015-06-11 01:09:17.000000000', 'files': ['magnum/tests/functional/test_magnum_python_client.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/789cf0ad2b8b05b94c942c8b406b569e409b0c82', 'message': 'Refactor magnum functional test to add Kubernetes API test\n\nTo test Kubernetes API, we need bay created and as already in\nmagnum functional test, we were creating bay. So this patch\nrefactors the code to seperate methods for each operation. So\nthat it can be used at other places.\n\nChange-Id: I64d1b13cdc7c86a007b200bf2e2547216a66eefc\nPartial-bug: #1460236\n'}]",10,189637,789cf0ad2b8b05b94c942c8b406b569e409b0c82,16,8,3,10206,,,0,"Refactor magnum functional test to add Kubernetes API test

To test Kubernetes API, we need bay created and as already in
magnum functional test, we were creating bay. So this patch
refactors the code to seperate methods for each operation. So
that it can be used at other places.

Change-Id: I64d1b13cdc7c86a007b200bf2e2547216a66eefc
Partial-bug: #1460236
",git fetch https://review.opendev.org/openstack/magnum refs/changes/37/189637/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/functional/test_magnum_python_client.py'],1,e5b7768dac1707e106147b6d568d34f106bc1139,bug/1460236," @classmethod def setUpClass(cls): cls.image_id = image_id cls.nic_id = nic_id cls.cs = client.Client(username=user, api_key=passwd, project_id=tenant_id, project_name=tenant, auth_url=auth_url, service_type='container', region_name=region_name, magnum_url=magnum_url) @classmethod def _wait_on_status(cls, bay, wait_status, finish_status): # Check status every 5 seconds for a total of 120 minutes for i in range(100): status = cls.cs.bays.get(bay.uuid).status if status in wait_status: time.sleep(60) elif status in finish_status: break else: raise Exception(""Unknown Status : %s"" % status) @classmethod def _create_baymodel(cls): baymodel = cls.cs.baymodels.create( name='default', keypair_id='default', external_network_id=cls.nic_id, image_id=cls.image_id, flavor_id='m1.small', docker_volume_size=5, coe='kubernetes', ) return baymodel @classmethod def _create_bay(cls, baymodel_uuid, wait=True): bay = cls.cs.bays.create( name='k8s', baymodel_id=baymodel_uuid, node_count=None, ) if wait: cls._wait_on_status(bay, [None, ""CREATE_IN_PROGRESS""], [""CREATE_FAILED"", ""CREATED"", ""CREATE_COMPLETE""]) return bay @classmethod def _delete_baymodel(cls, baymodel_uuid): cls.cs.baymodels.delete(baymodel_uuid) @classmethod def _delete_bay(cls, bay_uuid): cls.cs.bays.delete(bay_uuid) baymodel = self._create_baymodel() self.baymodel = self._create_baymodel() def test_bay_create_and_delete(self): bay = self._create_bay(self.baymodel.uuid)"," self.image_id = image_id self.nic_id = nic_id self.cs = client.Client(username=user, api_key=passwd, project_id=tenant_id, project_name=tenant, auth_url=auth_url, service_type='container', region_name=region_name, magnum_url=magnum_url) baymodel = self.cs.baymodels.create( name='default', keypair_id='default', external_network_id=self.nic_id, image_id=self.image_id, flavor_id='m1.small', docker_volume_size=5, coe='kubernetes', ) self.baymodel = self.cs.baymodels.create( name='default', keypair_id='default', external_network_id=self.nic_id, image_id=self.image_id, flavor_id='m1.small', docker_volume_size=5, coe='kubernetes', ) def _wait_on_status(self, bay, wait_status, finish_status): # Check status every 5 seconds for a total of 120 minutes for i in range(100): status = self.cs.bays.get(bay.uuid).status if status in wait_status: time.sleep(60) elif status in finish_status: break else: self.assertTrue(False, ""Unknown Status : %s"" % status) def test_bay_create_and_delete(self): bay = self.cs.bays.create( name='k8s', baymodel_id=self.baymodel.uuid, node_count=None, ) self._wait_on_status(bay, [None, ""CREATE_IN_PROGRESS""], [""CREATE_FAILED"", ""CREATED"", ""CREATE_COMPLETE""])",65,49
openstack%2Fnova-specs~master~I0988295d0e74be1ebfb83bbd4fd56540f8728e71,openstack/nova-specs,master,I0988295d0e74be1ebfb83bbd4fd56540f8728e71,Improved server actions api,ABANDONED,2015-03-11 01:23:46.000000000,2015-06-11 05:16:51.000000000,,"[{'_account_id': 3}, {'_account_id': 782}]","[{'number': 1, 'created': '2015-03-11 01:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a63b9b7ff66a26f12076321bc69ce5d5e2058961', 'message': 'Improved server actions api\n\nThe list server actions API is often used in situation of\ntroubleshooting by cloud administrator. However, This API has\nsome limitations. We need to remove these limitations for\nmake it more useful.\n\nBlueprint: improved-server-actions-api\n\nChange-Id: I0988295d0e74be1ebfb83bbd4fd56540f8728e71\n'}, {'number': 2, 'created': '2015-03-11 01:41:11.000000000', 'files': ['specs/liberty/improved-server-actions-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b38a33272ec18184180837549ce201b9c91e96e4', 'message': 'Improved server actions api\n\nThe list server actions API is often used in situation of\ntroubleshooting by cloud administrator. However, This API has\nsome limitations. We need to remove these limitations for\nmake it more useful.\n\nBlueprint: improved-server-actions-api\nChange-Id: I0988295d0e74be1ebfb83bbd4fd56540f8728e71\n'}]",11,163253,b38a33272ec18184180837549ce201b9c91e96e4,6,2,2,7121,,,0,"Improved server actions api

The list server actions API is often used in situation of
troubleshooting by cloud administrator. However, This API has
some limitations. We need to remove these limitations for
make it more useful.

Blueprint: improved-server-actions-api
Change-Id: I0988295d0e74be1ebfb83bbd4fd56540f8728e71
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/53/163253/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/improved-server-actions-api.rst'],1,a63b9b7ff66a26f12076321bc69ce5d5e2058961,bp/improved-server-actions-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Improved server actions API ========================================== https://blueprints.launchpad.net/nova/+spec/improved-server-actions-api The list server actions API is often used in situation of troubleshooting by cloud administrator. However, This API has some limitations. We need to remove these limitations for make it more useful. Problem description =================== The list server actions API has the following limitations. * User can not only see the start time of each action. * User can not only grep actions by instance. * Some of the actions ( e.g. image-create, lock, unlock ) are not registered in action lists. ( So, user can't confirm about these actions.) <Example of use> nova instance-action-list 3cd10ad2-55c7-47a4-9c04-0a8d253ba2cf +---------+------------------------------------------+---------+----------------------------+ | Action | Request_ID | Message | Start_Time | +=========+==========================================+=========+============================+ | create | req-f4c9644d-0bb5-4ae2-8347-baef7f32111b | - | 2015-03-02T07:23:27.000000 | | suspend | req-3acf0e11-122f-4162-81c9-f68ecebe41c3 | - | 2015-03-02T07:27:23.000000 | | resume | req-12d67d94-b809-405d-80ef-01f6740441b7 | - | 2015-03-02T07:27:46.000000 | | reboot | req-e51e866b-d29b-4de4-bff1-564d8a76d618 | - | 2015-03-03T04:57:50.000000 | +---------+------------------------------------------+---------+----------------------------+ Use Cases ---------- The improved API may be used the following situations. Case 1. Cloud administrator see the execution time of each action to evaluate cloud performance. * The execution time is very important information to evaluate cloud performance. * The admin user can retrieve all the actions in the system. Case 2. When something problem occurred, cloud administrator confirm what operation have been executed at that time range. * The API allow user to grep actions by a specified user, tenant and time range. <Example of use> nova instance-action-list --tenant 2b91981800ec4eb69c111eb77e0d589b --time start=2015-03-02T06:00:00,end=2015-03-03T06:00:00 +---------------+------------------------------------------+---------------------------------------+---------+----------------------------+-----------------+ | Action | Request_ID | Instance_ID | Message | Start_Time | Execution_Time | +---------------+------------------------------------------+---------------------------------------+---------+----------------------------+-----------------+ | create | req-f4c9644d-0bb5-4ae2-8347-baef7f32111b | 3cd10ad2-55c7-47a4-9c04-0a8d253ba2cf | - | 2015-03-02T07:23:27.000000 | 00:05:10.000000 | | suspend | req-3acf0e11-122f-4162-81c9-f68ecebe41c3 | 3cd10ad2-55c7-47a4-9c04-0a8d253ba2cf | - | 2015-03-02T07:27:23.000000 | 00:00:14.000000 | | resume | req-12d67d94-b809-405d-80ef-01f6740441b7 | 3cd10ad2-55c7-47a4-9c04-0a8d253ba2cf | - | 2015-03-02T07:27:46.000000 | 00:00:20.000000 | | reboot | req-e51e866b-d29b-4de4-bff1-564d8a76d618 | 1d21bc64-3e41-4ea0-9f5e-1291c9a9395c | - | 2015-03-03T04:57:50.000000 | 00:01:00.000000 | | create-image | req-7402a466-8119-4810-824b-5760702042cb | 1d21bc64-3e41-4ea0-9f5e-1291c9a9395c | - | 2015-03-03T05:00:00.000000 | 00:15:30.000000 | | live-migrate | req-3912c3b0-2d65-44ba-a864-c00323e5c694 | a9e30a9f-9294-4c74-b6e1-9dcde7d183c6 | - | 2015-03-03T05:30:00.000000 | 00:01:30.000000 | +---------------+------------------------------------------+---------------------------------------+---------+----------------------------+-----------------+ Project Priority ----------------- None Proposed change =============== The nova-api, database module and python-novaclient need to be modified. nova-api * Add the _record_action_finish() method in nova.compute.api to registrate the finish_time of action. * Modify nova.compute.api so that all the actions call the _record_action_start() and _record_action_finish() method. * Modify nova.api.openstack.compute.contrib.instance_actions as follows. * Store the query information into filter_dictionary and sort_dictionary. * Request to the database with filter_dictionary and sort_dictionary. * Return the action lists after calculating the execution time of each action. database module * Modify the actions_get() method in nova.db.sqlalchemy.api to search according to the specified parameters. python-novaclient * Modify the instance-action-list command according to the improved specification (see ""REST API impact"" section for details). Alternatives ------------ All the services send notifications about the executed operations in OpenStack. So user can confirm details of actions (e.g. execution time of each action) by analyzing notification data. However, it is necessary to manage a service which collect and analyze notification data (like logstash) to make it possible. Data model impact ----------------- None REST API impact --------------- * Request /v2/?{tenant_id}?/os-instance-actions * Request parameters +---------------+-------+--------------+--------------------------------------+ | Parameter | Style | Type | Description | +===============+=======+==============+======================================+ | user | query | csapi:UUID | UUID of the user which | | (optional) | | | you want to grep by. | +---------------+-------+--------------+--------------------------------------+ | tenant | query | csapi:UUID | UUID of the tenant which | | (optional) | | | you want to grep by. | +---------------+-------+--------------+--------------------------------------+ | instance | query | csapi:UUID | UUID of the instanace which | | (optional) | | | you want to grep by. | +---------------+-------+--------------+--------------------------------------+ | start_time | query | xsd:dateTime | Start time of the time range. | | (optional) | | | | +---------------+-------+--------------+--------------------------------------+ | end_time | query | xsd:dateTime | End time of the time range. | | (optional) | | | | +---------------+-------+--------------+--------------------------------------+ * Response :: { ""instanceActions"": [ { ""action"": ""resize"", ""execution_time"": ""00:10:00.000000"", ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"", ""message"": """", ""project_id"": ""842"", ""request_id"": ""req-25517360-b757-47d3-be45-0e8d2a01b36a"", ""start_time"": ""2012-12-05 01:00:00.000000"", ""user_id"": ""789"" }, { ""action"": ""reboot"", ""execution_time"": ""00:15:00.000000"", ""instance_uuid"": ""b48316c5-71e8-45e4-9884-6c78055b9b13"", ""message"": """", ""project_id"": ""147"", ""request_id"": ""req-3293a3f1-b44c-4609-b8d2-d81b105636b8"", ""start_time"": ""2012-12-05 00:00:00.000000"", ""user_id"": ""789"" } ] } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <h-eguchi> Work Items ---------- * Modify the nova-api and database module (include unit tests) at first (see ""Proposed change"" section for details). * Modify the python-novaclient (see ""REST API impact"" section for details). * Modify the tempest. * Update the API documentations (see ""REST API impact"" section for details). Dependencies ============ None Testing ======= Both unit and Tempest tests need to be created to ensure that the action lists are accurate. Documentation Impact ==================== Need to update Compute v2 API extension (see ""REST API impact"" section for details). References ========== None ",,246,0
openstack%2Fnova-specs~master~I7fdc9850da2f75552fde2cebb9811b222b4b0a9b,openstack/nova-specs,master,I7fdc9850da2f75552fde2cebb9811b222b4b0a9b,flavor access create should check public/private,MERGED,2015-04-10 12:03:33.000000000,2015-06-11 04:59:48.000000000,2015-06-11 04:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 5754}, {'_account_id': 6062}]","[{'number': 1, 'created': '2015-04-10 12:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3e1b84391d76211691094483a442fc972d92a098', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}, {'number': 2, 'created': '2015-04-10 12:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6765045f303f13bcf4289c04bb6c07afdc038314', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}, {'number': 3, 'created': '2015-04-30 13:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2764b388e9b926f4b23f09a91a0794772b7cb60c', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}, {'number': 4, 'created': '2015-04-30 13:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f0c7455666a0c875b941ce4dff69a62363dfd95f', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}, {'number': 5, 'created': '2015-04-30 13:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7b57b8a7859719ac54a3039df3c82c4212f444ab', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}, {'number': 6, 'created': '2015-05-04 16:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/45030eb5a3b66dbc6cb2542ab86ad935023a58a6', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nAPIImpact\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}, {'number': 7, 'created': '2015-05-12 09:22:01.000000000', 'files': ['specs/liberty/approved/check-flavor-type-before-add-tenant.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/968a5e2ed0d45964b4ad51ad1c5387006eb90905', 'message': 'flavor access create should check public/private\n\nAdd check-flavor-type-before-add-tenant.rst\n\nAPIImpact\n\nChange-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b\n'}]",13,172388,968a5e2ed0d45964b4ad51ad1c5387006eb90905,25,5,7,6062,,,0,"flavor access create should check public/private

Add check-flavor-type-before-add-tenant.rst

APIImpact

Change-Id: I7fdc9850da2f75552fde2cebb9811b222b4b0a9b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/88/172388/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/approved/check-flavor-type-before-add-tenant.rst'],1,3e1b84391d76211691094483a442fc972d92a098,check-flavor-type-before-add-tenant,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Check flavor type before add tenant access ========================================== https://blueprints.launchpad.net/nova/+spec/check-flavor-type-before-add-tenant Problem description =================== Because flavor can be public and private, we need to check public and private first before create flavor access, detailed in [1] [2]. This is backward incompatible bug, every API change need spec. Use Cases ---------- Fix bug in [1]. Project Priority ----------------- None Proposed change =============== According to [1][2] , need to change the API validation of os-flavor-access/addTenantAccess action. Alternatives ------------ No because it's a bug. Data model impact ----------------- None REST API impact --------------- os-flavor-access/addTenantAccess will be affected, but input/output will not be affected, only additional check will be added. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- jichenjc <jichenjc@cn.ibm.com> Work Items ---------- Add API change through microversion because it's backward incompatible. 1) Add microversion to os-flavor-access/addTenantAccess 2) Add validation before add access. Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== [1] https://bugs.launchpad.net/nova/+bug/1361476 ",,115,0
openstack%2Fnova-specs~master~I806b35a29f70a09fd06692adff6d0af9ef486fe3,openstack/nova-specs,master,I806b35a29f70a09fd06692adff6d0af9ef486fe3,Add liberty priorities,MERGED,2015-06-01 18:21:15.000000000,2015-06-11 04:52:16.000000000,2015-06-11 04:52:15.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 162}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4992}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8688}, {'_account_id': 12171}, {'_account_id': 12898}]","[{'number': 1, 'created': '2015-06-01 18:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5b2df3e646b92d5af938b75f0279ba10da2199b7', 'message': 'Add liberty priorities\n\nWIP\n\nChange-Id: I806b35a29f70a09fd06692adff6d0af9ef486fe3\n'}, {'number': 2, 'created': '2015-06-02 10:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/18a155459fe42da2dca550d6c362fb5a12ae85f0', 'message': ""Add liberty priorities\n\nAt the summit we agreed the priorities for the liberty release.\nThis records the outcome of that discussion, and allows those unable\nto be at the summit to be involved in  that discussion.\n\nIn addition, I have added some information about the most important\nthings that were discussed, but don't yet have a firm enough plan\nto go on the list of priorities.\n\nChange-Id: I806b35a29f70a09fd06692adff6d0af9ef486fe3\n""}, {'number': 3, 'created': '2015-06-02 10:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/83a9951b00df37df71073e4c5c1c50a9c42c36c8', 'message': ""Add liberty priorities\n\nAt the summit we agreed the priorities for the liberty release.\nThis records the outcome of that discussion, and allows those unable\nto be at the summit to be involved in  that discussion.\n\nIn addition, I have added some information about the most important\nthings that were discussed, but don't yet have a firm enough plan\nto go on the list of priorities.\n\nThe raw discussion notes can be found here:\nhttps://etherpad.openstack.org/p/YVR-nova-liberty-priorities\n\nChange-Id: I806b35a29f70a09fd06692adff6d0af9ef486fe3\n""}, {'number': 4, 'created': '2015-06-08 09:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0b1eaba072ddbe58323a06ea9a3b287d5dedbbd2', 'message': ""Add liberty priorities\n\nAt the summit we agreed the priorities for the liberty release.\nThis records the outcome of that discussion, and allows those unable\nto be at the summit to be involved in  that discussion.\n\nIn addition, I have added some information about the most important\nthings that were discussed, but don't yet have a firm enough plan\nto go on the list of priorities.\n\nThe raw discussion notes can be found here:\nhttps://etherpad.openstack.org/p/YVR-nova-liberty-priorities\n\nChange-Id: I806b35a29f70a09fd06692adff6d0af9ef486fe3\n""}, {'number': 5, 'created': '2015-06-08 19:43:13.000000000', 'files': ['priorities/liberty-priorities.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/353215cf168e500ef940f8eca852bed5c93dcb4f', 'message': ""Add liberty priorities\n\nAt the summit we agreed the priorities for the liberty release.\nThis records the outcome of that discussion, and allows those unable\nto be at the summit to be involved in  that discussion.\n\nIn addition, I have added some information about the most important\nthings that were discussed, but don't yet have a firm enough plan\nto go on the list of priorities.\n\nThe raw discussion notes can be found here:\nhttps://etherpad.openstack.org/p/YVR-nova-liberty-priorities\n\nChange-Id: I806b35a29f70a09fd06692adff6d0af9ef486fe3\n""}]",28,187272,353215cf168e500ef940f8eca852bed5c93dcb4f,33,17,5,782,,,0,"Add liberty priorities

At the summit we agreed the priorities for the liberty release.
This records the outcome of that discussion, and allows those unable
to be at the summit to be involved in  that discussion.

In addition, I have added some information about the most important
things that were discussed, but don't yet have a firm enough plan
to go on the list of priorities.

The raw discussion notes can be found here:
https://etherpad.openstack.org/p/YVR-nova-liberty-priorities

Change-Id: I806b35a29f70a09fd06692adff6d0af9ef486fe3
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/72/187272/1 && git format-patch -1 --stdout FETCH_HEAD,['priorities/liberty-priorities.rst'],1,5b2df3e646b92d5af938b75f0279ba10da2199b7,187272,".. _kilo-priorities: =========================== Liberty Project Priorities =========================== List of priorities (in the form of use cases) the nova development team is prioritizing in Liberty (in no particular order). For more information see: http://docs.openstack.org/developer/nova/devref/kilo.blueprints.html#project-priorities +-------------------------+-----------------------+ | Priority | Owner | +=========================+=======================+ | `Cells V2`_ | `Andrew Laski`_ | +-------------------------+-----------------------+ | `V2.1 API`_ | `Ken'ichi Ohmichi`_, | | | `Sean Dague`_ | +-------------------------+-----------------------+ | `Scheduler`_ | `Jay Pipes`_ | +-------------------------+-----------------------+ | `Upgrades`_ | `Dan Smith`_ | +-------------------------+-----------------------+ | `DevRef Update`_ | `John Garbutt`_ | +-------------------------+-----------------------+ .. _Andrew Laski: https://launchpad.net/~alaski .. _Ken'ichi Ohmichi: https://launchpad.net/~oomichi .. _Sean Dague: https://launchpad.net/~sdague .. _Jay Pipes: https://launchpad.net/~jaypipes .. _Dan Smith: https://launchpad.net/~danms .. _John Garbutt: https://launchpad.net/~johngarbutt Priorities without a clear plan ------------------------------- Here are some things we would like to be a priority, but we are currently lacking either a clear plan or someone to lead that effort. * A plan for the future of flavors, image properties and host aggregates * Tasks for API triggered operations * Simplify Quotas * Revisit how we talk to Glance, Neutron and Cinder APIs * Neutron/Nova-network integration (Fast Path, VIF plug) * Feature Test Classification * Fixing more bugs `John Garbutt`_ will work with the Nova community to get backlog specs defined for all of the above. Should we find people to work on these issues, it possible we might promote them to an official priority later in the release, should their appear to be room in the review pipeline. Cells v2 -------- We started the cells v2 effort in Kilo. During Liberty are are focusing on making the default setup a single cells v2 deployment. In the M release, we hope to look allowing having multiple cells in a cells v2 deployment, and look at having a way to migrate existing cells v1 deployments to cells v2. V2.1 API --------- Complete the work around API microversions, with a particular focus on documentation and python-novaclient support. We also need to define the policy around when to bump the API microversion and what is changes are allowed in a microversion bump. We are explicitly excluding work on porting any cosmetic changes from the previous v3 API efforts into new API microversions. Scheduler --------- During Kilo we made much progress on cleaning up the interface between the scheduler and the test of Nova. In Liberty we hope to complete the work around request spec and resource objects. We also want to start looking at the service group API, and more work on the resource tracker. Upgrades --------- While we have made great strides with our upgrades, we still need to complete the online DB schema migrations. We need to also spend time documenting the current approach around online data migrations, object versioning, and RPC versioning. DevRef Update -------------- A key part of being able to scale out the Nova team, is doing a better job of sharing information on how the Nova community operates, how the Nova architecture works, the basic design tenants we are suing, the scope of Nova, and so on. The main goal, is to make it easier to on board new Nova contributors, and make it easier to discover and decisions that have been already made by the community. ",,106,0
openstack%2Fsenlin~master~I88cb033974b57acda1678039a8362bdbee5bf7a4,openstack/senlin,master,I88cb033974b57acda1678039a8362bdbee5bf7a4,Add data field to action DB model for policy_check,MERGED,2015-06-10 05:28:20.000000000,2015-06-11 04:27:26.000000000,2015-06-11 04:27:24.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-10 05:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/929c210878d259742158ad3f73626476ab910ed3', 'message': ""Add data field to action DB model for policy_check\n\nThis patch added a data field to action DB model. This field is\nused to store result data that generated during policy_check and\naction execution.\n\nThis patch also recorded the id of nodes which was deleted or\ncreated during action progress. This id list will be persisted\ninto DB as action data and then consumed by policies whose check\ntarget is 'AFTER'.\n\nChange-Id: I88cb033974b57acda1678039a8362bdbee5bf7a4\n""}, {'number': 2, 'created': '2015-06-10 09:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/63ec333afc1e29db196d5e04ed93f730f6962ef8', 'message': ""Add data field to action DB model for policy_check\n\nThis patch added a data field to action DB model. This field is\nused to store result data that generated during policy_check and\naction execution. Based on this, policy_data parameter is not\nneeded anymore when invoking attach/detach/pre_op/post_op methods\nof policy and all action methods.\n\nThis patch also recorded the id of nodes which was deleted or\ncreated during action progress. This id list will be persisted\ninto DB as action data and then consumed by policies whose check\ntarget is 'AFTER'.\n\nChange-Id: I88cb033974b57acda1678039a8362bdbee5bf7a4\n""}, {'number': 3, 'created': '2015-06-11 03:29:02.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/policies/lb_policy.py', 'senlin/tests/db/test_action_api.py', 'senlin/engine/actions/node_action.py', 'senlin/policies/deletion_policy.py', 'senlin/policies/base.py', 'senlin/engine/actions/base.py', 'senlin/db/sqlalchemy/migrate_repo/versions/001_first_version.py', 'senlin/policies/placement_policy.py', 'senlin/policies/update_policy.py', 'senlin/db/sqlalchemy/models.py', 'senlin/policies/scaling_in_policy.py', 'senlin/engine/actions/cluster_action.py', 'senlin/policies/scaling_out_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7f992b772e52e003351547bade8e1487756851d4', 'message': ""Add data field to action DB model for policy_check\n\nThis patch added a data field to action DB model. This field is\nused to store result data that generated during policy_check and\naction execution. Based on this, policy_data parameter is not\nneeded anymore when invoking attach/detach/pre_op/post_op methods\nof policy and all action methods.\n\nThis patch also recorded the id of nodes which was deleted or\ncreated during action progress. This id list will be persisted\ninto DB as action data and then consumed by policies whose check\ntarget is 'AFTER'.\n\nChange-Id: I88cb033974b57acda1678039a8362bdbee5bf7a4\n""}]",11,190027,7f992b772e52e003351547bade8e1487756851d4,14,3,3,11034,,,0,"Add data field to action DB model for policy_check

This patch added a data field to action DB model. This field is
used to store result data that generated during policy_check and
action execution. Based on this, policy_data parameter is not
needed anymore when invoking attach/detach/pre_op/post_op methods
of policy and all action methods.

This patch also recorded the id of nodes which was deleted or
created during action progress. This id list will be persisted
into DB as action data and then consumed by policies whose check
target is 'AFTER'.

Change-Id: I88cb033974b57acda1678039a8362bdbee5bf7a4
",git fetch https://review.opendev.org/openstack/senlin refs/changes/27/190027/3 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/db/sqlalchemy/migrate_repo/versions/001_first_version.py', 'senlin/db/sqlalchemy/models.py', 'senlin/tests/db/test_action_api.py', 'senlin/engine/actions/cluster_action.py', 'senlin/policies/base.py', 'senlin/engine/actions/base.py']",6,929c210878d259742158ad3f73626476ab910ed3,add-action-data-field-for-policy-data," self.data = kwargs.get('data', {}) 'data': self.data, db_api.action_update(context, self.id, values) self.id = action.id 'data': record.data, # Initialize a PolicyData object for policy check result data = policy_mod.PolicyData(data=self.data) # Persist policy check result into DB self.data = data.data self.store(self.context) 'data': self.data,"," action = db_api.action_update(context, values) self.id = action.id # Initialize an empty dict for policy check result data = policy_mod.PolicyData()",37,10
openstack%2Fopenstack-doc-tools~master~I01422bf33be286cc0176a3e1e4ac1c348c6821ef,openstack/openstack-doc-tools,master,I01422bf33be286cc0176a3e1e4ac1c348c6821ef,autohelp: use correct option names from extensions,MERGED,2015-06-11 02:00:53.000000000,2015-06-11 04:14:59.000000000,2015-06-11 04:14:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-06-11 02:00:53.000000000', 'files': ['autogenerate_config_docs/autohelp.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/6329eea32aaedce2dfb41a99c767795d80e1da57', 'message': ""autohelp: use correct option names from extensions\n\nautohelp's OptionsCache.load_extension_options() loads options from\nlibraries. An oslo_config.cfg.Opt object has a 'name' attribute and\na 'dest' attribute. The option name that we're interested in (that\nthe user sets) is the 'dest' value, not the 'name' value. The\nload_extension_options() method was incorrectly using the option's\n'name' attribute.\n\nThis fixes it so that the option's 'dest' attribute is used instead.\nEg, from oslo_log library, it now correctly uses 'log_config_append'\ninstead of 'log-config-append'.\n\nChange-Id: I01422bf33be286cc0176a3e1e4ac1c348c6821ef\nCloses-Bug: #1464058\n""}]",0,190455,6329eea32aaedce2dfb41a99c767795d80e1da57,7,3,1,6618,,,0,"autohelp: use correct option names from extensions

autohelp's OptionsCache.load_extension_options() loads options from
libraries. An oslo_config.cfg.Opt object has a 'name' attribute and
a 'dest' attribute. The option name that we're interested in (that
the user sets) is the 'dest' value, not the 'name' value. The
load_extension_options() method was incorrectly using the option's
'name' attribute.

This fixes it so that the option's 'dest' attribute is used instead.
Eg, from oslo_log library, it now correctly uses 'log_config_append'
instead of 'log-config-append'.

Change-Id: I01422bf33be286cc0176a3e1e4ac1c348c6821ef
Closes-Bug: #1464058
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/55/190455/1 && git format-patch -1 --stdout FETCH_HEAD,['autogenerate_config_docs/autohelp.py'],1,6329eea32aaedce2dfb41a99c767795d80e1da57,bug/1464058," self._add_opt(opt.dest, 'DEFAULT', opt) else: self._add_opt(group + '/' + opt.dest, group, opt)"," self._add_opt(opt.name, 'DEFAULT', opt) else: self._add_opt(group + '/' + opt.name, group, opt)",2,2
openstack%2Fheat~master~I75e07158588827456eaf0448b5b47d25d788ce16,openstack/heat,master,I75e07158588827456eaf0448b5b47d25d788ce16,Add unit test case for Keystone client plug-in for domain,MERGED,2015-06-09 09:15:16.000000000,2015-06-11 04:08:21.000000000,2015-06-11 04:08:20.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}]","[{'number': 1, 'created': '2015-06-09 09:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3b5055e976e56f6ec626cfa5ba53f2e2d4d7be7f', 'message': 'Add unit test case for Keystone client plugin for domain\n\nAdds required unit test cases for the keystone domain\nin the keystone client plugin\n\nPartially Closes-bug: #1463267\n\nChange-Id: I75e07158588827456eaf0448b5b47d25d788ce16\n'}, {'number': 2, 'created': '2015-06-09 10:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/38a9c224b5b318c446b34d4174e13075a5c427d0', 'message': 'Add unit test case for Keystone client plugin for domain\n\nAdds required unit test cases for the keystone domain\nin the keystone client plugin\n\nPartially Closes-bug: #1463267\n\nChange-Id: I75e07158588827456eaf0448b5b47d25d788ce16\n'}, {'number': 3, 'created': '2015-06-10 11:45:21.000000000', 'files': ['heat/tests/keystone/test_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d821a9f9ba141218d96b01a2a113f3ee35cd7c01', 'message': 'Add unit test case for Keystone client plug-in for domain\n\nAdds required unit test cases for the keystone domain\nin the keystone client plug-in\n\nPartial-Bug: #1463267\n\nChange-Id: I75e07158588827456eaf0448b5b47d25d788ce16\n'}]",1,189606,d821a9f9ba141218d96b01a2a113f3ee35cd7c01,15,3,3,10487,,,0,"Add unit test case for Keystone client plug-in for domain

Adds required unit test cases for the keystone domain
in the keystone client plug-in

Partial-Bug: #1463267

Change-Id: I75e07158588827456eaf0448b5b47d25d788ce16
",git fetch https://review.opendev.org/openstack/heat refs/changes/06/189606/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/keystone/test_client.py'],1,3b5055e976e56f6ec626cfa5ba53f2e2d4d7be7f,bug/1463267-keystone-client-plugin-tests," class KeystoneClientPluginDomainTest(common.HeatTestCase): sample_uuid = '477e8273-60a7-4c41-b683-fdb0bc7cd152' sample_name = 'sample_domain' def _get_mock_domain(self): domain = mock.MagicMock() domain.id = self.sample_uuid domain.name = self.sample_name return domain def setUp(self): super(KeystoneClientPluginDomainTest, self).setUp() self._client = mock.MagicMock() self._client.client = mock.MagicMock() self._client.client.domains = mock.MagicMock() @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_domain_id(self, client_keystone): self._client.client.domains.get.return_value = (self ._get_mock_domain()) client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_domain_id(self.sample_uuid)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_domain_id_with_name(self, client_keystone): self._client.client.domains.get.side_effect = (keystone_exceptions .NotFound) self._client.client.domains.list.return_value = [ self._get_mock_domain() ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_domain_id(self.sample_name)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_domain_id_not_found(self, client_keystone): self._client.client.domains.get.side_effect = (keystone_exceptions .NotFound) self._client.client.domains.list.return_value = [ ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) ex = self.assertRaises(exception.EntityNotFound, client_plugin.get_domain_id, self.sample_name) msg = (""The KeystoneDomain (%(name)s) could not be found."" % {'name': self.sample_name}) self.assertEqual(msg, six.text_type(ex))",,66,0
openstack%2Fheat~master~Id29274d1419fd89fa2e0d8474a580e67db5622d7,openstack/heat,master,Id29274d1419fd89fa2e0d8474a580e67db5622d7,Add unit test case for Keystone client plug-in for project,MERGED,2015-06-09 09:15:16.000000000,2015-06-11 04:08:12.000000000,2015-06-11 04:08:11.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-09 09:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d635b539befb5a8562dc9888cf6e229a91f8ac6e', 'message': 'Add unit test case for Keystone client plugin for project\n\nAdds required unit test cases for the keystone project\nin the keystone client plugin\n\nPartially Closes-bug: #1463267\n\nChange-Id: Id29274d1419fd89fa2e0d8474a580e67db5622d7\n'}, {'number': 2, 'created': '2015-06-10 11:45:21.000000000', 'files': ['heat/tests/keystone/test_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/838aa3a96dd45e06adf897946f7ab3a5d976d35b', 'message': 'Add unit test case for Keystone client plug-in for project\n\nAdds required unit test cases for the keystone project\nin the keystone client plug-in\n\nPartial-Bug: #1463267\n\nChange-Id: Id29274d1419fd89fa2e0d8474a580e67db5622d7\n'}]",0,189605,838aa3a96dd45e06adf897946f7ab3a5d976d35b,12,4,2,10487,,,0,"Add unit test case for Keystone client plug-in for project

Adds required unit test cases for the keystone project
in the keystone client plug-in

Partial-Bug: #1463267

Change-Id: Id29274d1419fd89fa2e0d8474a580e67db5622d7
",git fetch https://review.opendev.org/openstack/heat refs/changes/05/189605/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/keystone/test_client.py'],1,d635b539befb5a8562dc9888cf6e229a91f8ac6e,bug/1463267-keystone-client-plugin-tests," class KeystoneClientPluginProjectTest(common.HeatTestCase): sample_uuid = '477e8273-60a7-4c41-b683-fdb0bc7cd152' sample_name = 'sample_project' def _get_mock_project(self): project = mock.MagicMock() project.id = self.sample_uuid project.name = self.sample_name return project def setUp(self): super(KeystoneClientPluginProjectTest, self).setUp() self._client = mock.MagicMock() self._client.client = mock.MagicMock() self._client.client.projects = mock.MagicMock() @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_project_id(self, client_keystone): self._client.client.projects.get.return_value = (self ._get_mock_project()) client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_project_id(self.sample_uuid)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_project_id_with_name(self, client_keystone): self._client.client.projects.get.side_effect = (keystone_exceptions .NotFound) self._client.client.projects.list.return_value = [ self._get_mock_project() ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_project_id(self.sample_name)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_project_id_not_found(self, client_keystone): self._client.client.projects.get.side_effect = (keystone_exceptions .NotFound) self._client.client.projects.list.return_value = [ ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) ex = self.assertRaises(exception.EntityNotFound, client_plugin.get_project_id, self.sample_name) msg = (""The KeystoneProject (%(name)s) could not be found."" % {'name': self.sample_name}) self.assertEqual(msg, six.text_type(ex))",,65,0
openstack%2Fheat~master~I2c0d88882d441537c1b2280b401b7034a1174eb8,openstack/heat,master,I2c0d88882d441537c1b2280b401b7034a1174eb8,Add unit test case for Keystone client plug-in for role,MERGED,2015-06-09 09:15:16.000000000,2015-06-11 04:08:09.000000000,2015-06-11 04:08:06.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 10487}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-09 09:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/396e82a5227b57b0c03096e2efdfffca2c2e60eb', 'message': 'Add unit test case for Keystone client plugin for role\n\nAdds required unit test cases for the keystone role\nin the keystone client plugin\n\nPartially Closes-bug: #1463267\n\nChange-Id: I2c0d88882d441537c1b2280b401b7034a1174eb8\n'}, {'number': 2, 'created': '2015-06-09 10:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a75eccf3a2ea169fce02fb2180c39c94a16e2732', 'message': 'Add unit test case for Keystone client plugin for role\n\nAdds required unit test cases for the keystone role\nin the keystone client plugin\n\nPartially Closes-bug: #1463267\n\nChange-Id: I2c0d88882d441537c1b2280b401b7034a1174eb8\n'}, {'number': 3, 'created': '2015-06-10 11:45:21.000000000', 'files': ['heat/tests/keystone/test_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/56843d55d173b46fe09b31693ddbcfdc544f90dd', 'message': 'Add unit test case for Keystone client plug-in for role\n\nAdds required unit test cases for the keystone role\nin the keystone client plug-in\n\nPartial-Bug: #1463267\n\nChange-Id: I2c0d88882d441537c1b2280b401b7034a1174eb8\n'}]",8,189604,56843d55d173b46fe09b31693ddbcfdc544f90dd,16,5,3,10487,,,0,"Add unit test case for Keystone client plug-in for role

Adds required unit test cases for the keystone role
in the keystone client plug-in

Partial-Bug: #1463267

Change-Id: I2c0d88882d441537c1b2280b401b7034a1174eb8
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/189604/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/keystone/test_client.py'],1,396e82a5227b57b0c03096e2efdfffca2c2e60eb,bug/1463267-keystone-client-plugin-tests," class KeystoneClientPluginRoleTest(common.HeatTestCase): sample_uuid = '477e8273-60a7-4c41-b683-fdb0bc7cd152' sample_name = 'sample_role' def _get_mock_role(self): role = mock.MagicMock() role.id = self.sample_uuid role.name = self.sample_name return role def setUp(self): super(KeystoneClientPluginRoleTest, self).setUp() self._client = mock.MagicMock() self._client.client = mock.MagicMock() self._client.client.roles = mock.MagicMock() @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_role_id(self, client_keystone): self._client.client.roles.get.return_value = self._get_mock_role() client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_role_id(self.sample_uuid)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_role_id_with_name(self, client_keystone): self._client.client.roles.get.side_effect = (keystone_exceptions .NotFound) self._client.client.roles.list.return_value = [ self._get_mock_role() ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) self.assertEqual(self.sample_uuid, client_plugin.get_role_id(self.sample_name)) @mock.patch.object(client.KeystoneClientPlugin, 'client') def test_get_role_id_not_found(self, client_keystone): self._client.client.roles.get.side_effect = (keystone_exceptions .NotFound) self._client.client.roles.list.return_value = [ ] client_keystone.return_value = self._client client_plugin = client.KeystoneClientPlugin( context=mock.MagicMock() ) ex = self.assertRaises(exception.EntityNotFound, client_plugin.get_role_id, self.sample_name) msg = (""The KeystoneRole (%(name)s) could not be found."" % {'name': self.sample_name}) self.assertEqual(msg, six.text_type(ex)) ",,66,0
openstack%2Fhorizon~master~I9221338a50424d4f3aa71335fba980cdc8c92607,openstack/horizon,master,I9221338a50424d4f3aa71335fba980cdc8c92607,(DEMO) Merged files from master and babel for comparison.,ABANDONED,2015-06-08 23:13:04.000000000,2015-06-11 04:08:07.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 3108}, {'_account_id': 6547}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-06-08 23:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e1b2d0dcb320e53c907a53c59425f1fe25f3df09', 'message': '(DEMO) Merged files from master and babel for comparison.\n\nChange-Id: I9221338a50424d4f3aa71335fba980cdc8c92607\n'}, {'number': 2, 'created': '2015-06-08 23:17:06.000000000', 'files': ['horizon/locale/de/LC_MESSAGES/djangojs.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/dd05c335578b5524e873b5193dec235b80b6ee15', 'message': '(DEMO) Merged files from master and babel for comparison.\n\nChange-Id: I9221338a50424d4f3aa71335fba980cdc8c92607'}]",1,189502,dd05c335578b5524e873b5193dec235b80b6ee15,9,5,2,9576,,,0,"(DEMO) Merged files from master and babel for comparison.

Change-Id: I9221338a50424d4f3aa71335fba980cdc8c92607",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/189502/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/de/LC_MESSAGES/djangojs.po', 'horizon/locale/de/LC_MESSAGES/django.po', 'horizon/locale/en/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/en/LC_MESSAGES/djangojs.po', 'horizon/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po']",8,e1b2d0dcb320e53c907a53c59425f1fe25f3df09,i18n/compare,"# Copyright (C) 2015 THE PACKAGE'S COPYRIGHT HOLDER# FIRST AUTHOR <EMAIL@ADDRESS>, 2015.""POT-Creation-Date: 2015-06-08 15:38-0700\n""""Language-Team: en <LL@li.org>\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n""""Content-Type: text/plain; charset=utf-8\n""""Generated-By: Babel 1.3\n"" #: settings.py:80 msgid ""Select format"" msgstr """" #: settings.py:81 msgid ""AKI - Amazon Kernel Image"" msgstr """" #: settings.py:82 msgid ""AMI - Amazon Machine Image"" msgstr """" #: settings.py:83 msgid ""ARI - Amazon Ramdisk Image"" msgstr """" #: settings.py:84 msgid ""Docker"" msgstr """" #: settings.py:85 msgid ""ISO - Optical Disk Image"" msgstr """" #: settings.py:86 msgid ""OVA - Open Virtual Appliance"" msgstr """" #: settings.py:87 msgid ""QCOW2 - QEMU Emulator"" msgstr """" #: settings.py:88 msgid ""Raw"" msgstr """" #: settings.py:89 msgid ""VDI - Virtual Disk Image"" msgstr """" #: settings.py:90 msgid ""VHD - Virtual Hard Disk"" msgstr """" #: settings.py:91 msgid ""VMDK - Virtual Machine Disk"" msgstr """" #: settings.py:239 local/local_settings.py:494 msgid ""All TCP"" msgstr """" #: settings.py:245 local/local_settings.py:500 msgid ""All UDP"" msgstr """" #: settings.py:251 local/local_settings.py:506 msgid ""All ICMP"" msgstr """"""The requested feature '%(feature)s' is unknown. Please make sure to "" ""specify a feature defined in FEATURE_MAP.""#: api/nova.py:110 api/nova.py:120 dashboards/project/databases/tables.py:279""Failed to modify %(num_groups_to_modify)d instance security groups: "" ""%(err)s""#: dashboards/admin/dashboard.py:22 msgid ""System"" msgstr """" #: dashboards/admin/dashboard.py:29 msgid ""Admin"" msgstr """" #: dashboards/admin/networks/forms.py:38 dashboards/admin/networks/forms.py:234#: dashboards/admin/routers/ports/tables.py:24#: dashboards/project/networks/tables.py:168#: dashboards/project/routers/ports/tables.py:107#: dashboards/admin/aggregates/forms.py:73 dashboards/admin/flavors/forms.py:44 #: dashboards/admin/images/forms.py:61#: dashboards/admin/aggregates/tables.py:28#: dashboards/admin/aggregates/tables.py:36#: dashboards/admin/flavors/tables.py:71 dashboards/admin/images/tables.py:46#: dashboards/admin/aggregates/views.py:108 msgid ""Update Aggregate Metadata"" msgstr """" #: dashboards/admin/aggregates/views.py:157 msgid ""Manage Hosts Aggregate"" msgstr """" ""Host aggregates divide an availability zone into logical units by "" ""grouping together hosts. Create a host aggregate then select the hosts "" ""contained in it.""#: dashboards/admin/aggregates/workflows.py:209 #: dashboards/admin/flavors/workflows.py:266 #: dashboards/admin/volumes/volume_types/extras/views.py:88 #: dashboards/admin/volumes/volume_types/qos_specs/views.py:103 #: dashboards/identity/domains/workflows.py:300 #: dashboards/identity/projects/workflows.py:602 #: dashboards/identity/users/views.py:209 #: dashboards/project/instances/workflows/update_instance.py:133 #: dashboards/project/networks/subnets/workflows.py:159 #: dashboards/settings/user/views.py:30 msgid ""Save"" msgstr """" #: dashboards/admin/defaults/panel.py:23 dashboards/admin/defaults/views.py:29#: usage/tables.py:33 usage/views.py:68#: usage/quotas.py:64 usage/views.py:67#: dashboards/project/volumes/panel.py:23 dashboards/project/volumes/tabs.py:83#: usage/views.py:78#: dashboards/admin/volumes/snapshots/tables.py:69#: dashboards/project/volumes/tabs.py:99 #: dashboards/project/volumes/snapshots/tables.py:156 usage/quotas.py:75#: dashboards/project/access_and_security/tabs.py:80#: usage/quotas.py:68 usage/quotas.py:81#: dashboards/project/access_and_security/security_groups/tables.py:149#: usage/quotas.py:70 usage/quotas.py:82 usage/views.py:73#: dashboards/project/access_and_security/tabs.py:63#: usage/quotas.py:72#: dashboards/admin/flavors/tables.py:34#: dashboards/admin/flavors/tables.py:42#: dashboards/admin/flavors/tables.py:54 dashboards/admin/flavors/views.py:66#: dashboards/admin/flavors/tables.py:62 dashboards/admin/flavors/views.py:72#: dashboards/admin/flavors/tables.py:125 usage/tables.py:37 usage/views.py:69#: dashboards/admin/networks/agents/tables.py:90#: dashboards/identity/roles/forms.py:37 dashboards/identity/users/forms.py:172#: dashboards/project/routers/forms.py:121 dashboards/project/vpn/forms.py:33 #: dashboards/project/vpn/forms.py:68 dashboards/project/vpn/forms.py:147 #: dashboards/project/vpn/forms.py:225#: dashboards/admin/flavors/views.py:97 msgid ""Update Flavor Metadata"" msgstr """" ""Flavor ID should be UUID4 or integer. Leave this field blank or use "" ""'auto' to set a random UUID4.""msgid ""Name may only contain letters, numbers, underscores, periods and hyphens.""""Flavors define the sizes for RAM, disk, number of cores, and other "" ""resources and can be selected when users deploy instances.""""Edit the flavor details. Flavors define the sizes for RAM, disk, number "" ""of cores, and other resources. Flavors are selected when users deploy "" ""instances.""#: dashboards/admin/hypervisors/views.py:59 msgid ""Hypervisor Servers"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:25 #: dashboards/admin/hypervisors/compute/forms.py:99 #: dashboards/admin/instances/forms.py:27 msgid ""Current Host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:29 msgid ""Target Host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:30 msgid ""Choose a Host to evacuate servers to."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:32 msgid ""Shared Storage"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:48 msgid ""Select a target host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:50 msgid ""No other hosts available."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:61 #, python-format msgid ""Starting evacuation from %(current)s to %(target)s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:67 #, python-format msgid ""Failed to evacuate host: %s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:73 #: dashboards/admin/hypervisors/compute/tables.py:142 #: dashboards/admin/info/tables.py:66 dashboards/admin/info/tables.py:95 #: dashboards/admin/info/tables.py:119 dashboards/admin/info/tables.py:170 #: dashboards/admin/info/tables.py:209 dashboards/admin/instances/tables.py:134 #: dashboards/admin/networks/agents/tables.py:91 #: dashboards/admin/volumes/snapshots/tables.py:64 #: dashboards/admin/volumes/volumes/forms.py:43 #: dashboards/admin/volumes/volumes/forms.py:130 #: dashboards/admin/volumes/volumes/tables.py:81 #: dashboards/project/databases/tables.py:325 msgid ""Host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:77 msgid ""Reason"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:86 #, python-format msgid ""Disabled compute service for host: %s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:91 #, python-format msgid ""Failed to disable compute service for host: %s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:106 msgid ""Running Instance Migration Type"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:108 #: dashboards/admin/instances/views.py:157 msgid ""Live Migrate"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:109 msgid ""Cold Migrate"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:120 #: dashboards/admin/hypervisors/compute/forms.py:127 #: dashboards/admin/instances/forms.py:33 msgid ""Disk Over Commit"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:133 #: dashboards/admin/hypervisors/compute/forms.py:140 #: dashboards/admin/instances/forms.py:35 msgid ""Block Migration"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:159 #, python-format msgid ""Starting to migrate host: %(current)s"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:164 #, python-format msgid ""Failed to migrate host \""%s\""."" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:27 #: dashboards/admin/hypervisors/compute/views.py:30 msgid ""Evacuate Host"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:45 #: dashboards/admin/hypervisors/compute/views.py:62 msgid ""Disable Service"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:63 msgid ""Enable Service"" msgid_plural ""Enable Services"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/hypervisors/compute/tables.py:71 msgid ""Enabled Service"" msgid_plural ""Enabled Services"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/hypervisors/compute/tables.py:91 #: dashboards/admin/hypervisors/compute/tables.py:96 #: dashboards/admin/hypervisors/compute/views.py:80 #, fuzzy msgid ""Migrate Host"" msgid_plural ""Migrate Hosts"" msgstr[0] """" ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" msgstr[1] ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" #: dashboards/admin/hypervisors/compute/tables.py:104 msgid ""Migrated Host"" msgid_plural ""Migrated Hosts"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/hypervisors/compute/tables.py:132 msgctxt ""Current status of a Hypervisor"" msgid ""Enabled"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:134 msgctxt ""Current status of a Hypervisor"" msgid ""Disabled"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:136 msgctxt ""Current state of a Hypervisor"" msgid ""Up"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:138 msgctxt ""Current state of a Hypervisor"" msgid ""Down"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:143 #: dashboards/admin/info/tables.py:96 dashboards/admin/info/tables.py:120 msgid ""Zone"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:148 #: dashboards/admin/info/tables.py:68 dashboards/admin/info/tables.py:97 #: dashboards/admin/info/tables.py:121 dashboards/admin/info/tables.py:171 #: dashboards/admin/info/tables.py:217 dashboards/admin/instances/tables.py:150 #: dashboards/admin/networks/tables.py:103 #: dashboards/admin/networks/agents/tables.py:92 #: dashboards/admin/volumes/snapshots/forms.py:34 #: dashboards/admin/volumes/volumes/forms.py:179 #: dashboards/project/access_and_security/floating_ips/tables.py:202 #: dashboards/project/data_processing/clusters/tables.py:36 #: dashboards/project/data_processing/clusters/tables.py:158 #: dashboards/project/data_processing/job_executions/tables.py:40 #: dashboards/project/data_processing/job_executions/tables.py:205 #: dashboards/project/database_backups/tables.py:174 #: dashboards/project/databases/tables.py:333 #: dashboards/project/databases/tables.py:399 #: dashboards/project/firewalls/tables.py:355 #: dashboards/project/images/images/tables.py:281 #: dashboards/project/instances/tables.py:1062 #: dashboards/project/loadbalancers/tables.py:324 #: dashboards/project/loadbalancers/tables.py:377 #: dashboards/project/networks/tables.py:174 #: dashboards/project/networks/ports/tables.py:74 #: dashboards/project/routers/tables.py:212 #: dashboards/project/routers/ports/tables.py:112 #: dashboards/project/stacks/tables.py:275 #: dashboards/project/stacks/tables.py:320 #: dashboards/project/stacks/tables.py:371 #: dashboards/project/volumes/backups/tables.py:130 #: dashboards/project/volumes/volumes/tables.py:405 #: dashboards/project/vpn/tables.py:247 dashboards/project/vpn/tables.py:292 msgid ""Status"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:153 #: dashboards/admin/info/tables.py:98 dashboards/admin/info/tables.py:122 #: dashboards/admin/info/tables.py:172 dashboards/project/overview/views.py:34 msgid ""State"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:155 #: dashboards/admin/networks/agents/tables.py:95 msgid ""Updated At"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:167 #: dashboards/admin/hypervisors/compute/tabs.py:24 msgid ""Compute Host"" msgstr """" #: dashboards/admin/hypervisors/compute/tabs.py:33 #: dashboards/admin/info/tabs.py:56 msgid ""Unable to get nova services list."" msgstr """" #: dashboards/admin/hypervisors/compute/views.py:45 msgid ""Unable to retrieve compute host information."" msgstr """" #: dashboards/admin/images/views.py:47 dashboards/project/images/panel.py:24#: dashboards/project/images/images/tables.py:303#: dashboards/admin/images/views.py:119 #: dashboards/project/images/images/views.py:44 #: dashboards/project/images/images/views.py:50 msgid ""Create An Image"" msgstr """" #: dashboards/admin/images/views.py:127 dashboards/admin/images/views.py:142 #: dashboards/project/images/images/views.py:56 #: dashboards/project/images/images/views.py:57 #: dashboards/project/images/images/views.py:61 msgid ""Update Image"" msgstr """" #: dashboards/admin/images/views.py:147 msgid ""Update Image Metadata"" msgstr """" #: dashboards/admin/info/panel.py:27 dashboards/admin/info/views.py:32#: dashboards/admin/info/tables.py:101 dashboards/admin/info/tables.py:125 #: dashboards/admin/info/tables.py:174 dashboards/admin/info/tables.py:212#: dashboards/admin/instances/tables.py:49#: dashboards/admin/instances/tables.py:57#: dashboards/admin/metering/tables.py:41 dashboards/admin/networks/forms.py:40 #: dashboards/admin/networks/tables.py:93 dashboards/admin/routers/tables.py:39#: dashboards/project/access_and_security/floating_ips/workflows.py:91#: dashboards/admin/metadata_defs/tables.py:40#: dashboards/admin/metadata_defs/tables.py:48#: dashboards/admin/metadata_defs/views.py:86 msgid ""Create a Metadata Namespace"" msgstr """" #: dashboards/admin/metering/tables.py:26 dashboards/admin/metering/views.py:48#: dashboards/admin/metering/views.py:106 dashboards/admin/overview/views.py:33#: dashboards/admin/networks/forms.py:77 dashboards/admin/networks/forms.py:239#: dashboards/project/networks/ports/forms.py:41#: dashboards/admin/networks/forms.py:78 dashboards/admin/networks/forms.py:240#: dashboards/project/networks/ports/forms.py:42#: dashboards/admin/networks/forms.py:79 dashboards/admin/networks/forms.py:241 #: dashboards/admin/networks/tables.py:106 #: dashboards/admin/networks/agents/tables.py:93 #: dashboards/admin/networks/ports/forms.py:48 #: dashboards/project/firewalls/forms.py:134 #: dashboards/project/firewalls/tables.py:358 #: dashboards/project/firewalls/workflows.py:286 #: dashboards/project/loadbalancers/forms.py:40 #: dashboards/project/loadbalancers/forms.py:95 #: dashboards/project/loadbalancers/forms.py:178 #: dashboards/project/loadbalancers/forms.py:241 #: dashboards/project/loadbalancers/workflows.py:48 #: dashboards/project/loadbalancers/workflows.py:190 #: dashboards/project/loadbalancers/workflows.py:343 #: dashboards/project/loadbalancers/workflows.py:547 #: dashboards/project/networks/forms.py:43 #: dashboards/project/networks/tables.py:177 #: dashboards/project/networks/workflows.py:49 #: dashboards/project/networks/ports/forms.py:43 #: dashboards/project/networks/ports/tables.py:77 #: dashboards/project/routers/forms.py:36 #: dashboards/project/routers/forms.py:120 #: dashboards/project/routers/tables.py:225 #: dashboards/project/routers/ports/tables.py:117 #: dashboards/project/vpn/forms.py:39 dashboards/project/vpn/forms.py:283 #: dashboards/project/vpn/workflows.py:33 #: dashboards/project/vpn/workflows.py:434 msgid ""Admin State"" msgstr """" #: dashboards/admin/networks/forms.py:80 dashboards/admin/networks/forms.py:242#: dashboards/admin/networks/forms.py:82 dashboards/admin/networks/forms.py:243#: dashboards/project/routers/ports/forms.py:153""For VLAN networks, the VLAN VID on the physical network that realizes the"" "" virtual network. Valid VLAN VIDs are %(vlan_min)s through %(vlan_max)s. "" ""For GRE or VXLAN networks, the tunnel ID. Valid tunnel IDs for GRE "" ""networks are %(gre_min)s through %(gre_max)s. For VXLAN networks, "" ""%(vxlan_min)s through %(vxlan_max)s.""#: dashboards/admin/networks/tables.py:37 #: dashboards/project/networks/tables.py:48 msgid ""Delete Network"" msgid_plural ""Delete Networks"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/tables.py:45 #: dashboards/project/networks/tables.py:56 msgid ""Deleted Network"" msgid_plural ""Deleted Networks"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/tables.py:57 #: dashboards/project/networks/tables.py:79 #, python-format msgid ""Failed to delete network %s"" msgstr """" #: dashboards/admin/networks/tables.py:65 dashboards/admin/networks/views.py:99 #: dashboards/project/networks/tables.py:87 #: dashboards/project/networks/tables.py:100 #: dashboards/project/networks/workflows.py:342 msgid ""Create Network"" msgstr """" #: dashboards/admin/networks/tables.py:74 #: dashboards/project/networks/tables.py:109 #: dashboards/project/networks/views.py:68 msgid ""Edit Network"" msgstr """" #: dashboards/admin/networks/tables.py:87 #: dashboards/project/networks/tables.py:146 msgctxt ""Admin state of a Network"" msgid ""UP"" msgstr """" #: dashboards/admin/networks/tables.py:88 #: dashboards/project/networks/tables.py:147 msgctxt ""Admin state of a Network"" msgid ""DOWN"" msgstr """" #: dashboards/admin/networks/tables.py:94 #: dashboards/admin/networks/agents/forms.py:32 #: dashboards/admin/networks/ports/forms.py:36 #: dashboards/project/networks/workflows.py:37 msgid ""Network Name"" msgstr """" #: dashboards/admin/networks/tables.py:97 #: dashboards/project/networks/tables.py:171 msgid ""Subnets Associated"" msgstr """" #: dashboards/admin/networks/tables.py:99 #: dashboards/admin/networks/agents/tables.py:101 msgid ""DHCP Agents"" msgstr """" #: dashboards/admin/networks/views.py:50 msgid ""Unable to retrieve information about the networks' projects."" msgstr """" #: dashboards/admin/networks/views.py:59 #: dashboards/project/instances/tables.py:646 #: dashboards/project/volumes/backups/tables.py:37 #: dashboards/project/volumes/snapshots/tables.py:126 msgid ""Unknown"" msgstr """" #: dashboards/admin/networks/views.py:78 #: dashboards/project/networks/views.py:54 msgid ""Network list can not be retrieved."" msgstr """" #: dashboards/admin/networks/views.py:90 dashboards/admin/networks/views.py:137 #: dashboards/admin/networks/agents/forms.py:62 msgid ""Unable to list dhcp agents hosting network."" msgstr """" #: dashboards/admin/networks/views.py:107 #: dashboards/project/networks/views.py:103 msgid ""Network Details: {{ network.name }}"" msgstr """" #: dashboards/admin/networks/views.py:116 #: dashboards/project/networks/views.py:112 msgid ""Subnet list can not be retrieved."" msgstr """" #: dashboards/admin/networks/views.py:126 #: dashboards/project/networks/views.py:122 msgid ""Port list can not be retrieved."" msgstr """" #: dashboards/admin/networks/views.py:149 #: dashboards/admin/networks/subnets/tables.py:109 #: dashboards/project/networks/views.py:133 #: dashboards/project/networks/subnets/tables.py:143 #, python-format msgid ""Unable to retrieve details for network \""%s\""."" msgstr """" #: dashboards/admin/networks/agents/forms.py:36 msgid ""New DHCP Agent"" msgstr """" #: dashboards/admin/networks/agents/forms.py:37 msgid ""Choose an DHCP Agent to attach to."" msgstr """" #: dashboards/admin/networks/agents/forms.py:55 msgid ""Select a new agent"" msgstr """" #: dashboards/admin/networks/agents/forms.py:57 msgid ""No other agents available."" msgstr """" #: dashboards/admin/networks/agents/forms.py:74 #, python-format msgid ""Agent %s was successfully added."" msgstr """" #: dashboards/admin/networks/agents/forms.py:80 #, python-format msgid ""Failed to add agent %(agent_name)s for network %(network)s."" msgstr """" #: dashboards/admin/networks/agents/tables.py:35 msgid ""Delete DHCP Agent"" msgid_plural ""Delete DHCP Agents"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/agents/tables.py:43 msgid ""Deleted DHCP Agent"" msgid_plural ""Deleted DHCP Agents"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/agents/tables.py:57 #, python-format msgid ""Failed to delete agent: %s"" msgstr """" #: dashboards/admin/networks/agents/tables.py:66 #: dashboards/admin/networks/agents/views.py:35 msgid ""Add DHCP Agent"" msgstr """" #: dashboards/admin/networks/agents/views.py:63 #: dashboards/admin/networks/ports/views.py:56 #: dashboards/project/networks/subnets/views.py:48 msgid ""Unable to retrieve network."" msgstr """" #: dashboards/admin/networks/agents/views.py:74 msgid ""Unable to retrieve agent list."" msgstr """" #: dashboards/admin/networks/ports/tables.py:35#: dashboards/admin/networks/ports/tables.py:43#: dashboards/admin/networks/subnets/tables.py:37 #: dashboards/project/networks/subnets/tables.py:60#: dashboards/admin/networks/subnets/tables.py:45 #: dashboards/project/networks/subnets/tables.py:68#: dashboards/project/networks/workflows.py:91#: dashboards/project/networks/workflows.py:127#: dashboards/project/networks/subnets/tables.py:133#: dashboards/project/routers/ports/tabs.py:24#: dashboards/project/stacks/resource_types/tabs.py:21#: dashboards/admin/routers/panel.py:24 dashboards/admin/routers/tables.py:46 #: dashboards/identity/projects/workflows.py:77 #: dashboards/project/firewalls/workflows.py:173 #: dashboards/project/firewalls/workflows.py:179 #: dashboards/project/network_topology/routers/tables.py:27 #: dashboards/project/routers/panel.py:24 #: dashboards/project/routers/tables.py:244 #: dashboards/project/routers/views.py:42 usage/quotas.py:80 msgid ""Routers"" msgstr """" #: dashboards/admin/routers/views.py:42 dashboards/project/routers/views.py:53 msgid ""Unable to retrieve router list."" msgstr """" #: dashboards/project/routers/ports/tables.py:125#: dashboards/admin/volumes/tabs.py:53 dashboards/admin/volumes/tabs.py:141 #: dashboards/admin/volumes/snapshots/tables.py:52 msgid ""Unable to retrieve volume project information.""#: dashboards/admin/volumes/tabs.py:68 #: dashboards/admin/volumes/volume_types/tables.py:163 msgid ""Volume Types""#: dashboards/admin/volumes/tabs.py:80 msgid ""Unable to retrieve volume types"" msgstr """" #: dashboards/admin/volumes/tabs.py:88 msgid ""Unable to retrieve volume type encryption information."" msgstr """" #: dashboards/admin/volumes/tabs.py:109 msgid ""Unable to retrieve QoS specs"" msgstr """" #: dashboards/admin/volumes/tabs.py:133 dashboards/project/volumes/tabs.py:113 #: dashboards/project/volumes/volumes/forms.py:232 msgid ""Unable to retrieve volume snapshots.""#: dashboards/admin/volumes/volume_types/forms.py:52 #, python-format msgid ""Successfully created encryption for volume type: %s""#: dashboards/admin/volumes/volume_types/forms.py:58 msgid ""Unable to create encrypted volume type.""#: dashboards/admin/volumes/volume_types/forms.py:64 msgid ""QoS Spec to be associated""#: dashboards/admin/volumes/volume_types/forms.py:65 msgid ""Choose associated QoS Spec."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:89 #: dashboards/project/databases/workflows/create_instance.py:232 msgid ""None"" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:110 msgid """" ""New associated QoS Spec must be different than the current associated QoS"" "" Spec."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:142 msgid ""Successfully updated QoS Spec association."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:147 msgid ""Error updating QoS Spec association."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:153 msgid ""QoS Spec Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:155 msgid ""Choose consumer for this QoS Spec."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:171 msgid ""QoS Spec consumer value must be different than the current consumer value."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:185 msgid ""Successfully modified QoS Spec consumer."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:189 msgid ""Error editing QoS Spec consumer."" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:34 msgid ""View Extra Specs""#: dashboards/admin/volumes/volume_types/tables.py:42 msgid ""Manage QoS Spec Association""#: dashboards/admin/volumes/volume_types/tables.py:52 msgid ""Delete Volume Type"" msgid_plural ""Delete Volume Types"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:60 msgid ""Deleted Volume Type"" msgid_plural ""Deleted Volume Types"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:73 msgid ""Create Encryption""#: dashboards/admin/volumes/volume_types/tables.py:93 msgid ""Delete Encryption"" msgid_plural ""Delete Encryptions"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:101 msgid ""Deleted Encryption"" msgid_plural ""Deleted Encryptions"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:122 msgid ""Unable to determine if volume type encryption is supported.""#: dashboards/admin/volumes/volume_types/tables.py:148 msgid ""Associated QoS Spec""#: dashboards/admin/volumes/volume_types/tables.py:150 msgid ""Encryption""#: dashboards/admin/volumes/volume_types/tables.py:176 msgid ""Manage Specs""#: dashboards/admin/volumes/volume_types/tables.py:190 #: dashboards/admin/volumes/volume_types/views.py:121 msgid ""Create QoS Spec""#: dashboards/admin/volumes/volume_types/tables.py:200 msgid ""Delete QoS Spec"" msgid_plural ""Delete QoS Specs"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:208 msgid ""Deleted QoS Spec"" msgid_plural ""Deleted QoS Specs"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:221 msgid ""Edit Consumer""#: dashboards/admin/volumes/volume_types/tables.py:230 #: dashboards/admin/volumes/volumes/forms.py:222 msgid ""Consumer""#: dashboards/admin/volumes/volume_types/tables.py:232 #: dashboards/admin/volumes/volume_types/qos_specs/tables.py:36 msgid ""Specs""#: dashboards/admin/volumes/volume_types/tables.py:245 msgid ""QoS Specs""#: dashboards/admin/volumes/volume_types/views.py:41 msgid ""Create a Volume Type""#: dashboards/admin/volumes/volume_types/views.py:72 msgid ""Unable to retrieve volume type encryption details.""#: dashboards/admin/volumes/volume_types/views.py:83 #: dashboards/admin/volumes/volume_types/views.py:87 msgid ""Create Volume Type Encryption""#: dashboards/admin/volumes/volume_types/views.py:90 msgid ""Create an Encrypted Volume Type""#: dashboards/admin/volumes/volume_types/views.py:100 msgid ""Unable to retrieve volume type name.""#: dashboards/admin/volumes/volume_types/views.py:125 msgid ""Create a QoS Spec""#: dashboards/admin/volumes/volume_types/views.py:126 #: dashboards/admin/volumes/volume_types/extras/tables.py:48 #: dashboards/admin/volumes/volume_types/extras/views.py:64 #: dashboards/admin/volumes/volume_types/qos_specs/tables.py:24 #: dashboards/admin/volumes/volume_types/qos_specs/views.py:76 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:236 #: dashboards/project/data_processing/data_sources/workflows/create.py:95 #: dashboards/project/data_processing/jobs/workflows/create.py:156 #: dashboards/project/data_processing/jobs/workflows/launch.py:429 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:255 #: dashboards/project/networks/workflows.py:343 #: dashboards/project/networks/subnets/workflows.py:57 msgid ""Create""#: dashboards/admin/volumes/volume_types/views.py:136 msgid ""Edit Consumer of QoS Spec"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:139 msgid ""Modify Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:142 msgid ""Edit QoS Spec Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:161 msgid ""Unable to retrieve QoS Spec details."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:175 #: dashboards/admin/volumes/volume_types/views.py:182 msgid ""Associate QoS Spec with Volume Type"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:178 #: dashboards/project/access_and_security/floating_ips/tables.py:110 #: dashboards/project/access_and_security/floating_ips/workflows.py:137 #: dashboards/project/loadbalancers/workflows.py:670 msgid ""Associate"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:201 #: dashboards/admin/volumes/volume_types/extras/views.py:36 msgid ""Unable to retrieve volume type details."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:211 msgid ""Unable to retrieve QoS Specs."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:231 msgid ""Unable to retrieve QoS Spec association.""#: dashboards/admin/volumes/volume_types/extras/tables.py:26#: dashboards/admin/volumes/volume_types/extras/tables.py:34#: dashboards/admin/volumes/volume_types/extras/views.py:62 msgid ""Create Volume Type Extra Spec"" msgstr """" #: dashboards/admin/volumes/volume_types/qos_specs/views.py:73 msgid ""Create Spec"" msgstr """" ""Cinder host on which the existing volume resides; takes the form: host"" ""@backend-name#pool""#: dashboards/admin/volumes/volumes/tables.py:33 #: dashboards/admin/volumes/volumes/views.py:47 msgid ""Manage Volume"" msgstr """" #: dashboards/admin/volumes/volumes/tables.py:43 msgid ""Unmanage Volume"" msgstr """" #: dashboards/admin/volumes/volumes/tables.py:69 #: dashboards/admin/volumes/volumes/views.py:106 #: dashboards/admin/volumes/volumes/views.py:112 msgid ""Update Volume Status"" msgstr """" #: dashboards/identity/domains/tables.py:94#: dashboards/identity/domains/tables.py:102#: dashboards/identity/users/forms.py:89 dashboards/identity/users/forms.py:166""different organizations. Edit the domain details to add or remove groups "" ""in the domain.""""currently logged into. Please switch to another domain with "" ""administrative privileges or remove the administrative role manually via "" ""the CLI.""#: dashboards/identity/groups/tables.py:64#: dashboards/identity/groups/tables.py:72#: dashboards/identity/groups/tables.py:140#: dashboards/identity/groups/tables.py:148#: dashboards/identity/users/forms.py:95 dashboards/identity/users/forms.py:173#: dashboards/identity/users/forms.py:97 dashboards/identity/users/forms.py:175#: dashboards/identity/groups/tables.py:213#: dashboards/identity/groups/tables.py:221#: dashboards/identity/groups/views.py:70 #: dashboards/identity/groups/views.py:74 #: dashboards/identity/groups/views.py:76 msgid ""Update Group"" msgstr """" #: dashboards/identity/projects/tables.py:139#: dashboards/identity/projects/tables.py:147#: dashboards/identity/projects/tables.py:236 local/local_settings.py:290 msgid ""Project ID""#: dashboards/identity/users/forms.py:92 dashboards/identity/users/forms.py:169""Failed to add %(users_to_add)s project members%(group_msg)s and set "" ""project quotas.""#: dashboards/identity/projects/workflows.py:561""You cannot revoke your administrative privileges from the project you are"" "" currently logged into. Please switch to another project with "" ""administrative privileges or remove the administrative role manually via "" ""the CLI.""""Failed to modify %(users_to_modify)s project members%(group_msg)s and "" ""update project quotas.""#: dashboards/identity/roles/panel.py:24 dashboards/identity/roles/tables.py:86#: dashboards/identity/roles/tables.py:25 dashboards/identity/roles/views.py:88 #: dashboards/identity/roles/views.py:91 dashboards/identity/roles/views.py:94#: dashboards/identity/roles/tables.py:50#: dashboards/identity/roles/tables.py:58#: dashboards/identity/roles/views.py:56 dashboards/identity/roles/views.py:59 #: dashboards/identity/roles/views.py:62 msgid ""Update Role"" msgstr """" #: dashboards/identity/users/forms.py:99 dashboards/identity/users/forms.py:177#: dashboards/identity/users/tables.py:77#: dashboards/identity/users/tables.py:82#: dashboards/identity/users/tables.py:92#: dashboards/identity/users/tables.py:97#: dashboards/identity/users/tables.py:142 #: dashboards/project/databases/tables.py:123#: dashboards/identity/users/tables.py:150 #: dashboards/project/databases/tables.py:131#: dashboards/identity/users/views.py:76 dashboards/identity/users/views.py:79 #: dashboards/identity/users/views.py:82 msgid ""Update User"" msgstr """" #: dashboards/project/dashboard.py:22 msgid ""Compute"" msgstr """" #: dashboards/project/dashboard.py:32 dashboards/project/instances/forms.py:173 #: dashboards/project/networks/workflows.py:79 msgid ""Network"" msgstr """" #: dashboards/project/dashboard.py:43 msgid ""Object Store"" msgstr """" #: dashboards/project/dashboard.py:49 msgid ""Orchestration"" msgstr """" #: dashboards/project/dashboard.py:56 #: dashboards/project/database_backups/tables.py:168 msgid ""Database"" msgstr """" #: dashboards/project/dashboard.py:63 msgid ""Data Processing"" msgstr """" #: dashboards/project/access_and_security/panel.py:24 #: dashboards/project/access_and_security/views.py:35 #: dashboards/project/instances/workflows/create_instance.py:562 msgid ""Access & Security"" msgstr """" #: dashboards/project/access_and_security/tabs.py:57 #: dashboards/project/access_and_security/security_groups/views.py:138 #: usage/base.py:116 msgid ""Unable to retrieve security groups."" msgstr """" #: dashboards/project/access_and_security/tabs.py:74 msgid ""Unable to retrieve key pair list."" msgstr """" #: dashboards/project/access_and_security/tabs.py:94 #: dashboards/project/access_and_security/floating_ips/workflows.py:73 #: usage/base.py:111 msgid ""Unable to retrieve floating IP addresses."" msgstr """" #: dashboards/project/access_and_security/tabs.py:104 #: dashboards/project/access_and_security/floating_ips/views.py:76 msgid ""Unable to retrieve floating IP pools."" msgstr """" #: dashboards/project/access_and_security/tabs.py:128 msgid ""API Access"" msgstr """" #: dashboards/project/access_and_security/floating_ips/tables.py:81#: dashboards/project/access_and_security/floating_ips/tables.py:89""Select the IP address you wish to associate with the selected instance or"" "" port.""""The requested instance port is already associated with another floating "" ""IP.""#: dashboards/project/access_and_security/keypairs/tables.py:30#: dashboards/project/access_and_security/keypairs/tables.py:38""from all members of another security group select &quot;Security "" ""Group&quot;.""""The \""to\"" port number must be greater than or equal to the \""from\"" port"" "" number.""#: dashboards/project/access_and_security/security_groups/tables.py:36#: dashboards/project/access_and_security/security_groups/tables.py:44#: dashboards/project/access_and_security/security_groups/tables.py:176 #: dashboards/project/firewalls/tables.py:63#: dashboards/project/access_and_security/security_groups/tables.py:184""Manage Security Group Rules: {{ security_group.name }} ({{ "" ""security_group.id }})""""Slashes are allowed, and are treated as pseudo-folders by the Object "" ""Store.""#: dashboards/project/containers/tables.py:104#: dashboards/project/containers/tables.py:112#: dashboards/project/containers/tables.py:327#: dashboards/project/containers/tables.py:335#: dashboards/project/containers/views.py:229 msgid ""Copy Object"" msgstr """" #: dashboards/project/containers/views.py:298 msgid ""Object Details""#: dashboards/project/containers/views.py:324 msgid ""Update Object""#: dashboards/project/data_processing/cluster_templates/tables.py:71 #: dashboards/project/data_processing/nodegroup_templates/tables.py:62#: dashboards/project/data_processing/cluster_templates/tables.py:79 #: dashboards/project/data_processing/nodegroup_templates/tables.py:70#: dashboards/project/data_processing/cluster_templates/views.py:57 msgid ""Unable to fetch cluster template list""#: dashboards/project/data_processing/cluster_templates/views.py:90 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:80 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:235 msgid ""Create Cluster Template""#: dashboards/project/stacks/views.py:93 dashboards/project/stacks/views.py:109#: dashboards/project/data_processing/cluster_templates/workflows/create.py:82 #: dashboards/project/data_processing/jobs/workflows/launch.py:430 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:400 #: dashboards/project/database_backups/tables.py:165 #: dashboards/project/databases/tables.py:388 #: dashboards/project/stacks/tables.py:262 msgid ""Created"" msgstr """" #: dashboards/project/data_processing/clusters/tables.py:66#: dashboards/project/data_processing/clusters/tables.py:74#: dashboards/project/data_processing/clusters/views.py:59 msgid ""Cluster Details"" msgstr """" #: dashboards/project/data_processing/clusters/workflows/create.py:83 msgid ""Base Image"" msgstr """" #: dashboards/project/data_processing/clusters/workflows/create.py:87 msgid ""Keypair"" msgstr """" #: dashboards/project/data_processing/clusters/workflows/create.py:100 msgid ""Neutron Management Network"" msgstr """" #: dashboards/project/data_processing/data_image_registry/tables.py:53#: dashboards/project/data_processing/data_image_registry/tables.py:61#: dashboards/project/data_processing/data_image_registry/views.py:85 msgid ""Edit Image Tags"" msgstr """" #: dashboards/project/data_processing/data_plugins/views.py:49 msgid ""Data Processing Plugin Details"" msgstr """" #: dashboards/project/data_processing/data_sources/tables.py:37#: dashboards/project/data_processing/data_sources/tables.py:45#: dashboards/project/data_processing/data_sources/views.py:62 msgid ""Data Source Details"" msgstr """" #: dashboards/project/data_processing/data_sources/workflows/create.py:40 #: dashboards/project/data_processing/job_binaries/forms.py:59 #: dashboards/project/data_processing/job_binaries/forms.py:65 #: dashboards/project/loadbalancers/workflows.py:523 #: dashboards/project/loadbalancers/workflows.py:527 #: dashboards/project/loadbalancers/workflows.py:528 #: dashboards/project/stacks/forms.py:63 msgid ""URL"" msgstr """" #: dashboards/project/data_processing/job_binaries/tables.py:40#: dashboards/project/data_processing/job_binaries/tables.py:48#: dashboards/project/data_processing/job_binaries/views.py:76 msgid ""Job Binary Details"" msgstr """" #: dashboards/project/data_processing/job_executions/tables.py:52#: dashboards/project/data_processing/job_executions/tables.py:60#: dashboards/project/data_processing/job_executions/tables.py:73 #: dashboards/project/data_processing/job_executions/tables.py:102#: dashboards/project/data_processing/job_executions/tables.py:81 #: dashboards/project/data_processing/job_executions/tables.py:110#: dashboards/project/data_processing/job_executions/tables.py:175#: dashboards/project/data_processing/job_executions/tables.py:177#: dashboards/project/data_processing/job_executions/tables.py:179#: dashboards/project/data_processing/job_executions/tables.py:181#: dashboards/project/data_processing/jobs/tables.py:46#: dashboards/project/data_processing/jobs/tables.py:54#: dashboards/project/data_processing/jobs/views.py:70 msgid ""Job Template Details"" msgstr """" #: dashboards/project/data_processing/jobs/workflows/create.py:55 msgid ""Libs"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/tables.py:90 msgid ""Node Processes"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/views.py:79 #: dashboards/project/data_processing/nodegroup_templates/views.py:87 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:254 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:398 msgid ""Create Node Group Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:66 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:72 msgid ""Volumes per node"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:88 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:94 msgid ""Volumes Availability Zone"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:127 msgid ""Floating IP Pool"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:132 msgid ""Proxy Gateway"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:205 msgid ""Auto Security Group"" msgstr """" #: dashboards/project/data_processing/utils/helpers.py:126 msgid ""Pig"" msgstr """" #: dashboards/project/data_processing/utils/helpers.py:127 msgid ""Hive"" msgstr """" #: dashboards/project/data_processing/utils/helpers.py:128 msgid ""Spark"" msgstr """" #: dashboards/project/data_processing/utils/helpers.py:129 msgid ""MapReduce"" msgstr """" #: dashboards/project/data_processing/wizard/views.py:90 msgid ""Choose plugin and version"" msgstr """" #: dashboards/project/data_processing/wizard/views.py:99 msgid ""Choose job type"" msgstr """" #: dashboards/project/database_backups/tables.py:36#: dashboards/project/database_backups/tables.py:38#: dashboards/project/database_backups/tables.py:40#: dashboards/project/database_backups/tables.py:42#: dashboards/project/database_backups/tables.py:44#: dashboards/project/database_backups/tables.py:46#: dashboards/project/database_backups/tables.py:95#: dashboards/project/database_backups/tables.py:103#: dashboards/project/database_backups/views.py:69 #: dashboards/project/database_backups/workflows/create_backup.py:82 msgid ""Backup Database"" msgstr """" #: dashboards/project/database_backups/workflows/create_backup.py:38 msgid ""Parent Backup"" msgstr """" #: dashboards/project/databases/tables.py:39 #: dashboards/project/instances/tables.py:90#: dashboards/project/databases/tables.py:47 #: dashboards/project/instances/tables.py:98#: dashboards/project/databases/tables.py:67#: dashboards/project/databases/tables.py:75#: dashboards/project/databases/tables.py:95#: dashboards/project/databases/tables.py:103#: dashboards/project/databases/tables.py:149#: dashboards/project/databases/tables.py:157#: dashboards/project/databases/tables.py:296#: dashboards/project/databases/tables.py:298#: dashboards/project/databases/tables.py:300#: dashboards/project/databases/tables.py:302#: dashboards/project/databases/tables.py:304#: dashboards/project/databases/tables.py:306#: dashboards/project/databases/tables.py:308#: dashboards/project/databases/tables.py:310#: dashboards/project/databases/tables.py:312#: dashboards/project/databases/tables.py:315#: dashboards/project/databases/views.py:145 msgid ""Resize Database Volume"" msgstr """" #: dashboards/project/databases/views.py:172 msgid ""Resize Database Instance"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:36 #: dashboards/project/instances/workflows/create_instance.py:87 msgid ""Flavor"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:43#: dashboards/project/databases/workflows/create_instance.py:134 #: dashboards/project/instances/workflows/create_instance.py:701#: dashboards/project/databases/workflows/create_instance.py:188 msgid ""Initial Databases"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:192 msgid ""Initial Admin User"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:198 msgid ""Allowed Host (optional)"" msgstr """" #: dashboards/project/firewalls/tables.py:71#: dashboards/project/firewalls/tables.py:85#: dashboards/project/firewalls/tables.py:93#: dashboards/project/firewalls/tables.py:108#: dashboards/project/firewalls/tables.py:116#: dashboards/project/firewalls/tables.py:323#: dashboards/project/firewalls/tables.py:325#: dashboards/project/firewalls/tables.py:327#: dashboards/project/firewalls/tables.py:329#: dashboards/project/firewalls/tables.py:331#: dashboards/project/firewalls/tables.py:333#: dashboards/project/firewalls/tables.py:335#: dashboards/project/firewalls/tables.py:337#: dashboards/project/firewalls/views.py:96 msgid ""Add New Rule"" msgstr """" #: dashboards/project/firewalls/views.py:102 msgid ""Add New Policy"" msgstr """" #: dashboards/project/firewalls/views.py:108 msgid ""Add New Firewall"" msgstr """" #: dashboards/project/networks/ports/views.py:88#: dashboards/project/firewalls/views.py:264 msgid ""Insert Rule to Policy"" msgstr """" #: dashboards/project/firewalls/views.py:298 #: dashboards/project/firewalls/views.py:304 msgid ""Remove Rule from Policy"" msgstr """" #: dashboards/project/firewalls/views.py:371 #: dashboards/project/firewalls/views.py:374 msgid ""Add Router to Firewall"" msgstr """" #: dashboards/project/firewalls/views.py:379 #: dashboards/project/firewalls/views.py:382 msgid ""Remove Router from Firewall"" msgstr """" ""A name must be given. Firewall rules are added in the order placed under "" ""the Rules tab.""#: dashboards/project/images/utils.py:44 msgid ""Unable to retrieve public images."" msgstr """" #: dashboards/project/images/utils.py:60 msgid ""Unable to retrieve images for the current project."" msgstr """" #: dashboards/project/images/utils.py:95 msgid ""Unable to retrieve images"" msgstr """" #: dashboards/project/images/utils.py:104 #: dashboards/project/instances/forms.py:70 #: dashboards/project/instances/workflows/create_instance.py:449 msgid ""No images available"" msgstr """" #: dashboards/project/images/views.py:55 msgid ""Unable to retrieve images."" msgstr """" #: dashboards/project/images/images/forms.py:297 local/local_settings.py:286""The minimum disk size required to boot the image. If unspecified, this "" ""value defaults to 0 (no minimum).""""Specify this option to copy image data to the image service. If "" ""unspecified, image data will be used in its current location.""#: dashboards/project/images/images/forms.py:286 local/local_settings.py:287#: dashboards/project/images/images/forms.py:292 local/local_settings.py:288#: dashboards/project/images/images/tables.py:89#: dashboards/project/images/images/tables.py:97#: dashboards/project/images/images/tables.py:227#: dashboards/project/images/images/tables.py:265#: dashboards/project/instances/audit_tables.py:30#: dashboards/project/instances/tables.py:121#: dashboards/project/instances/tables.py:129#: dashboards/project/instances/tables.py:152#: dashboards/project/instances/tables.py:160#: dashboards/project/instances/tables.py:177#: dashboards/project/instances/tables.py:182 #: dashboards/project/instances/tables.py:250#: dashboards/project/instances/tables.py:192#: dashboards/project/instances/tables.py:197 #: dashboards/project/instances/tables.py:265#: dashboards/project/instances/tables.py:245#: dashboards/project/instances/tables.py:260""There is not enough capacity for this flavor in the selected availability"" "" zone. Try again later or select a different availability zone.""""Failed to perform requested operation on instance \""%s\"", the instance "" ""has an error status""#: dashboards/project/instances/tables.py:693#: dashboards/project/instances/tables.py:701#: dashboards/project/instances/tables.py:723#: dashboards/project/instances/tables.py:732#: dashboards/project/instances/tables.py:754#: dashboards/project/instances/tables.py:762#: dashboards/project/instances/tables.py:785#: dashboards/project/instances/tables.py:793#: dashboards/project/instances/tables.py:904#: dashboards/project/instances/tables.py:908#: dashboards/project/instances/tables.py:910#: dashboards/project/instances/tables.py:912#: dashboards/project/instances/tables.py:915#: dashboards/project/instances/tables.py:919#: dashboards/project/instances/tables.py:924#: dashboards/project/instances/tables.py:927#: dashboards/project/instances/tables.py:935#: dashboards/project/instances/tables.py:937#: dashboards/project/instances/tables.py:939#: dashboards/project/instances/tables.py:942#: dashboards/project/instances/tables.py:944#: dashboards/project/instances/tables.py:946#: dashboards/project/instances/tables.py:948#: dashboards/project/instances/tables.py:950#: dashboards/project/instances/tables.py:952#: dashboards/project/instances/tables.py:954#: dashboards/project/instances/tables.py:956#: dashboards/project/instances/tables.py:958#: dashboards/project/instances/tables.py:960#: dashboards/project/instances/tables.py:962#: dashboards/project/instances/tables.py:964#: dashboards/project/instances/tables.py:967#: dashboards/project/instances/tables.py:969#: dashboards/project/instances/tables.py:971#: dashboards/project/instances/tables.py:973#: dashboards/project/instances/tables.py:975#: dashboards/project/instances/tables.py:979#: dashboards/project/instances/tables.py:982#: dashboards/project/instances/tables.py:984#: dashboards/project/instances/tables.py:987#: dashboards/project/instances/tables.py:989#: dashboards/project/instances/tables.py:991#: dashboards/project/instances/tables.py:993#: dashboards/project/instances/tables.py:997#: dashboards/project/instances/tables.py:1001#: dashboards/project/instances/tables.py:1003#: dashboards/project/instances/tables.py:1005#: dashboards/project/instances/tables.py:1007#: dashboards/project/instances/views.py:213#: dashboards/project/instances/views.py:225#: dashboards/project/instances/views.py:277 msgid ""Retrieve Instance Password"" msgstr """" msgid ""Unable to retrieve flavor information for instance \""%(name)s\"" (%(id)s).""""Unable to retrieve IP addresses from Neutron for instance \""%(name)s\"" "" ""(%(id)s).""#: dashboards/project/instances/workflows/create_instance.py:102 #: dashboards/project/instances/workflows/create_instance.py:425 #: dashboards/project/volumes/volumes/forms.py:249 msgid ""Volume"" msgstr """" ""Volume mount point (e.g. 'vda' mounts at '/dev/vda'). Leave this field "" ""blank to let the system choose a device name for you.""#: dashboards/project/instances/workflows/create_instance.py:212""The requested instance cannot be launched as you only have %(avail)i of "" ""your quota available. """"The requested instance cannot be launched. Requested volume exceeds "" ""quota: Available: %(avail)s, Requested: %(req)s.""""The requested instance cannot be launched. The following requested "" ""resource(s) exceed quota(s): %s.""""Minimum requirements: %(min_ram)s MB of RAM and %(min_disk)s GB of Root "" ""Disk.""""The Volume size is too small for the '%(image_name)s' image and has to be"" "" greater than or equal to '%(smallest_size)d' GB.""""Control access to your instance via key pairs, security groups, and other"" "" mechanisms.""""A script or set of commands to be executed after the instance has been "" ""built (max 16kb).""""Automatic: The entire disk is a single partition and automatically "" ""resizes. Manual: Results in faster build times but requires manual "" ""partitioning.""""Configure OpenStack to write metadata to a special configuration drive "" ""that attaches to the instance when it boots.""""Add and remove security groups to this project from the list of available"" "" security groups.""#: dashboards/project/instances/workflows/update_instance.py:119 msgid ""Information"" msgstr """" ""Maximum number of connections allowed for the VIP or '-1' if the limit is"" "" not set""""The minimum time in seconds between regular checks of a member. It must "" ""be greater than or equal to timeout""""The maximum time in seconds for a monitor to wait for a reply. It must be"" "" less than or equal to delay""#: dashboards/project/loadbalancers/tables.py:81#: dashboards/project/loadbalancers/tables.py:89#: dashboards/project/loadbalancers/tables.py:107#: dashboards/project/loadbalancers/tables.py:115#: dashboards/project/loadbalancers/tables.py:134#: dashboards/project/loadbalancers/tables.py:142#: dashboards/project/loadbalancers/tables.py:155#: dashboards/project/loadbalancers/tables.py:163#: dashboards/project/loadbalancers/tables.py:295#: dashboards/project/loadbalancers/tables.py:297#: dashboards/project/loadbalancers/tables.py:299#: dashboards/project/loadbalancers/tables.py:301#: dashboards/project/loadbalancers/tables.py:303#: dashboards/project/loadbalancers/tables.py:305#: dashboards/project/loadbalancers/tables.py:307#: dashboards/project/loadbalancers/tables.py:309#: dashboards/project/loadbalancers/tables.py:320 msgid ""N/A"" msgstr """" #: dashboards/project/networks/workflows.py:159""%(type)s: url:%(url_path)s method:%(http_method)s "" ""codes:%(expected_codes)s delay:%(delay)d retries:%(max_retries)d "" ""timeout:%(timeout)d""#: dashboards/project/loadbalancers/views.py:43 msgid ""Load Balancer"" msgstr """" ""Create a VIP for this pool. Assign a name, description, IP address, port,"" "" and maximum connections allowed for the VIP. Choose the protocol and "" ""session persistence method for the VIP. Admin State is UP (checked) by "" ""default.""#: dashboards/project/loadbalancers/workflows.py:273""Enter an integer value between 1 and 65535. The same port will be used "" ""for all the selected members and can be modified later.""#: dashboards/project/loadbalancers/workflows.py:371""Choose one or more listed instances to be added to the pool as member(s)."" "" Assign a numeric weight and port number for the selected member(s) to "" ""operate(s) on; e.g., 80. \n""#: dashboards/project/loadbalancers/workflows.py:511 #: dashboards/project/loadbalancers/workflows.py:516 #: dashboards/project/loadbalancers/workflows.py:517 msgid ""HTTP Method"" msgstr """" ""Expected code may be a single value (e.g. 200), a list of values (e.g. "" ""200, 202), or range of values (e.g. 200-204)""""Please enter a single value (e.g. 200), a list of values (e.g. 200, 202),"" "" or range of values (e.g. 200-204)""""Select type of monitoring. Specify delay, timeout, and retry limits "" ""required by the monitor. Specify method, URL path, and expected HTTP "" ""codes upon success.""#: dashboards/project/networks/tables.py:98 msgid ""Create Network (Quota exceeded)""#: dashboards/project/networks/views.py:73 msgid ""Update Network""""Create a new network. In addition, a subnet associated with the network "" ""can be created in the next panel.""#: dashboards/project/networks/workflows.py:109 #: dashboards/project/networks/subnets/tables.py:131 #: dashboards/project/networks/subnets/workflows.py:81 msgid ""Network Address"" msgstr """" ""IP address of Gateway (e.g. 192.168.0.254) The default value is the first"" "" IP of the network address (e.g. 192.168.0.1 for 192.168.0.0/24, "" ""2001:DB8::1 for 2001:DB8::/48). If you use the default, leave blank. If "" ""you do not want to use a gateway, check 'Disable Gateway' below."" msgstr """" #: dashboards/project/networks/workflows.py:146 #: dashboards/project/networks/subnets/workflows.py:112 msgid ""Disable Gateway""#: dashboards/project/networks/workflows.py:218 #: dashboards/project/networks/workflows.py:222 msgid ""IPv6 Address Configuration Mode"" msgstr """" ""Specifies how IPv6 addresses and additional information are configured. "" ""We can specify SLAAC/DHCPv6 stateful/DHCPv6 stateless provided by "" ""OpenStack, or specify no option. 'No options specified' means addresses "" ""are configured manually or configured by a non-OpenStack system.""""IP address allocation pools. Each entry is: "" ""start_ip_address,end_ip_address (e.g., 192.168.1.100,192.168.1.120) and "" ""one entry per line.""msgid ""IP address list of DNS name servers for this subnet. One entry per line.""""Additional routes announced to the hosts. Each entry is: "" ""destination_cidr,nexthop (e.g., 192.168.200.0/24,10.56.1.254) and one "" ""entry per line."" msgstr """" #: dashboards/project/networks/workflows.py:256 #: dashboards/project/networks/subnets/views.py:103 #: dashboards/project/networks/subnets/workflows.py:148 msgid ""Subnet Details"" msgstr """" #: dashboards/project/networks/workflows.py:257 #: dashboards/project/networks/subnets/workflows.py:149 msgid ""Specify additional attributes for the subnet.""msgid ""Failed to create subnet \""%(sub)s\"" for network \""%(net)s\"": %(reason)s""#: dashboards/project/networks/ports/tables.py:36 msgid ""Attached"" msgstr """" #: dashboards/project/networks/ports/tables.py:38 msgid ""Detached"" msgstr """" #: dashboards/project/networks/ports/tables.py:43 #: dashboards/project/networks/ports/views.py:85 msgid ""Edit Port"" msgstr """" #: dashboards/project/networks/ports/tables.py:55 #: dashboards/project/routers/ports/tables.py:94 msgctxt ""Admin state of a Port"" msgid ""UP"" msgstr """" #: dashboards/project/networks/ports/tables.py:56 #: dashboards/project/routers/ports/tables.py:95 msgctxt ""Admin state of a Port"" msgid ""DOWN"" msgstr """" #: dashboards/project/networks/ports/tables.py:60 msgctxt ""status of a network port"" msgid ""Active"" msgstr """" #: dashboards/project/networks/ports/tables.py:61 msgctxt ""status of a network port"" msgid ""Down"" msgstr """" #: dashboards/project/networks/ports/tables.py:62 msgctxt ""status of a neteork port"" msgid ""Error"" msgstr """" #: dashboards/project/networks/ports/tables.py:63 msgctxt ""status of a network port"" msgid ""Build"" msgstr """" #: dashboards/project/networks/ports/tables.py:72 msgid ""Attached Device"" msgstr """" #: dashboards/project/networks/ports/views.py:39 msgid ""Port Details"" msgstr """" #: dashboards/project/networks/ports/views.py:54 #: dashboards/project/routers/views.py:135 #: dashboards/project/routers/ports/tabs.py:35 msgid ""Unable to retrieve port details."" msgstr """" #: dashboards/project/networks/ports/views.py:91 msgid ""Update Port"" msgstr """" #: dashboards/project/networks/ports/views.py:104 msgid ""Unable to retrieve port details"" msgstr """" #: dashboards/project/networks/subnets/tables.py:106 msgid ""Create Subnet (Quota exceeded)"" msgstr """" #: dashboards/project/networks/subnets/utils.py:20 msgid ""No options specified"" msgstr """" #: dashboards/project/networks/subnets/utils.py:22 msgid ""SLAAC: Address discovered from OpenStack Router"" msgstr """" #: dashboards/project/networks/subnets/utils.py:24 msgid ""DHCPv6 stateful: Address discovered from OpenStack DHCP"" msgstr """" #: dashboards/project/networks/subnets/utils.py:26 msgid """" ""DHCPv6 stateless: Address discovered from OpenStack Router and additional"" "" information from OpenStack DHCP"" msgstr """" #: dashboards/project/networks/subnets/views.py:67 msgid ""Unable to retrieve subnet details"" msgstr """" #: dashboards/project/networks/subnets/views.py:112 msgid ""Unable to retrieve subnet details."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:35 msgid ""Specify \""Network Address\"""" msgstr """" #: dashboards/project/networks/subnets/workflows.py:39 msgid """" ""Create a subnet associated with the network. Advanced configuration is "" ""available by clicking on the \""Subnet Details\"" tab."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:58 #, python-format msgid ""Created subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:59 #, python-format msgid ""Unable to create subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:86 msgid ""Network address in CIDR format (e.g. 192.168.0.0/24)"" msgstr """" #: dashboards/project/networks/subnets/workflows.py:103 msgid ""Gateway IP (optional)"" msgstr """" #: dashboards/project/networks/subnets/workflows.py:106 msgid """" ""IP address of Gateway (e.g. 192.168.0.254). Specify an explicit address "" ""to set the gateway. If you do not want to use a gateway, check 'Disable "" ""Gateway' below."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:117 msgid """" ""Update a subnet associated with the network. Advanced configuration are "" ""available at \""Subnet Details\"" tab."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:160 #, python-format msgid ""Updated subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:161 #, python-format msgid ""Unable to update subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:196 #, python-format msgid ""Subnet \""%s\"" was successfully updated."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:200 #, python-format msgid ""Failed to update subnet \""%(sub)s\"": %(reason)s""#: dashboards/project/routers/tables.py:39 msgid ""Delete Router"" msgid_plural ""Delete Routers"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:47 msgid ""Deleted Router"" msgid_plural ""Deleted Routers"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:67 #: dashboards/project/routers/tables.py:75 #, python-format msgid ""Unable to delete router \""%s\"""" msgstr """" #: dashboards/project/routers/tables.py:85 #: dashboards/project/routers/tables.py:98 #: dashboards/project/routers/views.py:164 #: dashboards/project/routers/views.py:167 #: dashboards/project/routers/views.py:168 msgid ""Create Router"" msgstr """" #: dashboards/project/routers/tables.py:96 msgid ""Create Router (Quota exceeded)"" msgstr """" #: dashboards/project/routers/tables.py:106 #: dashboards/project/routers/views.py:175 msgid ""Edit Router"" msgstr """" #: dashboards/project/routers/tables.py:115 #: dashboards/project/routers/ports/views.py:68 msgid ""Set Gateway"" msgstr """" #: dashboards/project/routers/tables.py:128 msgid """" ""You may reset the gateway later by using the set gateway action, but the "" ""gateway IP may change."" msgstr """" #: dashboards/project/routers/tables.py:133 msgid ""Clear Gateway"" msgid_plural ""Clear Gateways"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:141 msgid ""Cleared Gateway"" msgid_plural ""Cleared Gateways"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:158 #, python-format msgid ""Unable to clear gateway for router \""%(name)s\"": \""%(msg)s\"""" msgstr """" #: dashboards/project/routers/tables.py:200 msgctxt ""current status of router"" msgid ""Active"" msgstr """" #: dashboards/project/routers/tables.py:201 msgctxt ""current status of router"" msgid ""Error"" msgstr """" #: dashboards/project/routers/tables.py:204 msgctxt ""Admin state of a Router"" msgid ""UP"" msgstr """" #: dashboards/project/routers/tables.py:205 msgctxt ""Admin state of a Router"" msgid ""DOWN"" msgstr """" #: dashboards/project/routers/tables.py:221 msgid ""HA mode"" msgstr """" #: dashboards/project/routers/views.py:74 #, python-format msgid ""Unable to retrieve a list of external networks \""%s\""."" msgstr """" #: dashboards/project/routers/views.py:87 #, python-format msgid """" ""External network \""%(ext_net_id)s\"" expected but not found for router "" ""\""%(router_id)s\""."" msgstr """" #: dashboards/project/routers/views.py:92 #, python-format msgctxt ""External network not found"" msgid ""%s (Not Found)"" msgstr """" #: dashboards/project/routers/views.py:102 msgid ""Router Details"" msgstr """" #: dashboards/project/routers/views.py:111 #, python-format msgid ""Unable to retrieve details for router \""%s\""."" msgstr """" #: dashboards/project/routers/views.py:122 #, python-format msgid ""Unable to retrieve an external network \""%s\""."" msgstr """" #: dashboards/project/routers/views.py:178 msgid ""Update Router"" msgstr """" #: dashboards/project/routers/views.py:195 msgid ""Unable to retrieve router details."" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:33 #: dashboards/project/routers/extensions/extraroutes/tables.py:65 #: dashboards/project/routers/extensions/routerrules/forms.py:50 #: dashboards/project/routers/extensions/routerrules/tables.py:72 msgid ""Destination CIDR"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:34 #: dashboards/project/routers/extensions/extraroutes/tables.py:66 msgid ""Next Hop"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:45 msgid ""Static route added"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:50 #, python-format msgid ""Invalid format for routes : %s"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:56 #, python-format msgid ""Failed to add route : %s"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/tables.py:28 msgid ""Add Static Route"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/tables.py:42 msgid ""Delete Static Route"" msgid_plural ""Delete Static Routes"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/extraroutes/tables.py:50 msgid ""Deleted Static Route"" msgid_plural ""Deleted Static Routes"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/extraroutes/tabs.py:40 msgid ""Failed to check if Neutron extraroute extension is supported"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/views.py:48 #: dashboards/project/routers/extensions/routerrules/views.py:50 #: dashboards/project/routers/ports/views.py:49 msgid ""Unable to retrieve router."" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:43 msgid ""Input must be in CIDR format"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:48 #: dashboards/project/routers/extensions/routerrules/tables.py:70 msgid ""Source CIDR"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:53 msgid ""Optional: Next Hop Addresses (comma delimited)"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:56 #: dashboards/project/routers/ports/forms.py:38 #: dashboards/project/routers/ports/forms.py:157 msgid ""Router ID"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:63 msgid ""Permit"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:64 msgid ""Deny"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:73 msgid ""Unable to delete router rule."" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:88 msgid ""Router rule added"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:93 #, python-format msgid ""Failed to add router rule %s"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tables.py:32 #: dashboards/project/routers/extensions/routerrules/views.py:37 msgid ""Add Router Rule"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tables.py:46 msgid ""Delete Router Rule"" msgid_plural ""Delete Router Rules"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/routerrules/tables.py:54 msgid ""Deleted Router Rule"" msgid_plural ""Deleted Router Rules"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/routerrules/tables.py:74 msgid ""Next Hops"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tables.py:81 #: dashboards/project/routers/extensions/routerrules/tabs.py:32 msgid ""Router Rules"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tabs.py:60 msgid ""Router Rules Grid"" msgstr """" #: dashboards/project/routers/ports/tables.py:57#: dashboards/project/routers/ports/tables.py:65#: dashboards/project/stacks/forms.py:56 dashboards/project/stacks/views.py:90 #: dashboards/project/stacks/views.py:96 dashboards/project/stacks/views.py:106""This is required for operations to be performed throughout the lifecycle "" ""of the stack""#: dashboards/project/stacks/tables.py:54#: dashboards/project/stacks/tables.py:62#: dashboards/project/stacks/tables.py:79#: dashboards/project/stacks/tables.py:87#: dashboards/project/stacks/tables.py:104#: dashboards/project/stacks/tables.py:112#: dashboards/project/stacks/tables.py:136#: dashboards/project/stacks/tables.py:144#: dashboards/project/stacks/tables.py:197#: dashboards/project/stacks/tables.py:199#: dashboards/project/stacks/tables.py:201#: dashboards/project/stacks/tables.py:203#: dashboards/project/stacks/tables.py:205#: dashboards/project/stacks/tables.py:207#: dashboards/project/stacks/tables.py:209#: dashboards/project/stacks/tables.py:211#: dashboards/project/stacks/tables.py:213#: dashboards/project/stacks/tables.py:215#: dashboards/project/stacks/tables.py:217#: dashboards/project/stacks/tables.py:219#: dashboards/project/stacks/tables.py:221#: dashboards/project/stacks/tables.py:223#: dashboards/project/stacks/tables.py:225#: dashboards/project/stacks/tables.py:227#: dashboards/project/stacks/tables.py:229#: dashboards/project/stacks/tables.py:231#: dashboards/project/stacks/tables.py:233#: dashboards/project/stacks/tables.py:235#: dashboards/project/stacks/tables.py:237#: dashboards/project/stacks/tables.py:239#: dashboards/project/stacks/tables.py:241#: dashboards/project/stacks/tables.py:243#: dashboards/project/stacks/tables.py:245#: dashboards/project/stacks/tables.py:247#: dashboards/project/stacks/tables.py:249#: dashboards/project/stacks/tables.py:251#: dashboards/project/stacks/tables.py:253#: dashboards/project/stacks/tables.py:255#: dashboards/project/stacks/tables.py:266 msgid ""Updated"" msgstr """" #: dashboards/project/stacks/tables.py:312 #: dashboards/project/stacks/tables.py:362 #: dashboards/project/stacks/resource_types/tables.py:38 msgid ""Resource"" msgstr """" #: dashboards/project/stacks/tabs.py:107#: dashboards/project/stacks/tabs.py:135#: dashboards/project/stacks/views.py:113 msgid ""Change Template"" msgstr """" #: dashboards/project/stacks/views.py:255 msgid ""Preview Stack Details"" msgstr """" #: dashboards/project/stacks/resource_types/tables.py:26 msgid ""AWS compatible"" msgstr """" #: dashboards/project/stacks/resource_types/tables.py:34 msgid ""Implementation"" msgstr """" #: dashboards/project/stacks/resource_types/tables.py:36 msgid ""Component"" msgstr """" #: dashboards/project/stacks/resource_types/views.py:41 msgid ""Unable to retrieve stack resource types."" msgstr """" #: dashboards/project/stacks/resource_types/views.py:49 msgid ""Resource Type Details"" msgstr """" #: dashboards/project/stacks/resource_types/views.py:58 msgid ""Unable to retrieve resource type details."" msgstr """" #: dashboards/project/volumes/tabs.py:38 msgid ""Unable to retrieve volume list."" msgstr """" #: dashboards/project/volumes/tabs.py:48 msgid ""Unable to retrieve volume/instance attachment information"" msgstr """" #: dashboards/project/volumes/tabs.py:62 msgid ""Unable to retrieve snapshot list."" msgstr """" #: dashboards/project/volumes/tabs.py:127 #: dashboards/project/volumes/backups/tables.py:49 #: dashboards/project/volumes/backups/tables.py:141 msgid ""Volume Backups"" msgstr """" #: dashboards/project/volumes/tabs.py:144 msgid ""Unable to retrieve volume backups."" msgstr """" #: dashboards/project/volumes/utils.py:28 msgid ""Unable to retrieve volumes availability zones."" msgstr """" ""Successfully restored backup %(backup_name)s to volume with id: "" ""%(volume_id)s""#: dashboards/project/volumes/backups/tables.py:107#: dashboards/project/volumes/backups/tables.py:109#: dashboards/project/volumes/backups/tables.py:111#: dashboards/project/volumes/backups/tables.py:113#: dashboards/project/volumes/backups/tables.py:115#: dashboards/project/volumes/backups/tables.py:117#: dashboards/project/volumes/snapshots/tables.py:55#: dashboards/project/volumes/snapshots/tables.py:63#: dashboards/project/volumes/volumes/forms.py:85 msgid ""Volume Source"" msgstr """" msgid ""Volume size must be equal to or greater than the origin volume size (%s)""""A volume of %(req)iGB cannot be created as you only have %(avail)iGB of "" ""your quota available.""""Actual device name may differ due to hypervisor settings. If not "" ""specified, then hypervisor will select a device name.""#: dashboards/project/volumes/volumes/forms.py:639 msgid ""Disk Format"" msgstr """" #: dashboards/project/volumes/volumes/forms.py:643#: dashboards/project/volumes/volumes/forms.py:678msgid ""Successfully sent the request to upload volume to image for volume: \""%s\""""#: dashboards/project/volumes/volumes/forms.py:686""Volume cannot be extended to %(req)iGB as you only have %(avail)iGB of "" ""your quota available.""#: dashboards/project/volumes/volumes/forms.py:746 msgid ""Never"" msgstr """" #: dashboards/project/volumes/volumes/forms.py:773#: dashboards/project/volumes/volumes/forms.py:789""Successfully sent the request to change the volume type to \""%(vtype)s\"" "" ""for volume: \""%(name)s\""""#: dashboards/project/volumes/volumes/forms.py:799#: dashboards/project/volumes/volumes/tables.py:68#: dashboards/project/volumes/volumes/tables.py:76#: dashboards/project/volumes/volumes/tables.py:133 #: dashboards/project/volumes/volumes/views.py:100 #: dashboards/project/volumes/volumes/views.py:102 #: dashboards/project/volumes/volumes/views.py:105 msgid ""Extend Volume"" msgstr """" #: dashboards/project/volumes/volumes/tables.py:232 #: dashboards/project/volumes/volumes/views.py:283 #: dashboards/project/volumes/volumes/views.py:288 msgid ""Edit Volume"" msgstr """" #: dashboards/project/volumes/volumes/tables.py:244 #: dashboards/project/volumes/volumes/views.py:394 #: dashboards/project/volumes/volumes/views.py:396 #: dashboards/project/volumes/volumes/views.py:399 msgid ""Change Volume Type"" msgstr """" #: dashboards/project/volumes/volumes/tables.py:372#: dashboards/project/volumes/volumes/tables.py:376#: dashboards/project/volumes/volumes/tables.py:378#: dashboards/project/volumes/volumes/tables.py:380#: dashboards/project/volumes/volumes/tables.py:382#: dashboards/project/volumes/volumes/tables.py:384#: dashboards/project/volumes/volumes/tables.py:386#: dashboards/project/volumes/volumes/tables.py:388#: dashboards/project/volumes/volumes/tables.py:390#: dashboards/project/volumes/volumes/tables.py:392#: dashboards/project/volumes/volumes/tables.py:430 msgid ""Attached To"" msgstr """" #: dashboards/project/volumes/volumes/tables.py:464#: dashboards/project/volumes/volumes/tables.py:473#: dashboards/project/volumes/volumes/tables.py:521 msgid ""Attachments"" msgstr """" #: dashboards/project/volumes/volumes/views.py:141 msgid ""Create Volume Snapshot"" msgstr """" ""This volume is currently attached to an instance. In some cases, creating"" "" a snapshot from an attached volume can result in a corrupted snapshot.""#: dashboards/project/volumes/volumes/views.py:174 #: dashboards/project/volumes/volumes/views.py:179 msgid ""Upload Volume to Image"" msgstr """" #: dashboards/project/volumes/volumes/views.py:176 msgid ""Upload"" msgstr """" #: dashboards/project/volumes/volumes/views.py:187 #: dashboards/project/volumes/volumes/views.py:407#: dashboards/project/volumes/volumes/views.py:216 #: dashboards/project/volumes/volumes/views.py:217 msgid ""Create Volume Transfer"" msgstr """" #: dashboards/project/volumes/volumes/views.py:237 #: dashboards/project/volumes/volumes/views.py:238 #: dashboards/project/volumes/volumes/views.py:241 msgid ""Accept Volume Transfer"" msgstr """" #: dashboards/project/volumes/volumes/views.py:249 msgid ""Volume Transfer"" msgstr """" #: dashboards/project/volumes/volumes/views.py:251 msgid ""Close"" msgstr """" #: dashboards/project/volumes/volumes/views.py:252 msgid ""Volume Transfer Details"" msgstr """" #: dashboards/project/volumes/volumes/views.py:320 #: dashboards/project/volumes/volumes/views.py:325 msgid ""Manage Volume Attachments"" msgstr """" #: dashboards/project/vpn/forms.py:86 dashboards/project/vpn/workflows.py:119#: dashboards/project/vpn/forms.py:109 dashboards/project/vpn/workflows.py:129#: dashboards/project/vpn/forms.py:158 dashboards/project/vpn/workflows.py:220#: dashboards/project/vpn/forms.py:187 dashboards/project/vpn/workflows.py:232#: dashboards/project/vpn/forms.py:230 dashboards/project/vpn/workflows.py:328#: dashboards/project/vpn/forms.py:236 dashboards/project/vpn/workflows.py:334""Peer router identity for authentication. Can be IPv4/IPv6 address, "" ""e-mail, key ID, or FQDN""""Remote peer subnet(s) address(es) with mask(s) in CIDR format separated "" ""with commas if needed (e.g. 20.1.0.0/24, 21.1.0.0/24)""""Equal to or greater than 68 if the local subnet is IPv4. Equal to or "" ""greater than 1280 if the local subnet is IPv6.""#: dashboards/project/vpn/forms.py:269 dashboards/project/vpn/workflows.py:422#: dashboards/project/vpn/forms.py:274 dashboards/project/vpn/workflows.py:427#: dashboards/project/vpn/forms.py:277 dashboards/project/vpn/workflows.py:431#: dashboards/project/vpn/tables.py:68#: dashboards/project/vpn/tables.py:76#: dashboards/project/vpn/tables.py:94#: dashboards/project/vpn/tables.py:102#: dashboards/project/vpn/tables.py:120#: dashboards/project/vpn/tables.py:128#: dashboards/project/vpn/tables.py:146#: dashboards/project/vpn/tables.py:154#: dashboards/project/vpn/tables.py:163 dashboards/project/vpn/views.py:274 #: dashboards/project/vpn/views.py:280#: dashboards/project/vpn/tables.py:179 dashboards/project/vpn/views.py:310 #: dashboards/project/vpn/views.py:316#: dashboards/project/vpn/tables.py:193 dashboards/project/vpn/views.py:353 #: dashboards/project/vpn/views.py:359#: dashboards/project/vpn/tables.py:229#: dashboards/project/vpn/tables.py:231#: dashboards/project/vpn/tables.py:233#: dashboards/project/vpn/tables.py:268#: dashboards/project/vpn/tables.py:270#: dashboards/project/vpn/tables.py:272#: dashboards/project/vpn/tables.py:274#: dashboards/project/vpn/tables.py:276#: dashboards/project/vpn/tables.py:278#: dashboards/project/vpn/tables.py:280#: dashboards/project/vpn/tables.py:282#: dashboards/project/vpn/tables.py:290 dashboards/project/vpn/workflows.py:29 #: dashboards/router/dashboard.py:19 msgid ""Router"" msgstr """" #: dashboards/project/vpn/views.py:395 dashboards/project/vpn/views.py:401 msgid ""Edit IPSec Site Connection"" msgstr """" ""Specify a name, description, router, and subnet for the VPN Service. "" ""Admin State is Up (checked) by default.""""Assign a name and description for the IPSec Site Connection. All fields "" ""in this tab are required.""""Fields in this tab are optional. You can configure the detail of IPSec "" ""site connection created.""#: dashboards/router/nexus1000v/tables.py:38#: dashboards/router/nexus1000v/tables.py:46#: dashboards/router/nexus1000v/views.py:125 msgid ""Update Network Profile"" msgstr """" #: dashboards/settings/user/panel.py:23 dashboards/settings/user/views.py:27 #: dashboards/settings/user/views.py:29#: local/local_settings.py:175 msgid ""Keystone Credentials""#: local/local_settings.py:176 msgid ""OpenID Connect""#: local/local_settings.py:177 msgid ""Security Assertion Markup Language""#: local/local_settings.py:289 msgid ""Euca2ools state""#: local/local_settings.py:291 msgid ""Image Type""#: openstack/common/log.py:287 #, python-format msgid ""Deprecated: %s""#: openstack/common/log.py:395 #, python-format msgid ""Error loading logging config %(log_config)s: %(err_msg)s""#: openstack/common/log.py:456 #, python-format msgid ""syslog facility must be one of: %s""#: openstack/common/log.py:707 #, python-format msgid ""Fatal call to deprecated config: %(msg)s""#: openstack/common/policy.py:97 msgid ""The JSON file that defines policies.""#: openstack/common/policy.py:100 msgid ""Default rule. Enforced when a requested rule is not found.""#: openstack/common/policy.py:104 msgid ""The directories of policy configuration files is stored""#: openstack/common/policy.py:119 #, python-format msgid ""Policy doesn't allow %s to be performed.""#: openstack/common/policy.py:213 #, python-format msgid ""Rules must be an instance of dict or Rules, got %s instead""#: templates/403.html:5 templates/403.html:10#: templates/403.html:13"" privileges to access this content. If you believe this message "" ""to\n""""An unexpected error has occurred. Try refreshing the page. If that "" ""doesn't help, contact your local administrator.""""Invalid time period. The end date should be more recent than the start "" ""date.""""Invalid time period. You are requesting data from the future which may "" ""not exist.""#: usage/tables.py:34 msgid ""Disk"" msgstr """" msgid ""Total VCPU usage (Number of VCPU in instance * Hours Used) for the project""#: usage/views.py:71 msgid ""Allocated"" msgstr """" #: usage/views.py:80 msgid ""Volume Storage"" msgstr """" #~ msgid ""Description:"" #~ msgstr """" #~ msgid """" #~ ""Host aggregates divide an availability "" #~ ""zone into logical units by grouping "" #~ ""together hosts. Edit the aggregate host"" #~ "" to select hosts contained in it."" #~ msgstr """" #~ msgid ""Cancel"" #~ msgstr """" #~ msgid ""Disable the compute service."" #~ msgstr """" #~ msgid """" #~ ""Evacuate the servers from the selected"" #~ "" down host to an active target "" #~ ""host."" #~ msgstr """" #~ msgid """" #~ ""Migrate all instances from a host "" #~ ""with disabled nova-compute service. "" #~ ""Optionally you can choose type of "" #~ ""migration. All running instances of the"" #~ "" host can be Live Migrated. Cold "" #~ ""Migration is trying to use 'nova "" #~ ""migrate' on each instance of migrated"" #~ "" host."" #~ msgstr """" #~ msgid ""Hypervisor Summary"" #~ msgstr """" #~ msgid ""VCPU Usage"" #~ msgstr """" #~ msgid ""Used <span> %(used)s </span> of <span> %(available)s </span>"" #~ msgstr """" #~ msgid ""Memory Usage"" #~ msgstr """" #~ msgid ""Local Disk Usage"" #~ msgstr """" #~ msgid ""Specify an image to upload to the Image Service."" #~ msgstr """" #~ msgid """" #~ ""Currently only images available via an"" #~ "" HTTP URL are supported. The image"" #~ "" location must be accessible to the"" #~ "" Image Service. Compressed image binaries"" #~ "" are supported (.zip and .tar.gz.)"" #~ msgstr """" #~ msgid ""Please note: "" #~ msgstr """" #~ msgid """" #~ ""The Image Location field MUST be a"" #~ "" valid and direct URL to the "" #~ ""image binary. URLs that redirect or "" #~ ""serve error pages will result in "" #~ ""unusable images."" #~ msgstr """" #~ msgid ""Edit the image details."" #~ msgstr """" #~ msgid ""Reason: %(disabled_reason)s"" #~ msgstr """" #~ msgid """" #~ ""Version: %(version_info)s\n"" #~ "" "" #~ msgstr """" #~ msgid ""Live migrate an instance to a specific host."" #~ msgstr """" #~ msgid ""Specify a metadata definition namespace to import."" #~ msgstr """" #~ msgid ""Only definitions in raw JSON format are supported."" #~ msgstr """" #~ msgid """" #~ ""Administrator Note: Use the following "" #~ ""CLI command to import the default "" #~ ""definitions into Glance: "" #~ msgstr """" #~ msgid ""Undefined"" #~ msgstr """" #~ msgid ""Info"" #~ msgstr """" #~ msgid ""Display Name"" #~ msgstr """" #~ msgid ""Namespace"" #~ msgstr """" #~ msgid ""Never updated"" #~ msgstr """" #~ msgid ""Associated Resource Types"" #~ msgstr """" #~ msgid ""Prefix: "" #~ msgstr """" #~ msgid ""Properties Target: "" #~ msgstr """" #~ msgid ""No associations defined."" #~ msgstr """" #~ msgid ""Namespace Resource Type Associations"" #~ msgstr """" #~ msgid ""Namespace Details"" #~ msgstr """" #~ msgid ""Available Types"" #~ msgstr """" #~ msgid ""Filter"" #~ msgstr """" #~ msgid """" #~ ""Namespaces can be associated to "" #~ ""different resource types. This makes the"" #~ "" properties in the namespace visible "" #~ ""in the 'Update Metadata' action for "" #~ ""that type of resource."" #~ msgstr """" #~ msgid """" #~ ""Additionally, some resource types may "" #~ ""require a prefix to be used when"" #~ "" applying the metadata. In certain "" #~ ""cases, the prefix may differ between "" #~ ""the resource type (for example, flavor"" #~ "" vs image)."" #~ msgstr """" #~ msgid """" #~ ""Example: The prefix 'hw:' is added "" #~ ""to OS::Nova::Flavor for the Virtual CPU"" #~ "" Topology namespace so that the "" #~ ""properties will be prefixed with 'hw:'"" #~ "" when applied to flavors."" #~ msgstr """" #~ msgid """" #~ ""Do not use a colon ':' with "" #~ ""OS::Glance::Images. This resource type does"" #~ "" not support the use of colons."" #~ msgstr """" #~ msgid ""Select a pre-defined period or specify date."" #~ msgstr """" #~ msgid ""View Usage Report"" #~ msgstr """" #~ msgid ""Metric:"" #~ msgstr """" #~ msgid ""Compute (Nova)"" #~ msgstr """" #~ msgid ""Network (Neutron)"" #~ msgstr """" #~ msgid ""Image (Glance)"" #~ msgstr """" #~ msgid ""Volume (Cinder)"" #~ msgstr """" #~ msgid ""Object Storage (Swift)"" #~ msgstr """" #~ msgid ""Energy (Kwapi)"" #~ msgstr """" #~ msgid ""Intelligent Platform Management Interface (IPMI)"" #~ msgstr """" #~ msgid ""Group by:"" #~ msgstr """" #~ msgid ""--"" #~ msgstr """" #~ msgid ""Value:"" #~ msgstr """" #~ msgid ""Avg."" #~ msgstr """" #~ msgid ""Min."" #~ msgstr """" #~ msgid ""Max."" #~ msgstr """" #~ msgid ""Sum."" #~ msgstr """" #~ msgid ""Period:"" #~ msgstr """" #~ msgid ""From:"" #~ msgstr """" #~ msgid ""To:"" #~ msgstr """" #~ msgid ""Statistics of all resources"" #~ msgstr """" #~ msgid ""Create a new network for any project as you need."" #~ msgstr """" #~ msgid """" #~ ""Provider specified network can be "" #~ ""created. You can specify a physical "" #~ ""network type (like Flat, VLAN, GRE, "" #~ ""and VXLAN) and its segmentation_id or"" #~ "" physical network name for a new "" #~ ""virtual network."" #~ msgstr """" #~ msgid """" #~ ""In addition, you can create an "" #~ ""external network or a shared network "" #~ ""by checking the corresponding checkbox."" #~ msgstr """" #~ msgid ""You may update the editable properties of your network here."" #~ msgstr """" #~ msgid ""From here you can add a DHCP agent for the network."" #~ msgstr """" #~ msgid """" #~ ""You can create a port for the "" #~ ""network. If you specify device ID "" #~ ""to be attached, the device specified "" #~ ""will be attached to the port "" #~ ""created."" #~ msgstr """" #~ msgid ""MAC Address"" #~ msgstr """" #~ msgid ""On"" #~ msgstr """" #~ msgid ""Fixed IP"" #~ msgstr """" #~ msgid ""Subnet ID"" #~ msgstr """" #~ msgid ""No attached device"" #~ msgstr """" #~ msgid ""Binding"" #~ msgstr """" #~ msgid ""Profile"" #~ msgstr """" #~ msgid ""VIF Type"" #~ msgstr """" #~ msgid ""VIF Details"" #~ msgstr """" #~ msgid ""VNIC Type"" #~ msgstr """" #~ msgid ""You may update the editable properties of your port here."" #~ msgstr """" #~ msgid ""Usage Report For Period:"" #~ msgstr """" #~ msgid ""Active Instances:"" #~ msgstr """" #~ msgid ""Total VCPU Usage (Hours):"" #~ msgstr """" #~ msgid ""Total Active RAM (MB):"" #~ msgstr """" #~ msgid ""Total Memory Usage (Hours):"" #~ msgstr """" #~ msgid ""Total Disk Size (GB):"" #~ msgstr """" #~ msgid ""Total Disk Usage (Hours):"" #~ msgstr """" #~ msgid ""Usage Overview"" #~ msgstr """" #~ msgid ""Monitoring:"" #~ msgstr """" #~ msgid ""Volume Snapshot Overview"" #~ msgstr """" #~ msgid ""GB"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" The status of a volume "" #~ ""snapshot is normally managed automatically."" #~ "" In some circumstances\n"" #~ "" an administrator may need to "" #~ ""explicitly update the status value. This"" #~ "" is equivalent to\n"" #~ "" the <tt>cinder snapshot-reset-state</tt> command.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Add, modify or remove the QoS Spec associated with this volume type."" #~ msgstr """" #~ msgid """" #~ ""\""None\"" indicates that no QoS Spec "" #~ ""is currently associated. Conversely, setting"" #~ "" the QoS Spec to \""None\"" will "" #~ ""remove the current association."" #~ msgstr """" #~ msgid """" #~ ""This is equivalent to the <tt>cinder "" #~ ""qos-associate</tt> and <tt>cinder qos-"" #~ ""disassociate</tt> commands."" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" QoS Specs can be associated with volume types.\n"" #~ "" It is used to map to a"" #~ "" set of quality of service "" #~ ""capabilities requested\n"" #~ "" by the volume owner. This is equivalent to the\n"" #~ "" <tt>cinder qos-create</tt> command. "" #~ ""Once the QoS Spec gets created,\n"" #~ "" click the \""Manage Specs\"" button"" #~ "" to manage the key-value specs "" #~ ""for the QoS Spec.\n"" #~ "" <br>\n"" #~ "" <br>\n"" #~ "" Each QoS Specs entity will "" #~ ""have a \""Consumer\"" value which "" #~ ""indicates where the\n"" #~ "" administrator would like the QoS"" #~ "" policy to be enforced. This value"" #~ "" can be \""front-end\""\n"" #~ "" (Nova Compute), \""back-end\"" (Cinder back-end), or \""both\"".\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Volume type is a type or "" #~ ""label that can be selected at "" #~ ""volume creation\n"" #~ "" time in OpenStack. It usually "" #~ ""maps to a set of capabilities of"" #~ "" the storage\n"" #~ "" back-end driver to be used"" #~ "" for this volume. Examples: "" #~ ""\""Performance\"",\n"" #~ "" \""SSD\"", \""Backup\"", etc. This is equivalent to the\n"" #~ "" <tt>cinder type-create</tt> command. "" #~ ""Once the volume type gets created,\n"" #~ """" #~ "" click the \""View Extra Specs\"" "" #~ ""button to set up extra specs "" #~ ""key-value\n"" #~ "" pair(s) for that volume type.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""Creating encryption for a volume type"" #~ "" causes all volumes with that volume"" #~ "" type to be encrypted. Encryption "" #~ ""information cannot be added to a "" #~ ""volume type if volumes are currently "" #~ ""in use with that volume type."" #~ msgstr """" #~ msgid """" #~ ""The <strong>Provider</strong> is the class "" #~ ""providing encryption support (e.g. "" #~ ""LuksEncryptor)."" #~ msgstr """" #~ msgid """" #~ ""The <strong>Control Location</strong> is the"" #~ "" notional service where encryption is "" #~ ""performed (e.g., front-end=Nova). The "" #~ ""default value is 'front-end.'"" #~ msgstr """" #~ msgid """" #~ ""The <strong>Cipher</strong> is the encryption"" #~ "" algorithm/mode to use (e.g., aes-"" #~ ""xts-plain64). If the field is left"" #~ "" empty, the provider default will be"" #~ "" used."" #~ msgstr """" #~ msgid """" #~ ""The <strong>Key Size</strong> is the "" #~ ""size of the encryption key, in "" #~ ""bits (e.g., 128, 256). If the "" #~ ""field is left empty, the provider "" #~ ""default will be used."" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Each QoS Specs entity will "" #~ ""have a \""Consumer\"" value which "" #~ ""indicates where the\n"" #~ "" administrator would like the QoS "" #~ ""policy to be enforced. This value "" #~ ""can be \""front-end\""\n"" #~ "" (Nova Compute), \""back-end\"" (Cinder back-end), or \""both\"".\n"" #~ "" "" #~ msgstr """" #~ msgid ""Volume Type Encryption Overview"" #~ msgstr """" #~ msgid ""Volume Type is Unencrypted."" #~ msgstr """" #~ msgid ""Associate QoS Spec"" #~ msgstr """" #~ msgid ""Create Encrypted Volume Type"" #~ msgstr """" #~ msgid ""Create a new \""extra spec\"" key-value pair for a volume type."" #~ msgstr """" #~ msgid ""Update the \""extra spec\"" value for \""%(key)s\"""" #~ msgstr """" #~ msgid ""Volume Type Extra Specs"" #~ msgstr """" #~ msgid ""Volume Type: %(volume_type_name)s "" #~ msgstr """" #~ msgid ""Edit Volume Type Extra Spec"" #~ msgstr """" #~ msgid ""Volume Type: %(volume_type_name)s"" #~ msgstr """" #~ msgid ""Create a new \""spec\"" key-value pair for QoS Spec \""%(qos_spec_name)s\"""" #~ msgstr """" #~ msgid ""Update the spec value for \""%(key)s\"""" #~ msgstr """" #~ msgid ""Edit Spec"" #~ msgstr """" #~ msgid ""QoS Spec: "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" \""Manage\"" an existing volume from"" #~ "" a Cinder host. This will make "" #~ ""the volume visible within\n"" #~ "" OpenStack.\n"" #~ "" <br>\n"" #~ "" <br>\n"" #~ "" This is equivalent to the <tt>cinder manage</tt> command.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" When a volume is \""unmanaged\"", "" #~ ""the volume will no longer be "" #~ ""visible within OpenStack. Note that the"" #~ ""\n"" #~ "" volume will not be deleted from the Cinder host.\n"" #~ "" <br>\n"" #~ "" <br>\n"" #~ "" This is equivalent to the <tt>cinder unmanage</tt> command.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" The status of a volume is "" #~ ""normally managed automatically. In some "" #~ ""circumstances an\n"" #~ "" administrator may need to explicitly"" #~ "" update the status value. This is"" #~ "" equivalent to\n"" #~ "" the <tt>cinder reset-state</tt> command.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Volume Details"" #~ msgstr """" #~ msgid ""Add Group Assignment"" #~ msgstr """" #~ msgid """" #~ ""Groups are used to manage access "" #~ ""and assign roles to multiple users "" #~ ""at once. After creating the group, "" #~ ""edit the group to add users."" #~ msgstr """" #~ msgid """" #~ ""Groups are used to manage access "" #~ ""and assign roles to multiple users "" #~ ""at once. Edit the group to add "" #~ ""users."" #~ msgstr """" #~ msgid ""Add User to Group"" #~ msgstr """" #~ msgid ""Group Management"" #~ msgstr """" #~ msgid ""Project Overview"" #~ msgstr """" #~ msgid ""Project Details"" #~ msgstr """" #~ msgid ""Project Usage Overview"" #~ msgstr """" #~ msgid ""Create a new role."" #~ msgstr """" #~ msgid ""Edit the role's details."" #~ msgstr """" #~ msgid ""Change user's password. We highly recommend you create a strong one."" #~ msgstr """" #~ msgid """" #~ ""Create a new user and set related"" #~ "" properties including the Primary Project"" #~ "" and Role."" #~ msgstr """" #~ msgid ""User Overview"" #~ msgstr """" #~ msgid ""Edit the user's details, including the Primary Project."" #~ msgstr """" #~ msgid ""User Details"" #~ msgstr """" #~ msgid ""User Credentials"" #~ msgstr """" #~ msgid ""Authentication URL"" #~ msgstr """" #~ msgid ""EC2 URL"" #~ msgstr """" #~ msgid ""S3 URL"" #~ msgstr """" #~ msgid ""EC2 Access Key"" #~ msgstr """" #~ msgid ""EC2 Secret Key"" #~ msgstr """" #~ msgid ""Allocate a floating IP from a given floating IP pool."" #~ msgstr """" #~ msgid ""Project Quotas"" #~ msgstr """" #~ msgid ""Floating IP"" #~ msgstr """" #~ msgid ""Access &amp; Security"" #~ msgstr """" #~ msgid """" #~ ""Key pairs are ssh credentials which "" #~ ""are injected into images when they "" #~ ""are launched. Creating a new key "" #~ ""pair registers the public key and "" #~ ""downloads the private key (a .pem "" #~ ""file)."" #~ msgstr """" #~ msgid ""Protect and use the key as you would any normal ssh private key."" #~ msgstr """" #~ msgid ""Key Pairs are how you login to your instance after it is launched."" #~ msgstr """" #~ msgid """" #~ ""Choose a key pair name you will"" #~ "" recognise and paste your SSH public"" #~ "" key into the space provided."" #~ msgstr """" #~ msgid ""SSH key pairs can be generated with the ssh-keygen command:"" #~ msgstr """" #~ msgid """" #~ ""This generates a pair of keys: a"" #~ "" key you keep private (cloud.key) and"" #~ "" a public key (cloud.key.pub). Paste "" #~ ""the contents of the public key "" #~ ""file here."" #~ msgstr """" #~ msgid """" #~ ""After launching an instance, you login"" #~ "" using the private key (the username"" #~ "" might be different depending on the"" #~ "" image you launched):"" #~ msgstr """" #~ msgid """" #~ ""The key pair &quot;%(keypair_name)s&quot; "" #~ ""should download automatically. If not "" #~ ""use the link below."" #~ msgstr """" #~ msgid ""Download key pair &quot;%(keypair_name)s&quot;"" #~ msgstr """" #~ msgid """" #~ ""Rules define which traffic is allowed"" #~ "" to instances assigned to the "" #~ ""security group. A security group rule"" #~ "" consists of three main parts:"" #~ msgstr """" #~ msgid ""Rule:"" #~ msgstr """" #~ msgid """" #~ ""You can specify the desired rule "" #~ ""template or use custom rules, the "" #~ ""options are Custom TCP Rule, Custom "" #~ ""UDP Rule, or Custom ICMP Rule."" #~ msgstr """" #~ msgid ""Open Port/Port Range:"" #~ msgstr """" #~ msgid """" #~ ""For TCP and UDP rules you may "" #~ ""choose to open either a single "" #~ ""port or a range of ports. "" #~ ""Selecting the \""Port Range\"" option will"" #~ "" provide you with space to provide"" #~ "" both the starting and ending ports"" #~ "" for the range. For ICMP rules "" #~ ""you instead specify an ICMP type "" #~ ""and code in the spaces provided."" #~ msgstr """" #~ msgid ""Remote:"" #~ msgstr """" #~ msgid """" #~ ""You must specify the source of the"" #~ "" traffic to be allowed via this "" #~ ""rule. You may do so either in "" #~ ""the form of an IP address block"" #~ "" (CIDR) or via a source group "" #~ ""(Security Group). Selecting a security "" #~ ""group as the source will allow any"" #~ "" other instance in that security "" #~ ""group access to any other instance "" #~ ""via this rule."" #~ msgstr """" #~ msgid """" #~ ""Security groups are sets of IP "" #~ ""filter rules that are applied to "" #~ ""the network settings for the VM. "" #~ ""After the security group is created, "" #~ ""you can add rules to the security"" #~ "" group."" #~ msgstr """" #~ msgid """" #~ ""Security groups are sets of IP "" #~ ""filter rules that are applied to "" #~ ""the network settings for the VM. "" #~ ""Edit the security group to add and"" #~ "" change the rules."" #~ msgstr """" #~ msgid ""Manage Security Group Rules"" #~ msgstr """" #~ msgid ""Public URL"" #~ msgstr """" #~ msgid ""Object Count"" #~ msgstr """" #~ msgid ""Object Count: "" #~ msgstr """" #~ msgid ""Size: "" #~ msgstr """" #~ msgid ""Access: "" #~ msgstr """" #~ msgid ""Copy Object: %(object_name)s"" #~ msgstr """" #~ msgid """" #~ ""Make a new copy of an existing "" #~ ""object to store in this or another"" #~ "" container. You may additionally specify"" #~ "" the path within the selected "" #~ ""container where the new copy should "" #~ ""be stored."" #~ msgstr """" #~ msgid """" #~ ""A container is a storage compartment "" #~ ""for your data and provides a way"" #~ "" for you to organize your data. "" #~ ""You can think of a container as"" #~ "" a folder in Windows &reg; or a"" #~ "" directory in UNIX &reg;. The primary"" #~ "" difference between a container and "" #~ ""these other file system concepts is "" #~ ""that containers cannot be nested. You"" #~ "" can, however, create an unlimited "" #~ ""number of containers within your "" #~ ""account. Data must be stored in a"" #~ "" container so you must have at "" #~ ""least one container defined in your "" #~ ""account prior to uploading data."" #~ msgstr """" #~ msgid """" #~ ""Note: A Public Container will allow "" #~ ""anyone with the Public URL to gain"" #~ "" access to your objects in the "" #~ ""container."" #~ msgstr """" #~ msgid ""Create pseudo-folder in container %(container_name)s"" #~ msgstr """" #~ msgid ""Pseudo-folder:"" #~ msgstr """" #~ msgid """" #~ ""Within a container you can group "" #~ ""your objects into pseudo-folders, which"" #~ "" behave similarly to folders in your"" #~ "" desktop operating system, with the "" #~ ""exception that they are virtual "" #~ ""collections defined by a common prefix"" #~ "" on the object's name. A slash "" #~ ""(/) character is used as the "" #~ ""delimiter for pseudo-folders in the "" #~ ""Object Store."" #~ msgstr """" #~ msgid ""Hash"" #~ msgstr """" #~ msgid ""Content Type"" #~ msgstr """" #~ msgid ""Last Modified"" #~ msgstr """" #~ msgid ""Edit Object"" #~ msgstr """" #~ msgid ""Object:"" #~ msgstr """" #~ msgid """" #~ ""An object is the basic storage "" #~ ""entity that represents a file you "" #~ ""store in the OpenStack Object Storage"" #~ "" system. When you upload data to "" #~ ""OpenStack Object Storage, the data is"" #~ "" stored as-is (no compression or "" #~ ""encryption) and consists of a location"" #~ "" (container), the object's name, and "" #~ ""any metadata consisting of key/value "" #~ ""pairs."" #~ msgstr """" #~ msgid ""File:"" #~ msgstr """" #~ msgid ""A new uploaded file will replace the content of the current object"" #~ msgstr """" #~ msgid ""Upload Object To Container: %(container_name)s"" #~ msgstr """" #~ msgid ""This Cluster Template will be created for:"" #~ msgstr """" #~ msgid """" #~ ""The Cluster Template object should "" #~ ""specify Node Group Templates that will"" #~ "" be used to build a Cluster.\n"" #~ "" You can add Node Groups using"" #~ "" Node Group Templates on a &quot;Node"" #~ "" Groups&quot; tab."" #~ msgstr """" #~ msgid ""You may set <b>cluster</b> scoped configurations on corresponding tabs."" #~ msgstr """" #~ msgid """" #~ ""The Cluster Template object may specify"" #~ "" a list of processes in anti-"" #~ ""affinity group.\n"" #~ "" That means these processes may "" #~ ""not be launched more than once on"" #~ "" a single host."" #~ msgstr """" #~ msgid ""Select a plugin and version for a new Cluster template."" #~ msgstr """" #~ msgid ""Template Overview"" #~ msgstr """" #~ msgid ""Anti-affinity enabled for"" #~ msgstr """" #~ msgid ""no processes"" #~ msgstr """" #~ msgid ""Node Configurations"" #~ msgstr """" #~ msgid ""%(conf_name)s: %(conf_value)s"" #~ msgstr """" #~ msgid ""No configurations"" #~ msgstr """" #~ msgid ""Cluster configurations are not specified"" #~ msgstr """" #~ msgid ""Node Group: %(node_group_name)s"" #~ msgstr """" #~ msgid ""Nodes Count"" #~ msgstr """" #~ msgid ""Flavor is not specified"" #~ msgstr """" #~ msgid ""Template not specified"" #~ msgstr """" #~ msgid ""Node processes are not specified"" #~ msgstr """" #~ msgid ""Node configurations are not specified"" #~ msgstr """" #~ msgid ""Select a Node Group Template to add:"" #~ msgstr """" #~ msgid ""Add Node Group"" #~ msgstr """" #~ msgid ""This Cluster will be started with:"" #~ msgstr """" #~ msgid ""Cluster can be launched using existing Cluster Templates."" #~ msgstr """" #~ msgid """" #~ ""The Cluster object should specify "" #~ ""OpenStack Image to boot instances for"" #~ "" Cluster."" #~ msgstr """" #~ msgid ""User has to choose a keypair to have access to clusters instances."" #~ msgstr """" #~ msgid "" Done"" #~ msgstr """" #~ msgid ""Select a plugin and version for a new Cluster."" #~ msgstr """" #~ msgid ""Cluster Overview"" #~ msgstr """" #~ msgid ""Error Details"" #~ msgstr """" #~ msgid ""%(key)s: %(val)s"" #~ msgstr """" #~ msgid ""Name: %(node_group_name)s"" #~ msgstr """" #~ msgid ""Number of Nodes"" #~ msgstr """" #~ msgid ""Done"" #~ msgstr """" #~ msgid ""Image Registry tool:"" #~ msgstr """" #~ msgid """" #~ ""Image Registry is used to provide "" #~ ""additional information about images for "" #~ ""Data Processing."" #~ msgstr """" #~ msgid """" #~ ""Specified User Name will be used "" #~ ""by Data Processing to apply configs "" #~ ""and manage processes on instances."" #~ msgstr """" #~ msgid """" #~ ""Tags are used for filtering images "" #~ ""suitable for each plugin and each "" #~ ""Data Processing version.\n"" #~ "" To add required tags, select "" #~ ""a plugin and a Data Processing "" #~ ""version and click &quot;Add plugin "" #~ ""tags&quot; button."" #~ msgstr """" #~ msgid ""You may also add any custom tag."" #~ msgstr """" #~ msgid ""Unnecessary tags may be removed by clicking a cross near tag's name."" #~ msgstr """" #~ msgid """" #~ ""Register tags required for the Plugin"" #~ "" with specified Data Processing Version"" #~ msgstr """" #~ msgid ""Add plugin tags"" #~ msgstr """" #~ msgid ""Add custom tag"" #~ msgstr """" #~ msgid ""Data Processing Plugin Overview"" #~ msgstr """" #~ msgid ""Create a Data Source with a specified name."" #~ msgstr """" #~ msgid ""Select the type of your Data Source."" #~ msgstr """" #~ msgid ""You may need to enter the username and password for your Data Source."" #~ msgstr """" #~ msgid ""You may also enter an optional description for your Data Source."" #~ msgstr """" #~ msgid ""Data Source Overview"" #~ msgstr """" #~ msgid ""Create time"" #~ msgstr """" #~ msgid """" #~ ""<b>Important</b>: The name that you "" #~ ""give your job binary will be the"" #~ "" name used in your job execution."" #~ ""\n"" #~ "" If your binary requires a "" #~ ""particular name or extension (ie: "" #~ ""\"".jar\""), be sure to include it "" #~ ""here."" #~ msgstr """" #~ msgid ""Select the storage type for your job binary."" #~ msgstr """" #~ msgid ""Data Processing internal database"" #~ msgstr """" #~ msgid """" #~ ""For Data Processing internal job "" #~ ""binaries, you may choose from the "" #~ ""following:"" #~ msgstr """" #~ msgid ""Choose an existing file"" #~ msgstr """" #~ msgid ""Upload a new file"" #~ msgstr """" #~ msgid ""Create a script to be uploaded dynamically"" #~ msgstr """" #~ msgid ""For Object Store job binaries, you must:"" #~ msgstr """" #~ msgid ""Enter the URL for the file"" #~ msgstr """" #~ msgid ""Enter the username and password required to access that file"" #~ msgstr """" #~ msgid ""You may also enter an optional description for your job binary."" #~ msgstr """" #~ msgid ""Job Binary Overview"" #~ msgstr """" #~ msgid ""Download job binary"" #~ msgstr """" #~ msgid ""Job Overview"" #~ msgstr """" #~ msgid ""Input Data Source"" #~ msgstr """" #~ msgid ""Output Data Source"" #~ msgstr """" #~ msgid ""Last Updated"" #~ msgstr """" #~ msgctxt ""Start time"" #~ msgid ""Started"" #~ msgstr """" #~ msgctxt ""End time"" #~ msgid ""Ended"" #~ msgstr """" #~ msgid ""Return Code"" #~ msgstr """" #~ msgid ""Oozie Job ID"" #~ msgstr """" #~ msgctxt ""Created time"" #~ msgid ""Created"" #~ msgstr """" #~ msgid ""Job Configuration"" #~ msgstr """" #~ msgid ""%(group)s:"" #~ msgstr """" #~ msgid ""Job Details"" #~ msgstr """" #~ msgid ""Create a job template with a specified name."" #~ msgstr """" #~ msgid ""Select the type of your job:"" #~ msgstr """" #~ msgid ""Java Action"" #~ msgstr """" #~ msgid """" #~ ""Choose or create your main binary. "" #~ ""Additional libraries can be added from"" #~ "" the \""Libs\"" tab."" #~ msgstr """" #~ msgid ""For Spark jobs, only a main is required, \""libs\"" are optional."" #~ msgstr """" #~ msgid """" #~ ""For MapReduce or Java Action jobs, "" #~ ""\""mains\"" are not applicable. You are"" #~ "" required to add one\n"" #~ "" or more \""libs\"" for these jobs."" #~ msgstr """" #~ msgid ""You may also enter an optional description for your job template."" #~ msgstr """" #~ msgid ""Add libraries to your job template."" #~ msgstr """" #~ msgid """" #~ ""Choose from the list of binaries "" #~ ""and click \""choose\"" to add the "" #~ ""library to your job template. This "" #~ ""can be repeated for additional "" #~ ""libraries."" #~ msgstr """" #~ msgid ""Mains"" #~ msgstr """" #~ msgid ""Created time"" #~ msgstr """" #~ msgid ""Updated time"" #~ msgstr """" #~ msgid ""Enter any custom configuration required for your job's execution."" #~ msgstr """" #~ msgid ""Launch the given job template on a cluster."" #~ msgstr """" #~ msgid ""Choose the cluster to use for the job."" #~ msgstr """" #~ msgid ""Choose the Input Data Source (n/a for Java jobs)."" #~ msgstr """" #~ msgid ""Choose the Output Data Source (n/a for Java jobs)."" #~ msgstr """" #~ msgid ""Select property name"" #~ msgstr """" #~ msgid ""Remove"" #~ msgstr """" #~ msgid ""Configuration"" #~ msgstr """" #~ msgid ""Parameters"" #~ msgstr """" #~ msgid ""Arguments"" #~ msgstr """" #~ msgid ""Choose"" #~ msgstr """" #~ msgid ""Chosen Libraries"" #~ msgstr """" #~ msgid ""This Node Group Template will be created for:"" #~ msgstr """" #~ msgid """" #~ ""The Node Group Template object specifies the processes\n"" #~ "" that will be launched on "" #~ ""each instance. Check one or more "" #~ ""processes.\n"" #~ "" When processes are selected, you may set <b>node</b> scoped\n"" #~ "" configurations on corresponding tabs."" #~ msgstr """" #~ msgid """" #~ ""You must choose a flavor to "" #~ ""determine the size (VCPUs, memory and"" #~ "" storage) of all launched VMs."" #~ msgstr """" #~ msgid """" #~ ""Data Processing provides different storage "" #~ ""location options. You may choose "" #~ ""Ephemeral Drive or a Cinder Volume "" #~ ""to be attached to instances."" #~ msgstr """" #~ msgid ""Select a plugin and version for the new Node Group template."" #~ msgstr """" #~ msgid ""HDFS placement"" #~ msgstr """" #~ msgid ""Cinder volumes"" #~ msgstr """" #~ msgid ""Volumes size"" #~ msgstr """" #~ msgid ""Ephemeral drive"" #~ msgstr """" #~ msgid ""Show full configuration"" #~ msgstr """" #~ msgid ""Hide full configuration"" #~ msgstr """" #~ msgid ""%(conf_name)s: %(conf_val)s"" #~ msgstr """" #~ msgid ""Nodegroup Template Details"" #~ msgstr """" #~ msgid ""Select"" #~ msgstr """" #~ msgid """" #~ ""Select which type of job that you want to run.\n"" #~ "" This choice will dictate which "" #~ ""steps are required to successfully\n"" #~ "" execute your job.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""Select which plugin and version that you\n"" #~ "" want to use to create your cluster."" #~ msgstr """" #~ msgid """" #~ ""The first step is to determine which type of\n"" #~ "" cluster you want to "" #~ ""run. You may have several choices\n"" #~ """" #~ "" available depending on the"" #~ "" configuration of your system.\n"" #~ "" Click on \""choose plugin\"""" #~ "" to bring up the list of data"" #~ ""\n"" #~ "" processing plugins. There "" #~ ""you will be able to choose the"" #~ ""\n"" #~ "" data processing plugin "" #~ ""along with the version number.\n"" #~ "" Choosing this up front "" #~ ""will allow the rest of the cluster"" #~ ""\n"" #~ "" creation steps to focus"" #~ "" only on options that are pertinent"" #~ ""\n"" #~ "" to your desired cluster type."" #~ msgstr """" #~ msgid ""Choose plugin"" #~ msgstr """" #~ msgid ""Current choice:"" #~ msgstr """" #~ msgid ""Plugin:"" #~ msgstr """" #~ msgid ""Version:"" #~ msgstr """" #~ msgid ""No plugin chosen"" #~ msgstr """" #~ msgid """" #~ ""Next, you need to define the different\n"" #~ "" types of machines in"" #~ "" your cluster. This is done by\n"" #~ """" #~ "" defining a Node Group"" #~ "" Template for each type of\n"" #~ "" machine. A very common case is where you\n"" #~ "" need to have one "" #~ ""or more machines running a \""master\"""" #~ ""\n"" #~ "" set of processes while"" #~ "" another set of machines need\n"" #~ "" to be running the "" #~ ""\""worker\"" processes. Here,\n"" #~ "" you will define the"" #~ "" Node Group Template for your\n"" #~ "" \""master\"" node(s).\n"" #~ "" "" #~ msgstr """" #~ msgid ""Create a Master Node Group Template"" #~ msgstr """" #~ msgid ""Master Node Group Template:"" #~ msgstr """" #~ msgid ""No Master Node Group Template Created"" #~ msgstr """" #~ msgid """" #~ ""Repeat the Node Group Template\n"" #~ "" creation process, but "" #~ ""this time you are creating\n"" #~ "" your \""worker\"" Node Group Template."" #~ msgstr """" #~ msgid ""Create a Worker Node Group Template"" #~ msgstr """" #~ msgid ""Worker Node Group Template:"" #~ msgstr """" #~ msgid ""No Worker Node Group Template Created"" #~ msgstr """" #~ msgid """" #~ ""Now you need to set the layout of your\n"" #~ "" cluster. By\n"" #~ "" creating a Cluster "" #~ ""Template, you will be choosing the\n"" #~ """" #~ "" number of instances of"" #~ "" each Node Group Template that\n"" #~ "" will appear in your cluster. Additionally,\n"" #~ "" you will have a "" #~ ""chance to set any cluster-specific\n"" #~ """" #~ "" configuration items in "" #~ ""the additional tabs on the\n"" #~ "" create Cluster Template form."" #~ msgstr """" #~ msgid ""Create a Cluster Template"" #~ msgstr """" #~ msgid ""No Cluster Template Created"" #~ msgstr """" #~ msgid """" #~ ""You are now ready to\n"" #~ "" launch your cluster. "" #~ ""When you click on the link\n"" #~ "" below, you will need"" #~ "" to give your cluster a name,\n"" #~ "" choose the Cluster "" #~ ""Template to use and choose which\n"" #~ "" image to use to "" #~ ""build your instances. After you\n"" #~ "" click on \""Create\"", "" #~ ""your instances will begin to\n"" #~ "" spawn. Your cluster "" #~ ""should be operational in a few\n"" #~ "" minutes."" #~ msgstr """" #~ msgid ""Launch a Cluster"" #~ msgstr """" #~ msgid ""Reset Cluster Guide"" #~ msgstr """" #~ msgid ""Reset Cluster Creation Guide"" #~ msgstr """" #~ msgid """" #~ ""First, select which type of job that\n"" #~ "" you want to run."" #~ "" This choice will determine which\n"" #~ "" other steps are required\n"" #~ "" "" #~ msgstr """" #~ msgid ""Select type"" #~ msgstr """" #~ msgid ""Current type:"" #~ msgstr """" #~ msgid ""No type chosen"" #~ msgstr """" #~ msgid """" #~ ""Data Sources are what your\n"" #~ "" job uses for input"" #~ "" and output. Depending on the type"" #~ ""\n"" #~ "" of job you will"" #~ "" be running, you may need to "" #~ ""define one\n"" #~ "" or more data "" #~ ""sources. You can create multiple data"" #~ ""\n"" #~ "" sources by repeating this step.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Create a data source"" #~ msgstr """" #~ msgid """" #~ ""Define your Job Template.\n"" #~ "" This is where you "" #~ ""choose the type of job that you"" #~ ""\n"" #~ "" want to run (Pig, "" #~ ""Java Action, Spark, etc) and choose\n"" #~ """" #~ "" or upload the files"" #~ "" necessary to run it. The inputs"" #~ ""\n"" #~ "" and outputs will be defined later.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Create a job template"" #~ msgstr """" #~ msgid ""Job template:"" #~ msgstr """" #~ msgid ""No job template created"" #~ msgstr """" #~ msgid """" #~ ""Launch your job. When\n"" #~ "" launching, you may "" #~ ""need to choose your input and\n"" #~ "" output data sources. "" #~ ""This is where you would also\n"" #~ "" add any special "" #~ ""configuration values, parameters,\n"" #~ "" or arguments that you need to pass along\n"" #~ "" to your job.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Launch job"" #~ msgstr """" #~ msgid ""Reset Job Execution Guide"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Each of the Data "" #~ ""Processing frameworks require a cluster "" #~ ""of machines\n"" #~ "" in order to do the "" #~ ""work they are assigned. A cluster "" #~ ""is\n"" #~ "" formed by creating a "" #~ ""set of Node Group Templates, combining"" #~ ""\n"" #~ "" those into a Cluster "" #~ ""Template and then launching a Cluster."" #~ ""\n"" #~ "" You can do each of "" #~ ""those steps manually, or you can "" #~ ""follow\n"" #~ "" this guide to help take you through the steps of\n"" #~ "" Cluster creation.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Cluster Guide"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" In order to run a "" #~ ""Data Processing job, you need to "" #~ ""make\n"" #~ "" the files for your program available to the\n"" #~ "" Data Processing system, "" #~ ""define where the input and output\n"" #~ """" #~ "" need to go and create a Job Template that describes\n"" #~ "" how to run your job."" #~ "" Each of those steps can be "" #~ ""done\n"" #~ "" manually or you can "" #~ ""follow this guide to help take you"" #~ ""\n"" #~ "" through the steps to "" #~ ""run a job on an existing cluster."" #~ ""\n"" #~ "" "" #~ msgstr """" #~ msgid ""Job Execution Guide"" #~ msgstr """" #~ msgid ""Specify the details for the database backup."" #~ msgstr """" #~ msgid """" #~ ""You can perform an incremental backup"" #~ "" by specifying a parent backup. "" #~ ""<strong>However,</strong> not all databases "" #~ ""support incremental backups in which "" #~ ""case this operation will result in "" #~ ""an error."" #~ msgstr """" #~ msgid ""Backup Details"" #~ msgstr """" #~ msgid ""Backup Overview"" #~ msgstr """" #~ msgid ""Backup File Location"" #~ msgstr """" #~ msgid ""Initial Volume Size"" #~ msgstr """" #~ msgid ""Backup Duration"" #~ msgstr """" #~ msgid ""Incremental Backup"" #~ msgstr """" #~ msgid ""Database Info"" #~ msgstr """" #~ msgid ""Database Backups"" #~ msgstr """" #~ msgid ""Instance Overview"" #~ msgstr """" #~ msgid ""Replication"" #~ msgstr """" #~ msgid ""Is a Replica Of"" #~ msgstr """" #~ msgid ""Replicas"" #~ msgstr """" #~ msgid ""Connection Info"" #~ msgstr """" #~ msgid ""Database Port"" #~ msgstr """" #~ msgid ""Connection Examples"" #~ msgstr """" #~ msgid ""USERNAME"" #~ msgstr """" #~ msgid ""PASSWORD"" #~ msgstr """" #~ msgid ""DATABASE"" #~ msgstr """" #~ msgid """" #~ ""Optionally choose to create this "" #~ ""database using a previous backup, or "" #~ ""as a replica of another database "" #~ ""instance."" #~ msgstr """" #~ msgid ""Specify the details for launching an instance."" #~ msgstr """" #~ msgid """" #~ ""<strong>Please note:</strong> The value "" #~ ""specified in the Volume Size field "" #~ ""should be greater than 0, however, "" #~ ""some configurations do not support "" #~ ""specifying volume size. If specifying "" #~ ""the volume size results in an "" #~ ""error stating volume support is not "" #~ ""enabled, enter 0."" #~ msgstr """" #~ msgid ""Optionally provide a comma separated list of databases to create:"" #~ msgstr """" #~ msgid """" #~ ""Create an optional initial user.\n"" #~ "" This user will have access to all databases you create."" #~ msgstr """" #~ msgid ""Username (required)"" #~ msgstr """" #~ msgid ""Password (required)"" #~ msgstr """" #~ msgid """" #~ ""Allow the user to connect from this host\n"" #~ "" only. If not provided this "" #~ ""user will be allowed to connect "" #~ ""from anywhere.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Move networks from 'Available Networks' to 'Selected Networks' by\n"" #~ "" clicking the button, or dragging and dropping. You can change the\n"" #~ "" NIC order by dragging and dropping as well.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Selected networks"" #~ msgstr """" #~ msgid ""Available networks"" #~ msgstr """" #~ msgid ""Specify a new flavor for the database instance."" #~ msgstr """" #~ msgid ""Specify the new volume size for the database instance."" #~ msgstr """" #~ msgid """" #~ ""<strong>Please note:</strong> The new value"" #~ "" must be greater than the existing"" #~ "" volume size."" #~ msgstr """" #~ msgid ""Instance Details"" #~ msgstr """" #~ msgid ""Choose the router(s) you want to add."" #~ msgstr """" #~ msgid ""Policy ID"" #~ msgstr """" #~ msgid ""Admin State Up"" #~ msgstr """" #~ msgid """" #~ ""Choose the rule you want to "" #~ ""insert. Specify either the rule you "" #~ ""want to insert immediately before, or"" #~ "" the rule to insert immediately "" #~ ""after. If both are specified, the "" #~ ""prior takes precedence."" #~ msgstr """" #~ msgid ""Unselect the routers you want to disassociate from the firewall."" #~ msgstr """" #~ msgid ""Choose the rule you want to remove."" #~ msgstr """" #~ msgid ""Source IP Address"" #~ msgstr """" #~ msgid ""Destination IP Address"" #~ msgstr """" #~ msgid ""Used in Policy"" #~ msgstr """" #~ msgid ""Position in Policy"" #~ msgstr """" #~ msgid """" #~ ""Choose router(s) from Available Routers "" #~ ""to Selected Routers by push button "" #~ ""or drag and drop. "" #~ msgstr """" #~ msgid ""Selected Routers"" #~ msgstr """" #~ msgid ""Available Routers"" #~ msgstr """" #~ msgid """" #~ ""Choose rule(s) from Available Rules to"" #~ "" Selected Rule by push button or "" #~ ""drag and drop,\n"" #~ ""you may change their order by drag and drop as well. "" #~ msgstr """" #~ msgid ""Selected Rules"" #~ msgstr """" #~ msgid ""Available Rules"" #~ msgstr """" #~ msgid ""You may update firewall details here."" #~ msgstr """" #~ msgid """" #~ ""You may update policy details here. "" #~ ""Use 'Insert Rule' or 'Remove Rule' "" #~ ""links instead to insert or remove "" #~ ""a rule"" #~ msgstr """" #~ msgid ""You may update rule details here."" #~ msgstr """" #~ msgid """" #~ ""Images can be provided via an HTTP"" #~ "" URL or be uploaded from your "" #~ ""local file system. Compressed image "" #~ ""binaries are supported (.zip and "" #~ "".tar.gz.)"" #~ msgstr """" #~ msgid """" #~ ""If you select an image via an "" #~ ""HTTP URL, the Image Location field "" #~ ""MUST be a valid and direct URL "" #~ ""to the image binary; it must also"" #~ "" be accessible to the Image Service."" #~ "" URLs that redirect or serve error"" #~ "" pages will result in unusable "" #~ ""images."" #~ msgstr """" #~ msgid ""Image Overview"" #~ msgstr """" #~ msgid ""Owner"" #~ msgstr """" #~ msgid ""Checksum"" #~ msgstr """" #~ msgid ""Virtual Size"" #~ msgstr """" #~ msgid ""Container Format"" #~ msgstr """" #~ msgid ""Min Disk"" #~ msgstr """" #~ msgid ""Min RAM"" #~ msgstr """" #~ msgid ""Custom Properties"" #~ msgstr """" #~ msgid ""Image Details"" #~ msgstr """" #~ msgid """" #~ ""A snapshot is an image which "" #~ ""preserves the disk state of a "" #~ ""running instance."" #~ msgstr """" #~ msgid ""Select the network for interface attaching."" #~ msgstr """" #~ msgid """" #~ ""To decrypt your password you will "" #~ ""need the private key of your key"" #~ "" pair for this instance. Select the"" #~ "" private key file, or copy and "" #~ ""paste the content of your private "" #~ ""key file into the text area below,"" #~ "" then click Decrypt Password."" #~ msgstr """" #~ msgid ""Note: "" #~ msgstr """" #~ msgid """" #~ ""The private key will be only used"" #~ "" in your browser and will not "" #~ ""be sent to the server"" #~ msgstr """" #~ msgid ""Decrypt Password"" #~ msgstr """" #~ msgid ""Select the port to detach."" #~ msgstr """" #~ msgid ""Instance Console"" #~ msgstr """" #~ msgid """" #~ ""If console is not responding to "" #~ ""keyboard input: click the grey status"" #~ "" bar below."" #~ msgstr """" #~ msgid ""Click here to show only console"" #~ msgstr """" #~ msgid ""To exit the fullscreen mode, click the browser's back button."" #~ msgstr """" #~ msgid ""console is currently unavailable. Please try again later."" #~ msgstr """" #~ msgid ""Reload"" #~ msgstr """" #~ msgid ""Instance Console Log"" #~ msgstr """" #~ msgid ""Log Length"" #~ msgstr """" #~ msgid ""Go"" #~ msgstr """" #~ msgid ""View Full Log"" #~ msgstr """" #~ msgid ""Time Since Created"" #~ msgstr """" #~ msgid ""Fault"" #~ msgstr """" #~ msgid ""Flavor ID"" #~ msgstr """" #~ msgid ""VCPU"" #~ msgstr """" #~ msgid ""IP Addresses"" #~ msgstr """" #~ msgid ""No rules defined."" #~ msgstr """" #~ msgid ""Key Name"" #~ msgstr """" #~ msgid ""Volumes Attached"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" <a "" #~ ""href=\""%(volume_url)s\"">%(volume_label)s</a> on "" #~ ""%(volume_device)s\n"" #~ "" "" #~ msgstr """" #~ msgid ""No volumes attached."" #~ msgstr """" #~ msgid ""Flavor Details"" #~ msgstr """" #~ msgid ""Total Disk"" #~ msgstr """" #~ msgid ""MB"" #~ msgstr """" #~ msgid ""Project Limits"" #~ msgstr """" #~ msgid ""Number of Instances"" #~ msgstr """" #~ msgid ""<p>%(used)s of %(quota)s Used</p>"" #~ msgstr """" #~ msgid ""Total RAM"" #~ msgstr """" #~ msgid ""<p>%(used)s of %(quota)s MB Used</p>"" #~ msgstr """" #~ msgid ""Some flavors not meeting minimum image requirements have been disabled."" #~ msgstr """" #~ msgid ""No flavors meet minimum criteria for selected image."" #~ msgstr """" #~ msgid ""Flavor Details: %(name)s\"">%(name)s"" #~ msgstr """" #~ msgid ""Floating IPs:"" #~ msgstr """" #~ msgid ""Specify advanced options to use when launching an instance."" #~ msgstr """" #~ msgid """" #~ ""You can customize your instance after"" #~ "" it has launched using the options"" #~ "" available here."" #~ msgstr """" #~ msgid """" #~ ""\""Customization Script\"" is analogous to "" #~ ""\""User Data\"" in other systems."" #~ msgstr """" #~ msgid """" #~ ""The chart below shows the resources "" #~ ""used by this project in relation "" #~ ""to the project's quotas."" #~ msgstr """" #~ msgid """" #~ ""Choose network from Available networks "" #~ ""to Selected networks by push button "" #~ ""or drag and drop, you may change"" #~ "" NIC order by drag and drop as"" #~ "" well. "" #~ msgstr """" #~ msgid """" #~ ""An instance can be launched with "" #~ ""varying types of attached storage. You"" #~ "" may select from those options here."" #~ msgstr """" #~ msgid ""Select the image to rebuild your instance."" #~ msgstr """" #~ msgid ""You may optionally set a password on the rebuilt instance."" #~ msgstr """" #~ msgid ""Instance Admin Password"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Assign a name and description "" #~ ""for the pool. Choose one subnet "" #~ ""where all\n"" #~ "" members of this pool must be "" #~ ""on. Select the protocol and load "" #~ ""balancing\n"" #~ "" method for this pool. Admin State is UP (checked) by default.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""Use one of these load balancing "" #~ ""methods to distribute incoming requests:"" #~ msgstr """" #~ msgid ""Round robin"" #~ msgstr """" #~ msgid ""Rotates requests evenly between multiple instances."" #~ msgstr """" #~ msgid """" #~ ""Requests from a unique source IP address are consistently\n"" #~ "" directed to the same instance."" #~ msgstr """" #~ msgid ""Least connections"" #~ msgstr """" #~ msgid """" #~ ""Allocates requests to the instance with the least number of\n"" #~ "" active connections."" #~ msgstr """" #~ msgid ""Address"" #~ msgstr """" #~ msgid ""URL Path"" #~ msgstr """" #~ msgid ""Expected Codes"" #~ msgstr """" #~ msgid ""Health Monitors"" #~ msgstr """" #~ msgid """" #~ ""You may update member attributes here:"" #~ "" edit pool, weight or admin state."" #~ msgstr """" #~ msgid """" #~ ""You may update health monitor attributes"" #~ "" here: edit delay, timeout, max "" #~ ""retries or admin state."" #~ msgstr """" #~ msgid """" #~ ""You may update pool attributes here: "" #~ ""edit name, description, load balancing "" #~ ""method or admin state."" #~ msgstr """" #~ msgid """" #~ ""You may update VIP attributes here: "" #~ ""edit name, description, pool, session "" #~ ""persistence, connection limit or admin "" #~ ""state."" #~ msgstr """" #~ msgid ""Port ID"" #~ msgstr """" #~ msgid ""Type: %(persistence_type)s"" #~ msgstr """" #~ msgid ""Cookie Name: %(cookie_name)s"" #~ msgstr """" #~ msgid ""This pane needs javascript support."" #~ msgstr """" #~ msgid ""Small"" #~ msgstr """" #~ msgid ""Launch Instance (Quota exceeded)"" #~ msgstr """" #~ msgid ""There are no networks, routers, or connected instances to display."" #~ msgstr """" #~ msgid ""Select a name for your network."" #~ msgstr """" #~ msgid ""Network Overview"" #~ msgstr """" #~ msgid ""MTU"" #~ msgstr """" #~ msgid ""Provider Network"" #~ msgstr """" #~ msgid ""Network Type:"" #~ msgstr """" #~ msgid ""Physical Network:"" #~ msgstr """" #~ msgid ""Segmentation ID:"" #~ msgstr """" #~ msgid ""&laquo;&nbsp;Back"" #~ msgstr """" #~ msgid ""Next&nbsp;&raquo;"" #~ msgstr """" #~ msgid ""Network Details"" #~ msgstr """" #~ msgid ""Subnet Overview"" #~ msgstr """" #~ msgid ""IP version"" #~ msgstr """" #~ msgid ""IP allocation pool"" #~ msgstr """" #~ msgid ""Start"" #~ msgstr """" #~ msgid "" - End"" #~ msgstr """" #~ msgid ""DHCP Enable"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Other IPv6 modes: "" #~ ""ipv6_ra_mode=%(ra_mode)s, ipv6_address_mode=%(addr_mode)s\n"" #~ """" #~ "" "" #~ msgstr """" #~ msgid ""Additional routes"" #~ msgstr """" #~ msgid ""Destination"" #~ msgstr """" #~ msgid "" : Next hop"" #~ msgstr """" #~ msgid ""DNS name server"" #~ msgstr """" #~ msgid ""Project ID:"" #~ msgstr """" #~ msgid ""Creates a router with specified parameters."" #~ msgstr """" #~ msgid ""External Fixed IPs"" #~ msgstr """" #~ msgid ""SNAT"" #~ msgstr """" #~ msgid ""You may update the editable properties of your router here."" #~ msgstr """" #~ msgid ""Add static route to the router."" #~ msgstr """" #~ msgid """" #~ ""Next Hop IP must be a part "" #~ ""of one of the subnets to which "" #~ ""the router interfaces are connected."" #~ msgstr """" #~ msgid ""Add route"" #~ msgstr """" #~ msgid ""Add Router Route"" #~ msgstr """" #~ msgid """" #~ ""Routing rules to apply to router. "" #~ ""Rules are matched by most specific "" #~ ""source first and then by most "" #~ ""specific destination."" #~ msgstr """" #~ msgid """" #~ ""The next hop addresses can be used"" #~ "" to override the router used by "" #~ ""the client."" #~ msgstr """" #~ msgid ""Add rule"" #~ msgstr """" #~ msgid ""Router Rule Grid"" #~ msgstr """" #~ msgid ""Reset to Default"" #~ msgstr """" #~ msgid ""Source"" #~ msgstr """" #~ msgid ""Subnet: %(dest_subnetname)s"" #~ msgstr """" #~ msgid ""Subnet: %(row_source_subnetname)s"" #~ msgstr """" #~ msgid ""Rule Conflict"" #~ msgstr """" #~ msgid """" #~ ""A more specific rule affects a "" #~ ""portion of this traffic so a rule"" #~ "" cannot be automatically generated to "" #~ ""control the behavior of the entire "" #~ ""source/destination combination."" #~ msgstr """" #~ msgid ""Conflicting Rule"" #~ msgstr """" #~ msgid ""Source:"" #~ msgstr """" #~ msgid ""Destination:"" #~ msgstr """" #~ msgid ""Action:"" #~ msgstr """" #~ msgid """" #~ ""The color and icon of an "" #~ ""intersection indicates whether or not "" #~ ""traffic is permitted from the source "" #~ ""(row) to the destination (column).\n"" #~ "" Clicking the <i class=\""fa fa-"" #~ ""random\""></i> button in the intersection "" #~ ""will install a rule to switch the"" #~ "" traffic behavior.<br/>\n"" #~ ""\n"" #~ "" <b>Note:</b> Rules only affect one"" #~ "" direction of traffic. The opposite "" #~ ""direction is outlined when hovering over"" #~ "" an intersection.\n"" #~ "" "" #~ msgstr """" #~ msgid ""You can connect a specified subnet to the router."" #~ msgstr """" #~ msgid """" #~ ""The default IP address of the "" #~ ""interface created is a gateway of "" #~ ""the selected subnet. You can specify "" #~ ""another IP address of the interface "" #~ ""here. You must select a subnet to"" #~ "" which the specified IP address "" #~ ""belongs to from the above list."" #~ msgstr """" #~ msgid ""Add interface"" #~ msgstr """" #~ msgid """" #~ ""You can connect a specified external "" #~ ""network to the router. The external "" #~ ""network is regarded as a default "" #~ ""route of the router and the router"" #~ "" acts as a gateway for external "" #~ ""connectivity."" #~ msgstr """" #~ msgid ""Resource Type"" #~ msgstr """" #~ msgid ""Attributes"" #~ msgstr """" #~ msgid ""Properties"" #~ msgstr """" #~ msgid """" #~ ""Use one of the available template "" #~ ""source options to specify the template"" #~ "" to be used in creating this "" #~ ""stack."" #~ msgstr """" #~ msgid ""Create a new stack with the provided values."" #~ msgstr """" #~ msgid ""Stack Overview"" #~ msgstr """" #~ msgid ""%(stack_status_title)s: %(stack_status_reason)s"" #~ msgstr """" #~ msgid ""Outputs"" #~ msgstr """" #~ msgid ""Stack Parameters"" #~ msgstr """" #~ msgid ""Launch Parameters"" #~ msgstr """" #~ msgid ""Minutes"" #~ msgstr """" #~ msgid ""Rollback"" #~ msgstr """" #~ msgid ""Preview a new stack with the provided values."" #~ msgstr """" #~ msgid ""Stack Preview"" #~ msgstr """" #~ msgid ""Links"" #~ msgstr """" #~ msgid """" #~ ""Use one of the available template "" #~ ""source options to specify the template"" #~ "" to be used in previewing this "" #~ ""stack."" #~ msgstr """" #~ msgid ""Resource Overview"" #~ msgstr """" #~ msgid ""Stack Resource ID"" #~ msgstr """" #~ msgid ""Resource ID"" #~ msgstr """" #~ msgid ""%(resource_status)s: %(resource_status_reason)s"" #~ msgstr """" #~ msgid ""Resource Metadata"" #~ msgstr """" #~ msgid ""Stack Template"" #~ msgstr """" #~ msgid """" #~ ""Update a stack with the provided "" #~ ""values. Please note that any encrypted"" #~ "" parameters, such as passwords, will "" #~ ""be reset to default if you do "" #~ ""not change them here."" #~ msgstr """" #~ msgid ""Stack Details"" #~ msgstr """" #~ msgid ""Resource Details"" #~ msgstr """" #~ msgid ""Volume Backup:"" #~ msgstr """" #~ msgid """" #~ ""Volume Backups are stored using the "" #~ ""Object Storage service. You must have"" #~ "" this service activated in order to"" #~ "" create a backup."" #~ msgstr """" #~ msgid """" #~ ""If no container name is provided, "" #~ ""a default container named volumebackups "" #~ ""will be provisioned for you. Backups "" #~ ""will be the same size as the "" #~ ""volume they originate from."" #~ msgstr """" #~ msgid ""Volume Backup Overview: %(backup_display_name)s"" #~ msgstr """" #~ msgid ""Restore Backup:"" #~ msgstr """" #~ msgid ""Select a volume to restore to."" #~ msgstr """" #~ msgid ""Optionally, you may choose to create a new volume."" #~ msgstr """" #~ msgid ""Volume Backup Details"" #~ msgstr """" #~ msgid ""Modify the name and description of a snapshot."" #~ msgstr """" #~ msgid ""Volume Snapshot Details"" #~ msgstr """" #~ msgid """" #~ ""Ownership of a volume can be "" #~ ""transferred from one project to another."" #~ "" Accepting a transfer requires obtaining"" #~ "" the Transfer ID and Authorization "" #~ ""Key from the donor. This is "" #~ ""equivalent to the <tt>cinder transfer-"" #~ ""accept</tt> command."" #~ msgstr """" #~ msgid ""Attach To Instance"" #~ msgstr """" #~ msgid ""Attach Volume"" #~ msgstr """" #~ msgid ""Create Volume Snapshot (Force)"" #~ msgstr """" #~ msgid """" #~ ""Ownership of a volume can be "" #~ ""transferred from one project to another."" #~ "" Once a volume transfer is created"" #~ "" in a donor project, it then "" #~ ""can be \""accepted\"" by a recipient "" #~ ""project. This is equivalent to the "" #~ ""<tt>cinder transfer-create</tt> command."" #~ msgstr """" #~ msgid ""Volume Overview"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" <a href=\""%(instance_url)s\"">%(instance_name)s</a>"" #~ "" on %(device)s\n"" #~ "" "" #~ msgstr """" #~ msgid ""Not attached"" #~ msgstr """" #~ msgid ""Volume Encryption Overview"" #~ msgstr """" #~ msgid ""Volume Type Name"" #~ msgstr """" #~ msgid ""Volume is Unencrypted"" #~ msgstr """" #~ msgid ""Extend the size of a volume."" #~ msgstr """" #~ msgid ""Volume Limits"" #~ msgstr """" #~ msgid ""Total Gigabytes"" #~ msgstr """" #~ msgid ""Volumes are block devices that can be attached to instances."" #~ msgstr """" #~ msgid ""Number of Volumes"" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Change the volume type of a volume after its creation.\n"" #~ "" This is equivalent to the <tt>cinder retype</tt> command.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" The \""Volume Type\"" selected must"" #~ "" be different from the current volume"" #~ "" type.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" The \""Migration Policy\"" is only"" #~ "" used if the volume retype cannot "" #~ ""be\n"" #~ "" completed. If the \""Migration "" #~ ""Policy\"" is \""On Demand\"", the back "" #~ ""end will\n"" #~ "" perform volume migration. Note "" #~ ""that migration may take a significant"" #~ ""\n"" #~ "" amount of time to complete, in some cases hours.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""The Transfer ID and the Authorization"" #~ "" Key are needed by the recipient "" #~ ""in order to accept the transfer. "" #~ ""Please capture both the Transfer ID "" #~ ""and the Authorization Key and provide"" #~ "" them to your transfer recipient."" #~ msgstr """" #~ msgid """" #~ ""The Authorization Key will not be "" #~ ""available after closing this page, so"" #~ "" you must capture it now, or "" #~ ""else you will be unable to use "" #~ ""the transfer."" #~ msgstr """" #~ msgid ""From here you can create a snapshot of a volume."" #~ msgstr """" #~ msgid ""Snapshot Limits"" #~ msgstr """" #~ msgid ""Number of Snapshots"" #~ msgstr """" #~ msgid ""Modify name and description of a volume."" #~ msgstr """" #~ msgid """" #~ ""The \""Bootable\"" flag specifies that "" #~ ""this volume can be used to launch"" #~ "" an instance."" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Upload the volume to the Image Service as an image.\n"" #~ "" This is equivalent to the "" #~ ""<tt>cinder upload-to-image</tt> command.\n"" #~ """" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" Choose \""Disk Format\"" for the "" #~ ""image. The volume images are created "" #~ ""with\n"" #~ "" the QEMU disk image utility.\n"" #~ "" "" #~ msgstr """" #~ msgid """" #~ ""\n"" #~ "" When the volume status is "" #~ ""\""in-use\"", you can use \""Force\"" to"" #~ "" upload the\n"" #~ "" volume to an image.\n"" #~ "" "" #~ msgstr """" #~ msgid ""Volume Encryption Details"" #~ msgstr """" #~ msgid ""Lifetime Units"" #~ msgstr """" #~ msgid ""Lifetime Value"" #~ msgstr """" #~ msgid ""Remote peer subnet"" #~ msgstr """" #~ msgid ""Pre-Shared Key string"" #~ msgstr """" #~ msgid ""Dead peer detection action"" #~ msgstr """" #~ msgid ""Authorization mode"" #~ msgstr """" #~ msgid ""Route mode"" #~ msgstr """" #~ msgid ""You may update IKE Policy details here."" #~ msgstr """" #~ msgid ""You may update IPSec Policy details here."" #~ msgstr """" #~ msgid ""You may update IPSec Site Connection details here."" #~ msgstr """" #~ msgid ""You may update VPN Service details here."" #~ msgstr """" #~ msgid ""VPN Connections"" #~ msgstr """" #~ msgid ""Name:"" #~ msgstr """" #~ msgid "" Select a name for your network profile."" #~ msgstr """" #~ msgid ""Segment Type:"" #~ msgstr """" #~ msgid "" Segment types available are VLAN, Overlay and Trunk."" #~ msgstr """" #~ msgid ""Segment Sub Type:"" #~ msgstr """" #~ msgid """" #~ "" Sub types available are for the"" #~ "" Overlay and Trunk segments. Available "" #~ ""sub-types for Overlay are: Native-"" #~ ""VXLAN, Enhanced-VXLAN or 'Other' (eg."" #~ "" GRE) which can be manually inputed"" #~ "" as a text parameter for subtype. "" #~ ""Available sub-type for Trunk is: "" #~ ""VLAN."" #~ msgstr """" #~ msgid ""Segment Range:"" #~ msgstr """" #~ msgid """" #~ "" Segment Ranges are 1-4093 for "" #~ ""VLAN and above 5000 for Enhanced-"" #~ ""VXLAN Overlay."" #~ msgstr """" #~ msgid """" #~ ""Edit the network profile to update "" #~ ""name, segment range or multicast IP "" #~ ""range."" #~ msgstr """" #~ msgid ""Cisco Nexus 1000V Networking"" #~ msgstr """" #~ msgid ""Change your password. We highly recommend you create a strong one. "" #~ msgstr """" #~ msgid ""Modify dashboard settings for your user."" #~ msgstr """" ","# Copyright (C) YEAR THE PACKAGE'S COPYRIGHT HOLDER# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.""POT-Creation-Date: 2015-06-05 01:18-0500\n""""Language-Team: LANGUAGE <LL@li.org>\n"" ""Language: \n""""Content-Type: text/plain; charset=UTF-8\n""#: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:28#. Translators: Only used inside Horizon code and invisible to users""The requested feature '%(feature)s' is unknown. Please make sure to specify "" ""a feature defined in FEATURE_MAP.""#. Translators: Only used inside Horizon code and invisible to users#: api/nova.py:110 api/nova.py:120 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:14 #: dashboards/project/databases/tables.py:279 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:8 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:11 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:39 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:8 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:11 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:27 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:8 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:11 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:43 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:48 #: dashboards/project/instances/templates/instances/_detail_overview.html:17 #: dashboards/project/instances/templates/instances/_detail_overview.html:24#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:10 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:13 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:23 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:47 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:59 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:10 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:13 #: dashboards/project/networks/templates/networks/_detail_overview.html:12 #: dashboards/project/networks/templates/networks/_detail_overview.html:26 #: dashboards/project/networks/templates/networks/_detail_overview.html:27 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:14 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:18 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:29""Failed to modify %(num_groups_to_modify)d instance security groups: %(err)s""#: dashboards/admin/networks/forms.py:38 #: dashboards/admin/networks/forms.py:234#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:6 #: dashboards/admin/routers/ports/tables.py:24#: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:10 #: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:11#: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:12 #: dashboards/project/containers/templates/containers/_object_detail.html:10#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:6#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:6 #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:9#: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:5#: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:5#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:6 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:54#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:6#: dashboards/project/database_backups/templates/database_backups/details.html:14 #: dashboards/project/database_backups/templates/database_backups/details.html:60#: dashboards/project/databases/templates/databases/_detail_overview.html:10#: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:7 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:7 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:7#: dashboards/project/images/templates/images/images/_detail_overview.html:9 #: dashboards/project/instances/templates/instances/_detail_overview.html:10 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:9#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:9 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:9#: dashboards/project/networks/tables.py:168 #: dashboards/project/networks/templates/networks/_detail_overview.html:7 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:6 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:10#: dashboards/project/routers/ports/tables.py:107#: dashboards/project/routers/templates/routers/_detail_overview.html:5 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:9#: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:12 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:91#: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:6 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:6 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:7 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:7#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:22 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:19#: dashboards/project/instances/templates/instances/_detail_overview.html:16#: dashboards/admin/aggregates/forms.py:73 #: dashboards/admin/flavors/forms.py:44 dashboards/admin/images/forms.py:61#: dashboards/admin/aggregates/templates/aggregates/index.html:3#: dashboards/admin/aggregates/tables.py:29#: dashboards/admin/aggregates/tables.py:37#: dashboards/admin/aggregates/templates/aggregates/create.html:3#: dashboards/admin/aggregates/templates/aggregates/_update_metadata.html:11 #: dashboards/admin/flavors/tables.py:71 #: dashboards/admin/flavors/templates/flavors/_update_metadata.html:11 #: dashboards/admin/images/tables.py:46#: dashboards/admin/aggregates/templates/aggregates/_update.html:9 #: dashboards/admin/aggregates/templates/aggregates/update.html:3#: dashboards/project/instances/templates/instances/_detail_overview.html:108 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:46 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:68#: dashboards/admin/aggregates/templates/aggregates/_update.html:18 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_disable_service.html:17 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_evacuate_host.html:17 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_migrate_host.html:16 #: dashboards/admin/images/templates/images/_create.html:8 #: dashboards/admin/images/templates/images/_update.html:5 #: dashboards/admin/instances/templates/instances/_live_migrate.html:17 #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:18 #: dashboards/admin/metering/templates/metering/_daily.html:18 #: dashboards/admin/networks/templates/networks/_create.html:18 #: dashboards/admin/networks/templates/networks/_update.html:5 #: dashboards/admin/networks/templates/networks/agents/_add.html:5 #: dashboards/admin/networks/templates/networks/ports/_create.html:5 #: dashboards/admin/networks/templates/networks/ports/_update.html:5 #: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/_associate_qos_spec.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/_create_qos_spec.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type_encryption.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/_edit_qos_spec_consumer.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/extras/_create.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/extras/_edit.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/_create.html:5 #: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/_edit.html:5 #: dashboards/admin/volumes/templates/volumes/volumes/_manage_volume.html:5 #: dashboards/admin/volumes/templates/volumes/volumes/_unmanage_volume.html:5 #: dashboards/admin/volumes/templates/volumes/volumes/_update_status.html:5 #: dashboards/identity/groups/templates/groups/_create.html:5 #: dashboards/identity/groups/templates/groups/_update.html:5 #: dashboards/identity/roles/templates/roles/_create.html:5 #: dashboards/identity/roles/templates/roles/_update.html:5 #: dashboards/identity/users/templates/users/_change_password.html:5 #: dashboards/identity/users/templates/users/_create.html:5 #: dashboards/identity/users/templates/users/_update.html:5 #: dashboards/project/access_and_security/templates/access_and_security/floating_ips/_allocate.html:6 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_create.html:5 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_import.html:5 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:5 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_create.html:5 #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:5 #: dashboards/project/containers/templates/containers/_copy.html:17 #: dashboards/project/containers/templates/containers/_create.html:17 #: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:19 #: dashboards/project/containers/templates/containers/_update.html:20 #: dashboards/project/containers/templates/containers/_upload.html:21 #: dashboards/project/firewalls/templates/firewalls/_add_router_to_firewall.html:5 #: dashboards/project/firewalls/templates/firewalls/_insert_rule_to_policy.html:5 #: dashboards/project/firewalls/templates/firewalls/_remove_router_from_firewall.html:5 #: dashboards/project/firewalls/templates/firewalls/_remove_rule_from_policy.html:5 #: dashboards/project/firewalls/templates/firewalls/_updatefirewall.html:5 #: dashboards/project/firewalls/templates/firewalls/_updatepolicy.html:5 #: dashboards/project/firewalls/templates/firewalls/_updaterule.html:5 #: dashboards/project/images/templates/images/images/_create.html:9 #: dashboards/project/images/templates/images/images/_update.html:5 #: dashboards/project/images/templates/images/snapshots/_create.html:5 #: dashboards/project/instances/templates/instances/_attach_interface.html:5 #: dashboards/project/instances/templates/instances/_decryptpassword.html:20 #: dashboards/project/instances/templates/instances/_detach_interface.html:4 #: dashboards/project/instances/templates/instances/_rebuild.html:18 #: dashboards/project/loadbalancers/templates/loadbalancers/_updatemember.html:5 #: dashboards/project/loadbalancers/templates/loadbalancers/_updatemonitor.html:5 #: dashboards/project/loadbalancers/templates/loadbalancers/_updatepool.html:5 #: dashboards/project/loadbalancers/templates/loadbalancers/_updatevip.html:5 #: dashboards/project/networks/templates/networks/_create.html:17 #: dashboards/project/networks/templates/networks/_update.html:5 #: dashboards/project/networks/templates/networks/ports/_update.html:5 #: dashboards/project/routers/templates/routers/_create.html:5 #: dashboards/project/routers/templates/routers/_update.html:5 #: dashboards/project/routers/templates/routers/extensions/routerroutes/_create.html:18 #: dashboards/project/routers/templates/routers/extensions/routerrules/_create.html:18 #: dashboards/project/routers/templates/routers/ports/_create.html:18 #: dashboards/project/routers/templates/routers/ports/_setgateway.html:18 #: dashboards/project/stacks/templates/stacks/_change_template.html:5 #: dashboards/project/stacks/templates/stacks/_create.html:4 #: dashboards/project/stacks/templates/stacks/_preview.html:4 #: dashboards/project/stacks/templates/stacks/_preview_template.html:5 #: dashboards/project/stacks/templates/stacks/_select_template.html:5 #: dashboards/project/stacks/templates/stacks/_update.html:4 #: dashboards/project/volumes/templates/volumes/snapshots/_update.html:5 #: dashboards/project/volumes/templates/volumes/volumes/_accept_transfer.html:5 #: dashboards/project/volumes/templates/volumes/volumes/_create_transfer.html:5 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:3 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:3 #: dashboards/project/volumes/templates/volumes/volumes/_retype.html:5 #: dashboards/project/volumes/templates/volumes/volumes/_show_transfer.html:5 #: dashboards/project/volumes/templates/volumes/volumes/_update.html:5 #: dashboards/project/volumes/templates/volumes/volumes/_upload_to_image.html:5 #: dashboards/project/vpn/templates/vpn/_update_ikepolicy.html:5 #: dashboards/project/vpn/templates/vpn/_update_ipsecpolicy.html:5 #: dashboards/project/vpn/templates/vpn/_update_ipsecsiteconnection.html:5 #: dashboards/project/vpn/templates/vpn/_update_vpnservice.html:5 #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:5 #: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:5 #: dashboards/settings/password/templates/password/_change.html:5 #: dashboards/settings/user/templates/user/_settings.html:5 msgid ""Description:"" msgstr """" #: dashboards/admin/aggregates/templates/aggregates/_update.html:19 msgid """" ""Host aggregates divide an availability zone into logical units by grouping "" ""together hosts. Edit the aggregate host to select hosts contained in it."" msgstr """" #: dashboards/admin/aggregates/templates/aggregates/_update.html:24 #: dashboards/admin/aggregates/workflows.py:209 #: dashboards/admin/flavors/workflows.py:266 #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:79 #: dashboards/admin/volumes/volume_types/extras/views.py:88 #: dashboards/admin/volumes/volume_types/qos_specs/views.py:103 #: dashboards/identity/domains/workflows.py:300 #: dashboards/identity/projects/workflows.py:602 #: dashboards/identity/users/views.py:209 #: dashboards/project/instances/workflows/update_instance.py:133 #: dashboards/project/networks/subnets/workflows.py:159 #: dashboards/settings/user/views.py:30 msgid ""Save"" msgstr """" #: dashboards/admin/aggregates/templates/aggregates/_update.html:25 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_disable_service.html:24 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_evacuate_host.html:24 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_migrate_host.html:23 #: dashboards/admin/instances/templates/instances/_live_migrate.html:24 #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:36 #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:80 #: dashboards/admin/metering/templates/metering/_daily.html:25 #: dashboards/admin/networks/templates/networks/_create.html:27 #: dashboards/identity/groups/templates/groups/_add_non_member.html:8 #: dashboards/project/containers/templates/containers/_copy.html:24 #: dashboards/project/containers/templates/containers/_create.html:25 #: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:26 #: dashboards/project/containers/templates/containers/_update.html:28 #: dashboards/project/containers/templates/containers/_upload.html:29 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_upload_file.html:23 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_create_cluster.html:22 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html:28 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html:26 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create.html:26 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_job_type_select.html:30 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_plugin_select.html:30 #: dashboards/project/databases/templates/databases/_resize_instance.html:24 #: dashboards/project/databases/templates/databases/_resize_volume.html:25 #: dashboards/project/instances/templates/instances/_decryptpassword.html:34 #: dashboards/project/instances/templates/instances/_rebuild.html:28 #: dashboards/project/network_topology/templates/network_topology/_create_router.html:21 #: dashboards/project/networks/templates/networks/_create.html:24 #: dashboards/project/networks/templates/networks/create.html:8 #: dashboards/project/networks/templates/networks/create.html:15 #: dashboards/project/routers/templates/routers/extensions/routerroutes/_create.html:28 #: dashboards/project/routers/templates/routers/extensions/routerrules/_create.html:28 #: dashboards/project/routers/templates/routers/ports/_create.html:30 #: dashboards/project/routers/templates/routers/ports/_setgateway.html:25 #: dashboards/project/volumes/templates/volumes/volumes/_attach.html:20 #: dashboards/project/volumes/templates/volumes/volumes/_create_snapshot.html:17 msgid ""Cancel"" msgstr """" #: dashboards/admin/aggregates/templates/aggregates/_update_metadata.html:4 #: dashboards/admin/aggregates/templates/aggregates/_update_metadata.html:7 #: dashboards/admin/aggregates/templates/aggregates/update_metadata.html:3 #: dashboards/admin/aggregates/views.py:108 msgid ""Update Aggregate Metadata"" msgstr """" #: dashboards/admin/aggregates/templates/aggregates/manage_hosts.html:3 #: dashboards/admin/aggregates/views.py:157 msgid ""Manage Hosts Aggregate"" msgstr """" ""Host aggregates divide an availability zone into logical units by grouping "" ""together hosts. Create a host aggregate then select the hosts contained in "" ""it.""#: dashboards/admin/dashboard.py:22 msgid ""System"" msgstr """" #: dashboards/admin/dashboard.py:29 msgid ""Admin"" msgstr """" #: dashboards/admin/defaults/panel.py:23 #: dashboards/admin/defaults/templates/defaults/index.html:3 #: dashboards/admin/defaults/views.py:29#: dashboards/project/instances/templates/instances/_detail_overview.html:57 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:10 #: dashboards/project/instances/templates/instances/_instance_flavor.html:5#: usage/tables.py:33#: dashboards/admin/instances/templates/instances/index.html:3#: dashboards/project/databases/templates/databases/index.html:3#: dashboards/project/instances/templates/instances/index.html:3#: usage/quotas.py:64#: dashboards/admin/volumes/templates/volumes/index.html:3#: dashboards/project/volumes/panel.py:23 #: dashboards/project/volumes/tabs.py:83 #: dashboards/project/volumes/templates/volumes/index.html:3#: dashboards/admin/volumes/snapshots/tables.py:69#: dashboards/project/volumes/snapshots/tables.py:156 #: dashboards/project/volumes/tabs.py:99 usage/quotas.py:75#: dashboards/project/access_and_security/tabs.py:80 usage/quotas.py:68 #: usage/quotas.py:81#: dashboards/project/access_and_security/security_groups/tables.py:149#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:32 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:35 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:47#: dashboards/project/instances/templates/instances/_detail_overview.html:87#: usage/quotas.py:70 usage/quotas.py:82#: dashboards/project/access_and_security/tabs.py:63 usage/quotas.py:72#: dashboards/admin/flavors/templates/flavors/index.html:3#: dashboards/admin/flavors/tables.py:35#: dashboards/admin/flavors/tables.py:43#: dashboards/admin/flavors/tables.py:54 #: dashboards/admin/flavors/templates/flavors/create.html:3 #: dashboards/admin/flavors/views.py:66#: dashboards/admin/flavors/tables.py:62 #: dashboards/admin/flavors/templates/flavors/update.html:3 #: dashboards/admin/flavors/views.py:72#: dashboards/admin/flavors/tables.py:125 #: dashboards/project/databases/templates/databases/_detail_overview.html:29 #: dashboards/project/instances/templates/instances/_detail_overview.html:55 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:14 #: dashboards/project/instances/templates/instances/_instance_flavor.html:6 #: usage/tables.py:37#: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11#: dashboards/project/instances/templates/instances/_detail_overview.html:62 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12#: dashboards/admin/networks/agents/tables.py:90#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:8 #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:12#: dashboards/identity/roles/forms.py:37 #: dashboards/identity/users/forms.py:172 #: dashboards/identity/users/templates/users/_detail_overview.html:19 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:14 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:8 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:8 #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:7 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:7#: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:8 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:8 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:8 #: dashboards/project/database_backups/templates/database_backups/details.html:18 #: dashboards/project/database_backups/templates/database_backups/details.html:62 #: dashboards/project/databases/templates/databases/_detail_overview.html:12 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:13 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:13 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:13 #: dashboards/project/images/templates/images/images/_detail_overview.html:15 #: dashboards/project/instances/templates/instances/_detail_overview.html:12 #: dashboards/project/instances/templates/instances/_instance_flavor.html:4#: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:6 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:6 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:6 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:6#: dashboards/project/networks/templates/networks/_detail_overview.html:9 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:8 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:12 #: dashboards/project/routers/forms.py:121 #: dashboards/project/routers/templates/routers/_detail_overview.html:7 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:11 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:14 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:12 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:12 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:87 #: dashboards/project/vpn/forms.py:33 dashboards/project/vpn/forms.py:68 #: dashboards/project/vpn/forms.py:147 dashboards/project/vpn/forms.py:225 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:12 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:12 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:13 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:13#: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:18#: dashboards/project/containers/templates/containers/_container_detail.html:14 #: dashboards/project/containers/templates/containers/_container_metadata.html:7#: dashboards/project/images/templates/images/images/_detail_overview.html:21#: dashboards/admin/flavors/templates/flavors/_update_metadata.html:4 #: dashboards/admin/flavors/templates/flavors/_update_metadata.html:7 #: dashboards/admin/flavors/templates/flavors/update_metadata.html:3 #: dashboards/admin/flavors/views.py:97 msgid ""Update Flavor Metadata"" msgstr """" ""Flavor ID should be UUID4 or integer. Leave this field blank or use 'auto' "" ""to set a random UUID4.""msgid """" ""Name may only contain letters, numbers, underscores, periods and hyphens.""""Flavors define the sizes for RAM, disk, number of cores, and other resources "" ""and can be selected when users deploy instances.""""Edit the flavor details. Flavors define the sizes for RAM, disk, number of "" ""cores, and other resources. Flavors are selected when users deploy instances.""#: dashboards/admin/hypervisors/compute/forms.py:25 #: dashboards/admin/hypervisors/compute/forms.py:99 #: dashboards/admin/instances/forms.py:27 msgid ""Current Host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:29 msgid ""Target Host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:30 msgid ""Choose a Host to evacuate servers to."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:32 msgid ""Shared Storage"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:48 msgid ""Select a target host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:50 msgid ""No other hosts available."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:61 #, python-format msgid ""Starting evacuation from %(current)s to %(target)s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:67 #, python-format msgid ""Failed to evacuate host: %s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:73 #: dashboards/admin/hypervisors/compute/tables.py:142 #: dashboards/admin/info/tables.py:66 dashboards/admin/info/tables.py:95 #: dashboards/admin/info/tables.py:119 dashboards/admin/info/tables.py:170 #: dashboards/admin/info/tables.py:209 #: dashboards/admin/instances/tables.py:134 #: dashboards/admin/networks/agents/tables.py:91 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:50 #: dashboards/admin/volumes/snapshots/tables.py:64 #: dashboards/admin/volumes/volumes/forms.py:43 #: dashboards/admin/volumes/volumes/forms.py:130 #: dashboards/admin/volumes/volumes/tables.py:81 #: dashboards/project/databases/tables.py:325 #: dashboards/project/databases/templates/databases/_detail_overview_cassandra.html:10 #: dashboards/project/databases/templates/databases/_detail_overview_couchbase.html:10 #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:10 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:10 #: dashboards/project/databases/templates/databases/_detail_overview_redis.html:10 #: dashboards/project/instances/templates/instances/_detail_overview.html:23 msgid ""Host"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:77 msgid ""Reason"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:86 #, python-format msgid ""Disabled compute service for host: %s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:91 #, python-format msgid ""Failed to disable compute service for host: %s."" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:106 msgid ""Running Instance Migration Type"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:108 #: dashboards/admin/instances/templates/instances/_live_migrate.html:8 #: dashboards/admin/instances/templates/instances/live_migrate.html:3 #: dashboards/admin/instances/views.py:157 msgid ""Live Migrate"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:109 msgid ""Cold Migrate"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:120 #: dashboards/admin/hypervisors/compute/forms.py:127 #: dashboards/admin/instances/forms.py:33 msgid ""Disk Over Commit"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:133 #: dashboards/admin/hypervisors/compute/forms.py:140 #: dashboards/admin/instances/forms.py:35 msgid ""Block Migration"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:159 #, python-format msgid ""Starting to migrate host: %(current)s"" msgstr """" #: dashboards/admin/hypervisors/compute/forms.py:164 #, python-format msgid ""Failed to migrate host \""%s\""."" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:27 #: dashboards/admin/hypervisors/compute/views.py:30 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_evacuate_host.html:8 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_evacuate_host.html:23 #: dashboards/admin/hypervisors/templates/hypervisors/compute/evacuate_host.html:3 msgid ""Evacuate Host"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:45 #: dashboards/admin/hypervisors/compute/views.py:62 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_disable_service.html:8 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_disable_service.html:23 #: dashboards/admin/hypervisors/templates/hypervisors/compute/disable_service.html:3 msgid ""Disable Service"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:64 msgid ""Enable Service"" msgid_plural ""Enable Services"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/hypervisors/compute/tables.py:72 msgid ""Enabled Service"" msgid_plural ""Enabled Services"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/hypervisors/compute/tables.py:91 #: dashboards/admin/hypervisors/compute/tables.py:97 #: dashboards/admin/hypervisors/compute/views.py:80 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_migrate_host.html:8 #: dashboards/admin/hypervisors/templates/hypervisors/compute/_migrate_host.html:22 #: dashboards/admin/hypervisors/templates/hypervisors/compute/migrate_host.html:3 #, fuzzy msgid ""Migrate Host"" msgid_plural ""Migrate Hosts"" msgstr[0] """" ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" msgstr[1] ""#-#-#-#-# django.pot (PACKAGE VERSION) #-#-#-#-#\n"" #: dashboards/admin/hypervisors/compute/tables.py:105 msgid ""Migrated Host"" msgid_plural ""Migrated Hosts"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/hypervisors/compute/tables.py:133 msgctxt ""Current status of a Hypervisor"" msgid ""Enabled"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:135 msgctxt ""Current status of a Hypervisor"" msgid ""Disabled"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:137 msgctxt ""Current state of a Hypervisor"" msgid ""Up"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:139 msgctxt ""Current state of a Hypervisor"" msgid ""Down"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:143 #: dashboards/admin/info/tables.py:96 dashboards/admin/info/tables.py:120 msgid ""Zone"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:148 #: dashboards/admin/info/tables.py:68 dashboards/admin/info/tables.py:97 #: dashboards/admin/info/tables.py:121 dashboards/admin/info/tables.py:171 #: dashboards/admin/info/tables.py:217 #: dashboards/admin/instances/tables.py:150 #: dashboards/admin/networks/agents/tables.py:92 #: dashboards/admin/networks/tables.py:103 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:17 #: dashboards/admin/volumes/snapshots/forms.py:34 #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:18 #: dashboards/admin/volumes/volumes/forms.py:179 #: dashboards/project/access_and_security/floating_ips/tables.py:202 #: dashboards/project/data_processing/clusters/tables.py:36 #: dashboards/project/data_processing/clusters/tables.py:158 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:12 #: dashboards/project/data_processing/job_executions/tables.py:40 #: dashboards/project/data_processing/job_executions/tables.py:205 #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:6 #: dashboards/project/database_backups/tables.py:174 #: dashboards/project/database_backups/templates/database_backups/details.html:26 #: dashboards/project/database_backups/templates/database_backups/details.html:67 #: dashboards/project/databases/tables.py:333 #: dashboards/project/databases/tables.py:399 #: dashboards/project/databases/templates/databases/_detail_overview.html:18 #: dashboards/project/firewalls/tables.py:355 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:25 #: dashboards/project/images/images/tables.py:281 #: dashboards/project/images/templates/images/images/_detail_overview.html:19 #: dashboards/project/instances/tables.py:1062 #: dashboards/project/instances/templates/instances/_detail_overview.html:14 #: dashboards/project/loadbalancers/tables.py:324 #: dashboards/project/loadbalancers/tables.py:377 #: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:28 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:66 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:60 #: dashboards/project/networks/ports/tables.py:74 #: dashboards/project/networks/tables.py:174 #: dashboards/project/networks/templates/networks/_detail_overview.html:13 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:17 #: dashboards/project/routers/ports/tables.py:112 #: dashboards/project/routers/tables.py:212 #: dashboards/project/routers/templates/routers/_detail_overview.html:11 #: dashboards/project/stacks/tables.py:275 #: dashboards/project/stacks/tables.py:320 #: dashboards/project/stacks/tables.py:371 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:19 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:26 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:35 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:40 #: dashboards/project/volumes/backups/tables.py:130 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:20 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:18 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:18 #: dashboards/project/volumes/volumes/tables.py:405 #: dashboards/project/vpn/tables.py:247 dashboards/project/vpn/tables.py:292 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:71 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:38 msgid ""Status"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:153 #: dashboards/admin/info/tables.py:98 dashboards/admin/info/tables.py:122 #: dashboards/admin/info/tables.py:172 dashboards/project/overview/views.py:34 msgid ""State"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:155 #: dashboards/admin/networks/agents/tables.py:95 msgid ""Updated At"" msgstr """" #: dashboards/admin/hypervisors/compute/tables.py:167 #: dashboards/admin/hypervisors/compute/tabs.py:24 msgid ""Compute Host"" msgstr """" #: dashboards/admin/hypervisors/compute/tabs.py:33 #: dashboards/admin/info/tabs.py:56 msgid ""Unable to get nova services list."" msgstr """" #: dashboards/admin/hypervisors/compute/views.py:45 msgid ""Unable to retrieve compute host information."" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/index.html:4#: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:9#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:10#: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:12#: dashboards/admin/hypervisors/templates/hypervisors/compute/_disable_service.html:18 msgid ""Disable the compute service."" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/compute/_evacuate_host.html:18 msgid """" ""Evacuate the servers from the selected down host to an active target host."" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/compute/_migrate_host.html:17 msgid """" ""Migrate all instances from a host with disabled nova-compute service. "" ""Optionally you can choose type of migration. All running instances of the "" ""host can be Live Migrated. Cold Migration is trying to use 'nova migrate' on "" ""each instance of migrated host."" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/detail.html:3 #: dashboards/admin/hypervisors/views.py:59 msgid ""Hypervisor Servers"" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/index.html:8 msgid ""Hypervisor Summary"" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/index.html:11 msgid ""VCPU Usage"" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/index.html:12 #: dashboards/admin/hypervisors/templates/hypervisors/index.html:19 #: dashboards/admin/hypervisors/templates/hypervisors/index.html:26 #, python-format msgid ""Used <span> %(used)s </span> of <span> %(available)s </span>"" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/index.html:18 msgid ""Memory Usage"" msgstr """" #: dashboards/admin/hypervisors/templates/hypervisors/index.html:25 msgid ""Local Disk Usage"" msgstr """" #: dashboards/admin/images/templates/images/index.html:3 #: dashboards/admin/images/views.py:47 #: dashboards/project/images/images/tables.py:303 #: dashboards/project/images/panel.py:24 #: dashboards/project/images/templates/images/index.html:3#: dashboards/project/instances/templates/instances/_detail_overview.html:117#: dashboards/admin/images/templates/images/_create.html:9 msgid ""Specify an image to upload to the Image Service."" msgstr """" #: dashboards/admin/images/templates/images/_create.html:11 #: dashboards/project/images/templates/images/images/_create.html:14 msgid """" ""Currently only images available via an HTTP URL are supported. The image "" ""location must be accessible to the Image Service. Compressed image binaries "" ""are supported (.zip and .tar.gz.)"" msgstr """" #: dashboards/admin/images/templates/images/_create.html:14 #: dashboards/project/images/templates/images/images/_create.html:18 msgid ""Please note: "" msgstr """" #: dashboards/admin/images/templates/images/_create.html:15 #: dashboards/project/images/templates/images/images/_create.html:22 msgid """" ""The Image Location field MUST be a valid and direct URL to the image binary. "" ""URLs that redirect or serve error pages will result in unusable images."" msgstr """" #: dashboards/admin/images/templates/images/_update.html:6 #: dashboards/project/images/templates/images/images/_update.html:6 msgid ""Edit the image details."" msgstr """" #: dashboards/admin/images/templates/images/create.html:3 #: dashboards/admin/images/views.py:119 #: dashboards/project/images/images/views.py:44 #: dashboards/project/images/images/views.py:50 #: dashboards/project/images/templates/images/images/create.html:3 msgid ""Create An Image"" msgstr """" #: dashboards/admin/images/templates/images/update.html:4 #: dashboards/admin/images/views.py:127 dashboards/admin/images/views.py:142 #: dashboards/project/images/images/views.py:56 #: dashboards/project/images/images/views.py:57 #: dashboards/project/images/images/views.py:61 #: dashboards/project/images/templates/images/images/update.html:3 msgid ""Update Image"" msgstr """" #: dashboards/admin/images/templates/images/update_metadata.html:3 #: dashboards/admin/images/views.py:147 msgid ""Update Image Metadata"" msgstr """" #: dashboards/admin/info/panel.py:27 #: dashboards/admin/info/templates/info/index.html:3 #: dashboards/admin/info/views.py:32#: dashboards/admin/info/templates/info/_cell_status.html:8#: dashboards/identity/projects/templates/projects/_detail_overview.html:13#: dashboards/identity/users/templates/users/_detail_overview.html:23#: dashboards/project/firewalls/templates/firewalls/_rule_details.html:53#: dashboards/project/routers/templates/routers/_detail_overview.html:48 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:65#: dashboards/admin/info/templates/info/_cell_status.html:3#: dashboards/project/routers/templates/routers/_detail_overview.html:50 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:65#: dashboards/admin/info/tables.py:103 dashboards/admin/info/tables.py:127 #: dashboards/admin/info/tables.py:176 dashboards/admin/info/tables.py:214#: dashboards/admin/info/templates/info/_cell_status.html:5 #, python-format msgid ""Reason: %(disabled_reason)s"" msgstr """" #: dashboards/admin/info/templates/info/index.html:10 #, python-format msgid """" ""Version: %(version_info)s\n"" "" "" msgstr """" #: dashboards/admin/instances/tables.py:50#: dashboards/admin/instances/tables.py:58#: dashboards/admin/instances/templates/instances/_live_migrate.html:23#: dashboards/admin/metering/tables.py:41 #: dashboards/admin/metering/templates/metering/stats.html:94 #: dashboards/admin/networks/forms.py:40 #: dashboards/admin/networks/tables.py:93 #: dashboards/admin/routers/tables.py:39#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:29#: dashboards/project/networks/templates/networks/ports/_detail_overview.html:29 #: dashboards/project/routers/templates/routers/_detail_overview.html:40#: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:33#: dashboards/project/containers/templates/containers/_container_detail.html:22 #: dashboards/project/containers/templates/containers/_object_detail.html:18#: dashboards/project/images/templates/images/images/_detail_overview.html:46#: dashboards/project/instances/templates/instances/_instance_flavor.html:7#: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:37 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:37 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:27#: dashboards/admin/instances/templates/instances/_live_migrate.html:18 msgid ""Live migrate an instance to a specific host."" msgstr """" #: dashboards/project/access_and_security/floating_ips/workflows.py:91#: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:20#: dashboards/project/images/templates/images/images/_detail_overview.html:23#: dashboards/admin/metadata_defs/templates/metadata_defs/index.html:3#: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:9 #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:35#: dashboards/admin/metadata_defs/tables.py:41#: dashboards/admin/metadata_defs/tables.py:49#: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:15 #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:57#: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:15#: dashboards/identity/projects/templates/projects/_detail_overview.html:15#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:10#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:10#: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:13#: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:13#: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:11#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:12#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:10#: dashboards/project/database_backups/templates/database_backups/details.html:16#: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:10 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:10 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:10#: dashboards/project/images/templates/images/images/_detail_overview.html:12#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:12 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:12#: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:122 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:13 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:29#: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:17 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:15 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:15#: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:9 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:9 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:10 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:10#: dashboards/project/stacks/resource_types/templates/stacks.resource_types/index.html:3#: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:3#: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:20 msgid ""Specify a metadata definition namespace to import."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:23 msgid ""Only definitions in raw JSON format are supported."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_create.html:26 msgid """" ""Administrator Note: Use the following CLI command to import the default "" ""definitions into Glance: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_contents.html:4 msgid ""Undefined"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:7 #: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:8 #: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:8 msgid ""Info"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:10 msgid ""Display Name"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:11 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:13 #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:35 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:7 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:9 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:12 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:16 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:18 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:20 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:36 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:42 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:44 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:51 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:53 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:66 #: dashboards/admin/volumes/volume_types/forms.py:89 #: dashboards/identity/projects/templates/projects/_detail_overview.html:16 #: dashboards/identity/users/templates/users/_detail_overview.html:22 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:13 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:15 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:17 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:25 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:27 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:11 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:11 #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:14 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:12 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:13 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:18 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:24 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:11 #: dashboards/project/databases/workflows/create_instance.py:232 #: dashboards/project/images/templates/images/images/_detail_overview.html:10 #: dashboards/project/images/templates/images/images/_detail_overview.html:16 #: dashboards/project/images/templates/images/images/_detail_overview.html:53 #: dashboards/project/images/templates/images/images/_detail_overview.html:55 #: dashboards/project/instances/templates/instances/_detail_overview.html:112 #: dashboards/project/instances/templates/instances/_detail_overview.html:122 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:45 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:51 #: dashboards/project/networks/templates/networks/_detail_overview.html:8 #: dashboards/project/networks/templates/networks/_detail_overview.html:10 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:7 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:9 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:12 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:18 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:20 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:36 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:42 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:44 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:11 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:13 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:20 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:48 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:56 #: dashboards/project/routers/templates/routers/_detail_overview.html:6 #: dashboards/project/routers/templates/routers/_detail_overview.html:30 #: dashboards/project/routers/templates/routers/_detail_overview.html:42 #: dashboards/project/routers/templates/routers/_detail_overview.html:54 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:77 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:7 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:10 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:7 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:10 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:8 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:11 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:8 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:11 msgid ""None"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:12 msgid ""Namespace"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:22 #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:35 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:18 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:82 #: dashboards/project/data_processing/jobs/workflows/launch.py:430 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:400 #: dashboards/project/database_backups/tables.py:165 #: dashboards/project/database_backups/templates/database_backups/details.html:32 #: dashboards/project/databases/tables.py:388 #: dashboards/project/databases/templates/databases/_detail_overview.html:35 #: dashboards/project/images/templates/images/images/_detail_overview.html:27 #: dashboards/project/instances/templates/instances/_detail_overview.html:18 #: dashboards/project/instances/templates/instances/_detail_overview.html:40 #: dashboards/project/stacks/tables.py:262 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:22 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:39 msgid ""Created"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:23 #: dashboards/admin/networks/views.py:59 #: dashboards/project/images/templates/images/images/_detail_overview.html:20 #: dashboards/project/images/templates/images/images/_detail_overview.html:31 #: dashboards/project/instances/tables.py:646 #: dashboards/project/networks/templates/networks/_detail_overview.html:14 #: dashboards/project/networks/templates/networks/_detail_overview.html:16 #: dashboards/project/networks/templates/networks/_detail_overview.html:22 #: dashboards/project/networks/templates/networks/_detail_overview.html:25 #: dashboards/project/routers/templates/routers/_detail_overview.html:14 #: dashboards/project/routers/templates/routers/_detail_overview.html:33 #: dashboards/project/routers/templates/routers/_detail_overview.html:39 #: dashboards/project/volumes/backups/tables.py:37 #: dashboards/project/volumes/snapshots/tables.py:126 msgid ""Unknown"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:24 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:21 #: dashboards/project/database_backups/templates/database_backups/details.html:34 #: dashboards/project/databases/templates/databases/_detail_overview.html:37 #: dashboards/project/images/templates/images/images/_detail_overview.html:33 #: dashboards/project/stacks/tables.py:266 msgid ""Updated"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:25 #: dashboards/project/images/templates/images/images/_detail_overview.html:37 msgid ""Never updated"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:32 msgid ""Associated Resource Types"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:39 msgid ""Prefix: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:42 msgid ""Properties Target: "" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_detail_overview.html:47 msgid ""No associations defined."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html:5 #: dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html:8 #: dashboards/admin/metadata_defs/templates/metadata_defs/_resource_types.html:14 msgid ""Namespace Resource Type Associations"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/create.html:3 #: dashboards/admin/metadata_defs/views.py:86 msgid ""Create a Metadata Namespace"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/detail.html:4 msgid ""Namespace Details"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:15 msgid ""Available Types"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:19 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:3 msgid ""Filter"" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:59 msgid """" ""Namespaces can be associated to different resource types. This makes the "" ""properties in the namespace visible in the 'Update Metadata' action for that "" ""type of resource."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:61 msgid """" ""Additionally, some resource types may require a prefix to be used when "" ""applying the metadata. In certain cases, the prefix may differ between the "" ""resource type (for example, flavor vs image)."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:63 msgid """" ""Example: The prefix 'hw:' is added to OS::Nova::Flavor for the Virtual CPU "" ""Topology namespace so that the properties will be prefixed with 'hw:' when "" ""applied to flavors."" msgstr """" #: dashboards/admin/metadata_defs/templates/metadata_defs/resource_types.html:65 msgid """" ""Do not use a colon ':' with OS::Glance::Images. This resource type does not "" ""support the use of colons."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:116#: dashboards/admin/metering/templates/metering/stats.html:117#: dashboards/admin/metering/templates/metering/stats.html:118#: dashboards/admin/metering/templates/metering/stats.html:119#: dashboards/admin/metering/templates/metering/stats.html:120#: dashboards/admin/metering/templates/metering/stats.html:121#: dashboards/admin/metering/templates/metering/stats.html:122#: dashboards/admin/metering/tables.py:26 #: dashboards/admin/metering/templates/metering/_daily.html:9 #: dashboards/admin/metering/templates/metering/daily.html:3 #: dashboards/admin/metering/views.py:48#: dashboards/admin/metering/templates/metering/_daily.html:19 msgid ""Select a pre-defined period or specify date."" msgstr """" #: dashboards/admin/metering/templates/metering/_daily.html:24 msgid ""View Usage Report"" msgstr """" #: dashboards/admin/metering/templates/metering/index.html:3#: dashboards/admin/metering/templates/metering/stats.html:10 msgid ""Metric:"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:16 msgid ""Compute (Nova)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:26 msgid ""Network (Neutron)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:36 msgid ""Image (Glance)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:46 msgid ""Volume (Cinder)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:56 msgid ""Object Storage (Swift)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:66 msgid ""Energy (Kwapi)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:76 msgid ""Intelligent Platform Management Interface (IPMI)"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:89 msgid ""Group by:"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:93 msgid ""--"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:99 msgid ""Value:"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:104 msgid ""Avg."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:105 msgid ""Min."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:106 msgid ""Max."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:107 msgid ""Sum."" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:112 msgid ""Period:"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:127 msgid ""From:"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:134 msgid ""To:"" msgstr """" #: dashboards/admin/metering/templates/metering/stats.html:146 msgid ""Statistics of all resources"" msgstr """" #: dashboards/admin/metering/views.py:106 #: dashboards/admin/overview/views.py:33 #: dashboards/identity/projects/templates/projects/_detail_overview.html:9 #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:18#: dashboards/admin/networks/agents/forms.py:32 #: dashboards/admin/networks/ports/forms.py:36 #: dashboards/admin/networks/tables.py:94 #: dashboards/project/networks/workflows.py:37 #: dashboards/project/routers/templates/routers/_detail_overview.html:29 msgid ""Network Name"" msgstr """" #: dashboards/admin/networks/agents/forms.py:36 msgid ""New DHCP Agent"" msgstr """" #: dashboards/admin/networks/agents/forms.py:37 msgid ""Choose an DHCP Agent to attach to."" msgstr """" #: dashboards/admin/networks/agents/forms.py:55 msgid ""Select a new agent"" msgstr """" #: dashboards/admin/networks/agents/forms.py:57 msgid ""No other agents available."" msgstr """" #: dashboards/admin/networks/agents/forms.py:62 #: dashboards/admin/networks/views.py:90 #: dashboards/admin/networks/views.py:137 msgid ""Unable to list dhcp agents hosting network."" msgstr """" #: dashboards/admin/networks/agents/forms.py:74 #, python-format msgid ""Agent %s was successfully added."" msgstr """" #: dashboards/admin/networks/agents/forms.py:80 #, python-format msgid ""Failed to add agent %(agent_name)s for network %(network)s."" msgstr """" #: dashboards/admin/networks/agents/tables.py:36 msgid ""Delete DHCP Agent"" msgid_plural ""Delete DHCP Agents"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/agents/tables.py:44 msgid ""Deleted DHCP Agent"" msgid_plural ""Deleted DHCP Agents"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/agents/tables.py:57 #, python-format msgid ""Failed to delete agent: %s"" msgstr """" #: dashboards/admin/networks/agents/tables.py:66 #: dashboards/admin/networks/agents/views.py:35 #: dashboards/admin/networks/templates/networks/agents/add.html:3 msgid ""Add DHCP Agent"" msgstr """" #: dashboards/admin/networks/agents/tables.py:93 #: dashboards/admin/networks/forms.py:79 #: dashboards/admin/networks/forms.py:241 #: dashboards/admin/networks/ports/forms.py:48 #: dashboards/admin/networks/tables.py:106 #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:19 #: dashboards/project/firewalls/forms.py:134 #: dashboards/project/firewalls/tables.py:358 #: dashboards/project/firewalls/workflows.py:286 #: dashboards/project/loadbalancers/forms.py:40 #: dashboards/project/loadbalancers/forms.py:95 #: dashboards/project/loadbalancers/forms.py:178 #: dashboards/project/loadbalancers/forms.py:241 #: dashboards/project/loadbalancers/workflows.py:48 #: dashboards/project/loadbalancers/workflows.py:190 #: dashboards/project/loadbalancers/workflows.py:343 #: dashboards/project/loadbalancers/workflows.py:547 #: dashboards/project/networks/forms.py:43 #: dashboards/project/networks/ports/forms.py:43 #: dashboards/project/networks/ports/tables.py:77 #: dashboards/project/networks/tables.py:177 #: dashboards/project/networks/templates/networks/_detail_overview.html:15 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:19 #: dashboards/project/networks/workflows.py:49 #: dashboards/project/routers/forms.py:36 #: dashboards/project/routers/forms.py:120 #: dashboards/project/routers/ports/tables.py:117 #: dashboards/project/routers/tables.py:225 #: dashboards/project/routers/templates/routers/_detail_overview.html:13 #: dashboards/project/vpn/forms.py:39 dashboards/project/vpn/forms.py:283 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:68 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:35 #: dashboards/project/vpn/workflows.py:33 #: dashboards/project/vpn/workflows.py:434 msgid ""Admin State"" msgstr """" #: dashboards/admin/networks/agents/tables.py:101 #: dashboards/admin/networks/tables.py:99 msgid ""DHCP Agents"" msgstr """" #: dashboards/admin/networks/agents/views.py:63 #: dashboards/admin/networks/ports/views.py:56 #: dashboards/project/networks/subnets/views.py:48 msgid ""Unable to retrieve network."" msgstr """" #: dashboards/admin/networks/agents/views.py:74 msgid ""Unable to retrieve agent list."" msgstr """" #: dashboards/admin/networks/forms.py:77 #: dashboards/admin/networks/forms.py:239#: dashboards/project/networks/ports/forms.py:41#: dashboards/admin/networks/forms.py:78 #: dashboards/admin/networks/forms.py:240#: dashboards/project/networks/ports/forms.py:42#: dashboards/admin/networks/forms.py:80 #: dashboards/admin/networks/forms.py:242#: dashboards/project/firewalls/templates/firewalls/_policy_details.html:31 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:50#: dashboards/project/networks/templates/networks/_detail_overview.html:17#: dashboards/admin/networks/forms.py:82 #: dashboards/admin/networks/forms.py:243 #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:177 #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:220 #: dashboards/project/networks/templates/networks/_detail_overview.html:19#: dashboards/project/routers/ports/forms.py:153""For VLAN networks, the VLAN VID on the physical network that realizes the "" ""virtual network. Valid VLAN VIDs are %(vlan_min)s through %(vlan_max)s. For "" ""GRE or VXLAN networks, the tunnel ID. Valid tunnel IDs for GRE networks are "" ""%(gre_min)s through %(gre_max)s. For VXLAN networks, %(vxlan_min)s through "" ""%(vxlan_max)s.""#: dashboards/admin/networks/templates/networks/index.html:3#: dashboards/project/networks/templates/networks/index.html:3#: dashboards/project/network_topology/templates/network_topology/index.html:26#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:11 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:11 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:15 #: dashboards/project/routers/templates/routers/_detail_overview.html:32#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:43 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:43#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:41 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:41#: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:22#: dashboards/project/networks/templates/networks/ports/_detail_overview.html:22#: dashboards/admin/networks/ports/tables.py:36#: dashboards/admin/networks/ports/tables.py:44#: dashboards/admin/networks/templates/networks/ports/create.html:3#: dashboards/admin/networks/subnets/tables.py:38 #: dashboards/project/networks/subnets/tables.py:61#: dashboards/admin/networks/subnets/tables.py:46 #: dashboards/project/networks/subnets/tables.py:69#: dashboards/project/networks/workflows.py:91#: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:19#: dashboards/project/networks/workflows.py:127#: dashboards/project/networks/subnets/tables.py:133 #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:28#: dashboards/admin/networks/subnets/tables.py:109 #: dashboards/admin/networks/views.py:149 #: dashboards/project/networks/subnets/tables.py:143 #: dashboards/project/networks/views.py:133 #, python-format msgid ""Unable to retrieve details for network \""%s\""."" msgstr """" #: dashboards/admin/networks/tables.py:38 #: dashboards/project/networks/tables.py:49 msgid ""Delete Network"" msgid_plural ""Delete Networks"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/tables.py:46 #: dashboards/project/networks/tables.py:57 msgid ""Deleted Network"" msgid_plural ""Deleted Networks"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/networks/tables.py:57 #: dashboards/project/networks/tables.py:79 #, python-format msgid ""Failed to delete network %s"" msgstr """" #: dashboards/admin/networks/tables.py:65 #: dashboards/admin/networks/templates/networks/_create.html:9 #: dashboards/admin/networks/templates/networks/_create.html:26 #: dashboards/admin/networks/templates/networks/create.html:3 #: dashboards/admin/networks/views.py:99 #: dashboards/project/network_topology/templates/network_topology/index.html:37 #: dashboards/project/networks/tables.py:87 #: dashboards/project/networks/tables.py:100 #: dashboards/project/networks/templates/networks/_create.html:8 #: dashboards/project/networks/templates/networks/_create.html:23 #: dashboards/project/networks/workflows.py:342 msgid ""Create Network"" msgstr """" #: dashboards/admin/networks/tables.py:74 #: dashboards/project/networks/tables.py:109 #: dashboards/project/networks/views.py:68 msgid ""Edit Network"" msgstr """" #: dashboards/admin/networks/tables.py:87 #: dashboards/project/networks/tables.py:146 msgctxt ""Admin state of a Network"" msgid ""UP"" msgstr """" #: dashboards/admin/networks/tables.py:88 #: dashboards/project/networks/tables.py:147 msgctxt ""Admin state of a Network"" msgid ""DOWN"" msgstr """" #: dashboards/admin/networks/tables.py:97 #: dashboards/project/networks/tables.py:171 msgid ""Subnets Associated"" msgstr """" #: dashboards/admin/networks/templates/networks/_create.html:19 msgid ""Create a new network for any project as you need."" msgstr """" #: dashboards/admin/networks/templates/networks/_create.html:20 msgid """" ""Provider specified network can be created. You can specify a physical "" ""network type (like Flat, VLAN, GRE, and VXLAN) and its segmentation_id or "" ""physical network name for a new virtual network."" msgstr """" #: dashboards/admin/networks/templates/networks/_create.html:21 msgid """" ""In addition, you can create an external network or a shared network by "" ""checking the corresponding checkbox."" msgstr """" #: dashboards/admin/networks/templates/networks/_update.html:6 #: dashboards/project/networks/templates/networks/_update.html:6 msgid ""You may update the editable properties of your network here."" msgstr """" #: dashboards/admin/networks/templates/networks/agents/_add.html:6 msgid ""From here you can add a DHCP agent for the network."" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_create.html:6 msgid """" ""You can create a port for the network. If you specify device ID to be "" ""attached, the device specified will be attached to the port created."" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:13 #: dashboards/identity/projects/tables.py:236 #: dashboards/identity/projects/templates/projects/_detail_overview.html:11 #: dashboards/identity/users/templates/users/_detail_overview.html:25 #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:22 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:16 #: dashboards/project/firewalls/templates/firewalls/_policy_details.html:16 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:16 #: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:9 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:9 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:15 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:15 #: dashboards/project/networks/templates/networks/_detail_overview.html:11 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:13 #: dashboards/project/routers/templates/routers/_detail_overview.html:9 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:15 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:15 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:16 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:16 msgid ""Project ID"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:15 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:15 msgid ""MAC Address"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:23 msgid ""On"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:25 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:25 msgid ""Fixed IP"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:32 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:32 #: dashboards/project/routers/templates/routers/_detail_overview.html:39 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:23 msgid ""Subnet ID"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:38 #: dashboards/project/networks/ports/tables.py:72 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:38 msgid ""Attached Device"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:46 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:46 msgid ""No attached device"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:48 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:48 msgid ""Binding"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:52 msgid ""Profile"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:54 msgid ""VIF Type"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:56 msgid ""VIF Details"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_detail_overview.html:69 #: dashboards/project/networks/templates/networks/ports/_detail_overview.html:51 msgid ""VNIC Type"" msgstr """" #: dashboards/admin/networks/templates/networks/ports/_update.html:6 #: dashboards/project/networks/templates/networks/ports/_update.html:6 msgid ""You may update the editable properties of your port here."" msgstr """" #: dashboards/admin/networks/templates/networks/ports/update.html:3 #: dashboards/project/networks/ports/views.py:91 #: dashboards/project/networks/templates/networks/ports/update.html:3 msgid ""Update Port"" msgstr """" #: dashboards/admin/networks/templates/networks/update.html:3 #: dashboards/project/networks/templates/networks/update.html:3 #: dashboards/project/networks/views.py:73 msgid ""Update Network"" msgstr """" #: dashboards/admin/networks/views.py:50 msgid ""Unable to retrieve information about the networks' projects."" msgstr """" #: dashboards/admin/networks/views.py:78 #: dashboards/project/networks/views.py:54 msgid ""Network list can not be retrieved."" msgstr """" #: dashboards/admin/networks/views.py:107 #: dashboards/project/networks/views.py:103 msgid ""Network Details: {{ network.name }}"" msgstr """" #: dashboards/admin/networks/views.py:116 #: dashboards/project/networks/views.py:112 msgid ""Subnet list can not be retrieved."" msgstr """" #: dashboards/admin/networks/views.py:126 #: dashboards/project/networks/views.py:122 msgid ""Port list can not be retrieved."" msgstr """" #: dashboards/project/routers/ports/tabs.py:24#: dashboards/project/stacks/resource_types/tabs.py:21#: dashboards/admin/overview/templates/overview/usage.csv:1 #: dashboards/project/overview/templates/overview/usage.csv:1 msgid ""Usage Report For Period:"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.csv:2 #: dashboards/project/overview/templates/overview/usage.csv:3 msgid ""Active Instances:"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.csv:3 #: dashboards/project/overview/templates/overview/usage.csv:4 msgid ""Total VCPU Usage (Hours):"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.csv:4 #: dashboards/project/overview/templates/overview/usage.csv:5 msgid ""Total Active RAM (MB):"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.csv:5 #: dashboards/project/overview/templates/overview/usage.csv:6 msgid ""Total Memory Usage (Hours):"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.csv:6 #: dashboards/project/overview/templates/overview/usage.csv:7 msgid ""Total Disk Size (GB):"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.csv:7 #: dashboards/project/overview/templates/overview/usage.csv:8 msgid ""Total Disk Usage (Hours):"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.html:3 msgid ""Usage Overview"" msgstr """" #: dashboards/admin/overview/templates/overview/usage.html:8 msgid ""Monitoring:"" msgstr """" #: dashboards/admin/routers/panel.py:24 dashboards/admin/routers/tables.py:46 #: dashboards/admin/routers/templates/routers/index.html:3 #: dashboards/identity/projects/workflows.py:77 #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:31 #: dashboards/project/firewalls/workflows.py:173 #: dashboards/project/firewalls/workflows.py:179 #: dashboards/project/network_topology/routers/tables.py:27 #: dashboards/project/routers/panel.py:24 #: dashboards/project/routers/tables.py:244 #: dashboards/project/routers/templates/routers/index.html:3 #: dashboards/project/routers/views.py:42 usage/quotas.py:80 msgid ""Routers"" msgstr """" #: dashboards/project/routers/ports/tables.py:125#: dashboards/admin/routers/templates/routers/detail.html:3 #: dashboards/project/routers/templates/routers/detail.html:3 #: dashboards/project/routers/views.py:102 msgid ""Router Details""#: dashboards/admin/routers/templates/routers/update.html:3 #: dashboards/project/routers/templates/routers/update.html:3 #: dashboards/project/routers/views.py:178 msgid ""Update Router""#: dashboards/admin/routers/views.py:42 dashboards/project/routers/views.py:53 msgid ""Unable to retrieve router list.""#: dashboards/admin/volumes/snapshots/tables.py:52 #: dashboards/admin/volumes/tabs.py:53 dashboards/admin/volumes/tabs.py:141 msgid ""Unable to retrieve volume project information."" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/update_status.html:3#: dashboards/admin/volumes/tabs.py:68 #: dashboards/admin/volumes/volume_types/tables.py:163 msgid ""Volume Types"" msgstr """" #: dashboards/admin/volumes/tabs.py:80 msgid ""Unable to retrieve volume types"" msgstr """" #: dashboards/admin/volumes/tabs.py:88 msgid ""Unable to retrieve volume type encryption information."" msgstr """" #: dashboards/admin/volumes/tabs.py:109 msgid ""Unable to retrieve QoS specs"" msgstr """" #: dashboards/admin/volumes/tabs.py:133 dashboards/project/volumes/tabs.py:113 #: dashboards/project/volumes/volumes/forms.py:232 msgid ""Unable to retrieve volume snapshots."" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:4 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:4 msgid ""Volume Snapshot Overview"" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:7 #: dashboards/identity/projects/templates/projects/_detail_overview.html:6 #: dashboards/identity/users/templates/users/_detail_overview.html:6 #: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:9 #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:6 #: dashboards/project/database_backups/templates/database_backups/details.html:11 #: dashboards/project/databases/templates/databases/_detail_overview.html:7 #: dashboards/project/images/templates/images/images/_detail_overview.html:6 #: dashboards/project/instances/templates/instances/_detail_overview.html:7 #: dashboards/project/instances/workflows/update_instance.py:119 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:6 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:6 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:9 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:7 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:7 msgid ""Information"" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:20 #: dashboards/project/instances/templates/instances/_detail_overview.html:147 #: dashboards/project/instances/workflows/create_instance.py:102 #: dashboards/project/instances/workflows/create_instance.py:425 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:23 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:20 #: dashboards/project/volumes/volumes/forms.py:249 msgid ""Volume"" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:30 #: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/_index.html:7 #: dashboards/admin/volumes/volume_types/qos_specs/tables.py:36 #: dashboards/admin/volumes/volume_types/tables.py:232 #: dashboards/project/databases/templates/databases/_detail_overview.html:24 #: dashboards/project/images/templates/images/images/_detail_overview.html:43 #: dashboards/project/instances/templates/instances/_detail_overview.html:47 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:34 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:24 msgid ""Specs"" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_detail_overview.html:34 #: dashboards/project/database_backups/templates/database_backups/details.html:31 #: dashboards/project/instances/templates/instances/_detail_overview.html:60 #: dashboards/project/instances/templates/instances/_detail_overview.html:63 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:11 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:12 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:38 #: dashboards/project/volumes/templates/volumes/snapshots/_detail_overview.html:38 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:28 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:11 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:11 msgid ""GB"" msgstr """" #: dashboards/admin/volumes/templates/volumes/snapshots/_update_status.html:6 msgid """" ""\n"" "" The status of a volume snapshot is normally managed automatically. In "" ""some circumstances\n"" "" an administrator may need to explicitly update the status value. This is "" ""equivalent to\n"" "" the <tt>cinder snapshot-reset-state</tt> command.\n"" "" "" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_associate_qos_spec.html:6 msgid ""Add, modify or remove the QoS Spec associated with this volume type."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_associate_qos_spec.html:7 msgid """" ""\""None\"" indicates that no QoS Spec is currently associated. Conversely, "" ""setting the QoS Spec to \""None\"" will remove the current association."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_associate_qos_spec.html:8 msgid """" ""This is equivalent to the <tt>cinder qos-associate</tt> and <tt>cinder qos-"" ""disassociate</tt> commands."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_qos_spec.html:6 msgid """" ""\n"" "" QoS Specs can be associated with volume types.\n"" "" It is used to map to a set of quality of service capabilities "" ""requested\n"" "" by the volume owner. This is equivalent to the\n"" "" <tt>cinder qos-create</tt> command. Once the QoS Spec gets created,\n"" "" click the \""Manage Specs\"" button to manage the key-value specs for "" ""the QoS Spec.\n"" "" <br>\n"" "" <br>\n"" "" Each QoS Specs entity will have a \""Consumer\"" value which indicates "" ""where the\n"" "" administrator would like the QoS policy to be enforced. This value can "" ""be \""front-end\""\n"" "" (Nova Compute), \""back-end\"" (Cinder back-end), or \""both\"".\n"" "" "" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type.html:6 msgid """" ""\n"" "" Volume type is a type or label that can be selected at volume "" ""creation\n"" "" time in OpenStack. It usually maps to a set of capabilities of the "" ""storage\n"" "" back-end driver to be used for this volume. Examples: \""Performance"" ""\"",\n"" "" \""SSD\"", \""Backup\"", etc. This is equivalent to the\n"" "" <tt>cinder type-create</tt> command. Once the volume type gets "" ""created,\n"" "" click the \""View Extra Specs\"" button to set up extra specs key-value\n"" "" pair(s) for that volume type.\n"" "" "" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type_encryption.html:7 msgid """" ""Creating encryption for a volume type causes all volumes with that volume "" ""type to be encrypted. Encryption information cannot be added to a volume "" ""type if volumes are currently in use with that volume type."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type_encryption.html:10 msgid """" ""The <strong>Provider</strong> is the class providing encryption support (e."" ""g. LuksEncryptor)."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type_encryption.html:13 msgid """" ""The <strong>Control Location</strong> is the notional service where "" ""encryption is performed (e.g., front-end=Nova). The default value is 'front-"" ""end.'"" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type_encryption.html:16 msgid """" ""The <strong>Cipher</strong> is the encryption algorithm/mode to use (e.g., "" ""aes-xts-plain64). If the field is left empty, the provider default will be "" ""used."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_create_volume_type_encryption.html:19 msgid """" ""The <strong>Key Size</strong> is the size of the encryption key, in bits (e."" ""g., 128, 256). If the field is left empty, the provider default will be used."" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_edit_qos_spec_consumer.html:6 msgid """" ""\n"" "" Each QoS Specs entity will have a \""Consumer\"" value which indicates "" ""where the\n"" "" administrator would like the QoS policy to be enforced. This value can "" ""be \""front-end\""\n"" "" (Nova Compute), \""back-end\"" (Cinder back-end), or \""both\"".\n"" "" "" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:4 msgid ""Volume Type Encryption Overview"" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:13#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:26#: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:13#: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:15#: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:15#: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:17#: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:17#: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:19#: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:19#: dashboards/admin/volumes/templates/volumes/volume_types/_volume_encryption_type_detail.html:25 msgid ""Volume Type is Unencrypted.""#: dashboards/admin/volumes/templates/volumes/volume_types/associate_qos_spec.html:3 msgid ""Associate QoS Spec""#: dashboards/admin/volumes/templates/volumes/volume_types/create_qos_spec.html:3 #: dashboards/admin/volumes/volume_types/tables.py:190 #: dashboards/admin/volumes/volume_types/views.py:121 msgid ""Create QoS Spec""#: dashboards/admin/volumes/templates/volumes/volume_types/create_volume_type.html:3#: dashboards/admin/volumes/templates/volumes/volume_types/create_volume_type_encryption.html:3 msgid ""Create Encrypted Volume Type""#: dashboards/admin/volumes/templates/volumes/volume_types/edit_qos_spec_consumer.html:3 #: dashboards/admin/volumes/volume_types/views.py:142 msgid ""Edit QoS Spec Consumer""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/_create.html:6 msgid ""Create a new \""extra spec\"" key-value pair for a volume type.""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/_edit.html:6 #, python-format msgid ""Update the \""extra spec\"" value for \""%(key)s\""""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/_index.html:6 #: dashboards/admin/volumes/templates/volumes/volume_types/extras/index.html:4 msgid ""Volume Type Extra Specs""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/_index.html:13 #: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/_index.html:14 #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:63 #: dashboards/project/containers/templates/containers/_container_detail.html:29 #: dashboards/project/containers/templates/containers/_object_detail.html:25 #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:104 #: dashboards/project/stacks/templates/stacks/_preview_details.html:58 #: dashboards/project/volumes/volumes/views.py:251 msgid ""Close""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/create.html:4 #: dashboards/admin/volumes/volume_types/extras/views.py:62 msgid ""Create Volume Type Extra Spec""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/create.html:8 #: dashboards/admin/volumes/templates/volumes/volume_types/extras/edit.html:8 #, python-format msgid ""Volume Type: %(volume_type_name)s ""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/edit.html:4 msgid ""Edit Volume Type Extra Spec""#: dashboards/admin/volumes/templates/volumes/volume_types/extras/index.html:7 #, python-format msgid ""Volume Type: %(volume_type_name)s""#: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/_create.html:6 #, python-format msgid ""Create a new \""spec\"" key-value pair for QoS Spec \""%(qos_spec_name)s\""""#: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/_edit.html:6 #, python-format msgid ""Update the spec value for \""%(key)s\""""#: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/create.html:4 #: dashboards/admin/volumes/volume_types/qos_specs/views.py:73 msgid ""Create Spec""#: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/edit.html:4 msgid ""Edit Spec"" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/qos_specs/edit.html:7 msgid ""QoS Spec: "" msgstr """" #: dashboards/admin/volumes/templates/volumes/volume_types/volume_encryption_type_detail.html:3#: dashboards/admin/volumes/templates/volumes/volumes/_manage_volume.html:6 msgid """" ""\n"" "" \""Manage\"" an existing volume from a Cinder host. This will make the "" ""volume visible within\n"" "" OpenStack.\n"" "" <br>\n"" "" <br>\n"" "" This is equivalent to the <tt>cinder manage</tt> command.\n"" "" ""#: dashboards/admin/volumes/templates/volumes/volumes/_unmanage_volume.html:6 msgid """" ""\n"" "" When a volume is \""unmanaged\"", the volume will no longer be visible "" ""within OpenStack. Note that the\n"" "" volume will not be deleted from the Cinder host.\n"" "" <br>\n"" "" <br>\n"" "" This is equivalent to the <tt>cinder unmanage</tt> command.\n"" "" ""#: dashboards/admin/volumes/templates/volumes/volumes/_update_status.html:6 msgid """" ""\n"" "" The status of a volume is normally managed automatically. In some "" ""circumstances an\n"" "" administrator may need to explicitly update the status value. This is "" ""equivalent to\n"" "" the <tt>cinder reset-state</tt> command.\n"" "" ""#: dashboards/admin/volumes/templates/volumes/volumes/detail.html:3 #: dashboards/project/volumes/templates/volumes/volumes/detail.html:3 msgid ""Volume Details""#: dashboards/admin/volumes/templates/volumes/volumes/manage_volume.html:3 #: dashboards/admin/volumes/volumes/tables.py:33 #: dashboards/admin/volumes/volumes/views.py:47 msgid ""Manage Volume""#: dashboards/admin/volumes/templates/volumes/volumes/unmanage_volume.html:3 #: dashboards/admin/volumes/volumes/tables.py:43 msgid ""Unmanage Volume""#: dashboards/admin/volumes/templates/volumes/volumes/update_status.html:3 #: dashboards/admin/volumes/volumes/tables.py:69 #: dashboards/admin/volumes/volumes/views.py:106 #: dashboards/admin/volumes/volumes/views.py:112 msgid ""Update Volume Status""#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:55 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:65#: dashboards/admin/volumes/volume_types/extras/tables.py:27#: dashboards/admin/volumes/volume_types/extras/tables.py:35#: dashboards/admin/volumes/volume_types/extras/tables.py:48 #: dashboards/admin/volumes/volume_types/extras/views.py:64 #: dashboards/admin/volumes/volume_types/qos_specs/tables.py:24 #: dashboards/admin/volumes/volume_types/qos_specs/views.py:76 #: dashboards/admin/volumes/volume_types/views.py:126 #: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:25 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:236 #: dashboards/project/data_processing/data_sources/workflows/create.py:95 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create.html:25 #: dashboards/project/data_processing/jobs/workflows/create.py:156 #: dashboards/project/data_processing/jobs/workflows/launch.py:429 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:255 #: dashboards/project/networks/subnets/workflows.py:57 #: dashboards/project/networks/workflows.py:343 msgid ""Create"" msgstr """" #: dashboards/admin/volumes/volume_types/extras/views.py:36 #: dashboards/admin/volumes/volume_types/views.py:201 msgid ""Unable to retrieve volume type details."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:52 #, python-format msgid ""Successfully created encryption for volume type: %s"" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:58 msgid ""Unable to create encrypted volume type."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:64 msgid ""QoS Spec to be associated"" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:65 msgid ""Choose associated QoS Spec."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:110 msgid """" ""New associated QoS Spec must be different than the current associated QoS "" ""Spec."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:142 msgid ""Successfully updated QoS Spec association."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:147 msgid ""Error updating QoS Spec association."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:153 msgid ""QoS Spec Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:155 msgid ""Choose consumer for this QoS Spec."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:171 msgid """" ""QoS Spec consumer value must be different than the current consumer value."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:185 msgid ""Successfully modified QoS Spec consumer."" msgstr """" #: dashboards/admin/volumes/volume_types/forms.py:189 msgid ""Error editing QoS Spec consumer."" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:34 msgid ""View Extra Specs"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:42 msgid ""Manage QoS Spec Association"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:53 msgid ""Delete Volume Type"" msgid_plural ""Delete Volume Types"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:61 msgid ""Deleted Volume Type"" msgid_plural ""Deleted Volume Types"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:73 msgid ""Create Encryption"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:94 msgid ""Delete Encryption"" msgid_plural ""Delete Encryptions"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:102 msgid ""Deleted Encryption"" msgid_plural ""Deleted Encryptions"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:122 msgid ""Unable to determine if volume type encryption is supported."" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:148 msgid ""Associated QoS Spec"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:150 msgid ""Encryption"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:176 msgid ""Manage Specs"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:201 msgid ""Delete QoS Spec"" msgid_plural ""Delete QoS Specs"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:209 msgid ""Deleted QoS Spec"" msgid_plural ""Deleted QoS Specs"" msgstr[0] """" msgstr[1] """" #: dashboards/admin/volumes/volume_types/tables.py:221 msgid ""Edit Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:230 #: dashboards/admin/volumes/volumes/forms.py:222 msgid ""Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/tables.py:245 msgid ""QoS Specs"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:41 msgid ""Create a Volume Type"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:72 msgid ""Unable to retrieve volume type encryption details."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:83 #: dashboards/admin/volumes/volume_types/views.py:87 msgid ""Create Volume Type Encryption"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:90 msgid ""Create an Encrypted Volume Type"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:100 msgid ""Unable to retrieve volume type name."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:125 msgid ""Create a QoS Spec"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:136 msgid ""Edit Consumer of QoS Spec"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:139 msgid ""Modify Consumer"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:161 msgid ""Unable to retrieve QoS Spec details."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:175 #: dashboards/admin/volumes/volume_types/views.py:182 msgid ""Associate QoS Spec with Volume Type"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:178 #: dashboards/project/access_and_security/floating_ips/tables.py:110 #: dashboards/project/access_and_security/floating_ips/workflows.py:137 #: dashboards/project/loadbalancers/workflows.py:670 msgid ""Associate"" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:211 msgid ""Unable to retrieve QoS Specs."" msgstr """" #: dashboards/admin/volumes/volume_types/views.py:231 msgid ""Unable to retrieve QoS Spec association."" msgstr """" ""Cinder host on which the existing volume resides; takes the form: "" ""host@backend-name#pool""#: dashboards/identity/domains/templates/domains/index.html:3#: dashboards/identity/domains/tables.py:95#: dashboards/identity/domains/tables.py:103#: dashboards/identity/users/forms.py:89 #: dashboards/identity/users/forms.py:166 #: dashboards/identity/users/templates/users/_detail_overview.html:10""different organizations. Edit the domain details to add or remove groups in "" ""the domain.""""currently logged into. Please switch to another domain with administrative "" ""privileges or remove the administrative role manually via the CLI.""#: dashboards/identity/groups/templates/groups/index.html:3#: dashboards/identity/groups/templates/groups/create.html:3#: dashboards/identity/groups/tables.py:65#: dashboards/identity/groups/tables.py:73#: dashboards/identity/groups/tables.py:141#: dashboards/identity/groups/tables.py:149#: dashboards/identity/users/forms.py:95 #: dashboards/identity/users/forms.py:173#: dashboards/identity/users/templates/users/_detail_overview.html:17 #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:14#: dashboards/identity/users/forms.py:97 #: dashboards/identity/users/forms.py:175#: dashboards/identity/users/templates/users/_detail_overview.html:21#: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:24#: dashboards/identity/groups/tables.py:214#: dashboards/identity/groups/tables.py:222#: dashboards/identity/groups/templates/groups/_add_non_member.html:5 msgid ""Add Group Assignment"" msgstr """" #: dashboards/identity/groups/templates/groups/_create.html:6 msgid """" ""Groups are used to manage access and assign roles to multiple users at once. "" ""After creating the group, edit the group to add users."" msgstr """" #: dashboards/identity/groups/templates/groups/_update.html:6 msgid """" ""Groups are used to manage access and assign roles to multiple users at once. "" ""Edit the group to add users."" msgstr """" #: dashboards/identity/groups/templates/groups/add_non_member.html:3 msgid ""Add User to Group"" msgstr """" #: dashboards/identity/groups/templates/groups/manage.html:3 msgid ""Group Management"" msgstr """" #: dashboards/identity/groups/templates/groups/update.html:3 #: dashboards/identity/groups/views.py:70 #: dashboards/identity/groups/views.py:74 #: dashboards/identity/groups/views.py:76 msgid ""Update Group"" msgstr """" #: dashboards/identity/projects/templates/projects/index.html:3#: dashboards/identity/projects/tables.py:140#: dashboards/identity/projects/tables.py:148#: dashboards/identity/projects/templates/projects/_detail_overview.html:3 msgid ""Project Overview"" msgstr """" #: dashboards/identity/projects/templates/projects/detail.html:3 msgid ""Project Details"" msgstr """" #: dashboards/identity/projects/templates/projects/usage.html:3 msgid ""Project Usage Overview""#: dashboards/identity/users/forms.py:92 #: dashboards/identity/users/forms.py:169 #: dashboards/identity/users/templates/users/_detail_overview.html:14""Failed to add %(users_to_add)s project members%(group_msg)s and set project "" ""quotas.""#: dashboards/identity/projects/workflows.py:562""You cannot revoke your administrative privileges from the project you are "" ""currently logged into. Please switch to another project with administrative "" ""privileges or remove the administrative role manually via the CLI.""""Failed to modify %(users_to_modify)s project members%(group_msg)s and update "" ""project quotas.""#: dashboards/identity/roles/panel.py:24 #: dashboards/identity/roles/tables.py:86 #: dashboards/identity/roles/templates/roles/index.html:3#: dashboards/identity/roles/tables.py:25 #: dashboards/identity/roles/templates/roles/create.html:3 #: dashboards/identity/roles/views.py:88 dashboards/identity/roles/views.py:91 #: dashboards/identity/roles/views.py:94#: dashboards/identity/roles/tables.py:51#: dashboards/identity/roles/tables.py:59#: dashboards/identity/roles/templates/roles/_create.html:6 msgid ""Create a new role."" msgstr """" #: dashboards/identity/roles/templates/roles/_update.html:6 msgid ""Edit the role's details."" msgstr """" #: dashboards/identity/roles/templates/roles/update.html:3 #: dashboards/identity/roles/views.py:56 dashboards/identity/roles/views.py:59 #: dashboards/identity/roles/views.py:62 msgid ""Update Role"" msgstr """" #: dashboards/identity/users/forms.py:99 #: dashboards/identity/users/forms.py:177#: dashboards/identity/users/templates/users/index.html:3#: dashboards/identity/users/templates/users/create.html:3#: dashboards/identity/users/templates/users/change_password.html:3#: dashboards/settings/password/templates/password/change.html:3#: dashboards/identity/users/tables.py:78#: dashboards/identity/users/tables.py:83#: dashboards/identity/users/tables.py:93#: dashboards/identity/users/tables.py:98#: dashboards/identity/users/tables.py:143 #: dashboards/project/databases/tables.py:124#: dashboards/identity/users/tables.py:151 #: dashboards/project/databases/tables.py:132#: dashboards/identity/users/templates/users/_change_password.html:6 msgid ""Change user's password. We highly recommend you create a strong one."" msgstr """" #: dashboards/identity/users/templates/users/_create.html:6 msgid """" ""Create a new user and set related properties including the Primary Project "" ""and Role."" msgstr """" #: dashboards/identity/users/templates/users/_detail_overview.html:3 msgid ""User Overview"" msgstr """" #: dashboards/identity/users/templates/users/_update.html:6 msgid ""Edit the user's details, including the Primary Project."" msgstr """" #: dashboards/identity/users/templates/users/detail.html:3 msgid ""User Details"" msgstr """" #: dashboards/identity/users/templates/users/update.html:3 #: dashboards/identity/users/views.py:76 dashboards/identity/users/views.py:79 #: dashboards/identity/users/views.py:82 msgid ""Update User"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:12 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:31#: dashboards/project/access_and_security/floating_ips/tables.py:82#: dashboards/project/access_and_security/floating_ips/tables.py:90#: dashboards/project/access_and_security/templates/access_and_security/floating_ips/allocate.html:3#: dashboards/project/access_and_security/floating_ips/views.py:76 #: dashboards/project/access_and_security/tabs.py:104 msgid ""Unable to retrieve floating IP pools."" msgstr """" #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:202""Select the IP address you wish to associate with the selected instance or "" ""port.""#: dashboards/project/access_and_security/floating_ips/workflows.py:73 #: dashboards/project/access_and_security/tabs.py:94 usage/base.py:111 msgid ""Unable to retrieve floating IP addresses."" msgstr """" ""The requested instance port is already associated with another floating IP.""#: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:26#: dashboards/project/access_and_security/keypairs/tables.py:31#: dashboards/project/access_and_security/keypairs/tables.py:39#: dashboards/project/access_and_security/templates/access_and_security/keypairs/import.html:3#: dashboards/project/access_and_security/templates/access_and_security/keypairs/create.html:3#: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:16#: dashboards/project/access_and_security/templates/access_and_security/keypairs/detail.html:4#: dashboards/project/access_and_security/templates/access_and_security/keypairs/download.html:4#: dashboards/project/access_and_security/panel.py:24 #: dashboards/project/access_and_security/views.py:35 #: dashboards/project/instances/workflows/create_instance.py:562 msgid ""Access & Security"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:36""from all members of another security group select &quot;Security Group&quot;.""""The \""to\"" port number must be greater than or equal to the \""from\"" port "" ""number.""#: dashboards/project/access_and_security/security_groups/tables.py:37#: dashboards/project/access_and_security/security_groups/tables.py:45#: dashboards/project/access_and_security/templates/access_and_security/security_groups/create.html:3#: dashboards/project/access_and_security/templates/access_and_security/security_groups/update.html:3#: dashboards/project/access_and_security/templates/access_and_security/security_groups/add_rule.html:3#: dashboards/project/access_and_security/security_groups/tables.py:177 #: dashboards/project/firewalls/tables.py:64#: dashboards/project/access_and_security/security_groups/tables.py:185""Manage Security Group Rules: {{ security_group.name }} ({{ security_group."" ""id }})""#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:59 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:69#: dashboards/project/access_and_security/security_groups/views.py:138 #: dashboards/project/access_and_security/tabs.py:57 usage/base.py:116 msgid ""Unable to retrieve security groups."" msgstr """" #: dashboards/project/access_and_security/tabs.py:74 msgid ""Unable to retrieve key pair list."" msgstr """" #: dashboards/project/access_and_security/tabs.py:128 msgid ""API Access"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:5 #: dashboards/project/access_and_security/templates/access_and_security/api_access/credentials.html:3 msgid ""User Credentials"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:26 msgid ""Authentication URL"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:36 msgid ""EC2 URL"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:39 msgid ""S3 URL"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:43 msgid ""EC2 Access Key"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/api_access/_credentials.html:49 msgid ""EC2 Secret Key"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/floating_ips/_allocate.html:7 msgid ""Allocate a floating IP from a given floating IP pool."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/floating_ips/_allocate.html:9 msgid ""Project Quotas"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/floating_ips/_allocate.html:11 msgid ""Floating IP"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/index.html:3 msgid ""Access &amp; Security"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_create.html:6 msgid """" ""Key pairs are ssh credentials which are injected into images when they are "" ""launched. Creating a new key pair registers the public key and downloads the "" ""private key (a .pem file)."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_create.html:7 msgid ""Protect and use the key as you would any normal ssh private key."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_import.html:6 msgid ""Key Pairs are how you login to your instance after it is launched."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_import.html:7 msgid """" ""Choose a key pair name you will recognise and paste your SSH public key into "" ""the space provided."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_import.html:8 msgid ""SSH key pairs can be generated with the ssh-keygen command:"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_import.html:10 msgid """" ""This generates a pair of keys: a key you keep private (cloud.key) and a "" ""public key (cloud.key.pub). Paste the contents of the public key file here."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/_import.html:11 msgid """" ""After launching an instance, you login using the private key (the username "" ""might be different depending on the image you launched):"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/download.html:8 #, python-format msgid """" ""The key pair &quot;%(keypair_name)s&quot; should download automatically. If "" ""not use the link below."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/keypairs/download.html:12 #, python-format msgid ""Download key pair &quot;%(keypair_name)s&quot;"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:6 msgid """" ""Rules define which traffic is allowed to instances assigned to the security "" ""group. A security group rule consists of three main parts:"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:7 msgid ""Rule:"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:7 msgid """" ""You can specify the desired rule template or use custom rules, the options "" ""are Custom TCP Rule, Custom UDP Rule, or Custom ICMP Rule."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:8 msgid ""Open Port/Port Range:"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:8 msgid """" ""For TCP and UDP rules you may choose to open either a single port or a range "" ""of ports. Selecting the \""Port Range\"" option will provide you with space to "" ""provide both the starting and ending ports for the range. For ICMP rules you "" ""instead specify an ICMP type and code in the spaces provided."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:9 msgid ""Remote:"" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_add_rule.html:9 msgid """" ""You must specify the source of the traffic to be allowed via this rule. You "" ""may do so either in the form of an IP address block (CIDR) or via a source "" ""group (Security Group). Selecting a security group as the source will allow "" ""any other instance in that security group access to any other instance via "" ""this rule."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_create.html:6 msgid """" ""Security groups are sets of IP filter rules that are applied to the network "" ""settings for the VM. After the security group is created, you can add rules "" ""to the security group."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/_update.html:6 msgid """" ""Security groups are sets of IP filter rules that are applied to the network "" ""settings for the VM. Edit the security group to add and change the rules."" msgstr """" #: dashboards/project/access_and_security/templates/access_and_security/security_groups/detail.html:3 msgid ""Manage Security Group Rules"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:11#: dashboards/project/containers/templates/containers/_container_detail.html:18 #: dashboards/project/containers/templates/containers/_container_metadata.html:9#: dashboards/project/containers/templates/containers/_container_detail.html:10#: dashboards/project/containers/templates/containers/_container_detail.html:12""Slashes are allowed, and are treated as pseudo-folders by the Object Store.""#: dashboards/project/containers/templates/containers/index.html:5 #: dashboards/project/containers/templates/containers/index.html:9#: dashboards/project/containers/tables.py:105#: dashboards/project/containers/tables.py:113#: dashboards/project/containers/templates/containers/_create.html:8 #: dashboards/project/containers/templates/containers/_create.html:24 #: dashboards/project/containers/templates/containers/create.html:3#: dashboards/project/containers/templates/containers/create_pseudo_folder.html:3#: dashboards/project/containers/templates/containers/_upload.html:28 #: dashboards/project/containers/templates/containers/upload.html:3#: dashboards/project/containers/templates/containers/_container_detail.html:5 #: dashboards/project/containers/templates/containers/container_detail.html:3#: dashboards/project/containers/tables.py:328#: dashboards/project/containers/tables.py:336#: dashboards/project/containers/templates/containers/_container_detail.html:15 msgid ""Public URL"" msgstr """" #: dashboards/project/containers/templates/containers/_container_detail.html:20 msgid ""Object Count"" msgstr """" #: dashboards/project/containers/templates/containers/_container_metadata.html:3 msgid ""Object Count: "" msgstr """" #: dashboards/project/containers/templates/containers/_container_metadata.html:4 msgid ""Size: "" msgstr """" #: dashboards/project/containers/templates/containers/_container_metadata.html:5 msgid ""Access: "" msgstr """" #: dashboards/project/containers/templates/containers/_copy.html:8 #, python-format msgid ""Copy Object: %(object_name)s"" msgstr """" #: dashboards/project/containers/templates/containers/_copy.html:18 msgid """" ""Make a new copy of an existing object to store in this or another container. "" ""You may additionally specify the path within the selected container where "" ""the new copy should be stored."" msgstr """" #: dashboards/project/containers/templates/containers/_copy.html:23 #: dashboards/project/containers/templates/containers/copy.html:3 #: dashboards/project/containers/views.py:229 msgid ""Copy Object"" msgstr """" #: dashboards/project/containers/templates/containers/_create.html:18 msgid """" ""A container is a storage compartment for your data and provides a way for "" ""you to organize your data. You can think of a container as a folder in "" ""Windows &reg; or a directory in UNIX &reg;. The primary difference between a "" ""container and these other file system concepts is that containers cannot be "" ""nested. You can, however, create an unlimited number of containers within "" ""your account. Data must be stored in a container so you must have at least "" ""one container defined in your account prior to uploading data."" msgstr """" #: dashboards/project/containers/templates/containers/_create.html:19 msgid """" ""Note: A Public Container will allow anyone with the Public URL to gain "" ""access to your objects in the container."" msgstr """" #: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:9 #, python-format msgid ""Create pseudo-folder in container %(container_name)s"" msgstr """" #: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:20 #: dashboards/project/containers/templates/containers/_upload.html:23 msgid ""Pseudo-folder:"" msgstr """" #: dashboards/project/containers/templates/containers/_create_pseudo_folder.html:20 #: dashboards/project/containers/templates/containers/_upload.html:23 msgid """" ""Within a container you can group your objects into pseudo-folders, which "" ""behave similarly to folders in your desktop operating system, with the "" ""exception that they are virtual collections defined by a common prefix on "" ""the object's name. A slash (/) character is used as the delimiter for pseudo-"" ""folders in the Object Store."" msgstr """" #: dashboards/project/containers/templates/containers/_object_detail.html:5 #: dashboards/project/containers/templates/containers/object_detail.html:3 #: dashboards/project/containers/views.py:298 msgid ""Object Details"" msgstr """" #: dashboards/project/containers/templates/containers/_object_detail.html:12 msgid ""Hash"" msgstr """" #: dashboards/project/containers/templates/containers/_object_detail.html:14 msgid ""Content Type"" msgstr """" #: dashboards/project/containers/templates/containers/_object_detail.html:16 msgid ""Last Modified"" msgstr """" #: dashboards/project/containers/templates/containers/_update.html:11 msgid ""Edit Object"" msgstr """" #: dashboards/project/containers/templates/containers/_update.html:21 #: dashboards/project/containers/templates/containers/_upload.html:22 msgid ""Object:"" msgstr """" #: dashboards/project/containers/templates/containers/_update.html:21 #: dashboards/project/containers/templates/containers/_upload.html:22 msgid """" ""An object is the basic storage entity that represents a file you store in "" ""the OpenStack Object Storage system. When you upload data to OpenStack "" ""Object Storage, the data is stored as-is (no compression or encryption) and "" ""consists of a location (container), the object's name, and any metadata "" ""consisting of key/value pairs."" msgstr """" #: dashboards/project/containers/templates/containers/_update.html:22 msgid ""File:"" msgstr """" #: dashboards/project/containers/templates/containers/_update.html:22 msgid ""A new uploaded file will replace the content of the current object"" msgstr """" #: dashboards/project/containers/templates/containers/_update.html:27 #: dashboards/project/containers/templates/containers/update.html:3 #: dashboards/project/containers/views.py:324 msgid ""Update Object"" msgstr """" #: dashboards/project/containers/templates/containers/_upload.html:11 #, python-format msgid ""Upload Object To Container: %(container_name)s"" msgstr """" #: dashboards/project/dashboard.py:22 msgid ""Compute""#: dashboards/project/dashboard.py:32 #: dashboards/project/instances/forms.py:173 #: dashboards/project/networks/workflows.py:79 msgid ""Network"" msgstr """" #: dashboards/project/dashboard.py:43 msgid ""Object Store"" msgstr """" #: dashboards/project/dashboard.py:49 msgid ""Orchestration"" msgstr """" #: dashboards/project/dashboard.py:56 #: dashboards/project/database_backups/tables.py:168 msgid ""Database"" msgstr """" #: dashboards/project/dashboard.py:63 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_templates.html:3 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/clusters.html:3 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/image_registry.html:3 #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/plugins.html:3 #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/data_sources.html:3 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/job_binaries.html:3 #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/job_executions.html:3 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/jobs.html:3 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/nodegroup_templates.html:3 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:4 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:4 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:4 msgid ""Data Processing""#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:14 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:30 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:22#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:6 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:14#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:6 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:24 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:7#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:6 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:30#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:8 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:16#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:8 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:26 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:8#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:8 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:32#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_upload_file.html:11 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/upload_file.html:3#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_create_cluster.html:10 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/configure.html:3 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/create.html:3 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/create_cluster.html:3#: dashboards/project/data_processing/cluster_templates/tables.py:72 #: dashboards/project/data_processing/nodegroup_templates/tables.py:63#: dashboards/project/data_processing/cluster_templates/tables.py:80 #: dashboards/project/data_processing/nodegroup_templates/tables.py:71#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:3#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:6#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:4 msgid ""This Cluster Template will be created for:""#: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:12 msgid """" ""The Cluster Template object should specify Node Group Templates that will be "" ""used to build a Cluster.\n"" "" You can add Node Groups using Node Group Templates on a &quot;Node "" ""Groups&quot; tab."" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:16 msgid ""You may set <b>cluster</b> scoped configurations on corresponding tabs."" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_configure_general_help.html:19 msgid """" ""The Cluster Template object may specify a list of processes in anti-affinity "" ""group.\n"" "" That means these processes may not be launched more than once on a "" ""single host."" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_create_general_help.html:3 msgid ""Select a plugin and version for a new Cluster template."" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:3 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:3 msgid ""Template Overview"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:20 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:46 msgid ""Anti-affinity enabled for"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:30 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:56 msgid ""no processes"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:34 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:58 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:60 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:61 msgid ""Node Configurations"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:42 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:66 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:68 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:69 #, python-format msgid ""%(conf_name)s: %(conf_value)s"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:46 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:70 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:72 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:73 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:17 msgid ""No configurations"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_details.html:51 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:77 msgid ""Cluster configurations are not specified"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:7 #, python-format msgid ""Node Group: %(node_group_name)s"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:8 msgid ""Nodes Count"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:11 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:14 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:14 #: dashboards/project/databases/templates/databases/_detail_overview.html:27 #: dashboards/project/databases/workflows/create_instance.py:36 #: dashboards/project/instances/templates/instances/_detail_overview.html:50 #: dashboards/project/instances/workflows/create_instance.py:87 msgid ""Flavor"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:12 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:15 msgid ""Flavor is not specified"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:18 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:34 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:26 msgid ""Template not specified"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:26 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:29 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:37 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:132 msgid ""Proxy Gateway"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:29 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:32 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:42 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:205 msgid ""Auto Security Group"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:45 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:48 #: dashboards/project/data_processing/nodegroup_templates/tables.py:90 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:62 msgid ""Node Processes"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:55 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:58 msgid ""Node processes are not specified"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_nodegroups_details.html:75 #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:78 msgid ""Node configurations are not specified"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/_upload_file.html:22 #: dashboards/project/volumes/volumes/views.py:176 msgid ""Upload"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_node_groups_template.html:95 msgid ""Select a Node Group Template to add:"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_templates.html:19 msgid ""Add Node Group"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/configure.html:3 #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/create.html:3 #: dashboards/project/data_processing/cluster_templates/views.py:90 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:80 #: dashboards/project/data_processing/cluster_templates/workflows/create.py:235 msgid ""Create Cluster Template"" msgstr """" #: dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/details.html:3#: dashboards/project/data_processing/cluster_templates/views.py:57 msgid ""Unable to fetch cluster template list""#: dashboards/project/stacks/views.py:93 #: dashboards/project/stacks/views.py:109#: dashboards/project/instances/templates/instances/_detail_overview.html:38#: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:27#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/scale.html:3#: dashboards/project/data_processing/clusters/tables.py:67#: dashboards/project/data_processing/clusters/tables.py:75#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_instances_details.html:2#: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:4 msgid ""This Cluster will be started with:"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:12 msgid ""Cluster can be launched using existing Cluster Templates."" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:15 msgid """" ""The Cluster object should specify OpenStack Image to boot instances for "" ""Cluster."" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_configure_general_help.html:18 msgid ""User has to choose a keypair to have access to clusters instances."" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_create_cluster.html:21 msgid "" Done"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_create_general_help.html:3 msgid ""Select a plugin and version for a new Cluster."" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:3 msgid ""Cluster Overview"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:17 msgid ""Error Details"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:36 #: dashboards/project/data_processing/clusters/workflows/create.py:83 msgid ""Base Image"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:39 #: dashboards/project/data_processing/clusters/workflows/create.py:100 msgid ""Neutron Management Network"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:42 #: dashboards/project/data_processing/clusters/workflows/create.py:87 msgid ""Keypair"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_details.html:86 #, python-format msgid ""%(key)s: %(val)s"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:10 #, python-format msgid ""Name: %(node_group_name)s"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:11 msgid ""Number of Nodes"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/_nodegroups_details.html:18 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:25 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:127 msgid ""Floating IP Pool"" msgstr """" #: dashboards/project/data_processing/clusters/templates/data_processing.clusters/details.html:3 #: dashboards/project/data_processing/clusters/views.py:59 msgid ""Cluster Details"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:58#: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html:10 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/register_image.html:3#: dashboards/project/data_processing/data_image_registry/tables.py:54#: dashboards/project/data_processing/data_image_registry/tables.py:62#: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html:10 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/edit_tags.html:3 #: dashboards/project/data_processing/data_image_registry/views.py:85 msgid ""Edit Image Tags"" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_edit_tags.html:27 #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_register_image.html:25 msgid ""Done"" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:3 msgid ""Image Registry tool:"" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:6 msgid """" ""Image Registry is used to provide additional information about images for "" ""Data Processing."" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:9 msgid """" ""Specified User Name will be used by Data Processing to apply configs and "" ""manage processes on instances."" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:12 msgid """" ""Tags are used for filtering images suitable for each plugin and each Data "" ""Processing version.\n"" "" To add required tags, select a plugin and a Data Processing version "" ""and click &quot;Add plugin tags&quot; button."" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:16 msgid ""You may also add any custom tag."" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_help.html:19 msgid ""Unnecessary tags may be removed by clicking a cross near tag's name."" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:5 msgid """" ""Register tags required for the Plugin with specified Data Processing Version"" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:30 msgid ""Add plugin tags"" msgstr """" #: dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html:38 msgid ""Add custom tag"" msgstr """" #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:11#: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:15#: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/_details.html:3 msgid ""Data Processing Plugin Overview"" msgstr """" #: dashboards/project/data_processing/data_plugins/templates/data_processing.data_plugins/details.html:3 #: dashboards/project/data_processing/data_plugins/views.py:49 msgid ""Data Processing Plugin Details"" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/create.html:3#: dashboards/project/data_processing/data_sources/tables.py:38#: dashboards/project/data_processing/data_sources/tables.py:46#: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:4 msgid ""Create a Data Source with a specified name."" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:7 msgid ""Select the type of your Data Source."" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:10 msgid ""You may need to enter the username and password for your Data Source."" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_create_data_source_help.html:13 msgid ""You may also enter an optional description for your Data Source."" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:2 msgid ""Data Source Overview"" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:11 #: dashboards/project/data_processing/data_sources/workflows/create.py:40 #: dashboards/project/data_processing/job_binaries/forms.py:59 #: dashboards/project/data_processing/job_binaries/forms.py:65 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:9 #: dashboards/project/loadbalancers/workflows.py:523 #: dashboards/project/loadbalancers/workflows.py:527 #: dashboards/project/loadbalancers/workflows.py:528 #: dashboards/project/stacks/forms.py:63 msgid ""URL"" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/_details.html:15 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:13 msgid ""Create time"" msgstr """" #: dashboards/project/data_processing/data_sources/templates/data_processing.data_sources/details.html:3 #: dashboards/project/data_processing/data_sources/views.py:62 msgid ""Data Source Details"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create.html:11 #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/create.html:3#: dashboards/project/data_processing/job_binaries/tables.py:41#: dashboards/project/data_processing/job_binaries/tables.py:49#: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:4 msgid """" ""<b>Important</b>: The name that you give your job binary will be the name "" ""used in your job execution.\n"" "" If your binary requires a particular name or extension (ie: \"".jar\""), be "" ""sure to include it here."" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:8 msgid ""Select the storage type for your job binary."" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:10 msgid ""Data Processing internal database"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:15 msgid """" ""For Data Processing internal job binaries, you may choose from the following:"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:17 msgid ""Choose an existing file"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:18 msgid ""Upload a new file"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:19 msgid ""Create a script to be uploaded dynamically"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:23 msgid ""For Object Store job binaries, you must:"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:25 msgid ""Enter the URL for the file"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:26 msgid ""Enter the username and password required to access that file"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_create_job_binary_help.html:30 msgid ""You may also enter an optional description for your job binary."" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:2 msgid ""Job Binary Overview"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/_details.html:16 msgid ""Download job binary"" msgstr """" #: dashboards/project/data_processing/job_binaries/templates/data_processing.job_binaries/details.html:3 #: dashboards/project/data_processing/job_binaries/views.py:76 msgid ""Job Binary Details"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:20#: dashboards/project/data_processing/job_executions/tables.py:53#: dashboards/project/data_processing/job_executions/tables.py:61#: dashboards/project/data_processing/job_executions/tables.py:74 #: dashboards/project/data_processing/job_executions/tables.py:103 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/launch.html:3#: dashboards/project/data_processing/job_executions/tables.py:82 #: dashboards/project/data_processing/job_executions/tables.py:111#: dashboards/project/instances/templates/instances/_detail_overview.html:66 #: dashboards/project/instances/templates/instances/_detail_overview.html:102#: dashboards/project/data_processing/job_executions/tables.py:176#: dashboards/project/data_processing/job_executions/tables.py:178#: dashboards/project/data_processing/job_executions/tables.py:180#: dashboards/project/data_processing/job_executions/tables.py:182#: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:10 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:3#: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:3 msgid ""Job Overview"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:13 msgid ""Input Data Source"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:17 msgid ""Output Data Source"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:22 #: dashboards/project/stacks/templates/stacks/_detail_overview.html:24 #: dashboards/project/stacks/templates/stacks/_resource_overview.html:38 msgid ""Last Updated"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:24 msgctxt ""Start time"" msgid ""Started"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:26 msgctxt ""End time"" msgid ""Ended"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:28 msgid ""Return Code"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:30 msgid ""Oozie Job ID"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:32 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:29 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:95 msgctxt ""Created time"" msgid ""Created"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:34 msgid ""Job Configuration"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/_details.html:36 #, python-format msgid ""%(group)s:"" msgstr """" #: dashboards/project/data_processing/job_executions/templates/data_processing.job_executions/details.html:3 msgid ""Job Details"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/create.html:3#: dashboards/project/data_processing/jobs/tables.py:47#: dashboards/project/data_processing/jobs/tables.py:55#: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:4 msgid ""Create a job template with a specified name."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:7 msgid ""Select the type of your job:"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:9 #: dashboards/project/data_processing/utils/helpers.py:126 msgid ""Pig"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:10 #: dashboards/project/data_processing/utils/helpers.py:127 msgid ""Hive"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:11 #: dashboards/project/data_processing/utils/helpers.py:128 msgid ""Spark"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:12 #: dashboards/project/data_processing/utils/helpers.py:129 msgid ""MapReduce"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:13 msgid ""Java Action"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:17 msgid """" ""Choose or create your main binary. Additional libraries can be added from "" ""the \""Libs\"" tab."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:20 msgid ""For Spark jobs, only a main is required, \""libs\"" are optional."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:23 msgid """" ""For MapReduce or Java Action jobs, \""mains\"" are not applicable. You are "" ""required to add one\n"" "" or more \""libs\"" for these jobs."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_help.html:27 msgid ""You may also enter an optional description for your job template."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_libs_help.html:4 msgid ""Add libraries to your job template."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_create_job_libs_help.html:7 msgid """" ""Choose from the list of binaries and click \""choose\"" to add the library to "" ""your job template. This can be repeated for additional libraries."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:14 msgid ""Mains"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:20 #: dashboards/project/data_processing/jobs/workflows/create.py:55 msgid ""Libs"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:26 msgid ""Created time"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:28 msgid ""Updated time"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_details.html:29 #: dashboards/project/volumes/volumes/forms.py:746 msgid ""Never"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_launch_job_configure_help.html:4 msgid ""Enter any custom configuration required for your job's execution."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:4 msgid ""Launch the given job template on a cluster."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:7 msgid ""Choose the cluster to use for the job."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:10 msgid ""Choose the Input Data Source (n/a for Java jobs)."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/_launch_job_help.html:13 msgid ""Choose the Output Data Source (n/a for Java jobs)."" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:5 msgid ""Select property name"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:16 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:34 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:47 #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html:3 msgid ""Remove"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:223 msgid ""Configuration"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:226 #: dashboards/project/stacks/templates/stacks/_preview_details.html:20 msgid ""Parameters"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/config_template.html:229 msgid ""Arguments"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/details.html:3 #: dashboards/project/data_processing/jobs/views.py:70 msgid ""Job Template Details"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html:86 msgid ""Choose"" msgstr """" #: dashboards/project/data_processing/jobs/templates/data_processing.jobs/library_template.html:98 msgid ""Chosen Libraries"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:2#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:4 msgid ""This Node Group Template will be created for:"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:12 msgid """" ""The Node Group Template object specifies the processes\n"" "" that will be launched on each instance. Check one or more "" ""processes.\n"" "" When processes are selected, you may set <b>node</b> scoped\n"" "" configurations on corresponding tabs."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:18 msgid """" ""You must choose a flavor to determine the size (VCPUs, memory and storage) "" ""of all launched VMs."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_configure_general_help.html:21 msgid """" ""Data Processing provides different storage location options. You may choose "" ""Ephemeral Drive or a Cinder Volume to be attached to instances."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_create_general_help.html:3 msgid ""Select a plugin and version for the new Node Group template."" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:72 msgid ""HDFS placement"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:74 msgid ""Cinder volumes"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:75 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:66 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:72 msgid ""Volumes per node"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:77 msgid ""Volumes size"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:80 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:88 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:94 msgid ""Volumes Availability Zone"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_details.html:84 msgid ""Ephemeral drive"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:4 msgid ""Show full configuration"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_fields_help.html:5 msgid ""Hide full configuration"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:12 #, python-format msgid ""%(conf_name)s: %(conf_val)s"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/configure.html:3 #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/create.html:3 #: dashboards/project/data_processing/nodegroup_templates/views.py:79 #: dashboards/project/data_processing/nodegroup_templates/views.py:87 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:254 #: dashboards/project/data_processing/nodegroup_templates/workflows/create.py:398 msgid ""Create Node Group Template"" msgstr """" #: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/details.html:3 msgid ""Nodegroup Template Details"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_job_type_select.html:13 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/job_type_select.html:3 #: dashboards/project/data_processing/wizard/views.py:99 msgid ""Choose job type"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_job_type_select.html:28 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_plugin_select.html:28 msgid ""Select"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_job_type_select_help.html:3 msgid """" ""Select which type of job that you want to run.\n"" "" This choice will dictate which steps are required to successfully\n"" "" execute your job.\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_plugin_select.html:13 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/plugin_select.html:3 #: dashboards/project/data_processing/wizard/views.py:90 msgid ""Choose plugin and version"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/_plugin_select_help.html:3 msgid """" ""Select which plugin and version that you\n"" "" want to use to create your cluster."" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:12 msgid """" ""The first step is to determine which type of\n"" "" cluster you want to run. You may have several choices\n"" "" available depending on the configuration of your "" ""system.\n"" "" Click on \""choose plugin\"" to bring up the list of data\n"" "" processing plugins. There you will be able to choose "" ""the\n"" "" data processing plugin along with the version number.\n"" "" Choosing this up front will allow the rest of the "" ""cluster\n"" "" creation steps to focus only on options that are "" ""pertinent\n"" "" to your desired cluster type."" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:23 msgid ""Choose plugin"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:24 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:60 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:87 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:119 msgid ""Current choice:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:27 msgid ""Plugin:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:29 msgid ""Version:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:34 msgid ""No plugin chosen"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:43 msgid """" ""Next, you need to define the different\n"" "" types of machines in your cluster. This is done by\n"" "" defining a Node Group Template for each type of\n"" "" machine. A very common case is where you\n"" "" need to have one or more machines running a \""master"" ""\""\n"" "" set of processes while another set of machines need\n"" "" to be running the \""worker\"" processes. Here,\n"" "" you will define the Node Group Template for your\n"" "" \""master\"" node(s).\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:58 msgid ""Create a Master Node Group Template"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:63 msgid ""Master Node Group Template:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:68 msgid ""No Master Node Group Template Created"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:77 msgid """" ""Repeat the Node Group Template\n"" "" creation process, but this time you are creating\n"" "" your \""worker\"" Node Group Template."" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:85 msgid ""Create a Worker Node Group Template"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:90 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:122 msgid ""Worker Node Group Template:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:95 msgid ""No Worker Node Group Template Created"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:104 msgid """" ""Now you need to set the layout of your\n"" "" cluster. By\n"" "" creating a Cluster Template, you will be choosing "" ""the\n"" "" number of instances of each Node Group Template "" ""that\n"" "" will appear in your cluster. Additionally,\n"" "" you will have a chance to set any cluster-specific\n"" "" configuration items in the additional tabs on the\n"" "" create Cluster Template form."" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:117 msgid ""Create a Cluster Template"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:127 msgid ""No Cluster Template Created"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:136 msgid """" ""You are now ready to\n"" "" launch your cluster. When you click on the link\n"" "" below, you will need to give your cluster a name,\n"" "" choose the Cluster Template to use and choose which\n"" "" image to use to build your instances. After you\n"" "" click on \""Create\"", your instances will begin to\n"" "" spawn. Your cluster should be operational in a few\n"" "" minutes."" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:149 msgid ""Launch a Cluster"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:157 msgid ""Reset Cluster Guide"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/cluster_guide.html:159 msgid ""Reset Cluster Creation Guide"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:13 msgid """" ""First, select which type of job that\n"" "" you want to run. This choice will determine "" ""which\n"" "" other steps are required\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:21 msgid ""Select type"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:24 msgid ""Current type:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:31 msgid ""No type chosen"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:42 msgid """" ""Data Sources are what your\n"" "" job uses for input and output. Depending on the "" ""type\n"" "" of job you will be running, you may need to "" ""define one\n"" "" or more data sources. You can create multiple "" ""data\n"" "" sources by repeating this step.\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:52 msgid ""Create a data source"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:61 msgid """" ""Define your Job Template.\n"" "" This is where you choose the type of job that you\n"" "" want to run (Pig, Java Action, Spark, etc) and "" ""choose\n"" "" or upload the files necessary to run it. The "" ""inputs\n"" "" and outputs will be defined later.\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:71 msgid ""Create a job template"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:73 msgid ""Job template:"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:80 msgid ""No job template created"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:89 msgid """" ""Launch your job. When\n"" "" launching, you may need to choose your input and\n"" "" output data sources. This is where you would also\n"" "" add any special configuration values, parameters,\n"" "" or arguments that you need to pass along\n"" "" to your job.\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:99 msgid ""Launch job"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:108 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/jobex_guide.html:110 msgid ""Reset Job Execution Guide"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:12 msgid """" ""\n"" "" Each of the Data Processing frameworks require a cluster of "" ""machines\n"" "" in order to do the work they are assigned. A cluster is\n"" "" formed by creating a set of Node Group Templates, "" ""combining\n"" "" those into a Cluster Template and then launching a "" ""Cluster.\n"" "" You can do each of those steps manually, or you can follow\n"" "" this guide to help take you through the steps of\n"" "" Cluster creation.\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:25 msgid ""Cluster Guide"" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:34 msgid """" ""\n"" "" In order to run a Data Processing job, you need to make\n"" "" the files for your program available to the\n"" "" Data Processing system, define where the input and output\n"" "" need to go and create a Job Template that describes\n"" "" how to run your job. Each of those steps can be done\n"" "" manually or you can follow this guide to help take you\n"" "" through the steps to run a job on an existing cluster.\n"" "" "" msgstr """" #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:47 #: dashboards/project/data_processing/wizard/templates/data_processing.wizard/wizard.html:49 msgid ""Job Execution Guide"" msgstr """" #: dashboards/project/database_backups/tables.py:37#: dashboards/project/database_backups/tables.py:39#: dashboards/project/database_backups/tables.py:41#: dashboards/project/database_backups/tables.py:43#: dashboards/project/database_backups/tables.py:45#: dashboards/project/database_backups/tables.py:47#: dashboards/project/database_backups/tables.py:96#: dashboards/project/database_backups/tables.py:104#: dashboards/project/database_backups/templates/database_backups/details.html:21#: dashboards/project/databases/templates/databases/_detail_overview.html:14#: dashboards/project/database_backups/templates/database_backups/details.html:23#: dashboards/project/databases/templates/databases/_detail_overview.html:16#: dashboards/project/database_backups/templates/database_backups/_backup_details_help.html:3 msgid ""Specify the details for the database backup."" msgstr """" #: dashboards/project/database_backups/templates/database_backups/_backup_details_help.html:4 msgid """" ""You can perform an incremental backup by specifying a parent backup. "" ""<strong>However,</strong> not all databases support incremental backups in "" ""which case this operation will result in an error."" msgstr """" #: dashboards/project/database_backups/templates/database_backups/backup.html:3 #: dashboards/project/database_backups/views.py:69 #: dashboards/project/database_backups/workflows/create_backup.py:82 msgid ""Backup Database"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:3 msgid ""Backup Details"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:8 msgid ""Backup Overview"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:28 msgid ""Backup File Location"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:30 msgid ""Initial Volume Size"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:36 msgid ""Backup Duration"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:43 msgid ""Incremental Backup"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:46 #: dashboards/project/database_backups/workflows/create_backup.py:38 msgid ""Parent Backup"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/details.html:57 msgid ""Database Info"" msgstr """" #: dashboards/project/database_backups/templates/database_backups/index.html:3 msgid ""Database Backups"" msgstr """" #: dashboards/project/databases/tables.py:40 #: dashboards/project/instances/tables.py:91#: dashboards/project/databases/tables.py:48 #: dashboards/project/instances/tables.py:99#: dashboards/project/databases/tables.py:68#: dashboards/project/databases/tables.py:76#: dashboards/project/databases/tables.py:96#: dashboards/project/databases/tables.py:104#: dashboards/project/databases/tables.py:150#: dashboards/project/databases/tables.py:158#: dashboards/project/databases/templates/databases/launch.html:3#: dashboards/project/network_topology/templates/network_topology/index.html:32 #: dashboards/project/network_topology/templates/network_topology/index.html:34#: dashboards/project/databases/templates/databases/_detail_overview_cassandra.html:12 #: dashboards/project/databases/templates/databases/_detail_overview_couchbase.html:12 #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:12 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:12 #: dashboards/project/databases/templates/databases/_detail_overview_redis.html:12#: dashboards/project/databases/tables.py:297#: dashboards/project/databases/tables.py:299#: dashboards/project/databases/tables.py:301#: dashboards/project/databases/tables.py:303#: dashboards/project/databases/tables.py:305#: dashboards/project/databases/tables.py:307#: dashboards/project/databases/tables.py:309#: dashboards/project/databases/tables.py:311#: dashboards/project/databases/tables.py:313#: dashboards/project/databases/tables.py:316#: dashboards/project/databases/templates/databases/_detail_overview.html:32#: dashboards/project/databases/templates/databases/_detail_overview.html:4 #: dashboards/project/instances/templates/instances/_detail_overview.html:4 #: dashboards/project/overview/templates/overview/usage.html:3 msgid ""Instance Overview"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:47 msgid ""Replication"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:51 msgid ""Is a Replica Of"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview.html:59 msgid ""Replicas"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview_cassandra.html:6 #: dashboards/project/databases/templates/databases/_detail_overview_couchbase.html:6 #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:6 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:6 #: dashboards/project/databases/templates/databases/_detail_overview_redis.html:6 msgid ""Connection Info"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview_cassandra.html:15 #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:15 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:15 msgid ""Database Port"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview_cassandra.html:17 #: dashboards/project/databases/templates/databases/_detail_overview_couchbase.html:15 #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:17 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:17 #: dashboards/project/databases/templates/databases/_detail_overview_redis.html:15 msgid ""Connection Examples"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:19 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:18 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:19 msgid ""USERNAME"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:19 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:19 msgid ""PASSWORD"" msgstr """" #: dashboards/project/databases/templates/databases/_detail_overview_mongodb.html:19 #: dashboards/project/databases/templates/databases/_detail_overview_mysql.html:19 msgid ""DATABASE"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_advanced_help.html:3 msgid """" ""Optionally choose to create this database using a previous backup, or as a "" ""replica of another database instance."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:3 #: dashboards/project/instances/templates/instances/_launch_details_help.html:5 msgid ""Specify the details for launching an instance."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_details_help.html:4 msgid """" ""<strong>Please note:</strong> The value specified in the Volume Size field "" ""should be greater than 0, however, some configurations do not support "" ""specifying volume size. If specifying the volume size results in an error "" ""stating volume support is not enabled, enter 0."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:3 #: dashboards/project/databases/workflows/create_instance.py:188 msgid ""Initial Databases"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:4 msgid ""Optionally provide a comma separated list of databases to create:"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:7 #: dashboards/project/databases/workflows/create_instance.py:192 msgid ""Initial Admin User"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:8 msgid """" ""Create an optional initial user.\n"" "" This user will have access to all databases you create."" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:12 msgid ""Username (required)"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:13 msgid ""Password (required)"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:14 #: dashboards/project/databases/workflows/create_instance.py:198 msgid ""Allowed Host (optional)"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_initialize_help.html:15 msgid """" ""Allow the user to connect from this host\n"" "" only. If not provided this user will be allowed to connect from "" ""anywhere.\n"" "" "" msgstr """" #: dashboards/project/databases/templates/databases/_launch_network_help.html:4 msgid """" ""\n"" "" Move networks from 'Available Networks' to 'Selected Networks' by\n"" "" clicking the button, or dragging and dropping. You can change the\n"" "" NIC order by dragging and dropping as well.\n"" "" "" msgstr """" #: dashboards/project/databases/templates/databases/_launch_networks.html:8 #: dashboards/project/instances/templates/instances/_update_networks.html:6 msgid ""Selected networks"" msgstr """" #: dashboards/project/databases/templates/databases/_launch_networks.html:11 #: dashboards/project/instances/templates/instances/_update_networks.html:8 msgid ""Available networks"" msgstr """" #: dashboards/project/databases/templates/databases/_resize_instance.html:9 #: dashboards/project/databases/templates/databases/_resize_instance.html:23 #: dashboards/project/databases/templates/databases/resize_instance.html:3 #: dashboards/project/databases/views.py:172 msgid ""Resize Database Instance"" msgstr """" #: dashboards/project/databases/templates/databases/_resize_instance.html:18 msgid ""Specify a new flavor for the database instance."" msgstr """" #: dashboards/project/databases/templates/databases/_resize_volume.html:9 #: dashboards/project/databases/templates/databases/_resize_volume.html:24 #: dashboards/project/databases/templates/databases/resize_volume.html:3 #: dashboards/project/databases/views.py:145 msgid ""Resize Database Volume"" msgstr """" #: dashboards/project/databases/templates/databases/_resize_volume.html:18 msgid ""Specify the new volume size for the database instance."" msgstr """" #: dashboards/project/databases/templates/databases/_resize_volume.html:19 msgid """" ""<strong>Please note:</strong> The new value must be greater than the "" ""existing volume size."" msgstr """" #: dashboards/project/databases/templates/databases/detail.html:3 #: dashboards/project/instances/templates/instances/detail.html:3 msgid ""Instance Details"" msgstr """" #: dashboards/project/databases/workflows/create_instance.py:44#: dashboards/project/databases/workflows/create_instance.py:135 #: dashboards/project/instances/workflows/create_instance.py:702#: dashboards/project/firewalls/templates/firewalls/_rule_details.html:22#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:33 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:28#: dashboards/project/firewalls/templates/firewalls/_rule_details.html:23 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:26 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:29 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:32 #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:35#: dashboards/project/firewalls/templates/firewalls/_rule_details.html:19#: dashboards/project/firewalls/templates/firewalls/_policy_details.html:34#: dashboards/project/firewalls/templates/firewalls/details_tabs.html:3#: dashboards/project/firewalls/tables.py:72#: dashboards/project/firewalls/tables.py:86#: dashboards/project/firewalls/tables.py:94#: dashboards/project/firewalls/tables.py:109#: dashboards/project/firewalls/tables.py:117#: dashboards/project/firewalls/templates/firewalls/updaterule.html:3#: dashboards/project/firewalls/templates/firewalls/updatepolicy.html:3#: dashboards/project/firewalls/templates/firewalls/updatefirewall.html:3#: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:16#: dashboards/project/firewalls/templates/firewalls/_rule_details.html:28#: dashboards/project/firewalls/templates/firewalls/_rule_details.html:34#: dashboards/project/firewalls/templates/firewalls/_policy_details.html:19#: dashboards/project/firewalls/tables.py:324#: dashboards/project/firewalls/tables.py:326#: dashboards/project/firewalls/tables.py:328#: dashboards/project/firewalls/tables.py:330#: dashboards/project/firewalls/tables.py:332#: dashboards/project/firewalls/tables.py:334#: dashboards/project/firewalls/tables.py:336#: dashboards/project/firewalls/tables.py:338#: dashboards/project/firewalls/templates/firewalls/_add_router_to_firewall.html:6 msgid ""Choose the router(s) you want to add."" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:19 msgid ""Policy ID"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_firewall_details.html:28 #: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:25 #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:35 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:63 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:57 msgid ""Admin State Up"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_insert_rule_to_policy.html:6 msgid """" ""Choose the rule you want to insert. Specify either the rule you want to "" ""insert immediately before, or the rule to insert immediately after. If both "" ""are specified, the prior takes precedence."" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_remove_router_from_firewall.html:6 msgid ""Unselect the routers you want to disassociate from the firewall."" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_remove_rule_from_policy.html:6 msgid ""Choose the rule you want to remove."" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:25 msgid ""Source IP Address"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:31 msgid ""Destination IP Address"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:37 msgid ""Used in Policy"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_rule_details.html:47 msgid ""Position in Policy"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_update_router_help.html:3 msgid """" ""Choose router(s) from Available Routers to Selected Routers by push button "" ""or drag and drop. "" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_update_routers.html:8 msgid ""Selected Routers"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_update_routers.html:11 msgid ""Available Routers"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_update_rule_help.html:3 msgid """" ""Choose rule(s) from Available Rules to Selected Rule by push button or drag "" ""and drop,\n"" ""you may change their order by drag and drop as well. "" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_update_rules.html:8 msgid ""Selected Rules"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_update_rules.html:11 msgid ""Available Rules"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_updatefirewall.html:6 msgid ""You may update firewall details here."" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_updatepolicy.html:6 msgid """" ""You may update policy details here. Use 'Insert Rule' or 'Remove Rule' links "" ""instead to insert or remove a rule"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/_updaterule.html:6 msgid ""You may update rule details here."" msgstr """" #: dashboards/project/firewalls/templates/firewalls/add_router_to_firewall.html:3 #: dashboards/project/firewalls/views.py:371 #: dashboards/project/firewalls/views.py:374 msgid ""Add Router to Firewall"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/addfirewall.html:3 #: dashboards/project/firewalls/views.py:108 msgid ""Add New Firewall"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/addpolicy.html:3 #: dashboards/project/firewalls/views.py:102 msgid ""Add New Policy"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/addrule.html:3 #: dashboards/project/firewalls/views.py:96 msgid ""Add New Rule"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/insert_rule_to_policy.html:3 #: dashboards/project/firewalls/views.py:264 msgid ""Insert Rule to Policy"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/remove_router_from_firewall.html:3 #: dashboards/project/firewalls/views.py:379 #: dashboards/project/firewalls/views.py:382 msgid ""Remove Router from Firewall"" msgstr """" #: dashboards/project/firewalls/templates/firewalls/remove_rule_from_policy.html:3 #: dashboards/project/firewalls/views.py:298 #: dashboards/project/firewalls/views.py:304 msgid ""Remove Rule from Policy"" msgstr """" #: dashboards/project/networks/ports/views.py:88""A name must be given. Firewall rules are added in the order placed under the "" ""Rules tab.""#: dashboards/project/images/images/forms.py:297""The minimum disk size required to boot the image. If unspecified, this value "" ""defaults to 0 (no minimum).""""Specify this option to copy image data to the image service. If unspecified, "" ""image data will be used in its current location.""#: dashboards/project/images/images/forms.py:286#: dashboards/project/images/images/forms.py:292#: dashboards/project/images/images/tables.py:90#: dashboards/project/images/images/tables.py:98#: dashboards/project/volumes/templates/volumes/volumes/create.html:3#: dashboards/project/images/images/tables.py:228#: dashboards/project/images/images/tables.py:266#: dashboards/project/images/templates/images/snapshots/create.html:3#: dashboards/project/images/templates/images/images/_create.html:12 msgid """" ""Images can be provided via an HTTP URL or be uploaded from your local file "" ""system. Compressed image binaries are supported (.zip and .tar.gz.)"" msgstr """" #: dashboards/project/images/templates/images/images/_create.html:20 msgid """" ""If you select an image via an HTTP URL, the Image Location field MUST be a "" ""valid and direct URL to the image binary; it must also be accessible to the "" ""Image Service. URLs that redirect or serve error pages will result in "" ""unusable images."" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:3 msgid ""Image Overview"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:17 msgid ""Owner"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:25 msgid ""Checksum"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:49 msgid ""Virtual Size"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:52 msgid ""Container Format"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:54 #: dashboards/project/volumes/volumes/forms.py:639 msgid ""Disk Format"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:57 msgid ""Min Disk"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:61 msgid ""Min RAM"" msgstr """" #: dashboards/project/images/templates/images/images/_detail_overview.html:68 msgid ""Custom Properties"" msgstr """" #: dashboards/project/images/templates/images/images/detail.html:4 msgid ""Image Details"" msgstr """" #: dashboards/project/images/templates/images/snapshots/_create.html:6 msgid """" ""A snapshot is an image which preserves the disk state of a running instance."" msgstr """" #: dashboards/project/images/utils.py:44 msgid ""Unable to retrieve public images."" msgstr """" #: dashboards/project/images/utils.py:60 msgid ""Unable to retrieve images for the current project."" msgstr """" #: dashboards/project/images/utils.py:95 msgid ""Unable to retrieve images"" msgstr """" #: dashboards/project/images/utils.py:104 #: dashboards/project/instances/forms.py:70 #: dashboards/project/instances/workflows/create_instance.py:449 msgid ""No images available"" msgstr """" #: dashboards/project/images/views.py:55 msgid ""Unable to retrieve images."" msgstr """" #: dashboards/project/instances/audit_tables.py:31#: dashboards/project/instances/templates/instances/_detail_overview.html:34#: dashboards/project/instances/tables.py:122#: dashboards/project/instances/tables.py:130#: dashboards/project/instances/tables.py:153#: dashboards/project/instances/tables.py:161#: dashboards/project/instances/tables.py:178#: dashboards/project/instances/tables.py:183 #: dashboards/project/instances/tables.py:251#: dashboards/project/instances/tables.py:193#: dashboards/project/instances/tables.py:198 #: dashboards/project/instances/tables.py:266#: dashboards/project/instances/tables.py:246#: dashboards/project/instances/tables.py:261#: dashboards/project/instances/templates/instances/_rebuild.html:9 #: dashboards/project/instances/templates/instances/_rebuild.html:27 #: dashboards/project/instances/templates/instances/rebuild.html:3""There is not enough capacity for this flavor in the selected availability "" ""zone. Try again later or select a different availability zone.""""Failed to perform requested operation on instance \""%s\"", the instance has "" ""an error status""#: dashboards/project/instances/tables.py:694#: dashboards/project/instances/tables.py:702#: dashboards/project/instances/tables.py:725#: dashboards/project/instances/tables.py:734#: dashboards/project/instances/tables.py:755#: dashboards/project/instances/tables.py:763#: dashboards/project/instances/tables.py:786#: dashboards/project/instances/tables.py:794#: dashboards/project/instances/templates/instances/attach_interface.html:3#: dashboards/project/instances/templates/instances/detach_interface.html:3#: dashboards/project/instances/tables.py:905#: dashboards/project/instances/tables.py:909#: dashboards/project/instances/tables.py:911#: dashboards/project/instances/tables.py:913#: dashboards/project/instances/tables.py:916#: dashboards/project/instances/tables.py:920#: dashboards/project/instances/tables.py:925#: dashboards/project/instances/tables.py:928#: dashboards/project/instances/tables.py:936#: dashboards/project/instances/tables.py:938#: dashboards/project/instances/tables.py:940#: dashboards/project/instances/tables.py:943#: dashboards/project/instances/tables.py:945#: dashboards/project/instances/tables.py:947#: dashboards/project/instances/tables.py:949#: dashboards/project/instances/tables.py:951#: dashboards/project/instances/tables.py:953#: dashboards/project/instances/tables.py:955#: dashboards/project/instances/tables.py:957#: dashboards/project/instances/tables.py:959#: dashboards/project/instances/tables.py:961#: dashboards/project/instances/tables.py:963#: dashboards/project/instances/tables.py:965#: dashboards/project/instances/tables.py:968#: dashboards/project/instances/tables.py:970#: dashboards/project/instances/tables.py:972#: dashboards/project/instances/tables.py:974#: dashboards/project/instances/tables.py:976#: dashboards/project/instances/tables.py:980#: dashboards/project/instances/tables.py:983#: dashboards/project/instances/tables.py:985#: dashboards/project/instances/tables.py:988#: dashboards/project/instances/tables.py:990#: dashboards/project/instances/tables.py:992#: dashboards/project/instances/tables.py:994#: dashboards/project/instances/tables.py:998#: dashboards/project/instances/tables.py:1002#: dashboards/project/instances/tables.py:1004#: dashboards/project/instances/tables.py:1006#: dashboards/project/instances/tables.py:1008#: dashboards/project/instances/templates/instances/_attach_interface.html:6 msgid ""Select the network for interface attaching."" msgstr """" #: dashboards/project/instances/templates/instances/_decryptpassword.html:10 #: dashboards/project/instances/views.py:277 msgid ""Retrieve Instance Password"" msgstr """" #: dashboards/project/instances/templates/instances/_decryptpassword.html:21 msgid """" ""To decrypt your password you will need the private key of your key pair for "" ""this instance. Select the private key file, or copy and paste the content of "" ""your private key file into the text area below, then click Decrypt Password."" msgstr """" #: dashboards/project/instances/templates/instances/_decryptpassword.html:22 msgid ""Note: "" msgstr """" #: dashboards/project/instances/templates/instances/_decryptpassword.html:22 msgid """" ""The private key will be only used in your browser and will not be sent to "" ""the server"" msgstr """" #: dashboards/project/instances/templates/instances/_decryptpassword.html:30 msgid ""Decrypt Password"" msgstr """" #: dashboards/project/instances/templates/instances/_detach_interface.html:5 msgid ""Select the port to detach."" msgstr """" #: dashboards/project/instances/templates/instances/_detail_console.html:4 msgid ""Instance Console"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_console.html:8 msgid """" ""If console is not responding to keyboard input: click the grey status bar "" ""below."" msgstr """" #: dashboards/project/instances/templates/instances/_detail_console.html:10 msgid ""Click here to show only console"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_console.html:11 msgid ""To exit the fullscreen mode, click the browser's back button."" msgstr """" #: dashboards/project/instances/templates/instances/_detail_console.html:25 msgid ""console is currently unavailable. Please try again later."" msgstr """" #: dashboards/project/instances/templates/instances/_detail_console.html:26 msgid ""Reload"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_log.html:5 msgid ""Instance Console Log"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_log.html:8 msgid ""Log Length"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_log.html:10 msgid ""Go"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_log.html:12 msgid ""View Full Log"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:20 msgid ""Time Since Created"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:31 msgid ""Fault"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:53 msgid ""Flavor ID"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:58 msgid ""VCPU"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:59 #: usage/tables.py:34 msgid ""Disk"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:72 msgid ""IP Addresses"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:97 msgid ""No rules defined."" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:111 msgid ""Key Name"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:125 #: dashboards/project/loadbalancers/tables.py:320 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:27 msgid ""N/A"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:135 msgid ""Volumes Attached"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:139 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:39 #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:47 #: dashboards/project/volumes/volumes/tables.py:430 msgid ""Attached To"" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:142 #, python-format msgid """" ""\n"" "" <a href=\""%(volume_url)s\"">%(volume_label)s</a> on "" ""%(volume_device)s\n"" "" "" msgstr """" #: dashboards/project/instances/templates/instances/_detail_overview.html:148 msgid ""No volumes attached."" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:6 msgid ""Flavor Details"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:13 msgid ""Total Disk"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:14 msgid ""MB"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:19 msgid ""Project Limits"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:21 msgid ""Number of Instances"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:22 #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:29 #, python-format msgid ""<p>%(used)s of %(quota)s Used</p>"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:35 msgid ""Total RAM"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:36 #, python-format msgid ""<p>%(used)s of %(quota)s MB Used</p>"" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:43 msgid ""Some flavors not meeting minimum image requirements have been disabled."" msgstr """" #: dashboards/project/instances/templates/instances/_flavors_and_quotas.html:44 msgid ""No flavors meet minimum criteria for selected image."" msgstr """" #: dashboards/project/instances/templates/instances/_instance_flavor.html:9 #, python-format msgid ""Flavor Details: %(name)s\"">%(name)s"" msgstr """" #: dashboards/project/instances/templates/instances/_instance_ips.html:12 msgid ""Floating IPs:"" msgstr """" #: dashboards/project/instances/templates/instances/_launch_advanced_help.html:2 msgid ""Specify advanced options to use when launching an instance."" msgstr """" #: dashboards/project/instances/templates/instances/_launch_customize_help.html:2 msgid """" ""You can customize your instance after it has launched using the options "" ""available here."" msgstr """" #: dashboards/project/instances/templates/instances/_launch_customize_help.html:3 msgid """" ""\""Customization Script\"" is analogous to \""User Data\"" in other systems."" msgstr """" #: dashboards/project/instances/templates/instances/_launch_details_help.html:6 msgid """" ""The chart below shows the resources used by this project in relation to the "" ""project's quotas."" msgstr """" #: dashboards/project/instances/templates/instances/_launch_network_help.html:3 msgid """" ""Choose network from Available networks to Selected networks by push button "" ""or drag and drop, you may change NIC order by drag and drop as well. "" msgstr """" #: dashboards/project/instances/templates/instances/_launch_volumes_help.html:3 msgid """" ""An instance can be launched with varying types of attached storage. You may "" ""select from those options here."" msgstr """" #: dashboards/project/instances/templates/instances/_rebuild.html:19 msgid ""Select the image to rebuild your instance."" msgstr """" #: dashboards/project/instances/templates/instances/_rebuild.html:21 msgid ""You may optionally set a password on the rebuilt instance."" msgstr """" #: dashboards/project/instances/templates/instances/decryptpassword.html:3 msgid ""Instance Admin Password"" msgstr """" #: dashboards/project/instances/views.py:214#: dashboards/project/instances/views.py:226msgid """" ""Unable to retrieve flavor information for instance \""%(name)s\"" (%(id)s).""""Unable to retrieve IP addresses from Neutron for instance \""%(name)s"" ""\"" (%(id)s).""""Volume mount point (e.g. 'vda' mounts at '/dev/vda'). Leave this field blank "" ""to let the system choose a device name for you.""#: dashboards/project/instances/workflows/create_instance.py:213""The requested instance cannot be launched as you only have %(avail)i of your "" ""quota available. """"The requested instance cannot be launched. Requested volume exceeds quota: "" ""Available: %(avail)s, Requested: %(req)s.""""The requested instance cannot be launched. The following requested resource"" ""(s) exceed quota(s): %s.""""Minimum requirements: %(min_ram)s MB of RAM and %(min_disk)s GB of Root Disk.""""The Volume size is too small for the '%(image_name)s' image and has to be "" ""greater than or equal to '%(smallest_size)d' GB.""""Control access to your instance via key pairs, security groups, and other "" ""mechanisms.""""A script or set of commands to be executed after the instance has been built "" ""(max 16kb).""""Automatic: The entire disk is a single partition and automatically resizes. "" ""Manual: Results in faster build times but requires manual partitioning.""""Configure OpenStack to write metadata to a special configuration drive that "" ""attaches to the instance when it boots.""""Add and remove security groups to this project from the list of available "" ""security groups.""#: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:10 #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:36#: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:39#: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:54""Maximum number of connections allowed for the VIP or '-1' if the limit is "" ""not set""#: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:22#: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:15""The minimum time in seconds between regular checks of a member. It must be "" ""greater than or equal to timeout""#: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:18#: dashboards/project/stacks/templates/stacks/_detail_overview.html:62""The maximum time in seconds for a monitor to wait for a reply. It must be "" ""less than or equal to delay""#: dashboards/project/loadbalancers/tables.py:82#: dashboards/project/loadbalancers/tables.py:90#: dashboards/project/loadbalancers/tables.py:108#: dashboards/project/loadbalancers/tables.py:116#: dashboards/project/loadbalancers/tables.py:135#: dashboards/project/loadbalancers/tables.py:143#: dashboards/project/loadbalancers/tables.py:156#: dashboards/project/loadbalancers/tables.py:164#: dashboards/project/loadbalancers/templates/loadbalancers/updatepool.html:3#: dashboards/project/loadbalancers/templates/loadbalancers/updatevip.html:3#: dashboards/project/loadbalancers/templates/loadbalancers/updatemember.html:3#: dashboards/project/loadbalancers/templates/loadbalancers/updatemonitor.html:3#: dashboards/project/loadbalancers/tables.py:296#: dashboards/project/loadbalancers/tables.py:298#: dashboards/project/loadbalancers/tables.py:300#: dashboards/project/loadbalancers/tables.py:302#: dashboards/project/loadbalancers/tables.py:304#: dashboards/project/loadbalancers/tables.py:306#: dashboards/project/loadbalancers/tables.py:308#: dashboards/project/loadbalancers/tables.py:310#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:29 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:18#: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:7 #: dashboards/project/networks/workflows.py:159#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:18#: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:38#: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:19 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:25#: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:39#: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:21#: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:3 msgid """" ""\n"" "" Assign a name and description for the pool. Choose one subnet where all\n"" "" members of this pool must be on. Select the protocol and load balancing\n"" "" method for this pool. Admin State is UP (checked) by default.\n"" "" "" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:11 msgid """" ""Use one of these load balancing methods to distribute incoming requests:"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:14 msgid ""Round robin"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:15 msgid ""Rotates requests evenly between multiple instances."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:17 msgid """" ""Requests from a unique source IP address are consistently\n"" "" directed to the same instance."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:19 msgid ""Least connections"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_create_pool_help.html:20 msgid """" ""Allocates requests to the instance with the least number of\n"" "" active connections."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_member_details.html:16 #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:22 msgid ""Address"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:25 #: dashboards/project/loadbalancers/workflows.py:511 #: dashboards/project/loadbalancers/workflows.py:516 #: dashboards/project/loadbalancers/workflows.py:517 msgid ""HTTP Method"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:28 msgid ""URL Path"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_monitor_details.html:31 msgid ""Expected Codes"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_pool_details.html:51 msgid ""Health Monitors"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_updatemember.html:6 msgid """" ""You may update member attributes here: edit pool, weight or admin state."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_updatemonitor.html:6 msgid """" ""You may update health monitor attributes here: edit delay, timeout, max "" ""retries or admin state."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_updatepool.html:6 msgid """" ""You may update pool attributes here: edit name, description, load balancing "" ""method or admin state."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_updatevip.html:6 msgid """" ""You may update VIP attributes here: edit name, description, pool, session "" ""persistence, connection limit or admin state."" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:35 msgid ""Port ID"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:42 #, python-format msgid ""Type: %(persistence_type)s"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/_vip_details.html:47 #, python-format msgid ""Cookie Name: %(cookie_name)s"" msgstr """" #: dashboards/project/loadbalancers/templates/loadbalancers/details_tabs.html:3 #: dashboards/project/loadbalancers/views.py:43 msgid ""Load Balancer"" msgstr """" ""%(type)s: url:%(url_path)s method:%(http_method)s codes:%(expected_codes)s "" ""delay:%(delay)d retries:%(max_retries)d timeout:%(timeout)d""""Create a VIP for this pool. Assign a name, description, IP address, port, "" ""and maximum connections allowed for the VIP. Choose the protocol and session "" ""persistence method for the VIP. Admin State is UP (checked) by default.""#: dashboards/project/loadbalancers/workflows.py:274""Enter an integer value between 1 and 65535. The same port will be used for "" ""all the selected members and can be modified later.""#: dashboards/project/loadbalancers/workflows.py:372""Choose one or more listed instances to be added to the pool as member(s). "" ""Assign a numeric weight and port number for the selected member(s) to operate"" ""(s) on; e.g., 80. \n""""Expected code may be a single value (e.g. 200), a list of values (e.g. 200, "" ""202), or range of values (e.g. 200-204)""""Please enter a single value (e.g. 200), a list of values (e.g. 200, 202), or "" ""range of values (e.g. 200-204)""""Select type of monitoring. Specify delay, timeout, and retry limits required "" ""by the monitor. Specify method, URL path, and expected HTTP codes upon "" ""success.""#: dashboards/project/network_topology/templates/network_topology/index.html:4#: dashboards/project/network_topology/templates/network_topology/_create_router.html:9 #: dashboards/project/network_topology/templates/network_topology/_create_router.html:20 #: dashboards/project/network_topology/templates/network_topology/create_router.html:3 #: dashboards/project/network_topology/templates/network_topology/index.html:40 #: dashboards/project/routers/tables.py:85 #: dashboards/project/routers/tables.py:98 #: dashboards/project/routers/templates/routers/create.html:3 #: dashboards/project/routers/views.py:164 #: dashboards/project/routers/views.py:167 #: dashboards/project/routers/views.py:168 msgid ""Create Router"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/_svg_element.html:184 #: dashboards/project/vpn/tables.py:290 dashboards/project/vpn/workflows.py:29 #: dashboards/router/dashboard.py:19 msgid ""Router"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:9 msgid ""This pane needs javascript support."" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:21 msgid ""Small"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:32 #: dashboards/project/network_topology/templates/network_topology/index.html:34 msgid ""Launch Instance (Quota exceeded)"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:37 #: dashboards/project/networks/tables.py:98 msgid ""Create Network (Quota exceeded)"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:40 #: dashboards/project/routers/tables.py:96 msgid ""Create Router (Quota exceeded)"" msgstr """" #: dashboards/project/network_topology/templates/network_topology/index.html:46 msgid ""There are no networks, routers, or connected instances to display."" msgstr """" #: dashboards/project/networks/ports/tables.py:36 msgid ""Attached"" msgstr """" #: dashboards/project/networks/ports/tables.py:38 msgid ""Detached"" msgstr """" #: dashboards/project/networks/ports/tables.py:43 #: dashboards/project/networks/ports/views.py:85 msgid ""Edit Port"" msgstr """" #: dashboards/project/networks/ports/tables.py:55 #: dashboards/project/routers/ports/tables.py:94 msgctxt ""Admin state of a Port"" msgid ""UP"" msgstr """" #: dashboards/project/networks/ports/tables.py:56 #: dashboards/project/routers/ports/tables.py:95 msgctxt ""Admin state of a Port"" msgid ""DOWN"" msgstr """" #: dashboards/project/networks/ports/tables.py:60 msgctxt ""status of a network port"" msgid ""Active"" msgstr """" #: dashboards/project/networks/ports/tables.py:61 msgctxt ""status of a network port"" msgid ""Down"" msgstr """" #: dashboards/project/networks/ports/tables.py:62 msgctxt ""status of a neteork port"" msgid ""Error"" msgstr """" #: dashboards/project/networks/ports/tables.py:63 msgctxt ""status of a network port"" msgid ""Build"" msgstr """" #: dashboards/project/networks/ports/views.py:39 #: dashboards/project/networks/templates/networks/ports/detail.html:3 msgid ""Port Details"" msgstr """" #: dashboards/project/networks/ports/views.py:54 #: dashboards/project/routers/ports/tabs.py:35 #: dashboards/project/routers/views.py:135 msgid ""Unable to retrieve port details."" msgstr """" #: dashboards/project/networks/ports/views.py:104 msgid ""Unable to retrieve port details"" msgstr """" #: dashboards/project/networks/subnets/tables.py:106 msgid ""Create Subnet (Quota exceeded)"" msgstr """" #: dashboards/project/networks/subnets/tables.py:131 #: dashboards/project/networks/subnets/workflows.py:81 #: dashboards/project/networks/workflows.py:109 msgid ""Network Address"" msgstr """" #: dashboards/project/networks/subnets/utils.py:20 msgid ""No options specified"" msgstr """" #: dashboards/project/networks/subnets/utils.py:22 msgid ""SLAAC: Address discovered from OpenStack Router"" msgstr """" #: dashboards/project/networks/subnets/utils.py:24 msgid ""DHCPv6 stateful: Address discovered from OpenStack DHCP"" msgstr """" #: dashboards/project/networks/subnets/utils.py:26 msgid """" ""DHCPv6 stateless: Address discovered from OpenStack Router and additional "" ""information from OpenStack DHCP"" msgstr """" #: dashboards/project/networks/subnets/views.py:67 msgid ""Unable to retrieve subnet details"" msgstr """" #: dashboards/project/networks/subnets/views.py:103 #: dashboards/project/networks/subnets/workflows.py:148 #: dashboards/project/networks/templates/networks/subnets/detail.html:3 #: dashboards/project/networks/workflows.py:256 msgid ""Subnet Details"" msgstr """" #: dashboards/project/networks/subnets/views.py:112 msgid ""Unable to retrieve subnet details."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:35 msgid ""Specify \""Network Address\"""" msgstr """" #: dashboards/project/networks/subnets/workflows.py:39 msgid """" ""Create a subnet associated with the network. Advanced configuration is "" ""available by clicking on the \""Subnet Details\"" tab."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:58 #, python-format msgid ""Created subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:59 #, python-format msgid ""Unable to create subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:86 msgid ""Network address in CIDR format (e.g. 192.168.0.0/24)"" msgstr """" #: dashboards/project/networks/subnets/workflows.py:103 msgid ""Gateway IP (optional)"" msgstr """" #: dashboards/project/networks/subnets/workflows.py:106 msgid """" ""IP address of Gateway (e.g. 192.168.0.254). Specify an explicit address to "" ""set the gateway. If you do not want to use a gateway, check 'Disable "" ""Gateway' below."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:112 #: dashboards/project/networks/workflows.py:146 msgid ""Disable Gateway"" msgstr """" #: dashboards/project/networks/subnets/workflows.py:117 msgid """" ""Update a subnet associated with the network. Advanced configuration are "" ""available at \""Subnet Details\"" tab."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:149 #: dashboards/project/networks/workflows.py:257 msgid ""Specify additional attributes for the subnet."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:160 #, python-format msgid ""Updated subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:161 #, python-format msgid ""Unable to update subnet \""%s\""."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:196 #, python-format msgid ""Subnet \""%s\"" was successfully updated."" msgstr """" #: dashboards/project/networks/subnets/workflows.py:200 #, python-format msgid ""Failed to update subnet \""%(sub)s\"": %(reason)s""#: dashboards/project/networks/templates/networks/_create.html:18 msgid ""Select a name for your network."" msgstr """" #: dashboards/project/networks/templates/networks/_detail_overview.html:3 msgid ""Network Overview"" msgstr """" #: dashboards/project/networks/templates/networks/_detail_overview.html:21 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:47 msgid ""MTU"" msgstr """" #: dashboards/project/networks/templates/networks/_detail_overview.html:24 msgid ""Provider Network"" msgstr """" #: dashboards/project/networks/templates/networks/_detail_overview.html:25 msgid ""Network Type:"" msgstr """" #: dashboards/project/networks/templates/networks/_detail_overview.html:26 msgid ""Physical Network:"" msgstr """" #: dashboards/project/networks/templates/networks/_detail_overview.html:27 msgid ""Segmentation ID:"" msgstr """" #: dashboards/project/networks/templates/networks/create.html:9 msgid ""&laquo;&nbsp;Back"" msgstr """" #: dashboards/project/networks/templates/networks/create.html:10 msgid ""Next&nbsp;&raquo;"" msgstr """" #: dashboards/project/networks/templates/networks/detail.html:3 msgid ""Network Details"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:4 msgid ""Subnet Overview"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:17 msgid ""IP version"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:21 msgid ""IP allocation pool"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:24 msgid ""Start"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:25 msgid "" - End"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:30 msgid ""DHCP Enable"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:33 #: dashboards/project/networks/workflows.py:218 #: dashboards/project/networks/workflows.py:222 msgid ""IPv6 Address Configuration Mode"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:37 #, python-format msgid """" ""\n"" "" Other IPv6 modes: ipv6_ra_mode=%(ra_mode)s, ipv6_address_mode="" ""%(addr_mode)s\n"" "" "" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:42 msgid ""Additional routes"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:45 #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:24 msgid ""Destination"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:46 msgid "" : Next hop"" msgstr """" #: dashboards/project/networks/templates/networks/subnets/_detail_overview.html:51 msgid ""DNS name server""""Create a new network. In addition, a subnet associated with the network can "" ""be created in the next panel.""""IP address of Gateway (e.g. 192.168.0.254) The default value is the first IP "" ""of the network address (e.g. 192.168.0.1 for 192.168.0.0/24, 2001:DB8::1 for "" ""2001:DB8::/48). If you use the default, leave blank. If you do not want to "" ""use a gateway, check 'Disable Gateway' below.""""Specifies how IPv6 addresses and additional information are configured. We "" ""can specify SLAAC/DHCPv6 stateful/DHCPv6 stateless provided by OpenStack, or "" ""specify no option. 'No options specified' means addresses are configured "" ""manually or configured by a non-OpenStack system.""""IP address allocation pools. Each entry is: start_ip_address,end_ip_address "" ""(e.g., 192.168.1.100,192.168.1.120) and one entry per line.""msgid """" ""IP address list of DNS name servers for this subnet. One entry per line.""""Additional routes announced to the hosts. Each entry is: destination_cidr,"" ""nexthop (e.g., 192.168.200.0/24,10.56.1.254) and one entry per line.""msgid """" ""Failed to create subnet \""%(sub)s\"" for network \""%(net)s\"": %(reason)s""#: dashboards/project/overview/templates/overview/usage.csv:2 msgid ""Project ID:""#: dashboards/project/routers/extensions/extraroutes/forms.py:33 #: dashboards/project/routers/extensions/extraroutes/tables.py:65 #: dashboards/project/routers/extensions/routerrules/forms.py:50 #: dashboards/project/routers/extensions/routerrules/tables.py:72 msgid ""Destination CIDR"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:34 #: dashboards/project/routers/extensions/extraroutes/tables.py:66 msgid ""Next Hop"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:45 msgid ""Static route added"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:50 #, python-format msgid ""Invalid format for routes : %s"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/forms.py:56 #, python-format msgid ""Failed to add route : %s"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/tables.py:28 #: dashboards/project/routers/templates/routers/extensions/routerroutes/_create.html:9 msgid ""Add Static Route"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/tables.py:43 msgid ""Delete Static Route"" msgid_plural ""Delete Static Routes"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/extraroutes/tables.py:51 msgid ""Deleted Static Route"" msgid_plural ""Deleted Static Routes"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/extraroutes/tabs.py:40 msgid ""Failed to check if Neutron extraroute extension is supported"" msgstr """" #: dashboards/project/routers/extensions/extraroutes/views.py:48 #: dashboards/project/routers/extensions/routerrules/views.py:50 #: dashboards/project/routers/ports/views.py:49 msgid ""Unable to retrieve router."" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:43 msgid ""Input must be in CIDR format"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:48 #: dashboards/project/routers/extensions/routerrules/tables.py:70 msgid ""Source CIDR"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:53 msgid ""Optional: Next Hop Addresses (comma delimited)"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:56 #: dashboards/project/routers/ports/forms.py:38 #: dashboards/project/routers/ports/forms.py:157 #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:19 msgid ""Router ID"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:63 msgid ""Permit"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:64 msgid ""Deny"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:73 msgid ""Unable to delete router rule."" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:88 msgid ""Router rule added"" msgstr """" #: dashboards/project/routers/extensions/routerrules/forms.py:93 #, python-format msgid ""Failed to add router rule %s"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tables.py:32 #: dashboards/project/routers/extensions/routerrules/views.py:37 #: dashboards/project/routers/templates/routers/extensions/routerrules/_create.html:9 #: dashboards/project/routers/templates/routers/extensions/routerrules/create.html:3 msgid ""Add Router Rule"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tables.py:47 msgid ""Delete Router Rule"" msgid_plural ""Delete Router Rules"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/routerrules/tables.py:55 msgid ""Deleted Router Rule"" msgid_plural ""Deleted Router Rules"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/extensions/routerrules/tables.py:74 msgid ""Next Hops"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tables.py:81 #: dashboards/project/routers/extensions/routerrules/tabs.py:32 msgid ""Router Rules"" msgstr """" #: dashboards/project/routers/extensions/routerrules/tabs.py:60 msgid ""Router Rules Grid"" msgstr """" #: dashboards/project/routers/templates/routers/_detail_overview.html:20#: dashboards/project/routers/templates/routers/_detail_overview.html:16#: dashboards/project/routers/templates/routers/_detail_overview.html:26 #: dashboards/project/routers/templates/routers/_detail_overview.html:53#: dashboards/project/routers/templates/routers/ports/_create.html:9 #: dashboards/project/routers/templates/routers/ports/create.html:3#: dashboards/project/routers/ports/tables.py:58#: dashboards/project/routers/ports/tables.py:66#: dashboards/project/routers/ports/views.py:68 #: dashboards/project/routers/tables.py:115 #: dashboards/project/routers/templates/routers/ports/_setgateway.html:9 #: dashboards/project/routers/templates/routers/ports/_setgateway.html:24 #: dashboards/project/routers/templates/routers/ports/setgateway.html:3 msgid ""Set Gateway"" msgstr """" #: dashboards/project/routers/tables.py:40 msgid ""Delete Router"" msgid_plural ""Delete Routers"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:48 msgid ""Deleted Router"" msgid_plural ""Deleted Routers"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:67 #: dashboards/project/routers/tables.py:75 #, python-format msgid ""Unable to delete router \""%s\"""" msgstr """" #: dashboards/project/routers/tables.py:106 #: dashboards/project/routers/views.py:175 msgid ""Edit Router"" msgstr """" #: dashboards/project/routers/tables.py:128 msgid """" ""You may reset the gateway later by using the set gateway action, but the "" ""gateway IP may change."" msgstr """" #: dashboards/project/routers/tables.py:134 msgid ""Clear Gateway"" msgid_plural ""Clear Gateways"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:142 msgid ""Cleared Gateway"" msgid_plural ""Cleared Gateways"" msgstr[0] """" msgstr[1] """" #: dashboards/project/routers/tables.py:158 #, python-format msgid ""Unable to clear gateway for router \""%(name)s\"": \""%(msg)s\"""" msgstr """" #: dashboards/project/routers/tables.py:200 msgctxt ""current status of router"" msgid ""Active"" msgstr """" #: dashboards/project/routers/tables.py:201 msgctxt ""current status of router"" msgid ""Error"" msgstr """" #: dashboards/project/routers/tables.py:204 msgctxt ""Admin state of a Router"" msgid ""UP"" msgstr """" #: dashboards/project/routers/tables.py:205 msgctxt ""Admin state of a Router"" msgid ""DOWN"" msgstr """" #. Translators: High Availability mode of Neutron router #: dashboards/project/routers/tables.py:221 msgid ""HA mode"" msgstr """" #: dashboards/project/routers/templates/routers/_create.html:6 msgid ""Creates a router with specified parameters."" msgstr """" #: dashboards/project/routers/templates/routers/_detail_overview.html:34 msgid ""External Fixed IPs"" msgstr """" #: dashboards/project/routers/templates/routers/_detail_overview.html:46 msgid ""SNAT"" msgstr """" #: dashboards/project/routers/templates/routers/_update.html:6 msgid ""You may update the editable properties of your router here."" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerroutes/_create.html:20 msgid ""Add static route to the router."" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerroutes/_create.html:21 msgid """" ""Next Hop IP must be a part of one of the subnets to which the router "" ""interfaces are connected."" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerroutes/_create.html:27 msgid ""Add route"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerroutes/create.html:3 #: dashboards/project/routers/templates/routers/extensions/routerroutes/create.html:6 msgid ""Add Router Route"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/_create.html:20 msgid """" ""Routing rules to apply to router. Rules are matched by most specific source "" ""first and then by most specific destination."" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/_create.html:21 msgid """" ""The next hop addresses can be used to override the router used by the client."" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/_create.html:27 msgid ""Add rule"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:11 msgid ""Router Rule Grid"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:18 msgid ""Reset to Default"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:24 msgid ""Source"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:30 #, python-format msgid ""Subnet: %(dest_subnetname)s"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:45 #, python-format msgid ""Subnet: %(row_source_subnetname)s"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:93 msgid ""Rule Conflict"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:96 msgid """" ""A more specific rule affects a portion of this traffic so a rule cannot be "" ""automatically generated to control the behavior of the entire source/"" ""destination combination."" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:98 msgid ""Conflicting Rule"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:99 msgid ""Source:"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:100 msgid ""Destination:"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:101 msgid ""Action:"" msgstr """" #: dashboards/project/routers/templates/routers/extensions/routerrules/grid.html:123 msgid """" ""The color and icon of an intersection indicates whether or not traffic is "" ""permitted from the source (row) to the destination (column).\n"" "" Clicking the <i class=\""fa fa-random\""></i> button in the intersection "" ""will install a rule to switch the traffic behavior.<br/>\n"" ""\n"" "" <b>Note:</b> Rules only affect one direction of traffic. The opposite "" ""direction is outlined when hovering over an intersection.\n"" "" "" msgstr """" #: dashboards/project/routers/templates/routers/ports/_create.html:20 msgid ""You can connect a specified subnet to the router."" msgstr """" #: dashboards/project/routers/templates/routers/ports/_create.html:23 msgid """" ""The default IP address of the interface created is a gateway of the selected "" ""subnet. You can specify another IP address of the interface here. You must "" ""select a subnet to which the specified IP address belongs to from the above "" ""list."" msgstr """" #: dashboards/project/routers/templates/routers/ports/_create.html:29 msgid ""Add interface"" msgstr """" #: dashboards/project/routers/templates/routers/ports/_setgateway.html:19 msgid """" ""You can connect a specified external network to the router. The external "" ""network is regarded as a default route of the router and the router acts as "" ""a gateway for external connectivity."" msgstr """" #: dashboards/project/routers/views.py:74 #, python-format msgid ""Unable to retrieve a list of external networks \""%s\""."" msgstr """" #: dashboards/project/routers/views.py:87 #, python-format msgid """" ""External network \""%(ext_net_id)s\"" expected but not found for router "" ""\""%(router_id)s\""."" msgstr """" #. Translators: The usage is ""<UUID of ext_net> (Not Found)"" #: dashboards/project/routers/views.py:95 #, python-format msgctxt ""External network not found"" msgid ""%s (Not Found)"" msgstr """" #: dashboards/project/routers/views.py:111 #, python-format msgid ""Unable to retrieve details for router \""%s\""."" msgstr """" #: dashboards/project/routers/views.py:122 #, python-format msgid ""Unable to retrieve an external network \""%s\""."" msgstr """" #: dashboards/project/routers/views.py:195 msgid ""Unable to retrieve router details."" msgstr """" #: dashboards/project/stacks/forms.py:56 #: dashboards/project/stacks/templates/stacks/select_template.html:3 #: dashboards/project/stacks/views.py:90 dashboards/project/stacks/views.py:96 #: dashboards/project/stacks/views.py:106#: dashboards/project/stacks/templates/stacks/preview_template.html:3""This is required for operations to be performed throughout the lifecycle of "" ""the stack""#: dashboards/project/stacks/templates/stacks/update.html:3#: dashboards/project/stacks/templates/stacks/index.html:3#: dashboards/project/stacks/resource_types/tables.py:26 msgid ""AWS compatible"" msgstr """" #: dashboards/project/stacks/resource_types/tables.py:34 msgid ""Implementation"" msgstr """" #: dashboards/project/stacks/resource_types/tables.py:36 msgid ""Component"" msgstr """" #: dashboards/project/stacks/resource_types/tables.py:38 #: dashboards/project/stacks/tables.py:312 #: dashboards/project/stacks/tables.py:362 msgid ""Resource"" msgstr """" #: dashboards/project/stacks/resource_types/templates/stacks.resource_types/_details.html:4 msgid ""Resource Type"" msgstr """" #: dashboards/project/stacks/resource_types/templates/stacks.resource_types/_details.html:12 msgid ""Attributes"" msgstr """" #: dashboards/project/stacks/resource_types/templates/stacks.resource_types/_details.html:18 msgid ""Properties"" msgstr """" #: dashboards/project/stacks/resource_types/templates/stacks.resource_types/details.html:3 #: dashboards/project/stacks/resource_types/views.py:49 msgid ""Resource Type Details"" msgstr """" #: dashboards/project/stacks/resource_types/views.py:41 msgid ""Unable to retrieve stack resource types."" msgstr """" #: dashboards/project/stacks/resource_types/views.py:58 msgid ""Unable to retrieve resource type details."" msgstr """" #: dashboards/project/stacks/templates/stacks/create.html:3#: dashboards/project/stacks/templates/stacks/preview.html:3#: dashboards/project/stacks/tables.py:55#: dashboards/project/stacks/tables.py:63#: dashboards/project/stacks/tables.py:80#: dashboards/project/stacks/tables.py:88#: dashboards/project/stacks/tables.py:105#: dashboards/project/stacks/tables.py:113#: dashboards/project/stacks/tables.py:137#: dashboards/project/stacks/tables.py:145#: dashboards/project/stacks/tables.py:198#: dashboards/project/stacks/tables.py:200#: dashboards/project/stacks/tables.py:202#: dashboards/project/stacks/tables.py:204#: dashboards/project/stacks/tables.py:206#: dashboards/project/stacks/tables.py:208#: dashboards/project/stacks/tables.py:210#: dashboards/project/stacks/tables.py:212#: dashboards/project/stacks/tables.py:214#: dashboards/project/stacks/tables.py:216#: dashboards/project/stacks/tables.py:218#: dashboards/project/stacks/tables.py:220#: dashboards/project/stacks/tables.py:222#: dashboards/project/stacks/tables.py:224#: dashboards/project/stacks/tables.py:226#: dashboards/project/stacks/tables.py:228#: dashboards/project/stacks/tables.py:230#: dashboards/project/stacks/tables.py:232#: dashboards/project/stacks/tables.py:234#: dashboards/project/stacks/tables.py:236#: dashboards/project/stacks/tables.py:238#: dashboards/project/stacks/tables.py:240#: dashboards/project/stacks/tables.py:242#: dashboards/project/stacks/tables.py:244#: dashboards/project/stacks/tables.py:246#: dashboards/project/stacks/tables.py:248#: dashboards/project/stacks/tables.py:250#: dashboards/project/stacks/tables.py:252#: dashboards/project/stacks/tables.py:254#: dashboards/project/stacks/tables.py:256#: dashboards/project/stacks/templates/stacks/_resource_overview.html:25#: dashboards/project/stacks/tabs.py:108#: dashboards/project/stacks/templates/stacks/_preview_details.html:42#: dashboards/project/stacks/tabs.py:136#: dashboards/project/stacks/templates/stacks/_change_template.html:6 #: dashboards/project/stacks/templates/stacks/_select_template.html:6 msgid """" ""Use one of the available template source options to specify the template to "" ""be used in creating this stack."" msgstr """" #: dashboards/project/stacks/templates/stacks/_create.html:5 msgid ""Create a new stack with the provided values."" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:3 msgid ""Stack Overview"" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:28 #, python-format msgid ""%(stack_status_title)s: %(stack_status_reason)s"" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:34 msgid ""Outputs"" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:48 msgid ""Stack Parameters"" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:59 msgid ""Launch Parameters"" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:63 msgid ""Minutes"" msgstr """" #: dashboards/project/stacks/templates/stacks/_detail_overview.html:64 msgid ""Rollback"" msgstr """" #: dashboards/project/stacks/templates/stacks/_preview.html:5 msgid ""Preview a new stack with the provided values."" msgstr """" #: dashboards/project/stacks/templates/stacks/_preview_details.html:5 msgid ""Stack Preview"" msgstr """" #: dashboards/project/stacks/templates/stacks/_preview_details.html:31 msgid ""Links"" msgstr """" #: dashboards/project/stacks/templates/stacks/_preview_template.html:6 msgid """" ""Use one of the available template source options to specify the template to "" ""be used in previewing this stack."" msgstr """" #: dashboards/project/stacks/templates/stacks/_resource_overview.html:3 msgid ""Resource Overview"" msgstr """" #: dashboards/project/stacks/templates/stacks/_resource_overview.html:9 msgid ""Stack Resource ID"" msgstr """" #: dashboards/project/stacks/templates/stacks/_resource_overview.html:13 msgid ""Resource ID"" msgstr """" #: dashboards/project/stacks/templates/stacks/_resource_overview.html:42 #, python-format msgid ""%(resource_status)s: %(resource_status_reason)s"" msgstr """" #: dashboards/project/stacks/templates/stacks/_resource_overview.html:48 msgid ""Resource Metadata"" msgstr """" #: dashboards/project/stacks/templates/stacks/_stack_template.html:3 msgid ""Stack Template"" msgstr """" #: dashboards/project/stacks/templates/stacks/_update.html:5 msgid """" ""Update a stack with the provided values. Please note that any encrypted "" ""parameters, such as passwords, will be reset to default if you do not change "" ""them here."" msgstr """" #: dashboards/project/stacks/templates/stacks/change_template.html:3 #: dashboards/project/stacks/views.py:113 msgid ""Change Template"" msgstr """" #: dashboards/project/stacks/templates/stacks/detail.html:3 msgid ""Stack Details"" msgstr """" #: dashboards/project/stacks/templates/stacks/preview_details.html:3 #: dashboards/project/stacks/views.py:255 msgid ""Preview Stack Details"" msgstr """" #: dashboards/project/stacks/templates/stacks/resource.html:3 msgid ""Resource Details"" msgstr """" ""Successfully restored backup %(backup_name)s to volume with id: %(volume_id)s""#: dashboards/project/volumes/backups/tables.py:49 #: dashboards/project/volumes/backups/tables.py:141 #: dashboards/project/volumes/tabs.py:127 msgid ""Volume Backups"" msgstr """" #: dashboards/project/volumes/backups/tables.py:108#: dashboards/project/volumes/backups/tables.py:110#: dashboards/project/volumes/backups/tables.py:112#: dashboards/project/volumes/backups/tables.py:114#: dashboards/project/volumes/backups/tables.py:116#: dashboards/project/volumes/backups/tables.py:118#: dashboards/project/volumes/templates/volumes/backups/create_backup.html:3#: dashboards/project/volumes/templates/volumes/backups/restore_backup.html:3#: dashboards/project/volumes/snapshots/tables.py:56#: dashboards/project/volumes/snapshots/tables.py:64#: dashboards/project/volumes/templates/volumes/snapshots/update.html:3#: dashboards/project/volumes/tabs.py:38 msgid ""Unable to retrieve volume list."" msgstr """" #: dashboards/project/volumes/tabs.py:48 msgid ""Unable to retrieve volume/instance attachment information"" msgstr """" #: dashboards/project/volumes/tabs.py:62 msgid ""Unable to retrieve snapshot list."" msgstr """" #: dashboards/project/volumes/tabs.py:144 msgid ""Unable to retrieve volume backups."" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_create_backup.html:5 msgid ""Volume Backup:"" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_create_backup.html:5 msgid """" ""Volume Backups are stored using the Object Storage service. You must have "" ""this service activated in order to create a backup."" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_create_backup.html:6 msgid """" ""If no container name is provided, a default container named volumebackups "" ""will be provisioned for you. Backups will be the same size as the volume "" ""they originate from."" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_detail_overview.html:5 #, python-format msgid ""Volume Backup Overview: %(backup_display_name)s"" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_restore_backup.html:5 msgid ""Restore Backup:"" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_restore_backup.html:5 msgid ""Select a volume to restore to."" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/_restore_backup.html:6 msgid ""Optionally, you may choose to create a new volume."" msgstr """" #: dashboards/project/volumes/templates/volumes/backups/detail.html:3 msgid ""Volume Backup Details"" msgstr """" #: dashboards/project/volumes/templates/volumes/snapshots/_update.html:6 msgid ""Modify the name and description of a snapshot."" msgstr """" #: dashboards/project/volumes/templates/volumes/snapshots/detail.html:3 msgid ""Volume Snapshot Details"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_accept_transfer.html:6 msgid """" ""Ownership of a volume can be transferred from one project to another. "" ""Accepting a transfer requires obtaining the Transfer ID and Authorization "" ""Key from the donor. This is equivalent to the <tt>cinder transfer-accept</"" ""tt> command."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_attach.html:9 msgid ""Attach To Instance"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_attach.html:18 msgid ""Attach Volume"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_create_snapshot.html:13 msgid ""Create Volume Snapshot (Force)"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_create_snapshot.html:15 #: dashboards/project/volumes/templates/volumes/volumes/create_snapshot.html:3 #: dashboards/project/volumes/volumes/views.py:141 msgid ""Create Volume Snapshot"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_create_transfer.html:6 msgid """" ""Ownership of a volume can be transferred from one project to another. Once a "" ""volume transfer is created in a donor project, it then can be \""accepted\"" "" ""by a recipient project. This is equivalent to the <tt>cinder transfer-"" ""create</tt> command."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:4 msgid ""Volume Overview"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:35 #: dashboards/project/volumes/volumes/tables.py:521 msgid ""Attachments"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:42 #, python-format msgid """" ""\n"" "" <a href=\""%(instance_url)s\"">%(instance_name)s</a> on %(device)s\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:48 msgid ""Not attached"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:55 #: dashboards/project/volumes/volumes/forms.py:85 msgid ""Volume Source"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_detail_overview.html:84 #: dashboards/project/volumes/volumes/views.py:249 msgid ""Volume Transfer"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:4 msgid ""Volume Encryption Overview"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:11 msgid ""Volume Type Name"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_encryption_detail_overview.html:25 msgid ""Volume is Unencrypted"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:5 msgid ""Extend the size of a volume."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:7 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:7 msgid ""Volume Limits"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_extend_limits.html:10 #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:10 msgid ""Total Gigabytes"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:5 msgid ""Volumes are block devices that can be attached to instances."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_limits.html:18 msgid ""Number of Volumes"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_retype.html:6 msgid """" ""\n"" "" Change the volume type of a volume after its creation.\n"" "" This is equivalent to the <tt>cinder retype</tt> command.\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_retype.html:11 msgid """" ""\n"" "" The \""Volume Type\"" selected must be different from the current volume "" ""type.\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_retype.html:15 msgid """" ""\n"" "" The \""Migration Policy\"" is only used if the volume retype cannot be\n"" "" completed. If the \""Migration Policy\"" is \""On Demand\"", the back end "" ""will\n"" "" perform volume migration. Note that migration may take a significant\n"" "" amount of time to complete, in some cases hours.\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_show_transfer.html:6 msgid """" ""The Transfer ID and the Authorization Key are needed by the recipient in "" ""order to accept the transfer. Please capture both the Transfer ID and the "" ""Authorization Key and provide them to your transfer recipient."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_show_transfer.html:7 msgid """" ""The Authorization Key will not be available after closing this page, so you "" ""must capture it now, or else you will be unable to use the transfer."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_snapshot_limits.html:5 msgid ""From here you can create a snapshot of a volume."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_snapshot_limits.html:9 msgid ""Snapshot Limits"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_snapshot_limits.html:21 msgid ""Number of Snapshots"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_update.html:6 msgid ""Modify name and description of a volume."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_update.html:7 msgid """" ""The \""Bootable\"" flag specifies that this volume can be used to launch an "" ""instance."" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_upload_to_image.html:6 msgid """" ""\n"" "" Upload the volume to the Image Service as an image.\n"" "" This is equivalent to the <tt>cinder upload-to-image</tt> command.\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_upload_to_image.html:11 msgid """" ""\n"" "" Choose \""Disk Format\"" for the image. The volume images are created "" ""with\n"" "" the QEMU disk image utility.\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/_upload_to_image.html:17 msgid """" ""\n"" "" When the volume status is \""in-use\"", you can use \""Force\"" to "" ""upload the\n"" "" volume to an image.\n"" "" "" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/accept_transfer.html:3 #: dashboards/project/volumes/volumes/views.py:237 #: dashboards/project/volumes/volumes/views.py:238 #: dashboards/project/volumes/volumes/views.py:241 msgid ""Accept Volume Transfer"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/attach.html:3 #: dashboards/project/volumes/volumes/views.py:320 #: dashboards/project/volumes/volumes/views.py:325 msgid ""Manage Volume Attachments"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/create_transfer.html:3 #: dashboards/project/volumes/volumes/views.py:216 #: dashboards/project/volumes/volumes/views.py:217 msgid ""Create Volume Transfer"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/encryption_detail.html:3 msgid ""Volume Encryption Details"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/extend.html:3 #: dashboards/project/volumes/volumes/tables.py:133 #: dashboards/project/volumes/volumes/views.py:100 #: dashboards/project/volumes/volumes/views.py:102 #: dashboards/project/volumes/volumes/views.py:105 msgid ""Extend Volume"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/retype.html:3 #: dashboards/project/volumes/volumes/tables.py:244 #: dashboards/project/volumes/volumes/views.py:394 #: dashboards/project/volumes/volumes/views.py:396 #: dashboards/project/volumes/volumes/views.py:399 msgid ""Change Volume Type"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/show_transfer.html:3 #: dashboards/project/volumes/volumes/views.py:252 msgid ""Volume Transfer Details"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/update.html:3 #: dashboards/project/volumes/volumes/tables.py:232 #: dashboards/project/volumes/volumes/views.py:283 #: dashboards/project/volumes/volumes/views.py:288 msgid ""Edit Volume"" msgstr """" #: dashboards/project/volumes/templates/volumes/volumes/upload_to_image.html:3 #: dashboards/project/volumes/volumes/views.py:174 #: dashboards/project/volumes/volumes/views.py:179 msgid ""Upload Volume to Image"" msgstr """" #: dashboards/project/volumes/utils.py:28 msgid ""Unable to retrieve volumes availability zones."" msgstr """" msgid """" ""Volume size must be equal to or greater than the origin volume size (%s)""""A volume of %(req)iGB cannot be created as you only have %(avail)iGB of your "" ""quota available.""""Actual device name may differ due to hypervisor settings. If not specified, "" ""then hypervisor will select a device name.""#: dashboards/project/volumes/volumes/forms.py:644#: dashboards/project/volumes/volumes/forms.py:679msgid """" ""Successfully sent the request to upload volume to image for volume: \""%s\""""#: dashboards/project/volumes/volumes/forms.py:687""Volume cannot be extended to %(req)iGB as you only have %(avail)iGB of your "" ""quota available.""#: dashboards/project/volumes/volumes/forms.py:774#: dashboards/project/volumes/volumes/forms.py:790""Successfully sent the request to change the volume type to \""%(vtype)s\"" for "" ""volume: \""%(name)s\""""#: dashboards/project/volumes/volumes/forms.py:800#: dashboards/project/volumes/volumes/tables.py:69#: dashboards/project/volumes/volumes/tables.py:77#: dashboards/project/volumes/volumes/tables.py:373#: dashboards/project/volumes/volumes/tables.py:377#: dashboards/project/volumes/volumes/tables.py:379#: dashboards/project/volumes/volumes/tables.py:381#: dashboards/project/volumes/volumes/tables.py:383#: dashboards/project/volumes/volumes/tables.py:385#: dashboards/project/volumes/volumes/tables.py:387#: dashboards/project/volumes/volumes/tables.py:389#: dashboards/project/volumes/volumes/tables.py:391#: dashboards/project/volumes/volumes/tables.py:393#: dashboards/project/volumes/volumes/tables.py:465#: dashboards/project/volumes/volumes/tables.py:474""This volume is currently attached to an instance. In some cases, creating a "" ""snapshot from an attached volume can result in a corrupted snapshot.""#: dashboards/project/volumes/volumes/views.py:188 #: dashboards/project/volumes/volumes/views.py:408#: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:18 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:18#: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:21 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:24#: dashboards/project/vpn/forms.py:86 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:24 #: dashboards/project/vpn/workflows.py:119#: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:33 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:33#: dashboards/project/vpn/forms.py:109 #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:36 #: dashboards/project/vpn/workflows.py:129#: dashboards/project/vpn/forms.py:158 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:21 #: dashboards/project/vpn/workflows.py:220#: dashboards/project/vpn/forms.py:187 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:36 #: dashboards/project/vpn/workflows.py:232#: dashboards/project/vpn/forms.py:230 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:31 #: dashboards/project/vpn/workflows.py:328#: dashboards/project/vpn/forms.py:236 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:34 #: dashboards/project/vpn/workflows.py:334""Peer router identity for authentication. Can be IPv4/IPv6 address, e-mail, "" ""key ID, or FQDN""""Remote peer subnet(s) address(es) with mask(s) in CIDR format separated with "" ""commas if needed (e.g. 20.1.0.0/24, 21.1.0.0/24)""""Equal to or greater than 68 if the local subnet is IPv4. Equal to or greater "" ""than 1280 if the local subnet is IPv6.""#: dashboards/project/vpn/forms.py:269 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:56 #: dashboards/project/vpn/workflows.py:422#: dashboards/project/vpn/forms.py:274 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:59 #: dashboards/project/vpn/workflows.py:427#: dashboards/project/vpn/forms.py:277 #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:50 #: dashboards/project/vpn/workflows.py:431#: dashboards/project/vpn/tables.py:69#: dashboards/project/vpn/tables.py:77#: dashboards/project/vpn/tables.py:95#: dashboards/project/vpn/tables.py:103#: dashboards/project/vpn/tables.py:121#: dashboards/project/vpn/tables.py:129#: dashboards/project/vpn/tables.py:147#: dashboards/project/vpn/tables.py:155#: dashboards/project/vpn/tables.py:163 #: dashboards/project/vpn/templates/vpn/update_vpnservice.html:3 #: dashboards/project/vpn/views.py:274 dashboards/project/vpn/views.py:280#: dashboards/project/vpn/tables.py:179 #: dashboards/project/vpn/templates/vpn/update_ikepolicy.html:3 #: dashboards/project/vpn/views.py:310 dashboards/project/vpn/views.py:316#: dashboards/project/vpn/tables.py:193 #: dashboards/project/vpn/templates/vpn/update_ipsecpolicy.html:3 #: dashboards/project/vpn/views.py:353 dashboards/project/vpn/views.py:359#: dashboards/project/vpn/tables.py:230#: dashboards/project/vpn/tables.py:232#: dashboards/project/vpn/tables.py:234#: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:19#: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:23#: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:27#: dashboards/project/vpn/tables.py:269#: dashboards/project/vpn/tables.py:271#: dashboards/project/vpn/tables.py:273#: dashboards/project/vpn/tables.py:275#: dashboards/project/vpn/tables.py:277#: dashboards/project/vpn/tables.py:279#: dashboards/project/vpn/tables.py:281#: dashboards/project/vpn/tables.py:283#: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:27 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:27 msgid ""Lifetime Units"" msgstr """" #: dashboards/project/vpn/templates/vpn/_ikepolicy_details.html:30 #: dashboards/project/vpn/templates/vpn/_ipsecpolicy_details.html:30 msgid ""Lifetime Value"" msgstr """" #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:37 msgid ""Remote peer subnet"" msgstr """" #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:44 msgid ""Pre-Shared Key string"" msgstr """" #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:53 msgid ""Dead peer detection action"" msgstr """" #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:62 msgid ""Authorization mode"" msgstr """" #: dashboards/project/vpn/templates/vpn/_ipsecsiteconnection_details.html:65 msgid ""Route mode"" msgstr """" #: dashboards/project/vpn/templates/vpn/_update_ikepolicy.html:6 msgid ""You may update IKE Policy details here."" msgstr """" #: dashboards/project/vpn/templates/vpn/_update_ipsecpolicy.html:6 msgid ""You may update IPSec Policy details here."" msgstr """" #: dashboards/project/vpn/templates/vpn/_update_ipsecsiteconnection.html:6 msgid ""You may update IPSec Site Connection details here."" msgstr """" #: dashboards/project/vpn/templates/vpn/_update_vpnservice.html:6 msgid ""You may update VPN Service details here."" msgstr """" #: dashboards/project/vpn/templates/vpn/_vpnservice_details.html:27 msgid ""VPN Connections"" msgstr """" #: dashboards/project/vpn/templates/vpn/details_tabs.html:3 #: dashboards/project/vpn/templates/vpn/index.html:3#: dashboards/project/vpn/templates/vpn/update_ipsecsiteconnection.html:3 #: dashboards/project/vpn/views.py:395 dashboards/project/vpn/views.py:401 msgid ""Edit IPSec Site Connection"" msgstr """" ""Specify a name, description, router, and subnet for the VPN Service. Admin "" ""State is Up (checked) by default.""""Assign a name and description for the IPSec Site Connection. All fields in "" ""this tab are required.""""Fields in this tab are optional. You can configure the detail of IPSec site "" ""connection created.""#: dashboards/router/nexus1000v/templates/nexus1000v/create_network_profile.html:3#: dashboards/router/nexus1000v/tables.py:39#: dashboards/router/nexus1000v/tables.py:47#: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:6 msgid ""Name:"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:6 msgid "" Select a name for your network profile."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:7 msgid ""Segment Type:"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:7 msgid "" Segment types available are VLAN, Overlay and Trunk."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:8 msgid ""Segment Sub Type:"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:8 msgid """" "" Sub types available are for the Overlay and Trunk segments. Available sub-"" ""types for Overlay are: Native-VXLAN, Enhanced-VXLAN or 'Other' (eg. GRE) "" ""which can be manually inputed as a text parameter for subtype. Available sub-"" ""type for Trunk is: VLAN."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:9 msgid ""Segment Range:"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_create_network_profile.html:9 msgid """" "" Segment Ranges are 1-4093 for VLAN and above 5000 for Enhanced-VXLAN "" ""Overlay."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/_update_network_profile.html:6 msgid """" ""Edit the network profile to update name, segment range or multicast IP range."" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/index.html:3 #: dashboards/router/nexus1000v/templates/nexus1000v/network_profile/index.html:3 #: dashboards/router/nexus1000v/templates/nexus1000v/policy_profile/index.html:3 msgid ""Cisco Nexus 1000V Networking"" msgstr """" #: dashboards/router/nexus1000v/templates/nexus1000v/update_network_profile.html:3 #: dashboards/router/nexus1000v/views.py:125 msgid ""Update Network Profile"" msgstr """" #: dashboards/settings/password/templates/password/_change.html:6 msgid ""Change your password. We highly recommend you create a strong one. "" msgstr """" #. Translators: UTC offset and timezone label#: dashboards/settings/user/panel.py:23 #: dashboards/settings/user/templates/user/settings.html:3 #: dashboards/settings/user/views.py:27 dashboards/settings/user/views.py:29#: dashboards/settings/user/templates/user/_settings.html:6 msgid ""Modify dashboard settings for your user.""#: settings.py:80 msgid ""Select format""#: settings.py:81 msgid ""AKI - Amazon Kernel Image""#: settings.py:82 msgid ""AMI - Amazon Machine Image""#: settings.py:83 msgid ""ARI - Amazon Ramdisk Image""#: settings.py:84 msgid ""Docker""#: settings.py:85 msgid ""ISO - Optical Disk Image""#: settings.py:86 msgid ""OVA - Open Virtual Appliance""#: settings.py:87 msgid ""QCOW2 - QEMU Emulator""#: settings.py:88 msgid ""Raw""#: settings.py:89 msgid ""VDI - Virtual Disk Image""#: settings.py:90 msgid ""VHD - Virtual Hard Disk""#: settings.py:91 msgid ""VMDK - Virtual Machine Disk""#: settings.py:239 msgid ""All TCP""#: settings.py:245 msgid ""All UDP"" msgstr """" #: settings.py:251 msgid ""All ICMP"" msgstr """" #: templates/403.html:5 templates/403.html.py:10#: templates/403.html:11"" privileges to access this content. If you believe this message to\n""""An unexpected error has occurred. Try refreshing the page. If that doesn't "" ""help, contact your local administrator.""""Invalid time period. The end date should be more recent than the start date.""""Invalid time period. You are requesting data from the future which may not "" ""exist.""msgid """" ""Total VCPU usage (Number of VCPU in instance * Hours Used) for the project""",21130,19518
openstack%2Fheat~master~I4c69d7a8e52655f354d9a1feea81e6744a626f8a,openstack/heat,master,I4c69d7a8e52655f354d9a1feea81e6744a626f8a,Convergence resource operations,MERGED,2015-03-10 18:49:33.000000000,2015-06-11 04:07:58.000000000,2015-06-11 04:07:56.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6899}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 9751}, {'_account_id': 10487}, {'_account_id': 11424}]","[{'number': 1, 'created': '2015-03-10 18:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cae92678073aeb973d9869f44cc75f53dfb447d5', 'message': 'Convergence resource operations\n\nUpdates convergence worker with RPC methods for resource\ncreate/update/delete actions\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\nImplements: blueprint convergence-resource-operations\n'}, {'number': 2, 'created': '2015-05-28 11:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/353d7780f87ff6634d8bcf272e63c79ef9caeb42', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 3, 'created': '2015-05-29 06:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/06a2bcde32761a9862c863b5a34cf561c1cf5545', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 4, 'created': '2015-06-03 11:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/61106a9c2d68a3deadb957e0bf147914a4324643', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 5, 'created': '2015-06-08 05:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9fd2c70628319dcf08fddd8cc8a3734b26580f14', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 6, 'created': '2015-06-08 05:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/64e577933bcbd3c675da8d48b6f9304f00f11eb5', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 7, 'created': '2015-06-09 06:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4e5bf8c8f38df5197f5c5d08b69b436aafcfc91c', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 8, 'created': '2015-06-10 06:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/037e7cd4f80aa30715fe3e72cb172675e8273fca', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}, {'number': 9, 'created': '2015-06-10 10:19:30.000000000', 'files': ['heat/tests/test_engine_worker.py', 'heat/engine/worker.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c577ee502063368b9a7bde7bee745f88ba86ac4b', 'message': 'Convergence resource operations\n\nUpdates enging resource module with required\nwrapper functions for supporting convergence.\n\nImplements: blueprint convergence-resource-operations\n\nChange-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a\n'}]",36,163132,c577ee502063368b9a7bde7bee745f88ba86ac4b,63,11,9,10487,,,0,"Convergence resource operations

Updates enging resource module with required
wrapper functions for supporting convergence.

Implements: blueprint convergence-resource-operations

Change-Id: I4c69d7a8e52655f354d9a1feea81e6744a626f8a
",git fetch https://review.opendev.org/openstack/heat refs/changes/32/163132/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/worker.py'],1,cae92678073aeb973d9869f44cc75f53dfb447d5,bp/convergence-resource-operations,"from heat.common import context from heat.common import exceptionfrom heat.common.i18n import _from heat.engine import resource from heat.engine import scheduler from heat.engine import stack @context.request_context def create_resource(self, ctxt, **kwargs ): stack_id = kwargs.get('stack_id'); resource_name = kwargs.get('resource_name') if stack_id is None or resource_name is None: raise exception.Invalid( reason=_('Internal engine error, ' 'stack id or resource name is missing') ) # create the stack object s = stack.Stack.load(stack_id=stack_id) # get resource definition from template r_dfn = s.t.resource_definitions(s)[resource_name] # create Resource object r = resource.Resource(resource_name, r_dfn, s) # validate and start creation task runner r.validate() creator = scheduler.TaskRunner( r.create) creator(timeout=s.timeout_secs())",,35,0
openstack%2Fhorizon~master~I4ec2687cc208e61b2be00dc86e42f95fa8a1a363,openstack/horizon,master,I4ec2687cc208e61b2be00dc86e42f95fa8a1a363,corrected the wrong url in admin instance detail,MERGED,2015-06-09 09:08:40.000000000,2015-06-11 04:03:46.000000000,2015-06-11 04:03:44.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 13785}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-09 09:08:40.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html', 'openstack_dashboard/dashboards/admin/instances/views.py', 'openstack_dashboard/dashboards/project/instances/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/863f7fcd067efd2bfbd58cc7829953768c2a6685', 'message': 'corrected the wrong url in admin instance detail\n\nIn admin instance detail page, the image url pointing to image detail page in project panel.\n\nThis behavior is wrong, it should be link to admin panel only.\n\nThis patch corrected the url to point to the admin panel image detail page.\n\nChange-Id: I4ec2687cc208e61b2be00dc86e42f95fa8a1a363\nCloses-Bug: #1463312\n'}]",0,189601,863f7fcd067efd2bfbd58cc7829953768c2a6685,8,7,1,10442,,,0,"corrected the wrong url in admin instance detail

In admin instance detail page, the image url pointing to image detail page in project panel.

This behavior is wrong, it should be link to admin panel only.

This patch corrected the url to point to the admin panel image detail page.

Change-Id: I4ec2687cc208e61b2be00dc86e42f95fa8a1a363
Closes-Bug: #1463312
",git fetch https://review.opendev.org/openstack/horizon refs/changes/01/189601/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/templates/instances/_detail_overview.html', 'openstack_dashboard/dashboards/admin/instances/views.py', 'openstack_dashboard/dashboards/project/instances/views.py']",3,863f7fcd067efd2bfbd58cc7829953768c2a6685,bug/1463312," image_url = 'horizon:project:images:images:detail' if instance.image: instance.image_url = reverse(self.image_url, args=[instance.image['id']])",,6,2
openstack%2Fironic~master~I02211da5fad039dc7e6b509d547e473e9b57009b,openstack/ironic,master,I02211da5fad039dc7e6b509d547e473e9b57009b,Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers,MERGED,2015-02-27 07:18:24.000000000,2015-06-11 04:01:11.000000000,2015-06-11 02:17:01.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6637}, {'_account_id': 6697}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9315}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 10662}, {'_account_id': 11655}, {'_account_id': 12081}, {'_account_id': 12356}, {'_account_id': 13997}, {'_account_id': 16628}]","[{'number': 1, 'created': '2015-02-27 07:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e9756706e489b9050430f0e32b9823b1eb90e292', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver.\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 2, 'created': '2015-02-27 09:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a62beaaa7600b4559fa0184800e9d4522f51d9f2', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 3, 'created': '2015-02-27 10:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7623488b47200335ce18dbc6c18cd7662ed5fc36', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 4, 'created': '2015-03-12 06:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/af176b3b33c915b5382e5652016273fe81ed647c', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 5, 'created': '2015-03-12 07:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b96983bebaa62e07b8b3af788bea3c77158757b3', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 6, 'created': '2015-03-12 08:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/73e089dcfe0e391964ff0f288d76ed3e58bfb1bd', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 7, 'created': '2015-03-12 08:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/20e488f384fe181a47bdafac3f25dbc6aae208ab', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers using pxe_ucs driver\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 8, 'created': '2015-03-12 09:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2ee4488c1644b2a190a9eee43b95032d02299604', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers.\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 9, 'created': '2015-03-12 11:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c01841686d8281f953b1cef9d1ba9659eeaccdaf', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 10, 'created': '2015-03-13 05:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a3a3c545acbf06f5fb9aad5551784e0b5f8a3dad', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 11, 'created': '2015-03-16 10:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/344a5f1045c30cf212caae6831f4a19360a8e9e1', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 12, 'created': '2015-03-17 11:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b57889a60991f90f1b43882ee053ccf828171101', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 13, 'created': '2015-03-17 17:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/932824cbd1b60b67466228d84e1781cecbbfbbdd', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 14, 'created': '2015-03-18 06:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b7af40031614f5842ad8e5b1300de724aed48c90', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 15, 'created': '2015-04-22 11:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/571a7a29a6ffef1a5f0b0aa035324a09aed062b1', 'message': 'Add pxe_ucs driver to manage Cisco UCS servers\n\nThis commit adds pxe_ucs driver changes. Adds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 16, 'created': '2015-04-29 10:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/049e1aa3af32949780176f609b17925997957f4f', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 17, 'created': '2015-05-04 10:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3dd6fd20f023c1b16b9946cbbcea110ee82aefd9', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 18, 'created': '2015-05-06 13:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dadd569c33d9ecf7f1099cff2b357f5db7e3b5dd', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 19, 'created': '2015-05-06 17:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/944daa84fbc65159e5e51f10d0b10ac14012e658', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 20, 'created': '2015-05-07 05:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52ad9c4d39597a31b396711bf24351b83ea8dc41', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 21, 'created': '2015-05-14 22:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3b870e38b24bcd5df980701ca5638a15cb53fa12', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 22, 'created': '2015-05-28 10:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0290acc8daf1d3b06d69e612f6e593b51410d850', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 23, 'created': '2015-05-28 10:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1df6ee545fde14bb5d71f2f766cb166b873b591d', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 24, 'created': '2015-05-28 10:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8d2e8ea55fe446d7c3e101d5fa49395fbdf387d6', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 25, 'created': '2015-06-09 05:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b1c1dc8dd995329999b08bd0d30bd08c7326e3a1', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 26, 'created': '2015-06-09 06:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/02c8adf1c27a3d8bd2b693c66ee6a4afae492a9c', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 27, 'created': '2015-06-09 10:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9089c91e8a9b3d5ec1033fa0cf6ede909f497ffc', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}, {'number': 28, 'created': '2015-06-10 13:47:12.000000000', 'files': ['ironic/drivers/modules/ucs/management.py', 'ironic/tests/db/utils.py', 'ironic/drivers/modules/ucs/__init__.py', 'ironic/tests/drivers/ucs/test_helper.py', 'doc/source/drivers/ucs.rst', 'ironic/drivers/fake.py', 'ironic/tests/drivers/ucs/test_management.py', 'ironic/drivers/pxe.py', 'ironic/tests/drivers/ucs/test_power.py', 'ironic/common/exception.py', 'ironic/drivers/modules/ucs/helper.py', 'etc/ironic/ironic.conf.sample', 'ironic/drivers/agent.py', 'ironic/tests/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/ucs/power.py', 'driver-requirements.txt', 'doc/source/deploy/drivers.rst', 'ironic/tests/drivers/ucs/__init__.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8c26a8c33ba2589f8cec74ec3914fd5e2505b07f', 'message': 'Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers\n\nThis commit adds pxe_ucs, agent_ucs driver changes.\nAdds support for the following:\n\n- Power driver changes\n- Management interface changes\n- UCS Helper code, which can be reused with other parts of the driver,\n  ex: to support vendor apis.\n\nChange-Id: I02211da5fad039dc7e6b509d547e473e9b57009b\nImplements: blueprint cisco-ucs-pxe-driver\n'}]",613,159734,8c26a8c33ba2589f8cec74ec3914fd5e2505b07f,193,17,28,10662,,,0,"Add pxe_ucs and agent_ucs drivers to manage Cisco UCS servers

This commit adds pxe_ucs, agent_ucs driver changes.
Adds support for the following:

- Power driver changes
- Management interface changes
- UCS Helper code, which can be reused with other parts of the driver,
  ex: to support vendor apis.

Change-Id: I02211da5fad039dc7e6b509d547e473e9b57009b
Implements: blueprint cisco-ucs-pxe-driver
",git fetch https://review.opendev.org/openstack/ironic refs/changes/34/159734/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/ucs/management.py', 'ironic/tests/db/utils.py', 'ironic/drivers/modules/ucs/__init__.py', 'ironic/tests/drivers/ucs/test_helper.py', 'doc/source/drivers/ucs.rst', 'ironic/drivers/fake.py', 'ironic/tests/drivers/ucs/test_management.py', 'ironic/drivers/pxe.py', 'ironic/tests/drivers/ucs/test_power.py', 'ironic/drivers/modules/ucs/helper.py', 'etc/ironic/ironic.conf.sample', 'ironic/tests/drivers/third_party_driver_mocks.py', 'ironic/drivers/modules/ucs/power.py', 'driver-requirements.txt', 'ironic/drivers/modules/ucs/constants.py', 'ironic/tests/drivers/ucs/__init__.py', 'setup.cfg']",17,e9756706e489b9050430f0e32b9823b1eb90e292,bp/cisco-ucs-pxe-driver, pxe_ucs = ironic.drivers.pxe:PXEAndUcsDriver fake_ucs = ironic.drivers.fake:FakeUcsDriver,,1290,0
openstack%2Fceilometer~master~Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858,openstack/ceilometer,master,Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858,Use oslo_db instead of deprecated oslo.db,ABANDONED,2015-01-12 11:28:50.000000000,2015-06-11 03:56:43.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}]","[{'number': 1, 'created': '2015-01-12 11:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4073b4d7169e07f5c6a5e6cf65efa8c6ee7c4ad1', 'message': 'Use oslo_db instead of deprecated oslo.db\n\nChange-Id: Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858\n'}, {'number': 2, 'created': '2015-01-14 10:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/21383cb347b4ccee573f7ace0cfe1eb19da2bd5e', 'message': 'Use oslo_db instead of deprecated oslo.db\n\nChange-Id: Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858\n'}, {'number': 3, 'created': '2015-01-15 12:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bc7a3d0f97ba70b7d74add1bd547c593ece2d1ee', 'message': 'Use oslo_db instead of deprecated oslo.db\n\nChange-Id: Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858\n'}, {'number': 4, 'created': '2015-01-16 10:57:22.000000000', 'files': ['requirements.txt', 'ceilometer/tests/test_collector.py', 'ceilometer/alarm/storage/impl_sqlalchemy.py', 'ceilometer/storage/__init__.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/storage/impl_sqlalchemy.py', 'requirements-py3.txt', 'ceilometer/event/storage/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1e5cca2386746952b41674c321c23eba0b7907f1', 'message': 'Use oslo_db instead of deprecated oslo.db\n\nChange-Id: Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858\n'}]",0,146424,1e5cca2386746952b41674c321c23eba0b7907f1,25,9,4,3012,,,0,"Use oslo_db instead of deprecated oslo.db

Change-Id: Ic825864a5c3b06c5a0ab5de36e98b4c32d80e858
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/24/146424/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/test_collector.py', 'ceilometer/alarm/storage/impl_sqlalchemy.py', 'ceilometer/storage/__init__.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/event/storage/impl_sqlalchemy.py']",6,4073b4d7169e07f5c6a5e6cf65efa8c6ee7c4ad1,use-oslo_db,from oslo_db import exception as dbexc from oslo_db.sqlalchemy import session as db_session from oslo_db.sqlalchemy import migration,from oslo.db import exception as dbexc from oslo.db.sqlalchemy import session as db_session from oslo.db.sqlalchemy import migration,14,14
openstack%2Fsenlin~master~Ia6b76322043a568fd46c67cf42d52e0e1137a096,openstack/senlin,master,Ia6b76322043a568fd46c67cf42d52e0e1137a096,Sync requirements versions,MERGED,2015-06-11 00:38:46.000000000,2015-06-11 03:54:22.000000000,2015-06-11 03:54:22.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-11 00:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/86394fa925a39f8ca8b998c91190ce0e6418f96b', 'message': 'Sync requirements versions\n\nWe have to do this every time, before our request is approved.\n\nChange-Id: Ia6b76322043a568fd46c67cf42d52e0e1137a096\n'}, {'number': 2, 'created': '2015-06-11 00:44:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin/commit/60c786c98bfb4db7e7f34712e1cac57d175448e1', 'message': 'Sync requirements versions\n\nWe have to do this every time, before our request is approved.\n\nChange-Id: Ia6b76322043a568fd46c67cf42d52e0e1137a096\n'}]",0,190424,60c786c98bfb4db7e7f34712e1cac57d175448e1,7,2,2,8246,,,0,"Sync requirements versions

We have to do this every time, before our request is approved.

Change-Id: Ia6b76322043a568fd46c67cf42d52e0e1137a096
",git fetch https://review.opendev.org/openstack/senlin refs/changes/24/190424/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,86394fa925a39f8ca8b998c91190ce0e6418f96b,requirements,"SQLAlchemy>=0.9.7,<1.1.0","SQLAlchemy>=0.9.7,<=0.9.99",1,1
openstack%2Fsenlin~master~If200d375d6505237a3aa4b266ece3e69871d4474,openstack/senlin,master,If200d375d6505237a3aa4b266ece3e69871d4474,Remove UPDATE_CANCELLED cluster state,MERGED,2015-06-11 00:55:46.000000000,2015-06-11 03:53:50.000000000,2015-06-11 03:53:48.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-11 00:55:46.000000000', 'files': ['senlin/engine/cluster.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/1965a14a5d7a5893366d5f9a9d103beef43497af', 'message': ""Remove UPDATE_CANCELLED cluster state\n\nThis state doesn't make sense. When a cluster update is cancelled, we\ncan put the cluster in ERROR or WARNING status, depending on the\nseverity of errors detected.\n\nChange-Id: If200d375d6505237a3aa4b266ece3e69871d4474\n""}]",0,190441,1965a14a5d7a5893366d5f9a9d103beef43497af,6,2,1,8246,,,0,"Remove UPDATE_CANCELLED cluster state

This state doesn't make sense. When a cluster update is cancelled, we
can put the cluster in ERROR or WARNING status, depending on the
severity of errors detected.

Change-Id: If200d375d6505237a3aa4b266ece3e69871d4474
",git fetch https://review.opendev.org/openstack/senlin refs/changes/41/190441/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/engine/cluster.py'],1,1965a14a5d7a5893366d5f9a9d103beef43497af,remove-cluster-state," INIT, ACTIVE, DELETED, CREATING, UPDATING, DELETING, CRITICAL, ERROR, WARNING, 'INIT', 'ACTIVE', 'DELETED', 'CREATING', 'UPDATING', 'DELETING', 'CRITICAL', 'ERROR', 'WARNING',"," INIT, CREATING, ACTIVE, ERROR, CRITICAL, DELETING, DELETED, WARNING, UPDATING, UPDATE_CANCELLED, 'INIT', 'CREATING', 'ACTIVE', 'ERROR', 'CRITICAL', 'DELETING', 'DELETED', 'WARNING', 'UPDATING', 'UPDATE_CANCELLED',",4,4
openstack%2Fkeystonemiddleware~master~I8601cd7ff9cea778911cbfc306dc03089530bc9d,openstack/keystonemiddleware,master,I8601cd7ff9cea778911cbfc306dc03089530bc9d,Refactor request methods onto request object,MERGED,2015-05-06 03:32:27.000000000,2015-06-11 03:45:27.000000000,2015-06-11 03:45:25.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 13063}, {'_account_id': 16803}]","[{'number': 1, 'created': '2015-05-06 03:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/e2c0433abee3321109d01aaf4ea6b84a2588d8dc', 'message': 'Refactor request methods onto request object\n\nTake advantage of webob Request objects to move methods that deal with\nmanipulating the request onto the request.\n\nChange-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d\n'}, {'number': 2, 'created': '2015-05-06 23:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4ddc07ae1cfa63c138580adada69eefca001f0a6', 'message': 'Refactor request methods onto request object\n\nTake advantage of webob Request objects to move methods that deal with\nmanipulating the request onto the request.\n\nChange-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d\n'}, {'number': 3, 'created': '2015-05-07 01:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/70b4154a55eab4046b14aeb5b17eaee3ff1c3532', 'message': 'Refactor request methods onto request object\n\nTake advantage of webob Request objects to move methods that deal with\nmanipulating the request onto the request.\n\nChange-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d\n'}, {'number': 4, 'created': '2015-06-03 22:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/cc675ab91dd5af411fe37b64510ebf75dc4d7f8f', 'message': 'Refactor request methods onto request object\n\nTake advantage of webob Request objects to move methods that deal with\nmanipulating the request onto the request.\n\nChange-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d\n'}, {'number': 5, 'created': '2015-06-08 12:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f0c6b74c3630259ac00c212c5bbd02716510f1bd', 'message': ""Refactor request methods onto request object\n\nTake advantage of webob Request objects to move methods that deal with\nmanipulating the request onto the request.\n\nThis removes a debug statement that prints a static list of headers that\nwill be removed because we no longer keep the static list. This list was\nnot really useful to debugging as the list doesn't change.\n\nChange-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d\n""}, {'number': 6, 'created': '2015-06-10 03:20:47.000000000', 'files': ['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py', 'keystonemiddleware/auth_token/_request.py', 'keystonemiddleware/tests/unit/auth_token/test_request.py', 'keystonemiddleware/auth_token/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/9fd39860899921689357f3238862c995a6d20d23', 'message': ""Refactor request methods onto request object\n\nTake advantage of webob Request objects to move methods that deal with\nmanipulating the request onto the request.\n\nThis removes a debug statement that prints a static list of headers that\nwill be removed because we no longer keep the static list. This list was\nnot really useful to debugging as the list doesn't change.\n\nChange-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d\n""}]",32,180394,9fd39860899921689357f3238862c995a6d20d23,23,6,6,7191,,,0,"Refactor request methods onto request object

Take advantage of webob Request objects to move methods that deal with
manipulating the request onto the request.

This removes a debug statement that prints a static list of headers that
will be removed because we no longer keep the static list. This list was
not really useful to debugging as the list doesn't change.

Change-Id: I8601cd7ff9cea778911cbfc306dc03089530bc9d
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/94/180394/4 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token/__init__.py'],1,e2c0433abee3321109d01aaf4ea6b84a2588d8dc,rework,"class _AuthTokenRequest(webob.Request): _HEADER_TEMPLATE = { 'X%s-Domain-Id': 'domain_id', 'X%s-Domain-Name': 'domain_name', 'X%s-Project-Id': 'project_id', 'X%s-Project-Name': 'project_name', 'X%s-Project-Domain-Id': 'project_domain_id', 'X%s-Project-Domain-Name': 'project_domain_name', 'X%s-User-Id': 'user_id', 'X%s-User-Name': 'username', 'X%s-User-Domain-Id': 'user_domain_id', 'X%s-User-Domain-Name': 'user_domain_name', } _USER_STATUS_HEADER = 'X-Identity-Status' _SERVICE_STATUS_HEADER = 'X-Service-Identity-Status' _CONFIRMED = 'Confirmed' _INVALID = 'Invalid' def _confirmed(cls, value): return cls._CONFIRMED if value else cls._INVALID @property def user_token_valid(self): return self.headers[self._USER_STATUS_HEADER] == self._CONFIRMED @user_token_valid.setter def user_token_valid(self, value): self.headers[self._USER_STATUS_HEADER] = self._confirmed(value) @property def service_token_valid(self): return self.headers[self._SERVICE_STATUS_HEADER] == self._CONFIRMED @service_token_valid.setter def service_token_valid(self, value): self.headers[self._SERVICE_STATUS_HEADER] = self._confirmed(value) def _set_auth_headers(self, auth_ref, prefix): self.headers['X%s-Roles' % prefix] = ','.join(auth_ref.role_names) for header_tmplt, attr in six.iteritems(self._HEADER_TEMPLATE): self.headers[header_tmplt % prefix] = getattr(auth_ref, attr) def set_user_headers(self, auth_ref, include_service_catalog): """"""Convert token object into headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. """""" self.user_token_valid = True self._set_auth_headers(auth_ref, '') # Deprecated headers self.headers['X-Role'] = self.headers['X-Roles'] self.headers['X-User'] = self.headers['X-User-Name'] self.headers['X-Tenant-Id'] = self.headers['X-Project-id'] self.headers['X-Tenant-Name'] = self.headers['X-Project-Name'] self.headers['X-Tenant'] = self.headers['X-Project-Name'] if include_service_catalog and auth_ref.has_service_catalog(): catalog = auth_ref.service_catalog.get_data() if auth_ref.version == 'v3': catalog = _v3_to_v2_catalog(catalog) self.headers['X-Service-Catalog'] = jsonutils.dumps(catalog) def set_service_headers(self, auth_ref): """"""Convert token object into service headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. """""" self.service_token_valid = True self._set_auth_headers(auth_ref, '-Service') def remove_auth_headers(self): """"""Remove headers so a user can't fake authentication. Both user and service token headers are removed. """""" for header in ('X-Service-Catalog', 'X-Identity-Status', 'X-Service-Identity-Status', 'X-Roles', 'X-Service-Roles', # deprecated 'X-Role', 'X-User', 'X-Tenant-Id', 'X-Tenant-Name', 'X-Tenant'): self.headers.pop(header, None) for header in self._HEADER_TEMPLATE: self.headers.pop(header % '', None) self.headers.pop(header % '-Service', None) @webob.dec.wsgify(RequestClass=_AuthTokenRequest) request.remove_auth_headers() request.set_user_headers(user_auth_ref, self._include_service_catalog) request.set_service_headers(serv_auth_ref)","_HEADER_TEMPLATE = { 'X%s-Domain-Id': 'domain_id', 'X%s-Domain-Name': 'domain_name', 'X%s-Project-Id': 'project_id', 'X%s-Project-Name': 'project_name', 'X%s-Project-Domain-Id': 'project_domain_id', 'X%s-Project-Domain-Name': 'project_domain_name', 'X%s-User-Id': 'user_id', 'X%s-User-Name': 'username', 'X%s-User-Domain-Id': 'user_domain_id', 'X%s-User-Domain-Name': 'user_domain_name', } self._init_auth_headers() @webob.dec.wsgify self._remove_auth_headers(request) user_headers = self._build_user_headers(user_auth_ref) request.headers.update(user_headers) serv_headers = self._build_service_headers(serv_auth_ref) request.headers.update(serv_headers) def _init_auth_headers(self): """"""Initialize auth header list. Both user and service token headers are generated. """""" auth_headers = ['X-Service-Catalog', 'X-Identity-Status', 'X-Service-Identity-Status', 'X-Roles', 'X-Service-Roles'] for key in six.iterkeys(_HEADER_TEMPLATE): auth_headers.append(key % '') # Service headers auth_headers.append(key % '-Service') # Deprecated headers auth_headers.append('X-Role') for key in six.iterkeys(_DEPRECATED_HEADER_TEMPLATE): auth_headers.append(key) self._auth_headers = auth_headers def _remove_auth_headers(self, request): """"""Remove headers so a user can't fake authentication. Both user and service token headers are removed. :param env: wsgi request environment """""" for k in self._auth_headers: request.headers.pop(k, None) def _build_user_headers(self, auth_ref): """"""Convert token object into headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. :param token_info: token object returned by identity server on authentication :raises exc.InvalidToken: when unable to parse token object """""" roles = ','.join(auth_ref.role_names) rval = { 'X-Identity-Status': 'Confirmed', 'X-Roles': roles, } for header_tmplt, attr in six.iteritems(_HEADER_TEMPLATE): rval[header_tmplt % ''] = getattr(auth_ref, attr) # Deprecated headers rval['X-Role'] = roles for header_tmplt, attr in six.iteritems(_DEPRECATED_HEADER_TEMPLATE): rval[header_tmplt] = getattr(auth_ref, attr) if self._include_service_catalog and auth_ref.has_service_catalog(): catalog = auth_ref.service_catalog.get_data() if auth_ref.version == 'v3': catalog = _v3_to_v2_catalog(catalog) rval['X-Service-Catalog'] = jsonutils.dumps(catalog) return rval def _build_service_headers(self, auth_ref): """"""Convert token object into service headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. :param auth_ref: authentication information """""" roles = ','.join(auth_ref.role_names) rval = { 'X-Service-Identity-Status': 'Confirmed', 'X-Service-Roles': roles, } header_type = '-Service' for header_tmplt, attr in six.iteritems(_HEADER_TEMPLATE): rval[header_tmplt % header_type] = getattr(auth_ref, attr) return rval ",107,108
openstack%2Fheat~master~I59f50957f8a3f4fbbd001ebc0a8b68471d921337,openstack/heat,master,I59f50957f8a3f4fbbd001ebc0a8b68471d921337,Clean openstack common modules,MERGED,2015-06-10 11:35:37.000000000,2015-06-11 03:43:14.000000000,2015-06-11 03:43:12.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-10 11:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e736aa997c6879cbd565b3bd152ea4ed06c455f0', 'message': 'Clean openstack common modules\n\nRemove unused fileutils and versionutils modules from\nheat.openstack.commmon.\n\nChange-Id: I59f50957f8a3f4fbbd001ebc0a8b68471d921337\n'}, {'number': 2, 'created': '2015-06-10 12:01:18.000000000', 'files': ['heat/openstack/common/versionutils.py', 'heat/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7219244b148f2a6611db8e8c8f83753bf2ffaf25', 'message': 'Clean openstack common modules\n\nRemove unused fileutils and versionutils modules from\nheat.openstack.common.\n\nChange-Id: I59f50957f8a3f4fbbd001ebc0a8b68471d921337\n'}]",1,190130,7219244b148f2a6611db8e8c8f83753bf2ffaf25,14,5,2,7385,,,0,"Clean openstack common modules

Remove unused fileutils and versionutils modules from
heat.openstack.common.

Change-Id: I59f50957f8a3f4fbbd001ebc0a8b68471d921337
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/190130/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/versionutils.py', 'heat/openstack/common/fileutils.py']",2,e736aa997c6879cbd565b3bd152ea4ed06c455f0,oslo-cleanup,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import logging import os import stat import tempfile from oslo_utils import excutils LOG = logging.getLogger(__name__) _FILE_CACHE = {} DEFAULT_MODE = stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO def ensure_tree(path, mode=DEFAULT_MODE): """"""Create a directory (and any ancestor directories required) :param path: Directory to create :param mode: Directory creation permissions """""" try: os.makedirs(path, mode) except OSError as exc: if exc.errno == errno.EEXIST: if not os.path.isdir(path): raise else: raise def read_cached_file(filename, force_reload=False): """"""Read from a file if it has been modified. :param force_reload: Whether to reload the file. :returns: A tuple with a boolean specifying if the data is fresh or not. """""" global _FILE_CACHE if force_reload: delete_cached_file(filename) reloaded = False mtime = os.path.getmtime(filename) cache_info = _FILE_CACHE.setdefault(filename, {}) if not cache_info or mtime > cache_info.get('mtime', 0): LOG.debug(""Reloading cached file %s"" % filename) with open(filename) as fap: cache_info['data'] = fap.read() cache_info['mtime'] = mtime reloaded = True return (reloaded, cache_info['data']) def delete_cached_file(filename): """"""Delete cached file if present. :param filename: filename to delete """""" global _FILE_CACHE if filename in _FILE_CACHE: del _FILE_CACHE[filename] def delete_if_exists(path, remove=os.unlink): """"""Delete a file, but ignore file not found error. :param path: File to delete :param remove: Optional function to remove passed path """""" try: remove(path) except OSError as e: if e.errno != errno.ENOENT: raise @contextlib.contextmanager def remove_path_on_error(path, remove=delete_if_exists): """"""Protect code that wants to operate on PATH atomically. Any exception will cause PATH to be removed. :param path: File to work with :param remove: Optional function to remove passed path """""" try: yield except Exception: with excutils.save_and_reraise_exception(): remove(path) def file_open(*args, **kwargs): """"""Open file see built-in open() documentation for more details Note: The reason this is kept in a separate module is to easily be able to provide a stub module that doesn't alter system state at all (for unit tests) """""" return open(*args, **kwargs) def write_to_tempfile(content, path=None, suffix='', prefix='tmp'): """"""Create temporary file or use existing file. This util is needed for creating temporary file with specified content, suffix and prefix. If path is not None, it will be used for writing content. If the path doesn't exist it'll be created. :param content: content for temporary file. :param path: same as parameter 'dir' for mkstemp :param suffix: same as parameter 'suffix' for mkstemp :param prefix: same as parameter 'prefix' for mkstemp For example: it can be used in database tests for creating configuration files. """""" if path: ensure_tree(path) (fd, path) = tempfile.mkstemp(suffix=suffix, dir=path, prefix=prefix) try: os.write(fd, content) finally: os.close(fd) return path ",0,411
openstack%2Fceilometer~master~Idbb2c93ed00dc2359f555d245c2283844d5a1da4,openstack/ceilometer,master,Idbb2c93ed00dc2359f555d245c2283844d5a1da4,Remove pagination code,MERGED,2015-05-25 15:24:05.000000000,2015-06-11 03:42:31.000000000,2015-06-11 03:42:29.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-25 15:24:05.000000000', 'files': ['ceilometer/alarm/storage/impl_log.py', 'ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/alarm/storage/impl_sqlalchemy.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/api/controllers/v2/alarms.py', 'ceilometer/api/controllers/v2/capabilities.py', 'ceilometer/alarm/storage/pymongo_base.py', 'ceilometer/tests/api/v2/test_query.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/tests/gabbi/gabbits/capabilities.yaml', 'ceilometer/tests/storage/test_impl_mongodb.py', 'ceilometer/alarm/storage/base.py', 'ceilometer/tests/storage/test_impl_db2.py', 'ceilometer/alarm/storage/impl_hbase.py', 'ceilometer/tests/storage/test_impl_sqlalchemy.py', 'ceilometer/storage/pymongo_base.py', 'ceilometer/tests/storage/test_impl_hbase.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1dfb2cb44b9b81133f75e1c9e8622306a14a7bb0', 'message': ""Remove pagination code\n\nThis code is actually dead code we carry over for a long time now, as\nthe pagination support never landed completely. Let's clean that old cruft.\n\nChange-Id: Idbb2c93ed00dc2359f555d245c2283844d5a1da4\n""}]",0,185408,1dfb2cb44b9b81133f75e1c9e8622306a14a7bb0,19,15,1,1669,,,0,"Remove pagination code

This code is actually dead code we carry over for a long time now, as
the pagination support never landed completely. Let's clean that old cruft.

Change-Id: Idbb2c93ed00dc2359f555d245c2283844d5a1da4
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/08/185408/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/storage/impl_log.py', 'ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/storage/base.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/impl_log.py', 'ceilometer/alarm/storage/impl_sqlalchemy.py', 'ceilometer/storage/impl_db2.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/api/controllers/v2/alarms.py', 'ceilometer/api/controllers/v2/capabilities.py', 'ceilometer/alarm/storage/pymongo_base.py', 'ceilometer/tests/api/v2/test_query.py', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/tests/gabbi/gabbits/capabilities.yaml', 'ceilometer/tests/storage/test_impl_mongodb.py', 'ceilometer/alarm/storage/base.py', 'ceilometer/tests/storage/test_impl_db2.py', 'ceilometer/alarm/storage/impl_hbase.py', 'ceilometer/tests/storage/test_impl_sqlalchemy.py', 'ceilometer/storage/pymongo_base.py', 'ceilometer/tests/storage/test_impl_hbase.py']",21,1dfb2cb44b9b81133f75e1c9e8622306a14a7bb0,jd/remove-pagination," 'meters': {'query': {'simple': True, 'resources': {'query': {'simple': True, 'samples': {'query': {'simple': True, 'statistics': {'groupby': False,"," 'meters': {'pagination': False, 'query': {'simple': True, 'resources': {'pagination': False, 'query': {'simple': True, 'samples': {'pagination': False, 'query': {'simple': True, 'statistics': {'pagination': False, 'groupby': False,",44,415
openstack%2Fkeystonemiddleware~master~Ifb79e1ea30663efca4696a219739a15d27bb76ef,openstack/keystonemiddleware,master,Ifb79e1ea30663efca4696a219739a15d27bb76ef,Remove custom header handling,MERGED,2015-05-06 02:50:43.000000000,2015-06-11 03:29:50.000000000,2015-06-11 03:29:50.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2015-05-06 02:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6562b06ff8806bd9d4fea4d7bdfb9e2708a5dc92', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 2, 'created': '2015-05-06 23:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/67bd301f7372486fa2680f1e73e3979902eb7ccf', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 3, 'created': '2015-05-13 01:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/b84f2ffba5cea096f63b26c0d21d221bd5aaaa30', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 4, 'created': '2015-05-13 02:04:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/118d34b2232f69de11bfa065a6193a213b0a1155', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 5, 'created': '2015-05-26 02:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/0a0670673f97c133d2a23a562b67f740163aa074', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 6, 'created': '2015-05-26 02:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/296ece92d892d7acc918b91ffeb24b5ecc8f58d8', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 7, 'created': '2015-06-03 22:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/5624d3bb94729d333c9b022fddb70cd4feb97b1b', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}, {'number': 8, 'created': '2015-06-08 12:28:53.000000000', 'files': ['keystonemiddleware/auth_token/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6f9b7a452845cd55fca2eb275a315fe2c0860d8c', 'message': ""Remove custom header handling\n\nNow we have a webob request remove all the transformation between a\nheader and an environment variable in favour of webob's handling.\n\nChange-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef\n""}]",4,180385,6f9b7a452845cd55fca2eb275a315fe2c0860d8c,25,5,8,7191,,,0,"Remove custom header handling

Now we have a webob request remove all the transformation between a
header and an environment variable in favour of webob's handling.

Change-Id: Ifb79e1ea30663efca4696a219739a15d27bb76ef
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/85/180385/3 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token/__init__.py'],1,6562b06ff8806bd9d4fea4d7bdfb9e2708a5dc92,rework," self._remove_auth_headers(request) request.headers.update(user_headers) request.headers['X-Identity-Status'] = 'Invalid' request.headers.update(serv_headers) request.headers['X-Service-Identity-Status'] = 'Invalid' def _remove_auth_headers(self, request): for k in self._auth_headers: request.headers.pop(k, None)"," self._remove_auth_headers(request.environ) self._add_headers(request.environ, user_headers) self._add_headers(request.environ, {'X-Identity-Status': 'Invalid'}) self._add_headers(request.environ, serv_headers) self._add_headers(request.environ, {'X-Service-Identity-Status': 'Invalid'}) def _remove_auth_headers(self, env): self._LOG.debug('Removing headers from request environment: %s', ','.join(self._auth_headers)) self._remove_headers(env, self._auth_headers) def _header_to_env_var(self, key): """"""Convert header to wsgi env variable. :param key: http header name (ex. 'X-Auth-Token') :returns: wsgi env variable name (ex. 'HTTP_X_AUTH_TOKEN') """""" return 'HTTP_%s' % key.replace('-', '_').upper() def _add_headers(self, env, headers): """"""Add http headers to environment."""""" for (k, v) in six.iteritems(headers): env_key = self._header_to_env_var(k) env[env_key] = v def _remove_headers(self, env, keys): """"""Remove http headers from environment."""""" for k in keys: env_key = self._header_to_env_var(k) try: del env[env_key] except KeyError: pass def _get_header(self, env, key, default=None): """"""Get http header from environment."""""" env_key = self._header_to_env_var(key) return env.get(env_key, default) ",8,40
openstack%2Fnetworking-odl~master~Ie696e26349f580a6412c7a0ef37b8ecc05c9df6e,openstack/networking-odl,master,Ie696e26349f580a6412c7a0ef37b8ecc05c9df6e,Test unwedged CI with latest ODL snapshot,ABANDONED,2015-06-11 02:59:18.000000000,2015-06-11 03:25:49.000000000,,"[{'_account_id': 3}, {'_account_id': 10386}]","[{'number': 1, 'created': '2015-06-11 02:59:18.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/d3f5a58332846656399a00cfa29197408e1988ae', 'message': 'Test unwedged CI with latest ODL snapshot\n\nChange-Id: Ie696e26349f580a6412c7a0ef37b8ecc05c9df6e\n'}]",0,190466,d3f5a58332846656399a00cfa29197408e1988ae,4,2,1,748,,,0,"Test unwedged CI with latest ODL snapshot

Change-Id: Ie696e26349f580a6412c7a0ef37b8ecc05c9df6e
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/66/190466/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,d3f5a58332846656399a00cfa29197408e1988ae,test,ODL_RELEASE=${ODL_RELEASE:-lithium-snapshot-0.3.0},ODL_RELEASE=${ODL_RELEASE:-helium-snapshot},1,1
openstack%2Fheat~master~I0acb7de7b44715531375de59e6037f9237e74b17,openstack/heat,master,I0acb7de7b44715531375de59e6037f9237e74b17,Updated from global requirements,MERGED,2015-06-10 21:21:01.000000000,2015-06-11 03:18:31.000000000,2015-06-11 03:18:29.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8246}, {'_account_id': 8289}]","[{'number': 1, 'created': '2015-06-10 21:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3b6516a08c6e9215f663f7cf088d04de587b418a', 'message': 'Updated from global requirements\n\nChange-Id: I0acb7de7b44715531375de59e6037f9237e74b17\n'}, {'number': 2, 'created': '2015-06-10 23:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10a89df13280d2b2e651f0f847fec7e52212d7f0', 'message': 'Updated from global requirements\n\nChange-Id: I0acb7de7b44715531375de59e6037f9237e74b17\n'}, {'number': 3, 'created': '2015-06-11 00:41:50.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/f9002c1ac99b2fc64883b5e9c00bbea03bc10dba', 'message': 'Updated from global requirements\n\nChange-Id: I0acb7de7b44715531375de59e6037f9237e74b17\n'}]",0,190355,f9002c1ac99b2fc64883b5e9c00bbea03bc10dba,16,4,3,11131,,,0,"Updated from global requirements

Change-Id: I0acb7de7b44715531375de59e6037f9237e74b17
",git fetch https://review.opendev.org/openstack/heat refs/changes/55/190355/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,3b6516a08c6e9215f663f7cf088d04de587b418a,openstack/requirements,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,2,2
openstack%2Fkeystone~master~I6d593b97517460395ef31a84a986a73a36b82078,openstack/keystone,master,I6d593b97517460395ef31a84a986a73a36b82078,Avoid using the interactive interpreter for a one-liner,MERGED,2015-06-05 14:34:06.000000000,2015-06-11 03:18:21.000000000,2015-06-11 03:18:20.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-06-05 14:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7b090fe4181d732c8b2eece9f670beffa7c1c495', 'message': ""Avoid using the interactive interpreter for a one-liner\n\nThere's no reason to jump into the interactive interpreter if you only\nneed to run a single line of code and ensure that it doesn't fail.\n\nChange-Id: I6d593b97517460395ef31a84a986a73a36b82078\n""}, {'number': 2, 'created': '2015-06-05 14:34:48.000000000', 'files': ['doc/source/setup.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6bd9cb6a8d6a2ae76d25ef8af71e7670267453b3', 'message': ""Avoid using the interactive interpreter for a one-liner\n\nThere's no reason to jump into the interactive interpreter if you only\nneed to run a single line of code and ensure that it doesn't fail.\n\nChange-Id: I6d593b97517460395ef31a84a986a73a36b82078\n""}]",0,188799,6bd9cb6a8d6a2ae76d25ef8af71e7670267453b3,18,6,2,4,,,0,"Avoid using the interactive interpreter for a one-liner

There's no reason to jump into the interactive interpreter if you only
need to run a single line of code and ensure that it doesn't fail.

Change-Id: I6d593b97517460395ef31a84a986a73a36b82078
",git fetch https://review.opendev.org/openstack/keystone refs/changes/99/188799/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/setup.rst'],1,7b090fe4181d732c8b2eece9f670beffa7c1c495,," You should then be able to `import keystone` using Python without issue: .. code-block:: bash $ python -c ""import keystone"" If you can import Keystone without a traceback, you should be ready to move on to :doc:`developing`."," $ python You should then be able to `import keystone` from your Python shell without issue: .. code-block:: python >>> import keystone >>> If you can import Keystone successfully, you should be ready to move on to :doc:`developing`.",6,8
openstack%2Fnetworking-odl~master~Ibade3f37c53f273a64413bef57061d6eea45d195,openstack/networking-odl,master,Ibade3f37c53f273a64413bef57061d6eea45d195,Get upstream CI job working,MERGED,2015-06-10 16:46:22.000000000,2015-06-11 03:17:49.000000000,2015-06-11 03:17:49.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 7016}, {'_account_id': 10386}, {'_account_id': 11952}]","[{'number': 1, 'created': '2015-06-10 16:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/65e60861a240ece23a4543eef61f8108d034a2ca', 'message': 'Get upstream CI job working\n\nThis commit unwedges the upstream CI job. It does this by both\nupping the ODL_BOOT_WAIT and also by ensuring features are\ninstalled in a manner which allows ODL to work on VMs running\nin both the HP and RAX clouds.\n\nChange-Id: Ibade3f37c53f273a64413bef57061d6eea45d195\nCloses-Bug: #1450603\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 2, 'created': '2015-06-10 19:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/298964af7497fe43196b747a872848784ca54b08', 'message': 'Get upstream CI job working\n\nThis commit unwedges the upstream CI job. It does this by both\nupping the ODL_BOOT_WAIT and also by ensuring features are\ninstalled in a manner which allows ODL to work on VMs running\nin both the HP and RAX clouds. We will also enable debug logs\nby default now as well to make debugging easier.\n\nChange-Id: Ibade3f37c53f273a64413bef57061d6eea45d195\nCloses-Bug: #1450603\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 3, 'created': '2015-06-10 20:25:41.000000000', 'files': ['devstack/settings.odl'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/ba4bcafaa58cea00a189a994f2eb4e7669d6c584', 'message': 'Get upstream CI job working\n\nThis commit unwedges the upstream CI job. It does this by both\nupping the ODL_BOOT_WAIT and also by ensuring features are\ninstalled in a manner which allows ODL to work on VMs running\nin both the HP and RAX clouds. We will also enable debug logs\nby default now as well to make debugging easier.\n\nChange-Id: Ibade3f37c53f273a64413bef57061d6eea45d195\nCloses-Bug: #1450603\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}]",0,190255,ba4bcafaa58cea00a189a994f2eb4e7669d6c584,19,7,3,105,,,0,"Get upstream CI job working

This commit unwedges the upstream CI job. It does this by both
upping the ODL_BOOT_WAIT and also by ensuring features are
installed in a manner which allows ODL to work on VMs running
in both the HP and RAX clouds. We will also enable debug logs
by default now as well to make debugging easier.

Change-Id: Ibade3f37c53f273a64413bef57061d6eea45d195
Closes-Bug: #1450603
Signed-off-by: Kyle Mestery <mestery@mestery.com>
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/55/190255/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings.odl'],1,65e60861a240ece23a4543eef61f8108d034a2ca,ci,"ODL_BOOT_WAIT=${ODL_BOOT_WAIT:-360}ODL_NETVIRT_KARAF_FEATURE=${ODL_NETVIRT_KARAF_FEATURE:-odl-base-all,odl-restconf-all,odl-aaa-authn,odl-dlux-core,odl-mdsal-apidocs,odl-adsal-northbound,odl-nsf-all,odl-ovsdb-northbound}",ODL_BOOT_WAIT=${ODL_BOOT_WAIT:-90}ODL_NETVIRT_KARAF_FEATURE=${ODL_NETVIRT_KARAF_FEATURE:-odl-ovsdb-openstack},2,2
openstack%2Fkeystone~master~I367ae5c1351d8eac4291b6c912f188e9bfa3792f,openstack/keystone,master,I367ae5c1351d8eac4291b6c912f188e9bfa3792f,Fix spelling in configuration comment.,MERGED,2015-06-10 19:44:38.000000000,2015-06-11 03:14:16.000000000,2015-06-11 03:14:15.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-06-10 19:44:38.000000000', 'files': ['keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/336ef068228c5d14ccec1337fe80934184d63c99', 'message': 'Fix spelling in configuration comment.\n\nNon-functional change to fixup some spelling.\n\nChange-Id: I367ae5c1351d8eac4291b6c912f188e9bfa3792f\n'}]",0,190318,336ef068228c5d14ccec1337fe80934184d63c99,7,3,1,5046,,,0,"Fix spelling in configuration comment.

Non-functional change to fixup some spelling.

Change-Id: I367ae5c1351d8eac4291b6c912f188e9bfa3792f
",git fetch https://review.opendev.org/openstack/keystone refs/changes/18/190318/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/config.py'],1,336ef068228c5d14ccec1337fe80934184d63c99,crypt-rounds, # NOTE(lbragstad/morganfainberg): This value of 10k was # static and grows over time to constantly approximate ~300ms, # NOTE(lbragstd/morganfainberg): This value of 10k was # static and grows over time to constatly approximate ~300ms,2,2
openstack%2Fpuppet-keystone~stable%2Fjuno~I6bcbddca5dcfd625a325917174339f7be5206827,openstack/puppet-keystone,stable/juno,I6bcbddca5dcfd625a325917174339f7be5206827,Add native types for keystone paste configuration,MERGED,2015-06-02 01:16:54.000000000,2015-06-11 03:12:07.000000000,2015-06-11 03:12:05.000000000,"[{'_account_id': 3}, {'_account_id': 2265}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 9983}]","[{'number': 1, 'created': '2015-06-02 01:16:54.000000000', 'files': ['spec/unit/provider/keystone_paste_ini/ini_setting_spec.rb', 'spec/unit/type/keystone_paste_ini_spec.rb', 'lib/puppet/provider/keystone_paste_ini/ini_setting.rb', 'lib/puppet/type/keystone_paste_ini.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7e3ed6d962136338fc2d273329007eab0e34941e', 'message': 'Add native types for keystone paste configuration\n\nso that pipeline configuration can be updated from\nPuppet for keystone.\n\nChange-Id: I6bcbddca5dcfd625a325917174339f7be5206827\n(cherry picked from commit 1699792a23b86d6b50ca21d7e57871d71b6a29c6)\n'}]",0,187412,7e3ed6d962136338fc2d273329007eab0e34941e,8,5,1,8482,,,0,"Add native types for keystone paste configuration

so that pipeline configuration can be updated from
Puppet for keystone.

Change-Id: I6bcbddca5dcfd625a325917174339f7be5206827
(cherry picked from commit 1699792a23b86d6b50ca21d7e57871d71b6a29c6)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/12/187412/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_paste_ini/ini_setting_spec.rb', 'spec/unit/type/keystone_paste_ini_spec.rb', 'lib/puppet/provider/keystone_paste_ini/ini_setting.rb', 'lib/puppet/type/keystone_paste_ini.rb']",4,7e3ed6d962136338fc2d273329007eab0e34941e,,"Puppet::Type.newtype(:keystone_paste_ini) do ensurable newparam(:name, :namevar => true) do desc 'Section/setting name to manage from keystone/keystone-paste.ini' newvalues(/\S+\/\S+/) end newproperty(:value) do desc 'The value of the setting to be defined.' munge do |value| value = value.to_s.strip value.capitalize! if value =~ /^(true|false)$/i value end def is_to_s( currentvalue ) if resource.secret? return '[old secret redacted]' else return currentvalue end end def should_to_s( newvalue ) if resource.secret? return '[new secret redacted]' else return newvalue end end end newparam(:secret, :boolean => true) do desc 'Whether to hide the value from Puppet logs. Defaults to `false`.' newvalues(:true, :false) defaultto false end end ",,122,0
openstack%2Fneutron~master~I994f3abdb1b0ad3b2766f409b206ad4a8b2309b6,openstack/neutron,master,I994f3abdb1b0ad3b2766f409b206ad4a8b2309b6,Allow update_port_status to take network param,MERGED,2015-06-04 20:43:24.000000000,2015-06-11 03:09:09.000000000,2015-06-11 03:09:07.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11343}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-06-04 20:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7aab47344ed5ab455902f46e42edb42fc942acce', 'message': 'Allow update_port_status to take network param\n\nAllow the update_port_status function to take a network as\nan optional parameter to skip calling get_network again if\nthe caller has already done so.\n\nChange-Id: I994f3abdb1b0ad3b2766f409b206ad4a8b2309b6\n'}, {'number': 2, 'created': '2015-06-10 04:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/799d5b4254267ea05becb9a4f90e42523e67ae83', 'message': 'Allow update_port_status to take network param\n\nAllow the update_port_status function to take a network as\nan optional parameter to skip calling get_network again if\nthe caller has already done so.\n\nChange-Id: I994f3abdb1b0ad3b2766f409b206ad4a8b2309b6\n'}, {'number': 3, 'created': '2015-06-10 04:29:04.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea35b299f06050608f3e7bb6fbc880006ed31024', 'message': 'Allow update_port_status to take network param\n\nAllow the update_port_status function to take a network as\nan optional parameter to skip calling get_network again if\nthe caller has already done so.\n\nCloses-Bug: #1463656\nChange-Id: I994f3abdb1b0ad3b2766f409b206ad4a8b2309b6\n'}]",1,188585,ea35b299f06050608f3e7bb6fbc880006ed31024,75,34,3,7787,,,0,"Allow update_port_status to take network param

Allow the update_port_status function to take a network as
an optional parameter to skip calling get_network again if
the caller has already done so.

Closes-Bug: #1463656
Change-Id: I994f3abdb1b0ad3b2766f409b206ad4a8b2309b6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/188585/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/plugin.py']",3,7aab47344ed5ab455902f46e42edb42fc942acce,bug/1463656," def update_port_status(self, context, port_id, status, host=None, network=None): network can be passed in to avoid another get_network call if one was already performed by the caller. network = network or self.get_network( context, original_port['network_id']) network = network or self.get_network( context, original_port['network_id'])"," def update_port_status(self, context, port_id, status, host=None): network = self.get_network(context, original_port['network_id']) network = self.get_network(context, original_port['network_id'])",20,6
openstack%2Fdevstack~master~I175ddaf9362bf48d35b0e648904eeb21bdc3c793,openstack/devstack,master,I175ddaf9362bf48d35b0e648904eeb21bdc3c793,Cleanup FAQ somewhat,MERGED,2015-06-02 00:31:51.000000000,2015-06-11 03:06:28.000000000,2015-06-11 03:06:25.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 8119}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-02 00:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0766cbe4621fce6f329b285169c09f489df79bb6', 'message': 'Cleanup FAQ somewhat\n\nRemove some old discussions that no longer seem relevant and cleanup a\nfew other points\n\nChange-Id: I175ddaf9362bf48d35b0e648904eeb21bdc3c793\n'}, {'number': 2, 'created': '2015-06-02 19:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/46d23a1be7b98ec39474707b678ca06ad4f39889', 'message': 'Cleanup FAQ somewhat\n\nRemove some old discussions that no longer seem relevant and cleanup a\nfew other points\n\nChange-Id: I175ddaf9362bf48d35b0e648904eeb21bdc3c793\n'}, {'number': 3, 'created': '2015-06-05 00:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/eb59658df9bb17407e9388421aff55a3b1a35b89', 'message': 'Cleanup FAQ somewhat\n\nRemove some old discussions that no longer seem relevant and cleanup a\nfew other points.\n\nChange-Id: I175ddaf9362bf48d35b0e648904eeb21bdc3c793\n'}, {'number': 4, 'created': '2015-06-09 02:40:33.000000000', 'files': ['doc/source/faq.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a16e46100a2f676457abf884fc2b852d67597807', 'message': 'Cleanup FAQ somewhat\n\nRemove some old discussions that no longer seem relevant and cleanup a\nfew other points.\n\nChange-Id: I175ddaf9362bf48d35b0e648904eeb21bdc3c793\n'}]",10,187403,a16e46100a2f676457abf884fc2b852d67597807,31,10,4,7118,,,0,"Cleanup FAQ somewhat

Remove some old discussions that no longer seem relevant and cleanup a
few other points.

Change-Id: I175ddaf9362bf48d35b0e648904eeb21bdc3c793
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/187403/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/faq.rst'],1,0766cbe4621fce6f329b285169c09f489df79bb6,bug/1460656," A: devstack is targeted at developers and CI systems to use the raw upstream code. It makes many choices that are not appropriate for production systems. Your best choice is probably to choose a `distribution of OpenStack <https://www.openstack.org/marketplace/distros/distribution>`__. production deployments. Q: Are there any differences between Ubuntu and Centos/Fedora support? A: both should work well and are tested by devstack CI Q: Can I test on OS/X? A: Some people have success with bash 4 installed via homebrew to keep running tests on OS/X A: Yes, see :doc:`multinode lab guide <guides/multinode-lab>` A: OpenStack milestones have tags set in the git repo. Set the appropriate tag in the ``*_BRANCH`` variables in ``local.conf``. Swift is on its own release schedule so pick a tag in the Swift repo that is just before the milestone release. For example:"," A: No. We mean it. Really. DevStack makes some implementation choices that are not appropriate for production deployments. We warned you! Q: Then why selinux in enforcing mode? A: That is the default on current Fedora and RHEL releases. DevStack has (rightly so) a bad reputation for its security practices; it has always been meant as a development tool first and system integration later. This is changing as the security issues around OpenStack's use of root (for example) have been tightened and developers need to be better equipped to work in these environments. ``stack.sh``'s use of root is primarily to support the activities that would be handled by packaging in ""real"" deployments. To remove additional protections that will be desired/required in production would be a step backward. Q: But selinux is disabled in RHEL! A: Today it is, yes. That is a specific exception that certain DevStack contributors fought strongly against. The primary reason it was allowed was to support using RHEL6 as the Python 2.6 test platform and that took priority time-wise. This will not be the case with RHEL 7.Q: Why not use Crowbar? A: DevStack is optimized for documentation & developers. As some of us use `Crowbar <https://github.com/dellcloudedge/crowbar>`__ for production deployments, we hope developers documenting how they setup systems for new features supports projects like Crowbar. production deployments. We hope this script serves as a way to communicate configuration changes between developers and packagers.Q: What about Fedora/RHEL/CentOS? A: Fedora and CentOS/RHEL are supported via rpm dependency files and specific checks in ``stack.sh``. Support will follow the pattern set with the Ubuntu testing, i.e. only a single release of the distro will receive regular testing, others will be handled on a best-effort basis. Q: Are there any differences between Ubuntu and Fedora support? A: Neutron is not fully supported prior to Fedora 18 due lack of OpenVSwitch packages.Q: But, but, can't I test on OS/X? A: Yes, even you, core developer who complained about this, needs to install bash 4 via homebrew to keep running tests on OS/X. Get a Real Operating System. (For most of you who don't know, I am referring to myself.) A: Indirectly, yes. You run DevStack on each node with the appropriate configuration in ``local.conf``. The primary considerations are turning off the services not required on the secondary nodes, making sure the passwords match and setting the various API URLs to the right place. A: OpenStack milestones have tags set in the git repo. Set the appropriate tag in the ``*_BRANCH`` variables in ``local.conf``. Swift is on its own release schedule so pick a tag in the Swift repo that is just before the milestone release. For example:",31,47
openstack%2Fpuppet-swift~stable%2Fjuno~If7b88bf51046317171f6fa85bb8c01390fa26a37,openstack/puppet-swift,stable/juno,If7b88bf51046317171f6fa85bb8c01390fa26a37,Swift proxy won't start if using proxy:ceilometer,MERGED,2015-06-05 22:07:27.000000000,2015-06-11 03:01:55.000000000,2015-06-11 03:01:54.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-05 22:07:27.000000000', 'files': ['manifests/proxy/ceilometer.pp', 'spec/classes/swift_proxy_ceilometer_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/564baf1dd93e220c95ae2238a2df06d58e6bf76c', 'message': ""Swift proxy won't start if using proxy:ceilometer\n\nThe Swift ceilometer middleware needs to be able to\nwrite its log file in the /var/log/ceilometer\ndirectory. Not all distributions set permissions\non this directory such that the swift user/group\ncan write into the ceilometer log directory. This\ncan cause the swift-proxy to fail to startup due\nto permissions issues.\n\nThis patch updates the swift::proxy::ceilometer so\nthat we create an empty /var/log/ceilometer/swift-proxy-server.log\nfile with proper permissions before starting the swift-proxy\nservice.\n\nChange-Id: If7b88bf51046317171f6fa85bb8c01390fa26a37\n(cherry picked from commit 499386a89d2b5059445c887ff383655610f3fcb9)\n""}]",0,188943,564baf1dd93e220c95ae2238a2df06d58e6bf76c,10,4,1,8482,,,0,"Swift proxy won't start if using proxy:ceilometer

The Swift ceilometer middleware needs to be able to
write its log file in the /var/log/ceilometer
directory. Not all distributions set permissions
on this directory such that the swift user/group
can write into the ceilometer log directory. This
can cause the swift-proxy to fail to startup due
to permissions issues.

This patch updates the swift::proxy::ceilometer so
that we create an empty /var/log/ceilometer/swift-proxy-server.log
file with proper permissions before starting the swift-proxy
service.

Change-Id: If7b88bf51046317171f6fa85bb8c01390fa26a37
(cherry picked from commit 499386a89d2b5059445c887ff383655610f3fcb9)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/43/188943/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/proxy/ceilometer.pp', 'spec/classes/swift_proxy_ceilometer_spec.rb']",2,564baf1dd93e220c95ae2238a2df06d58e6bf76c,," it { should contain_file('/var/log/ceilometer/swift-proxy-server.log').with(:owner => 'swift', :group => 'swift', :mode => '0664') }",,12,0
openstack%2Fpuppet-swift~stable%2Fjuno~I9ddb12d2614440fe245aaaa10b7b17781a742f37,openstack/puppet-swift,stable/juno,I9ddb12d2614440fe245aaaa10b7b17781a742f37,Add base `swift` class name to call,MERGED,2015-06-05 22:08:03.000000000,2015-06-11 03:01:49.000000000,2015-06-11 03:01:48.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 14835}]","[{'number': 1, 'created': '2015-06-05 22:08:03.000000000', 'files': ['manifests/ringserver.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/0237f262fd043b438b77e45831caf8efe418ad52', 'message': ""Add base `swift` class name to call\n\nWhen the ring server manifest `swift::ringserver` is called\nthe client throws and error with missing class. The module\n`swift::ringserver` appears to refer to an incorrect class of\n`Class['ringbuilder']` which should be `Class['swift::ringbuilder']`.\n\nChange-Id: I9ddb12d2614440fe245aaaa10b7b17781a742f37\nImplements: Add swift base class name to class call\nCloses-Bug: 1414900\n(cherry picked from commit 88541bdef61665c752e31961706f395a53f53506)\n""}]",0,188944,0237f262fd043b438b77e45831caf8efe418ad52,10,4,1,8482,,,0,"Add base `swift` class name to call

When the ring server manifest `swift::ringserver` is called
the client throws and error with missing class. The module
`swift::ringserver` appears to refer to an incorrect class of
`Class['ringbuilder']` which should be `Class['swift::ringbuilder']`.

Change-Id: I9ddb12d2614440fe245aaaa10b7b17781a742f37
Implements: Add swift base class name to class call
Closes-Bug: 1414900
(cherry picked from commit 88541bdef61665c752e31961706f395a53f53506)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/44/188944/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/ringserver.pp'],1,0237f262fd043b438b77e45831caf8efe418ad52,, Class['swift::ringbuilder'] -> Class['swift::ringserver'], Class['ringbuilder'] -> Class['swift::ringserver'],1,1
openstack%2Fpuppet-horizon~stable%2Fjuno~I5831f2fe70d4d72eaa560413236a80b63b940b1d,openstack/puppet-horizon,stable/juno,I5831f2fe70d4d72eaa560413236a80b63b940b1d,Add support for the configuration of OPENSTACK_CINDER_FEATURES,MERGED,2015-06-05 23:29:07.000000000,2015-06-11 03:01:40.000000000,2015-06-11 03:01:38.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-05 23:29:07.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/edb942d28b00ed40448befc516823eb4283ae222', 'message': 'Add support for the configuration of OPENSTACK_CINDER_FEATURES\n\nChange-Id: I5831f2fe70d4d72eaa560413236a80b63b940b1d\n(cherry picked from commit dc32ea4940b7882017a954d848f5d7eae7e01fe5)\n'}]",0,188970,edb942d28b00ed40448befc516823eb4283ae222,6,5,1,8482,,,0,"Add support for the configuration of OPENSTACK_CINDER_FEATURES

Change-Id: I5831f2fe70d4d72eaa560413236a80b63b940b1d
(cherry picked from commit dc32ea4940b7882017a954d848f5d7eae7e01fe5)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/70/188970/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,edb942d28b00ed40448befc516823eb4283ae222,," :cinder_options => {'enable_backup' => true }, "" 'enable_backup': True,"",",,22,0
openstack%2Fpuppet-swift~stable%2Fjuno~I2d19bcf6fa01aca6025cdd5828e35db4a2b17199,openstack/puppet-swift,stable/juno,I2d19bcf6fa01aca6025cdd5828e35db4a2b17199,doc spelling corrections,MERGED,2015-06-05 22:09:28.000000000,2015-06-11 03:00:14.000000000,2015-06-11 03:00:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 9500}, {'_account_id': 11176}]","[{'number': 1, 'created': '2015-06-05 22:09:28.000000000', 'files': ['manifests/storage.pp', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/527f392820ae5cd5b1c373b23022ebe309dab9a0', 'message': 'doc spelling corrections\n\nChange-Id: I2d19bcf6fa01aca6025cdd5828e35db4a2b17199\n(cherry picked from commit 0d40df78fe40b002380cb3c58ac22dc6ee8b913f)\n'}]",0,188945,527f392820ae5cd5b1c373b23022ebe309dab9a0,11,5,1,8482,,,0,"doc spelling corrections

Change-Id: I2d19bcf6fa01aca6025cdd5828e35db4a2b17199
(cherry picked from commit 0d40df78fe40b002380cb3c58ac22dc6ee8b913f)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/45/188945/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage.pp', 'README.md']",2,527f392820ae5cd5b1c373b23022ebe309dab9a0,,"The swift module is a thorough attempt to make Puppet capable of managing the entirety of swift. This includes manifests to provision such things as keystone, storage backends, proxies, and the ring. Types are shipped as part of the swift module to assist in manipulation of configuration files. The classes in this module will deploy Swift using best practices for a typical deployment.","The swift module is a thorough attempt to make Puppet capable of managing the entirety of swift. This includes manifests to provision such things as keystone, stroage backends, proxies, and the ring. Types are shipped as part of the swift module to assist in manipulation of configuration files. The classes in this module will deploy Swift using best practices for a typical deployment.",2,2
openstack%2Fpuppet-swift~stable%2Fjuno~Ife0a30158289ea1dd44c1e93f058538c45c3a9c8,openstack/puppet-swift,stable/juno,Ife0a30158289ea1dd44c1e93f058538c45c3a9c8,read_affinity requires affinity sorting_method,MERGED,2015-06-05 22:12:18.000000000,2015-06-11 03:00:13.000000000,2015-06-11 03:00:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 11176}]","[{'number': 1, 'created': '2015-06-05 22:12:18.000000000', 'files': ['templates/proxy-server.conf.erb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/d12fe4e748dadc7b3e563c7e628180b1389d63c9', 'message': ""read_affinity requires affinity sorting_method\n\nproxy-server.conf read_affinity setting has no\neffect unless sorting_method is set to 'affinity'\n\nChange-Id: Ife0a30158289ea1dd44c1e93f058538c45c3a9c8\n(cherry picked from commit e04486fe46452978839b1c11a67d7fee59697106)\n""}]",0,188949,d12fe4e748dadc7b3e563c7e628180b1389d63c9,11,4,1,8482,,,0,"read_affinity requires affinity sorting_method

proxy-server.conf read_affinity setting has no
effect unless sorting_method is set to 'affinity'

Change-Id: Ife0a30158289ea1dd44c1e93f058538c45c3a9c8
(cherry picked from commit e04486fe46452978839b1c11a67d7fee59697106)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/49/188949/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/proxy-server.conf.erb'],1,d12fe4e748dadc7b3e563c7e628180b1389d63c9,,sorting_method = affinity,,1,0
openstack%2Fpuppet-swift~stable%2Fjuno~I572af876cbce704c0a252695afd44ec782f6b1d1,openstack/puppet-swift,stable/juno,I572af876cbce704c0a252695afd44ec782f6b1d1,Correct proxy::authtoken docs,MERGED,2015-06-05 22:06:14.000000000,2015-06-11 02:57:29.000000000,2015-06-11 02:57:27.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-05 22:06:14.000000000', 'files': ['manifests/proxy/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/029500e331bd79489ae73bfbc592318820c42a86', 'message': 'Correct proxy::authtoken docs\n\nUpdates several proxy::authtoken documentation parameters so\nthat they match the implementation defaults.\n\nChange-Id: I572af876cbce704c0a252695afd44ec782f6b1d1\n(cherry picked from commit 1e1c6041acad135e37ed7e20cfcf2aedf82fbe9a)\n'}]",0,188941,029500e331bd79489ae73bfbc592318820c42a86,10,4,1,8482,,,0,"Correct proxy::authtoken docs

Updates several proxy::authtoken documentation parameters so
that they match the implementation defaults.

Change-Id: I572af876cbce704c0a252695afd44ec782f6b1d1
(cherry picked from commit 1e1c6041acad135e37ed7e20cfcf2aedf82fbe9a)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/41/188941/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/proxy/authtoken.pp'],1,029500e331bd79489ae73bfbc592318820c42a86,,"# Optional. Defaults to 'swift'.# Optional. Defaults to 'services'.# Optional. Defaults to 'password'. # [delay_auth_decision] Set to 1 to support token-less access (anonymous access,","# Optional. Defaults to admin# Optional. Defaults to openstack.# Optional. Defaults to ChangeMe. # [delay_decision] Set to 1 to support token-less access (anonymous access,",4,4
openstack%2Fpuppet-swift~stable%2Fjuno~I840b8fe0125ed25e84f7681fada1b1102e48f32b,openstack/puppet-swift,stable/juno,I840b8fe0125ed25e84f7681fada1b1102e48f32b,Add seed parameter to ringbuilder::rebalance.,MERGED,2015-06-05 22:06:48.000000000,2015-06-11 02:57:04.000000000,2015-06-11 02:57:04.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-05 22:06:48.000000000', 'files': ['manifests/ringbuilder/rebalance.pp', 'spec/defines/swift_ringbuilder_rebalance_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/bd7244ed58e89aca83aaeb17e570635f9e5f6285', 'message': 'Add seed parameter to ringbuilder::rebalance.\n\nThis patch adds an optional seed parameter to the\nswift::ringbuilder::rebalance definition. The seed\nparameter can be useful if you want to (manually)\ngenerate rings on independant servers and ensure that\nthe partition assignments are the same.\n\nChange-Id: I840b8fe0125ed25e84f7681fada1b1102e48f32b\n(cherry picked from commit b8b443416de65f59dfc2dcfa23bfa7222906f55e)\n'}]",0,188942,bd7244ed58e89aca83aaeb17e570635f9e5f6285,10,4,1,8482,,,0,"Add seed parameter to ringbuilder::rebalance.

This patch adds an optional seed parameter to the
swift::ringbuilder::rebalance definition. The seed
parameter can be useful if you want to (manually)
generate rings on independant servers and ensure that
the partition assignments are the same.

Change-Id: I840b8fe0125ed25e84f7681fada1b1102e48f32b
(cherry picked from commit b8b443416de65f59dfc2dcfa23bfa7222906f55e)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/42/188942/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/ringbuilder/rebalance.pp', 'spec/defines/swift_ringbuilder_rebalance_spec.rb']",2,bd7244ed58e89aca83aaeb17e570635f9e5f6285,," describe 'with valid seed' do let :params do { :seed => '999' } end let :title do 'object' end it { should contain_exec(""rebalance_object"").with( {:command => ""swift-ring-builder /etc/swift/object.builder rebalance 999"", :path => '/usr/bin', :refreshonly => true} )} end describe 'with an invalid seed' do let :title do 'object' end let :params do { :seed => 'invalid' } end it 'should raise an error' do expect { subject }.to raise_error(Puppet::Error) end end",,33,2
openstack%2Fpuppet-swift~stable%2Fjuno~Ica96e07b58472a12ac3a06893a4fa89c1799b081,openstack/puppet-swift,stable/juno,Ica96e07b58472a12ac3a06893a4fa89c1799b081,Remove unused fragment_title variable,MERGED,2015-06-05 22:11:00.000000000,2015-06-11 02:56:33.000000000,2015-06-11 02:56:33.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-05 22:11:00.000000000', 'files': ['manifests/proxy/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/a5b112cddd23598f776afcbf76e7a50e5ea750d3', 'message': ""Remove unused fragment_title variable\n\nThis variable was added in commit 020b772 but it doesn't\nappear that it was ever used.\n\nChange-Id: Ica96e07b58472a12ac3a06893a4fa89c1799b081\n(cherry picked from commit 15aa71f0015532fbe39b9f399c5bd000ca9b52c7)\n""}]",0,188948,a5b112cddd23598f776afcbf76e7a50e5ea750d3,10,4,1,8482,,,0,"Remove unused fragment_title variable

This variable was added in commit 020b772 but it doesn't
appear that it was ever used.

Change-Id: Ica96e07b58472a12ac3a06893a4fa89c1799b081
(cherry picked from commit 15aa71f0015532fbe39b9f399c5bd000ca9b52c7)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/48/188948/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/proxy/authtoken.pp'],1,a5b112cddd23598f776afcbf76e7a50e5ea750d3,,," $fragment_title = regsubst($name, '/', '_', 'G')",0,1
openstack%2Fpuppet-glance~stable%2Fjuno~If2eb52a6d0d9be89c9323702616f62f8ecba5e02,openstack/puppet-glance,stable/juno,If2eb52a6d0d9be89c9323702616f62f8ecba5e02,Fix is_public munge,MERGED,2015-06-01 20:32:43.000000000,2015-06-11 02:56:14.000000000,2015-06-11 02:56:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9500}, {'_account_id': 13294}]","[{'number': 1, 'created': '2015-06-01 20:32:43.000000000', 'files': ['lib/puppet/type/glance_image.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/e624368d1c6bfccb21915a75e0012251648947a3', 'message': ""Fix is_public munge\n\nCommit 031609b57284cf13877ce727c2e4672831a3dbe2 changed the way\nis_public was munged. However, when testing it it looks like it\nwas always seen as an empty string after this, so all created\nimages were private. Changing the way the 'if' block is done fixes\nit.\n\nChange-Id: If2eb52a6d0d9be89c9323702616f62f8ecba5e02\n""}]",0,187318,e624368d1c6bfccb21915a75e0012251648947a3,10,6,1,8482,,,0,"Fix is_public munge

Commit 031609b57284cf13877ce727c2e4672831a3dbe2 changed the way
is_public was munged. However, when testing it it looks like it
was always seen as an empty string after this, so all created
images were private. Changing the way the 'if' block is done fixes
it.

Change-Id: If2eb52a6d0d9be89c9323702616f62f8ecba5e02
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/18/187318/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/type/glance_image.rb'],1,e624368d1c6bfccb21915a75e0012251648947a3,187317, if v =~ /^(y|Y)es$/ 'True' elsif v =~ /^(n|N)o$/ 'False' end, 'True' if v =~ /^(y|Y)es$/ 'False' if v =~ /^(n|N)o$/,5,2
openstack%2Fpuppet-swift~stable%2Fjuno~Ia230720e2cafb5b03404cea1ba54dd3b0ced6af3,openstack/puppet-swift,stable/juno,Ia230720e2cafb5b03404cea1ba54dd3b0ced6af3,Handle both string and array for memcache param.,MERGED,2015-06-05 22:14:04.000000000,2015-06-11 02:54:05.000000000,2015-06-11 02:54:03.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 16133}]","[{'number': 1, 'created': '2015-06-05 22:14:04.000000000', 'files': ['manifests/proxy/cache.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/3d608ac65b82724db5453392d44fbd8144357531', 'message': 'Handle both string and array for memcache param.\n\nEvaluation Error: Left match operand must result in a String value. Got\nan Array. at .../modules/swift/manifests/proxy/cache.pp:26:6\n\nPlease note that Puppet syntax, while it defines a regex type, does NOT\npermit regex type arguments to be passed to functions (as literals or\nassigned to variables).\n\nChange-Id: Ia230720e2cafb5b03404cea1ba54dd3b0ced6af3\nCloses-Bug: #1449272\nSigned-off-by: Robin H. Johnson <robbat2@gentoo.org>\n(cherry picked from commit ef9f9a4194237b3cd00446f42d1b407d203cbfd5)\n'}]",0,188950,3d608ac65b82724db5453392d44fbd8144357531,10,4,1,8482,,,0,"Handle both string and array for memcache param.

Evaluation Error: Left match operand must result in a String value. Got
an Array. at .../modules/swift/manifests/proxy/cache.pp:26:6

Please note that Puppet syntax, while it defines a regex type, does NOT
permit regex type arguments to be passed to functions (as literals or
assigned to variables).

Change-Id: Ia230720e2cafb5b03404cea1ba54dd3b0ced6af3
Closes-Bug: #1449272
Signed-off-by: Robin H. Johnson <robbat2@gentoo.org>
(cherry picked from commit ef9f9a4194237b3cd00446f42d1b407d203cbfd5)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/50/188950/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/proxy/cache.pp'],1,3d608ac65b82724db5453392d44fbd8144357531,," if grep(any2array($memcache_servers), '^127\.0\.0\.1') {", if $memcache_servers =~ /^127\.0\.0\.1/ {,1,1
openstack%2Fpuppet-swift~stable%2Fjuno~Iddfa6416e68127f874ce38edcdf1e208def2473f,openstack/puppet-swift,stable/juno,Iddfa6416e68127f874ce38edcdf1e208def2473f,Fix concat file mode,MERGED,2015-06-05 22:15:27.000000000,2015-06-11 02:53:38.000000000,2015-06-11 02:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-06-05 22:15:27.000000000', 'files': ['manifests/storage/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/d854c8298c366c1c8c1b88759ecdb6ba690ffe27', 'message': 'Fix concat file mode\n\nThe concat module passes the file permissions straight through to a file\nresource, so for this to work in future parser then the mode has to be a\nquoted string.\n\nChange-Id: Iddfa6416e68127f874ce38edcdf1e208def2473f\n(cherry picked from commit 3ceea9fa89cfe9c26c79146479a97c2519c332f7)\n'}]",0,188951,d854c8298c366c1c8c1b88759ecdb6ba690ffe27,10,4,1,8482,,,0,"Fix concat file mode

The concat module passes the file permissions straight through to a file
resource, so for this to work in future parser then the mode has to be a
quoted string.

Change-Id: Iddfa6416e68127f874ce38edcdf1e208def2473f
(cherry picked from commit 3ceea9fa89cfe9c26c79146479a97c2519c332f7)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/51/188951/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/storage/server.pp'],1,d854c8298c366c1c8c1b88759ecdb6ba690ffe27,," mode => '0640',"," mode => 640,",1,1
openstack%2Fpython-openstackclient~master~I4055698d0e4492a17623836e802ac56cd869ab0a,openstack/python-openstackclient,master,I4055698d0e4492a17623836e802ac56cd869ab0a,Updated from global requirements,MERGED,2015-06-11 00:48:28.000000000,2015-06-11 02:52:59.000000000,2015-06-11 02:52:58.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-11 00:48:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f3725b4761fb4cb6765a75d6cd2c861f5af99f1a', 'message': 'Updated from global requirements\n\nChange-Id: I4055698d0e4492a17623836e802ac56cd869ab0a\n'}]",0,190438,f3725b4761fb4cb6765a75d6cd2c861f5af99f1a,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I4055698d0e4492a17623836e802ac56cd869ab0a
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/38/190438/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f3725b4761fb4cb6765a75d6cd2c861f5af99f1a,openstack/requirements,stevedore>=1.5.0 # Apache-2.0,stevedore>=1.3.0 # Apache-2.0,1,1
openstack%2Fpuppet-swift~stable%2Fjuno~I173fd7b916456a96642458ef52f2af1edfa58841,openstack/puppet-swift,stable/juno,I173fd7b916456a96642458ef52f2af1edfa58841,mount.pp: fix lint issue,MERGED,2015-06-05 22:15:56.000000000,2015-06-11 02:52:37.000000000,2015-06-11 02:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-05 22:15:56.000000000', 'files': ['manifests/storage/mount.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/de5d5ad70c884dc27b1f6e1d73829a12479b6a6a', 'message': 'mount.pp: fix lint issue\n\nMake sure ::selinux fact is a boolean to support all\nversions of Facter.\n\nChange-Id: I173fd7b916456a96642458ef52f2af1edfa58841\n(cherry picked from commit 49fd248002605b80a51a35d254fdfca0736502e5)\n'}]",0,188952,de5d5ad70c884dc27b1f6e1d73829a12479b6a6a,10,3,1,8482,,,0,"mount.pp: fix lint issue

Make sure ::selinux fact is a boolean to support all
versions of Facter.

Change-Id: I173fd7b916456a96642458ef52f2af1edfa58841
(cherry picked from commit 49fd248002605b80a51a35d254fdfca0736502e5)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/52/188952/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/storage/mount.pp'],1,de5d5ad70c884dc27b1f6e1d73829a12479b6a6a,," # It would be definitely nice if passing options uid=,gid= if (str2bool($::selinux) == true) {"," # It would be definetly nice if passing options uid=,gid= if ($::selinux == 'true') {",2,2
openstack%2Ftempest~master~Ibadb2c55f40e0bd7a7787f93fd7c3f8da706303e,openstack/tempest,master,Ibadb2c55f40e0bd7a7787f93fd7c3f8da706303e,Added neutron cli test case,ABANDONED,2014-08-18 07:04:42.000000000,2015-06-11 02:52:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-18 07:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b153640116b6799e07ab94fb715137627dbe2c30', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nneutron-net-list-on-dhcp-agent\n\nChange-Id: Ibadb2c55f40e0bd7a7787f93fd7c3f8da706303e\n'}, {'number': 2, 'created': '2014-09-15 06:15:57.000000000', 'files': ['tempest/cli/simple_read_only/network/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/df1fff3897fed148dcb1b0b379ad3d9d443ef906', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nneutron-net-list-on-dhcp-agent\nChange-Id: Ibadb2c55f40e0bd7a7787f93fd7c3f8da706303e\n'}]",5,114897,df1fff3897fed148dcb1b0b379ad3d9d443ef906,15,5,2,12837,,,0,"Added neutron cli test case

Test case added for below CLI:-
neutron-net-list-on-dhcp-agent
Change-Id: Ibadb2c55f40e0bd7a7787f93fd7c3f8da706303e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/97/114897/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_neutron.py'],1,b153640116b6799e07ab94fb715137627dbe2c30,neutronCli_test," @test.attr(type='smoke') @test.requires_ext(extension='dhcp_agent_scheduler', service='network') def test_neutron_net_list_on_dhcp_agent(self): agent_list = self.parser.listing(self.neutron('agent-list')) for agent in agent_list: if agent['agent_type'] == ""DHCP agent"": net_list = self.parser.listing(self.neutron ('net-list-on-dhcp-agent', params=agent['id'])) self.assertTableStruct(net_list, ['id', 'name', 'subnets']) ",,12,0
openstack%2Ftempest~master~Ibd2da6d2952bab6ef4cb630a52f28c0bfd0eb2d1,openstack/tempest,master,Ibd2da6d2952bab6ef4cb630a52f28c0bfd0eb2d1,Added neutron cli test case,ABANDONED,2014-08-20 12:32:15.000000000,2015-06-11 02:50:36.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 12837}, {'_account_id': 12838}]","[{'number': 1, 'created': '2014-08-20 12:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f5928d72169b569da25c8eef066c925a78e1ad5', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nagent-show\n\nChange-Id: Ibd2da6d2952bab6ef4cb630a52f28c0bfd0eb2d1\n'}, {'number': 2, 'created': '2014-09-15 07:47:29.000000000', 'files': ['tempest/cli/simple_read_only/network/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1521909e219be8bd7d7a7edf1006a9f47278f766', 'message': 'Added neutron cli test case\n\nTest case added for below CLI:-\nagent-show\nChange-Id: Ibd2da6d2952bab6ef4cb630a52f28c0bfd0eb2d1\n'}]",5,115621,1521909e219be8bd7d7a7edf1006a9f47278f766,28,9,2,12837,,,0,"Added neutron cli test case

Test case added for below CLI:-
agent-show
Change-Id: Ibd2da6d2952bab6ef4cb630a52f28c0bfd0eb2d1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/21/115621/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_neutron.py'],1,1f5928d72169b569da25c8eef066c925a78e1ad5,neutronCLI_test," @test.requires_ext(extension='agent', service='network') def test_neutron_agent_show(self): agents = self.parser.listing(self.neutron('agent-list')) for agent in agents: output = self.parser.listing(self.neutron('agent-show', params=agent['id'])) self.assertTableStruct(output, ['Field', 'Value']) @test.attr(type='smoke')",,9,0
openstack%2Fcinder~master~I82dc89b4a65c5bc5d08117ed5d18bf503975e4c4,openstack/cinder,master,I82dc89b4a65c5bc5d08117ed5d18bf503975e4c4,Fix Python 3 issues,ABANDONED,2015-05-25 15:29:14.000000000,2015-06-11 02:46:26.000000000,,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11611}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 16595}]","[{'number': 1, 'created': '2015-05-25 15:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e5665c29b081a59a9bbd20b239e3bc298a48116a', 'message': 'Fix Python 3 issues\n\n* Replace basestring with six.string_types\n* Replace unicode with six.text_type\n* Replace 123L with 123: ""123L"" is a syntax error on Python 3\n* Replace ""raise a, b, c"" with ""six.reraise(a, b, c)""\n* Replace it.next() with next(it). next(it) works on Python 2 and\n  Python 3. The next() method of iterators was renamed to __next__() in\n  Python 3.\n* Replace dict.itervalues() with six.itervalues(dict)\n\nThis patch was generated by the sixer tool using the basestring,\nitervalues, long, next and raise operations:\nhttps://pypi.python.org/pypi/sixer\n\nManual changes:\n\n* cinder/volume/drivers/san/hp/hp_3par_iscsi.py:\n  replace ""isinstance(value, str) or isinstance(value, unicode)""\n  with ""isinstance(value, six.string_types)""\n* reformat code to respect the 80 columns constraint\n* cinder/tests/unit/test_cmd.py: use ""tpgs = iter([tpg])"" instead of\n  using a magic mock for tpgs\n\nFor more information on Python 3, see:\nhttps://wiki.openstack.org/wiki/Python3\n\nChange-Id: I82dc89b4a65c5bc5d08117ed5d18bf503975e4c4\n'}, {'number': 2, 'created': '2015-06-09 12:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/54715cc1f662ee0a7d073ec9238ba0f62e28d451', 'message': 'Fix Python 3 issues\n\n* Replace basestring with six.string_types\n* Replace unicode with six.text_type\n* Replace 123L with 123: ""123L"" is a syntax error on Python 3\n* Replace ""raise a, b, c"" with ""six.reraise(a, b, c)""\n* Replace it.next() with next(it). next(it) works on Python 2 and\n  Python 3. The next() method of iterators was renamed to __next__() in\n  Python 3.\n* Replace dict.itervalues() with six.itervalues(dict)\n\nThis patch was generated by the sixer tool using the basestring,\nitervalues, long, next and raise operations:\nhttps://pypi.python.org/pypi/sixer\n\nManual changes:\n\n* cinder/volume/drivers/san/hp/hp_3par_iscsi.py:\n  replace ""isinstance(value, str) or isinstance(value, unicode)""\n  with ""isinstance(value, six.string_types)""\n* reformat code to respect the 80 columns constraint\n* cinder/tests/unit/test_cmd.py: use ""tpgs = iter([tpg])"" instead of\n  using a magic mock for tpgs\n\nFor more information on Python 3, see:\nhttps://wiki.openstack.org/wiki/Python3\n\nChange-Id: I82dc89b4a65c5bc5d08117ed5d18bf503975e4c4\n'}, {'number': 3, 'created': '2015-06-09 12:40:29.000000000', 'files': ['cinder/backup/manager.py', 'cinder/api/contrib/admin_actions.py', 'cinder/tests/unit/test_ibm_flashsystem.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/scheduler/host_manager.py', 'cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/api/urlmap.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/exception.py', 'cinder/volume/drivers/emc/emc_vmax_provision_v3.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/quota.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/api/contrib/volume_actions.py', 'cinder/cmd/rtstool.py', 'cinder/volume/drivers/lvm.py', 'cinder/volume/drivers/netapp/dataontap/client/client_base.py', 'cinder/tests/unit/api/openstack/test_wsgi.py', 'cinder/volume/drivers/datera.py', 'cinder/context.py', 'cinder/volume/throttling.py', 'cinder/image/glance.py', 'cinder/tests/unit/test_emc_vmax.py', 'cinder/tests/unit/test_cmd.py', 'cinder/tests/unit/test_backup_tsm.py', 'cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/drivers/emc/emc_vmax_https.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/tests/unit/fake_utils.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/api/xmlutil.py', 'cinder/volume/drivers/violin/v6000_common.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/api/openstack/wsgi.py', 'cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f00b8acca96658cb5f49bdd349d96ef66f42d69a', 'message': 'Fix Python 3 issues\n\n* Replace basestring with six.string_types\n* Replace unicode with six.text_type\n* Replace 123L with 123: ""123L"" is a syntax error on Python 3\n* Replace ""raise a, b, c"" with ""six.reraise(a, b, c)""\n* Replace it.next() with next(it). next(it) works on Python 2 and\n  Python 3. The next() method of iterators was renamed to __next__() in\n  Python 3.\n* Replace dict.itervalues() with six.itervalues(dict)\n* hp_3par_common: bump version to 2.0.42\n* hp_3par_iscsi: bump version to 2.0.17\n\nThis patch was generated by the sixer tool using the basestring,\nitervalues, long, next and raise operations:\nhttps://pypi.python.org/pypi/sixer\n\nManual changes:\n\n* cinder/volume/drivers/san/hp/hp_3par_iscsi.py:\n  replace ""isinstance(value, str) or isinstance(value, unicode)""\n  with ""isinstance(value, six.string_types)""\n* reformat code to respect the 80 columns constraint\n* cinder/tests/unit/test_cmd.py: use ""tpgs = iter([tpg])"" instead of\n  using a magic mock for tpgs\n\nFor more information on Python 3, see:\nhttps://wiki.openstack.org/wiki/Python3\n\nChange-Id: I82dc89b4a65c5bc5d08117ed5d18bf503975e4c4\n'}]",8,185410,f00b8acca96658cb5f49bdd349d96ef66f42d69a,51,28,3,9107,,,0,"Fix Python 3 issues

* Replace basestring with six.string_types
* Replace unicode with six.text_type
* Replace 123L with 123: ""123L"" is a syntax error on Python 3
* Replace ""raise a, b, c"" with ""six.reraise(a, b, c)""
* Replace it.next() with next(it). next(it) works on Python 2 and
  Python 3. The next() method of iterators was renamed to __next__() in
  Python 3.
* Replace dict.itervalues() with six.itervalues(dict)
* hp_3par_common: bump version to 2.0.42
* hp_3par_iscsi: bump version to 2.0.17

This patch was generated by the sixer tool using the basestring,
itervalues, long, next and raise operations:
https://pypi.python.org/pypi/sixer

Manual changes:

* cinder/volume/drivers/san/hp/hp_3par_iscsi.py:
  replace ""isinstance(value, str) or isinstance(value, unicode)""
  with ""isinstance(value, six.string_types)""
* reformat code to respect the 80 columns constraint
* cinder/tests/unit/test_cmd.py: use ""tpgs = iter([tpg])"" instead of
  using a magic mock for tpgs

For more information on Python 3, see:
https://wiki.openstack.org/wiki/Python3

Change-Id: I82dc89b4a65c5bc5d08117ed5d18bf503975e4c4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/185410/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/backup/manager.py', 'cinder/api/contrib/admin_actions.py', 'cinder/tests/unit/test_ibm_flashsystem.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/db/sqlalchemy/api.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py', 'cinder/scheduler/host_manager.py', 'cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/api/urlmap.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/exception.py', 'cinder/volume/drivers/emc/emc_vmax_provision_v3.py', 'cinder/tests/unit/test_storwize_svc.py', 'cinder/volume/drivers/san/hp/hp_3par_iscsi.py', 'cinder/quota.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py', 'cinder/api/contrib/volume_actions.py', 'cinder/cmd/rtstool.py', 'cinder/volume/drivers/lvm.py', 'cinder/volume/drivers/netapp/dataontap/client/client_base.py', 'cinder/tests/unit/api/openstack/test_wsgi.py', 'cinder/volume/drivers/datera.py', 'cinder/context.py', 'cinder/volume/throttling.py', 'cinder/image/glance.py', 'cinder/tests/unit/test_emc_vmax.py', 'cinder/tests/unit/test_cmd.py', 'cinder/tests/unit/test_backup_tsm.py', 'cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/ibm/storwize_svc/ssh.py', 'cinder/volume/drivers/emc/emc_vmax_https.py', 'cinder/volume/drivers/ibm/storwize_svc/__init__.py', 'cinder/tests/unit/fake_utils.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/api/xmlutil.py', 'cinder/volume/drivers/violin/v6000_common.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/api/openstack/wsgi.py', 'cinder/utils.py']",39,e5665c29b081a59a9bbd20b239e3bc298a48116a,py3," if isinstance(hostname, six.text_type):"," if isinstance(hostname, unicode):",185,172
openstack%2Fpuppet-cinder~stable%2Fjuno~Iab8b1530ee349bd2c4143f82dfa2a26018eb8efa,openstack/puppet-cinder,stable/juno,Iab8b1530ee349bd2c4143f82dfa2a26018eb8efa,Don't add a new line if the rbd_user changes,MERGED,2015-06-02 04:08:14.000000000,2015-06-11 02:44:44.000000000,2015-06-11 02:44:42.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 10263}, {'_account_id': 10540}, {'_account_id': 15313}]","[{'number': 1, 'created': '2015-06-02 04:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/5dec2cc0db3e92e66b58f55873ef0d94c8ed8f8d', 'message': ""Don't add a new line if the rbd_user changes\n\nChange-Id: Iab8b1530ee349bd2c4143f82dfa2a26018eb8efa\nCloses-Bug: #1284742\n(cherry picked from commit 3641ea9547e2ba9fb5107e160e76b57d576a5cb3)\n""}, {'number': 2, 'created': '2015-06-04 21:09:09.000000000', 'files': ['manifests/backend/rbd.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/869fa2edcd14dc30f078e58d84d73330e2b284cd', 'message': ""Don't add a new line if the rbd_user changes\n\nChange-Id: Iab8b1530ee349bd2c4143f82dfa2a26018eb8efa\nCloses-Bug: #1284742\n(cherry picked from commit 3641ea9547e2ba9fb5107e160e76b57d576a5cb3)\n""}]",0,187448,869fa2edcd14dc30f078e58d84d73330e2b284cd,13,6,2,9500,,,0,"Don't add a new line if the rbd_user changes

Change-Id: Iab8b1530ee349bd2c4143f82dfa2a26018eb8efa
Closes-Bug: #1284742
(cherry picked from commit 3641ea9547e2ba9fb5107e160e76b57d576a5cb3)
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/48/187448/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/backend/rbd.pp'],1,5dec2cc0db3e92e66b58f55873ef0d94c8ed8f8d,," $override_match = '^env CEPH_ARGS=' $override_match = '^export CEPH_ARGS=' match => $override_match,",,3,0
openstack%2Fheat-translator~master~I571969ec9fc377298e76182e47c6d20a6fa4cce0,openstack/heat-translator,master,I571969ec9fc377298e76182e47c6d20a6fa4cce0,Add unit tests for parsing timestamps,ABANDONED,2015-06-10 07:53:12.000000000,2015-06-11 02:43:00.000000000,,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-06-10 07:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/b8455887ca32b80ee9b7b94ebcf05f9c5aa0df60', 'message': 'Add unit tests for parsing timestamps\n\nthis is part of a greater effort to move away from python_dateutil\nto oslo.utils or datetime. but at a minimum we should include tests\non valid and invalid times so that if/when we switch over, we can\nbe sure we are not regressing.\n\nChange-Id: I571969ec9fc377298e76182e47c6d20a6fa4cce0\n'}, {'number': 2, 'created': '2015-06-10 17:10:10.000000000', 'files': ['translator/toscalib/tests/test_constraints.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/52eaba39c5f817236c1d1ac5d695a1c778e865db', 'message': 'Add unit tests for parsing timestamps\n\nthis is part of a greater effort to move away from python_dateutil\nto oslo.utils or datetime. but at a minimum we should include tests\non valid and invalid times so that if/when we switch over, we can\nbe sure we are not regressing.\n\nChange-Id: I571969ec9fc377298e76182e47c6d20a6fa4cce0\n'}]",2,190056,52eaba39c5f817236c1d1ac5d695a1c778e865db,7,3,2,6482,,,0,"Add unit tests for parsing timestamps

this is part of a greater effort to move away from python_dateutil
to oslo.utils or datetime. but at a minimum we should include tests
on valid and invalid times so that if/when we switch over, we can
be sure we are not regressing.

Change-Id: I571969ec9fc377298e76182e47c6d20a6fa4cce0
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/56/190056/1 && git format-patch -1 --stdout FETCH_HEAD,['translator/toscalib/tests/test_constraints.py'],1,b8455887ca32b80ee9b7b94ebcf05f9c5aa0df60,use_oslo_utils,"from translator.toscalib.elements import constraints def test_valid_timestamps(self): """"""Verify a set of sample times."""""" CANONICAL_TIME = ""2001-12-15T02:59:43.1Z"" VALID_ISO_TIME = ""2001-12-14T21:59:43.10-05:00"" SPACE_SEPARATED_TIME = ""2001-12-14 21:59:43.10 -5"" NO_TIME_ZONE_TIME = ""2001-12-15 2:59:43.10"" VALID_ISO_LOWER_CASE_TIME = ""2001-12-14t21:59:43.10-05:00"" valid_times = [CANONICAL_TIME, VALID_ISO_TIME, SPACE_SEPARATED_TIME, NO_TIME_ZONE_TIME, VALID_ISO_LOWER_CASE_TIME] for time in valid_times: Constraint.validate_timestamp(time) def test_invalid_timestamp_format(self): SIMPLE_DATE_TIME = ""(00:00:00Z): 2002-12-14"" self.assertRaises(ValueError, Constraint.validate_timestamp, SIMPLE_DATE_TIME)",,26,0
openstack%2Fpython-keystoneclient~master~I98c3d7695bbfe3a6a4f23990af45a07dc147f22f,openstack/python-keystoneclient,master,I98c3d7695bbfe3a6a4f23990af45a07dc147f22f,Iterate over copy of sys.modules keys in Python2/3,MERGED,2015-06-09 17:52:25.000000000,2015-06-11 02:41:38.000000000,2015-06-11 02:41:36.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-06-09 17:52:25.000000000', 'files': ['keystoneclient/tests/unit/utils.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d99c56fa531ba149df84f7a1178ec9a2a740f1ee', 'message': ""Iterate over copy of sys.modules keys in Python2/3\n\nIterate over a copy of sys.modules keys in both Python 2.x and\nPython 3.x.  In Python 3.x, keys() is not a copy, and therefore\nitems can't be popped from it while iterating.\n\nChange-Id: I98c3d7695bbfe3a6a4f23990af45a07dc147f22f\nCloses-Bug: #1463503\n""}]",0,189834,d99c56fa531ba149df84f7a1178ec9a2a740f1ee,8,4,1,11805,,,0,"Iterate over copy of sys.modules keys in Python2/3

Iterate over a copy of sys.modules keys in both Python 2.x and
Python 3.x.  In Python 3.x, keys() is not a copy, and therefore
items can't be popped from it while iterating.

Change-Id: I98c3d7695bbfe3a6a4f23990af45a07dc147f22f
Closes-Bug: #1463503
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/34/189834/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/tests/unit/utils.py'],1,d99c56fa531ba149df84f7a1178ec9a2a740f1ee,bug/1463503, for fullname in list(sys.modules):, for fullname in sys.modules.keys():,1,1
openstack%2Fkeystonemiddleware~master~I521dc07b17b21d93ae601870b81c0229251124a3,openstack/keystonemiddleware,master,I521dc07b17b21d93ae601870b81c0229251124a3,Fixes a spelling error in a test name,MERGED,2015-06-08 16:46:49.000000000,2015-06-11 02:40:57.000000000,2015-06-11 02:40:56.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 9382}]","[{'number': 1, 'created': '2015-06-08 16:46:49.000000000', 'files': ['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8723d88b59b848e6c2ae09ff11b5a70f891aecf1', 'message': 'Fixes a spelling error in a test name\n\nChange-Id: I521dc07b17b21d93ae601870b81c0229251124a3\n'}]",0,189365,8723d88b59b848e6c2ae09ff11b5a70f891aecf1,8,4,1,7725,,,0,"Fixes a spelling error in a test name

Change-Id: I521dc07b17b21d93ae601870b81c0229251124a3
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/65/189365/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py'],1,8723d88b59b848e6c2ae09ff11b5a70f891aecf1,, def test_invalid_plugin_fails_to_initialize(self):, def test_invalid_plugin_fails_to_intialize(self):,1,1
openstack%2Fkeystonemiddleware~master~I6e6aecfa44bc96ca70ad99c56feb2d281c6410e0,openstack/keystonemiddleware,master,I6e6aecfa44bc96ca70ad99c56feb2d281c6410e0,Updated from global requirements,MERGED,2015-06-11 00:42:49.000000000,2015-06-11 02:34:51.000000000,2015-06-11 02:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-06-11 00:42:49.000000000', 'files': ['test-requirements.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/5690dc11dab11c563918c6bbd5684e5f32930324', 'message': 'Updated from global requirements\n\nChange-Id: I6e6aecfa44bc96ca70ad99c56feb2d281c6410e0\n'}]",0,190428,5690dc11dab11c563918c6bbd5684e5f32930324,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I6e6aecfa44bc96ca70ad99c56feb2d281c6410e0
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/28/190428/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'test-requirements-py3.txt']",2,5690dc11dab11c563918c6bbd5684e5f32930324,openstack/requirements,stevedore>=1.5.0 # Apache-2.0,stevedore>=1.3.0 # Apache-2.0,2,2
openstack%2Fkeystoneauth~master~I5114dc7ef658565d82d922dded88f0e6cf484335,openstack/keystoneauth,master,I5114dc7ef658565d82d922dded88f0e6cf484335,removed custom assertDictEqual,MERGED,2015-06-08 14:54:10.000000000,2015-06-11 02:34:28.000000000,2015-06-11 02:34:26.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 9382}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-08 14:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/7c8bc926c2e65d6039afc124a337c78ddde6865d', 'message': 'removed custom assertDictEqual\n\nChange-Id: I5114dc7ef658565d82d922dded88f0e6cf484335\n'}, {'number': 2, 'created': '2015-06-09 14:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/eaf440ad909973fb643aed3d6a3dedbe7195bf98', 'message': 'removed custom assertDictEqual\n\nassertDictEqual is implemented in unittest2 which is used for tests\n\nChange-Id: I5114dc7ef658565d82d922dded88f0e6cf484335\n'}, {'number': 3, 'created': '2015-06-09 14:42:05.000000000', 'files': ['keystoneauth/tests/unit/utils.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/f503bdd9a85c0267d6e9883a5039224e20b1e84b', 'message': 'removed custom assertDictEqual\n\nassertDictEqual is implemented in unittest2 which is a dependency for\ntesttools which is used in tests\n\nChange-Id: I5114dc7ef658565d82d922dded88f0e6cf484335\n'}]",0,189320,f503bdd9a85c0267d6e9883a5039224e20b1e84b,13,5,3,13478,,,0,"removed custom assertDictEqual

assertDictEqual is implemented in unittest2 which is a dependency for
testtools which is used in tests

Change-Id: I5114dc7ef658565d82d922dded88f0e6cf484335
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/20/189320/2 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth/tests/unit/utils.py'],1,7c8bc926c2e65d6039afc124a337c78ddde6865d,cleanup,,"if tuple(sys.version_info)[0:2] < (2, 7): def assertDictEqual(self, d1, d2, msg=None): # Simple version taken from 2.7 self.assertIsInstance(d1, dict, 'First argument is not a dictionary') self.assertIsInstance(d2, dict, 'Second argument is not a dictionary') if d1 != d2: if msg: self.fail(msg) else: standardMsg = '%r != %r' % (d1, d2) self.fail(standardMsg) TestCase.assertDictEqual = assertDictEqual ",0,18
openstack%2Ftaskflow~master~Ib8345d536a1d4895d7f91ad415545c3573b09e10,openstack/taskflow,master,Ib8345d536a1d4895d7f91ad415545c3573b09e10,Updated from global requirements,MERGED,2015-06-10 23:50:44.000000000,2015-06-11 02:31:08.000000000,2015-06-11 02:31:07.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-06-10 23:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/67af7b83d7d10e529ac24239b3ff0260365a712b', 'message': 'Updated from global requirements\n\nChange-Id: Ib8345d536a1d4895d7f91ad415545c3573b09e10\n'}, {'number': 2, 'created': '2015-06-11 00:49:03.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4b28b32778de58ff6b893bba1438c54c2092e5dc', 'message': 'Updated from global requirements\n\nChange-Id: Ib8345d536a1d4895d7f91ad415545c3573b09e10\n'}]",0,190412,4b28b32778de58ff6b893bba1438c54c2092e5dc,10,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ib8345d536a1d4895d7f91ad415545c3573b09e10
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/12/190412/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,67af7b83d7d10e529ac24239b3ff0260365a712b,openstack/requirements,"SQLAlchemy>=0.9.7,<1.1.0","SQLAlchemy>=0.9.7,<=0.9.99",1,1
openstack%2Fpython-keystoneclient~master~I299a6998ccbe237a244473aff08697c20e606623,openstack/python-keystoneclient,master,I299a6998ccbe237a244473aff08697c20e606623,Updated from global requirements,MERGED,2015-06-11 00:48:16.000000000,2015-06-11 02:28:40.000000000,2015-06-11 02:28:39.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-06-11 00:48:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/08783e0fb5e5277e9ac02d7bb94496d7ff4846dd', 'message': 'Updated from global requirements\n\nChange-Id: I299a6998ccbe237a244473aff08697c20e606623\n'}]",0,190436,08783e0fb5e5277e9ac02d7bb94496d7ff4846dd,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I299a6998ccbe237a244473aff08697c20e606623
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/36/190436/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,08783e0fb5e5277e9ac02d7bb94496d7ff4846dd,openstack/requirements,stevedore>=1.5.0 # Apache-2.0,stevedore>=1.3.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~Ibce2ff9e0a7a7f8b28cd63b02cafffe5bef697b6,openstack/openstack-manuals,master,Ibce2ff9e0a7a7f8b28cd63b02cafffe5bef697b6,fixed typo in networking guide,MERGED,2015-06-11 02:13:24.000000000,2015-06-11 02:27:22.000000000,2015-06-11 02:27:21.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 02:13:24.000000000', 'files': ['doc/common-rst/dashboard_customizing.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5291c43a09832b12ac0383d1987371faa37d2c38', 'message': 'fixed typo in networking guide\n\narritbute should be attribute - corrected\n\nChange-Id: Ibce2ff9e0a7a7f8b28cd63b02cafffe5bef697b6\n'}]",0,190462,5291c43a09832b12ac0383d1987371faa37d2c38,6,2,1,9382,,,0,"fixed typo in networking guide

arritbute should be attribute - corrected

Change-Id: Ibce2ff9e0a7a7f8b28cd63b02cafffe5bef697b6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/190462/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common-rst/dashboard_customizing.rst'],1,5291c43a09832b12ac0383d1987371faa37d2c38,db_cust, by editing the following attribute to the URL of your choice in, by editing the following arritbute to the URL of your choice in,1,1
openstack%2Foperations-guide~master~I52b214588f9d6c0e755c610d37731243f6401040,openstack/operations-guide,master,I52b214588f9d6c0e755c610d37731243f6401040,Updated from openstack-manuals,MERGED,2015-06-11 02:11:17.000000000,2015-06-11 02:25:43.000000000,2015-06-11 02:25:41.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 02:11:17.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/a2f1c40907a74163ad4ccafaad0092220ec289d7', 'message': 'Updated from openstack-manuals\n\nChange-Id: I52b214588f9d6c0e755c610d37731243f6401040\n'}]",0,190460,a2f1c40907a74163ad4ccafaad0092220ec289d7,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I52b214588f9d6c0e755c610d37731243f6401040
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/60/190460/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,a2f1c40907a74163ad4ccafaad0092220ec289d7,openstack/openstack-manuals," /etc/passwd, OpenLDAP, OpenStack Identity, and so on.</para> Identity service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity service, the worker process that service.</para> service.</para> service.</para> <para>The Identity service component that provides authentication <para>The Identity component that provides high-level <para>The storage method used by the Identity service catalog service authentication with the Identity service.</para> <para>An Identity service that lists API endpoints that are available to a user after authentication with the Identity service.</para> of the cloud; talks to services, such as Identity authentication, Object Storage, and node/storage workers through a <para>An Identity service token that is not associated with a specific opposed to using the Identity service.</para> service (glance).</para> <para>Alternative term for an Identity service catalog.</para> of Identity service, this is a call that is specific to the Identity and Compute. Requires Redis.</para> <para>The Identity service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity, <para>Alternative term for the Identity service API.</para> <primary>Identity</primary> <para>The source used by Identity service to retrieve user <glossterm>Identity</glossterm> <primary>Identity</primary> authentication system. The project name of Identity is <glossterm>Identity service API</glossterm> <primary>Identity service</primary> <secondary>Identity service API</secondary> <para>The API used to access the OpenStack Identity service provided <primary>Identity</primary> service.</para> service.</para> service.</para> service.</para> a password and a private key. Currently not supported in Identity.</para> Identity.</para> <para>Component of Identity that provides a rule-management service.</para> that typically shares only the Identity (keystone) with other both Identity and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity service role.</para> <para>An Identity service API access token that is associated with a service that implements delayed delete.</para> service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity service catalog.</para> Identity service catalog.</para> <para>An Identity service feature that enables services, such as securely with the Identity service.</para> Identity.</para> <para>An Identity service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity service. <para>An Identity service component that manages and validates tokens <para>Alternative term for an Identity service default token.</para> <para>In Identity, each user is associated with one or more service.</para> service.</para> service.</para>"," /etc/passwd, OpenLDAP, OpenStack Identity Service, and so on.</para> Identity Service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity Service, the worker process that Service.</para> Service.</para> Service.</para> <para>The Identity Service component that provides authentication <para>The Identity Service component that provides high-level <para>The storage method used by the Identity Service catalog service authentication with the Identity Service.</para> <para>An Identity Service that lists API endpoints that are available to a user after authentication with the Identity Service.</para> of the cloud; talks to services, such as Identity Service authentication, Object Storage, and node/storage workers through a <para>An Identity Service token that is not associated with a specific opposed to using the Identity Service.</para> Service (glance).</para> <para>Alternative term for an Identity Service catalog.</para> of Identity Service, this is a call that is specific to the Identity Service and Compute. Requires Redis.</para> <para>The Identity Service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity Service, <para>Alternative term for the Identity Service API.</para> <primary>Identity Service</primary> <para>The source used by Identity Service to retrieve user <glossterm>Identity Service</glossterm> <primary>Identity Service</primary> authentication system. The project name of the Identity Service is <glossterm>Identity Service API</glossterm> <primary>Identity Service</primary> <secondary>Identity Service API</secondary> <para>The API used to access the OpenStack Identity Service provided <primary>Identity Service</primary> Service.</para> Service.</para> Service.</para> Service.</para> a password and a private key. Currently not supported in Identity Service.</para> Identity Service.</para> <para>Component of Identity Service that provides a rule-management Service.</para> that typically shares only the Identity Service (keystone) with other both Identity Service and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity Service role.</para> <para>An Identity Service API access token that is associated with a Service that implements delayed delete.</para> Service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity Service catalog.</para> Identity Service catalog.</para> <para>An Identity Service feature that enables services, such as securely with the Identity Service.</para> Identity Service.</para> <para>An Identity Service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity Service. <para>An Identity Service component that manages and validates tokens <para>Alternative term for an Identity Service default token.</para> <para>In Identity Service, each user is associated with one or more Service.</para> Service.</para> Service.</para>",61,61
openstack%2Fapi-site~master~If11a43ea4642e9298be1829d0996946cb9a9a2f8,openstack/api-site,master,If11a43ea4642e9298be1829d0996946cb9a9a2f8,Updated from openstack-manuals,MERGED,2015-06-11 02:11:10.000000000,2015-06-11 02:24:01.000000000,2015-06-11 02:24:00.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2015-06-11 02:11:10.000000000', 'files': ['firstapp/source/imported/glossary.rst'], 'web_link': 'https://opendev.org/openstack/api-site/commit/af3a51c1251dd298717140e23c225b1bf914cae2', 'message': 'Updated from openstack-manuals\n\nChange-Id: If11a43ea4642e9298be1829d0996946cb9a9a2f8\n'}]",0,190458,af3a51c1251dd298717140e23c225b1bf914cae2,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: If11a43ea4642e9298be1829d0996946cb9a9a2f8
",git fetch https://review.opendev.org/openstack/api-site refs/changes/58/190458/1 && git format-patch -1 --stdout FETCH_HEAD,['firstapp/source/imported/glossary.rst'],1,af3a51c1251dd298717140e23c225b1bf914cae2,openstack/openstack-manuals," /etc/passwd, OpenLDAP, OpenStack Identity, and so on. Identity service, OpenLDAP, or similar user-account services. In the context of the Identity service, the worker process that service. service. service. The Identity service component that provides authentication The Identity component that provides high-level The storage method used by the Identity service catalog service authentication with the Identity service. An Identity service that lists API endpoints that are available to a user after authentication with the Identity service. of the cloud; talks to services, such as Identity authentication, Object Storage, and node/storage workers through a An Identity service token that is not associated with a specific opposed to using the Identity service. service (glance). Alternative term for an Identity service catalog. of Identity service, this is a call that is specific to the Identity and Compute. Requires Redis. The Identity service endpoint template that contains services Unique numeric ID associated with each user in Identity, Alternative term for the Identity service API. The source used by Identity service to retrieve user Identity authentication system. The project name of Identity is Identity service API The API used to access the OpenStack Identity service provided service. service. service. service. a password and a private key. Currently not supported in Identity. Identity. Component of Identity that provides a rule-management service. that typically shares only the Identity (keystone) with other both Identity and Compute and can be configured using the Alphanumeric ID assigned to each Identity service role. An Identity service API access token that is associated with a service that implements delayed delete. service. Provides one or more endpoints through which users can access Alternative term for the Identity service catalog. Identity service catalog. An Identity service feature that enables services, such as securely with the Identity service. Identity. An Identity service API endpoint that is associated with one or Unique ID assigned to each tenant within the Identity service. An Identity service component that manages and validates tokens Alternative term for an Identity service default token. In Identity, each user is associated with one or more service. service. service."," /etc/passwd, OpenLDAP, OpenStack Identity Service, and so on. Identity Service, OpenLDAP, or similar user-account services. In the context of the Identity Service, the worker process that Service. Service. Service. The Identity Service component that provides authentication The Identity Service component that provides high-level The storage method used by the Identity Service catalog service authentication with the Identity Service. An Identity Service that lists API endpoints that are available to a user after authentication with the Identity Service. of the cloud; talks to services, such as Identity Service authentication, Object Storage, and node/storage workers through a An Identity Service token that is not associated with a specific opposed to using the Identity Service. Service (glance). Alternative term for an Identity Service catalog. of Identity Service, this is a call that is specific to the Identity Service and Compute. Requires Redis. The Identity Service endpoint template that contains services Unique numeric ID associated with each user in Identity Service, Alternative term for the Identity Service API. The source used by Identity Service to retrieve user Identity Service authentication system. The project name of the Identity Service is Identity Service API The API used to access the OpenStack Identity Service provided Service. Service. Service. Service. a password and a private key. Currently not supported in Identity Service. Identity Service. Component of Identity Service that provides a rule-management Service. that typically shares only the Identity Service (keystone) with other both Identity Service and Compute and can be configured using the Alphanumeric ID assigned to each Identity Service role. An Identity Service API access token that is associated with a Service that implements delayed delete. Service. Provides one or more endpoints through which users can access Alternative term for the Identity Service catalog. Identity Service catalog. An Identity Service feature that enables services, such as securely with the Identity Service. Identity Service. An Identity Service API endpoint that is associated with one or Unique ID assigned to each tenant within the Identity Service. An Identity Service component that manages and validates tokens Alternative term for an Identity Service default token. In Identity Service, each user is associated with one or more Service. Service. Service.",56,56
openstack%2Fheat-translator~master~Iea19fe27acffda7c54db801b728a66ea427e8662,openstack/heat-translator,master,Iea19fe27acffda7c54db801b728a66ea427e8662,Installer scripts should not run simultaneously on the same server,MERGED,2015-05-14 22:25:34.000000000,2015-06-11 02:21:48.000000000,2015-06-11 02:21:46.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 9498}, {'_account_id': 9591}]","[{'number': 1, 'created': '2015-05-14 22:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2eaef8a308a7d374d14f644f184d10a532af1f67', 'message': ""Inject dependency between 'create' SoftwareDeployment resources\n\nDue to Linux's limitation of apt-get and yum utilities that cannot\nrun multiple sessions in parallel, SoftwareDeployment resources\nthat install some package, are deployed to the same server, and do\nnot have any dependency between them need to become dependent so\nthat the above limitation does not impact the deployment of the\ntranslated HOT template.\n\nEven thought for two independenct resources the direction of\ninjected dependency can be random, we use name comparison to make\nthe resource with bigger name dependent on the one with smaller\nname. This is simply to avoid tests failing.\n\nChange-Id: Iea19fe27acffda7c54db801b728a66ea427e8662\nCloses-Bug: #1455251\n""}, {'number': 2, 'created': '2015-05-26 17:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8c8e5103f9a09301457ced290bbdc1bf230cf2d6', 'message': ""Inject dependency between 'create' SoftwareDeployment resources\n\nDue to Linux's limitation of apt-get and yum utilities that cannot\nrun multiple sessions in parallel, SoftwareDeployment resources\nthat install some package, are deployed to the same server, and do\nnot have any dependency between them need to become dependent so\nthat the above limitation does not impact the deployment of the\ntranslated HOT template.\n\nEven thought for two independenct resources the direction of\ninjected dependency can be random, we use name comparison to make\nthe resource with bigger name dependent on the one with smaller\nname. This is simply to avoid tests failing.\n\nChange-Id: Iea19fe27acffda7c54db801b728a66ea427e8662\nCloses-Bug: #1455251\n""}, {'number': 3, 'created': '2015-06-10 18:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8a6419407e0735aa84c414338a28d295bf1f70e7', 'message': ""Inject dependency between 'create' SoftwareDeployment resources\n\nDue to Linux's limitation of apt-get and yum utilities that cannot\nrun multiple sessions in parallel, SoftwareDeployment resources\nthat install some package, are deployed to the same server, and do\nnot have any dependency between them could fail installing those\npackages. We update the scripts to verify no other install session\nis in progress before attemting an install. This needs to be done\nin any future installer script that makes use of such utilities.\n\nChange-Id: Iea19fe27acffda7c54db801b728a66ea427e8662\nCloses-Bug: #1455251\n""}, {'number': 4, 'created': '2015-06-10 18:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4a42373f9e2fd720afeab2bd45135f3a841f016b', 'message': ""Inject dependency between 'create' SoftwareDeployment resources\n\nDue to Linux's limitation of apt-get and yum utilities that cannot\nrun multiple sessions in parallel, SoftwareDeployment resources\nthat install some package, are deployed to the same server, and do\nnot have any dependency between them could fail installing those\npackages. We update the scripts to verify no other install session\nis in progress before attemting an install. This needs to be done\nin any future installer script that makes use of such utilities.\n\nChange-Id: Iea19fe27acffda7c54db801b728a66ea427e8662\nCloses-Bug: #1455251\nCloses-Bug: #1463595\n""}, {'number': 5, 'created': '2015-06-10 19:55:03.000000000', 'files': ['translator/toscalib/tests/artifacts/nodejs/create.sh', 'translator/toscalib/tests/artifacts/rsyslog/create.sh', 'translator/toscalib/tests/artifacts/logstash/create.sh', 'translator/toscalib/tests/artifacts/elasticsearch/create.sh', 'translator/toscalib/tests/artifacts/collectd/create.sh', 'translator/toscalib/tests/artifacts/mysql/mysql_dbms_install.sh', 'translator/toscalib/tests/artifacts/webserver/webserver_install.sh', 'translator/toscalib/tests/artifacts/wordpress/wordpress_install.sh', 'translator/toscalib/tests/artifacts/mongodb/create.sh'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/ae6585fe5ecb30185d606b0ac6d707e1cd742d76', 'message': ""Installer scripts should not run simultaneously on the same server\n\nDue to Linux's limitation of apt-get and yum utilities that cannot\nrun multiple sessions in parallel, SoftwareDeployment resources\nthat install some package, are deployed to the same server, and do\nnot have any dependency between them could fail installing those\npackages. We update the scripts to verify no other install session\nis in progress before attemting an install. This needs to be done\nin any future installer script that makes use of such utilities.\n\nChange-Id: Iea19fe27acffda7c54db801b728a66ea427e8662\nCloses-Bug: #1455251\nCloses-Bug: #1463595\n""}]",7,183333,ae6585fe5ecb30185d606b0ac6d707e1cd742d76,20,4,5,9498,,,0,"Installer scripts should not run simultaneously on the same server

Due to Linux's limitation of apt-get and yum utilities that cannot
run multiple sessions in parallel, SoftwareDeployment resources
that install some package, are deployed to the same server, and do
not have any dependency between them could fail installing those
packages. We update the scripts to verify no other install session
is in progress before attemting an install. This needs to be done
in any future installer script that makes use of such utilities.

Change-Id: Iea19fe27acffda7c54db801b728a66ea427e8662
Closes-Bug: #1455251
Closes-Bug: #1463595
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/33/183333/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/tests/data/hot_output/hot_single_instance_wordpress.yaml', 'translator/hot/translate_node_templates.py']",2,2eaef8a308a7d374d14f644f184d10a532af1f67,bug/1455251,"import itertools # Avoid situations where two 'create' lifecycle operations can run # concurrently by injecting a dependency between them. # step #1: find all create_deploy resources and store them by server. deployment_dict = {} for resource in self.hot_resources: if resource.type == 'OS::Heat::SoftwareDeployment' and \ resource.name.endswith('_create_deploy'): server = resource.properties['server']['get_resource'] if server in deployment_dict.keys(): deployment_dict[server].add(resource) else: deployment_dict[server] = set([resource]) # step #2: check all resources assigned to each server and inject # a dependency between them if one does not already exist. for server in deployment_dict.keys(): resources = deployment_dict[server] count = len(resources) if count < 2: continue for r1, r2 in itertools.combinations(resources, 2): if not self.depends_on(r1, r2) and not self.depends_on(r2, r1): if r1.name > r2.name: r1.depends_on.append(r2) else: r2.depends_on.append(r1) def depends_on(self, res1, res2): '''Returns true if res1 depends on res2, false otherwise.''' if res1 is None or res2 is None: return False return res2 in self.get_required_resources(res1) def get_required_resources(self, res): '''Find all the resources required for the given resource. Using a depth-first-search algorithm it finds all the resources the given resource directly or indirectly depends on. ''' required = set() to_be_processed = [res] while to_be_processed: r = to_be_processed.pop() if r not in required: required.add(r) to_be_processed.extend(set(r.depends_on) - required) return required ",,52,0
openstack%2Foperations-guide~master~I8ee00c853a6f3182958cbf3edf63d205432694d3,openstack/operations-guide,master,I8ee00c853a6f3182958cbf3edf63d205432694d3,small edit to operations guide partition doc,MERGED,2015-06-10 15:44:47.000000000,2015-06-11 02:20:31.000000000,2015-06-11 02:20:30.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 9162}, {'_account_id': 9563}, {'_account_id': 10705}, {'_account_id': 14046}]","[{'number': 1, 'created': '2015-06-10 15:44:47.000000000', 'files': ['doc/openstack-ops/ch_arch_provision.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/3976e7b11fd30801445a0a104b498c09e7acfad3', 'message': 'small edit to operations guide partition doc\n\ncorrected typo for partitioning\n\nChange-Id: I8ee00c853a6f3182958cbf3edf63d205432694d3\n'}]",0,190236,3976e7b11fd30801445a0a104b498c09e7acfad3,10,6,1,9382,,,0,"small edit to operations guide partition doc

corrected typo for partitioning

Change-Id: I8ee00c853a6f3182958cbf3edf63d205432694d3
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/36/190236/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_arch_provision.xml'],1,3976e7b11fd30801445a0a104b498c09e7acfad3,ch_arch_provision, <para>Disk partitioning and disk array setup for scalability</para>, <para>Disk partioning and disk array setup for scalability</para>,1,1
openstack%2Foperations-guide~master~Ic5ca6148662ba3445109a858b45861296d27f328,openstack/operations-guide,master,Ic5ca6148662ba3445109a858b45861296d27f328,made minor doc change in ops guide,MERGED,2015-06-10 16:58:35.000000000,2015-06-11 02:19:02.000000000,2015-06-11 02:19:02.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 9563}, {'_account_id': 10705}, {'_account_id': 14046}]","[{'number': 1, 'created': '2015-06-10 16:58:35.000000000', 'files': ['doc/openstack-ops/ch_ops_network_troubleshooting.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/20827db9eb725ff1bcec73ebab4ed27d044611e5', 'message': 'made minor doc change in ops guide\n\ncorrected typo: dissaociate to disassociate\n\nChange-Id: Ic5ca6148662ba3445109a858b45861296d27f328\n'}]",0,190263,20827db9eb725ff1bcec73ebab4ed27d044611e5,9,5,1,9382,,,0,"made minor doc change in ops guide

corrected typo: dissaociate to disassociate

Change-Id: Ic5ca6148662ba3445109a858b45861296d27f328
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/63/190263/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/ch_ops_network_troubleshooting.xml'],1,20827db9eb725ff1bcec73ebab4ed27d044611e5,troubleshooting," an inconsistent state, the usual tools to disassociate the IP no longer"," an inconsistent state, the usual tools to dissaociate the IP no longer",1,1
openstack%2Fdevstack~master~Iab662128083ef0c7c327a6a9b5ff1d1f0222de92,openstack/devstack,master,Iab662128083ef0c7c327a6a9b5ff1d1f0222de92,[WIP] Run devstack with oslo.db engine facade changes plus nova changes,ABANDONED,2015-06-04 13:39:25.000000000,2015-06-11 02:16:31.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-04 13:39:25.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a847c56621ddfbe82b8edd42619cac97b77d7e6b', 'message': '[WIP] Run devstack with oslo.db engine facade changes plus nova changes\n\nDepends-On: I9a3d0c26bb727eb2c0bd823b9a12fde57cc7c9c3\nChange-Id: Iab662128083ef0c7c327a6a9b5ff1d1f0222de92\n'}]",0,188395,a847c56621ddfbe82b8edd42619cac97b77d7e6b,3,1,1,5638,,,0,"[WIP] Run devstack with oslo.db engine facade changes plus nova changes

Depends-On: I9a3d0c26bb727eb2c0bd823b9a12fde57cc7c9c3
Change-Id: Iab662128083ef0c7c327a6a9b5ff1d1f0222de92
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/188395/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,a847c56621ddfbe82b8edd42619cac97b77d7e6b,,"LIBS_FROM_GIT+=""oslo.db""",,1,0
openstack%2Fmagnum~master~I4009f0ab6bbe23e07cc2548c933d59150adba68c,openstack/magnum,master,I4009f0ab6bbe23e07cc2548c933d59150adba68c,Updated from global requirements,MERGED,2015-06-10 21:22:00.000000000,2015-06-11 02:15:15.000000000,2015-06-11 02:15:14.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 10206}]","[{'number': 1, 'created': '2015-06-10 21:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8363ff2a4774c043f21db28b28167e666213b39f', 'message': 'Updated from global requirements\n\nChange-Id: I4009f0ab6bbe23e07cc2548c933d59150adba68c\n'}, {'number': 2, 'created': '2015-06-10 23:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/41f4c65a8898aa9f52642d2fcc08b49cc1d761ee', 'message': 'Updated from global requirements\n\nChange-Id: I4009f0ab6bbe23e07cc2548c933d59150adba68c\n'}, {'number': 3, 'created': '2015-06-11 00:42:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/64cfd559d045008ed722d238be789e51b49db585', 'message': 'Updated from global requirements\n\nChange-Id: I4009f0ab6bbe23e07cc2548c933d59150adba68c\n'}]",0,190358,64cfd559d045008ed722d238be789e51b49db585,12,4,3,11131,,,0,"Updated from global requirements

Change-Id: I4009f0ab6bbe23e07cc2548c933d59150adba68c
",git fetch https://review.opendev.org/openstack/magnum refs/changes/58/190358/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8363ff2a4774c043f21db28b28167e666213b39f,openstack/requirements,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,1,1
openstack%2Foslotest~master~I7df083998adcee710cf1c5b87a1b8f091e7ad522,openstack/oslotest,master,I7df083998adcee710cf1c5b87a1b8f091e7ad522,Document the mock attribute for mockpatch,MERGED,2015-06-10 01:21:02.000000000,2015-06-11 02:11:17.000000000,2015-06-11 02:11:15.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-10 01:21:02.000000000', 'files': ['oslotest/mockpatch.py'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/ecad0651b1c9a269785d645d839bbd6113632cf7', 'message': ""Document the mock attribute for mockpatch\n\nWhen using mockpatch.Patch/PatchObject you need access to the\nmock in order to verify that it's getting called (e.g.,\nassert_called_once_with), but this attribute wasn't documented so\nnobody can tell how to do it.\n\nWhile adding the attribute, other issues with the docs are\ncorrected.\n\nChange-Id: I7df083998adcee710cf1c5b87a1b8f091e7ad522\n""}]",0,189994,ecad0651b1c9a269785d645d839bbd6113632cf7,7,3,1,6486,,,0,"Document the mock attribute for mockpatch

When using mockpatch.Patch/PatchObject you need access to the
mock in order to verify that it's getting called (e.g.,
assert_called_once_with), but this attribute wasn't documented so
nobody can tell how to do it.

While adding the attribute, other issues with the docs are
corrected.

Change-Id: I7df083998adcee710cf1c5b87a1b8f091e7ad522
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/94/189994/1 && git format-patch -1 --stdout FETCH_HEAD,['oslotest/mockpatch.py'],1,ecad0651b1c9a269785d645d839bbd6113632cf7,doc," """"""Deal with code around mock. .. py:attribute:: mock The mock. """""" """"""Deal with code around mock. .. py:attribute:: mock The mock. """""" """"""Deal with code around mock.patch.multiple. Pass name=value to replace obj.name with value. Pass name= :py:attr:`Multiple.DEFAULT` to replace obj.name with a MagicMock instance. :param obj: Object or name containing values being mocked. :type obj: str or object :param kwargs: names and values of attributes of obj to be mocked. .. py:attribute:: mock The mock. """""" """"""Triggers a MagicMock to be created for a named attribute."""""""," """"""Deal with code around mock."""""" """"""Deal with code around mock.patch."""""" """"""Deal with code around mock.patch.multiple."""""" # Default value to trigger a MagicMock to be created for a named # attribute. """"""Initialize the mocks Pass name=value to replace obj.name with value. Pass name=Multiple.DEFAULT to replace obj.name with a MagicMock instance. :param obj: Object or name containing values being mocked. :type obj: str or object :param kwargs: names and values of attributes of obj to be mocked. """"""",31,17
openstack%2Fopenstack-manuals~master~I6010cc49dda81ee57c4774aabdf21d85a68d5b34,openstack/openstack-manuals,master,I6010cc49dda81ee57c4774aabdf21d85a68d5b34,few changes to doc in networking guide,MERGED,2015-06-10 17:28:47.000000000,2015-06-11 02:08:05.000000000,2015-06-11 02:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 9383}, {'_account_id': 9563}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 14046}, {'_account_id': 14920}, {'_account_id': 15804}]","[{'number': 1, 'created': '2015-06-10 17:28:47.000000000', 'files': ['doc/networking-guide/source/intro_basic_networking.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c79e5ef2a9868a7268f79aa2989118650e6259d5', 'message': 'few changes to doc in networking guide\n\ncommnunicate to communicate - typo fix\nidentifer to identifier - typo fix\nenusre to ensure - typo fix\n\nChange-Id: I6010cc49dda81ee57c4774aabdf21d85a68d5b34\n'}]",0,190272,c79e5ef2a9868a7268f79aa2989118650e6259d5,13,9,1,9382,,,0,"few changes to doc in networking guide

commnunicate to communicate - typo fix
identifer to identifier - typo fix
enusre to ensure - typo fix

Change-Id: I6010cc49dda81ee57c4774aabdf21d85a68d5b34
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/72/190272/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/source/intro_basic_networking.rst'],1,c79e5ef2a9868a7268f79aa2989118650e6259d5,basic_net,"number. Recall that two hosts can only communicate directly over Ethernet ifthe subnet. A common convention is to set the host identifier to all zeros to makeensure that transmitted data does not overrun the sender's data buffers,","number. Recall that two hosts can only commnunicate directly over Ethernet ifthe subnet. A common convention is to set the host identifer to all zeros to makeenusre that transmitted data does not overrun the sender's data buffers,",3,3
openstack%2Fopenstack-manuals~master~Idde7a0881b60984fe92ff76b1d82af6185638779,openstack/openstack-manuals,master,Idde7a0881b60984fe92ff76b1d82af6185638779,[glossary] Follow the docs conventions,MERGED,2015-06-10 14:38:05.000000000,2015-06-11 02:07:19.000000000,2015-06-11 02:07:18.000000000,"[{'_account_id': 3}, {'_account_id': 321}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10705}, {'_account_id': 14962}, {'_account_id': 15081}]","[{'number': 1, 'created': '2015-06-10 14:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6734a219997fd5eef2bf930570fa36fd7903494e', 'message': 'Change OpenStack services conventions\n\nfollow Documentaion conventions:\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: Idde7a0881b60984fe92ff76b1d82af6185638779\n'}, {'number': 2, 'created': '2015-06-10 22:25:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/638e0b00bb69bd03b075081df41df284a10cd7cf', 'message': 'Change `Service` to `service`\n\n* Identity Service to Identity service\n* Image Service to Image service\n\nfollow the Documentaion conventions:\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: Idde7a0881b60984fe92ff76b1d82af6185638779\n'}, {'number': 3, 'created': '2015-06-11 00:38:07.000000000', 'files': ['doc/glossary/glossary-terms.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6d6f0f63f8692798e37d2782561986607c3939ed', 'message': '[glossary] Follow the docs conventions\n\n* change Image Service to Image service\n* change Identity Service to Identity or Identity service\n\nfollow the Documentaion conventions:\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\n\nChange-Id: Idde7a0881b60984fe92ff76b1d82af6185638779\n'}]",2,190208,6d6f0f63f8692798e37d2782561986607c3939ed,19,9,3,10497,,,0,"[glossary] Follow the docs conventions

* change Image Service to Image service
* change Identity Service to Identity or Identity service

follow the Documentaion conventions:
https://wiki.openstack.org/wiki/Documentation/Conventions

Change-Id: Idde7a0881b60984fe92ff76b1d82af6185638779
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/08/190208/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/glossary-terms.xml'],1,6734a219997fd5eef2bf930570fa36fd7903494e,docs-conventions," /etc/passwd, OpenLDAP, OpenStack Identity service, and so on.</para> Identity service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity service, the worker process that service.</para> service.</para> service.</para> <para>The Identity service component that provides authentication <para>The Identity service component that provides high-level <para>The storage method used by the Identity service catalog service authentication with the Identity service.</para> <para>An Identity service that lists API endpoints that are available to a user after authentication with the Identity service.</para> of the cloud; talks to services, such as Identity service <para>An Identity service token that is not associated with a specific opposed to using the Identity service.</para> service (glance).</para> <para>Alternative term for an Identity service catalog.</para> of Identity service, this is a call that is specific to the Identity service and Compute. Requires Redis.</para> <para>The Identity service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity service, <para>Alternative term for the Identity service API.</para> <primary>Identity service</primary> <para>The source used by Identity service to retrieve user <glossterm>Identity service</glossterm> <primary>Identity service</primary> authentication system. The project name of the Identity service is <glossterm>Identity service API</glossterm> <primary>Identity service</primary> <secondary>Identity service API</secondary> <para>The API used to access the OpenStack Identity service provided <primary>Identity service</primary> service.</para> service.</para> service.</para> service.</para> service.</para> Identity service.</para> <para>Component of Identity service that provides a rule-management service.</para> that typically shares only the Identity service (keystone) with other both Identity service and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity service role.</para> <para>An Identity service API access token that is associated with a service that implements delayed delete.</para> service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity service catalog.</para> Identity service catalog.</para> <para>An Identity service feature that enables services, such as securely with the Identity service.</para> Identity service.</para> <para>An Identity service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity service. <para>An Identity service component that manages and validates tokens <para>Alternative term for an Identity service default token.</para> <para>In Identity service, each user is associated with one or more service.</para> service.</para> service.</para>"," /etc/passwd, OpenLDAP, OpenStack Identity Service, and so on.</para> Identity Service, OpenLDAP, or similar user-account services.</para> <para>In the context of the Identity Service, the worker process that Service.</para> Service.</para> Service.</para> <para>The Identity Service component that provides authentication <para>The Identity Service component that provides high-level <para>The storage method used by the Identity Service catalog service authentication with the Identity Service.</para> <para>An Identity Service that lists API endpoints that are available to a user after authentication with the Identity Service.</para> of the cloud; talks to services, such as Identity Service <para>An Identity Service token that is not associated with a specific opposed to using the Identity Service.</para> Service (glance).</para> <para>Alternative term for an Identity Service catalog.</para> of Identity Service, this is a call that is specific to the Identity Service and Compute. Requires Redis.</para> <para>The Identity Service endpoint template that contains services <para>Unique numeric ID associated with each user in Identity Service, <para>Alternative term for the Identity Service API.</para> <primary>Identity Service</primary> <para>The source used by Identity Service to retrieve user <glossterm>Identity Service</glossterm> <primary>Identity Service</primary> authentication system. The project name of the Identity Service is <glossterm>Identity Service API</glossterm> <primary>Identity Service</primary> <secondary>Identity Service API</secondary> <para>The API used to access the OpenStack Identity Service provided <primary>Identity Service</primary> Service.</para> Service.</para> Service.</para> Service.</para> Service.</para> Identity Service.</para> <para>Component of Identity Service that provides a rule-management Service.</para> that typically shares only the Identity Service (keystone) with other both Identity Service and Compute and can be configured using the <para>Alphanumeric ID assigned to each Identity Service role.</para> <para>An Identity Service API access token that is associated with a Service that implements delayed delete.</para> Service. Provides one or more endpoints through which users can access <para>Alternative term for the Identity Service catalog.</para> Identity Service catalog.</para> <para>An Identity Service feature that enables services, such as securely with the Identity Service.</para> Identity Service.</para> <para>An Identity Service API endpoint that is associated with one or <para>Unique ID assigned to each tenant within the Identity Service. <para>An Identity Service component that manages and validates tokens <para>Alternative term for an Identity Service default token.</para> <para>In Identity Service, each user is associated with one or more Service.</para> Service.</para> Service.</para>",59,59
openstack%2Fopenstack-manuals~master~I63ff09e364c056abf0ae66d065343a420a46c169,openstack/openstack-manuals,master,I63ff09e364c056abf0ae66d065343a420a46c169,Updates the Cloudbase-Init download url,MERGED,2015-06-11 00:12:52.000000000,2015-06-11 02:03:41.000000000,2015-06-11 02:03:39.000000000,"[{'_account_id': 3}, {'_account_id': 8358}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 10705}, {'_account_id': 12686}, {'_account_id': 12952}]","[{'number': 1, 'created': '2015-06-11 00:12:52.000000000', 'files': ['doc/image-guide/section_windows-example.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/59adc237145c877a1fd1ab0c3fa2458154d2d3f2', 'message': 'Updates the Cloudbase-Init download url\n\nThe Windows image creation sample contains a download url for\nCloudbase-Init that needs to point to latest stable release.\n\nChange-Id: I63ff09e364c056abf0ae66d065343a420a46c169\nCloses-Bug: #1464045\n'}]",0,190420,59adc237145c877a1fd1ab0c3fa2458154d2d3f2,12,8,1,3185,,,0,"Updates the Cloudbase-Init download url

The Windows image creation sample contains a download url for
Cloudbase-Init that needs to point to latest stable release.

Change-Id: I63ff09e364c056abf0ae66d065343a420a46c169
Closes-Bug: #1464045
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/20/190420/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-guide/section_windows-example.xml'],1,59adc237145c877a1fd1ab0c3fa2458154d2d3f2,, <screen><prompt>C:\</prompt><userinput>Invoke-WebRequest -UseBasicParsing http://www.cloudbase.it/downloads/CloudbaseInitSetup_Stable_x64.msi -OutFile cloudbaseinit.msi</userinput>, <screen><prompt>C:\</prompt><userinput>Invoke-WebRequest -UseBasicParsing http://www.cloudbase.it/downloads/CloudbaseInitSetup_Beta_x64.msi -OutFile cloudbaseinit.msi</userinput>,1,1
openstack%2Fopenstack-manuals~master~Idcd0a943f28c80d265d08efee87766890d2cce3c,openstack/openstack-manuals,master,Idcd0a943f28c80d265d08efee87766890d2cce3c,Convert ch_objectstorage.xml to RST,MERGED,2015-06-09 16:31:24.000000000,2015-06-11 02:02:59.000000000,2015-06-11 02:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 12686}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-09 16:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a009083e14c92927b14a2a7fd5bb933f728e264d', 'message': 'Convert ch_objectstorage.xml to RST\n\n-Initial conversion of ch_objectstorage.xml to RST.\n-Converted section objectstorage-characteristics.xml\nto RST and added objectstorage.png to common dir.\n\nChange-Id: Idcd0a943f28c80d265d08efee87766890d2cce3c\nImplements: blueprint reorganise-user-guides\n'}, {'number': 2, 'created': '2015-06-10 13:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/db9064819187e241e2f38fb79eaa2d8580fc87f1', 'message': 'Convert ch_objectstorage.xml to RST\n\n-Initial conversion of ch_objectstorage.xml to RST.\n-Converted section objectstorage-characteristics.xml\nto RST and added objectstorage.png to local figures dir.\n\nChange-Id: Idcd0a943f28c80d265d08efee87766890d2cce3c\nImplements: blueprint reorganise-user-guides\n'}, {'number': 3, 'created': '2015-06-10 17:54:12.000000000', 'files': ['doc/admin-guide-cloud-rst/source/objectstorage_characteristics.rst', 'doc/admin-guide-cloud-rst/source/objectstorage.rst', 'doc/admin-guide-cloud-rst/source/index.rst', 'doc/common-rst/cli_overview.rst', 'doc/admin-guide-cloud-rst/source/figures/objectstorage.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a098c3117ff6f4220a17bb91ec4e0e7b590d6e4', 'message': 'Convert ch_objectstorage.xml to RST\n\n-Initial conversion of ch_objectstorage.xml to RST.\n-Converted section objectstorage-characteristics.xml\nto RST and added objectstorage.png to local figures dir.\n\nChange-Id: Idcd0a943f28c80d265d08efee87766890d2cce3c\nImplements: blueprint reorganise-user-guides\n'}]",0,189806,0a098c3117ff6f4220a17bb91ec4e0e7b590d6e4,21,8,3,15293,,,0,"Convert ch_objectstorage.xml to RST

-Initial conversion of ch_objectstorage.xml to RST.
-Converted section objectstorage-characteristics.xml
to RST and added objectstorage.png to local figures dir.

Change-Id: Idcd0a943f28c80d265d08efee87766890d2cce3c
Implements: blueprint reorganise-user-guides
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/06/189806/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud-rst/source/objectstorage_characteristics.rst', 'doc/admin-guide-cloud-rst/source/objectstorage.rst', 'doc/common-rst/figures/objectstorage.png', 'doc/admin-guide-cloud-rst/source/index.rst', 'doc/common-rst/cli_overview.rst']",5,a009083e14c92927b14a2a7fd5bb933f728e264d,bp/reorganise-user-guides,"|Identity |keystone |python-keystoneclient |Create and manage | | | | |users, tenants, roles, |","|Identity |keystone |python-keystoneclient |Create and manage users,| | | | |tenants, roles, |",72,2
openstack%2Fopenstack-manuals~master~I54b5f13862bdf70b5e6214354beb6a41b1c48d52,openstack/openstack-manuals,master,I54b5f13862bdf70b5e6214354beb6a41b1c48d52,[networking] Add NAT section,MERGED,2015-06-10 01:03:41.000000000,2015-06-11 01:52:46.000000000,2015-06-11 01:52:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 8358}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2015-06-10 01:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/813bb2e58e36cb9d6d6448a3462a32539a3f7250', 'message': '[networking] Add NAT section\n\nNetwork guide: add section that describes Network Address Translation (NAT).\n\nChange-Id: I54b5f13862bdf70b5e6214354beb6a41b1c48d52\n'}, {'number': 2, 'created': '2015-06-10 03:15:56.000000000', 'files': ['doc/networking-guide/source/intro_networking.rst', 'doc/networking-guide/source/intro_network_address_translation.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4d4f8708c48f7727fbeb4e5421c1e039f41abf3a', 'message': '[networking] Add NAT section\n\nNetwork guide: add section that describes Network Address Translation (NAT).\n\nChange-Id: I54b5f13862bdf70b5e6214354beb6a41b1c48d52\n'}]",1,189992,4d4f8708c48f7727fbeb4e5421c1e039f41abf3a,14,6,2,321,,,0,"[networking] Add NAT section

Network guide: add section that describes Network Address Translation (NAT).

Change-Id: I54b5f13862bdf70b5e6214354beb6a41b1c48d52
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/189992/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/intro_networking.rst', 'doc/networking-guide/source/intro_network_address_translation.rst']",2,813bb2e58e36cb9d6d6448a3462a32539a3f7250,nat,"=========================== Network address translation =========================== *Network address translation* (NAT) is a process for modifying the source or destination addresses in the headers of an IP packet while the packet is in transit. In general, the sender and receiver applications are not aware that the IP packets are being manipulated. NAT is often implemented by routers, and so we will refer to the host performing NAT as a *NAT router*. However, in OpenStack deployments it is typically Linux servers that implement the NAT functionality, not hardware routers. These servers use the iptables_ software package to implement the NAT functionality. There are multiple variations of NAT, and here we describe three kinds commonly found in OpenStack deployments. .. _iptables: http://www.netfilter.org/projects/iptables/index.html SNAT ~~~~ In *Source Network Address Translation* (SNAT), the NAT router modifies the IP address of the sender in IP packets. SNAT is commonly used to enable hosts with *private addresses* to communicate with servers on the public Internet. `RFC 1918`_ reserves the following three subnets as private addresses: * ``10.0.0.0/8`` * ``172.16.0.0/12`` * ``192.168.0.0/16`` .. _RFC 1918: https://tools.ietf.org/html/rfc1918 These IP addresses are not publicly routable, meaning that a host on the public Internet can not send an IP packet to any of these addresses. Private IP addresses are widely used in both residential and corporate environments. Often, an application running on a host with a private IP address will need to connect to a server on the public Internet. One such example is a user who wants to access a public website such as www.openstack.org. If the IP packets reach the web server at www.openstack.org with a private IP address as the source, then the web server cannot send packets back to the sender. SNAT solves this problem by modifying the source IP address to an IP address that is routable on the public Internet. There are different variations of SNAT; in the form that OpenStack deployments use, a NAT router on the path between the sender and receiver replaces the packet's source IP address with the router's public IP address. The router also modifies the source TCP or UDP port to another value, and the router maintains a record of the sender's true IP address and port, as well as the modified IP address and port. When the router receives a packet with the matching IP address and port, it translates these back to the private IP address and port, and forwards the packet along. Because the NAT router modifies ports as well as IP addresses, this form of SNAT is sometimes referred to as *Port Address Translation* (PAT). It is also sometimes referred to as *NAT overload*. OpenStack uses SNAT to enable applications running inside of instances to connect out to the public Internet. DNAT ~~~~ In *Destination Network Address Translation* (DNAT), the NAT router modifies the IP address of the destination in IP packet headers. OpenStack uses DNAT to route packets from instances to the OpenStack metadata service. Applications running inside of instances access the OpenStack metadata service by making HTTP GET requests to a web server with IP address 169.254.169.254. In an OpenStack deployment, there is no host with this IP address. Instead, OpenStack uses DNAT to change the destination IP of these packets so they reach the network interface that a metadata service is listening on. One-to-one NAT ~~~~~~~~~~~~~~ In *one-to-one NAT*, the NAT router maintains a one-to-one mapping between private IP addresses and public IP addresses. OpenStack uses one-to-one NAT to implement floating IP addresses. ",,86,0
openstack%2Fnetworking-midonet~master~I6c769deb22d5262037191b8354ee7a861b845991,openstack/networking-midonet,master,I6c769deb22d5262037191b8354ee7a861b845991,Provide better V2 configs in devstack,MERGED,2015-06-10 00:08:56.000000000,2015-06-11 01:46:35.000000000,2015-06-11 01:46:33.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 7505}, {'_account_id': 8837}]","[{'number': 1, 'created': '2015-06-10 00:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/71b53cfa7b712e294c2e538d54c477e063470625', 'message': 'Allow setting of API port for the cluster API\n\nTo be able to run Kilo with the cluster REST API, devstack must be able\nto set the REST API port correctly in midonet plugin configuration\nfile.\n\nChange-Id: I6c769deb22d5262037191b8354ee7a861b845991\nImplements: MNP-139\n'}, {'number': 2, 'created': '2015-06-10 00:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/9d892fa7253766a1e5cf4c247a3b4493da1cf710', 'message': 'Allow setting of API port for the cluster API\n\nTo be able to run Kilo with the cluster REST API, devstack must be able\nto set the REST API port correctly in midonet plugin configuration\nfile.\n\nChange-Id: I6c769deb22d5262037191b8354ee7a861b845991\nImplements: MNP-139\n'}, {'number': 3, 'created': '2015-06-10 00:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/265049d64a04fb70795e863304d49fea199615f9', 'message': 'Allow setting of API port for the cluster API\n\nTo be able to run Kilo with the cluster REST API, devstack must be able\nto set the REST API port correctly in midonet plugin configuration\nfile.\n\nChange-Id: I6c769deb22d5262037191b8354ee7a861b845991\nImplements: MNP-139\n'}, {'number': 4, 'created': '2015-06-10 00:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/c04e5a9574b12c6947f13886fb7421717ad7d2b3', 'message': 'Provide better V2 configs in devstack\n\nTo be able to run Kilo with the cluster REST API with ZOOM backend,\ndevstack must be able to set the REST API port correctly as well as\ninstruct the agent to use ZOOM in the midonet plugin configuration\nfile.\n\nChange-Id: I6c769deb22d5262037191b8354ee7a861b845991\nImplements: MNP-139\n'}, {'number': 5, 'created': '2015-06-10 16:09:49.000000000', 'files': ['devstack/local.conf.sample', 'devstack/plugin.sh', 'devstack/README.rst', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/d56125e2df81cc4e1b395a2b3b83c8df5680aba4', 'message': 'Provide better V2 configs in devstack\n\nTo be able to run Kilo with the cluster REST API with ZOOM backend,\ndevstack must be able to set the REST API port correctly as well as\ninstruct the agent to use ZOOM in the midonet plugin configuration\nfile.\n\nChange-Id: I6c769deb22d5262037191b8354ee7a861b845991\nImplements: MNP-139\n'}]",13,189980,d56125e2df81cc4e1b395a2b3b83c8df5680aba4,22,5,5,156,,,0,"Provide better V2 configs in devstack

To be able to run Kilo with the cluster REST API with ZOOM backend,
devstack must be able to set the REST API port correctly as well as
instruct the agent to use ZOOM in the midonet plugin configuration
file.

Change-Id: I6c769deb22d5262037191b8354ee7a861b845991
Implements: MNP-139
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/80/189980/5 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'devstack/settings']",2,71b53cfa7b712e294c2e538d54c477e063470625,(detached,"MIDONET_CLUSTER_API_PORT=${MIDONET_CLUSTER_API_PORT:-8082} if [[ $USE_NEW_STACK = ""True"" ]]; then MIDONET_SERVICE_API_PORT=$MIDONET_CLUSTER_API_PORT else MIDONET_SERVICE_API_PORT=$MIDONET_API_PORT fi MIDONET_API_URL=""${MIDONET_SERVICE_PROTOCOL}://${MIDONET_SERVICE_HOST}:${MIDONET_SERVICE_API_PORT}/midonet-api""","MIDONET_API_URL=""${MIDONET_SERVICE_PROTOCOL}://${MIDONET_SERVICE_HOST}:${MIDONET_API_PORT}/midonet-api""",10,2
openstack%2Fheat~master~Iab8d4d737e3fd839a12d8782367ff0b731f93fe7,openstack/heat,master,Iab8d4d737e3fd839a12d8782367ff0b731f93fe7,Copy environment before decrypting,MERGED,2015-06-10 20:23:27.000000000,2015-06-11 01:32:13.000000000,2015-06-11 01:32:11.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 8246}]","[{'number': 1, 'created': '2015-06-10 20:23:27.000000000', 'files': ['heat/objects/raw_template.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e45eca4dc5d74d800145f985e6e2617650398d09', 'message': 'Copy environment before decrypting\n\nThis is to prevent the decrypted values from being written to the\ndatabase.\n\nChange-Id: Iab8d4d737e3fd839a12d8782367ff0b731f93fe7\nCloses-Bug: #1463929\nCo-Authored-By: Thomas Herve <therve@redhat.com>\n'}]",0,190334,e45eca4dc5d74d800145f985e6e2617650398d09,9,3,1,7253,,,0,"Copy environment before decrypting

This is to prevent the decrypted values from being written to the
database.

Change-Id: Iab8d4d737e3fd839a12d8782367ff0b731f93fe7
Closes-Bug: #1463929
Co-Authored-By: Thomas Herve <therve@redhat.com>
",git fetch https://review.opendev.org/openstack/heat refs/changes/34/190334/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/objects/raw_template.py'],1,e45eca4dc5d74d800145f985e6e2617650398d09,bug/1463929,import copy tpl.environment = copy.deepcopy(tpl.environment),,3,0
openstack%2Fhorizon~master~I8e2e78cf4c64615ac03362ce390de5ff7dabe18e,openstack/horizon,master,I8e2e78cf4c64615ac03362ce390de5ff7dabe18e,Updated from global requirements,MERGED,2015-06-10 21:21:32.000000000,2015-06-11 01:32:02.000000000,2015-06-11 01:32:01.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9576}, {'_account_id': 9622}]","[{'number': 1, 'created': '2015-06-10 21:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/06e839d220e992c3a755bddf6da1f4ef2f52248b', 'message': 'Updated from global requirements\n\nChange-Id: I8e2e78cf4c64615ac03362ce390de5ff7dabe18e\n'}, {'number': 2, 'created': '2015-06-10 23:44:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5a01d2d0f3128df9169e00ed775ed55859878a26', 'message': 'Updated from global requirements\n\nChange-Id: I8e2e78cf4c64615ac03362ce390de5ff7dabe18e\n'}]",0,190356,5a01d2d0f3128df9169e00ed775ed55859878a26,11,4,2,11131,,,0,"Updated from global requirements

Change-Id: I8e2e78cf4c64615ac03362ce390de5ff7dabe18e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/190356/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,06e839d220e992c3a755bddf6da1f4ef2f52248b,openstack/requirements,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,1,1
openstack%2Fproject-config~master~Ic02b03b941516fabd4c27f787ca2ec33e3a474d1,openstack/project-config,master,Ic02b03b941516fabd4c27f787ca2ec33e3a474d1,Add experimental cue-dsvm-rally job,MERGED,2015-06-02 14:54:49.000000000,2015-06-11 01:23:46.000000000,2015-06-11 01:23:45.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 5263}, {'_account_id': 10584}, {'_account_id': 13771}, {'_account_id': 14955}]","[{'number': 1, 'created': '2015-06-02 14:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0e4d43e3a7e2c1a7a0dc7ded843ebb080aa4a00b', 'message': 'Add experimental cue-dsvm-rally job\n\nThis job will deploy cue-dsvm and run rally task from rally-jobs/cue.yaml\n\nChange-Id: Ic02b03b941516fabd4c27f787ca2ec33e3a474d1\n'}, {'number': 2, 'created': '2015-06-02 17:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/18d1e392e25330faf5f4988c03b7d2d916945d84', 'message': 'Add experimental cue-dsvm-rally job\n\nThis job will deploy cue-dsvm and run rally task from rally-jobs/cue.yaml\n\nAdded new job template gate-{name}-integrate-dsvm-rally. This job\ntemaplte is useful for projects which are not integrated into\ndevstack yet, and custom builder should be used.\n\nRemainig jobs will be moved to this tempalte in the next patchset.\n\nChange-Id: Ic02b03b941516fabd4c27f787ca2ec33e3a474d1\n'}, {'number': 3, 'created': '2015-06-03 09:56:23.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/47af398ceab954cd25ecfce8fdc9b29317037880', 'message': 'Add experimental cue-dsvm-rally job\n\nThis job will deploy cue-dsvm and run rally task from rally-jobs/cue.yaml\n\nAdded new job template gate-{name}-integrate-dsvm-rally. This job\ntemaplte is useful for projects which are not integrated into\ndevstack yet, and custom builder should be used.\n\nRemainig jobs will be moved to this tempalte in the next patchset.\n\nChange-Id: Ic02b03b941516fabd4c27f787ca2ec33e3a474d1\n'}]",0,187620,47af398ceab954cd25ecfce8fdc9b29317037880,14,7,3,7369,,,0,"Add experimental cue-dsvm-rally job

This job will deploy cue-dsvm and run rally task from rally-jobs/cue.yaml

Added new job template gate-{name}-integrate-dsvm-rally. This job
temaplte is useful for projects which are not integrated into
devstack yet, and custom builder should be used.

Remainig jobs will be moved to this tempalte in the next patchset.

Change-Id: Ic02b03b941516fabd4c27f787ca2ec33e3a474d1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/187620/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/rally.yaml']",3,0e4d43e3a7e2c1a7a0dc7ded843ebb080aa4a00b,rally-cue-job,"- builder: name: devstack-cue-rally-gate builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PROJECTS=""openstack/rally $PROJECTS"" export ENABLED_SERVICES=rally export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=100 export DEVSTACK_GATE_INSTALL_TESTONLY=1 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_NOTESTS=1 export PROJECTS=""stackforge/cue stackforge/python-cueclient $PROJECTS"" function pre_test_hook {{ cd /opt/stack/new/cue/tests ./pre_test_hook.sh {broker} # Install rally-devstack integration cp -r $BASE/new/rally/contrib/devstack/* $BASE/new/devstack/ }} export -f pre_test_hook function gate_hook {{ $BASE/new/rally/tests/ci/rally-gate.py }} export -f gate_hook cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh - job-template: name: 'gate-{name}-dsvm-rally' node: 'devstack-precise || devstack-trusty' wrappers: - build-timeout: timeout: 125 - timestamps builders: - devstack-{name}-rally-gate publishers: - devstack-logs - console-log - rally-plot - 'gate-{name}-dsvm-rally'",,56,0
openstack%2Fheat~stable%2Fkilo~I6501395ab458b75ba7d27c8ce9643bd6d18cb203,openstack/heat,stable/kilo,I6501395ab458b75ba7d27c8ce9643bd6d18cb203,Fix block_device_mapping property validation when using get_attr,MERGED,2015-06-10 10:01:27.000000000,2015-06-11 01:15:25.000000000,2015-06-11 01:15:24.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7256}, {'_account_id': 8833}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-10 10:01:27.000000000', 'files': ['heat/engine/resources/openstack/nova/server.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/754851d7cd45bf0effcdccd9658b916317f59f6a', 'message': 'Fix block_device_mapping property validation when using get_attr\n\nChange-Id: I6501395ab458b75ba7d27c8ce9643bd6d18cb203\nCloses-Bug: #1463531\n(cherry picked from commit 4d2b275358cd010c0ba19697d5e623a1edef3daf)\n'}]",0,190097,754851d7cd45bf0effcdccd9658b916317f59f6a,11,6,1,8833,,,0,"Fix block_device_mapping property validation when using get_attr

Change-Id: I6501395ab458b75ba7d27c8ce9643bd6d18cb203
Closes-Bug: #1463531
(cherry picked from commit 4d2b275358cd010c0ba19697d5e623a1edef3daf)
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/190097/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/nova/server.py', 'heat/tests/test_server.py']",2,754851d7cd45bf0effcdccd9658b916317f59f6a,," def test_validate_block_device_mapping_with_empty_ref(self): stack_name = 'val_blkdev2' (tmpl, stack) = self._setup_test_stack(stack_name) bdm = [{'device_name': 'vda', 'volume_id': '', 'volume_size': '10'}] wsp = tmpl.t['Resources']['WebServer']['Properties'] wsp['block_device_mapping'] = bdm resource_defns = tmpl.resource_definitions(stack) server = servers.Server('server_create_image_err', resource_defns['WebServer'], stack) self.m.StubOutWithMock(nova.NovaClientPlugin, '_create') self.stub_VolumeConstraint_validate() nova.NovaClientPlugin._create().AndReturn(self.fc) self._mock_get_image_id_success('F17-x86_64-gold', 'image_id') self.m.ReplayAll() self.assertIsNone(server.validate()) self.m.VerifyAll() ",,21,2
openstack%2Fnova~master~Ibabcf48c95185ba443ef7575590eae6a63e0f8e5,openstack/nova,master,Ibabcf48c95185ba443ef7575590eae6a63e0f8e5,virt: convert disk mount API to use nova.virt.image.model,MERGED,2014-10-30 13:22:08.000000000,2015-06-11 01:01:55.000000000,2015-06-10 18:55:25.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 8802}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12898}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2014-10-30 13:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0be61a3f32880dd46c0092372ccb8a352434cda3', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 2, 'created': '2014-10-30 17:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d30dda39ed59bcd2dc945da094cc39cd194986a8', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 3, 'created': '2014-11-13 09:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c08b3678d011635382850bba879c8d438a3fa472', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 4, 'created': '2014-11-18 12:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2bd71670aa7996eb240d78bf30bfee5846d919b0', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 5, 'created': '2014-11-20 15:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46e274b2c0fc6070c12ddd4f65cfaacb76a54a40', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 6, 'created': '2014-11-20 15:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6ff320922b69c4e93b9cf959ef207f3b92fa827e', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 7, 'created': '2014-12-02 15:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55e618aa92e92e0e9b7b7fbd7535513ea11ecb05', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 8, 'created': '2014-12-08 17:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60d446dd06a957660fa0998c87813c610979a227', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 9, 'created': '2014-12-09 10:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9616193f30ee054d15b7a99b0e61143e9f1389dc', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 10, 'created': '2014-12-16 11:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/407d7f875319ac5ad406dc72f648c88d5b2230ac', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 11, 'created': '2014-12-18 10:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e4e7ebb559df101dabd7cf78181e01d7466f2eb', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 12, 'created': '2014-12-19 11:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2241a021b82a77ae9eb9058b36cd044b624f0814', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 13, 'created': '2015-01-12 12:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7bc5b9140a160bc42cf1c8d6adca1caf69515603', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConver the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 14, 'created': '2015-01-13 11:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe154b7d62ca6fbd89f17f6b66c7b8fcd571ed41', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 15, 'created': '2015-01-19 12:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/118e36490104210d50f59063153762ce5fb53f4d', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 16, 'created': '2015-01-26 11:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9743e7217b6cbf4041d99702627c81c25ca7f5bd', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 17, 'created': '2015-01-26 15:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2942c67dfde31b2a1d67319e41778c6a7f75aebe', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 18, 'created': '2015-01-27 11:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30bc4bf40a3f5644f0382f02020b196980380292', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 19, 'created': '2015-01-28 12:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53c9ee28f56ae5069a8c7a733f2d46933959487e', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 20, 'created': '2015-02-03 10:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d27ba22fc2767498f75b7a591d28cf315f82e74e', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 21, 'created': '2015-02-16 10:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/870a732cc6c8a253bf6816f3bfe82007a0f69435', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 22, 'created': '2015-04-30 11:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91bfba4ca2fba7eac438c8cbc18e82827c7cbb4d', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 23, 'created': '2015-05-14 10:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d18cee0d5b9cf2531f186c442d29bbbc82fbc1d', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 24, 'created': '2015-05-18 10:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/030ff32c9008f1379b52053af807a6bdd9c66c71', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 25, 'created': '2015-05-26 16:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dbfe972a3198be46cb242b205bce632a01fa34ea', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 26, 'created': '2015-06-02 14:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0dbb99522ee37ed32a3562cf731c7a6f7fb4598', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}, {'number': 27, 'created': '2015-06-04 13:04:14.000000000', 'files': ['nova/virt/disk/mount/loop.py', 'nova/exception.py', 'nova/tests/unit/virt/test_virt.py', 'nova/tests/unit/virt/disk/test_api.py', 'nova/virt/disk/vfs/localfs.py', 'nova/virt/disk/mount/api.py', 'nova/virt/disk/mount/nbd.py', 'nova/tests/unit/virt/disk/mount/test_loop.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0ea510f5560516bdcbf9167be68be58ea1ee3a41', 'message': 'virt: convert disk mount API to use nova.virt.image.model\n\nConvert the nova.virt.disk.mount classes to use the\nnova.virt.image.model classes instead of manually\npassing a filename and image format as parameters.\n\nRelated-Bug: #1257674\nChange-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5\n'}]",19,132021,0ea510f5560516bdcbf9167be68be58ea1ee3a41,230,21,27,1779,,,0,"virt: convert disk mount API to use nova.virt.image.model

Convert the nova.virt.disk.mount classes to use the
nova.virt.image.model classes instead of manually
passing a filename and image format as parameters.

Related-Bug: #1257674
Change-Id: Ibabcf48c95185ba443ef7575590eae6a63e0f8e5
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/132021/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/virt/disk/mount/test_nbd.py', 'nova/virt/disk/mount/loop.py', 'nova/tests/virt/test_virt.py', 'nova/virt/disk/vfs/localfs.py', 'nova/tests/virt/disk/test_api.py', 'nova/virt/disk/mount/api.py', 'nova/tests/virt/disk/mount/test_loop.py', 'nova/virt/disk/mount/nbd.py', 'nova/virt/disk/api.py']",10,0be61a3f32880dd46c0092372ccb8a352434cda3,bug/1257674,"from nova.virt.image import model as imgmodel """"""Increase image to size. :param image: path to disk image file :param size: image size in bytes :param use_cow: whether the disk is a qcow2 file """""" imgmodel.LocalFileImage(image, imgmodel.FORMAT_QCOW2), None, None) """"""Create a new _DiskImage object instance :param image: the path to the disk image file :param partition: the partition number within the image :param use_cow: whether the disk is in qcow2 format :param mount_dir: the directory to mount the image on """""" if use_cow: self.image = imgmodel.LocalFileImage(image, imgmodel.FORMAT_QCOW2) else: self.image = imgmodel.LocalFileImage(image, imgmodel.FORMAT_RAW) self._mounter = mount.Mount.instance_for_device( self.image, self.mount_dir, self.partition, device) mounter = mount.Mount.instance_for_format( self.image, self.mount_dir, self.partition) "," """"""Increase image to size."""""" image, None, None, 'qcow2') self.image = image self.use_cow = use_cow self._mounter = mount.Mount.instance_for_device(self.image, self.mount_dir, self.partition, device) imgfmt = ""raw"" if self.use_cow: imgfmt = ""qcow2"" mounter = mount.Mount.instance_for_format(self.image, self.mount_dir, self.partition, imgfmt)",169,70
openstack%2Fopenstacksdk~master~I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c,openstack/openstacksdk,master,I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c,Compare message data outside of assert_called_with,MERGED,2015-06-04 21:56:22.000000000,2015-06-11 00:50:50.000000000,2015-06-11 00:50:49.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-06-04 21:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0e902c837792254455db128ed40b1cf8175253fd', 'message': 'Use an OrderedDict for fake data\n\nApparently json.dumps randomly outputs the keys of a dict under\nPython 3. This can cause unit tests to fail when comparing\njson.dumps output. Hopefully using an OrderedDict resovlves it.\n\nChange-Id: I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c\n'}, {'number': 2, 'created': '2015-06-04 22:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a344f08fdaa467a6ba96f635be23f73c5dd12d7e', 'message': 'Use sort_keys=True to pass tests\n\nApparently json.dumps randomly outputs the keys of a dict under\nPython 3. This can cause unit tests to fail when comparing\njson.dumps output. Using sort_keys=True when encoding the object\nis the proper way to solve it.\n\nChange-Id: I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c\n'}, {'number': 3, 'created': '2015-06-05 14:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c9ff780a9b4a17f0c56b409845927c808ddd605b', 'message': 'Use sort_keys=True to pass tests\n\nApparently json.dumps randomly outputs the keys of a dict under\nPython 3. This can cause unit tests to fail when comparing\njson.dumps output. Using sort_keys=True when encoding the object\nis the proper way to solve it.\n\nChange-Id: I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c\n'}, {'number': 4, 'created': '2015-06-10 17:45:08.000000000', 'files': ['openstack/tests/unit/message/v1/test_message.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/fa26bab5595dbb07cc1d4313dd109048f39a86e9', 'message': 'Compare message data outside of assert_called_with\n\nThe sort order of message data in a dictionary is sometimes inconsistent\nbetween what is passed in the system under test and what is created in\nthe test method for comparison. Instead of having assert_called_with do\nthe comparison, test that it is called with anything at all, and then\nbreakdown what was sent in the call and check the dictionary contents\nindependently. This will fix the spurious test failures under Python\n3.4.\n\nChange-Id: I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c\n'}]",0,188605,fa26bab5595dbb07cc1d4313dd109048f39a86e9,29,6,4,1112,,,0,"Compare message data outside of assert_called_with

The sort order of message data in a dictionary is sometimes inconsistent
between what is passed in the system under test and what is created in
the test method for comparison. Instead of having assert_called_with do
the comparison, test that it is called with anything at all, and then
breakdown what was sent in the call and check the dictionary contents
independently. This will fix the spurious test failures under Python
3.4.

Change-Id: I0182c9d8aaecf28db24b59ef3039a9c873ee2b5c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/05/188605/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/unit/message/v1/test_message.py'],1,0e902c837792254455db128ed40b1cf8175253fd,sort-keys,import collectionsMESSAGE = {FAKE = collections.OrderedDict(sorted(MESSAGE.items())) MESSAGE_HREF = {FAKE_HREF = collections.OrderedDict(sorted(MESSAGE_HREF.items())),FAKE = {FAKE_HREF = {,5,2
openstack%2Fopenstacksdk~master~Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c,openstack/openstacksdk,master,Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c,Rename clustering to cluster service,MERGED,2015-06-04 03:47:24.000000000,2015-06-11 00:44:51.000000000,2015-06-11 00:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-04 03:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3cb4a44fa78fc0d0c1860a862002db1ef1366aa7', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}, {'number': 2, 'created': '2015-06-05 02:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/176ff1786d00172e74dbbd5b303416476900159d', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}, {'number': 3, 'created': '2015-06-05 07:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5c857f7b0859ceda9383c318213f90cca7d96eb7', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}, {'number': 4, 'created': '2015-06-09 05:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7e32029cc54659cddfd8f90cce82e0fd7210568c', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}, {'number': 5, 'created': '2015-06-10 01:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1238c9ddcf32dd1c0835bea6b709c008f0031bf7', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}, {'number': 6, 'created': '2015-06-10 01:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/108be1d2fc82b05dad2986455ee01e7de508fcd2', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}, {'number': 7, 'created': '2015-06-11 00:16:50.000000000', 'files': ['openstack/cluster/version.py', 'openstack/tests/unit/cluster/v1/__init__.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/clustering/v1/__init__.py', 'openstack/tests/unit/cluster/v1/test_proxy.py', 'openstack/tests/unit/cluster/test_cluster_service.py', 'openstack/tests/unit/test_connection.py', 'openstack/tests/unit/test_profile.py', 'openstack/profile.py', 'openstack/clustering/v1/__init__.py', 'openstack/tests/unit/cluster/__init__.py', 'openstack/cluster/v1/cluster.py', 'openstack/cluster/__init__.py', 'openstack/cluster/v1/__init__.py', 'openstack/tests/unit/cluster/v1/test_cluster.py', 'openstack/tests/unit/cluster/test_version.py', 'openstack/cluster/cluster_service.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4530cbbd55d55af3003209283574dba99e913888', 'message': ""Rename clustering to cluster service\n\nThis patch renames the 'clustering' service to 'cluster' service and\nmakes it appear in the profile module.\n\nChange-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c\n""}]",3,188250,4530cbbd55d55af3003209283574dba99e913888,32,4,7,8246,,,0,"Rename clustering to cluster service

This patch renames the 'clustering' service to 'cluster' service and
makes it appear in the profile module.

Change-Id: Iea0f0041ec4860ef0226cad4d28e5f63bacbe69c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/50/188250/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cluster/version.py', 'openstack/tests/unit/cluster/v1/__init__.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/clustering/v1/__init__.py', 'openstack/tests/unit/cluster/v1/test_proxy.py', 'openstack/tests/unit/cluster/test_cluster_service.py', 'openstack/tests/unit/test_connection.py', 'openstack/tests/unit/test_profile.py', 'openstack/profile.py', 'openstack/clustering/v1/__init__.py', 'openstack/tests/unit/cluster/__init__.py', 'openstack/cluster/v1/cluster.py', 'openstack/cluster/__init__.py', 'openstack/cluster/v1/__init__.py', 'openstack/tests/unit/cluster/v1/test_cluster.py', 'openstack/tests/unit/cluster/test_version.py', 'openstack/cluster/cluster_service.py']",17,3cb4a44fa78fc0d0c1860a862002db1ef1366aa7,cluster-service,"class ClusterService(service_filter.ServiceFilter): """"""The cluster service."""""" """"""Create a cluster service."""""" super(ClusterService, self).__init__( service_type='cluster',","class ClusteringService(service_filter.ServiceFilter): """"""The clustering service."""""" """"""Create a clustering service."""""" super(ClusteringService, self).__init__( service_type='clustering',",42,32
openstack%2Frequirements~master~Ie715f98fe0d3cba8b2f4f6235e7c2b6f79be7ea0,openstack/requirements,master,Ie715f98fe0d3cba8b2f4f6235e7c2b6f79be7ea0,Raise min version of stevedore to 1.5.0,MERGED,2015-06-03 11:38:20.000000000,2015-06-11 00:40:21.000000000,2015-06-11 00:40:19.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1669}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-06-03 11:38:20.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4f76ab512d1d36e4a05a783fc93284f80f9ff2b9', 'message': 'Raise min version of stevedore to 1.5.0\n\nstevedore 1.5.0 provides a new feature for building documentation from a\nplugin set in sphinx. We would like to use this in the docs for some of\nthe Oslo libraries like oslo.messaging.\n\nChange-Id: Ie715f98fe0d3cba8b2f4f6235e7c2b6f79be7ea0\n'}]",0,187957,4f76ab512d1d36e4a05a783fc93284f80f9ff2b9,7,6,1,2472,,,0,"Raise min version of stevedore to 1.5.0

stevedore 1.5.0 provides a new feature for building documentation from a
plugin set in sphinx. We would like to use this in the docs for some of
the Oslo libraries like oslo.messaging.

Change-Id: Ie715f98fe0d3cba8b2f4f6235e7c2b6f79be7ea0
",git fetch https://review.opendev.org/openstack/requirements refs/changes/57/187957/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,4f76ab512d1d36e4a05a783fc93284f80f9ff2b9,stevedore-1-5-0,stevedore>=1.5.0 # Apache-2.0,stevedore>=1.3.0 # Apache-2.0,1,1
openstack%2Frally~master~I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7,openstack/rally,master,I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7,Better mocking for self.[admin_]clients in Scenario tests,MERGED,2015-06-04 19:05:15.000000000,2015-06-11 00:29:14.000000000,2015-06-11 00:29:13.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 13609}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-04 19:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/643d9ebeb24b0724019ca95054bcc76e669be3ea', 'message': 'WIP: Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nI\'ve converted the Keystone and Nova scenarios; if those, and the\napproach, look good, then I\'ll do the rest and resubmit this patch\ns/WIP//.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 2, 'created': '2015-06-05 20:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ab7a1c1a597123c2b53f060122635786ba05cc98', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 3, 'created': '2015-06-08 15:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/92bc01d857c2943ddaf75d471c27ec2f46901543', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 4, 'created': '2015-06-09 19:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0d626b3653106e513435c1ddd125ecf18948619d', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 5, 'created': '2015-06-09 19:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/571572dfcbf28d62d493b142423d7aef74f7acbc', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 6, 'created': '2015-06-09 20:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/148be973a33b0e8f8b5db5f9fca851374b865167', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 7, 'created': '2015-06-10 15:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6a410b9f4dd4fb6a87938d6bf18f0fc2b2d98b6f', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}, {'number': 8, 'created': '2015-06-10 16:46:17.000000000', 'files': ['tests/unit/plugins/openstack/scenarios/quotas/test_utils.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_utils.py', 'tests/unit/plugins/openstack/scenarios/zaqar/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_clusters.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_jobs.py', 'tests/unit/plugins/openstack/scenarios/swift/test_utils.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_utils.py', 'tests/unit/plugins/openstack/scenarios/neutron/test_network.py', 'tests/unit/plugins/openstack/scenarios/swift/test_objects.py', 'tests/unit/plugins/openstack/scenarios/quotas/test_quotas.py', 'tests/unit/plugins/openstack/scenarios/designate/test_utils.py', 'tests/unit/plugins/openstack/scenarios/mistral/test_utils.py', 'tests/unit/plugins/openstack/scenarios/glance/test_images.py', 'tests/unit/plugins/openstack/scenarios/sahara/test_utils.py', 'tests/unit/plugins/openstack/scenarios/glance/test_utils.py', 'tests/unit/plugins/openstack/scenarios/keystone/test_utils.py', 'tests/unit/plugins/openstack/scenarios/heat/test_stacks.py', 'tests/unit/test.py', 'tests/unit/plugins/openstack/scenarios/ec2/test_servers.py', 'tests/unit/plugins/openstack/scenarios/murano/test_utils.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_volumes.py', 'tests/unit/plugins/openstack/scenarios/fuel/test_utils.py', 'tests/unit/plugins/openstack/scenarios/heat/test_utils.py', 'tests/unit/plugins/openstack/scenarios/cinder/test_utils.py', 'tests/unit/plugins/openstack/scenarios/authenticate/test_authenticate.py', 'tests/unit/plugins/openstack/scenarios/ceilometer/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/48fb0bdf5fb69ba63eb50be3920163fd9d9b1df9', 'message': 'Better mocking for self.[admin_]clients in Scenario tests\n\nself.clients and self.admin_clients are mocked out in all sorts of fun\nand interesting ways in the Scenario test cases, but rarely is it done\nthe same way twice. Many of the tests fail to distinguish between a\ncall to self.clients and a call to self.admin_clients, and all (or\nnearly all) don\'t distinguish between clients -- that is, if a test\nexpects a call to self.clients(""nova"").foo, that would be satisfied by\nself.clients(""keystone"").foo. This patch fixes those issues, and gives\nus a consistent way to mock them going forward.\n\nChange-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7\n'}]",13,188554,48fb0bdf5fb69ba63eb50be3920163fd9d9b1df9,35,6,8,11748,,,0,"Better mocking for self.[admin_]clients in Scenario tests

self.clients and self.admin_clients are mocked out in all sorts of fun
and interesting ways in the Scenario test cases, but rarely is it done
the same way twice. Many of the tests fail to distinguish between a
call to self.clients and a call to self.admin_clients, and all (or
nearly all) don't distinguish between clients -- that is, if a test
expects a call to self.clients(""nova"").foo, that would be satisfied by
self.clients(""keystone"").foo. This patch fixes those issues, and gives
us a consistent way to mock them going forward.

Change-Id: I98a532cedbe186c49bd5b6db903a72e7d1b6bcc7
",git fetch https://review.opendev.org/openstack/rally refs/changes/54/188554/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/plugins/openstack/scenarios/keystone/test_utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'tests/unit/test.py', 'tests/unit/plugins/openstack/scenarios/nova/test_utils.py']",4,643d9ebeb24b0724019ca95054bcc76e669be3ea,mock-clients,"class NovaScenarioTestCase(test.ClientsTestCase): def test__list_servers(self): self.clients(""nova"").servers.list.return_value = servers_list def test__boot_server(self, mock_generate_random_name): self.clients(""nova"").servers.create.return_value = self.server self.clients(""nova"").servers.create.assert_called_once_with( def test__boot_server_with_network(self, mock_generate_random_name): self.clients(""nova"").servers.create.return_value = self.server self.clients(""nova"").networks.list.return_value = networks self.clients(""nova"").servers.create.assert_called_once_with( def test__boot_server_with_network_exception(self): self.clients(""nova"").servers.create.return_value = self.server def test__boot_server_with_ssh(self, mock_generate_random_name): self.clients(""nova"").servers.create.return_value = self.server self.clients(""nova"").servers.create.assert_called_once_with( def test__boot_server_with_sec_group(self, mock_generate_random_name): self.clients(""nova"").servers.create.return_value = self.server self.clients(""nova"").servers.create.assert_called_once_with( def test__boot_server_with_similar_sec_group(self, mock_generate_random_name): self.clients(""nova"").servers.create.return_value = self.server self.clients(""nova"").servers.create.assert_called_once_with( def test__create_image(self): self.clients(""nova"").images.get.return_value = self.image def _test_delete_servers(self, force=False): def test__boot_servers(self): self.clients(""nova"").servers.list.return_value = [self.server, def test__list_networks(self): self.clients(""nova"").networks.list.return_value = network_list def test__attach_volume(self): self.clients(""nova"").volumes.create_server_volume.return_value = None def test__detach_volume(self): self.clients(""nova"").volumes.delete_server_volume.return_value = None def test__live_migrate_server(self): self.admin_clients(""nova"").servers.get(return_value=self.server) nova_scenario = utils.NovaScenario() def test__find_host_to_migrate(self): self.admin_clients(""nova"").servers.get.return_value = fake_server self.admin_clients(""nova"").availability_zones.list.return_value = [ nova_scenario = utils.NovaScenario() def test__migrate_server(self): self.clients(""nova"").servers.get(return_value=fake_server) nova_scenario = utils.NovaScenario() self.assertEqual( security_group_count, self.clients(""nova"").security_groups.create.call_count) self.assertEqual( len(fake_secgroups) * rules_per_security_group, self.clients(""nova"").security_group_rules.create.call_count) self.clients(""nova"").security_groups.delete.call_args_list) self.clients(""nova"").security_groups.list.assert_called_once_with() def test__list_keypairs(self): self.clients(""nova"").keypairs.list.return_value = keypairs_list def test__create_keypair(self): self.clients(""nova"").keypairs.create.return_value.name = self.keypair def test__delete_keypair(self): self.clients(""nova"").keypairs.delete.assert_called_once_with( def test__list_floating_ips_bulk(self): self.admin_clients(""nova"").floating_ips_bulk.list.return_value = ( def test__create_floating_ips_bulk(self, mock_gencidr): self.admin_clients(""nova"").floating_ips_bulk.create.return_value = ( def test__delete_floating_ips_bulk(self): self.admin_clients( ""nova"").floating_ips_bulk.delete.assert_called_once_with(fake_cidr) def test__list_hypervisors(self): self.admin_clients(""nova"").hypervisors.list.assert_called_once_with( False)","class NovaScenarioTestCase(test.TestCase): @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__list_servers(self, mock_clients): mock_clients(""nova"").servers.list.return_value = servers_list @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_server(self, mock_clients, mock_generate_random_name): mock_clients(""nova"").servers.create.return_value = self.server mock_clients(""nova"").servers.create.assert_called_once_with( @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_server_with_network(self, mock_clients, mock_generate_random_name): mock_clients(""nova"").servers.create.return_value = self.server mock_clients(""nova"").networks.list.return_value = networks mock_clients(""nova"").servers.create.assert_called_once_with( @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_server_with_network_exception(self, mock_clients): mock_clients(""nova"").servers.create.return_value = self.server @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_server_with_ssh(self, mock_clients, mock_generate_random_name): mock_clients(""nova"").servers.create.return_value = self.server mock_clients(""nova"").servers.create.assert_called_once_with( @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_server_with_sec_group(self, mock_clients, mock_generate_random_name): mock_clients(""nova"").servers.create.return_value = self.server mock_clients(""nova"").servers.create.assert_called_once_with( @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_server_with_similar_sec_group(self, mock_clients, mock_generate_random_name): mock_clients(""nova"").servers.create.return_value = self.server mock_clients(""nova"").servers.create.assert_called_once_with( @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__create_image(self, mock_clients): mock_clients(""nova"").images.get.return_value = self.image @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def _test_delete_servers(self, mock_clients, force=False): @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__boot_servers(self, mock_clients): mock_clients(""nova"").servers.list.return_value = [self.server, @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__list_networks(self, mock_clients): mock_clients(""nova"").networks.list.return_value = network_list @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__attach_volume(self, mock_clients): mock_clients(""nova"").volumes.create_server_volume.return_value = None @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__detach_volume(self, mock_clients): mock_clients(""nova"").volumes.delete_server_volume.return_value = None @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__live_migrate_server(self, mock_clients): mock_clients(""nova"").servers.get(return_value=self.server) nova_scenario = utils.NovaScenario(admin_clients=mock_clients) @mock.patch(NOVA_UTILS + "".NovaScenario.admin_clients"") def test__find_host_to_migrate(self, mock_clients): nova_client = mock.MagicMock() mock_clients.return_value = nova_client nova_client.servers.get.return_value = fake_server nova_client.availability_zones.list.return_value = [ nova_scenario = utils.NovaScenario(admin_clients=fakes.FakeClients()) @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__migrate_server(self, mock_clients): mock_clients(""nova"").servers.get(return_value=fake_server) nova_scenario = utils.NovaScenario(admin_clients=mock_clients) clients = mock.MagicMock() nova_scenario.clients = clients self.assertEqual(security_group_count, clients.call_count) self.assertEqual(security_group_count, clients().security_groups.create.call_count) clients = mock.MagicMock() nova_scenario.clients = clients self.assertEqual(len(fake_secgroups) * rules_per_security_group, clients.call_count) self.assertEqual(len(fake_secgroups) * rules_per_security_group, clients().security_group_rules.create.call_count) clients = mock.MagicMock() nova_scenario.clients = clients self.assertEqual(len(fake_secgroups), clients.call_count) clients().security_groups.delete.call_args_list) clients = mock.MagicMock() nova_scenario.clients = clients clients.assert_called_once_with(""nova"") clients().security_groups.list.assert_called_once_with() @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__list_keypairs(self, mock_clients): mock_clients(""nova"").keypairs.list.return_value = keypairs_list @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__create_keypair(self, mock_clients): (mock_clients(""nova"").keypairs.create. return_value.name) = self.keypair @mock.patch(NOVA_UTILS + "".NovaScenario.clients"") def test__delete_keypair(self, mock_clients): mock_clients(""nova"").keypairs.delete.assert_called_once_with( @mock.patch(NOVA_UTILS + "".NovaScenario.admin_clients"") def test__list_floating_ips_bulk(self, mock_clients): mock_clients(""nova"").floating_ips_bulk.list.return_value = ( @mock.patch(NOVA_UTILS + "".NovaScenario.admin_clients"") def test__create_floating_ips_bulk(self, mock_clients, mock_gencidr): mock_clients(""nova"").floating_ips_bulk.create.return_value = ( @mock.patch(NOVA_UTILS + "".NovaScenario.admin_clients"") def test__delete_floating_ips_bulk(self, mock_clients): mock_clients(""nova"").floating_ips_bulk.delete.assert_called_once_with( fake_cidr) @mock.patch(NOVA_UTILS + "".NovaScenario.admin_clients"") def test__list_hypervisors(self, mock_clients): mock_clients(""nova"").hypervisors.list.assert_called_once_with(False)",172,285
openstack%2Fneutron~master~I6861498e7609b0c21fad844009420ea9734e2352,openstack/neutron,master,I6861498e7609b0c21fad844009420ea9734e2352,Actually allow to pass TRACE_FAILONLY to ostestr,MERGED,2015-06-10 11:12:54.000000000,2015-06-11 00:19:06.000000000,2015-06-10 17:34:43.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-10 11:12:54.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eeacb95e65a749ce3a032246c36d10cad9df22b1', 'message': 'Actually allow to pass TRACE_FAILONLY to ostestr\n\nThe comment below suggests to use TRACE_FAILONLY to fail quickly when\nrunning unit tests, while tox 2.0 does not allow to pass envvars from\nthe cli caller unless they are explicitly mentioned in passenv=\ndirective.\n\nChange-Id: I6861498e7609b0c21fad844009420ea9734e2352\n'}]",0,190122,eeacb95e65a749ce3a032246c36d10cad9df22b1,25,21,1,9656,,,0,"Actually allow to pass TRACE_FAILONLY to ostestr

The comment below suggests to use TRACE_FAILONLY to fail quickly when
running unit tests, while tox 2.0 does not allow to pass envvars from
the cli caller unless they are explicitly mentioned in passenv=
directive.

Change-Id: I6861498e7609b0c21fad844009420ea9734e2352
",git fetch https://review.opendev.org/openstack/neutron refs/changes/22/190122/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,eeacb95e65a749ce3a032246c36d10cad9df22b1,ostestr,passenv = TRACE_FAILONLY,,1,0
openstack%2Fnova~master~I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e,openstack/nova,master,I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e,virt: introduce model for describing local image metadata,MERGED,2014-10-30 13:22:08.000000000,2015-06-11 00:04:49.000000000,2015-06-10 15:29:54.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8412}, {'_account_id': 8802}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12898}, {'_account_id': 13734}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2014-10-30 13:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49c9d79a95269307bffb77adff4afbb35899679d', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 2, 'created': '2014-10-30 17:45:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39c014aad1216185f93bab16e8df34bd8b874ae0', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 3, 'created': '2014-11-13 09:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66f43b37ab45db1b64edc1009e1abd122ce53178', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 4, 'created': '2014-11-18 12:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1f9821315696475d5c1a4a9c3a38974eeaf9b19', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 5, 'created': '2014-11-20 15:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9357680b0a83ea06bbd1c2455f5af3b2404979cb', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 6, 'created': '2014-11-20 15:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/223ebb7aaa8b3f996b05048afd569e7301b6935d', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 7, 'created': '2014-12-02 15:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46130fa57b765a94b93c383c5bbd09be892bde65', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 8, 'created': '2014-12-08 17:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e00a9521ebf33c67049780906ca7721eb7696535', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 9, 'created': '2014-12-09 10:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3fc7d8f7ade55f151acb73916bec3411c365565', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 10, 'created': '2014-12-16 11:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd4c5289520fe10cb2ee7f36953b8377e6069995', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 11, 'created': '2014-12-18 10:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47d6e7aeff8c199e6d9bf923a1d10a9903708075', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 12, 'created': '2014-12-19 11:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ac78d4fe314b8755a1487ccc3b1cf32c36280d48', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 13, 'created': '2015-01-12 12:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ec89d44f4376ba4df0e7967b4c04f70db04710d', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 14, 'created': '2015-01-13 11:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79f38ba6b1b8545ad62d0711c0314b9da4583f13', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 15, 'created': '2015-01-19 12:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c0a1f52b217841a7788d1e8139373f49cbc952d', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 16, 'created': '2015-01-26 11:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5ea2200c38b165b35b027f5cd049c689cbfd09f7', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 17, 'created': '2015-01-26 15:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4b5defafabda89459401c4add03113b6729ee33', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 18, 'created': '2015-01-27 11:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3451a59c7ce6c064d993eab9ddd6f7f065d3757e', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 19, 'created': '2015-01-28 12:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ada1298cf78eccdf9c0a1b9f076b915fd4316182', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 20, 'created': '2015-02-03 10:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4922411999497678edd93e5e04b172ad91ccc173', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 21, 'created': '2015-02-16 10:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/515b5e4f4f10cf588a612f1975135fe59ed631fb', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 22, 'created': '2015-04-30 11:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c0b1955f5542467bd0e72a226cc1b3700c419406', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 23, 'created': '2015-05-14 10:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdaee759b3b1f8e1fc0d3667ad4c7e7a46b21c3c', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 24, 'created': '2015-05-18 10:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6e634c471e95e4f4a640138e4f345547c525087', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 25, 'created': '2015-05-26 16:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7712a6cd13d1b6edad53d30bb204c9fa9fa39614', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nThese classes are only intended to contain identifying\nattributes for the various storage backends used as\nimages. They are not intended to hold any functional\nlogic, as that will remain in the libvirt driver private\nimage backend classes. This separates generic description\nof storage backends, from driver specific implementation\ndetails.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 26, 'created': '2015-06-02 14:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf7af6a0eb5d7c73016d171aa58aa08d54ac44ae', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nThese classes are only intended to contain identifying\nattributes for the various storage backends used as\nimages. They are not intended to hold any functional\nlogic, as that will remain in the libvirt driver private\nimage backend classes. This separates generic description\nof storage backends, from driver specific implementation\ndetails.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}, {'number': 27, 'created': '2015-06-04 13:04:14.000000000', 'files': ['nova/virt/image/model.py', 'nova/tests/unit/virt/image/test_model.py', 'nova/exception.py', 'nova/tests/unit/virt/image/__init__.py', 'nova/virt/image/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/79af02046dab23ddb6399adfa8d9785694925be0', 'message': 'virt: introduce model for describing local image metadata\n\nIt is not sufficient to just pass a filename into the\nlibguestfs APIs. There needs to be various pieces of\nmetadata passed in order to support network based images.\nThis introduces a simple data model to describe images\nwhen passing info from virt drivers to the VFS APIs.\n\nThese classes are only intended to contain identifying\nattributes for the various storage backends used as\nimages. They are not intended to hold any functional\nlogic, as that will remain in the libvirt driver private\nimage backend classes. This separates generic description\nof storage backends, from driver specific implementation\ndetails.\n\nRelated-Bug: #1257674\nChange-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e\n'}]",28,132020,79af02046dab23ddb6399adfa8d9785694925be0,267,27,27,1779,,,0,"virt: introduce model for describing local image metadata

It is not sufficient to just pass a filename into the
libguestfs APIs. There needs to be various pieces of
metadata passed in order to support network based images.
This introduces a simple data model to describe images
when passing info from virt drivers to the VFS APIs.

These classes are only intended to contain identifying
attributes for the various storage backends used as
images. They are not intended to hold any functional
logic, as that will remain in the libvirt driver private
image backend classes. This separates generic description
of storage backends, from driver specific implementation
details.

Related-Bug: #1257674
Change-Id: I5f86d91aa2bcef2385d5d16022a9bd4ea7b0485e
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/132020/27 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/image/model.py', 'nova/virt/image/__init__.py', 'nova/tests/virt/image/test_model.py', 'nova/tests/virt/image/__init__.py']",4,49c9d79a95269307bffb77adff4afbb35899679d,bug/1257674,,,151,0
openstack%2Fneutron~master~I2268ed45ab628fe5dcab657d6287594847ab587c,openstack/neutron,master,I2268ed45ab628fe5dcab657d6287594847ab587c,Switch to os-testr to control testr,MERGED,2015-06-09 09:55:10.000000000,2015-06-10 23:59:05.000000000,2015-06-10 12:53:03.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-09 09:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9790726f6734d3b6ac829d9479aff48f6398785f', 'message': ""Switch to os-testr to control testr\n\nIt's a nice wrapper spinned out recently from tempest-lib that should\ncover all our needs that we currently fulfill with pretty_tox.sh.\n\nChange-Id: I2268ed45ab628fe5dcab657d6287594847ab587c\n""}, {'number': 2, 'created': '2015-06-10 11:12:54.000000000', 'files': ['test-requirements.txt', 'tox.ini', 'tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c124a309bc941c078b8bb622ea248a3ed3829e1', 'message': ""Switch to os-testr to control testr\n\nIt's a nice wrapper spinned out recently from tempest-lib that should\ncover all our needs that we currently fulfill with pretty_tox.sh.\n\nChange-Id: I2268ed45ab628fe5dcab657d6287594847ab587c\n""}]",7,189626,1c124a309bc941c078b8bb622ea248a3ed3829e1,49,25,2,9656,,,0,"Switch to os-testr to control testr

It's a nice wrapper spinned out recently from tempest-lib that should
cover all our needs that we currently fulfill with pretty_tox.sh.

Change-Id: I2268ed45ab628fe5dcab657d6287594847ab587c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/189626/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini', 'tools/pretty_tox.sh']",3,9790726f6734d3b6ac829d9479aff48f6398785f,ostestr,,"#! /bin/sh TESTRARGS=$1 exec 3>&1 status=$(exec 4>&1 >&3; ( python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS""; echo $? >&4 ) | subunit-trace -f) && exit $status ",3,8
openstack%2Fhorizon~master~I3a6b89d690966080c85b629e0b2b7f2a790a0aaf,openstack/horizon,master,I3a6b89d690966080c85b629e0b2b7f2a790a0aaf,Use bdmv2 format when instance is boot from volume,MERGED,2014-11-18 11:57:50.000000000,2015-06-10 23:41:56.000000000,2015-06-10 23:41:54.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 6825}, {'_account_id': 6914}, {'_account_id': 7665}, {'_account_id': 10068}, {'_account_id': 11592}, {'_account_id': 11941}, {'_account_id': 12355}, {'_account_id': 13325}, {'_account_id': 14005}]","[{'number': 1, 'created': '2014-11-18 11:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b0cf752727becc8ce43172e083004c1ff3020134', 'message': 'Changes for blueprint: Use new block device mapping (bdmv2) for booting a instance from volume\n\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 2, 'created': '2014-11-27 11:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/79e5da0aa62c5551ef877f212dfc06bfb1e4e981', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements bp horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 3, 'created': '2014-12-04 12:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b6e81ca5edde26977c9df83b048cd98cd9427662', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements bp horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 4, 'created': '2014-12-18 07:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a39b5c7a6b1880790616b0f1774976406c27aadd', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements bp horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 5, 'created': '2014-12-24 13:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/734bf73fecdb294fd49a8c05507373405a3122d7', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements blueprint horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 6, 'created': '2014-12-29 11:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/343c8c65c0af36f98263c944f6f8c67d4e6ae4d8', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements blueprint horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 7, 'created': '2015-03-11 06:36:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/93865a718c92f26b7429b9034572a1ce07f207a7', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements bp horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 8, 'created': '2015-03-11 09:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/030daa94c7aa9ee6d980df5c41e21392cc89364c', 'message': ' Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements bp horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}, {'number': 9, 'created': '2015-03-17 10:07:17.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/instances/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/45ed4ab8f8f5517a36c1f65a47ebc1e5ac5867eb', 'message': 'Use bdmv2 format when instance is boot from volume\n\nCurrently boot from volume uses bdmv1 format. In this blueprint\nbdmv2 format will be used for block device mapping instead bdmv1\nformat if V2 extension api is supported else bdmv1 format will\nbe used. Unit tests have been added.\n\nimplements bp horizon-block-device-mapping-v2\nChange-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf\n'}]",40,135253,45ed4ab8f8f5517a36c1f65a47ebc1e5ac5867eb,80,14,9,14005,,,0,"Use bdmv2 format when instance is boot from volume

Currently boot from volume uses bdmv1 format. In this blueprint
bdmv2 format will be used for block device mapping instead bdmv1
format if V2 extension api is supported else bdmv1 format will
be used. Unit tests have been added.

implements bp horizon-block-device-mapping-v2
Change-Id: I3a6b89d690966080c85b629e0b2b7f2a790a0aaf
",git fetch https://review.opendev.org/openstack/horizon refs/changes/53/135253/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/workflows/create_instance.py'],1,b0cf752727becc8ce43172e083004c1ff3020134,bp/bdmv2," elif source_type in ['volume_id']: if api.nova.extension_supported(""BlockDeviceMappingV2Boot"", request): uuidStr = context['source_id'].split(':')[0] dev_mapping_2 = [ {'device_name': str(context['device_name']), 'source_type': 'volume', 'destination_type': 'volume', 'delete_on_termination': int(bool(context['delete_on_terminate'])), 'uuid': uuidStr, 'boot_index': '0', 'volume_size': context['volume_size'] } ] else: dev_mapping_1 = {context['device_name']: '%s::%s' % (context['source_id'], int(bool(context['delete_on_terminate'])))} elif source_type in ['volume_snapshot_id']: if api.nova.extension_supported(""BlockDeviceMappingV2Boot"", request): uuidStr = context['source_id'].split(':')[0] dev_mapping_2 = [ {'device_name': str(context['device_name']), 'source_type': 'snapshot', 'destination_type': 'volume', 'delete_on_termination': int(bool(context['delete_on_terminate'])), 'uuid': uuidStr, 'boot_index': '0', 'volume_size': context['volume_size'] } ] else: dev_mapping_1 = {context['device_name']: '%s::%s' % (context['source_id'], int(bool(context['delete_on_terminate'])))}"," elif source_type in ['volume_id', 'volume_snapshot_id']: dev_mapping_1 = {context['device_name']: '%s::%s' % (context['source_id'], int(bool(context['delete_on_terminate'])))}",38,5
openstack%2Fneutron~master~I240b935741e49fbf65c0b95715af04af4b2a73e7,openstack/neutron,master,I240b935741e49fbf65c0b95715af04af4b2a73e7,policy: cleanup deprecation code to handle old extension:xxx rules,MERGED,2015-04-23 12:28:12.000000000,2015-06-10 23:41:44.000000000,2015-06-10 23:41:42.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 6951}, {'_account_id': 7293}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-23 12:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b39786fc55c48085af6dbd03408c1a7e15f5526', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}, {'number': 2, 'created': '2015-04-23 17:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da3eb09d985dcbdb39ddf11ebf0a338bb5dfb353', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}, {'number': 3, 'created': '2015-05-11 12:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b464e2864d9ce1a9acba6725f88b8eea9f494bf', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}, {'number': 4, 'created': '2015-06-04 14:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/090a1a1894e68030f2305c26ebb514a9c6f28c61', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}, {'number': 5, 'created': '2015-06-04 15:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/086a9be9f09734738479e46eede23977a68ad2b3', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}, {'number': 6, 'created': '2015-06-05 15:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4983a62424f6a1890433deeab1129b6766844be8', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}, {'number': 7, 'created': '2015-06-09 17:06:38.000000000', 'files': ['neutron/tests/unit/test_policy.py', 'neutron/policy.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/66fece4f84e62f14fb59a721b37986784976d0c4', 'message': 'policy: cleanup deprecation code to handle old extension:xxx rules\n\nIt served and warned users for enough time (since Icehouse) to be sure\neveryone was notified about the need to update their policy file.\n\nChange-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7\n'}]",1,176710,66fece4f84e62f14fb59a721b37986784976d0c4,187,39,7,9656,,,0,"policy: cleanup deprecation code to handle old extension:xxx rules

It served and warned users for enough time (since Icehouse) to be sure
everyone was notified about the need to update their policy file.

Change-Id: I240b935741e49fbf65c0b95715af04af4b2a73e7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/176710/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_policy.py', 'neutron/policy.py']",2,0b39786fc55c48085af6dbd03408c1a7e15f5526,policy,"from neutron.i18n import _LE, _LW","import itertoolsfrom neutron.i18n import _LE, _LI, _LW# Maps deprecated 'extension' policies to new-style policies DEPRECATED_POLICY_MAP = { 'extension:provider_network': ['network:provider:network_type', 'network:provider:physical_network', 'network:provider:segmentation_id'], 'extension:router': ['network:router:external'], 'extension:port_binding': ['port:binding:vif_type', 'port:binding:vif_details', 'port:binding:profile', 'port:binding:host_id'] } DEPRECATED_ACTION_MAP = { 'view': ['get'], 'set': ['create', 'update'] } # Ensure backward compatibility with folsom/grizzly convention # for extension rules for pol in policies.keys(): if any([pol.startswith(depr_pol) for depr_pol in DEPRECATED_POLICY_MAP.keys()]): LOG.warn(_LW(""Found deprecated policy rule:%s. Please consider "" ""upgrading your policy configuration file""), pol) pol_name, action = pol.rsplit(':', 1) try: new_actions = DEPRECATED_ACTION_MAP[action] new_policies = DEPRECATED_POLICY_MAP[pol_name] # bind new actions and policies together for actual_policy in ['_'.join(item) for item in itertools.product(new_actions, new_policies)]: if actual_policy not in policies: # New policy, same rule LOG.info(_LI(""Inserting policy:%(new_policy)s in "" ""place of deprecated "" ""policy:%(old_policy)s""), {'new_policy': actual_policy, 'old_policy': pol}) policies[actual_policy] = policies[pol] # Remove old-style policy del policies[pol] except KeyError: LOG.error(_LE(""Backward compatibility unavailable for "" ""deprecated policy %s. The policy will "" ""not be enforced""), pol)",1,77
openstack%2Frequirements~master~I0f9ac55122f04c9acd11e382219dfd562035faea,openstack/requirements,master,I0f9ac55122f04c9acd11e382219dfd562035faea,Bump SQLAlchemy upper bound.,MERGED,2015-06-09 18:22:26.000000000,2015-06-10 23:41:39.000000000,2015-06-10 23:41:37.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 5638}, {'_account_id': 6476}, {'_account_id': 11816}, {'_account_id': 12000}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-09 18:22:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2862e72dd0fc007dcf594acda9443ce518ce2d57', 'message': 'Drop SQLAlchemy upper bound.\n\nSQLAlchemy 1.0.x should just work. So remove the cap and treat this most\nother libraries (uncapped).\n\nChange-Id: I0f9ac55122f04c9acd11e382219dfd562035faea\n'}, {'number': 2, 'created': '2015-06-10 15:57:32.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e59efee4feba64b37dba05ad706b775c5487e72d', 'message': 'Bump SQLAlchemy upper bound.\n\nSQLAlchemy 1.0.x should just work. So move the cap to 1.1 as suggested\nby Mike Bayer, the SQLAlchemy maintainer.\n\n""I would note that capping under 1.1 might be a good idea.   Each 1.x,\n1.y, etc. is where we might make bigger changes.""  - Michael Bayer\n\nChange-Id: I0f9ac55122f04c9acd11e382219dfd562035faea\n'}]",0,189847,e59efee4feba64b37dba05ad706b775c5487e72d,17,8,2,1849,,,0,"Bump SQLAlchemy upper bound.

SQLAlchemy 1.0.x should just work. So move the cap to 1.1 as suggested
by Mike Bayer, the SQLAlchemy maintainer.

""I would note that capping under 1.1 might be a good idea.   Each 1.x,
1.y, etc. is where we might make bigger changes.""  - Michael Bayer

Change-Id: I0f9ac55122f04c9acd11e382219dfd562035faea
",git fetch https://review.opendev.org/openstack/requirements refs/changes/47/189847/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,2862e72dd0fc007dcf594acda9443ce518ce2d57,SQLAlchemy,SQLAlchemy>=0.9.7,"SQLAlchemy>=0.9.7,<=0.9.99",1,1
openstack%2Fpython-openstackclient~master~I5b469d19ac58bcb31ebd276e1d62b3db8ccfb5a3,openstack/python-openstackclient,master,I5b469d19ac58bcb31ebd276e1d62b3db8ccfb5a3,Updated from global requirements,MERGED,2015-06-10 21:27:27.000000000,2015-06-10 23:28:13.000000000,2015-06-10 23:28:12.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-06-10 21:27:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/18991ab9a26546895f14508ffc282e807da90a0c', 'message': 'Updated from global requirements\n\nChange-Id: I5b469d19ac58bcb31ebd276e1d62b3db8ccfb5a3\n'}]",0,190365,18991ab9a26546895f14508ffc282e807da90a0c,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I5b469d19ac58bcb31ebd276e1d62b3db8ccfb5a3
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/65/190365/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,18991ab9a26546895f14508ffc282e807da90a0c,openstack/requirements,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,1,1
openstack%2Fbarbican~master~Ic61448ebda764900b01e76e78d4c6327663f9a4b,openstack/barbican,master,Ic61448ebda764900b01e76e78d4c6327663f9a4b,Sync with latest oslo-incubator,MERGED,2015-06-07 14:05:07.000000000,2015-06-10 23:26:18.000000000,2015-06-10 23:26:15.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7973}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-06-07 14:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8c7f05926029ea48468585927ae84f82ba106921', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: Ic61448ebda764900b01e76e78d4c6327663f9a4b\n'}, {'number': 2, 'created': '2015-06-10 11:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/af40d83eea216b66921d3094c49479597cca2c65', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest changes in oslo-incubator\n\nChange-Id: Ic61448ebda764900b01e76e78d4c6327663f9a4b'}, {'number': 3, 'created': '2015-06-10 11:07:43.000000000', 'files': ['barbican/openstack/common/eventlet_backdoor.py', 'barbican/openstack/common/service.py', 'barbican/openstack/common/threadgroup.py', 'openstack-common.conf', 'barbican/openstack/common/periodic_task.py', 'barbican/openstack/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/39885e89e243ce0e8c6c19fddcea2033d5f1a53e', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest changes in oslo-incubator\n\nChange-Id: Ic61448ebda764900b01e76e78d4c6327663f9a4b'}]",0,189103,39885e89e243ce0e8c6c19fddcea2033d5f1a53e,15,6,3,5638,,,0,"Sync with latest oslo-incubator

Periodic sync with latest changes in oslo-incubator

Change-Id: Ic61448ebda764900b01e76e78d4c6327663f9a4b",git fetch https://review.opendev.org/openstack/barbican refs/changes/03/189103/2 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/openstack/common/eventlet_backdoor.py', 'barbican/openstack/common/service.py', 'barbican/openstack/common/threadgroup.py', 'openstack-common.conf', 'barbican/openstack/common/periodic_task.py', 'barbican/openstack/common/loopingcall.py']",6,8c7f05926029ea48468585927ae84f82ba106921,," LOG.warning(_LW('task %(func_name)r run outlasted ' 'interval by %(delay).2f sec'), {'func_name': self.f, 'delay': delay})"," LOG.warn(_LW('task %(func_name)r run outlasted ' 'interval by %(delay).2f sec'), {'func_name': self.f, 'delay': delay})",59,41
openstack%2Fbarbican-specs~master~I935b94620766fa0cba19e1953690f89f976dbac9,openstack/barbican-specs,master,I935b94620766fa0cba19e1953690f89f976dbac9,Add spec for transport key reference,MERGED,2015-06-01 19:47:45.000000000,2015-06-10 23:22:35.000000000,2015-06-10 23:22:33.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7789}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-06-01 19:47:45.000000000', 'files': ['specs/liberty/add-transport-cert-ref.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/cd1ff0009843fd8a5deadf9ec289587506a71f83', 'message': 'Add spec for transport key reference\n\nChange-Id: I935b94620766fa0cba19e1953690f89f976dbac9\nImplements: blueprint add-transport-cert-ref\n'}]",0,187308,cd1ff0009843fd8a5deadf9ec289587506a71f83,8,4,1,9914,,,0,"Add spec for transport key reference

Change-Id: I935b94620766fa0cba19e1953690f89f976dbac9
Implements: blueprint add-transport-cert-ref
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/08/187308/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/add-transport-cert-ref.rst'],1,cd1ff0009843fd8a5deadf9ec289587506a71f83,bp/add-transport-cert-ref,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Add Transport Cert Reference ============================ Launchpad blueprint: https://blueprints.launchpad.net/barbican/+spec/add-transport-cert-ref Problem description =================== Transport keys are used to ensure that the secret is pre-encrypted in such a way that only the client and the back-end store can decrypt the secret. This is for users which do not trust Barbican, but do trust the back-end secret store. Alternatively, clients that are required by FIPS or Common Criteria (CC) requirements only to use CC certified components may be able to argue for being able to use Barbican if the secrets remain opaque in transit through Barbican to their final storage back-ends. Currently, the client gets the transport key from Barbican. But if the client does not trust Barbican, this is a potential vulnerability. We need to add the ability for the client to retrieve the transport key from the back-end store directly. Proposed change =============== The change here is straightforward. Instead of only returning the transport certificate as a result of the GET /transportkeys/{key_id} call, we will also return a reference to the transport key in the header (TRANSPORT_KEY_URL) This reference will be provided by the plugin, and should be a link to a trusted location where the transport cert could be retrieved. In practice, this would most likely be an HTTPS connection to the backend secret store. Internally, what this means is that the get_transport_key() method in the secret_store interface would be modified to return a dict containing both the value of the transport key and an external URL. We would use this dict to fill in the contents and header of the response. As this method already has a None default configuration, this change should not require any changes in existing plugins. Alternatives ------------ This is a trivial change that makes the transport key story more complete. Data model impact ----------------- None. REST API impact --------------- A new field will be added to the header in the response to GET /transportkeys/{key_id} as described above. Security impact --------------- Makes transport keys more secure. Notifications impact -------------------- None. Other end user impact --------------------- The client would need to decide whether to accept the value of the transport cert as returned by Barbican, or to retrieve the value from the provided URL. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: alee Work Items ---------- 1. The server side changes can likely be done in a single CR. 2. Client side changes. Dependencies ============ None. Testing ======= Unit and functional tests will need to be written. Documentation Impact ==================== Docs on transport key use will need to be written and updated. References ========== None ",,142,0
openstack%2Foslo.concurrency~master~I98565b22e68358efe28fea62f74f8ebfcc438ff7,openstack/oslo.concurrency,master,I98565b22e68358efe28fea62f74f8ebfcc438ff7,Replace locks and replace with fasteners library provides ones,MERGED,2015-05-25 01:42:28.000000000,2015-06-10 23:06:28.000000000,2015-06-10 23:06:26.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-05-25 01:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/2c13771ad683931e8f878187587eee539109c35a', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nDepends-On: I1e22d52b7186fac97fef30748e40cbd49c5f10b4\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 2, 'created': '2015-05-25 01:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/9c6a8b6d2c3382c304712a2dfc51b8574e97bccb', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nDepends-On: I1e22d52b7186fac97fef30748e40cbd49c5f10b4\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 3, 'created': '2015-05-25 03:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/715b8dbfc0614d6221e95e3ae056b6f3481770b7', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nDepends-On: I1e22d52b7186fac97fef30748e40cbd49c5f10b4\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 4, 'created': '2015-05-25 16:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/479470fdfeb297e84263a66d185ff9acc5cf22ae', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nThe tests that were ensuring the internals of this file lock have\nnow moved to the repo where that library is (for the time being):\n\nhttps://github.com/harlowja/fasteners/tree/master/fasteners/tests\n\nDepends-On: I1e22d52b7186fac97fef30748e40cbd49c5f10b4\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 5, 'created': '2015-05-26 04:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/011faab28341b54cfd53dd38227da3f005ac2cad', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nThe tests that were ensuring the internals of this file lock have\nnow moved to the repo where that library is (for the time being),\ncurrently travis is testing that repo against py2.6, py2.7 and py3.4.\n\nhttps://github.com/harlowja/fasteners/tree/master/fasteners/tests\n\nDepends-On: I1e22d52b7186fac97fef30748e40cbd49c5f10b4\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 6, 'created': '2015-06-02 16:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/27725e436e744ef39d28a6c95592ccd126640510', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nThe tests that were ensuring the internals of this file lock have\nnow moved to the repo where that library is (for the time being),\ncurrently travis is testing that repo against py2.6, py2.7 and py3.4.\n\nhttps://github.com/harlowja/fasteners/tree/master/fasteners/tests\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 7, 'created': '2015-06-02 18:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/75baff5730f4a6608e3aedca2cf12272f6c6a80a', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nThe tests that were ensuring the internals of this file lock have\nnow moved to the repo where that library is (for the time being),\ncurrently travis is testing that repo against py2.6, py2.7 and py3.4.\n\nhttps://github.com/harlowja/fasteners/tree/master/fasteners/tests\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 8, 'created': '2015-06-06 00:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/895049b6a173cae1b85550dc927131dcb29d719a', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nThe tests that were ensuring the internals of this file lock have\nnow moved to the repo where that library is (for the time being),\ncurrently travis is testing that repo against py2.6, py2.7 and py3.4.\n\nhttps://github.com/harlowja/fasteners/tree/master/fasteners/tests\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}, {'number': 9, 'created': '2015-06-06 00:44:22.000000000', 'files': ['requirements.txt', 'oslo_concurrency/lockutils.py', 'oslo_concurrency/tests/unit/test_lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/9f22c45397784f922f85025eb5c9f42a1fe561ce', 'message': 'Replace locks and replace with fasteners library provides ones\n\nThe fasteners library (extracted from this library and a couple other\nvariations) provides the interprocess lock logic and the reader writer\nlock logic so we can remove the local version and we can just use it\nfrom that library instead.\n\nThe tests that were ensuring the internals of this file lock have\nnow moved to the repo where that library is (for the time being),\ncurrently travis is testing that repo against py2.6, py2.7 and py3.4.\n\nhttps://github.com/harlowja/fasteners/tree/master/fasteners/tests\n\nDocs also exist at:\n\nhttp://fasteners.readthedocs.org/en/latest/\n\nChange-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7\n'}]",0,185291,9f22c45397784f922f85025eb5c9f42a1fe561ce,23,4,9,1297,,,0,"Replace locks and replace with fasteners library provides ones

The fasteners library (extracted from this library and a couple other
variations) provides the interprocess lock logic and the reader writer
lock logic so we can remove the local version and we can just use it
from that library instead.

The tests that were ensuring the internals of this file lock have
now moved to the repo where that library is (for the time being),
currently travis is testing that repo against py2.6, py2.7 and py3.4.

https://github.com/harlowja/fasteners/tree/master/fasteners/tests

Docs also exist at:

http://fasteners.readthedocs.org/en/latest/

Change-Id: I98565b22e68358efe28fea62f74f8ebfcc438ff7
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/91/185291/9 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo_concurrency/lockutils.py', 'oslo_concurrency/tests/unit/test_lockutils.py']",3,2c13771ad683931e8f878187587eee539109c35a,,,"import errnofrom concurrent import futures class BrokenLock(lockutils._FileLock): def __init__(self, name, errno_code): super(BrokenLock, self).__init__(name) self.errno_code = errno_code def unlock(self): pass def trylock(self): err = IOError() err.errno = self.errno_code raise err def test_bad_acquire(self): lock_file = os.path.join(self.lock_dir, 'lock') lock = BrokenLock(lock_file, errno.EBUSY) self.assertRaises(threading.ThreadError, lock.acquire) class ReadWriteLockTest(test_base.BaseTestCase): # This test works by sending up a bunch of threads and then running # them all at once and having different threads either a read lock # or a write lock; and sleeping for a period of time while using it. # # After the tests have completed the timings of each thread are checked # to ensure that there are no *invalid* overlaps (a writer should never # overlap with any readers, for example). # We will spend this amount of time doing some ""fake"" work. WORK_TIMES = [(0.01 + x / 100.0) for x in range(0, 5)] # NOTE(harlowja): Sleep a little so time.time() can not be the same (which # will cause false positives when our overlap detection code runs). If # there are real overlaps then they will still exist. NAPPY_TIME = 0.05 @staticmethod def _find_overlaps(times, start, end): """"""Counts num of overlaps between start and end in the given times."""""" overlaps = 0 for (s, e) in times: if s >= start and e <= end: overlaps += 1 return overlaps @classmethod def _spawn_variation(cls, readers, writers, max_workers=None): """"""Spawns the given number of readers and writers."""""" start_stops = collections.deque() lock = lockutils.ReaderWriterLock() def read_func(ident): with lock.read_lock(): # TODO(harlowja): sometime in the future use a monotonic clock # here to avoid problems that can be caused by ntpd resyncing # the clock while we are actively running. enter_time = time.time() time.sleep(cls.WORK_TIMES[ident % len(cls.WORK_TIMES)]) exit_time = time.time() start_stops.append((lock.READER, enter_time, exit_time)) time.sleep(cls.NAPPY_TIME) def write_func(ident): with lock.write_lock(): enter_time = time.time() time.sleep(cls.WORK_TIMES[ident % len(cls.WORK_TIMES)]) exit_time = time.time() start_stops.append((lock.WRITER, enter_time, exit_time)) time.sleep(cls.NAPPY_TIME) if max_workers is None: max_workers = max(0, readers) + max(0, writers) if max_workers > 0: with futures.ThreadPoolExecutor(max_workers=max_workers) as e: count = 0 for _i in range(0, readers): e.submit(read_func, count) count += 1 for _i in range(0, writers): e.submit(write_func, count) count += 1 writer_times = [] reader_times = [] for (lock_type, start, stop) in list(start_stops): if lock_type == lock.WRITER: writer_times.append((start, stop)) else: reader_times.append((start, stop)) return (writer_times, reader_times) def test_writer_abort(self): # Ensures that the lock is released when the writer has an # exception... lock = lockutils.ReaderWriterLock() self.assertFalse(lock.owner_type) def blow_up(): with lock.write_lock(): self.assertEqual(lock.WRITER, lock.owner_type) raise RuntimeError(""Broken"") self.assertRaises(RuntimeError, blow_up) self.assertFalse(lock.owner_type) def test_reader_abort(self): lock = lockutils.ReaderWriterLock() self.assertFalse(lock.owner_type) def blow_up(): with lock.read_lock(): self.assertEqual(lock.READER, lock.owner_type) raise RuntimeError(""Broken"") self.assertRaises(RuntimeError, blow_up) self.assertFalse(lock.owner_type) def test_double_reader_abort(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() def double_bad_reader(): with lock.read_lock(): with lock.read_lock(): raise RuntimeError(""Broken"") def happy_writer(): with lock.write_lock(): activated.append(lock.owner_type) # Submit a bunch of work to a pool, and then ensure that the correct # number of writers eventually executed (every other thread will # be a reader thread that will fail)... max_workers = 8 with futures.ThreadPoolExecutor(max_workers=max_workers) as e: for i in range(0, max_workers): if i % 2 == 0: e.submit(double_bad_reader) else: e.submit(happy_writer) self.assertEqual(max_workers / 2, len([a for a in activated if a == lockutils.ReaderWriterLock.WRITER])) def test_double_reader_writer(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() active = threading.Event() def double_reader(): with lock.read_lock(): active.set() # Wait for the writer thread to get into pending mode using a # simple spin-loop... while not lock._has_pending_writers(): time.sleep(0.001) with lock.read_lock(): activated.append(lock.owner_type) def happy_writer(): with lock.write_lock(): activated.append(lock.owner_type) reader = threading.Thread(target=double_reader) reader.daemon = True reader.start() # Wait for the reader to become the active reader. active.wait() self.assertTrue(active.is_set()) # Start up the writer (the reader will wait until its going). writer = threading.Thread(target=happy_writer) writer.daemon = True writer.start() # Ensure it went in the order we expected. reader.join() writer.join() self.assertEqual(2, len(activated)) self.assertEqual([lockutils.ReaderWriterLock.READER, lockutils.ReaderWriterLock.WRITER], list(activated)) def test_reader_chaotic(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() def chaotic_reader(blow_up): with lock.read_lock(): if blow_up: raise RuntimeError(""Broken"") else: activated.append(lock.owner_type) def happy_writer(): with lock.write_lock(): activated.append(lock.owner_type) # Test that every 4th reader blows up and that we get the expected # number of owners with this occuring. max_workers = 8 with futures.ThreadPoolExecutor(max_workers=max_workers) as e: for i in range(0, max_workers): if i % 2 == 0: e.submit(chaotic_reader, blow_up=bool(i % 4 == 0)) else: e.submit(happy_writer) writers = [a for a in activated if a == lockutils.ReaderWriterLock.WRITER] readers = [a for a in activated if a == lockutils.ReaderWriterLock.READER] self.assertEqual(4, len(writers)) self.assertEqual(2, len(readers)) def test_writer_chaotic(self): lock = lockutils.ReaderWriterLock() activated = collections.deque() def chaotic_writer(blow_up): with lock.write_lock(): if blow_up: raise RuntimeError(""Broken"") else: activated.append(lock.owner_type) def happy_reader(): with lock.read_lock(): activated.append(lock.owner_type) # Test that every 4th reader blows up and that we get the expected # number of owners with this occuring. max_workers = 8 with futures.ThreadPoolExecutor(max_workers=max_workers) as e: for i in range(0, max_workers): if i % 2 == 0: e.submit(chaotic_writer, blow_up=bool(i % 4 == 0)) else: e.submit(happy_reader) writers = [a for a in activated if a == lockutils.ReaderWriterLock.WRITER] readers = [a for a in activated if a == lockutils.ReaderWriterLock.READER] self.assertEqual(2, len(writers)) self.assertEqual(4, len(readers)) def test_single_reader_writer(self): results = [] lock = lockutils.ReaderWriterLock() with lock.read_lock(): self.assertTrue(lock._is_reader()) self.assertEqual(0, len(results)) with lock.write_lock(): results.append(1) self.assertTrue(lock._is_writer()) with lock.read_lock(): self.assertTrue(lock._is_reader()) self.assertEqual(1, len(results)) self.assertFalse(lock._is_reader()) self.assertFalse(lock._is_writer()) def test_reader_to_writer(self): lock = lockutils.ReaderWriterLock() def writer_func(): with lock.write_lock(): pass with lock.read_lock(): self.assertRaises(RuntimeError, writer_func) self.assertFalse(lock._is_writer()) self.assertFalse(lock._is_reader()) self.assertFalse(lock._is_writer()) def test_writer_to_reader(self): lock = lockutils.ReaderWriterLock() def reader_func(): with lock.read_lock(): pass with lock.write_lock(): self.assertRaises(RuntimeError, reader_func) self.assertFalse(lock._is_reader()) self.assertFalse(lock._is_reader()) self.assertFalse(lock._is_writer()) def test_double_writer(self): lock = lockutils.ReaderWriterLock() with lock.write_lock(): self.assertFalse(lock._is_reader()) self.assertTrue(lock._is_writer()) with lock.write_lock(): self.assertTrue(lock._is_writer()) self.assertTrue(lock._is_writer()) self.assertFalse(lock._is_reader()) self.assertFalse(lock._is_writer()) def test_double_reader(self): lock = lockutils.ReaderWriterLock() with lock.read_lock(): self.assertTrue(lock._is_reader()) self.assertFalse(lock._is_writer()) with lock.read_lock(): self.assertTrue(lock._is_reader()) self.assertTrue(lock._is_reader()) self.assertFalse(lock._is_reader()) self.assertFalse(lock._is_writer()) def test_multi_reader_multi_writer(self): writer_times, reader_times = self._spawn_variation(10, 10) self.assertEqual(10, len(writer_times)) self.assertEqual(10, len(reader_times)) for (start, stop) in writer_times: self.assertEqual(0, self._find_overlaps(reader_times, start, stop)) self.assertEqual(1, self._find_overlaps(writer_times, start, stop)) for (start, stop) in reader_times: self.assertEqual(0, self._find_overlaps(writer_times, start, stop)) def test_multi_reader_single_writer(self): writer_times, reader_times = self._spawn_variation(9, 1) self.assertEqual(1, len(writer_times)) self.assertEqual(9, len(reader_times)) start, stop = writer_times[0] self.assertEqual(0, self._find_overlaps(reader_times, start, stop)) def test_multi_writer(self): writer_times, reader_times = self._spawn_variation(0, 10) self.assertEqual(10, len(writer_times)) self.assertEqual(0, len(reader_times)) for (start, stop) in writer_times: self.assertEqual(1, self._find_overlaps(writer_times, start, stop)) ",5,714
openstack%2Frally~master~I641f5d03b8e67a56d09fd0cba4632ff803e793c1,openstack/rally,master,I641f5d03b8e67a56d09fd0cba4632ff803e793c1,Decrease time of rally verify job,MERGED,2015-06-10 21:27:12.000000000,2015-06-10 22:55:16.000000000,2015-06-10 22:55:14.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 14168}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-10 21:27:12.000000000', 'files': ['tests/ci/rally-verify.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/540aefc44015f327a404675ace64e855dc70bbae', 'message': ""Decrease time of rally verify job\n\nLet's use regex 'tempest.api.compute.servers.test_servers' instead of\nwhole compute set.\n\nChange-Id: I641f5d03b8e67a56d09fd0cba4632ff803e793c1\n""}]",0,190364,540aefc44015f327a404675ace64e855dc70bbae,9,4,1,9545,,,0,"Decrease time of rally verify job

Let's use regex 'tempest.api.compute.servers.test_servers' instead of
whole compute set.

Change-Id: I641f5d03b8e67a56d09fd0cba4632ff803e793c1
",git fetch https://review.opendev.org/openstack/rally refs/changes/64/190364/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/ci/rally-verify.sh'],1,540aefc44015f327a404675ace64e855dc70bbae,tempest, rally --rally-debug verify start --regex tempest.api.compute.servers.test_servers > ${OUTPUT_FILE} 2>&1,"# Run to verification for one SET_NAME and then compare them. SET_NAME=""compute"" rally --rally-debug verify start --set ${SET_NAME} > ${OUTPUT_FILE} 2>&1",1,4
openstack%2Fkeystone~master~Idb882d9acfdfac3ef5067e832bd923be5e4b506a,openstack/keystone,master,Idb882d9acfdfac3ef5067e832bd923be5e4b506a,Remove identity_api from AuthInfo dependencies,MERGED,2015-05-11 19:30:15.000000000,2015-06-10 22:46:28.000000000,2015-06-10 22:46:26.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 9142}, {'_account_id': 13063}, {'_account_id': 16165}]","[{'number': 1, 'created': '2015-05-11 19:30:15.000000000', 'files': ['keystone/auth/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/85b867520535e4f5bb77d59607d14c8424a02c0c', 'message': ""Remove identity_api from AuthInfo dependencies\n\nThe identity_api dependency isn't used by AuthInfo. Somebody must\nhave done the thing I had noted as a TODO.\n\nChange-Id: Idb882d9acfdfac3ef5067e832bd923be5e4b506a\n""}]",0,182032,85b867520535e4f5bb77d59607d14c8424a02c0c,12,7,1,6486,,,0,"Remove identity_api from AuthInfo dependencies

The identity_api dependency isn't used by AuthInfo. Somebody must
have done the thing I had noted as a TODO.

Change-Id: Idb882d9acfdfac3ef5067e832bd923be5e4b506a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/32/182032/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/auth/controllers.py'],1,85b867520535e4f5bb77d59607d14c8424a02c0c,cleanup,"@dependency.requires('resource_api', 'trust_api')","# TODO(blk-u): this class doesn't use identity_api directly, but makes it # available for consumers. Consumers should probably not be getting # identity_api from this since it's available in global registry, then # identity_api should be removed from this list. @dependency.requires('identity_api', 'resource_api', 'trust_api')",1,5
openstack%2Fironic-specs~master~Icb29fdc92ecd54e388b7c16899070572458308da,openstack/ironic-specs,master,Icb29fdc92ecd54e388b7c16899070572458308da,Add ironicclient version caching,MERGED,2015-06-05 01:20:27.000000000,2015-06-10 22:46:00.000000000,2015-06-10 22:45:58.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 13362}, {'_account_id': 13997}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-06-05 01:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2500332edfa90cc571301a435915055d38b438fc', 'message': 'Add ironicclient version caching\n\nImplement client-side version caching to the ironicclient so that\neach conversation between ironic and the client need not\nrenegotiate which version to use.\n\nChange-Id: Icb29fdc92ecd54e388b7c16899070572458308da\n'}, {'number': 2, 'created': '2015-06-05 02:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0a36dcf685b4cbe2997f221200561df4c562c396', 'message': 'Add ironicclient version caching\n\nImplement client-side version caching to the ironicclient so that\neach conversation between ironic and the client need not\nrenegotiate which version to use.\n\nChange-Id: Icb29fdc92ecd54e388b7c16899070572458308da\n'}, {'number': 3, 'created': '2015-06-09 00:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/f40fa04716e6430c00bcc08abaa271619ea56aaf', 'message': 'Add ironicclient version caching\n\nImplement client-side version caching to the ironicclient so that\neach conversation between ironic and the client need not\nrenegotiate which version to use.\n\nChange-Id: Icb29fdc92ecd54e388b7c16899070572458308da\n'}, {'number': 4, 'created': '2015-06-09 01:00:37.000000000', 'files': ['specs/liberty/version-caching.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/1a78de353857b1b5659958f89be2745b5ade98cf', 'message': 'Add ironicclient version caching\n\nImplement client-side version caching to the ironicclient so that\neach conversation between ironic and the client need not\nrenegotiate which version to use.\n\nChange-Id: Icb29fdc92ecd54e388b7c16899070572458308da\n'}]",30,188641,1a78de353857b1b5659958f89be2745b5ade98cf,25,8,4,8125,,,0,"Add ironicclient version caching

Implement client-side version caching to the ironicclient so that
each conversation between ironic and the client need not
renegotiate which version to use.

Change-Id: Icb29fdc92ecd54e388b7c16899070572458308da
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/41/188641/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/version-caching.rst'],1,2500332edfa90cc571301a435915055d38b438fc,version-caching,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Version Caching ================================================== https://blueprints.launchpad.net/ironic/+spec/version-caching This blueprint adds support for caching the version negiotiated by the ironicclient, between itself and the ironic server. This is supplimentary to the 'api microversion' spec approved last cycle. Problem description =================== When the ironicclient talks to the ironic server, there may be a mismatch in supported api versions. The client and server negotiate a version to be used in communicating, but since the ironicclient can be used as a user interactive client, this process of negotiation would be repeated for each command line invocation. It would be useful, for each ironic server that the ironicclient talks to, to cache the version agreed upon for communication, so that each conversation between client and server does not require renegotiation. This version caching would need to be per ironic server (host, network port pair specific) and would be time-bound (say 5 minutes), so any future upgrade of the client or server would benefit from supporting newer available versions. Proposed change =============== The proposed implementation consists of caching the negotiated version information between an ironicclient and ironic server in local file storage for use by future invocations of the ironicclient. This information would be cached for a specific period of time, before becoming stale and ignored. Specifically, we are proposing: * Using the dogpile.cache[1] caching system, since it has been used in other parts of OpenStack[2] * Storing the cached information in local file storage, using appdirs[3] to provide the correct location * Indexing the version information in a ironic-server:network-port pair so that multiple ironic servers running on the same IP address will be cached independently * Having a default period of 5 minutes for caching version information for each ironic server Storing the version information in a well-known, standardised, local file storage location means that, if the user wants to, they can remove the cached version information manually triggering a renegotiation of the version to be used in communication between the client and server. Alternatives ------------ An alternative file-based solution was proposed[4], but rejected in favour of using dogpile.cache. Data model impact ----------------- None State Machine Impact -------------------- None REST API impact --------------- None Client (CLI) impact ------------------- This spec only affects the python-ironicclient, not ironic server. RPC API impact -------------- None Driver API impact ----------------- None Nova driver impact ------------------ None Security impact --------------- None Other end user impact --------------------- None Scalability impact ------------------ None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: mrda - Michael Davies <michael@the-davies.net> Work Items ---------- * The implementation of this spec has already commenced - see [5] Dependencies ============ None Testing ======= Unit tests will be provided to verify this solution Upgrades and Backwards Compatibility ==================================== None Documentation Impact ==================== None References ========== * [1] Documentation on dogpile.cache is found here: https://dogpilecache.readthedocs.org/en/latest/ * [2] dogpile.cache is already specified in https://github.com/openstack/requirements/blob/master/global-requirements.txt and is used by https://github.com/openstack/os-client-config * [3] Documentation on appdirs is found here: https://pypi.python.org/pypi/appdirs * [4] Original custom file cache solution: https://review.openstack.org/#/c/173674/1/ * [5] Current state of the implemenation at the time of this spec being raised: https://review.openstack.org/#/c/173674/19 ",,180,0
openstack%2Frally~master~I3d529308fdce83122e3bbebdb30ccaa261fecd49,openstack/rally,master,I3d529308fdce83122e3bbebdb30ccaa261fecd49,Fix formatting of maintainers section in docs,MERGED,2015-06-06 22:28:19.000000000,2015-06-10 22:42:04.000000000,2015-06-10 22:42:01.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-06 22:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/34b79c7523a5cf15202cb315ea8cbbda813ed8f5', 'message': 'Fix for Italic parts of text\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}, {'number': 2, 'created': '2015-06-07 12:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/929cf86b92e553169eed837ed0e7682954536016', 'message': 'Fix for Italic parts of text\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}, {'number': 3, 'created': '2015-06-07 12:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/748bd9f515b3c2289ea0b3e3e3b8bef9b06fcd81', 'message': 'Fix for Italic parts of text and line breakers in contact info\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}, {'number': 4, 'created': '2015-06-08 20:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/272f402a54f8efa2eaa57cfbf885f567dd55ed64', 'message': 'Fix for Italic parts of text and line breakers in contact info plus unified email notation\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}, {'number': 5, 'created': '2015-06-09 11:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1f2ae5fd798126af0eb795c608faa7acf32bbb73', 'message': 'Fix formatting of maintainers section in docs \n\n\n* Fix notes formating  \n* Unify email styles always use @ \n* Better formatting of contact infomration\n\n\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}, {'number': 6, 'created': '2015-06-09 11:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/290033e0c4866176a2b1a1b86aa50342f95ae3ba', 'message': 'Fix formatting of maintainers section in docs \n\n\n* Fix notes formating  \n* Unify email styles always use @ \n* Better formatting of contact information\n\n\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}, {'number': 7, 'created': '2015-06-10 19:20:11.000000000', 'files': ['doc/source/project_info.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/d57e10d20b69f98e8caa9996ff64806b6de0fa2b', 'message': 'Fix formatting of maintainers section in docs\n\n* Fix notes formating\n* Unify email styles always use @\n* Better formatting of contact information\n\nChange-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49\n'}]",5,189061,d57e10d20b69f98e8caa9996ff64806b6de0fa2b,30,5,7,16198,,,0,"Fix formatting of maintainers section in docs

* Fix notes formating
* Unify email styles always use @
* Better formatting of contact information

Change-Id: I3d529308fdce83122e3bbebdb30ccaa261fecd49
",git fetch https://review.opendev.org/openstack/rally refs/changes/61/189061/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/project_info.rst'],1,34b79c7523a5cf15202cb315ea8cbbda813ed8f5,ipo-new-branch,"*If you would like to refactor whole Rally or have UX/community/other* *issues please contact me.**All cores from this list are reviewing all changes that are proposed to Rally* *To avoid duplication of efforts, please contact them before starting work on* *your code.**All cores from this list are responsible for their component plugins.* *To avoid duplication of efforts, please contact them before starting working* *on your own plugins.*","*If you would like to refactor whole Rally or have UX/community/other issues please contact me.**All cores from this list are reviewing all changes that are proposed to Rally To avoid duplication of efforts, please contact them before starting work on your code.**All cores from this list are responsible for their component plugins. To avoid duplication of efforts, please contact them before starting working on your own plugins.*",8,8
openstack%2Ftaskflow~master~I5e59efc4edd51b05cfb1e67d3e7014e378e352aa,openstack/taskflow,master,I5e59efc4edd51b05cfb1e67d3e7014e378e352aa,Use a lru cache to limit the size of the internal file cache,MERGED,2015-04-21 22:14:41.000000000,2015-06-10 22:41:01.000000000,2015-06-10 22:40:59.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-04-21 22:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1caf39e3cb4b0044eccdd0b5f994e91edcfccc1c', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nDepends-On: I31f5838ede9628ce25676381a35e974406a43a69\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 2, 'created': '2015-05-14 05:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7b58e1edd9e9d2ab4417aad8110a580c83e3a367', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nDepends-On: I31f5838ede9628ce25676381a35e974406a43a69\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 3, 'created': '2015-05-14 06:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/6c981965753127818bfca847599d1cb8199a9e99', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 4, 'created': '2015-05-23 20:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/84f103d4128cd5a815d5288a7960da1e6b33a65b', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 5, 'created': '2015-05-23 21:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/37cb56bd4a3f39888915afde852640c8dc64444e', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 6, 'created': '2015-05-30 03:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/028b9e609e4a12c428835f354ba2bfae27d76188', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 7, 'created': '2015-06-03 18:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4f0612951bc2cc97897132f2a9e23f864dabca09', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 8, 'created': '2015-06-04 02:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f04f2e72504d050202b7a1654c2fae55f325993f', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 9, 'created': '2015-06-04 04:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/573b81afa335c1e74d90c017f76be6a7eb5095cd', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 10, 'created': '2015-06-04 17:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/25a95b41ff8fd8588b6f819a8249696e29edd8f4', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}, {'number': 11, 'created': '2015-06-10 18:04:27.000000000', 'files': ['requirements.txt', 'taskflow/persistence/backends/impl_dir.py', 'taskflow/tests/unit/persistence/test_dir_persistence.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/33e9ccc42566f4b666e04c1291bf01539288ffaf', 'message': 'Use a lru cache to limit the size of the internal file cache\n\nInstead of having an unbounded internal file cache which will\neventually absorb all memory of the running/containing python\nprocess have the size of that cache be limited by an optionally\nprovided size (and have eviction be based on how recent a cached\nentry was used).\n\nFixes bug 1458248\n\nChange-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa\n'}]",8,176104,33e9ccc42566f4b666e04c1291bf01539288ffaf,40,5,11,1297,,,0,"Use a lru cache to limit the size of the internal file cache

Instead of having an unbounded internal file cache which will
eventually absorb all memory of the running/containing python
process have the size of that cache be limited by an optionally
provided size (and have eviction be based on how recent a cached
entry was used).

Fixes bug 1458248

Change-Id: I5e59efc4edd51b05cfb1e67d3e7014e378e352aa
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/04/176104/9 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'taskflow/persistence/backends/impl_dir.py', 'taskflow/tests/unit/persistence/test_dir_persistence.py']",3,1caf39e3cb4b0044eccdd0b5f994e91edcfccc1c,bug/1458248,"import testscenarios class DirPersistenceTest(testscenarios.TestWithScenarios, test.TestCase, base.PersistenceTestMixin): scenarios = [ ('no_cache', {'max_cache_size': None}), # The sizes are limits in the number of unicode characters of # each file, which will be used by the caching mechanism to determine # when to evict (when the size is breached...) ('zero', {'max_cache_size': 0}), ('tiny', {'max_cache_size': 512}), ('medimum', {'max_cache_size': 8192}), ('large', {'max_cache_size': 65536}), ] 'max_cache_size': self.max_cache_size,","class DirPersistenceTest(test.TestCase, base.PersistenceTestMixin):",32,2
openstack%2Fneutron~master~I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc,openstack/neutron,master,I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc,Introduce functions using arping executable,MERGED,2015-06-08 15:50:52.000000000,2015-06-10 22:39:36.000000000,2015-06-10 18:55:45.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7037}, {'_account_id': 8124}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-06-08 15:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1e0ff88209d141d6715db3caf69f1352ac716b0', 'message': 'Introduce Arpinger for testing ARPs\n\nThis patches splits Pinger class into base and actual implementation of\nPinger. Arpinger uses most of Pinger and just defines command used for\npinging destination.\n\nChange-Id: I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc\n'}, {'number': 2, 'created': '2015-06-09 14:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6cbc311a71668daaedfd88b785e33e463251c6b7', 'message': 'Break Pinger class to functions\n\nAs the class served only for storing parameters that can be passed as\nactual function parameters, there is no reason for class.\n\nChange-Id: I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc\n'}, {'number': 3, 'created': '2015-06-09 16:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6700ce5db166e716a58f0b79db44a17f01ac081', 'message': 'Introduce Arpinger for testing ARPs\n\nThe arpinger is gonna be used in the next changeset introducing\nconnection testers.\n\nChange-Id: I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc\n'}, {'number': 4, 'created': '2015-06-09 17:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc194342d37bcd6d326996749fa4a5d65eb36505', 'message': 'Introduce functions using arping executable\n\nThe arpinger is gonna be used in the next changeset introducing\nconnection testers.\n\nChange-Id: I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc\n'}, {'number': 5, 'created': '2015-06-10 08:46:00.000000000', 'files': ['neutron/tests/common/net_helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/da42745c466c14e6dbe58cdbc830ae5d1c8bb114', 'message': 'Introduce functions using arping executable\n\nThe arpinger is gonna be used in the next changeset introducing\nconnection testers.\n\nChange-Id: I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc\n'}]",15,189349,da42745c466c14e6dbe58cdbc830ae5d1c8bb114,99,27,5,8655,,,0,"Introduce functions using arping executable

The arpinger is gonna be used in the next changeset introducing
connection testers.

Change-Id: I90ae32c2f52f1debfb11ae2a08b2828ee2be04cc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/189349/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/common/machine_fixtures.py', 'neutron/tests/functional/agent/test_ovs_flows.py']",2,f1e0ff88209d141d6715db3caf69f1352ac716b0,arpinger," self.src_namespace, count=2)"," self.src_namespace, max_attempts=2)",48,12
openstack%2Fnetworking-l2gw~master~Id57891ab640b62b83d781eceab48478d4a262e94,openstack/networking-l2gw,master,Id57891ab640b62b83d781eceab48478d4a262e94,Add API Negative tests for L2Gateway extension,MERGED,2015-05-15 06:42:44.000000000,2015-06-10 22:37:54.000000000,2015-06-10 22:37:51.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6558}, {'_account_id': 10068}, {'_account_id': 10780}, {'_account_id': 10781}, {'_account_id': 11670}, {'_account_id': 11671}, {'_account_id': 11765}, {'_account_id': 14323}, {'_account_id': 15142}]","[{'number': 1, 'created': '2015-05-15 06:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/823d755a1fd1d741d218ad41ccce6dce21f165a7', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}, {'number': 2, 'created': '2015-05-15 09:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/485f3ed86c6a77e10f6c4ea1fa8f33e71cebe7fa', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}, {'number': 3, 'created': '2015-05-19 06:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/c6658ddf23ca770a809abf9d82165c116ea9754c', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}, {'number': 4, 'created': '2015-05-19 07:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/648f152fe738150cee4e6ab6f33455a45bc97f70', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}, {'number': 5, 'created': '2015-05-25 06:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/1ea6f47490a5caf7c61c9793954f0e32e88fdc59', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}, {'number': 6, 'created': '2015-05-26 06:03:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/72917c24fe1778573ad7e94c2f8883dacbd40381', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}, {'number': 7, 'created': '2015-06-02 07:24:39.000000000', 'files': ['networking_l2gw/tests/api/test_l2gw_negative.py'], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/bf7333aa92bbcb41631428584171fd946c8c67b2', 'message': 'Add API Negative tests for L2Gateway extension\n\nThis patch adds  negative tests for the L2Gateway\n\nChange-Id: Id57891ab640b62b83d781eceab48478d4a262e94\n'}]",6,183408,bf7333aa92bbcb41631428584171fd946c8c67b2,40,11,7,15142,,,0,"Add API Negative tests for L2Gateway extension

This patch adds  negative tests for the L2Gateway

Change-Id: Id57891ab640b62b83d781eceab48478d4a262e94
",git fetch https://review.opendev.org/openstack/networking-l2gw refs/changes/08/183408/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_l2gw/tests/api/test_l2gw_negative.py'],1,823d755a1fd1d741d218ad41ccce6dce21f165a7,183408," @test.attr(type=['negative', 'smoke']) def test_create_l2gw_with_empty_device_name(self): # Create an L2Gateway seg_id = [""55""] gw_name = data_utils.rand_name('l2gw') dev_name = """" interface_name = data_utils.rand_name('interface') device = [{""device_name"": dev_name, ""interfaces"": [{""name"": interface_name, ""segmentation_id"": seg_id}]}] self.assertRaises(lib_exc.BadRequest, self.admin_client.create_l2_gateway, name=gw_name, devices=device ) @test.attr(type=['negative', 'smoke']) def test_create_l2gw_connection_with_invalid_segmentation_id(self): # Create an L2Gateway gw_name = data_utils.rand_name('l2gw') dev_name = data_utils.rand_name('device_name') interface_name = data_utils.rand_name('interface') devices = [{""device_name"": dev_name, ""interfaces"": [{""name"": interface_name}]}] body = self.admin_client.create_l2_gateway( name=gw_name, devices=devices) l2_gateway = body['l2_gateway'] l2_gw_id = l2_gateway['id'] self.addCleanup(self.admin_client.delete_l2_gateway, l2_gw_id) # Create a network name = data_utils.rand_name('network') net_body = self.admin_client.create_network(name=name) net_id = net_body['network']['id'] self.addCleanup(self.admin_client.delete_network, net_id) for i in ['-1', '0', '4095', '4096']: seg_id = [i] self.assertRaises(lib_exc.BadRequest, self.admin_client.create_l2_gateway_connection, l2_gateway_id=l2_gw_id, network_id=net_id, segmentation_id=seg_id) @test.attr(type=['negative', 'smoke']) def test_create_l2gw_with_invalid_segmentation_id(self): # Create an L2Gateway gw_name = data_utils.rand_name('l2gw') dev_name = data_utils.rand_name('device_name') interface_name = data_utils.rand_name('interface') for i in ['-1', '0', '4095', '4096']: seg_id = [i] device = [{""device_name"": dev_name, ""interfaces"": [{""name"": interface_name, ""segmentation_id"": seg_id}]}] self.assertRaises(lib_exc.BadRequest, self.admin_client.create_l2_gateway, name=gw_name, devices=device ) @test.attr(type=['negative', 'smoke']) def test_create_l2gw_with_empty_interface_name(self): # Create an L2Gateway seg_id = [""55""] gw_name = data_utils.rand_name('l2gw') dev_name = data_utils.rand_name('device') interface_name = """" device = [{""device_name"": dev_name, ""interfaces"": [{""name"": interface_name, ""segmentation_id"": seg_id}]}] self.assertRaises(lib_exc.BadRequest, self.admin_client.create_l2_gateway, name=gw_name, devices=device ) @test.attr(type=['negative', 'smoke']) def test_delete_non_existent_l2gateway(self): non_exist_id = data_utils.rand_name('l2gw') self.assertRaises(lib_exc.NotFound, self.admin_client.delete_l2_gateway, non_exist_id) @test.attr(type=['negative', 'smoke']) def test_delete_non_existent_l2gateway_connection(self): non_exist_id = data_utils.rand_name('l2gwConnection') self.assertRaises(lib_exc.NotFound, self.admin_client.delete_l2_gateway_connection, non_exist_id) @test.attr(type=['negative', 'smoke']) def test_create_l2gw_connection_with_invalid_network_name(self): # Create an L2Gateway gw_name = data_utils.rand_name('l2gw') devices = base_l2gw.get_l2gw_body(CONF.network.l2gw_switch)[""devices""] body = self.admin_client.create_l2_gateway( name=gw_name, devices=devices) l2_gateway = body['l2_gateway'] l2_gw_id = l2_gateway['id'] self.addCleanup(self.admin_client.delete_l2_gateway, l2_gw_id) # Create a network net_id = ""network"" self.assertRaises(lib_exc.NotFound, self.admin_client.create_l2_gateway_connection, l2_gateway_id=l2_gw_id, network_id=net_id ) @test.attr(type=['negative', 'smoke']) def test_update_gateway_with_invalid_device_name(self): # Create an L2Gateway gw_name = data_utils.rand_name('l2gw') devices = base_l2gw.get_l2gw_body(CONF.network.l2gw_switch)[""devices""] body = self.admin_client.create_l2_gateway( name=gw_name, devices=devices) l2_gateway = body['l2_gateway'] self.addCleanup(self.admin_client.delete_l2_gateway, l2_gateway['id']) device_1 = [{""device_name"": """"}] # Create a connection again for same L2Gateway and Network self.assertRaises(lib_exc.BadRequest, self.admin_client.update_l2_gateway, gw_name, devices=device_1 ) @test.attr(type=['negative', 'smoke']) def test_create_l2gw_and_l2gw_connection_both_without_seg_id(self): # Create an L2Gateway gw_name = data_utils.rand_name('l2gw') devices = base_l2gw.get_l2gw_body(CONF.network.l2gw_switch)[""devices""] if devices[0]['interfaces'][0]['segmentation_id']: devices[0]['interfaces'][0].pop('segmentation_id') body = self.admin_client.create_l2_gateway( name=gw_name, devices=devices) l2_gateway = body['l2_gateway'] l2_gw_id = l2_gateway['id'] self.addCleanup(self.admin_client.delete_l2_gateway, l2_gw_id) # Create a network name = data_utils.rand_name('network') net_body = self.admin_client.create_network(name=name) net_id = net_body['network']['id'] self.addCleanup(self.admin_client.delete_network, net_id) self.assertRaises(lib_exc.BadRequest, self.admin_client.create_l2_gateway_connection, l2_gateway_id=l2_gw_id, network_id=net_id )"," @classmethod def _initialize_l2gw_attributes(self, vlan_id): self.interface_name = CONF.network.interface_name self.device_name = CONF.network.device_name self.device = [{""device_name"": self.device_name, ""interfaces"": [{""name"": self.interface_name, ""segmentation_id"": [vlan_id]}]}] return self.device ",141,9
openstack%2Fopenstack-ansible~kilo~I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071,openstack/openstack-ansible,kilo,I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071,Updated kilo for new dev work,MERGED,2015-06-05 22:22:18.000000000,2015-06-10 22:29:30.000000000,2015-06-10 22:29:28.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-05 22:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/95b17c4fb2284ee554121ff3446251029e5a8a04', 'message': 'Updated kilo for new dev work\n\nThis change starts the process for getting Kilo updated for 11.0.3\n\nChange-Id: I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071\n'}, {'number': 2, 'created': '2015-06-05 23:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9ee8362ad77bee58e88c708adc191af9f4bedee7', 'message': 'Updated kilo for new dev work\n\nThis change starts the process for getting Kilo updated for 11.0.3\n\nChange-Id: I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071\n'}, {'number': 3, 'created': '2015-06-10 13:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d4aec5c245d1d909f10d7295ef970ffb990f5ec7', 'message': 'Updated kilo for new dev work\n\nThis change starts the process for getting Kilo updated for 11.0.3\n\nChange-Id: I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071\n'}, {'number': 4, 'created': '2015-06-10 13:38:12.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'scripts/update-revision.sh', '.gitignore', 'scripts/sources-branch-updater.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/all.yml', 'playbooks/defaults/repo_packages/openstack_clients.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c3b7d2907be540e3d2e99b9751629d7a8ba42667', 'message': 'Updated kilo for new dev work\n\nThis change starts the process for getting Kilo updated for 11.0.3\n\nChange-Id: I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071\n'}]",10,188954,c3b7d2907be540e3d2e99b9751629d7a8ba42667,32,6,4,7353,,,0,"Updated kilo for new dev work

This change starts the process for getting Kilo updated for 11.0.3

Change-Id: I06b2ba00ee5c9190b67b5d0df90b7bdd69ebe071
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/54/188954/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'scripts/update-revision.sh', 'scripts/sources-branch-updater.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/inventory/group_vars/all.yml', 'playbooks/defaults/repo_packages/openstack_clients.yml']",6,95b17c4fb2284ee554121ff3446251029e5a8a04,kilo-1103,"barbicanclient_git_install_branch: 60eed382a73982ddcd8d89545c03505699eab164 # HEAD of ""stable/kilo"" as of 05.06.2015ceilometerclient_git_install_branch: a6d7335ddd7e11401fb6ef2fe8b20be0aef33c44 # HEAD of ""stable/kilo"" as of 05.06.2015cinderclient_git_install_branch: a3cf1296da15ddd4dcdc7aa116507db246bddea4 # HEAD of ""stable/kilo"" as of 05.06.2015designateclient_git_install_branch: a036d042f51dd0c7e876d548e5092db20a2ee8be # HEAD of ""stable/kilo"" as of 05.06.2015glanceclient_git_install_branch: 7771d3b55d36e58cede0bc827433a3046e492143 # HEAD of ""stable/kilo"" as of 05.06.2015heatclient_git_install_branch: 76a8e7217558c4e43d7ff45c50c2b2702a20a454 # HEAD of ""stable/kilo"" as of 05.06.2015ironicclient_git_install_branch: 3b71c4ec7bfc9181d972e7f6e706853ec4588236 # HEAD of ""stable/kilo"" as of 05.06.2015keystoneclient_git_install_branch: 8fa6b6f0b5e95493342ce71489d04f73db2418b8 # HEAD of ""stable/kilo"" as of 05.06.2015neutronclient_git_install_branch: dc62768c5b6655e12dd9e19e1152807090845528 # HEAD of ""stable/kilo"" as of 05.06.2015novaclient_git_install_branch: 0ae7a08c08f83a71f877d83ec8260c3ee9293195 # HEAD of ""stable/kilo"" as of 05.06.2015openstackclient_git_install_branch: 6972c34b6633df2864f45d6a463f2b7d964b97f5 # HEAD of ""stable/kilo"" as of 05.06.2015saharaclient_git_install_branch: 46e7ce0506a2ed11e45fd6b86949c85c06df3dde # HEAD of ""stable/kilo"" as of 05.06.2015swiftclient_git_install_branch: 98d31d8ead462dfbf91ccf41270514fbc8fe73f2 # HEAD of ""stable/kilo"" as of 05.06.2015troveclient_git_install_branch: ebb87b3125771965afc52851e4028176bad3e151 # HEAD of ""stable/kilo"" as of 05.06.2015zaqarclient_git_install_branch: 6e5df973a5a0e311262041fefd1603ce9705ae7c # HEAD of ""stable/kilo"" as of 05.06.2015","barbicanclient_git_install_branch: 3.0.2ceilometerclient_git_install_branch: 1.0.13cinderclient_git_install_branch: 1.1.1designateclient_git_install_branch: 1.1.1glanceclient_git_install_branch: 0.16.0heatclient_git_install_branch: 76a8e7217558c4e43d7ff45c50c2b2702a20a454 # HEAD of ""stable/kilo"" as of 30.04.2015ironicclient_git_install_branch: 0.4.1keystoneclient_git_install_branch: 1.2.0neutronclient_git_install_branch: 2.3.11novaclient_git_install_branch: 2.22.0openstackclient_git_install_branch: 1.0.2saharaclient_git_install_branch: 0.8.0swiftclient_git_install_branch: 2.3.1troveclient_git_install_branch: 1.0.8zaqarclient_git_install_branch: 0.1.0",31,31
openstack%2Fopenstack-manuals~master~I73f60610450eb08a61b7150685901ca93065b6ec,openstack/openstack-manuals,master,I73f60610450eb08a61b7150685901ca93065b6ec,Add telemetry best practices to the admin guide,MERGED,2015-06-01 21:00:47.000000000,2015-06-10 22:26:06.000000000,2015-06-10 22:26:04.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 9382}, {'_account_id': 9562}, {'_account_id': 10607}, {'_account_id': 10897}, {'_account_id': 11564}, {'_account_id': 14396}, {'_account_id': 14947}, {'_account_id': 14962}, {'_account_id': 16233}]","[{'number': 1, 'created': '2015-06-01 21:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/78b028ba3e8e459e072b6163725844a5f5a56f6a', 'message': 'Add telemetry best practices to the admin guide\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 2, 'created': '2015-06-01 21:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ade5d3e691451b91592625723011d837dacbbdbe', 'message': 'Add telemetry best practices to the admin guide\n\nCloses-Bug: #1460824\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 3, 'created': '2015-06-02 13:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0e4b8b96ec946ff0482c742a6f0e118057f1c7e1', 'message': 'Add telemetry best practices to the admin guide\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 4, 'created': '2015-06-02 22:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5099e1858f0514b0be85148556eabe479e03f907', 'message': 'Add telemetry best practices to the admin guide\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 5, 'created': '2015-06-02 22:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/13261f33a38b33cff06aa6dd022d5befdefe3bf5', 'message': 'Add telemetry best practices to the admin guide\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 6, 'created': '2015-06-03 15:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9942ca9340cbf29f45e7246852d5ae72eb884bbd', 'message': 'Add telemetry best practices to the admin guide\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 7, 'created': '2015-06-03 18:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/76bc20d6cd7fc48350b09e326c4296d6db7bfaf5', 'message': 'Add telemetry best practices to the admin guide\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 8, 'created': '2015-06-04 19:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c7283df89e6d511d47a8cac56a977b9ea929d61e', 'message': 'Add telemetry best practices to the admin guide\n\nCloses-Bug: #1460824\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 9, 'created': '2015-06-08 15:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/987f9595d537131525ae0e97f8797cd04a526837', 'message': 'Add telemetry best practices to the admin guide\n\nCloses-Bug: #1460824\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 10, 'created': '2015-06-08 16:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d02ee6a1a8051a91b0d73fb00fd9dea5843a372f', 'message': 'Add telemetry best practices to the admin guide\n\nCloses-Bug: #1460824\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 11, 'created': '2015-06-08 17:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f0f430a475e2183616594cc88a0d887f10c96a46', 'message': 'Add telemetry best practices to the admin guide\n\nCloses-Bug: #1460824\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}, {'number': 12, 'created': '2015-06-09 17:35:08.000000000', 'files': ['doc/admin-guide-cloud/ch_telemetry.xml', 'doc/admin-guide-cloud/telemetry/section_telemetry-best-practices.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6a26fff4d37ffa0c6398db5e56619a4f9abbd78c', 'message': 'Add telemetry best practices to the admin guide\n\nCloses-Bug: #1460824\n\nChange-Id: I73f60610450eb08a61b7150685901ca93065b6ec\n'}]",124,187339,6a26fff4d37ffa0c6398db5e56619a4f9abbd78c,57,15,12,6924,,,0,"Add telemetry best practices to the admin guide

Closes-Bug: #1460824

Change-Id: I73f60610450eb08a61b7150685901ca93065b6ec
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/187339/12 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/ch_telemetry.xml', 'doc/admin-guide-cloud/telemetry/section_telemetry-best-practices.xml']",2,78b028ba3e8e459e072b6163725844a5f5a56f6a,bug/1460824,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""section_telemetry-best-practices""> <title>Telemetry Best Practices</title> <para> The following are some suggested best practices to follow when deploying and configuring Telemetry service. The best practices are divided into Data collection and storage. </para> <section xml:id=""section_telemetry-data-collection-best-practices""> <title>Data Collection</title> <procedure> <step> <para> The Telemetry module collects a world of data. Not all data is needed. Based on a cloud admins needs the amount of data collected can be tweaked by changing the <filename>pipeline.yaml</filename>. </para> </step> <step> <para> By default, ceilometer polls the service APIs every 10 minutes. This could be a bit excessive if your data doesnt change that often. Consider to tweak polling interval as needed to match your needs. </para> </step> <step> <para> If using Kilo+, we added support to allow jittering to polling. This adds a random delay on how the polling agenets sends requests to service APIs. If you have a lot of polling agents it might be helpful to enable jittering. By default, jittering is disabled. To enable, set <literal>shuffle_time_before_polling_task</literal> in <filename>ceilometer.conf</filename> to an integer greater than 0. </para> </step> <step> <para> Based on the increase in load, add more agents as necessary. The agents are designed to scale horizontally. </para> </step> <step> <para> If using Juno+, Do use the notifier:// publisher rather than rpc:// as there is a certain level of overhead that comes with rpc. </para> </step> <step> <para> In Kilo, we expanded notification event handling (existing stacktach integration code) and said events can be published to an external source(s) or to a database (ElasticSearch for full-text querying, in addition to mongo, sql). </para> </step> </procedure> </section> <section xml:id=""section_telemetry-data-storage-best-practices""> <title>Data Storage</title> <procedure> <step> <para> Avoid open-ended queries, query on a reasonable time range. </para> </step> <step> <para> Install API behind mod_wsgi. mod_wsgi provides a lot more knobs to tweak. For example, tweak WSGIDaemon settings such as threads and processes. </para> </step> <step> <para> No point keeping the data collected for ever. Set a TTL and expire data to minimise database size. </para> </step> <step> <para> Don't use SQL backend prior to Juno. weird relationships between data to cope with v1 and v2 models. </para> </step> <step> <para> Don't Run mongodb on the same node as the controller. Keep it on a separate node for better performance. </para> </step> <step> <para> Use replica-sets in mongodb. Replica sets provide high availability through automatic failover. If your primary node fails, a secondary node will be elected as primary and your cluster will remain functional. </para> </step> </procedure> </section> </section> ",,104,0
openstack%2Fheat~master~I6eeef5fa2b080df610e52620d2b935450d8d49e3,openstack/heat,master,I6eeef5fa2b080df610e52620d2b935450d8d49e3,Move mistral resources in-tree,MERGED,2015-06-04 05:48:03.000000000,2015-06-10 22:23:28.000000000,2015-06-10 22:23:26.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7253}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9751}, {'_account_id': 12321}, {'_account_id': 12363}, {'_account_id': 12606}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2015-06-04 05:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0b5294077093d329fe075b9a73cfa25c9a5b9b01', 'message': 'Move mistral resources in-tree\n\nThis change relocates the mistral resources from the contrib area into the main\nresource tree, to save users from the trouble of installing it as a plugin.\nThese resources are only registered if the mistral client is installed.\n\nChange-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3\n'}, {'number': 2, 'created': '2015-06-06 01:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2b92a25a3bb28030b0f266803ba5659198fe4898', 'message': ""Move mistral resources in-tree\n\nThis change relocates the manila resources from the contrib area into the main\nresource tree. It was originally added to contrib/ because of the project's\nincubation status, and more specifically because the client is not in the\nglobal-requirements.txt file. However, when this was discussed at the summit in\nVancouver, the decision was to move the resources to main tree but skip\nregistration if the client is not installed. This will save users from the\ntrouble of installing it as a plugin.\n\nChange-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3\n""}, {'number': 3, 'created': '2015-06-06 02:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/12e6a6030d8d6330d6aaa0f9c7841cd2521b91fa', 'message': ""Move mistral resources in-tree\n\nThis change relocates the mistral resources from the contrib area into the main\nresource tree. It was originally added to contrib/ because of the project's\nincubation status, and more specifically because the client is not in the\nglobal-requirements.txt file. However, when this was discussed at the summit in\nVancouver, the decision was to move the resources to main tree but skip\nregistration if the client is not installed. This will save users from the\ntrouble of installing it as a plugin.\n\nChange-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3\n""}, {'number': 4, 'created': '2015-06-08 19:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/396ddade07ff2dc1294c0c361d3841a4c3575681', 'message': ""Move mistral resources in-tree\n\nThis change relocates the mistral resources from the contrib area into the main\nresource tree. It was originally added to contrib/ because of the project's\nincubation status, and more specifically because the client is not in the\nglobal-requirements.txt file. However, when this was discussed at the summit in\nVancouver, the decision was to move the resources to main tree but skip\nregistration if the client is not installed. This will save users from the\ntrouble of installing it as a plugin.\n\nChange-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3\n""}, {'number': 5, 'created': '2015-06-09 06:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4898515f6507826161ae2cb53029dc5b2117bc1c', 'message': ""Move mistral resources in-tree\n\nThis change relocates the mistral resources from the contrib area into the main\nresource tree. It was originally added to contrib/ because of the project's\nincubation status, and more specifically because the client is not in the\nglobal-requirements.txt file. However, when this was discussed at the summit in\nVancouver, the decision was to move the resources to main tree but skip\nregistration if the client is not installed. This will save users from the\ntrouble of installing it as a plugin.\n\nChange-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3\n""}, {'number': 6, 'created': '2015-06-09 17:23:17.000000000', 'files': ['heat/engine/resources/openstack/mistral/cron_trigger.py', 'heat/engine/resources/openstack/mistral/workflow.py', 'heat/tests/test_mistral_workflow.py', 'heat/tests/test_mistral_client.py', 'contrib/heat_mistral/README.md', 'contrib/heat_mistral/heat_mistral/resources/__init__.py', 'heat/engine/resources/openstack/mistral/__init__.py', 'contrib/heat_mistral/setup.py', 'heat/engine/clients/os/mistral.py', 'contrib/heat_mistral/setup.cfg', 'contrib/heat_mistral/requirements.txt', 'setup.cfg', 'contrib/heat_mistral/heat_mistral/tests/__init__.py', 'heat/tests/test_mistral_cron_trigger.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c31a9533fa3718c0712cf59530a66f0aeb291958', 'message': ""Move mistral resources in-tree\n\nThis change relocates the mistral resources from the contrib area into the main\nresource tree. It was originally added to contrib/ because of the project's\nincubation status, and more specifically because the client is not in the\nglobal-requirements.txt file. However, when this was discussed at the summit in\nVancouver, the decision was to move the resources to main tree but skip\nregistration if the client is not installed. This will save users from the\ntrouble of installing it as a plugin.\n\nChange-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3\n""}]",3,188262,c31a9533fa3718c0712cf59530a66f0aeb291958,53,12,6,12606,,,0,"Move mistral resources in-tree

This change relocates the mistral resources from the contrib area into the main
resource tree. It was originally added to contrib/ because of the project's
incubation status, and more specifically because the client is not in the
global-requirements.txt file. However, when this was discussed at the summit in
Vancouver, the decision was to move the resources to main tree but skip
registration if the client is not installed. This will save users from the
trouble of installing it as a plugin.

Change-Id: I6eeef5fa2b080df610e52620d2b935450d8d49e3
",git fetch https://review.opendev.org/openstack/heat refs/changes/62/188262/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/mistral/cron_trigger.py', 'heat/engine/resources/openstack/mistral/workflow.py', 'heat/tests/test_mistral_workflow.py', 'contrib/heat_mistral/README.md', 'contrib/heat_mistral/heat_mistral/resources/__init__.py', 'heat/engine/resources/openstack/mistral/__init__.py', 'contrib/heat_mistral/setup.py', 'heat/engine/clients/os/mistral.py', 'contrib/heat_mistral/setup.cfg', 'contrib/heat_mistral/requirements.txt', 'contrib/heat_mistral/heat_mistral/tests/__init__.py', 'heat/tests/test_mistral_cron_trigger.py']",12,0b5294077093d329fe075b9a73cfa25c9a5b9b01,contrib-move-mistral,"import testtools from heat.common import exceptionfrom heat.engine import clients from heat.engine.resources.openstack.mistral import cron_triggerfrom heat.engine import stack as stack_parser from heat.engine import templateclass MistralCronTriggerTest(common.HeatTestCase): super(MistralCronTriggerTest, self).setUp() @testtools.skipIf(clients.has_client('mistral'), 'Tests mistral client not installed') def test_no_client(self): tmpl = template.Template((template_format.parse(stack_template))) stack = stack_parser.Stack(utils.dummy_context(), 'foo', tmpl) self.assertRaises(exception.ResourceTypeNotFound, stack.validate)","from ..resources import cron_trigger # noqa class CronTriggerTest(common.HeatTestCase): super(CronTriggerTest, self).setUp()",59,96
openstack%2Fapp-catalog~master~Iaf0b91f33ee7eaab0e93a8cd526e63b1d2a698a7,openstack/app-catalog,master,Iaf0b91f33ee7eaab0e93a8cd526e63b1d2a698a7,Split direct and indirect glance image url's,MERGED,2015-06-10 22:07:39.000000000,2015-06-10 22:19:44.000000000,2015-06-10 22:19:44.000000000,"[{'_account_id': 3}, {'_account_id': 9788}]","[{'number': 1, 'created': '2015-06-10 22:07:39.000000000', 'files': ['openstack_catalog/web/static/glance_images.yaml', 'openstack_catalog/web/index.html'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/096212acfb8184d0406719dfd61b5fec13f9f8b8', 'message': ""Split direct and indirect glance image url's\n\nSplit out direct and indirect url's so that direct url's can show the cli and\nindirect url's take the user to the webiste where they can be downloaded.\n\nChange-Id: Iaf0b91f33ee7eaab0e93a8cd526e63b1d2a698a7\n""}]",0,190374,096212acfb8184d0406719dfd61b5fec13f9f8b8,6,2,1,9237,,,0,"Split direct and indirect glance image url's

Split out direct and indirect url's so that direct url's can show the cli and
indirect url's take the user to the webiste where they can be downloaded.

Change-Id: Iaf0b91f33ee7eaab0e93a8cd526e63b1d2a698a7
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/74/190374/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_catalog/web/static/glance_images.yaml', 'openstack_catalog/web/index.html']",2,096212acfb8184d0406719dfd61b5fec13f9f8b8,indirect_url," {{if attributes['url']}} {{else}} <span class=""label"">Website where the image can be downloaded:</span> <a href=""${attributes['indirect_url']}"">Link...</a> {{/if}}",,6,1
openstack%2Frally~master~Icc531992f16638afd93a88134a89d941bf209a05,openstack/rally,master,Icc531992f16638afd93a88134a89d941bf209a05,utils: make parse_docstring respect multi-line,ABANDONED,2015-06-10 17:25:31.000000000,2015-06-10 22:18:45.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 8851}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-10 17:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1aeebc5af34d1e616fc43e698c1f3ffad95e1591', 'message': 'utils: make parse_docstring respect multi-line\n\nChange-Id: Icc531992f16638afd93a88134a89d941bf209a05\n'}, {'number': 2, 'created': '2015-06-10 17:48:31.000000000', 'files': ['tests/unit/common/test_utils.py', 'rally/common/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/263dad313c4de6f3d1c6973e8a46686da0b1b11a', 'message': 'utils: make parse_docstring respect multi-line\n\nChange-Id: Icc531992f16638afd93a88134a89d941bf209a05\n'}]",2,190270,263dad313c4de6f3d1c6973e8a46686da0b1b11a,7,6,2,13609,,,0,"utils: make parse_docstring respect multi-line

Change-Id: Icc531992f16638afd93a88134a89d941bf209a05
",git fetch https://review.opendev.org/openstack/rally refs/changes/70/190270/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/common/test_utils.py', 'rally/common/utils.py']",2,1aeebc5af34d1e616fc43e698c1f3ffad95e1591,bp/vm-workloads-framework,"import textwrap docstring = format_docstring(docstring) lines = docstring.split(""\n"", 1) long_description = docstring = lines[1].strip() param_or_returns_re = re.compile("":(?:param|returns)"") match = param_or_returns_re.search(docstring) if match: long_description_end = match.start() long_description = docstring[:long_description_end].rstrip() docstring = docstring[long_description_end:].lstrip() def reindent(string, indent=""\t""): if ""\n"" not in string: return string first, rest = string.split(""\n"", 1) return ""\n"".join( [first, textwrap.dedent(rest)]).replace( ""\n"", ""\n"" + indent).rstrip() param_regex = re.compile( "":param (?P<name>[\*\w]+): (?P<doc>.*?)"" ""(?:(?=:param)|(?=:return)|\Z)"", re.S) params = [ { ""name"": name, ""doc"": reindent(doc) } for name, doc in param_regex.findall(docstring) ] returns_regex = re.compile("":returns: (?P<doc>.*)"", re.S) match = returns_regex.search(docstring) if match: returns = reindent(match.group(""doc""))"," lines = docstrings.prepare_docstring(docstring) lines = [line for line in lines if line] else: lines = [] if lines: param_start = first_index(lines, lambda l: l.startswith("":param"")) returns_start = first_index(lines, lambda l: l.startswith("":returns"")) if param_start or returns_start: description_end = param_start or returns_start long_description = ""\n"".join(lines[1:description_end]) else: long_description = ""\n"".join(lines[1:]) param_lines = [] if param_start: current_line = lines[param_start] current_line_index = param_start + 1 while current_line_index < (returns_start or len(lines)): if lines[current_line_index].startswith("":param""): param_lines.append(current_line) current_line = lines[current_line_index] else: continuation_line = lines[current_line_index].strip() current_line += "" "" + continuation_line current_line_index += 1 param_lines.append(current_line) params = [] param_regex = re.compile(""^:param (?P<name>\w+): (?P<doc>.*)$"") for param_line in param_lines: match = param_regex.match(param_line) if match: params.append({ ""name"": match.group(""name""), ""doc"": match.group(""doc"") }) if returns_start: returns_line = "" "".join([l.strip() for l in lines[returns_start:]]) returns_regex = re.compile(""^:returns: (?P<doc>.*)$"") match = returns_regex.match(returns_line) if match: returns = match.group(""doc"")",38,46
openstack%2Fgovernance~master~I65f388892ef0bf2fd1f85fd5ed898717577d052d,openstack/governance,master,I65f388892ef0bf2fd1f85fd5ed898717577d052d,Update projects with correct repos,ABANDONED,2015-06-09 01:16:12.000000000,2015-06-10 22:02:12.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-06-09 01:16:12.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/57c479e717995d135bd86ea5b27a1aa5db5878cb', 'message': ""Update projects with correct repos\n\nSome projects were being listed as being in the 'openstack/' namespace\nwhen they are actually in the 'stackforge/' namespace.\n\nThis causes problems for programs parsing this data as the projects do\nnot actually exist at the stated location.\n\nChange-Id: I65f388892ef0bf2fd1f85fd5ed898717577d052d\n""}]",4,189521,57c479e717995d135bd86ea5b27a1aa5db5878cb,10,4,1,14760,,,0,"Update projects with correct repos

Some projects were being listed as being in the 'openstack/' namespace
when they are actually in the 'stackforge/' namespace.

This causes problems for programs parsing this data as the projects do
not actually exist at the stated location.

Change-Id: I65f388892ef0bf2fd1f85fd5ed898717577d052d
",git fetch https://review.opendev.org/openstack/governance refs/changes/21/189521/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,57c479e717995d135bd86ea5b27a1aa5db5878cb,, - repo: stackforge/mistral - repo: stackforge/mistral-dashboard - repo: stackforge/mistral-extra - repo: stackforge/python-mistralclient - repo: stackforge/magnetodb - repo: stackforge/python-magnetodbclient - repo: stackforge/magnetodb-specs - repo: stackforge/puppet-ceilometer - repo: stackforge/puppet-cinder - repo: stackforge/puppet-designate - repo: stackforge/puppet-glance - repo: stackforge/puppet-gnocchi - repo: stackforge/puppet-heat - repo: stackforge/puppet-horizon - repo: stackforge/puppet-ironic - repo: stackforge/puppet-keystone - repo: stackforge/puppet-manila - repo: stackforge/puppet-neutron - repo: stackforge/puppet-nova - repo: stackforge/puppet-openstacklib - repo: stackforge/puppet-openstack-specs - repo: stackforge/puppet-openstack_extras - repo: stackforge/puppet-sahara - repo: stackforge/puppet-swift - repo: stackforge/puppet-tempest - repo: stackforge/puppet-tripleo - repo: stackforge/puppet-trove - repo: stackforge/puppet-tuskar - repo: stackforge/puppet-vswitch - repo: stackforge/cookbook-openstack-bare-metal - repo: stackforge/cookbook-openstack-block-storage - repo: stackforge/cookbook-openstack-client - repo: stackforge/cookbook-openstack-common - repo: stackforge/cookbook-openstack-compute - repo: stackforge/cookbook-openstack-dashboard - repo: stackforge/cookbook-openstack-data-processing - repo: stackforge/cookbook-openstack-image - repo: stackforge/cookbook-openstack-integration-test - repo: stackforge/cookbook-openstack-network - repo: stackforge/cookbook-openstack-object-storage - repo: stackforge/cookbook-openstack-ops-messaging - repo: stackforge/cookbook-openstack-ops-database - repo: stackforge/cookbook-openstack-orchestration - repo: stackforge/cookbook-openstack-telemetry - repo: stackforge/openstack-chef-repo, - repo: openstack/mistral - repo: openstack/mistral-dashboard - repo: openstack/mistral-extra - repo: openstack/python-mistralclient - repo: openstack/magnetodb - repo: openstack/python-magnetodbclient - repo: openstack/magnetodb-specs - repo: openstack/puppet-ceilometer - repo: openstack/puppet-cinder - repo: openstack/puppet-designate - repo: openstack/puppet-glance - repo: openstack/puppet-gnocchi - repo: openstack/puppet-heat - repo: openstack/puppet-horizon - repo: openstack/puppet-ironic - repo: openstack/puppet-keystone - repo: openstack/puppet-manila - repo: openstack/puppet-neutron - repo: openstack/puppet-nova - repo: openstack/puppet-openstacklib - repo: openstack/puppet-openstack-specs - repo: openstack/puppet-openstack_extras - repo: openstack/puppet-sahara - repo: openstack/puppet-swift - repo: openstack/puppet-tempest - repo: openstack/puppet-tripleo - repo: openstack/puppet-trove - repo: openstack/puppet-tuskar - repo: openstack/puppet-vswitch - repo: openstack/cookbook-openstack-bare-metal - repo: openstack/cookbook-openstack-block-storage - repo: openstack/cookbook-openstack-client - repo: openstack/cookbook-openstack-common - repo: openstack/cookbook-openstack-compute - repo: openstack/cookbook-openstack-dashboard - repo: openstack/cookbook-openstack-data-processing - repo: openstack/cookbook-openstack-image - repo: openstack/cookbook-openstack-integration-test - repo: openstack/cookbook-openstack-network - repo: openstack/cookbook-openstack-object-storage - repo: openstack/cookbook-openstack-ops-messaging - repo: openstack/cookbook-openstack-ops-database - repo: openstack/cookbook-openstack-orchestration - repo: openstack/cookbook-openstack-telemetry - repo: openstack/openstack-chef-repo,45,45
openstack%2Fapp-catalog~master~Ib54a09a9b4f7a245c8654efebcdaa83705f1359c,openstack/app-catalog,master,Ib54a09a9b4f7a245c8654efebcdaa83705f1359c,Glance Format Switchover,MERGED,2015-06-10 21:17:03.000000000,2015-06-10 21:40:07.000000000,2015-06-10 21:40:06.000000000,"[{'_account_id': 3}, {'_account_id': 9788}]","[{'number': 1, 'created': '2015-06-10 21:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/6eca393b98fe33fc0594c2b20b3f1602e161df6d', 'message': 'Glance Format Switchover\n\nSwitch format over to disk_format and container_format in glance images.\nUpdate the website to support the new format. Also add license info in\nsince it was all in the same place.\n\nChange-Id: Ib54a09a9b4f7a245c8654efebcdaa83705f1359c\n'}, {'number': 2, 'created': '2015-06-10 21:21:29.000000000', 'files': ['openstack_catalog/web/static/glance_images.schema.yaml', 'openstack_catalog/web/static/glance_images.yaml', 'openstack_catalog/web/index.html', 'openstack_catalog/web/static/js/apps-catalog.js'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/4bc5102ea94669d572fba7ae839d5c7a4358bffc', 'message': 'Glance Format Switchover\n\nSwitch format over to disk_format and container_format in glance images.\nUpdate the website to support the new format. Also add license info in\nsince it was all in the same place.\n\nChange-Id: Ib54a09a9b4f7a245c8654efebcdaa83705f1359c\n'}]",0,190352,4bc5102ea94669d572fba7ae839d5c7a4358bffc,8,2,2,9237,,,0,"Glance Format Switchover

Switch format over to disk_format and container_format in glance images.
Update the website to support the new format. Also add license info in
since it was all in the same place.

Change-Id: Ib54a09a9b4f7a245c8654efebcdaa83705f1359c
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/52/190352/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_catalog/web/static/glance_images.schema.yaml', 'openstack_catalog/web/static/glance_images.yaml', 'openstack_catalog/web/index.html', 'openstack_catalog/web/static/js/apps-catalog.js']",4,6eca393b98fe33fc0594c2b20b3f1602e161df6d,propchange," [""name_html"", ""description"", ""disk_format"", ""license""],"," [""name_html"", ""description"", ""format""],",84,37
openstack%2Frequirements~master~I332c12a60705770cd819f4ef3ef73bc24a209fa1,openstack/requirements,master,I332c12a60705770cd819f4ef3ef73bc24a209fa1,Bump python-glanceclient,MERGED,2015-06-08 21:39:37.000000000,2015-06-10 21:18:51.000000000,2015-06-10 21:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-08 21:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/dd5c8f68ce0e8c711bd9f1869f45e649a9a1baed', 'message': 'Bump python-glacneclient\n\nThe current minimum python-glanceclient still has the old pbr\nversion requirements, need to bump it up to use pbr>=0.11,<2.0.\n\nChange-Id: I332c12a60705770cd819f4ef3ef73bc24a209fa1\n'}, {'number': 2, 'created': '2015-06-09 20:04:33.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/66b19d2a405c14c60e80385b3830cc6dcf97a979', 'message': 'Bump python-glanceclient\n\nThe current minimum python-glanceclient still has the old pbr\nversion requirements, need to bump it up to use pbr>=0.11,<2.0.\n\nChange-Id: I332c12a60705770cd819f4ef3ef73bc24a209fa1\n'}]",1,189479,66b19d2a405c14c60e80385b3830cc6dcf97a979,15,5,2,970,,,0,"Bump python-glanceclient

The current minimum python-glanceclient still has the old pbr
version requirements, need to bump it up to use pbr>=0.11,<2.0.

Change-Id: I332c12a60705770cd819f4ef3ef73bc24a209fa1
",git fetch https://review.opendev.org/openstack/requirements refs/changes/79/189479/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,dd5c8f68ce0e8c711bd9f1869f45e649a9a1baed,,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,1,1
openstack%2Fkeystone~master~I4bd7ef633070159b81c5e5d6d75275d63f976d28,openstack/keystone,master,I4bd7ef633070159b81c5e5d6d75275d63f976d28,Use lower default value for sha512_crypt rounds,MERGED,2015-03-18 05:01:29.000000000,2015-06-10 20:58:34.000000000,2015-06-10 20:58:32.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5803}, {'_account_id': 6486}, {'_account_id': 7118}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-03-18 05:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d180be9a78c51ea396fecfa82ab47a1f6f5c8734', 'message': ""Use default value for sha512_crypt rounds\n\nChange Ia7c359df0d2f846a16b9fb98937f2995e9791010 rasied the issue of\nhashes taking too long.  Upon investigation the default hasn't changed\nsince the original commit Idd5d09dc114cbb0cbd63e23e4178bb74d081c789\nwhich doesn't give rationale for the rounds chosen.\n\npasslib says the default is\n\n Passlib’s default_rounds values are retuned periodically, starting\n with a rough estimate of what an “average” system is capable of, and\n then setting all hash.default_rounds values to take ~300ms on such a\n system. [1]\n\nSo one proposal, as here, is to use the default value by passlib as\nthe default.  But as you can see from the regenerated sample config\nthis is actually 1000000, greater than the existing value.  Both\nvalues are way over the glibc default of 5000 [2].\n\nInterested in ideas if we should change this; change devstack defaults\nor just leave everything alone.\n\n[1] https://pythonhosted.org/passlib/password_hash_api.html#avgsys\n[2] https://sourceware.org/git/?p=glibc.git;a=blob;f=crypt/sha512-crypt.c;h=9c581abb00eb93ba6b0571c08e01fc65f1b1cd05;hb=HEAD#l87\n\nChange-Id: I4bd7ef633070159b81c5e5d6d75275d63f976d28\n""}, {'number': 2, 'created': '2015-03-18 05:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e1cb0a00db7bbd988f4aaf02b84afb2d1b8c95eb', 'message': ""Use default value for sha512_crypt rounds\n\nChange Ia7c359df0d2f846a16b9fb98937f2995e9791010 rasied the issue of\nhashes taking too long.  Upon investigation the default hasn't changed\nsince the original commit Idd5d09dc114cbb0cbd63e23e4178bb74d081c789\nwhich doesn't give rationale for the rounds chosen.\n\npasslib says the default is\n\n Passlib’s default_rounds values are retuned periodically, starting\n with a rough estimate of what an “average” system is capable of, and\n then setting all hash.default_rounds values to take ~300ms on such a\n system. [1]\n\nSo one proposal, as here, is to use the default value by passlib as\nthe default.  But this is actually 1000000, greater than the existing\nvalue.  Both values are way over the glibc default of 5000 [2].\n\nInterested in ideas if we should change this; change devstack defaults\nor just leave everything alone.\n\n[1] https://pythonhosted.org/passlib/password_hash_api.html#avgsys\n[2] https://sourceware.org/git/?p=glibc.git;a=blob;f=crypt/sha512-crypt.c;h=9c581abb00eb93ba6b0571c08e01fc65f1b1cd05;hb=HEAD#l87\n\nChange-Id: I4bd7ef633070159b81c5e5d6d75275d63f976d28\n""}, {'number': 3, 'created': '2015-03-19 23:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f20edc1e7a62438d982067a8629dfcfc3d7b2491', 'message': ""Use lower default value for sha512_crypt rounds\n\nChange Ia7c359df0d2f846a16b9fb98937f2995e9791010 rasied the issue of\nhashes taking too long.  Upon investigation the default hasn't changed\nsince the original commit Idd5d09dc114cbb0cbd63e23e4178bb74d081c789\n\npasslib's default comes with the rationale:\n\n Passlib’s default_rounds values are retuned periodically, starting\n with a rough estimate of what an “average” system is capable of, and\n then setting all hash.default_rounds values to take ~300ms on such a\n system. [1]\n\nPresumably at the time of creation passlib defined the default as\n40000 and that was copied here.  It is now 100000, and grows to keep\ntheir 300ms target.\n\nBoth values exceed the glibc default of 5000 [2] which seems sensible\nto use here.\n\n[1] https://pythonhosted.org/passlib/password_hash_api.html#avgsys\n[2] https://sourceware.org/git/?p=glibc.git;a=blob;f=crypt/sha512-crypt.c;h=9c581abb00eb93ba6b0571c08e01fc65f1b1cd05;hb=HEAD#l87\n\nChange-Id: I4bd7ef633070159b81c5e5d6d75275d63f976d28\n""}, {'number': 4, 'created': '2015-06-01 18:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7818af5a7121701f3696baa15d36d8c371733e62', 'message': ""Use lower default value for sha512_crypt rounds\n\nChange Ia7c359df0d2f846a16b9fb98937f2995e9791010 rasied the issue of\nhashes taking too long.  Upon investigation the default hasn't changed\nsince the original commit Idd5d09dc114cbb0cbd63e23e4178bb74d081c789\n\npasslib's default comes with the rationale:\n\n Passlib’s default_rounds values are retuned periodically, starting\n with a rough estimate of what an “average” system is capable of, and\n then setting all hash.default_rounds values to take ~300ms on such a\n system. [1]\n\nPresumably at the time of creation passlib defined the default as\n40000 and that was copied here.  It is now 100000, and grows to keep\ntheir 300ms target.\n\nBoth values exceed the glibc default of 5000 [2]. Based upon benchmarks\nthe reduction from 40000 to 10000 resulted in a net savings of ~30%. The\n10000 round mark still exceeds the glibc default.\n\n[1] https://pythonhosted.org/passlib/password_hash_api.html#avgsys\n[2] https://sourceware.org/git/?p=glibc.git;a=blob;f=crypt/sha512-crypt.c;h=9c581abb00eb93ba6b0571c08e01fc65f1b1cd05;hb=HEAD#l87\n\nChange-Id: I4bd7ef633070159b81c5e5d6d75275d63f976d28\n""}, {'number': 5, 'created': '2015-06-09 19:26:45.000000000', 'files': ['keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/67e0ba5ee2108731050e26f7b4dd6c8d3dab118d', 'message': ""Use lower default value for sha512_crypt rounds\n\nChange Ia7c359df0d2f846a16b9fb98937f2995e9791010 rasied the issue of\nhashes taking too long.  Upon investigation the default hasn't changed\nsince the original commit Idd5d09dc114cbb0cbd63e23e4178bb74d081c789\n\npasslib's default comes with the rationale:\n\n Passlib’s default_rounds values are retuned periodically, starting\n with a rough estimate of what an “average” system is capable of, and\n then setting all hash.default_rounds values to take ~300ms on such a\n system. [1]\n\nPresumably at the time of creation passlib defined the default as\n40000 and that was copied here.  It is now 100000, and grows to keep\ntheir 300ms target.\n\nBoth values exceed the glibc default of 5000 [2]. Based upon benchmarks\nthe reduction from 40000 to 10000 resulted in a net savings of ~30%. The\n10000 round mark still exceeds the glibc default.\n\n[1] https://pythonhosted.org/passlib/password_hash_api.html#avgsys\n[2] https://sourceware.org/git/?p=glibc.git;a=blob;f=crypt/sha512-crypt.c;h=9c581abb00eb93ba6b0571c08e01fc65f1b1cd05;hb=HEAD#l87\n\nChange-Id: I4bd7ef633070159b81c5e5d6d75275d63f976d28\n""}]",12,165295,67e0ba5ee2108731050e26f7b4dd6c8d3dab118d,48,11,5,7118,,,0,"Use lower default value for sha512_crypt rounds

Change Ia7c359df0d2f846a16b9fb98937f2995e9791010 rasied the issue of
hashes taking too long.  Upon investigation the default hasn't changed
since the original commit Idd5d09dc114cbb0cbd63e23e4178bb74d081c789

passlib's default comes with the rationale:

 Passlib’s default_rounds values are retuned periodically, starting
 with a rough estimate of what an “average” system is capable of, and
 then setting all hash.default_rounds values to take ~300ms on such a
 system. [1]

Presumably at the time of creation passlib defined the default as
40000 and that was copied here.  It is now 100000, and grows to keep
their 300ms target.

Both values exceed the glibc default of 5000 [2]. Based upon benchmarks
the reduction from 40000 to 10000 resulted in a net savings of ~30%. The
10000 round mark still exceeds the glibc default.

[1] https://pythonhosted.org/passlib/password_hash_api.html#avgsys
[2] https://sourceware.org/git/?p=glibc.git;a=blob;f=crypt/sha512-crypt.c;h=9c581abb00eb93ba6b0571c08e01fc65f1b1cd05;hb=HEAD#l87

Change-Id: I4bd7ef633070159b81c5e5d6d75275d63f976d28
",git fetch https://review.opendev.org/openstack/keystone refs/changes/95/165295/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py']",2,d180be9a78c51ea396fecfa82ab47a1f6f5c8734,crypt-rounds,"import passlib.hash cfg.IntOpt('crypt_strength', default=passlib.hash.sha512_crypt.default_rounds,"," cfg.IntOpt('crypt_strength', default=40000,",50,27
openstack%2Fneutron~master~I20b132a0181d35b0517330fb7fbf293c3e979d0e,openstack/neutron,master,I20b132a0181d35b0517330fb7fbf293c3e979d0e,"Revert ""Defer segment lookup in NetworkContext object""",MERGED,2015-06-10 07:04:25.000000000,2015-06-10 20:58:27.000000000,2015-06-10 09:08:40.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-10 07:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a73c9d35173a28713a3f70b758de5a801d6dcbdf', 'message': 'Revert ""Defer segment lookup in NetworkContext object""\n\nThis reverts commit e61865807c4c8ff959a7746fe3e17f1ae574c9d0.\n\nThis patch likely violated the idea of a NetworkContext being a snapshot of the network at the time it was created. This needs a different approach.\n\nChange-Id: I20b132a0181d35b0517330fb7fbf293c3e979d0e\n'}, {'number': 2, 'created': '2015-06-10 07:04:38.000000000', 'files': ['neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/plugins/ml2/test_driver_context.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/328b72cf8c5f514434de0b73c9137bde52b5eeea', 'message': 'Revert ""Defer segment lookup in NetworkContext object""\n\nThis reverts commit e61865807c4c8ff959a7746fe3e17f1ae574c9d0.\n\nThis patch likely violated the idea of a NetworkContext\nbeing a snapshot of the network at the time it was created.\nThis needs a different approach.\n\nChange-Id: I20b132a0181d35b0517330fb7fbf293c3e979d0e\n'}]",1,190046,328b72cf8c5f514434de0b73c9137bde52b5eeea,34,22,2,7787,,,0,"Revert ""Defer segment lookup in NetworkContext object""

This reverts commit e61865807c4c8ff959a7746fe3e17f1ae574c9d0.

This patch likely violated the idea of a NetworkContext
being a snapshot of the network at the time it was created.
This needs a different approach.

Change-Id: I20b132a0181d35b0517330fb7fbf293c3e979d0e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/190046/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/plugins/ml2/test_driver_context.py']",2,a73c9d35173a28713a3f70b758de5a801d6dcbdf,bug/1463254," with mock.patch.object(driver_context.db, 'get_network_segments'): ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) with mock.patch.object(driver_context.db, 'get_network_segments'): ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) with mock.patch.object(driver_context.db, 'get_network_segments'): ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) with mock.patch.object(driver_context.db, 'get_network_segments'): self.assertEqual('status', ctx.status)"," ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) ctx = driver_context.PortContext(plugin, plugin_context, port, network, binding, None) self.assertEqual('status', ctx.status) def test_segments_lazy_lookup(self): plugin = mock.Mock() plugin_context = mock.Mock() network = mock.MagicMock() binding = mock.Mock() port = {'device_owner': 'compute', 'status': 'status'} binding.status = 'foostatus' with mock.patch.object(driver_context.db, 'get_network_segments') as gs: self.assertFalse(gs.called) # accessing the network_segments property should trigger # a lookup the first time seg = ctx.network.network_segments self.assertTrue(gs.called) gs.reset_mock() self.assertEqual(seg, ctx.network.network_segments) self.assertFalse(gs.called)",25,51
openstack%2Fbarbican~master~Iec1c9fe52f03e0668d5fafdccd593b77b2bc8290,openstack/barbican,master,Iec1c9fe52f03e0668d5fafdccd593b77b2bc8290,Fixed Inconsistent Request Id in Log Messages,MERGED,2015-06-10 19:28:20.000000000,2015-06-10 20:51:55.000000000,2015-06-10 20:51:52.000000000,"[{'_account_id': 3}, {'_account_id': 7262}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-06-10 19:28:20.000000000', 'files': ['barbican/tests/api/middleware/test_context.py', 'barbican/api/middleware/context.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/9bf2d464d6ed49d78c89d21fe1684f6c7bac882e', 'message': 'Fixed Inconsistent Request Id in Log Messages\n\nTwo different request Ids were showing up in log messages.\nNow there is one consistent request Id that is also the one reflected in error messages.\n\nChange-Id: Iec1c9fe52f03e0668d5fafdccd593b77b2bc8290\nCloses-Bug: 1462069\n'}]",0,190310,9bf2d464d6ed49d78c89d21fe1684f6c7bac882e,10,4,1,11661,,,0,"Fixed Inconsistent Request Id in Log Messages

Two different request Ids were showing up in log messages.
Now there is one consistent request Id that is also the one reflected in error messages.

Change-Id: Iec1c9fe52f03e0668d5fafdccd593b77b2bc8290
Closes-Bug: 1462069
",git fetch https://review.opendev.org/openstack/barbican refs/changes/10/190310/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/api/middleware/test_context.py', 'barbican/api/middleware/context.py']",2,9bf2d464d6ed49d78c89d21fe1684f6c7bac882e,bug/1462069," def process_request(self, req): request_id = req.headers.get('x-openstack-request-id') setattr(req, 'request_id', request_id) def process_response(self, resp): resp.headers['x-openstack-request-id'] = resp.request.request_id LOG.info('%s: %s - %s %s', u._LI('Processed request'), super(ContextMiddleware, self).process_request(req) 'request_id': req.request_id super(UnauthenticatedContextMiddleware, self).process_request(req) 'is_admin': config_admin_role in roles, 'request_id': req.request_id"," def process_response(self, resp): request_id = resp.request.headers.get('x-openstack-request-id') resp.headers['x-openstack-request-id'] = request_id LOG.info('%s | %s: %s - %s %s', request_id, u._LI('Processed request'), 'is_admin': config_admin_role in roles",18,7
openstack%2Fneutron~master~I75b00946b7cae891c6eb192e853118e7d49e4a24,openstack/neutron,master,I75b00946b7cae891c6eb192e853118e7d49e4a24,Handle SIGHUP: neutron-server (multiprocess) and metadata agent,MERGED,2015-03-05 14:33:15.000000000,2015-06-10 20:25:19.000000000,2015-06-10 20:25:16.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 2035}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14956}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-03-05 14:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69cc7d7b5179f538f2fc23e88648807a09b4d16c', 'message': '[WIP]: Add reset methods to WsgiWorker and RPCWorker\n\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 2, 'created': '2015-03-05 17:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6bbc00b112201544caedda1290d8445bb213c5d', 'message': '[WIP]: Add reset methods to WsgiWorker and RPCWorker\n\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 3, 'created': '2015-03-12 14:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0309f5da8654245f5d79402c41fb458f66f5e42', 'message': '[WIP]: Add reset methods to WsgiWorker and RPCWorker\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 4, 'created': '2015-03-16 15:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b8507f75161b3e655fc1d945bd61f710af5c527', 'message': '[WIP]: Add reset methods to WsgiWorker and RPCWorker\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 5, 'created': '2015-04-01 15:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b58277f38eb50b9fa0b64d7b1da524a3899ab0ac', 'message': '[WIP]: Add reset methods to WsgiWorker and RPCWorker\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 6, 'created': '2015-04-03 10:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44f00807e221c116e9adcf9f620c867c2b9a7af6', 'message': '[WIP]: Add handling of SIGHUP\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 7, 'created': '2015-04-03 12:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2ac4860182bfc3725ed1b2ff6fca1981dfd9634', 'message': '[WIP]: Add handling of SIGHUP\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 8, 'created': '2015-04-06 16:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/df99d4f10c1696647e6bd2b871c9dc337a7733fb', 'message': '[WIP]: Add handling of SIGHUP - multiprocess mode\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 9, 'created': '2015-04-07 09:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5222f67a8a655db406e8f83b8c6922e80911c90', 'message': '[WIP]: Add handling of SIGHUP - multiprocess mode\n\nRelated-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 10, 'created': '2015-04-07 12:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3265702b6c40bca98a73b1f15cb6568ecc6665e7', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nrecieves a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would the be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 11, 'created': '2015-04-09 12:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba021fb4224dfbe7a2723c7d2f3eeb0f5f865a6e', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 12, 'created': '2015-04-09 13:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cbf09c260ca804d55d4f201747f5f316c3b57907', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 13, 'created': '2015-04-14 12:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fba44f519001e2c9971d571d5aa9e358bd80a09e', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 14, 'created': '2015-04-14 13:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d386bd1e2fb7b41952e73baac3a248d9d216222', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 15, 'created': '2015-04-14 13:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52fa44d09fe41336cef3f049e2d1efb61b98ef95', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 16, 'created': '2015-04-21 08:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b260f0106ba54183eccbcaeface840a2ac2995c4', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 17, 'created': '2015-04-21 08:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/65f3745f29c0236679e34da62d0a26337020c24c', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 18, 'created': '2015-04-22 08:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd9e321e29cf0ba0b1ff5d0556f0d24bff74d08c', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 19, 'created': '2015-04-23 13:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9af4ee4b16b8166877e61b1b1c8769506927500', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 20, 'created': '2015-04-24 10:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a30185886e5eec658ea86250b788a0f1d204a9c', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 21, 'created': '2015-05-12 09:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ccf1bb781a93d1b8336cb2569218cb7e11b1da0d', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 22, 'created': '2015-05-12 09:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9828569538d9d57b4b8a4d938ed433857fb1f09', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 23, 'created': '2015-05-26 15:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55cd36d3657828ec54b0e457f14d5ca13b415d07', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 24, 'created': '2015-06-01 13:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b219ea6d9ec9b5da2730d7d98e9a65be0decc67', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 25, 'created': '2015-06-01 13:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0cbf25fa56e8c2e3afab173b89f29df10dad943', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 26, 'created': '2015-06-02 09:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/810fe111d1ef1d7c11e3db5ac8153047c866ba12', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 27, 'created': '2015-06-02 13:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e16870a517b6b2106b4d731b097ccb03b7577498', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 28, 'created': '2015-06-02 14:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7849e10b850cc764828de89b3908efb42bb5d286', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nDocImpact\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 29, 'created': '2015-06-09 12:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/112ce25ad068242805c61ba3568e2b246c825c64', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nDocImpact\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}, {'number': 30, 'created': '2015-06-09 13:17:21.000000000', 'files': ['neutron/tests/functional/test_server.py', 'neutron/wsgi.py', 'neutron/common/config.py', 'neutron/service.py', 'neutron/tests/unit/test_wsgi.py', 'neutron/tests/unit/test_service.py', 'neutron/tests/functional/requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d0d72973152bb45587437c80d4ffe0fe7bba761', 'message': 'Handle SIGHUP: neutron-server (multiprocess) and metadata agent\n\nAll launchers implemented in common.service require each service to\nimplement reset method because it is called in case a process\nreceives a SIGHUP.\n\nThis change adds the reset method to neutron.service.RpcWorker and\nneutron.wsgi.WorkerService which are used to wrap rpc and api\nworkers correspondingly.\n\nNow neutron-server running in multiprocess mode (api_workers > 0 and\nrpc_workers > 0) and metadata agent don\'t die on receiving SIGHUP and support\nreloading policy_path and logging options in config.\n\nNote that reset is called only in case a service is running in daemon mode.\n\nOther changes made in the scope of this patch that need to be mentioned:\n\n* Don\'t empty self._servers list in RpcWorker\'s stop method\n\n  When a service is restarted all services are gracefully shutdowned,\n  resetted and started again (see openstack.common.service code).\n  As graceful shutdown implies calling service.stop() and then\n  service.wait() we don\'t want to clean self._servers list because\n  it would be impossible to wait for them to stop processing\n  requests and cleaning up their resources.\n  Otherwise, this would lead to problems with rpc after starting\n  the rpc server again.\n\n* Create a duplicate socket each time WorkerService starts\n\n  When api worker is stopped it kills the eventlet wsgi server\n  which internally closes the wsgi server socket object. This server\n  socket object becomes not usable which leads to ""Bad file\n  descriptor"" errors on service restart.\n\nAdded functional and unit tests.\n\nDocImpact\nPartial-Bug: #1276694\nChange-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24\n'}]",59,161732,6d0d72973152bb45587437c80d4ffe0fe7bba761,703,49,30,7293,,,0,"Handle SIGHUP: neutron-server (multiprocess) and metadata agent

All launchers implemented in common.service require each service to
implement reset method because it is called in case a process
receives a SIGHUP.

This change adds the reset method to neutron.service.RpcWorker and
neutron.wsgi.WorkerService which are used to wrap rpc and api
workers correspondingly.

Now neutron-server running in multiprocess mode (api_workers > 0 and
rpc_workers > 0) and metadata agent don't die on receiving SIGHUP and support
reloading policy_path and logging options in config.

Note that reset is called only in case a service is running in daemon mode.

Other changes made in the scope of this patch that need to be mentioned:

* Don't empty self._servers list in RpcWorker's stop method

  When a service is restarted all services are gracefully shutdowned,
  resetted and started again (see openstack.common.service code).
  As graceful shutdown implies calling service.stop() and then
  service.wait() we don't want to clean self._servers list because
  it would be impossible to wait for them to stop processing
  requests and cleaning up their resources.
  Otherwise, this would lead to problems with rpc after starting
  the rpc server again.

* Create a duplicate socket each time WorkerService starts

  When api worker is stopped it kills the eventlet wsgi server
  which internally closes the wsgi server socket object. This server
  socket object becomes not usable which leads to ""Bad file
  descriptor"" errors on service restart.

Added functional and unit tests.

DocImpact
Partial-Bug: #1276694
Change-Id: I75b00946b7cae891c6eb192e853118e7d49e4a24
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/161732/13 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/wsgi.py', 'neutron/service.py']",2,69cc7d7b5179f538f2fc23e88648807a09b4d16c,refactor_service_tests, def reset(self): pass ,,8,1
openstack%2Fneutron-specs~master~I1be979641fe114b8a069bcc192936761a6bb2238,openstack/neutron-specs,master,I1be979641fe114b8a069bcc192936761a6bb2238,Enable spoofchk control for SR-IOV ports,MERGED,2015-05-13 09:30:20.000000000,2015-06-10 20:24:36.000000000,2015-06-10 20:24:34.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6509}, {'_account_id': 6598}, {'_account_id': 10980}, {'_account_id': 11547}, {'_account_id': 12171}]","[{'number': 1, 'created': '2015-05-13 09:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d1b3106a1ecf2c4b84639d0e256414b2659fb849', 'message': 'Enable spoofchk control for SR-IOV ports\n\nAllow user to control setting of spoof checking for the SR-IOV ports.\n\nBlueprint: sriov-spoofchk\nChange-Id: I1be979641fe114b8a069bcc192936761a6bb2238\n'}, {'number': 2, 'created': '2015-05-14 06:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e343e73b50ca9ed5f085e3531e19928623ffdcb9', 'message': 'Enable spoofchk control for SR-IOV ports\n\nAllow user to control setting of spoof checking for the SR-IOV ports.\n\nBlueprint: sriov-spoofchk\nChange-Id: I1be979641fe114b8a069bcc192936761a6bb2238\n'}, {'number': 3, 'created': '2015-05-14 11:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4ceb2c05504f080aad875388322cb64b253b498d', 'message': 'Enable spoofchk control for SR-IOV ports\n\nAllow user to control setting of spoof checking for the SR-IOV ports.\n\nBlueprint: sriov-spoofchk\nChange-Id: I1be979641fe114b8a069bcc192936761a6bb2238\n'}, {'number': 4, 'created': '2015-05-15 06:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6644e03a83ed2ef2a3ed31d19f0afa327acca713', 'message': 'Enable spoofchk control for SR-IOV ports\n\nAllow user to control setting of spoof checking for the SR-IOV ports.\n\nBlueprint: sriov-spoofchk\nChange-Id: I1be979641fe114b8a069bcc192936761a6bb2238\n'}, {'number': 5, 'created': '2015-05-20 10:48:45.000000000', 'files': ['specs/liberty/sriov-spoofchk.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ec72c07f87153423c0d7225c3ed792fa2cc071c4', 'message': 'Enable spoofchk control for SR-IOV ports\n\nAllow user to control setting of MAC spoof checking for the SR-IOV ports.\n\nBlueprint: sriov-spoofchk\nChange-Id: I1be979641fe114b8a069bcc192936761a6bb2238\n'}]",30,182593,ec72c07f87153423c0d7225c3ed792fa2cc071c4,32,7,5,6509,,,0,"Enable spoofchk control for SR-IOV ports

Allow user to control setting of MAC spoof checking for the SR-IOV ports.

Blueprint: sriov-spoofchk
Change-Id: I1be979641fe114b8a069bcc192936761a6bb2238
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/93/182593/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/sriov-spoofchk.rst'],1,d1b3106a1ecf2c4b84639d0e256414b2659fb849,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Enable spoofchk control for SR-IOV ports ========================================== https://blueprints.launchpad.net/neutron/+spec/sriov-spoofchk Allow user to control setting of spoof checking for the SR-IOV ports. Problem Description =================== A support for SR-IOV ports appeared in Neutron Juno and it allows VMs to access virtual network via SR-IOV NICs. SR-IOV ports in Linux allow to specify if spoof checking should be enabled or disabled for them, for example it could be done using the ip-link(8) tool: ip link set eth0 vf 2 spoofchk off This command disables spoof checking for Virtual Function 2 on Physical Device 'eth0'. In some configurations, for example bonding, this feature is very useful and it would be convenient to allow to be able to set spoof checking mode through Neutron. Proposed Change =============== The portbinding model will be extended with a 'spoofchk' attribute that would store a boolean value, 'True' meaning spoof checking is enabled and 'False' meaning that spoof checking is disabled. Relevant changes in API handlers will be added to expose this attribute through API so user could specify it in port create or port update request. Database migration will be added as well. Actual setting for the VF will be done by the sriovnicagent using the ip-link(8) tool. Default value for the spoof checking will be disabled, so the change will not affect a default behavior. Data Model Impact ----------------- * A new field 'spoofchk' of type Boolean will be added to the PortBinding model class * An appropriate database migration will be added for this change REST API Impact --------------- The portbindings extension will have a new attribute. +----------+-------+---------+---------+------------+--------------+ |Attribute |Type |Access |Default |Validation/ |Description | |Name | | |Value |Conversion | | +==========+=======+=========+=========+============+==============+ |spoofchk |bool |RW, | True |bool |spoof checking| | | | admin | | | setting | +----------+-------+---------+---------+------------+--------------+ Security Impact --------------- That could have a security impact if user disables spoof checking for a specific port, however it is expected and user can manually decide if that's applicable for his configuration. As spoof checking is enabled by default, there would be no security impact with the default setting. Notifications Impact -------------------- None Other End User Impact --------------------- And user will have a facility to control spoof checking settings on specific Neutron ports. * python-neutronclient does not need to be modified for a new attribute Performance Impact ------------------ It'll have a slight impact on the sriovagent as it'll have to run one more external command (ip-link(8)). IPv6 Impact ----------- None Other Deployer Impact --------------------- None Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the API, discussion of how other plugins would implement the feature is required. Community Impact ---------------- This changes has not been discussed so far. Alternatives ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Implementation ============== Assignee(s) ----------- Primary assignee: novel Work Items ---------- * Update data model to add the new attribute * Modify sriovagent to be able to enable or disable spoof checking based on user setting Dependencies ============ None Testing ======= Tempest tests are not planned currently as SR-IOV hardware is not always available. 3rd party CI testing could be considered, though probably the feature is relatively minor for that. Tempest Tests ------------- None Functional Tests ---------------- None API Tests --------- API tests will be implemented for the new 'spoofchk' portbindings attribute. Documentation Impact ==================== User Documentation ------------------ User documentation will be updated with information about spoof checking control and its security considerations. Developer Documentation ----------------------- None References ========== None ",,191,0
openstack%2Fossa~master~If5817c700fa6d66ddd6fc08d10400db3c9b3dd6e,openstack/ossa,master,If5817c700fa6d66ddd6fc08d10400db3c9b3dd6e,Change Tristan's mail address,MERGED,2015-06-09 19:33:15.000000000,2015-06-10 20:23:36.000000000,2015-06-10 20:23:36.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 7473}]","[{'number': 1, 'created': '2015-06-09 19:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ossa/commit/fdf931a5d0914da38fdb8eec37d0009c75bd6371', 'message': ""Change Tristan's mail address\n\nChange-Id: If5817c700fa6d66ddd6fc08d10400db3c9b3dd6e\n""}, {'number': 2, 'created': '2015-06-10 18:08:04.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/ossa/commit/c563b6f444fb6f78089cf3fe5f041c70ba0a3c10', 'message': ""Change Tristan's mail address\n\nChange-Id: If5817c700fa6d66ddd6fc08d10400db3c9b3dd6e\n""}]",0,189888,c563b6f444fb6f78089cf3fe5f041c70ba0a3c10,9,3,2,9311,,,0,"Change Tristan's mail address

Change-Id: If5817c700fa6d66ddd6fc08d10400db3c9b3dd6e
",git fetch https://review.opendev.org/openstack/ossa refs/changes/88/189888/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,fdf931a5d0914da38fdb8eec37d0009c75bd6371,, * Tristan Cacqueray (tdecacqu@redhat.com): `GPG key for Tristan`_, * Tristan Cacqueray (tristan.cacqueray@enovance.com): `GPG key for Tristan`_,1,1
openstack%2Fossa~master~I465467aa80405c29b3835528ce3f644271d19709,openstack/ossa,master,I465467aa80405c29b3835528ce3f644271d19709,"Revert ""Fix the missing man_pages config warning error""",MERGED,2015-06-10 17:59:12.000000000,2015-06-10 20:23:32.000000000,2015-06-10 20:23:30.000000000,"[{'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-06-10 17:59:12.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ossa/commit/0fd4bff9e46ce6bcca82bddb7e092513a7ca07cf', 'message': 'Revert ""Fix the missing man_pages config warning error""\n\nThis reverts commit e5e48e44028bf7c134ce33985aa195168b2a9736.\n\nChange-Id: I465467aa80405c29b3835528ce3f644271d19709\n'}]",0,190283,0fd4bff9e46ce6bcca82bddb7e092513a7ca07cf,6,2,1,9311,,,0,"Revert ""Fix the missing man_pages config warning error""

This reverts commit e5e48e44028bf7c134ce33985aa195168b2a9736.

Change-Id: I465467aa80405c29b3835528ce3f644271d19709
",git fetch https://review.opendev.org/openstack/ossa refs/changes/83/190283/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,0fd4bff9e46ce6bcca82bddb7e092513a7ca07cf,,warnerrors = True,warnerrors = False,1,1
openstack%2Fmagnum~master~I41aaf59c37a78e618ea1daf21bbdc19284b9ea40,openstack/magnum,master,I41aaf59c37a78e618ea1daf21bbdc19284b9ea40,cleanup openstack-common.conf and sync updated files,MERGED,2015-06-07 14:09:57.000000000,2015-06-10 20:23:10.000000000,2015-06-10 20:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}, {'_account_id': 9591}, {'_account_id': 11536}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-06-07 14:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6e15cd7c3042dec496d6c8d5f43bb5b1fe440a1a', 'message': 'cleanup openstack-common.conf and sync updated files\n\nChange-Id: I41aaf59c37a78e618ea1daf21bbdc19284b9ea40\n'}, {'number': 2, 'created': '2015-06-10 11:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3302218f6015e573031922ad9dfbbe22a24d37da', 'message': 'cleanup openstack-common.conf and sync updated files\n\nCloses-Bug: #1463778\nChange-Id: I41aaf59c37a78e618ea1daf21bbdc19284b9ea40'}, {'number': 3, 'created': '2015-06-10 11:05:55.000000000', 'files': ['magnum/openstack/common/threadgroup.py', 'magnum/openstack/common/periodic_task.py', 'magnum/openstack/common/loopingcall.py', 'magnum/openstack/common/eventlet_backdoor.py', 'magnum/openstack/common/service.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/magnum/commit/576374a6cce53f061807b87a9e40552397f0b098', 'message': 'cleanup openstack-common.conf and sync updated files\n\nCloses-Bug: #1463778\nChange-Id: I41aaf59c37a78e618ea1daf21bbdc19284b9ea40'}]",0,189115,576374a6cce53f061807b87a9e40552397f0b098,13,6,3,5638,,,0,"cleanup openstack-common.conf and sync updated files

Closes-Bug: #1463778
Change-Id: I41aaf59c37a78e618ea1daf21bbdc19284b9ea40",git fetch https://review.opendev.org/openstack/magnum refs/changes/15/189115/3 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/openstack/common/periodic_task.py', 'magnum/openstack/common/threadgroup.py', 'magnum/openstack/common/loopingcall.py', 'magnum/openstack/common/eventlet_backdoor.py', 'magnum/openstack/common/service.py', 'openstack-common.conf']",6,6e15cd7c3042dec496d6c8d5f43bb5b1fe440a1a,,,module=versionutils,39,35
openstack%2Fneutron-lbaas~master~I54e99e810d9e22336cc292abd53ed9be14159946,openstack/neutron-lbaas,master,I54e99e810d9e22336cc292abd53ed9be14159946,Fixed A10 v2 driver to correctly handle HM deletion,ABANDONED,2015-05-27 22:39:53.000000000,2015-06-10 20:19:29.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 10068}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 12040}, {'_account_id': 16537}]","[{'number': 1, 'created': '2015-05-27 22:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/6967bb4fc9bbedc62b0f55b298667721330d82ca', 'message': 'Fixed references to old logging library to make tests pass\nChange-Id: I54e99e810d9e22336cc292abd53ed9be14159946\n'}, {'number': 2, 'created': '2015-06-09 23:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/f3fe80c4fb1ddbdb86021bfde105310b610c47f6', 'message': 'Fixed A10 v2 driver to correctly handle HM deletion\nAdded tests for above\nAdded logging to listeners tests (part of greater ""fix tests"" task)\n\nChange-Id: I54e99e810d9e22336cc292abd53ed9be14159946\n'}, {'number': 3, 'created': '2015-06-09 23:23:20.000000000', 'files': ['neutron_lbaas/tests/tempest/v2/api/test_listeners.py', 'neutron_lbaas/drivers/a10networks/driver_v2.py', 'neutron_lbaas/tests/unit/drivers/a10networks/test_hm_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/7d7bc05385e205c643ce6130595538761a8d94d5', 'message': 'Fixed A10 v2 driver to correctly handle HM deletion\n\nAdded tests for above\nAdded logging to listeners tests (part of greater ""fix tests"" task)\n\nChange-Id: I54e99e810d9e22336cc292abd53ed9be14159946\n'}]",1,186203,7d7bc05385e205c643ce6130595538761a8d94d5,21,8,3,16537,,,0,"Fixed A10 v2 driver to correctly handle HM deletion

Added tests for above
Added logging to listeners tests (part of greater ""fix tests"" task)

Change-Id: I54e99e810d9e22336cc292abd53ed9be14159946
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/03/186203/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/tempest/v2/api/test_listeners.py', 'neutron_lbaas/tests/tempest/v2/api/test_load_balancers_admin.py', 'neutron_lbaas/tests/tempest/v2/api/base.py', 'neutron_lbaas/tests/tempest/v2/api/test_load_balancers_non_admin.py', 'neutron_lbaas/tests/tempest/v2/api/test_members.py']",5,6967bb4fc9bbedc62b0f55b298667721330d82ca,tempest-test-fixesv2,from oslo_log import log as logging,from tempest.openstack.common import log as logging,5,5
openstack%2Fhorizon~master~I5860a6a92bf1ab685d57b7f834a9ea495d196ecc,openstack/horizon,master,I5860a6a92bf1ab685d57b7f834a9ea495d196ecc,Encase helper-functions spec in IIFE,MERGED,2015-05-26 19:52:20.000000000,2015-06-10 20:15:06.000000000,2015-06-10 20:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 13785}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-05-26 19:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a04ee8d3572bf662afd6d3ddd381de03598ef894', 'message': 'Encase helper-functions spec in IIEF\n\nImmediately Invoked Function Expression (IIFE).\nThis spec needs to be enclosed and jshint globals removed.\n\nChange-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc\nCloses-bug: #1458993\n'}, {'number': 2, 'created': '2015-05-26 22:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9abbde407f17aaa37ce019c65f341c6e7b54dedb', 'message': 'Encase helper-functions spec in IIFE\n\nImmediately Invoked Function Expression (IIFE).\nThis spec needs to be enclosed and jshint globals removed.\n\nChange-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc\nCloses-bug: #1458993'}, {'number': 3, 'created': '2015-06-05 22:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/efe21941385e3cd78aa0be9d2f5215e48afee1a1', 'message': 'Encase helper-functions spec in IIFE\n\nImmediately Invoked Function Expression (IIFE).\nThis spec needs to be enclosed and jshint globals removed.\n\nChange-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc\nCloses-bug: #1458993\n'}, {'number': 4, 'created': '2015-06-05 22:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/012a992c7a3d5f25d87e2c301eef7bb3cb207d8f', 'message': 'Encase helper-functions spec in IIFE\n\nImmediately Invoked Function Expression (IIFE).\nThis spec needs to be enclosed and jshint globals removed.\n\nChange-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc\nCloses-bug: #1458993'}, {'number': 5, 'created': '2015-06-05 22:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4a0b90235fe7214c005582dd860285694531355e', 'message': 'Encase helper-functions spec in IIFE\n\nImmediately Invoked Function Expression (IIFE).\nThis spec needs to be enclosed and jshint globals removed.\n\nChange-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc\nCloses-bug: #1458993'}, {'number': 6, 'created': '2015-06-09 05:27:31.000000000', 'files': ['horizon/static/framework/util/tech-debt/helper-functions.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/af52de093a16d04319a22341f605adb296d613c3', 'message': 'Encase helper-functions spec in IIFE\n\nImmediately Invoked Function Expression (IIFE).\nThis spec needs to be enclosed and jshint globals removed.\n\nChange-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc\nCloses-bug: #1458993'}]",5,185721,af52de093a16d04319a22341f605adb296d613c3,21,7,6,9576,,,0,"Encase helper-functions spec in IIFE

Immediately Invoked Function Expression (IIFE).
This spec needs to be enclosed and jshint globals removed.

Change-Id: I5860a6a92bf1ab685d57b7f834a9ea495d196ecc
Closes-bug: #1458993",git fetch https://review.opendev.org/openstack/horizon refs/changes/21/185721/5 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/framework/util/tech-debt/helper-functions.spec.js'],1,a04ee8d3572bf662afd6d3ddd381de03598ef894,jshint/enclose-helper-functions,"(function() { describe('horizon.framework.util.tech-debt', function () { 'use strict'; describe('horizon.framework.util.tech-debt.helper-functions', function () { beforeEach(module('horizon.dashboard-app')); beforeEach(function () { angular.mock.module('horizon.framework.util.tech-debt'); describe('horizon.framework.util.tech-debt.helper-functions', function () { var hzUtils; beforeEach(function () { angular.mock.inject(function ($injector) { hzUtils = $injector.get('horizon.framework.util.tech-debt.helper-functions'); describe('log', function () { var hzConfig, $log, log; beforeEach(function () { log = 'display a log'; angular.mock.inject(function ($injector) { $log = $injector.get('$log'); hzConfig = $injector.get('horizon.dashboard-app.conf'); //jasmine cannot mock properties hzConfig.debug = true; }); it('should display a log at default log level', function () { hzUtils.log(log); expect($log.log.logs.length).toBe(1); expect($log.log.logs[0][0]).toBe(log); }); it('should have a configurable log level', function () { hzUtils.log(log, 'debug'); expect($log.debug.logs.length).toBe(1); hzUtils.log(log, 'error'); expect($log.error.logs.length).toBe(1); hzUtils.log(log, 'info'); expect($log.info.logs.length).toBe(1); hzUtils.log(log, 'log'); expect($log.log.logs.length).toBe(1); hzUtils.log(log, 'warn'); expect($log.warn.logs.length).toBe(1); }); describe('capitalize', function () { it('should capitalize the first letter of a string', function () { expect(hzUtils.capitalize('string to test')).toBe('String to test'); }); }); describe('humanizeNumbers', function () { it('should add a comma every three number', function () { expect(hzUtils.humanizeNumbers('1234')).toBe('1,234'); expect(hzUtils.humanizeNumbers('1234567')).toBe('1,234,567'); }); it('should work with string or numbers', function () { expect(hzUtils.humanizeNumbers('1234')).toBe('1,234'); expect(hzUtils.humanizeNumbers(1234)).toBe('1,234'); }); it('should work with multiple values through a string', function () { expect(hzUtils.humanizeNumbers('My Total: 1234')). toBe('My Total: 1,234'); expect(hzUtils.humanizeNumbers('My Total: 1234, His Total: 1234567')). toBe('My Total: 1,234, His Total: 1,234,567'); }); }); describe('truncate', function () { var string = 'This will be cut', ellipsis = '&hellip;'; it('should truncate a string at a given length', function () { expect(hzUtils.truncate(string, 15)). toBe(string.slice(0, 15)); expect(hzUtils.truncate(string, 20)). toBe(string); }); it('should add an ellipsis if needed ', function () { expect(hzUtils.truncate(string, 15, true)). toBe(string.slice(0, 12) + ellipsis); expect(hzUtils.truncate(string, 20, true)). toBe(string); expect(hzUtils.truncate(string, 2, true)). toBe(ellipsis); }); }); describe('loadAngular', function () { var rootScope, element; beforeEach(function () { element = angular.element('<div>'); angular.mock.inject(function ($injector) { rootScope = $injector.get('$rootScope'); });s spyOn(rootScope, '$apply'); }); it('should call a compile and apply ', function () { hzUtils.loadAngular(element); //checks the use of apply function expect(rootScope.$apply).toHaveBeenCalled(); //checks the use of compile function expect(element.hasClass('ng-scope')).toBeTruthy(); }); })(); ","/*global describe, it, expect, beforeEach, spyOn, angular*/ describe('horizon.framework.util.tech-debt', function () { describe('horizon.framework.util.tech-debt.helper-functions', function () { beforeEach(module('horizon.dashboard-app')); beforeEach(function () { angular.mock.module('horizon.framework.util.tech-debt'); }); describe('horizon.framework.util.tech-debt.helper-functions', function () { var hzUtils; beforeEach(function () { angular.mock.inject(function ($injector) { hzUtils = $injector.get('horizon.framework.util.tech-debt.helper-functions'); }); describe('log', function () { var hzConfig, $log, log; beforeEach(function () { log = 'display a log'; angular.mock.inject(function ($injector) { $log = $injector.get('$log'); hzConfig = $injector.get('horizon.dashboard-app.conf'); //jasmine cannot mock properties hzConfig.debug = true; it('should display a log at default log level', function () { hzUtils.log(log); expect($log.log.logs.length).toBe(1); expect($log.log.logs[0][0]).toBe(log); }); it('should have a configurable log level', function () { hzUtils.log(log, 'debug'); expect($log.debug.logs.length).toBe(1); hzUtils.log(log, 'error'); expect($log.error.logs.length).toBe(1); hzUtils.log(log, 'info'); expect($log.info.logs.length).toBe(1); hzUtils.log(log, 'log'); expect($log.log.logs.length).toBe(1); hzUtils.log(log, 'warn'); expect($log.warn.logs.length).toBe(1); }); }); describe('capitalize', function () { it('should capitalize the first letter of a string', function () { expect(hzUtils.capitalize('string to test')).toBe('String to test'); }); }); describe('humanizeNumbers', function () { it('should add a comma every three number', function () { expect(hzUtils.humanizeNumbers('1234')).toBe('1,234'); expect(hzUtils.humanizeNumbers('1234567')).toBe('1,234,567'); }); it('should work with string or numbers', function () { expect(hzUtils.humanizeNumbers('1234')).toBe('1,234'); expect(hzUtils.humanizeNumbers(1234)).toBe('1,234'); }); it('should work with multiple values through a string', function () { expect(hzUtils.humanizeNumbers('My Total: 1234')). toBe('My Total: 1,234'); expect(hzUtils.humanizeNumbers('My Total: 1234, His Total: 1234567')). toBe('My Total: 1,234, His Total: 1,234,567'); }); }); describe('truncate', function () { var string = 'This will be cut', ellipsis = '&hellip;'; it('should truncate a string at a given length', function () { expect(hzUtils.truncate(string, 15)). toBe(string.slice(0, 15)); expect(hzUtils.truncate(string, 20)). toBe(string); }); it('should add an ellipsis if needed ', function () { expect(hzUtils.truncate(string, 15, true)). toBe(string.slice(0, 12) + ellipsis); expect(hzUtils.truncate(string, 20, true)). toBe(string); expect(hzUtils.truncate(string, 2, true)). toBe(ellipsis); }); }); describe('loadAngular', function () { var rootScope, element; beforeEach(function () { element = angular.element('<div>'); angular.mock.inject(function ($injector) { rootScope = $injector.get('$rootScope'); spyOn(rootScope, '$apply'); it('should call a compile and apply ', function () { hzUtils.loadAngular(element); //checks the use of apply function expect(rootScope.$apply).toHaveBeenCalled(); //checks the use of compile function expect(element.hasClass('ng-scope')).toBeTruthy();});",111,107
openstack%2Fmonasca-api~master~I5034ea256372d22b9f824e301c379da81f82b4e2,openstack/monasca-api,master,I5034ea256372d22b9f824e301c379da81f82b4e2,Updated for Falcon 0.2 and clean-up,MERGED,2015-06-05 15:39:39.000000000,2015-06-10 20:13:24.000000000,2015-06-10 20:13:22.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 12133}, {'_account_id': 12512}, {'_account_id': 14273}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-06-05 15:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/00ff3b670c67c6d6ecdb7c42d43ad9d8e8c8a7a2', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 2, 'created': '2015-06-05 16:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/216ba6afc7ae5c06ab81a384a9bc1078bc230a91', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 3, 'created': '2015-06-05 16:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/78e6da9d815bfbd2a896cac391f6e8388ce7d8ab', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 4, 'created': '2015-06-05 16:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/f69a3ea6c6d5da6a7ff2b6159c4be52e6a5199ad', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 5, 'created': '2015-06-05 17:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/bb0c571ab977062f4191aed9c05a4a39c386c583', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 6, 'created': '2015-06-05 17:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/20ad3694f44858a46f0fb6b3bbf81962484c7e79', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 7, 'created': '2015-06-05 18:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/823fca4a2880b3f2fe38ad1b9bb5fd75bec8659b', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 8, 'created': '2015-06-05 20:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/0988fa9de12b7fe89e96a89c39e52dc585786740', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 9, 'created': '2015-06-05 21:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3c0726a1a86c68daf700e04307603ad8506d4fed', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 10, 'created': '2015-06-05 21:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3bf8007460924cbfbb2cd6259ee21f4d8030915a', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 11, 'created': '2015-06-05 22:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e8def5607a470ee1a4b6e96de4b560727968f452', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 12, 'created': '2015-06-05 22:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/219f400bea17b3f8385abe4cbfb60ed9fcc4dfc7', 'message': 'Updated for Falcon 0.2 and clean-up\n\nConverted to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 13, 'created': '2015-06-06 03:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/4b34986104df5ec37a5e0c2726b1c6dd9ec23138', 'message': 'Updated for Falcon 0.2 and clean-up\n\nUpgraded to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events. Events api is in monasca-events-api\nRemoved references to elastic search\nRemoved support for message format translations\nRemoved unused and dead code\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 14, 'created': '2015-06-06 04:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/1c66ed5dd6a242879ec14c06824e776326acb32d', 'message': 'Updated for Falcon 0.2 and clean-up\n\nUpgraded to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events. Events api is in monasca-events-api\nRemoved references to elastic search\nRemoved support for message format translations\nRemoved unused and dead code\nRemoved author tags\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 15, 'created': '2015-06-06 04:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/538cfc04ff1da3bd86649a116ef4fda6cdea434e', 'message': 'Updated for Falcon 0.2 and clean-up\n\nUpgraded to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events. Events api is in monasca-events-api\nRemoved references to elastic search\nRemoved support for message format translations\nRemoved unused and dead code\nRemoved author tags\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 16, 'created': '2015-06-07 03:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/352188ec675cba68e94114bec17f5d2172e5dc46', 'message': 'Updated for Falcon 0.2 and clean-up\n\nUpgraded to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events. Events api is in monasca-events-api\nRemoved references to elastic search\nRemoved support for message format translations\nRemoved unused and dead code\nRemoved author tags\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}, {'number': 17, 'created': '2015-06-07 03:47:16.000000000', 'files': ['monasca_api/common/repositories/mysql/alarm_definitions_repository.py', 'monasca_api/openstack/common/gettextutils.py', 'etc/monasca.ini', 'monasca_api/common/repositories/mysql/notifications_repository.py', 'monasca/common/messaging/message_formats/cadf/events.py', 'monasca_api/common/messaging/message_formats/__init__.py', 'monasca_api/openstack/common/fixture/moxstubout.py', 'monasca_api/middleware/inspector.py', 'monasca_api/openstack/common/fixture/logging.py', 'monasca_api/common/repositories/fake/metrics_repository.py', 'monasca_api/openstack/common/fixture/lockutils.py', 'monasca/api/monasca_events_api_v2.py', 'monasca/api/server.py', 'monasca/__init__.py', 'monasca_api/openstack/common/excutils.py', 'monasca/v2/reference/events.py', 'monasca_api/api/notifications_api_v2.py', 'monasca_api/openstack/common/systemd.py', 'monasca_api/common/repositories/model/__init__.py', 'monasca_api/openstack/common/threadgroup.py', 'monasca_api/api/metrics_api_v2.py', 'monasca_api/api/alarm_definitions_api_v2.py', 'monasca_api/common/messaging/message_formats/exceptions.py', 'monasca_api/common/repositories/alarm_definitions_repository.py', 'monasca_api/expression_parser/__init__.py', 'monasca_api/openstack/common/loopingcall.py', 'monasca_api/openstack/common/fixture/config.py', 'monasca_api/common/repositories/mysql/__init__.py', 'monasca_api/common/messaging/message_formats/metrics.py', 'monasca/common/messaging/message_formats/identity/metrics.py', 'monasca/dispatcher/__init__.py', 'monasca_api/v2/reference/__init__.py', 'monasca_api/v2/common/schemas/alarm_definition_request_body_schema.py', 'monasca_api/openstack/common/fileutils.py', 'monasca_api/v2/common/schemas/metrics_request_body_schema.py', 'monasca_api/middleware/__init__.py', 'monasca_api/v2/common/schemas/metric_name_schema.py', 'monasca_api/common/repositories/metrics_repository.py', 'monasca_api/v2/reference/alarming.py', 'monasca/middleware/metric_validator.py', 'monasca/api/monasca_transforms_api_v2.py', 'monasca_api/api/versions_api.py', 'monasca/api/monasca_notifications_api_v2.py', 'monasca_api/common/repositories/model/sub_alarm_definition.py', 'monasca/api/alarm_definitions_api_v2.py', 'monasca/common/messaging/message_formats/cadf/__init__.py', 'monasca_api/v2/reference/resource.py', 'monasca/common/kafka_conn.py', 'monasca_api/openstack/common/strutils.py', 'requirements.txt', 'monasca_api/openstack/common/log.py', 'monasca_api/v2/reference/alarms.py', 'ref-impl-requirements.txt', 'monasca_api/openstack/common/importutils.py', 'monasca_api/common/repositories/alarms_repository.py', 'monasca/api/monasca_api_v2.py', 'monasca_api/v2/common/__init__.py', 'monasca_api/openstack/common/service.py', 'monasca/common/messaging/message_formats/reference/events.py', 'monasca_api/openstack/common/fixture/mockpatch.py', 'monasca_api/v2/common/schemas/dimensions_schema.py', 'monasca/common/messaging/message_formats/metrics_transform_factory.py', 'monasca_api/expression_parser/alarm_expr_parser.py', 'monasca_api/common/messaging/exceptions.py', 'monasca_api/common/repositories/mysql/alarms_repository.py', 'monasca_api/common/messaging/fake_publisher.py', 'monasca/common/repositories/mysql/streams_repository.py', 'monasca_api/v2/reference/versions.py', 'monasca/common/messaging/message_formats/cadf/metrics.py', 'monasca_api/api/alarms_api_v2.py', 'monasca_api/middleware/keystone_context_filter.py', 'es-impl-requirements.txt', 'monasca_api/locale/monasca.pot', 'monasca/api/stream_definitions_api_v2.py', 'etc/api-config.ini', 'monasca_api/v2/reference/notifications.py', 'monasca/v2/common/schemas/transforms_request_body_schema.py', 'monasca/common/messaging/message_formats/reference/__init__.py', 'monasca_api/common/messaging/__init__.py', 'monasca_api/v2/reference/alarm_definitions.py', 'monasca_api/v2/common/schemas/__init__.py', 'monasca/common/repositories/streams_repository.py', 'monasca_api/openstack/common/jsonutils.py', 'monasca_api/middleware/context.py', 'monasca_api/v2/common/schemas/notifications_request_body_schema.py', 'monasca/dispatcher/kafka_dispatcher.py', 'monasca_api/common/repositories/constants.py', 'monasca_api/openstack/common/__init__.py', 'monasca/common/repositories/transforms_repository.py', 'monasca_api/__init__.py', 'etc/api-config.conf', 'monasca_api/openstack/__init__.py', 'monasca_api/tests/__init__.py', 'monasca/common/repositories/events_repository.py', 'monasca_api/v2/common/schemas/exceptions.py', 'monasca_api/common/repositories/notifications_repository.py', 'monasca_api/v2/reference/metrics.py', 'monasca_api/common/repositories/influxdb/__init__.py', 'monasca/v2/reference/transforms.py', 'monasca_api/openstack/common/fixture/__init__.py', 'monasca/middleware/login.py', 'monasca/common/messaging/message_formats/identity/__init__.py', 'monasca_api/common/messaging/publisher.py', 'monasca/v2/common/schemas/events_request_body_schema.py', 'monasca_api/v2/common/utils.py', 'monasca_api/api/server.py', 'setup.cfg', 'monasca/common/messaging/message_formats/identity/events.py', 'monasca/common/repositories/mysql/transforms_repository.py', 'monasca_api/common/repositories/mysql/mysql_repository.py', 'tox.ini', 'monasca/api/alarms_api_v2.py', 'monasca/v2/common/schemas/stream_definition_request_body_schema.py', 'monasca/dispatcher/sample_dispatcher.py', 'monasca/common/messaging/rabbitmq_publisher.py', 'monasca_api/openstack/common/timeutils.py', 'monasca/v2/reference/stream_definitions.py', 'monasca/common/repositories/mysql/model.py', 'monasca_api/common/repositories/__init__.py', 'monasca_api/common/repositories/fake/__init__.py', 'monasca_api/openstack/common/local.py', 'monasca_api/v2/common/schemas/alarm_update_schema.py', 'monasca_api/middleware/mock_auth_filter.py', 'monasca_api/common/messaging/kafka_publisher.py', 'monasca_api/openstack/common/lockutils.py', 'monasca_api/v2/reference/helpers.py', 'monasca_api/common/repositories/exceptions.py', 'monasca_api/tests/first_test.py', 'monasca/common/messaging/message_formats/events_transform_factory.py', 'monasca_api/openstack/common/eventlet_backdoor.py', 'monasca_api/api/__init__.py', 'monasca_api/common/repositories/influxdb/metrics_repository.py', 'monasca_api/openstack/common/uuidutils.py', 'monasca/common/resource_api.py', 'monasca/common/repositories/mysql/events_repository.py', 'monasca_api/common/__init__.py', 'monasca_api/v2/__init__.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/89731de2a62bf4050b9baa6f0d22ccaafc35d5fd', 'message': 'Updated for Falcon 0.2 and clean-up\n\nUpgraded to Falcon 0.2\nConverted from stevedore to simport\nConverted from monasca to monasca_api\nRemoved events. Events api is in monasca-events-api\nRemoved references to elastic search\nRemoved support for message format translations\nRemoved unused and dead code\nRemoved author tags\n\nChange-Id: I5034ea256372d22b9f824e301c379da81f82b4e2\n'}]",11,188829,89731de2a62bf4050b9baa6f0d22ccaafc35d5fd,52,6,17,2419,,,0,"Updated for Falcon 0.2 and clean-up

Upgraded to Falcon 0.2
Converted from stevedore to simport
Converted from monasca to monasca_api
Removed events. Events api is in monasca-events-api
Removed references to elastic search
Removed support for message format translations
Removed unused and dead code
Removed author tags

Change-Id: I5034ea256372d22b9f824e301c379da81f82b4e2
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/29/188829/9 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_api/common/repositories/mysql/alarm_definitions_repository.py', 'monasca_api/openstack/common/gettextutils.py', 'etc/monasca.ini', 'monasca_api/common/repositories/mysql/notifications_repository.py', 'monasca/common/messaging/message_formats/cadf/events.py', 'monasca_api/common/messaging/message_formats/__init__.py', 'monasca_api/openstack/common/fixture/moxstubout.py', 'monasca_api/middleware/inspector.py', 'monasca_api/openstack/common/fixture/logging.py', 'monasca_api/common/repositories/fake/metrics_repository.py', 'monasca_api/openstack/common/fixture/lockutils.py', 'monasca/api/monasca_events_api_v2.py', 'monasca/api/server.py', 'monasca/__init__.py', 'monasca_api/openstack/common/excutils.py', 'monasca/v2/reference/events.py', 'monasca_api/api/notifications_api_v2.py', 'monasca_api/openstack/common/systemd.py', 'monasca_api/common/repositories/model/__init__.py', 'monasca_api/openstack/common/threadgroup.py', 'monasca_api/api/metrics_api_v2.py', 'monasca_api/api/alarm_definitions_api_v2.py', 'monasca_api/common/messaging/message_formats/exceptions.py', 'monasca_api/common/repositories/alarm_definitions_repository.py', 'monasca_api/expression_parser/__init__.py', 'monasca_api/openstack/common/loopingcall.py', 'monasca_api/openstack/common/fixture/config.py', 'monasca_api/common/repositories/mysql/__init__.py', 'monasca_api/common/messaging/message_formats/metrics.py', 'monasca/common/messaging/message_formats/identity/metrics.py', 'monasca/dispatcher/__init__.py', 'monasca_api/v2/reference/__init__.py', 'monasca_api/v2/common/schemas/alarm_definition_request_body_schema.py', 'monasca_api/openstack/common/fileutils.py', 'monasca_api/v2/common/schemas/metrics_request_body_schema.py', 'monasca_api/middleware/__init__.py', 'monasca_api/v2/common/schemas/metric_name_schema.py', 'monasca_api/common/repositories/metrics_repository.py', 'monasca_api/v2/reference/alarming.py', 'monasca/middleware/metric_validator.py', 'monasca/api/monasca_transforms_api_v2.py', 'monasca_api/api/versions_api.py', 'monasca/api/monasca_notifications_api_v2.py', 'monasca_api/common/repositories/model/sub_alarm_definition.py', 'monasca/api/alarm_definitions_api_v2.py', 'monasca/common/messaging/message_formats/cadf/__init__.py', 'monasca_api/v2/reference/resource.py', 'monasca/common/kafka_conn.py', 'monasca_api/openstack/common/strutils.py', 'requirements.txt', 'monasca_api/openstack/common/log.py', 'monasca_api/v2/reference/alarms.py', 'ref-impl-requirements.txt', 'monasca_api/openstack/common/importutils.py', 'monasca_api/common/repositories/alarms_repository.py', 'monasca/api/monasca_api_v2.py', 'monasca_api/v2/common/__init__.py', 'monasca_api/openstack/common/service.py', 'monasca/common/messaging/message_formats/reference/events.py', 'monasca_api/openstack/common/fixture/mockpatch.py', 'monasca_api/v2/common/schemas/dimensions_schema.py', 'monasca/common/messaging/message_formats/metrics_transform_factory.py', 'monasca_api/expression_parser/alarm_expr_parser.py', 'monasca_api/common/messaging/exceptions.py', 'monasca_api/common/repositories/mysql/alarms_repository.py', 'monasca_api/common/messaging/fake_publisher.py', 'monasca/common/repositories/mysql/streams_repository.py', 'monasca_api/v2/reference/versions.py', 'monasca/common/messaging/message_formats/cadf/metrics.py', 'monasca_api/api/alarms_api_v2.py', 'monasca_api/middleware/keystone_context_filter.py', 'es-impl-requirements.txt', 'monasca_api/locale/monasca.pot', 'monasca/api/stream_definitions_api_v2.py', 'etc/api-config.ini', 'monasca_api/v2/reference/notifications.py', 'monasca/v2/common/schemas/transforms_request_body_schema.py', 'monasca/common/messaging/message_formats/reference/__init__.py', 'monasca_api/common/messaging/__init__.py', 'monasca_api/v2/reference/alarm_definitions.py', 'monasca_api/v2/common/schemas/__init__.py', 'monasca/common/repositories/streams_repository.py', 'monasca_api/openstack/common/jsonutils.py', 'monasca_api/middleware/context.py', 'monasca_api/v2/common/schemas/notifications_request_body_schema.py', 'monasca/dispatcher/kafka_dispatcher.py', 'monasca_api/common/repositories/constants.py', 'monasca_api/openstack/common/__init__.py', 'monasca/common/repositories/transforms_repository.py', 'monasca_api/__init__.py', 'etc/api-config.conf', 'monasca_api/openstack/__init__.py', 'monasca_api/tests/__init__.py', 'monasca/common/repositories/events_repository.py', 'monasca_api/v2/common/schemas/exceptions.py', 'monasca_api/common/repositories/notifications_repository.py', 'monasca_api/v2/reference/metrics.py', 'monasca_api/common/repositories/influxdb/__init__.py', 'monasca/v2/reference/transforms.py', 'monasca_api/openstack/common/fixture/__init__.py', 'monasca/middleware/login.py', 'monasca/common/messaging/message_formats/identity/__init__.py', 'monasca_api/common/messaging/publisher.py', 'monasca/v2/common/schemas/events_request_body_schema.py', 'monasca_api/v2/common/utils.py', 'monasca_api/api/server.py', 'setup.cfg', 'monasca/common/messaging/message_formats/identity/events.py', 'monasca/common/repositories/mysql/transforms_repository.py', 'monasca_api/common/repositories/mysql/mysql_repository.py', 'monasca/api/alarms_api_v2.py', 'monasca/v2/common/schemas/stream_definition_request_body_schema.py', 'monasca/dispatcher/sample_dispatcher.py', 'monasca/common/messaging/rabbitmq_publisher.py', 'monasca_api/openstack/common/timeutils.py', 'monasca/v2/reference/stream_definitions.py', 'monasca/common/repositories/mysql/model.py', 'monasca_api/common/repositories/__init__.py', 'monasca_api/common/repositories/fake/__init__.py', 'monasca_api/openstack/common/local.py', 'monasca_api/v2/common/schemas/alarm_update_schema.py', 'monasca_api/middleware/mock_auth_filter.py', 'monasca_api/common/messaging/kafka_publisher.py', 'monasca_api/openstack/common/lockutils.py', 'monasca_api/v2/reference/helpers.py', 'monasca_api/common/repositories/exceptions.py', 'monasca_api/tests/first_test.py', 'monasca/common/messaging/message_formats/events_transform_factory.py', 'monasca_api/openstack/common/eventlet_backdoor.py', 'monasca_api/api/__init__.py', 'monasca_api/common/repositories/influxdb/metrics_repository.py', 'monasca_api/openstack/common/uuidutils.py', 'monasca/common/resource_api.py', 'monasca/common/repositories/mysql/events_repository.py', 'monasca_api/common/__init__.py', 'monasca_api/v2/__init__.py']",136,00ff3b670c67c6d6ecdb7c42d43ad9d8e8c8a7a2,,,,895,3143
openstack%2Fopenstacksdk~master~Ie41d506c64be4afa3b4d09eb34c739d82c28cf80,openstack/openstacksdk,master,Ie41d506c64be4afa3b4d09eb34c739d82c28cf80,Refactor verify_delete in proxy tests,MERGED,2015-06-05 20:05:30.000000000,2015-06-10 20:11:50.000000000,2015-06-10 20:11:49.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-05 20:05:30.000000000', 'files': ['openstack/tests/unit/message/v1/test_proxy.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'openstack/tests/unit/keystore/v1/test_proxy.py', 'openstack/tests/unit/identity/v2/test_proxy.py', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/tests/unit/image/v1/test_proxy.py', 'openstack/tests/unit/clustering/v1/test_proxy.py', 'openstack/tests/unit/telemetry/v2/test_proxy.py', 'openstack/tests/unit/test_proxy_base.py', 'openstack/tests/unit/identity/v3/test_proxy.py', 'openstack/tests/unit/database/v1/test_proxy.py', 'openstack/tests/unit/object_store/v1/test_proxy.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/tests/unit/volume/v2/test_proxy.py', 'openstack/tests/unit/compute/v2/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c9f5a75ae8b825779d23538e85dcfee455817110', 'message': 'Refactor verify_delete in proxy tests\n\nThis mostly rearranges arguments to fall in line with how the others are\nlisted, and also gets rid of additional versions.\n\nSince message does things differently, one of its tests was adjusted to\nuse the more direct verify2 method.\n\nChange-Id: Ie41d506c64be4afa3b4d09eb34c739d82c28cf80\n'}]",0,188905,c9f5a75ae8b825779d23538e85dcfee455817110,10,3,1,8257,,,0,"Refactor verify_delete in proxy tests

This mostly rearranges arguments to fall in line with how the others are
listed, and also gets rid of additional versions.

Since message does things differently, one of its tests was adjusted to
use the more direct verify2 method.

Change-Id: Ie41d506c64be4afa3b4d09eb34c739d82c28cf80
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/05/188905/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/message/v1/test_proxy.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'openstack/tests/unit/keystore/v1/test_proxy.py', 'openstack/tests/unit/identity/v2/test_proxy.py', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/tests/unit/image/v1/test_proxy.py', 'openstack/tests/unit/clustering/v1/test_proxy.py', 'openstack/tests/unit/telemetry/v2/test_proxy.py', 'openstack/tests/unit/test_proxy_base.py', 'openstack/tests/unit/identity/v3/test_proxy.py', 'openstack/tests/unit/database/v1/test_proxy.py', 'openstack/tests/unit/object_store/v1/test_proxy.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/tests/unit/volume/v2/test_proxy.py', 'openstack/tests/unit/compute/v2/test_proxy.py']",15,c9f5a75ae8b825779d23538e85dcfee455817110,," self.verify_delete(self.proxy.delete_flavor, flavor.Flavor, False) self.verify_delete(self.proxy.delete_flavor, flavor.Flavor, True) self.verify_delete(self.proxy.delete_image, image.Image, False) self.verify_delete(self.proxy.delete_image, image.Image, True) self.verify_delete(self.proxy.delete_keypair, keypair.Keypair, False) self.verify_delete(self.proxy.delete_keypair, keypair.Keypair, True) self.verify_delete(self.proxy.delete_server_interface, server_interface.ServerInterface, False) self.verify_delete(self.proxy.delete_server_interface, server_interface.ServerInterface, True) self.verify_delete(self.proxy.delete_server, server.Server, False) self.verify_delete(self.proxy.delete_server, server.Server, True)"," self.verify_delete2(flavor.Flavor, self.proxy.delete_flavor, False) self.verify_delete2(flavor.Flavor, self.proxy.delete_flavor, True) self.verify_delete2(image.Image, self.proxy.delete_image, False) self.verify_delete2(image.Image, self.proxy.delete_image, True) self.verify_delete2(keypair.Keypair, self.proxy.delete_keypair, False) self.verify_delete2(keypair.Keypair, self.proxy.delete_keypair, True) self.verify_delete2(server_interface.ServerInterface, self.proxy.delete_server_interface, False) self.verify_delete2(server_interface.ServerInterface, self.proxy.delete_server_interface, True) self.verify_delete2(server.Server, self.proxy.delete_server, False) self.verify_delete2(server.Server, self.proxy.delete_server, True)",159,171
openstack%2Fos-net-config~master~Ic9b4e8c68b788b98a19ea33a76c9210a80deabeb,openstack/os-net-config,master,Ic9b4e8c68b788b98a19ea33a76c9210a80deabeb,Automate selection of active bond slave,MERGED,2015-06-09 17:50:40.000000000,2015-06-10 20:05:51.000000000,2015-06-10 20:05:51.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}]","[{'number': 1, 'created': '2015-06-09 17:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/d958845fbf014cde19006c3abdf724d8855c7114', 'message': ""Set primary interface on OVS bonds\n\nThis change sets one of the member interfaces of a bond as the primary\ninterface, which results in that interface being the active slave.\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support. If a member interface on the bond is set\nas primary, that interface will be used.\n\nChange-Id: Ic9b4e8c68b788b98a19ea33a76c9210a80deabeb\nCo-Authored-By: Dan Prince <dprince@redhat.com>\n""}, {'number': 2, 'created': '2015-06-09 18:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/92ca918a0888f420f23936b524c63cce870b8ee8', 'message': 'Automate selection of active bond slave\n\n\nThis change selects an interface to be the active slave in a bond\nwith active/passive characteristics. If one of the interfaces is\nmarked as primary, it will be the active slave. If none of the\ninterfaces are marked, the interface with the lowest alphanumeric\nvalue will be chosen. For instance em2 comes before em3.\n\nCo-Authored-By: Dan Prince <dprince@redhat.com>\n\nChange-Id: Ic9b4e8c68b788b98a19ea33a76c9210a80deabeb\n'}, {'number': 3, 'created': '2015-06-09 18:17:49.000000000', 'files': ['os_net_config/tests/test_impl_ifcfg.py', 'os_net_config/objects.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/9355a535e71407911332c228a382ee592452f5e7', 'message': 'Automate selection of active bond slave\n\nThis change selects an interface to be the active slave in a bond\nwith active/passive characteristics. If one of the interfaces is\nmarked as primary, it will be the active slave. If none of the\ninterfaces are marked, the interface with the lowest alphanumeric\nvalue will be chosen. For instance em2 comes before em3.\n\nCo-Authored-By: Dan Prince <dprince@redhat.com>\n\nChange-Id: Ic9b4e8c68b788b98a19ea33a76c9210a80deabeb\n'}]",1,189832,9355a535e71407911332c228a382ee592452f5e7,18,3,3,12398,,,0,"Automate selection of active bond slave

This change selects an interface to be the active slave in a bond
with active/passive characteristics. If one of the interfaces is
marked as primary, it will be the active slave. If none of the
interfaces are marked, the interface with the lowest alphanumeric
value will be chosen. For instance em2 comes before em3.

Co-Authored-By: Dan Prince <dprince@redhat.com>

Change-Id: Ic9b4e8c68b788b98a19ea33a76c9210a80deabeb
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/32/189832/3 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/tests/test_impl_ifcfg.py', 'os_net_config/objects.py']",2,d958845fbf014cde19006c3abdf724d8855c7114,bond_primary_interface, if not self.primary_interface_name: bond_members = list(self.members) bond_members.sort() self.primary_interface_name = bond_members[0].name,,18,1
openstack%2Fos-net-config~master~I795bb3b8ef977f9276bfec062b197c473393942e,openstack/os-net-config,master,I795bb3b8ef977f9276bfec062b197c473393942e,Set primary interface on OVS bonds,MERGED,2015-06-08 20:55:07.000000000,2015-06-10 20:04:43.000000000,2015-06-10 20:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6928}, {'_account_id': 12398}]","[{'number': 1, 'created': '2015-06-08 20:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/aa63239ebc584882032d4e82caef82c8d6b09e0f', 'message': ""Set primary interface on OVS bonds\n\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support.\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 2, 'created': '2015-06-08 21:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/9289d4eda70fed514ee1593bd4439999222a0c02', 'message': ""Set primary interface on OVS bonds\n\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support.\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 3, 'created': '2015-06-08 21:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/1dba14d894fe4a2ca4b17f9536a545f1c040d70b', 'message': ""Set primary interface on OVS bonds\n\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support.\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 4, 'created': '2015-06-08 22:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/db8e18ab1678766b5596c47893a93ece0f1d6446', 'message': ""Set primary interface on OVS bonds\n\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support.\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 5, 'created': '2015-06-08 23:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/f61645e0bf6859416425e630f73e30b27d2b3bf9', 'message': ""Set primary interface on OVS bonds\n\nThis change sets one of the member interfaces of a bond as the primary\ninterface, which results in that interface being the active slave.\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support. If a member interface on the bond is set\nas primary, that interface will be used. If no interface is marked as\nprimary, then the interface with the lowest alphanumeric value is set\nas primary (em2 comes before em3, etc.).\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 6, 'created': '2015-06-09 00:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/4e2260f8e0ac3fc0e70ef7e1808ae1d1db628ded', 'message': ""Set primary interface on OVS bonds\n\nThis change sets one of the member interfaces of a bond as the primary\ninterface, which results in that interface being the active slave.\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support. If a member interface on the bond is set\nas primary, that interface will be used. If no interface is marked as\nprimary, then the interface with the lowest alphanumeric value is set\nas primary (em2 comes before em3, etc.).\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 7, 'created': '2015-06-09 06:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/9ce2aa4d15afbbc9f50bf74e45d81b7d74b9f43f', 'message': ""Set primary interface on OVS bonds\n\nThis change sets one of the member interfaces of a bond as the primary\ninterface, which results in that interface being the active slave.\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support. If a member interface on the bond is set\nas primary, that interface will be used.\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}, {'number': 8, 'created': '2015-06-09 16:35:02.000000000', 'files': ['os_net_config/tests/test_impl_ifcfg.py', 'os_net_config/impl_ifcfg.py', 'os_net_config/__init__.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/7ce531d3c099e310c81f94328b9bfa20de58699b', 'message': ""Set primary interface on OVS bonds\n\nThis change sets one of the member interfaces of a bond as the primary\ninterface, which results in that interface being the active slave.\nThis change adds a step to the apply method in impl_ifcfg which runs\n'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up\nthe bond interfaces. This step ensures that the bonds work correctly\nwithout LACP switch support. If a member interface on the bond is set\nas primary, that interface will be used.\n\nCo-Authored-By: Dan Prince <dprince@redhat.com>\n\nChange-Id: I795bb3b8ef977f9276bfec062b197c473393942e\n""}]",2,189447,7ce531d3c099e310c81f94328b9bfa20de58699b,34,4,8,12398,,,0,"Set primary interface on OVS bonds

This change sets one of the member interfaces of a bond as the primary
interface, which results in that interface being the active slave.
This change adds a step to the apply method in impl_ifcfg which runs
'ovs-appctl bond/set-active-slave <bond> <iface>' after bringing up
the bond interfaces. This step ensures that the bonds work correctly
without LACP switch support. If a member interface on the bond is set
as primary, that interface will be used.

Co-Authored-By: Dan Prince <dprince@redhat.com>

Change-Id: I795bb3b8ef977f9276bfec062b197c473393942e
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/47/189447/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/impl_ifcfg.py', 'os_net_config/__init__.py']",2,aa63239ebc584882032d4e82caef82c8d6b09e0f,primary_bond_interface," def ovs_appctl(self, action, parameters): msg = 'Running ovs-appctl %s %s' % (action, parameters) self.execute(msg, '/bin/ovs-appctl', action + ' ' + parameters) ",,14,1
openstack%2Fhorizon~master~Ib0cf3f42581c1eda3a2213c612bb387c17cc567d,openstack/horizon,master,Ib0cf3f42581c1eda3a2213c612bb387c17cc567d,Unified the position of modal's buttons,MERGED,2015-05-08 09:20:54.000000000,2015-06-10 20:04:33.000000000,2015-06-10 20:04:31.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6638}, {'_account_id': 9576}, {'_account_id': 12355}, {'_account_id': 13785}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-05-08 09:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f6c9fd9cbb45587e89ade0b028ebc320ffdebec0', 'message': 'Fix the buttoms dislocation\n\nIn the disassociate floating ip modal, the cancel buttom\nand confirm buttom is dislocation. Change it as other.\n\nChange-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d\nCloses-bug:#1453048\n'}, {'number': 2, 'created': '2015-05-28 01:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/234386e130743b5bbf70132c3c6eda01070040d8', 'message': 'Fix the buttons dislocation\n\nIn the disassociate floating ip modal, the cancel button\nand confirm button is dislocation. Change it as other.\n\nChange-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d\nCloses-bug:#1453048\n'}, {'number': 3, 'created': '2015-05-28 03:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/09801dd0ccf642987facd9ef180d66d7d7e5d241', 'message': 'Fix the buttons dislocation\n\nIn the disassociate floating ip modal, the cancel button\nand confirm button is dislocation. Change it as other.\n\nChange-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d\nCloses-bug:#1453048\n'}, {'number': 4, 'created': '2015-06-03 07:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/25a2a2bb3b33a3bf66af6f481040eafb2f5aa96f', 'message': ""Unified the position of modal's buttons\n\nIn some only confirm modals, the 'cancel' button in the\nright, 'action' button in the left. Hower most of modals,\nthe position of button  is opposite. This patch unified\nthe position of button. \n\nChange-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d\nCloses-bug:#1453048\n""}, {'number': 5, 'created': '2015-06-08 05:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fd5e891fd0605008a4e93631d36d07355ada9abf', 'message': ""Unified the position of modal's buttons\n\nIn some only confirm modals, the 'cancel' button in the\nright, 'action' button in the left. However most of modals,\nthe position of button  is opposite. This patch unified\nthe position of button.\n\nChange-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d\nCloses-bug:#1453048\n""}, {'number': 6, 'created': '2015-06-10 15:30:48.000000000', 'files': ['horizon/templates/horizon/client_side/_modal.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d99ac9bea8771e0bc3717b294046bd1b1a4cd893', 'message': ""Unified the position of modal's buttons\n\nIn some only confirm modals, the 'cancel' button in the\nright, 'action' button in the left. However most of modals,\nthe position of button  is opposite. This patch unified\nthe position of button.\n\nChange-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d\nCloses-bug:#1453048\n""}]",4,181335,d99ac9bea8771e0bc3717b294046bd1b1a4cd893,26,7,6,9961,,,0,"Unified the position of modal's buttons

In some only confirm modals, the 'cancel' button in the
right, 'action' button in the left. However most of modals,
the position of button  is opposite. This patch unified
the position of button.

Change-Id: Ib0cf3f42581c1eda3a2213c612bb387c17cc567d
Closes-bug:#1453048
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/181335/5 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/client_side/_modal.html'],1,f6c9fd9cbb45587e89ade0b028ebc320ffdebec0,fix-bug/1453048, <a href='#' class='btn btn-primary'>[[confirm]]</a>, <a href='#' class='btn btn-primary'>[[confirm]]</a>,1,1
openstack%2Ffuel-library~master~I90531cf0b12cbfce5a376845df769def6e4c7d93,openstack/fuel-library,master,I90531cf0b12cbfce5a376845df769def6e4c7d93,Adapt rsyslog module for fuel,ABANDONED,2015-01-10 16:59:35.000000000,2015-06-10 19:31:44.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-01-10 16:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8b954c25d4df057bca5904ee7aea7f2d77aa5b6d', 'message': 'Adapt rsyslog module for fuel\n\nChange-Id: I90531cf0b12cbfce5a376845df769def6e4c7d93\n'}, {'number': 2, 'created': '2015-01-12 10:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/26aad814dd10e9c6ef6e647fbda858c005f665b6', 'message': 'Adapt rsyslog module for fuel\n\nChange-Id: I90531cf0b12cbfce5a376845df769def6e4c7d93\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 3, 'created': '2015-01-12 16:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e566b52b9c6e21a20bca850ef6692efdfa2485dc', 'message': 'Adapt rsyslog module for fuel\n\nChange-Id: I90531cf0b12cbfce5a376845df769def6e4c7d93\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 4, 'created': '2015-01-14 16:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d981bb4d94d9b580e57e97a5e6685cf7e80834f0', 'message': 'Adapt rsyslog module for fuel\n\nChange-Id: I90531cf0b12cbfce5a376845df769def6e4c7d93\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 5, 'created': '2015-02-13 10:22:23.000000000', 'files': ['deployment/puppet/rsyslog/Gemfile', 'deployment/puppet/openstack/manifests/logging.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e0f09df53e88515b635862397dde64055e545574', 'message': 'Adapt rsyslog module for fuel\n\nChange-Id: I90531cf0b12cbfce5a376845df769def6e4c7d93\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",0,146283,e0f09df53e88515b635862397dde64055e545574,48,4,5,11090,,,0,"Adapt rsyslog module for fuel

Change-Id: I90531cf0b12cbfce5a376845df769def6e4c7d93
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/83/146283/5 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/rsyslog/Gemfile'],1,8b954c25d4df057bca5904ee7aea7f2d77aa5b6d,adapt-rsyslog,.gemfile,,1,0
openstack%2Ffuel-library~master~I8cf604951fce7cb56a42b0e2f64c5bc175b8619d,openstack/fuel-library,master,I8cf604951fce7cb56a42b0e2f64c5bc175b8619d,Merge saz-rsyslog,ABANDONED,2015-01-10 13:56:08.000000000,2015-06-10 19:31:34.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-01-10 13:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/57f98d9243adf82644f8632610a93043ed957d17', 'message': 'Merge saz-rsyslog\n\ne6dddeec8b71cda20d3a682af7b973e3027f4f01 v3.4.0\n\nChange-Id: I8cf604951fce7cb56a42b0e2f64c5bc175b8619d\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 2, 'created': '2015-01-10 16:56:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/da0c0f345a1c98975e564ef95e20834db6d69d31', 'message': 'Merge saz-rsyslog\n\ne6dddeec8b71cda20d3a682af7b973e3027f4f01 v3.4.0\n\nChange-Id: I8cf604951fce7cb56a42b0e2f64c5bc175b8619d\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 3, 'created': '2015-01-12 10:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/020a7047a14c0b8705c81c9be3738f4045066c13', 'message': 'Merge saz-rsyslog\n\ne6dddeec8b71cda20d3a682af7b973e3027f4f01 v3.4.0\n\nChange-Id: I8cf604951fce7cb56a42b0e2f64c5bc175b8619d\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}, {'number': 4, 'created': '2015-02-13 10:07:55.000000000', 'files': ['deployment/puppet/rsyslog/.fixtures.yml', 'deployment/puppet/rsyslog/manifests/client.pp', 'deployment/puppet/rsyslog/templates/rsyslog.erb', 'deployment/puppet/rsyslog/.gitignore', 'deployment/puppet/rsyslog/.gemfile', 'deployment/puppet/rsyslog/README.md', 'deployment/puppet/rsyslog/metadata.json', 'deployment/puppet/rsyslog/spec/classes/rsyslog_client_spec.rb', 'deployment/puppet/rsyslog/manifests/modload.pp', 'deployment/puppet/rsyslog/lib/facter/rsyslog_version.rb', 'deployment/puppet/rsyslog/spec/classes/rsyslog_database_spec.rb', 'deployment/puppet/rsyslog/spec/classes/rsyslog_spec.rb', 'deployment/puppet/rsyslog/spec/classes/rsyslog_server_spec.rb', 'deployment/puppet/rsyslog/.travis.yml', 'deployment/puppet/rsyslog/files/rsyslog_default_rhel7', 'deployment/puppet/rsyslog/manifests/config.pp', 'deployment/puppet/rsyslog/templates/database.conf.erb', 'deployment/puppet/rsyslog/tests/log_templates.pp', 'deployment/puppet/rsyslog/files/rsyslog_default', 'deployment/puppet/rsyslog/templates/client.conf.erb', 'deployment/puppet/rsyslog/templates/server-hostname.conf.erb', 'deployment/puppet/rsyslog/templates/server-default.conf.erb', 'deployment/puppet/rsyslog/manifests/server.pp', 'deployment/puppet/rsyslog/Rakefile', 'deployment/puppet/rsyslog/tests/multiple_hosts.pp', 'deployment/puppet/rsyslog/manifests/init.pp', 'deployment/puppet/rsyslog/manifests/install.pp', 'deployment/puppet/rsyslog/spec/spec_helper.rb', 'deployment/puppet/rsyslog/files/rsyslog_default_gentoo', 'deployment/puppet/rsyslog/templates/imfile.erb', 'deployment/puppet/rsyslog/templates/server/_default-header.conf.erb', 'deployment/puppet/rsyslog/manifests/service.pp', 'deployment/puppet/rsyslog/tests/database.pp', 'deployment/puppet/rsyslog/manifests/snippet.pp', 'deployment/puppet/rsyslog/templates/server/_default-footer.conf.erb', 'deployment/puppet/rsyslog/templates/00-server.conf.erb', 'deployment/puppet/rsyslog/Modulefile', 'deployment/puppet/rsyslog/examples/site.pp', 'deployment/puppet/rsyslog/LICENSE', 'deployment/puppet/rsyslog/.project', 'deployment/puppet/rsyslog/spec/defines/rsyslog_imfile_spec.rb', 'deployment/puppet/rsyslog/manifests/database.pp', 'deployment/puppet/rsyslog/manifests/params.pp', 'deployment/puppet/rsyslog/templates/modload.erb', 'deployment/puppet/rsyslog/templates/01-client.conf.erb', 'deployment/puppet/rsyslog/spec/defines/rsyslog_snippet_spec.rb', 'deployment/puppet/rsyslog/manifests/imfile.pp', 'deployment/puppet/rsyslog/templates/rsyslog.conf.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c1de1caed9e2103cb41fa13947ed2ef5e10073a7', 'message': 'Merge saz-rsyslog\n\ne6dddeec8b71cda20d3a682af7b973e3027f4f01 v3.4.0\n\nChange-Id: I8cf604951fce7cb56a42b0e2f64c5bc175b8619d\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",0,146277,c1de1caed9e2103cb41fa13947ed2ef5e10073a7,35,4,4,11090,,,0,"Merge saz-rsyslog

e6dddeec8b71cda20d3a682af7b973e3027f4f01 v3.4.0

Change-Id: I8cf604951fce7cb56a42b0e2f64c5bc175b8619d
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/77/146277/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/rsyslog/.fixtures.yml', 'deployment/puppet/rsyslog/manifests/client.pp', 'deployment/puppet/rsyslog/templates/rsyslog.erb', 'deployment/puppet/rsyslog/.gitignore', 'deployment/puppet/rsyslog/.gemfile', 'deployment/puppet/rsyslog/README.md', 'deployment/puppet/rsyslog/metadata.json', 'deployment/puppet/rsyslog/spec/classes/rsyslog_client_spec.rb', 'deployment/puppet/rsyslog/manifests/modload.pp', 'deployment/puppet/rsyslog/lib/facter/rsyslog_version.rb', 'deployment/puppet/rsyslog/spec/classes/rsyslog_database_spec.rb', 'deployment/puppet/rsyslog/spec/classes/rsyslog_spec.rb', 'deployment/puppet/rsyslog/spec/classes/rsyslog_server_spec.rb', 'deployment/puppet/rsyslog/.travis.yml', 'deployment/puppet/rsyslog/manifests/config.pp', 'deployment/puppet/rsyslog/templates/database.conf.erb', 'deployment/puppet/rsyslog/tests/log_templates.pp', 'deployment/puppet/rsyslog/templates/rsyslog_default.erb', 'deployment/puppet/rsyslog/files/rsyslog_default', 'deployment/puppet/rsyslog/templates/client.conf.erb', 'deployment/puppet/rsyslog/templates/server-hostname.conf.erb', 'deployment/puppet/rsyslog/templates/server-default.conf.erb', 'deployment/puppet/rsyslog/manifests/server.pp', 'deployment/puppet/rsyslog/Rakefile', 'deployment/puppet/rsyslog/tests/multiple_hosts.pp', 'deployment/puppet/rsyslog/manifests/init.pp', 'deployment/puppet/rsyslog/manifests/install.pp', 'deployment/puppet/rsyslog/spec/spec_helper.rb', 'deployment/puppet/rsyslog/templates/imfile.erb', 'deployment/puppet/rsyslog/templates/server/_default-header.conf.erb', 'deployment/puppet/rsyslog/manifests/service.pp', 'deployment/puppet/rsyslog/tests/database.pp', 'deployment/puppet/rsyslog/manifests/snippet.pp', 'deployment/puppet/rsyslog/templates/server/_default-footer.conf.erb', 'deployment/puppet/rsyslog/templates/00-server.conf.erb', 'deployment/puppet/rsyslog/Modulefile', 'deployment/puppet/rsyslog/examples/site.pp', 'deployment/puppet/rsyslog/templates/rsyslog_default_gentoo.erb', 'deployment/puppet/rsyslog/LICENSE', 'deployment/puppet/rsyslog/.project', 'deployment/puppet/rsyslog/spec/defines/rsyslog_imfile_spec.rb', 'deployment/puppet/rsyslog/manifests/database.pp', 'deployment/puppet/rsyslog/manifests/params.pp', 'deployment/puppet/rsyslog/templates/modload.erb', 'deployment/puppet/rsyslog/templates/01-client.conf.erb', 'deployment/puppet/rsyslog/spec/defines/rsyslog_snippet_spec.rb', 'deployment/puppet/rsyslog/manifests/imfile.pp', 'deployment/puppet/rsyslog/templates/rsyslog_default_rhel7.erb', 'deployment/puppet/rsyslog/templates/rsyslog.conf.erb']",49,57f98d9243adf82644f8632610a93043ed957d17,merge-rsyslog,<% if scope.lookupvar('rsyslog::preserve_fqdn') -%> $PreserveFQDN on <% end -%><% scope.lookupvar('rsyslog::modules').each do |module_row| -%> <%= module_row %> <% end -%># # Set max message size for sending and receiving # $MaxMessageSize <%= scope.lookupvar('rsyslog::max_message_size') %>$FileOwner <%= scope.lookupvar('rsyslog::log_user') %> $FileGroup <%= scope.lookupvar('rsyslog::log_group') %> $FileCreateMode <%= scope.lookupvar('rsyslog::perm_file') %> $DirOwner <%= scope.lookupvar('rsyslog::log_user') %> $DirGroup <%= scope.lookupvar('rsyslog::log_group') %> $DirCreateMode <%= scope.lookupvar('rsyslog::perm_dir') %> $PrivDropToUser <%= scope.lookupvar('rsyslog::run_user') %> $PrivDropToGroup <%= scope.lookupvar('rsyslog::run_group') %> <% if scope.lookupvar('rsyslog::umask') -%> $Umask <%= scope.lookupvar('rsyslog::umask') %> <% end -%># Include all config files in <%= scope.lookupvar('rsyslog::rsyslog_d') %>$IncludeConfig <%= scope.lookupvar('rsyslog::rsyslog_d') -%>*.conf # # Emergencies are sent to everybody logged in. # <% if @rsyslog_version and @rsyslog_version.split('.')[0].to_i >= 8 -%> *.emerg :omusrmsg:* <% else -%> *.emerg * <% end -%>,$ModLoad imuxsock # provides support for local system logging $ModLoad imklog # provides kernel logging support (previously done by rklogd) #$ModLoad immark # provides --MARK-- message capability$FileOwner <%= scope.lookupvar('rsyslog::params::log_user') %> $FileGroup <%= scope.lookupvar('rsyslog::params::log_group') %> $FileCreateMode 0640 $DirCreateMode 0755 $PrivDropToUser <%= scope.lookupvar('rsyslog::params::run_user') %> $PrivDropToGroup <%= scope.lookupvar('rsyslog::params::run_group') %> $MaxMessageSize 32k# Include all config files in <%= scope.lookupvar('rsyslog::params::rsyslog_d') %>$IncludeConfig <%= scope.lookupvar('rsyslog::params::rsyslog_d') -%>*.conf ,3121,435
openstack%2Fmanila~master~Ibe9cb2321936c3dcecbb61bc23a7c5c6d9e90bd4,openstack/manila,master,Ibe9cb2321936c3dcecbb61bc23a7c5c6d9e90bd4,Remove unused contrib/ci files,MERGED,2015-06-08 07:22:36.000000000,2015-06-10 19:12:42.000000000,2015-06-10 19:12:40.000000000,"[{'_account_id': 3}, {'_account_id': 7102}, {'_account_id': 7872}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 13515}, {'_account_id': 14232}, {'_account_id': 15100}]","[{'number': 1, 'created': '2015-06-08 07:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d36a25e7e65da766eee08110c43b341bf5ebf5c9', 'message': 'Remove unused contrib/ci files\n\nFiles located in contrib/ci/multi_backend are unused. So, remove it.\n\nChange-Id: Ibe9cb2321936c3dcecbb61bc23a7c5c6d9e90bd4\n'}, {'number': 2, 'created': '2015-06-08 08:33:45.000000000', 'files': ['contrib/ci/multi_backend/post_test_hook.sh', 'contrib/ci/multi_backend/pre_test_hook.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/9d6ae07585e5adb3e65c4b980397b958cb734dfc', 'message': 'Remove unused contrib/ci files\n\nFiles located in contrib/ci/multi_backend are unused. So, remove it.\n\nChange-Id: Ibe9cb2321936c3dcecbb61bc23a7c5c6d9e90bd4\n'}]",0,189211,9d6ae07585e5adb3e65c4b980397b958cb734dfc,17,9,2,8851,,,0,"Remove unused contrib/ci files

Files located in contrib/ci/multi_backend are unused. So, remove it.

Change-Id: Ibe9cb2321936c3dcecbb61bc23a7c5c6d9e90bd4
",git fetch https://review.opendev.org/openstack/manila refs/changes/11/189211/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/ci/multi_backend/post_test_hook.sh', 'contrib/ci/multi_backend/pre_test_hook.sh']",2,d36a25e7e65da766eee08110c43b341bf5ebf5c9,,,"#!/bin/bash -xe # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # This script is executed inside pre_test_hook function in devstack gate. # Call common pre_test_hook source $BASE/new/manila/contrib/ci/pre_test_hook.sh ",0,35
openstack%2Fopenstack-ansible~master~Ia8c0b8be67fd0f479c492d9919b542806f9b204f,openstack/openstack-ansible,master,Ia8c0b8be67fd0f479c492d9919b542806f9b204f,Allow Horizon to access multiple regions,MERGED,2015-06-10 11:09:03.000000000,2015-06-10 19:07:32.000000000,2015-06-10 16:56:21.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-10 11:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/67db24bfba81c55956c11023149ef457006d787b', 'message': '[WIP] Allow Horizon to access multiple regions\n\nThis patch introduces the capability for Horizon to access\nmultiple regions.\n\nThis only takes effect if horizon_available_regions is defined,\notherwise the current default comment is applied to the\nlocal_settings file.\n\nUsage is described via comments in the role defaults and in the\netc/openstack_deploy/user_variables.yml file.\n\nChange-Id: Ia8c0b8be67fd0f479c492d9919b542806f9b204f\n'}, {'number': 2, 'created': '2015-06-10 11:33:58.000000000', 'files': ['playbooks/roles/os_horizon/defaults/main.yml', 'etc/openstack_deploy/user_variables.yml', 'playbooks/roles/os_horizon/templates/horizon_local_settings.py.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a274b2287110e18791e76e77ab71176a225ed315', 'message': 'Allow Horizon to access multiple regions\n\nThis patch introduces the capability for Horizon to access\nmultiple regions.\n\nThis only takes effect if horizon_available_regions is defined,\notherwise the current default comment is applied to the\nlocal_settings file.\n\nUsage is described via comments in the role defaults and in the\netc/openstack_deploy/user_variables.yml file.\n\nChange-Id: Ia8c0b8be67fd0f479c492d9919b542806f9b204f\n'}]",3,190118,a274b2287110e18791e76e77ab71176a225ed315,14,5,2,6816,,,0,"Allow Horizon to access multiple regions

This patch introduces the capability for Horizon to access
multiple regions.

This only takes effect if horizon_available_regions is defined,
otherwise the current default comment is applied to the
local_settings file.

Usage is described via comments in the role defaults and in the
etc/openstack_deploy/user_variables.yml file.

Change-Id: Ia8c0b8be67fd0f479c492d9919b542806f9b204f
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/18/190118/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_horizon/defaults/main.yml', 'etc/openstack_deploy/user_variables.yml', 'playbooks/roles/os_horizon/templates/horizon_local_settings.py.j2']",3,67db24bfba81c55956c11023149ef457006d787b,bug/1463772,"{% if horizon_available_regions is defined %} # Set the regions accessible through Horizon AVAILABLE_REGIONS = [ {% for key, value in horizon_available_regions.iteritems() %} ('{{ value.url }}', '{{ value.name }}'), {% endfor %} ] {% else %}{% endif %}",,23,0
openstack%2Fswift~feature%2Fhummingbird~I8fd8825a93a177871bce941b196b7be7079f11a1,openstack/swift,feature/hummingbird,I8fd8825a93a177871bce941b196b7be7079f11a1,go: fix output of /recon/mounted,MERGED,2015-06-10 03:51:27.000000000,2015-06-10 19:00:08.000000000,2015-06-10 19:00:06.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 1009}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-06-10 03:51:27.000000000', 'files': ['go/hummingbird/recon_test.go', 'go/hummingbird/recon.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/222d8d322d2b189beddd849011a24e1064249930', 'message': ""go: fix output of /recon/mounted\n\n/recon/mounted didn't match swift's, which made drivescout not work.\n\nChange-Id: I8fd8825a93a177871bce941b196b7be7079f11a1\n""}]",0,190012,222d8d322d2b189beddd849011a24e1064249930,9,4,1,2828,,,0,"go: fix output of /recon/mounted

/recon/mounted didn't match swift's, which made drivescout not work.

Change-Id: I8fd8825a93a177871bce941b196b7be7079f11a1
",git fetch https://review.opendev.org/openstack/swift refs/changes/12/190012/1 && git format-patch -1 --stdout FETCH_HEAD,"['go/hummingbird/recon_test.go', 'go/hummingbird/recon.go']",2,222d8d322d2b189beddd849011a24e1064249930,drivescout," results = append(results, map[string]string{""device"": vals[0], ""path"": vals[1]})"," results = append(results, map[string]string{vals[0]: vals[1]})",13,1
openstack%2Fpuppet-glance~master~I885a11fd33577618138ddffaf0de196e7bb62a77,openstack/puppet-glance,master,I885a11fd33577618138ddffaf0de196e7bb62a77,"The package python-ceph no longer exists in el7, use python-rbd.",MERGED,2015-06-03 22:53:30.000000000,2015-06-10 18:56:12.000000000,2015-06-10 18:56:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 7984}, {'_account_id': 8482}, {'_account_id': 13564}, {'_account_id': 14496}]","[{'number': 1, 'created': '2015-06-03 22:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/c71c8eb793dbbdc44a8bd2ba5a8fd37ba63bf666', 'message': 'The package python-ceph no longer exists, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 2, 'created': '2015-06-03 23:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9cca82abbfc3864321b2487c4f5b54418f36522a', 'message': 'The package python-ceph no longer exists, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 3, 'created': '2015-06-03 23:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9d0f957fbd175ccde17bfad9db6c85e44c14d8b6', 'message': 'The package python-ceph no longer exists, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 4, 'created': '2015-06-04 00:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/1fbda2270a0103e452e2de89b762fa7854a5af1a', 'message': 'The package python-ceph no longer exists in el7, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 5, 'created': '2015-06-04 01:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/41484ebdb824589d0121cec16477623c60050a29', 'message': 'The package python-ceph no longer exists in el7, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 6, 'created': '2015-06-08 16:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/698c85a345695dc5613ab61b9d21399f3b37f3e4', 'message': 'The package python-ceph no longer exists in el7, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 7, 'created': '2015-06-08 16:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/5069c2eade56179d891666cd98ea4787eb234987', 'message': 'The package python-ceph no longer exists in el7, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 8, 'created': '2015-06-08 17:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/5ba29fbdd434e485c1e1f33d0f40515ee8daacce', 'message': 'The package python-ceph no longer exists in el7, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}, {'number': 9, 'created': '2015-06-08 18:36:00.000000000', 'files': ['spec/classes/glance_backend_rbd_spec.rb', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/ef19c5584da92084c0c804392d6e0c3ac92c2ab9', 'message': 'The package python-ceph no longer exists in el7, use python-rbd.\n\nChange-Id: I885a11fd33577618138ddffaf0de196e7bb62a77\n'}]",3,188200,ef19c5584da92084c0c804392d6e0c3ac92c2ab9,41,7,9,13564,,,0,"The package python-ceph no longer exists in el7, use python-rbd.

Change-Id: I885a11fd33577618138ddffaf0de196e7bb62a77
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/00/188200/8 && git format-patch -1 --stdout FETCH_HEAD,['manifests/params.pp'],1,c71c8eb793dbbdc44a8bd2ba5a8fd37ba63bf666,python-ceph_rpm_name_change, $pyceph_package_name = 'python-rbd', $pyceph_package_name = 'python-ceph',1,1
openstack%2Fbifrost~master~Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900,openstack/bifrost,master,Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900,Add cookiecutter-generated files for project,MERGED,2015-06-05 22:41:25.000000000,2015-06-10 18:56:01.000000000,2015-06-10 18:55:59.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 11680}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-05 22:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1c6233e80cb0073cc7ddfa6c07deac625ec9a514', 'message': ""Add cookiecutter-generated files for project\n\nUse cookiecutter (https://git.openstack.org/openstack-dev/cookiecutter)\nto generate config for tox so we can generate docs, run pep8, etc.\nAlso move CONTRIBUTING.rst to the root of the repository in keeping\nwith what seems to be the standard location. This move allows us to\neasily generate the docs. NB - pep8 will not run cleanly yet, and I\nanticipate that we'll want to change the default rules to be ignored\nto be more in line with ironic itself.\n\nChange-Id: Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900\n""}, {'number': 2, 'created': '2015-06-08 20:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/741474a9bedebb30b0015f6b8e59501c32d95d44', 'message': ""Add cookiecutter-generated files for project\n\nUse cookiecutter (https://git.openstack.org/openstack-dev/cookiecutter)\nto generate config for tox so we can generate docs, run pep8, etc.\nAlso move CONTRIBUTING.rst to the root of the repository in keeping\nwith what seems to be the standard location. This move allows us to\neasily generate the docs. NB - pep8 will not run cleanly yet, and I\nanticipate that we'll want to change the default rules to be ignored\nto be more in line with ironic itself.\n\nChange-Id: Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900\n""}, {'number': 3, 'created': '2015-06-08 23:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/90103081f750f1344b5c33a6b86d2609f30dc374', 'message': 'Add cookiecutter-generated files for project\n\nUse cookiecutter (https://git.openstack.org/openstack-dev/cookiecutter)\nto generate config for tox so we can generate docs, run pep8, etc.\nAlso move CONTRIBUTING.rst to the root of the repository in keeping\nwith what seems to be the standard location. This move allows us to\neasily generate the docs. Also include a tiny fix to allow pep8 to\nrun cleanly.\n\nChange-Id: Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900\n'}, {'number': 4, 'created': '2015-06-09 20:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/267133a2bf641cd5b5f81df85337f891eaeff0ef', 'message': 'Add cookiecutter-generated files for project\n\nUse cookiecutter (https://git.openstack.org/openstack-dev/cookiecutter)\nto generate config for tox so we can generate docs, run pep8, etc.\nAlso move CONTRIBUTING.rst to the root of the repository in keeping\nwith what seems to be the standard location. This move allows us to\neasily generate the docs. Also include a tiny fix to allow pep8 to\nrun cleanly.\n\nChange-Id: Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900\n'}, {'number': 5, 'created': '2015-06-10 15:40:29.000000000', 'files': ['doc/source/contributing.rst', '.gitignore', 'test-requirements.txt', 'babel.cfg', 'setup.py', '.mailmap', 'doc/source/conf.py', 'MANIFEST.in', 'CONTRIBUTING.rst', 'doc/source/index.rst', 'requirements.txt', 'openstack-common.conf', 'doc/source/readme.rst', 'playbooks/library/os_ironic_node.py', 'setup.cfg', 'tox.ini', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/2a9d49d9bc916e2e3d220ccbc288f8c7a31e3827', 'message': 'Add cookiecutter-generated files for project\n\nUse cookiecutter (https://git.openstack.org/openstack-dev/cookiecutter)\nto generate config for tox so we can generate docs, run pep8, etc.\nAlso move CONTRIBUTING.rst to the root of the repository in keeping\nwith what seems to be the standard location. This move allows us to\neasily generate the docs. Also include a tiny fix to allow pep8 to\nrun cleanly.\n\nChange-Id: Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900\n'}]",14,188959,2a9d49d9bc916e2e3d220ccbc288f8c7a31e3827,26,5,5,12459,,,0,"Add cookiecutter-generated files for project

Use cookiecutter (https://git.openstack.org/openstack-dev/cookiecutter)
to generate config for tox so we can generate docs, run pep8, etc.
Also move CONTRIBUTING.rst to the root of the repository in keeping
with what seems to be the standard location. This move allows us to
easily generate the docs. Also include a tiny fix to allow pep8 to
run cleanly.

Change-Id: Ifbfc6d85c7b02bf4ab989974b491a3a1ae6f0900
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/59/188959/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributing.rst', '.gitignore', 'test-requirements.txt', 'babel.cfg', 'setup.py', '.mailmap', 'doc/source/conf.py', 'MANIFEST.in', 'CONTRIBUTING.rst', 'doc/source/index.rst', 'requirements.txt', 'openstack-common.conf', 'doc/source/readme.rst', 'setup.cfg', 'tox.ini', 'HACKING.rst']",16,1c6233e80cb0073cc7ddfa6c07deac625ec9a514,cookiecutter-things,bifrost Style Commandments =============================================== Read the OpenStack Style Commandments http://docs.openstack.org/developer/hacking/ ,,307,2
openstack%2Fbarbican~master~Ic07993fae58f300400d12bfc019db74c89581adb,openstack/barbican,master,Ic07993fae58f300400d12bfc019db74c89581adb,Changes to fix dogtag nss db handling,MERGED,2015-06-08 17:38:59.000000000,2015-06-10 18:55:58.000000000,2015-06-10 18:55:56.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-06-08 17:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/bc4a4c95013774cd0bdd1313e63773c0a31401fa', 'message': 'Changes to fix dogtag nss db handling - TESTING DO NOT MERGE\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 2, 'created': '2015-06-08 19:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/00d793fb4e1f5ea811557bc57462e1b08c867732', 'message': 'Changes to fix dogtag nss db handling - TESTING DO NOT MERGE\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 3, 'created': '2015-06-08 20:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e85b26553be1d5e3768dc7beb11b9fcc4633b911', 'message': 'Changes to fix dogtag nss db handling - TESTING DO NOT MERGE\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 4, 'created': '2015-06-09 07:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6ec8bd74a9186155b23841b3b3330c14ca9ba7f7', 'message': 'Changes to fix dogtag nss db handling - TESTING DO NOT MERGE\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 5, 'created': '2015-06-09 11:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8be1fb1c73303356aae94131aa31953718468278', 'message': 'Changes to fix dogtag nss db handling - TESTING DO NOT MERGE\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 6, 'created': '2015-06-10 06:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/01242cefd7c2b51a5255bb4fe183c54bd87db356', 'message': 'Changes to fix dogtag nss db handling - TESTING DO NOT MERGE\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 7, 'created': '2015-06-10 07:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ebb748df65b2d30080deb1b1ebe52ac5cb24df1c', 'message': 'Changes to fix dogtag nss db handling\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 8, 'created': '2015-06-10 08:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3e8e3efc3b19303d2e6c71f1e0b79ef6b590c36e', 'message': 'Changes to fix dogtag nss db handling\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 9, 'created': '2015-06-10 09:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/62b31be70c56301ac0f078c56c6149ac2469f366', 'message': 'Changes to fix dogtag nss db handling\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}, {'number': 10, 'created': '2015-06-10 10:19:36.000000000', 'files': ['barbican/plugin/dogtag.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/7b9dfa76ffa39f9e12657309e61a2e35a6b292bb', 'message': 'Changes to fix dogtag nss db handling\n\nChange-Id: Ic07993fae58f300400d12bfc019db74c89581adb\n'}]",2,189379,7b9dfa76ffa39f9e12657309e61a2e35a6b292bb,51,13,10,9914,,,0,"Changes to fix dogtag nss db handling

Change-Id: Ic07993fae58f300400d12bfc019db74c89581adb
",git fetch https://review.opendev.org/openstack/barbican refs/changes/79/189379/10 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/dogtag.py'],1,bc4a4c95013774cd0bdd1313e63773c0a31401fa,alee_fix_dogtag_certdb," help=u._('Path to the NSS certificate database')),def setup_nss_db(conf): nss_db_path = conf.dogtag_plugin.nss_db_path if create_nss_db: import_transport_cert(conf, crypto) return crypto def import_transport_cert(conf, crypto): try: connection = create_connection(conf, 'kra') kraclient = pki.kra.KRAClient(connection, crypto) systemcert_client = kraclient.system_certs transport_cert = systemcert_client.get_transport_cert() crypto.import_cert(DogtagKRAPlugin.TRANSPORT_NICK, transport_cert, ""u,u,u"") except Exception as e: LOG.debug(""Error in importing transport cert."" "" KRA may not be enabled: "" + e)# initialize the NSS DB crypto = setup_nss_db(CONF) crypto.initialize() self.keyclient.set_transport_cert( DogtagKRAPlugin.TRANSPORT_NICK)"," help=u._('Path to the NSS certificate database for the KRA')), cfg.StrOpt('nss_db_path_ca', help=u._('Path to the NSS certificate database for the CA')),def setup_nss_db(conf, subsystem): if subsystem == 'ca': nss_db_path = conf.dogtag_plugin.nss_db_path_ca else: nss_db_path = conf.dogtag_plugin.nss_db_path return crypto, create_nss_db crypto, create_nss_db = setup_nss_db(conf, 'kra') self.systemcert_client = kraclient.system_certs if crypto is not None: if create_nss_db: self.import_transport_cert(crypto) crypto.initialize() self.keyclient.set_transport_cert( DogtagKRAPlugin.TRANSPORT_NICK) def import_transport_cert(self, crypto): # Get transport cert and insert in the certdb transport_cert = self.systemcert_client.get_transport_cert() crypto.import_cert(DogtagKRAPlugin.TRANSPORT_NICK, transport_cert, ""u,u,u"") crypto, create_nss_db = setup_nss_db(conf, 'ca') if crypto is not None: crypto.initialize() ",27,30
openstack%2Fheat~master~I8a069275d5ea3f3913b6f8ae8c6fc48b69861551,openstack/heat,master,I8a069275d5ea3f3913b6f8ae8c6fc48b69861551,Move the heat_keystoneclient_v2 contrib package,MERGED,2015-06-10 01:00:20.000000000,2015-06-10 18:55:16.000000000,2015-06-10 18:55:14.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-10 01:00:20.000000000', 'files': ['contrib/rackspace/heat_keystoneclient_v2/tests/test_client.py', 'contrib/rackspace/heat_keystoneclient_v2/client.py', 'contrib/heat_keystoneclient_v2/setup.cfg', 'contrib/heat_keystoneclient_v2/README.md', 'contrib/rackspace/heat_keystoneclient_v2/__init__.py', 'contrib/rackspace/setup.cfg', 'contrib/heat_keystoneclient_v2/setup.py', 'contrib/rackspace/README.md', 'contrib/rackspace/heat_keystoneclient_v2/tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e7d9c4dfe2c0af9ec536d2ac237268cb92602ac5', 'message': 'Move the heat_keystoneclient_v2 contrib package\n\nAs discussed in the Vancouver summit, the only known user of the\nheat_keystoneclient_v2 contrib package is Rackspace, so it was agreed to\nmerge it with contrib/rackspace package.\n\nChange-Id: I8a069275d5ea3f3913b6f8ae8c6fc48b69861551\n'}]",0,189991,e7d9c4dfe2c0af9ec536d2ac237268cb92602ac5,10,6,1,12606,,,0,"Move the heat_keystoneclient_v2 contrib package

As discussed in the Vancouver summit, the only known user of the
heat_keystoneclient_v2 contrib package is Rackspace, so it was agreed to
merge it with contrib/rackspace package.

Change-Id: I8a069275d5ea3f3913b6f8ae8c6fc48b69861551
",git fetch https://review.opendev.org/openstack/heat refs/changes/91/189991/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/rackspace/heat_keystoneclient_v2/tests/test_client.py', 'contrib/rackspace/heat_keystoneclient_v2/client.py', 'contrib/heat_keystoneclient_v2/setup.cfg', 'contrib/heat_keystoneclient_v2/README.md', 'contrib/rackspace/heat_keystoneclient_v2/__init__.py', 'contrib/rackspace/setup.cfg', 'contrib/heat_keystoneclient_v2/setup.py', 'contrib/rackspace/README.md', 'contrib/rackspace/heat_keystoneclient_v2/tests/__init__.py']",9,e7d9c4dfe2c0af9ec536d2ac237268cb92602ac5,contrib-move-keystoneclient_v2,,,33,90
openstack%2Fheat~master~I7b4a177fde0b3acf7ea55a44e9fc60e716c0f7b1,openstack/heat,master,I7b4a177fde0b3acf7ea55a44e9fc60e716c0f7b1,Add explicit return to _get_property_value(),MERGED,2015-06-10 13:10:59.000000000,2015-06-10 18:53:17.000000000,2015-06-10 18:53:15.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 8833}, {'_account_id': 9408}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-10 13:10:59.000000000', 'files': ['heat/engine/properties.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/435ee13dd3e74590d58f4376788ba5a0875e0049', 'message': ""Add explicit return to _get_property_value()\n\nThis doesn't change behaviour - it was implicitly returning None before -\nbut it makes the code a lot easier to read because it is now clear that we\ncan return None if the property is not required, does not have a default,\nand is not specified by the user.\n\nChange-Id: I7b4a177fde0b3acf7ea55a44e9fc60e716c0f7b1\n""}]",0,190182,435ee13dd3e74590d58f4376788ba5a0875e0049,11,6,1,4257,,,0,"Add explicit return to _get_property_value()

This doesn't change behaviour - it was implicitly returning None before -
but it makes the code a lot easier to read because it is now clear that we
can return None if the property is not required, does not have a default,
and is not specified by the user.

Change-Id: I7b4a177fde0b3acf7ea55a44e9fc60e716c0f7b1
",git fetch https://review.opendev.org/openstack/heat refs/changes/82/190182/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/properties.py'],1,435ee13dd3e74590d58f4376788ba5a0875e0049,, else: return None,,2,0
openstack%2Fnova~master~Ic342025815b92db3d427b44fadfe906937f32520,openstack/nova,master,Ic342025815b92db3d427b44fadfe906937f32520,Improve formatting of rest_api_version_history,MERGED,2015-06-10 15:54:13.000000000,2015-06-10 18:53:01.000000000,2015-06-10 18:52:57.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-10 15:54:13.000000000', 'files': ['nova/api/openstack/rest_api_version_history.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/ce5e0b9a2f3a8bea948c8475e161ea5c90e87841', 'message': ""Improve formatting of rest_api_version_history\n\nAs this document will inevitably be referenced a lot by users who are\ntrying to figure out what version 2.12 means, this document should be\neasy as possible to navigate.\n\n* DON'T PUT THE TITLE IN ALL CAPITALS\n* Make each microversion a subtitle, so they come up as links in the\n  table of contents\n* Differentiate prose versus code.\n\nChange-Id: Ic342025815b92db3d427b44fadfe906937f32520\n""}]",0,190241,ce5e0b9a2f3a8bea948c8475e161ea5c90e87841,13,9,1,1849,,,0,"Improve formatting of rest_api_version_history

As this document will inevitably be referenced a lot by users who are
trying to figure out what version 2.12 means, this document should be
easy as possible to navigate.

* DON'T PUT THE TITLE IN ALL CAPITALS
* Make each microversion a subtitle, so they come up as links in the
  table of contents
* Differentiate prose versus code.

Change-Id: Ic342025815b92db3d427b44fadfe906937f32520
",git fetch https://review.opendev.org/openstack/nova refs/changes/41/190241/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/rest_api_version_history.rst'],1,ce5e0b9a2f3a8bea948c8475e161ea5c90e87841,microversion,"REST API Version History2.1 ---- A user can specify a header in the API request:: X-OpenStack-Nova-API-Version: <version> where ``<version>`` is any valid api version for this API.2.2 --- A user can request the creation of a certain 'type' of keypair (``ssh`` or ``x509``) in the ``os-keypairs`` plugin If no keypair type is specified, then the default ``ssh`` type of keypair is Fixes status code for ``os-keypairs`` create method from 200 to 201 Fixes status code for ``os-keypairs`` delete method from 202 to 204 2.3 --- Exposed additional attributes in ``os-extended-server-attributes``: ``reservation_id``, ``launch_index``, ``ramdisk_id``, ``kernel_id``, ``hostname``, ``root_device_name``, ``userdata``. Exposed ``delete_on_termination`` for ``attached_volumes`` in ``os-extended-volumes``.","REST API VERSION HISTORY- **2.1** A user can specify a header in the API request: X-OpenStack-Nova-API-Version: <version> where <version> is any valid api version for this API.- **2.2** A user can request the creation of a certain 'type' of keypair (ssh or x509) in the os-keypairs plugin If no keypair type is specified, then the default 'ssh' type of keypair is Fixes status code for os-keypairs create method from 200 to 201 Fixes status code for os-keypairs delete method from 202 to 204 - **2.3** Exposed additional attributes in os-extended-server-attributes: reservation_id, launch_index, ramdisk_id, kernel_id, hostname, root_device_name, userdata. Exposed delete_on_termination for attached_volumes in os-extended-volumes.",19,16
openstack%2Fnova~master~I270944bf9739b113a43b932948fdbf83e449603b,openstack/nova,master,I270944bf9739b113a43b932948fdbf83e449603b,Link to microversion history in docs,MERGED,2015-06-10 15:54:13.000000000,2015-06-10 18:52:39.000000000,2015-06-10 18:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-10 15:54:13.000000000', 'files': ['doc/source/index.rst', 'doc/source/api_microversion_history.rst', 'doc/source/api_microversion_dev.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/61d48c5f47932d010a898093664506417c76b995', 'message': ""Link to microversion history in docs\n\nMake the API microversion history more accessible by adding it to nova's\ndoc landing page.\n\nMaking sure it is easy to discover what the difference between each\nmicroversion is fundamental piece of the microversion puzzle, so lets\nnot require end users to have to look through git.\n\nrename api_microversions.rst to api_microversion_dev.rst to clarify that\nit is about development and versus history.\n\nChange-Id: I270944bf9739b113a43b932948fdbf83e449603b\n""}]",0,190240,61d48c5f47932d010a898093664506417c76b995,13,9,1,1849,,,0,"Link to microversion history in docs

Make the API microversion history more accessible by adding it to nova's
doc landing page.

Making sure it is easy to discover what the difference between each
microversion is fundamental piece of the microversion puzzle, so lets
not require end users to have to look through git.

rename api_microversions.rst to api_microversion_dev.rst to clarify that
it is about development and versus history.

Change-Id: I270944bf9739b113a43b932948fdbf83e449603b
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/190240/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/api_microversion_history.rst', 'doc/source/api_microversion_dev.rst']",3,61d48c5f47932d010a898093664506417c76b995,microversion,,,11,1
openstack%2Fhorizon~master~Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5,openstack/horizon,master,Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5,"Add the column 'Shared' to firewall, policy and rules table",MERGED,2015-06-10 05:03:50.000000000,2015-06-10 18:47:46.000000000,2015-06-10 18:47:45.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 10442}, {'_account_id': 12525}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-06-10 05:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6a903b39b5c2bc34bc902c6bddbaac52c090a77a', 'message': ""Add the column 'Shared' to firewall rules table\n\nThe current implementation of firewall rules table does not display the\n'Shared' attribute and its value.This patch set adds a column to display\n'Shared' atribute and its value.\n\nChange-Id: Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5\nCloses-Bug: #1463658\n""}, {'number': 2, 'created': '2015-06-10 05:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/32a8166893c70a28fa1b765730054394a0729134', 'message': ""Add the column 'Shared' to firewall rules table\n\nThe current implementation of firewall rules table does not display the\n'Shared' attribute and its value.This patch set adds a column to display\n'Shared' atribute and its value.\n\nChange-Id: Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5\nCloses-Bug: #1463658\n""}, {'number': 3, 'created': '2015-06-10 05:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d0d7e55127d166667df115517e4ae8ebce76980a', 'message': ""Add the column 'Shared' to firewall rules table\n\nThe current implementation of firewall rules table does not display the\n'Shared' attribute and its value.This patch set adds a column to display\n'Shared' atribute and its value.\n\nChange-Id: Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5\nCloses-Bug: #1463658\n""}, {'number': 4, 'created': '2015-06-10 14:12:22.000000000', 'files': ['openstack_dashboard/dashboards/project/firewalls/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/92b9e4071a359b4516c1530af9cb74b7d5fa35e3', 'message': ""Add the column 'Shared' to firewall, policy and rules table\n\nThe current implementation of firewall resources table does not display the\n'Shared' attribute and its value.This patch set adds a column to display\n'Shared' atribute and its value.\n\nChange-Id: Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5\nCloses-Bug: #1463658\n""}]",2,190023,92b9e4071a359b4516c1530af9cb74b7d5fa35e3,17,7,4,12525,,,0,"Add the column 'Shared' to firewall, policy and rules table

The current implementation of firewall resources table does not display the
'Shared' attribute and its value.This patch set adds a column to display
'Shared' atribute and its value.

Change-Id: Ic688126c658c5a3fa7f1859e2eef0d53afec7ce5
Closes-Bug: #1463658
",git fetch https://review.opendev.org/openstack/horizon refs/changes/23/190023/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/firewalls/tables.py'],1,6a903b39b5c2bc34bc902c6bddbaac52c090a77a,bug/1463658," shared = tables.Column(""shared"", verbose_name=_(""Shared""), filters=(filters.yesno, filters.capfirst))",,4,0
openstack%2Fnova~master~I22eb056b0631104ecce98d84f73b3e18e1d40430,openstack/nova,master,I22eb056b0631104ecce98d84f73b3e18e1d40430,Remove unused instance_group_policy db calls,MERGED,2015-06-04 12:30:15.000000000,2015-06-10 18:47:39.000000000,2015-06-10 16:05:10.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8119}, {'_account_id': 8276}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-04 12:30:15.000000000', 'files': ['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ffee0df18c9342e4f98f82f6ccd0554636f8a411', 'message': 'Remove unused instance_group_policy db calls\n\nThe following db api methods were added in 2013 with\n501ff418df4c08e52a697772200aa08dd67a4a43 but never used.\n\ninstance_group_policies_add\ninstance_group_policy_delete\ninstance_group_policies_get\n\nChange-Id: I22eb056b0631104ecce98d84f73b3e18e1d40430\n'}]",0,188373,ffee0df18c9342e4f98f82f6ccd0554636f8a411,18,12,1,1849,,,0,"Remove unused instance_group_policy db calls

The following db api methods were added in 2013 with
501ff418df4c08e52a697772200aa08dd67a4a43 but never used.

instance_group_policies_add
instance_group_policy_delete
instance_group_policies_get

Change-Id: I22eb056b0631104ecce98d84f73b3e18e1d40430
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/188373/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",3,ffee0df18c9342e4f98f82f6ccd0554636f8a411,cleanup,,"def instance_group_policies_add(context, group_uuid, policies, set_delete=False): id = _instance_group_id(context, group_uuid) return _instance_group_policies_add(context, id, policies, set_delete=set_delete) def instance_group_policy_delete(context, group_uuid, policy): id = _instance_group_id(context, group_uuid) count = _instance_group_get_query(context, models.InstanceGroupPolicy, models.InstanceGroupPolicy.group_id, id).\ filter_by(policy=policy).\ soft_delete() if count == 0: raise exception.InstanceGroupPolicyNotFound(group_uuid=group_uuid, policy=policy) def instance_group_policies_get(context, group_uuid): id = _instance_group_id(context, group_uuid) policies = model_query(context, models.InstanceGroupPolicy, (models.InstanceGroupPolicy.policy,)).\ filter_by(group_id=id).all() return [policy[0] for policy in policies] ",0,103
openstack%2Fswift~feature%2Fhummingbird~Ie07fd64a6179f094fd422b31865bf868618017bf,openstack/swift,feature/hummingbird,Ie07fd64a6179f094fd422b31865bf868618017bf,go: ring self-reloading,MERGED,2015-05-31 02:37:23.000000000,2015-06-10 18:46:24.000000000,2015-06-10 18:46:22.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 995}, {'_account_id': 1009}, {'_account_id': 2622}, {'_account_id': 2828}, {'_account_id': 16206}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-05-31 02:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6ddcda92afcbb3147eb1dedc961e359378f442d0', 'message': 'go: ring self-reloading\n\nAdd automatic self-reloading to the ring.\nMostly requires cramming mutex locks everywhere.\n\nChange-Id: Ie07fd64a6179f094fd422b31865bf868618017bf\n'}, {'number': 2, 'created': '2015-05-31 02:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8625abcb1fc436d6eaa3b9f6b52be59cf10a735a', 'message': 'go: ring self-reloading\n\nAdd automatic self-reloading to the ring.\nMostly requires cramming mutex locks everywhere.\n\nChange-Id: Ie07fd64a6179f094fd422b31865bf868618017bf\n'}, {'number': 3, 'created': '2015-06-09 16:18:55.000000000', 'files': ['go/hummingbird/ring_test.go', 'go/hummingbird/ring.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/834c98bfc9f4d8d3abdd812d1a5189f7e9f0ccc1', 'message': 'go: ring self-reloading\n\nAdd automatic self-reloading to the ring.\n\nChange-Id: Ie07fd64a6179f094fd422b31865bf868618017bf\n'}]",0,187030,834c98bfc9f4d8d3abdd812d1a5189f7e9f0ccc1,24,8,3,2828,,,0,"go: ring self-reloading

Add automatic self-reloading to the ring.

Change-Id: Ie07fd64a6179f094fd422b31865bf868618017bf
",git fetch https://review.opendev.org/openstack/swift refs/changes/30/187030/1 && git format-patch -1 --stdout FETCH_HEAD,"['go/hummingbird/ring_test.go', 'go/hummingbird/ring.go']",2,6ddcda92afcbb3147eb1dedc961e359378f442d0,ringreload," ""sync"" ""time""const reloadTime = 15 * time.Second path string lock sync.RWMutex mtime, ctime time.Time r.reload() r.lock.RLock() defer r.lock.RUnlock() r.reload() r.lock.RLock() defer r.lock.RUnlock() r.reload() r.lock.RLock() defer r.lock.RUnlock() r.reload() r.lock.RLock() defer r.lock.RUnlock()func (r *hashRing) reload() error { if time.Since(r.ctime) < reloadTime { return nil } r.lock.Lock() defer r.lock.Unlock() r.ctime = time.Now() fi, err := os.Stat(r.path) if err != nil { return err } if fi.ModTime() == r.mtime { return nil } fp, err := os.Open(r.path) if err != nil { return err } gz, err := gzip.NewReader(fp) if err != nil { return err } magicBuf := make([]byte, 4) io.ReadFull(gz, magicBuf) if string(magicBuf) != ""R1NG"" { return errors.New(""Bad magic string"") } var ringVersion uint16 binary.Read(gz, binary.BigEndian, &ringVersion) if ringVersion != 1 { return fmt.Errorf(""Unknown ring version %d"", ringVersion) } var json_len uint32 binary.Read(gz, binary.BigEndian, &json_len) jsonBuf := make([]byte, json_len) io.ReadFull(gz, jsonBuf) if err := json.Unmarshal(jsonBuf, &r); err != nil { return err } partitionCount := 1 << (32 - r.PartShift) for i := 0; i < r.ReplicaCount; i++ { part2dev := make([]uint16, partitionCount) binary.Read(gz, binary.LittleEndian, &part2dev) r.replica2part2devId = append(r.replica2part2devId, part2dev) } regionCount := make(map[int]bool) zoneCount := make(map[regionZone]bool) ipPortCount := make(map[ipPort]bool) for _, d := range r.Devs { regionCount[d.Region] = true zoneCount[regionZone{d.Region, d.Zone}] = true ipPortCount[ipPort{d.Region, d.Zone, d.Port, d.Ip}] = true } r.regionCount = len(regionCount) r.zoneCount = len(zoneCount) r.ipPortCount = len(ipPortCount) r.mtime = fi.ModTime() r.ctime = time.Now() return nil } m.r.lock.RLock() defer m.r.lock.RUnlock() m.r.lock.RLock() defer m.r.lock.RUnlock() ring := &hashRing{prefix: prefix, suffix: suffix, path: path, mtime: time.Unix(0, 0), ctime: time.Unix(0, 0)} return ring, ring.reload() return nil, fmt.Errorf(""Error loading %s ring"", ring_type)"," fp, err := os.Open(path) if err != nil { if os.IsNotExist(err) { errMsg := fmt.Sprintf(""File at %s doesn't exists"", path) return nil, errors.New(errMsg) } else { return nil, err } } gz, err := gzip.NewReader(fp) if err != nil { return nil, err } magicBuf := make([]byte, 4) io.ReadFull(gz, magicBuf) if string(magicBuf) != ""R1NG"" { return nil, errors.New(""Bad magic string"") } var ringVersion uint16 binary.Read(gz, binary.BigEndian, &ringVersion) if ringVersion != 1 { return nil, errors.New(fmt.Sprintf(""Unknown ring version %d"", ringVersion)) } // TODO: assert ringVersion == 1 var json_len uint32 binary.Read(gz, binary.BigEndian, &json_len) jsonBuf := make([]byte, json_len) io.ReadFull(gz, jsonBuf) var ring hashRing json.Unmarshal(jsonBuf, &ring) ring.prefix = prefix ring.suffix = suffix partitionCount := 1 << (32 - ring.PartShift) for i := 0; i < ring.ReplicaCount; i++ { part2dev := make([]uint16, partitionCount) binary.Read(gz, binary.LittleEndian, &part2dev) ring.replica2part2devId = append(ring.replica2part2devId, part2dev) } regionCount := make(map[int]bool) zoneCount := make(map[regionZone]bool) ipPortCount := make(map[ipPort]bool) for _, d := range ring.Devs { regionCount[d.Region] = true zoneCount[regionZone{d.Region, d.Zone}] = true ipPortCount[ipPort{d.Region, d.Zone, d.Port, d.Ip}] = true } ring.regionCount = len(regionCount) ring.zoneCount = len(zoneCount) ring.ipPortCount = len(ipPortCount) return &ring, nil return nil, errors.New(fmt.Sprintf(""Error loading %s ring"", ring_type))",199,68
openstack%2Fnova~master~I68a1f1362318ae3d50793ed0d353bf609b01710c,openstack/nova,master,I68a1f1362318ae3d50793ed0d353bf609b01710c,Remove db layer hard-code permission checks for quota_destroy_all_*,MERGED,2015-03-01 23:41:36.000000000,2015-06-10 18:44:12.000000000,2015-06-10 18:44:09.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9459}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12175}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-01 23:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/08f39fa5fe041a02aa51dd9eaef2f25d41583d40', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp v3-api-policy\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 2, 'created': '2015-03-02 02:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47392ab57a2293aeffc13ddf11e7953759a0c5db', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp v3-api-policy\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 3, 'created': '2015-03-19 09:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/350fd98920a6cc20b8069bf0a6c0a6a4605bd0a7', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp v3-api-policy\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 4, 'created': '2015-04-23 05:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f1d2828095f83ab9665b624326e23a1c83c66643', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp v3-api-policy\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 5, 'created': '2015-04-23 05:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fafdd53bbda2f42ee790ec337ca7b0d561649e53', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 6, 'created': '2015-04-23 07:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6000f9af82927eb30500258692aa8175921fc1c6', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 7, 'created': '2015-05-05 00:42:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6bf514f661f3f50ffd7ed1e4247e5197433c01a', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 8, 'created': '2015-05-05 02:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69c18beca8ec724aa34d4f460debc63180009d61', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 9, 'created': '2015-05-07 03:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea3c923ed19415a4f2e781484390c2d51c45849f', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patches remove the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 10, 'created': '2015-05-07 05:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3cd165581a3176e663f79bbce8026154785b754', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patch removes the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}, {'number': 11, 'created': '2015-05-12 11:27:48.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/tests/unit/api/openstack/compute/contrib/test_quotas.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a853fb4ddc42f036c0dc562b2d150f6b670155d', 'message': 'Remove db layer hard-code permission checks for quota_destroy_all_*\n\nThis patch removes the hard-code permission checks for db call\nquota_destroy_all_by_project_and_user and quota_destroy_all_by_project.\n\nFor v2 API adds back-compatible checking. For v2.1 API, remove useless\nproject owner permission checks that should be done by policy.\n\nAnd correct related unittest. For v2.1 API, the unittest should use\nnon-admin context. For v2 API, the unitest keep as before and add\nnon-admin context test to ensure the v2 back-comaptible.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c\n'}]",8,160201,7a853fb4ddc42f036c0dc562b2d150f6b670155d,94,20,11,5754,,,0,"Remove db layer hard-code permission checks for quota_destroy_all_*

This patch removes the hard-code permission checks for db call
quota_destroy_all_by_project_and_user and quota_destroy_all_by_project.

For v2 API adds back-compatible checking. For v2.1 API, remove useless
project owner permission checks that should be done by policy.

And correct related unittest. For v2.1 API, the unittest should use
non-admin context. For v2 API, the unitest keep as before and add
non-admin context test to ensure the v2 back-comaptible.

Partially implements bp nova-api-policy-final-part

Change-Id: I68a1f1362318ae3d50793ed0d353bf609b01710c
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/160201/11 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/quota_sets.py', 'nova/tests/unit/api/openstack/compute/contrib/test_quotas.py', 'nova/api/openstack/compute/contrib/quotas.py', 'nova/db/sqlalchemy/api.py']",4,08f39fa5fe041a02aa51dd9eaef2f25d41583d40,bp/nova-api-policy-final-part,,@require_admin_context@require_admin_context,56,34
openstack%2Fnova~master~Iee40bf103d7586e89d5d3573b72086c67eb5324c,openstack/nova,master,Iee40bf103d7586e89d5d3573b72086c67eb5324c,Clean up Fake_Url for unit test of flavor_access,MERGED,2015-03-10 05:42:22.000000000,2015-06-10 18:43:47.000000000,2015-06-10 16:52:19.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8276}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12175}, {'_account_id': 13663}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-10 05:42:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7801577928efb4a59d14db2c93a13b5a8b7e83ef', 'message': 'Clean up Fake_Url for unit test of flavor_access\n\nSwitch _prefix from ""/v3"" to ""/v2/fake"", can be shared by\nv21 and v2\n\nPartially implements blueprint v2-on-v3-api\nChange-Id: Iee40bf103d7586e89d5d3573b72086c67eb5324c\n'}, {'number': 2, 'created': '2015-03-16 01:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e10b97a558f22182315e331a4cceea3da330a560', 'message': 'Clean up Fake_Url for unit test of flavor_access\n\nSwitch _prefix from ""/v3"" to ""/v2/fake"", can be shared by\nv21 and v2\n\nPartially implements blueprint v2-on-v3-api\nChange-Id: Iee40bf103d7586e89d5d3573b72086c67eb5324c\n'}, {'number': 3, 'created': '2015-06-10 05:29:01.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_flavor_access.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aa0191cbfae019a2b5bf3e02baed9a0b436164f6', 'message': 'Clean up Fake_Url for unit test of flavor_access\n\nSwitch _prefix from ""/v3"" to ""/v2/fake"", can be shared by\nv21 and v2\n\nPartially implements blueprint v2-on-v3-api\nChange-Id: Iee40bf103d7586e89d5d3573b72086c67eb5324c\n'}]",2,162869,aa0191cbfae019a2b5bf3e02baed9a0b436164f6,40,15,3,12175,,,0,"Clean up Fake_Url for unit test of flavor_access

Switch _prefix from ""/v3"" to ""/v2/fake"", can be shared by
v21 and v2

Partially implements blueprint v2-on-v3-api
Change-Id: Iee40bf103d7586e89d5d3573b72086c67eb5324c
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/162869/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/contrib/test_flavor_access.py'],1,7801577928efb4a59d14db2c93a13b5a8b7e83ef,bp/v2-on-v3-api," _prefix = ""/v2/fake"""," _prefix = ""/v3"" _prefix = ""/v2/fake""",1,2
openstack%2Fnova~master~I06f254fd9c8d8b6aac4ed135c6c407f3a993431f,openstack/nova,master,I06f254fd9c8d8b6aac4ed135c6c407f3a993431f,Add a hacking rule for consistent HTTP501 message,MERGED,2015-03-12 05:04:34.000000000,2015-06-10 18:43:44.000000000,2015-06-10 18:43:41.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 11103}, {'_account_id': 13663}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-12 05:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5afdc1cea1b8657af5c980fa550376724224719f', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_http_not_implemented_error() for returing a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 2, 'created': '2015-03-12 08:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a19650e6e0e643cd5956965e7f294a66133a2736', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_http_not_implemented_error() for returing a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 3, 'created': '2015-03-17 00:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68c423e8ceead6ca82229134983759aafc5212bc', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_http_not_implemented_error() for returing a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 4, 'created': '2015-03-17 08:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d9dcaf5a1eee9f7095cf12897be506b0b0c22bf', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_http_not_implemented_error() for returing a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 5, 'created': '2015-03-19 22:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b448a5905230cb4e799b5596e260db179a29e229', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_http_not_implemented_error() for returing a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 6, 'created': '2015-06-01 07:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf645ab6e7c86b7d4af1ceb584c25f463dba8f87', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_feature_not_supported() for returing a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 7, 'created': '2015-06-01 23:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a51bf4c23333a4a5d2083498b3ac26a03aa4cbc', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_feature_not_supported() for returning a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 8, 'created': '2015-06-02 02:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48f045a23b5d1e7979512659fc0f06b6d5964b07', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_feature_not_supported() for returning a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}, {'number': 9, 'created': '2015-06-08 03:18:37.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/unit/test_hacking.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/198a3bea231883251ef00596ddda625f33219efd', 'message': 'Add a hacking rule for consistent HTTP501 message\n\nThere is raise_feature_not_supported() for returning a HTTP501\nresponse with consistent error message, and this patch adds a rule\nfor enforcing to use the method on v2.1 API.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f\n'}]",8,163698,198a3bea231883251ef00596ddda625f33219efd,102,22,9,6167,,,0,"Add a hacking rule for consistent HTTP501 message

There is raise_feature_not_supported() for returning a HTTP501
response with consistent error message, and this patch adds a rule
for enforcing to use the method on v2.1 API.

Partially implements blueprint v2-on-v3-api

Change-Id: I06f254fd9c8d8b6aac4ed135c6c407f3a993431f
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/163698/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/unit/test_hacking.py', 'HACKING.rst']",3,5afdc1cea1b8657af5c980fa550376724224719f,bp/v2-on-v3-api,- [N339] Check common raise_http_not_implemented_error() is used for v2.1 HTTPNotImplemented response.,,34,0
openstack%2Fironic~master~Ice85ae4bb84d2f7c53759264812e5fbc29ac510f,openstack/ironic,master,Ice85ae4bb84d2f7c53759264812e5fbc29ac510f,Remove auth token saving from iLO driver,MERGED,2015-06-03 09:48:03.000000000,2015-06-10 18:43:37.000000000,2015-06-10 18:43:36.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 9315}, {'_account_id': 9751}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-06-03 09:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9fd7da5331a8e577eb430f31bbb585cb6581b38b', 'message': 'Remove auth token saving from iLO driver\n\nAfter I12cfdc0a8a7740cadd768068b91c258e028ef385 iSCSI deploying\ndoes not require Keystone token for ramdisk callback. This patch\nremoves token saving to virtual floppy image.\n\nChange-Id: Ice85ae4bb84d2f7c53759264812e5fbc29ac510f\n'}, {'number': 2, 'created': '2015-06-04 14:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/00d89376752a55347969339fc60223bd015d9b91', 'message': 'Remove auth token saving from iLO driver\n\nAfter I12cfdc0a8a7740cadd768068b91c258e028ef385 iSCSI deploying\ndoes not require Keystone token for ramdisk callback. This patch\nremoves token saving to virtual floppy image.\n\nChange-Id: Ice85ae4bb84d2f7c53759264812e5fbc29ac510f\n'}, {'number': 3, 'created': '2015-06-08 13:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5c4712ac054e6bf02a10b541d18ac0acfe9b0073', 'message': 'Remove auth token saving from iLO driver\n\nAfter I12cfdc0a8a7740cadd768068b91c258e028ef385 iSCSI deploying\ndoes not require Keystone token for ramdisk callback. This patch\nremoves token saving to virtual floppy image.\n\nChange-Id: Ice85ae4bb84d2f7c53759264812e5fbc29ac510f\n'}, {'number': 4, 'created': '2015-06-08 14:50:18.000000000', 'files': ['ironic/tests/drivers/ilo/test_common.py', 'ironic/drivers/modules/ilo/common.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/23407710ae56c9e2778798ce328f359494a2fac5', 'message': 'Remove auth token saving from iLO driver\n\nAfter I12cfdc0a8a7740cadd768068b91c258e028ef385 iSCSI deploying\ndoes not require Keystone token for ramdisk callback. This patch\nremoves token saving to virtual floppy image.\n\nChange-Id: Ice85ae4bb84d2f7c53759264812e5fbc29ac510f\n'}]",6,187924,23407710ae56c9e2778798ce328f359494a2fac5,33,9,4,7711,,,0,"Remove auth token saving from iLO driver

After I12cfdc0a8a7740cadd768068b91c258e028ef385 iSCSI deploying
does not require Keystone token for ramdisk callback. This patch
removes token saving to virtual floppy image.

Change-Id: Ice85ae4bb84d2f7c53759264812e5fbc29ac510f
",git fetch https://review.opendev.org/openstack/ironic refs/changes/24/187924/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/ilo/test_common.py', 'ironic/drivers/modules/ilo/common.py']",2,9fd7da5331a8e577eb430f31bbb585cb6581b38b,ilo-no-token," file into the image which containing the parameters to be passed to the ramdisk. Then it uploads the file to Swift in 'swift_ilo_container', setting it to auto-expire after 'swift_object_expiry_timeout' seconds. Then it returns the temp url for the Swift object. images.create_vfat_image(vfat_image_tmpfile, parameters=params)","from ironic.common import utils two files into the image - one containing the authentication token and the other containing the parameters to be passed to the ramdisk. Then it uploads the file to Swift in 'swift_ilo_container', setting it to auto-expire after 'swift_object_expiry_timeout' seconds. Then it returns the temp url for the Swift object. # If auth_strategy is noauth, then no need to write token into # the image file. if task.context.auth_token: with tempfile.NamedTemporaryFile() as token_tmpfile_obj: files_info = {} token_tmpfile = token_tmpfile_obj.name utils.write_to_file(token_tmpfile, task.context.auth_token) files_info[token_tmpfile] = 'token' images.create_vfat_image(vfat_image_tmpfile, files_info=files_info, parameters=params) else: images.create_vfat_image(vfat_image_tmpfile, parameters=params)",8,65
openstack%2Fironic~master~Ibe1dfd8748535c75040a8d8ef6d33d0791d022d1,openstack/ironic,master,Ibe1dfd8748535c75040a8d8ef6d33d0791d022d1,Doc: Use --notest for creating venv,MERGED,2015-06-10 00:20:50.000000000,2015-06-10 18:42:23.000000000,2015-06-10 18:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 9751}, {'_account_id': 10250}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 12356}]","[{'number': 1, 'created': '2015-06-10 00:20:50.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/286f72e359dcf3bc55efa872c178905b84cfb808', 'message': ""Doc: Use --notest for creating venv\n\nThe docs were saying to use:\n    tox -evenv -- echo 'done'\n\nWhich would create the virtualenv 'venv' but then error.\n\nUpdate the docs to do:\n    tox -evenv --notest\n\nChange-Id: Ibe1dfd8748535c75040a8d8ef6d33d0791d022d1\n""}]",0,189984,286f72e359dcf3bc55efa872c178905b84cfb808,13,7,1,14760,,,0,"Doc: Use --notest for creating venv

The docs were saying to use:
    tox -evenv -- echo 'done'

Which would create the virtualenv 'venv' but then error.

Update the docs to do:
    tox -evenv --notest

Change-Id: Ibe1dfd8748535c75040a8d8ef6d33d0791d022d1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/84/189984/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,286f72e359dcf3bc55efa872c178905b84cfb808,, tox -evenv --notest tox -evenv --notest tox -evenv --notest, tox -evenv -- echo 'done' tox -evenv -- echo 'done' tox -evenv -- echo 'done',3,3
openstack%2Fnova~master~Iadfe3a3870235705af458bb2d35d0569ba212291,openstack/nova,master,Iadfe3a3870235705af458bb2d35d0569ba212291,Hyper-V: sets supports_migrate_to_same_host capability,MERGED,2015-06-09 16:10:15.000000000,2015-06-10 18:42:05.000000000,2015-06-10 18:42:01.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11530}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-09 16:10:15.000000000', 'files': ['nova/virt/hyperv/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8895dca4588f8a196b7a7ee8d33dc117f73249ed', 'message': 'Hyper-V: sets supports_migrate_to_same_host capability\n\nCommit 9b224641295af3763d011816d6399565ac7b98de removed\nCONF.allow_migrate_to_same_host and introduced the\nsupports_migrate_to_same_host capability in compute drivers.\n\nThis commit adds the capability to the Hyper-V driver.\n\nChange-Id: Iadfe3a3870235705af458bb2d35d0569ba212291\nPartial-Bug: #1364851\n'}]",0,189798,8895dca4588f8a196b7a7ee8d33dc117f73249ed,30,12,1,3185,,,0,"Hyper-V: sets supports_migrate_to_same_host capability

Commit 9b224641295af3763d011816d6399565ac7b98de removed
CONF.allow_migrate_to_same_host and introduced the
supports_migrate_to_same_host capability in compute drivers.

This commit adds the capability to the Hyper-V driver.

Change-Id: Iadfe3a3870235705af458bb2d35d0569ba212291
Partial-Bug: #1364851
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/189798/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/hyperv/driver.py'],1,8895dca4588f8a196b7a7ee8d33dc117f73249ed,," capabilities = { ""has_imagecache"": False, ""supports_recreate"": False, ""supports_migrate_to_same_host"": True } ",,6,0
openstack%2Fkeystone~master~Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8,openstack/keystone,master,Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8,Switch keystone over to oslo_log versionutils,MERGED,2015-06-08 11:23:40.000000000,2015-06-10 18:35:55.000000000,2015-06-10 18:35:54.000000000,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 7725}]","[{'number': 1, 'created': '2015-06-08 11:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a4075aef7c386466a19cba48c915b24de9db765', 'message': ""Switch keystone over to oslo_log versionutils\n\nversionutils has graduated to oslo_log, let's switch our\nreferences to that one and drop the oslo-incubator copy of\nthe module\n\nChange-Id: Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8\n""}, {'number': 2, 'created': '2015-06-08 11:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8bff2acf17fac3cd758aa683bbf482f382263962', 'message': ""Switch keystone over to oslo_log versionutils\n\nversionutils has graduated to oslo_log, let's switch our\nreferences to that one and drop the oslo-incubator copy of\nthe module\n\nChange-Id: Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8\n""}, {'number': 3, 'created': '2015-06-10 11:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0d9897b601210b1c5dae167a159fc625083df2ed', 'message': ""Switch keystone over to oslo_log versionutils\n\nversionutils has graduated to oslo_log, let's switch our\nreferences to that one and drop the oslo-incubator copy of\nthe module\n\nChange-Id: Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8\n""}, {'number': 4, 'created': '2015-06-10 12:32:15.000000000', 'files': ['keystone/notifications.py', 'keystone/common/manager.py', 'keystone/middleware/core.py', 'keystone/contrib/endpoint_policy/routers.py', 'keystone/openstack/common/versionutils.py', 'keystone/contrib/revoke/core.py', 'keystone/contrib/endpoint_policy/backends/sql.py', 'keystone/token/providers/common.py', 'keystone/assignment/core.py', 'keystone/contrib/revoke/backends/kvs.py', 'keystone/trust/controllers.py', 'openstack-common.conf', 'keystone/tests/unit/test_backend_sql.py', 'keystone/common/kvs/legacy.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4991179523c625543f0a930e2da74c07da3c6716', 'message': ""Switch keystone over to oslo_log versionutils\n\nversionutils has graduated to oslo_log, let's switch our\nreferences to that one and drop the oslo-incubator copy of\nthe module\n\nChange-Id: Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8\n""}]",0,189267,4991179523c625543f0a930e2da74c07da3c6716,12,3,4,5638,,,0,"Switch keystone over to oslo_log versionutils

versionutils has graduated to oslo_log, let's switch our
references to that one and drop the oslo-incubator copy of
the module

Change-Id: Ib865fa31f1ace78d77951880ee8dfda9c2fd32e8
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/189267/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/notifications.py', 'keystone/auth/plugins/external.py', 'keystone/common/manager.py', 'keystone/middleware/core.py', 'keystone/contrib/endpoint_policy/routers.py', 'keystone/openstack/common/versionutils.py', 'keystone/contrib/revoke/core.py', 'keystone/contrib/endpoint_policy/backends/sql.py', 'keystone/token/providers/common.py', 'keystone/assignment/core.py', 'keystone/contrib/revoke/backends/kvs.py', 'keystone/trust/controllers.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/common/kvs/legacy.py', 'keystone/assignment/backends/ldap.py']",15,6a4075aef7c386466a19cba48c915b24de9db765,,from oslo_log import versionutils,from keystone.openstack.common import versionutils,17,277
openstack%2Fgrenade~master~I0492329d7c39279ccc6877a87eb3853ae423a99c,openstack/grenade,master,I0492329d7c39279ccc6877a87eb3853ae423a99c,Make rsync output less verbose,MERGED,2015-06-10 12:12:28.000000000,2015-06-10 18:35:53.000000000,2015-06-10 18:35:51.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2015-06-10 12:12:28.000000000', 'files': ['grenade.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/eee9efdb6c6d60e7b0b724a93287379a6936edf0', 'message': ""Make rsync output less verbose\n\nCurrently rsync output is very verbose. So drop the -v and -P flags.\n\n(search grenade.sh for 'sending incremental file list')\n\n-v, --verbose           increase verbosity\n-P                      same as --partial --progress\n--progress              show progress during transfer\n--partial               keep partially transferred files\n\nChange-Id: I0492329d7c39279ccc6877a87eb3853ae423a99c\n""}]",0,190143,eee9efdb6c6d60e7b0b724a93287379a6936edf0,8,4,1,1849,,,0,"Make rsync output less verbose

Currently rsync output is very verbose. So drop the -v and -P flags.

(search grenade.sh for 'sending incremental file list')

-v, --verbose           increase verbosity
-P                      same as --partial --progress
--progress              show progress during transfer
--partial               keep partially transferred files

Change-Id: I0492329d7c39279ccc6877a87eb3853ae423a99c
",git fetch https://review.opendev.org/openstack/grenade refs/changes/43/190143/1 && git format-patch -1 --stdout FETCH_HEAD,['grenade.sh'],1,eee9efdb6c6d60e7b0b724a93287379a6936edf0,rsync, rsync -a $BASE_DEVSTACK_DIR/files/$IMAGE_FNAME $BASE_RELEASE_DIR/images rsync -a $BASE_DEVSTACK_DIR/files/images/ $BASE_RELEASE_DIR/images rsync -a $BASE_RELEASE_DIR/tempest/$file/ $TARGET_RELEASE_DIR/tempest/$file/, rsync -av $BASE_DEVSTACK_DIR/files/$IMAGE_FNAME $BASE_RELEASE_DIR/images rsync -av $BASE_DEVSTACK_DIR/files/images/ $BASE_RELEASE_DIR/images rsync -avP $BASE_RELEASE_DIR/tempest/$file/ $TARGET_RELEASE_DIR/tempest/$file/,3,3
openstack%2Fdevstack~master~Ifb648c9eb4a57ac0fc97afb842e83286789801dd,openstack/devstack,master,Ifb648c9eb4a57ac0fc97afb842e83286789801dd,Fix typo: _create_volume_group => _create_lvm_volume_group,MERGED,2015-05-28 05:19:16.000000000,2015-06-10 18:33:47.000000000,2015-06-10 18:33:45.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7715}, {'_account_id': 10068}, {'_account_id': 14257}]","[{'number': 1, 'created': '2015-05-28 05:19:16.000000000', 'files': ['lib/lvm'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9ee1ef6cb8e06864e2341f4121372028d6d59c64', 'message': 'Fix typo: _create_volume_group => _create_lvm_volume_group\n\nChange-Id: Ifb648c9eb4a57ac0fc97afb842e83286789801dd\n'}]",0,186257,9ee1ef6cb8e06864e2341f4121372028d6d59c64,9,5,1,16521,,,0,"Fix typo: _create_volume_group => _create_lvm_volume_group

Change-Id: Ifb648c9eb4a57ac0fc97afb842e83286789801dd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/57/186257/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/lvm'],1,9ee1ef6cb8e06864e2341f4121372028d6d59c64,typo,# _create_lvm_volume_group creates default volume group,# _create_volume_group creates default volume group,1,1
openstack%2Fpython-designateclient~stable%2Fkilo~I13d6c9ed46406fefc8cfa5de46811e4be009f1af,openstack/python-designateclient,stable/kilo,I13d6c9ed46406fefc8cfa5de46811e4be009f1af,Move all_tenants and edit_managed attributes to designate Client,MERGED,2015-06-10 11:00:59.000000000,2015-06-10 18:33:40.000000000,2015-06-10 18:33:39.000000000,"[{'_account_id': 3}, {'_account_id': 6550}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-10 11:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/8af18e60230341997082cf8be79d89a22e841332', 'message': ""Move all_tenants and edit_managed attributes to designate Client\n\nInitializing designate client with a pre-existing keystone session\nwon't work as designate expects keystone session to have the\n'all_tenants' and 'edit_managed' attributes:\n\nExample code:\n\n    keystone_session = ksc_session.Session(\n      auth=keystone_auth,\n      verify=True,\n      cert=my_cert\n    )\n\nthan later:\n\n    self._designate_client = designate_client(\n      session=keystone_session,\n      region_name=region_name\n    )\n\nwith that code, wrap_api_call() will raise an exception:\n\n  AttributeError: 'Session' object has no attribute 'all_tenants'\n\nSame goes for 'edit_managed'.\n\nThis patch moves both attributes from Keystone session to designate\nClient.\n\nCloses-Bug: 1457821\nChange-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af\n""}, {'number': 2, 'created': '2015-06-10 11:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/53c624eff025423754311754eef885cbd6c5267d', 'message': ""Move all_tenants and edit_managed attributes to designate Client\n\nInitializing designate client with a pre-existing keystone session\nwon't work as designate expects keystone session to have the\n'all_tenants' and 'edit_managed' attributes:\n\nExample code:\n\n    keystone_session = ksc_session.Session(\n      auth=keystone_auth,\n      verify=True,\n      cert=my_cert\n    )\n\nthan later:\n\n    self._designate_client = designate_client(\n      session=keystone_session,\n      region_name=region_name\n    )\n\nwith that code, wrap_api_call() will raise an exception:\n\n  AttributeError: 'Session' object has no attribute 'all_tenants'\n\nSame goes for 'edit_managed'.\n\nThis patch moves both attributes from Keystone session to designate\nClient.\n\nCloses-Bug: 1457821\nChange-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af\n""}, {'number': 3, 'created': '2015-06-10 12:19:20.000000000', 'files': ['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py', 'designateclient/cli/base.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/7f61582cacc755cfe4be2ba7b1fe9e2fddb1ed68', 'message': ""Move all_tenants and edit_managed attributes to designate Client\n\nInitializing designate client with a pre-existing keystone session\nwon't work as designate expects keystone session to have the\n'all_tenants' and 'edit_managed' attributes:\n\nExample code:\n\n    keystone_session = ksc_session.Session(\n      auth=keystone_auth,\n      verify=True,\n      cert=my_cert\n    )\n\nthan later:\n\n    self._designate_client = designate_client(\n      session=keystone_session,\n      region_name=region_name\n    )\n\nwith that code, wrap_api_call() will raise an exception:\n\n  AttributeError: 'Session' object has no attribute 'all_tenants'\n\nSame goes for 'edit_managed'.\n\nThis patch moves both attributes from Keystone session to designate\nClient.\n\nCloses-Bug: 1457821\nChange-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af\n""}]",0,190114,7f61582cacc755cfe4be2ba7b1fe9e2fddb1ed68,12,4,3,741,,,0,"Move all_tenants and edit_managed attributes to designate Client

Initializing designate client with a pre-existing keystone session
won't work as designate expects keystone session to have the
'all_tenants' and 'edit_managed' attributes:

Example code:

    keystone_session = ksc_session.Session(
      auth=keystone_auth,
      verify=True,
      cert=my_cert
    )

than later:

    self._designate_client = designate_client(
      session=keystone_session,
      region_name=region_name
    )

with that code, wrap_api_call() will raise an exception:

  AttributeError: 'Session' object has no attribute 'all_tenants'

Same goes for 'edit_managed'.

This patch moves both attributes from Keystone session to designate
Client.

Closes-Bug: 1457821
Change-Id: I13d6c9ed46406fefc8cfa5de46811e4be009f1af
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/14/190114/1 && git format-patch -1 --stdout FETCH_HEAD,"['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py', 'designateclient/cli/base.py']",4,8af18e60230341997082cf8be79d89a22e841332,bug/1457821," session=self.app.session, all_tenants=self.app.options.all_tenants, edit_managed=self.app.options.edit_managed)", session=self.app.session),11,12
openstack%2Fpython-designateclient~stable%2Fkilo~I5502da0ca1f04e428b2723038d369d317338ce51,openstack/python-designateclient,stable/kilo,I5502da0ca1f04e428b2723038d369d317338ce51,Add --edit-managed flag to cli,MERGED,2015-06-10 11:00:59.000000000,2015-06-10 18:33:34.000000000,2015-06-10 18:33:33.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-10 11:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/490049674d3ffbe3dfa65330bf7ca808c35a33d9', 'message': 'Add --edit-managed flag to cli\n\nAllows users with the right role to edit managed records\n\nChange-Id: I5502da0ca1f04e428b2723038d369d317338ce51\n'}, {'number': 2, 'created': '2015-06-10 11:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/00a27d0b7b1420321a9b9d34a6f0dcc19d510c0a', 'message': 'Add --edit-managed flag to cli\n\nAllows users with the right role to edit managed records\n\nChange-Id: I5502da0ca1f04e428b2723038d369d317338ce51\n'}, {'number': 3, 'created': '2015-06-10 12:19:20.000000000', 'files': ['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/feb621a56cf8f77e0cee4df206735819d55457ea', 'message': 'Add --edit-managed flag to cli\n\nAllows users with the right role to edit managed records\n\nChange-Id: I5502da0ca1f04e428b2723038d369d317338ce51\n'}]",0,190113,feb621a56cf8f77e0cee4df206735819d55457ea,10,3,3,741,,,0,"Add --edit-managed flag to cli

Allows users with the right role to edit managed records

Change-Id: I5502da0ca1f04e428b2723038d369d317338ce51
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/13/190113/1 && git format-patch -1 --stdout FETCH_HEAD,"['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py']",3,490049674d3ffbe3dfa65330bf7ca808c35a33d9,bug/1457821," cacert=None, all_tenants=False, edit_managed=False): edit_managed=edit_managed, if self.session.session.edit_managed: kw['headers'].update({'X-Designate-Edit-Managed-Records': 'true'})"," cacert=None, all_tenants=False):",11,2
openstack%2Fpython-designateclient~stable%2Fkilo~I4cd4dd5427f5f35cdec95dbdf36c7386b60a2949,openstack/python-designateclient,stable/kilo,I4cd4dd5427f5f35cdec95dbdf36c7386b60a2949,Added extra previllege to list all domains from all tenants,MERGED,2015-06-10 11:00:59.000000000,2015-06-10 18:33:32.000000000,2015-06-10 18:33:31.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 7512}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-10 11:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/a5221f12147dd384371b04a1dac391bfe46e0a45', 'message': 'Added extra previllege to list all domains from all tenants\n\nThe user has to use the command ""designate --all-tenants domain-list"" to list all domains from all tenants.\nWhen the above command is used ""X-Auth-All-Projects"" value is set to true and it is passed as a header to\ndesignate.This will allow us to list all domains from all tenants.\n\nChange-Id: I4cd4dd5427f5f35cdec95dbdf36c7386b60a2949\nFixes: bug #1418156\n'}, {'number': 2, 'created': '2015-06-10 11:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/b9ef16915470d891892cd99ad6d8d19f60fc7324', 'message': 'Added extra previllege to list all domains from all tenants\n\nThe user has to use the command ""designate --all-tenants domain-list"" to list all domains from all tenants.\nWhen the above command is used ""X-Auth-All-Projects"" value is set to true and it is passed as a header to\ndesignate.This will allow us to list all domains from all tenants.\n\nChange-Id: I4cd4dd5427f5f35cdec95dbdf36c7386b60a2949\nFixes: bug #1418156\n'}, {'number': 3, 'created': '2015-06-10 12:19:20.000000000', 'files': ['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/eba7c2e58472638c5675f4b7dac95415daf23ec8', 'message': 'Added extra previllege to list all domains from all tenants\n\nThe user has to use the command ""designate --all-tenants domain-list"" to list all domains from all tenants.\nWhen the above command is used ""X-Auth-All-Projects"" value is set to true and it is passed as a header to\ndesignate.This will allow us to list all domains from all tenants.\n\nChange-Id: I4cd4dd5427f5f35cdec95dbdf36c7386b60a2949\nFixes: bug #1418156\n'}]",0,190112,eba7c2e58472638c5675f4b7dac95415daf23ec8,12,6,3,741,,,0,"Added extra previllege to list all domains from all tenants

The user has to use the command ""designate --all-tenants domain-list"" to list all domains from all tenants.
When the above command is used ""X-Auth-All-Projects"" value is set to true and it is passed as a header to
designate.This will allow us to list all domains from all tenants.

Change-Id: I4cd4dd5427f5f35cdec95dbdf36c7386b60a2949
Fixes: bug #1418156
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/12/190112/3 && git format-patch -1 --stdout FETCH_HEAD,"['designateclient/utils.py', 'designateclient/shell.py', 'designateclient/v1/__init__.py']",3,a5221f12147dd384371b04a1dac391bfe46e0a45,bug/1457821," cacert=None, all_tenants=False): all_tenants=all_tenants, if self.session.session.all_tenants: kw['headers'].update({'X-Auth-All-Projects': 'true'})", cacert=None):,10,2
openstack%2Fnova~master~I9aeac709cbbf0f9ddfa6cf724d55af8fa3a962ee,openstack/nova,master,I9aeac709cbbf0f9ddfa6cf724d55af8fa3a962ee,Map uuid db field to instance_uuid in BandwidthUsage object,MERGED,2015-06-08 18:55:10.000000000,2015-06-10 18:25:02.000000000,2015-06-10 18:24:59.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 6735}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-08 18:55:10.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/objects/bandwidth_usage.py', 'nova/tests/unit/objects/test_bandwidth_usage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f99af38cade764445fe7a40b4763293a0f91b514', 'message': ""Map uuid db field to instance_uuid in BandwidthUsage object\n\nThe BandwidthUsage database model stores the instance relation as 'uuid'\nbut the BandwidthUsage Nova Object stores it as instance_uuid.  The\n_from_db_object needs to handle this discrepancy.\n\nThis wasn't caught before because unit tests were passing back a\nsimulated db return which didn't match reality.\n\nChange-Id: I9aeac709cbbf0f9ddfa6cf724d55af8fa3a962ee\nCloses-Bug: 1463039\n""}]",0,189397,f99af38cade764445fe7a40b4763293a0f91b514,17,11,1,5441,,,0,"Map uuid db field to instance_uuid in BandwidthUsage object

The BandwidthUsage database model stores the instance relation as 'uuid'
but the BandwidthUsage Nova Object stores it as instance_uuid.  The
_from_db_object needs to handle this discrepancy.

This wasn't caught before because unit tests were passing back a
simulated db return which didn't match reality.

Change-Id: I9aeac709cbbf0f9ddfa6cf724d55af8fa3a962ee
Closes-Bug: 1463039
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/189397/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/objects/bandwidth_usage.py', 'nova/tests/unit/objects/test_bandwidth_usage.py']",3,f99af38cade764445fe7a40b4763293a0f91b514,bug/1442749," obj_field = field if obj_field == 'uuid': obj_field = 'instance_uuid' test.assertEqual(db[field], obj[obj_field]) 'uuid': 'fake_uuid1',"," test.assertEqual(db[field], obj[field]) 'instance_uuid': 'fake_uuid1',",10,4
openstack%2Fpython-openstackclient~master~Ibfde558b17e333989bf155c52b60f93f82cfe898,openstack/python-openstackclient,master,Ibfde558b17e333989bf155c52b60f93f82cfe898,Add a bunch of profiling hacks,ABANDONED,2015-03-17 18:32:01.000000000,2015-06-10 18:22:10.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 6172}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-03-17 18:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0f5011914f11511ebd86f5843b4853939528c29e', 'message': ""Add a bunch of profiling hacks\n\nI'm sure someone will show me the right way to do this but it does expose\nwhere the long times are:\n* importing keystoneclient.session\n* loading some extension plugins\n* performing authentication (mostly REST round trip time)\n* loading OSC command classes\n* performing commands\n\nChange-Id: Ibfde558b17e333989bf155c52b60f93f82cfe898\n""}, {'number': 2, 'created': '2015-03-17 18:47:34.000000000', 'files': ['openstackclient/api/auth.py', 'openstackclient/shell.py', 'openstackclient/common/time.py', 'openstackclient/common/clientmanager.py', 'openstackclient/common/commandmanager.py', 'openstackclient/api/api.py', 'openstackclient/common/timing.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4a1a39043329cc1195c71ed5719bc2623c1aafc3', 'message': ""Add a bunch of profiling hacks\n\nI'm sure someone will show me the right way to do this but it does expose\nwhere the long times are:\n* importing keystoneclient.session\n* loading some extension plugins\n* performing authentication (mostly REST round trip time)\n* loading OSC command classes\n* performing commands\n\nChange-Id: Ibfde558b17e333989bf155c52b60f93f82cfe898\n""}]",2,165181,4a1a39043329cc1195c71ed5719bc2623c1aafc3,10,5,2,970,,,0,"Add a bunch of profiling hacks

I'm sure someone will show me the right way to do this but it does expose
where the long times are:
* importing keystoneclient.session
* loading some extension plugins
* performing authentication (mostly REST round trip time)
* loading OSC command classes
* performing commands

Change-Id: Ibfde558b17e333989bf155c52b60f93f82cfe898
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/81/165181/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/api/auth.py', 'openstackclient/shell.py', 'openstackclient/common/clientmanager.py', 'openstackclient/common/commandmanager.py', 'openstackclient/api/api.py', 'openstackclient/common/timing.py']",6,0f5011914f11511ebd86f5843b4853939528c29e,profiles," results.append((url, ""%3.6f"" % sec))"," results.append((url, sec))",73,1
openstack%2Fpython-designateclient~stable%2Fkilo~If61dfcf74b82e155552e2450350d8d3de109879f,openstack/python-designateclient,stable/kilo,If61dfcf74b82e155552e2450350d8d3de109879f,Use oslosphinx from PyPi,MERGED,2015-06-10 11:06:49.000000000,2015-06-10 18:19:32.000000000,2015-06-10 18:19:30.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-10 11:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/9e6f8428dbaed27761955d5410ec0a862b14a59f', 'message': 'Use oslosphinx from PyPi\n\nChange-Id: If61dfcf74b82e155552e2450350d8d3de109879f\n'}, {'number': 2, 'created': '2015-06-10 12:19:20.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/05b085875b32522f8da14fe09f7659a77180436f', 'message': 'Use oslosphinx from PyPi\n\nChange-Id: If61dfcf74b82e155552e2450350d8d3de109879f\n'}]",0,190116,05b085875b32522f8da14fe09f7659a77180436f,9,5,2,741,,,0,"Use oslosphinx from PyPi

Change-Id: If61dfcf74b82e155552e2450350d8d3de109879f
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/16/190116/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,9e6f8428dbaed27761955d5410ec0a862b14a59f,bug/1457821,oslosphinx>=2.5.0 # Apache-2.0,# Needed for the incubation theme on oslosphinx http://tarballs.openstack.org/oslosphinx/oslosphinx-2.2.0.0a3.tar.gz#egg=oslosphinx-2.2.0.0a3,1,2
openstack%2Fnova~master~I0618a300754d012db62df52faa12cc3cedfe2b65,openstack/nova,master,I0618a300754d012db62df52faa12cc3cedfe2b65,Add AggregateTypeAffinityFilter multi values support,MERGED,2014-12-15 19:19:26.000000000,2015-06-10 18:18:40.000000000,2015-06-10 10:37:58.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 3217}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9820}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 11604}, {'_account_id': 11647}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2014-12-15 19:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3b1ac8ca64db2c61e956c4746e1f9ae4926d1cf', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nthis change allows to function when multiple instance_type names are set\nin the Aggregate Metadata\n\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 2, 'created': '2014-12-17 15:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6db0ab59b7edb1882ad4f4458e70b673e6de96ac', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nthis change allows to function when multiple instance_type names are set\nin the Aggregate Metadata\n\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 3, 'created': '2014-12-18 18:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e7eae5bfdde661b325acb541bf26f04d8833e49', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nthis change allows to function when multiple instance_type names are set\nin the Aggregate Metadata\n\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 4, 'created': '2015-01-13 19:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c82a95b4585ef1353b07a8f80f2e3c57012cd749', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nthis change allows to function when multiple instance_type names are set\nin the Aggregate Metadata\n\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 5, 'created': '2015-01-15 16:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5fc9cbe59363eeb01d9b01916a1693dc278d4fe', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nThis change allows the AggregateTypeAffinityFilter to function when\nmultiple instance_type names are set in the Aggregate Metadata\n\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 6, 'created': '2015-01-26 18:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1803316504858f46257dc684418ddcf4eb681943', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nThis change allows the AggregateTypeAffinityFilter to function when\nmultiple instance_type names are set in the Aggregate Metadata.\nThis change implements and documents a new json based syntax for\nthe aggregate instance_type metadata attribute. The legacy syntax is\nstill supported when a single instace_type is specified.\ne.g. \'m1.nano\' or \'[""m1.nano"",""m1.small""]\'\n\nDocImpact\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 7, 'created': '2015-05-08 15:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6413dbd470a9631a4bdf8eeb6be6801851df0f0', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nThis change allows the AggregateTypeAffinityFilter to function when\nmultiple instance_type names are set in the Aggregate Metadata.\nThis change implements and documents a new comma separated syntax for\nthe aggregate instance_type metadata attribute. The legacy syntax is\nstill supported when a single instace_type is specified.\ne.g. \'m1.nano\' or ""m1.nano,m1.small""\n\nDocImpact\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 8, 'created': '2015-05-11 18:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2859b91574a8911265f400839c96e18daab8976a', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nThis change allows the AggregateTypeAffinityFilter to function when\nmultiple instance_type names are set in the Aggregate Metadata.\nThis change implements and documents a new comma separated syntax for\nthe aggregate instance_type metadata attribute. The legacy syntax is\nstill supported when a single instace_type is specified.\ne.g. \'m1.nano\' or ""m1.nano,m1.small""\n\nDocImpact\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 9, 'created': '2015-06-03 21:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55e4cf2e90df886a294afd225ef0b275ce8c416a', 'message': 'fix AggregateTypeAffinityFilter multi values support\n\nThis change allows the AggregateTypeAffinityFilter to function when\nmultiple instance_type names are set in the Aggregate Metadata.\nThis change implements and documents a new comma separated syntax for\nthe aggregate instance_type metadata attribute. The legacy syntax is\nstill supported when a single instace_type is specified.\ne.g. \'m1.nano\' or ""m1.nano,m1.small""\n\nDocImpact\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204\n'}, {'number': 10, 'created': '2015-06-09 19:00:22.000000000', 'files': ['nova/tests/unit/scheduler/filters/test_type_filters.py', 'doc/source/filter_scheduler.rst', 'nova/scheduler/filters/type_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/66e1427f14dee477f27cd899a25b9e3cdeb38ff4', 'message': 'Add AggregateTypeAffinityFilter multi values support\n\nThis change allows the AggregateTypeAffinityFilter to function when\nmultiple instance_type names are set in the Aggregate Metadata.\nThis change implements and documents a new comma separated syntax for\nthe aggregate instance_type metadata attribute. The legacy syntax is\nstill supported when a single instace_type is specified.\ne.g. \'m1.nano\' or ""m1.nano,m1.small""\n\nDocImpact\nChange-Id: I0618a300754d012db62df52faa12cc3cedfe2b65\nCloses-bug: #1399204'}]",38,141883,66e1427f14dee477f27cd899a25b9e3cdeb38ff4,150,20,10,11604,,,0,"Add AggregateTypeAffinityFilter multi values support

This change allows the AggregateTypeAffinityFilter to function when
multiple instance_type names are set in the Aggregate Metadata.
This change implements and documents a new comma separated syntax for
the aggregate instance_type metadata attribute. The legacy syntax is
still supported when a single instace_type is specified.
e.g. 'm1.nano' or ""m1.nano,m1.small""

DocImpact
Change-Id: I0618a300754d012db62df52faa12cc3cedfe2b65
Closes-bug: #1399204",git fetch https://review.opendev.org/openstack/nova refs/changes/83/141883/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/filters/test_type_filters.py', 'nova/scheduler/filters/type_filter.py']",2,d3b1ac8ca64db2c61e956c4746e1f9ae4926d1cf,bug/1399204," return (not aggregate_vals or any(instance_type['name'] in x.split(',') for x in aggregate_vals))", if not aggregate_vals: return True return instance_type['name'] in aggregate_vals,14,8
openstack%2Fnova~master~Ie32ba7e8e262528494c5dfec4d7b49950f72ecb0,openstack/nova,master,Ie32ba7e8e262528494c5dfec4d7b49950f72ecb0,Improve compute swap_volume logging,MERGED,2015-06-04 09:30:08.000000000,2015-06-10 18:16:46.000000000,2015-06-09 10:23:21.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15882}]","[{'number': 1, 'created': '2015-06-04 09:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d159ffe9597a57bb535c3014e41bdd4eb2dec4f', 'message': 'Improve compute swap_volume logging\n\nEven though this is a reasonably complicated bit of code that also can\nget called by cinder when doing volume retyping, there is close to zero\nlogging at the moment.\n\nChange-Id: Ie32ba7e8e262528494c5dfec4d7b49950f72ecb0\n'}, {'number': 2, 'created': '2015-06-04 11:20:45.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b34ace256700a3e4da3b88d7baccfd79fc868e2e', 'message': 'Improve compute swap_volume logging\n\nEven though this is a reasonably complicated bit of code that also can\nget called by cinder when doing volume retyping, there is close to zero\nlogging at the moment.\n\nChange-Id: Ie32ba7e8e262528494c5dfec4d7b49950f72ecb0\n'}]",2,188320,b34ace256700a3e4da3b88d7baccfd79fc868e2e,23,12,2,5511,,,0,"Improve compute swap_volume logging

Even though this is a reasonably complicated bit of code that also can
get called by cinder when doing volume retyping, there is close to zero
logging at the moment.

Change-Id: Ie32ba7e8e262528494c5dfec4d7b49950f72ecb0
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/188320/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,2d159ffe9597a57bb535c3014e41bdd4eb2dec4f,improve_swap_vol_logging," LOG.debug(""swap_volume: Calling driver volume swap with "" ""connection infos: new: %(new_cinfo)s; "" ""old: %(old_cinfo)s"", {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo}, contex=context, instance=instance) LOG.debug(""swap_volume: Cinder migrate_volume_completion "" ""returned: %(comp_ret)s"", {'comp_ret': comp_ret}, context=context, instance=instance) LOG.info(_LI('Swapping volume %(old_volume)s for %(new_volume)s'), {'old_volume': old_volume_id, 'new_volume': new_volume_id}, context=context, instance=instance) LOG.debug(""swap_volume: Updating volume %(volume_id)s BDM record with "" ""%(updates)s"", {'volume_id': bdm.volume_id, 'updates': values}, context=context, instance=instance)",,15,0
openstack%2Fgrenade~master~I966c45efa9e8eb8868323de74f363eb1990e534e,openstack/grenade,master,I966c45efa9e8eb8868323de74f363eb1990e534e,Allow cache_git.sh to handle additional projects adhoc,MERGED,2015-06-08 21:29:03.000000000,2015-06-10 18:15:56.000000000,2015-06-10 18:15:54.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}]","[{'number': 1, 'created': '2015-06-08 21:29:03.000000000', 'files': ['cache_git.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/d9f79d94b6509fa995411911ec9a13c8b71da93e', 'message': ""Allow cache_git.sh to handle additional projects adhoc\n\nWhen testing external plugins it's extremely useful to be able to\ncache additional repositories with cache_git.sh. This allows us to\njust pass a whole set of additional items on the cli that will also\nget cached.\n\nChange-Id: I966c45efa9e8eb8868323de74f363eb1990e534e\n""}]",0,189474,d9f79d94b6509fa995411911ec9a13c8b71da93e,7,3,1,2750,,,0,"Allow cache_git.sh to handle additional projects adhoc

When testing external plugins it's extremely useful to be able to
cache additional repositories with cache_git.sh. This allows us to
just pass a whole set of additional items on the cli that will also
get cached.

Change-Id: I966c45efa9e8eb8868323de74f363eb1990e534e
",git fetch https://review.opendev.org/openstack/grenade refs/changes/74/189474/1 && git format-patch -1 --stdout FETCH_HEAD,['cache_git.sh'],1,d9f79d94b6509fa995411911ec9a13c8b71da93e,git_cache,"for dir in $@; do PROJECTS+=""$dir "" done",,3,0
openstack%2Fautomaton~master~Iac8ce50b0a17468190f3f737663b5b094c324a55,openstack/automaton,master,Iac8ce50b0a17468190f3f737663b5b094c324a55,Split the state machine runners off into own file,MERGED,2015-06-06 00:13:55.000000000,2015-06-10 18:15:05.000000000,2015-06-10 18:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-06 00:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/e72bfffb5283b0c740a5eb1af7fdc7fa40713f4c', 'message': 'Split the state machine runners off into own file\n\nWhen using a state machine it is not always desired\nto use the runner concept, so to ensure both concepts\nare modular split runners off into there own module.\n\nChange-Id: Iac8ce50b0a17468190f3f737663b5b094c324a55\n'}, {'number': 2, 'created': '2015-06-06 00:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/a8e600f658a950e2c3313a0c2e1403196e656385', 'message': 'Split the state machine runners off into own file\n\nWhen using a state machine it is not always desired\nto use the runner concept, so to ensure both concepts\nare modular split runners off into there own module.\n\nChange-Id: Iac8ce50b0a17468190f3f737663b5b094c324a55\n'}, {'number': 3, 'created': '2015-06-09 22:14:38.000000000', 'files': ['automaton/runners.py', 'automaton/tests/test_fsm.py', 'doc/source/api.rst', 'automaton/machines.py'], 'web_link': 'https://opendev.org/openstack/automaton/commit/bcb61f0b0da1439cae99bb01b67ea85584e4c302', 'message': 'Split the state machine runners off into own file\n\nWhen using a state machine it is not always desired\nto use the runner concept, so to ensure both concepts\nare modular split runners off into there own module.\n\nChange-Id: Iac8ce50b0a17468190f3f737663b5b094c324a55\n'}]",0,188976,bcb61f0b0da1439cae99bb01b67ea85584e4c302,14,4,3,1297,,,0,"Split the state machine runners off into own file

When using a state machine it is not always desired
to use the runner concept, so to ensure both concepts
are modular split runners off into there own module.

Change-Id: Iac8ce50b0a17468190f3f737663b5b094c324a55
",git fetch https://review.opendev.org/openstack/automaton refs/changes/76/188976/1 && git format-patch -1 --stdout FETCH_HEAD,"['automaton/runners.py', 'automaton/tests/test_fsm.py', 'doc/source/api.rst', 'automaton/machines.py']",4,e72bfffb5283b0c740a5eb1af7fdc7fa40713f4c,,,"import weakref_JUMPER_NOT_FOUND_TPL = (""Unable to progress since no reaction (or"" "" sent event) has been made available in"" "" new state '%s' (moved to from state '%s'"" "" in response to event '%s')"") self._runner = _FiniteRunner(self) def runner(self): return self._runner @propertyclass _FiniteRunner(object): """"""Finite machine runner used to run a finite machine."""""" def __init__(self, machine): self._machine = weakref.proxy(machine) def run(self, event, initialize=True): """"""Runs the state machine, using reactions only."""""" for transition in self.run_iter(event, initialize=initialize): pass def run_iter(self, event, initialize=True): """"""Returns a iterator/generator that will run the state machine. NOTE(harlowja): only one runner iterator/generator should be active for a machine, if this is not observed then it is possible for initialization and other local state to be corrupted and cause issues when running... """""" if initialize: self._machine.initialize() while True: old_state = self._machine.current_state reaction, terminal = self._machine.process_event(event) new_state = self._machine.current_state try: sent_event = yield (old_state, new_state) except GeneratorExit: break if terminal: break if reaction is None and sent_event is None: raise excp.NotFound(_JUMPER_NOT_FOUND_TPL % (new_state, old_state, event)) elif sent_event is not None: event = sent_event else: cb, args, kwargs = reaction event = cb(old_state, new_state, event, *args, **kwargs) self._runner = _HierarchicalRunner(self) class _HierarchicalRunner(object): """"""Hierarchical machine runner used to run a hierarchical machine."""""" def __init__(self, machine): self._machine = weakref.proxy(machine) def run(self, event, initialize=True): """"""Runs the state machine, using reactions only."""""" for transition in self.run_iter(event, initialize=initialize): pass @staticmethod def _process_event(machines, event): """"""Matches a event to the machine hierarchy. If the lowest level machine does not handle the event, then the parent machine is referred to and so on, until there is only one machine left which *must* handle the event. The machine whose ``process_event`` does not throw invalid state or not found exceptions is expected to be the machine that should continue handling events... """""" while True: machine = machines[-1] try: result = machine.process_event(event) except (excp.InvalidState, excp.NotFound): if len(machines) == 1: raise else: current = machine._current if current is not None and current.on_exit is not None: current.on_exit(current.name, event) machine._current = None machines.pop() else: return result def run_iter(self, event, initialize=True): """"""Returns a iterator/generator that will run the state machine. This will keep a stack (hierarchy) of machines active and jumps through them as needed (depending on which machine handles which event) during the running lifecycle. NOTE(harlowja): only one runner iterator/generator should be active for a machine hierarchy, if this is not observed then it is possible for initialization and other local state to be corrupted and causes issues when running... """""" machines = [self._machine] if initialize: machines[-1].initialize() while True: old_state = machines[-1].current_state effect = self._process_event(machines, event) new_state = machines[-1].current_state try: machine = effect.machine except AttributeError: pass else: if machine is not None and machine is not machines[-1]: machine.initialize() machines.append(machine) try: sent_event = yield (old_state, new_state) except GeneratorExit: break if len(machines) == 1 and effect.terminal: # Only allow the top level machine to actually terminate the # execution, the rest of the nested machines must not handle # events if they wish to have the root machine terminate... break if effect.reaction is None and sent_event is None: raise excp.NotFound(_JUMPER_NOT_FOUND_TPL % (new_state, old_state, event)) elif sent_event is not None: event = sent_event else: cb, args, kwargs = effect.reaction event = cb(old_state, new_state, event, *args, **kwargs)",188,153
openstack%2Fsolum~master~I14c4729727b17ab7671c155a1ed32765af1e7b6b,openstack/solum,master,I14c4729727b17ab7671c155a1ed32765af1e7b6b,Modifying the heat deployer to use injected file to download DU,MERGED,2015-06-02 19:21:23.000000000,2015-06-10 17:58:31.000000000,2015-06-10 17:58:30.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 6662}]","[{'number': 1, 'created': '2015-06-02 19:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b31598efbe7232a255ad440e00233b1eba5ff607', 'message': ""Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure in\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. Heat provides the mechanism of 'get_file'\nusing which we inject this script into the VM.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nNote that the location of the file to inject is currently specified\nas a publicly available gist URL. We will change this to point to\nthe URL of the 'robust-du-handling' script once it is merged into\nmaster.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 2, 'created': '2015-06-02 19:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/59992a984bd4de86863acd9ae28baafec7fd1633', 'message': ""(WIP): Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure in\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n(Will remove the unused code once the downstream tests pass)\n\nNote that the location of the file to inject is currently specified\nas a publicly available gist URL. We will change this to point to\nthe URL of the 'robust-du-handling' script once it is merged into\nmaster.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 3, 'created': '2015-06-02 19:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/43d6051044707394a187fd27d4de07b6e3784720', 'message': ""(WIP): Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure in\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nNote that the location of the file to inject is currently specified\nas a publicly available gist URL. We will change this to point to\nthe URL of the 'robust-du-handling' script once it is merged into\nmaster.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 4, 'created': '2015-06-04 20:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8c8f3af0c2dbf335761f64d22185f6f786594e5e', 'message': ""(WIP): Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure in\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nNote that the location of the file to inject is currently specified\nas a publicly available gist URL. We will change this to point to\nthe URL of the 'robust-du-handling' script once it is merged into\nmaster.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 5, 'created': '2015-06-05 21:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/847ae8cb09a124e6bc986fe0b3f13c2873d0e5ff', 'message': ""Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure in\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nNote that the location of the file to inject is currently specified\nas a publicly available gist URL. We will change this to point to\nthe URL of the 'robust-du-handling' script once it is merged into\nmaster.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 6, 'created': '2015-06-09 17:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/04fd927b00c62a7668fd1d4117b121e499aca0b4', 'message': ""Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure in\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nNote that the location of the file to inject is currently specified\nas a publicly available gist URL. We will change this to point to\nthe URL of the 'robust-du-handling' script once it is merged into\nmaster.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 7, 'created': '2015-06-09 19:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ed7654cf629712a0a6884042a01839867c4527fd', 'message': ""Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}, {'number': 8, 'created': '2015-06-09 22:14:37.000000000', 'files': ['solum/tests/deployer/handlers/test_heat.py', 'solum/deployer/handlers/heat.py', 'etc/solum/templates/coreos.yaml', 'contrib/common/robust-du-handling.sh', 'solum/common/catalog.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/a708d6d1b1cf34128bddf4cd6ce7a2776b0c6054', 'message': ""Modifying the heat deployer to use injected file to download DU\n\nProblem:\nWe have noticed that occassionally the downloading of DU on the\nVM will fail to download the entire file. This causes failure\nduring docker load, which loads and makes the DU available to\nbe run on the VM.\n\nSolution:\nOne way to address this issue is to check docker load for success,\nand try the steps of downloading the DU and loading it again, if it\nhas failed. Towards this we have developed a script which will\nperform such checks. We inject this script into the VM using the\nmechanism of 'get_file' provided by Heat.\n\nThis patch implements this solution.\n\nAs a consequence of this change, the heat deployer is simplied,\nas we no longer need to customize the template in our code.\nWe just need to pass the correct parameters to the template.\n\nChange-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b\n""}]",9,187732,a708d6d1b1cf34128bddf4cd6ce7a2776b0c6054,24,4,8,2506,,,0,"Modifying the heat deployer to use injected file to download DU

Problem:
We have noticed that occassionally the downloading of DU on the
VM will fail to download the entire file. This causes failure
during docker load, which loads and makes the DU available to
be run on the VM.

Solution:
One way to address this issue is to check docker load for success,
and try the steps of downloading the DU and loading it again, if it
has failed. Towards this we have developed a script which will
perform such checks. We inject this script into the VM using the
mechanism of 'get_file' provided by Heat.

This patch implements this solution.

As a consequence of this change, the heat deployer is simplied,
as we no longer need to customize the template in our code.
We just need to pass the correct parameters to the template.

Change-Id: I14c4729727b17ab7671c155a1ed32765af1e7b6b
",git fetch https://review.opendev.org/openstack/solum refs/changes/32/187732/7 && git format-patch -1 --stdout FETCH_HEAD,"['solum/deployer/handlers/heat.py', 'solum/tests/deployer/handlers/test_heat.py', 'etc/solum/templates/coreos.yaml', 'contrib/common/robust-du-handling.sh']",4,b31598efbe7232a255ad440e00233b1eba5ff607,robust-du-load,"#!/bin/sh location=""%location%"" du=""%du%"" publish_ports=""%publish_ports%"" trial_count=3 # Try wget and docker_load stage1_success=false RETRIES=0 until [ $RETRIES -ge $trial_count ]; do wget ""$location"" --output-document=""$du"" docker load < $du if [[ $? == 0 ]]; then stage1_success=true break fi RETRIES=$[$RETRIES+1] sleep 2 done if [ ""$stage1_success"" = false ]; then wc_notify --data-binary '{""status"": ""FAILURE"", ""reason"": ""wget and docker load failed.""}' fi # Try docker run docker_run_success=false RETRIES=0 until [ $RETRIES -ge $trial_count ]; do docker run $publish_ports -d $du if [[ $? == 0 ]]; then docker_run_success=true break fi RETRIES=$[$RETRIES+1] sleep 2 done if [ ""$docker_run_success"" = false ]; then wc_notify --data-binary '{""status"": ""FAILURE"", ""reason"": ""docker run failed.""}' else wc_notify --data-binary '{""status"": ""SUCCESS""}' fi",,87,25
openstack%2Fheat-translator~master~I315e6d4ddfbb3fb558d115f1ca7aae9089982d19,openstack/heat-translator,master,I315e6d4ddfbb3fb558d115f1ca7aae9089982d19,TOSCA: Update memory size per spec changes,MERGED,2015-06-10 15:23:50.000000000,2015-06-10 17:51:27.000000000,2015-06-10 17:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 9498}]","[{'number': 1, 'created': '2015-06-10 15:23:50.000000000', 'files': ['translator/toscalib/tests/data/tosca_helloworld.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/698834270ac01955cc97045e8500afdaa01a702d', 'message': 'TOSCA: Update memory size per spec changes\n\nThe hello world example in spec has been updated to provide a better example\nof instance memory size.\n\nChange-Id: I315e6d4ddfbb3fb558d115f1ca7aae9089982d19\n'}]",0,190231,698834270ac01955cc97045e8500afdaa01a702d,7,3,1,6456,,,0,"TOSCA: Update memory size per spec changes

The hello world example in spec has been updated to provide a better example
of instance memory size.

Change-Id: I315e6d4ddfbb3fb558d115f1ca7aae9089982d19
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/31/190231/1 && git format-patch -1 --stdout FETCH_HEAD,['translator/toscalib/tests/data/tosca_helloworld.yaml'],1,698834270ac01955cc97045e8500afdaa01a702d,, mem_size: 512 MB, mem_size: 4 MB,1,1
openstack%2Fgrenade~master~I02a777077d40408766204b05ed284fe98efbce8e,openstack/grenade,master,I02a777077d40408766204b05ed284fe98efbce8e,implement external plugin mechanism for grenade,MERGED,2015-05-22 15:41:54.000000000,2015-06-10 17:49:17.000000000,2015-06-10 17:49:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 6899}, {'_account_id': 7710}, {'_account_id': 7973}, {'_account_id': 8411}, {'_account_id': 9234}]","[{'number': 1, 'created': '2015-05-22 15:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/82927646597528075ec334c75c9cc187d8bfb976', 'message': 'implement external plugin mechanism for grenade\n\nImplement an external plugin mechanism for grenade in the spirit of\ndevstack plugins. This code is currently untested, however should be a\nvery reasonable base point to get projects working with out of tree\nplugins.\n\nChange-Id: I02a777077d40408766204b05ed284fe98efbce8e\n'}, {'number': 2, 'created': '2015-06-08 21:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/e3ebfe302381a8d873c275dd14492cd6bae63157', 'message': ""implement external plugin mechanism for grenade\n\nImplement an external plugin mechanism for grenade in the spirit of\ndevstack plugins. This assumes that external plugins will live in the\ndevstack/upgrade tree in their respective repository.\n\nExternal plugins are enabled by adding\n\nenable_grenade_plugin <name> <giturl> [branch]\n\nto ``pluginrc`` at the top of the grenade directory. (``localrc``\ncould not be used due to timing issues on parsing)\n\na new ``devstack_localrc <base|target> ...`` is also added to grenade\nthat allows settings files to add content to base and target devstack\nlocalrcs. This is quite critical for out of tree support, because for\nupgrade testing there will often be a need to add services to the\nlocalrc.\n\nPartially tested on the existing Heat plugin implemented in\nI0847004a8ac023a113cabaee46896abc823a01da, though that doesn't yet\nfully pass due to conflicts in it's upgrade process.\n\nInclude documentation for out of tree best practices.\n\nChange-Id: I02a777077d40408766204b05ed284fe98efbce8e\n""}, {'number': 3, 'created': '2015-06-09 14:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/3a2dc000e04e8e8d48986190fff242fade360d4e', 'message': ""implement external plugin mechanism for grenade\n\nImplement an external plugin mechanism for grenade in the spirit of\ndevstack plugins. This assumes that external plugins will live in the\ndevstack/upgrade tree in their respective repository.\n\nExternal plugins are enabled by adding\n\nenable_grenade_plugin <name> <giturl> [branch]\n\nto ``pluginrc`` at the top of the grenade directory. (``localrc``\ncould not be used due to timing issues on parsing)\n\na new ``devstack_localrc <base|target> ...`` is also added to grenade\nthat allows settings files to add content to base and target devstack\nlocalrcs. This is quite critical for out of tree support, because for\nupgrade testing there will often be a need to add services to the\nlocalrc.\n\nPartially tested on the existing Heat plugin implemented in\nI0847004a8ac023a113cabaee46896abc823a01da, though that doesn't yet\nfully pass due to conflicts in it's upgrade process.\n\nInclude documentation for out of tree best practices.\n\nChange-Id: I02a777077d40408766204b05ed284fe98efbce8e\n""}, {'number': 4, 'created': '2015-06-09 17:12:01.000000000', 'files': ['inc/plugin', 'grenade.sh', 'PLUGINS.rst'], 'web_link': 'https://opendev.org/openstack/grenade/commit/2923b056b868c6be0ee7a3f11100878607e48cfc', 'message': ""implement external plugin mechanism for grenade\n\nImplement an external plugin mechanism for grenade in the spirit of\ndevstack plugins. This assumes that external plugins will live in the\ndevstack/upgrade tree in their respective repository.\n\nExternal plugins are enabled by adding\n\nenable_grenade_plugin <name> <giturl> [branch]\n\nto ``pluginrc`` at the top of the grenade directory. (``localrc``\ncould not be used due to timing issues on parsing)\n\na new ``devstack_localrc <base|target> ...`` is also added to grenade\nthat allows settings files to add content to base and target devstack\nlocalrcs. This is quite critical for out of tree support, because for\nupgrade testing there will often be a need to add services to the\nlocalrc.\n\nPartially tested on the existing Heat plugin implemented in\nI0847004a8ac023a113cabaee46896abc823a01da, though that doesn't yet\nfully pass due to conflicts in it's upgrade process.\n\nInclude documentation for out of tree best practices.\n\nChange-Id: I02a777077d40408766204b05ed284fe98efbce8e\n""}]",13,185050,2923b056b868c6be0ee7a3f11100878607e48cfc,24,10,4,2750,,,0,"implement external plugin mechanism for grenade

Implement an external plugin mechanism for grenade in the spirit of
devstack plugins. This assumes that external plugins will live in the
devstack/upgrade tree in their respective repository.

External plugins are enabled by adding

enable_grenade_plugin <name> <giturl> [branch]

to ``pluginrc`` at the top of the grenade directory. (``localrc``
could not be used due to timing issues on parsing)

a new ``devstack_localrc <base|target> ...`` is also added to grenade
that allows settings files to add content to base and target devstack
localrcs. This is quite critical for out of tree support, because for
upgrade testing there will often be a need to add services to the
localrc.

Partially tested on the existing Heat plugin implemented in
I0847004a8ac023a113cabaee46896abc823a01da, though that doesn't yet
fully pass due to conflicts in it's upgrade process.

Include documentation for out of tree best practices.

Change-Id: I02a777077d40408766204b05ed284fe98efbce8e
",git fetch https://review.opendev.org/openstack/grenade refs/changes/50/185050/1 && git format-patch -1 --stdout FETCH_HEAD,['inc/plugin'],1,82927646597528075ec334c75c9cc187d8bfb976,ext_plugin," # In tree plugins # External plugins local plugins=""${GRENADE_PLUGINS}"" local plugin # short circuit if nothing to do if [[ -z $plugins ]]; then return fi echo ""Loading plugin settings"" for plugin in ${plugins//,/ }; do local dir=${GITDIR[$plugin]} # source any known settings if [[ -f $dir/devstack/upgrade/settings ]]; then source $dir/devstack/upgrade/settings fi done # External plugin interface for grenade function enable_grenade_plugin { local name=$1 local url=$2 local branch=${3:-$TARGET_DEVSTACK_BRANCH} GRENADE_PLUGINS+="",$name"" # NOTE(sdague): we're intentional namespace colliding with # devstack to reuse devstack architecture. I don't think this is # going to get us in trouble, but it might. So here be dragons, or # at least small fierce lizards of unknown providence. GITREPO[$name]=$url GITDIR[$name]=$STACK_ROOT/plugins/$name GITBRANCH[$name]=$branch } function fetch_grenade_plugins { local plugins=""${GRENADE_PLUGINS}"" local plugin # short circuit if nothing to do if [[ -z $plugins ]]; then return fi echo ""Fetching Grenade plugins"" for plugin in ${plugins//,/ }; do git_clone_by_name $plugin done }",,51,0
openstack%2Fastara~master~I140227cad770fadfd4d2157149da2c6c65c2d1a2,openstack/astara,master,I140227cad770fadfd4d2157149da2c6c65c2d1a2,Get devstack running in the gate (DO NOT MERGE),ABANDONED,2015-06-01 19:04:20.000000000,2015-06-10 17:43:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 8005}, {'_account_id': 16341}]","[{'number': 1, 'created': '2015-06-01 19:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/f2a40dfa081a2369ba2b493ef4a86249ca18abe9', 'message': 'Do not hard-code requirements path when adding blessed\n\nAvoid using a hard-coded path here, causing issues in slave nodes.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 2, 'created': '2015-06-01 19:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/b0530eeb8705713e65fa39af1694a86ca3fbfef9', 'message': 'Do not hard-code requirements path when adding blessed\n\nAvoid using a hard-coded path here, causing issues in slave nodes.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 3, 'created': '2015-06-01 20:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d8f9cea6e694564b8f20a6e74d6e0167e7910b1f', 'message': 'Do not hard-code requirements path when adding blessed\n\nAvoid using a hard-coded path here, causing issues in slave nodes.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 4, 'created': '2015-06-01 20:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/bc3dba189f7686260dbd2472c919b3a099233712', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 5, 'created': '2015-06-01 21:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/6dcc4290dafd4deb8e5801d3e02cbaab6849b899', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 6, 'created': '2015-06-01 21:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d394c91724ab56b8c1de9204ac4b489759a8997d', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 7, 'created': '2015-06-01 23:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/113195ebd5d29d8000d9cc2ac47fd60ec9a7c84b', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 8, 'created': '2015-06-01 23:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/fce2aea1ddad7219043d91ebc49fbcf3c17d4f1d', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 9, 'created': '2015-06-02 01:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/5cf8c115631c6e92b909d155a68cd9d25031991a', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 10, 'created': '2015-06-02 01:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/1f479ba39732c469a366b054d3ec66ab44c6ebc3', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 11, 'created': '2015-06-02 01:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/fe8eb1bf83ccb8284b53eface3c045db424ecb95', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 12, 'created': '2015-06-02 02:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/c1632a93a3002ff8dd39e676635a4bc610b5271c', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 13, 'created': '2015-06-02 05:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d4ad13f2a26a4e74238d968e6a7db54e19025b04', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 14, 'created': '2015-06-02 05:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/11af36ff7adf9198d37d4c531460d87323b22f11', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 15, 'created': '2015-06-02 06:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/a649b9f418c399dd8407eccec258d821b33f6e96', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 16, 'created': '2015-06-02 07:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/734a122511778d8cf9d18402ccf0b512492a8c0d', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 17, 'created': '2015-06-02 17:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/8436fc06613f763a4d4ad497f38f2c295e1aad5e', 'message': 'Remove blessed from requirements\n\nThis drops blessed from our requirements, as it is not part of OpenStack\nglobal-requirements.  Instead, it adds a try/except around the only\nplace its imported.  Users will get an error when attempting to browse\nrouters, but the rest of the CLI should be functional.\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 18, 'created': '2015-06-02 19:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/bede8916fb53fed7d83d343061551ee3b301ca76', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 19, 'created': '2015-06-02 19:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/ea151a2606ad5d01bfea2d01bb519988dd71f78a', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 20, 'created': '2015-06-02 20:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/273970215c8367c669c150e1cededdd0c704d8f8', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 21, 'created': '2015-06-03 05:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/3b8afd2725f6caba1328e28bd5caca7eaaa1126b', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 22, 'created': '2015-06-03 17:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/73701fb95b9f731713f88e19146b48c90308ef70', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 23, 'created': '2015-06-03 17:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/a52ae1d944f28be72cc6e5353d3b7938b36f8172', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 24, 'created': '2015-06-03 20:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/9f3ed16604c60523f67fcfa9a85716d74eac4b27', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 25, 'created': '2015-06-03 21:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/1c2b73fa7a32048824737afecad2a76c7277ecb5', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 26, 'created': '2015-06-03 23:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/1085ee9ee6920cc319524c4b4f7bc7c509b8a6ad', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 27, 'created': '2015-06-05 18:28:09.000000000', 'files': ['tools/run_functional.sh'], 'web_link': 'https://opendev.org/openstack/astara/commit/de1e80e8b243983d6b02fe982f731eee0cf77018', 'message': 'Get devstack running in the gate (DO NOT MERGE)\n\nDebugging experimental job\n\nChange-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}]",2,187283,de1e80e8b243983d6b02fe982f731eee0cf77018,108,4,27,1420,,,0,"Get devstack running in the gate (DO NOT MERGE)

Debugging experimental job

Change-Id: I140227cad770fadfd4d2157149da2c6c65c2d1a2
",git fetch https://review.opendev.org/openstack/astara refs/changes/83/187283/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,f2a40dfa081a2369ba2b493ef4a86249ca18abe9,blessed_devstack," echo ""blessed"" >> $REQUIREMENTS_DIR/global-requirements.txt"," echo ""blessed"" >> /opt/stack/requirements/global-requirements.txt",1,1
openstack%2Fcookbook-openstack-network~master~Ia584a6c6a64fcaa92012c957da004ac029ca7db2,openstack/cookbook-openstack-network,master,Ia584a6c6a64fcaa92012c957da004ac029ca7db2,Auth_url changes following auth_plugin in nova section,MERGED,2015-05-28 10:25:03.000000000,2015-06-10 17:38:41.000000000,2015-06-10 17:38:40.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 8112}, {'_account_id': 10486}, {'_account_id': 12323}]","[{'number': 1, 'created': '2015-05-28 10:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/016a6d9c0c7bfe6c3ea051c9acad649b67170033', 'message': ""Remove the v2.0 uri path from nova.auth_url in neutron.conf\n\nAs described in bug 1449058, the auth_url of nova in neutron.conf\nshould be like 'auth_url = http://127.0.0.1:35357'. But current\ncode still using 'auth_url = http://127.0.0.1:35357/v2.0'. So\nhere using correct auth_url of nova in neutron.conf\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\n""}, {'number': 2, 'created': '2015-06-03 06:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/7fd063fa0cbec7a8c5cece36ce23acd474781603', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\n'}, {'number': 3, 'created': '2015-06-03 08:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/2ed19d2ec1f2f6d542b38ea6075f86db00d70261', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\n'}, {'number': 4, 'created': '2015-06-03 09:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/df0d632c8dc04a04ac2d948eb5dcb459493eaa72', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\n'}, {'number': 5, 'created': '2015-06-03 11:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/68eb5276acdccb484ad1bc6fd7a1d431dc2d15e5', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\nCloses-bug: #1461480\n'}, {'number': 6, 'created': '2015-06-04 13:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/92f167cfd1c1dc0eda87718ff0e34a3897060763', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\nCloses-bug: #1461480\n'}, {'number': 7, 'created': '2015-06-05 03:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/01e6074cf7db87a77b43fccd3e0431648ccb4385', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\nCloses-bug: #1461480\n'}, {'number': 8, 'created': '2015-06-08 03:51:50.000000000', 'files': ['attributes/default.rb', 'spec/default_spec.rb', 'templates/default/neutron.conf.erb', 'recipes/default.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/aea5f5ac7bccdb6fff8990d7c9ae88d157d0f8a0', 'message': 'Auth_url changes following auth_plugin in nova section\n\nAfter the refact of nova authentication in neutron, it supports\nthree auth_plugin: password, v2password, v3password. Each\nauth_plugin match a different auth_url. For example:\na) password\nauth_plugin = password\nauth_url = http://127.0.0.1:35357/\nb) v2password\nauth_plugin = v2password\nauth_url = http://127.0.0.1:35357/v2.0\nc) v3password\nauth_plugin = v3password\nauth_url = http://127.0.0.1:35357/v3\n\nThe auth_url should be set following the auth_plugin automatically.\n\nChange-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2\nCloses-bug: #1459594\nCloses-bug: #1461480\n'}]",10,186347,aea5f5ac7bccdb6fff8990d7c9ae88d157d0f8a0,32,5,8,10486,,,0,"Auth_url changes following auth_plugin in nova section

After the refact of nova authentication in neutron, it supports
three auth_plugin: password, v2password, v3password. Each
auth_plugin match a different auth_url. For example:
a) password
auth_plugin = password
auth_url = http://127.0.0.1:35357/
b) v2password
auth_plugin = v2password
auth_url = http://127.0.0.1:35357/v2.0
c) v3password
auth_plugin = v3password
auth_url = http://127.0.0.1:35357/v3

The auth_url should be set following the auth_plugin automatically.

Change-Id: Ia584a6c6a64fcaa92012c957da004ac029ca7db2
Closes-bug: #1459594
Closes-bug: #1461480
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/47/186347/8 && git format-patch -1 --stdout FETCH_HEAD,"['spec/default_spec.rb', 'templates/default/neutron.conf.erb']",2,016a6d9c0c7bfe6c3ea051c9acad649b67170033,bug/1459594,auth_url = <%= @identity_uri %>,auth_url = <%= @identity_admin_endpoint.to_s %>,2,2
openstack%2Fnova~master~I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9,openstack/nova,master,I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9,libvirt: make default_device_names DRY-er,MERGED,2015-05-06 17:23:16.000000000,2015-06-10 17:34:20.000000000,2015-06-10 17:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10224}, {'_account_id': 10385}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-06 17:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1485238d2f90fa910fb0b8c74027acecd28aa4f2', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 2, 'created': '2015-05-21 09:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4cf339f85ab13816e4f39153857c3485b7e14d0', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 3, 'created': '2015-05-22 12:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d20b20c783b77831a0d633b022b3972f8d848d52', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 4, 'created': '2015-05-27 11:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/889249f4bd6a41967b6feaec9c543c6be53ed832', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 5, 'created': '2015-05-27 15:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c099d1547d86c3509315b702fa4bae10eb050dc', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 6, 'created': '2015-05-28 09:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51d8d155d1c9b8662b334aa6e73e59c540076aa2', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 7, 'created': '2015-06-08 11:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/183a11d7e5245318f141b40c301de367050b08a0', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}, {'number': 8, 'created': '2015-06-09 10:09:51.000000000', 'files': ['nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_blockinfo.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb3d3773a2c2b07af2849608f1481c9f37a9ec62', 'message': ""libvirt: make default_device_names DRY-er\n\nSince we now have a reusable method to call to get the block_device_info\nstructure that most driver code is designed to work with, we don't need\nto re-write it in the blockinfo code - we can just use it.\n\nIn addition to this - this fixes a (yet unreported) issue that libvirt\nwould not consider blank volumes in it's device assignments.\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9\n""}]",0,180636,fb3d3773a2c2b07af2849608f1481c9f37a9ec62,78,19,8,5511,,,0,"libvirt: make default_device_names DRY-er

Since we now have a reusable method to call to get the block_device_info
structure that most driver code is designed to work with, we don't need
to re-write it in the blockinfo code - we can just use it.

In addition to this - this fixes a (yet unreported) issue that libvirt
would not consider blank volumes in it's device assignments.

Related-bug: 1231874
Partial-bug: 1452224

Change-Id: I4b9a6fd1b08ff787fdd1226f533f4181fe44b7e9
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/180636/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/blockinfo.py', 'nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_blockinfo.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,1485238d2f90fa910fb0b8c74027acecd28aa4f2,bug/1452224," @mock.patch.object(driver, ""get_block_device_info"") def test_default_device_names_for_instance( self, mock_meta, mock_devnames, mock_blockinfo): instance.root_device_name = '/dev/vda' mock_blockinfo.return_value = 'fake-block-device-info' drvr.default_device_names_for_instance(instance, instance.root_device_name, instance, 'fake-block-device-info',"," def test_default_device_names_for_instance(self, mock_meta, mock_devnames): root_device_name = '/dev/vda' drvr.default_device_names_for_instance(instance, root_device_name, instance, root_device_name, ephemerals, swap, block_device_mapping,",20,31
openstack%2Fnova~master~I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f,openstack/nova,master,I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f,Add and use raise_feature_not_supported(),MERGED,2015-03-12 05:04:34.000000000,2015-06-10 17:33:57.000000000,2015-06-10 17:33:52.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-12 05:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe5733a926d62cb743c36caf7cbadffae738fd8f', 'message': 'Add and use raise_http_not_implemented_error()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_http_not_implemented_error() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 2, 'created': '2015-03-12 08:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36307d728c6adf34b92067a240a6d74c4c552d4a', 'message': 'Add and use raise_http_not_implemented_error()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_http_not_implemented_error() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 3, 'created': '2015-03-17 00:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3fdc4c65fa8e304e48da0cccd9976a7f493b45aa', 'message': 'Add and use raise_http_not_implemented_error()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_http_not_implemented_error() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 4, 'created': '2015-03-19 22:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6db1ed5a47023e74e8269ba54a2e22bf92479685', 'message': 'Add and use raise_http_not_implemented_error()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_http_not_implemented_error() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 5, 'created': '2015-05-11 19:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb53167b19889e4a74f6a7a5c65a345f46c3b7ca', 'message': 'Add and use raise_http_not_implemented_error()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_http_not_implemented_error() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 6, 'created': '2015-06-01 07:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/def20dadb892541a816540501c9438e2108fdc78', 'message': 'Add and use raise_feature_not_supported()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_feature_not_supported() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 7, 'created': '2015-06-01 23:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11be282ea4940b9f5dfd9835d66c39b515deb1d6', 'message': 'Add and use raise_feature_not_supported()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_feature_not_supported() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 8, 'created': '2015-06-02 02:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56565d071c070fdd7b703a4e17a85a4a87b5aeb7', 'message': 'Add and use raise_feature_not_supported()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_feature_not_supported() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}, {'number': 9, 'created': '2015-06-08 03:18:37.000000000', 'files': ['nova/api/openstack/compute/plugins/v3/certificates.py', 'nova/api/openstack/compute/plugins/v3/floating_ip_dns.py', 'nova/api/openstack/compute/plugins/v3/pause_server.py', 'nova/api/openstack/compute/plugins/v3/server_diagnostics.py', 'nova/api/openstack/common.py', 'nova/api/openstack/compute/plugins/v3/admin_password.py', 'nova/api/openstack/compute/plugins/v3/baremetal_nodes.py', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py', 'nova/api/openstack/compute/plugins/v3/console_output.py', 'nova/api/openstack/compute/plugins/v3/remote_consoles.py', 'nova/api/openstack/compute/plugins/v3/networks.py', 'nova/api/openstack/compute/plugins/v3/hypervisors.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/networks_associate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/735c45070e67a3c080bb706af6639106dfd16cb2', 'message': 'Add and use raise_feature_not_supported()\n\nIn HTTPNotImplemented cases, each API passes its original message.\nThe meaning of these messages are almost the same but messages are\ninconsistent.\nThis patch adds common raise_feature_not_supported() and replaces\nthese messages with the method for consistent message.\n\nPartially implements blueprint v2-on-v3-api\n\nChange-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f\n'}]",9,163697,735c45070e67a3c080bb706af6639106dfd16cb2,94,19,9,6167,,,0,"Add and use raise_feature_not_supported()

In HTTPNotImplemented cases, each API passes its original message.
The meaning of these messages are almost the same but messages are
inconsistent.
This patch adds common raise_feature_not_supported() and replaces
these messages with the method for consistent message.

Partially implements blueprint v2-on-v3-api

Change-Id: I23da9bf153cb92944c0f4e76d70ce72a4ff6b16f
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/163697/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/plugins/v3/floating_ip_dns.py', 'nova/api/openstack/compute/plugins/v3/pause_server.py', 'nova/api/openstack/compute/plugins/v3/server_diagnostics.py', 'nova/api/openstack/common.py', 'nova/api/openstack/compute/plugins/v3/admin_password.py', 'nova/api/openstack/compute/plugins/v3/baremetal_nodes.py', 'nova/api/openstack/compute/plugins/v3/attach_interfaces.py', 'nova/api/openstack/compute/plugins/v3/console_output.py', 'nova/api/openstack/compute/plugins/v3/remote_consoles.py', 'nova/api/openstack/compute/plugins/v3/networks.py', 'nova/api/openstack/compute/plugins/v3/hypervisors.py', 'nova/api/openstack/compute/plugins/v3/hosts.py', 'nova/api/openstack/compute/plugins/v3/networks_associate.py']",13,fe5733a926d62cb743c36caf7cbadffae738fd8f,bp/v2-on-v3-api,from nova.api.openstack import common common.raise_http_not_implemented_error() common.raise_http_not_implemented_error() common.raise_http_not_implemented_error(), msg = _('Disassociate host is not implemented by the configured ' 'Network API') raise exc.HTTPNotImplemented(explanation=msg) msg = _('Disassociate project is not implemented by the ' 'configured Network API') raise exc.HTTPNotImplemented(explanation=msg) msg = _('Associate host is not implemented by the configured ' 'Network API') raise exc.HTTPNotImplemented(explanation=msg),40,71
openstack%2Fironic-python-agent~master~I333b0a1243f0e61f6957f161fea38351968816d0,openstack/ironic-python-agent,master,I333b0a1243f0e61f6957f161fea38351968816d0,Add docs tests to default tox envlist in IPA,ABANDONED,2015-06-08 21:13:16.000000000,2015-06-10 17:31:58.000000000,,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10343}, {'_account_id': 10380}]","[{'number': 1, 'created': '2015-06-08 21:13:16.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6cbdbd9983adc9e4f3937feb20dc7e4c3c01e48a', 'message': ""Add docs tests to default tox envlist in IPA\n\nIf we're going to gate on it, it should be in the default list.\n\nChange-Id: I333b0a1243f0e61f6957f161fea38351968816d0\n""}]",0,189455,6cbdbd9983adc9e4f3937feb20dc7e4c3c01e48a,7,4,1,10380,,,0,"Add docs tests to default tox envlist in IPA

If we're going to gate on it, it should be in the default list.

Change-Id: I333b0a1243f0e61f6957f161fea38351968816d0
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/55/189455/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6cbdbd9983adc9e4f3937feb20dc7e4c3c01e48a,(HEAD,"envlist = py27,pep8,docs","envlist = py27,pep8",1,1
openstack%2Fastara~master~I2b54ddfcce8dab446ac7418cca61320b370bc999,openstack/astara,master,I2b54ddfcce8dab446ac7418cca61320b370bc999,Wait for a configured test router to become active,MERGED,2015-06-08 20:36:34.000000000,2015-06-10 17:31:24.000000000,2015-06-10 17:31:23.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6923}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-08 20:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/a255bc9637e0c3e98665a6ac18fc277010269ea4', 'message': 'Wait for a configured test router to become active\n\nThe router VM that is spawned during RUG startup may not be active until some\ntime after the test suite, causing tests to start before the thing is active.\nThis adds an assertion to the functional test setUp to wait for a configured\nrouter to become active before continuing on with any tests.  The router to\nwait on is now configured in test.conf.  run_functional.sh will attempt to find\nthe devstack created one, and error if there are multiples.  Users can specify\ntheir own test router if running outside of the gate env.\n\nChange-Id: I2b54ddfcce8dab446ac7418cca61320b370bc999\n'}, {'number': 2, 'created': '2015-06-08 21:19:33.000000000', 'files': ['.gitignore', 'akanda/rug/test/functional/test_service_vm.py', 'akanda/rug/test/functional/test.conf', 'akanda/rug/test/functional/base.py', 'akanda/rug/test/functional/test.conf.sample', 'tools/run_functional.sh'], 'web_link': 'https://opendev.org/openstack/astara/commit/9942eb143378bb1e65d2dc604e3b2c25d01cb894', 'message': 'Wait for a configured test router to become active\n\nThe router VM that is spawned during RUG startup may not be active until some\ntime after the test suite, causing tests to start before the thing is active.\nThis adds an assertion to the functional test setUp to wait for a configured\nrouter to become active before continuing on with any tests.  The router to\nwait on is now configured in test.conf.  run_functional.sh will attempt to find\nthe devstack created one, and error if there are multiples.  Users can specify\ntheir own test router if running outside of the gate env.\n\nChange-Id: I2b54ddfcce8dab446ac7418cca61320b370bc999\n'}]",4,189433,9942eb143378bb1e65d2dc604e3b2c25d01cb894,23,4,2,1420,,,0,"Wait for a configured test router to become active

The router VM that is spawned during RUG startup may not be active until some
time after the test suite, causing tests to start before the thing is active.
This adds an assertion to the functional test setUp to wait for a configured
router to become active before continuing on with any tests.  The router to
wait on is now configured in test.conf.  run_functional.sh will attempt to find
the devstack created one, and error if there are multiples.  Users can specify
their own test router if running outside of the gate env.

Change-Id: I2b54ddfcce8dab446ac7418cca61320b370bc999
",git fetch https://review.opendev.org/openstack/astara refs/changes/33/189433/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'akanda/rug/test/functional/test_service_vm.py', 'akanda/rug/test/functional/test.conf', 'akanda/rug/test/functional/base.py', 'akanda/rug/test/functional/test.conf.sample', 'tools/run_functional.sh']",6,a255bc9637e0c3e98665a6ac18fc277010269ea4,189433,"# Functional tests require a test akanda router be created prior to the test # run. Devstack does this, but you may specify another here. If not specified, # the ID of the devstack created router will be used. AKANDA_TEST_ROUTER_UUID=${AKANDA_TEST_ROUTER_UUID:-''} function find_router() { # Find the UUID of the akanda router created by devstack. router=$(neutron router-list | grep ""ak-"" | awk '{ print $2 }') if [ $(echo ""$router"" | wc -l) -gt 1 ]; then echo ""ERROR: Found multiple akanda routers, cannot continue."" exit 1 elif [ -z ""$router"" ]; then echo ""ERROR: Could not locate akanda router."" exit 1 fi echo $router } appliance_active_timeout=240if [ -z ""$AKANDA_TEST_ROUTER_UUID"" ]; then AKANDA_TEST_ROUTER_UUID=""$(find_router)"" fi echo ""akanda_test_router_uuid=$AKANDA_TEST_ROUTER_UUID"" >>$CONFIG_FILE ",,81,12
openstack%2Fbarbican~master~I60ccfaaa43aa4aa68e99affb9837ecab48c36759,openstack/barbican,master,I60ccfaaa43aa4aa68e99affb9837ecab48c36759,service_enabled instead of environment variable for dogtag,MERGED,2015-05-22 22:50:10.000000000,2015-06-10 17:23:55.000000000,2015-06-10 16:31:18.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-22 22:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/51036d00f50cbc4c9f9b370f0dfff07c2c2dc651', 'message': 'service_enabled instead of environment variable for dogtag\n\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 2, 'created': '2015-05-22 23:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/05c8ff5b553825913173dd117cbd3068040b7bdb', 'message': 'service_enabled instead of environment variable for dogtag\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 3, 'created': '2015-05-26 08:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/a534c043426b67a0bc45d3579a01587163444fd7', 'message': 'service_enabled instead of environment variable for dogtag\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 4, 'created': '2015-05-26 15:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/aa83564d5b8eabca345572cd35b8d52b6c618503', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 5, 'created': '2015-06-04 07:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/68ea7f4f22d94e1f83350822ee854d7ee8ac683e', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 6, 'created': '2015-06-04 07:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/81ee3c840d17f611504c39191e5418a20452692b', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 7, 'created': '2015-06-04 09:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1ec498560e74303e9116c11202dc9d7aa671058d', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 8, 'created': '2015-06-04 09:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/48dab663ffc8cff88651eefa2630b14889f57adf', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 9, 'created': '2015-06-04 10:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/eaf6afd4d98e4d504ba84268ef426391ddfc0267', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 10, 'created': '2015-06-04 10:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f1c5ff0fab578b665b9b80c3a200ffa46d2dd9e6', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 11, 'created': '2015-06-04 10:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7ae1bcce8d4613a4e25dfbd13ed8b1c80f278a8e', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 12, 'created': '2015-06-04 11:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e163f620740fc502058035a05729d4b8df100e2c', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 13, 'created': '2015-06-04 13:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8a461d799beb534237ddb29364ae495f7e263dd4', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 14, 'created': '2015-06-04 14:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/e42ba8d855ffdb907ccdc1a6f3ebeef498950d3a', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 15, 'created': '2015-06-04 17:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3a872a79ec137a80081f6b6702347ae576a27851', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 16, 'created': '2015-06-04 17:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6c2960b705804bef6264103d0e077785b471d686', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 17, 'created': '2015-06-05 12:51:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/612398dd0ac6838c586e168965b6efe4c21c3039', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 18, 'created': '2015-06-08 13:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/45393c2cf3501d15571a520782006fb26d158aba', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 19, 'created': '2015-06-08 19:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1f8a514d9b23785a4c1e3095630eca13a7419151', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 20, 'created': '2015-06-09 07:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4de40e39827caba1576a20db29f9b90641595968', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}, {'number': 21, 'created': '2015-06-10 10:19:36.000000000', 'files': ['contrib/devstack/lib/barbican', 'contrib/devstack/extras.d/70-barbican.sh', 'functionaltests/pre_test_hook.sh', 'contrib/dogtag/install_dogtag.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/a488cdd53d1b51299ec1d137576fe5b1c33993e2', 'message': 'service_enabled instead of environment variable for dogtag\n\nThis change also adds the dogtag installation functions into the\ncontrib/devstack/lib/barbican scripts, and enables the installation of\ndogtag in the extras.d script making the calling of the dogtag\ninstallation from the functional test pre-hook script not necessary.\n\nDepends-on: I749539f387f163e829fdc8390b6bd16cf23c663b\nChange-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759\n'}]",0,185181,a488cdd53d1b51299ec1d137576fe5b1c33993e2,104,9,21,10873,,,0,"service_enabled instead of environment variable for dogtag

This change also adds the dogtag installation functions into the
contrib/devstack/lib/barbican scripts, and enables the installation of
dogtag in the extras.d script making the calling of the dogtag
installation from the functional test pre-hook script not necessary.

Depends-on: I749539f387f163e829fdc8390b6bd16cf23c663b
Change-Id: I60ccfaaa43aa4aa68e99affb9837ecab48c36759
",git fetch https://review.opendev.org/openstack/barbican refs/changes/81/185181/17 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/extras.d/70-barbican.sh'],1,51036d00f50cbc4c9f9b370f0dfff07c2c2dc651,alee_fix_dogtag_certdb, if is_service_enabled barbican-dogtag; then, if [[ -n $BARBICAN_USE_DOGTAG ]]; then,1,1
openstack%2Foslo.messaging~master~I5164b9e1b720f022b45a5718258df036ba8808ed,openstack/oslo.messaging,master,I5164b9e1b720f022b45a5718258df036ba8808ed,rabbit: Add logging on blocked connection,MERGED,2015-05-27 06:36:09.000000000,2015-06-10 17:11:52.000000000,2015-06-10 17:11:50.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 7491}, {'_account_id': 8873}]","[{'number': 1, 'created': '2015-05-27 06:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/cb710ac4d1fef707d87cc4f9d45642c5dfdeb827', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 2, 'created': '2015-05-27 14:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/0e7be0e96fb09cfc8d9f0ea477c0468d062a1d2e', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 3, 'created': '2015-05-27 14:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8671c5cf2a2fee5b740fb6bf91e84f0a12306dd6', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 4, 'created': '2015-05-27 15:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/894fbb544f94e42f93cee4a58b80a71e28f2181b', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 5, 'created': '2015-05-28 05:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/26bc58f677c571da1caf18b55b75d6c6677d1570', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 6, 'created': '2015-05-29 14:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/bd80bb60959e6ec2777c0d286bd0b682d7a63303', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 7, 'created': '2015-06-08 12:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/178c4070b70b0affda19233d4759806781d9e12e', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}, {'number': 8, 'created': '2015-06-09 08:35:32.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1f8ccd3ac50aa941f042b02069b7185c3d5b5ae7', 'message': 'rabbit: Add logging on blocked connection\n\nWhen the broker will block the connection for a server-side issue\nlike disk full, it notifies the client.\n\nThis change adds the callback methods when this occurs to inform\nthe deployer about the reason of this blocking.\n\nChange-Id: I5164b9e1b720f022b45a5718258df036ba8808ed\nCloses-bug: #1454449\n'}]",12,185851,1f8ccd3ac50aa941f042b02069b7185c3d5b5ae7,39,6,8,2813,,,0,"rabbit: Add logging on blocked connection

When the broker will block the connection for a server-side issue
like disk full, it notifies the client.

This change adds the callback methods when this occurs to inform
the deployer about the reason of this blocking.

Change-Id: I5164b9e1b720f022b45a5718258df036ba8808ed
Closes-bug: #1454449
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/51/185851/8 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,cb710ac4d1fef707d87cc4f9d45642c5dfdeb827,bug/1454449," heartbeat=self.driver_conf.heartbeat_timeout_threshold, on_blocked=self._on_connection_blocked, on_unblocked=self._on_connection_unblocked, ) def _on_connection_blocked(self, reason): LOG.warn(_LW(""The broker have blocked the connection: %s"", reason)) def _on_connection_unblocked(self): LOG.warn(_LW(""The broker have unblocked the connection"")) ", heartbeat=self.driver_conf.heartbeat_timeout_threshold),10,1
openstack%2Fpuppet-glance~stable%2Fjuno~Id72991da18dd1f467a7683f8f450e157da64f969,openstack/puppet-glance,stable/juno,Id72991da18dd1f467a7683f8f450e157da64f969,Support identity_uri,ABANDONED,2015-06-01 20:48:32.000000000,2015-06-10 17:10:27.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-01 20:48:32.000000000', 'files': ['manifests/registry.pp', 'manifests/api.pp', 'spec/classes/glance_registry_spec.rb', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/a7bf1b8e0c53ef04d44be17e6a84e9b9551a7fea', 'message': 'Support identity_uri\n\nThis patch adds the ability to set a new identity_uri parameter.\nIt also deprecates the old auth_host, auth_port, auth_protocol,\nand auth_admin_prefix parameters. Logic is in place so that\nusers of the deprecated settings should have a smooth upgrade\nprocess and get deprecation warnings until they adopt the\nnew settings.\n\nChange-Id: Id72991da18dd1f467a7683f8f450e157da64f969\nCloses-Bug: #1391235\n(cherry-picked from commit 2dff962a6505b890654f8a258638e746194ad35e)\n'}]",0,187329,a7bf1b8e0c53ef04d44be17e6a84e9b9551a7fea,6,3,1,8482,,,0,"Support identity_uri

This patch adds the ability to set a new identity_uri parameter.
It also deprecates the old auth_host, auth_port, auth_protocol,
and auth_admin_prefix parameters. Logic is in place so that
users of the deprecated settings should have a smooth upgrade
process and get deprecation warnings until they adopt the
new settings.

Change-Id: Id72991da18dd1f467a7683f8f450e157da64f969
Closes-Bug: #1391235
(cherry-picked from commit 2dff962a6505b890654f8a258638e746194ad35e)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/29/187329/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/registry.pp', 'manifests/api.pp', 'spec/classes/glance_api_spec.rb', 'spec/classes/glance_registry_spec.rb']",4,a7bf1b8e0c53ef04d44be17e6a84e9b9551a7fea,juno," describe 'with identity and auth settings' do let :params do { :keystone_password => 'ChangeMe', } end context 'with custom keystone identity_uri' do before do params.merge!({ :identity_uri => 'https://foo.bar:1234/', }) end it 'configures identity_uri' do should contain_glance_registry_config('keystone_authtoken/identity_uri').with_value(""https://foo.bar:1234/""); # since only auth_uri is set the deprecated auth parameters should # still get set in case they are still in use should contain_glance_registry_config('keystone_authtoken/auth_host').with_value('127.0.0.1'); should contain_glance_registry_config('keystone_authtoken/auth_port').with_value('35357'); should contain_glance_registry_config('keystone_authtoken/auth_protocol').with_value('http'); end end context 'with custom keystone identity_uri and auth_uri' do before do params.merge!({ :identity_uri => 'https://foo.bar:35357/', :auth_uri => 'https://foo.bar:5000/v2.0/', }) end it 'configures identity_uri' do should contain_glance_registry_config('keystone_authtoken/identity_uri').with_value(""https://foo.bar:35357/""); should contain_glance_registry_config('keystone_authtoken/auth_uri').with_value(""https://foo.bar:5000/v2.0/""); should contain_glance_registry_config('keystone_authtoken/auth_host').with_ensure('absent') should contain_glance_registry_config('keystone_authtoken/auth_port').with_ensure('absent') should contain_glance_registry_config('keystone_authtoken/auth_protocol').with_ensure('absent') should contain_glance_registry_config('keystone_authtoken/auth_admin_prefix').with_ensure('absent') end end end ",,196,45
openstack%2Fpuppet-glance~stable%2Fjuno~Ie8a2e45a4afea4828e02af36e64d65e7d4b7557e,openstack/puppet-glance,stable/juno,Ie8a2e45a4afea4828e02af36e64d65e7d4b7557e,Support identity_uri in provider,ABANDONED,2015-06-01 20:49:45.000000000,2015-06-10 17:09:59.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 13294}]","[{'number': 1, 'created': '2015-06-01 20:49:45.000000000', 'files': ['lib/puppet/provider/glance.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/7a9baba6d8bec38d632595d7d98303bb50de7772', 'message': 'Support identity_uri in provider\n\nAfter https://review.openstack.org/152321 was merged, it was no\nlonger guaranteed that some now deprecated settings like auth_host\nand auth_protocol would be present in glance-api.conf. This breaks\nthe Glance provider, which expects them to be present.\n\nThis patch adds support for identity_uri in provider, while\nkeeping backwards compatibility.\n\nChange-Id: Ie8a2e45a4afea4828e02af36e64d65e7d4b7557e\n(cherry picked from commit 9f44421ceb54f970986fd96d2e66faccba1909ec)\n'}]",0,187330,7a9baba6d8bec38d632595d7d98303bb50de7772,5,5,1,8482,,,0,"Support identity_uri in provider

After https://review.openstack.org/152321 was merged, it was no
longer guaranteed that some now deprecated settings like auth_host
and auth_protocol would be present in glance-api.conf. This breaks
the Glance provider, which expects them to be present.

This patch adds support for identity_uri in provider, while
keeping backwards compatibility.

Change-Id: Ie8a2e45a4afea4828e02af36e64d65e7d4b7557e
(cherry picked from commit 9f44421ceb54f970986fd96d2e66faccba1909ec)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/30/187330/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/glance.rb'],1,7a9baba6d8bec38d632595d7d98303bb50de7772,," elsif glance_file and glance_file['keystone_authtoken'] and glance_file['keystone_authtoken']['identity_uri'] and glance_file['keystone_authtoken']['admin_tenant_name'] and glance_file['keystone_authtoken']['admin_user'] and glance_file['keystone_authtoken']['admin_password'] and glance_file['DEFAULT']['os_region_name'] g = {} g['identity_uri'] = glance_file['keystone_authtoken']['identity_uri'].strip g['admin_tenant_name'] = glance_file['keystone_authtoken']['admin_tenant_name'].strip g['admin_user'] = glance_file['keystone_authtoken']['admin_user'].strip g['admin_password'] = glance_file['keystone_authtoken']['admin_password'].strip g['os_region_name'] = glance_file['DEFAULT']['os_region_name'].strip return g if g.key?('identity_uri') ""#{g['identity_uri']}/"" else ""#{g['auth_protocol']}://#{g['auth_host']}:#{g['auth_port']}#{g['auth_admin_prefix']}/v2.0/"" end"," ""#{g['auth_protocol']}://#{g['auth_host']}:#{g['auth_port']}#{g['auth_admin_prefix']}/v2.0/""",20,1
openstack%2Fpuppet-ceilometer~stable%2Fjuno~Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb,openstack/puppet-ceilometer,stable/juno,Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb,Add support for identity_uri.,ABANDONED,2015-06-04 20:14:04.000000000,2015-06-10 17:09:45.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 7156}]","[{'number': 1, 'created': '2015-06-04 20:14:04.000000000', 'files': ['manifests/api.pp', 'spec/classes/ceilometer_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/6b995734dc8dfbcff0a5975bf3ecc9b7e5881adc', 'message': 'Add support for identity_uri.\n\nThis patch adds the ability to set a new keystone_identity_uri\nparameter.  It also deprecates the old keystone_host, keystone_port,\nkeystone_protocol, and keystone_auth_admin_prefix parameters. Logic\nis in place so that users of the deprecated settings should have a\nsmooth upgrade process and get deprecation warnings until they adopt\nthe new settings.\n\nChange-Id: Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb\n(cherry-picked from commit 70faac7cfe4dafedea034dab81a32c758a524b61)\n'}]",0,188570,6b995734dc8dfbcff0a5975bf3ecc9b7e5881adc,5,4,1,8482,,,0,"Add support for identity_uri.

This patch adds the ability to set a new keystone_identity_uri
parameter.  It also deprecates the old keystone_host, keystone_port,
keystone_protocol, and keystone_auth_admin_prefix parameters. Logic
is in place so that users of the deprecated settings should have a
smooth upgrade process and get deprecation warnings until they adopt
the new settings.

Change-Id: Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb
(cherry-picked from commit 70faac7cfe4dafedea034dab81a32c758a524b61)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/70/188570/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/ceilometer_api_spec.rb']",2,6b995734dc8dfbcff0a5975bf3ecc9b7e5881adc,juno," describe ""with custom keystone identity_uri"" do let :facts do { :osfamily => 'RedHat' } end before do params.merge!({ :keystone_identity_uri => 'https://foo.bar:1234/', }) end it 'configures identity_uri' do should contain_ceilometer_config('keystone_authtoken/identity_uri').with_value(""https://foo.bar:1234/""); # since only auth_uri is set the deprecated auth parameters should # still get set in case they are still in use should contain_ceilometer_config('keystone_authtoken/auth_host').with_value('127.0.0.1'); should contain_ceilometer_config('keystone_authtoken/auth_port').with_value('35357'); should contain_ceilometer_config('keystone_authtoken/auth_protocol').with_value('http'); end end describe ""with custom keystone identity_uri and auth_uri"" do let :facts do { :osfamily => 'RedHat' } end before do params.merge!({ :keystone_identity_uri => 'https://foo.bar:35357/', :keystone_auth_uri => 'https://foo.bar:5000/v2.0/', }) end it 'configures identity_uri and auth_uri but deprecates old auth settings' do should contain_ceilometer_config('keystone_authtoken/identity_uri').with_value(""https://foo.bar:35357/""); should contain_ceilometer_config('keystone_authtoken/auth_uri').with_value(""https://foo.bar:5000/v2.0/""); should contain_ceilometer_config('keystone_authtoken/auth_admin_prefix').with(:ensure => 'absent') should contain_ceilometer_config('keystone_authtoken/auth_port').with(:ensure => 'absent') should contain_ceilometer_config('keystone_authtoken/auth_protocol').with(:ensure => 'absent') should contain_ceilometer_config('keystone_authtoken/auth_host').with(:ensure => 'absent') end end ",,116,19
openstack%2Fpuppet-swift~stable%2Fjuno~Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb,openstack/puppet-swift,stable/juno,Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb,Add support for identity_uri.,ABANDONED,2015-06-05 22:09:59.000000000,2015-06-10 17:09:28.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 7156}]","[{'number': 1, 'created': '2015-06-05 22:09:59.000000000', 'files': ['manifests/proxy/authtoken.pp', 'spec/classes/swift_proxy_authtoken_spec.rb', 'templates/proxy/authtoken.conf.erb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/958705d86c75a6c01f6acde8cb8bb8caf4bab315', 'message': 'Add support for identity_uri.\n\nThis patch adds the ability to set a new identity_uri parameter.\nIt also deprecates the old auth_host, auth_port, auth_protocol,\nand auth_admin_prefix parameters. Logic is in place so that\nusers of the deprecated settings should have a smooth upgrade\nprocess and get deprecation warnings until they adopt the\nnew settings.\n\nChange-Id: Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb\n(cherry picked from commit 119ff9c3e081281208c9b7da4290e94456b6dfb7)\n'}]",0,188946,958705d86c75a6c01f6acde8cb8bb8caf4bab315,6,4,1,8482,,,0,"Add support for identity_uri.

This patch adds the ability to set a new identity_uri parameter.
It also deprecates the old auth_host, auth_port, auth_protocol,
and auth_admin_prefix parameters. Logic is in place so that
users of the deprecated settings should have a smooth upgrade
process and get deprecation warnings until they adopt the
new settings.

Change-Id: Ideefb4d824cbd5b4b83f9eb773a75e536e3458fb
(cherry picked from commit 119ff9c3e081281208c9b7da4290e94456b6dfb7)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/46/188946/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/proxy/authtoken.pp', 'spec/classes/swift_proxy_authtoken_spec.rb', 'templates/proxy/authtoken.conf.erb']",3,958705d86c75a6c01f6acde8cb8bb8caf4bab315,, <% if not @identity_uri or not @auth_uri then -%><% end -%><% if @identity_uri -%> identity_uri = <%= @identity_uri %> <% end -%>,,80,7
openstack%2Fnova~master~I3bf60e5ea225e394bca67edfd4b0302b80d28019,openstack/nova,master,I3bf60e5ea225e394bca67edfd4b0302b80d28019,VMware: ensure that the adapter type is used,MERGED,2015-04-02 09:27:20.000000000,2015-06-10 16:59:27.000000000,2015-06-10 16:59:23.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 7400}, {'_account_id': 7634}, {'_account_id': 8119}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 14039}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-02 09:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/053f18d755da9772479c68dbc2a6f375b550f1a6', 'message': 'VMware: ensure that the adapter type is used\n\nIn the event that the boot was done and the adapter type was not\npassed we should use the default adapter type on the image.\n\nChange-Id: I3bf60e5ea225e394bca67edfd4b0302b80d28019\nCloses-bug: #1439585\n'}, {'number': 2, 'created': '2015-05-12 02:35:15.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2b4fcc594b21dacac77797824fa53ec6756acf52', 'message': 'VMware: ensure that the adapter type is used\n\nIn the event that the boot was done and the adapter type was not\npassed we should use the default adapter type on the image.\n\nChange-Id: I3bf60e5ea225e394bca67edfd4b0302b80d28019\nCloses-bug: #1439585\n'}]",0,170054,2b4fcc594b21dacac77797824fa53ec6756acf52,26,15,2,1653,,,0,"VMware: ensure that the adapter type is used

In the event that the boot was done and the adapter type was not
passed we should use the default adapter type on the image.

Change-Id: I3bf60e5ea225e394bca67edfd4b0302b80d28019
Closes-bug: #1439585
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/170054/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py']",2,053f18d755da9772479c68dbc2a6f375b550f1a6,boot-ephemeral," def _spawn_with_block_device_info_ephemerals(self, ephemerals): block_device_info = {'ephemerals': ephemerals} self._test_spawn(block_device_info=block_device_info) self._spawn_with_block_device_info_ephemerals(ephemerals) def test_spawn_with_block_device_info_ephemerals_no_disk_bus(self): ephemerals = [{'device_type': 'disk', 'disk_bus': None, 'device_name': '/dev/vdb', 'size': 1}] self._spawn_with_block_device_info_ephemerals(ephemerals)", block_device_info = {'ephemerals': ephemerals} self._test_spawn(block_device_info=block_device_info),13,3
openstack%2Fnova~master~I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27,openstack/nova,master,I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27,Add policy check for extension_info,MERGED,2015-04-14 08:32:24.000000000,2015-06-10 16:58:56.000000000,2015-06-10 16:58:53.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8300}, {'_account_id': 8846}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11530}, {'_account_id': 12175}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}]","[{'number': 1, 'created': '2015-04-14 08:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a149bf65bd0a5c3d1ab85c8ae7326101df48f28c', 'message': 'Add missing policy for extension_info in API\n\nAdd default policy rule for extension_info extension\n\nChange-Id: I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27\nClose-Bug:#1415286\n'}, {'number': 2, 'created': '2015-04-20 06:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b34f2dbd3baa13c7edd5154a61cfc9fd14d35e67', 'message': 'Add default policy rule for extension_info\n\nChange-Id: I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27\nCloses-Bug:#1415286\n'}, {'number': 3, 'created': '2015-04-20 08:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8574791215e0b6d7ffe9d310ee5f05cda84ef129', 'message': 'Add policy check for extension_info\n\nAdd policy check for extension_info\n\nChange-Id: I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27\nCloses-Bug:#1415286\n'}, {'number': 4, 'created': '2015-04-21 12:18:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d466928081ad4bcc7d70fa97b84aa59037d34369', 'message': ""Add policy check for extension_info\n\nThis patch adds default policy enforcement for extension infor.\nby default the rule is empty, but operator can configure it if they don't want\nnormal user to see extension infor.\n\nCloses-Bug: #1415286\nChange-Id: I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27\nCo-authored-by: Eli Qiao <liyong.qiao@intel.com>\n""}, {'number': 5, 'created': '2015-04-21 13:51:33.000000000', 'files': ['nova/tests/unit/fake_policy.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extension_info.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/extension_info.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/36df2936ad0c04013cc105f1eee56f9a515de346', 'message': ""Add policy check for extension_info\n\nThis patch adds default policy enforcement for extension info. By\ndefault the rule is empty, but operator can configure it if they\ndon't want normal user to see extension info.\n\nCloses-Bug: #1415286\nChange-Id: I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27\nCo-authored-by: Eli Qiao <liyong.qiao@intel.com>\n""}]",8,173210,36df2936ad0c04013cc105f1eee56f9a515de346,54,17,5,11189,,,0,"Add policy check for extension_info

This patch adds default policy enforcement for extension info. By
default the rule is empty, but operator can configure it if they
don't want normal user to see extension info.

Closes-Bug: #1415286
Change-Id: I6afcf6f9e2cedb86e899a360e1abb22ccc1f0a27
Co-authored-by: Eli Qiao <liyong.qiao@intel.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/173210/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/fake_policy.py', 'nova/tests/unit/api/openstack/compute/contrib/test_extension_info.py', 'etc/nova/policy.json', 'nova/api/openstack/compute/plugins/v3/extension_info.py']",4,a149bf65bd0a5c3d1ab85c8ae7326101df48f28c,extension_info,authorize = extensions.os_compute_authorizer(ALIAS), authorize = extensions.os_compute_soft_authorizer(alias),23,1
openstack%2Fproject-config~master~I56eee9e76b50d95bfcb38a6b9d2942e2113673da,openstack/project-config,master,I56eee9e76b50d95bfcb38a6b9d2942e2113673da,grouped all chef jobs into chef-test-jobs to dry projects.yaml,MERGED,2015-06-08 09:28:17.000000000,2015-06-10 16:56:50.000000000,2015-06-10 16:56:50.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 11915}]","[{'number': 1, 'created': '2015-06-08 09:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/05501faa1ad2cd169c3ceac3fa46cc804a55a903', 'message': 'grouped all chef jobs into chef-test-jobs to dry projects.yaml\n\nChange-Id: I56eee9e76b50d95bfcb38a6b9d2942e2113673da\n'}, {'number': 2, 'created': '2015-06-10 15:28:07.000000000', 'files': ['jenkins/jobs/chef-jobs.yaml', 'jenkins/jobs/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/23deaab13ba13befa75cb790fe8269daf9f19c6f', 'message': 'grouped all chef jobs into chef-test-jobs to dry projects.yaml\n\nChange-Id: I56eee9e76b50d95bfcb38a6b9d2942e2113673da\n'}]",0,189236,23deaab13ba13befa75cb790fe8269daf9f19c6f,13,5,2,11915,,,0,"grouped all chef jobs into chef-test-jobs to dry projects.yaml

Change-Id: I56eee9e76b50d95bfcb38a6b9d2942e2113673da
",git fetch https://review.opendev.org/openstack/project-config refs/changes/36/189236/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/chef-jobs.yaml', 'jenkins/jobs/projects.yaml']",2,05501faa1ad2cd169c3ceac3fa46cc804a55a903,chef_job_groups, - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs - chef-test-jobs, - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration - gate-{name}-chef-lint - gate-{name}-chef-style - gate-{name}-chef-unit - gate-{name}-chef-rake - gate-{name}-chef-rake-integration,26,85
openstack%2Fopenstack-ansible~kilo~I4b357ff7099a4c1c63c85ac9560aefc8d56709be,openstack/openstack-ansible,kilo,I4b357ff7099a4c1c63c85ac9560aefc8d56709be,Updated upgrade and deployment processes for https,MERGED,2015-06-10 07:23:26.000000000,2015-06-10 16:56:30.000000000,2015-06-10 16:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-10 07:23:26.000000000', 'files': ['playbooks/roles/openstack_hosts/defaults/main.yml', 'scripts/run-upgrade.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7a2221054607ad87a9b7ca8017181553e5300b35', 'message': ""Updated upgrade and deployment processes for https\n\nThis change simply makes sure that all containers and hosts have the\n`apt-transport-https` package installed. this package is absolutly\nrequired everywhere because we've changed all of the repo endpoints\nto https and not all systems have this package installed on a base\nkick. Furthermore an entry was added into the upgrade script to\nensure that upon upgrade everything will converge and remain\nconsistent.\n\nChange-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be\nCloses-Bug: #1463155\n(cherry picked from commit 8bcaac5702f3ed29d74a3f49690cf2d6e3655828)\n""}]",0,190049,7a2221054607ad87a9b7ca8017181553e5300b35,11,5,1,425,,,0,"Updated upgrade and deployment processes for https

This change simply makes sure that all containers and hosts have the
`apt-transport-https` package installed. this package is absolutly
required everywhere because we've changed all of the repo endpoints
to https and not all systems have this package installed on a base
kick. Furthermore an entry was added into the upgrade script to
ensure that upon upgrade everything will converge and remain
consistent.

Change-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be
Closes-Bug: #1463155
(cherry picked from commit 8bcaac5702f3ed29d74a3f49690cf2d6e3655828)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/49/190049/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/openstack_hosts/defaults/main.yml', 'scripts/run-upgrade.sh']",2,7a2221054607ad87a9b7ca8017181553e5300b35,," # Ensure that apt-transport-https is installed everywhere before doing anything else. ansible ""hosts:all_containers"" \ -m shell \ -a ""apt-get update && apt-get install -y apt-transport-https"" ",,6,0
openstack%2Fopenstacksdk~master~Ie484bc8b36da22a2b3894efb35903ae04a78db7b,openstack/openstacksdk,master,Ie484bc8b36da22a2b3894efb35903ae04a78db7b,Add functional test for Network Quota,MERGED,2015-06-09 18:17:55.000000000,2015-06-10 16:53:15.000000000,2015-06-10 16:53:13.000000000,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-09 18:17:55.000000000', 'files': ['openstack/tests/functional/network/v2/test_quota.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5b15efa07d9e619ead833d1ef0056a3c2b5df930', 'message': 'Add functional test for Network Quota\n\ntest:\ntest_list\n\nChange-Id: Ie484bc8b36da22a2b3894efb35903ae04a78db7b\n'}]",0,189846,5b15efa07d9e619ead833d1ef0056a3c2b5df930,8,2,1,15739,,,0,"Add functional test for Network Quota

test:
test_list

Change-Id: Ie484bc8b36da22a2b3894efb35903ae04a78db7b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/46/189846/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_quota.py'],1,5b15efa07d9e619ead833d1ef0056a3c2b5df930,test_subnet,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack.tests.functional import base class TestQuota(base.BaseFunctionalTest): def test_list(self): sot = self.conn.network.quotas() for qot in sot: self.assertIn('subnet', qot) self.assertIn('network', qot) self.assertIn('router', qot) self.assertIn('port', qot) self.assertIn('floatingip', qot) self.assertIn('security_rule_group', qot) self.assertIn('security_group', qot) ",,27,0
openstack%2Fnova~master~Ibb93636d767862470ebd704e3e23ec04e8a1f1ff,openstack/nova,master,Ibb93636d767862470ebd704e3e23ec04e8a1f1ff,Objects: update missing adapter types,MERGED,2015-06-07 08:36:31.000000000,2015-06-10 16:52:50.000000000,2015-06-10 16:52:47.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-07 08:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc0a82e98de00ad1b50500e03ebfb60f29320381', 'message': 'Objects: update missing adapter types\n\nThe followiing adaptre types also need to be supported:\n - ide\n - lsiLogicsas\n - paraVirtual\n\nChange-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff\n'}, {'number': 2, 'created': '2015-06-07 09:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5a29888d25d763a9fdbb9526bbfb9d37b496f4e', 'message': 'Objects: update missing adapter types\n\nThe followiing adaptre types also need to be supported:\n - ide\n - lsiLogicsas\n - paraVirtual\n\nThis is required for backwards compatibility due to:\nhttps://github.com/openstack/nova/blob/master/nova/objects/image_meta.py#L288\n\nChange-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff\n'}, {'number': 3, 'created': '2015-06-07 11:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b89eb592cca2eae3c6e0a5ec74f2a700d394c11e', 'message': 'Objects: update missing adapter types\n\nThe followiing adapter types need to be supported for\nthe VMware driver:\n\n- ""busLogic""\n- ""ide""\n- ""lsiLogicsas""\n- ""paraVirtual""\n\nThis is required for backwards compatibility due to:\nhttps://github.com/openstack/nova/blob/master/nova/objects/image_meta.py#L288\n\nWhich is also a bug. That should be hw_disk_bus.\n\nChange-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff\n'}, {'number': 4, 'created': '2015-06-08 12:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c31ddd16e5d784980f5d18b8ee22bb8f4732a9b', 'message': 'Objects: update missing adapter types\n\nThe vmware_adaptertype does not map 1:1 to the to either\nhw_disk_bus or hw_scsi_model. So we need a combination of\nboth.\n\nThe vmware_adaptertype will drive which flags are set.\n\nThe settings are as follows:\n\n+-----------------------------------------------+\n|vmware_apdaptertype|hw_disk_bus|hw_scsi_model  |\n+-----------------------------------------------+\n| ide               | ide       |               |\n| lsiLogic          | scsi      | lsilogic      |\n| busLogic          | scsi      | buslogic      |\n| lsiLogicsas       | scsi      | lsisas1068    |\n| paraVirtual       | scsi      | vmpvscsi      |\n+-------------------+-----------+---------------+\n\nChange-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff\n'}, {'number': 5, 'created': '2015-06-08 13:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bffac3e610e16cbb9e96b80d58ff4399b63ffaf', 'message': 'Objects: update missing adapter types\n\nThe vmware_adaptertype does not map 1:1 to either the\nhw_disk_bus or hw_scsi_model. So we need a combination of\nboth.\n\nThe vmware_adaptertype will drive which flags are set.\n\nThe settings are as follows:\n\n+-----------------------------------------------+\n|vmware_apdaptertype|hw_disk_bus|hw_scsi_model  |\n+-----------------------------------------------+\n| ide               | ide       |               |\n| lsiLogic          | scsi      | lsilogic      |\n| busLogic          | scsi      | buslogic      |\n| lsiLogicsas       | scsi      | lsisas1068    |\n| paraVirtual       | scsi      | vmpvscsi      |\n+-------------------+-----------+---------------+\n\nChange-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff\n'}, {'number': 6, 'created': '2015-06-09 09:32:42.000000000', 'files': ['nova/tests/unit/objects/test_image_meta.py', 'nova/objects/image_meta.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b927c42eaffc12294da9e365bfaa587ca180fcb8', 'message': 'Objects: update missing adapter types\n\nThe vmware_adaptertype does not map 1:1 to either the\nhw_disk_bus or hw_scsi_model. So we need a combination of\nboth.\n\nThe vmware_adaptertype will drive which flags are set.\n\nThe settings are as follows:\n\n+-----------------------------------------------+\n|vmware_apdaptertype|hw_disk_bus|hw_scsi_model  |\n+-----------------------------------------------+\n| ide               | ide       |               |\n| lsiLogic          | scsi      | lsilogic      |\n| busLogic          | scsi      | buslogic      |\n| lsiLogicsas       | scsi      | lsisas1068    |\n| paraVirtual       | scsi      | vmpvscsi      |\n+-------------------+-----------+---------------+\n\nChange-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff\n'}]",2,189086,b927c42eaffc12294da9e365bfaa587ca180fcb8,51,11,6,1653,,,0,"Objects: update missing adapter types

The vmware_adaptertype does not map 1:1 to either the
hw_disk_bus or hw_scsi_model. So we need a combination of
both.

The vmware_adaptertype will drive which flags are set.

The settings are as follows:

+-----------------------------------------------+
|vmware_apdaptertype|hw_disk_bus|hw_scsi_model  |
+-----------------------------------------------+
| ide               | ide       |               |
| lsiLogic          | scsi      | lsilogic      |
| busLogic          | scsi      | buslogic      |
| lsiLogicsas       | scsi      | lsisas1068    |
| paraVirtual       | scsi      | vmpvscsi      |
+-------------------+-----------+---------------+

Change-Id: Ibb93636d767862470ebd704e3e23ec04e8a1f1ff
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/189086/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/fields.py'],1,fc0a82e98de00ad1b50500e03ebfb60f29320381,use-image-meta-object," IDE = ""ide"" LSILOGICSAS = ""lsigogicsas"" PARAVIRTUAL = ""paravirtual"" ALL = (BUSLOGIC, IBMVSCSI, IDE, LSILOGIC, LSILOGICSAS, LSISAS1068, LSISAS1078, PARAVIRTUAL, VIRTIO_SCSI, VMPVSCSI)"," ALL = (BUSLOGIC, IBMVSCSI, LSILOGIC, LSISAS1068, LSISAS1078, VIRTIO_SCSI, VMPVSCSI)",5,2
openstack%2Fnova~master~Iadaae393fce0c78dbdfd3b02958ddfd6276edb94,openstack/nova,master,Iadaae393fce0c78dbdfd3b02958ddfd6276edb94,Show 'reserved' status in os-fixed-ips,MERGED,2015-03-30 15:43:47.000000000,2015-06-10 16:49:03.000000000,2015-06-10 16:48:55.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10224}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-30 15:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60e794adb32adf67fa0eb1f7c97808b314ec52c4', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 2, 'created': '2015-03-30 15:45:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/005e9e2695db025b7ae52aa8d9616ce829516fb0', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 3, 'created': '2015-04-01 14:06:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55502448bd358cac0554898491d892cc1efe8c1b', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 4, 'created': '2015-05-07 17:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9fe15213032bb6d2cfdecb4dcf0d766afa8d357', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 5, 'created': '2015-05-07 19:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/908844117cb5d743d58dfd0c628d8fb5200481af', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 6, 'created': '2015-05-11 21:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/257f23068a8f8ac3cf206d8cc718d6c362b4ca73', 'message': ""WIP: Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 7, 'created': '2015-05-11 21:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b4959d5363e4736f7dd1361a3f9572ae86ff56e', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}, {'number': 8, 'created': '2015-05-15 17:41:33.000000000', 'files': ['nova/tests/functional/v3/api_samples/os-fixed-ips/v2.4/fixedip-post-req.json.tpl', 'doc/api_samples/versions/versions-get-resp.json', 'nova/api/openstack/api_version_request.py', 'nova/api/openstack/compute/plugins/v3/fixed_ips.py', 'nova/tests/unit/api/openstack/compute/test_versions.py', 'nova/tests/functional/v3/test_fixed_ips.py', 'nova/tests/functional/v3/api_samples/os-fixed-ips/v2.4/fixedips-get-resp.json.tpl', 'nova/tests/unit/api/openstack/compute/contrib/test_fixed_ips.py', 'doc/v3/api_samples/os-fixed-ips/v2.4/fixedip-post-req.json', 'nova/api/openstack/rest_api_version_history.rst', 'doc/v3/api_samples/os-fixed-ips/v2.4/fixedips-get-resp.json', 'nova/tests/functional/api_samples/versions/versions-get-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/8886590f30daf736ae30a95b3e4a77cb586d4f02', 'message': ""Show 'reserved' status in os-fixed-ips\n\nAdds a new microversion to show the 'reserved' status on a FixedIP in\nthe os-fixed-ips extension.\n\nCloses-Bug: #1249526\n\nImplements blueprint show-reserved-status-in-os-fixed-ips-api\n\nChange-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94\n""}]",15,168966,8886590f30daf736ae30a95b3e4a77cb586d4f02,85,14,8,6873,,,0,"Show 'reserved' status in os-fixed-ips

Adds a new microversion to show the 'reserved' status on a FixedIP in
the os-fixed-ips extension.

Closes-Bug: #1249526

Implements blueprint show-reserved-status-in-os-fixed-ips-api

Change-Id: Iadaae393fce0c78dbdfd3b02958ddfd6276edb94
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/168966/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/contrib/test_fixed_ips.py', 'nova/api/openstack/api_version_request.py', 'nova/api/openstack/compute/plugins/v3/fixed_ips.py', 'nova/api/openstack/rest_api_version_history.rst']",4,60e794adb32adf67fa0eb1f7c97808b314ec52c4,bp/show-reserved-status-in-os-fixed-ips-api, - **2.4** Exposed the 'reserved' attribute in os-fixed-ips.,,40,2
openstack%2Fpuppet-neutron~master~I00085a1f6d5431256146aa5e9d4b506f33cf95fe,openstack/puppet-neutron,master,I00085a1f6d5431256146aa5e9d4b506f33cf95fe,LBaaS: update device_driver for Kilo,MERGED,2015-05-13 15:38:32.000000000,2015-06-10 16:43:55.000000000,2015-06-10 16:43:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-05-13 15:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a2bd9f61e7a1481ea52a4f672114609de5f8df08', 'message': 'LBaaS: update device_driver for Kilo\n\nNeutron LBaaS plugin has been pulled out from Neutron core so the\ndevice_driver Python plugin is now neutron_lbaas_*.\nThis patch breaks Juno deployments.\n\nChange-Id: I00085a1f6d5431256146aa5e9d4b506f33cf95fe\n'}, {'number': 2, 'created': '2015-06-09 14:21:21.000000000', 'files': ['spec/classes/neutron_agents_lbaas_spec.rb', 'manifests/agents/lbaas.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/cc9bc3169908ef170417cf94bb57d43ceaa9fe6d', 'message': 'LBaaS: update device_driver for Kilo\n\nNeutron LBaaS plugin has been pulled out from Neutron core so the\ndevice_driver Python plugin is now neutron_lbaas_*.\nThis patch breaks Juno deployments.\n\nDoc: http://docs.openstack.org/admin-guide-cloud/content/install_neutron-lbaas-agent.html\n\nChange-Id: I00085a1f6d5431256146aa5e9d4b506f33cf95fe'}]",0,182724,cc9bc3169908ef170417cf94bb57d43ceaa9fe6d,17,4,2,3153,,,0,"LBaaS: update device_driver for Kilo

Neutron LBaaS plugin has been pulled out from Neutron core so the
device_driver Python plugin is now neutron_lbaas_*.
This patch breaks Juno deployments.

Doc: http://docs.openstack.org/admin-guide-cloud/content/install_neutron-lbaas-agent.html

Change-Id: I00085a1f6d5431256146aa5e9d4b506f33cf95fe",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/24/182724/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_lbaas_spec.rb', 'manifests/agents/lbaas.pp']",2,a2bd9f61e7a1481ea52a4f672114609de5f8df08,lbaas_device_driver,"# (optional) Defaults to 'neutron_lbaas.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver'. $device_driver = 'neutron_lbaas.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver',","# (optional) Defaults to 'neutron.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver'. $device_driver = 'neutron.services.loadbalancer.drivers.haproxy.namespace_driver.HaproxyNSDriver',",3,3
openstack%2Fheat~master~I06cd458ce2e5eefb39f80d16573539a082c68c31,openstack/heat,master,I06cd458ce2e5eefb39f80d16573539a082c68c31,Sync with latest oslo-incubator,MERGED,2015-06-07 14:06:32.000000000,2015-06-10 16:42:23.000000000,2015-06-10 13:27:20.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-07 14:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fa0db44a124bdc32d1f1e66f89d92ca2a200c133', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: I06cd458ce2e5eefb39f80d16573539a082c68c31\n'}, {'number': 2, 'created': '2015-06-10 11:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/56fa07ff0d6b3541c67b0e1ac46905ba731ed0fe', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest oslo-incubator code\n\nChange-Id: I06cd458ce2e5eefb39f80d16573539a082c68c31'}, {'number': 3, 'created': '2015-06-10 11:11:05.000000000', 'files': ['heat/openstack/common/loopingcall.py', 'heat/openstack/common/eventlet_backdoor.py', 'heat/openstack/common/threadgroup.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/heat/commit/9dea28874702d3b35c5e18d2a1db9bf4eefba613', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest oslo-incubator code\n\nChange-Id: I06cd458ce2e5eefb39f80d16573539a082c68c31'}]",0,189108,9dea28874702d3b35c5e18d2a1db9bf4eefba613,15,5,3,5638,,,0,"Sync with latest oslo-incubator

Periodic sync with latest oslo-incubator code

Change-Id: I06cd458ce2e5eefb39f80d16573539a082c68c31",git fetch https://review.opendev.org/openstack/heat refs/changes/08/189108/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/openstack/common/loopingcall.py', 'heat/openstack/common/eventlet_backdoor.py', 'heat/openstack/common/threadgroup.py', 'openstack-common.conf']",4,fa0db44a124bdc32d1f1e66f89d92ca2a200c133,,,module=versionutils,11,11
openstack%2Fnova-specs~master~I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed,openstack/nova-specs,master,I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed,New nova API call to mark nova-compute down,MERGED,2015-04-01 16:43:48.000000000,2015-06-10 16:40:10.000000000,2015-06-10 16:40:08.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 136}, {'_account_id': 782}, {'_account_id': 1297}, {'_account_id': 1561}, {'_account_id': 2033}, {'_account_id': 4393}, {'_account_id': 5441}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6469}, {'_account_id': 6804}, {'_account_id': 6873}, {'_account_id': 6984}, {'_account_id': 7022}, {'_account_id': 7166}, {'_account_id': 8574}, {'_account_id': 8768}, {'_account_id': 9060}, {'_account_id': 9420}, {'_account_id': 9444}, {'_account_id': 9562}, {'_account_id': 9708}, {'_account_id': 10068}, {'_account_id': 10707}, {'_account_id': 11604}, {'_account_id': 13692}, {'_account_id': 14018}, {'_account_id': 15834}]","[{'number': 1, 'created': '2015-04-01 16:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/51bc0d96a789b5ddc2fb08db1a2b53fdee69b29c', 'message': 'State of compute node and instances running on it should be changed\ndown by new API when host fault detected by external tool.\n\nWhen a server goes down because of a host hardware, OS or hypervisor error,\nthe server state remains as operational in OpenStack API.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 2, 'created': '2015-04-01 18:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/21a81f5e56960894b3c2ba38caab091ebeefebef', 'message': 'New API to put compute node down.\n\nWhen a server goes down because of a host hardware, OS or hypervisor error,\nthe server state remains as operational in OpenStack API.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 3, 'created': '2015-04-02 03:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a3d53ecab62be5660dc2cedaa165b6a0ec6036e5', 'message': 'New API to put compute node down.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 4, 'created': '2015-04-02 03:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d3f8b228edbd9d49b2afddbc6142aa634603f598', 'message': 'New API to put compute node down.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 5, 'created': '2015-04-02 04:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d99b12343d9f1aa81b595b375d5154af49e39d26', 'message': 'New API to put compute node down.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 6, 'created': '2015-04-02 04:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/63f963ad0a7dc7f39055d8e7262de005ffa17aae', 'message': 'New API to put compute node down.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 7, 'created': '2015-04-02 19:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/99c429ad946651ce1cc5aac558179dd8227a1c20', 'message': 'New API to report compute node down.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 8, 'created': '2015-04-08 09:34:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3aa9eef2e166b7ed3b749fd46d4c9cd5593749e0', 'message': 'New API to put compute node down.\n\nA new API is needed to report a host fault to change the state of the\ninstances and compute node immediately. This allows usage of evacuate API\nwithout a delay. The new API provides the possibility for external monitoring\nsystem to detect any kind of host failure fast and reliably and inform\nOpenStack about it. Nova updates the compute node state and states of the\ninstances. This way the states in the Nova DB will be in sync with the\nreal state of the system.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 9, 'created': '2015-04-17 10:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3145b8d17c1865035cf8839782afbb8e8e833158', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 10, 'created': '2015-04-17 10:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b98cb6fe3d7327c2d52c635a33209367529bf675', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 11, 'created': '2015-04-17 10:45:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b0984c3831bbd35c895baeaaac1d7c2597d362be', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n'}, {'number': 12, 'created': '2015-04-21 03:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c288d61c5d6eebbd83ee99aae9cb45b0c35fa4c0', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n'}, {'number': 13, 'created': '2015-04-24 10:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f556cce146659a291e8406cbdafdee4e5692effc', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 14, 'created': '2015-04-24 10:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8a6f0c32000e69e93fe07b19bec17a45fa659e93', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 15, 'created': '2015-04-29 14:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ec50de2b1a8073da19a5c7efd0af19072cc3c343', 'message': 'New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service ""down""\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint update-server-state-immediately\n'}, {'number': 16, 'created': '2015-05-05 08:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e9bd508f9e151762ee09350be9e20167604b77ef', 'message': ""New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service 'down'\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n""}, {'number': 17, 'created': '2015-05-11 11:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/29b4ada9c7dfecbf6a4210d51f8b36e6a3104920', 'message': ""New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service 'down'\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n""}, {'number': 18, 'created': '2015-05-19 10:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c0c7b3d07e468fed6be7c5d02530ca66dd567b9e', 'message': ""New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service 'down'\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n""}, {'number': 19, 'created': '2015-05-19 10:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c5c6bd3a7da1c4e190d53652780336f8172c21d1', 'message': ""New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service 'down'\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n""}, {'number': 20, 'created': '2015-06-05 05:33:04.000000000', 'files': ['specs/liberty/approved/mark-host-down.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/01339f0056d0b0029c12513726f2e4ee1cf2e58c', 'message': ""New nova API call to mark nova-compute down\n\nNew API call is needed to change the state of compute service 'down'\nimmediately. This allows usage of evacuate API without a delay. Also as\nexternal system will make sure host is down and no VMs left running, there\nwill be no possibility to break shared storage or use same IPs again. API\nusage applies mainly for cases where there is single host mapped to\nnova-compute. Cases like in Ironic or vSphere would be out of scope.\n\nAPIImpact\n\nChange-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed\nImplements: blueprint mark-host-down\n""}]",194,169836,01339f0056d0b0029c12513726f2e4ee1cf2e58c,165,31,20,15834,,,0,"New nova API call to mark nova-compute down

New API call is needed to change the state of compute service 'down'
immediately. This allows usage of evacuate API without a delay. Also as
external system will make sure host is down and no VMs left running, there
will be no possibility to break shared storage or use same IPs again. API
usage applies mainly for cases where there is single host mapped to
nova-compute. Cases like in Ironic or vSphere would be out of scope.

APIImpact

Change-Id: I612582ba7b70bb6d167aa68bdfc47faa3b7b85ed
Implements: blueprint mark-host-down
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/36/169836/15 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/approved/report-host-fault-to-update-server-state-immediately.rst'],1,51bc0d96a789b5ddc2fb08db1a2b53fdee69b29c,bp/mark-host-down,"==================================================== Report host fault to update server state immediately ==================================================== https://blueprints.launchpad.net/nova/+spec/update-server-state-immediately When a server goes down because of a host hardware, OS or hypervisor error, the server state remains as operational in OpenStack API. A new API is needed to report a host fault to change the state of the instances and compute node immediately. This allows usage of evacuate API without a delay. The new API provides the possibility for external monitoring system to detect any kind of host failure fast and reliably and inform OpenStack about it. Nova updates the compute node state and states of the instances. This way the states in the Nova DB will be in sync with the real state of the system. Problem description =================== * Nova state change for failed or unreachable host is slow and does not reliably state compute node is down or not. This might cause same instance to run twice if action taken to evacuate instance to another host. * Nova state for instances on failed compute node will not change, but remains active and running. This gives user a false information about instance state. Currently one would need to call ""nova reset-state"" for each instance to have them in error state. * OpenStack user cannot make HA actions fast and reliably by trusting instance state and compute node state. * As compute node state changes slowly one cannot evacuate instances. Use Cases --------- Use case in general is that in case there is a host fault one should change compute node state fast and reliably when using DB servicegroup backend. On top of this here is the use cases that are not covered currently to have instance states changed correctly: * Management network connectivity lost between controller and compute node. * Host HW failed. Generic use case flow: * The external monitoring system detects a host fault. * The external monitoring system fences the host if not down already. * The external system calls the new Nova API to force the failed compute node into down state as well as instances running on it. * Nova updates the compute node state and state of the effected instances to Nova DB. Currently nova-compute state will be changing ""down"", but it takes a long time. Server state keeps as ""vm_state: active"" and ""power_state: running"", which is not correct. By having external tool to detect host faults fast, fence host by powering down and then report host down to OpenStack, all these states would reflect to actual situation. Also if OpenStack will not implement automatic actions for fault correlation, external tool can do that. This could be configured for example in server instance METADATA easily and be read by external tool. Project Priority ----------------- Liberty priorities have not yet been defined. Proposed change =============== There needs to be a new API for Admin to state host is down. This API is used to mark compute node and instances running on it down to reflect the real situation. Example on compute node is: * When compute node is up and running: vm_state: active and power_state: running nova-compute state: up status: enabled * When compute node goes down and new API is called to state host is down: vm_state: stopped power_state: shutdown nova-compute state: down status: enabled vm_state values: soft-delete, deleted, resized and error should not be touched. task_state effect needs to be worked out if needs to be touched. Alternatives ------------ There is no attractive alternatives to detect all different host faults than to have a external tool to detect different host faults. For this kind of tool to exist there needs to be new API in Nova to report fault. Currently there must have been some kind of workarounds implemented as cannot trust or get the states from OpenStack fast enough. Data model impact ----------------- None API impact ---------- * Update CLI to report host is down nova host-update command usage: nova host-update [--status <enable|disable>] [--maintenance <enable|disable>] [--report-host-down] <hostname> Update host settings. Positional arguments <hostname> Name of host. Optional arguments --status <enable|disable> Either enable or disable a host. --maintenance <enable|disable> Either put or resume host to/from maintenance. --down Report host down to update instance and compute node state in db. * Update Compute API to report host is down: /v2.1/{tenant_id}/os-hosts/{host_name} Normal response codes: 200 Request parameters Parameter Style Type Description host_name URI xsd:string The name of the host of interest to you. { ""host"": { ""status"": ""enable"", ""maintenance_mode"": ""enable"" ""host_down_reported"": ""true"" } } { ""host"": { ""host"": ""65c5d5b7e3bd44308e67fc50f362aee6"", ""maintenance_mode"": ""enabled"", ""status"": ""enabled"" ""host_down_reported"": ""true"" } } * New method to nova.compute.api module HostAPI class to have a to mark host related instances and compute node down: set_host_down(context, host_name) * class novaclient.v2.hosts.HostManager(api) method update(host, values) Needs to handle reporting host down. * Schema does not need changes as in db only service and server states are to be changed. Security impact --------------- API call needs admin privileges (in the default policy configuration). Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Only impact is that user can get information faster about instance and compute node state. This also gives possibility to evacuate faster. No impact that would slow down. Host down should be rare occurrence. Other deployer impact --------------------- Developer can make use of any external tool to detect host fault and report it to OpenStack. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Tomi Juvonen Other contributors: Ryota Mibu Work Items ---------- * Test cases. * API changes. * Documentation. Dependencies ============ None Testing ======= Test cases that exists for enabling or putting host to maintenance should be altered or similar new cases made test new functionality. Documentation Impact ==================== New API needs to be documented: * Compute API extensions documentation. http://developer.openstack.org/api-ref-compute-v2.1.html * Nova commands documentation. http://docs.openstack.org/user-guide-admin/content/novaclient_commands.html * Compute command-line client documentation. http://docs.openstack.org/cli-reference/content/novaclient_commands.html * nova.compute.api documentation. http://docs.openstack.org/developer/nova/api/nova.compute.api.html * High Availability guide might have page to tell external tool could provide ability to provide faster HA as able to update states by new API. http://docs.openstack.org/high-availability-guide/content/index.html References ========== * OPNFV Doctor project: https://wiki.opnfv.org/doctor * OpenStack Instance HA Proposal: http://blog.russellbryant.net/2014/10/15/openstack-instance-ha-proposal/ * The Different Facets of OpenStack HA: http://blog.russellbryant.net/2015/03/10/the-different-facets-of-openstack-ha/ ",,234,0
openstack%2Fironic-python-agent~master~I2ae0e93573e0348f023aa124a07bb16921b5c53e,openstack/ironic-python-agent,master,I2ae0e93573e0348f023aa124a07bb16921b5c53e,Add versioning to Agent decommission,ABANDONED,2014-07-14 20:32:55.000000000,2015-06-10 16:38:41.000000000,,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-07-14 20:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/62ff0469b334b6dfda9384e166f83e24a17d3a67', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 2, 'created': '2014-07-14 21:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a1d44e6041e2e1abf89c8ea14e54d7ed5cf43a78', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 3, 'created': '2014-07-15 02:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b68aa86d10daacd15b36d210d2f5f2f60656c93c', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 4, 'created': '2014-07-15 20:20:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/286e874db560cc02f44c258841c2f6b4021b1111', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 5, 'created': '2014-07-15 23:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/36a3874f189871205bce4441f650b941b978b676', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 6, 'created': '2014-07-16 01:06:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/132e6ee93d75d0ac4e5ac5a15b11b805390893f3', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 7, 'created': '2014-07-16 20:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fe09e27227c03a446abb7deedb9a19f7c9577d7e', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 8, 'created': '2014-07-16 21:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/28b82f0a90697defabc6089a21ec3e5db58617b2', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 9, 'created': '2014-07-16 21:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5794950ba1f5c30cdc3dda84d4e8f3c96bd5f21c', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 10, 'created': '2014-07-16 21:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/174debe42a19a31494bedb34a665311b8692ee0d', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 11, 'created': '2014-07-17 00:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9131b860ce8f3318e0f8a50f8771fed944ae9bb3', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 12, 'created': '2014-09-05 00:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b7a6f3cce1c7d0884f402cb2d5899ee457a3eb84', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 13, 'created': '2014-09-11 17:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/90a206c318894e4868455aea2489631651e25a00', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 14, 'created': '2014-09-22 22:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b7ac093d1ead146c06c0fd8649707c66ee3c1d4d', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 15, 'created': '2014-09-23 01:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f188fa5062404386635ef52c666a271b99d94591', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 16, 'created': '2014-09-23 21:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e0f726e446d878f69862fc1c5aaf72dc6111324a', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 17, 'created': '2014-09-26 00:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ca9de5f7b7f3fef50cc888072c2e9737ac761eb6', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 18, 'created': '2014-09-26 20:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/412174cc9acdc43095147aa63ce1f182af7ca7a3', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}, {'number': 19, 'created': '2014-11-18 00:47:21.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/extensions/decom.py', 'ironic_python_agent/tests/hardware.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/05059e14d665ace405c4766cc2f089dfe8d2eb12', 'message': ""Add versioning to Agent decommission\n\nAs the agent will likely be rebooting while decommissioning (to apply BIOS/\nfirmware upgrades), it is possible the version of the agent will change\nbetween boots. Including a version string in the Hardware Manager allows\nthe Hardware Manager builder to bump versions for any breaking changes.\nI recommend that the entire decommission process be restarted if there\nis a version mismatch, but that will be up to individual drivers to\nimplement.\n\nThis change also adds a new return value for Agent REST commands called\n'DECOM_VERSION_MISMATCH' that will signal no command was run, and\nIronic should update its stored value. A 'hardware_manager_version'\nwill be returned with AsyncCommandResult, and should be set in the\nIronic driver_info field and sent with any decommission command.\n\nChange-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e\n""}]",6,106859,05059e14d665ace405c4766cc2f089dfe8d2eb12,57,3,19,10380,,,0,"Add versioning to Agent decommission

As the agent will likely be rebooting while decommissioning (to apply BIOS/
firmware upgrades), it is possible the version of the agent will change
between boots. Including a version string in the Hardware Manager allows
the Hardware Manager builder to bump versions for any breaking changes.
I recommend that the entire decommission process be restarted if there
is a version mismatch, but that will be up to individual drivers to
implement.

This change also adds a new return value for Agent REST commands called
'DECOM_VERSION_MISMATCH' that will signal no command was run, and
Ironic should update its stored value. A 'hardware_manager_version'
will be returned with AsyncCommandResult, and should be set in the
Ironic driver_info field and sent with any decommission command.

Change-Id: I2ae0e93573e0348f023aa124a07bb16921b5c53e
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/59/106859/14 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/extensions/base.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/errors.py']",4,62ff0469b334b6dfda9384e166f83e24a17d3a67,decom-nodes,"class WrongDecommissionVersion(RESTError): """"""Error raised when Ironic and the Agent have different versions."""""" message = 'Decommission version mismatch, reboot to new agent' def __init__(self, agent_version, node_version): self.details = ('Agent decommission version: {0}, node decommission ' 'version: {1}').format(agent_version, node_version) ",,47,6
openstack%2Fironic-python-agent~master~Ia42a8e75d2b8887b2351de97c2137fe21a7f4041,openstack/ironic-python-agent,master,Ia42a8e75d2b8887b2351de97c2137fe21a7f4041,Adding support for decommissioning,ABANDONED,2014-07-02 23:51:15.000000000,2015-06-10 16:38:35.000000000,,"[{'_account_id': 3}, {'_account_id': 1030}, {'_account_id': 10343}, {'_account_id': 10380}]","[{'number': 1, 'created': '2014-07-02 23:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e6de59c23ce33f52653817b2a8023a5d95ace098', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 2, 'created': '2014-07-03 18:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e32c40a0ea974ca61d6e68bb0ac846f49f6ed9e8', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 3, 'created': '2014-07-03 18:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5769fb5b311d59bf7b90d31ea354db3d4f81e588', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 4, 'created': '2014-07-03 18:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8ee102bc69f8b06a26df899dff92a745a53a0555', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 5, 'created': '2014-07-03 19:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c6ab9b3315bab7db4e7aa3ec5c3f7d7abe7bdc89', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 6, 'created': '2014-07-09 23:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/efc2ea4cfa331cf7b87e50a9289f501e5316ccad', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 7, 'created': '2014-07-11 22:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/582fc5f855f830599ecb3babb0a059591d88fe4f', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 8, 'created': '2014-07-14 16:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/dbfb6bdcc16f9df29ca8cc42ae18a22d0eb1c899', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 9, 'created': '2014-07-14 17:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5b58eac6a88693645a265ace825e3eb82c79b64c', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 10, 'created': '2014-07-16 01:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/bdbb882037079ceaae1c73f0e1a0bb20c3d49373', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 11, 'created': '2014-07-19 01:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f3a9c24038b51fc3a3d1c52fcd975b5ca319f499', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 12, 'created': '2014-08-12 00:49:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/58611b6155100a35d1f962b85afbd56ba394be42', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 13, 'created': '2014-09-05 00:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fbf47bd6a99467fe38069985e723b4616769ca6f', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 14, 'created': '2014-09-11 17:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7a185716b70350ff4e70d3bf6bffed950c85fc59', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 15, 'created': '2014-09-15 22:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e5d46e24d30c8da6402b635b0f7f565c95d45cd6', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 16, 'created': '2014-09-15 22:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9bdecc08ecb82154f7e84ffb2f4bb3604a13285c', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 17, 'created': '2014-09-22 22:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7f8e05b2f44c1f1bdd253446af67b24620ee4430', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 18, 'created': '2014-09-22 22:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f59ef2d87d029c9b9efbe17bc492c695b1fe5e3a', 'message': 'Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work).\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n'}, {'number': 19, 'created': '2014-09-23 00:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6dc12e8f3274421afb50fcba98427f837e5fbaeb', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 20, 'created': '2014-09-23 21:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e2444f06ea80d2ee1391272504399177f2c52a7d', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 21, 'created': '2014-09-25 22:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ee5de439662aebce450c24a5f884f678d7a001da', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 22, 'created': '2014-09-25 22:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b4ef684b723630fd11faeb2c05201d6efe80c0af', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 23, 'created': '2014-09-26 00:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/dd05fab55236e304328ef3a384ecae60b7be1200', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 24, 'created': '2014-09-26 19:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/68804bd6f0404bca65452129372ade1358cd832d', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 25, 'created': '2014-11-18 00:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d93d0e3a53639a959e2ef32625bc68328bc15f3f', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}, {'number': 26, 'created': '2014-11-18 00:47:21.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/extensions/base.py', 'ironic_python_agent/extensions/decom.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/errors.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/aa27598f2b56614d76214805b0d2a8dde99e1aae', 'message': ""Adding support for decommissioning\n\nThe pluggable hardware manager should be able be used for decommissioning,\nsuch as erasing disks, updating firmwares, changing BIOS settings, and\nanything else specific hardware needs. This works with the agent driver\nto store state in Ironic and request out of band reboots (which may be\nrequired to make BIOS/firmware updates work). Also allows the agent to do\nsome basic verification of the node's properties, to ensure they haven't\nchanged, such as a stick of memory dying.\n\nChange-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041\n""}]",18,104379,aa27598f2b56614d76214805b0d2a8dde99e1aae,75,4,26,10380,,,0,"Adding support for decommissioning

The pluggable hardware manager should be able be used for decommissioning,
such as erasing disks, updating firmwares, changing BIOS settings, and
anything else specific hardware needs. This works with the agent driver
to store state in Ironic and request out of band reboots (which may be
required to make BIOS/firmware updates work). Also allows the agent to do
some basic verification of the node's properties, to ensure they haven't
changed, such as a stick of memory dying.

Change-Id: Ia42a8e75d2b8887b2351de97c2137fe21a7f4041
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/79/104379/12 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/extensions/decom.py', 'ironic_python_agent/tests/hardware.py', 'ironic_python_agent/errors.py']",4,e6de59c23ce33f52653817b2a8023a5d95ace098,decom-nodes, class DecommissionError(RESTError): message = 'Agent failed to decommission.',,179,0
openstack%2Fnova~master~Iac713b832b4cbc62ae69bfa1c4680c6932a735c3,openstack/nova,master,Iac713b832b4cbc62ae69bfa1c4680c6932a735c3,Extract helper method to get image metadata from volume,MERGED,2015-06-02 05:57:14.000000000,2015-06-10 16:37:51.000000000,2015-06-09 13:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 8276}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9312}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10224}, {'_account_id': 10234}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-02 05:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3a6cce4294f3e96a9a5b8b1fe9d5e5394fa4160', 'message': 'Extract helper method to get image metadata from volume\n\nThis refactoring needs for futher review(-s)\nlike this - https://review.openstack.org/#/c/170243/8\n\nChange-Id: Iac713b832b4cbc62ae69bfa1c4680c6932a735c3\n'}, {'number': 2, 'created': '2015-06-02 06:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b7de44f3ba78b07c162f92e8352afb92c29092f', 'message': 'Extract helper method to get image metadata from volume\n\nThis refactoring needs for futher review(-s).\nFirst is here - https://review.openstack.org/#/c/170243\nBut it will be divided to separate reviews and some refactoring\nshould be done first.\n\nChange-Id: Iac713b832b4cbc62ae69bfa1c4680c6932a735c3\n'}, {'number': 3, 'created': '2015-06-02 07:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a4360fbf373d5fb8a9dfabbf6c940c06e999111', 'message': 'Extract helper method to get image metadata from volume\n\nThis refactoring needs for futher review(-s).\nFirst is here - https://review.openstack.org/#/c/170243\nBut it will be divided to separate reviews and some refactoring\nshould be done first.\n\nChange-Id: Iac713b832b4cbc62ae69bfa1c4680c6932a735c3\n'}, {'number': 4, 'created': '2015-06-03 13:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b5106bb9af29175531198f1421f94029ad3c3b8', 'message': 'Extract helper method to get image metadata from volume\n\nThis refactoring needs for futher review(-s).\nFirst is here - https://review.openstack.org/#/c/170243\nBut it will be divided to separate reviews and some refactoring\nshould be done first.\n\nChange-Id: Iac713b832b4cbc62ae69bfa1c4680c6932a735c3\n'}, {'number': 5, 'created': '2015-06-04 07:42:45.000000000', 'files': ['nova/tests/unit/test_utils.py', 'nova/utils.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5a44a6b3afdd7c26f47187e0ada07fd581832eb6', 'message': 'Extract helper method to get image metadata from volume\n\nThis refactoring needs for futher review(-s).\nFirst is here - https://review.openstack.org/#/c/170243\nBut it will be divided to separate reviews and some refactoring\nshould be done first.\n\nChange-Id: Iac713b832b4cbc62ae69bfa1c4680c6932a735c3\n'}]",8,187461,5a44a6b3afdd7c26f47187e0ada07fd581832eb6,55,16,5,10234,,,0,"Extract helper method to get image metadata from volume

This refactoring needs for futher review(-s).
First is here - https://review.openstack.org/#/c/170243
But it will be divided to separate reviews and some refactoring
should be done first.

Change-Id: Iac713b832b4cbc62ae69bfa1c4680c6932a735c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/187461/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/utils.py', 'nova/compute/api.py']",2,c3a6cce4294f3e96a9a5b8b1fe9d5e5394fa4160,, return utils.get_image_metadata_from_volume(volume)," properties = volume.get('volume_image_metadata', {}) image_meta = {'properties': properties} # NOTE(yjiang5): restore the basic attributes # NOTE(mdbooth): These values come from volume_glance_metadata # in cinder. This is a simple key/value table, and all values # are strings. We need to convert them to ints to avoid # unexpected type errors. image_meta['min_ram'] = int(properties.get('min_ram', 0)) image_meta['min_disk'] = int(properties.get('min_disk', 0)) # Volume size is no longer related to the original image size, # so we take it from the volume directly. Cinder creates # volumes in Gb increments, and stores size in Gb, whereas # glance reports size in bytes. As we're returning glance # metadata here, we need to convert it. image_meta['size'] = volume.get('size', 0) * units.Gi # NOTE(yjiang5): Always set the image status as 'active' # and depends on followed volume_api.check_attach() to # verify it. This hack should be harmless with that check. image_meta['status'] = 'active' return image_meta",25,20
openstack%2Fpython-fuelclient~master~I9f5368cca5a8e4b64d823bc007ca9aa1a111ab49,openstack/python-fuelclient,master,I9f5368cca5a8e4b64d823bc007ca9aa1a111ab49,Bump version to 7.0,MERGED,2015-06-09 10:15:41.000000000,2015-06-10 16:27:23.000000000,2015-06-10 16:24:08.000000000,"[{'_account_id': 3}, {'_account_id': 8776}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 12817}]","[{'number': 1, 'created': '2015-06-09 10:15:41.000000000', 'files': ['fuelclient/main.py', 'specs/python-fuelclient.spec', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/8e221ab4b1565fc03382debfff1096768170362c', 'message': 'Bump version to 7.0\n\nChange-Id: I9f5368cca5a8e4b64d823bc007ca9aa1a111ab49\n'}]",0,189634,8e221ab4b1565fc03382debfff1096768170362c,12,5,1,9977,,,0,"Bump version to 7.0

Change-Id: I9f5368cca5a8e4b64d823bc007ca9aa1a111ab49
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/34/189634/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/main.py', 'specs/python-fuelclient.spec', 'setup.cfg']",3,8e221ab4b1565fc03382debfff1096768170362c,6.1-hcf,version = 7.0.0,version = 6.1.0,3,3
openstack%2Ffuel-web~master~I0c3a3a62c26724ad10a5108f019002c5fbf091f9,openstack/fuel-web,master,I0c3a3a62c26724ad10a5108f019002c5fbf091f9,Bump version to 7.0,MERGED,2015-06-08 21:15:39.000000000,2015-06-10 16:26:08.000000000,2015-06-10 16:14:16.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-06-08 21:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/df42942db294a334b34860436fa444dd7317bb56', 'message': 'Bump version to 7.0\n\nChange-Id: I0c3a3a62c26724ad10a5108f019002c5fbf091f9\n'}, {'number': 2, 'created': '2015-06-09 10:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5351490f8142754cdf862dee4610d21066d574bd', 'message': 'Bump version to 7.0\n\nChange-Id: I0c3a3a62c26724ad10a5108f019002c5fbf091f9\n'}, {'number': 3, 'created': '2015-06-09 10:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/02d6b5868ae26842eece65e50833c618aa26c7bb', 'message': 'Bump version to 7.0\n\nChange-Id: I0c3a3a62c26724ad10a5108f019002c5fbf091f9\n'}, {'number': 4, 'created': '2015-06-09 12:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/476e4232a530d2ff82870fc1ea121fca286ee788', 'message': 'Bump version to 7.0\n\nChange-Id: I0c3a3a62c26724ad10a5108f019002c5fbf091f9\n'}, {'number': 5, 'created': '2015-06-09 12:32:05.000000000', 'files': ['nailgun/nailgun/test/unit/test_deployment_serializer.py', 'debian/changelog', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'fuel_agent/setup.cfg', 'specs/nailgun.spec', 'fuelmenu/setup.py', 'shotgun/setup.py', 'nailgun/nailgun/fixtures/openstack.yaml', 'tasklib/setup.py', 'network_checker/setup.py', 'nailgun/nailgun/test/integration/test_attributes.py', 'fuel_agent_ci/setup.cfg', 'nailgun/nailgun/errors/__init__.py', 'nailgun/setup.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0e8f26772091cc5e05d87476d26ce794ac25d763', 'message': 'Bump version to 7.0\n\nChange-Id: I0c3a3a62c26724ad10a5108f019002c5fbf091f9\n'}]",5,189458,0e8f26772091cc5e05d87476d26ce794ac25d763,42,8,5,9977,,,0,"Bump version to 7.0

Change-Id: I0c3a3a62c26724ad10a5108f019002c5fbf091f9
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/58/189458/2 && git format-patch -1 --stdout FETCH_HEAD,"['debian/changelog', 'fuel_agent/setup.cfg', 'fuel_agent_ci/setup.cfg', 'specs/nailgun.spec', 'fuelmenu/setup.py', 'shotgun/setup.py', 'nailgun/nailgun/fixtures/openstack.yaml', 'tasklib/setup.py', 'network_checker/setup.py', 'nailgun/setup.py']",10,df42942db294a334b34860436fa444dd7317bb56,6.1-hcf,version = '7.0.0',version = '6.1.0',22,16
openstack%2Ffuel-ostf~master~I4a52b60f4bc3fd179c80441aefd1487208a8db88,openstack/fuel-ostf,master,I4a52b60f4bc3fd179c80441aefd1487208a8db88,Bump version to 7.0,MERGED,2015-06-08 16:13:50.000000000,2015-06-10 16:22:59.000000000,2015-06-10 16:20:39.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8777}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-06-08 16:13:50.000000000', 'files': ['setup.py', 'specs/fuel-ostf.spec'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/c6fd96ffd69ce490ee59c66c04dab9cb42c32346', 'message': 'Bump version to 7.0\n\nChange-Id: I4a52b60f4bc3fd179c80441aefd1487208a8db88\n'}]",0,189359,c6fd96ffd69ce490ee59c66c04dab9cb42c32346,11,4,1,9977,,,0,"Bump version to 7.0

Change-Id: I4a52b60f4bc3fd179c80441aefd1487208a8db88
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/59/189359/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.py', 'specs/fuel-ostf.spec']",2,c6fd96ffd69ce490ee59c66c04dab9cb42c32346,6.1-hcf,%{!?version: %define version 7.0.0},%{!?version: %define version 6.1.0},2,2
openstack%2Ffuel-main~master~I50d0d9bfba69d54030aeffd95c00a69538b6f4e4,openstack/fuel-main,master,I50d0d9bfba69d54030aeffd95c00a69538b6f4e4,Test build with CentOS 6.5,ABANDONED,2015-06-08 23:26:00.000000000,2015-06-10 16:21:12.000000000,,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9977}]","[{'number': 1, 'created': '2015-06-08 23:26:00.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/402d9137ae89b975e0d51e28eb274fe263d56fa9', 'message': 'Test build with CentOS 6.5\n\nChange-Id: I50d0d9bfba69d54030aeffd95c00a69538b6f4e4\nSigned-off-by: Igor Shishkin <ishishkin@mirantis.com>\n'}]",0,189503,402d9137ae89b975e0d51e28eb274fe263d56fa9,7,4,1,8965,,,0,"Test build with CentOS 6.5

Change-Id: I50d0d9bfba69d54030aeffd95c00a69538b6f4e4
Signed-off-by: Igor Shishkin <ishishkin@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/03/189503/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,402d9137ae89b975e0d51e28eb274fe263d56fa9,6.1-hcf,SANDBOX_MIRROR_CENTOS_UPSTREAM?=http://mirrors.msk.mirantis.net/centos/6.5/MIRROR_CENTOS?=http://mirrors.msk.mirantis.net/centos/6.5/SANDBOX_MIRROR_CENTOS_UPSTREAM?=http://mirrors.msk.mirantis.net/centos/6.5/,SANDBOX_MIRROR_CENTOS_UPSTREAM?=http://vault.centos.org/$(CENTOS_RELEASE)MIRROR_CENTOS?=http://mirrors-local-msk.msk.mirantis.net/centos-$(PRODUCT_VERSION)/$(CENTOS_RELEASE)SANDBOX_MIRROR_CENTOS_UPSTREAM?=http://mirrors-local-msk.msk.mirantis.net/centos-$(PRODUCT_VERSION)/$(CENTOS_RELEASE),3,3
openstack%2Ffuel-main~master~Ibad1d7f8492e072539781f7612ea5d6f62b6339d,openstack/fuel-main,master,Ibad1d7f8492e072539781f7612ea5d6f62b6339d,Bump version to 7.0,MERGED,2015-06-08 14:57:06.000000000,2015-06-10 16:20:57.000000000,2015-06-10 16:20:56.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 12817}, {'_account_id': 14820}]","[{'number': 1, 'created': '2015-06-08 14:57:06.000000000', 'files': ['packages/rpm/specs/fuel-docker-images.spec', 'config.mk', 'specs/fuel-main.spec', 'packages/rpm/specs/fuel-target-centos-images.spec', 'packages/rpm/specs/fuel-bootstrap-image.spec'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4ee166e529f4fc5027bb79f413f24d6d02a42727', 'message': 'Bump version to 7.0\n\nSee also\nhttps://review.openstack.org/#/c/189264/\n\nChange-Id: Ibad1d7f8492e072539781f7612ea5d6f62b6339d\n'}]",0,189322,4ee166e529f4fc5027bb79f413f24d6d02a42727,10,8,1,9977,,,0,"Bump version to 7.0

See also
https://review.openstack.org/#/c/189264/

Change-Id: Ibad1d7f8492e072539781f7612ea5d6f62b6339d
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/22/189322/1 && git format-patch -1 --stdout FETCH_HEAD,"['packages/rpm/specs/fuel-docker-images.spec', 'config.mk', 'specs/fuel-main.spec', 'packages/rpm/specs/fuel-target-centos-images.spec', 'packages/rpm/specs/fuel-bootstrap-image.spec']",5,4ee166e529f4fc5027bb79f413f24d6d02a42727,6.1-hcf,%{!?version: %define version 7.0.0},%{!?version: %define version 6.1.0},8,8
openstack%2Ffuel-astute~master~I63f09bc041d8604d9f2c23e568752db5b91583e2,openstack/fuel-astute,master,I63f09bc041d8604d9f2c23e568752db5b91583e2,Bump version to 7.0,MERGED,2015-06-08 17:56:10.000000000,2015-06-10 16:20:25.000000000,2015-06-10 16:18:30.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2015-06-08 17:56:10.000000000', 'files': ['mcagents/execute_shell_command.ddl', 'mcagents/systemtype.ddl', 'mcagents/net_probe.ddl', 'mcagents/version.ddl', 'mcagents/puppetsync.ddl', 'debian/changelog', 'specs/astute.spec', 'lib/astute/version.rb', 'mcagents/fake.ddl', 'mcagents/uploadfile.ddl', 'mcagents/erase_node.ddl'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/58869dfcc2abe4910d1986caa7eb2a8fc423dbc9', 'message': 'Bump version to 7.0\n\nChange-Id: I63f09bc041d8604d9f2c23e568752db5b91583e2\n'}]",0,189384,58869dfcc2abe4910d1986caa7eb2a8fc423dbc9,14,8,1,9977,,,0,"Bump version to 7.0

Change-Id: I63f09bc041d8604d9f2c23e568752db5b91583e2
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/84/189384/1 && git format-patch -1 --stdout FETCH_HEAD,"['mcagents/execute_shell_command.ddl', 'mcagents/net_probe.ddl', 'mcagents/systemtype.ddl', 'mcagents/version.ddl', 'mcagents/puppetsync.ddl', 'debian/changelog', 'specs/astute.spec', 'lib/astute/version.rb', 'mcagents/fake.ddl', 'mcagents/erase_node.ddl', 'mcagents/uploadfile.ddl']",11,58869dfcc2abe4910d1986caa7eb2a8fc423dbc9,6.1-hcf," :version => ""7.0.0"","," :version => ""6.1.0"",",17,11
openstack%2Ffuel-library~master~I86a4b953d517fa686d690fb104836f1aaace236e,openstack/fuel-library,master,I86a4b953d517fa686d690fb104836f1aaace236e,fuel-library spec update for 7.0.,MERGED,2015-06-09 00:50:33.000000000,2015-06-10 16:19:23.000000000,2015-06-10 16:18:42.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 12817}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-06-09 00:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4d5ad27ef1c680a666f1f952014f5c31923a3fe5', 'message': 'fuel-library spec update for 7.0\n\nChange-Id: I86a4b953d517fa686d690fb104836f1aaace236e\nSigned-off-by: Igor Shishkin <ishishkin@mirantis.com>\n'}, {'number': 2, 'created': '2015-06-09 00:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5fa73874536cc5af0a843321cc328dcf731adaab', 'message': 'fuel-library spec update for 7.0\n\nChange-Id: I86a4b953d517fa686d690fb104836f1aaace236e\nSigned-off-by: Igor Shishkin <ishishkin@mirantis.com>\n'}, {'number': 3, 'created': '2015-06-09 01:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/97ebb749605963616545001dd62dc03c9154458e', 'message': 'fuel-library spec update for 7.0\n\nChange-Id: I86a4b953d517fa686d690fb104836f1aaace236e\nSigned-off-by: Igor Shishkin <ishishkin@mirantis.com>\n'}, {'number': 4, 'created': '2015-06-09 01:11:36.000000000', 'files': ['debian/changelog', 'specs/fuel-library7.0.spec', 'debian/control'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c35e5cafdb71e17d3f1d2e6ba69d9770aebbb7e7', 'message': 'fuel-library spec update for 7.0.\n\nChange-Id: I86a4b953d517fa686d690fb104836f1aaace236e\nSigned-off-by: Igor Shishkin <ishishkin@mirantis.com>\n'}]",0,189518,c35e5cafdb71e17d3f1d2e6ba69d9770aebbb7e7,61,7,4,8965,,,0,"fuel-library spec update for 7.0.

Change-Id: I86a4b953d517fa686d690fb104836f1aaace236e
Signed-off-by: Igor Shishkin <ishishkin@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/18/189518/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/fuel-library7.0.spec'],1,4d5ad27ef1c680a666f1f952014f5c31923a3fe5,6.1-hcf,%define name fuel-library7.0 %{!?version: %define version 7.0.0}%define openstack_version 2014.2.2-7.0* Tue Jun 9 2015 Igor Shishkin <ishishkin@mirantis.com> - 7.0,%define name fuel-library6.1 %{!?version: %define version 6.1.0}%define openstack_version 2014.2.2-6.1* Tue Sep 10 2013 Vladimir Kuklin <vkuklin@mirantis.com> - 6.1,4,4
openstack%2Fopenstack-ansible~master~I7f1933680e2859e007f6b8be262852b164f90b33,openstack/openstack-ansible,master,I7f1933680e2859e007f6b8be262852b164f90b33,Generate a SHA-2 certificate for Horizon,MERGED,2015-06-10 03:18:13.000000000,2015-06-10 16:12:44.000000000,2015-06-10 16:12:43.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 8119}, {'_account_id': 9884}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-10 03:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327', 'message': 'Generate a SHA-2 certificate for Horizon\n\nSHA-1 certificates are being deprecated and browsers are starting to\nissue warnings about their use. We should begin generating SHA-2\ncertificates for Horizon.\n\nCloses-bug: 1461983\nChange-Id: I7f1933680e2859e007f6b8be262852b164f90b33\n'}, {'number': 2, 'created': '2015-06-10 04:32:21.000000000', 'files': ['playbooks/roles/os_horizon/tasks/horizon_ssl_key_create.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d81c195407c8a0922140e6d845e00a084d6f81e2', 'message': 'Generate a SHA-2 certificate for Horizon\n\nSHA-1 certificates are being deprecated and browsers are starting to\nissue warnings about their use. We should begin generating SHA-2\ncertificates for Horizon.\n\nCloses-bug: 1461983\nChange-Id: I7f1933680e2859e007f6b8be262852b164f90b33\n'}]",0,190004,d81c195407c8a0922140e6d845e00a084d6f81e2,17,6,2,12000,,,0,"Generate a SHA-2 certificate for Horizon

SHA-1 certificates are being deprecated and browsers are starting to
issue warnings about their use. We should begin generating SHA-2
certificates for Horizon.

Closes-bug: 1461983
Change-Id: I7f1933680e2859e007f6b8be262852b164f90b33
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/04/190004/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_horizon/tasks/horizon_ssl_key_create.yml'],1,ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327,bug/1461983, openssl req -new -nodes -sha256 -x509 -subj, openssl req -new -nodes -x509 -subj,1,1
openstack%2Fproject-config~master~Iacbd3fbe590cdfdfa84527b94a74aaf5248fc47f,openstack/project-config,master,Iacbd3fbe590cdfdfa84527b94a74aaf5248fc47f,Make gate-murano-devstack-dsvm voting again,MERGED,2015-06-03 16:08:11.000000000,2015-06-10 15:55:39.000000000,2015-06-10 15:55:37.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-06-03 16:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0cf364c6a684ee42702069d9dfea644147ffedae', 'message': 'Make gate-murano-devstack-dsvm voting again\n\nThis is a revert of a70e57b550266d11d984489b7e6c0a9000d621a9\n\nChange-Id: Iacbd3fbe590cdfdfa84527b94a74aaf5248fc47f\n'}, {'number': 2, 'created': '2015-06-10 11:57:47.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/28a3e7d7727c068b999383b077796262f060c339', 'message': 'Make gate-murano-devstack-dsvm voting again\n\nThis is a revert of a70e57b550266d11d984489b7e6c0a9000d621a9\n\nChange-Id: Iacbd3fbe590cdfdfa84527b94a74aaf5248fc47f\n'}]",0,188061,28a3e7d7727c068b999383b077796262f060c339,18,5,2,7549,,,0,"Make gate-murano-devstack-dsvm voting again

This is a revert of a70e57b550266d11d984489b7e6c0a9000d621a9

Change-Id: Iacbd3fbe590cdfdfa84527b94a74aaf5248fc47f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/188061/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,0cf364c6a684ee42702069d9dfea644147ffedae,revert-commit,, - name: gate-murano-devstack-dsvm branch: ^(?!stable/juno).*$ voting: false ,0,4
openstack%2Fpuppet-keystone~master~I8a9bd0cdc157430ade254650ceb1d77a72cda278,openstack/puppet-keystone,master,I8a9bd0cdc157430ade254650ceb1d77a72cda278,"Revert ""remove POSIX users, groups and file modes""",MERGED,2015-06-09 19:54:59.000000000,2015-06-10 15:52:13.000000000,2015-06-09 20:57:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 10540}]","[{'number': 1, 'created': '2015-06-09 19:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/17d2f7191a1ff997ddc2265bb3e28daaf30119fd', 'message': 'Revert ""remove POSIX users, groups and file modes""\n\nThis reverts commit 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I8a9bd0cdc157430ade254650ceb1d77a72cda278\nCloses-bug: 1463540\n'}, {'number': 2, 'created': '2015-06-09 20:00:23.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/deaff0106014f042af835c279a05fa615e0a3d5d', 'message': 'Revert ""remove POSIX users, groups and file modes""\n\nThis reverts commit 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nThis fixes issues in running the PKI setup which\nrequires the keystone user resource.\n\nChange-Id: I8a9bd0cdc157430ade254650ceb1d77a72cda278\nCloses-bug: 1463540'}]",0,189892,deaff0106014f042af835c279a05fa615e0a3d5d,12,4,2,360,,,0,"Revert ""remove POSIX users, groups and file modes""

This reverts commit 2abad789290be9f9b5f06e7eac40b438748de84e.

This fixes issues in running the PKI setup which
requires the keystone user resource.

Change-Id: I8a9bd0cdc157430ade254650ceb1d77a72cda278
Closes-bug: 1463540",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/92/189892/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,17d2f7191a1ff997ddc2265bb3e28daaf30119fd,bug/1463540," group { 'keystone': ensure => present, system => true, require => Package['keystone'], } user { 'keystone': ensure => 'present', gid => 'keystone', system => true, require => Package['keystone'], } mode => '0750', owner => 'keystone', group => 'keystone', mode => '0600', owner => 'keystone', group => 'keystone',",,33,0
openstack%2Fceilometer~master~I83441e5de7ff951f44e2d20b9660d14f0139f71c,openstack/ceilometer,master,I83441e5de7ff951f44e2d20b9660d14f0139f71c,Sync with latest oslo-incubator,MERGED,2015-06-07 14:05:34.000000000,2015-06-10 15:51:59.000000000,2015-06-10 15:51:57.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-06-07 14:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b191be60507a1cf2a2fe14b2324cbdf64a0e8cdb', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: I83441e5de7ff951f44e2d20b9660d14f0139f71c\n'}, {'number': 2, 'created': '2015-06-10 12:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/47f58b8f202bd298aabcd7f9472ebc9db9829705', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: I83441e5de7ff951f44e2d20b9660d14f0139f71c\n'}, {'number': 3, 'created': '2015-06-10 12:09:26.000000000', 'files': ['ceilometer/openstack/common/loopingcall.py', 'ceilometer/openstack/common/threadgroup.py', 'openstack-common.conf', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b1dbf6f12991b5f8db052cda44c43d1f64831b01', 'message': 'Sync with latest oslo-incubator\n\nPeriodic update to latest oslo-incubator code\n\nChange-Id: I83441e5de7ff951f44e2d20b9660d14f0139f71c'}]",0,189104,b1dbf6f12991b5f8db052cda44c43d1f64831b01,16,5,3,5638,,,0,"Sync with latest oslo-incubator

Periodic update to latest oslo-incubator code

Change-Id: I83441e5de7ff951f44e2d20b9660d14f0139f71c",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/04/189104/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/openstack/common/loopingcall.py', 'ceilometer/openstack/common/threadgroup.py', 'openstack-common.conf', 'ceilometer/openstack/common/service.py', 'ceilometer/openstack/common/eventlet_backdoor.py']",5,b191be60507a1cf2a2fe14b2324cbdf64a0e8cdb,," """"""Entry point for oslo-config-generator. _LI('Eventlet backdoor listening on %(port)s for process %(pid)d'),"," """"""Entry point for oslo.config-generator. _LI('Eventlet backdoor listening on %(port)s for process %(pid)d') %",34,30
openstack%2Fnova~master~I6a8f009bb21bce9e6408ebc4508094bdcbef05c5,openstack/nova,master,I6a8f009bb21bce9e6408ebc4508094bdcbef05c5,libvirt: fix live migration handling of disk_info,MERGED,2015-06-10 10:53:46.000000000,2015-06-10 15:47:39.000000000,2015-06-10 13:18:16.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6450}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-10 10:53:46.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/02d6ebf839799f893ac658943efa18d80dc76ca7', 'message': ""libvirt: fix live migration handling of disk_info\n\nPrevious commmit:\n\n  commit a7a0b4e542a65b3ba3650db2b7560eb587b9606c\n  Author: Joel Coffman <joel.coffman@jhuapl.edu>\n  Date:   Fri Apr 24 16:14:25 2015 -0400\n\n    libvirt: Remove unnecessary JSON conversions\n\nChanges the '_create_images_and_backing' method to take a\ndict instead of a JSON string for the 'disk_info' parameter.\nUnfortunately it only updated one of the callers, so the\nmigration code was still passing a JSON string.\n\nThis wasn't caught because all the unit tests were broken,\nmistakenly passing a dict instead of a json string to the\npre_live_migration method, and the _create_images_and_backing\nmethod was stubbed out with a mock, so never ran. Add a\ncheck on the parameters to the _create_images_and_backing\nmock to ensure it is given a dict, and not a json string.\n\nChange-Id: I6a8f009bb21bce9e6408ebc4508094bdcbef05c5\nCloses-bug: #1463747\n""}]",0,190110,02d6ebf839799f893ac658943efa18d80dc76ca7,16,11,1,1779,,,0,"libvirt: fix live migration handling of disk_info

Previous commmit:

  commit a7a0b4e542a65b3ba3650db2b7560eb587b9606c
  Author: Joel Coffman <joel.coffman@jhuapl.edu>
  Date:   Fri Apr 24 16:14:25 2015 -0400

    libvirt: Remove unnecessary JSON conversions

Changes the '_create_images_and_backing' method to take a
dict instead of a JSON string for the 'disk_info' parameter.
Unfortunately it only updated one of the callers, so the
migration code was still passing a JSON string.

This wasn't caught because all the unit tests were broken,
mistakenly passing a dict instead of a json string to the
pre_live_migration method, and the _create_images_and_backing
method was stubbed out with a mock, so never ran. Add a
check on the parameters to the _create_images_and_backing
mock to ensure it is given a dict, and not a json string.

Change-Id: I6a8f009bb21bce9e6408ebc4508094bdcbef05c5
Closes-bug: #1463747
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/190110/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,02d6ebf839799f893ac658943efa18d80dc76ca7,bug/1463747," disk_info_json = jsonutils.dumps({}) network_info=[], disk_info=disk_info_json) disk_info_json = jsonutils.dumps({}) network_info=[], disk_info=disk_info_json) disk_info_json = jsonutils.dumps({}) block_device_info=None, network_info=[], disk_info=disk_info_json, migrate_data=migrate_data) disk_info_json = jsonutils.dumps({}) block_device_info=None, network_info=[], disk_info=disk_info_json, migrate_data=migrate_data) create_image_mock.assert_has_calls( [mock.call(self.context, instance, mock.ANY, {}, fallback_from_host=instance.host)]) disk_info_json = jsonutils.dumps({}) network_info=[], disk_info=disk_info_json, migrate_data={})"," network_info=[], disk_info={}) network_info=[], disk_info={}) block_device_info=None, network_info=[], disk_info={}, migrate_data=migrate_data) block_device_info=None, network_info=[], disk_info={}, migrate_data=migrate_data) self.assertTrue(create_image_mock.called) network_info=[], disk_info={}, migrate_data={})",23,10
openstack%2Fopenstacksdk~master~I9d5b4999e9359d40bbd9e5afa460cb48cccf6dae,openstack/openstacksdk,master,I9d5b4999e9359d40bbd9e5afa460cb48cccf6dae,Add action() and check() method for heat support,MERGED,2015-06-09 04:30:05.000000000,2015-06-10 15:47:30.000000000,2015-06-10 15:47:29.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-09 04:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3c592a55c917e3f796a7e59651f4f4994e0d8cfd', 'message': 'Add action() and check() method for heat support\n\nChange-Id: I9d5b4999e9359d40bbd9e5afa460cb48cccf6dae\n'}, {'number': 2, 'created': '2015-06-09 09:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ee6ac84bf463f4dfec93f9b66aa5ffc2148888c7', 'message': 'Add action() and check() method for heat support\n\nChange-Id: I9d5b4999e9359d40bbd9e5afa460cb48cccf6dae\n'}, {'number': 3, 'created': '2015-06-10 01:14:49.000000000', 'files': ['openstack/orchestration/v1/stack.py', 'openstack/tests/unit/orchestration/v1/test_stack.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ebf3bec69dcce876ce80508aeaf4e8e00548d1a7', 'message': 'Add action() and check() method for heat support\n\nChange-Id: I9d5b4999e9359d40bbd9e5afa460cb48cccf6dae\n'}]",6,189548,ebf3bec69dcce876ce80508aeaf4e8e00548d1a7,14,4,3,6348,,,0,"Add action() and check() method for heat support

Change-Id: I9d5b4999e9359d40bbd9e5afa460cb48cccf6dae
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/48/189548/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/orchestration/v1/stack.py'],1,3c592a55c917e3f796a7e59651f4f4994e0d8cfd,add_heat_check," def action(self, session, body): """"""Perform stack actions"""""" url = utils.urljoin(self.base_path, self.id, 'action') resp = session.put(url, service=self.service, json=body).body return resp def check(self, session): body = {'check': null} return self.action(session, body) ",,10,0
openstack%2Fopenstacksdk~master~I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b,openstack/openstacksdk,master,I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b,Add some examples documentation,MERGED,2015-05-05 16:26:22.000000000,2015-06-10 15:31:54.000000000,2015-06-10 15:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 2750}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-05-05 16:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/57b09a9157bd9d1ceebe444d6067e0e4256f357c', 'message': 'Add some examples documentation\n\nChange-Id: I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b\n'}, {'number': 2, 'created': '2015-05-12 14:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c513fef9c3e62dd3e5342e5902af82470db78f41', 'message': 'Add some examples documentation\n\nChange-Id: I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b\n'}, {'number': 3, 'created': '2015-05-22 15:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/28f3e2e3c986f82d3cdfa440badb741685d5cfb6', 'message': 'Add some examples documentation\n\nChange-Id: I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b\n'}, {'number': 4, 'created': '2015-05-22 15:34:38.000000000', 'files': ['doc/source/users/index.rst', 'doc/source/users/examples.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c3b997dc77d3db46a8070aeb8d615379fabd6411', 'message': 'Add some examples documentation\n\nChange-Id: I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b\n'}]",1,180222,c3b997dc77d3db46a8070aeb8d615379fabd6411,17,4,4,8736,,,0,"Add some examples documentation

Change-Id: I2a4a0badc7d89722aaaeefae21dd3e92e4584c8b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/22/180222/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/index.rst', 'doc/source/users/examples.rst']",2,57b09a9157bd9d1ceebe444d6067e0e4256f357c,exampledocs,"OpenStack SDK Examples ====================== An effort has been made to provide some useful examples to try out the SDK. These examples reside in the examples directory of the project. The examples use an authentication configuration that is very similar to the configuration used for most OpenStack clients. Configuration ------------- Most of the examples use a common argument parser to collect authentication information to run requests. The authentication may come from the OS style environment variables used in many client libraries or is may use https://pypi.python.org/pypi/os-client-config which normally would select a configuration using the OS_CLOUD environment variable.:: OS_REGION_NAME=Manhattan OS_PROJECT_NAME=beasties OS_IDENTITY_API_VERSION=2.0 OS_PASSWORD=horovitz OS_AUTH_URL=https://127.0.0.1:5000/v2.0/ OS_USERNAME=adrock Alternatively, you may use os-cloud-config which typically uses a yaml file in ~/.config/openstack/clouds.yaml to store authentication and preference information. If you are using os-cloud-config, you can use the OS_CLOUD environment variable or use the --os-cloud command line option to specify the cloud you want to use.:: OS_CLOUD=miked Running ------- Once you have a configuration, most examples can be run by calling them directly. For example, the list example can be run by just passing it the name of the resource you want to list:: python examples/list.py openstack/compute/v2/flavor.py The example code uses some logic to parse the file name and generate a resource class name. That may not work if the resource class name does not match the file name. If that is the case, you will need to specify the resource module name:: python examples/list.py openstack.network.v2.floating_ip.FloatingIP ",,48,0
openstack%2Fpython-glanceclient~master~Ied7f5b4f298e2bbf4a5486eb6b7dbcea2d0e74d3,openstack/python-glanceclient,master,Ied7f5b4f298e2bbf4a5486eb6b7dbcea2d0e74d3,Add release notes for 0.19.0,MERGED,2015-06-10 03:42:59.000000000,2015-06-10 15:31:22.000000000,2015-06-10 15:31:20.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-10 03:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/3718e4dba6e8ad01c1719284b3cd5b882f067b85', 'message': 'Add release notes for 0.19.0\n\nChanges included in this release:\n\n    $ git log 0.18.0..HEAD --no-merges --oneline\n    dfa98ab Updated from global requirements\n    6cb26fc Include owner and status option in v2 image list\n    5d933b0 Fix Metadef Object update issue with python-glanceclient\n    9f5c581 Fix functional tests in gate\n    1686d6a Do not crash on homedir mkdir\n    1f89beb Improve import related error handling\n    583adc3 Check image-download for redirection\n    9c172fb Add some basic CLI functional tests\n    bf413a6 Use assertIn instead of assertTrue in tests\n    6431fae Unorder compare in tests\n    5fa71aa Add release notes for 0.18.0\n    6d31116 Update README to work with release tools\n    71d9783 Create functional test base\n    f2a8a52 Move unit tests to standard directory\n    f931a20 Fixed doc example\n\nChange-Id: Ied7f5b4f298e2bbf4a5486eb6b7dbcea2d0e74d3\n'}, {'number': 2, 'created': '2015-06-10 09:06:52.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/db6420b44779411d6d1f238f6b887f83f1988986', 'message': 'Add release notes for 0.19.0\n\nChanges included in this release:\n\n    $ git log 0.18.0..HEAD --no-merges --oneline\n    dfa98ab Updated from global requirements\n    6cb26fc Include owner and status option in v2 image list\n    5d933b0 Fix Metadef Object update issue with python-glanceclient\n    9f5c581 Fix functional tests in gate\n    1686d6a Do not crash on homedir mkdir\n    1f89beb Improve import related error handling\n    583adc3 Check image-download for redirection\n    9c172fb Add some basic CLI functional tests\n    bf413a6 Use assertIn instead of assertTrue in tests\n    6431fae Unorder compare in tests\n    5fa71aa Add release notes for 0.18.0\n    6d31116 Update README to work with release tools\n    71d9783 Create functional test base\n    f2a8a52 Move unit tests to standard directory\n    f931a20 Fixed doc example\n\nCo-Authored-By: Louis Taylor <louis@kragniz.eu>\n\nChange-Id: Ied7f5b4f298e2bbf4a5486eb6b7dbcea2d0e74d3\n'}]",0,190010,db6420b44779411d6d1f238f6b887f83f1988986,9,4,2,2537,,,0,"Add release notes for 0.19.0

Changes included in this release:

    $ git log 0.18.0..HEAD --no-merges --oneline
    dfa98ab Updated from global requirements
    6cb26fc Include owner and status option in v2 image list
    5d933b0 Fix Metadef Object update issue with python-glanceclient
    9f5c581 Fix functional tests in gate
    1686d6a Do not crash on homedir mkdir
    1f89beb Improve import related error handling
    583adc3 Check image-download for redirection
    9c172fb Add some basic CLI functional tests
    bf413a6 Use assertIn instead of assertTrue in tests
    6431fae Unorder compare in tests
    5fa71aa Add release notes for 0.18.0
    6d31116 Update README to work with release tools
    71d9783 Create functional test base
    f2a8a52 Move unit tests to standard directory
    f931a20 Fixed doc example

Co-Authored-By: Louis Taylor <louis@kragniz.eu>

Change-Id: Ied7f5b4f298e2bbf4a5486eb6b7dbcea2d0e74d3
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/10/190010/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,3718e4dba6e8ad01c1719284b3cd5b882f067b85,rel-notes-19,0.19.0 ------ * Global requirements update. * 1381514_: Include ``owner`` in v2 image list * 1433884_: Glance ``Metadata Object`` update doesn't work from python glanceclient * 1455102_: some test jobs broken by tox 2.0 not passing env variables * 1446096_: Glanceclient crashes on mkdir $HOME * 1402632_: issue with glance python client in ``Icehouse`` .. _1381514: https://bugs.launchpad.net/python-glanceclient/+bug/1381514 .. _1433884: https://bugs.launchpad.net/python-glanceclient/+bug/1433884 .. _1455102: https://bugs.launchpad.net/python-glanceclient/+bug/1455102 .. _1446096: https://bugs.launchpad.net/python-glanceclient/+bug/1446096 .. _1402632: https://bugs.launchpad.net/python-glanceclient/+bug/1402632 ,,16,0
openstack%2Fdevstack~master~I101fac0dc6fdc97b7fb0b2955cffc6b4905152e5,openstack/devstack,master,I101fac0dc6fdc97b7fb0b2955cffc6b4905152e5,"Revert ""Replace pip-installed requests CA bundle with link""",MERGED,2015-06-10 10:26:57.000000000,2015-06-10 15:31:14.000000000,2015-06-10 12:51:52.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-10 10:26:57.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7272afdf8bf55580f778530d590afd505394b4ae', 'message': 'Revert ""Replace pip-installed requests CA bundle with link""\n\nThis does not gracefully handle the situation where requests\nis not there at the beginning. Needs to be rethought.\n\nThis reverts commit 7d350720fe5d25fece68c5d1625a33a6cad431ef.\n\nChange-Id: I101fac0dc6fdc97b7fb0b2955cffc6b4905152e5\n'}]",0,190103,7272afdf8bf55580f778530d590afd505394b4ae,6,3,1,2750,,,0,"Revert ""Replace pip-installed requests CA bundle with link""

This does not gracefully handle the situation where requests
is not there at the beginning. Needs to be rethought.

This reverts commit 7d350720fe5d25fece68c5d1625a33a6cad431ef.

Change-Id: I101fac0dc6fdc97b7fb0b2955cffc6b4905152e5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/190103/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,7272afdf8bf55580f778530d590afd505394b4ae,1459789,," # If a non-system python-requests is installed then it will use the # built-in CA certificate store rather than the distro-specific # CA certificate store. Detect this and symlink to the correct # one. If the value for the CA is not rooted in /etc then we know # we need to change it. capath=$(python -c ""from requests import certs; print certs.where()"") if is_service_enabled tls-proxy || [ ""$USE_SSL"" == ""True"" ]; then if [[ ! $capath =~ ^/etc/.* && ! -L $capath ]]; then if is_fedora; then sudo rm -f $capath sudo ln -s /etc/pki/tls/certs/ca-bundle.crt $capath elif is_ubuntu; then sudo rm -f $capath sudo ln -s /etc/ssl/certs/ca-certificates.crt $capath else echo ""Don't know how to set the CA bundle, expect the install to fail."" fi fi fi",0,21
openstack%2Fceilometer~master~I3c81175c88744eed642b2448ae92ad822f0b9b36,openstack/ceilometer,master,I3c81175c88744eed642b2448ae92ad822f0b9b36,Merge tag '2015.1.0',MERGED,2015-04-30 23:28:07.000000000,2015-06-10 15:30:23.000000000,2015-06-10 15:30:20.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 11564}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-04-30 23:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9e171a2c4028f51b2e8a75639bf5fc055fd9a7e4', 'message': ""Merge tag '2015.1.0'\n\nCeilometer 2015.1.0\n\nChange-Id: I3c81175c88744eed642b2448ae92ad822f0b9b36\n""}, {'number': 2, 'created': '2015-06-09 17:47:00.000000000', 'files': ['ceilometer/locale/it/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-info.po', '.gitreview', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-info.po', 'test-requirements.txt', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-error.po', 'requirements.txt', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/te_IN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_AU/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/storage/__init__.py', 'ceilometer/locale/es/LC_MESSAGES/ceilometer-log-info.po', 'requirements-py3.txt', 'test-requirements-py3.txt', 'ceilometer/cmd/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b192f69f166317bbf048886f3a78d68fc89e64d1', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I3c81175c88744eed642b2448ae92ad822f0b9b36\n""}]",0,179290,b192f69f166317bbf048886f3a78d68fc89e64d1,21,6,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I3c81175c88744eed642b2448ae92ad822f0b9b36
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/90/179290/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/locale/it/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_AU/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-error.po', '.gitreview', 'ceilometer/locale/vi_VN/LC_MESSAGES/ceilometer-log-info.po', 'requirements.txt', 'ceilometer/locale/te_IN/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_AU/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer-log-error.po', 'test-requirements-py3.txt', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/es/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-warning.po', 'ceilometer/locale/ko_KR/LC_MESSAGES/ceilometer-log-info.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/ja/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/de/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/fr/LC_MESSAGES/ceilometer-log-error.po', 'ceilometer/locale/es/LC_MESSAGES/ceilometer-log-info.po', 'requirements-py3.txt', 'ceilometer/locale/pt_BR/LC_MESSAGES/ceilometer-log-error.po']",23,9e171a2c4028f51b2e8a75639bf5fc055fd9a7e4,merge/release-tag,"# Translations template for ceilometer. # Copyright (C) 2015 ORGANIZATION # This file is distributed under the same license as the ceilometer project. # # Translators: msgid """" msgstr """" ""Project-Id-Version: Ceilometer\n"" ""Report-Msgid-Bugs-To: EMAIL@ADDRESS\n"" ""POT-Creation-Date: 2015-03-31 06:06+0000\n"" ""PO-Revision-Date: 2015-03-18 21:15+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n"" ""Language-Team: Portuguese (Brazil) (http://www.transifex.com/projects/p/"" ""ceilometer/language/pt_BR/)\n"" ""Language: pt_BR\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" #: ceilometer/collector.py:170 #, python-format msgid ""Dispatcher failed to handle the %s, requeue it."" msgstr """" #: ceilometer/collector.py:212 #, python-format msgid ""Error processing event and it will be dropped: %s"" msgstr """" #: ceilometer/coordination.py:79 ceilometer/coordination.py:91 msgid ""Error connecting to coordination backend."" msgstr """" #: ceilometer/coordination.py:107 msgid ""Error sending a heartbeat to coordination backend."" msgstr """" #: ceilometer/coordination.py:177 msgid ""Error getting group membership info from coordination backend."" msgstr """" #: ceilometer/compute/pollsters/memory.py:106 #, python-format msgid ""Could not get Resident Memory Usage for %(id)s: %(e)s"" msgstr """" #: ceilometer/dispatcher/http.py:135 msgid ""Status Code: %{code}s. Failed to dispatch event: %{event}s"" msgstr """" #: ceilometer/openstack/common/loopingcall.py:95 msgid ""in fixed duration looping call"" msgstr ""em uma chamada de laço de duração fixa"" #: ceilometer/openstack/common/loopingcall.py:138 msgid ""in dynamic looping call"" msgstr ""em chamada de laço dinâmico"" #: ceilometer/openstack/common/service.py:268 msgid ""Unhandled exception"" msgstr ""Exceção não tratada"" #: ceilometer/publisher/kafka_broker.py:95 #: ceilometer/publisher/kafka_broker.py:177 #, python-format msgid ""Failed to connect to Kafka service: %s"" msgstr """" #: ceilometer/publisher/kafka_broker.py:158 msgid ""Failed to retry to send sample data with max_retry times"" msgstr """" #: ceilometer/publisher/kafka_broker.py:198 #, python-format msgid ""Failed to send sample data: %s"" msgstr """" ",,1756,27
openstack%2Fnova~master~Ic28ab566d083f30e2749361bd80f6f446e73a93d,openstack/nova,master,Ic28ab566d083f30e2749361bd80f6f446e73a93d,Remove db layer hard-code permission checks for network_get_associated_fixed_ips,MERGED,2015-03-05 06:54:32.000000000,2015-06-10 15:29:24.000000000,2015-06-10 15:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-05 06:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8eb5c948fb662dbb92746850d6193859274772ad', 'message': 'Remove db layer hard-code permission checks for network_get_associated_fixed_ips\n\nThis patches removes db layer hard-code permission checks for\nnetwork_get_associated_fixed_ips.\n\nIt is called by the follow function:\n    deallocate_for_instance\n    remove_fixed_ip_from_instance\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ic28ab566d083f30e2749361bd80f6f446e73a93d\n'}, {'number': 2, 'created': '2015-03-10 06:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a335f54400aafa733e16705841d38c741f8b58b', 'message': 'Remove db layer hard-code permission checks for network_get_associated_fixed_ips\n\nThis patches removes db layer hard-code permission checks for\nnetwork_get_associated_fixed_ips.\n\nIt is called by the follow function:\n  1. get_dhcp_leases, the contex is admin context\n  2. init_host, the contex is admin context\n  3. update_dhcp, it is called by:\n     _setup_network_on_host, context is elevated\n     _teardown_network_on_host, context is elevated\n  4. update_dns it is call by\n     _periodic_update_dns\n     allocate_for_instance, it is fixed by\n       https://review.openstack.org/#/c/150687\n     deallocate_for_instance, it is called by\n       _local_delete, context is elevated\n     _deallocate_network, it is called by\n       _build_instance, context is elevated\n       _try_deallocate_network, context is elevated\n       _cleanup_allocated_networks\n  5. objects.Network.in_use_on_host\n     deallocate_for_instance, it is called by\n       _local_delete, context is elevated\n     remove_fixed_ip_from_instance, it is called by _remove_fixed_ip\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ic28ab566d083f30e2749361bd80f6f446e73a93d\n'}, {'number': 3, 'created': '2015-04-20 09:02:21.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bd92f33f92c2fb8d4708108c280314f8b7c0e880', 'message': 'Remove db layer hard-code permission checks for network_get_associated_fixed_ips\n\nThis patches removes db layer hard-code permission checks for\nnetwork_get_associated_fixed_ips.\n\nIt is called by the follow function:\n  1. get_dhcp_leases, the contex is admin context\n  2. init_host, the contex is admin context\n  3. update_dhcp, it is called by:\n     _setup_network_on_host, context is elevated\n     _teardown_network_on_host, context is elevated\n  4. update_dns it is call by\n     _periodic_update_dns\n     allocate_for_instance, it is fixed by\n       https://review.openstack.org/#/c/150687\n     deallocate_for_instance, it is called by\n       _local_delete, context is elevated\n     _deallocate_network, it is called by\n       _build_instance, context is elevated\n       _try_deallocate_network, context is elevated\n       _cleanup_allocated_networks\n  5. objects.Network.in_use_on_host\n     deallocate_for_instance, it is called by\n       _local_delete, context is elevated\n     remove_fixed_ip_from_instance, it is called by _remove_fixed_ip\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: Ic28ab566d083f30e2749361bd80f6f446e73a93d\n'}]",0,161630,bd92f33f92c2fb8d4708108c280314f8b7c0e880,30,14,3,14131,,,0,"Remove db layer hard-code permission checks for network_get_associated_fixed_ips

This patches removes db layer hard-code permission checks for
network_get_associated_fixed_ips.

It is called by the follow function:
  1. get_dhcp_leases, the contex is admin context
  2. init_host, the contex is admin context
  3. update_dhcp, it is called by:
     _setup_network_on_host, context is elevated
     _teardown_network_on_host, context is elevated
  4. update_dns it is call by
     _periodic_update_dns
     allocate_for_instance, it is fixed by
       https://review.openstack.org/#/c/150687
     deallocate_for_instance, it is called by
       _local_delete, context is elevated
     _deallocate_network, it is called by
       _build_instance, context is elevated
       _try_deallocate_network, context is elevated
       _cleanup_allocated_networks
  5. objects.Network.in_use_on_host
     deallocate_for_instance, it is called by
       _local_delete, context is elevated
     remove_fixed_ip_from_instance, it is called by _remove_fixed_ip

Partially implements bp nova-api-policy-final-part

Change-Id: Ic28ab566d083f30e2749361bd80f6f446e73a93d
",git fetch https://review.opendev.org/openstack/nova refs/changes/30/161630/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,8eb5c948fb662dbb92746850d6193859274772ad,bp/nova-api-policy-final-part,,@require_admin_context,0,1
openstack%2Fnova~master~Ia60514c54f7ba473cc7c58b6c4a10779bafd15d0,openstack/nova,master,Ia60514c54f7ba473cc7c58b6c4a10779bafd15d0,Object: Fix incorrect parameter set in flavor save_extra_specs,MERGED,2015-04-22 01:48:06.000000000,2015-06-10 15:28:55.000000000,2015-06-10 15:28:51.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5441}, {'_account_id': 6450}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12175}, {'_account_id': 15286}]","[{'number': 1, 'created': '2015-04-22 01:48:06.000000000', 'files': ['nova/objects/flavor.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0589fd25093dfe9bdf154e24989db638578a0abb', 'message': ""Object: Fix incorrect parameter set in flavor save_extra_specs\n\nIn save_extra_specs, we pass to_add, and it's default value is None,\nwe have:\n    to_add = to_add if to_add is not None else []\nbut seen from db.flavor_extra_specs_update_or_create, to_add should be a dict\ninstead of a list.\n\nChange-Id: Ia60514c54f7ba473cc7c58b6c4a10779bafd15d0\n""}]",0,176157,0589fd25093dfe9bdf154e24989db638578a0abb,22,12,1,12175,,,0,"Object: Fix incorrect parameter set in flavor save_extra_specs

In save_extra_specs, we pass to_add, and it's default value is None,
we have:
    to_add = to_add if to_add is not None else []
but seen from db.flavor_extra_specs_update_or_create, to_add should be a dict
instead of a list.

Change-Id: Ia60514c54f7ba473cc7c58b6c4a10779bafd15d0
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/176157/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/flavor.py'],1,0589fd25093dfe9bdf154e24989db638578a0abb,fix_flavor_object_save_extra_specs, to_add = to_add if to_add is not None else {}, to_add = to_add if to_add is not None else [],1,1
openstack%2Fnova~master~Ia6e8ee37af82a934581f8ecccd320136a6774916,openstack/nova,master,Ia6e8ee37af82a934581f8ecccd320136a6774916,Remove db layer hard-code permission checks for floating_ips_bulk,MERGED,2015-01-28 06:19:52.000000000,2015-06-10 15:21:29.000000000,2015-06-10 15:21:26.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 11189}, {'_account_id': 12175}, {'_account_id': 14131}]","[{'number': 1, 'created': '2015-01-28 06:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca0d85d637831ad32b50fbe4aae5ea93319b8792', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk.\n\nPartially implements bp v3-api-policy\nDocImpact\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 2, 'created': '2015-02-28 16:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7e63d0ec5f12fd3a10a012147a8ceb414d11d3b5', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 3, 'created': '2015-03-16 10:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e53c73050b0f982291b5b1a94495c6abb79210d', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 4, 'created': '2015-03-18 03:23:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa59d690fe7939b149a8f52d1b85623105a932dd', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 5, 'created': '2015-03-18 08:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91548a3cc01a1c83136f2bd01312ffc02fccdd3c', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk and add policy checking test for API layer.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 6, 'created': '2015-03-18 12:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/167f154e177c956864993e2cda26bf2aa2e0cbdb', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk and add policy checking test for API layer.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 7, 'created': '2015-03-18 14:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf3df669d2bd0f501f335983396ac17db3506b5d', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk and add policy checking test for API layer.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 8, 'created': '2015-03-18 14:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0cea7c03eb293d63542e2b845a7e70b64a3ca73', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk and add policy checking test for API layer.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 9, 'created': '2015-03-18 14:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47d8735d368f669b5e1c1508f1d6466595df09a7', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk and add policy checking test for API layer.\n\nPartially implements bp v3-api-policy\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}, {'number': 10, 'created': '2015-04-23 07:00:34.000000000', 'files': ['nova/api/openstack/compute/contrib/floating_ips_bulk.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ips_bulk.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e6d6629709efd21654adc6bf534d98eb0eb24948', 'message': 'Remove db layer hard-code permission checks for floating_ips_bulk\n\nThis patches removes db layer hard-code permission checks for\nfloating_ips_bulk and add policy checking test for API layer.\n\nPartially implements bp nova-api-policy-final-part\n\nChange-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916\n'}]",8,150704,e6d6629709efd21654adc6bf534d98eb0eb24948,62,16,10,14131,,,0,"Remove db layer hard-code permission checks for floating_ips_bulk

This patches removes db layer hard-code permission checks for
floating_ips_bulk and add policy checking test for API layer.

Partially implements bp nova-api-policy-final-part

Change-Id: Ia6e8ee37af82a934581f8ecccd320136a6774916
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/150704/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/fake_policy.py', 'nova/api/openstack/compute/contrib/floating_ips_bulk.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ips_bulk.py', 'nova/db/sqlalchemy/api.py']",4,ca0d85d637831ad32b50fbe4aae5ea93319b8792,bp/nova-api-policy-final-part,,@require_context@require_context@require_context@require_context@require_context@require_context@require_admin_context@require_admin_context@require_context@require_context@require_context@require_context@require_context,20,20
openstack%2Ftempest~master~Id3b626b66f797e32e18f4d1771561a1db5ecd26c,openstack/tempest,master,Id3b626b66f797e32e18f4d1771561a1db5ecd26c,Add tenant network creation to account creation script,MERGED,2015-06-08 17:32:42.000000000,2015-06-10 15:18:28.000000000,2015-06-10 15:18:27.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 9377}, {'_account_id': 10385}, {'_account_id': 10644}]","[{'number': 1, 'created': '2015-06-08 17:32:42.000000000', 'files': ['tempest/cmd/account_generator.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0aa4a7bce6e2202116cab3d63c1449eb40bf86fb', 'message': 'Add tenant network creation to account creation script\n\nThe script will now create a tenant network for each account in the same\nway as the isolated creds code creates networks. In this case we always\ncreate all network resource options since each test account could run a test\nthat requires any one of them. The accounts will only be created if neutron\nis available and the user did not set auth.create_isolated_networks to\nFalse.\n\nPartially implements: blueprint test-accounts-continued\n\nChange-Id: Id3b626b66f797e32e18f4d1771561a1db5ecd26c\n'}]",1,189376,0aa4a7bce6e2202116cab3d63c1449eb40bf86fb,11,7,1,1192,,,0,"Add tenant network creation to account creation script

The script will now create a tenant network for each account in the same
way as the isolated creds code creates networks. In this case we always
create all network resource options since each test account could run a test
that requires any one of them. The accounts will only be created if neutron
is available and the user did not set auth.create_isolated_networks to
False.

Partially implements: blueprint test-accounts-continued

Change-Id: Id3b626b66f797e32e18f4d1771561a1db5ecd26c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/76/189376/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/account_generator.py'],1,0aa4a7bce6e2202116cab3d63c1449eb40bf86fb,bp/test-accounts-continued,"import netaddrfrom tempest.services.network.json import network_clientdef get_admin_clients(opts): identity_admin = identity_client.IdentityClientJSON( network_admin = None if (CONF.service_available.neutron and CONF.auth.create_isolated_networks): network_admin = network_client.NetworkClientJSON( _auth, CONF.network.catalog_type, CONF.network.region or CONF.identity.region, endpoint_type='adminURL', **params) return identity_admin, network_admin identity_admin, network_admin = get_admin_clients(opts) roles = identity_admin.list_roles() existing = [x['name'] for x in identity_admin.list_tenants()] identity_admin.create_tenant(tenant) tenant = identity_admin.get_tenant_by_name(u['tenant']) identity_admin.get_user_by_username(tenant['id'], u['name']) except tempest_lib.exceptions.NotFound: identity_admin.create_user( if network_admin: for u in resources['users']: tenant = identity_admin.get_tenant_by_name(u['tenant']) network_name = create_network_resources(network_admin, tenant['id'], u['name']) u['network'] = network_name LOG.info('Networks created') tenant = identity_admin.get_tenant_by_name(u['tenant']) user = identity_admin.get_user_by_username(tenant['id'], u['name']) identity_admin.assign_user_role(tenant['id'], user['id'], r)def create_network_resources(network_admin_client, tenant_id, name): def _create_network(name): resp_body = network_admin_client.create_network( name=name, tenant_id=tenant_id) return resp_body['network'] def _create_subnet(subnet_name, network_id): base_cidr = netaddr.IPNetwork(CONF.network.tenant_network_cidr) mask_bits = CONF.network.tenant_network_mask_bits for subnet_cidr in base_cidr.subnet(mask_bits): try: resp_body = network_admin_client.\ create_subnet( network_id=network_id, cidr=str(subnet_cidr), name=subnet_name, tenant_id=tenant_id, enable_dhcp=True, ip_version=4) break except tempest_lib.exceptions.BadRequest as e: if 'overlaps with another subnet' not in str(e): raise else: message = 'Available CIDR for subnet creation could not be found' raise Exception(message) return resp_body['subnet'] def _create_router(router_name): external_net_id = dict( network_id=CONF.network.public_network_id) resp_body = network_admin_client.create_router( router_name, external_gateway_info=external_net_id, tenant_id=tenant_id) return resp_body['router'] def _add_router_interface(router_id, subnet_id): network_admin_client.add_router_interface_with_subnet_id( router_id, subnet_id) network_name = name + ""-network"" network = _create_network(network_name) subnet_name = name + ""-subnet"" subnet = _create_subnet(subnet_name, network['id']) router_name = name + ""-router"" router = _create_router(router_name) _add_router_interface(router['id'], subnet['id']) return network_name account = { } if 'network' in user: account['resources'] = {'network': user['network']} accounts.append(account)","def keystone_admin(opts): return identity_client.IdentityClientJSON( admin = keystone_admin(opts) roles = admin.list_roles() existing = [x['name'] for x in admin.list_tenants()] admin.create_tenant(tenant) tenant = admin.get_tenant_by_name(u['tenant']) admin.get_user_by_username(tenant['id'], u['name']) except tempest_lib.exceptions.NotFound: admin.create_user( tenant = admin.get_tenant_by_name(u['tenant']) user = admin.get_user_by_username(tenant['id'], u['name']) admin.assign_user_role(tenant['id'], user['id'], r) accounts.append({ })",89,15
openstack%2Fopenstack-ansible~icehouse~I7f1933680e2859e007f6b8be262852b164f90b33,openstack/openstack-ansible,icehouse,I7f1933680e2859e007f6b8be262852b164f90b33,Generate a SHA-2 certificate for Horizon,MERGED,2015-06-10 03:22:39.000000000,2015-06-10 15:18:21.000000000,2015-06-10 15:18:20.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 7307}, {'_account_id': 7414}, {'_account_id': 8119}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-10 03:22:39.000000000', 'files': ['rpc_deployment/roles/openssl_pem_request/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0977e2ab5545f4653fdf6c1b17d37b9fa8abe26d', 'message': 'Generate a SHA-2 certificate for Horizon\n\nSHA-1 certificates are being deprecated and browsers are starting to\nissue warnings about their use. We should begin generating SHA-2\ncertificates for Horizon.\n\nCloses-bug: 1461983\nChange-Id: I7f1933680e2859e007f6b8be262852b164f90b33\n(cherry picked from commit ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327)\n(cherry picked from commit dc862c803c6e9839f814ba31f2a2271b9d356611)\n'}]",6,190005,0977e2ab5545f4653fdf6c1b17d37b9fa8abe26d,14,6,1,12000,,,0,"Generate a SHA-2 certificate for Horizon

SHA-1 certificates are being deprecated and browsers are starting to
issue warnings about their use. We should begin generating SHA-2
certificates for Horizon.

Closes-bug: 1461983
Change-Id: I7f1933680e2859e007f6b8be262852b164f90b33
(cherry picked from commit ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327)
(cherry picked from commit dc862c803c6e9839f814ba31f2a2271b9d356611)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/05/190005/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/openssl_pem_request/tasks/main.yml'],1,0977e2ab5545f4653fdf6c1b17d37b9fa8abe26d,bug/1461983, openssl req -newkey -sha256 rsa:2048, openssl req -newkey rsa:2048,1,1
openstack%2Fproject-config~master~I6718757a3399496f4f7bfc9d482714590bca0603,openstack/project-config,master,I6718757a3399496f4f7bfc9d482714590bca0603,"Remove the surplus comma, it breaks the tempest tests",MERGED,2015-06-10 14:07:00.000000000,2015-06-10 15:18:18.000000000,2015-06-10 15:18:15.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 9624}, {'_account_id': 14339}]","[{'number': 1, 'created': '2015-06-10 14:07:00.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/364699bfc9d1454bc03a63ea0e648aa4bde89b0e', 'message': 'Remove the surplus comma, it breaks the tempest tests\n\nBecause of that comma devstack believes that multiple backends are\nconfigured (lib/tempest:454); so the multi-backend tests are run,\nand consequently fail.\n\nChange-Id: I6718757a3399496f4f7bfc9d482714590bca0603\n'}]",0,190201,364699bfc9d1454bc03a63ea0e648aa4bde89b0e,9,6,1,10677,,,0,"Remove the surplus comma, it breaks the tempest tests

Because of that comma devstack believes that multiple backends are
configured (lib/tempest:454); so the multi-backend tests are run,
and consequently fail.

Change-Id: I6718757a3399496f4f7bfc9d482714590bca0603
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/190201/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,364699bfc9d1454bc03a63ea0e648aa4bde89b0e,," CINDER_ENABLED_BACKENDS=drbd:drbdmanage"""," CINDER_ENABLED_BACKENDS=,drbd:drbdmanage""",1,1
openstack%2Fproject-config~master~I17b07d86a0d8c502cba241c943bcbd8efccdc694,openstack/project-config,master,I17b07d86a0d8c502cba241c943bcbd8efccdc694,add experimental job for integration testing with rake on chef cookbooks,MERGED,2015-05-28 13:18:05.000000000,2015-06-10 15:16:37.000000000,2015-06-10 15:16:35.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 7128}, {'_account_id': 11915}, {'_account_id': 12323}]","[{'number': 1, 'created': '2015-05-28 13:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/350ab1898dcb1607062c149dea3cb0d285204c3b', 'message': ""add experimental job for integration testing with rake on chef cookbooks\n\n- added experimental job template 'gate-{name}-chef-rake-integration' to the queue to start\n  the building of integration layer tests for the openstack chef cookbooks\n- this job has to stay in 'experimental' until all cookbooks include working\n  and reliable rake tasks for integration testing and will be moved\n  afterwards to 'check' and 'gate'\n- modified regex to filter all chef-rake jobs depending on the branch\n\nChange-Id: I17b07d86a0d8c502cba241c943bcbd8efccdc694\n""}, {'number': 2, 'created': '2015-05-28 14:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/078a03e706c3fe59dfeda44bd7e226024ca6927c', 'message': ""add experimental job for integration testing with rake on chef cookbooks\n\n- added experimental job template 'gate-{name}-chef-rake-integration' to the queue to start\n  the building of integration layer tests for the openstack chef cookbooks\n- this job has to stay in 'experimental' until all cookbooks include working\n  and reliable rake tasks for integration testing and will be moved\n  afterwards to 'check' and 'gate'\n- modified regex to filter all chef-rake jobs depending on the branch\n\nChange-Id: I17b07d86a0d8c502cba241c943bcbd8efccdc694\n""}, {'number': 3, 'created': '2015-06-08 09:28:17.000000000', 'files': ['jenkins/jobs/chef-jobs.yaml', 'jenkins/jobs/projects.yaml', 'jenkins/jobs/macros.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a57d780e70667af66345b76c28151a7cb5d6abfd', 'message': ""add experimental job for integration testing with rake on chef cookbooks\n\n- added experimental job template 'gate-{name}-chef-rake-integration' to the queue to start\n  the building of integration layer tests for the openstack chef cookbooks\n- this job has to stay in 'experimental' until all cookbooks include working\n  and reliable rake tasks for integration testing and will be moved\n  afterwards to 'check' and 'gate'\n- modified regex to filter all chef-rake jobs depending on the branch\n\nChange-Id: I17b07d86a0d8c502cba241c943bcbd8efccdc694\n""}]",2,186379,a57d780e70667af66345b76c28151a7cb5d6abfd,26,8,3,11915,,,0,"add experimental job for integration testing with rake on chef cookbooks

- added experimental job template 'gate-{name}-chef-rake-integration' to the queue to start
  the building of integration layer tests for the openstack chef cookbooks
- this job has to stay in 'experimental' until all cookbooks include working
  and reliable rake tasks for integration testing and will be moved
  afterwards to 'check' and 'gate'
- modified regex to filter all chef-rake jobs depending on the branch

Change-Id: I17b07d86a0d8c502cba241c943bcbd8efccdc694
",git fetch https://review.opendev.org/openstack/project-config refs/changes/79/186379/3 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/chef-jobs.yaml', 'jenkins/jobs/macros.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",4,350ab1898dcb1607062c149dea3cb0d285204c3b,chef_job_groups, experimental: - 'gate-{name}-chef-rake-integration' - name: ^gate-.*-chef-rake.*$, - name: ^gate-.*-chef-rake$,48,1
openstack%2Fcompute-hyperv~stable%2Fkilo~I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c,openstack/compute-hyperv,stable/kilo,I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c,Hyper-V: Fix instance event handler,MERGED,2015-06-10 14:42:28.000000000,2015-06-10 15:15:00.000000000,2015-06-10 15:14:59.000000000,"[{'_account_id': 3}, {'_account_id': 8213}, {'_account_id': 8543}]","[{'number': 1, 'created': '2015-06-10 14:42:28.000000000', 'files': ['hyperv/tests/unit/test_eventhandler.py', 'hyperv/nova/eventhandler.py', 'hyperv/nova/vmutils.py', 'hyperv/tests/unit/test_vmutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/5249f17e28d879982c4b9bf83f08fa926f390d48', 'message': ""Hyper-V: Fix instance event handler\n\nThe listener currently used by the instance event handler records\nall WMI instance object changes, even though we only care about\npower state changes.\n\nFor this reason, we currently record the last emited power state\nchange in order to see whether the power state actually changed\nbefore emiting a new change.\n\nThis is problematic and unreliable. When the instance is created,\nit will be powered off. If anything changes, the current\nimplementation will emit a power off event, having no previous\nrecorded state. For this reason, the manager can consider that the\nthe instance was unexpectedly powered off, calling the stop\nAPI, which is highly undesirable.\n\nThis patch fixes the issue by constructing a WQL query used by the\nevent listener in order to catch events only in case the instance\nactually transitioned into one of the states that we're interested\nin.\n\nChange-Id: I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c\nCloses-Bug: #1463814\n(cherry picked from commit 490dfdd3167e27a38bb84299bb57350a11d846d4)\n""}]",0,190217,5249f17e28d879982c4b9bf83f08fa926f390d48,5,3,1,8213,,,0,"Hyper-V: Fix instance event handler

The listener currently used by the instance event handler records
all WMI instance object changes, even though we only care about
power state changes.

For this reason, we currently record the last emited power state
change in order to see whether the power state actually changed
before emiting a new change.

This is problematic and unreliable. When the instance is created,
it will be powered off. If anything changes, the current
implementation will emit a power off event, having no previous
recorded state. For this reason, the manager can consider that the
the instance was unexpectedly powered off, calling the stop
API, which is highly undesirable.

This patch fixes the issue by constructing a WQL query used by the
event listener in order to catch events only in case the instance
actually transitioned into one of the states that we're interested
in.

Change-Id: I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c
Closes-Bug: #1463814
(cherry picked from commit 490dfdd3167e27a38bb84299bb57350a11d846d4)
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/17/190217/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/tests/unit/test_eventhandler.py', 'hyperv/nova/eventhandler.py', 'hyperv/nova/vmutils.py', 'hyperv/tests/unit/test_vmutils.py']",4,5249f17e28d879982c4b9bf83f08fa926f390d48,," def test_get_event_wql_query(self): cls = self._vmutils._COMPUTER_SYSTEM_CLASS field = self._vmutils._VM_ENABLED_STATE_PROP timeframe = 10 filtered_states = [constants.HYPERV_VM_STATE_ENABLED, constants.HYPERV_VM_STATE_DISABLED] expected_checks = ' OR '.join( [""TargetInstance.%s = '%s'"" % (field, state) for state in filtered_states]) expected_query = ( ""SELECT %(field)s, TargetInstance "" ""FROM __InstanceModificationEvent "" ""WITHIN %(timeframe)s "" ""WHERE TargetInstance ISA '%(class)s' "" ""AND TargetInstance.%(field)s != "" ""PreviousInstance.%(field)s "" ""AND (%(checks)s)"" % {'class': cls, 'field': field, 'timeframe': timeframe, 'checks': expected_checks}) query = self._vmutils._get_event_wql_query( cls=cls, field=field, timeframe=timeframe, filtered_states=filtered_states) self.assertEqual(expected_query, query) def test_get_vm_power_state_change_listener(self): with mock.patch.object(self._vmutils, '_get_event_wql_query') as mock_get_query: listener = self._vmutils.get_vm_power_state_change_listener( mock.sentinel.timeframe, mock.sentinel.filtered_states) mock_get_query.assert_called_once_with( cls=self._vmutils._COMPUTER_SYSTEM_CLASS, field=self._vmutils._VM_ENABLED_STATE_PROP, timeframe=mock.sentinel.timeframe, filtered_states=mock.sentinel.filtered_states) watcher = self._vmutils._conn.Msvm_ComputerSystem.watch_for watcher.assert_called_once_with( raw_wql=mock_get_query.return_value, fields=[self._vmutils._VM_ENABLED_STATE_PROP]) self.assertEqual(watcher.return_value, listener)",,92,53
openstack%2Fneutron~feature%2Fqos~I2d35d0659bd3f06c570ba99e8b8a41b620253e75,openstack/neutron,feature/qos,I2d35d0659bd3f06c570ba99e8b8a41b620253e75,Change defaultbranch in .gitreview,MERGED,2015-06-09 09:56:43.000000000,2015-06-10 15:00:39.000000000,2015-06-10 10:47:39.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-09 09:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f353bb74f4ab7bd63e51ccb536bc9119aa57f69', 'message': 'Change defaultbranch in gitreview on the branch\n\nChange-Id: I2d35d0659bd3f06c570ba99e8b8a41b620253e75\n'}, {'number': 2, 'created': '2015-06-09 10:06:31.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d5ae8852a79eb4ba041122e65052abf8c196efb', 'message': 'Change defaultbranch in .gitreview\n\nThis is a branch-only change to make sure anybody\nworking on the branch will push to the right one.\n\nChange-Id: I2d35d0659bd3f06c570ba99e8b8a41b620253e75\n'}]",0,189627,4d5ae8852a79eb4ba041122e65052abf8c196efb,32,20,2,8788,,,0,"Change defaultbranch in .gitreview

This is a branch-only change to make sure anybody
working on the branch will push to the right one.

Change-Id: I2d35d0659bd3f06c570ba99e8b8a41b620253e75
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/189627/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,2f353bb74f4ab7bd63e51ccb536bc9119aa57f69,,defaultbranch=feature/qos,,1,0
openstack%2Fsahara~master~I8888f2c8969cfa6261351e44e6a6a35e986778d1,openstack/sahara,master,I8888f2c8969cfa6261351e44e6a6a35e986778d1,cleanup sahara docs in devref folder,ABANDONED,2015-05-29 18:14:49.000000000,2015-06-10 14:57:00.000000000,,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 12038}, {'_account_id': 13919}]","[{'number': 1, 'created': '2015-05-29 18:14:49.000000000', 'files': ['doc/source/devref/gerrit.rst', 'doc/source/devref/how_to_participate.rst', 'doc/source/devref/testing.rst', 'doc/source/devref/development.environment.rst', 'doc/source/devref/plugins.rst', 'doc/source/devref/plugin.spi.rst', 'doc/source/devref/launchpad.rst', 'doc/source/devref/quickstart.rst', 'doc/source/devref/log.guidelines.rst', 'doc/source/devref/adding_database_migrations.rst', 'doc/source/devref/edp.spi.rst', 'doc/source/devref/how_to_build_oozie.rst', 'doc/source/devref/devstack.rst', 'doc/source/devref/development.guidelines.rst', 'doc/source/devref/jenkins.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5832c64c0075a5ecf968eb1278dfa71d487359b4', 'message': 'cleanup sahara docs in devref folder\n\nde-capitalized sahara to comply w/ doc conventions\nchanged plugin to plug-in per doc conventions\nde-capitalized titles to comply w/ conventions\ndoc conventions can be found at below link\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I8888f2c8969cfa6261351e44e6a6a35e986778d1\n'}]",19,186865,5832c64c0075a5ecf968eb1278dfa71d487359b4,7,5,1,9382,,,0,"cleanup sahara docs in devref folder

de-capitalized sahara to comply w/ doc conventions
changed plugin to plug-in per doc conventions
de-capitalized titles to comply w/ conventions
doc conventions can be found at below link
https://wiki.openstack.org/wiki/Documentation/Conventions
Closes-Bug: #1448372

Change-Id: I8888f2c8969cfa6261351e44e6a6a35e986778d1
",git fetch https://review.opendev.org/openstack/sahara refs/changes/65/186865/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/gerrit.rst', 'doc/source/devref/how_to_participate.rst', 'doc/source/devref/testing.rst', 'doc/source/devref/development.environment.rst', 'doc/source/devref/plugins.rst', 'doc/source/devref/plugin.spi.rst', 'doc/source/devref/launchpad.rst', 'doc/source/devref/quickstart.rst', 'doc/source/devref/log.guidelines.rst', 'doc/source/devref/adding_database_migrations.rst', 'doc/source/devref/edp.spi.rst', 'doc/source/devref/how_to_build_oozie.rst', 'doc/source/devref/devstack.rst', 'doc/source/devref/development.guidelines.rst', 'doc/source/devref/jenkins.rst']",15,5832c64c0075a5ecf968eb1278dfa71d487359b4,devref_docs,"Continuous integration with JenkinsEach change made to the sahara core code is tested with unit and integration tests and style checks flake8.The result of those checks and unit tests are +1 or -1 to *Verify* column in a code review from *Jenkins* user. Integration tests check CRUD operations for image registry, templates and clusters.","Continuous Integration with JenkinsEach change made to Sahara core code is tested with unit and integration tests and style checks flake8.The result of those checks and Unit tests are +1 or -1 to *Verify* column in a code review from *Jenkins* user. Integration tests check CRUD operations for Image Registry, Templates and Clusters.",142,142
openstack%2Fsahara~master~I9704f82a1a0831195286a7c8de65e79f9e30e048,openstack/sahara,master,I9704f82a1a0831195286a7c8de65e79f9e30e048,made a number of changes to sahara docs,ABANDONED,2015-04-25 05:22:19.000000000,2015-06-10 14:56:44.000000000,,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9382}, {'_account_id': 9563}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 13953}, {'_account_id': 14920}]","[{'number': 1, 'created': '2015-04-25 05:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/826cc4eff33598bf1acd9409ca418d50d6548700', 'message': 'made a number of changes to features.rst\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 2, 'created': '2015-05-27 01:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e0ca2ca0b1434727b6091ad38b504aa7b310d9f2', 'message': 'made a number of changes to features.rst\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 3, 'created': '2015-05-27 15:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/565d6e69c028759d3f300d91c3a76ebb6b1b9e10', 'message': 'made a number of changes to features.rst\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 4, 'created': '2015-05-27 20:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3b66bcd6d9fa790b1ca31e98fe3fbacee25af35a', 'message': 'made a number of changes to features.rst\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 5, 'created': '2015-05-27 22:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/97c8cb8b856dce5f22ac240e1559d94af9b0558c', 'message': 'made a number of changes to sahara docs\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\ndecapitalized sahara to comply with doc conventions\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 6, 'created': '2015-05-28 18:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f746a1e73915a8d65015d0eed6c93c9e781ef751', 'message': 'made a number of changes to sahara docs\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\ndecapitalized sahara to comply with doc conventions\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 7, 'created': '2015-05-29 15:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/eac118a4636bafc1b45c7db278e5a26568d926ff', 'message': 'made a number of changes to sahara docs\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\ndecapitalized sahara to comply with doc conventions\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}, {'number': 8, 'created': '2015-06-03 16:50:35.000000000', 'files': ['doc/source/userdoc/mapr_plugin.rst', 'doc/source/userdoc/guest-requirements.rst', 'doc/source/userdoc/statuses.rst', 'doc/source/userdoc/registering_image.rst', 'doc/source/userdoc/diskimagebuilder.rst', 'doc/source/userdoc/cdh_plugin.rst', 'doc/source/userdoc/hdp_plugin.rst', 'doc/source/userdoc/plugins.rst', 'doc/source/userdoc/features.rst', 'doc/source/userdoc/spark_plugin.rst', 'doc/source/userdoc/vanilla_plugin.rst', 'doc/source/userdoc/edp.rst', 'doc/source/userdoc/overview.rst', 'doc/source/userdoc/advanced.configuration.guide.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2d232bb589aebb65d66410bab3abdee1f0d4b0f3', 'message': 'made a number of changes to sahara docs\n\ncorrected a number of things\n“distrbuted” should be distributed\n“availibility” should be availability\n“intance” should be instance\ndecapitalized sahara to comply with doc conventions\nchanged plugin to plug-in per doc conventions\nhttps://wiki.openstack.org/wiki/Documentation/Conventions\nCloses-Bug: #1448372\n\nChange-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048\n'}]",114,177523,2d232bb589aebb65d66410bab3abdee1f0d4b0f3,61,15,8,9382,,,0,"made a number of changes to sahara docs

corrected a number of things
“distrbuted” should be distributed
“availibility” should be availability
“intance” should be instance
decapitalized sahara to comply with doc conventions
changed plugin to plug-in per doc conventions
https://wiki.openstack.org/wiki/Documentation/Conventions
Closes-Bug: #1448372

Change-Id: I9704f82a1a0831195286a7c8de65e79f9e30e048
",git fetch https://review.opendev.org/openstack/sahara refs/changes/23/177523/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/userdoc/features.rst'],1,826cc4eff33598bf1acd9409ca418d50d6548700,saharadocs_,"This feature is supported by all plug-ins out of the box, and can be enabledFor an expanded discussion of configuring sahara to run in distributedavailability.volume instance locality functionality.","This feature is supported by all plugins out of the box, and can be enabledFor an expanded discussion of configuring sahara to run in distrbutedavailibility.volume intance locality functionality.",4,4
openstack%2Fopenstack-manuals~master~I2ad6c8cf7ce76fa42950e51f267224cd8142199c,openstack/openstack-manuals,master,I2ad6c8cf7ce76fa42950e51f267224cd8142199c,Instructions to resolve an openSUSE 13.2 dependency conflict,MERGED,2015-06-08 15:58:49.000000000,2015-06-10 14:56:12.000000000,2015-06-10 14:56:10.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7007}, {'_account_id': 9382}, {'_account_id': 9515}, {'_account_id': 10607}]","[{'number': 1, 'created': '2015-06-08 15:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7c7345c437fdfb21b0217d000c52bdbe2fb892ca', 'message': 'Instructions to resolve an openSUSE 13.2 dependency conflict\n\nAdds a note with instructions to respond to a pattern dependency\nconflict when a minimal server install is used.\n\nChange-Id: I2ad6c8cf7ce76fa42950e51f267224cd8142199c\nCloses-bug: #1462624\n'}, {'number': 2, 'created': '2015-06-08 16:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/46fdaf363e581f70588898c7be7d0d9bb3928605', 'message': 'Instructions to resolve an openSUSE 13.2 dependency conflict\n\nAdds a note with instructions to respond to a pattern dependency\nconflict when a minimal server install is used.\n\nModified: replaced the note with a simpler instruction to remove\nthe offending package in the Basic Environment section of the\nInstall Guide.\n\nChange-Id: I2ad6c8cf7ce76fa42950e51f267224cd8142199c\nCloses-bug: #1462624\n'}, {'number': 3, 'created': '2015-06-08 18:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d782b1a87ccb7ce344dc443ec98e7b0e7b8f435f', 'message': 'Instructions to resolve an openSUSE 13.2 dependency conflict\n\nAdds a note with instructions to respond to a pattern dependency\nconflict when a minimal server install is used.\n\nModified: replaced the note with a simpler instruction to remove\nthe offending package in the Basic Environment section of the\nInstall Guide.\n\nChange-Id: I2ad6c8cf7ce76fa42950e51f267224cd8142199c\nCloses-bug: #1462624\n'}, {'number': 4, 'created': '2015-06-08 18:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a80f2169ee800fc0d36564273a08712ad17b3cf4', 'message': 'Instructions to resolve an openSUSE 13.2 dependency conflict\n\nAdds a note with instructions to respond to a pattern dependency\nconflict when a minimal server install is used.\n\nModified: replaced the note with a simpler instruction to remove\nthe offending package in the Basic Environment section of the\nInstall Guide.\n\nChange-Id: I2ad6c8cf7ce76fa42950e51f267224cd8142199c\nCloses-bug: #1462624\nBackport: Kilo\n'}, {'number': 5, 'created': '2015-06-09 07:01:30.000000000', 'files': ['doc/install-guide/section_basics-packages.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e1beb211bd8ea8f1d6585ffc49f0979a66dad640', 'message': 'Instructions to resolve an openSUSE 13.2 dependency conflict\n\nAdds a note with instructions to respond to a pattern dependency\nconflict when a minimal server install is used.\n\nModified: replaced the note with a simpler instruction to remove\nthe offending package in the Basic Environment section of the\nInstall Guide.\n\nChange-Id: I2ad6c8cf7ce76fa42950e51f267224cd8142199c\nCloses-bug: #1462624\nBackport: Kilo\n'}]",5,189353,e1beb211bd8ea8f1d6585ffc49f0979a66dad640,28,8,5,13845,,,0,"Instructions to resolve an openSUSE 13.2 dependency conflict

Adds a note with instructions to respond to a pattern dependency
conflict when a minimal server install is used.

Modified: replaced the note with a simpler instruction to remove
the offending package in the Basic Environment section of the
Install Guide.

Change-Id: I2ad6c8cf7ce76fa42950e51f267224cd8142199c
Closes-bug: #1462624
Backport: Kilo
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/53/189353/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_keystone-install.xml'],1,7c7345c437fdfb21b0217d000c52bdbe2fb892ca,bug/1462624," <note os=""opensuse""> <para>The openSUSE distribution uses the concept of <i>patterns</i> to represent collections of packages. If you selected 'Minimal Server Selection (Text Mode)' during initial installation, you may be presented with a dependency conflict when you attempt to install the openstack packages. The proper response is <literal>Solution 3: deinstallation of patterns-openSUSE-minimal_base-conflicts-20141007-5.1x86_64</literal>, which will allow the openstack package installation to proceed. </para> </note>",,9,0
openstack%2Ftempest~master~I2c3abf9fd3eefccb6dbbe8d3a7865a1c4966c4dd,openstack/tempest,master,I2c3abf9fd3eefccb6dbbe8d3a7865a1c4966c4dd,Fix spell error in configuration.rst,MERGED,2015-06-10 04:59:18.000000000,2015-06-10 14:44:04.000000000,2015-06-10 09:14:06.000000000,"[{'_account_id': 3}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-10 04:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3d7e9b67ebaedf4a167fad9d59ae43292aadcaa1', 'message': ""Fix spell in configuration.rst\n\nIt should be 'location of your accounts.yaml', rather than\n'location of you accounts.yaml'.\n\nChange-Id: I2c3abf9fd3eefccb6dbbe8d3a7865a1c4966c4dd\n""}, {'number': 2, 'created': '2015-06-10 05:00:52.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/aa4aa69740d8ce3b1bc3d1afe856c2255d59f2e6', 'message': ""Fix spell error in configuration.rst\n\nIt should be 'location of your accounts.yaml', rather than\n'location of you accounts.yaml'.\n\nChange-Id: I2c3abf9fd3eefccb6dbbe8d3a7865a1c4966c4dd\n""}]",0,190022,aa4aa69740d8ce3b1bc3d1afe856c2255d59f2e6,10,4,2,16165,,,0,"Fix spell error in configuration.rst

It should be 'location of your accounts.yaml', rather than
'location of you accounts.yaml'.

Change-Id: I2c3abf9fd3eefccb6dbbe8d3a7865a1c4966c4dd
",git fetch https://review.opendev.org/openstack/tempest refs/changes/22/190022/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,3d7e9b67ebaedf4a167fad9d59ae43292aadcaa1,fix-doc-configuration-spell-error, #. Provide tempest with the location of your accounts.yaml file with the, #. Provide tempest with the location of you accounts.yaml file with the,1,1
openstack%2Fdesignate~master~I916e80aaaf0859da6e439de141618735866cb7db,openstack/designate,master,I916e80aaaf0859da6e439de141618735866cb7db,Sync with oslo-incubator 61f4461f91,MERGED,2015-06-07 14:48:03.000000000,2015-06-10 14:43:57.000000000,2015-06-10 14:43:54.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 4894}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-07 14:48:03.000000000', 'files': ['designate/openstack/common/threadgroup.py', 'designate/openstack/common/report/generators/version.py', 'designate/openstack/common/eventlet_backdoor.py', 'designate/openstack/common/loopingcall.py', 'designate/openstack/common/report/guru_meditation_report.py', 'designate/openstack/common/sslutils.py', 'designate/openstack/common/service.py', 'designate/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/bbaf8b3875c8ee1075a7b2924d031700e4fd7099', 'message': 'Sync with oslo-incubator 61f4461f91\n\nChange-Id: I916e80aaaf0859da6e439de141618735866cb7db\n'}]",0,189136,bbaf8b3875c8ee1075a7b2924d031700e4fd7099,10,6,1,741,,,0,"Sync with oslo-incubator 61f4461f91

Change-Id: I916e80aaaf0859da6e439de141618735866cb7db
",git fetch https://review.opendev.org/openstack/designate refs/changes/36/189136/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/openstack/common/threadgroup.py', 'designate/openstack/common/report/generators/version.py', 'designate/openstack/common/eventlet_backdoor.py', 'designate/openstack/common/loopingcall.py', 'designate/openstack/common/report/guru_meditation_report.py', 'designate/openstack/common/sslutils.py', 'designate/openstack/common/service.py', 'designate/openstack/common/fileutils.py']",8,bbaf8b3875c8ee1075a7b2924d031700e4fd7099,,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import contextlib import errno import logging import os import stat import tempfile from oslo_utils import excutils LOG = logging.getLogger(__name__) _FILE_CACHE = {} DEFAULT_MODE = stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO def ensure_tree(path, mode=DEFAULT_MODE): """"""Create a directory (and any ancestor directories required) :param path: Directory to create :param mode: Directory creation permissions """""" try: os.makedirs(path, mode) except OSError as exc: if exc.errno == errno.EEXIST: if not os.path.isdir(path): raise else: raise def read_cached_file(filename, force_reload=False): """"""Read from a file if it has been modified. :param force_reload: Whether to reload the file. :returns: A tuple with a boolean specifying if the data is fresh or not. """""" global _FILE_CACHE if force_reload: delete_cached_file(filename) reloaded = False mtime = os.path.getmtime(filename) cache_info = _FILE_CACHE.setdefault(filename, {}) if not cache_info or mtime > cache_info.get('mtime', 0): LOG.debug(""Reloading cached file %s"" % filename) with open(filename) as fap: cache_info['data'] = fap.read() cache_info['mtime'] = mtime reloaded = True return (reloaded, cache_info['data']) def delete_cached_file(filename): """"""Delete cached file if present. :param filename: filename to delete """""" global _FILE_CACHE if filename in _FILE_CACHE: del _FILE_CACHE[filename] def delete_if_exists(path, remove=os.unlink): """"""Delete a file, but ignore file not found error. :param path: File to delete :param remove: Optional function to remove passed path """""" try: remove(path) except OSError as e: if e.errno != errno.ENOENT: raise @contextlib.contextmanager def remove_path_on_error(path, remove=delete_if_exists): """"""Protect code that wants to operate on PATH atomically. Any exception will cause PATH to be removed. :param path: File to work with :param remove: Optional function to remove passed path """""" try: yield except Exception: with excutils.save_and_reraise_exception(): remove(path) def file_open(*args, **kwargs): """"""Open file see built-in open() documentation for more details Note: The reason this is kept in a separate module is to easily be able to provide a stub module that doesn't alter system state at all (for unit tests) """""" return open(*args, **kwargs) def write_to_tempfile(content, path=None, suffix='', prefix='tmp'): """"""Create temporary file or use existing file. This util is needed for creating temporary file with specified content, suffix and prefix. If path is not None, it will be used for writing content. If the path doesn't exist it'll be created. :param content: content for temporary file. :param path: same as parameter 'dir' for mkstemp :param suffix: same as parameter 'suffix' for mkstemp :param prefix: same as parameter 'prefix' for mkstemp For example: it can be used in database tests for creating configuration files. """""" if path: ensure_tree(path) (fd, path) = tempfile.mkstemp(suffix=suffix, dir=path, prefix=prefix) try: os.write(fd, content) finally: os.close(fd) return path ",53,206
openstack%2Fmanila~master~I979e7f5c0101353cb9c1819bde0e5051e2ce90c7,openstack/manila,master,I979e7f5c0101353cb9c1819bde0e5051e2ce90c7,Make required function arguments explicit,MERGED,2015-06-08 13:37:17.000000000,2015-06-10 14:42:34.000000000,2015-06-10 14:42:28.000000000,"[{'_account_id': 3}, {'_account_id': 7102}, {'_account_id': 7872}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 15100}]","[{'number': 1, 'created': '2015-06-08 13:37:17.000000000', 'files': ['manila/share/drivers/generic.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/63d7c0186119d0e82a4b76f5f9079729269e5c39', 'message': 'Make required function arguments explicit\n\nInstead of retrieving a value from `*args` as `*args[0]`\nunconditionally, add the required argument (`context`) as a standard\nnamed argument to the function prototype.\n\nChange-Id: I979e7f5c0101353cb9c1819bde0e5051e2ce90c7\n'}]",0,189297,63d7c0186119d0e82a4b76f5f9079729269e5c39,21,8,1,13777,,,0,"Make required function arguments explicit

Instead of retrieving a value from `*args` as `*args[0]`
unconditionally, add the required argument (`context`) as a standard
named argument to the function prototype.

Change-Id: I979e7f5c0101353cb9c1819bde0e5051e2ce90c7
",git fetch https://review.opendev.org/openstack/manila refs/changes/97/189297/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/generic.py'],1,63d7c0186119d0e82a4b76f5f9079729269e5c39,explicit-arguments," def wrap(self, context, *args, **kwargs): return f(self, context, *args, **kwargs)"," def wrap(self, *args, **kwargs): context = args[0] return f(self, *args, **kwargs)",2,3
openstack%2Fcompute-hyperv~master~I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c,openstack/compute-hyperv,master,I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c,Hyper-V: Fix instance event handler,MERGED,2015-06-10 12:42:59.000000000,2015-06-10 14:42:28.000000000,2015-06-10 14:30:19.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2015-06-10 12:42:59.000000000', 'files': ['hyperv/tests/unit/test_eventhandler.py', 'hyperv/nova/eventhandler.py', 'hyperv/nova/vmutils.py', 'hyperv/tests/unit/test_vmutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/490dfdd3167e27a38bb84299bb57350a11d846d4', 'message': ""Hyper-V: Fix instance event handler\n\nThe listener currently used by the instance event handler records\nall WMI instance object changes, even though we only care about\npower state changes.\n\nFor this reason, we currently record the last emited power state\nchange in order to see whether the power state actually changed\nbefore emiting a new change.\n\nThis is problematic and unreliable. When the instance is created,\nit will be powered off. If anything changes, the current\nimplementation will emit a power off event, having no previous\nrecorded state. For this reason, the manager can consider that the\nthe instance was unexpectedly powered off, calling the stop\nAPI, which is highly undesirable.\n\nThis patch fixes the issue by constructing a WQL query used by the\nevent listener in order to catch events only in case the instance\nactually transitioned into one of the states that we're interested\nin.\n\nChange-Id: I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c\nCloses-Bug: #1463814\n""}]",0,190158,490dfdd3167e27a38bb84299bb57350a11d846d4,7,2,1,8543,,,0,"Hyper-V: Fix instance event handler

The listener currently used by the instance event handler records
all WMI instance object changes, even though we only care about
power state changes.

For this reason, we currently record the last emited power state
change in order to see whether the power state actually changed
before emiting a new change.

This is problematic and unreliable. When the instance is created,
it will be powered off. If anything changes, the current
implementation will emit a power off event, having no previous
recorded state. For this reason, the manager can consider that the
the instance was unexpectedly powered off, calling the stop
API, which is highly undesirable.

This patch fixes the issue by constructing a WQL query used by the
event listener in order to catch events only in case the instance
actually transitioned into one of the states that we're interested
in.

Change-Id: I7efe33d8f4d8df44a09ac3c0ac3e29c2947fe67c
Closes-Bug: #1463814
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/58/190158/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/tests/unit/test_eventhandler.py', 'hyperv/nova/eventhandler.py', 'hyperv/nova/vmutils.py', 'hyperv/tests/unit/test_vmutils.py']",4,490dfdd3167e27a38bb84299bb57350a11d846d4,bug/1463814," def test_get_event_wql_query(self): cls = self._vmutils._COMPUTER_SYSTEM_CLASS field = self._vmutils._VM_ENABLED_STATE_PROP timeframe = 10 filtered_states = [constants.HYPERV_VM_STATE_ENABLED, constants.HYPERV_VM_STATE_DISABLED] expected_checks = ' OR '.join( [""TargetInstance.%s = '%s'"" % (field, state) for state in filtered_states]) expected_query = ( ""SELECT %(field)s, TargetInstance "" ""FROM __InstanceModificationEvent "" ""WITHIN %(timeframe)s "" ""WHERE TargetInstance ISA '%(class)s' "" ""AND TargetInstance.%(field)s != "" ""PreviousInstance.%(field)s "" ""AND (%(checks)s)"" % {'class': cls, 'field': field, 'timeframe': timeframe, 'checks': expected_checks}) query = self._vmutils._get_event_wql_query( cls=cls, field=field, timeframe=timeframe, filtered_states=filtered_states) self.assertEqual(expected_query, query) def test_get_vm_power_state_change_listener(self): with mock.patch.object(self._vmutils, '_get_event_wql_query') as mock_get_query: listener = self._vmutils.get_vm_power_state_change_listener( mock.sentinel.timeframe, mock.sentinel.filtered_states) mock_get_query.assert_called_once_with( cls=self._vmutils._COMPUTER_SYSTEM_CLASS, field=self._vmutils._VM_ENABLED_STATE_PROP, timeframe=mock.sentinel.timeframe, filtered_states=mock.sentinel.filtered_states) watcher = self._vmutils._conn.Msvm_ComputerSystem.watch_for watcher.assert_called_once_with( raw_wql=mock_get_query.return_value, fields=[self._vmutils._VM_ENABLED_STATE_PROP]) self.assertEqual(watcher.return_value, listener)",,92,53
openstack%2Fcompute-hyperv~stable%2Fkilo~I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41,openstack/compute-hyperv,stable/kilo,I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41,Fix QoS issues caused by unsupported OS versions,MERGED,2015-06-10 13:03:15.000000000,2015-06-10 14:38:27.000000000,2015-06-10 14:38:25.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2015-06-10 13:03:15.000000000', 'files': ['hyperv/nova/vmops.py', 'hyperv/nova/vmutilsv2.py', 'hyperv/tests/unit/test_vmutilsv2.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/36d6cf9cc20232e854c9794de735c46e3d67c2f5', 'message': 'Fix QoS issues caused by unsupported OS versions\n\nDisk QoS is not available on versions prior to WS 2012 R2.\n\nBecause of this and the fact that the driver attempts to set IOPS\nlimits even if those are not specified, spawning instances currently\nfails when using previous HyperV versions.\n\nThis patch fixes the issues by skipping setting QoS specs when\nthis feature is not supported, logging a warning.\n\nCloses-Bug: #1463317\n\nChange-Id: I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41\n(cherry picked from commit b97666aa6d897280a6a31d5ff6fd8d9eab3b7a4d)\n'}]",0,190177,36d6cf9cc20232e854c9794de735c46e3d67c2f5,5,2,1,8543,,,0,"Fix QoS issues caused by unsupported OS versions

Disk QoS is not available on versions prior to WS 2012 R2.

Because of this and the fact that the driver attempts to set IOPS
limits even if those are not specified, spawning instances currently
fails when using previous HyperV versions.

This patch fixes the issues by skipping setting QoS specs when
this feature is not supported, logging a warning.

Closes-Bug: #1463317

Change-Id: I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41
(cherry picked from commit b97666aa6d897280a6a31d5ff6fd8d9eab3b7a4d)
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/77/190177/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/vmops.py', 'hyperv/nova/vmutilsv2.py', 'hyperv/tests/unit/test_vmutilsv2.py']",3,36d6cf9cc20232e854c9794de735c46e3d67c2f5,," def _test_set_disk_qos_specs(self, mock_modify_virt_resource, mock_get_disk_resource, qos_available=True): mock_disk = mock.Mock() if not qos_available: type(mock_disk).IOPSLimit = mock.PropertyMock( side_effect=AttributeError) mock_get_disk_resource.return_value = mock_disk if qos_available: self.assertEqual(mock.sentinel.max_iops, mock_disk.IOPSLimit) self.assertEqual(mock.sentinel.min_iops, mock_disk.IOPSReservation) mock_modify_virt_resource.assert_called_once_with(mock_disk, None) else: self.assertFalse(mock_modify_virt_resource.called) def test_set_disk_qos_specs(self): self._test_set_disk_qos_specs() def test_set_disk_qos_specs_unsupported_feature(self): self._test_set_disk_qos_specs(qos_available=False)"," def test_set_disk_qos_specs(self, mock_modify_virt_resource, mock_get_disk_resource): mock_disk = mock_get_disk_resource.return_value self.assertEqual(mock.sentinel.max_iops, mock_disk.IOPSLimit) self.assertEqual(mock.sentinel.min_iops, mock_disk.IOPSReservation) mock_modify_virt_resource.assert_called_once_with(mock_disk, None)",34,14
openstack%2Fcompute-hyperv~stable%2Fkilo~Ia99576589af6049ee07337c631ed7d5d6cf602d9,openstack/compute-hyperv,stable/kilo,Ia99576589af6049ee07337c631ed7d5d6cf602d9,Hyper-V: Fix missing WMI namespace issue on Windows 2008 R2,MERGED,2015-06-10 13:03:41.000000000,2015-06-10 14:37:13.000000000,2015-06-10 14:37:12.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2015-06-10 13:03:41.000000000', 'files': ['hyperv/nova/pathutils.py', 'hyperv/tests/unit/test_base.py', 'hyperv/tests/unit/test_pathutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/1da566861adcdb335acc8ca6887a99bfc63c51f2', 'message': 'Hyper-V: Fix missing WMI namespace issue on Windows 2008 R2\n\nThe Hyper-V driver uses the Microsoft\\Windows\\SMB WMI namespace\nin order to handle SMB shares. The issue is that this namespace is\nnot available on Windows versions prior to Windows Server 2012.\n\nFor this reason, the Hyper-V driver fails to initialize on Windows\nServer 2008 R2.\n\nThis patch fixes the issue by properly handling the PathUtils\ninitialization.\n\nCloses-Bug: #1463044\nChange-Id: Ia99576589af6049ee07337c631ed7d5d6cf602d9\n(cherry picked from commit 1de39b99ac144698a1ea0e01bd17d8fc6c78298d)\n'}]",0,190178,1da566861adcdb335acc8ca6887a99bfc63c51f2,5,2,1,8543,,,0,"Hyper-V: Fix missing WMI namespace issue on Windows 2008 R2

The Hyper-V driver uses the Microsoft\Windows\SMB WMI namespace
in order to handle SMB shares. The issue is that this namespace is
not available on Windows versions prior to Windows Server 2012.

For this reason, the Hyper-V driver fails to initialize on Windows
Server 2008 R2.

This patch fixes the issue by properly handling the PathUtils
initialization.

Closes-Bug: #1463044
Change-Id: Ia99576589af6049ee07337c631ed7d5d6cf602d9
(cherry picked from commit 1de39b99ac144698a1ea0e01bd17d8fc6c78298d)
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/78/190178/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/pathutils.py', 'hyperv/tests/unit/test_base.py', 'hyperv/tests/unit/test_pathutils.py']",3,1da566861adcdb335acc8ca6887a99bfc63c51f2,," def _test_smb_conn(self, smb_available=True): self._mock_wmi.x_wmi = Exception self._mock_wmi.WMI.side_effect = None if smb_available else Exception self._pathutils._set_smb_conn() if smb_available: expected_conn = self._mock_wmi.WMI.return_value self.assertEqual(expected_conn, self._pathutils._smb_conn) else: self.assertRaises(vmutils.HyperVException, getattr, self._pathutils, '_smb_conn') def test_smb_conn_available(self): self._test_smb_conn() def test_smb_conn_unavailable(self): self._test_smb_conn(smb_available=False) ",,41,2
openstack%2Fopenstack-ansible~kilo~I9ab35cf4438a369563f8c08870c1acfd0cc394b0,openstack/openstack-ansible,kilo,I9ab35cf4438a369563f8c08870c1acfd0cc394b0,Enable udev for lvm in cinder-volume container,MERGED,2015-06-10 06:53:08.000000000,2015-06-10 14:26:23.000000000,2015-06-10 14:26:21.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-10 06:53:08.000000000', 'files': ['playbooks/os-cinder-install.yml', 'playbooks/roles/os_cinder/templates/lvm.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e741ea00abc83f086ec2b1180d3736d0448c56d7', 'message': ""Enable udev for lvm in cinder-volume container\n\nThe current configuration of LVM for cinder-volume has udev_sync=0.\nThis means that udev is not creating the devices that appear in /dev.\nThe device files created reference specific device numbers, and these\npersist between reboots. When the host is rebooted there is no\nguarantee that device numbers allocated to the logical volumes will\nmatch those defined in the device files. This can be observed by\ncomparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.\n\nLVM's use of udev was disabled in an attempt to protect the host from\nthe potential that uevents generated would be processed by all\ncontainers on the host. In practise this should not be an issue because\nthere are not other containers running on a cinder host.\n\nThis commit adjusts the lvm.conf file created so that udev is used. It\nalso adds a mount entry to create a devtmpfs on /dev. Finally\n'udevadm trigger' is run to add the devices under /dev/mapper.\nCloses-Bug: #1436999\nChange-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0\n(cherry picked from commit 6ba292a295ab2e7effeefd053802e6afadd0ab9e)\n""}]",0,190041,e741ea00abc83f086ec2b1180d3736d0448c56d7,7,4,1,7219,,,0,"Enable udev for lvm in cinder-volume container

The current configuration of LVM for cinder-volume has udev_sync=0.
This means that udev is not creating the devices that appear in /dev.
The device files created reference specific device numbers, and these
persist between reboots. When the host is rebooted there is no
guarantee that device numbers allocated to the logical volumes will
match those defined in the device files. This can be observed by
comparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.

LVM's use of udev was disabled in an attempt to protect the host from
the potential that uevents generated would be processed by all
containers on the host. In practise this should not be an issue because
there are not other containers running on a cinder host.

This commit adjusts the lvm.conf file created so that udev is used. It
also adds a mount entry to create a devtmpfs on /dev. Finally
'udevadm trigger' is run to add the devices under /dev/mapper.
Closes-Bug: #1436999
Change-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0
(cherry picked from commit 6ba292a295ab2e7effeefd053802e6afadd0ab9e)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/41/190041/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/os-cinder-install.yml', 'playbooks/roles/os_cinder/templates/lvm.conf.j2']",2,e741ea00abc83f086ec2b1180d3736d0448c56d7,, obtain_device_list_from_udev = 1 udev_sync = 1 udev_rules = 1,"{% if is_metal == false or is_metal == ""False"" %} {% set use_udev = 0 %} {% else %} {% set use_udev = 1 %} {% endif %} obtain_device_list_from_udev = {{ use_udev }} udev_sync = {{ use_udev }} udev_rules = {{ use_udev }}",22,10
openstack%2Fmanila~master~I11e2b90c23c9b820b85465452dce56dccefeea35,openstack/manila,master,I11e2b90c23c9b820b85465452dce56dccefeea35,Use oslo.utils to get host IP address,MERGED,2015-06-09 11:13:32.000000000,2015-06-10 14:16:55.000000000,2015-06-10 14:16:54.000000000,"[{'_account_id': 3}, {'_account_id': 7102}, {'_account_id': 7491}, {'_account_id': 7872}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}]","[{'number': 1, 'created': '2015-06-09 11:13:32.000000000', 'files': ['manila/common/config.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/605ce734d602a81936f5b815fa83a9b412923a5e', 'message': 'Use oslo.utils to get host IP address\n\nChange-Id: I11e2b90c23c9b820b85465452dce56dccefeea35\n'}]",0,189658,605ce734d602a81936f5b815fa83a9b412923a5e,18,8,1,7491,,,0,"Use oslo.utils to get host IP address

Change-Id: I11e2b90c23c9b820b85465452dce56dccefeea35
",git fetch https://review.opendev.org/openstack/manila refs/changes/58/189658/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/common/config.py'],1,605ce734d602a81936f5b815fa83a9b412923a5e,use-utils,"from oslo_utils import netutils default=netutils.get_my_ipv4(),","def _get_my_ip(): """"""Returns the actual ip of the local machine. This code figures out what source address would be used if some traffic were to be sent out to some well known address on the Internet. In this case, a Google DNS server is used, but the specific address does not matter much. No traffic is actually sent. """""" try: csock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) csock.connect(('8.8.8.8', 80)) (addr, port) = csock.getsockname() csock.close() return addr except socket.error: return ""127.0.0.1"" default=_get_my_ip(),",2,19
openstack%2Fmanila~master~I862b31acb710c31ce55cd90a55e4fea41f046c50,openstack/manila,master,I862b31acb710c31ce55cd90a55e4fea41f046c50,Remove deprecated WritableLogger,MERGED,2015-06-09 07:00:30.000000000,2015-06-10 14:12:14.000000000,2015-06-10 14:12:12.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 11904}]","[{'number': 1, 'created': '2015-06-09 07:00:30.000000000', 'files': ['manila/wsgi.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/a0b9de9b012d19e09fed834f31be099ad89014d9', 'message': 'Remove deprecated WritableLogger\n\nWritableLogger from oslo.log is deprecated and with eventlet >= 0.17.2\nwe can directly pass the logger instance.\n\nChange-Id: I862b31acb710c31ce55cd90a55e4fea41f046c50\nCloses-Bug: #1440773\n'}]",0,189575,a0b9de9b012d19e09fed834f31be099ad89014d9,15,6,1,7102,,,0,"Remove deprecated WritableLogger

WritableLogger from oslo.log is deprecated and with eventlet >= 0.17.2
we can directly pass the logger instance.

Change-Id: I862b31acb710c31ce55cd90a55e4fea41f046c50
Closes-Bug: #1440773
",git fetch https://review.opendev.org/openstack/manila refs/changes/75/189575/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/wsgi.py'],1,a0b9de9b012d19e09fed834f31be099ad89014d9,bug/1440773, log=self._logger),from oslo_log import loggers self._wsgi_logger = loggers.WritableLogger(self._logger) log=self._wsgi_logger),1,3
openstack%2Ffuel-specs~master~I3102a579fb7c9aebb69fb852dfe4192d089b754f,openstack/fuel-specs,master,I3102a579fb7c9aebb69fb852dfe4192d089b754f,Make Docker resource available by default,MERGED,2015-01-30 14:47:01.000000000,2015-06-10 14:11:32.000000000,2015-06-10 14:11:31.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6577}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 7109}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 9542}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 11090}]","[{'number': 1, 'created': '2015-01-30 14:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d18edf99dd64f15999c0566812544630f1415844', 'message': 'Make Docker resource available by default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 2, 'created': '2015-02-11 09:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c1158050ff10a8dd6c1cf0db0e49dadff2414353', 'message': 'Make Docker resource available by default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 3, 'created': '2015-03-05 11:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/21eec9ad7b7e37802792c270f072667b1379d28a', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications \n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 4, 'created': '2015-03-06 12:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6daca7fa43aa395797e537932b56818b9b0b6152', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications \nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 5, 'created': '2015-03-30 10:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/26e8d906b23d319415e15fff620ed84ffe20bd52', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications \nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 6, 'created': '2015-04-28 15:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/aea0b13c6b1ce7d303ad033ffe93baaffafb9b00', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications \nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 7, 'created': '2015-05-06 08:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/95ff853a971fc5eb2bf1810a2269c0200774bba7', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications\nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 8, 'created': '2015-05-12 07:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/68e609a97e245fb0bbbc641ffabe6e1778b58df1', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications\nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 9, 'created': '2015-05-22 17:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/89de52d4d17a8b4451035227436767b12d6fd85c', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications\nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 10, 'created': '2015-06-10 07:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/bc2767ead8c5bc74cbb76b7188f8b2628b900849', 'message': 'Make Docker resource available by default\n\nRelated blueprint murano-docker-based-applications\nImplements blueprint heat-docker-resource-by-default\n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}, {'number': 11, 'created': '2015-06-10 08:39:20.000000000', 'files': ['specs/6.1/docker-default-available-resource.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/5508b7326f3479e04d0051bcd87ac42e6b205510', 'message': 'Make Docker resource available by default\n\nRelated blueprint https://blueprints.launchpad.net/mos/+spec/murano-docker-based-applications\nImplements blueprint https://blueprints.launchpad.net/mos/+spec/heat-docker-resource-by-default \n\nChange-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f\n'}]",13,151655,5508b7326f3479e04d0051bcd87ac42e6b205510,54,18,11,6577,,,0,"Make Docker resource available by default

Related blueprint https://blueprints.launchpad.net/mos/+spec/murano-docker-based-applications
Implements blueprint https://blueprints.launchpad.net/mos/+spec/heat-docker-resource-by-default 

Change-Id: I3102a579fb7c9aebb69fb852dfe4192d089b754f
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/55/151655/11 && git format-patch -1 --stdout FETCH_HEAD,['specs/6.1/docker-default-available-resource.rst'],1,d18edf99dd64f15999c0566812544630f1415844,151655,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Enable Heat docker resource by default ========================================== https://blueprints.launchpad.net/mos/+spec/murano-docker-based-applications Docker resource is disabled by default for Heat, current Blueprint needs to enable this resource for using it by Murano without additional deployment workarounds. Problem description =================== MOX 2.3 already contains a bunch of Murano Docker-based applications. These apps are being forward-ported to MOX 3.0. At this moment these applications are not available in MOS. To avoid further differences between MOS and MOX, we're going to add Docker-based apps to MOS 6.1. Proposed change =============== Currently docker resource is palced in Heat contrib directory and can not be used without installation and restarting Heat services. These changes adds ability to install docker resource on deployment step, so it makes docker resource available for Heat on first launch. Alternatives ------------ None Data model impact ----------------- It does not require any changes in Data Base. REST API impact --------------- No API changes. Upgrade impact -------------- Several new packages should be installed (heat_docker and docker requirements) Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- User should see available docker resource in output of command: heat resource-list Performance Impact ------------------ None Other deployer impact --------------------- Requires installation of addtional packages and small changes in manifests, which need to configure the right path to docker files. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: skraynev@mirantis.com Other contributors: iyozhikov@mirantis.com Work Items ---------- - Build packages for docker requirements. - Build package for Heat docker resource. - Update fuel manifests to allow install packages above. Dependencies ============ None Testing ======= Enough manual testing, that current resource is available. Documentation Impact ==================== Changes about new added resource. References ========== 1. https://blueprints.launchpad.net/mos/+spec/murano-docker-based-applications ",,124,0
openstack%2Fglance_store~master~I5a065c0778436a12db90ac3b929fa840f3e86665,openstack/glance_store,master,I5a065c0778436a12db90ac3b929fa840f3e86665,Use six.moves to fix imports on Python 3,MERGED,2015-05-20 19:41:41.000000000,2015-06-10 14:11:29.000000000,2015-06-10 14:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 9107}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-20 19:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/46c819d2b4f1334759f7d08d839f8ccede2f5cc8', 'message': 'Use six.moves to fix imports on Python 3\n\n* Use six.moves to get builtins, configparser, http_client and urllib\n  modules.\n* Replace StringIO.StringIO with six.StringIO.\n* Replace reload(mod) with moves.reload_module(mod)\n\nChange-Id: I5a065c0778436a12db90ac3b929fa840f3e86665\n'}, {'number': 2, 'created': '2015-05-28 09:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/f518eff6cdde369e2c0a043818b32a82da63549c', 'message': 'Use six.moves to fix imports on Python 3\n\n* Use six.moves to get builtins, configparser, http_client\n  and urllib modules\n* Replace StringIO.StringIO with six.StringIO\n* Replace reload(mod) with moves.reload_module(mod)\n\nPatch generated by the six_moves and urllib operations of the sixer\ntool:\nhttps://pypi.python.org/pypi/sixer\n\nManual changes:\n\n* test_vmware_store: add _mock_http_connection() helper method to\n  factorize code mocking http_client.HTTPConnection\n* Reformat some lines to respect the constraint of 80 columns\n* Replace reload() with imp.reload_module()\n* Replace httplib with six.moves.http_client in mock.patch()\n\nChange-Id: I5a065c0778436a12db90ac3b929fa840f3e86665\n'}, {'number': 3, 'created': '2015-05-28 12:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance_store/commit/7506c49f599a26aae3e15ea73a9b5b16126b9d79', 'message': 'Use six.moves to fix imports on Python 3\n\n* Use six.moves to get builtins, configparser, http_client\n  and urllib modules\n* Replace StringIO.StringIO with six.StringIO\n* Replace reload(mod) with moves.reload_module(mod)\n\nPatch generated by the six_moves and urllib operations of the sixer\ntool:\nhttps://pypi.python.org/pypi/sixer\n\nManual changes:\n\n* test_vmware_store: add _mock_http_connection() helper method to\n  factorize code mocking http_client.HTTPConnection\n* Reformat some lines to respect the constraint of 80 columns\n* Replace reload() with imp.reload_module()\n* Replace httplib with six.moves.http_client in mock.patch()\n\nChange-Id: I5a065c0778436a12db90ac3b929fa840f3e86665\n'}, {'number': 4, 'created': '2015-06-10 09:33:06.000000000', 'files': ['tests/unit/test_filesystem_store.py', 'glance_store/location.py', 'tests/unit/test_vmware_store.py', 'glance_store/_drivers/s3.py', 'tests/unit/test_s3_store.py', 'glance_store/_drivers/vmware_datastore.py', 'glance_store/common/auth.py', 'glance_store/_drivers/rbd.py', 'glance_store/_drivers/swift/utils.py', 'glance_store/_drivers/swift/store.py', 'glance_store/exceptions.py', 'glance_store/_drivers/gridfs.py', 'glance_store/tests/utils.py', 'tests/unit/test_swift_store.py', 'glance_store/_drivers/filesystem.py', 'tests/unit/test_http_store.py', 'glance_store/_drivers/http.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/65b9489e19ce6c9bf958db471dacf307820050f2', 'message': 'Use six.moves to fix imports on Python 3\n\n* Use six.moves to get builtins, configparser, http_client\n  and urllib modules\n* Replace StringIO.StringIO with six.StringIO\n* Replace reload(mod) with moves.reload_module(mod)\n\nPatch generated by the six_moves, stringio and urllib operations of the\nsixer tool version 0.4:\nhttps://pypi.python.org/pypi/sixer\n\nManual changes:\n\n* test_vmware_store: add _mock_http_connection() helper method to\n  factorize code mocking http_client.HTTPConnection\n* Reformat some lines to respect the constraint of 80 columns\n* Replace reload() with imp.reload_module()\n* Replace httplib with six.moves.http_client in mock.patch()\n\nChange-Id: I5a065c0778436a12db90ac3b929fa840f3e86665\n'}]",10,184600,65b9489e19ce6c9bf958db471dacf307820050f2,24,5,4,9107,,,0,"Use six.moves to fix imports on Python 3

* Use six.moves to get builtins, configparser, http_client
  and urllib modules
* Replace StringIO.StringIO with six.StringIO
* Replace reload(mod) with moves.reload_module(mod)

Patch generated by the six_moves, stringio and urllib operations of the
sixer tool version 0.4:
https://pypi.python.org/pypi/sixer

Manual changes:

* test_vmware_store: add _mock_http_connection() helper method to
  factorize code mocking http_client.HTTPConnection
* Reformat some lines to respect the constraint of 80 columns
* Replace reload() with imp.reload_module()
* Replace httplib with six.moves.http_client in mock.patch()

Change-Id: I5a065c0778436a12db90ac3b929fa840f3e86665
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/00/184600/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_filesystem_store.py', 'glance_store/location.py', 'tests/unit/test_vmware_store.py', 'glance_store/_drivers/s3.py', 'glance_store/_drivers/vmware_datastore.py', 'glance_store/_drivers/swift/utils.py', 'glance_store/_drivers/swift/store.py', 'glance_store/_drivers/gridfs.py', 'glance_store/tests/utils.py', 'tests/unit/test_swift_store.py', 'glance_store/_drivers/filesystem.py', 'tests/unit/test_http_store.py', 'glance_store/_drivers/http.py']",13,46c819d2b4f1334759f7d08d839f8ccede2f5cc8,py3,"from six.moves import http_client from six.moves import urllib pieces = urllib.parse.urlparse(uri) if resp.status == http_client.NOT_FOUND: return {'http': http_client.HTTPConnection, 'https': http_client.HTTPSConnection}[loc.scheme]","import httplibimport urlparse pieces = urlparse.urlparse(uri) if resp.status == httplib.NOT_FOUND: return {'http': httplib.HTTPConnection, 'https': httplib.HTTPSConnection}[loc.scheme]",82,80
openstack%2Ftripleo-puppet-elements~master~Ie984f3c7782687235cdc2d72ef1f94af89dc3ed4,openstack/tripleo-puppet-elements,master,Ie984f3c7782687235cdc2d72ef1f94af89dc3ed4,Preserve data types in Hiera where possible,MERGED,2015-06-05 13:36:43.000000000,2015-06-10 14:11:02.000000000,2015-06-10 14:11:00.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 7582}, {'_account_id': 8042}]","[{'number': 1, 'created': '2015-06-05 13:36:43.000000000', 'files': ['elements/hiera/os-refresh-config/configure.d/40-hiera-datafiles'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/5d2d14f69085b3a7dac8474aa00b197e3521e4d0', 'message': ""Preserve data types in Hiera where possible\n\nWe didn't preserve the data types from Heat metadata when writing hiera\nfiles. We treated the metadata as raw YAML, unless it was multiline, in\nwhich case we wrapped it in quotes.\n\nThis commit fixes those things as much as possible:\n\n* Proper JSON escaping is preserved for multi-line strings.\n\n* Other data types such as arrays and hashes are properly passed into\n  hiera, regardless if their string representation would be single-line\n  or multi-line.\n\nHowever, single-line strings are still treated as raw YAML, because\ntripleo-heat-templates already depend on that behavior (instead of\nhaving arrays in Heat metadata, we have strings there formatted as\narrays).\n\nChange-Id: Ie984f3c7782687235cdc2d72ef1f94af89dc3ed4\nCloses-Bug: #1462369\n""}]",0,188772,5d2d14f69085b3a7dac8474aa00b197e3521e4d0,18,5,1,8042,,,0,"Preserve data types in Hiera where possible

We didn't preserve the data types from Heat metadata when writing hiera
files. We treated the metadata as raw YAML, unless it was multiline, in
which case we wrapped it in quotes.

This commit fixes those things as much as possible:

* Proper JSON escaping is preserved for multi-line strings.

* Other data types such as arrays and hashes are properly passed into
  hiera, regardless if their string representation would be single-line
  or multi-line.

However, single-line strings are still treated as raw YAML, because
tripleo-heat-templates already depend on that behavior (instead of
having arrays in Heat metadata, we have strings there formatted as
arrays).

Change-Id: Ie984f3c7782687235cdc2d72ef1f94af89dc3ed4
Closes-Bug: #1462369
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/72/188772/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/hiera/os-refresh-config/configure.d/40-hiera-datafiles'],1,5d2d14f69085b3a7dac8474aa00b197e3521e4d0,bug/1462369," local TYPE=$(jq -r "".[\""$KEY\""] | type"" <<< $HIERA_DATA) local VALUE=$(jq -a "".[\""$KEY\""]"" <<< $HIERA_DATA) # FIXME: We should pass data types unchanged from Heat metadata to # hiera. For now we need to treat single-line strings as raw data # because we already depend on this in tripleo-heat-templates # (e.g. we generate strings which look like arrays and depend on # them being processed as real arrays in hiera). if [ ""$TYPE"" = ""string"" ]; then local RAW_VALUE=$(jq -r -a "".[\""$KEY\""]"" <<< $HIERA_DATA) # Treat single-line strings as raw data if [ $(echo -ne ""$RAW_VALUE"" | grep -c '$') -gt 1 ]; then echo ""$KEY: $VALUE"" >> $filename else echo ""$KEY: $RAW_VALUE"" >> $filename fi"," local VALUE=$(jq -r -a "".[\""$KEY\""]"" <<< $HIERA_DATA) # Quote multi-line strings for YAML if [ $(echo -ne ""$VALUE"" | grep -c '$') -gt 1 ]; then echo ""$KEY: '$VALUE'"" >> $filename",16,4
openstack%2Frequirements~master~I853ebcd1fd153481fa089f924b532a6dfb880bd5,openstack/requirements,master,I853ebcd1fd153481fa089f924b532a6dfb880bd5,Tries removing the upper bound of SQLA,ABANDONED,2015-06-09 22:43:09.000000000,2015-06-10 14:05:22.000000000,,"[{'_account_id': 3}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-09 22:43:09.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/918eb2f66c120a1aece502efc308c60737da1c1e', 'message': ""Tries removing the upper bound of SQLA\n\nAccording to Mike Bayer, we should be able to run with the\nlatest version of SQLA. So let's try with this patch.\n\nChange-Id: I853ebcd1fd153481fa089f924b532a6dfb880bd5\n""}]",0,189968,918eb2f66c120a1aece502efc308c60737da1c1e,4,2,1,6476,,,0,"Tries removing the upper bound of SQLA

According to Mike Bayer, we should be able to run with the
latest version of SQLA. So let's try with this patch.

Change-Id: I853ebcd1fd153481fa089f924b532a6dfb880bd5
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/189968/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,918eb2f66c120a1aece502efc308c60737da1c1e,check-sqla-1.0,SQLAlchemy>=0.9.7,"SQLAlchemy>=0.9.7,<=0.9.99",1,1
openstack%2Fopenstack-manuals~master~I82922035cc39e51d94c778779d99aa0f4c1854ff,openstack/openstack-manuals,master,I82922035cc39e51d94c778779d99aa0f4c1854ff,Convert dashboard chapter to RST,MERGED,2015-06-09 05:26:28.000000000,2015-06-10 14:04:41.000000000,2015-06-10 14:04:39.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 10705}, {'_account_id': 12686}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-09 05:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f88948dbf0bc5193ac778c4de5707781bdcfb8f2', 'message': 'Convert dashboard chapter to RST\n\nCloud Admin Guide files converted:\n\ndashboard.rst\ndashboard_sessions.rst\ncommon-rst/dashboard_customizing.rst\n\nChange-Id: I82922035cc39e51d94c778779d99aa0f4c1854ff\nImplements: blueprint reorganise-user-guides\n'}, {'number': 2, 'created': '2015-06-10 02:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/394f60145d439e065b569baadd5ee690a57c9483', 'message': 'Convert dashboard chapter to RST\n\nCloud Admin Guide files converted:\n\ndashboard.rst\ndashboard_sessions.rst\ncommon-rst/dashboard_customizing.rst\n\nChange-Id: I82922035cc39e51d94c778779d99aa0f4c1854ff\nImplements: blueprint reorganise-user-guides\n'}, {'number': 3, 'created': '2015-06-10 06:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f2e53d32d08fc8a8596d6dbcfb32e782445d9146', 'message': 'Convert dashboard chapter to RST\n\nCloud Admin Guide files converted:\n\ndashboard.rst\ndashboard_sessions.rst\ncommon-rst/dashboard_customizing.rst\n\nChange-Id: I82922035cc39e51d94c778779d99aa0f4c1854ff\nImplements: blueprint reorganise-user-guides\n'}, {'number': 4, 'created': '2015-06-10 12:05:44.000000000', 'files': ['doc/admin-guide-cloud-rst/source/index.rst', 'doc/common-rst/dashboard_customizing.rst', 'doc/admin-guide-cloud-rst/source/dashboard_sessions.rst', 'doc/admin-guide-cloud-rst/source/dashboard.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/40836ff4b33b9f69b5960217c33b3fdb5cfe4d88', 'message': 'Convert dashboard chapter to RST\n\nCloud Admin Guide files converted:\n\ndashboard.rst\ndashboard_sessions.rst\ncommon-rst/dashboard_customizing.rst\n\nChange-Id: I82922035cc39e51d94c778779d99aa0f4c1854ff\nImplements: blueprint reorganise-user-guides\n'}]",10,189555,40836ff4b33b9f69b5960217c33b3fdb5cfe4d88,23,7,4,12686,,,0,"Convert dashboard chapter to RST

Cloud Admin Guide files converted:

dashboard.rst
dashboard_sessions.rst
common-rst/dashboard_customizing.rst

Change-Id: I82922035cc39e51d94c778779d99aa0f4c1854ff
Implements: blueprint reorganise-user-guides
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/55/189555/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud-rst/source/index.rst', 'doc/common-rst/dashboard_customizing.rst', 'doc/admin-guide-cloud-rst/source/dashboard_sessions.rst', 'doc/admin-guide-cloud-rst/source/dashboard.rst']",4,f88948dbf0bc5193ac778c4de5707781bdcfb8f2,bp/reorganise-user-guides,"========= Dashboard ========= The OpenStack dashboard is a web-based interface that allows you to manage OpenStack resources and services. The dashboard allows you to interact with the OpenStack Compute cloud controller using the OpenStack APIs. For more information about installing and configuring the dashboard, see the *OpenStack Installation Guide* for your operating system. .. toctree:: :maxdepth: 2 common/dashboard_customizing.rst dashboard_sessions.rst - To deploy the dashboard, see the `Horizon documentation <http://docs.openstack.org/developer/horizon/topics/deployment.html>`__. - To launch instances with the dashboard, see the `OpenStack End User Guide <http://docs.openstack.org/user-guide/index.html>`__. ",,391,0
openstack%2Fbarbican-specs~master~Ic35dc0fbd98a38c560a2e9cf8bd0b01325914646,openstack/barbican-specs,master,Ic35dc0fbd98a38c560a2e9cf8bd0b01325914646,Add Crypto/HSM MKEK Rotation Support (Light),MERGED,2015-05-09 00:53:22.000000000,2015-06-10 14:03:27.000000000,2015-06-10 14:03:24.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 6804}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 8004}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-05-09 00:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/dc972f1ed3cd5947b0e880e81a4b074e293df34f', 'message': ""Add Crypto/HSM MKEK Rotation Support (Light)\n\nCurrently Barbican has no means to migrate secrets encrypted with a\ncrypto/HSM-style plugin to a new master key encryption key (MKEK) and\nits associated wrapped project KEKs. This blueprint proposes adding a\nnew Barbican service process that supports completing the rotation\nprocess by re-wrapping the project KEKs with the new MKEK. Note that\nunlike the similarly-named blueprint at\nhttps://blueprints.launchpad.net/barbican/+spec/add-crypto-mkek-rotation-support,\nthis blueprint does *not* call for re-encrypting secrets and is\ntherefore this blueprint is a 'lightweight' alternative to that\nblueprint. Comparing the two approaches, this lightweight one should\nprocess more quickly when there are many secrets with numerous\nproject-IDs stored in the database. The downside to the lightweight\napproach is that if the old MKEK was compromised *and* the attacker has\naccess to backup versions of the database, they could decrypt current\nsecrets since they could then decrypt the unchanged project KEK used to\nencrypt the secret, and because the encrypted secret data is unchanged\nand so can be decrypted by the now-unwrapped project KEK. Similar to\nthe other blueprint, this process would be started after deployers, out\nof band: (1) generate new MKEK and HMAC signing keys with a binding to\nnew labels, and then (2) replicate these keys to other HSMs that may be\nin the high availability (HA) group, and then (3) update Barbican's\nconfig file to reference these new labels, and finally (4) restart the\nBarbican nodes. The proposed process would then re-wrap the project\nKEKs with the new MKEKs, updating the associated project KEK records\nwith the new wrapped project KEKs.\n\nChange-Id: Ic35dc0fbd98a38c560a2e9cf8bd0b01325914646\n""}, {'number': 2, 'created': '2015-05-11 05:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/b5750b6301f64cbab72e04f854b291dceb0a21a5', 'message': ""Add Crypto/HSM MKEK Rotation Support (Light)\n\nCurrently Barbican has no means to migrate secrets encrypted with a\ncrypto/HSM-style plugin to a new master key encryption key (MKEK) and\nits associated wrapped project KEKs. This blueprint proposes adding a\nnew Barbican service process that supports completing the rotation\nprocess by re-wrapping the project KEKs with the new MKEK.\n\nNote that unlike the similarly-named blueprint at\nhttps://blueprints.launchpad.net/barbican/+spec/add-crypto-mkek-rotation-support,\nthis blueprint does *not* call for re-encrypting secrets and is\ntherefore this blueprint is a 'lightweight' alternative to that\nblueprint.\n\nSimilar to the other blueprint, this process would be started after\ndeployers, out of band: (1) generate new MKEK and HMAC signing keys\nwith a binding to new labels, and then (2) replicate these keys to\nother HSMs that may be in the high availability (HA) group, and then\n(3) update Barbican's config file to reference these new labels, and\nfinally (4) restart the Barbican nodes. The proposed process would\nthen re-wrap the project KEKs with the new MKEKs, updating the\nassociated project KEK records with the new wrapped project KEKs.\n\nChange-Id: Ic35dc0fbd98a38c560a2e9cf8bd0b01325914646\n""}, {'number': 3, 'created': '2015-05-27 22:38:06.000000000', 'files': ['specs/liberty/add-crypto-mkek-rotation-support-lightweight.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/acf8737751d6fb87b2cb072bbb24d37c80799a40', 'message': ""Add Crypto/HSM MKEK Rotation Support (Light)\n\nCurrently Barbican has no means to migrate secrets encrypted with a\ncrypto/HSM-style plugin to a new master key encryption key (MKEK) and\nits associated wrapped project KEKs. This blueprint proposes adding a\nnew Barbican service process that supports completing the rotation\nprocess by re-wrapping the project KEKs with the new MKEK.\n\nNote that unlike the similarly-named blueprint at\nhttps://blueprints.launchpad.net/barbican/+spec/add-crypto-mkek-rotation-support,\nthis blueprint does *not* call for re-encrypting secrets and is\ntherefore this blueprint is a 'lightweight' alternative to that\nblueprint.\n\nSimilar to the other blueprint, this process would be started after\ndeployers, out of band: (1) generate new MKEK and HMAC signing keys\nwith a binding to new labels, and then (2) replicate these keys to\nother HSMs that may be in the high availability (HA) group, and then\n(3) update Barbican's config file to reference these new labels, and\nfinally (4) restart the Barbican nodes. The proposed process would\nthen re-wrap the project KEKs with the new MKEKs, updating the\nassociated project KEK records with the new wrapped project KEKs.\n\nChange-Id: Ic35dc0fbd98a38c560a2e9cf8bd0b01325914646\n""}]",38,181598,acf8737751d6fb87b2cb072bbb24d37c80799a40,19,7,3,7789,,,0,"Add Crypto/HSM MKEK Rotation Support (Light)

Currently Barbican has no means to migrate secrets encrypted with a
crypto/HSM-style plugin to a new master key encryption key (MKEK) and
its associated wrapped project KEKs. This blueprint proposes adding a
new Barbican service process that supports completing the rotation
process by re-wrapping the project KEKs with the new MKEK.

Note that unlike the similarly-named blueprint at
https://blueprints.launchpad.net/barbican/+spec/add-crypto-mkek-rotation-support,
this blueprint does *not* call for re-encrypting secrets and is
therefore this blueprint is a 'lightweight' alternative to that
blueprint.

Similar to the other blueprint, this process would be started after
deployers, out of band: (1) generate new MKEK and HMAC signing keys
with a binding to new labels, and then (2) replicate these keys to
other HSMs that may be in the high availability (HA) group, and then
(3) update Barbican's config file to reference these new labels, and
finally (4) restart the Barbican nodes. The proposed process would
then re-wrap the project KEKs with the new MKEKs, updating the
associated project KEK records with the new wrapped project KEKs.

Change-Id: Ic35dc0fbd98a38c560a2e9cf8bd0b01325914646
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/98/181598/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/add-crypto-mkek-rotation-support-lightweight.rst'],1,dc972f1ed3cd5947b0e880e81a4b074e293df34f,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================ Add Crypto/HSM MKEK Rotation and Migration Support (Lightweight) ================================================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/barbican/+spec/add-crypto-mkek-rotation-support-lightweight Currently Barbican has no means to migrate secrets encrypted with a crypto/HSM-style plugin to a new master key encryption key (MKEK) and its associated wrapped project KEKs. This blueprint proposes adding a new Barbican service process that supports completing the rotation process by rewrapping the project KEKs with the new MKEK. Note that unlike the similarly-named blueprint at [1], this blueprint does *not* call for re-encrypting secrets and is therefore this blueprint is a 'lightweight' alternative to that blueprint. Comparing the two approaches, this lightweight one should process more quickly when there are many secrets with numerous project-IDs stored in the database. The downside to the lightweight approach is that if the old MKEK was compromised *and* the attacker has access to backup versions of the database, they could decrypt current secrets since they could then decrypt the unchanged project KEK used to encrypt the secret, and because the encrypted secret data is unchanged and so can be decrypted by the now-unwrapped project KEK. The likelhood of such an attack is expected to be small however. Afterall, MKEKs are infrequently rotated due to their low probability of being guessed, and database backups are not likely to be kept much longer longer than the rotation period. For known compromises, the more stringent rotation approach would be advised. Similar to the other blueprint, this process would be started after deployers, out of band: 1. generate new MKEK and HMAC signing keys with a binding to new labels, and then 2. Replicate these keys to other HSMs that may be in the high availability (HA) group, and then 3. Update Barbican's config file to reference these new labels, and finally 4. Restart the Barbican nodes. The proposed process would then rewrap the project KEKs with the new MKEKs, updating the associated project KEK records with the new wrapped project KEKs. Problem Description =================== When a secret is stored in Barbican using the crypto-style plugin, a `KEKDatum` entity (from `barbican.model.models`) is retrieved for the secret's project. If no such entities are found for this project, then the following steps occur: 1. A new `KEKDatum` entity is created for the project and the specific crypto- style plugin with status of `ACTIVE`. The `ACTIVE` status indicates that this entity should be used for secret encryptions from then on. 2. The `bind_kek_metadata()` method is invoked on the crypto plugin. The plugin then creates a project-level KEK that will be used to encrypt new secrets for that project. For the PKCS11 HSM plugin, this is the project KEK that is wrapped/encrypted by the MKEK. 3. Information about this project-level KEK is then added to `plugin_meta` attribute of the new `KEKDatum` entity. 4. When a secret is finally stored, it has a `Secret` entity created for it to hold metadata, and also an associated `EncryptedDatum` entity that holds both the encrypted cypher text for the secret, and a reference to the project-level `KEKDatum` record. 5. Thereafter, new secrets that need to be encrypted for this same project will used this `KEKDatum` entity, with no further attempts made to generate a new entity. Hence the `KEKDatum` entity is associated with project-level KEKs, which in turn are associated with a single MKEK in the HSM. As rotation involves creating a new MKEK (but not the project KEKs for this lightweight version) on a periodic basis, the `KEKDatum` entity needs to be updated per project to rewrap/encrypt the project KEK it contains. Unlike the more stringent key rotation blueprint, no other steps are needed. The secrets, there UUIDs and their associated encrypted data, do not need to change at all, which should speed the overall migration process. A requirement is that this process be resilient, allowing for the process to be re-run if it fails midway. This blueprint details an approach to rewrap existing project KEKs with a new MKEK. Proposed Change =============== This blueprint proposes the following steps be taken to complete the KEK rotation and migration effort: 1. Out of band to Barbican (so by deployers), new MKEK and HMAC keys are created in the HSM, with new unique labels. For high availability configurations such keys must be replicated across all HSMs in the cluster. 2. For each API and worker node in the network, update their `/etc/barbican/barbican-api.conf` files' `mkek_label` and `hmac_label` attributes with the new unique labels generated above. 3. Restart the API and worker nodes. 4. Via a new process proposed in this blueprint, query for all `KEKDatum` entities for a specified crypto-style plugin class (e.g. `barbican.plugin.crypto.simple_crypto.SimpleCryptoPlugin`). These wrapped-project KEKs need to be rewrapped with the new MKEK. 5. For each `KEKDatum` entity, invoke a new method on the crypto-style plugin contract (defined in `barbican.plugin.crypto.crypto.py`) called 'rewrap_project_kek()', which takes the entity as input and updates it with the rewrapped project KEK. The plugin would need to load the wrapped project KEK into the HSM, decrypt it with the old MKEK, encrypted it with the new MKEK, and then then unload the new wrapped project KEK (but still containing the original project KEK). 6. Info log the UUID of the migrated `KEKDatum` entity to produce a record of the migration. The proposed process would be implemented as a Python `barbican.cmd` script and added as a `pbr` entry point in the `setup.cfg` file, and hence available as a callable command once Barbican is deployed. To preserve data integrity step 5 should be performed in a database transaction. Alternatives ------------ See the more heavy-weight alternative approach to key rotation at [1]. Data model impact ----------------- No data model or repository changes are needed for the proposed solution. Data migrations will be required as detailed in the Proposed Change section above. REST API impact --------------- None. Security impact --------------- The proposed solution completes necessary key rotation processes by rewrapping project KEKs used to encrypt secrets. There are improbable but possible data loss risks with the proposed approach however, since project KEKs encrypted with old MKEKs are replaced with these same project KEKs encrypted with the new MKEKs. If the database update fails and corrupts this record, all secrets derived from the project KEKs would be lost. Since these wrapped project KEKs do not change very often though (on the order of the MKEK rotation schedule) recovery from database backups is very likely, thus mitigating this risk. Notifications & Audit Impact ---------------------------- A log of each `KEKDatum` entity migrated is produced by the proposed process, which could be used to prove to auditors that a migration/rotation occurred. Other end user impact --------------------- None. Performance Impact ------------------ The proposed process could take a long time to process if there are many project-IDs to migrate, and thus it would represent an load on the database impacting all other operations. This process would be called quite infrequently however (maybe 1 to 4 times a year). There will also be far fewer project IDs than secrets, making this process more performant than that proposed in [1]. Other deployer impact --------------------- The proposed process would be executed as a new executable command available after deployment Barbican. The proposed changes would not require updates to the configuration file schema, but would require updates to provide new MKEK and HMAC key labels as detailed above. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- TBD Work Items ---------- The proposed work items are: 1. Create a Python command script to implement the steps in the Proposed Change section. 2. Add unit testing to cover the new code lines. 3. Add integration unit test that, using the default `simple_crypto.py` plugin and an in-memory SQLite database, first creates a few known secrets with the default MEK in the config file, and then modifies this MEK, and then executes the migration script logic. The secrets should be decrypted and verified for accuracy. The `KEKDatum` entities should have their `updated_at` dates updated. The secrets should again be decrypted and verified for accuracy, which proves the migration of all secrets to the updated `KEKDatum` record occurred successfully. 4. Document the overall key rotation and migration process, including the usage of the new migration command script. Dependencies ============ None. Testing ======= No DevStack functional tests are expected at this time. Once an HSM gate job is added, a future blueprint add tests will be added. Documentation Impact ==================== The last work item details the required documentation. References ========== [1] https://blueprints.launchpad.net/barbican/+spec/add-crypto-mkek-rotation-support ",,254,0
openstack%2Fneutron-specs~master~I9f8800a69e6d262d544117fe9b0b66293ad75cee,openstack/neutron-specs,master,I9f8800a69e6d262d544117fe9b0b66293ad75cee,Initial commit of the specs of a port-forwarding extension for the neutron router.,ABANDONED,2015-03-24 10:42:02.000000000,2015-06-10 14:02:32.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 333}, {'_account_id': 841}, {'_account_id': 13532}]","[{'number': 1, 'created': '2015-03-24 10:42:02.000000000', 'files': ['specs/kilo/router-port-forwarding.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/93f0f12f4149383a1ef45ee5206b39c8f210b19b', 'message': 'Initial commit of the specs of a port-forwarding\nextension for the neutron router.\n\nBlueprint: router-port-forwarding\n\nChange-Id: I9f8800a69e6d262d544117fe9b0b66293ad75cee\nCo-Authored-By: Marco Alfano <alfano8383@gmail.com>\nCo-Authored-By: Roberto Vela <roberto@robertovela.it>\n'}]",0,167165,93f0f12f4149383a1ef45ee5206b39c8f210b19b,8,5,1,13067,,,0,"Initial commit of the specs of a port-forwarding
extension for the neutron router.

Blueprint: router-port-forwarding

Change-Id: I9f8800a69e6d262d544117fe9b0b66293ad75cee
Co-Authored-By: Marco Alfano <alfano8383@gmail.com>
Co-Authored-By: Roberto Vela <roberto@robertovela.it>
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/65/167165/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/router-port-forwarding.rst'],1,93f0f12f4149383a1ef45ee5206b39c8f210b19b,bp/router-port-forwarding,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Router Port Forwarding ========================================== https://blueprints.launchpad.net/neutron/+spec/router-port-forwarding You often have a limited number of public ips available in your Cloud, so it is handy to use a single ip to reach multiple VMs. Problem Description =================== There are several use-cases where users need to reach a VM from public network and they don't have any floating ip available or don't want to use it for a single service, e.g.: * You just need to reach a VM using SSH; * You have a complex application composed by multiple servers that need to expose public ports. Proposed Change =============== This blueprint aims at implementing a Port Forwarding feature within the Neutron l3 router, so that users can use the gateway's public ip to reach the VMs. In this way the - already assigned - gateway's external ip can be used for incoming connections doing DNAT, in addition to the outgoing connections addressed by the default SNAT gateway rule. With this change, users can reach the Internet and expose their services by using a single public ip address. Data Model Impact ----------------- The change needs a new table in the Neutron database in order to store the port forwarding rules. These are the fields needed to store a single rule: +--------------+--------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +==============+==============+======+=====+=========+=======+ | id | varchar(36) | NO | PRI | NULL | | +--------------+--------------+------+-----+---------+-------+ | tenant_id | varchar(255) | YES | | NULL | | +--------------+--------------+------+-----+---------+-------+ | router_id | varchar(36) | YES | MUL | NULL | | +--------------+--------------+------+-----+---------+-------+ | outside_port | int(11) | YES | | NULL | | +--------------+--------------+------+-----+---------+-------+ | inside_addr | varchar(15) | YES | | NULL | | +--------------+--------------+------+-----+---------+-------+ | inside_port | int(11) | YES | | NULL | | +--------------+--------------+------+-----+---------+-------+ | protocol | varchar(4) | YES | | NULL | | +--------------+--------------+------+-----+---------+-------+ REST API Impact --------------- The change introduces this new resource map: .. code-block:: python RESOURCE_ATTRIBUTE_MAP = { 'portforwardings': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, 'router_id': {'allow_post': True, 'allow_put': False, 'required_by_policy': True, 'is_visible': True}, 'protocol': {'allow_post': True, 'allow_put': True, 'is_visible': True, 'default': None, 'convert_to': convert_protocol, 'validate': {'type:values': valid_protocol_values}}, 'inside_addr': {'allow_post': True, 'allow_put': True, 'validate': {'type:ip_or_subnet_or_none': None}, 'is_visible': True, 'default': None}, 'inside_port': {'allow_post': True, 'allow_put': True, 'validate': {'type:port_range': None}, 'convert_to': convert_port_to_string, 'default': None, 'is_visible': True}, 'outside_port': {'allow_post': True, 'allow_put': True, 'validate': {'type:port_range': None}, 'convert_to': convert_port_to_string, 'default': None, 'is_visible': True} } } The change introduces the following new API methods: 1. neutron portforwarding-create <router_id> <protocol> <ip_address> <inside_port> <outside_port> POST /v2.0/portforwardings.json This method adds a new forwarding rule from an external exposed port to a VM internal port. Normal Response code: 201 Error Response Code: Standard http error codes Input parameters: router_id, protocol, inside_address, inside_port, outside_port JSON Schema definition for the body: .. code-block:: javascript {""portforwarding"": {""router_id"": ""<Router ID>"", ""inside_addr"": ""<VM IP address>"", ""protocol"": ""<Protocol>"", ""inside_port"": ""<VM Port>"", ""outside_port"": ""<Public router port>""}} .. JSON Schema definition for the response: .. code-block:: javascript {""portforwarding"": {""router_id"": ""<Router ID>"", ""inside_addr"": ""<VM IP address>"", ""protocol"": ""<Protocol>"", ""inside_port"": ""<VM Port>"", ""outside_port"": ""<Public router port>"" ""id"": ""<Port forwarding rule id>""}} .. Example: Request: POST /v2.0/portforwardings.json .. code-block:: javascript {""portforwarding"": {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""inside_addr"": ""192.168.122.147"", ""protocol"": ""tcp"", ""inside_port"": ""9998"", ""outside_port"": ""9998""}} .. Reponse: 201 .. code-block:: javascript {""portforwarding"": {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""protocol"": ""tcp"", ""tenant_id"": ""c7f07ff38599451abdc8f15f99af8c2d"", ""inside_port"": ""9998"", ""inside_addr"": ""192.168.122.147"", ""outside_port"": ""9998"", ""id"": ""b8ce9d7d-a14e-42be-af36-2ba2c1887762""}} .. 2. neutron portforwarding-list GET /v2.0/portforwardings.json This method lists the existing port forwarding rules in the current tenant. Normal Response code: 200 Error Response Code: Standard http error codes Input parameters: none JSON Schema definition for the request body: none JSON Schema definition for the response: .. code-block:: javascript {""portforwardings"": [ {<rule_1>}, {<rule_2> ]}} .. Example: Request: GET /v2.0/portforwardings.json Response: 200 .. code-block:: javascript {""portforwardings"": [ {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""protocol"": ""tcp"", ""tenant_id"": ""c7f07ff38599451abdc8f15f99af8c2d"", ""inside_port"": 22, ""inside_addr"": ""192.168.122.147"", ""outside_port"": 9922, ""id"": ""419df3f0-fbf8-46d4-a9ed-1649534fbd9e""}, {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""protocol"": ""tcp"", ""tenant_id"": ""c7f07ff38599451abdc8f15f99af8c2d"", ""inside_port"": 9998, ""inside_addr"": ""192.168.122.147"", ""outside_port"": 9998, ""id"": ""8f7dfeaf-79de-4461-b021-62deeba258b6""}, {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""protocol"": ""tcp"", ""tenant_id"": ""c7f07ff38599451abdc8f15f99af8c2d"", ""inside_port"": 9999, ""inside_addr"": ""192.168.122.147"", ""outside_port"": 9999, ""id"": ""a31d867b-85c9-457a-87b1-5f7894aade3e""}]} .. 3. neutron portforwarding-show <rule_id> GET /v2.0/portforwardings/<rule_id>.json This method shows details on the portforwarding specified rule. Normal Response code: 200 Error Response Code: Standard http error codes Input parameters: none JSON Schema definition for the request body: none JSON Schema definition for the response: .. code-block:: javascript {""portforwarding"": {""router_id"": <router_id>, ""inside_addr"": <VM_IP_address>, ""protocol"": <Protocol>, ""inside_port"": <VM Port>, ""outside_port"": <Public router port> ""id"": ""<Port forwarding rule id>""}} .. Example: Request: GET /v2.0/portforwardings/8e41b328-72c4-41b9-83b6-e9c05c0a5905.json Response 200 .. code-block:: javascript {""portforwarding"": {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""protocol"": ""tcp"", ""tenant_id"": ""c7f07ff38599451abdc8f15f99af8c2d"", ""inside_port"": ""9998"", ""inside_addr"": ""192.168.122.147"", ""outside_port"": ""9998"", ""id"": ""8e41b328-72c4-41b9-83b6-e9c05c0a5905""}} .. 4. neutron portforwarding-delete <rule_id> DELETE /v2.0/portforwardings/<rule_id> This method deletes a port forwarding rule. Normal Response code: 204 Error Response Code: Standard http error codes Input parameters: <rule_id> JSON Schema definition for the request body: none JSON Schema definition for the response: none Example: Request: DELETE /v2.0/portforwardings/a31d867b-85c9-457a-87b1-5f7894aade3e.json Reponse: 204 5. neutron portforwarding-update <rule_id> <[--outside_port|--inside_port|--ip_addr|--protocol]> This method updates a port forwarding rule editing one or more parameters including VM address, internal port, external port and protocol. Normal Response code: 200 Error Response Code: Standard http error codes Input parameters: <rule_id> JSON Schema definition for the request body: .. code-block:: javascript {""portforwarding"": {""router_id"": <router_id>, ""inside_addr"": <VM_IP_address>, ""protocol"": <Protocol>, ""inside_port"": <VM Port>, ""outside_port"": <Public router port>}} .. JSON Schema definition for the response: .. code-block:: javascript {""portforwarding"": {""router_id"": <router_id>, ""inside_addr"": <VM_IP_address>, ""protocol"": <Protocol>, ""inside_port"": <VM Port>, ""outside_port"": <Public router port> ""id"": ""Port forwarding rule id""}} .. Example: Request: PUT /v2.0/portforwardings/a31d867b-85c9-457a-87b1-5f7894aade3e.json .. code-block:: javascript {""portforwarding"": {""outside_port"": ""9999""}} .. Response: 200 .. code-block:: javascript {""portforwarding"": {""router_id"": ""830a82ba-82e5-4062-b5ff-d56646b3470b"", ""protocol"": ""tcp"", ""tenant_id"": ""c7f07ff38599451abdc8f15f99af8c2d"", ""inside_port"": ""9998"", ""inside_addr"": ""192.168.122.147"", ""outside_port"": ""9999"", ""id"": ""a31d867b-85c9-457a-87b1-5f7894aade3e""}} .. Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- The python-neutronclient will invoke the port forwarding APIs. Performance Impact ------------------ None IPv6 Impact ----------- This spec does only support forwarding of IPv4 traffic. Other Deployer Impact --------------------- None Developer Impact ---------------- None Community Impact ---------------- This change has no impact on the current direction of the Neutron community, since it is just a minor extension of the router's functionalities. Alternatives ------------ 1. https://review.openstack.org/#/c/60512/ This blueprint implementation treats the whole list of rules as a unique object. The downside of this approach is that in order to edit or remove one of the rules, the entire list had to be uploaded again. The current spec allows the management of the rules as single entities, making thus operations like edit, add and delete much simpler. Implementation ============== Assignee(s) ----------- * Davide Michelino (davide-m) * Marco Alfano (marco-alfano) * Roberto Vela (roberto-vela) Work Items ---------- 1. Implementation of the router extension * Implementation of the REST API calls described in this spec; * Implementation of the proposed DB model; * Unit tests. 2. Implementation of new CLIs in neutron client Dependencies ============ None Testing ======= Tempest Tests ------------- None Functional Tests ---------------- None API Tests --------- The Tempest API test for CRUD operation will be added. Documentation Impact ==================== User Documentation ------------------ Functionality details will be documented. Developer Documentation ----------------------- None References ========== None ",,475,0
openstack%2Fdevstack~stable%2Fkilo~I7a2f3ee9c74b34fdf003f65f4936074a236784c2,openstack/devstack,stable/kilo,I7a2f3ee9c74b34fdf003f65f4936074a236784c2,Start and stop n-net with n-cpu for partial upgrades,ABANDONED,2015-06-10 00:52:29.000000000,2015-06-10 13:58:15.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}]","[{'number': 1, 'created': '2015-06-10 00:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4a8ecd8d99a9ab89ef40def659401238605e9516', 'message': 'Start and stop n-net with n-cpu for partial upgrades\n\nIn a real environment, n-net will be co-located with n-cpu, and\nupgraded at the same time. For the sake of expediency, this patch\nmakes n-cpu and n-net be started and stopped at the same time as\n""the compute family of services."" Grenade\'s existing partial upgrade\nsupport will still apply, and we\'ll get a more realistic test.\n\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2\n'}, {'number': 2, 'created': '2015-06-10 09:38:14.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1eab403938a15b6c4b778e07f8cd203a3ee6311a', 'message': 'Start and stop n-net with n-cpu for partial upgrades\n\nIn a real environment, n-net will be co-located with n-cpu, and\nupgraded at the same time. For the sake of expediency, this patch\nmakes n-cpu and n-net be started and stopped at the same time as\n""the compute family of services."" Grenade\'s existing partial upgrade\nsupport will still apply, and we\'ll get a more realistic test.\n\nSince grenade uses devstack old to do the shutdown, we need to backport\nthis patch to Kilo to make the Kilo -> master (Liberty) job work.\n\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2\n(cherry picked from commit 18e9151b03583ba2426e95fc74d1733633777eb0)\n'}]",0,189988,1eab403938a15b6c4b778e07f8cd203a3ee6311a,6,2,2,4393,,,0,"Start and stop n-net with n-cpu for partial upgrades

In a real environment, n-net will be co-located with n-cpu, and
upgraded at the same time. For the sake of expediency, this patch
makes n-cpu and n-net be started and stopped at the same time as
""the compute family of services."" Grenade's existing partial upgrade
support will still apply, and we'll get a more realistic test.

Since grenade uses devstack old to do the shutdown, we need to backport
this patch to Kilo to make the Kilo -> master (Liberty) job work.

Change-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2
(cherry picked from commit 18e9151b03583ba2426e95fc74d1733633777eb0)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/88/189988/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,4a8ecd8d99a9ab89ef40def659401238605e9516,backport-partial-nnet," # NOTE(danms): We're conflating all the things that run on a compute # host into the ""nova_compute service"" here. That means n-cpu and n-net. run_process n-net ""$NOVA_BIN_DIR/nova-network --config-file $compute_cell_conf"" # NOTE(danms): We're conflating all the things that run on a compute # host into the ""nova_compute service"" here. That means n-cpu and n-net. stop_process n-net for serv in n-api n-crt n-sch n-novnc n-xvnc n-cauth n-spice n-cond n-cell n-cell n-api-meta n-obj n-sproxy; do"," run_process n-net ""$NOVA_BIN_DIR/nova-network --config-file $compute_cell_conf"" for serv in n-api n-crt n-net n-sch n-novnc n-xvnc n-cauth n-spice n-cond n-cell n-cell n-api-meta n-obj n-sproxy; do",9,2
openstack%2Fnova~master~I61dbc60ceab0578c2e65ac5449b801a7ffbb6f5f,openstack/nova,master,I61dbc60ceab0578c2e65ac5449b801a7ffbb6f5f,"Revert ""libvirt: Remove unnecessary JSON conversions""",ABANDONED,2015-06-10 10:06:36.000000000,2015-06-10 13:56:33.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-10 10:06:36.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ae31c58fbc0ff0e1dbb4b27b9d025aab9b0a9051', 'message': 'Revert ""libvirt: Remove unnecessary JSON conversions""\n\nThis reverts commit a7a0b4e542a65b3ba3650db2b7560eb587b9606c.\n\na7a0b4e542a65b3ba3650db2b7560eb587b9606c is causing live migrate to\nfail. Live migration is now tested by check-tempest-dsvm-multinode-full.\n\nSince this patch has landed no multinode jobs have worked, and the first\nn-cpu stacktrace related to this bug was found on patch a7a0b4.\n\nChange-Id: I61dbc60ceab0578c2e65ac5449b801a7ffbb6f5f\nCloses-Bug: #1463747\n'}]",0,190098,ae31c58fbc0ff0e1dbb4b27b9d025aab9b0a9051,13,10,1,1849,,,0,"Revert ""libvirt: Remove unnecessary JSON conversions""

This reverts commit a7a0b4e542a65b3ba3650db2b7560eb587b9606c.

a7a0b4e542a65b3ba3650db2b7560eb587b9606c is causing live migrate to
fail. Live migration is now tested by check-tempest-dsvm-multinode-full.

Since this patch has landed no multinode jobs have worked, and the first
n-cpu stacktrace related to this bug was found on patch a7a0b4.

Change-Id: I61dbc60ceab0578c2e65ac5449b801a7ffbb6f5f
Closes-Bug: #1463747
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/190098/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,ae31c58fbc0ff0e1dbb4b27b9d025aab9b0a9051,bug/1463747," disk_info_json = jsonutils.dumps([disk_info]) ""/fake/instance/dir"", disk_info_json) disk_info_json = jsonutils.dumps( [{u'backing_file': u'fake_image_backing_file', u'disk_size': 10747904, u'path': u'disk_path', u'type': u'qcow2', u'virt_disk_size': 25165824}]) ""/fake/instance/dir"", disk_info_json) disk_info_json = jsonutils.dumps( [{u'backing_file': u'fake_image_backing_file', u'disk_size': 10747904, u'path': u'disk_path', u'type': u'qcow2', u'virt_disk_size': 25165824}]) ""/fake/instance/dir"", disk_info_json, disk_info_json = jsonutils.dumps( [{u'backing_file': u'fake_image_backing_file', u'disk_size': 10747904, u'path': u'disk_path', u'type': u'qcow2', u'virt_disk_size': 25165824}, {u'backing_file': u'ephemeral_1_default', u'disk_size': 393216, u'over_committed_disk_size': 1073348608, u'path': u'disk_eph_path', u'type': u'qcow2', u'virt_disk_size': 1073741824}]) disk_info_json) disk_info_json = '[{""virt_disk_size"": 2}]' mock_get_instance_disk_info.return_value = disk_info_json return jsonutils.dumps(fake_disks.get(instance_name)) return jsonutils.dumps(fake_disks.get(name))"," ""/fake/instance/dir"", [disk_info]) disk_info = [ {u'backing_file': u'fake_image_backing_file', u'disk_size': 10747904, u'path': u'disk_path', u'type': u'qcow2', u'virt_disk_size': 25165824}] ""/fake/instance/dir"", disk_info) disk_info = [ {u'backing_file': u'fake_image_backing_file', u'disk_size': 10747904, u'path': u'disk_path', u'type': u'qcow2', u'virt_disk_size': 25165824}] ""/fake/instance/dir"", disk_info, disk_info = [ {u'backing_file': u'fake_image_backing_file', u'disk_size': 10747904, u'path': u'disk_path', u'type': u'qcow2', u'virt_disk_size': 25165824}, {u'backing_file': u'ephemeral_1_default', u'disk_size': 393216, u'over_committed_disk_size': 1073348608, u'path': u'disk_eph_path', u'type': u'qcow2', u'virt_disk_size': 1073741824}] disk_info) disk_info = [{""virt_disk_size"": 2}] mock_get_instance_disk_info.return_value = disk_info return fake_disks.get(instance_name) return fake_disks.get(name)",49,44
openstack%2Fbandit~master~I075c14df29c3abe668bb215b1ca9f799110cf782,openstack/bandit,master,I075c14df29c3abe668bb215b1ca9f799110cf782,Update README with missing usage changes,MERGED,2015-06-07 16:31:48.000000000,2015-06-10 13:51:28.000000000,2015-06-10 13:51:27.000000000,"[{'_account_id': 3}, {'_account_id': 11029}, {'_account_id': 11861}, {'_account_id': 15173}]","[{'number': 1, 'created': '2015-06-07 16:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/325951bd03280f1e6ff1a3187e3a1c49d00bc02f', 'message': ""Update README with missing usage changes\n\nThe README's usage section hadn't been updated in a while and did\nnot include some changes made in the past few commits.  These\ninclude:\n- csv and xml output format\n- config file default location\n- edit to context line description\n\nChange-Id: I075c14df29c3abe668bb215b1ca9f799110cf782\n""}, {'number': 2, 'created': '2015-06-10 02:40:51.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/bandit/commit/084b1abb753b719e63afc684c646e7bb90a4e3b4', 'message': ""Update README with missing usage changes\n\nThe README's usage section hadn't been updated in a while and did\nnot include some changes made in the past few commits.  These\ninclude:\n- csv and xml output format\n- config file default location\n- edit to context line description\n\nChange-Id: I075c14df29c3abe668bb215b1ca9f799110cf782\n""}]",0,189148,084b1abb753b719e63afc684c646e7bb90a4e3b4,12,4,2,8119,,,0,"Update README with missing usage changes

The README's usage section hadn't been updated in a while and did
not include some changes made in the past few commits.  These
include:
- csv and xml output format
- config file default location
- edit to context line description

Change-Id: I075c14df29c3abe668bb215b1ca9f799110cf782
",git fetch https://review.opendev.org/openstack/bandit refs/changes/48/189148/2 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,325951bd03280f1e6ff1a3187e3a1c49d00bc02f,update_readme," -a {file,vuln}, --aggregate {file,vuln} group results by vulnerability type or file it occurs in max number of code lines to display for each issue identified test config file, defaults to /etc/bandit/bandit.yaml, or./bandit.yaml if not given -f {csv,json,txt,xml}, --format {csv,json,txt,xml} specify output format"," -a AGG_TYPE, --aggregate AGG_TYPE group results by (vuln)erability type or (file) it occurs in number of context lines to print test config file (default: bandit.yaml) -f {txt,json}, --format {txt,json} output format for STDOUT or file",9,7
openstack%2Fproject-config~master~Ib40ea89407d0af747bcc32bfe2ab550d9aa55fcc,openstack/project-config,master,Ib40ea89407d0af747bcc32bfe2ab550d9aa55fcc,[dragonflow] Add branch creation permission to the core team,MERGED,2015-05-31 10:57:55.000000000,2015-06-10 13:50:18.000000000,2015-06-10 13:50:16.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-05-31 10:57:55.000000000', 'files': ['gerrit/acls/stackforge/dragonflow.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/283631edcd34cfaeda998fcb15a54e85d3aa541a', 'message': '[dragonflow] Add branch creation permission to the core team\n\nChange-Id: Ib40ea89407d0af747bcc32bfe2ab550d9aa55fcc\n'}]",0,187042,283631edcd34cfaeda998fcb15a54e85d3aa541a,14,7,1,2023,,,0,"[dragonflow] Add branch creation permission to the core team

Change-Id: Ib40ea89407d0af747bcc32bfe2ab550d9aa55fcc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/187042/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/stackforge/dragonflow.config'],1,283631edcd34cfaeda998fcb15a54e85d3aa541a,drangflow_branch,create = group dragonflow-core,,1,0
openstack%2Fproject-config~master~I2a9c23d4848404aa4f44585ee46d06562bb16862,openstack/project-config,master,I2a9c23d4848404aa4f44585ee46d06562bb16862,Added new SF repository for Fuel SolidFire Cinder,MERGED,2015-06-09 15:38:34.000000000,2015-06-10 13:50:14.000000000,2015-06-10 13:50:12.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 11809}]","[{'number': 1, 'created': '2015-06-09 15:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/96ee353bd471d304bcad1f3fce73ae1bf6c4eb81', 'message': 'Added new SF repository for Fuel SolidFire Cinder\n\nNew SF repository for Fuel plugin SolidFire Cinder\n\nChange-Id: I2a9c23d4848404aa4f44585ee46d06562bb16862\n'}, {'number': 2, 'created': '2015-06-09 15:39:25.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'gerrit/acls/stackforge/fuel-plugin-solidfire-cinder.config', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ff643aa624057372b5f2168a62aa5ff92a779897', 'message': 'Added new SF repository for Fuel SolidFire Cinder\n\nNew SF repository for Fuel plugin SolidFire Cinder\n\nChange-Id: I2a9c23d4848404aa4f44585ee46d06562bb16862\nCloses-Bug: #1463443\n'}]",0,189779,ff643aa624057372b5f2168a62aa5ff92a779897,11,8,2,14372,,,0,"Added new SF repository for Fuel SolidFire Cinder

New SF repository for Fuel plugin SolidFire Cinder

Change-Id: I2a9c23d4848404aa4f44585ee46d06562bb16862
Closes-Bug: #1463443
",git fetch https://review.opendev.org/openstack/project-config refs/changes/79/189779/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'gerrit/acls/stackforge/fuel-plugin-solidfire-cinder.config', 'zuul/layout.yaml']",4,96ee353bd471d304bcad1f3fce73ae1bf6c4eb81,bug/1463443, - name: stackforge/fuel-plugin-solidfire-cinder template: - name: merge-check - name: noop-jobs ,,27,0
openstack%2Fproject-config~master~I3818895d098b1e74570e38d8901d2622687327b6,openstack/project-config,master,I3818895d098b1e74570e38d8901d2622687327b6,Update project-team-guide groups,MERGED,2015-06-09 20:37:23.000000000,2015-06-10 13:50:10.000000000,2015-06-10 13:50:08.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-06-09 20:37:23.000000000', 'files': ['gerrit/acls/openstack/project-team-guide.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8dd5b537fb28b1c7d8c592aab5f270f5f4788088', 'message': 'Update project-team-guide groups\n\nUse standard group names for the project-team-guide for ease of\nadditions/removals from group.  We may still seed the group with\nTC members.\n\nChange-Id: I3818895d098b1e74570e38d8901d2622687327b6\n'}]",0,189926,8dd5b537fb28b1c7d8c592aab5f270f5f4788088,9,5,1,1,,,0,"Update project-team-guide groups

Use standard group names for the project-team-guide for ease of
additions/removals from group.  We may still seed the group with
TC members.

Change-Id: I3818895d098b1e74570e38d8901d2622687327b6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/189926/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/project-team-guide.config'],1,8dd5b537fb28b1c7d8c592aab5f270f5f4788088,,abandon = group project-team-guide-core label-Code-Review = -2..+2 group project-team-guide-core label-Workflow = -1..+1 group project-team-guide-corepushSignedTag = group project-team-guide-release,abandon = group tech-committee-chair label-Code-Review = -2..+2 group tech-committee label-Workflow = -1..+1 group tech-committeepushSignedTag = group tech-committee-chair,4,4
openstack%2Fproject-config~master~Id977b4e605196bafae593c4c6f59ef55d9d4f384,openstack/project-config,master,Id977b4e605196bafae593c4c6f59ef55d9d4f384,Add non-voting python34 job for glance_store,MERGED,2015-06-09 21:53:30.000000000,2015-06-10 13:49:40.000000000,2015-06-10 13:49:37.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-09 21:53:30.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/75112719a282bf3ad9030aa1e39a788981ba75f5', 'message': 'Add non-voting python34 job for glance_store\n\nChange-Id: Id977b4e605196bafae593c4c6f59ef55d9d4f384\n'}]",0,189954,75112719a282bf3ad9030aa1e39a788981ba75f5,8,4,1,11356,,,0,"Add non-voting python34 job for glance_store

Change-Id: Id977b4e605196bafae593c4c6f59ef55d9d4f384
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/189954/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,75112719a282bf3ad9030aa1e39a788981ba75f5,glance_store, - name: gate-glance_store-python34 voting: false check: - gate-glance_store-python34,,5,0
openstack%2Fproject-config~master~I562bec25df1addd1d8104811882de136eb72180f,openstack/project-config,master,I562bec25df1addd1d8104811882de136eb72180f,Add swig packages,MERGED,2015-06-09 21:02:36.000000000,2015-06-10 13:49:35.000000000,2015-06-10 13:49:32.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2015-06-09 21:02:36.000000000', 'files': ['jenkins/data/bindep-fallback.txt'], 'web_link': 'https://opendev.org/openstack/project-config/commit/81209a76d09a6e353705d4ccf958d8671378227c', 'message': ""Add swig packages\n\npython-qpid-proton does something similar to pyzmq when libzmq is not\ninstalled. It bundles the underlying library and builds it.\nUnfortunately, python-qpid-proton currently has a dependency on `swig`\nto build the python module. I'm adding swig to the list of packages to\ninstall by default.\n\nChange-Id: I562bec25df1addd1d8104811882de136eb72180f\n""}]",0,189939,81209a76d09a6e353705d4ccf958d8671378227c,9,7,1,6159,,,0,"Add swig packages

python-qpid-proton does something similar to pyzmq when libzmq is not
installed. It bundles the underlying library and builds it.
Unfortunately, python-qpid-proton currently has a dependency on `swig`
to build the python module. I'm adding swig to the list of packages to
install by default.

Change-Id: I562bec25df1addd1d8104811882de136eb72180f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/39/189939/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/data/bindep-fallback.txt'],1,81209a76d09a6e353705d4ccf958d8671378227c,,swig [platform:rpm] swig [platform:dpkg],,2,0
openstack%2Fproject-config~master~I0568ba0751f6d1a59d8bfb24de485bd4ddec0ad6,openstack/project-config,master,I0568ba0751f6d1a59d8bfb24de485bd4ddec0ad6,Announce diskimage-builder in infra channel,MERGED,2015-03-23 21:11:55.000000000,2015-06-10 13:49:31.000000000,2015-06-10 13:49:28.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6554}, {'_account_id': 7069}, {'_account_id': 7118}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-03-23 21:11:55.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c8775cf8e08ca360b3213e35c31a1443a267cf37', 'message': ""Announce diskimage-builder in infra channel\n\nPinging people in two different channels to talk about changes is\nstarting to get crazymaking. Infra uses diskimage-builder and lands\npaches to it for infra purposes. Let's watch the patches to it until\nthey become insane.\n\nChange-Id: I0568ba0751f6d1a59d8bfb24de485bd4ddec0ad6\n""}]",0,167011,c8775cf8e08ca360b3213e35c31a1443a267cf37,12,8,1,2,,,0,"Announce diskimage-builder in infra channel

Pinging people in two different channels to talk about changes is
starting to get crazymaking. Infra uses diskimage-builder and lands
paches to it for infra purposes. Let's watch the patches to it until
they become insane.

Change-Id: I0568ba0751f6d1a59d8bfb24de485bd4ddec0ad6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/11/167011/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,c8775cf8e08ca360b3213e35c31a1443a267cf37,, - openstack/diskimage-builder,,1,0
openstack%2Fproject-config~master~I1262f75c5b20ea719a195bc8cf2f47e94b453b3d,openstack/project-config,master,I1262f75c5b20ea719a195bc8cf2f47e94b453b3d,Added coverage job to Magnum,MERGED,2015-06-02 20:16:54.000000000,2015-06-10 13:49:26.000000000,2015-06-10 13:49:23.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 11536}, {'_account_id': 16051}]","[{'number': 1, 'created': '2015-06-02 20:16:54.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5a1a74fc5cf469d2d38186633791478769b13800', 'message': 'Added coverage job to Magnum\n\nChange-Id: I1262f75c5b20ea719a195bc8cf2f47e94b453b3d\n'}]",2,187753,5a1a74fc5cf469d2d38186633791478769b13800,12,7,1,16051,,,0,"Added coverage job to Magnum

Change-Id: I1262f75c5b20ea719a195bc8cf2f47e94b453b3d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/53/187753/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,5a1a74fc5cf469d2d38186633791478769b13800,magnum_coverage, post: - magnum-coverage,,2,0
openstack%2Fproject-config~master~Ie2df4a0f40e450f142c84449ed0d03f12b8786e6,openstack/project-config,master,Ie2df4a0f40e450f142c84449ed0d03f12b8786e6,Add puppet-hound module for managing hound,MERGED,2015-06-07 21:22:19.000000000,2015-06-10 13:49:21.000000000,2015-06-10 13:49:19.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6133}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-06-07 21:22:19.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack-infra/puppet-hound.config', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/31afadd6b3aef5158367bca04b0186435d047931', 'message': 'Add puppet-hound module for managing hound\n\nHound is a code-search tool that infra will run.\nThe code for this module is currently sitting around in 178488.\n\nChange-Id: Ie2df4a0f40e450f142c84449ed0d03f12b8786e6\n'}]",0,189161,31afadd6b3aef5158367bca04b0186435d047931,10,6,1,6554,,,0,"Add puppet-hound module for managing hound

Hound is a code-search tool that infra will run.
The code for this module is currently sitting around in 178488.

Change-Id: Ie2df4a0f40e450f142c84449ed0d03f12b8786e6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/189161/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack-infra/puppet-hound.config', 'zuul/layout.yaml']",5,31afadd6b3aef5158367bca04b0186435d047931,, - name: openstack-infra/puppet-hound template: - name: merge-check - name: puppet-check-jobs - name: infra-puppet-apply-jobs ,,34,0
openstack%2Fproject-config~master~I058d0622e505e8ca4268946c61e78c714c0aa025,openstack/project-config,master,I058d0622e505e8ca4268946c61e78c714c0aa025,jenkins/jobs/tripleo/puppet: drop puppet-openstack,MERGED,2015-06-09 13:35:34.000000000,2015-06-10 13:49:17.000000000,2015-06-10 13:49:15.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 7144}]","[{'number': 1, 'created': '2015-06-09 13:35:34.000000000', 'files': ['jenkins/jobs/tripleo.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d3365a8b2af51b9a5bdd70d00a175427b5ac69d4', 'message': ""jenkins/jobs/tripleo/puppet: drop puppet-openstack\n\npuppet-openstack module is not used at all by TripleO/Puppet. It's not\nuseful to have it in our OpenStack modules list.\n\nChange-Id: I058d0622e505e8ca4268946c61e78c714c0aa025\n""}]",0,189719,d3365a8b2af51b9a5bdd70d00a175427b5ac69d4,8,6,1,3153,,,0,"jenkins/jobs/tripleo/puppet: drop puppet-openstack

puppet-openstack module is not used at all by TripleO/Puppet. It's not
useful to have it in our OpenStack modules list.

Change-Id: I058d0622e505e8ca4268946c61e78c714c0aa025
",git fetch https://review.opendev.org/openstack/project-config refs/changes/19/189719/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/tripleo.yaml'],1,d3365a8b2af51b9a5bdd70d00a175427b5ac69d4,ooo-cleanup," export PROJECTS=""openstack/tripleo-puppet-elements stackforge/puppet-ceph stackforge/puppet-ceilometer stackforge/puppet-cinder stackforge/puppet-glance stackforge/puppet-heat stackforge/puppet-horizon stackforge/puppet-keystone stackforge/puppet-neutron stackforge/puppet-nova stackforge/puppet-sahara stackforge/puppet-swift stackforge/puppet-vswitch stackforge/puppet-openstacklib stackforge/puppet-tripleo stackforge/puppet-ironic stackforge/puppet-openstack_extras stackforge/puppet-tuskar"""," export PROJECTS=""openstack/tripleo-puppet-elements stackforge/puppet-ceph stackforge/puppet-ceilometer stackforge/puppet-cinder stackforge/puppet-glance stackforge/puppet-heat stackforge/puppet-horizon stackforge/puppet-keystone stackforge/puppet-neutron stackforge/puppet-nova stackforge/puppet-openstack stackforge/puppet-sahara stackforge/puppet-swift stackforge/puppet-vswitch stackforge/puppet-openstacklib stackforge/puppet-tripleo stackforge/puppet-ironic stackforge/puppet-openstack_extras stackforge/puppet-tuskar""",1,1
openstack%2Fproject-config~master~I67dceb8087d60e1bfc9d6402edcbbe5f5026fcba,openstack/project-config,master,I67dceb8087d60e1bfc9d6402edcbbe5f5026fcba,networking-ovn: Allow setting devstack-gate env vars,MERGED,2015-06-03 20:27:34.000000000,2015-06-10 13:49:13.000000000,2015-06-10 13:49:12.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6854}]","[{'number': 1, 'created': '2015-06-03 20:27:34.000000000', 'files': ['jenkins/jobs/networking-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6185ef643963c05d064429b59d9935f078a798f7', 'message': ""networking-ovn: Allow setting devstack-gate env vars\n\nI recently added the ability to have pre and post gate hook scripts in\nnetworking-ovn.  What I really wanted this for was to be able to set\nDEVSTACK_GATE_TEMPEST_REGEX in the pre hook script.  It turns out this\ndoesn't actually work like I expected.  It seems fine to leave the\nhooks for future use, but add a new call to a script to setup some env\nvars before calling devstack-gate.\n\nChange-Id: I67dceb8087d60e1bfc9d6402edcbbe5f5026fcba\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n""}]",0,188172,6185ef643963c05d064429b59d9935f078a798f7,10,6,1,1561,,,0,"networking-ovn: Allow setting devstack-gate env vars

I recently added the ability to have pre and post gate hook scripts in
networking-ovn.  What I really wanted this for was to be able to set
DEVSTACK_GATE_TEMPEST_REGEX in the pre hook script.  It turns out this
doesn't actually work like I expected.  It seems fine to leave the
hooks for future use, but add a new call to a script to setup some env
vars before calling devstack-gate.

Change-Id: I67dceb8087d60e1bfc9d6402edcbbe5f5026fcba
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/188172/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/networking-ovn.yaml'],1,6185ef643963c05d064429b59d9935f078a798f7,networking-ovn-gate-hooks, if [ -f $BASE/new/networking-ovn/devstack/setup_env.sh ] ; then . $BASE/new/networking-ovn/devstack/setup_env.sh fi ,,4,0
openstack%2Fproject-config~master~Id4295f0410b5f9f7acc568694811cd3dba6cae52,openstack/project-config,master,Id4295f0410b5f9f7acc568694811cd3dba6cae52,Disable future parser check on puppet-swift (juno),MERGED,2015-06-06 17:42:55.000000000,2015-06-10 13:49:10.000000000,2015-06-10 13:49:07.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-06-06 17:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/23107f878413818d26696af2a79a39270f66abf3', 'message': 'Disable future parser syntax check on puppet-swift\n\nThe puppet-future-syntax check runs a puppet 3 parser with the future\nparser option turned on in preparation for migrating to puppet 4.\nUnfortunately, it fails on the stable/juno branch of the puppet-swift\nmodule[1]. The fix has been committed in master[2] but cannot be\nbackported because it would break the API. The only way to continue\ndevelopment on the stable/juno branch is to disable this check and\naccept that the Juno version of the puppet-swift module is not\nfuture-parser or puppet 4 compatible.\n\n[1] http://logs.openstack.org/52/188952/1/check/gate-puppet-swift-puppet-syntax-future/1207ef3/console.html.gz#_2015-06-05_22_21_20_293\n[2] https://review.openstack.org/#/c/137187/\n\nChange-Id: Id4295f0410b5f9f7acc568694811cd3dba6cae52\n'}, {'number': 2, 'created': '2015-06-06 17:45:13.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/900fc2edfb303e7f244bb130e12ec22a87ff313f', 'message': 'Disable future parser check on puppet-swift (juno)\n\nThe puppet-future-syntax check runs a puppet 3 parser with the future\nparser option turned on in preparation for migrating to puppet 4.\nUnfortunately, it fails on the stable/juno branch of the puppet-swift\nmodule[1]. The fix has been committed in master[2] but cannot be\nbackported because it would break the API. The only way to continue\ndevelopment on the stable/juno branch is to disable this check and\naccept that the Juno version of the puppet-swift module is not\nfuture-parser or puppet 4 compatible.\n\n[1] http://logs.openstack.org/52/188952/1/check/gate-puppet-swift-puppet-syntax-future/1207ef3/console.html.gz#_2015-06-05_22_21_20_293\n[2] https://review.openstack.org/#/c/137187/\n\nChange-Id: Id4295f0410b5f9f7acc568694811cd3dba6cae52\n'}]",0,189033,900fc2edfb303e7f244bb130e12ec22a87ff313f,13,6,2,8482,,,0,"Disable future parser check on puppet-swift (juno)

The puppet-future-syntax check runs a puppet 3 parser with the future
parser option turned on in preparation for migrating to puppet 4.
Unfortunately, it fails on the stable/juno branch of the puppet-swift
module[1]. The fix has been committed in master[2] but cannot be
backported because it would break the API. The only way to continue
development on the stable/juno branch is to disable this check and
accept that the Juno version of the puppet-swift module is not
future-parser or puppet 4 compatible.

[1] http://logs.openstack.org/52/188952/1/check/gate-puppet-swift-puppet-syntax-future/1207ef3/console.html.gz#_2015-06-05_22_21_20_293
[2] https://review.openstack.org/#/c/137187/

Change-Id: Id4295f0410b5f9f7acc568694811cd3dba6cae52
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/189033/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,23107f878413818d26696af2a79a39270f66abf3,disable_future_syntax_on_puppet-swift, - name: ^gate-puppet-((?!swift).)*-puppet-syntax-future$ # puppet-swift can never be future parser compatible without breaking the API - name: ^gate-puppet-swift-puppet-syntax-future$ branch: ^(?!stable/(havana|icehouse|juno)).*$ , - name: ^gate-puppet-.*-puppet-syntax-future$,5,1
openstack%2Fproject-config~master~Ia864b2825bc2fa0924bb3e9ff45e2fa2dd7c2ec8,openstack/project-config,master,Ia864b2825bc2fa0924bb3e9ff45e2fa2dd7c2ec8,Create repo for oslo.reports,MERGED,2015-06-03 19:14:25.000000000,2015-06-10 13:48:59.000000000,2015-06-10 13:48:57.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 7677}, {'_account_id': 11809}]","[{'number': 1, 'created': '2015-06-03 19:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1b5044123446d4ab5c28f477711f9e16fd75e1b6', 'message': 'Create repor for oslo.reports\n\nblueprint graduate-oslo-reports\n\nChange-Id: Ia864b2825bc2fa0924bb3e9ff45e2fa2dd7c2ec8\n'}, {'number': 2, 'created': '2015-06-03 19:15:37.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack/oslo.reports.config', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5e7562cc36c2e348c77eecb4d5c2c8e0fe026f35', 'message': 'Create repo for oslo.reports\n\nblueprint graduate-oslo-reports\n\nChange-Id: Ia864b2825bc2fa0924bb3e9ff45e2fa2dd7c2ec8\n'}]",0,188150,5e7562cc36c2e348c77eecb4d5c2c8e0fe026f35,15,6,2,7677,,,0,"Create repo for oslo.reports

blueprint graduate-oslo-reports

Change-Id: Ia864b2825bc2fa0924bb3e9ff45e2fa2dd7c2ec8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/188150/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack/oslo.reports.config', 'zuul/layout.yaml']",5,1b5044123446d4ab5c28f477711f9e16fd75e1b6,new-project, - name: openstack/oslo.reports template: - name: merge-check - name: python-jobs - name: python3-jobs - name: openstack-server-publish-jobs - name: check-requirements - name: publish-to-pypi - name: lib-forward-testing ,,47,0
openstack%2Ffuel-library~master~Ibec45e3816774b9a4d7c1ce67b699cbff0cdf9ab,openstack/fuel-library,master,Ibec45e3816774b9a4d7c1ce67b699cbff0cdf9ab,Sync puppet concat module to v1.2.2 from upstream,ABANDONED,2015-05-15 16:46:57.000000000,2015-06-10 13:45:43.000000000,,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-05-15 16:46:57.000000000', 'files': ['deployment/puppet/concat/.fixtures.yml', 'deployment/puppet/concat/spec/spec.opts', 'deployment/puppet/concat/spec/acceptance/nodesets/centos-64-x64.yml', 'deployment/puppet/concat/lib/puppet/parser/functions/concat_getparam.rb', 'deployment/puppet/concat/spec/acceptance/fragments_are_always_replaced_spec.rb', 'deployment/puppet/concat/spec/acceptance/validation_spec.rb', 'deployment/puppet/concat/spec/spec_helper_acceptance.rb', 'deployment/puppet/concat/Modulefile', 'deployment/puppet/concat/spec/unit/classes/concat_setup_spec.rb', 'deployment/puppet/concat/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/concat/spec/unit/defines/concat_fragment_spec.rb', 'deployment/puppet/concat/.gitignore', 'deployment/puppet/concat/spec/acceptance/nodesets/default.yml', 'deployment/puppet/concat/spec/acceptance/deprecation_warnings_spec.rb', 'deployment/puppet/concat/files/concatfragments.sh', 'deployment/puppet/concat/manifests/init.pp', 'deployment/puppet/concat/CHANGELOG.md', 'deployment/puppet/concat/Gemfile', 'deployment/puppet/concat/spec/unit/defines/concat_spec.rb', 'deployment/puppet/concat/CONTRIBUTING.md', 'deployment/puppet/concat/spec/acceptance/specinfra_stubs.rb', 'deployment/puppet/concat/spec/acceptance/order_spec.rb', 'deployment/puppet/concat/manifests/fragment.pp', 'deployment/puppet/concat/manifests/setup.pp', 'deployment/puppet/concat/Rakefile', 'deployment/puppet/concat/spec/acceptance/concat_spec.rb', 'deployment/puppet/concat/spec/acceptance/fragment_source_spec.rb', 'deployment/puppet/concat/.sync.yml', 'deployment/puppet/concat/spec/acceptance/nodesets/fedora-18-x64.yml', 'deployment/puppet/concat/spec/acceptance/warn_spec.rb', 'deployment/puppet/concat/spec/acceptance/replace_spec.rb', 'deployment/puppet/concat/spec/acceptance/symbolic_name_spec.rb', 'deployment/puppet/concat/spec/acceptance/empty_spec.rb', 'deployment/puppet/concat/spec/acceptance/newline_spec.rb', 'deployment/puppet/concat/spec/acceptance/backup_spec.rb', 'deployment/puppet/concat/metadata.json', 'deployment/puppet/concat/.travis.yml', 'deployment/puppet/concat/README.md', 'deployment/puppet/concat/spec/acceptance/quoted_paths_spec.rb', 'deployment/puppet/concat/lib/puppet/parser/functions/concat_is_bool.rb', 'deployment/puppet/concat/files/concatfragments.rb', 'deployment/puppet/concat/CHANGELOG'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a88133ce10057c66b7ea34ba20ad409a07814d41', 'message': 'Sync puppet concat module to v1.2.2 from upstream\n\nv1.2.2 sha1: 2d5734c2976933dd5332059c503cc92ee23121fd\n\nConcat 1.1.0 has idempotancy bug described at\nhttps://tickets.puppetlabs.com/browse/MODULES-1311. Due to this bug\napache restarts everytime when we invoke radosgw granule\n\nPartial-Bug: 1455389\n\nChange-Id: Ibec45e3816774b9a4d7c1ce67b699cbff0cdf9ab\nSigned-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>\n'}]",0,183603,a88133ce10057c66b7ea34ba20ad409a07814d41,36,16,1,11090,,,0,"Sync puppet concat module to v1.2.2 from upstream

v1.2.2 sha1: 2d5734c2976933dd5332059c503cc92ee23121fd

Concat 1.1.0 has idempotancy bug described at
https://tickets.puppetlabs.com/browse/MODULES-1311. Due to this bug
apache restarts everytime when we invoke radosgw granule

Partial-Bug: 1455389

Change-Id: Ibec45e3816774b9a4d7c1ce67b699cbff0cdf9ab
Signed-off-by: Sergii Golovatiuk <sgolovatiuk@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/03/183603/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/concat/.fixtures.yml', 'deployment/puppet/concat/spec/spec.opts', 'deployment/puppet/concat/spec/acceptance/nodesets/centos-64-x64.yml', 'deployment/puppet/concat/lib/puppet/parser/functions/concat_getparam.rb', 'deployment/puppet/concat/spec/acceptance/fragments_are_always_replaced_spec.rb', 'deployment/puppet/concat/spec/acceptance/validation_spec.rb', 'deployment/puppet/concat/spec/spec_helper_acceptance.rb', 'deployment/puppet/concat/Modulefile', 'deployment/puppet/concat/spec/unit/classes/concat_setup_spec.rb', 'deployment/puppet/concat/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/concat/spec/unit/defines/concat_fragment_spec.rb', 'deployment/puppet/concat/.gitignore', 'deployment/puppet/concat/spec/acceptance/nodesets/default.yml', 'deployment/puppet/concat/spec/acceptance/deprecation_warnings_spec.rb', 'deployment/puppet/concat/files/concatfragments.sh', 'deployment/puppet/concat/manifests/init.pp', 'deployment/puppet/concat/CHANGELOG.md', 'deployment/puppet/concat/Gemfile', 'deployment/puppet/concat/spec/unit/defines/concat_spec.rb', 'deployment/puppet/concat/CONTRIBUTING.md', 'deployment/puppet/concat/spec/acceptance/specinfra_stubs.rb', 'deployment/puppet/concat/spec/acceptance/order_spec.rb', 'deployment/puppet/concat/manifests/fragment.pp', 'deployment/puppet/concat/manifests/setup.pp', 'deployment/puppet/concat/Rakefile', 'deployment/puppet/concat/spec/acceptance/concat_spec.rb', 'deployment/puppet/concat/spec/acceptance/fragment_source_spec.rb', 'deployment/puppet/concat/.sync.yml', 'deployment/puppet/concat/spec/acceptance/nodesets/fedora-18-x64.yml', 'deployment/puppet/concat/spec/acceptance/warn_spec.rb', 'deployment/puppet/concat/spec/acceptance/replace_spec.rb', 'deployment/puppet/concat/spec/acceptance/symbolic_name_spec.rb', 'deployment/puppet/concat/spec/acceptance/empty_spec.rb', 'deployment/puppet/concat/spec/acceptance/newline_spec.rb', 'deployment/puppet/concat/spec/acceptance/backup_spec.rb', 'deployment/puppet/concat/metadata.json', 'deployment/puppet/concat/.travis.yml', 'deployment/puppet/concat/README.md', 'deployment/puppet/concat/spec/acceptance/quoted_paths_spec.rb', 'deployment/puppet/concat/lib/puppet/parser/functions/concat_is_bool.rb', 'deployment/puppet/concat/files/concatfragments.rb', 'deployment/puppet/concat/CHANGELOG']",42,a88133ce10057c66b7ea34ba20ad409a07814d41,bug/1455389,,"2014-05-14 1.1.0 Summary This release is primarily a bugfix release since 1.1.0-rc1. Features: - Improved testing, with tests moved to beaker Bugfixes: - No longer attempts to set fragment owner and mode on Windows - Fix numeric sorting - Fix incorrect quoting - Fix newlines 2014-01-03 1.1.0-rc1 Summary: This release of concat was 90% written by Joshua Hoblitt, and the module team would like to thank him for the huge amount of work he put into this release. This module deprecates a bunch of old parameters and usage patterns, modernizes much of the manifest code, simplifies a whole bunch of logic and makes improvements to almost all parts of the module. The other major feature is windows support, courtesy of luisfdez, with an alternative version of the concat bash script in ruby. We've attempted to ensure that there are no backwards incompatible changes, all users of 1.0.0 should be able to use 1.1.0 without any failures, but you may find deprecation warnings and we'll be aggressively moving for a 2.0 to remove those too. For further information on deprecations, please read: https://github.com/puppetlabs/puppetlabs-concat/blob/master/README.md#api-deprecations Removed: - Puppet 0.24 support. - Filebucket backup of all file resources except the target concatenated file. - Default owner/user/group values. - Purging of long unused /usr/local/bin/concatfragments.sh Features: - Windows support via a ruby version of the concat bash script. - Huge amount of acceptance testing work added. - Documentation (README) completely rewritten. - New parameters in concat: - `ensure`: Controls if the file should be present/absent at all. - Remove requirement to include concat::setup in manifests. - Made `gnu` parameter deprecated. - Added parameter validation. Bugfixes: - Ensure concat::setup runs before concat::fragment in all cases. - Pluginsync references updated for modern Puppet. - Fix incorrect group parameter. - Use $owner instead of $id to avoid confusion with $::id - Compatibility fixes for Puppet 2.7/ruby 1.8.7 - Use LC_ALL=C instead of LANG=C - Always exec the concatfragments script as root when running as root. - Syntax and other cleanup changes. 2013-08-09 1.0.0 Summary: Many new features and bugfixes in this release, and if you're a heavy concat user you should test carefully before upgrading. The features should all be backwards compatible but only light testing has been done from our side before this release. Features: - New parameters in concat: - `replace`: specify if concat should replace existing files. - `ensure_newline`: controls if fragments should contain a newline at the end. - Improved README documentation. - Add rspec:system tests (rake spec:system to test concat) Bugfixes - Gracefully handle \n in a fragment resource name. - Adding more helpful message for 'pluginsync = true' - Allow passing `source` and `content` directly to file resource, rather than defining resource defaults. - Added -r flag to read so that filenames with \ will be read correctly. - sort always uses LANG=C. - Allow WARNMSG to contain/start with '#'. - Replace while-read pattern with for-do in order to support Solaris. CHANGELOG: - 2010/02/19 - initial release - 2010/03/12 - add support for 0.24.8 and newer - make the location of sort configurable - add the ability to add shell comment based warnings to top of files - add the ablity to create empty files - 2010/04/05 - fix parsing of WARN and change code style to match rest of the code - Better and safer boolean handling for warn and force - Don't use hard coded paths in the shell script, set PATH top of the script - Use file{} to copy the result and make all fragments owned by root. This means we can chnage the ownership/group of the resulting file at any time. - You can specify ensure => ""/some/other/file"" in concat::fragment to include the contents of a symlink into the final file. - 2010/04/16 - Add more cleaning of the fragment name - removing / from the $name - 2010/05/22 - Improve documentation and show the use of ensure => - 2010/07/14 - Add support for setting the filebucket behavior of files - 2010/10/04 - Make the warning message configurable - 2010/12/03 - Add flags to make concat work better on Solaris - thanks Jonathan Boyett - 2011/02/03 - Make the shell script more portable and add a config option for root group - 2011/06/21 - Make base dir root readable only for security - 2011/06/23 - Set base directory using a fact instead of hardcoding it - 2011/06/23 - Support operating as non privileged user - 2011/06/23 - Support dash instead of bash or sh - 2011/07/11 - Better solaris support - 2011/12/05 - Use fully qualified variables - 2011/12/13 - Improve Nexenta support - 2012/04/11 - Do not use any GNU specific extensions in the shell script - 2012/03/24 - Comply to community style guides - 2012/05/23 - Better errors when basedir isnt set - 2012/05/31 - Add spec tests - 2012/07/11 - Include concat::setup in concat improving UX - 2012/08/14 - Puppet Lint improvements - 2012/08/30 - The target path can be different from the $name - 2012/08/30 - More Puppet Lint cleanup - 2012/09/04 - RELEASE 0.2.0 - 2012/12/12 - Added (file) $replace parameter to concat ",2002,1236
openstack%2Foslo.messaging~master~Ia40b7733bd2e74b1a1703f2e1a5245f01debbd36,openstack/oslo.messaging,master,Ia40b7733bd2e74b1a1703f2e1a5245f01debbd36,"Get mox from mox3, not from six.moves",MERGED,2015-06-10 11:47:41.000000000,2015-06-10 13:38:48.000000000,2015-06-10 13:38:47.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-06-10 11:47:41.000000000', 'files': ['oslo_messaging/tests/test_transport.py', 'tests/test_transport.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2e5ba4538edc08424bea12e0fc0bad54578d8b3e', 'message': ""Get mox from mox3, not from six.moves\n\noslotest 1.7.0 breakes oslo.messaging unittests, because it doesn't add\nmox to six.moves anymore - see change Ic59c73abb9b09cb594bf7df4173d7f99f81d526c\n\nThis patch fixes imports on test run.\n\nChange-Id: Ia40b7733bd2e74b1a1703f2e1a5245f01debbd36\n""}]",0,190136,2e5ba4538edc08424bea12e0fc0bad54578d8b3e,7,3,1,7491,,,0,"Get mox from mox3, not from six.moves

oslotest 1.7.0 breakes oslo.messaging unittests, because it doesn't add
mox to six.moves anymore - see change Ic59c73abb9b09cb594bf7df4173d7f99f81d526c

This patch fixes imports on test run.

Change-Id: Ia40b7733bd2e74b1a1703f2e1a5245f01debbd36
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/36/190136/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/test_transport.py', 'tests/test_transport.py']",2,2e5ba4538edc08424bea12e0fc0bad54578d8b3e,,from mox3 import mox,from six.moves import mox,2,2
openstack%2Fmurano~master~I15dab7dd3d8de48f123e9eb8906901a2e29356a3,openstack/murano,master,I15dab7dd3d8de48f123e9eb8906901a2e29356a3,Add note to docs that hash is not used in images.lst,MERGED,2015-05-21 15:41:56.000000000,2015-06-10 13:37:55.000000000,2015-06-10 13:37:54.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-05-21 15:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/e9003995d2f2cb241e9f66624d870e19e9438c04', 'message': 'Add note to docs that hash is not used in images.lst\n\nChange-Id: I15dab7dd3d8de48f123e9eb8906901a2e29356a3\n'}, {'number': 2, 'created': '2015-06-04 14:07:24.000000000', 'files': ['doc/source/articles/app_pkg.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/181ccac40f54121b1b71ef981198169c40c76585', 'message': 'Add note to docs that hash is not used in images.lst\n\nChange-Id: I15dab7dd3d8de48f123e9eb8906901a2e29356a3\n'}]",2,184805,181ccac40f54121b1b71ef981198169c40c76585,25,7,2,7549,,,0,"Add note to docs that hash is not used in images.lst

Change-Id: I15dab7dd3d8de48f123e9eb8906901a2e29356a3
",git fetch https://review.opendev.org/openstack/murano refs/changes/05/184805/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/articles/app_pkg.rst'],1,e9003995d2f2cb241e9f66624d870e19e9438c04,bug/1443936," title: 'This Name Helps Me Select This Image' title: 'This Name Helps Me Select This Image'.. note :: ``Hash`` key is ignored right now. It produces a situation, when there are two images with the same name (but with different hashes).If image name is written in the app definition, heat would not be able to create the template, based on that definition. ", title: 'tef' title: 'tef',9,2
openstack%2Fglance~master~Ib332b7f84d4afe11a30bd9b00a358fd37f3e1bc5,openstack/glance,master,Ib332b7f84d4afe11a30bd9b00a358fd37f3e1bc5,Sync with latest oslo-incubator,MERGED,2015-06-07 14:06:17.000000000,2015-06-10 13:35:36.000000000,2015-06-10 13:35:34.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11356}, {'_account_id': 11391}]","[{'number': 1, 'created': '2015-06-07 14:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0eaef0c791df8352c53fcd8f40cba70ba15cc803', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: Ib332b7f84d4afe11a30bd9b00a358fd37f3e1bc5\n'}, {'number': 2, 'created': '2015-06-10 11:10:21.000000000', 'files': ['glance/openstack/common/threadgroup.py', 'glance/openstack/common/service.py', 'openstack-common.conf', 'glance/openstack/common/loopingcall.py', 'glance/openstack/common/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1665eb1af4ba2a181a22d8293f0955053dafe316', 'message': 'Sync with latest oslo-incubator\n\nPeriodic sync with latest oslo-incubator code\n\nChange-Id: Ib332b7f84d4afe11a30bd9b00a358fd37f3e1bc5'}]",0,189107,1665eb1af4ba2a181a22d8293f0955053dafe316,10,4,2,5638,,,0,"Sync with latest oslo-incubator

Periodic sync with latest oslo-incubator code

Change-Id: Ib332b7f84d4afe11a30bd9b00a358fd37f3e1bc5",git fetch https://review.opendev.org/openstack/glance refs/changes/07/189107/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/openstack/common/threadgroup.py', 'glance/openstack/common/service.py', 'openstack-common.conf', 'glance/openstack/common/loopingcall.py', 'glance/openstack/common/eventlet_backdoor.py']",5,0eaef0c791df8352c53fcd8f40cba70ba15cc803,," _LI('Eventlet backdoor listening on %(port)s for process %(pid)d'),", _LI('Eventlet backdoor listening on %(port)s for process %(pid)d') %,45,33
openstack%2Fsenlin~master~Ia43d26514efbfc69d935e1b26476d64f0e74d4c2,openstack/senlin,master,Ia43d26514efbfc69d935e1b26476d64f0e74d4c2,Test cases for engine scheduler module,MERGED,2015-06-01 07:13:13.000000000,2015-06-10 13:34:33.000000000,2015-06-10 13:34:31.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-01 07:13:13.000000000', 'files': ['senlin/engine/scheduler.py', 'senlin/tests/test_scheduler.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3c40a8e0a36ce90c135e04d2ee1eedc67b6c7282', 'message': ""Test cases for engine scheduler module\n\nThis patch adds unit test cases for the engine scheduler module. Maybe\nwe should call the 'scheduler' a 'thread_group_manager' or something\nalike because it is not doing any scheduling at the moment.\n\nThis patch also deleted the 'action_wait' method which 1) is not used\nanywhere 2) the implementation is buggy.\n\nChange-Id: Ia43d26514efbfc69d935e1b26476d64f0e74d4c2\n""}]",0,187121,3c40a8e0a36ce90c135e04d2ee1eedc67b6c7282,6,2,1,8246,,,0,"Test cases for engine scheduler module

This patch adds unit test cases for the engine scheduler module. Maybe
we should call the 'scheduler' a 'thread_group_manager' or something
alike because it is not doing any scheduling at the moment.

This patch also deleted the 'action_wait' method which 1) is not used
anywhere 2) the implementation is buggy.

Change-Id: Ia43d26514efbfc69d935e1b26476d64f0e74d4c2
",git fetch https://review.opendev.org/openstack/senlin refs/changes/21/187121/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/scheduler.py', 'senlin/tests/test_scheduler.py']",2,3c40a8e0a36ce90c135e04d2ee1eedc67b6c7282,test-scheduler,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import eventlet import mock from oslo_config import cfg from senlin.engine.actions import base as actionm from senlin.engine import scheduler from senlin.openstack.common import threadgroup from senlin.tests.common import base from senlin.tests.common import utils class DummyThread(object): def __init__(self, function, *args, **kwargs): self.function = function def link(self, callback, *args): callback(self, *args) class DummyThreadGroup(object): def __init__(self): self.threads = [] def add_timer(self, interval, callback, initial_delay=None, *args, **kwargs): self.threads.append(callback) def stop_timers(self): pass def add_thread(self, callback, *args, **kwargs): callback = args[1] self.threads.append(callback) return DummyThread() def stop(self, graceful=False): pass def wait(self): pass class SchedulerTest(base.SenlinTestCase): def setUp(self): super(SchedulerTest, self).setUp() self.fake_tg = DummyThreadGroup() self.mock_tg = self.patchobject(threadgroup, 'ThreadGroup') self.mock_tg.return_value = self.fake_tg self.context = utils.dummy_context() def test_create(self): tgm = scheduler.ThreadGroupManager() self.assertEqual({}, tgm.workers) mock_group = mock.Mock() self.mock_tg.return_value = mock_group tgm = scheduler.ThreadGroupManager() mock_group.add_timer.assert_called_once_with( cfg.CONF.periodic_interval, tgm._service_task) def test_start(self): def f(): pass mock_group = mock.Mock() self.mock_tg.return_value = mock_group tgm = scheduler.ThreadGroupManager() tgm.start(f) mock_group.add_thread.assert_called_once_with(f) def test_start_action(self): mock_group = mock.Mock() self.mock_tg.return_value = mock_group tgm = scheduler.ThreadGroupManager() tgm.start_action(self.context, '0123', '4567') mock_group.add_thread.assert_called_once_with(actionm.ActionProc, self.context, '0123', '4567') mock_thread = mock_group.add_thread.return_value self.assertEqual(mock_thread, tgm.workers['0123']) mock_thread.link.assert_called_once_with(mock.ANY, self.context, '0123') def test_cancel_action(self): mock_action = mock.Mock() mock_load = self.patchobject(actionm.Action, 'load', return_value=mock_action) tgm = scheduler.ThreadGroupManager() tgm.cancel_action(self.context, 'action0123') mock_load.assert_called_once_with(self.context, 'action0123') mock_action.signal.assert_called_once_with(self.context, mock_action.SIG_CANCEL) def test_suspend_action(self): mock_action = mock.Mock() mock_load = self.patchobject(actionm.Action, 'load', return_value=mock_action) tgm = scheduler.ThreadGroupManager() tgm.suspend_action(self.context, 'action0123') mock_load.assert_called_once_with(self.context, 'action0123') mock_action.signal.assert_called_once_with(self.context, mock_action.SIG_SUSPEND) def test_resume_action(self): mock_action = mock.Mock() mock_load = self.patchobject(actionm.Action, 'load', return_value=mock_action) tgm = scheduler.ThreadGroupManager() tgm.resume_action(self.context, 'action0123') mock_load.assert_called_once_with(self.context, 'action0123') mock_action.signal.assert_called_once_with(self.context, mock_action.SIG_RESUME) def test_add_timer(self): def f(): pass tgm = scheduler.ThreadGroupManager() tgm.add_timer(10, f) # The first element is the '_service_task' self.assertEqual(2, len(self.fake_tg.threads)) self.assertEqual(f, self.fake_tg.threads[1]) def test_stop_timer(self): mock_group = mock.Mock() self.mock_tg.return_value = mock_group tgm = scheduler.ThreadGroupManager() tgm.stop_timers() mock_group.stop_timers.assert_called_once_with() def test_stop(self): def f(): pass mock_group = mock.Mock() self.mock_tg.return_value = mock_group tgm = scheduler.ThreadGroupManager() mock_group.threads = [ DummyThread(tgm._service_task), DummyThread(f) ] tgm.start(f) tgm.stop() mock_group.stop.assert_called_once_with(False) mock_group.wait.assert_called_once_with() def test_reschedule(self): action = mock.Mock() action.id = '0123' mock_sleep = self.patchobject(eventlet, 'sleep') scheduler.reschedule(action) mock_sleep.assert_called_once_with(1) mock_sleep.reset_mock() scheduler.reschedule(action, None) self.assertEqual(0, mock_sleep.call_count) def test_sleep(self): mock_sleep = self.patchobject(eventlet, 'sleep') scheduler.sleep(1) mock_sleep.assert_called_once_with(1) ",,203,22
openstack%2Fironic-specs~master~I443d969638ce56beb5bc9b8484b65fdac4bc469a,openstack/ironic-specs,master,I443d969638ce56beb5bc9b8484b65fdac4bc469a,iPXE dynamic configuration,MERGED,2015-04-27 11:47:02.000000000,2015-06-10 13:33:21.000000000,2015-06-10 13:33:19.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10380}, {'_account_id': 13295}, {'_account_id': 13362}, {'_account_id': 13997}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-04-27 11:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ffdee57c2cc4e682566a300d8c28802b58a75e43', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}, {'number': 2, 'created': '2015-04-27 11:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/57e90c8a3f434c311ef8dfadf0b66244018654d9', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}, {'number': 3, 'created': '2015-05-08 13:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a7773fb09592e94968dccac3111d8eca8aa64187', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}, {'number': 4, 'created': '2015-05-08 16:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/09499ef4243e2c2e18ca50fba234f690bc0aabdb', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}, {'number': 5, 'created': '2015-05-25 11:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/982a195abce6251305397b75e5451af6c8ad4ecf', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}, {'number': 6, 'created': '2015-05-25 11:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/0ed181a23bc5dd0ab7fe276cb8b5c251df94e926', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}, {'number': 7, 'created': '2015-06-09 09:53:59.000000000', 'files': ['specs/liberty/ipxe-dynamic-config.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e6e4a04b109904060cdcd5abf9985224094097ae', 'message': 'iPXE dynamic configuration\n\nThis blueprint adds support for dynamically generating iPXE configuration\nfiles when booting a node.\n\nChange-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a\n'}]",35,177726,e6e4a04b109904060cdcd5abf9985224094097ae,46,10,7,6773,,,0,"iPXE dynamic configuration

This blueprint adds support for dynamically generating iPXE configuration
files when booting a node.

Change-Id: I443d969638ce56beb5bc9b8484b65fdac4bc469a
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/26/177726/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/ipxe-dynamic-config.rst'],1,ffdee57c2cc4e682566a300d8c28802b58a75e43,bp/adds,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================== iPXE Dynamic Configuration ========================== https://blueprints.launchpad.net/ironic/+spec/ipxe-dynamic-config This blueprint adds support for dynamically generating iPXE configuration files when booting a node. Problem description =================== The current iPXE support depends on configuration files to be cached in the disk. This creates a dependency between a given ``ironic-conductor`` and a given node (even without a conductor lock on a node) because that ``ironic-conductor`` is the only one able to boot that node. This also makes take-over more complicated because the new ``ironic-conductor`` will need to regenerate the iPXE configuration files for the new nodes it's now managing and update the DHCP server accordingly. Proposed change =============== The proposed implementation consists in creating a new ``Vendor Passthru`` method called ``ipxe_config`` that will dynamically generate the iPXE configuration files for a given node depending on it's provision state. When iPXE is enabled, it will configure the DHCP server to make a request to the ``Vendor Passthru`` endpoint when booting the node, e.g:: http://<Ironic API Address>:6385/v1/nodes/<uuid>/vendor_passthru/ipxe_config Ironic will then check the ``provision_state`` of the node and generate the iPXE configuration file for that state. Say, the node ``provision_state`` is DEPLOYING, we then will return an iPXE configuration to boot the deploy ramdisk and kernel. If the node ``provision_state`` is ACTIVE, we then return an iPXE configuration to boot from the image ramdisk and kernel (If local boot and/or full disk image is not specified). For unknown ``provision_state`` we just return an iPXE configuration file that prints out an error explaining the problem. This work can get even more powerful when the images are set to boot from ``http`` [#]_, then the iPXE drive won't need to save any state in the disk. As a future work, it would be also possible to add support for creating a ``Swift Temporary URL`` when booting images being served by ``Glance`` with a ``Swift`` storage backend. Alternatives ------------ Continue doing what we are doing, generate the configuration files and saving it in the disk. Data model impact ----------------- None State Machine Impact -------------------- None REST API impact --------------- A new ``Vendor Passthru`` method called ``ipxe_config`` that supports GET HTTP. RPC API impact -------------- Currently the RPC method for ``vendor_passthru`` and ``driver_vendor_passthru`` returns a tuple with the return value and a boolean indicating if the method is asynchronous. We will need another flag to indicate if the value should be returned as a static file that will be served by the Ironic API instead of a response body message. Driver API impact ----------------- None Nova driver impact ------------------ None Security impact --------------- The new ``Vendor Passthru`` method endpoint needs to be part of the public API, so that iPXE can get the configuration file from without authentication. This is the same as the methods ``heartbeat`` or ``lookup`` for the agent driver [#]_. Other end user impact --------------------- None Scalability impact ------------------ A stateless driver can scale much nicer since it won't depend on any information to be saved in the local conductor. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: lucasagomes Other contributors: Work Items ---------- * Create the new ``ipxe_config`` method for the PXEVendorPassthru interface. * Extend the ``vendor_passthru`` and ``driver_vendor_passthru`` RPC methods to return a flag indicating whether the return value should be attached to the response object as a file or returned as a response message. Dependencies ============ None Testing ======= Unittests will be added. Upgrades and Backwards Compatibility ==================================== None Documentation Impact ==================== The iPXE documentation will be updated to reflect the changes made by this spec. References ========== .. [#] http://specs.openstack.org/openstack/ironic-specs/specs/kilo/non-glance-image-refs.html .. [#] https://github.com/openstack/ironic/blob/master/ironic/api/config.py ",,176,0
openstack%2Fdevstack-gate~master~Ia3ea9c2216b93febd20c91a31acc34069ccf56a6,openstack/devstack-gate,master,Ia3ea9c2216b93febd20c91a31acc34069ccf56a6,Handle the case of REMAINING_TIME <= 0,MERGED,2015-04-28 04:58:39.000000000,2015-06-10 13:31:53.000000000,2015-06-10 13:31:52.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-04-28 04:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/4de574992c86a4981badc2b50659e4cde45b9bf1', 'message': ""Handle the case of REMAINING_TIME <= 0\n\nhttp://logs.openstack.org/56/160856/7/check/gate-tempest-dsvm-large-ops/513c4cb/console.html#_2015-04-28_03_55_09_639\n\n2015-04-28 03:55:09.638 | + remaining_time\n2015-04-28 03:55:09.638 | ++ date +%s\n2015-04-28 03:55:09.639 | + local now=1430193309\n2015-04-28 03:55:09.639 | + local elapsed=57\n2015-04-28 03:55:09.639 | + REMAINING_TIME=-2\n2015-04-28 03:55:09.639 | + echo 'Job timeout set to: -2 minutes'\n2015-04-28 03:55:09.639 | Job timeout set to: -2 minutes\n2015-04-28 03:55:09.640 | + timeout -s 9 -2m /opt/stack/new/devstack-gate/devstack-vm-gate.sh\n2015-04-28 03:55:09.660 | timeout: invalid option -- '2'\n2015-04-28 03:55:09.660 | Try 'timeout --help' for more information.\n\nChange-Id: Ia3ea9c2216b93febd20c91a31acc34069ccf56a6\n""}, {'number': 2, 'created': '2015-05-12 01:48:34.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/fa64acd0dc2ae37e05d43a0ea984cf7ae3861cff', 'message': ""Handle the case of REMAINING_TIME <= 0\n\nhttp://logs.openstack.org/56/160856/7/check/gate-tempest-dsvm-large-ops/513c4cb/console.html#_2015-04-28_03_55_09_639\n\n2015-04-28 03:55:09.638 | + remaining_time\n2015-04-28 03:55:09.638 | ++ date +%s\n2015-04-28 03:55:09.639 | + local now=1430193309\n2015-04-28 03:55:09.639 | + local elapsed=57\n2015-04-28 03:55:09.639 | + REMAINING_TIME=-2\n2015-04-28 03:55:09.639 | + echo 'Job timeout set to: -2 minutes'\n2015-04-28 03:55:09.639 | Job timeout set to: -2 minutes\n2015-04-28 03:55:09.640 | + timeout -s 9 -2m /opt/stack/new/devstack-gate/devstack-vm-gate.sh\n2015-04-28 03:55:09.660 | timeout: invalid option -- '2'\n2015-04-28 03:55:09.660 | Try 'timeout --help' for more information.\n\nChange-Id: Ia3ea9c2216b93febd20c91a31acc34069ccf56a6\n""}]",0,178043,fa64acd0dc2ae37e05d43a0ea984cf7ae3861cff,15,6,2,6854,,,0,"Handle the case of REMAINING_TIME <= 0

http://logs.openstack.org/56/160856/7/check/gate-tempest-dsvm-large-ops/513c4cb/console.html#_2015-04-28_03_55_09_639

2015-04-28 03:55:09.638 | + remaining_time
2015-04-28 03:55:09.638 | ++ date +%s
2015-04-28 03:55:09.639 | + local now=1430193309
2015-04-28 03:55:09.639 | + local elapsed=57
2015-04-28 03:55:09.639 | + REMAINING_TIME=-2
2015-04-28 03:55:09.639 | + echo 'Job timeout set to: -2 minutes'
2015-04-28 03:55:09.639 | Job timeout set to: -2 minutes
2015-04-28 03:55:09.640 | + timeout -s 9 -2m /opt/stack/new/devstack-gate/devstack-vm-gate.sh
2015-04-28 03:55:09.660 | timeout: invalid option -- '2'
2015-04-28 03:55:09.660 | Try 'timeout --help' for more information.

Change-Id: Ia3ea9c2216b93febd20c91a31acc34069ccf56a6
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/43/178043/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,4de574992c86a4981badc2b50659e4cde45b9bf1,remaining_time," if [ ${REMAINING_TIME} -le 0 ]; then echo ""Already timed out."" exit 1 fi",,4,0
openstack%2Fglance~master~I71a3cc3ed6bf14f3c0273df053667f1cbf99e98f,openstack/glance,master,I71a3cc3ed6bf14f3c0273df053667f1cbf99e98f,Fixed error message for negative values of min_disk and min_ram,MERGED,2015-06-05 07:38:25.000000000,2015-06-10 13:29:19.000000000,2015-06-10 13:27:15.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9096}, {'_account_id': 10485}, {'_account_id': 11391}]","[{'number': 1, 'created': '2015-06-05 07:38:25.000000000', 'files': ['glance/common/utils.py', 'glance/tests/unit/v1/test_api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/b7a29b7825799187678953a6052ce784ec285604', 'message': 'Fixed error message for negative values of min_disk and min_ram\n\nIn case of v1 api if min_disk or min_ram is passed with a negative value\nto the image create command, it returns 400 response with error message\nformatted to HTML entity.\n\nEliminated special characters (>=) from error message, so it will not\ncause any encoding issues. Also with this change the error message for\nv1 api will be identical to v2 api.\n\nCloses-Bug: 1461776\nChange-Id: I71a3cc3ed6bf14f3c0273df053667f1cbf99e98f\n'}]",0,188693,b7a29b7825799187678953a6052ce784ec285604,13,7,1,10485,,,0,"Fixed error message for negative values of min_disk and min_ram

In case of v1 api if min_disk or min_ram is passed with a negative value
to the image create command, it returns 400 response with error message
formatted to HTML entity.

Eliminated special characters (>=) from error message, so it will not
cause any encoding issues. Also with this change the error message for
v1 api will be identical to v2 api.

Closes-Bug: 1461776
Change-Id: I71a3cc3ed6bf14f3c0273df053667f1cbf99e98f
",git fetch https://review.opendev.org/openstack/glance refs/changes/93/188693/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/common/utils.py', 'glance/tests/unit/v1/test_api.py']",2,b7a29b7825799187678953a6052ce784ec285604,bug/1461776," expected = ""Cannot be a negative value."""," expected = ""Image size must be >= 0 ('-10' specified).""",2,4
openstack%2Fopenstacksdk~master~I90b29c2e48303867ae2f670643171d113e485cf1,openstack/openstacksdk,master,I90b29c2e48303867ae2f670643171d113e485cf1,Add functional tests for security groups,MERGED,2015-06-04 17:58:43.000000000,2015-06-10 13:19:15.000000000,2015-06-10 13:19:14.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}, {'_account_id': 15739}]","[{'number': 1, 'created': '2015-06-04 17:58:43.000000000', 'files': ['openstack/tests/functional/network/v2/test_security_group.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/353dc990b12647ba784ad06a23dc3e374754081a', 'message': 'Add functional tests for security groups\n\nChange-Id: I90b29c2e48303867ae2f670643171d113e485cf1\n'}]",4,188533,353dc990b12647ba784ad06a23dc3e374754081a,13,4,1,8736,,,0,"Add functional tests for security groups

Change-Id: I90b29c2e48303867ae2f670643171d113e485cf1
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/33/188533/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_security_group.py'],1,353dc990b12647ba784ad06a23dc3e374754081a,aftsg,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from openstack.network.v2 import security_group from openstack.tests.functional import base class TestSecurityGroup(base.BaseFunctionalTest): NAME = uuid.uuid4().hex ID = None @classmethod def setUpClass(cls): super(TestSecurityGroup, cls).setUpClass() sot = cls.conn.network.create_security_group(name=cls.NAME) assert isinstance(sot, security_group.SecurityGroup) cls.assertIs(cls.NAME, sot.name) cls.ID = sot.id @classmethod def tearDownClass(cls): sot = cls.conn.network.delete_security_group(cls.ID, ignore_missing=False) cls.assertIs(None, sot) def test_find(self): sot = self.conn.network.find_security_group(self.NAME) self.assertEqual(self.ID, sot.id) def test_get(self): sot = self.conn.network.get_security_group(self.ID) self.assertEqual(self.NAME, sot.name) self.assertEqual(self.ID, sot.id) def test_list(self): names = [o.name for o in self.conn.network.security_groups()] self.assertIn(self.NAME, names) ",,49,0
openstack%2Fdevstack-gate~master~I09c37b0cec3b0656da104f3ff2ad756385e9e219,openstack/devstack-gate,master,I09c37b0cec3b0656da104f3ff2ad756385e9e219,create GRENADE_PLUGINRC to pass through grenade external plugins,MERGED,2015-06-09 10:59:01.000000000,2015-06-10 13:07:53.000000000,2015-06-10 13:07:50.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 7069}]","[{'number': 1, 'created': '2015-06-09 10:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/43082bd93fe8acd3c1f3eef4eb790e32acab30dc', 'message': 'create GRENADE_PLUGINRC to pass through grenade external plugins\n\nGrenade is starting to support external plugins, this piece will be\nneeded to specify which plugins grenade should load.\n\nChange-Id: I09c37b0cec3b0656da104f3ff2ad756385e9e219\n'}, {'number': 2, 'created': '2015-06-09 17:11:53.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/36a92a283af8f1ec7b84b03995c4f6f6c9913224', 'message': 'create GRENADE_PLUGINRC to pass through grenade external plugins\n\nGrenade is starting to support external plugins, this piece will be\nneeded to specify which plugins grenade should load.\n\nThis also overwrites PLUGIN_DIR to be the same as TARGET_RELEASE_DIR\nso that we can reuse zuul checkout magic.\n\nChange-Id: I09c37b0cec3b0656da104f3ff2ad756385e9e219\n'}]",0,189652,36a92a283af8f1ec7b84b03995c4f6f6c9913224,12,5,2,2750,,,0,"create GRENADE_PLUGINRC to pass through grenade external plugins

Grenade is starting to support external plugins, this piece will be
needed to specify which plugins grenade should load.

This also overwrites PLUGIN_DIR to be the same as TARGET_RELEASE_DIR
so that we can reuse zuul checkout magic.

Change-Id: I09c37b0cec3b0656da104f3ff2ad756385e9e219
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/52/189652/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,43082bd93fe8acd3c1f3eef4eb790e32acab30dc,grenade_ext," # Create a pass through variable that can add content to the # grenade pluginrc. Needed for grenade external plugins in gate # jobs. if [[ -n ""$GRENADE_PLUGINRC"" ]]; then echo ""$GRENADE_PLUGINRC"" >>$BASE/new/grenade/pluginrc fi ",,7,0
openstack%2Fmagnum~master~I4d1c9d511c907aefbf574941df1501335a41a38b,openstack/magnum,master,I4d1c9d511c907aefbf574941df1501335a41a38b,Updated from global requirements,MERGED,2015-06-09 19:58:57.000000000,2015-06-10 13:07:13.000000000,2015-06-10 13:07:12.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 11536}]","[{'number': 1, 'created': '2015-06-09 19:58:57.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8562e5d3d8dc5cd6786143789113a6636fda429f', 'message': 'Updated from global requirements\n\nChange-Id: I4d1c9d511c907aefbf574941df1501335a41a38b\n'}]",0,189902,8562e5d3d8dc5cd6786143789113a6636fda429f,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I4d1c9d511c907aefbf574941df1501335a41a38b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/02/189902/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8562e5d3d8dc5cd6786143789113a6636fda429f,openstack/requirements,oslo.concurrency>=2.0.0 # Apache-2.0,oslo.concurrency>=1.8.0 # Apache-2.0,1,1
openstack%2Fpython-swiftclient~master~Ib5502c23b236986bea5a4d4a63a46fca411a8494,openstack/python-swiftclient,master,Ib5502c23b236986bea5a4d4a63a46fca411a8494,"Fix inconsistent usage of ""Positional argument""",MERGED,2015-06-08 18:22:01.000000000,2015-06-10 13:06:05.000000000,2015-06-10 13:06:04.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 6547}, {'_account_id': 6968}, {'_account_id': 14867}]","[{'number': 1, 'created': '2015-06-08 18:22:01.000000000', 'files': ['swiftclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e48f487335e970f8b61a7f891118639203a746b8', 'message': 'Fix inconsistent usage of ""Positional argument""\n\nAll help texts uses ""Positional argument"" with the exception of tempurl.\nUpdate tempurl to use this as well so that the formatting tools work\nfine and can show this nicely on\nhttp://docs.openstack.org/cli-reference/content/swiftclient_commands.html#swiftclient_subcommand_tempurl\nlike it\'s done for other options.\n\nChange-Id: Ib5502c23b236986bea5a4d4a63a46fca411a8494\nCloses-Bug: #1463081\n'}]",0,189390,e48f487335e970f8b61a7f891118639203a746b8,10,5,1,6547,,,0,"Fix inconsistent usage of ""Positional argument""

All help texts uses ""Positional argument"" with the exception of tempurl.
Update tempurl to use this as well so that the formatting tools work
fine and can show this nicely on
http://docs.openstack.org/cli-reference/content/swiftclient_commands.html#swiftclient_subcommand_tempurl
like it's done for other options.

Change-Id: Ib5502c23b236986bea5a4d4a63a46fca411a8494
Closes-Bug: #1463081
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/90/189390/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/shell.py'],1,e48f487335e970f8b61a7f891118639203a746b8,bug/1463081,Positional arguments:,Positions arguments:,1,1
openstack%2Fcompute-hyperv~master~Ia99576589af6049ee07337c631ed7d5d6cf602d9,openstack/compute-hyperv,master,Ia99576589af6049ee07337c631ed7d5d6cf602d9,Hyper-V: Fix missing WMI namespace issue on Windows 2008 R2,MERGED,2015-06-09 13:33:43.000000000,2015-06-10 13:03:41.000000000,2015-06-09 16:04:54.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2015-06-09 13:33:43.000000000', 'files': ['hyperv/nova/pathutils.py', 'hyperv/tests/unit/test_base.py', 'hyperv/tests/unit/test_pathutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/1de39b99ac144698a1ea0e01bd17d8fc6c78298d', 'message': 'Hyper-V: Fix missing WMI namespace issue on Windows 2008 R2\n\nThe Hyper-V driver uses the Microsoft\\Windows\\SMB WMI namespace\nin order to handle SMB shares. The issue is that this namespace is\nnot available on Windows versions prior to Windows Server 2012.\n\nFor this reason, the Hyper-V driver fails to initialize on Windows\nServer 2008 R2.\n\nThis patch fixes the issue by properly handling the PathUtils\ninitialization.\n\nCloses-Bug: #1463044\nChange-Id: Ia99576589af6049ee07337c631ed7d5d6cf602d9\n'}]",0,189717,1de39b99ac144698a1ea0e01bd17d8fc6c78298d,7,2,1,8543,,,0,"Hyper-V: Fix missing WMI namespace issue on Windows 2008 R2

The Hyper-V driver uses the Microsoft\Windows\SMB WMI namespace
in order to handle SMB shares. The issue is that this namespace is
not available on Windows versions prior to Windows Server 2012.

For this reason, the Hyper-V driver fails to initialize on Windows
Server 2008 R2.

This patch fixes the issue by properly handling the PathUtils
initialization.

Closes-Bug: #1463044
Change-Id: Ia99576589af6049ee07337c631ed7d5d6cf602d9
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/17/189717/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/pathutils.py', 'hyperv/tests/unit/test_base.py', 'hyperv/tests/unit/test_pathutils.py']",3,1de39b99ac144698a1ea0e01bd17d8fc6c78298d,bug/1463044," def _test_smb_conn(self, smb_available=True): self._mock_wmi.x_wmi = Exception self._mock_wmi.WMI.side_effect = None if smb_available else Exception self._pathutils._set_smb_conn() if smb_available: expected_conn = self._mock_wmi.WMI.return_value self.assertEqual(expected_conn, self._pathutils._smb_conn) else: self.assertRaises(vmutils.HyperVException, getattr, self._pathutils, '_smb_conn') def test_smb_conn_available(self): self._test_smb_conn() def test_smb_conn_unavailable(self): self._test_smb_conn(smb_available=False) ",,41,2
openstack%2Fcompute-hyperv~master~I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41,openstack/compute-hyperv,master,I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41,Fix QoS issues caused by unsupported OS versions,MERGED,2015-06-09 09:13:34.000000000,2015-06-10 13:03:15.000000000,2015-06-09 14:05:02.000000000,"[{'_account_id': 3}, {'_account_id': 8213}, {'_account_id': 8543}]","[{'number': 1, 'created': '2015-06-09 09:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/82cb02e60e97eb9a89ded5079ec2c33ed7f71e6d', 'message': 'Fix QoS issues caused by unsupported OS versions\n\nDisk QoS is not available on versions prior to WS 2012 R2.\n\nBecaue of this and the fact that the driver attempts to set IOPS\nlimits even if those are not specified, spawning instances currently\nfails when using such Windows versions.\n\nThis patch fixes the issues by skipping setting QoS specs when\nthis feature is not supported, logging a warning.\n\nCloses-Bug: #1463317\n\nChange-Id: I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41\n'}, {'number': 2, 'created': '2015-06-09 12:52:06.000000000', 'files': ['hyperv/nova/vmops.py', 'hyperv/nova/vmutilsv2.py', 'hyperv/tests/unit/test_vmutilsv2.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/b97666aa6d897280a6a31d5ff6fd8d9eab3b7a4d', 'message': 'Fix QoS issues caused by unsupported OS versions\n\nDisk QoS is not available on versions prior to WS 2012 R2.\n\nBecause of this and the fact that the driver attempts to set IOPS\nlimits even if those are not specified, spawning instances currently\nfails when using previous HyperV versions.\n\nThis patch fixes the issues by skipping setting QoS specs when\nthis feature is not supported, logging a warning.\n\nCloses-Bug: #1463317\n\nChange-Id: I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41\n'}]",6,189602,b97666aa6d897280a6a31d5ff6fd8d9eab3b7a4d,11,3,2,8543,,,0,"Fix QoS issues caused by unsupported OS versions

Disk QoS is not available on versions prior to WS 2012 R2.

Because of this and the fact that the driver attempts to set IOPS
limits even if those are not specified, spawning instances currently
fails when using previous HyperV versions.

This patch fixes the issues by skipping setting QoS specs when
this feature is not supported, logging a warning.

Closes-Bug: #1463317

Change-Id: I086f3a034ffcc56a09a5ecf3e9a142cc86e67c41
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/02/189602/2 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/vmops.py', 'hyperv/nova/vmutilsv2.py', 'hyperv/tests/unit/test_vmutilsv2.py']",3,82cb02e60e97eb9a89ded5079ec2c33ed7f71e6d,bug/1463317," def _test_set_disk_qos_specs(self, mock_modify_virt_resource, mock_get_disk_resource, qos_available=True): mock_disk = mock.Mock() if not qos_available: type(mock_disk).IOPSLimit = mock.PropertyMock( side_effect=AttributeError) mock_get_disk_resource.return_value = mock_disk if qos_available: self.assertEqual(mock.sentinel.max_iops, mock_disk.IOPSLimit) self.assertEqual(mock.sentinel.min_iops, mock_disk.IOPSReservation) mock_modify_virt_resource.assert_called_once_with(mock_disk, None) else: self.assertFalse(mock_modify_virt_resource.called) def test_set_disk_qos_specs(self): self._test_set_disk_qos_specs() def test_set_disk_qos_specs_unsupported_feature(self): self._test_set_disk_qos_specs(qos_available=False)"," def test_set_disk_qos_specs(self, mock_modify_virt_resource, mock_get_disk_resource): mock_disk = mock_get_disk_resource.return_value self.assertEqual(mock.sentinel.max_iops, mock_disk.IOPSLimit) self.assertEqual(mock.sentinel.min_iops, mock_disk.IOPSReservation) mock_modify_virt_resource.assert_called_once_with(mock_disk, None)",34,14
openstack%2Fproject-config~master~Ica2375d5ace0f815fc8d16ea62c65fb85f61a281,openstack/project-config,master,Ica2375d5ace0f815fc8d16ea62c65fb85f61a281,Announce release tools changes in relmgr-office channel,MERGED,2015-06-05 20:02:15.000000000,2015-06-10 13:01:24.000000000,2015-06-10 13:01:23.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-06-05 20:02:15.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e54d4f1c3aa6db63309c14256f059dea037cc607', 'message': 'Announce release tools changes in relmgr-office channel\n\nChange-Id: Ica2375d5ace0f815fc8d16ea62c65fb85f61a281\n'}]",0,188904,e54d4f1c3aa6db63309c14256f059dea037cc607,9,5,1,2472,,,0,"Announce release tools changes in relmgr-office channel

Change-Id: Ica2375d5ace0f815fc8d16ea62c65fb85f61a281
",git fetch https://review.opendev.org/openstack/project-config refs/changes/04/188904/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,e54d4f1c3aa6db63309c14256f059dea037cc607,release-tools-announce,openstack-relmgr-office: events: - patchset-created - change-merged - x-vrif-minus-2 projects: - openstack-infra/release-tools - openstack-infra/releasestatus branches: - master ,,11,0
openstack%2Fproject-config~master~I92424e5e8bb560ad7e127f6de976f843a32d546f,openstack/project-config,master,I92424e5e8bb560ad7e127f6de976f843a32d546f,Import puppet-stackalytics into openstack-infra,MERGED,2015-06-01 18:11:15.000000000,2015-06-10 13:01:21.000000000,2015-06-10 13:01:18.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 16051}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-01 18:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/84c603ecdec292ded1755ca997d741b82a9b9348', 'message': ""Import puppet-stackalytics into openstack-infra\n\nThis is a very basic git repo for puppet-stackalytics. Once imported,\nwe'll use the existing work by Monty to build up the module correctly.\n\nChange-Id: I92424e5e8bb560ad7e127f6de976f843a32d546f\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}, {'number': 2, 'created': '2015-06-01 18:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/97613d8152a09dfc39c09d01a93f6a1cfa79faec', 'message': ""Import puppet-stackalytics into openstack-infra\n\nThis is a very basic git repo for puppet-stackalytics. Once imported,\nwe'll use the existing work by Monty to build up the module correctly.\n\nChange-Id: I92424e5e8bb560ad7e127f6de976f843a32d546f\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}, {'number': 3, 'created': '2015-06-02 15:49:51.000000000', 'files': ['gerrit/acls/openstack-infra/puppet-stackalytics.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/11a90cee2572d46c922cb8fc9b75c8b2484f04e4', 'message': ""Import puppet-stackalytics into openstack-infra\n\nThis is a very basic git repo for puppet-stackalytics. Once imported,\nwe'll use the existing work by Monty to build up the module correctly.\n\nChange-Id: I92424e5e8bb560ad7e127f6de976f843a32d546f\nDepends-On: Iaae173a301e8ea64a4271f0f49349363ac3a9553\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",1,187269,11a90cee2572d46c922cb8fc9b75c8b2484f04e4,17,8,3,4162,,,0,"Import puppet-stackalytics into openstack-infra

This is a very basic git repo for puppet-stackalytics. Once imported,
we'll use the existing work by Monty to build up the module correctly.

Change-Id: I92424e5e8bb560ad7e127f6de976f843a32d546f
Depends-On: Iaae173a301e8ea64a4271f0f49349363ac3a9553
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/187269/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack-infra/puppet-stackalytics.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,84c603ecdec292ded1755ca997d741b82a9b9348,puppet-stackalytics, - name: openstack-infra/puppet-stackalytics template: - name: merge-check - name: puppet-check-jobs - name: infra-puppet-apply-jobs ,,35,0
openstack%2Fproject-config~master~I32947e905770475ed3aea342dd80984fc90e3d69,openstack/project-config,master,I32947e905770475ed3aea342dd80984fc90e3d69,Rename ironic-milestone group in gerrit to ironic-stable-maint,MERGED,2015-05-28 19:51:31.000000000,2015-06-10 13:01:16.000000000,2015-06-10 13:01:13.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 2889}]","[{'number': 1, 'created': '2015-05-28 19:51:31.000000000', 'files': ['gerrit/acls/openstack/ironic.config', 'gerrit/acls/openstack/python-ironicclient.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/20f45701a488e3f9500fdff8de663ac25c1d3307', 'message': 'Rename ironic-milestone group in gerrit to ironic-stable-maint\n\nI was having a hard time finding the stable branch maintenance team for\nironic because they used a different naming convention for their group\nfrom the rest of the projects:\n\nhttps://review.openstack.org/#/admin/groups/?filter=stable\n\nSo rename the group to match the standard naming convention.\n\nChange-Id: I32947e905770475ed3aea342dd80984fc90e3d69\n'}]",0,186548,20f45701a488e3f9500fdff8de663ac25c1d3307,10,5,1,6873,,,0,"Rename ironic-milestone group in gerrit to ironic-stable-maint

I was having a hard time finding the stable branch maintenance team for
ironic because they used a different naming convention for their group
from the rest of the projects:

https://review.openstack.org/#/admin/groups/?filter=stable

So rename the group to match the standard naming convention.

Change-Id: I32947e905770475ed3aea342dd80984fc90e3d69
",git fetch https://review.opendev.org/openstack/project-config refs/changes/48/186548/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/ironic.config', 'gerrit/acls/openstack/python-ironicclient.config']",2,20f45701a488e3f9500fdff8de663ac25c1d3307,project-rename,abandon = group ironic-stable-maintlabel-Code-Review = -2..+2 group ironic-stable-maintlabel-Workflow = -1..+1 group ironic-stable-maint,abandon = group ironic-milestonelabel-Code-Review = -2..+2 group ironic-milestonelabel-Workflow = -1..+1 group ironic-milestone,6,6
openstack%2Fironic-specs~master~I046030cc42f943435ec6fc078c31228c1b22bd99,openstack/ironic-specs,master,I046030cc42f943435ec6fc078c31228c1b22bd99,Bare Metal Trust Using Intel TXT,MERGED,2014-11-12 07:08:06.000000000,2015-06-10 13:00:45.000000000,2015-06-10 13:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 4573}, {'_account_id': 4992}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 10202}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10380}, {'_account_id': 11076}, {'_account_id': 12385}, {'_account_id': 13063}, {'_account_id': 13295}, {'_account_id': 13362}, {'_account_id': 13997}, {'_account_id': 14760}]","[{'number': 1, 'created': '2014-11-12 07:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d41f574be9a792754242c5855fc09c525904502e', 'message': 'Bare Metal Trust\n\nThis blueprint provides a trust boot solution, guaranteeing the node is\ntrusted after deploying with Ironic, leveraging Intel TXT to measure BIOS,\nOption ROM and Kernel/Ramdisk.\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 2, 'created': '2014-11-12 07:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7190e34ad6eb7daca022b455fe3023abe9b83c8e', 'message': 'Bare Metal Trust\n\nThis blueprint provides a trust boot solution, guaranteeing\nthe node is trusted after deploying with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 3, 'created': '2014-11-12 07:17:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/858cb2540059c7d742d2804b1215645001e05f89', 'message': 'Bare Metal Trust\n\nThis bp provides a trust boot solution, to determine the node\nis trusted or not after deploying with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 4, 'created': '2014-11-12 07:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5139fd99af2a8f23a2fcb06ad4985eec739b55ec', 'message': 'Bare Metal Trust\n\nThis bp provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 5, 'created': '2014-11-12 07:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6942b8a35e417231c8e656ed7e90cfc5d983472b', 'message': 'Bare Metal Trust\n\nThis bp provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 6, 'created': '2014-11-12 07:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ca86ba68383f948c4df8989f0627d1b1fe4e6ba7', 'message': 'Bare Metal Trust\n\nThis bp provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 7, 'created': '2014-11-12 08:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4528fe6b5c473fc656969e08304a3adb8e26c9be', 'message': 'Bare Metal Trust\n\nThis bp provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 8, 'created': '2014-11-17 10:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/aa5a53e6002282163561c63229f4229ebeecb7ee', 'message': 'Bare Metal Trust\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 9, 'created': '2014-11-25 11:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/412514c11740541557d005789f4d1163cd331e3f', 'message': 'Bare Metal Trust\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 10, 'created': '2014-12-04 13:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ccf8c21a5ba5c31a13cea69256e55c35cb06b227', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 11, 'created': '2014-12-08 05:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9ae23f2db4506881949195a3aff17be609b1d9ec', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 12, 'created': '2014-12-10 09:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/87f5c5b10594fd8142f9e64af9d1bf9372829ed3', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 13, 'created': '2014-12-10 11:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/71752f05ad892ecef9ae8ab608c8978cbb2bd1c2', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 14, 'created': '2014-12-14 04:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/53e1cbf8b5d0eaca0b095658e35869847ba7e466', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 15, 'created': '2015-01-15 12:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/220721905d75bd2d4eb4a382b50089014b9ab23b', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 16, 'created': '2015-01-19 13:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/dac4d95b9a68bfc17f6fda0d7165c317fb9b12ee', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 17, 'created': '2015-01-20 11:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b8fad406ca2c8ad9abd62c8ab02168c6373767e2', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\n\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 18, 'created': '2015-03-10 02:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b6dbcf8b379dc525c37626785277bd79f0d4f276', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 19, 'created': '2015-04-14 06:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/51ba002eaf1430c91aa3e962bbad2c39b3e2133f', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 20, 'created': '2015-05-04 10:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2141b4ac26e2b4a3b0df2b0650945e129875648e', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 21, 'created': '2015-05-05 01:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a95cdb1f103383bd4e631ca5f904ff6ad720e23f', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 22, 'created': '2015-05-05 01:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/d69a4e20d12bd4112d707ff5b79634c684f231b1', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 23, 'created': '2015-05-06 08:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5662522b45eb54ac43846cd7c47ff21079951e22', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 24, 'created': '2015-05-25 07:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a173918009f4eb1fab40d7f58a665d1a05b7ed53', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 25, 'created': '2015-05-25 07:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/98b7f0b70e9a4b30a9cc97aaa75ba010d52d8c6b', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 26, 'created': '2015-05-29 07:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/3141ee7f94e281f5328615b9449f774d4940c070', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trust boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 27, 'created': '2015-05-29 09:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/fb28c987b29361a0e893ef41994c9fecc548132c', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trusted boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 28, 'created': '2015-06-01 02:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/04dc04ab20be4fb40328852a8d97a9bd161bb1fd', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trusted boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 29, 'created': '2015-06-03 02:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7a6b4306be1b26f2a6cd0e52bc1d2deca8946ac5', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trusted boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 30, 'created': '2015-06-03 08:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/be3c90e6455f1ce82c5da39341adf0516a1f0e0f', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trusted boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}, {'number': 31, 'created': '2015-06-04 08:12:57.000000000', 'files': ['specs/liberty/bare-metal-trust-using-intel-txt.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/79f20e08ad49f12117ae7ef5d5366d842696c4cb', 'message': 'Bare Metal Trust Using Intel TXT\n\nThis provides a trusted boot solution, to determine the node\nis trusted or not after deployed with Ironic, leveraging\nIntel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.\nTalk and Demo:\nhttps://www.openstack.org/summit/openstack-paris-summit-2014/\nsession-videos/presentation/trusted-bare-metal-what-and-39-s-that\n\nCo-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>\nCo-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>\n\nChange-Id: I046030cc42f943435ec6fc078c31228c1b22bd99\n'}]",230,133902,79f20e08ad49f12117ae7ef5d5366d842696c4cb,115,18,31,13362,,,0,"Bare Metal Trust Using Intel TXT

This provides a trusted boot solution, to determine the node
is trusted or not after deployed with Ironic, leveraging
Intel TXT to measure BIOS, Option ROM and Kernel/Ramdisk.
Talk and Demo:
https://www.openstack.org/summit/openstack-paris-summit-2014/
session-videos/presentation/trusted-bare-metal-what-and-39-s-that

Co-Authored-By: Bhandaru, Malini K <malini.k.bhandaru@intel.com>
Co-Authored-By: Villalovos, John L <john.l.villalovos@intel.com>

Change-Id: I046030cc42f943435ec6fc078c31228c1b22bd99
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/02/133902/30 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/bare-metal-trust.rst'],1,d41f574be9a792754242c5855fc09c525904502e,trusted_boot,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Bare Metal Trust ========================================== https://blueprints.launchpad.net/ironic/+spec/bare-metal-trust This blueprint provides a trust boot solution, guaranteeing the node is trusted after deploying with Ironic, leveraging Intel TXT to measure BIOS, Option ROM and Kernel/Ramdisk. Problem description =================== When re-allocating the bare metal node to another tenant, are we free of malware? We think we need to find a way to keep us safe. So we integrate Ironic with TXT to enables detection on boot, that means we will detect changes in BIOS, changes in PCIe devices and changes in Kernel. If something is changed and is not we expected, we treated it as untrusted noe. Leverage Intel TXT to ""measure"" BIOS and OS software and save their hashes on the trusted-platform-module (TPM) on chip. Will increase confidence in the cloud that OpenStack service nodes can be attested as Trusted. Tenants seeking bare metal can also ascertain whether the allocated node on launching their provided images can be ""trusted"" before deploying applications on them. The solution involves an open source project TBOOT to work with TXT to generate the hash values and also involves an open source project OAT as attestation server that determines whether the hashes match provisioned known-good-value. The solution includes two parts, measure and verify: 1.1 Enable TXT in BIOS We need at least three times reboots to enable TPM and TXT. There is no generic solution so far becuase of OEM's specifical platform. So we have to manually setting. Future plan is working with IPA during first PXE boot. 1.2. Using Trust Boot model to measure. Leverage TBOOT to generate PCR values during second PXE boot. 2.1 Inject OAT-client into image Create a golden image with oat-client installed. 2.2 Register Node with OAT-Server to verify. Pass OAT-Server IP address to Node to configure OAT-Client after booting and wait for OAT-Server's call to fetch PCR values from TPM and compare with whitelist in OAT-Server. Proposed change =============== In the scope of Ironic, we are focusing on the measurement: * Read driver_info ""deploy_trust“ - pass flag ”deply_trust"" to switch_pxe_config() - swith to ""boot_trust"" section The flag will be passed from flavor like deploy_kernel. * PXE configuration - Add a new section ""boot_trust"". It will make use mboot.c32 which support multiple loading. It loads TBOOT at first. TBOOT will measure Kernel/Ramdisk before load them. Alternatives ------------ As TXT can measure BIOS/Option ROM without tboot. Tboot is focusing on measuring Kernel/Ramdisk during every booting. If we can trust the Kernel/Ramdisk sources(Ironic Server), we can use https with ipxe to guarantee Kernel/Ramdisk is safe during transporting. That means we need to verify the hash values of Kernel/Ramdisk before sending to target nodes. But the disadvantage of this is not easy to verify the hash values of Kernel/Ramdisk if target node reboot. Because it will not send signals to Ironic Server. Data model impact ----------------- None REST API impact --------------- None RPC API impact -------------- None Driver API impact ----------------- None Nova driver impact ------------------ None Security impact --------------- None Other end user impact --------------------- None Scalability impact ------------------ None Performance Impact ------------------ None Other deployer impact --------------------- Additionally one field need to be provided with driver_info * ``deploy_trust`` - whether to use trust_boot with PXE driver. Additionally two items need to be provided with tftpboot/httpboot folder * ``mboot.c32`` - Support multiple loading from /usr/lib/syslinux/mboot.c32 * ``tboot.gz`` - a pre-kernel module to do the measurement. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: tan-lin-good Work Items ---------- * Add trust_boot section to pxe_config.template * Support deploy_trust flag and switch to trust_boot. Dependencies ============ TBOOT: http://sourceforge.net/projects/tboot/ OAT: https://github.com/OpenAttestation/OpenAttestation Testing ======= Will add Unit Testing. Upgrades and Backwards Compatibility ==================================== None Documentation Impact ==================== Will document the usage of this scenery. References ========== None ",,167,0
openstack%2Fzaqar~master~Id9cbd64a7c4f49870f767d1427f7de4a0ada3846,openstack/zaqar,master,Id9cbd64a7c4f49870f767d1427f7de4a0ada3846,Move transport v1 tests out of tests/,MERGED,2015-06-05 07:20:13.000000000,2015-06-10 13:00:33.000000000,2015-06-10 13:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-06-05 07:20:13.000000000', 'files': ['zaqar/tests/unit/transport/wsgi/v1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/test_utils.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'tests/unit/transport/wsgi/__init__.py', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', '.testr.conf', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1/__init__.py', 'tests/unit/transport/wsgi/test_v1_0.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/379c2d4cd8ee410607b7e6704d23e149a02a2abd', 'message': 'Move transport v1 tests out of tests/\n\nThis moves tests for wsgi v1 out of the tests directory. This finishes\nthe transport unit tests.\n\nblueprint tests-refactoring\n\nChange-Id: Id9cbd64a7c4f49870f767d1427f7de4a0ada3846\n'}]",0,188689,379c2d4cd8ee410607b7e6704d23e149a02a2abd,8,4,1,7385,,,0,"Move transport v1 tests out of tests/

This moves tests for wsgi v1 out of the tests directory. This finishes
the transport unit tests.

blueprint tests-refactoring

Change-Id: Id9cbd64a7c4f49870f767d1427f7de4a0ada3846
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/89/188689/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/tests/unit/transport/wsgi/v1/test_health.py', 'zaqar/tests/unit/transport/wsgi/v1/test_claims.py', 'zaqar/tests/unit/transport/wsgi/test_utils.py', 'zaqar/tests/unit/transport/wsgi/v1/test_messages.py', 'zaqar/tests/unit/transport/wsgi/v1/test_queue_lifecycle.py', 'tests/unit/transport/wsgi/__init__.py', '.testr.conf', 'zaqar/tests/unit/transport/wsgi/v1/test_pools.py', 'zaqar/tests/unit/transport/wsgi/base.py', 'zaqar/tests/unit/transport/wsgi/v1/__init__.py', 'tests/unit/transport/wsgi/test_v1_0.py']",11,379c2d4cd8ee410607b7e6704d23e149a02a2abd,bp/tests-refactoring,,"# Copyright (c) 2014 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may not # use this file except in compliance with the License. You may obtain a copy # of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations under # the License. import falcon from zaqar.tests.unit.transport.wsgi import base from zaqar.tests.unit.transport.wsgi import v1 # -------------------------------------------------------------------------- # Identical or just minor variations across versions # -------------------------------------------------------------------------- URL_PREFIX = '/v1' class TestAuth(v1.TestAuth): url_prefix = URL_PREFIX class TestClaimsFaultyDriver(v1.TestClaimsFaultyDriver): url_prefix = URL_PREFIX class TestClaimsMongoDB(v1.TestClaimsMongoDB): url_prefix = URL_PREFIX class TestDefaultLimits(v1.TestDefaultLimits): url_prefix = URL_PREFIX class TestHomeDocument(v1.TestHomeDocument): url_prefix = URL_PREFIX class TestMediaType(v1.TestMediaType): url_prefix = URL_PREFIX class TestMessagesFaultyDriver(v1.TestMessagesFaultyDriver): url_prefix = URL_PREFIX class TestMessagesMongoDB(v1.TestMessagesMongoDB): url_prefix = URL_PREFIX class TestMessagesMongoDBPooled(v1.TestMessagesMongoDBPooled): url_prefix = URL_PREFIX class TestQueueFaultyDriver(v1.TestQueueFaultyDriver): url_prefix = URL_PREFIX class TestQueueLifecycleMongoDB(v1.TestQueueLifecycleMongoDB): url_prefix = URL_PREFIX # NOTE(flaper87): We'll need this later on # class TestQueueLifecycleSqlalchemy(v1.TestQueueLifecycleSqlalchemy): # url_prefix = URL_PREFIX class TestPoolsMongoDB(v1.TestPoolsMongoDB): url_prefix = URL_PREFIX # class TestPoolsSqlalchemy(v1.TestPoolsSqlalchemy): # url_prefix = URL_PREFIX class TestValidation(v1.TestValidation): url_prefix = URL_PREFIX # -------------------------------------------------------------------------- # v1.0 only # -------------------------------------------------------------------------- class TestHealth(base.V1Base): config_file = 'wsgi_mongodb.conf' def test_get(self): response = self.simulate_get('/v1/health') self.assertEqual(self.srmock.status, falcon.HTTP_204) self.assertEqual(response, []) def test_head(self): response = self.simulate_head('/v1/health') self.assertEqual(self.srmock.status, falcon.HTTP_204) self.assertEqual(response, []) ",78,246
openstack%2Fproject-config~master~I44c476ddfb67e5b3ebd3aaba3b26561f02708477,openstack/project-config,master,I44c476ddfb67e5b3ebd3aaba3b26561f02708477,Drop usage of `` in if statements,MERGED,2015-05-21 23:30:55.000000000,2015-06-10 13:00:24.000000000,2015-06-10 13:00:23.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 9369}]","[{'number': 1, 'created': '2015-05-21 23:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/dcd5ef9657034bd05f7c26f9252766fadc35f907', 'message': 'Switch to using $() for subshells\n\nCleanup every use of `` for subshells, replacing them with $(), and\nfinally making the scripts consistent. This also changes some calls\nwhere subshells are not required, ie: within if.\n\nChange-Id: I44c476ddfb67e5b3ebd3aaba3b26561f02708477\n'}, {'number': 2, 'created': '2015-05-21 23:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a535d4de623e2c8398b9352d7f1f88be5e5e4c95', 'message': 'Switch to using $() for subshells\n\nCleanup every use of `` for subshells, replacing them with $(), and\nfinally making the scripts consistent. This also changes some calls\nwhere subshells are not required, ie: within if.\n\nChange-Id: I44c476ddfb67e5b3ebd3aaba3b26561f02708477\n'}, {'number': 3, 'created': '2015-05-29 07:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eb7ac167b23e225a7301264712515d59ddc4147a', 'message': 'Switch to using $() for subshells\n\nCleanup every use of `` for subshells, replacing them with $(), and\nfinally making the scripts consistent. This also changes some calls\nwhere subshells are not required, ie: within if.\n\nChange-Id: I44c476ddfb67e5b3ebd3aaba3b26561f02708477\n'}, {'number': 4, 'created': '2015-06-02 05:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/338b3aa1feb9a1754bed46ea38ab7477bfaf13e4', 'message': 'Switch to using $() for subshells\n\nCleanup every use of `` for subshells, replacing them with $(), and\nfinally making the scripts consistent. This also changes some calls\nwhere subshells are not required, ie: within if.\n\nChange-Id: I44c476ddfb67e5b3ebd3aaba3b26561f02708477\n'}, {'number': 5, 'created': '2015-06-04 05:48:32.000000000', 'files': ['jenkins/scripts/upstream_translation_django_openstack_auth.sh', 'jenkins/scripts/upstream_translation_update_manuals.sh', 'jenkins/scripts/upstream_translation_horizon.sh', 'jenkins/scripts/upstream_translation_update.sh', 'jenkins/scripts/common_translation_update.sh', 'jenkins/scripts/run-docs.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e2c58de6fe1bda17e2edd4fffa14b260bba6cfb5', 'message': 'Drop usage of `` in if statements\n\nSubshells are not required for if statements, so remove them. This\nalso drops all usage of `` in scripts.\n\nChange-Id: I44c476ddfb67e5b3ebd3aaba3b26561f02708477\n'}]",0,184907,e2c58de6fe1bda17e2edd4fffa14b260bba6cfb5,21,5,5,9369,,,0,"Drop usage of `` in if statements

Subshells are not required for if statements, so remove them. This
also drops all usage of `` in scripts.

Change-Id: I44c476ddfb67e5b3ebd3aaba3b26561f02708477
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/184907/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/puppet/pre-install.d/10-preseed', 'tools/check_valid_gerrit_config.sh', 'tools/mount-image.sh', 'jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/propose_translation_update.sh', 'jenkins/scripts/mavencentral-upload.sh', 'jenkins/scripts/run-xmllint.sh', 'jenkins/scripts/common_translation_update.sh', 'tools/run-compare-xml.sh', 'nodepool/scripts/install_devstack_dependencies.sh', 'jenkins/scripts/upstream_translation_horizon.sh', 'jenkins/scripts/upstream_translation_update.sh', 'jenkins/scripts/lvm-kexec-reset.sh', 'jenkins/scripts/propose_translation_update_django_openstack_auth.sh', 'jenkins/scripts/baremetal-deploy.sh', 'jenkins/scripts/upstream_translation_django_openstack_auth.sh', 'jenkins/scripts/propose_update.sh', 'jenkins/scripts/bump-milestone.sh', 'jenkins/scripts/merge_tags.sh', 'nodepool/scripts/multinode_setup.sh', 'jenkins/scripts/run-tox.sh', 'jenkins/scripts/jenkinsci-upload.sh', 'jenkins/scripts/upstream_translation_update_manuals.sh', 'jenkins/scripts/version-properties.sh', 'nodepool/scripts/prepare_devstack.sh', 'jenkins/scripts/pypi-tarball-upload.sh', 'jenkins/scripts/run-docs.sh']",27,dcd5ef9657034bd05f7c26f9252766fadc35f907,subshell-change,elif echo $ZUUL_REFNAME | grep refs/tags/ >/dev/null ; then TAG=$(echo $ZUUL_REFNAME | sed 's/refs.tags.//') LATEST=$(git tag | sed -n -e '/^2012\..*$/d' -e '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1) LATEST=$(git tag | sed -n '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1)elif echo $ZUUL_REFNAME | grep stable/ >/dev/null ; then BRANCH=$(echo $ZUUL_REFNAME | sed 's/stable.//'),elif `echo $ZUUL_REFNAME | grep refs/tags/ >/dev/null` ; then TAG=`echo $ZUUL_REFNAME | sed 's/refs.tags.//'` LATEST=`git tag | sed -n -e '/^2012\..*$/d' -e '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1` LATEST=`git tag | sed -n '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1`elif `echo $ZUUL_REFNAME | grep stable/ >/dev/null` ; then BRANCH=`echo $ZUUL_REFNAME | sed 's/stable.//'`,70,70
openstack%2Fproject-config~master~Id3e45fb873c1ebeae6ab63a0caa4c427a7ccbb62,openstack/project-config,master,Id3e45fb873c1ebeae6ab63a0caa4c427a7ccbb62,"Switch to using $() for subshells, part 2",MERGED,2015-06-04 05:48:32.000000000,2015-06-10 13:00:16.000000000,2015-06-10 13:00:16.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}]","[{'number': 1, 'created': '2015-06-04 05:48:32.000000000', 'files': ['jenkins/scripts/propose_translation_update_django_openstack_auth.sh', 'jenkins/scripts/baremetal-deploy.sh', 'jenkins/scripts/propose_update.sh', 'jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/bump-milestone.sh', 'jenkins/scripts/propose_translation_update.sh', 'jenkins/scripts/mavencentral-upload.sh', 'jenkins/scripts/merge_tags.sh', 'jenkins/scripts/run-xmllint.sh', 'jenkins/scripts/common_translation_update.sh', 'jenkins/scripts/run-tox.sh', 'jenkins/scripts/jenkinsci-upload.sh', 'jenkins/scripts/version-properties.sh', 'jenkins/scripts/upstream_translation_horizon.sh', 'jenkins/scripts/pypi-tarball-upload.sh', 'jenkins/scripts/lvm-kexec-reset.sh', 'jenkins/scripts/run-docs.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e3060b094c95513e26616f44ac82ed4a457af81f', 'message': 'Switch to using $() for subshells, part 2\n\nCleanup every use of `` for subshells in the jenkins/scripts\ndirectory, replacing them with $(), and finally making the\nscripts consistent.\n\nChange-Id: Id3e45fb873c1ebeae6ab63a0caa4c427a7ccbb62\n'}]",0,188264,e3060b094c95513e26616f44ac82ed4a457af81f,7,3,1,9369,,,0,"Switch to using $() for subshells, part 2

Cleanup every use of `` for subshells in the jenkins/scripts
directory, replacing them with $(), and finally making the
scripts consistent.

Change-Id: Id3e45fb873c1ebeae6ab63a0caa4c427a7ccbb62
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/188264/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/propose_translation_update_django_openstack_auth.sh', 'jenkins/scripts/baremetal-deploy.sh', 'jenkins/scripts/propose_update.sh', 'jenkins/scripts/pypi-wheel-upload.sh', 'jenkins/scripts/bump-milestone.sh', 'jenkins/scripts/propose_translation_update.sh', 'jenkins/scripts/mavencentral-upload.sh', 'jenkins/scripts/merge_tags.sh', 'jenkins/scripts/run-xmllint.sh', 'jenkins/scripts/common_translation_update.sh', 'jenkins/scripts/run-tox.sh', 'jenkins/scripts/jenkinsci-upload.sh', 'jenkins/scripts/version-properties.sh', 'jenkins/scripts/upstream_translation_horizon.sh', 'jenkins/scripts/pypi-tarball-upload.sh', 'jenkins/scripts/lvm-kexec-reset.sh', 'jenkins/scripts/run-docs.sh']",17,e3060b094c95513e26616f44ac82ed4a457af81f,subshell-change, TAG=$(echo $ZUUL_REFNAME | sed 's/refs.tags.//') LATEST=$(git tag | sed -n -e '/^2012\..*$/d' -e '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1) LATEST=$(git tag | sed -n '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1) BRANCH=$(echo $ZUUL_REFNAME | sed 's/stable.//'), TAG=`echo $ZUUL_REFNAME | sed 's/refs.tags.//'` LATEST=`git tag | sed -n -e '/^2012\..*$/d' -e '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1` LATEST=`git tag | sed -n '/^\([0-9]\+\.\?\)\+$/p' | sort -V | tail -1` BRANCH=`echo $ZUUL_REFNAME | sed 's/stable.//'`,48,48
openstack%2Fproject-config~master~I2b05cd20f9c9a30ab88f8db235aa81da93b1fad3,openstack/project-config,master,I2b05cd20f9c9a30ab88f8db235aa81da93b1fad3,"Switch to using $() for subshells, part 1",MERGED,2015-06-04 05:48:32.000000000,2015-06-10 13:00:07.000000000,2015-06-10 13:00:06.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-04 05:48:32.000000000', 'files': ['nodepool/elements/puppet/pre-install.d/10-preseed', 'tools/check_valid_gerrit_config.sh', 'nodepool/scripts/install_devstack_dependencies.sh', 'tools/mount-image.sh', 'nodepool/scripts/prepare_devstack.sh', 'nodepool/scripts/multinode_setup.sh', 'tools/run-compare-xml.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/85a0f4f44f82402088363a2feb025093c348a232', 'message': 'Switch to using $() for subshells, part 1\n\nCleanup every use of `` for subshells in the nodepool and tools\ndirectory , replacing them with $(), and finally making the scripts\nconsistent.\n\nChange-Id: I2b05cd20f9c9a30ab88f8db235aa81da93b1fad3\n'}]",0,188263,85a0f4f44f82402088363a2feb025093c348a232,9,5,1,9369,,,0,"Switch to using $() for subshells, part 1

Cleanup every use of `` for subshells in the nodepool and tools
directory , replacing them with $(), and finally making the scripts
consistent.

Change-Id: I2b05cd20f9c9a30ab88f8db235aa81da93b1fad3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/188263/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/puppet/pre-install.d/10-preseed', 'tools/check_valid_gerrit_config.sh', 'nodepool/scripts/install_devstack_dependencies.sh', 'tools/mount-image.sh', 'nodepool/scripts/prepare_devstack.sh', 'nodepool/scripts/multinode_setup.sh', 'tools/run-compare-xml.sh']",7,85a0f4f44f82402088363a2feb025093c348a232,subshell-change,GITHEAD=$(git rev-parse HEAD),GITHEAD=`git rev-parse HEAD`,9,9
openstack%2Fceilometer~master~Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97,openstack/ceilometer,master,Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97,Remove deprecated Swift middleware,MERGED,2015-05-25 05:30:54.000000000,2015-06-10 12:52:41.000000000,2015-06-10 12:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7634}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-25 05:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d4d690751c56eca77815214e9e4ee63e85e0cafa', 'message': 'Remove deprecated Swift middleware\n\nChange-Id: Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97\n'}, {'number': 2, 'created': '2015-05-25 06:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1fb5fc0cac366e112fd85b7a549c8809dad1df31', 'message': 'Remove deprecated Swift middleware\n\nChange-Id: Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97\n'}, {'number': 3, 'created': '2015-05-27 15:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bbc668fedf5440f083b66954996ca8589e26bf1c', 'message': 'Remove deprecated Swift middleware\n\nChange-Id: Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97\n'}, {'number': 4, 'created': '2015-05-29 07:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/55d2477a2baf096a2f8cf43976b87530168240ea', 'message': 'Remove deprecated Swift middleware\n\nChange-Id: Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97\n'}, {'number': 5, 'created': '2015-06-09 16:05:28.000000000', 'files': ['ceilometer/objectstore/swift_middleware.py', 'ceilometer/openstack/common/versionutils.py', 'openstack-common.conf', 'setup.cfg', 'tox.ini', 'ceilometer/tests/objectstore/test_swift_middleware.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/191f7bf9ccee33d8444f7dac5c09ceccce72ca29', 'message': 'Remove deprecated Swift middleware\n\nChange-Id: Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97\n'}]",0,185304,191f7bf9ccee33d8444f7dac5c09ceccce72ca29,35,10,5,1669,,,0,"Remove deprecated Swift middleware

Change-Id: Ifd1861e3df46fad0e44ff9b5cbd58711bbc87c97
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/04/185304/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/objectstore/swift_middleware.py', 'ceilometer/openstack/common/versionutils.py', 'openstack-common.conf', 'setup.cfg']",4,d4d690751c56eca77815214e9e4ee63e85e0cafa,jd/remove-swift-middleware-deprecated,,paste.filter_factory = swift = ceilometer.objectstore.swift_middleware:filter_factory ,0,492
openstack%2Fceilometer~master~Id70693dafc823927b3d72e0371e3e55d4e5588ce,openstack/ceilometer,master,Id70693dafc823927b3d72e0371e3e55d4e5588ce,Handle database failures on api startup,MERGED,2015-05-21 00:15:17.000000000,2015-06-10 12:52:05.000000000,2015-06-10 12:52:03.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7052}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 9013}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13560}, {'_account_id': 14320}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-21 00:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be128c7e3f1e9f0521811497638baa5531af2237', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: bug/1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 2, 'created': '2015-05-21 01:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d3861e7bfe9480f431cd4123a6194aadd708bf34', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 3, 'created': '2015-05-21 02:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aca3cbeb605c2c2b0fabaa3abc81d8069afa1d44', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 4, 'created': '2015-05-25 06:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/506ea9030a1628bd956f22b284ecefba1aed77cc', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 5, 'created': '2015-05-26 16:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/61981e367437c6fdb750ca063f38e629f2c0712d', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 6, 'created': '2015-05-26 20:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e19fff1dbf012f751061d4983511f7165a07e28e', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 7, 'created': '2015-05-27 07:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b507acaf79cef75fdb31e3e5b04513e5251c1c09', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 8, 'created': '2015-05-27 15:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e3813f3265512148405df9b548161872fda8bd6b', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 9, 'created': '2015-05-27 17:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d887405ae75c23b11a0d473da9ce18bd621d2b01', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 10, 'created': '2015-05-29 06:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d38df214f9be0164978b6d8d8351a6a6604f1f76', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 11, 'created': '2015-05-29 18:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8f428c1ffa87e2b628afdc5acd212ad83d19125d', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 12, 'created': '2015-06-02 23:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/470b8232754a4881ffd57d6aea2268afa2c0f7ee', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 13, 'created': '2015-06-02 23:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0a9fe122dfb78e47ec05410481fbb103434a3ba1', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 14, 'created': '2015-06-04 00:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/40eb254ba77e0c345fca4651b64159cec511de4b', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 15, 'created': '2015-06-04 05:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/efef894ced3ce0b149edfe736c3bbc1c1225a7f5', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}, {'number': 16, 'created': '2015-06-09 15:10:06.000000000', 'files': ['ceilometer/tests/test_bin.py', 'ceilometer/api/app.py', 'ceilometer/api/hooks.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1f30839494c5b5002173a1f81eb960d735f39643', 'message': 'Handle database failures on api startup\n\nStorage layer connections are initialized\nfor metering, alarm and event in Pecan hook\nmiddleware.\nIf any of the backends are not responding,\nthe connections are retried till maximum\nretries and the exception propagated to the\nCeilometer-api which fails to startup.\n\nThis fix logs and handles the exception in\nthe Pecan hook and allows all connection\ntypes to be initialized.\n\nCloses-Bug: 1456944\n\nChange-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce\n'}]",7,184655,1f30839494c5b5002173a1f81eb960d735f39643,92,13,16,13560,,,0,"Handle database failures on api startup

Storage layer connections are initialized
for metering, alarm and event in Pecan hook
middleware.
If any of the backends are not responding,
the connections are retried till maximum
retries and the exception propagated to the
Ceilometer-api which fails to startup.

This fix logs and handles the exception in
the Pecan hook and allows all connection
types to be initialized.

Closes-Bug: 1456944

Change-Id: Id70693dafc823927b3d72e0371e3e55d4e5588ce
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/55/184655/16 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/api/app.py', 'ceilometer/api/hooks.py']",2,be128c7e3f1e9f0521811497638baa5531af2237,bug/1456944,"from ceilometer.openstack.common import logfrom ceilometer import storage LOG = log.getLogger(__name__) @staticmethod def get_connection(purpose): try: return storage.get_connection_from_config(cfg.CONF, purpose) except Exception as e: LOG.exception(e) ",,14,4
openstack%2Fpython-cinderclient~master~Ie9f64ed73b246164978532f872e09e16d26556d9,openstack/python-cinderclient,master,Ie9f64ed73b246164978532f872e09e16d26556d9,cleanup openstack-common.conf and sync updated files,ABANDONED,2015-06-07 14:11:42.000000000,2015-06-10 12:50:17.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-07 14:11:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/5aefda6d5c4230ceca322e020436226bc2add000', 'message': 'cleanup openstack-common.conf and sync updated files\n\nChange-Id: Ie9f64ed73b246164978532f872e09e16d26556d9\n'}, {'number': 2, 'created': '2015-06-10 12:05:47.000000000', 'files': ['cinderclient/openstack/common/apiclient/fake_client.py', 'cinderclient/openstack/common/apiclient/client.py', 'cinderclient/openstack/common/__init__.py', 'cinderclient/openstack/common/apiclient/auth.py', 'openstack-common.conf', 'tools/install_venv_common.py', 'cinderclient/openstack/common/apiclient/exceptions.py', 'cinderclient/openstack/common/apiclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/6928a6d77cf811a06b971e440c19fc7c56aa99ef', 'message': ""cleanup openstack-common.conf and sync updated files\n\nperiodic update of latest files from oslo-incubator. Please\nnote that a lot of files in */openstack/common/* are no\nlonger in oslo-incubator as they graduated into new oslo.*\nlibraries. So there's more work needed to move to those\nlibraries and delete the code from here.\n\nChange-Id: Ie9f64ed73b246164978532f872e09e16d26556d9\n""}]",0,189120,6928a6d77cf811a06b971e440c19fc7c56aa99ef,7,2,2,5638,,,0,"cleanup openstack-common.conf and sync updated files

periodic update of latest files from oslo-incubator. Please
note that a lot of files in */openstack/common/* are no
longer in oslo-incubator as they graduated into new oslo.*
libraries. So there's more work needed to move to those
libraries and delete the code from here.

Change-Id: Ie9f64ed73b246164978532f872e09e16d26556d9
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/20/189120/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/openstack/common/apiclient/fake_client.py', 'cinderclient/openstack/common/__init__.py', 'cinderclient/openstack/common/apiclient/client.py', 'cinderclient/openstack/common/apiclient/auth.py', 'openstack-common.conf', 'tools/install_venv_common.py', 'cinderclient/openstack/common/apiclient/exceptions.py', 'cinderclient/openstack/common/apiclient/base.py']",8,5aefda6d5c4230ceca322e020436226bc2add000,,"######################################################################## # # THIS MODULE IS DEPRECATED # # Please refer to # https://etherpad.openstack.org/p/kilo-cinderclient-library-proposals for # the discussion leading to this deprecation. # # We recommend checking out the python-openstacksdk project # (https://launchpad.net/python-openstacksdk) instead. # ######################################################################## import copy from oslo_utils import strutilsfrom cinderclient.openstack.common._i18n import _ :param args: args to be passed to every hook function :param kwargs: kwargs to be passed to every hook function def _list(self, url, response_key=None, obj_class=None, json=None): e.g., 'servers'. If response_key is None - all response body will be used. data = body[response_key] if response_key is not None else body def _get(self, url, response_key=None): e.g., 'server'. If response_key is None - all response body will be used. data = body[response_key] if response_key is not None else body return self.resource_class(self, data, loaded=True) def _post(self, url, json, response_key=None, return_raw=False): e.g., 'server'. If response_key is None - all response body will be used. data = body[response_key] if response_key is not None else body if return_raw: return data return self.resource_class(self, data) e.g., 'servers'. If response_key is None - all response body will be used. e.g., 'servers'. If response_key is None - all response body will be used. msg = _(""No %(name)s matching %(args)s."") % { 'name': self.resource_class.__name__, 'args': kwargs } msg = _(""No %(name)s matching %(args)s."") % { 'name': self.resource_class.__name__, 'args': kwargs } raise exceptions.NotFound(msg) if self.HUMAN_ID: name = getattr(self, self.NAME_ATTR, None) if name is not None: return strutils.to_slug(name) # NOTE(bcwaldon): disallow lazy-loading if already loaded once """"""Support for lazy loading details. Some clients, such as novaclient have the option to lazy load the details, details which can be loaded with this function. """""" self._add_details( {'x_request_id': self.manager.client.last_request_id}) def to_dict(self): return copy.deepcopy(self._info)","from cinderclient.openstack.common import strutils :param **args: args to be passed to every hook function :param **kwargs: kwargs to be passed to every hook function def _list(self, url, response_key, obj_class=None, json=None): e.g., 'servers' data = body[response_key] def _get(self, url, response_key): e.g., 'server' return self.resource_class(self, body[response_key], loaded=True) def _post(self, url, json, response_key, return_raw=False): e.g., 'servers' if return_raw: return body[response_key] return self.resource_class(self, body[response_key]) e.g., 'servers' e.g., 'servers' msg = ""No %s matching %s."" % (self.resource_class.__name__, kwargs) msg = ""No %s matching %s."" % (self.resource_class.__name__, kwargs) raise exceptions.NotFound(404, msg) if self.NAME_ATTR in self.__dict__ and self.HUMAN_ID: return strutils.to_slug(getattr(self, self.NAME_ATTR)) #NOTE(bcwaldon): disallow lazy-loading if already loaded once",220,107
openstack%2Fcinder~master~Ia807cc46f855f5919ad33d36bde7d62b650b3362,openstack/cinder,master,Ia807cc46f855f5919ad33d36bde7d62b650b3362,Sync with latest oslo-incubator,ABANDONED,2015-06-07 14:05:49.000000000,2015-06-10 12:50:07.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9751}, {'_account_id': 11611}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 15374}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}]","[{'number': 1, 'created': '2015-06-07 14:05:49.000000000', 'files': ['cinder/openstack/common/scheduler/base_filter.py', 'cinder/openstack/common/eventlet_backdoor.py', 'cinder/openstack/common/middleware/request_id.py', 'cinder/openstack/common/scheduler/base_handler.py', 'cinder/openstack/common/scheduler/filters/capabilities_filter.py', 'cinder/openstack/common/periodic_task.py', 'cinder/openstack/common/fileutils.py', 'cinder/openstack/common/loopingcall.py', 'cinder/openstack/common/scheduler/base_weight.py', 'cinder/openstack/common/service.py', 'cinder/openstack/common/threadgroup.py', 'cinder/openstack/common/middleware/catch_errors.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b5972c18a906b939be8e25353c09d27401f6e75f', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: Ia807cc46f855f5919ad33d36bde7d62b650b3362\n'}]",0,189105,b5972c18a906b939be8e25353c09d27401f6e75f,24,16,1,5638,,,0,"Sync with latest oslo-incubator

Change-Id: Ia807cc46f855f5919ad33d36bde7d62b650b3362
",git fetch https://review.opendev.org/openstack/cinder refs/changes/05/189105/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/openstack/common/scheduler/base_filter.py', 'cinder/openstack/common/eventlet_backdoor.py', 'cinder/openstack/common/middleware/request_id.py', 'cinder/openstack/common/scheduler/base_handler.py', 'cinder/openstack/common/scheduler/filters/capabilities_filter.py', 'cinder/openstack/common/periodic_task.py', 'cinder/openstack/common/fileutils.py', 'cinder/openstack/common/loopingcall.py', 'cinder/openstack/common/scheduler/base_weight.py', 'cinder/openstack/common/service.py', 'cinder/openstack/common/threadgroup.py', 'cinder/openstack/common/middleware/catch_errors.py', 'openstack-common.conf']",13,b5972c18a906b939be8e25353c09d27401f6e75f,,,module=config.generator module=contextmodule=gettextutilsmodule=install_venv_commonmodule=middlewaremodule=policymodule=versionutils,160,54
openstack%2Fpuppet-neutron~master~I6f0d4248033e8e2324754541c77f934f1279ff52,openstack/puppet-neutron,master,I6f0d4248033e8e2324754541c77f934f1279ff52,Opencontrail: Enable opencontrail config provider,ABANDONED,2015-06-03 11:51:10.000000000,2015-06-10 12:48:34.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-06-03 11:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/4ef5b98c898713f9b6a9a6b643f3694a45934af8', 'message': 'Opencontrail: Enable opencontrail config provider\n\nThis patch adds support for neutron_plugin_opencontrail provider to edit\nContrailPlugin.ini configuration file.\n\nChange-Id: I6f0d4248033e8e2324754541c77f934f1279ff52\n'}, {'number': 2, 'created': '2015-06-03 11:53:11.000000000', 'files': ['lib/puppet/type/neutron_plugin_opencontrail.rb', 'lib/puppet/provider/neutron_plugin_opencontrail/ini_setting.rb', 'spec/unit/provider/neutron_plugin_opencontrail/ini_setting_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2424041b9b732322af4e3b8334fcabd91ecaf232', 'message': 'Opencontrail: Enable opencontrail config provider\n\nThis patch adds support for neutron_plugin_opencontrail provider to edit\nContrailPlugin.ini configuration file.\n\nChange-Id: I6f0d4248033e8e2324754541c77f934f1279ff52\n'}]",0,187962,2424041b9b732322af4e3b8334fcabd91ecaf232,7,3,2,9410,,,0,"Opencontrail: Enable opencontrail config provider

This patch adds support for neutron_plugin_opencontrail provider to edit
ContrailPlugin.ini configuration file.

Change-Id: I6f0d4248033e8e2324754541c77f934f1279ff52
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/62/187962/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/type/neutron_plugin_opencontrail.rb', 'lib/puppet/provider/neutron_plugin_opencontrail/ini_setting.rb', 'spec/unit/provider/neutron_plugin_opencontrail/ini_setting_spec.rb']",3,4ef5b98c898713f9b6a9a6b643f3694a45934af8,opencontrail,"$LOAD_PATH.push( File.join( File.dirname(__FILE__), '..', '..', '..', 'fixtures', 'modules', 'inifile', 'lib') ) require 'spec_helper' provider_class = Puppet::Type.type(:neutron_plugin_opencontrail).provider(:ini_setting) describe provider_class do let(:resource ) do Puppet::Type::Neutron_plugin_opencontrail.new({ :name => 'DEFAULT/foo', :value => 'bar', }) end let (:provider) { resource.provider } [ 'RedHat', 'Debian' ].each do |os| context ""on #{os} with default setting"" do it 'it should fall back to default and use ContrailPlugin.ini' do Facter.fact(:operatingsystem).stubs(:value).returns(""#{os}"") expect(provider.section).to eq('DEFAULT') expect(provider.setting).to eq('foo') expect(provider.file_path).to eq('/etc/neutron/plugins/opencontrail/ContrailPlugin.ini') end end end end ",,107,0
openstack%2Fswift~master~I914ded4e5726e50bb93b05759c3bfb76edda53ab,openstack/swift,master,I914ded4e5726e50bb93b05759c3bfb76edda53ab,Object are sorted and concatenated by swift in cardinal order.,MERGED,2015-06-06 12:26:22.000000000,2015-06-10 12:45:11.000000000,2015-06-10 04:08:58.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2696}, {'_account_id': 10068}, {'_account_id': 14867}, {'_account_id': 16206}]","[{'number': 1, 'created': '2015-06-06 12:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d840ae24928132d42eb7846eae7d31099480b9be', 'message': 'Object are sorted and concatenated by swift in cardinal order\n\nModified values in example in decimal to be more precise,\nadded a small description on Object are sorted and concatenated\nby swift in cardinal order as a small phrase would be suffiecient.\n\nChange-Id: I914ded4e5726e50bb93b05759c3bfb76edda53ab\nbackport: none\nCloses-Bug: #1383893\n'}, {'number': 2, 'created': '2015-06-06 19:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7319f8900e77c30b30af4150e03d1873e5f43d40', 'message': 'Running tox with py27 environment.\n\nChange-Id: I914ded4e5726e50bb93b05759c3bfb76edda53ab\nbackport: none\nCloses-Bug: #1383893\n'}, {'number': 3, 'created': '2015-06-06 19:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/705877f3230016df8ccd244aebda3838c8c0c59b', 'message': 'Object are sorted and concatenated by swift in cardinal order.\n\nModified values in example in decimal to be more precise,\nadded a small description on Object are sorted and concatenated\nby swift in cardinal order as a small phrase would be sufficient.\n\nChange-Id: I914ded4e5726e50bb93b05759c3bfb76edda53ab\nbackport: none\nCloses-Bug: #1383893\n'}, {'number': 4, 'created': '2015-06-07 07:23:29.000000000', 'files': ['doc/source/overview_large_objects.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/037a0c5dbe01a57b741d34988e21f4f763b6204b', 'message': 'Object are sorted and concatenated by swift in cardinal order.\n\nModified values in example in decimal to be more precise,\nadded a small description on Object are sorted and concatenated\nby swift in cardinal order as a small phrase would be sufficient.\n\nChange-Id: I914ded4e5726e50bb93b05759c3bfb76edda53ab\nbackport: none\nCloses-Bug: #1383893\n'}]",2,189015,037a0c5dbe01a57b741d34988e21f4f763b6204b,26,6,4,14867,,,0,"Object are sorted and concatenated by swift in cardinal order.

Modified values in example in decimal to be more precise,
added a small description on Object are sorted and concatenated
by swift in cardinal order as a small phrase would be sufficient.

Change-Id: I914ded4e5726e50bb93b05759c3bfb76edda53ab
backport: none
Closes-Bug: #1383893
",git fetch https://review.opendev.org/openstack/swift refs/changes/15/189015/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/overview_large_objects.rst'],1,d840ae24928132d42eb7846eae7d31099480b9be,detached,"name prefix, and their names sorted in cardinal order in which they should be concatenated. http://<storage_url>/container/myobject/00000001 --data-binary '1' http://<storage_url>/container/myobject/00000002 --data-binary '2' http://<storage_url>/container/myobject/00000003 --data-binary '3'","name prefix, and their names sort in the order they should be concatenated. http://<storage_url>/container/myobject/1 --data-binary '1' http://<storage_url>/container/myobject/2 --data-binary '2' http://<storage_url>/container/myobject/3 --data-binary '3'",5,4
openstack%2Fopenstack-specs~master~Ie62d2f49ca0cb073ec3e54aedd8567e78cd45b6e,openstack/openstack-specs,master,Ie62d2f49ca0cb073ec3e54aedd8567e78cd45b6e,Supported messaging drivers policy,MERGED,2015-04-15 21:16:30.000000000,2015-06-10 12:40:38.000000000,2015-06-09 20:31:40.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 170}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 970}, {'_account_id': 1247}, {'_account_id': 1297}, {'_account_id': 2243}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 2750}, {'_account_id': 4257}, {'_account_id': 6159}, {'_account_id': 6488}, {'_account_id': 6537}, {'_account_id': 6873}, {'_account_id': 7849}, {'_account_id': 8770}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-04-15 21:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/ff19d9ba86cd18459bb912acdb9cedccc6076151', 'message': 'Supported messaging drivers policy\n\nChange-Id: Ie62d2f49ca0cb073ec3e54aedd8567e78cd45b6e\n'}, {'number': 2, 'created': '2015-04-16 20:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/b09a3fbe9dbcc1070c93860c5e94437a6f61e6dd', 'message': 'Supported messaging drivers policy\n\nChange-Id: Ie62d2f49ca0cb073ec3e54aedd8567e78cd45b6e\n'}, {'number': 3, 'created': '2015-04-20 23:10:37.000000000', 'files': ['specs/supported-messaging-drivers.rst'], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/fa30228a7152dd98fd1908714ce1576fd268c9a4', 'message': 'Supported messaging drivers policy\n\nChange-Id: Ie62d2f49ca0cb073ec3e54aedd8567e78cd45b6e\n'}]",29,174105,fa30228a7152dd98fd1908714ce1576fd268c9a4,50,20,3,6488,,,0,"Supported messaging drivers policy

Change-Id: Ie62d2f49ca0cb073ec3e54aedd8567e78cd45b6e
",git fetch https://review.opendev.org/openstack/openstack-specs refs/changes/05/174105/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/supported-messaging-drivers.rst'],1,ff19d9ba86cd18459bb912acdb9cedccc6076151,,".. ============================= Supported Messaging Drivers ============================= We need to define a policy on messaging in general. Problem description =================== OpenStack has gravitated toward using RabbitMQ for message passing. There are numerous excellent alternatives available as backends, including QPID and 0mq, but only RabbitMQ has received attention direclty in the community at large. As a result, more and more users of these backends are switching to RabbitMQ, and this leaves QPID code lying around that is not well tested and not well supported by the community. Said code will continue to be a burden, and should be removed if it is doing more harm than good. There is also anecdotal evidence that users are using the zmq driver to achieve high scale with fixes, but the zmq driver is not well tested either, which may actually be worse than not having it at all, as now anecdotes are passed from user to user but results will be very different for users who stick to upstream code. Proposed change =============== RabbitMQ may not be sufficient for the entire community as the community grows. Pluggability is still something we should maintain, but we should have a very high standard for drivers that are shipped and documented as being supported. We will define a very clear policy as to the requirements for drivers to be carried in oslo.messaging and thus supported by the OpenStack community as a whole. We will deprecate any drivers that do not meet the requirements, and announce said deprecations in any appropriate channels to give users time to signal their needs. Deprecation will last for two release cycles before removing the code. We will also review and update documentation to annotate which drivers are supported and which are deprecated given these policies Policy ------ Testing ~~~~~~~ * Must have unit and/or functional test coverage of at least 60% as reported by coverage report. * Must have integration testing including at least 3 popular oslo.messaging dependents, preferrably at the minimum a devstack-gate job with Nova, Cinder, and Neutron. * All testing above must be voting in the gate of oslo.messaging. Documentation ~~~~~~~~~~~~~ * Must have a reasonable amount of documentation including documentation in the official OpenStack deployment guide. Support ~~~~~~~ * Must have at least two individuals from the community commited to triaging and fixing bugs, and responding to test failures in a timely manner. Alternatives ------------ We could remove pluggability from oslo.messaging entirely, and just ship RabbitMQ drivers. This option would alienate users who have private drivers, and would also force users of the zmq driver who are trying to fix it to abandon those efforts and try to scale with RabbitMQ. Implementation ============== Assignee(s) ----------- Clint ""SpamapS"" Byrum Work Items ---------- - Record policy in oslo developer documentation - Announce policy to mailing lists - Mark non-compliant drivers as deprecated - Update configuration guides to note non-supported drivers - After deprecation period, remove non-compliant drivers from code and docs Dependencies ============ N/A History ======= .. list-table:: Revisions :header-rows: 1 * - Liberty - Introduced .. note:: This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ",,114,0
openstack%2Fbifrost~master~I02fce16edd9d1494a7bee3c534db4c264923a12d,openstack/bifrost,master,I02fce16edd9d1494a7bee3c534db4c264923a12d,Update test-birfrost to limit log lines,MERGED,2015-06-02 17:58:53.000000000,2015-06-10 12:23:02.000000000,2015-06-10 12:23:00.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 12459}, {'_account_id': 13997}]","[{'number': 1, 'created': '2015-06-02 17:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/be76173ec662f0958fc766777712a24e25e3c12f', 'message': 'Update test-birfrost to limit log lines\n\ntest-birfrost notes that only the last 1000 lines of some log files\nwill be output, but uses cat to dump the entire file. This patch limits\noutput to 1000 lines.\n\nChange-Id: I02fce16edd9d1494a7bee3c534db4c264923a12d\n'}, {'number': 2, 'created': '2015-06-02 22:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/19798f35079765a94cd9082b7ab332ea5a8bca54', 'message': 'Update test-birfrost to limit log lines\n\ntest-birfrost notes that only the last 1000 lines of some log files\nwill be output, but uses cat to dump the entire file. This patch limits\noutput to 1000 lines.\n\nChange-Id: I02fce16edd9d1494a7bee3c534db4c264923a12d\n'}, {'number': 3, 'created': '2015-06-03 11:49:38.000000000', 'files': ['scripts/test-bifrost.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0609604ec88e74d6b7d4842aee279be6b3f0f8e9', 'message': 'Update test-birfrost to limit log lines\n\ntest-birfrost notes that only the last 1000 lines of some log files\nwill be output, but uses cat to dump the entire file. This patch limits\noutput to 1000 lines.\n\nChange-Id: I02fce16edd9d1494a7bee3c534db4c264923a12d\n'}]",0,187703,0609604ec88e74d6b7d4842aee279be6b3f0f8e9,17,6,3,5805,,,0,"Update test-birfrost to limit log lines

test-birfrost notes that only the last 1000 lines of some log files
will be output, but uses cat to dump the entire file. This patch limits
output to 1000 lines.

Change-Id: I02fce16edd9d1494a7bee3c534db4c264923a12d
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/03/187703/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/test-bifrost.sh'],1,be76173ec662f0958fc766777712a24e25e3c12f,test_cat_cmd_update, sudo tail -n 1000 /var/log/upstart/ironic-api.log sudo tail -n 1000 /var/log/upstart/ironic-conductor.log, sudo cat /var/log/upstart/ironic-api.log sudo cat /var/log/upstart/ironic-conductor.log,2,2
openstack%2Fglance~master~I72016c5c7868fdc7a72def8b6f5a05324dcee387,openstack/glance,master,I72016c5c7868fdc7a72def8b6f5a05324dcee387,Fix HTTP 500 on NotAuthenticated in registry (v2),MERGED,2015-05-18 15:29:44.000000000,2015-06-10 12:19:09.000000000,2015-06-10 12:19:06.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6484}, {'_account_id': 9303}, {'_account_id': 11391}, {'_account_id': 13717}]","[{'number': 1, 'created': '2015-05-18 15:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/957eef97cd299841c6a11102e4ac86e1346eb952', 'message': 'Fix HTTP 500 on NotAuthenticated in registry (v2)\n\nIf for some reason (absent\\invalid token) authentication fails during a\nregistry call, 401 Unauthorized will be raised instead of former 500\nInternalServerError.\n\nChange-Id: I72016c5c7868fdc7a72def8b6f5a05324dcee387\nCloses-Bug: #1451850\n'}, {'number': 2, 'created': '2015-06-09 18:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b08318e604b6d93501ac1ed71332df948c50703d', 'message': 'Fix HTTP 500 on NotAuthenticated in registry (v2)\n\nIf for some reason (absent\\invalid token) authentication fails during a\nregistry call, 401 Unauthorized will be raised instead of former 500\nInternalServerError.\n\nChange-Id: I72016c5c7868fdc7a72def8b6f5a05324dcee387\nCloses-Bug: #1451850\n'}, {'number': 3, 'created': '2015-06-09 19:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7a98b90c5b421a42c5c93b2a009a07889b48faae', 'message': 'Fix HTTP 500 on NotAuthenticated in registry (v2)\n\nIf for some reason (absent\\invalid token) authentication failed during a\nregistry call, InternalServerError appeared as long as exception.NotAuthenticated was not being caught in ImageController methods. \n\nThis patch fixes the issue by catching the exception and raising 401 Unauthorized. \n\nChange-Id: I72016c5c7868fdc7a72def8b6f5a05324dcee387\nCloses-Bug: #1451850\n'}, {'number': 4, 'created': '2015-06-09 19:12:03.000000000', 'files': ['glance/tests/functional/v2/test_images.py', 'glance/api/v2/images.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/9906d3493b22e6965a2a072696c404c9e8b6ae60', 'message': 'Fix HTTP 500 on NotAuthenticated in registry (v2)\n\nIf for some reason (absent\\invalid token) authentication failed during a\nregistry call, InternalServerError appeared as long as\nexception.NotAuthenticated was not being caught in ImagesController.\n\nThis patch fixes the issue by catching the exception and raising\n401 Unauthorized.\n\nChange-Id: I72016c5c7868fdc7a72def8b6f5a05324dcee387\nCloses-Bug: #1451850\n'}]",0,184082,9906d3493b22e6965a2a072696c404c9e8b6ae60,19,7,4,13717,,,0,"Fix HTTP 500 on NotAuthenticated in registry (v2)

If for some reason (absent\invalid token) authentication failed during a
registry call, InternalServerError appeared as long as
exception.NotAuthenticated was not being caught in ImagesController.

This patch fixes the issue by catching the exception and raising
401 Unauthorized.

Change-Id: I72016c5c7868fdc7a72def8b6f5a05324dcee387
Closes-Bug: #1451850
",git fetch https://review.opendev.org/openstack/glance refs/changes/82/184082/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/v2/test_images.py', 'glance/api/v2/images.py']",2,957eef97cd299841c6a11102e4ac86e1346eb952,bug/1451850, except exception.NotAuthenticated as e: raise webob.exc.HTTPUnauthorized(explanation=e.msg) except exception.NotAuthenticated as e: raise webob.exc.HTTPUnauthorized(explanation=e.msg) except exception.NotAuthenticated as e: raise webob.exc.HTTPUnauthorized(explanation=e.msg) except exception.NotAuthenticated as e: raise webob.exc.HTTPUnauthorized(explanation=e.msg) except exception.NotAuthenticated as e: raise webob.exc.HTTPUnauthorized(explanation=e.msg),,44,0
openstack%2Fsahara-specs~master~Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b,openstack/sahara-specs,master,Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b,Adding custom scenario tests,MERGED,2015-06-05 15:02:28.000000000,2015-06-10 12:18:16.000000000,2015-06-10 12:18:15.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13919}]","[{'number': 1, 'created': '2015-06-05 15:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/522b4900c2a58776c321b1f23c44e6953e561299', 'message': 'Adding custom scenario tests\n\nSpec describes adding custom checks for scenario tests\n\nChange-Id: Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b\n'}, {'number': 2, 'created': '2015-06-05 15:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/c116ca346bb0400477200c3ccf3c305474969a09', 'message': 'Adding custom scenario tests\n\nSpec describes adding custom checks for scenario tests\n\nChange-Id: Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b\n'}, {'number': 3, 'created': '2015-06-08 07:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/eb66e6b3fb6b5eaf6c882a6bcc2aaabd1f338be7', 'message': 'Adding custom scenario tests\n\nSpec describes adding custom checks for scenario tests\n\nbp custom-check\n\nChange-Id: Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b\n'}, {'number': 4, 'created': '2015-06-08 07:52:57.000000000', 'files': ['specs/liberty/adding-custom-scenario-tests.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/a81bf472c201aafa9a7161005ba8b90f4de101aa', 'message': 'Adding custom scenario tests\n\nSpec describes adding custom checks for scenario tests\nbp custom-check\n\nChange-Id: Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b\n'}]",6,188807,a81bf472c201aafa9a7161005ba8b90f4de101aa,18,6,4,13919,,,0,"Adding custom scenario tests

Spec describes adding custom checks for scenario tests
bp custom-check

Change-Id: Ia8b4fdaaed9286df5570d198dbcf9aae0c56219b
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/07/188807/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/adding-custom-scenario-tests.rst'],1,522b4900c2a58776c321b1f23c44e6953e561299,bp/custom-check,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================== Adding custom scenario to scenario tests ======================================== This specification proposes to add custom tests to scenario tests for more exhaustive testing of Sahara. Problem description =================== Now, scenario tests testing of basic functionality and user can not add custom personal tests for check of other functionality in Sahara. Extra tests should be added: * checks for mount and available cinder volumes; * checks for started services on cluster; * checks for other processes that now not testing Proposed change =============== Custom test need add to sahara/tests/scenario/custom_checks and need implement support of this scenarios in scenario tests. For implementation this spec, need change field parameters for field ""scenario"" in scenario tests. Now is type ""enum"", need change to ""string"" for adding ability set custom tests. Additionally, should be rewrite sahara/tests/scenario/testcase.py.mako template. Custom tests will be called from module with name in format `check_{name of check}` with method `check()` inside. All auxiliary methods for current custom check will be written in module with this tests. Methods, for global using in several custom scenario can be implemented in sahara/tests/scenario/base.py. Alternatives ------------ Tests can be added manually to scenario tests in Base class. Data model impact ----------------- None REST API impact --------------- None Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- None Sahara-image-elements impact ---------------------------- None Sahara-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: esikachev Work Items ---------- * Adding ability to run custom scenario tests; * Move old custom check to scenario tests; * Adding new custom checks. Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== None ",,118,0
openstack%2Fceilometer~master~Iaed05cac703604639608e5fd203cffc2ed474e34,openstack/ceilometer,master,Iaed05cac703604639608e5fd203cffc2ed474e34,Merge tag '2014.2',MERGED,2014-10-16 12:26:38.000000000,2015-06-10 12:14:29.000000000,2015-06-10 12:14:26.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7729}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13273}, {'_account_id': 15843}]","[{'number': 1, 'created': '2014-10-16 12:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/db96eff47891a7db56ded75bce8cb51ac4144b21', 'message': ""Merge tag '2014.2'\n\nCeilometer 2014.2\n\nChange-Id: Iaed05cac703604639608e5fd203cffc2ed474e34\n""}, {'number': 2, 'created': '2015-06-09 16:36:29.000000000', 'files': ['ceilometer/tests/ipmi/pollsters/test_sensor.py', 'tools/config/oslo.config.generator.rc', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'requirements.txt', 'ceilometer/tests/ipmi/pollsters/test_node.py', 'ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/tests/ipmi/pollsters/base.py', 'ceilometer/ipmi/platform/intel_node_manager.py', 'requirements-py3.txt', 'ceilometer/ipmi/pollsters/node.py', 'ceilometer/locale/ceilometer.pot'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e67bdae2a2430d5d7763e83daa202bcb5cebf619', 'message': ""Merge tag '2014.2'\n\nThis is a null-merge of the 2014.2 release tag back into the\nmaster branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: Iaed05cac703604639608e5fd203cffc2ed474e34\n""}]",0,128905,e67bdae2a2430d5d7763e83daa202bcb5cebf619,25,10,2,11131,,,0,"Merge tag '2014.2'

This is a null-merge of the 2014.2 release tag back into the
master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: Iaed05cac703604639608e5fd203cffc2ed474e34
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/05/128905/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/ipmi/pollsters/test_sensor.py', 'ceilometer/ipmi/pollsters/sensor.py', 'tools/config/oslo.config.generator.rc', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po', 'ceilometer/tests/ipmi/pollsters/base.py', 'ceilometer/ipmi/platform/intel_node_manager.py', 'ceilometer/locale/ceilometer.pot']",7,db96eff47891a7db56ded75bce8cb51ac4144b21,merge/release-tag,,"<<<<<<< HEAD (f3994f Merge ""add script to generate test event data"")======= ""Project-Id-Version: ceilometer 2014.2.dev9.g2adf348\n"" >>>>>>> BRANCH (94579b Merge ""Fix recording failure for system pollster"" into propo)<<<<<<< HEAD (f3994f Merge ""add script to generate test event data"")======= ""POT-Creation-Date: 2014-10-07 16:24+0000\n"" >>>>>>> BRANCH (94579b Merge ""Fix recording failure for system pollster"" into propo)<<<<<<< HEAD (f3994f Merge ""add script to generate test event data"")======= #: ceilometer/alarm/storage/impl_hbase.py:129 #: ceilometer/storage/impl_hbase.py:193 #, python-format msgid ""connecting to HBase on %(host)s:%(port)s"" msgstr """" #: ceilometer/api/app.py:165 >>>>>>> BRANCH (94579b Merge ""Fix recording failure for system pollster"" into propo)<<<<<<< HEAD (f3994f Merge ""add script to generate test event data"")======= #: ceilometer/api/app.py:166 >>>>>>> BRANCH (94579b Merge ""Fix recording failure for system pollster"" into propo)<<<<<<< HEAD (f3994f Merge ""add script to generate test event data"")======= #: ceilometer/api/app.py:170 >>>>>>> BRANCH (94579b Merge ""Fix recording failure for system pollster"" into propo)<<<<<<< HEAD (f3994f Merge ""add script to generate test event data"")======= #: ceilometer/api/app.py:174 >>>>>>> BRANCH (94579b Merge ""Fix recording failure for system pollster"" into propo)",0,93
openstack%2Fopenstack-ansible~juno~I7f1933680e2859e007f6b8be262852b164f90b33,openstack/openstack-ansible,juno,I7f1933680e2859e007f6b8be262852b164f90b33,Generate a SHA-2 certificate for Horizon,MERGED,2015-06-10 03:22:50.000000000,2015-06-10 12:10:18.000000000,2015-06-10 12:10:16.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 8119}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-10 03:22:50.000000000', 'files': ['rpc_deployment/roles/openssl_pem_request/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dc862c803c6e9839f814ba31f2a2271b9d356611', 'message': 'Generate a SHA-2 certificate for Horizon\n\nSHA-1 certificates are being deprecated and browsers are starting to\nissue warnings about their use. We should begin generating SHA-2\ncertificates for Horizon.\n\nCloses-bug: 1461983\nChange-Id: I7f1933680e2859e007f6b8be262852b164f90b33\n(cherry picked from commit ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327)\n'}]",0,190006,dc862c803c6e9839f814ba31f2a2271b9d356611,10,6,1,12000,,,0,"Generate a SHA-2 certificate for Horizon

SHA-1 certificates are being deprecated and browsers are starting to
issue warnings about their use. We should begin generating SHA-2
certificates for Horizon.

Closes-bug: 1461983
Change-Id: I7f1933680e2859e007f6b8be262852b164f90b33
(cherry picked from commit ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/06/190006/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/openssl_pem_request/tasks/main.yml'],1,dc862c803c6e9839f814ba31f2a2271b9d356611,bug/1461983, openssl req -newkey -sha256 rsa:2048, openssl req -newkey rsa:2048,1,1
openstack%2Fopenstack-ansible~kilo~I7f1933680e2859e007f6b8be262852b164f90b33,openstack/openstack-ansible,kilo,I7f1933680e2859e007f6b8be262852b164f90b33,Generate a SHA-2 certificate for Horizon,MERGED,2015-06-10 03:23:01.000000000,2015-06-10 12:10:16.000000000,2015-06-10 12:10:15.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7307}, {'_account_id': 8119}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-10 03:23:01.000000000', 'files': ['playbooks/roles/os_horizon/tasks/horizon_ssl_key_create.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b7a46b42ec0a24b3971865fd91fc002edbda6e12', 'message': 'Generate a SHA-2 certificate for Horizon\n\nSHA-1 certificates are being deprecated and browsers are starting to\nissue warnings about their use. We should begin generating SHA-2\ncertificates for Horizon.\n\nCloses-bug: 1461983\nChange-Id: I7f1933680e2859e007f6b8be262852b164f90b33\n(cherry picked from commit ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327)\n'}]",0,190007,b7a46b42ec0a24b3971865fd91fc002edbda6e12,9,5,1,12000,,,0,"Generate a SHA-2 certificate for Horizon

SHA-1 certificates are being deprecated and browsers are starting to
issue warnings about their use. We should begin generating SHA-2
certificates for Horizon.

Closes-bug: 1461983
Change-Id: I7f1933680e2859e007f6b8be262852b164f90b33
(cherry picked from commit ed29e8a3d9e9f102158e35f8b0ea7bd3ef278327)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/07/190007/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_horizon/tasks/horizon_ssl_key_create.yml'],1,b7a46b42ec0a24b3971865fd91fc002edbda6e12,bug/1461983, openssl req -new -nodes -sha256 -x509 -subj, openssl req -new -nodes -x509 -subj,1,1
openstack%2Fceilometer~master~I7287a160b510bdb91a68594874bbbba45e6a210f,openstack/ceilometer,master,I7287a160b510bdb91a68594874bbbba45e6a210f,add DNS events,MERGED,2015-05-29 23:44:04.000000000,2015-06-10 12:02:34.000000000,2015-06-10 12:02:32.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7729}, {'_account_id': 11189}, {'_account_id': 11564}, {'_account_id': 13560}, {'_account_id': 14320}, {'_account_id': 15843}, {'_account_id': 16044}]","[{'number': 1, 'created': '2015-05-29 23:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/db12d09c4bd7ca6a9e22f7ab0914d4c25b9bdbd8', 'message': 'add DNS events\n\nthis patch adds support for dns crud notifications\nas events in ceilometer.\n\nChange-Id: I7287a160b510bdb91a68594874bbbba45e6a210f\nPartially-Implements: blueprint dns-service-notifications\n'}, {'number': 2, 'created': '2015-06-04 18:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ec4835d899c9a36e5cac2f8de612962dccacfdcd', 'message': 'add DNS events\n\nthis patch adds support for dns crud notifications\nas events in ceilometer.\n\nChange-Id: I7287a160b510bdb91a68594874bbbba45e6a210f\nPartially-Implements: blueprint dns-service-notifications\n'}, {'number': 3, 'created': '2015-06-09 15:11:04.000000000', 'files': ['etc/ceilometer/event_definitions.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/22cf71f1f2e68a49f65062c606dc95dab0246d54', 'message': 'add DNS events\n\nthis patch adds support for dns crud notifications\nas events in ceilometer.\n\nChange-Id: I7287a160b510bdb91a68594874bbbba45e6a210f\nPartially-Implements: blueprint dns-service-notifications\n'}]",3,186962,22cf71f1f2e68a49f65062c606dc95dab0246d54,27,10,3,13560,,,0,"add DNS events

this patch adds support for dns crud notifications
as events in ceilometer.

Change-Id: I7287a160b510bdb91a68594874bbbba45e6a210f
Partially-Implements: blueprint dns-service-notifications
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/62/186962/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/ceilometer/event_definitions.yaml'],1,db12d09c4bd7ca6a9e22f7ab0914d4c25b9bdbd8,bp/dns-service-notifications,"- event_type: ['dns.domain.create', 'dns.domain.update', 'dns.domain.delete'] traits: &dns_domain_traits status: fields: payload.status retry: fields: payload.retry description: fields: payload.description expire: fields: payload.expire email: fields: payload.email ttl: fields: payload.ttl action: fields: payload.action name: fields: payload.name id: fields: payload.id created_at: fields: payload.created_at updated_at: fields: payload.updated_at version: fields: payload.version parent_domain_id: fields: parent_domain_id serial: fields: payload.serial",,30,0
openstack%2Fha-guide~master~I832a6a8d1e8dbb00aee200e263697b46c0117731,openstack/ha-guide,master,I832a6a8d1e8dbb00aee200e263697b46c0117731,Basic installation info from old ha-guide,MERGED,2015-05-21 20:21:46.000000000,2015-06-10 12:01:54.000000000,2015-06-10 12:01:53.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9382}, {'_account_id': 10014}, {'_account_id': 11444}, {'_account_id': 14947}]","[{'number': 1, 'created': '2015-05-21 20:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/06576b4b0735144b3a88095d65b5355a99ec5b52', 'message': 'Basic installatin info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 2, 'created': '2015-05-26 02:05:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/b619f962a94afc622bd8280f405cceee7ca7d6f4', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 3, 'created': '2015-05-28 09:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/9aef5eb91e37fd5aa3987a8e47b72437e05d3abd', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 4, 'created': '2015-05-28 10:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/44d981de573af56b4a511708d2bcb98be6ab28fe', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 5, 'created': '2015-05-28 11:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/bd5003dd60de76d643e02f8964329306ce1eb21d', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 6, 'created': '2015-06-04 22:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/d43d29fcaea4c37fe94a9875a8fb32904f42c00d', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 7, 'created': '2015-06-05 05:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/28208dbf0715d0c5e0343bab39b6fa1980331e2b', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}, {'number': 8, 'created': '2015-06-10 09:09:42.000000000', 'files': ['doc/ha-guide/source/install-ha.rst', 'doc/ha-guide/source/install-ha-memcached.rst', 'doc/ha-guide/source/install-ha-os.rst', 'doc/ha-guide/source/hardware-ha.rst', 'doc/ha-guide/source/install-ha-vip.rst', 'doc/ha-guide/source/install-ha-ntp.rst', 'doc/ha-guide/source/hardware-ha-basic.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/0f92295fa09a30b3f7dd07dfc0d6434a725575e6', 'message': 'Basic installation info from old ha-guide\n\nChange-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731\n'}]",12,184858,0f92295fa09a30b3f7dd07dfc0d6434a725575e6,36,6,8,10014,,,0,"Basic installation info from old ha-guide

Change-Id: I832a6a8d1e8dbb00aee200e263697b46c0117731
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/58/184858/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/install-ha.rst', 'doc/ha-guide/source/install-ha-memcached.rst', 'doc/ha-guide/source/install-ha-os.rst', 'doc/ha-guide/source/hardware-ha.rst', 'doc/ha-guide/source/hardware-ha-basic.rst', 'doc/ha-guide/source/install-ha-ntp.rst']",6,06576b4b0735144b3a88095d65b5355a99ec5b52,install, ============= Configure NTP ============= ,,83,0
openstack%2Fceilometer~master~I058419b25f55dcfd93af522aa1f5f61b8f06407e,openstack/ceilometer,master,I058419b25f55dcfd93af522aa1f5f61b8f06407e,Switch from MySQL-python to PyMySQL,MERGED,2015-05-20 01:07:21.000000000,2015-06-10 12:00:20.000000000,2015-06-10 12:00:18.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6537}, {'_account_id': 11564}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-05-20 01:07:21.000000000', 'files': ['doc/source/install/manual.rst', 'test-requirements.txt', 'setup-test-env-mysql.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6b7d6f68a848e2f1359d92fab7bc5bc90e294d2c', 'message': 'Switch from MySQL-python to PyMySQL\n\nAs discussed in the Liberty Design Summit ""Moving apps to Python 3""\ncross-project workshop, the way forward in the near future is to\nswitch to the pure-python PyMySQL library as a default.\n\nhttps://etherpad.openstack.org/p/liberty-cross-project-python3\n\nChange-Id: I058419b25f55dcfd93af522aa1f5f61b8f06407e\n'}]",0,184368,6b7d6f68a848e2f1359d92fab7bc5bc90e294d2c,10,5,1,5263,,,0,"Switch from MySQL-python to PyMySQL

As discussed in the Liberty Design Summit ""Moving apps to Python 3""
cross-project workshop, the way forward in the near future is to
switch to the pure-python PyMySQL library as a default.

https://etherpad.openstack.org/p/liberty-cross-project-python3

Change-Id: I058419b25f55dcfd93af522aa1f5f61b8f06407e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/68/184368/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/manual.rst', 'test-requirements.txt', 'setup-test-env-mysql.sh']",3,6b7d6f68a848e2f1359d92fab7bc5bc90e294d2c,pymysql-switch,"export CEILOMETER_TEST_MYSQL_URL=""mysql+pymysql://root@localhost/template1?unix_socket=${MYSQL_DATA}/mysql.socket&charset=utf8""","export CEILOMETER_TEST_MYSQL_URL=""mysql://root@localhost/template1?unix_socket=${MYSQL_DATA}/mysql.socket&charset=utf8""",3,3
openstack%2Fironic-inspector~master~I8401f95236e269583257c3c5ba3762d0920d32e8,openstack/ironic-inspector,master,I8401f95236e269583257c3c5ba3762d0920d32e8,Naming clean up,MERGED,2015-06-08 15:09:05.000000000,2015-06-10 11:53:11.000000000,2015-06-10 11:53:11.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 7882}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-06-08 15:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/f25eee9b1f9f9c3a1495e024ab704285812e67e0', 'message': 'Naming clean up\n\nThis refactoring patch fixes a few naming problems:\n* namespace for processing hooks implied that it\'s the only type\n  of hooks, added "".processing"" postfix\n* node_info -> introspection_data\n* cached_node -> node_info\n\nChange-Id: I8401f95236e269583257c3c5ba3762d0920d32e8\nImplements: blueprint plugin-interface-v2\n'}, {'number': 2, 'created': '2015-06-09 13:44:43.000000000', 'files': ['ironic_inspector/introspect.py', 'ironic_inspector/process.py', 'ironic_inspector/test/test_introspect.py', 'ironic_inspector/test/test_plugins_root_device_hint.py', 'ironic_inspector/plugins/root_device_hint.py', 'setup.py', 'ironic_inspector/test/test_plugins_edeploy.py', 'ironic_inspector/plugins/example.py', 'ironic_inspector/test/test_main.py', 'ironic_inspector/plugins/edeploy.py', 'ironic_inspector/plugins/standard.py', 'ironic_inspector/plugins/base.py', 'ironic_inspector/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/d09da96e02e8ef7edbe102caf890b3f20c7a9f54', 'message': 'Naming clean up\n\nThis refactoring patch fixes a few naming problems:\n* namespace for processing hooks implied that it\'s the only type\n  of hooks, added "".processing"" postfix\n* node_info -> introspection_data\n* cached_node -> node_info\n\nChange-Id: I8401f95236e269583257c3c5ba3762d0920d32e8\nImplements: blueprint plugin-interface-v2\n'}]",1,189329,d09da96e02e8ef7edbe102caf890b3f20c7a9f54,11,4,2,10239,,,0,"Naming clean up

This refactoring patch fixes a few naming problems:
* namespace for processing hooks implied that it's the only type
  of hooks, added "".processing"" postfix
* node_info -> introspection_data
* cached_node -> node_info

Change-Id: I8401f95236e269583257c3c5ba3762d0920d32e8
Implements: blueprint plugin-interface-v2
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/29/189329/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/introspect.py', 'ironic_inspector/process.py', 'ironic_inspector/test/test_introspect.py', 'ironic_inspector/test/test_plugins_root_device_hint.py', 'ironic_inspector/plugins/root_device_hint.py', 'setup.py', 'ironic_inspector/test/test_plugins_edeploy.py', 'ironic_inspector/plugins/example.py', 'ironic_inspector/test/test_main.py', 'ironic_inspector/plugins/edeploy.py', 'ironic_inspector/plugins/standard.py', 'ironic_inspector/plugins/base.py', 'ironic_inspector/test/test_process.py']",13,f25eee9b1f9f9c3a1495e024ab704285812e67e0,bp/plugin-interface-v2," self.node_info = node_cache.NodeInfo(uuid=self.uuid, started_at=self.started_at) return process._process_node(self.node, self.data, self.node_info) self.node_info.set_option('new_ipmi_credentials', self.new_creds) self.node_info.set_option('new_ipmi_credentials', self.new_creds) self.node_info.set_option('new_ipmi_credentials', self.new_creds) self.node_info.set_option('new_ipmi_credentials', self.new_creds)"," self.cached_node = node_cache.NodeInfo(uuid=self.uuid, started_at=self.started_at) return process._process_node(self.node, self.data, self.cached_node) self.cached_node.set_option('new_ipmi_credentials', self.new_creds) self.cached_node.set_option('new_ipmi_credentials', self.new_creds) self.cached_node.set_option('new_ipmi_credentials', self.new_creds) self.cached_node.set_option('new_ipmi_credentials', self.new_creds)",193,177
openstack%2Fironic-inspector~master~If2060095d7f4c11bd25ea0e0e2fd5e8aca1d53a5,openstack/ironic-inspector,master,If2060095d7f4c11bd25ea0e0e2fd5e8aca1d53a5,Add node() and ports() to NodeInfo,MERGED,2015-06-08 14:23:18.000000000,2015-06-10 11:53:06.000000000,2015-06-10 11:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 7882}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-06-08 14:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/6b616655af543c6674f7cbe6831835e07392ce27', 'message': 'Add node() and ports() to NodeInfo\n\nWill be useful for plugins once we pass NodeInfo in.\nImplements: blueprint plugin-interface-v2\n\nChange-Id: If2060095d7f4c11bd25ea0e0e2fd5e8aca1d53a5\n'}, {'number': 2, 'created': '2015-06-09 13:44:43.000000000', 'files': ['ironic_inspector/node_cache.py', 'ironic_inspector/introspect.py', 'ironic_inspector/process.py', 'ironic_inspector/test/test_introspect.py', 'ironic_inspector/test/test_node_cache.py', 'ironic_inspector/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/3ac546b1576c32051f74db1ae0facea3bf80d93a', 'message': 'Add node() and ports() to NodeInfo\n\nWill be useful for plugins once we pass NodeInfo in.\nImplements: blueprint plugin-interface-v2\n\nChange-Id: If2060095d7f4c11bd25ea0e0e2fd5e8aca1d53a5\n'}]",8,189310,3ac546b1576c32051f74db1ae0facea3bf80d93a,15,3,2,10239,,,0,"Add node() and ports() to NodeInfo

Will be useful for plugins once we pass NodeInfo in.
Implements: blueprint plugin-interface-v2

Change-Id: If2060095d7f4c11bd25ea0e0e2fd5e8aca1d53a5
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/10/189310/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/node_cache.py', 'ironic_inspector/introspect.py', 'ironic_inspector/process.py', 'ironic_inspector/test/test_introspect.py', 'ironic_inspector/test/test_process.py']",5,6b616655af543c6674f7cbe6831835e07392ce27,bp/plugin-interface-v2," process_mock.assert_called_once_with(cli.node.get.return_value, process_mock.assert_called_once_with(cli.node.get.return_value, process_mock.assert_called_once_with(cli.node.get.return_value, process_mock.assert_called_once_with(cli.node.get.return_value, process_mock.assert_called_once_with(cli.node.get.return_value, process_mock.assert_called_once_with(cli.node.get.return_value, process_mock.assert_called_once_with(cli.node.get.return_value, @mock.patch.object(utils, 'get_client') def call(self, mock_cli): mock_cli.return_value = self.cli return process._process_node(self.node, self.data, self.cached_node)"," process_mock.assert_called_once_with(cli, cli.node.get.return_value, process_mock.assert_called_once_with(cli, cli.node.get.return_value, process_mock.assert_called_once_with(cli, cli.node.get.return_value, process_mock.assert_called_once_with(cli, cli.node.get.return_value, process_mock.assert_called_once_with(cli, cli.node.get.return_value, process_mock.assert_called_once_with(cli, cli.node.get.return_value, process_mock.assert_called_once_with(cli, cli.node.get.return_value, def call(self): return process._process_node(self.cli, self.node, self.data, self.cached_node)",43,28
openstack%2Ffreezer~master~Iaae4d028cd19e1732925ec5bd86665b839528cd3,openstack/freezer,master,Iaae4d028cd19e1732925ec5bd86665b839528cd3,Reduce SQL Server downtime and Snapshot option on windows,MERGED,2015-06-09 09:46:40.000000000,2015-06-10 11:40:07.000000000,2015-06-10 11:40:07.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 12211}, {'_account_id': 14159}, {'_account_id': 14340}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-06-09 09:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/1d6610d11d4f6e9a8919fd007605e154cee92267', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 2, 'created': '2015-06-09 09:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/b54cf47b9c320120e1c3824e177dadb6d19b018b', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 3, 'created': '2015-06-09 10:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c6c8195726eb6316a25e368e504f714e58354ffb', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 4, 'created': '2015-06-09 13:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/a3125649e499e9285965c228da2804516ced267e', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 5, 'created': '2015-06-10 11:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/c74d7480f9c2772a82be1ed967911ab470707d8f', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 6, 'created': '2015-06-10 11:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/6988025ee0b12b0e39628b806e74f545104aca2e', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 7, 'created': '2015-06-10 11:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/5c19ec99c3575fef4c52cf4d37e91982e82c68d9', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}, {'number': 8, 'created': '2015-06-10 11:28:25.000000000', 'files': ['freezer/swift.py', 'freezer/vss.py', 'freezer/arguments.py', 'tests/test_vss.py', 'freezer/backup.py', 'freezer/winutils.py', 'README.rst', 'tests/test_arguments.py', 'tests/test_winutils.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/257ea34d238d5b3156eb253f081cac27c128465e', 'message': 'Reduce SQL Server downtime and Snapshot option on windows\n\nCLI argument for snapshots on windows (vssadmin)\nReduce downtime with SQL Server if a snapshot is available\n\nChange-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3\n'}]",0,189618,257ea34d238d5b3156eb253f081cac27c128465e,27,6,8,14340,,,0,"Reduce SQL Server downtime and Snapshot option on windows

CLI argument for snapshots on windows (vssadmin)
Reduce downtime with SQL Server if a snapshot is available

Change-Id: Iaae4d028cd19e1732925ec5bd86665b839528cd3
",git fetch https://review.opendev.org/openstack/freezer refs/changes/18/189618/3 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/swift.py', 'freezer/vss.py', 'freezer/arguments.py', 'tests/test_vss.py', 'freezer/backup.py', 'freezer/winutils.py', 'README.rst', 'tests/test_winutils.py']",8,1d6610d11d4f6e9a8919fd007605e154cee92267,volume_fix,"from freezer import winutilsimport logging def test_start_sql_server(self, monkeypatch): fake_disable_redirection = FakeDisableFileSystemRedirection() backup_opt = BackupOpt1() fakelogging = FakeLogging() fakesubprocess = FakeSubProcess() fakesubprocesspopen = fakesubprocess.Popen() monkeypatch.setattr( subprocess.Popen, 'communicate', fakesubprocesspopen.communicate) monkeypatch.setattr( subprocess, 'Popen', fakesubprocesspopen) monkeypatch.setattr( winutils.DisableFileSystemRedirection, '__enter__', fake_disable_redirection.__enter__) monkeypatch.setattr( winutils.DisableFileSystemRedirection, '__exit__', fake_disable_redirection.__exit__) monkeypatch.setattr(logging, 'info', fakelogging.info) assert winutils.start_sql_server(backup_opt) is not False fakesubprocess = FakeSubProcess3() fakesubprocesspopen = fakesubprocess.Popen() monkeypatch.setattr( subprocess.Popen, 'communicate', fakesubprocesspopen.communicate) monkeypatch.setattr( subprocess, 'Popen', fakesubprocesspopen) pytest.raises(Exception, winutils.start_sql_server(backup_opt)) def test_stop_sql_server(self, monkeypatch): fake_disable_redirection = FakeDisableFileSystemRedirection() backup_opt = BackupOpt1() fakelogging = FakeLogging() fakesubprocess = FakeSubProcess() fakesubprocesspopen = fakesubprocess.Popen() monkeypatch.setattr( subprocess.Popen, 'communicate', fakesubprocesspopen.communicate) monkeypatch.setattr( subprocess, 'Popen', fakesubprocesspopen) monkeypatch.setattr( winutils.DisableFileSystemRedirection, '__enter__', fake_disable_redirection.__enter__) monkeypatch.setattr( winutils.DisableFileSystemRedirection, '__exit__', fake_disable_redirection.__exit__) monkeypatch.setattr(logging, 'info', fakelogging.info) assert winutils.start_sql_server(backup_opt) is not False fakesubprocess = FakeSubProcess3() fakesubprocesspopen = fakesubprocess.Popen() monkeypatch.setattr( subprocess.Popen, 'communicate', fakesubprocesspopen.communicate) monkeypatch.setattr( subprocess, 'Popen', fakesubprocesspopen) pytest.raises(Exception, winutils.stop_sql_server(backup_opt))",,127,110
openstack%2Fnova~master~Ic753b11a48cb2c17c24c6636a456f00966f7c8ab,openstack/nova,master,Ic753b11a48cb2c17c24c6636a456f00966f7c8ab,volume: log which encryptor class is being used,MERGED,2015-06-09 16:11:08.000000000,2015-06-10 11:33:30.000000000,2015-06-10 05:15:35.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15524}, {'_account_id': 15751}, {'_account_id': 15888}]","[{'number': 1, 'created': '2015-06-09 16:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7295453051b8e30b3ddb60b8f64126d211b5500a', 'message': 'volume: log which encryptor class is being used\n\nAfter resolving which encryptor class to use with a cinder\nvolume, record it in the logs for easier debugging.\n\nChange-Id: Ic753b11a48cb2c17c24c6636a456f00966f7c8ab\n'}, {'number': 2, 'created': '2015-06-09 17:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3222d67ee7027888632aaf32ab8c10f53a4ee1ac', 'message': 'volume: log which encryptor class is being used\n\nAfter resolving which encryptor class to use with a cinder\nvolume, record it in the logs for easier debugging.\n\nChange-Id: Ic753b11a48cb2c17c24c6636a456f00966f7c8ab\n'}, {'number': 3, 'created': '2015-06-09 18:52:09.000000000', 'files': ['nova/volume/encryptors/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c13588517a270bd8349c084c1f210598917180d4', 'message': 'volume: log which encryptor class is being used\n\nAfter resolving which encryptor class to use with a cinder\nvolume, record it in the logs for easier debugging.\n\nRelated-Bug: #1463525\n\nChange-Id: Ic753b11a48cb2c17c24c6636a456f00966f7c8ab\n'}]",11,189799,c13588517a270bd8349c084c1f210598917180d4,44,13,3,1779,,,0,"volume: log which encryptor class is being used

After resolving which encryptor class to use with a cinder
volume, record it in the logs for easier debugging.

Related-Bug: #1463525

Change-Id: Ic753b11a48cb2c17c24c6636a456f00966f7c8ab
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/189799/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/volume/encryptors/__init__.py'],1,7295453051b8e30b3ddb60b8f64126d211b5500a,bug/1463525," LOG.debug(""Using encryptor %(encryptor)s for conn %(connection_info)s"", {'encryptor': encryptor, 'connection_info': connection_info}) ",,3,0
openstack%2Fneutron-vpnaas~master~I17e475b2a870a1ecdb2a1cacf2087a96beac3f78,openstack/neutron-vpnaas,master,I17e475b2a870a1ecdb2a1cacf2087a96beac3f78,VPNaaS: And devref doc infrastructure,MERGED,2015-06-03 21:40:20.000000000,2015-06-10 11:23:04.000000000,2015-06-09 23:08:02.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 10980}, {'_account_id': 12403}, {'_account_id': 13380}, {'_account_id': 14216}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-06-03 21:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/d5ea0552a5c7c89cddce8c4fa47095f81f7d338f', 'message': ""VPNaaS: And devref doc infrastructure\n\nThis wasn't setup in the reppo, so I'm adding it now. Empty for\nnow, with TODOs for some sections.\n\nChange-Id: I17e475b2a870a1ecdb2a1cacf2087a96beac3f78\n""}, {'number': 2, 'created': '2015-06-08 21:21:44.000000000', 'files': ['doc/source/index.rst', 'doc/source/devref/index.rst', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/18f3915374e4b12fd1f508c1e9402aa1e2b39b4f', 'message': 'VPNaaS: And devref doc infrastructure\n\nThis wasn\'t setup in the reppo, so I\'m adding it now. Empty for\nnow, with TODOs for some sections. The ""tox -e docs"" was updated\nto generate the documentation.\n\nChange-Id: I17e475b2a870a1ecdb2a1cacf2087a96beac3f78\n'}]",4,188185,18f3915374e4b12fd1f508c1e9402aa1e2b39b4f,18,11,2,6659,,,0,"VPNaaS: And devref doc infrastructure

This wasn't setup in the reppo, so I'm adding it now. Empty for
now, with TODOs for some sections. The ""tox -e docs"" was updated
to generate the documentation.

Change-Id: I17e475b2a870a1ecdb2a1cacf2087a96beac3f78
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/85/188185/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/devref/index.rst', 'tox.ini']",3,d5ea0552a5c7c89cddce8c4fa47095f81f7d338f,pcm/devref,commands = sphinx-build -W -b html doc/source doc/build,commands = python setup.py build_sphinx,119,11
openstack%2Fneutron-vpnaas~master~I3e2ba541142aefc38ca10e94400f942443c00f7b,openstack/neutron-vpnaas,master,I3e2ba541142aefc38ca10e94400f942443c00f7b,VPNaaS: Enable pylint duplicate-key check,MERGED,2015-06-04 16:57:33.000000000,2015-06-10 11:20:54.000000000,2015-06-10 05:11:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-06-04 16:57:33.000000000', 'files': ['.pylintrc'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/92030ba6e3589cfa76a65356f3b8a32e4281b234', 'message': 'VPNaaS: Enable pylint duplicate-key check\n\nI tried this in the VPNaaS repo and it passes, so we can enable\nthis, in a manner similar to Neutron (see review 188247 with commit\nIf4fed9714cd7fa586845f21f8f56dde2645cc5e0).\n\nChange-Id: I3e2ba541142aefc38ca10e94400f942443c00f7b\n'}]",0,188517,92030ba6e3589cfa76a65356f3b8a32e4281b234,10,6,1,6659,,,0,"VPNaaS: Enable pylint duplicate-key check

I tried this in the VPNaaS repo and it passes, so we can enable
this, in a manner similar to Neutron (see review 188247 with commit
If4fed9714cd7fa586845f21f8f56dde2645cc5e0).

Change-Id: I3e2ba541142aefc38ca10e94400f942443c00f7b
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/17/188517/1 && git format-patch -1 --stdout FETCH_HEAD,['.pylintrc'],1,92030ba6e3589cfa76a65356f3b8a32e4281b234,remove-dict-duplicate-keys,," duplicate-key,",0,1
openstack%2Fhorizon~master~I30a9e686baf2c428d0f76d8eb8320f9af3752256,openstack/horizon,master,I30a9e686baf2c428d0f76d8eb8320f9af3752256,DO NOT MERGE. TEST PATCH,ABANDONED,2015-06-10 11:10:26.000000000,2015-06-10 11:13:02.000000000,,[{'_account_id': 12826}],"[{'number': 1, 'created': '2015-06-10 11:10:26.000000000', 'files': ['horizon/templates/auth/_login.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f81e724486b2614a0ff2e68a691346f0ff7128e0', 'message': 'DO NOT MERGE. TEST PATCH\n\nChange-Id: I30a9e686baf2c428d0f76d8eb8320f9af3752256\nRelated-bug: #1463739\n'}]",0,190119,f81e724486b2614a0ff2e68a691346f0ff7128e0,3,1,1,8786,,,0,"DO NOT MERGE. TEST PATCH

Change-Id: I30a9e686baf2c428d0f76d8eb8320f9af3752256
Related-bug: #1463739
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/190119/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/auth/_login.html'],1,f81e724486b2614a0ff2e68a691346f0ff7128e0,,"{% block modal-header %}{% trans ""Log In TO PATCHED HORIZON!"" %}{% endblock %}","{% block modal-header %}{% trans ""Log In"" %}{% endblock %}",1,1
openstack%2Fec2-api~master~I7ce96f7ccddfa4df168bd442e5471c6193ae6f3c,openstack/ec2-api,master,I7ce96f7ccddfa4df168bd442e5471c6193ae6f3c,Sync with latest oslo-incubator,ABANDONED,2015-06-07 14:04:19.000000000,2015-06-10 11:09:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-07 14:04:19.000000000', 'files': ['ec2api/openstack/common/eventlet_backdoor.py', 'ec2api/openstack/common/service.py', 'ec2api/openstack/common/fileutils.py', 'openstack-common.conf', 'ec2api/openstack/common/threadgroup.py', 'ec2api/openstack/common/loopingcall.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0f15573733bd18ced359f8a646b60a4c610d982b', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: I7ce96f7ccddfa4df168bd442e5471c6193ae6f3c\n'}]",4,189102,0f15573733bd18ced359f8a646b60a4c610d982b,8,3,1,5638,,,0,"Sync with latest oslo-incubator

Change-Id: I7ce96f7ccddfa4df168bd442e5471c6193ae6f3c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/02/189102/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/openstack/common/eventlet_backdoor.py', 'ec2api/openstack/common/service.py', 'ec2api/openstack/common/fileutils.py', 'openstack-common.conf', 'ec2api/openstack/common/threadgroup.py', 'ec2api/openstack/common/loopingcall.py']",6,0f15573733bd18ced359f8a646b60a4c610d982b,," LOG.warning(_LW('task %(func_name)r run outlasted ' 'interval by %(delay).2f sec'), {'func_name': self.f, 'delay': delay})"," LOG.warn(_LW('task %(func_name)r run outlasted ' 'interval by %(delay).2f sec'), {'func_name': self.f, 'delay': delay})",32,33
openstack%2Fheat~master~I2e88cb9f04864c901a67340620949eb7c54d5543,openstack/heat,master,I2e88cb9f04864c901a67340620949eb7c54d5543,Merge tag '2015.1.0',MERGED,2015-04-30 23:30:00.000000000,2015-06-10 11:09:00.000000000,2015-06-10 07:38:06.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 5263}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-04-30 23:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2ee9c823d45d8ce9974fe897059b1da1a92982e3', 'message': ""Merge tag '2015.1.0'\n\nHeat 2015.1.0\n\nChange-Id: I2e88cb9f04864c901a67340620949eb7c54d5543\n""}, {'number': 2, 'created': '2015-06-09 17:45:13.000000000', 'files': ['heat/locale/pt_BR/LC_MESSAGES/heat-log-error.po', 'heat/engine/environment.py', '.gitreview', 'heat/tests/test_eip.py', 'contrib/nova_flavor/nova_flavor/tests/test_nova_flavor.py', 'heat/tests/test_security_group.py', 'heat/locale/de/LC_MESSAGES/heat-log-error.po', 'heat/engine/service.py', 'heat/tests/test_engine_service.py', 'requirements.txt', 'heat/tests/db/test_sqlalchemy_api.py', 'heat/engine/clients/os/nova.py', 'heat/engine/stack.py', 'heat/tests/db/test_migrations.py', 'heat/tests/test_api_cfn_v1.py', 'heat/locale/es/LC_MESSAGES/heat-log-info.po', 'heat/tests/test_nova_utils.py', 'heat/common/crypt.py', 'heat/tests/test_instance.py', 'heat/engine/resources/openstack/nova/server.py', 'heat/locale/fr/LC_MESSAGES/heat-log-error.po', 'heat/db/sqlalchemy/migrate_repo/versions/061_status_reason_longtext.py', 'heat/tests/nova/fakes.py', 'heat/tests/test_api_openstack_v1.py', 'heat/objects/stack.py', 'MANIFEST.in', 'heat/tests/test_hot.py', 'heat/tests/test_loadbalancer.py', 'heat/rpc/client.py', 'heat/db/sqlalchemy/migrate_repo/versions/062_parent_resource.py', 'heat/locale/es/LC_MESSAGES/heat-log-error.po', 'heat/tests/test_server.py', 'heat/locale/fr/LC_MESSAGES/heat-log-info.po', 'heat/tests/test_instance_network.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5d725ecd09a35e3d5fb042956c4ecebb309c0a41', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I2e88cb9f04864c901a67340620949eb7c54d5543\n""}]",0,179291,5d725ecd09a35e3d5fb042956c4ecebb309c0a41,18,6,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I2e88cb9f04864c901a67340620949eb7c54d5543
",git fetch https://review.opendev.org/openstack/heat refs/changes/91/179291/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/locale/pt_BR/LC_MESSAGES/heat-log-error.po', '.gitreview', 'heat/tests/test_eip.py', 'heat/tests/test_security_group.py', 'heat/locale/de/LC_MESSAGES/heat-log-error.po', 'heat/engine/service.py', 'heat/tests/test_engine_service.py', 'requirements.txt', 'heat/engine/clients/os/nova.py', 'heat/tests/test_api_cfn_v1.py', 'heat/locale/es/LC_MESSAGES/heat-log-info.po', 'heat/common/crypt.py', 'heat/tests/test_instance.py', 'heat/locale/fr/LC_MESSAGES/heat-log-error.po', 'heat/db/sqlalchemy/migrate_repo/versions/061_status_reason_longtext.py', 'heat/tests/nova/fakes.py', 'heat/tests/test_api_openstack_v1.py', 'heat/objects/stack.py', 'heat/tests/test_hot.py', 'heat/tests/test_loadbalancer.py', 'heat/rpc/client.py', 'heat/db/sqlalchemy/migrate_repo/versions/062_parent_resource.py', 'heat/locale/es/LC_MESSAGES/heat-log-error.po', 'heat/locale/fr/LC_MESSAGES/heat-log-info.po', 'heat/tests/test_instance_network.py']",25,2ee9c823d45d8ce9974fe897059b1da1a92982e3,merge/release-tag,,"<<<<<<< HEAD (5eb30d Merge ""Remove the is_id boolean check for domains"") ======= # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import copy import uuid from heat.common import template_format from heat.engine.clients.os import glance from heat.engine.clients.os import neutron from heat.engine.clients.os import nova from heat.engine import environment from heat.engine import parser from heat.engine.resources.aws.ec2 import instance as instances from heat.engine.resources.aws.ec2 import network_interface as net_interfaces from heat.engine import scheduler from heat.tests import common from heat.tests.nova import fakes as fakes_nova from heat.tests import utils wp_template = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Description"" : ""WordPress"", ""Parameters"" : { ""KeyName"" : { ""Description"" : ""KeyName"", ""Type"" : ""String"", ""Default"" : ""test"" }, ""InstanceType"": { ""Type"": ""String"", ""Description"": ""EC2 instance type"", ""Default"": ""m1.small"", ""AllowedValues"": [ ""m1.small"", ""m1.large"" ] }, ""SubnetId"": { ""Type"" : ""String"", ""Description"" : ""SubnetId of an existing subnet in your VPC"" }, }, ""Resources"" : { ""WebServer"": { ""Type"": ""AWS::EC2::Instance"", ""Properties"": { ""ImageId"" : ""F17-x86_64-gold"", ""InstanceType"" : { ""Ref"" : ""InstanceType"" }, ""SubnetId"" : { ""Ref"" : ""SubnetId"" }, ""KeyName"" : { ""Ref"" : ""KeyName"" }, ""UserData"" : ""wordpress"" } } } } ''' wp_template_with_nic = ''' { ""AWSTemplateFormatVersion"" : ""2010-09-09"", ""Description"" : ""WordPress"", ""Parameters"" : { ""KeyName"" : { ""Description"" : ""KeyName"", ""Type"" : ""String"", ""Default"" : ""test"" }, ""InstanceType"": { ""Type"": ""String"", ""Description"": ""EC2 instance type"", ""Default"": ""m1.small"", ""AllowedValues"": [ ""m1.small"", ""m1.large"" ] }, ""SubnetId"": { ""Type"" : ""String"", ""Description"" : ""SubnetId of an existing subnet in your VPC"" }, }, ""Resources"" : { ""nic1"": { ""Type"": ""AWS::EC2::NetworkInterface"", ""Properties"": { ""SubnetId"": { ""Ref"": ""SubnetId"" } } }, ""WebServer"": { ""Type"": ""AWS::EC2::Instance"", ""Properties"": { ""ImageId"" : ""F17-x86_64-gold"", ""InstanceType"" : { ""Ref"" : ""InstanceType"" }, ""NetworkInterfaces"": [ { ""NetworkInterfaceId"" : {""Ref"": ""nic1""}, ""DeviceIndex"" : ""0"" } ], ""KeyName"" : { ""Ref"" : ""KeyName"" }, ""UserData"" : ""wordpress"" } } } } ''' class FakeNeutron(object): def show_subnet(self, subnet, **_params): return { 'subnet': { 'name': 'name', 'network_id': 'fc68ea2c-b60b-4b4f-bd82-94ec81110766', 'tenant_id': 'c1210485b2424d48804aad5d39c61b8f', 'allocation_pools': [{'start': '10.10.0.2', 'end': '10.10.0.254'}], 'gateway_ip': '10.10.0.1', 'ip_version': 4, 'cidr': '10.10.0.0/24', 'id': '4156c7a5-e8c4-4aff-a6e1-8f3c7bc83861', 'enable_dhcp': False, }} def create_port(self, body=None): return { 'port': { 'admin_state_up': True, 'device_id': '', 'device_owner': '', 'fixed_ips': [{ 'ip_address': '10.0.3.3', 'subnet_id': '4156c7a5-e8c4-4aff-a6e1-8f3c7bc83861'}], 'id': '64d913c1-bcb1-42d2-8f0a-9593dbcaf251', 'mac_address': 'fa:16:3e:25:32:5d', 'name': '', 'network_id': 'fc68ea2c-b60b-4b4f-bd82-94ec81110766', 'status': 'ACTIVE', 'tenant_id': 'c1210485b2424d48804aad5d39c61b8f' }} def delete_port(self, port_id): return None class instancesTest(common.HeatTestCase): def setUp(self): super(instancesTest, self).setUp() self.fc = fakes_nova.FakeClient() def _mock_get_image_id_success(self, imageId_input, imageId): self.m.StubOutWithMock(glance.GlanceClientPlugin, 'get_image_id') glance.GlanceClientPlugin.get_image_id( imageId_input).MultipleTimes().AndReturn(imageId) def _test_instance_create_delete(self, vm_status='ACTIVE', vm_delete_status='NotFound'): return_server = self.fc.servers.list()[1] instance = self._create_test_instance(return_server, 'in_create') instance.resource_id = '1234' instance.status = vm_status # this makes sure the auto increment worked on instance creation self.assertTrue(instance.id > 0) expected_ip = return_server.networks['public'][0] self.assertEqual(expected_ip, instance.FnGetAtt('PublicIp')) self.assertEqual(expected_ip, instance.FnGetAtt('PrivateIp')) self.assertEqual(expected_ip, instance.FnGetAtt('PrivateDnsName')) self.assertEqual(expected_ip, instance.FnGetAtt('PublicDnsName')) d1 = {'server': self.fc.client.get_servers_detail()[1]['servers'][0]} d1['server']['status'] = vm_status self.m.StubOutWithMock(self.fc.client, 'get_servers_1234') get = self.fc.client.get_servers_1234 get().AndReturn((200, d1)) d2 = copy.deepcopy(d1) if vm_delete_status == 'DELETED': d2['server']['status'] = vm_delete_status get().AndReturn((200, d2)) else: get().AndRaise(fakes_nova.fake_exception()) self.m.ReplayAll() scheduler.TaskRunner(instance.delete)() self.assertEqual((instance.DELETE, instance.COMPLETE), instance.state) self.m.VerifyAll() def _create_test_instance(self, return_server, name): stack_name = '%s_s' % name t = template_format.parse(wp_template) kwargs = {'KeyName': 'test', 'InstanceType': 'm1.large', 'SubnetId': '4156c7a5-e8c4-4aff-a6e1-8f3c7bc83861'} template = parser.Template(t, env=environment.Environment(kwargs)) stack = parser.Stack(utils.dummy_context(), stack_name, template, stack_id=str(uuid.uuid4())) image_id = 'CentOS 5.2' t['Resources']['WebServer']['Properties']['ImageId'] = image_id resource_defns = stack.t.resource_definitions(stack) instance = instances.Instance('%s_name' % name, resource_defns['WebServer'], stack) metadata = instance.metadata_get() self.m.StubOutWithMock(nova.NovaClientPlugin, '_create') nova.NovaClientPlugin._create().AndReturn(self.fc) self._mock_get_image_id_success(image_id, 1) self.stub_SubnetConstraint_validate() self.m.StubOutWithMock(instance, 'neutron') instance.neutron().MultipleTimes().AndReturn(FakeNeutron()) self.m.StubOutWithMock(neutron.NeutronClientPlugin, '_create') neutron.NeutronClientPlugin._create().MultipleTimes().AndReturn( FakeNeutron()) # need to resolve the template functions server_userdata = instance.client_plugin().build_userdata( metadata, instance.t['Properties']['UserData'], 'ec2-user') self.m.StubOutWithMock(nova.NovaClientPlugin, 'build_userdata') nova.NovaClientPlugin.build_userdata( metadata, instance.t['Properties']['UserData'], 'ec2-user').AndReturn(server_userdata) self.m.StubOutWithMock(self.fc.servers, 'create') self.fc.servers.create( image=1, flavor=3, key_name='test', name=utils.PhysName(stack_name, instance.name), security_groups=None, userdata=server_userdata, scheduler_hints=None, meta=None, nics=[{'port-id': '64d913c1-bcb1-42d2-8f0a-9593dbcaf251'}], availability_zone=None, block_device_mapping=None).AndReturn( return_server) self.m.ReplayAll() scheduler.TaskRunner(instance.create)() return instance def _create_test_instance_with_nic(self, return_server, name): stack_name = '%s_s' % name t = template_format.parse(wp_template_with_nic) kwargs = {'KeyName': 'test', 'InstanceType': 'm1.large', 'SubnetId': '4156c7a5-e8c4-4aff-a6e1-8f3c7bc83861'} template = parser.Template(t, env=environment.Environment(kwargs)) stack = parser.Stack(utils.dummy_context(), stack_name, template, stack_id=str(uuid.uuid4())) image_id = 'CentOS 5.2' t['Resources']['WebServer']['Properties']['ImageId'] = image_id resource_defns = stack.t.resource_definitions(stack) nic = net_interfaces.NetworkInterface('%s_nic' % name, resource_defns['nic1'], stack) instance = instances.Instance('%s_name' % name, resource_defns['WebServer'], stack) metadata = instance.metadata_get() self._mock_get_image_id_success(image_id, 1) self.stub_SubnetConstraint_validate() self.m.StubOutWithMock(nic, 'neutron') nic.neutron().MultipleTimes().AndReturn(FakeNeutron()) self.m.StubOutWithMock(neutron.NeutronClientPlugin, '_create') neutron.NeutronClientPlugin._create().MultipleTimes().AndReturn( FakeNeutron()) self.m.StubOutWithMock(nova.NovaClientPlugin, '_create') nova.NovaClientPlugin._create().AndReturn(self.fc) # need to resolve the template functions server_userdata = instance.client_plugin().build_userdata( metadata, instance.t['Properties']['UserData'], 'ec2-user') self.m.StubOutWithMock(nova.NovaClientPlugin, 'build_userdata') nova.NovaClientPlugin.build_userdata( metadata, instance.t['Properties']['UserData'], 'ec2-user').AndReturn(server_userdata) self.m.StubOutWithMock(self.fc.servers, 'create') self.fc.servers.create( image=1, flavor=3, key_name='test', name=utils.PhysName(stack_name, instance.name), security_groups=None, userdata=server_userdata, scheduler_hints=None, meta=None, nics=[{'port-id': '64d913c1-bcb1-42d2-8f0a-9593dbcaf251'}], availability_zone=None, block_device_mapping=None).AndReturn( return_server) self.m.ReplayAll() # create network interface scheduler.TaskRunner(nic.create)() stack.resources[""nic1""] = nic scheduler.TaskRunner(instance.create)() return instance def test_instance_create_delete_with_SubnetId(self): self._test_instance_create_delete(vm_delete_status='DELETED') def test_instance_create_with_nic(self): return_server = self.fc.servers.list()[1] instance = self._create_test_instance_with_nic( return_server, 'in_create_wnic') # this makes sure the auto increment worked on instance creation self.assertTrue(instance.id > 0) expected_ip = return_server.networks['public'][0] self.assertEqual(expected_ip, instance.FnGetAtt('PublicIp')) self.assertEqual(expected_ip, instance.FnGetAtt('PrivateIp')) self.assertEqual(expected_ip, instance.FnGetAtt('PrivateDnsName')) self.assertEqual(expected_ip, instance.FnGetAtt('PublicDnsName')) self.m.VerifyAll() >>>>>>> BRANCH (6db885 Merge ""Fix ResourceGroup validate when there are removal_pol) ",1191,4798
openstack%2Fsolum~master~I06525ba84a3744d67ebc62ab4eb646e0d87efab0,openstack/solum,master,I06525ba84a3744d67ebc62ab4eb646e0d87efab0,Remove modules no longer in oslo-incubator,ABANDONED,2015-06-07 14:02:16.000000000,2015-06-10 11:08:21.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 5638}, {'_account_id': 6662}]","[{'number': 1, 'created': '2015-06-07 14:02:16.000000000', 'files': ['solum/openstack/common/__init__.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/solum/commit/8a5819dea8cd09e0c26cedba12f0482388b4a63e', 'message': 'Remove modules no longer in oslo-incubator\n\nChange-Id: I06525ba84a3744d67ebc62ab4eb646e0d87efab0\n'}]",0,189100,8a5819dea8cd09e0c26cedba12f0482388b4a63e,9,4,1,5638,,,0,"Remove modules no longer in oslo-incubator

Change-Id: I06525ba84a3744d67ebc62ab4eb646e0d87efab0
",git fetch https://review.opendev.org/openstack/solum refs/changes/00/189100/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/openstack/common/__init__.py', 'openstack-common.conf']",2,8a5819dea8cd09e0c26cedba12f0482388b4a63e,,,module=config module=context module=fixture.config module=log module=uuidutils module=versionutils ,0,24
openstack%2Fhorizon~master~I319dafa1c6d8d28656db146cf04ae1f0dcc136ab,openstack/horizon,master,I319dafa1c6d8d28656db146cf04ae1f0dcc136ab,Sync with latest oslo-incubator,ABANDONED,2015-06-07 14:07:16.000000000,2015-06-10 11:03:51.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-07 14:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/944b6f828159ab328ebf1041ffd44c7bfe09a04b', 'message': 'Sync with latest oslo-incubator\n\nChange-Id: I319dafa1c6d8d28656db146cf04ae1f0dcc136ab\n'}, {'number': 2, 'created': '2015-06-10 10:21:37.000000000', 'files': ['openstack-common.conf', 'tools/install_venv_common.py', 'tools/install_venv.py', 'openstack_dashboard/openstack/common/_i18n.py', 'openstack_dashboard/openstack/common/fileutils.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f2b9fcb914878a481cc1469f323be5307d238dc5', 'message': 'Sync with latest oslo-incubator\n\nopenstack-common.conf had a lot of files that are no longer\nin oslo-incubator, so cleaned them up. The other files\nwere synced with latest code.\n\nChange-Id: I319dafa1c6d8d28656db146cf04ae1f0dcc136ab'}]",0,189109,f2b9fcb914878a481cc1469f323be5307d238dc5,5,2,2,5638,,,0,"Sync with latest oslo-incubator

openstack-common.conf had a lot of files that are no longer
in oslo-incubator, so cleaned them up. The other files
were synced with latest code.

Change-Id: I319dafa1c6d8d28656db146cf04ae1f0dcc136ab",git fetch https://review.opendev.org/openstack/horizon refs/changes/09/189109/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-common.conf', 'tools/install_venv_common.py', 'tools/install_venv.py', 'openstack_dashboard/openstack/common/_i18n.py', 'openstack_dashboard/openstack/common/fileutils.py']",5,944b6f828159ab328ebf1041ffd44c7bfe09a04b,,"import loggingimport statDEFAULT_MODE = stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO def ensure_tree(path, mode=DEFAULT_MODE): :param mode: Directory creation permissions os.makedirs(path, mode) LOG.debug(""Reloading cached file %s"", filename)","from openstack_dashboard.openstack.common import log as logging def ensure_tree(path): os.makedirs(path) LOG.debug(""Reloading cached file %s"" % filename)",34,32
openstack%2Fnetworking-midonet~master~I4cf05d3ab23b7b36f2645eac47b606585285afba,openstack/networking-midonet,master,I4cf05d3ab23b7b36f2645eac47b606585285afba,Add non *py files in the package,MERGED,2015-06-09 14:01:15.000000000,2015-06-10 10:51:56.000000000,2015-06-10 10:51:56.000000000,"[{'_account_id': 3}, {'_account_id': 7505}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-09 14:01:15.000000000', 'files': ['packaging/deb/debian/rules'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/b8482d2128bab83b7b9c9375210bbb957ebc5ece', 'message': ""Add non *py files in the package\n\nIt seems like current approach to build the packages don't include\nnon-python files. Fixing this using `python_distutils` in deb.\n\nChange-Id: I4cf05d3ab23b7b36f2645eac47b606585285afba\n""}]",0,189726,b8482d2128bab83b7b9c9375210bbb957ebc5ece,14,3,1,7505,,,0,"Add non *py files in the package

It seems like current approach to build the packages don't include
non-python files. Fixing this using `python_distutils` in deb.

Change-Id: I4cf05d3ab23b7b36f2645eac47b606585285afba
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/26/189726/1 && git format-patch -1 --stdout FETCH_HEAD,['packaging/deb/debian/rules'],1,b8482d2128bab83b7b9c9375210bbb957ebc5ece,python_distutils, dh $@ --with python2 --buildsystem=python_distutils, dh $@ --with python2 --buildsystem=pybuild,1,1
openstack%2Fneutron~master~I192e4d12380346c53c8ae0246371ccc41a836c4c,openstack/neutron,master,I192e4d12380346c53c8ae0246371ccc41a836c4c,Change L3 agent AdvancedService class to be non-singleton,MERGED,2015-02-23 22:20:10.000000000,2015-06-10 10:48:25.000000000,2015-02-26 20:19:36.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 8344}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-02-23 22:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e51258b2217acb148366583e8dcbbcb39c62fbd1', 'message': ""Change L3 agent AdvancedService class to be non-singleton\n\nThe idea behind the AdvancedServices (Metadata, *aaS) drivers\nto be singletons was to (1) offer a way to get an instance of such\na driver in a convinient manner, and to (2) ensure that only one\ndriver registered per driver type.\n\n(1) Since the AdvancedService.instance method required an instance\nof a L3 agent, this point was kind of missed. If you have a L3 agent\ninstance in your hand, just use it to access the driver you're looking\nfor.\n\n(2) This is now fulfilled by asserting that only one driver is registered\n(per type) in the .add method.\n\nThe motivation to make them non-singletons is that:\na) They don't need to be\nb) The code is simplified this way\nc) I've been facing crazy issues during functional testing where we're\n   constantly instantiating L3 agents, and the (singleton) drivers were\n   referencing the wrong configuration object. Basically the driver was\n   re-initialized during a test, screwing up the configuration of other\n   mid-run tests.\n\nChange-Id: I192e4d12380346c53c8ae0246371ccc41a836c4c\n""}, {'number': 2, 'created': '2015-02-23 23:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/22a54b3a5fa1eaadd4146f18a03220e439c7c289', 'message': ""Change L3 agent AdvancedService class to be non-singleton\n\nThe idea behind the AdvancedServices (Metadata, *aaS) drivers\nto be singletons was to (1) offer a way to get an instance of such\na driver in a convinient manner, and to (2) ensure that only one\ndriver registered per driver type.\n\n(1) Since the AdvancedService.instance method required an instance\nof a L3 agent, this point was kind of missed. If you have a L3 agent\ninstance in your hand, just use it to access the driver you're looking\nfor.\n\n(2) This is now fulfilled by asserting that only one driver is registered\n(per type) in the .add method.\n\nThe motivation to make them non-singletons is that:\na) They don't need to be\nb) The code is simplified this way\nc) I've been facing crazy issues during functional testing where we're\n   constantly instantiating L3 agents, and the (singleton) drivers were\n   referencing the wrong configuration object. Basically the driver was\n   re-initialized during a test, screwing up the configuration of other\n   mid-run tests.\n\nDepends-On: I155aece9b7028f1bdd3d9709facef392b38aec27\nDepends-On: I199f6a967c64e921624b397fa5b7dfc56572d63a\nChange-Id: I192e4d12380346c53c8ae0246371ccc41a836c4c\n""}, {'number': 3, 'created': '2015-02-26 00:09:51.000000000', 'files': ['neutron/agent/l3/event_observers.py', 'neutron/tests/common/agents/l3_agent.py', 'neutron/agent/l3/agent.py', 'neutron/tests/unit/services/test_advanced_service.py', 'neutron/services/advanced_service.py', 'neutron/tests/unit/agent/test_l3_event_observers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/911f8b57f80798ec8fe3c82282fb4c812cc9472c', 'message': ""Change L3 agent AdvancedService class to be non-singleton\n\nThe idea behind the AdvancedServices (Metadata, *aaS) services\nto be singletons was to (1) offer a way to get an instance of such\na service in a convinient manner, and to (2) ensure that only one\nservice registered per service type.\n\n(1) Since the AdvancedService.instance method required an instance\nof a L3 agent, this point was kind of missed. If you have a L3 agent\ninstance in your hand, just use it to access the service you're looking\nfor.\n\n(2) This is now fulfilled by asserting that only one driver is registered\n(per type) in the .add method.\n\nThe motivation to make them non-singletons is that:\na) They don't need to be\nb) The code is simplified this way\nc) I've been facing crazy issues during functional testing where we're\n   constantly instantiating L3 agents, and the (singleton) metadata\n   service was referencing the wrong configuration object. The service\n   was re-initialized during a test, screwing up the configuration of\n   other mid-run tests.\n\nCloses-Bug: #1425759\nDepends-On: I155aece9b7028f1bdd3d9709facef392b38aec27\nDepends-On: I199f6a967c64e921624b397fa5b7dfc56572d63a\nChange-Id: I192e4d12380346c53c8ae0246371ccc41a836c4c\n""}]",7,158468,911f8b57f80798ec8fe3c82282fb4c812cc9472c,83,24,3,8873,,,0,"Change L3 agent AdvancedService class to be non-singleton

The idea behind the AdvancedServices (Metadata, *aaS) services
to be singletons was to (1) offer a way to get an instance of such
a service in a convinient manner, and to (2) ensure that only one
service registered per service type.

(1) Since the AdvancedService.instance method required an instance
of a L3 agent, this point was kind of missed. If you have a L3 agent
instance in your hand, just use it to access the service you're looking
for.

(2) This is now fulfilled by asserting that only one driver is registered
(per type) in the .add method.

The motivation to make them non-singletons is that:
a) They don't need to be
b) The code is simplified this way
c) I've been facing crazy issues during functional testing where we're
   constantly instantiating L3 agents, and the (singleton) metadata
   service was referencing the wrong configuration object. The service
   was re-initialized during a test, screwing up the configuration of
   other mid-run tests.

Closes-Bug: #1425759
Depends-On: I155aece9b7028f1bdd3d9709facef392b38aec27
Depends-On: I199f6a967c64e921624b397fa5b7dfc56572d63a
Change-Id: I192e4d12380346c53c8ae0246371ccc41a836c4c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/158468/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/agent/l3/event_observers.py', 'neutron/tests/common/agents/l3_agent.py', 'neutron/tests/unit/services/test_advanced_service.py', 'neutron/services/advanced_service.py', 'neutron/tests/unit/agent/test_l3_event_observers.py']",6,e51258b2217acb148366583e8dcbbcb39c62fbd1,bug/1425759,import testtools def test_add_duplicate_observer_type_raises(self): agent = mock.Mock() observer = DummyService1(agent) observer2 = DummyService1(agent) with testtools.ExpectedException(ValueError): self.event_observers.add(observer2) observer1 = DummyService1(l3_agent) observer2 = DummyService2(l3_agent), def test_add_duplicate_observer_is_ignored(self): observer = object() try: self.event_observers.add(observer) except Exception: self.fail('Duplicate additions of observers should be ignored') observer1 = DummyService1.instance(l3_agent) observer2 = DummyService2.instance(l3_agent),25,54
openstack%2Fcinder-specs~master~I579564be2ff0c94f4bbb5af03809e2bda91d722c,openstack/cinder-specs,master,I579564be2ff0c94f4bbb5af03809e2bda91d722c,Generic image volume cache functionality,MERGED,2015-05-13 02:00:25.000000000,2015-06-10 10:41:20.000000000,2015-06-10 10:41:18.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2861}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 8846}, {'_account_id': 9003}, {'_account_id': 10115}, {'_account_id': 10263}, {'_account_id': 11904}, {'_account_id': 12924}]","[{'number': 1, 'created': '2015-05-13 02:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/b6770789dc88a407946321265be76b7d212d34ad', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 2, 'created': '2015-05-13 04:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0e47fb8c87c6c7a514e8bf6daf15ebd5a46a3fc7', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 3, 'created': '2015-05-13 15:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/196aeaa4e39793ab42a6307a9db9a9e35f094535', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 4, 'created': '2015-05-13 16:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/b5d6ebe2125468de4f130d1a546e074316df4f93', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 5, 'created': '2015-05-13 20:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/683af922b242225fec23f6a2bc58e02e5a05821b', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 6, 'created': '2015-05-13 20:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/82e874c2d8404aa11b2dc0b0fee06652e81d001a', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 7, 'created': '2015-05-27 00:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/2d90f07e4f2eb5ca9e1dd00d14356d31ba51594a', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 8, 'created': '2015-05-27 14:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3aac6a4f3c927c38697fb4a2fc724483cebe5419', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 9, 'created': '2015-05-28 00:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/f3118d9f0932fa4f866b77220616fbee6acc9a36', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 10, 'created': '2015-05-28 02:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/52d95a18150adb673564c1b5f9f1d8eb63db0176', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 11, 'created': '2015-05-28 05:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/41dabbea62bbe47c61efca48ab0b679305a8db63', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c\n'}, {'number': 12, 'created': '2015-06-01 16:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/144434a1b17f48d938f5ec89bc1838e2238330cb', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c\n'}, {'number': 13, 'created': '2015-06-01 18:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/a5b2d4f20576cac56085ab29fc12cc2d4bd6e23d', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c\n'}, {'number': 14, 'created': '2015-06-01 22:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/b5d12ed965f82895c7b716ba882f0a62a7463524', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}, {'number': 15, 'created': '2015-06-03 16:23:34.000000000', 'files': ['specs/liberty/image-volume-cache.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/bf0cded87a9c72c3886c019b19863f4e03f44146', 'message': 'Generic image volume cache functionality\n\nThe proposes a generic image cache feature that would allow any backend\nto use volumes to store images as a cache for future create from image\noperations.\n\nChange-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c'}]",55,182520,bf0cded87a9c72c3886c019b19863f4e03f44146,72,14,15,12924,,,0,"Generic image volume cache functionality

The proposes a generic image cache feature that would allow any backend
to use volumes to store images as a cache for future create from image
operations.

Change-Id: I579564be2ff0c94f4bbb5af03809e2bda91d722c",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/20/182520/10 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/image-volume-cache.rst'],1,b6770789dc88a407946321265be76b7d212d34ad,bp/cinder-internal-tenant,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Generic image cache functionality ========================================== https://blueprints.launchpad.net/cinder/+spec/image-volume-cache Currently some volume drivers implement the clone_image method and use an internal cache of volumes on the backend that hold recently used images. For storage backends that can do very efficient volume clones it is a potentially large performance improvement over having to attach and copy the image contents to a each volume. To make this functionality easier for other volume drivers to use, and prevent any duplication in the code base, we should implement a more unified way to do this caching. Problem description =================== If we don't create a unified approach to this image caching we will end up with multiple vendors implementing it in volume drivers. This means duplicated code, redundant vendor prefixed config options, and a non-uniform way for admins to set up and configure image caching. Use Cases ========= The primary (and I think only) use case for this is when creating a volume from an image more than once. As an end user I will see (potentially) faster volume creation from an image after the first time, and as ad admin once I set this up once in the backend configuration it should require no more interaction. Proposed change =============== When creating a volume from an image using the cache there are a few high level steps to take: * Check if an image is in the cache. * If it is and has been updated, delete it. * If it wasn't in the cache (or isn't anymore) * Evict an old image in room is needed. * Create a volume from an image (the 'normal' way of copying data over), this volume will henceforth be known as the 'image-volume'. * Update the cache to know about this new image-volume and its image contents. * Clone the image cache volume. This new behavior would be enabled via a new volume driver config option called 'enable_image_volume_cache'. The size of this cache will then be defined by a config option called 'image_volume_cache_size'. These options are scoped to each backend. In the _create_from_image of CreateVolumeFromSpecTask we can add in the logic to check first if the image cache is enabled for the target backend. If it is then we can use the cache, if not we use the slow path only. This would be done after driver.clone_image is called to give a backend a chance to do an even more optimal clone if possible. For the actual image-volume I think it would be best if we can re-use the normal Cinder Volume model and database table. This would mean a new field on the Volume model with a flag such as: Name: cinder_internal Type: Boolean Default: False We then would need a new table to track our image cache. This table will have the following fields: :: +------------+-----------+--------------------------------+ | NAME | TYPE | DESCRIPTION | +------------+-----------+--------------------------------+ | | | | | id | Integer | Auto generated unique id | | | | | | updated_at | DateTime | The updated_at time from the | | | | image metadata | | | | | | host_id | String | ForeignKey for Host.id that h | | | | as the backing volume | | | | | | volume_id | String | ForeignKey for Volume.id of t | | | | he backing volume | +------------+-----------+--------------------------------+ This information gives us enough to look up whether or not a image is in the cache for a target backend, and make the decision to either create a new one or not and then call _create_from_source_volume with the image-volume. As far as the volume driver is concerned it would be creating volumes from an image and cloning volumes, it would not need to be aware of the cache at all for the creation methods. One downside of this approach is that the api's which list volumes and search for them would need to be updated to ignore the cinder_internal volumes. These internal volumes would not be counted towards any quota and would potentially eat up space on the backend that would need to be reported by the volume driver accordingly. There is a possibility of a race within the cache where an image would be getting deleted and is selected to be used for a clone operation. If this happens we should catch the error and attempt to create the volume by downloading the image. It is also possible that multiple images are cached at the same time, this is considered 'OK', eventually one or both will be evicted if needed. Alternatives ------------ A very simple alternative to this is to simply push all this logic and behavior into each volume driver and live with the duplicated code and config options. This however prohibits backends that cannot store meta-data for their volumes anywhere. Another alternative is to not use the actual Volume objects and to expand the image cache table to have enough information for a backend to create volumes and clones from it (maybe metadata type values?). Then we could add new API's to the volume driver such as 'create_cached_image_volume', 'delete_cached_image_volume', 'create_volume_from_cached_image', and so on. This would put more of the logic into the volume drivers, but requires them to implement these new methods. The benefit here is that we don't start having special 'internal' volumes. The downside being that each driver then has to implement all of these methods which would do almost the same thing as create_volume, delete_volume, etc, but with different parameters. Data model impact ----------------- A new database table for the image cache and new column for the Volume table. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ This should improve performance on average for systems that can do efficient volume clones when doing create volume from image. There will be many factors involved as to how much it changes, but it is unlikely to be much slower. It is possible this will add some delay on occasional requests which hit a 'worst case' scenario of having to do the database lookups, trying to create from a cached image, failing because it got evicted, and then doing the image download. In situations where that occurs frequently the cache size could be modified or the feature disabled. Other deployer impact --------------------- New configuration options for a cinder backend that would potentially need to be set. Developer impact ---------------- Just new DB API's and tables to be aware of. Implementation ============== Assignee(s) ----------- Primary assignee: patrick-east Other contributors: None Work Items ---------- * DB changes * create_volume flow changes Dependencies ============ None Testing ======= * DB migration tests * Unit tests for DB API's * Unit tests for flow changes Documentation Impact ==================== New configuration options. References ========== None ",,227,0
openstack%2Fcinder-specs~master~I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c,openstack/cinder-specs,master,I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c,Cinder internal tenant,MERGED,2015-05-28 00:10:44.000000000,2015-06-10 10:40:47.000000000,2015-06-10 10:40:45.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2861}, {'_account_id': 6491}, {'_account_id': 7173}, {'_account_id': 9003}, {'_account_id': 12924}]","[{'number': 1, 'created': '2015-05-28 00:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/d9ce76bc8970d2e6237e9d352a6c779079a9f376', 'message': 'Cinder internal tenant\n\nThis spec proposes the addition of config options and utilities needed\nfor a cinder-internal tenant.\n\nChange-Id: I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c\n'}, {'number': 2, 'created': '2015-05-28 05:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/5440dd3c2307610dc42d6053a98934dc86e19414', 'message': 'Cinder internal tenant\n\nThis spec proposes the addition of config options and utilities needed\nfor a cinder-internal tenant.\n\nChange-Id: I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c\n'}, {'number': 3, 'created': '2015-06-01 16:41:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4a7481f6321a2016c7d03e766204b91ed89abc47', 'message': 'Cinder internal tenant\n\nThis spec proposes the addition of config options and utilities needed\nfor a cinder-internal tenant.\n\nChange-Id: I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c\n'}, {'number': 4, 'created': '2015-06-01 18:47:07.000000000', 'files': ['specs/liberty/cinder-internal-tenant.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4243c5835b3f27acae0c9f3bb8bf46814906603e', 'message': 'Cinder internal tenant\n\nThis spec proposes the addition of config options and utilities needed\nfor a cinder-internal tenant.\n\nChange-Id: I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c\n'}]",23,186232,4243c5835b3f27acae0c9f3bb8bf46814906603e,29,9,4,12924,,,0,"Cinder internal tenant

This spec proposes the addition of config options and utilities needed
for a cinder-internal tenant.

Change-Id: I57259a92a8993d0f1ccdd6a4b51f7f10cab1985c
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/32/186232/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/cinder-internal-tenant.rst'],1,d9ce76bc8970d2e6237e9d352a6c779079a9f376,bp/cinder-internal-tenant,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== https://blueprints.launchpad.net/cinder/+spec/cinder-internal-tenant This spec proposes the addition of config options and internal plumbing required for a cinder-internal tenant. This tenant can then be used by Cinder as the owner of internal objects that we don't really want owned by any normal users. Problem description =================== There are several use cases for 'internal' cinder objects where we would like to prevent a normal user from seeing them. The approach that seems to have the most backing is to a special tenant that cinder can use for owning these internal volumes/snapshots/etc. Use Cases ========= There are a few different use cases for the internal tenant. The generic use case is for any volume or snapshot object in Cinder that we do not want exposed to normal users, but would like to keep track of and have treated as normal volumes and snapshots. There are a few features which would be able to take advantage of this: * Image Caching - Volumes (and potentially snapshots) that are used as part of the image cache could be owned by the tenant. * Volume Migration - Temporary volumes while migrations are taking place could be owned by the cinder-internal tenant. * Live Backups - Temporary snapshots and volumes could be owned by the cinder-internal tenant. * Public Snapshots - Snapshots (and maybe their backing volumes) could be owned by the cinder-internal tenant. Proposed change =============== I think initially the easiest way to make this work is to add new config options that take in the credentials for the tenant. This would require an admin to create and configure the tenant manually and then set the values in cinder.conf. Things like quota and other permissions would be managed by an admin only, cinder will not modify things automatically. For the initial change I don't think we should keep any of this info in the cinder db. Everything comes from teh config file and is re-checked at startup. Any usage of this tenants objects should assume they could be deleted or cleaned up at any time, I don't think this is any different than the case today where a user could delete a second volume halfway through migration though. So this is not a regression. The idea behind this being that as an admin you could periodically clean these objects up if they start to accumulate, but you wouldn't really need to worry about which ones are 'safe'. Alternatives ------------ Another way to approach this problem is to add 'hidden' flags to volumes and snapshots. The biggest downside of this is that all API's need to then know about this and start filtering, and potentially clients and commands need new '--hidden' or '--show-all' kind of flags. In addition these hidden volumes may either take quota from a real user or not be accounted for at all. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- Care will need to be taken to ensure the tenant credentials are not exposed anywhere and that users cannot create volumes or other objects as the internal tenant. Notifications impact -------------------- None Other end user impact --------------------- This change by itself shouldn't have any end user impact. Things built on top of it may change what a user sees while using commands like migrate. Performance Impact ------------------ None Other deployer impact --------------------- New config options and setup steps when configuring cinder. Additional documentation to read. Developer impact ---------------- New internal API's to use to create objects as the internal tenant. Implementation ============== Assignee(s) ----------- Primary assignee: patrick-east Other contributors: None Work Items ---------- * Add in support for the new config options. * Add in utility functions to get the tenant information and anything else required to use the internal tenant for operations. * Possibly add support in to DevStack to configure this by default for future development on top of the feature. * Documentation on how to create and configure the tenant. Dependencies ============ None Testing ======= Unit tests for the utility functions. Documentation Impact ==================== * New instructions for how to create and configure the tenant in the installation instructions. References ========== * http://eavesdrop.openstack.org/meetings/cinder/2015 /cinder.2015-05-27-16.00.log.html * https://blueprints.launchpad.net/cinder/+spec/image-volume-cache",,167,0
openstack%2Fcinder-specs~master~Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961,openstack/cinder-specs,master,Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961,capacity-headroom,MERGED,2015-04-03 08:15:12.000000000,2015-06-10 10:32:28.000000000,2015-06-10 10:32:26.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 8846}, {'_account_id': 9003}, {'_account_id': 10263}, {'_account_id': 12924}, {'_account_id': 13063}, {'_account_id': 13636}, {'_account_id': 14274}, {'_account_id': 15252}]","[{'number': 1, 'created': '2015-04-03 08:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c6904e00ce05ed30b7291986461ef5982138f663', 'message': 'capacity headroom\n\nIt is submitted for Libery Release to get ealy\ncomments.\n\nThe proposal is to calculate and show the storage\ncapacity infomation, especially the remaining\nvitual storage information totally.\n\nblueprint capacity-headroom\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\n'}, {'number': 2, 'created': '2015-04-07 08:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3cd5d097cf88f440bea03d4dd6d34e420279df8c', 'message': 'capacity headroom\n\nIt is submitted for Libery Release to get ealy\ncomments.\n\nThe proposal is to calculate and show the storage\ncapacity infomation, especially the remaining\nvitual storage information totally.\n\nblueprint capacity-headroom\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\n'}, {'number': 3, 'created': '2015-05-11 02:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4f739fdccd303ce854be7bb7bcd4fb1d8bd119dc', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\nThe proposol is to calculate and show the\nvirtual cinder storage capacity based on the\nover-subscription-in-thin-provisioning for\nall the backend totally.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}, {'number': 4, 'created': '2015-05-12 07:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/da6c6fa5ab4ff42a45281357cc92f7da58f870b2', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\n\nThe proposol groups the backends into\nthin/thick/unknown, calculates and show\ntotal capacity for each group individually.\n\nFor thin, calculates total virtual free\ncapacity for all thin provisioning backends.\n\nFor thick, calculates total free capacity.\nFor unknown, calculates total backends number.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}, {'number': 5, 'created': '2015-05-14 05:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ce34f616b78408c94b7aa063c96e3dce3a87591f', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\n\nThe proposol calculates various total capacity\nfor all backends reported capacity normally and\nwill notify the total capacity info to Ceilometer.\n\nIt groups the backends into 2 groups:\nthin/thick and unknown/infinite.\n\nFor thin/thick group, it calculates various\ntotal capacity.\nFor unknown/infinite, just calculates the total\nbackends numbers.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}, {'number': 6, 'created': '2015-05-27 06:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/9f117e0337ae719afb7bbfe31858227358d52396', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\n\nThe proposol calculates various total capacity\nfor all backends reported capacity normally and\nwill notify the total capacity info to Ceilometer.\n\nIt groups the backends into 2 groups:\nthin/thick and unknown/infinite.\n\nFor thin/thick group, it calculates various\ntotal capacity.\nFor unknown/infinite, just calculates the total\nbackends numbers.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}, {'number': 7, 'created': '2015-06-01 02:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/610eb4f97cb4da7e58ecc4faee566d176e921fbb', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\n\nThe proposol calculates various total capacity\nfor all backends reported capacity normally and\nwill notify the total capacity info to Ceilometer.\n\nIt groups the backends into 2 groups:\nthin/thick and unknown/infinite.\n\nFor thin/thick group, it calculates various\ntotal capacity.\nFor unknown/infinite, just calculates the total\nbackends numbers.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}, {'number': 8, 'created': '2015-06-03 07:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/19c6ffa3425f7f9be7a3bcf75951f8dd6f96238a', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\n\nThe proposol calculates total virtual free\ncapacity for each backend which support thin\nprovisioning. It will then notify various\ncapacity info to Ceilometer service.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}, {'number': 9, 'created': '2015-06-09 06:29:29.000000000', 'files': ['specs/liberty/capacity-headroom.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/26cc28283caf9847f20e6f1647cd4d0d211b5827', 'message': 'capacity-headroom\n\nThe spec is for blueprint capacity-headroom.\n\nThe proposol calculates virtual free capacity\nfor pool and sum total for the backend which\nsupport thin provisioning. It will then notify\nvarious capacity info to ceilometer service.\n\nChange-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961\nblueprint: capacity-headroom\n'}]",36,170380,26cc28283caf9847f20e6f1647cd4d0d211b5827,45,14,9,14274,,,0,"capacity-headroom

The spec is for blueprint capacity-headroom.

The proposol calculates virtual free capacity
for pool and sum total for the backend which
support thin provisioning. It will then notify
various capacity info to ceilometer service.

Change-Id: Ifc9c3ecbc4c5c4f03da2ec4971dfdc6b127b2961
blueprint: capacity-headroom
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/80/170380/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/capacity-headroom.rst'],1,c6904e00ce05ed30b7291986461ef5982138f663,bp/capacity-headroom,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== capacity headroom ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/capacity-headroom The proposal is to provide a mechanism surfacing the visibility of the total remaining block storage capacity which is available to allocate or resize volumes. It will be an indication for deployer to plan the future plan. Problem description =================== Currently, there is no a clear way for users to know how much block storage capacity left totally in cinder can be deployed. * conditions with several backends * conditions with a backend which exports capacity as ""infinite"" or ""unknown"" * conditions with a backend support ""over subscription"" Proposed change =============== * The proposal calculates the total remaining virtual capacity for all the backends based on over subscription mechanism. If a backend doesn't implement the mechanism, just use the physical capacity instead. According to the over subscrition mechanism implemented for LVM, the remaining virtual capacity for a backend can be used as terminology: apparent_available_capacity. And it can be calculated by following formula: apparent_available_capacity = total_capacity * max_over_subscription_ratio - provisioned_capacity * The proposal provides a cinder api to export the capacity infos of each backend (total/allocated/virtual). New methods in HostState ------------------------------------- * get_host_state_map() - call _update_host_state_map() - return the host_state_map dict. * get_capacity() - call get_host_state_map() - calculate the totally capacity for all the backends Alternatives ------------ Another alternative could be: * create a new data table which describe all relative capacity info (total/allocated/virtual) for each host_state into database in scheduler. * provide a cinder api to retrieve capacity info from database. Compare with the proposal, database write operations in scheduler may cost more. Data model impact ----------------- None. REST API impact --------------- * Show capacity for total and each host_state * List detail capacity information for the total of all backends (total/allocated/virtual) and then for each active host_state. * Method type (GET) * Normal http response code : 200 * Expected error http response code(s) * 404 : No current available volume service. * /v2/{tenant-id}/storage-capacity * JSON schema definition for V2:: { capacity: { ""total_capacity_gb_of_all"": 10.1, ""allocated_capacity_gb_of_all"": 0, ""virtual_capacity_gb_of_all"": 0, ""host_states"":[ { ""name"": ""ubuntu@lvm#backend_name"", ""total_capacity_gb"": 4.01, ""allocated_capacity_gb"": 0, ""virtual_capacity_gb"": 0, } ] } } Security impact --------------- None. Notifications impact -------------------- Will notify the storage capacity info to Ceilometer Service. Then ceilometer service can produce capacity samples feeding to Horizon service, which may show a line chart displaying the capacity utilization trend during a period time. Other end user impact --------------------- * The current storage capacity info should be exposed to horizon via cinder API. It's the basic infomation for admin to deploy or resize new volumes. * python-cliderclient needs to be changed to support it. CLI is as followed: To list the total storage info of all the backends: cinder capacity-show Performance Impact ------------------ N/A. Other deployer impact --------------------- N/A. Developer impact ---------------- * Cinder volume drivers should report provisoning_capability if it has. This will improve the efficency of the storage utiilization. Note: This proposal will calculate virtual capacity thru provisioning_capability. Otherwise we will calculate physical capacity instead. Implementation ============== Assignee(s) ----------- Primary assignee: XinXiaohui Other contributors: Work Items ---------- * Calculate the virtual capacity: - calculates the total remaining virtual capacity for all the backends. - If a backend doesn't implement the over subscription mechanism, just use the physical capacity instead. - According to the over subscription mechanism implemented for LVM, the remaining virtual capacity for a backend can be used as terminology : apparent_available_capacity. And it can be calculated by following formula: apparent_available_capacity = total_capacity * max_over_subscription_ration - provisioned_capacity * Get the capacity from cinder Scheduler Service. - Add a new method named ""get_host_state_map() in Class HostManager It calls _update_host_map() and return the host_state_map dict. - Add a new method named ""get_capacity"" in Class HostManager It calls get_host_state_map(), and calculate all the capacity that we need according to the formula above. - Add a new method named ""get_capacity"" in Class FilterScheduler It calls the hostmanager.get_capacity(). - Add a new method named ""get_capacity"" in Class SchedulerManager It calls the get_capacity of the Class FilterScheduler - Add a new rpcapi named ""get_capacity()"" in Class SchedulerAPI. This function will be called by the resource action of Cinder REST API as below. * Make a cinder REST API as resource extensions to report the capacity - Add a new file named capacity_stats.py and add a new class named as CapacityStats Class to be the extension. - Add a CapacityController in capacity_stats.py defining resource actions as get_capacity() - The action get_capacity() will call get_capacity() of the Scheduler rpcapi. * Make changes in cinderclient to send the resource request - Add a CapacityManager Class to handle the web request - Add CLI Dependencies ============ * The proposal depends on the over subscription mechanism of backend drivers. Testing ======= * Unit tests will be added to have a test. Documentation Impact ==================== * Documents need to be added to the new API. References ========== https://etherpad.openstack.org/p/kilo-cinder-over-subscription https://etherpad.openstack.org/p/kilo-cinder-capacity-headroom ",,240,0
openstack%2Fdevstack~master~I349662ff8f851b4a7f879f89b8975a068f2d73dc,openstack/devstack,master,I349662ff8f851b4a7f879f89b8975a068f2d73dc,Replace pip-installed requests CA bundle with link,MERGED,2015-05-28 19:43:52.000000000,2015-06-10 10:26:57.000000000,2015-06-09 23:00:07.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6735}, {'_account_id': 7118}, {'_account_id': 7662}, {'_account_id': 8871}, {'_account_id': 14807}]","[{'number': 1, 'created': '2015-05-28 19:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5420b6f2ae9f74ed0eb1c1b923f37a19d4e81f61', 'message': 'Replace pip-installed requests CA bundle with link\n\nIf the version of python-requests required is higher than\nthat provided by the operating system, pip will install\nit from upstream.\n\nThe upstream version provides its own CA certificate bundle\nbased on the Mozilla bundle, and defaults to that in case\na CA certificate file is not specified for a request.\n\nThe distribution-specific packages point to the system-wide\nCA bundle that can be managed by tools such as\nupdate-ca-trust (Fedora/RHEL) and update-ca-certificates\n(Debian/Ubuntu).\n\nWhen installing in SSL/TLS mode, either with SSL=True or by\nadding tls-proxy to ENABLED_SERVICES, if a non-systemwide\nCA bundle is used, then the CA generated by devstack will\nnot be used causing the installation to fail.\n\nReplace the upstream-provided bundle with a link to the\nsystem bundle when possible.\n\nChange-Id: I349662ff8f851b4a7f879f89b8975a068f2d73dc\nCloses-Bug: #1459789\n'}, {'number': 2, 'created': '2015-06-02 22:35:47.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7d350720fe5d25fece68c5d1625a33a6cad431ef', 'message': 'Replace pip-installed requests CA bundle with link\n\nIf the version of python-requests required is higher than\nthat provided by the operating system, pip will install\nit from upstream.\n\nThe upstream version provides its own CA certificate bundle\nbased on the Mozilla bundle, and defaults to that in case\na CA certificate file is not specified for a request.\n\nThe distribution-specific packages point to the system-wide\nCA bundle that can be managed by tools such as\nupdate-ca-trust (Fedora/RHEL) and update-ca-certificates\n(Debian/Ubuntu).\n\nWhen installing in SSL/TLS mode, either with SSL=True or by\nadding tls-proxy to ENABLED_SERVICES, if a non-systemwide\nCA bundle is used, then the CA generated by devstack will\nnot be used causing the installation to fail.\n\nReplace the upstream-provided bundle with a link to the\nsystem bundle when possible.\n\nChange-Id: I349662ff8f851b4a7f879f89b8975a068f2d73dc\nCloses-Bug: #1459789\n'}]",3,186545,7d350720fe5d25fece68c5d1625a33a6cad431ef,16,8,2,7662,,,0,"Replace pip-installed requests CA bundle with link

If the version of python-requests required is higher than
that provided by the operating system, pip will install
it from upstream.

The upstream version provides its own CA certificate bundle
based on the Mozilla bundle, and defaults to that in case
a CA certificate file is not specified for a request.

The distribution-specific packages point to the system-wide
CA bundle that can be managed by tools such as
update-ca-trust (Fedora/RHEL) and update-ca-certificates
(Debian/Ubuntu).

When installing in SSL/TLS mode, either with SSL=True or by
adding tls-proxy to ENABLED_SERVICES, if a non-systemwide
CA bundle is used, then the CA generated by devstack will
not be used causing the installation to fail.

Replace the upstream-provided bundle with a link to the
system bundle when possible.

Change-Id: I349662ff8f851b4a7f879f89b8975a068f2d73dc
Closes-Bug: #1459789
",git fetch https://review.opendev.org/openstack/devstack refs/changes/45/186545/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,5420b6f2ae9f74ed0eb1c1b923f37a19d4e81f61,1459789," # If a non-system python-requests is installed then it will use the # built-in CA certificate store rather than the distro-specific # CA certificate store. Detect this and symlink to the correct # one. pip installs packages into /usr/local, so if the capath # includes that then we know we need to change it. capath=$(python -c ""from requests import certs; print certs.where()"") if is_service_enabled tls-proxy || [ ""$USE_SSL"" == ""True"" ]; then if [[ $capath =~ ^/usr/local.* && ! -L $capath ]]; then if is_fedora; then sudo rm -f $capath sudo ln -s /etc/pki/tls/certs/ca-bundle.crt $capath elif is_ubuntu; then sudo rm -f $capath sudo ln -s /etc/ssl/certs/ca-certificates.crt $capath else echo ""Don't know how to set the CA bundle, expect the install to fail."" fi fi fi",,21,0
openstack%2Fironic~master~Ie7036b2fe48dde67d835e0701dbbbdc5cb05457b,openstack/ironic,master,Ie7036b2fe48dde67d835e0701dbbbdc5cb05457b,Merge tag '2015.1.0',MERGED,2015-04-30 23:35:39.000000000,2015-06-10 10:26:57.000000000,2015-06-09 23:06:43.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-04-30 23:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fff1cd494165c75611a5157fcea15c2d11134fba', 'message': ""Merge tag '2015.1.0'\n\nIronic 2015.1.0\n\nChange-Id: Ie7036b2fe48dde67d835e0701dbbbdc5cb05457b\n""}, {'number': 2, 'created': '2015-06-09 17:19:16.000000000', 'files': ['ironic/locale/ironic.pot', 'ironic/locale/ironic-log-error.pot', 'requirements.txt', 'ironic/locale/ironic-log-warning.pot', '.gitreview', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9e7af5dbdc0c13049a633c2b716eff638398ad3e', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: Ie7036b2fe48dde67d835e0701dbbbdc5cb05457b\n""}]",0,179294,9e7af5dbdc0c13049a633c2b716eff638398ad3e,17,6,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: Ie7036b2fe48dde67d835e0701dbbbdc5cb05457b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/94/179294/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/locale/ironic.pot', 'ironic/locale/ironic-log-error.pot', 'requirements.txt', 'ironic/locale/ironic-log-warning.pot', '.gitreview', 'test-requirements.txt']",6,fff1cd494165c75611a5157fcea15c2d11134fba,merge/release-tag,python-ironicclient>=0.2.1,"python-ironicclient>=0.2.1,<0.6.0",110,138
openstack%2Fheat~master~Ic039d9aaf3804ab09e3d546d3ae55a18b528d585,openstack/heat,master,Ic039d9aaf3804ab09e3d546d3ae55a18b528d585,Provide a signal URL attribute for alarms,MERGED,2014-04-13 09:19:07.000000000,2015-06-10 10:26:48.000000000,2015-06-10 05:27:18.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 9751}, {'_account_id': 10327}, {'_account_id': 10487}, {'_account_id': 11424}, {'_account_id': 12437}, {'_account_id': 12606}, {'_account_id': 13323}, {'_account_id': 15881}, {'_account_id': 16203}]","[{'number': 1, 'created': '2014-04-13 09:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4676e171458629d0defc61f842eb7c2a27eedfbf', 'message': 'Provide a trust URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 2, 'created': '2014-04-26 15:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9bc91d3c20583c9eb33e033386dd8ca43bbba7ff', 'message': 'Provide a trust URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 3, 'created': '2015-05-20 18:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/87e8dafc070c0db18ba9f2b2f0d766ed46707b36', 'message': 'Provide a trust URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 4, 'created': '2015-05-26 06:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e2a8f2c23b89e6cfd64c97bf1e43083fe136d117', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 5, 'created': '2015-05-26 07:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9f74ac6f67cdbf19cba9b0b8fbb55d9765ce0f6b', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 6, 'created': '2015-05-26 11:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cdc3a191f2c27b4265af2b2c994caa7cf43e6b55', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 7, 'created': '2015-06-08 08:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/89573d01e99340c42ab03e4d21505c441a328f44', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 8, 'created': '2015-06-08 09:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/048ad8968942a373662c9c668197c22d381c8708', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 9, 'created': '2015-06-09 09:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cf82b281c963e6ceb7072eab5011f3d9e864a1ef', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}, {'number': 10, 'created': '2015-06-09 10:12:04.000000000', 'files': ['heat/engine/resources/signal_responder.py', 'heat/engine/resources/openstack/heat/scaling_policy.py', 'heat/tests/autoscaling/test_heat_scaling_policy.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6b573daa967e0432e4eea317cf51fa8c2ec64e03', 'message': 'Provide a signal URL attribute for alarms\n\nThis patch adds a new attribute to scaling policies allowing it to be\ncalled by the ceilometer service user using trusts on alarming.\n\nImplements: blueprint trust-alarm-urls\nChange-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585\n'}]",14,87111,6b573daa967e0432e4eea317cf51fa8c2ec64e03,75,17,10,7385,,,0,"Provide a signal URL attribute for alarms

This patch adds a new attribute to scaling policies allowing it to be
called by the ceilometer service user using trusts on alarming.

Implements: blueprint trust-alarm-urls
Change-Id: Ic039d9aaf3804ab09e3d546d3ae55a18b528d585
",git fetch https://review.opendev.org/openstack/heat refs/changes/11/87111/9 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat.conf.sample', 'heat/engine/resources/autoscaling.py', 'heat/tests/fakes.py', 'heat/tests/test_heat_autoscaling_group.py', 'heat/common/heat_keystoneclient.py', 'heat/engine/signal_responder.py', 'heat/common/config.py']",7,4676e171458629d0defc61f842eb7c2a27eedfbf,bp/trust-alarm-urls," cfg.StrOpt('alarm_service_user_id', help='User ID of the alarm service.'),",,55,8
openstack%2Ftempest~master~Ie5617e2cd086a6f3b1484526067373bb519d8a31,openstack/tempest,master,Ie5617e2cd086a6f3b1484526067373bb519d8a31,"Use dynamic method to get ""ip"" path not ""/bin/ip""",ABANDONED,2014-10-23 01:17:51.000000000,2015-06-10 10:26:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 4727}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 10969}, {'_account_id': 12412}]","[{'number': 1, 'created': '2014-10-23 01:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/413334da71191fa5ee51504a4c6e5f53a92591fc', 'message': 'Use dynamic method to get ""ip"" path not ""/bin/ip""\n\n""ip"" path is different in different Linux distributions, eg.\n""/sbin/ip"" in CentOS, ""/usr/sbin/ip"" in fedora, so it\'s better\nto get the real ""ip"" path dynamicly by ""whereis"" command, and\nthen use it safely.\n\nChange-Id: Ie5617e2cd086a6f3b1484526067373bb519d8a31\n'}, {'number': 2, 'created': '2014-10-24 16:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5a0858d6af097c3c386f1de1a540fe4400049e4d', 'message': 'Use dynamic method to get ""ip"" path not ""/bin/ip""\n\nSSH only executes commands in ""/bin/"" if we don\'t use absolute\npath, ""ip"" path is different(not always ""/bin/ip"") in different\nLinux distributions, eg. ""/sbin/ip"" in CentOS, ""/usr/sbin/ip"" in\nfedora, so we have to get the real ""ip"" path dynamicly by ""whereis""\ncommand, and then use it safely.\n\nChange-Id: Ie5617e2cd086a6f3b1484526067373bb519d8a31\nRelated-Bug: 1381416\n'}, {'number': 3, 'created': '2014-11-18 02:31:57.000000000', 'files': ['tempest/common/utils/linux/remote_client.py', 'tempest/tests/common/utils/linux/test_remote_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/aae2a292f4a88d00688b09fcecdf5e49b919f1f1', 'message': 'Use dynamic method to get ""ip"" path not ""/bin/ip""\n\nSSH only executes commands in ""/bin/"" if we don\'t use absolute\npath, ""ip"" path is different(not always ""/bin/ip"") in different\nLinux distributions, eg. ""/sbin/ip"" in CentOS, ""/usr/sbin/ip"" in\nfedora, so we have to get the real ""ip"" path dynamicly by ""whereis""\ncommand, and then use it safely.\n\nChange-Id: Ie5617e2cd086a6f3b1484526067373bb519d8a31\nRelated-Bug: 1381416\n'}]",30,130411,aae2a292f4a88d00688b09fcecdf5e49b919f1f1,57,10,3,12412,,,0,"Use dynamic method to get ""ip"" path not ""/bin/ip""

SSH only executes commands in ""/bin/"" if we don't use absolute
path, ""ip"" path is different(not always ""/bin/ip"") in different
Linux distributions, eg. ""/sbin/ip"" in CentOS, ""/usr/sbin/ip"" in
fedora, so we have to get the real ""ip"" path dynamicly by ""whereis""
command, and then use it safely.

Change-Id: Ie5617e2cd086a6f3b1484526067373bb519d8a31
Related-Bug: 1381416
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/130411/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/utils/linux/remote_client.py', 'tempest/tests/common/utils/linux/test_remote_client.py']",2,413334da71191fa5ee51504a4c6e5f53a92591fc,bug/1381416," # The real ip path is ""/sbin/ip"" ip_path = """"""/sbin/ip """""" self.ssh_mock.mock.exec_command.return_value = ip_path # Now in get_mac_address function, it will call exec_comand # twice(one for ip path, one for mac address), but we can't # give two return_values for this call, this is why we use # ""ip_path"" not ""macs"" here. self.assertEqual(self.conn.get_mac_address(), ip_path) self._assert_exec_called_with( ""/sbin/ip addr | awk '/ether/ {print $2}'"") # No valid ""ip"" path found ip_path = """""" """""" self.ssh_mock.mock.exec_command.return_value = ip_path self.assertEqual(self.conn.get_mac_address(), ip_path) # The real ip path is ""/sbin/ip"" ip_path = """"""/bin/ip """""" self.ssh_mock.mock.exec_command.return_value = ip_path self.conn.get_ip_list() self._assert_exec_called_with('/bin/ip address') # No valid ""ip"" path found ip_path = """""" """""" self.ssh_mock.mock.exec_command.return_value = ip_path self.conn.get_ip_list() # The real ip path is ""/sbin/ip"" ip_path = """"""/usr/bin/ip """""" self.ssh_mock.mock.exec_command.return_value = ip_path self.conn.assign_static_ip(nic, ip) self._assert_exec_called_with( ""sudo /usr/bin/ip addr add %s/%s dev %s"" % (ip, '28', nic)) # No valid ""ip"" path found ip_path = """""" """""" self.ssh_mock.mock.exec_command.return_value = ip_path ip = '10.0.0.2' nic = 'eth0' self.conn.assign_static_ip(nic, ip) # The real ip path is ""/sbin/ip"" ip_path = """"""/usr/sbin/ip """""" self.ssh_mock.mock.exec_command.return_value = ip_path nic = 'eth0' self.conn.turn_nic_on(nic) self._assert_exec_called_with('sudo /usr/sbin/ip link set %s up' % nic) # No valid ""ip"" path found ip_path = """""" """""" self.ssh_mock.mock.exec_command.return_value = ip_path"," macs = """"""0a:0b:0c:0d:0e:0f a0:b0:c0:d0:e0:f0"""""" self.ssh_mock.mock.exec_command.return_value = macs self.assertEqual(self.conn.get_mac_address(), macs) ips = """"""1: lo: <LOOPBACK,UP,LOWER_UP> mtu 16436 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast qlen 1000 link/ether fa:16:3e:6e:26:3b brd ff:ff:ff:ff:ff:ff inet 10.0.0.4/24 brd 10.0.0.255 scope global eth0 inet6 fd55:faaf:e1ab:3d9:f816:3eff:fe6e:263b/64 scope global dynamic valid_lft 2591936sec preferred_lft 604736sec inet6 fe80::f816:3eff:fe6e:263b/64 scope link valid_lft forever preferred_lft forever"""""" self.ssh_mock.mock.exec_command.return_value = ips self.assertEqual(self.conn.get_ip_list(), ips) self.ssh_mock.mock.exec_command.return_value = '' self.assertEqual(self.conn.assign_static_ip(nic, ip), '')",85,24
openstack%2Fmanila~master~I3fbe75023d3dec266c0121df436639a2041eadd5,openstack/manila,master,I3fbe75023d3dec266c0121df436639a2041eadd5,Stop using deprecated 'oslo' namespace,MERGED,2015-06-10 06:59:12.000000000,2015-06-10 10:25:51.000000000,2015-06-10 10:25:49.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 5638}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 7491}, {'_account_id': 8851}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 12198}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-06-10 06:59:12.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/manila/commit/c4e055bd8f7b9ec3b55cc46a0ce804f648a09331', 'message': ""Stop using deprecated 'oslo' namespace\n\nReplace usage of deprecated 'oslo' namespace with appropriate 'oslo_*'\nnamespaces in Manila setup.cfg file.\n\nChange-Id: I3fbe75023d3dec266c0121df436639a2041eadd5\n""}]",0,190043,c4e055bd8f7b9ec3b55cc46a0ce804f648a09331,16,11,1,8851,,,0,"Stop using deprecated 'oslo' namespace

Replace usage of deprecated 'oslo' namespace with appropriate 'oslo_*'
namespaces in Manila setup.cfg file.

Change-Id: I3fbe75023d3dec266c0121df436639a2041eadd5
",git fetch https://review.opendev.org/openstack/manila refs/changes/43/190043/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c4e055bd8f7b9ec3b55cc46a0ce804f648a09331,oslo, manila-rootwrap = oslo_rootwrap.cmd:mainoslo_messaging.notify.drivers = manila.openstack.common.notifier.log_notifier = oslo_messaging.notify._impl_log:LogDriver manila.openstack.common.notifier.no_op_notifier = oslo_messaging.notify._impl_noop:NoOpDriver manila.openstack.common.notifier.rpc_notifier2 = oslo_messaging.notify._impl_messaging:MessagingV2Driver manila.openstack.common.notifier.rpc_notifier = oslo_messaging.notify._impl_messaging:MessagingDriver manila.openstack.common.notifier.test_notifier = oslo_messaging.notify._impl_test:TestDriver oslo_config.opts =, manila-rootwrap = oslo.rootwrap.cmd:mainoslo.messaging.notify.drivers = manila.openstack.common.notifier.log_notifier = oslo.messaging.notify._impl_log:LogDriver manila.openstack.common.notifier.no_op_notifier = oslo.messaging.notify._impl_noop:NoOpDriver manila.openstack.common.notifier.rpc_notifier2 = oslo.messaging.notify._impl_messaging:MessagingV2Driver manila.openstack.common.notifier.rpc_notifier = oslo.messaging.notify._impl_messaging:MessagingDriver manila.openstack.common.notifier.test_notifier = oslo.messaging.notify._impl_test:TestDriver oslo.config.opts =,8,8
openstack%2Fnova~master~Ic67f0f6edb0d38722787a6b88b39eae218110dc9,openstack/nova,master,Ic67f0f6edb0d38722787a6b88b39eae218110dc9,Handle cells race condition deleting unscheduled instance,MERGED,2015-06-03 18:00:11.000000000,2015-06-10 10:24:37.000000000,2015-06-10 10:24:32.000000000,"[{'_account_id': 3}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5280}, {'_account_id': 5441}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-03 18:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c237acc3f5e82b5ae026fbd5e2b62572b491e47', 'message': 'Handle cells race condition deleting unscheduled instance\n\nIn cells, if a delete request comes in before an instance has been\nscheduled to a cell, the API cell will broadcast a message to\ndelete the instance ""everywhere"" (in all cells) followed by a local\ndelete at the top. This causes a race between cells who have a\nrecord for the instance syncing to the top via instance_destroy_at_top\nand the local delete at the top (double delete is possible). If a\nsecond delete is attemped, InstanceNotFound will be raised and\npropagated up to the API, resulting in a 404 response to the caller\nwho requested to delete the instance.\n\nThis change catches and ignores InstanceNotFound during local delete\nat the API cell to prevent propagating an error when the instance\nhas already been deleted.\n\nChange-Id: Ic67f0f6edb0d38722787a6b88b39eae218110dc9\n'}, {'number': 2, 'created': '2015-06-03 20:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db0b31c38fa13adb9374b80e1d45979c6a04630e', 'message': 'Handle cells race condition deleting unscheduled instance\n\nIn cells, if a delete request comes in before an instance has been\nscheduled to a cell, the API cell will broadcast a message to\ndelete the instance ""everywhere"" (in all cells) followed by a local\ndelete at the top. This causes a race between cells who have a\nrecord for the instance syncing to the top via instance_destroy_at_top\nand the local delete at the top (double delete is possible). If a\nsecond delete is attemped, InstanceNotFound will be raised and\npropagated up to the API, resulting in a 404 response to the caller\nwho requested to delete the instance.\n\nThis change catches and ignores InstanceNotFound during local delete\nat the API cell to prevent propagating an error when the instance\nhas already been deleted.\n\nChange-Id: Ic67f0f6edb0d38722787a6b88b39eae218110dc9\n'}, {'number': 3, 'created': '2015-06-03 20:19:47.000000000', 'files': ['nova/compute/cells_api.py', 'nova/tests/unit/compute/test_compute_cells.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c38c1f8277ddac3b8ec8ff844fe96eb684127ed3', 'message': 'Handle cells race condition deleting unscheduled instance\n\nIn cells, if a delete request comes in before an instance has been\nscheduled to a cell, the API cell will broadcast a message to\ndelete the instance ""everywhere"" (in all cells) followed by a local\ndelete at the top. This causes a race between cells who have a\nrecord for the instance syncing to the top via instance_destroy_at_top\nand the local delete at the top (double delete is possible). If a\nsecond delete is attempted, InstanceNotFound will be raised and\npropagated up to the API, resulting in a 404 response to the caller\nwho requested to delete the instance.\n\nThis change catches and ignores InstanceNotFound during local delete\nat the API cell to prevent propagating an error when the instance\nhas already been deleted.\n\nChange-Id: Ic67f0f6edb0d38722787a6b88b39eae218110dc9'}]",0,188126,c38c1f8277ddac3b8ec8ff844fe96eb684127ed3,26,12,3,4690,,,0,"Handle cells race condition deleting unscheduled instance

In cells, if a delete request comes in before an instance has been
scheduled to a cell, the API cell will broadcast a message to
delete the instance ""everywhere"" (in all cells) followed by a local
delete at the top. This causes a race between cells who have a
record for the instance syncing to the top via instance_destroy_at_top
and the local delete at the top (double delete is possible). If a
second delete is attempted, InstanceNotFound will be raised and
propagated up to the API, resulting in a 404 response to the caller
who requested to delete the instance.

This change catches and ignores InstanceNotFound during local delete
at the API cell to prevent propagating an error when the instance
has already been deleted.

Change-Id: Ic67f0f6edb0d38722787a6b88b39eae218110dc9",git fetch https://review.opendev.org/openstack/nova refs/changes/26/188126/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/cells_api.py'],1,7c237acc3f5e82b5ae026fbd5e2b62572b491e47,cells-double-delete," try: instance.refresh() except exception.InstanceNotFound: # NOTE(melwitt): If the instance has already been # deleted by instance_destroy_at_top from a cell, # instance.refresh() will raise InstanceNotFound. else: if instance.cell_name: exc.reraise = False self._handle_cell_delete(context, instance, method_name) except exception.InstanceNotFound: # NOTE(melwitt): We can get here if anything tries to # lookup the instance after a instance_destroy_at_top hits. pass"," instance.refresh() if instance.cell_name: self._handle_cell_delete(context, instance, method_name)",15,4
openstack%2Fironic~master~Icf942802a151d4816ce38fac343a70375720ed47,openstack/ironic,master,Icf942802a151d4816ce38fac343a70375720ed47,Merge tag '2014.2',MERGED,2014-10-16 15:48:57.000000000,2015-06-10 10:22:03.000000000,2015-06-09 20:17:17.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 9751}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 12081}, {'_account_id': 14760}]","[{'number': 1, 'created': '2014-10-16 15:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/eefcd694fd3b8febe1c961831899308e29c9edbe', 'message': ""Merge tag '2014.2'\n\nIronic 2014.2\n\nChange-Id: Icf942802a151d4816ce38fac343a70375720ed47\n""}, {'number': 2, 'created': '2015-06-09 16:41:25.000000000', 'files': ['ironic/drivers/drac.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b21efd1ff20ffc8cbabd25b5375c2ff4045b447f', 'message': ""Merge tag '2014.2'\n\nThis is a null-merge of the 2014.2 release tag back into the\nmaster branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: Icf942802a151d4816ce38fac343a70375720ed47\n""}]",1,128965,b21efd1ff20ffc8cbabd25b5375c2ff4045b447f,32,11,2,11131,,,0,"Merge tag '2014.2'

This is a null-merge of the 2014.2 release tag back into the
master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: Icf942802a151d4816ce38fac343a70375720ed47
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/128965/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/conductor/test_rpcapi.py'],1,eefcd694fd3b8febe1c961831899308e29c9edbe,merge/release-tag,," def test_get_topic_for_driver_doesnt_cache(self): CONF.set_override('host', 'fake-host') rpcapi = conductor_rpcapi.ConductorAPI(topic='fake-topic') self.assertRaises(exception.DriverNotFound, rpcapi.get_topic_for_driver, 'fake-driver') self.dbapi.register_conductor({ 'hostname': 'fake-host', 'drivers': ['fake-driver'], }) rpcapi = conductor_rpcapi.ConductorAPI(topic='fake-topic') self.assertEqual('fake-topic.fake-host', rpcapi.get_topic_for_driver('fake-driver')) ",0,15
openstack%2Fglance~master~I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef,openstack/glance,master,I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef,Make create task as non-blocking,MERGED,2015-05-18 21:17:43.000000000,2015-06-10 10:17:27.000000000,2015-06-10 10:17:24.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 6159}, {'_account_id': 7575}]","[{'number': 1, 'created': '2015-05-18 21:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a049def70663b46cf35276b64e3dd489f6636a2f', 'message': 'Make create task as non-blocking\n\nCurrently, the create task api is blocking and waits until the task\nis complete to return a 201 but that too with a Pending status.\n\nThe patch runs the task executor in an eventlet thread.\n\nChange-Id: I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef\n'}, {'number': 2, 'created': '2015-05-26 23:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d773d33fa827591750d9be2a3a92fb034473088a', 'message': 'Make create task as non-blocking\n\nCurrently, the create task api is blocking and waits until the task\nis complete to return a 201 but that too with a Pending status.\n\nThe patch runs the task executor in an eventlet thread.\n\nChange-Id: I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef\n'}, {'number': 3, 'created': '2015-05-27 00:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a431544421f672aa8fc393c2ec61ee0de629009a', 'message': 'Make create task as non-blocking\n\nCurrently, the create task api is blocking and waits until the task\nis complete to return a 201 but that too with a Pending status.\n\nThe patch runs the task executor in an eventlet thread.\n\nCloses-Bug: #1459051\n\nChange-Id: I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef\n'}, {'number': 4, 'created': '2015-05-27 05:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4804382ee88212a04111bde9efdca0fad951dc22', 'message': 'Make create task as non-blocking\n\nCurrently, the create task api is blocking and waits until the task\nis complete to return a 201 but that too with a Pending status.\n\nThe patch runs the task executor in an eventlet thread.\n\nCloses-Bug: #1459051\n\nChange-Id: I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef\n'}, {'number': 5, 'created': '2015-06-04 00:41:21.000000000', 'files': ['glance/api/v2/tasks.py', 'glance/tests/integration/v2/test_tasks_api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/1296c6d0eb004a5c15b392bf7154db9217200631', 'message': 'Make create task as non-blocking\n\nCurrently, the create task api is blocking and waits until the task\nis complete to return a 201 but that too with a Pending status.\n\nThe patch runs the task executor in an eventlet thread.\n\nCloses-Bug: #1459051\n\nChange-Id: I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef\n'}]",0,184125,1296c6d0eb004a5c15b392bf7154db9217200631,24,5,5,7575,,,0,"Make create task as non-blocking

Currently, the create task api is blocking and waits until the task
is complete to return a 201 but that too with a Pending status.

The patch runs the task executor in an eventlet thread.

Closes-Bug: #1459051

Change-Id: I94f932afb5b754d9bcfa7bbbd1c450bdef7f28ef
",git fetch https://review.opendev.org/openstack/glance refs/changes/25/184125/3 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/tasks.py'],1,a049def70663b46cf35276b64e3dd489f6636a2f,task_async,"from glance.api import common pool = common.get_thread_pool(""tasks_eventlet_pool"") pool.spawn_n(new_task.run, task_executor)", new_task.run(task_executor),3,1
openstack%2Ftempest~master~I6640ba8a0eaaea187cf38582ab537394dec020b6,openstack/tempest,master,I6640ba8a0eaaea187cf38582ab537394dec020b6,Added documentation to tempest-account-generator,MERGED,2015-05-27 15:52:10.000000000,2015-06-10 10:17:15.000000000,2015-06-10 10:17:13.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 7822}, {'_account_id': 8871}, {'_account_id': 9377}, {'_account_id': 10068}, {'_account_id': 10385}, {'_account_id': 16433}]","[{'number': 1, 'created': '2015-05-27 15:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ba0b5e3d57fe2a9dc36579379b9a8db9ae9036a3', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}, {'number': 2, 'created': '2015-05-27 15:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/974914d67d8a15d9342d52476937cde7bbee3dc4', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}, {'number': 3, 'created': '2015-05-28 09:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0b15ce1ed136b53b9f45d7b2f576525dfa01eb91', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}, {'number': 4, 'created': '2015-06-02 16:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f4e5a620fbbfbe0f97791cb94ec3dd4cdbfd0689', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}, {'number': 5, 'created': '2015-06-02 18:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fb641f3a3ddf658c6f855aa16e2c02035d0cdd8b', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}, {'number': 6, 'created': '2015-06-03 14:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e97a287466c4f70522aecf54effaa66d93b0b0d5', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}, {'number': 7, 'created': '2015-06-03 15:18:48.000000000', 'files': ['doc/source/index.rst', 'doc/source/account_generator.rst', 'tempest/cmd/account_generator.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/00fc3dc40c571b9de1f173e626c7a2dfe06c36a4', 'message': 'Added documentation to tempest-account-generator\n\nAdded docstring to cmd/account_generator.py.\nFixed help messages.\nAdded sphinx documentation for tempest-account-generator utility.\n\nChange-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6\n'}]",2,186052,00fc3dc40c571b9de1f173e626c7a2dfe06c36a4,27,11,7,16433,,,0,"Added documentation to tempest-account-generator

Added docstring to cmd/account_generator.py.
Fixed help messages.
Added sphinx documentation for tempest-account-generator utility.

Change-Id: I6640ba8a0eaaea187cf38582ab537394dec020b6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/52/186052/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/account_generator.rst', 'etc/tempest.conf.sample', 'tempest/cmd/account_generator.py']",4,ba0b5e3d57fe2a9dc36579379b9a8db9ae9036a3,account_generator_docs,""""""" Utility for creating **accounts.yaml** file for concurrent test runs. Creates one primary user, one alt user, one swift admin, one stack owner and one admin (optionally) for each concurrent thread. The utility creates user for each tenant. The **accounts.yaml** file will be valid and contain credentials for created users, so each user will be in separate tenant and have the username, tenant_name, password and roles. **Usage:** ``tempest-account-generator [-h] [OPTIONS] accounts_file.yaml``. Positional Arguments ----------------- **accounts_file.yaml** (Required) Provide an output accounts yaml file. Utility creates a .yaml file in the directory where the command is ran. The appropriate name for the file is *accounts.yaml* and it should be placed in *tempest/etc* directory. Authentication -------------- Account generator creates users and tenants so it needs the admin credentials of your cloud to operate properly. The corresponding info can be given either through CLI options or environment variables. You're probably familiar with these, but just to remind:: +----------+------------------+----------------------+ | Param | CLI | Environment Variable | +----------+------------------+----------------------+ | Username | --os-username | OS_USERNAME | | Password | --os-password | OS_PASSWORD | | Tenant | --os-tenant-name | OS_TENANT_NAME | +----------+------------------+----------------------+ Optional Arguments ----------------- **-h**, **--help** (Optional) Shows help message with the description of utility and its arguments, and exits. **c /etc/tempest.conf**, **--config-file /etc/tempest.conf** (Optional) Path to tempest config file. **--os-username <auth-user-name>** (Optional) Name used for authentication with the OpenStack Identity service. Defaults to env[OS_USERNAME]. Note: User should have permissions to create new user accounts and tenants. **--os-password <auth-password>** (Optional) Password used for authentication with the OpenStack Identity service. Defaults to env[OS_PASSWORD]. **--os-tenant-name <auth-tenant-name>** (Optional) Tenant to request authorization on. Defaults to env[OS_TENANT_NAME]. **--tag TAG** (Optional) Resources tag. Each created resource (user, project) will have the prefix with the given TAG in its name. Using tag is recommended for the further using, cleaning resources. **-r CONCURRENCY**, **--concurrency CONCURRENCY** (Required) Concurrency count (default: 1). The number of accounts required can be estimated as CONCURRENCY x 2. Each user provided in *accounts.yaml* file will be in a different tenant. This is required to provide isolation between test for running in parallel. **--with-admin** (Optional) Creates admin for each concurrent group (default: False). To see help on specific argument, please do: ``tempest-account-generator [OPTIONS] <accounts_file.yaml> -h``. """""" usage_string = ('tempest-account-generator [-h] <ARG> ...\n\n' 'tempest-account-generator <ARG> -h') help='User should have permissions ' help='Creates admin for each concurrent group')", usage_string = ('account_generator [-h] <ARG> ...\n\n' 'account_generator <ARG> -h') help='User should have permitions ' help='Create admin in every tenant'),86,7
openstack%2Fnova~master~I608042c58c04f333f6fbb8d9824eb8f3913c6310,openstack/nova,master,I608042c58c04f333f6fbb8d9824eb8f3913c6310,virt: Move building the block_device_info dict into a method,MERGED,2015-05-06 17:23:16.000000000,2015-06-10 10:17:00.000000000,2015-06-10 09:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9382}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10224}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}]","[{'number': 1, 'created': '2015-05-06 17:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec912213905dbd7c89dd50687d9f904029eb123b', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 2, 'created': '2015-05-21 09:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f336034941757f300b2661be9c7e6bf0a6647ce', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 3, 'created': '2015-05-22 12:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c6b9e160992ba2ed542491302e9b1b49f8d5a3a', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 4, 'created': '2015-05-27 11:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c42b33b79ac0684a03a7013b7ee994ac64eea092', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 5, 'created': '2015-05-27 15:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6942e0400b1a7d73e7f0bcd4dd732f8e5af7d61e', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 6, 'created': '2015-05-28 09:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb62e7be1beac57cb8e0435ff6332766d71d09ef', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 7, 'created': '2015-06-08 11:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a6820c969da9d87190a2c275d12361ec7474361', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}, {'number': 8, 'created': '2015-06-09 10:09:51.000000000', 'files': ['nova/tests/unit/compute/test_compute.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/94a5793d63a797697fb1f937340cb49b3c7e9787', 'message': ""virt: Move building the block_device_info dict into a method\n\nThe block_device_info structure is needed in several places, so it's\nuseful to move it into a method and remove the code repetition that is\nall over the place.\n\nAlso make sure there is a single way to get the legacy dict format for\nthe drivers that need this (however at this point we should probably\nremove that soon, and convert all the in-tree drivers to expect the new\nformat).\n\nRelated-bug: 1231874\nPartial-bug: 1452224\n\nChange-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310\n""}]",17,180635,94a5793d63a797697fb1f937340cb49b3c7e9787,94,19,8,5511,,,0,"virt: Move building the block_device_info dict into a method

The block_device_info structure is needed in several places, so it's
useful to move it into a method and remove the code repetition that is
all over the place.

Also make sure there is a single way to get the legacy dict format for
the drivers that need this (however at this point we should probably
remove that soon, and convert all the in-tree drivers to expect the new
format).

Related-bug: 1231874
Partial-bug: 1452224

Change-Id: I608042c58c04f333f6fbb8d9824eb8f3913c6310
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/180635/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute.py', 'nova/virt/driver.py', 'nova/compute/manager.py', 'nova/virt/block_device.py']",4,ec912213905dbd7c89dd50687d9f904029eb123b,bug/1452224," do_check_attach=True, do_driver_attach=False, **kwargs):"," do_check_attach=True, do_driver_attach=False):",57,65
openstack%2Fopenstack-manuals~master~Id109437e45144653d894b6d1bced3a6106db58d4,openstack/openstack-manuals,master,Id109437e45144653d894b6d1bced3a6106db58d4,Convert the Identity Management chapter to RST,MERGED,2015-06-09 06:28:42.000000000,2015-06-10 10:10:42.000000000,2015-06-10 08:18:07.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 10705}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-09 06:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cd87d6f8ae534314b8b8177a68467de9574a789e', 'message': 'Convert the Identity Management chapter to RST\n\nConverted Cloud Admin Guide files:\n- admin-guide-cloud-rst/source/identity_management.rst\n- common-rst/keystone_user_management.rst\n- common-rst/troubleshooting_identity_service.rst\n\nChange-Id: Id109437e45144653d894b6d1bced3a6106db58d4\nImplements: blueprint reorganise-user-guides\n'}, {'number': 2, 'created': '2015-06-10 04:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7c78ef61556a86002756f33eede9cf762e15d7ea', 'message': 'Convert the Identity Management chapter to RST\n\nCommon files converted to RST and directly added to the Cloud Admin Guide (since they are not used elsewhere):\n- Identity user management\n- Identity service management\n- Groups\n- Troubleshoot the Identity service\n\nChange-Id: Id109437e45144653d894b6d1bced3a6106db58d4\nImplements: blueprint reorganise-user-guides\n'}, {'number': 3, 'created': '2015-06-10 05:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c69512d426e075ef25fa8bef20c300bceffb3d6d', 'message': 'Convert the Identity Management chapter to RST\n\nCommon files converted to RST and directly added to the Cloud Admin Guide (since they are not used elsewhere):\n- Identity user management\n- Identity service management\n- Groups\n- Troubleshoot the Identity service\n\nChange-Id: Id109437e45144653d894b6d1bced3a6106db58d4\nImplements: blueprint reorganise-user-guides\n'}, {'number': 4, 'created': '2015-06-10 05:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d141afbd4a7824ad062dff72f0d876bd77d16b0', 'message': 'Convert the Identity Management chapter to RST\n\nCommon files converted to RST and directly added to the Cloud Admin Guide (since they are not used elsewhere):\n- Identity user management\n- Identity service management\n- Groups\n- Troubleshoot the Identity service\n\nChange-Id: Id109437e45144653d894b6d1bced3a6106db58d4\nImplements: blueprint reorganise-user-guides\n'}, {'number': 5, 'created': '2015-06-10 06:59:21.000000000', 'files': ['doc/admin-guide-cloud-rst/source/identity_management.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/30c9b53a8ca2be3bf9e61eecf9aaec6e31a78686', 'message': 'Convert the Identity Management chapter to RST\n\nCommon files converted to RST and directly added to the Cloud Admin Guide (since they are not used elsewhere):\n- Identity user management\n- Identity service management\n- Groups\n- Troubleshoot the Identity service\n\nChange-Id: Id109437e45144653d894b6d1bced3a6106db58d4\nImplements: blueprint reorganise-user-guides\n'}]",22,189566,30c9b53a8ca2be3bf9e61eecf9aaec6e31a78686,28,6,5,10705,,,0,"Convert the Identity Management chapter to RST

Common files converted to RST and directly added to the Cloud Admin Guide (since they are not used elsewhere):
- Identity user management
- Identity service management
- Groups
- Troubleshoot the Identity service

Change-Id: Id109437e45144653d894b6d1bced3a6106db58d4
Implements: blueprint reorganise-user-guides
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/66/189566/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common-rst/keystone_user_management.rst', 'doc/admin-guide-cloud-rst/source/identity_management.rst', 'doc/common-rst/troubleshooting_identity_service.rst']",3,cd87d6f8ae534314b8b8177a68467de9574a789e,bp/reorganise-user-guides,":orphan: ================================= Troubleshoot the Identity service ================================= To troubleshoot the Identity service, review the logs in the ``/var/log/keystone/keystone.log`` file. .. note Use the :file:`/etc/keystone/logging.conf` file to configure the location of log files. The logs show the components that have come in to the WSGI request, and ideally show an error that explains why an authorization request failed. If you do not see the request in the logs, run keystone with the :option:`--debug` parameter. Pass the :option:`--debug` parameter before the command parameters. Debug PKI middleware ~~~~~~~~~~~~~~~~~~~~ If you receive an ``Invalid OpenStack Identity Credentials`` message when you talk to an OpenStack service, it might be caused by the changeover from UUID tokens to PKI tokens in the Grizzly release. Learn how to troubleshoot this error. The PKI-based token validation scheme relies on certificates from Identity that are fetched through HTTP and stored in a local directory. The location for this directory is specified by the ``signing_dir`` configuration option. In your services configuration file, look for a section like this: .. code-block:: ini :linenos: [keystone_authtoken] signing_dir = /var/cache/glance/api auth_uri = http://controller:5000/v2.0 identity_uri = http://controller:35357 admin_tenant_name = service admin_user = glance If your service lacks this stanza, the `keystoneclient/middleware/auth\_token.py <https://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/middleware/auth_token.py#L198>`__ file specifies the defaults. If no value is specified for this directory, it `defaults to a secure temporary directory. <https://github.com/openstack/python-keystoneclient/blob/master/keystoneclient/middleware/auth_token.py#L299>`__ Initialization code for the service checks that the directory exists and is writable. If it does not exist, the code tries to create it. If this fails, the service fails to start. However, it often succeeds but problems occur later. The first thing to check is that the ``signing_dir`` does, in fact, exist. If it does, check for certificate files: .. code:: $ ls -la /var/cache/glance/api/ .. code:: total 24 drwx------. 2 ayoung root 4096 Jul 22 10:58 . drwxr-xr-x. 4 root root 4096 Nov 7 2012 .. -rw-r-----. 1 ayoung ayoung 1424 Jul 22 10:58 cacert.pem -rw-r-----. 1 ayoung ayoung 15 Jul 22 10:58 revoked.pem -rw-r-----. 1 ayoung ayoung 4518 Jul 22 10:58 signing_cert.pem This directory contains two certificates and the token revocation list. If these files are not present, your service cannot fetch them from Identity. To troubleshoot, try to talk to Identity to make sure it correctly serves files, as follows: .. code:: $ curl http://localhost:35357/v2.0/certificates/signing This command fetches the signing certificate: .. code:: Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha1WithRSAEncryption Issuer: C=US, ST=Unset, L=Unset, O=Unset, CN=www.example.com Validity Not Before: Jul 22 14:57:31 2013 GMT Not After : Jul 20 14:57:31 2023 GMT Subject: C=US, ST=Unset, O=Unset, CN=www.example.com Note the expiration dates of the certificate: .. code:: Not Before: Jul 22 14:57:31 2013 GMT Not After : Jul 20 14:57:31 2023 GMT The token revocation list is updated once a minute, but the certificates are not. One possible problem is that the certificates are the wrong files or garbage. You can remove these files and run another command against your server; they are fetched on demand. The Identity service log should show the access of the certificate files. You might have to turn up your logging levels. Set ``debug = True`` and ``verbose = True`` in your Identity configuration file and restart the Identity server. .. code:: (keystone.common.wsgi): 2013-07-24 12:18:11,461 DEBUG wsgi __call__ arg_dict: {} (access): 2013-07-24 12:18:11,462 INFO core __call__ 127.0.0.1 - - [24/Jul/2013:16:18:11 +0000] ""GET http://localhost:35357/v2.0/certificates/signing HTTP/1.0"" 200 4518 If the files do not appear in your directory after this, it is likely one of the following issues: * Your service is configured incorrectly and cannot talk to Identity. Check the ``auth_port`` and ``auth_host`` values and make sure that you can talk to that service through cURL, as shown previously. * Your signing directory is not writable. Use the ``chmod`` command to change its permissions so that the service (POSIX) user can write to it. Verify the change through ``su`` and ``touch`` commands. * The SELinux policy is denying access to the directory. SELinux troubles often occur when you use Fedora or RHEL-based packages and you choose configuration options that do not match the standard policy. Run the ``setenforce permissive`` command. If that makes a difference, you should relabel the directory. If you are using a sub-directory of the ``/var/cache/`` directory, run the following command: .. code:: # restorecon /var/cache/ If you are not using a ``/var/cache`` sub-directory, you should. Modify the ``signing_dir`` configuration option for your service and restart. Set back to ``setenforce enforcing`` to confirm that your changes solve the problem. If your certificates are fetched on demand, the PKI validation is working properly. Most likely, the token from Identity is not valid for the operation you are attempting to perform, and your user needs a different role for the operation. Debug signing key file errors ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ If an error occurs when the signing key file opens, it is possible that the person who ran the ``keystone-manage pki_setup`` command to generate certificates and keys did not use the correct user. When you run the ``keystone-manage pki_setup`` command, Identity generates a set of certificates and keys in ``/etc/keystone/ssl*``, which is owned by ``root:root``. This can present a problem when you run the Identity daemon under the keystone user account (nologin) when you try to run PKI. Unless you run the ``chown`` command against the files ``keystone:keystone``, or run the ``keystone-manage pki_setup`` command with the :option:`--keystone-user` and :option:`--keystone-group`` parameters, you will get an error. For example: .. code:: 2012-07-31 11:10:53 ERROR [keystone.common.cms] Error opening signing key file /etc/keystone/ssl/private/signing_key.pem 140380567730016:error:0200100D:system library:fopen:Permission denied:bss_file.c:398:fopen('/etc/keystone/ssl/private/signing_key.pem','r') 140380567730016:error:20074002:BIO routines:FILE_CTRL:system lib:bss_file.c:400: unable to load signing key file Flush expired tokens from the token database table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ As you generate tokens, the token database table on the Identity server grows. To clear the token table, an administrative user must run the ``keystone-manage token_flush`` command to flush the tokens. When you flush tokens, expired tokens are deleted and traceability is eliminated. Use ``cron`` to schedule this command to run frequently based on your workload. For large workloads, running it every minute is recommended. ",,418,0
openstack%2Fnova~master~Iec47ed1c43007c7852bdf81945ffa0ff9003150f,openstack/nova,master,Iec47ed1c43007c7852bdf81945ffa0ff9003150f,libvirt: Remove unnecessary JSON conversions,MERGED,2015-04-24 20:19:12.000000000,2015-06-10 10:06:53.000000000,2015-06-10 05:13:19.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 6802}, {'_account_id': 8276}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-24 20:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56872480c9787f41b438df770565473fb602465f', 'message': 'libvirt: Remove unnecessary JSON conversions\n\n_get_instance_disk_info creates information as a list but returns a\nJSON representation of the list. The JSON is repeatedly converted by\nother methods that operate on the original list.\n\nThis change updates _get_instance_disk_info to return a list rather\nthan JSON. The get_instance_disk_info method still returns JSON --\nthe only difference between the methods is their arguments.\n\nChange-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f\n'}, {'number': 2, 'created': '2015-05-08 21:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65a34c9565e37f7992f29989d9c26a36714c66af', 'message': 'libvirt: Remove unnecessary JSON conversions\n\n_get_instance_disk_info creates information as a list but returns a\nJSON representation of the list. The JSON is repeatedly converted by\nother methods that operate on the original list.\n\nThis change updates _get_instance_disk_info to return a list rather\nthan JSON. The get_instance_disk_info method still returns JSON --\nthe only difference between the methods is their arguments.\n\nChange-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f\n'}, {'number': 3, 'created': '2015-05-12 12:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c06d18f65f28cc37d01b4f1f78cdd6fe062c4902', 'message': 'libvirt: Remove unnecessary JSON conversions\n\n_get_instance_disk_info creates information as a list but returns a\nJSON representation of the list. The JSON is repeatedly converted by\nother methods that operate on the original list.\n\nThis change updates _get_instance_disk_info to return a list rather\nthan JSON. The get_instance_disk_info method still returns JSON --\nthe only difference between the methods is their arguments.\n\nChange-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f\n'}, {'number': 4, 'created': '2015-05-20 21:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/569d7f86ac3cd9e985e861b8839d207695b35c98', 'message': 'libvirt: Remove unnecessary JSON conversions\n\n_get_instance_disk_info creates information as a list but returns a\nJSON representation of the list. The JSON is repeatedly converted by\nother methods that operate on the original list.\n\nThis change updates _get_instance_disk_info to return a list rather\nthan JSON. The get_instance_disk_info method still returns JSON --\nthe only difference between the methods is their arguments.\n\nChange-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f\n'}, {'number': 5, 'created': '2015-06-01 19:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b0c0ebef6b474450ac776e292cb77e794145f9f', 'message': 'libvirt: Remove unnecessary JSON conversions\n\n_get_instance_disk_info creates information as a list but returns a\nJSON representation of the list. The JSON is repeatedly converted by\nother methods that operate on the original list.\n\nThis change updates _get_instance_disk_info to return a list rather\nthan JSON. The get_instance_disk_info method still returns JSON --\nthe only difference between the methods is their arguments.\n\nChange-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f\n'}, {'number': 6, 'created': '2015-06-09 14:45:18.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7a0b4e542a65b3ba3650db2b7560eb587b9606c', 'message': 'libvirt: Remove unnecessary JSON conversions\n\n_get_instance_disk_info creates information as a list but returns a\nJSON representation of the list. The JSON is repeatedly converted by\nother methods that operate on the original list.\n\nThis change updates _get_instance_disk_info to return a list rather\nthan JSON. The get_instance_disk_info method still returns JSON --\nthe only difference between the methods is their arguments.\n\nChange-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f\n'}]",3,177437,a7a0b4e542a65b3ba3650db2b7560eb587b9606c,69,16,6,6802,,,0,"libvirt: Remove unnecessary JSON conversions

_get_instance_disk_info creates information as a list but returns a
JSON representation of the list. The JSON is repeatedly converted by
other methods that operate on the original list.

This change updates _get_instance_disk_info to return a list rather
than JSON. The get_instance_disk_info method still returns JSON --
the only difference between the methods is their arguments.

Change-Id: Iec47ed1c43007c7852bdf81945ffa0ff9003150f
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/177437/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,56872480c9787f41b438df770565473fb602465f,bp/stop-dmcrypt-on-suspend," @mock.patch('nova.virt.libvirt.LibvirtDriver.get_instance_disk_info') disk_info = '[{""virt_disk_size"": 2}]' mock_get_instance_disk_info.return_value = disk_info @mock.patch('nova.virt.libvirt.LibvirtDriver.get_instance_disk_info') mock_get_disk_info.return_value = '{}' mock.patch.object(drvr, 'get_instance_disk_info'), return fake_disks.get(instance_name) return fake_disks.get(name)"," @mock.patch('nova.virt.libvirt.LibvirtDriver._get_instance_disk_info') disk_info_json = '[{""virt_disk_size"": 2}]' mock_get_instance_disk_info.return_value = disk_info_json @mock.patch('nova.virt.libvirt.LibvirtDriver._get_instance_disk_info') mock_get_disk_info.return_value = {} mock.patch.object(drvr, '_get_instance_disk_info'), return jsonutils.dumps(fake_disks.get(instance_name)) return jsonutils.dumps(fake_disks.get(name))",15,15
openstack%2Fneutron-lbaas~stable%2Fkilo~I56cc80efc665d847872b4bdaa55b97954bf336bc,openstack/neutron-lbaas,stable/kilo,I56cc80efc665d847872b4bdaa55b97954bf336bc,Add redundance and lvs feature to LBaasv2,ABANDONED,2015-06-10 09:59:39.000000000,2015-06-10 10:03:03.000000000,,[],"[{'number': 1, 'created': '2015-06-10 09:59:39.000000000', 'files': ['neutron_lbaas/tests/tempest/v2/api/base.py', 'neutron_lbaas/drivers/driver_mixins.py', 'neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/59973929d429_add_lvs_support.py', 'neutron_lbaas/drivers/common/agent_callbacks.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/agent/agent_device_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_proxies.j2', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy.loadbalancer.j2', 'neutron_lbaas/db/migration/alembic_migrations/versions/1e60a79fa7d6_add_loadbalancer_redundance_table.py', 'neutron_lbaas/tests/tempest/v2/clients/lvs_client.py', 'neutron_lbaas/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/data_models.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_lbaas/tests/tempest/v2/scenario/test_create_delete.py', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py', 'neutron_lbaas/tests/unit/drivers/common/test_agent_callbacks.py', 'neutron_lbaas/drivers/logging_noop/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py', 'neutron_lbaas/tests/tempest/v2/clients/redundances_client.py', 'neutron_lbaas/tests/tempest/etc/tempest.conf', 'neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/5350b1d30c42_lvs_redundance_update.py', 'neutron_lbaas/drivers/driver_base.py', 'neutron_lbaas/db/loadbalancer/models.py', 'neutron_lbaas/tests/tempest/v2/scenario/lb-create-delete-test.json'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/f857109a0ec884612626f8a0ac750c55ff7cd21e', 'message': 'Add redundance and lvs feature to LBaasv2\n\nChange-Id: I56cc80efc665d847872b4bdaa55b97954bf336bc\n'}]",0,190095,f857109a0ec884612626f8a0ac750c55ff7cd21e,2,0,1,12412,,,0,"Add redundance and lvs feature to LBaasv2

Change-Id: I56cc80efc665d847872b4bdaa55b97954bf336bc
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/95/190095/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/tempest/v2/api/base.py', 'neutron_lbaas/drivers/driver_mixins.py', 'neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/59973929d429_add_lvs_support.py', 'neutron_lbaas/drivers/common/agent_callbacks.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/agent/agent_device_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_proxies.j2', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy.loadbalancer.j2', 'neutron_lbaas/db/migration/alembic_migrations/versions/1e60a79fa7d6_add_loadbalancer_redundance_table.py', 'neutron_lbaas/tests/tempest/v2/clients/lvs_client.py', 'neutron_lbaas/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/data_models.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_lbaas/tests/tempest/v2/scenario/test_create_delete.py', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py', 'neutron_lbaas/tests/unit/drivers/common/test_agent_callbacks.py', 'neutron_lbaas/drivers/logging_noop/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py', 'neutron_lbaas/tests/tempest/v2/clients/redundances_client.py', 'neutron_lbaas/tests/tempest/etc/tempest.conf', 'neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/5350b1d30c42_lvs_redundance_update.py', 'neutron_lbaas/drivers/driver_base.py', 'neutron_lbaas/db/loadbalancer/models.py', 'neutron_lbaas/tests/tempest/v2/scenario/lb-create-delete-test.json']",30,f857109a0ec884612626f8a0ac750c55ff7cd21e,rebase-kilo,"[{""action"": ""neutron_lbaas.tests.tempest.v2.scenario.test_create_delete.LoadbalancerStresstest"", ""threads"": 2, ""use_admin"": false, ""use_isolated_tenants"": false, ""kwargs"": {} } ] ",,2699,25
openstack%2Fneutron-lbaas~stable%2Fkilo~I0fa428ff759240f6364fcd33f6740bea1b287adc,openstack/neutron-lbaas,stable/kilo,I0fa428ff759240f6364fcd33f6740bea1b287adc,Restrict delete pool if it has binding healthmonitor,ABANDONED,2015-06-10 09:59:39.000000000,2015-06-10 10:02:54.000000000,,[{'_account_id': 9531}],"[{'number': 1, 'created': '2015-06-10 09:59:39.000000000', 'files': ['neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/tests/tempest/v2/api/test_pools_non_admin.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/5972800deb902a7928540be1512376a42cbd0f18', 'message': ""Restrict delete pool if it has binding healthmonitor\n\nTo delete pool you need to delete the pool's healthmonitor first.\n\nChange-Id: I0fa428ff759240f6364fcd33f6740bea1b287adc\n""}]",0,190091,5972800deb902a7928540be1512376a42cbd0f18,2,1,1,12412,,,0,"Restrict delete pool if it has binding healthmonitor

To delete pool you need to delete the pool's healthmonitor first.

Change-Id: I0fa428ff759240f6364fcd33f6740bea1b287adc
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/91/190091/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/tests/tempest/v2/api/test_pools_non_admin.py']",3,5972800deb902a7928540be1512376a42cbd0f18,rebase-kilo,"# Copyright 2015 Rackspace # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common.utils import data_utils from tempest import exceptions as ex from tempest import test from neutron_lbaas.tests.tempest.v2.api import base PROTOCOL_PORT = 80 class TestPools(base.BaseTestCase): """""" Tests the following operations in the Neutron-LBaaS API using the REST client for Pools: list pools create pool get pool update pool delete pool """""" @classmethod def resource_setup(cls): super(TestPools, cls).resource_setup() if not test.is_extension_enabled('lbaas', 'network'): msg = ""lbaas extension not enabled."" raise cls.skipException(msg) network_name = data_utils.rand_name('network-') cls.network = cls.create_network(network_name) cls.subnet = cls.create_subnet(cls.network) cls.load_balancer = cls._create_load_balancer( tenant_id=cls.subnet.get('tenant_id'), vip_subnet_id=cls.subnet.get('id')) def increment_protocol_port(self): global PROTOCOL_PORT PROTOCOL_PORT += 1 def _prepare_and_create_pool(self, protocol=None, lb_algorithm=None, listener_id=None, **kwargs): self.increment_protocol_port() if not protocol: protocol = 'HTTP' if not lb_algorithm: lb_algorithm = 'ROUND_ROBIN' if not listener_id: listener = self._create_listener( loadbalancer_id=self.load_balancer.get('id'), protocol='HTTP', protocol_port=PROTOCOL_PORT) listener_id = listener.get('id') response = self._create_pool(protocol=protocol, lb_algorithm=lb_algorithm, listener_id=listener_id, **kwargs) return response @test.attr(type='smoke') def test_list_pools_empty(self): """"""Test get pools when empty"""""" pools = self.pools_client.list_pools() self.assertEqual([], pools) @test.attr(type='smoke') def test_list_pools_one(self): """"""Test get pools with one pool"""""" new_pool = self._prepare_and_create_pool() new_pool = self.pools_client.get_pool(new_pool['id']) pools = self.pools_client.list_pools() self.assertEqual(1, len(pools)) self.assertIn(new_pool, pools) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_list_pools_two(self): """"""Test get pools with two pools"""""" new_pool1 = self._prepare_and_create_pool() new_pool2 = self._prepare_and_create_pool() pools = self.pools_client.list_pools() self.assertEqual(2, len(pools)) self.assertIn(new_pool1, pools) self.assertIn(new_pool2, pools) self._delete_pool(new_pool1.get('id')) self._delete_pool(new_pool2.get('id')) @test.attr(type='smoke') def test_get_pool(self): """"""Test get pool"""""" new_pool = self._prepare_and_create_pool() pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_create_pool(self): """"""Test create pool"""""" new_pool = self._prepare_and_create_pool() pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_create_pool_missing_required_fields(self): """"""Test create pool with a missing required fields"""""" tenant_id = self.subnet.get('tenant_id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=tenant_id, lb_algorithm='ROUND_ROBIN') @test.attr(type='smoke') def test_create_pool_missing_tenant_field(self): """"""Test create pool with a missing required tenant field"""""" tenant_id = self.subnet.get('tenant_id') new_pool = self._prepare_and_create_pool( protocol='HTTP', lb_algorithm='ROUND_ROBIN') pool = self.pools_client.get_pool(new_pool.get('id')) pool_tenant = pool['tenant_id'] self.assertEqual(tenant_id, pool_tenant) self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_create_pool_missing_protocol_field(self): """"""Test create pool with a missing required protocol field"""""" self.increment_protocol_port() listener = self.listeners_client.create_listener( loadbalancer_id=self.load_balancer.get('id'), protocol='HTTP', protocol_port=PROTOCOL_PORT) listener_id = listener.get('id') tenant_id = self.subnet.get('tenant_id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=tenant_id, listener_id=listener_id, lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_missing_lb_algorithm_field(self): """"""Test create pool with a missing required lb algorithm field"""""" self.increment_protocol_port() listener = self.listeners_client.create_listener( loadbalancer_id=self.load_balancer.get('id'), protocol='HTTP', protocol_port=PROTOCOL_PORT) listener_id = listener.get('id') tenant_id = self.subnet.get('tenant_id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=tenant_id, listener_id=listener_id, protocol='HTTP') @test.attr(type='negative') def test_create_pool_missing_listener_id_field(self): """"""Test create pool with a missing required listener id field"""""" tenant_id = self.subnet.get('tenant_id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=tenant_id, lb_algorithm='ROUND_ROBIN', protocol='HTTP') @test.attr(type='smoke') def test_create_pool_missing_description_field(self): """"""Test create pool with missing description field"""""" self._wait_for_load_balancer_status(self.load_balancer.get('id')) new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) desc = pool_initial.get('description') self.assertEqual(desc, """") self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_create_pool_missing_name_field(self): """"""Test create pool with a missing name field"""""" self._wait_for_load_balancer_status(self.load_balancer.get('id')) new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) name = pool_initial.get('name') self.assertEqual(name, """") self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_create_pool_missing_admin_state_up_field(self): """"""Test create pool with a missing admin_state_up field"""""" self._wait_for_load_balancer_status(self.load_balancer.get('id')) new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) state = pool_initial.get('admin_state_up') self.assertEqual(state, True) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_create_pool_missing_session_pers_field(self): """"""Test create pool with a missing session_pers field"""""" self._wait_for_load_balancer_status(self.load_balancer.get('id')) new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) sess = pool_initial.get('session_persistence') self.assertIsNone(sess) self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_create_pool_invalid_protocol(self): """"""Test create pool with an invalid protocol"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='UDP', lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_invalid_session_persistence_field(self): """"""Test create pool with invalid session persistance field"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', session_persistence={'type': 'HTTP'}, lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_invalid_algorithm(self): """"""Test create pool with an invalid algorithm"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', lb_algorithm='LEAST_CON') @test.attr(type='negative') def test_create_pool_invalid_admin_state_up(self): """"""Test create pool with an invalid admin state up field"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', admin_state_up=""$!1%9823"", lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_invalid_listener_field(self): """"""Test create pool with invalid listener field"""""" tenant_id = self.subnet.get('tenant_id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=tenant_id, lb_algorithm='ROUND_ROBIN', protocol='HTTP', listener_id=""$@5$%$7863"") @test.attr(type='negative') def test_create_pool_invalid_tenant_id_field(self): """"""Test create pool with invalid tenant_id field"""""" self.increment_protocol_port() listener = self.listeners_client.create_listener( loadbalancer_id=self.load_balancer.get('id'), protocol='HTTP', protocol_port=PROTOCOL_PORT) listener_id = listener.get('id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=""*&7653^%&"", lb_algorithm='ROUND_ROBIN', protocol='HTTP', listener_id=listener_id) @test.attr(type='negative') def test_create_pool_incorrect_attribute(self): """"""Test create a pool with an extra, incorrect field"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', lb_algorithm='ROUND_ROBIN', protocol_port=80) @test.attr(type='negative') def test_create_pool_empty_listener_field(self): """"""Test create pool with empty listener field"""""" tenant_id = self.subnet.get('tenant_id') self.assertRaises(ex.BadRequest, self._create_pool, tenant_id=tenant_id, lb_algorithm='ROUND_ROBIN', protocol='HTTP', listener_id="""") @test.attr(type='smoke') def test_create_pool_empty_description_field(self): """"""Test create pool with empty description field"""""" new_pool = self._prepare_and_create_pool( description="""") pool = self.pools_client.get_pool(new_pool.get('id')) pool_desc = pool.get('description') self.assertEqual(pool_desc, '') self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_create_pool_empty_name_field(self): """"""Test create pool with empty name field"""""" new_pool = self._prepare_and_create_pool( name="""") pool = self.pools_client.get_pool(new_pool.get('id')) pool_name = pool.get('name') self.assertEqual(pool_name, '') self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_create_pool_empty_protocol(self): """"""Test create pool with an empty protocol"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol="""", lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_empty_session_persistence_field(self): """"""Test create pool with empty session persistence field"""""" self.assertRaises(ex.BadRequest, self._create_pool, session_persistence="""", protocol='HTTP', lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_empty_algorithm(self): """"""Test create pool with an empty algorithm"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', lb_algorithm="""") @test.attr(type='negative') def test_create_pool_empty_admin_state_up(self): """"""Test create pool with an invalid admin state up field"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', admin_state_up="""", lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_empty_tenant_field(self): """"""Test create pool with empty tenant field"""""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', tenant_id="""", lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_for_other_tenant_field(self): """"""Test create pool for other tenant field"""""" tenant = 'deffb4d7c0584e89a8ec99551565713c' self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', tenant_id=tenant, lb_algorithm='ROUND_ROBIN') @test.skip_because(bug=""1434717"") @test.attr(type='negative') def test_create_pool_invalid_name_field(self): """""" known bug with input more than 255 chars Test create pool with invalid name field """""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', lb_algorithm='ROUND_ROBIN', name='n' * 256) @test.skip_because(bug=""1434717"") @test.attr(type='negative') def test_create_pool_invalid_desc_field(self): """""" known bug with input more than 255 chars Test create pool with invalid desc field """""" self.assertRaises(ex.BadRequest, self._create_pool, protocol='HTTP', lb_algorithm='ROUND_ROBIN', description='d' * 256) @test.attr(type='negative') def test_create_pool_with_session_persistence_unsupported_type(self): """"""Test create a pool with an incorrect type value for session persistence """""" self.assertRaises(ex.BadRequest, self._create_pool, session_persistence={'type': 'UNSUPPORTED'}, protocol='HTTP', lb_algorithm='ROUND_ROBIN') @test.attr(type='smoke') def test_create_pool_with_session_persistence_http_cookie(self): """"""Test create a pool with session_persistence type=HTTP_COOKIE"""""" new_pool = self._prepare_and_create_pool( session_persistence={'type': 'HTTP_COOKIE'}) pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_create_pool_with_session_persistence_app_cookie(self): """"""Test create a pool with session_persistence type=APP_COOKIE"""""" new_pool = self._prepare_and_create_pool( session_persistence={'type': 'APP_COOKIE', 'cookie_name': 'sessionId'}) pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_create_pool_with_session_persistence_redundant_cookie_name(self): """"""Test create a pool with session_persistence with cookie_name for type=HTTP_COOKIE """""" self.assertRaises(ex.BadRequest, self._create_pool, session_persistence={'type': 'HTTP_COOKIE', 'cookie_name': 'sessionId'}, protocol='HTTP', lb_algorithm='ROUND_ROBIN') @test.attr(type='negative') def test_create_pool_with_session_persistence_without_cookie_name(self): """"""Test create a pool with session_persistence without cookie_name for type=APP_COOKIE """""" self.assertRaises(ex.BadRequest, self._create_pool, session_persistence={'type': 'APP_COOKIE'}, protocol='HTTP', lb_algorithm='ROUND_ROBIN') @test.attr(type='smoke') def test_update_pool(self): """"""Test update pool"""""" new_pool = self._prepare_and_create_pool() desc = 'testing update with new description' pool = self._update_pool(new_pool.get('id'), description=desc) self.assertEqual(desc, pool.get('description')) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_update_pool_missing_name(self): """"""Test update pool with missing name"""""" new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) name = pool_initial.get('name') pool = self.pools_client.update_pool(new_pool.get('id')) self._wait_for_load_balancer_status(self.load_balancer.get('id')) self.assertEqual(name, pool.get('name')) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_update_pool_missing_description(self): """"""Test update pool with missing description"""""" new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) desc = pool_initial.get('description') pool = self.pools_client.update_pool(new_pool.get('id')) self._wait_for_load_balancer_status(self.load_balancer.get('id')) self.assertEqual(desc, pool.get('description')) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_update_pool_missing_admin_state_up(self): """"""Test update pool with missing admin state up field"""""" new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) admin = pool_initial.get('admin_state_up') pool = self.pools_client.update_pool(new_pool.get('id')) self._wait_for_load_balancer_status(self.load_balancer.get('id')) self.assertEqual(admin, pool.get('admin_state_up')) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_update_pool_missing_session_persistence(self): """"""Test update pool with missing session persistence"""""" new_pool = self._prepare_and_create_pool() pool_initial = self.pools_client.get_pool(new_pool.get('id')) sess_pers = pool_initial.get('session_persistence') pool = self.pools_client.update_pool(new_pool.get('id')) self._wait_for_load_balancer_status(self.load_balancer.get('id')) self.assertAlmostEqual(sess_pers, pool.get('session_persistence')) self._delete_pool(new_pool.get('id')) @test.skip_because(bug=""1434717"") @test.attr(type='negative') def test_update_pool_invalid_name(self): """"""Test update pool with invalid name"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self.pools_client.update_pool, new_pool.get('id'), name='n' * 256) self._delete_pool(new_pool.get('id')) @test.skip_because(bug=""1434717"") @test.attr(type='negative') def test_update_pool_invalid_desc(self): """"""Test update pool with invalid desc"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self.pools_client.update_pool, new_pool.get('id'), description='d' * 256) self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_update_pool_invalid_admin_state_up(self): """"""Test update pool with an invalid admin_state_up"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self.pools_client.update_pool, new_pool.get('id'), admin_state_up='hello') self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_update_pool_invalid_session_persistence(self): """"""Test update pool with an invalid session pers. field"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self.pools_client.update_pool, new_pool.get('id'), session_persistence={'type': 'Hello'}) self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_update_pool_empty_name(self): """"""Test update pool with empty name"""""" new_pool = self._prepare_and_create_pool() pool = self.pools_client.update_pool(new_pool.get('id'), name="""") self._wait_for_load_balancer_status(self.load_balancer.get('id')) self.assertEqual(pool.get('name'), """") self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_update_pool_empty_description(self): """"""Test update pool with empty description"""""" new_pool = self._prepare_and_create_pool() pool = self.pools_client.update_pool(new_pool.get('id'), description="""") self._wait_for_load_balancer_status(self.load_balancer.get('id')) self.assertEqual(pool.get('description'), """") self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_update_pool_empty_admin_state_up(self): """"""Test update pool with empty admin state up"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self.pools_client.update_pool, new_pool.get('id'), admin_state_up="""") self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_update_pool_empty_session_persistence(self): """"""Test update pool with empty session persistence field"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self.pools_client.update_pool, new_pool.get('id'), session_persistence="""") self.pools_client.delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_update_pool_invalid_attribute(self): """"""Test update pool with an invalid attribute"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self._update_pool, new_pool.get('id'), lb_algorithm='ROUNDED') self._delete_pool(new_pool.get('id')) @test.attr(type='negative') def test_update_pool_incorrect_attribute(self): """"""Test update a pool with an extra, incorrect field"""""" new_pool = self._prepare_and_create_pool() self.assertRaises(ex.BadRequest, self._update_pool, new_pool.get('id'), protocol='HTTPS') self._delete_pool(new_pool.get('id')) @test.attr(type='smoke') def test_delete_pool(self): """"""Test delete pool"""""" new_pool = self._prepare_and_create_pool() pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) self._delete_pool(new_pool.get('id')) self.assertRaises(ex.NotFound, self.pools_client.get_pool, new_pool.get('id')) @test.attr(type='smoke') def test_delete_invalid_pool(self): """"""Test delete pool that doesn't exist"""""" new_pool = self._prepare_and_create_pool() pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) self._delete_pool(new_pool.get('id')) self.assertRaises(ex.NotFound, self._delete_pool, new_pool.get('id')) @test.attr(type='negative') def test_delete_pool_with_health_monitor(self): new_pool = self._prepare_and_create_pool() pool = self.pools_client.get_pool(new_pool.get('id')) self.assertEqual(new_pool, pool) new_hm = self._create_health_monitor( type='HTTP', delay=3, max_retries=10, timeout=5, pool_id=new_pool.get('id')) hm = self.health_monitors_client.get_health_monitor(new_hm.get('id')) self.assertEqual(new_hm, hm) self.assertRaises(ex.Conflict, self._delete_pool, new_pool.get('id')) # delete health monitor first self._delete_health_monitor(hm.get('id')) self._delete_pool(new_pool.get('id')) self.assertRaises(ex.NotFound, self.pools_client.get_pool, new_pool.get('id')) ",,620,0
openstack%2Fneutron-lbaas~stable%2Fkilo~I5e34a923aff9fcaf2f2176e0e55275bfb066c153,openstack/neutron-lbaas,stable/kilo,I5e34a923aff9fcaf2f2176e0e55275bfb066c153,Update gitreview host,ABANDONED,2015-06-10 09:59:39.000000000,2015-06-10 10:02:43.000000000,,[{'_account_id': 9531}],"[{'number': 1, 'created': '2015-06-10 09:59:39.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/efcc609274076bf6d561267d2b5e49acc2197ea4', 'message': 'Update gitreview host\n\nUpdate gitreview host\n\nChange-Id: I5e34a923aff9fcaf2f2176e0e55275bfb066c153\n'}]",0,190090,efcc609274076bf6d561267d2b5e49acc2197ea4,2,1,1,12412,,,0,"Update gitreview host

Update gitreview host

Change-Id: I5e34a923aff9fcaf2f2176e0e55275bfb066c153
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/90/190090/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,efcc609274076bf6d561267d2b5e49acc2197ea4,rebase-kilo,host=review.et.letv.comproject=iaas/openstack/neutron-lbaas.git,host=review.openstack.orgproject=openstack/neutron-lbaas.git,2,2
openstack%2Fneutron-lbaas~stable%2Fkilo~I76e819e2a90ddb61756cb7fee52f4284ceab1661,openstack/neutron-lbaas,stable/kilo,I76e819e2a90ddb61756cb7fee52f4284ceab1661,Add vip_address to loadbalancer statuses Json,ABANDONED,2015-06-10 09:59:39.000000000,2015-06-10 10:02:21.000000000,,[{'_account_id': 9531}],"[{'number': 1, 'created': '2015-06-10 09:59:39.000000000', 'files': ['neutron_lbaas/services/loadbalancer/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/a1e5c0ca0dda47349aca3f578df67e786d93ed0e', 'message': 'Add vip_address to loadbalancer statuses Json\n\nAdd vip_address to loadbalancer statuses Json\n\nJira issue: OPENSTACK-337\n\nChange-Id: I76e819e2a90ddb61756cb7fee52f4284ceab1661\n'}]",0,190092,a1e5c0ca0dda47349aca3f578df67e786d93ed0e,2,1,1,12412,,,0,"Add vip_address to loadbalancer statuses Json

Add vip_address to loadbalancer statuses Json

Jira issue: OPENSTACK-337

Change-Id: I76e819e2a90ddb61756cb7fee52f4284ceab1661
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/92/190092/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/services/loadbalancer/plugin.py'],1,a1e5c0ca0dda47349aca3f578df67e786d93ed0e,rebase-kilo," status[""vip_address""] = getattr(obj, 'vip_address')",,1,0
openstack%2Ftempest~master~I0eba11d54b63dc2078e6987789933c1dc4650b71,openstack/tempest,master,I0eba11d54b63dc2078e6987789933c1dc4650b71,Fix several bugs in verify_tempest_config,MERGED,2015-06-02 21:07:16.000000000,2015-06-10 10:02:00.000000000,2015-06-10 10:01:57.000000000,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-02 21:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aa33b23ff33dc95d2989076c6039341f5603eba1', 'message': 'Fix several bugs in verify_tempest_config\n\nThe version of get_versions() in tempest_lib somehow lost the removal\nof the first argument so we need to capture it.\nThe version checking was looking for explicit minor version matches but\nit seems that some services bumped them. This commit fixes the check to\nonly look for a match against the major veresion number.\n\nChange-Id: I0eba11d54b63dc2078e6987789933c1dc4650b71\n'}, {'number': 2, 'created': '2015-06-02 21:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f8b5705e10d0d8a2447251c0d95908d1877627bd', 'message': 'Fix several bugs in verify_tempest_config\n\nThe version of get_versions() in tempest_lib somehow lost the removal\nof the first argument so we need to capture it.\nThe version checking was looking for explicit minor version matches but\nit seems that some services bumped them. This commit fixes the check to\nonly look for a match against the major veresion number.\n\nChange-Id: I0eba11d54b63dc2078e6987789933c1dc4650b71\n'}, {'number': 3, 'created': '2015-06-03 18:28:28.000000000', 'files': ['tempest/tests/cmd/test_verify_tempest_config.py', 'tempest/cmd/verify_tempest_config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0df154d56ea9ac663825a9d6ebb5abcd190d2333', 'message': 'Fix several bugs in verify_tempest_config\n\nThe version of get_versions() in tempest_lib somehow lost the removal\nof the first argument so we need to capture it.\nThe version checking was looking for explicit minor version matches but\nit seems that some services bumped them. This commit fixes the check to\nonly look for a match against the major veresion number.\n\nNote that the unit tests were passing in spite of this bug. It would be better\nif devstack failed when calling this script if there were any changes\nsuggested.\n\nChange-Id: I0eba11d54b63dc2078e6987789933c1dc4650b71\n'}]",0,187777,0df154d56ea9ac663825a9d6ebb5abcd190d2333,12,5,3,1192,,,0,"Fix several bugs in verify_tempest_config

The version of get_versions() in tempest_lib somehow lost the removal
of the first argument so we need to capture it.
The version checking was looking for explicit minor version matches but
it seems that some services bumped them. This commit fixes the check to
only look for a match against the major veresion number.

Note that the unit tests were passing in spite of this bug. It would be better
if devstack failed when calling this script if there were any changes
suggested.

Change-Id: I0eba11d54b63dc2078e6987789933c1dc4650b71
",git fetch https://review.opendev.org/openstack/tempest refs/changes/77/187777/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/verify_tempest_config.py'],1,aa33b23ff33dc95d2989076c6039341f5603eba1,fix-verify,"def contains_version(prefix, versions): return any([x for x in versions if x.startswith(prefix)]) _, versions = os.image_client.get_versions() if CONF.image_feature_enabled.api_v1 != contains_version('v1.', versions): if CONF.image_feature_enabled.api_v2 != contains_version('v2.', versions): if (CONF.identity_feature_enabled.api_v2 != contains_version('v2.', versions)): if (CONF.identity_feature_enabled.api_v3 != contains_version('v3.', versions)): if (CONF.volume_feature_enabled.api_v1 != contains_version('v1.', versions)): if (CONF.volume_feature_enabled.api_v2 != contains_version('v2.', versions)): # For Nova, Cinder and Neutron we use in the alias name rather than the"," versions = os.image_client.get_versions() if CONF.image_feature_enabled.api_v1 != ('v1.1' in versions or 'v1.0' in versions): if CONF.image_feature_enabled.api_v2 != ('v2.0' in versions): if CONF.identity_feature_enabled.api_v2 != ('v2.0' in versions): if CONF.identity_feature_enabled.api_v3 != ('v3.0' in versions): if CONF.volume_feature_enabled.api_v1 != ('v1.0' in versions): if CONF.volume_feature_enabled.api_v2 != ('v2.0' in versions): # For Nova, Cinder and Neutron we use the alias name rather than the",16,9
openstack%2Fneutron-lbaas~stable%2Fkilo~Icb2c890ecfead6ff674ec6026fd184b534a5a8ba,openstack/neutron-lbaas,stable/kilo,Icb2c890ecfead6ff674ec6026fd184b534a5a8ba,Set member subnet id to optional,ABANDONED,2015-06-10 09:59:39.000000000,2015-06-10 10:01:44.000000000,,[{'_account_id': 9531}],"[{'number': 1, 'created': '2015-06-10 09:59:39.000000000', 'files': ['neutron_lbaas/extensions/loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/5143a2d578f721c707de528cf091b368b9ebd44d', 'message': 'Set member subnet id to optional\n\nSet member subnet id to optional\n\nChange-Id: Icb2c890ecfead6ff674ec6026fd184b534a5a8ba\n'}]",0,190093,5143a2d578f721c707de528cf091b368b9ebd44d,2,1,1,12412,,,0,"Set member subnet id to optional

Set member subnet id to optional

Change-Id: Icb2c890ecfead6ff674ec6026fd184b534a5a8ba
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/93/190093/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/extensions/loadbalancerv2.py'],1,5143a2d578f721c707de528cf091b368b9ebd44d,rebase-kilo," 'validate': {'type:uuid_or_none': None}, 'default': None,"," 'validate': {'type:uuid': None},",2,1
openstack%2Fheat~master~I6501395ab458b75ba7d27c8ce9643bd6d18cb203,openstack/heat,master,I6501395ab458b75ba7d27c8ce9643bd6d18cb203,Fix block_device_mapping property validation when using get_attr,MERGED,2015-06-10 03:37:11.000000000,2015-06-10 10:01:27.000000000,2015-06-10 09:14:12.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 9751}, {'_account_id': 12259}]","[{'number': 1, 'created': '2015-06-10 03:37:11.000000000', 'files': ['heat/engine/resources/openstack/nova/server.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4d2b275358cd010c0ba19697d5e623a1edef3daf', 'message': 'Fix block_device_mapping property validation when using get_attr\n\nChange-Id: I6501395ab458b75ba7d27c8ce9643bd6d18cb203\nCloses-Bug: #1463531\n'}]",0,190008,4d2b275358cd010c0ba19697d5e623a1edef3daf,11,5,1,8833,,,0,"Fix block_device_mapping property validation when using get_attr

Change-Id: I6501395ab458b75ba7d27c8ce9643bd6d18cb203
Closes-Bug: #1463531
",git fetch https://review.opendev.org/openstack/heat refs/changes/08/190008/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/nova/server.py', 'heat/tests/test_server.py']",2,4d2b275358cd010c0ba19697d5e623a1edef3daf,bug/1463531," def test_validate_block_device_mapping_with_empty_ref(self): stack_name = 'val_blkdev2' (tmpl, stack) = self._setup_test_stack(stack_name) bdm = [{'device_name': 'vda', 'volume_id': '', 'volume_size': '10'}] wsp = tmpl.t['Resources']['WebServer']['Properties'] wsp['block_device_mapping'] = bdm resource_defns = tmpl.resource_definitions(stack) server = servers.Server('server_create_image_err', resource_defns['WebServer'], stack) self.m.StubOutWithMock(nova.NovaClientPlugin, '_create') self.stub_VolumeConstraint_validate() nova.NovaClientPlugin._create().AndReturn(self.fc) self._mock_get_image_id_success('F17-x86_64-gold', 'image_id') self.m.ReplayAll() self.assertIsNone(server.validate()) self.m.VerifyAll() ",,21,2
openstack%2Fneutron-lbaas~stable%2Fkilo~I4d73031e3a73553acba748941027822d793bfa3a,openstack/neutron-lbaas,stable/kilo,I4d73031e3a73553acba748941027822d793bfa3a,Add acl settings for loadbalancer listener,ABANDONED,2015-06-10 09:59:39.000000000,2015-06-10 10:01:24.000000000,,[{'_account_id': 9531}],"[{'number': 1, 'created': '2015-06-10 09:59:39.000000000', 'files': ['neutron_lbaas/tests/tempest/v2/api/base.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_synchronous_driver.py', 'neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/drivers/common/agent_callbacks.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/tests/tempest/v2/api/test_acls.py', 'neutron_lbaas/agent/agent_device_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_proxies.j2', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py', 'neutron_lbaas/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/data_models.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/3bf7f1a02b6a_add_acl_table.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py', 'neutron_lbaas/tests/tempest/v2/clients/acls_client.py', 'neutron_lbaas/drivers/logging_noop/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py', 'neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/drivers/driver_base.py', 'neutron_lbaas/db/loadbalancer/models.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/drivers/haproxy/synchronous_namespace_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/3b74f8ce91f9c068ecea1fe0fba83aea8021a038', 'message': 'Add acl settings for loadbalancer listener\n\nNow user can set acl for haproxy frontend(lbaas listener).\nRequired params are: name, action, condition,\noperator, match_condition.\n\nOne haproxy frontend acl will show like:\n""""""\nacl name action condition\noperator [match] if [name, [!name]...] match_condition\n""""""\n\nJira blueprint: OPENSTACK-321\n\nChange-Id: I4d73031e3a73553acba748941027822d793bfa3a\n'}]",0,190094,3b74f8ce91f9c068ecea1fe0fba83aea8021a038,2,1,1,12412,,,0,"Add acl settings for loadbalancer listener

Now user can set acl for haproxy frontend(lbaas listener).
Required params are: name, action, condition,
operator, match_condition.

One haproxy frontend acl will show like:
""""""
acl name action condition
operator [match] if [name, [!name]...] match_condition
""""""

Jira blueprint: OPENSTACK-321

Change-Id: I4d73031e3a73553acba748941027822d793bfa3a
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/94/190094/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/tempest/v2/api/base.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_synchronous_driver.py', 'neutron_lbaas/agent/agent_manager.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/drivers/common/agent_callbacks.py', 'neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/agent/test_agent_manager.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/tests/tempest/v2/api/test_acls.py', 'neutron_lbaas/agent/agent_device_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/templates/haproxy_proxies.j2', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/sample_configs/sample_configs.py', 'neutron_lbaas/drivers/common/agent_driver_base.py', 'neutron_lbaas/services/loadbalancer/data_models.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/3bf7f1a02b6a_add_acl_table.py', 'neutron_lbaas/db/migration/alembic_migrations/versions/HEAD', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancerv2.py', 'neutron_lbaas/tests/tempest/v2/clients/acls_client.py', 'neutron_lbaas/drivers/logging_noop/driver.py', 'neutron_lbaas/services/loadbalancer/drivers/haproxy/jinja_cfg.py', 'neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/drivers/driver_base.py', 'neutron_lbaas/db/loadbalancer/models.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/drivers/haproxy/synchronous_namespace_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_jinja_cfg.py']",27,3b74f8ce91f9c068ecea1fe0fba83aea8021a038,rebase-kilo," def test_render_template_frontend_with_acl(self): fe = (""frontend sample_listener_id_1\n"" "" option tcplog\n"" "" maxconn 98\n"" "" bind 10.0.0.2:443\n"" "" mode tcp\n"" "" acl acl_name acl_action acl_condition\n"" "" acl_operator acl_match if acl_match_condition\n"" "" default_backend sample_pool_id_1\n\n"") be = (""backend sample_pool_id_1\n"" "" mode tcp\n"" "" balance roundrobin\n"" "" cookie SRV insert indirect nocache\n"" "" timeout check 31\n"" "" option httpchk GET /index.html\n"" "" http-check expect rstatus 405|404|500\n"" "" option ssl-hello-chk\n"" "" server sample_member_id_1 10.0.0.99:82 "" ""weight 13 check inter 30s fall 3 cookie sample_member_id_1\n"" "" server sample_member_id_2 10.0.0.98:82 "" ""weight 13 check inter 30s fall 3 cookie sample_member_id_2\n\n"") rendered_obj = jinja_cfg.render_loadbalancer_obj( sample_configs.sample_loadbalancer_tuple(proto='HTTPS', acls=True), 'nogroup', '/sock_path', '/v2') self.assertEqual(sample_configs.sample_base_expected_config( frontend=fe, backend=be), rendered_obj) def test_transform_listener_with_acl(self): in_listener = sample_configs.sample_listener_tuple(acls=True) ret = jinja_cfg._transform_listener(in_listener, '/v2') self.assertEqual(sample_configs.RET_LISTENER_ACLS, ret) ",,2174,48
openstack%2Fglance_store~master~I5ec4b8a685e95a701f6e8497695bd672dc22ec5e,openstack/glance_store,master,I5ec4b8a685e95a701f6e8497695bd672dc22ec5e,Port remaining tests to Python 3,MERGED,2015-05-20 19:49:25.000000000,2015-06-10 09:55:11.000000000,2015-06-10 01:02:41.000000000,"[{'_account_id': 3}, {'_account_id': 9107}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-05-20 19:49:25.000000000', 'files': ['tests/unit/test_filesystem_store.py', 'tests/unit/test_gridfs_store.py', 'tests/unit/test_sheepdog_store.py', 'tests/unit/test_rbd_store.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/59703d0511736a03d883124d46b11f104c582534', 'message': 'Port remaining tests to Python 3\n\n* Use bytes to handle image content\n* Replace StringIO.StringIO with six.BytesIO for image content\n\nChange-Id: I5ec4b8a685e95a701f6e8497695bd672dc22ec5e\n'}]",0,184604,59703d0511736a03d883124d46b11f104c582534,15,4,1,9107,,,0,"Port remaining tests to Python 3

* Use bytes to handle image content
* Replace StringIO.StringIO with six.BytesIO for image content

Change-Id: I5ec4b8a685e95a701f6e8497695bd672dc22ec5e
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/04/184604/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_filesystem_store.py', 'tests/unit/test_gridfs_store.py', 'tests/unit/test_sheepdog_store.py', 'tests/unit/test_rbd_store.py']",4,59703d0511736a03d883124d46b11f104c582534,py3,import six self.data_iter = six.BytesIO(b'*' * self.data_len),import StringIO self.data_iter = StringIO.StringIO('*' * self.data_len),45,49
openstack%2Fopenstack-ansible~master~I9ab35cf4438a369563f8c08870c1acfd0cc394b0,openstack/openstack-ansible,master,I9ab35cf4438a369563f8c08870c1acfd0cc394b0,Enable udev for lvm in cinder-volume container,MERGED,2015-06-04 13:39:19.000000000,2015-06-10 09:51:28.000000000,2015-06-10 04:53:20.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7219}, {'_account_id': 7353}, {'_account_id': 9884}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-04 13:39:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3c742a8c39fae4ecedf08409c86d85cf5eb6060e', 'message': ""Enable udev for lvm in cinder-volumes container\n\nThere have been reports of cinder performing operations on the wrong\nvolume. This appears to be due to inconsistencies in the device\nnumbers recorded for the logical volume. The issue is difficult to\nreproduce but appears to be related lvm not using udev.\n\nLVM's use of udev was disabled due to the potential that the host would\nbe saturated with uevents from containers. The cinder-volumes container\nruns on its own host and so this should not be an issue.\n\nThis commit adjusts the lvm.conf file created so that udev is used. It\nalso adds a mount entry to create a devtmpfs on /dev. Finally\n'udevadm trigger' is run to add the devices under /dev/mapper. The\ncontainer creation configuration for cinder-volumes has been broken out\nfrom other cinder containers so that these changes are targeted at the\nrelevant hosts.\n\nCloses-Bug: #1436999\nChange-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0\n""}, {'number': 2, 'created': '2015-06-05 15:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/01a64246cce4ca46ccfef455b6bb8a50ca095fe1', 'message': ""Enable udev for lvm in cinder-volume container\n\nThe current configuration of LVM for cinder-volume has udev_sync=0.\nThis means that udev is not creating the devices that appear in /dev.\nThe device files created reference specific device numbers, and these\npersist between reboots. When the host is rebooted there is no\nguarantee that device numbers allocated to the logical volumes will\nmatch those defined in the device files. This can be observed by\ncomparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.\n\nLVM's use of udev was disabled in an attempt to protect the host from\nthe potential that uevents generated would be processed by all\ncontainers on the host. In practise this should not be an issue because\nthere are not other containers running on a cinder host.\n\nThis commit adjusts the lvm.conf file created so that udev is used. It\nalso adds a mount entry to create a devtmpfs on /dev. Finally\n'udevadm trigger' is run to add the devices under /dev/mapper.\nCloses-Bug: #1436999\nChange-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0\n""}, {'number': 3, 'created': '2015-06-05 21:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/088d74aa3736dc11a3624a1f1c112de44ced3ce5', 'message': ""Enable udev for lvm in cinder-volume container\n\nThe current configuration of LVM for cinder-volume has udev_sync=0.\nThis means that udev is not creating the devices that appear in /dev.\nThe device files created reference specific device numbers, and these\npersist between reboots. When the host is rebooted there is no\nguarantee that device numbers allocated to the logical volumes will\nmatch those defined in the device files. This can be observed by\ncomparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.\n\nLVM's use of udev was disabled in an attempt to protect the host from\nthe potential that uevents generated would be processed by all\ncontainers on the host. In practise this should not be an issue because\nthere are not other containers running on a cinder host.\n\nThis commit adjusts the lvm.conf file created so that udev is used. It\nalso adds a mount entry to create a devtmpfs on /dev. Finally\n'udevadm trigger' is run to add the devices under /dev/mapper.\nCloses-Bug: #1436999\nChange-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0\n""}, {'number': 4, 'created': '2015-06-08 09:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5c106d1136c7e7cc3532ef9cfb7492ed12b05f13', 'message': ""Enable udev for lvm in cinder-volume container\n\nThe current configuration of LVM for cinder-volume has udev_sync=0.\nThis means that udev is not creating the devices that appear in /dev.\nThe device files created reference specific device numbers, and these\npersist between reboots. When the host is rebooted there is no\nguarantee that device numbers allocated to the logical volumes will\nmatch those defined in the device files. This can be observed by\ncomparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.\n\nLVM's use of udev was disabled in an attempt to protect the host from\nthe potential that uevents generated would be processed by all\ncontainers on the host. In practise this should not be an issue because\nthere are not other containers running on a cinder host.\n\nThis commit adjusts the lvm.conf file created so that udev is used. It\nalso adds a mount entry to create a devtmpfs on /dev. Finally\n'udevadm trigger' is run to add the devices under /dev/mapper.\nCloses-Bug: #1436999\nChange-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0\n""}, {'number': 5, 'created': '2015-06-10 01:57:53.000000000', 'files': ['playbooks/os-cinder-install.yml', 'playbooks/roles/os_cinder/templates/lvm.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6ba292a295ab2e7effeefd053802e6afadd0ab9e', 'message': ""Enable udev for lvm in cinder-volume container\n\nThe current configuration of LVM for cinder-volume has udev_sync=0.\nThis means that udev is not creating the devices that appear in /dev.\nThe device files created reference specific device numbers, and these\npersist between reboots. When the host is rebooted there is no\nguarantee that device numbers allocated to the logical volumes will\nmatch those defined in the device files. This can be observed by\ncomparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.\n\nLVM's use of udev was disabled in an attempt to protect the host from\nthe potential that uevents generated would be processed by all\ncontainers on the host. In practise this should not be an issue because\nthere are not other containers running on a cinder host.\n\nThis commit adjusts the lvm.conf file created so that udev is used. It\nalso adds a mount entry to create a devtmpfs on /dev. Finally\n'udevadm trigger' is run to add the devices under /dev/mapper.\nCloses-Bug: #1436999\nChange-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0\n""}]",1,188394,6ba292a295ab2e7effeefd053802e6afadd0ab9e,40,8,5,7219,,,0,"Enable udev for lvm in cinder-volume container

The current configuration of LVM for cinder-volume has udev_sync=0.
This means that udev is not creating the devices that appear in /dev.
The device files created reference specific device numbers, and these
persist between reboots. When the host is rebooted there is no
guarantee that device numbers allocated to the logical volumes will
match those defined in the device files. This can be observed by
comparing the output of 'dmsetup info' and 'ls -l /dev/mapper'.

LVM's use of udev was disabled in an attempt to protect the host from
the potential that uevents generated would be processed by all
containers on the host. In practise this should not be an issue because
there are not other containers running on a cinder host.

This commit adjusts the lvm.conf file created so that udev is used. It
also adds a mount entry to create a devtmpfs on /dev. Finally
'udevadm trigger' is run to add the devices under /dev/mapper.
Closes-Bug: #1436999
Change-Id: I9ab35cf4438a369563f8c08870c1acfd0cc394b0
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/188394/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/os-cinder-install.yml', 'playbooks/roles/os_cinder/templates/lvm.conf.j2']",2,3c742a8c39fae4ecedf08409c86d85cf5eb6060e,udev, obtain_device_list_from_udev = 1 udev_sync = 1 udev_rules = 1,"{% if is_metal == false or is_metal == ""False"" %} {% set use_udev = 0 %} {% else %} {% set use_udev = 1 %} {% endif %} obtain_device_list_from_udev = {{ use_udev }} udev_sync = {{ use_udev }} udev_rules = {{ use_udev }}",58,12
openstack%2Fneutron~master~I4be63de2b115e16d54f73fb2cf4203244ad63d70,openstack/neutron,master,I4be63de2b115e16d54f73fb2cf4203244ad63d70,(WIP/DONT REVIEW/IM NOT HERE) ovs-fw-testing,ABANDONED,2015-05-27 10:27:34.000000000,2015-06-10 09:33:47.000000000,,"[{'_account_id': 3}, {'_account_id': 8124}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-05-27 10:27:34.000000000', 'files': ['neutron/tests/common/machine_fixtures.py', 'neutron/tests/functional/agent/linux/test_iptables_firewall.py', 'neutron/agent/linux/openvswitch_firewall.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/common/conn_testers.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/functional/agent/linux/test_iptables.py', 'neutron/tests/functional/agent/linux/helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f241ecc7a34699e2ff5b51893ead35c69581a5c6', 'message': '(WIP/DONT REVIEW/IM NOT HERE) ovs-fw-testing\n\nThis serves just a place for share and backup.\n\nChange-Id: I4be63de2b115e16d54f73fb2cf4203244ad63d70\n'}]",29,185920,f241ecc7a34699e2ff5b51893ead35c69581a5c6,33,23,1,8655,,,0,"(WIP/DONT REVIEW/IM NOT HERE) ovs-fw-testing

This serves just a place for share and backup.

Change-Id: I4be63de2b115e16d54f73fb2cf4203244ad63d70
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/185920/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/common/machine_fixtures.py', 'neutron/tests/functional/agent/linux/test_iptables_firewall.py', 'neutron/agent/linux/openvswitch_firewall.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/common/conn_testers.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/functional/agent/linux/test_iptables.py', 'neutron/tests/functional/agent/linux/helpers.py']",8,f241ecc7a34699e2ff5b51893ead35c69581a5c6,ovs-fw-testing," port, client_address=None, run_as_root=True, udp=False): self.client_namespace = ip_lib.IPWrapper(namespace=client_namespace) self.server_namespace = ip_lib.IPWrapper(namespace=server_namespace) self.establish_connection() @property def protocol(self): return 'udp' if self.udp else 'tcp' def establish_connection(self): if self._client_process: raise RuntimeError('%(proto)s connection to $(ip_addr)s is already' ' established' % {'proto': self.protocol, 'ip_addr': self.server_address}) if not self._server_process: self._spawn_server_process() self._client_process = self._spawn_nc_in_namespace( self.client_namespace, address=self.client_address) if self.udp: # Create an entry in conntrack table for UDP packets self.client_process.writeline(self.TESTING_STRING) "," port, client_address=None, run_as_root=False, udp=False): self.client_namespace = client_namespace self.server_namespace = server_namespace if not self._server_process: self._spawn_server_process() self._client_process = self._spawn_nc_in_namespace( self.client_namespace, address=self.client_address)",360,62
openstack%2Frally~master~Ic2dc13b84be107cd8c6add28a22835c448f1b71f,openstack/rally,master,Ic2dc13b84be107cd8c6add28a22835c448f1b71f,Add validator to check parameter inside a dictionary argument,MERGED,2015-06-04 10:51:04.000000000,2015-06-10 09:28:20.000000000,2015-06-10 09:28:19.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 8576}, {'_account_id': 8851}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}, {'_account_id': 14884}]","[{'number': 1, 'created': '2015-06-04 10:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f963423f8de7f98a5c63a882441bf4ee016e9a63', 'message': 'Check parameter inside a dictionary argument is set\n\nCurrently checking paramter in args i.e.\n{""args"": ""parameter""} is supported but checking\na parameter inside a dictionary in args\nis unsupported i.e. {""args"": {""dict"": ""parameter""}.\n\nChange-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f\n'}, {'number': 2, 'created': '2015-06-09 05:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9d0491ab0e26fddb22f46168ee8d0264460210c2', 'message': 'Add validator to check parameter inside a dictionary argument\n\nCurrently the validator checks parameter inside args i.e.\n{""args"": ""parameter""} but if the parameter is inside a\nspecific_args i.e. {""args"": {""specific_args"": ""parameter""}\nit fails to validate.\nThis is needed in scenarios like loadbalancer where the\nparameter ""subnet_id"" could be specified in ""pool_create_args""\n\nChange-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f\n'}, {'number': 3, 'created': '2015-06-09 05:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f7587cb5f961f22f4df0d528b6f78847935916c0', 'message': 'Add validator to check parameter inside a dictionary argument\n\nCurrently the validator checks parameter inside args i.e.\n{""args"": ""parameter""} but if the parameter is inside a\nspecific_args i.e. {""args"": {""specific_args"": ""parameter""}\nit fails to validate.\nThis is needed in scenarios like loadbalancer where the\nparameter ""subnet_id"" could be specified in ""pool_create_args""\n\nChange-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f\n'}, {'number': 4, 'created': '2015-06-09 05:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/daff53b88392d705e4c8faa31353c9089a8a6a60', 'message': 'Add validator to check parameter inside a dictionary argument\n\nCurrently the validator checks parameter inside args i.e.\n{""args"": ""parameter""} but if the parameter is inside a\nspecific_args i.e. {""args"": {""specific_args"": ""parameter""}\nit fails to validate.\nThis is needed in scenarios like loadbalancer where the\nparameter ""subnet_id"" could be specified in ""pool_create_args""\n\nChange-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f\n'}, {'number': 5, 'created': '2015-06-09 06:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6652dc6aa259c56f8e91359dae60a4c4ad36f57c', 'message': 'Add validator to check parameter inside a dictionary argument\n\nCurrently the validator checks parameter inside args i.e.\n{""args"": ""parameter""} but if the parameter is inside a\nspecific_args i.e. {""args"": {""specific_args"": ""parameter""}\nit fails to validate.\nThis is needed in scenarios like loadbalancer where the\nparameter ""subnet_id"" could be specified in ""pool_create_args""\n\nChange-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f\n'}, {'number': 6, 'created': '2015-06-09 14:45:50.000000000', 'files': ['rally/benchmark/validation.py', 'tests/unit/benchmark/test_validation.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b0a403b9a44be3499602d016538faad0af09ecba', 'message': 'Add validator to check parameter inside a dictionary argument\n\nCurrently the validator checks parameter inside args i.e.\n{""args"": ""parameter""} but if the parameter is inside a\nspecific_args i.e. {""args"": {""specific_args"": ""parameter""}\nit fails to validate.\nThis is needed in scenarios like loadbalancer where the\nparameter ""subnet_id"" could be specified in ""pool_create_args""\n\nChange-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f\n'}]",16,188334,b0a403b9a44be3499602d016538faad0af09ecba,31,12,6,14884,,,0,"Add validator to check parameter inside a dictionary argument

Currently the validator checks parameter inside args i.e.
{""args"": ""parameter""} but if the parameter is inside a
specific_args i.e. {""args"": {""specific_args"": ""parameter""}
it fails to validate.
This is needed in scenarios like loadbalancer where the
parameter ""subnet_id"" could be specified in ""pool_create_args""

Change-Id: Ic2dc13b84be107cd8c6add28a22835c448f1b71f
",git fetch https://review.opendev.org/openstack/rally refs/changes/34/188334/6 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/validation.py', 'tests/unit/benchmark/test_validation.py']",2,f963423f8de7f98a5c63a882441bf4ee016e9a63,validator," def test_restricted_parameters_in_dict(self): validator = self._unwrap_validator( validation.restricted_parameters, ""param_name"", ""dict_name"") result = validator({""args"": {""dict_name"": {}}}, None, None) self.assertTrue(result.is_valid, result.msg)",,16,4
openstack%2Ffuel-library~master~I49a0a1cdd15af6ee9098254d2b13aabb38499a0a,openstack/fuel-library,master,I49a0a1cdd15af6ee9098254d2b13aabb38499a0a,Merge puppetlabs/stdlib 4.6.0,ABANDONED,2015-06-08 12:33:06.000000000,2015-06-10 09:27:32.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-06-08 12:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1ad59600f2833a4b91372b9d62a48c9b7ff9b812', 'message': 'Merge puppetlabs/stdlib 4.6.0\n\nCommit: 73474b00b5ae3cbccec6cd0711311d6450139e51\nSource: https://github.com/puppetlabs/puppetlabs-stdlib.git\n\nRelated blueprint merge-openstack-puppet-modules\n\nChange-Id: I49a0a1cdd15af6ee9098254d2b13aabb38499a0a\n'}, {'number': 2, 'created': '2015-06-09 06:31:33.000000000', 'files': ['deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2003-i386.yml', 'deployment/puppet/stdlib/spec/functions/validate_numeric_spec.rb', 'deployment/puppet/stdlib/spec/functions/concat_spec.rb', 'deployment/puppet/stdlib/spec/functions/floor_spec.rb', 'deployment/puppet/stdlib/spec/functions/str2bool_spec.rb', 'deployment/puppet/stdlib/spec/functions/hash_spec.rb', 'deployment/puppet/stdlib/spec/functions/member_spec.rb', 'deployment/puppet/stdlib/spec/unit/facter/facter_dot_d_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/ensure_packages_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_domain_name_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_numeric_spec.rb', 'deployment/puppet/stdlib/spec/functions/shuffle_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/has_ip_address_spec.rb', 'deployment/puppet/stdlib/spec/functions/delete_undef_values_spec.rb', 'deployment/puppet/stdlib/lib/facter/facter_dot_d.rb', 'deployment/puppet/stdlib/spec/functions/strftime_spec.rb', 'deployment/puppet/stdlib/spec/unit/facter/root_home_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_key_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/parser/functions/basename_spec.rb', 'deployment/puppet/stdlib/spec/functions/type_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/validate_cmd_spec.rb', 'deployment/puppet/stdlib/spec/functions/rstrip_spec.rb', 'deployment/puppet/stdlib/spec/functions/pick_default_spec.rb', 'deployment/puppet/stdlib/spec/functions/suffix_spec.rb', 'deployment/puppet/stdlib/lib/puppet/provider/file_line/ruby.rb', 'deployment/puppet/stdlib/spec/functions/validate_cmd_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/fqdn_rotate.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/type3x.rb', 'deployment/puppet/stdlib/spec/acceptance/merge_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/chop.rb', 'deployment/puppet/stdlib/spec/functions/validate_slength_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_cmd.rb', 'deployment/puppet/stdlib/metadata.json', 'deployment/puppet/stdlib/lib/puppet/parser/functions/fqdn_rand_string.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/is_domain_name.rb', 'deployment/puppet/stdlib/spec/functions/get_module_path_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_interface_with_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_ip_network_spec.rb', 'deployment/puppet/stdlib/CONTRIBUTING.md', 'deployment/puppet/stdlib/lib/puppet/parser/functions/bool2str.rb', 'deployment/puppet/stdlib/spec/functions/downcase_spec.rb', 'deployment/puppet/stdlib/spec/functions/keys_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/to_bytes.rb', 'deployment/puppet/stdlib/spec/functions/flatten_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/ensure_resource_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/functions/type_of_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_float_spec.rb', 'deployment/puppet/stdlib/spec/functions/validate_absolute_path_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/uriescape.rb', 'deployment/puppet/stdlib/spec/functions/is_mac_address_spec.rb', 'deployment/puppet/stdlib/spec/unit/facter/util/puppet_settings_spec.rb', 'deployment/puppet/stdlib/spec/functions/max_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/values_at.rb', 'deployment/puppet/stdlib/spec/unit/facter/pe_version_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/concat.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/downcase.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/shuffle.rb', 'deployment/puppet/stdlib/spec/functions/str2saltedsha512_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/chop_spec.rb', 'deployment/puppet/stdlib/spec/functions/values_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/getvar.rb', 'deployment/puppet/stdlib/spec/functions/strip_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/pw_hash.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/ubuntu-server-1404-x64.yml', 'deployment/puppet/stdlib/spec/acceptance/nodesets/centos-59-x64.yml', 'deployment/puppet/stdlib/Modulefile', 'deployment/puppet/stdlib/spec/functions/getparam_spec.rb', 'deployment/puppet/stdlib/spec/functions/delete_values_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/validate_augeas_spec.rb', 'deployment/puppet/stdlib/spec/functions/fqdn_rotate_spec.rb', 'deployment/puppet/stdlib/spec/functions/merge_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/prefix.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_string.rb', 'deployment/puppet/stdlib/spec/functions/uriescape_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/delete.rb', 'deployment/puppet/stdlib/.travis.yml', 'deployment/puppet/stdlib/lib/puppet/parser/functions/strip.rb', 'deployment/puppet/stdlib/spec/functions/difference_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/parser/functions/camelcase_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/zip_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2012r2-x86_64.yml', 'deployment/puppet/stdlib/spec/unit/puppet/type/file_line_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/parser/functions/bool2str_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/chomp.rb', 'deployment/puppet/stdlib/spec/acceptance/any2array_spec.rb', 'deployment/puppet/stdlib/spec/functions/to_bytes_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/reverse.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_numeric.rb', 'deployment/puppet/stdlib/spec/functions/pw_hash_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/type/anchor_spec.rb', 'deployment/puppet/stdlib/Gemfile', 'deployment/puppet/stdlib/lib/puppet/functions/type_of.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/ensure_resource.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/private.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/member.rb', 'deployment/puppet/stdlib/spec/functions/bool2num_spec.rb', 'deployment/puppet/stdlib/spec/functions/type3x_spec.rb', 'deployment/puppet/stdlib/spec/functions/swapcase_spec.rb', 'deployment/puppet/stdlib/spec/functions/grep_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/values_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/range.rb', 'deployment/puppet/stdlib/spec/functions/range_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/capitalize.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2008-x86_64.yml', 'deployment/puppet/stdlib/spec/functions/min_spec.rb', 'deployment/puppet/stdlib/spec/functions/chomp_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/getparam_spec.rb', 'deployment/puppet/stdlib/spec/functions/defined_with_params_spec.rb', 'deployment/puppet/stdlib/spec/functions/values_at_spec.rb', 'deployment/puppet/stdlib/spec/functions/zip_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/basename.rb', 'deployment/puppet/stdlib/spec/functions/time_spec.rb', 'deployment/puppet/stdlib/spec/functions/parseyaml_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/zip.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/swapcase.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/type.rb', 'deployment/puppet/stdlib/.gitignore', 'deployment/puppet/stdlib/spec/functions/count_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/stdlib/spec/acceptance/concat_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/ceiling.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/lstrip.rb', 'deployment/puppet/stdlib/spec/functions/delete_at_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_string_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/bool2num_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/loadyaml_spec.rb', 'deployment/puppet/stdlib/spec/functions/reject_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_absolute_path.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/assert_private.rb', 'deployment/puppet/stdlib/spec/functions/size_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/count_spec.rb', 'deployment/puppet/stdlib/spec/functions/validate_integer_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_integer_spec.rb', 'deployment/puppet/stdlib/spec/functions/unique_spec.rb', 'deployment/puppet/stdlib/spec/functions/prefix_spec.rb', 'deployment/puppet/stdlib/spec/functions/union_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/member_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/has_ip_network_spec.rb', 'deployment/puppet/stdlib/spec/spec_helper.rb', 'deployment/puppet/stdlib/spec/functions/delete_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_integer.rb', 'deployment/puppet/stdlib/.sync.yml', 'deployment/puppet/stdlib/spec/functions/pick_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/fqdn_rotate_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/bool2num.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/empty.rb', 'deployment/puppet/stdlib/spec/functions/deep_merge_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/pw_hash_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/parseyaml_spec.rb', 'deployment/puppet/stdlib/spec/functions/reverse_spec.rb', 'deployment/puppet/stdlib/spec/functions/upcase_spec.rb', 'deployment/puppet/stdlib/spec/functions/intersection_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/rstrip.rb', 'deployment/puppet/stdlib/spec/functions/empty_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/has_interface_with.rb', 'deployment/puppet/stdlib/spec/functions/capitalize_spec.rb', 'deployment/puppet/stdlib/spec/functions/base64_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/ceiling_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/abs_spec.rb', 'deployment/puppet/stdlib/spec/functions/fqdn_rand_string_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/dirname.rb', 'deployment/puppet/stdlib/spec/acceptance/has_interface_with_spec.rb', 'deployment/puppet/stdlib/spec/functions/getvar_spec.rb', 'deployment/puppet/stdlib/README.markdown', 'deployment/puppet/stdlib/lib/puppet/parser/functions/upcase.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/camelcase.rb', 'deployment/puppet/stdlib/spec/functions/is_function_available.rb', 'deployment/puppet/stdlib/spec/acceptance/get_module_path_spec.rb', 'deployment/puppet/stdlib/spec/functions/join_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_ip_address_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_augeas.rb', 'deployment/puppet/stdlib/spec/functions/loadyaml_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2003-x86_64.yml', 'deployment/puppet/stdlib/spec/unit/puppet/provider/file_line/ruby_spec.rb', 'deployment/puppet/stdlib/spec/functions/lstrip_spec.rb', 'deployment/puppet/stdlib/.fixtures.yml', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2012-x86_64.yml', 'deployment/puppet/stdlib/spec/functions/abs_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_array_spec.rb', 'deployment/puppet/stdlib/spec/functions/chop_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_bool_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/shuffle_spec.rb', 'deployment/puppet/stdlib/spec/functions/validate_augeas_spec.rb', 'deployment/puppet/stdlib/spec/functions/num2bool_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/fqdn_rand_string_spec.rb', 'deployment/puppet/stdlib/spec/functions/dirname_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2008r2-x86_64.yml', 'deployment/puppet/stdlib/spec/functions/ceiling_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_hash_spec.rb', 'deployment/puppet/stdlib/lib/puppet/type/file_line.rb', 'deployment/puppet/stdlib/spec/functions/assert_private_spec.rb', 'deployment/puppet/stdlib/spec/functions/any2array_spec.rb', 'deployment/puppet/stdlib/CHANGELOG.md', 'deployment/puppet/stdlib/lib/puppet/parser/functions/unique.rb', 'deployment/puppet/stdlib/spec/functions/parsejson_spec.rb', 'deployment/puppet/stdlib/spec/spec_helper_acceptance.rb', 'deployment/puppet/stdlib/spec/functions/join_keys_to_values_spec.rb', 'deployment/puppet/stdlib/spec/functions/sort_spec.rb', 'deployment/puppet/stdlib/spec/functions/private_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/type_spec.rb', 'deployment/puppet/stdlib/spec/functions/squeeze_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_ip_address_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8fbd2614a42e09837bfa8e583e74939719a65813', 'message': 'Merge puppetlabs/stdlib 4.6.0\n\nCommit: 73474b00b5ae3cbccec6cd0711311d6450139e51\nSource: https://github.com/puppetlabs/puppetlabs-stdlib.git\n\nRelated blueprint merge-openstack-puppet-modules\n\nChange-Id: I49a0a1cdd15af6ee9098254d2b13aabb38499a0a\n'}]",0,189281,8fbd2614a42e09837bfa8e583e74939719a65813,37,14,2,13948,,,0,"Merge puppetlabs/stdlib 4.6.0

Commit: 73474b00b5ae3cbccec6cd0711311d6450139e51
Source: https://github.com/puppetlabs/puppetlabs-stdlib.git

Related blueprint merge-openstack-puppet-modules

Change-Id: I49a0a1cdd15af6ee9098254d2b13aabb38499a0a
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/81/189281/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2003-i386.yml', 'deployment/puppet/stdlib/spec/functions/validate_numeric_spec.rb', 'deployment/puppet/stdlib/spec/functions/concat_spec.rb', 'deployment/puppet/stdlib/spec/functions/floor_spec.rb', 'deployment/puppet/stdlib/spec/functions/str2bool_spec.rb', 'deployment/puppet/stdlib/spec/functions/hash_spec.rb', 'deployment/puppet/stdlib/spec/functions/member_spec.rb', 'deployment/puppet/stdlib/spec/unit/facter/facter_dot_d_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/ensure_packages_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_domain_name_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_numeric_spec.rb', 'deployment/puppet/stdlib/spec/functions/shuffle_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/has_ip_address_spec.rb', 'deployment/puppet/stdlib/spec/functions/delete_undef_values_spec.rb', 'deployment/puppet/stdlib/lib/facter/facter_dot_d.rb', 'deployment/puppet/stdlib/spec/functions/strftime_spec.rb', 'deployment/puppet/stdlib/spec/unit/facter/root_home_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_key_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/parser/functions/basename_spec.rb', 'deployment/puppet/stdlib/spec/functions/type_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/validate_cmd_spec.rb', 'deployment/puppet/stdlib/spec/functions/rstrip_spec.rb', 'deployment/puppet/stdlib/spec/functions/pick_default_spec.rb', 'deployment/puppet/stdlib/spec/functions/suffix_spec.rb', 'deployment/puppet/stdlib/lib/puppet/provider/file_line/ruby.rb', 'deployment/puppet/stdlib/spec/functions/validate_cmd_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/fqdn_rotate.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/type3x.rb', 'deployment/puppet/stdlib/spec/acceptance/merge_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/chop.rb', 'deployment/puppet/stdlib/spec/functions/validate_slength_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_cmd.rb', 'deployment/puppet/stdlib/metadata.json', 'deployment/puppet/stdlib/lib/puppet/parser/functions/fqdn_rand_string.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/is_domain_name.rb', 'deployment/puppet/stdlib/spec/functions/get_module_path_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_interface_with_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_ip_network_spec.rb', 'deployment/puppet/stdlib/CONTRIBUTING.md', 'deployment/puppet/stdlib/lib/puppet/parser/functions/bool2str.rb', 'deployment/puppet/stdlib/spec/functions/downcase_spec.rb', 'deployment/puppet/stdlib/spec/functions/keys_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/to_bytes.rb', 'deployment/puppet/stdlib/spec/functions/flatten_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/ensure_resource_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/functions/type_of_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_float_spec.rb', 'deployment/puppet/stdlib/spec/functions/validate_absolute_path_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/uriescape.rb', 'deployment/puppet/stdlib/spec/functions/is_mac_address_spec.rb', 'deployment/puppet/stdlib/spec/unit/facter/util/puppet_settings_spec.rb', 'deployment/puppet/stdlib/spec/functions/max_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/values_at.rb', 'deployment/puppet/stdlib/spec/unit/facter/pe_version_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/concat.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/downcase.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/shuffle.rb', 'deployment/puppet/stdlib/spec/functions/str2saltedsha512_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/chop_spec.rb', 'deployment/puppet/stdlib/spec/functions/values_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/getvar.rb', 'deployment/puppet/stdlib/spec/functions/strip_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/pw_hash.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/ubuntu-server-1404-x64.yml', 'deployment/puppet/stdlib/spec/acceptance/nodesets/centos-59-x64.yml', 'deployment/puppet/stdlib/Modulefile', 'deployment/puppet/stdlib/spec/functions/getparam_spec.rb', 'deployment/puppet/stdlib/spec/functions/delete_values_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/validate_augeas_spec.rb', 'deployment/puppet/stdlib/spec/functions/fqdn_rotate_spec.rb', 'deployment/puppet/stdlib/spec/functions/merge_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/prefix.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_string.rb', 'deployment/puppet/stdlib/spec/functions/uriescape_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/delete.rb', 'deployment/puppet/stdlib/.travis.yml', 'deployment/puppet/stdlib/lib/puppet/parser/functions/strip.rb', 'deployment/puppet/stdlib/spec/functions/difference_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/parser/functions/camelcase_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/zip_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2012r2-x86_64.yml', 'deployment/puppet/stdlib/spec/unit/puppet/type/file_line_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/parser/functions/bool2str_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/chomp.rb', 'deployment/puppet/stdlib/spec/acceptance/any2array_spec.rb', 'deployment/puppet/stdlib/spec/functions/to_bytes_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/reverse.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_numeric.rb', 'deployment/puppet/stdlib/spec/functions/pw_hash_spec.rb', 'deployment/puppet/stdlib/spec/unit/puppet/type/anchor_spec.rb', 'deployment/puppet/stdlib/Gemfile', 'deployment/puppet/stdlib/lib/puppet/functions/type_of.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/ensure_resource.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/private.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/member.rb', 'deployment/puppet/stdlib/spec/functions/bool2num_spec.rb', 'deployment/puppet/stdlib/spec/functions/type3x_spec.rb', 'deployment/puppet/stdlib/spec/functions/swapcase_spec.rb', 'deployment/puppet/stdlib/spec/functions/grep_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/values_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/range.rb', 'deployment/puppet/stdlib/spec/functions/range_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/capitalize.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2008-x86_64.yml', 'deployment/puppet/stdlib/spec/functions/min_spec.rb', 'deployment/puppet/stdlib/spec/functions/chomp_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/getparam_spec.rb', 'deployment/puppet/stdlib/spec/functions/defined_with_params_spec.rb', 'deployment/puppet/stdlib/spec/functions/values_at_spec.rb', 'deployment/puppet/stdlib/spec/functions/zip_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/basename.rb', 'deployment/puppet/stdlib/spec/functions/time_spec.rb', 'deployment/puppet/stdlib/spec/functions/parseyaml_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/zip.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/swapcase.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/type.rb', 'deployment/puppet/stdlib/.gitignore', 'deployment/puppet/stdlib/spec/functions/count_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/stdlib/spec/acceptance/concat_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/ceiling.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/lstrip.rb', 'deployment/puppet/stdlib/spec/functions/delete_at_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_string_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/bool2num_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/loadyaml_spec.rb', 'deployment/puppet/stdlib/spec/functions/reject_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_absolute_path.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/assert_private.rb', 'deployment/puppet/stdlib/spec/functions/size_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/count_spec.rb', 'deployment/puppet/stdlib/spec/functions/validate_integer_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_integer_spec.rb', 'deployment/puppet/stdlib/spec/functions/unique_spec.rb', 'deployment/puppet/stdlib/spec/functions/prefix_spec.rb', 'deployment/puppet/stdlib/spec/functions/union_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/member_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/has_ip_network_spec.rb', 'deployment/puppet/stdlib/spec/spec_helper.rb', 'deployment/puppet/stdlib/spec/functions/delete_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_integer.rb', 'deployment/puppet/stdlib/.sync.yml', 'deployment/puppet/stdlib/spec/functions/pick_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/fqdn_rotate_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/bool2num.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/empty.rb', 'deployment/puppet/stdlib/spec/functions/deep_merge_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/pw_hash_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/parseyaml_spec.rb', 'deployment/puppet/stdlib/spec/functions/reverse_spec.rb', 'deployment/puppet/stdlib/spec/functions/upcase_spec.rb', 'deployment/puppet/stdlib/spec/functions/intersection_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/rstrip.rb', 'deployment/puppet/stdlib/spec/functions/empty_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/has_interface_with.rb', 'deployment/puppet/stdlib/spec/functions/capitalize_spec.rb', 'deployment/puppet/stdlib/spec/functions/base64_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/ceiling_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/abs_spec.rb', 'deployment/puppet/stdlib/spec/functions/fqdn_rand_string_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/dirname.rb', 'deployment/puppet/stdlib/spec/acceptance/has_interface_with_spec.rb', 'deployment/puppet/stdlib/spec/functions/getvar_spec.rb', 'deployment/puppet/stdlib/README.markdown', 'deployment/puppet/stdlib/lib/puppet/parser/functions/upcase.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/camelcase.rb', 'deployment/puppet/stdlib/spec/functions/is_function_available.rb', 'deployment/puppet/stdlib/spec/acceptance/get_module_path_spec.rb', 'deployment/puppet/stdlib/spec/functions/join_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_ip_address_spec.rb', 'deployment/puppet/stdlib/lib/puppet/parser/functions/validate_augeas.rb', 'deployment/puppet/stdlib/spec/functions/loadyaml_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2003-x86_64.yml', 'deployment/puppet/stdlib/spec/unit/puppet/provider/file_line/ruby_spec.rb', 'deployment/puppet/stdlib/spec/functions/lstrip_spec.rb', 'deployment/puppet/stdlib/.fixtures.yml', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2012-x86_64.yml', 'deployment/puppet/stdlib/spec/functions/abs_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_array_spec.rb', 'deployment/puppet/stdlib/spec/functions/chop_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_bool_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/shuffle_spec.rb', 'deployment/puppet/stdlib/spec/functions/validate_augeas_spec.rb', 'deployment/puppet/stdlib/spec/functions/num2bool_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/fqdn_rand_string_spec.rb', 'deployment/puppet/stdlib/spec/functions/dirname_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/nodesets/windows-2008r2-x86_64.yml', 'deployment/puppet/stdlib/spec/functions/ceiling_spec.rb', 'deployment/puppet/stdlib/spec/functions/is_hash_spec.rb', 'deployment/puppet/stdlib/lib/puppet/type/file_line.rb', 'deployment/puppet/stdlib/spec/functions/assert_private_spec.rb', 'deployment/puppet/stdlib/spec/functions/any2array_spec.rb', 'deployment/puppet/stdlib/CHANGELOG.md', 'deployment/puppet/stdlib/lib/puppet/parser/functions/unique.rb', 'deployment/puppet/stdlib/spec/functions/parsejson_spec.rb', 'deployment/puppet/stdlib/spec/spec_helper_acceptance.rb', 'deployment/puppet/stdlib/spec/functions/join_keys_to_values_spec.rb', 'deployment/puppet/stdlib/spec/functions/sort_spec.rb', 'deployment/puppet/stdlib/spec/functions/private_spec.rb', 'deployment/puppet/stdlib/spec/acceptance/type_spec.rb', 'deployment/puppet/stdlib/spec/functions/squeeze_spec.rb', 'deployment/puppet/stdlib/spec/functions/has_ip_address_spec.rb']",202,1ad59600f2833a4b91372b9d62a48c9b7ff9b812,bp/merge-openstack-puppet-modules, expect(subject.call(['10.0.2.15'])).to be_truthy expect(subject.call(['127.0.0.1'])).to be_truthy expect(subject.call(['192.1681.1.1'])).to be_falsey expect(subject.call(['mspiggy'])).to be_falsey, subject.call(['10.0.2.15']).should be_true subject.call(['127.0.0.1']).should be_true subject.call(['192.1681.1.1']).should be_false subject.call(['mspiggy']).should be_false,4515,1986
openstack%2Fneutron~master~Iaa1a1e500facab50d8bcdffda39ccad3f2e4e9bb,openstack/neutron,master,Iaa1a1e500facab50d8bcdffda39ccad3f2e4e9bb,Python 3: use next() instead of iterator.next(),MERGED,2015-06-09 13:07:49.000000000,2015-06-10 09:13:57.000000000,2015-06-10 09:13:55.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 8122}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9107}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12561}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-09 13:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0509a64da4981e78aebe90bb97cfab0704dd0a2d', 'message': 'Python 3: use next() instead of iterator.next()\n\nThe latter only works in Python 2.\n\nChange-Id: Iaa1a1e500facab50d8bcdffda39ccad3f2e4e9bb\nBlueprint: neutron-python3\n'}, {'number': 2, 'created': '2015-06-09 14:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/986bff04ebc30dba336f61610af47556b69cdd26', 'message': 'Python 3: use next() instead of iterator.next()\n\nThe latter only works in Python 2.\n\nAlso define a __next__ method in the classes that define a next method.\n\nChange-Id: Iaa1a1e500facab50d8bcdffda39ccad3f2e4e9bb\nBlueprint: neutron-python3\n'}, {'number': 3, 'created': '2015-06-09 18:26:52.000000000', 'files': ['neutron/agent/linux/ip_lib.py', 'neutron/db/model_base.py', 'neutron/ipam/subnet_alloc.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'tox.ini', 'neutron/tests/tempest/common/glance_http.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/303f37f4e0c84f90e40b95731a828fc6ce8a0bbf', 'message': 'Python 3: use next() instead of iterator.next()\n\nThe latter only works in Python 2.\n\nAlso define a __next__ method in the classes that define a next method.\n\nChange-Id: Iaa1a1e500facab50d8bcdffda39ccad3f2e4e9bb\nBlueprint: neutron-python3\n'}]",7,189703,303f37f4e0c84f90e40b95731a828fc6ce8a0bbf,77,35,3,8122,,,0,"Python 3: use next() instead of iterator.next()

The latter only works in Python 2.

Also define a __next__ method in the classes that define a next method.

Change-Id: Iaa1a1e500facab50d8bcdffda39ccad3f2e4e9bb
Blueprint: neutron-python3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/189703/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ip_lib.py', 'neutron/ipam/subnet_alloc.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'tox.ini']",5,0509a64da4981e78aebe90bb97cfab0704dd0a2d,bp/neutron-python3, neutron.tests.unit.plugins.ml2.drivers.test_type_vxlan \ neutron.tests.unit.plugins.ml2.drivers.test_type_gre \ neutron.tests.unit.agent.linux.test_ip_lib \ neutron.tests.unit.ipam.test_subnet_alloc \,,13,9
openstack%2Fhorizon~master~Id96c6d416bc4fab2944c8431bbb147f9db5469d9,openstack/horizon,master,Id96c6d416bc4fab2944c8431bbb147f9db5469d9,Refactor of BaseTestCase,ABANDONED,2015-06-10 09:00:55.000000000,2015-06-10 09:01:16.000000000,,[],"[{'number': 1, 'created': '2015-06-10 09:00:55.000000000', 'files': ['openstack_dashboard/test/integration_tests/helpers.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b9bdfdff18bbcca2c03f1e97c974ca9e0d51cf1e', 'message': ""Refactor of BaseTestCase\n\nTo run integratin tests, there needs to be set environment variable\nINTEGRATION_TESTS. In past, positive behaviour was enclosed in one big\n'if' branch.\nI've moved negative behaviour to beginning and len rest of method as\nordinary function body.\n\nChange-Id: Id96c6d416bc4fab2944c8431bbb147f9db5469d9\n""}]",0,190076,b9bdfdff18bbcca2c03f1e97c974ca9e0d51cf1e,2,0,1,6890,,,0,"Refactor of BaseTestCase

To run integratin tests, there needs to be set environment variable
INTEGRATION_TESTS. In past, positive behaviour was enclosed in one big
'if' branch.
I've moved negative behaviour to beginning and len rest of method as
ordinary function body.

Change-Id: Id96c6d416bc4fab2944c8431bbb147f9db5469d9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/190076/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/helpers.py'],1,b9bdfdff18bbcca2c03f1e97c974ca9e0d51cf1e,bp/selenium-integration-testing," env_int_test_flag = os.environ.get('INTEGRATION_TESTS', False) if not env_int_test_flag: # Start a virtual display server for running the tests headless. if os.environ.get('SELENIUM_HEADLESS', False): self.vdisplay = xvfbwrapper.Xvfb(width=1280, height=720) # workaround for memory leak in Xvfb taken from: http://blog. # jeffterrace.com/2012/07/xvfb-memory-leak-workaround.html self.vdisplay.xvfb_cmd.append(""-noreset"") # disables X access control self.vdisplay.xvfb_cmd.append(""-ac"") self.vdisplay.start() # Start the Selenium webdriver and setup configuration. self.driver = webdriver.WebDriverWrapper() self.driver.maximize_window() self.driver.implicitly_wait(self.CONFIG.selenium.implicit_wait) self.driver.set_page_load_timeout( self.CONFIG.selenium.page_timeout) self.addOnException(self._dump_page_html_source) "," if os.environ.get('INTEGRATION_TESTS', False): # Start a virtual display server for running the tests headless. if os.environ.get('SELENIUM_HEADLESS', False): self.vdisplay = xvfbwrapper.Xvfb(width=1280, height=720) # workaround for memory leak in Xvfb taken from: http://blog. # jeffterrace.com/2012/07/xvfb-memory-leak-workaround.html self.vdisplay.xvfb_cmd.append(""-noreset"") # disables X access control self.vdisplay.xvfb_cmd.append(""-ac"") self.vdisplay.start() # Start the Selenium webdriver and setup configuration. self.driver = webdriver.WebDriverWrapper() self.driver.maximize_window() self.driver.implicitly_wait(self.CONFIG.selenium.implicit_wait) self.driver.set_page_load_timeout( self.CONFIG.selenium.page_timeout) self.addOnException(self._dump_page_html_source) else:",20,18
openstack%2Fnova~master~I896d390373731411fefe381f11872f3282cee48b,openstack/nova,master,I896d390373731411fefe381f11872f3282cee48b,libvirt: remove _get_disk_xml to use get_disk from Guest,MERGED,2015-06-05 13:02:18.000000000,2015-06-10 08:54:47.000000000,2015-06-10 08:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-06-05 13:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b795caf54d1b5907a3e8d6c9a7b6152b5d660460', 'message': 'libvirt: remove _get_disk_xml to use get_disk from Guest\n\nUpdates code to remove the method _get_disk_xml also this method\nhas been replaced to the method get_disk from the Guest object\nwhich return LibvirtGuestDisk object.\n\nChange-Id: I896d390373731411fefe381f11872f3282cee48b\n'}, {'number': 2, 'created': '2015-06-05 13:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1970493b5bf5608567f9929a5c35e6d0d54a1421', 'message': 'libvirt: remove _get_disk_xml to use get_disk from Guest\n\nUpdates code to remove the method _get_disk_xml also this method\nhas been replaced to the method get_disk from the Guest object\nwhich return LibvirtGuestDisk object.\n\nChange-Id: I896d390373731411fefe381f11872f3282cee48b\n'}, {'number': 3, 'created': '2015-06-08 08:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ac51ee69381dc65642e30d89930fa7a66a06025', 'message': 'libvirt: remove _get_disk_xml to use get_disk from Guest\n\nUpdates code to remove the method _get_disk_xml also this method\nhas been replaced with the method get_disk from the Guest object\nwhich returns a LibvirtGuestDisk object.\nAlso update LibvirtGuestDisk to handle an undefined property\n\nChange-Id: I896d390373731411fefe381f11872f3282cee48b\n'}, {'number': 4, 'created': '2015-06-09 15:31:08.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/config.py', 'nova/virt/libvirt/guest.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c81987da67e2a2807fe4c8f1bed1515e065bf2fe', 'message': 'libvirt: remove _get_disk_xml to use get_disk from Guest\n\nUpdates code to remove the method _get_disk_xml also this method\nhas been replaced with the method get_disk from the Guest object\nwhich returns a LibvirtGuestDisk object.\nAlso update LibvirtGuestDisk to handle an undefined property\n\nChange-Id: I896d390373731411fefe381f11872f3282cee48b\n'}]",2,188764,c81987da67e2a2807fe4c8f1bed1515e065bf2fe,38,10,4,7730,,,0,"libvirt: remove _get_disk_xml to use get_disk from Guest

Updates code to remove the method _get_disk_xml also this method
has been replaced with the method get_disk from the Guest object
which returns a LibvirtGuestDisk object.
Also update LibvirtGuestDisk to handle an undefined property

Change-Id: I896d390373731411fefe381f11872f3282cee48b
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/188764/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/guest.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,b795caf54d1b5907a3e8d6c9a7b6152b5d660460,refactor-libvirt," mock_get_domain): mock_xml = """"""<domain> <devices> <disk type='file'> <source file='/path/to/fake-volume'/> <target dev='vdc' bus='virtio'/> </disk> </devices> </domain>"""""" mock_dom.XMLDesc.return_value = mock_xml mock_dom.detachDeviceFlags.assert_called_with(""""""<disk type=""file"" device=""disk""> <source file=""/path/to/fake-volume""/> <target bus=""virtio"" dev=""vdc""/> </disk> """""", flags) def test_swap_volume_driver_bdm_save(self, get_domain, mock_dom.XMLDesc.return_value = """"""<domain> <devices> </devices> </domain> """""" get_domain.return_value = mock_dom diska_xml = """"""<disk type=""file"" device=""disk""> <source file=""disk1_file""/> <target bus=""virtio"" dev=""vda""/> <serial>0e38683e-f0af-418f-a3f1-6b67ea0f919d</serial> </disk>"""""" diskb_xml = """"""<disk type=""block"" device=""disk""> <source dev=""/path/to/dev/1""/> <target bus=""virtio"" dev=""vdb""/> </disk>"""""" dom = mock.MagicMock() dom.XMLDesc.return_value = dom_xml guest = libvirt_guest.Guest(dom) actual_diska_xml = guest.get_disk('vda').to_xml() actual_diskb_xml = guest.get_disk('vdb').to_xml() self.assertIsNone(guest.get_disk('vdc'))"," @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_disk_xml') mock_get_domain, mock_get_disk_xml): mock_xml = \ """""" <disk type='file'> <source file='/path/to/fake-volume'/> <target dev='vdc' bus='virtio'/> </disk> """""" mock_get_disk_xml.return_value = mock_xml mock_get_disk_xml.assert_called_with(mock_dom.XMLDesc(0), 'vdc') mock_dom.detachDeviceFlags.assert_called_with(mock_xml, flags) @mock.patch('nova.virt.libvirt.driver.LibvirtDriver._get_disk_xml') def test_swap_volume_driver_bdm_save(self, get_domain, get_disk_xml, mock_dom.XMLDesc.return_value = ""<domain/>"" get_domain.return_value = mock_dom mock_xml = \ """""" """""" get_disk_xml.return_value = mock_xml get_disk_xml.assert_called_once_with(mock_dom.XMLDesc(0), 'vdb') diska_xml = """"""<disk type=""file""> <source file=""disk1_file""/> <target dev=""vda"" bus=""virtio""/> <serial>0e38683e-f0af-418f-a3f1-6b67ea0f919d</serial> </disk> """""" diskb_xml = """"""<disk type=""block""> <source dev=""/path/to/dev/1""/> <target dev=""vdb"" bus=""virtio"" serial=""1234""/> </disk> """""" drv = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) actual_diska_xml = drv._get_disk_xml(dom_xml, 'vda') actual_diskb_xml = drv._get_disk_xml(dom_xml, 'vdb') self.assertIsNone(drv._get_disk_xml(dom_xml, 'vdc'))",55,50
openstack%2Fdesignate~master~I12249cf9db171494a8aa7101890b74e2f916b519,openstack/designate,master,I12249cf9db171494a8aa7101890b74e2f916b519,Updated from global requirements,MERGED,2015-06-09 19:57:22.000000000,2015-06-10 08:52:22.000000000,2015-06-10 08:52:21.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2015-06-09 19:57:22.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/6518d39b2f85fb94e73933c146d0550b4ae5195b', 'message': 'Updated from global requirements\n\nChange-Id: I12249cf9db171494a8aa7101890b74e2f916b519\n'}]",0,189895,6518d39b2f85fb94e73933c146d0550b4ae5195b,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I12249cf9db171494a8aa7101890b74e2f916b519
",git fetch https://review.opendev.org/openstack/designate refs/changes/95/189895/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6518d39b2f85fb94e73933c146d0550b4ae5195b,openstack/requirements,"oslo.concurrency>=2.0.0 # Apache-2.0oslo.middleware>=1.2.0,!=2.0.0 # Apache-2.0oslo.rootwrap>=2.0.0 # Apache-2.0",oslo.concurrency>=1.8.0 # Apache-2.0oslo.middleware>=1.2.0 # Apache-2.0oslo.rootwrap>=1.6.0 # Apache-2.0,3,3
openstack%2Foslo.vmware~master~Ibf2a16e3fc62aadc995c70b5dfe2258f1cf23f85,openstack/oslo.vmware,master,Ibf2a16e3fc62aadc995c70b5dfe2258f1cf23f85,Fix bandit tox environment to properly run,MERGED,2015-06-09 16:20:51.000000000,2015-06-10 08:47:10.000000000,2015-06-10 08:47:08.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5638}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9172}, {'_account_id': 11861}]","[{'number': 1, 'created': '2015-06-09 16:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/72837f2bbb25fbf88f38a5416bfeda2a5c54b937', 'message': 'Fix bandit tox environment to properly run\n\nThese changes were necessary:\n- Move bandit dependency from test-requirements-bandit.txt to\n  test-requirements.txt\n- Only print high and medium severity errors (-ll)\n- Rename blacklist_functions to proper plugin name of\n  blacklist_calls\n\nChange-Id: Ibf2a16e3fc62aadc995c70b5dfe2258f1cf23f85\n'}, {'number': 2, 'created': '2015-06-09 20:44:58.000000000', 'files': ['test-requirements.txt', 'bandit.yaml', 'test-requirements-bandit.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/84492c14a760df5e257d23c93bb91da916c2e87d', 'message': 'Fix bandit tox environment to properly run\n\nThese changes were necessary:\n- Move bandit dependency from test-requirements-bandit.txt to\n  test-requirements.txt\n- Only print high and medium severity errors (-ll)\n- Rename blacklist_functions to proper plugin name of\n  blacklist_calls\n\nChange-Id: Ibf2a16e3fc62aadc995c70b5dfe2258f1cf23f85\n'}]",1,189805,84492c14a760df5e257d23c93bb91da916c2e87d,13,9,2,8119,,,0,"Fix bandit tox environment to properly run

These changes were necessary:
- Move bandit dependency from test-requirements-bandit.txt to
  test-requirements.txt
- Only print high and medium severity errors (-ll)
- Rename blacklist_functions to proper plugin name of
  blacklist_calls

Change-Id: Ibf2a16e3fc62aadc995c70b5dfe2258f1cf23f85
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/05/189805/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'bandit.yaml', 'test-requirements-bandit.txt', 'tox.ini']",4,72837f2bbb25fbf88f38a5416bfeda2a5c54b937,bandit,deps = -r{toxinidir}/test-requirements.txt commands = bandit -c bandit.yaml -r oslo_vmware -ll,deps = -r{toxinidir}/test-requirements-bandit.txt commands = bandit -c bandit.yaml -r oslo_vmware -n 5,5,5
openstack%2Fopenstack-manuals~master~I2c75f5728f6c5daeb9f9381d8e3e0e69767b4ac3,openstack/openstack-manuals,master,I2c75f5728f6c5daeb9f9381d8e3e0e69767b4ac3,[networking-guide] TCP/UDP/ICMP,MERGED,2015-06-08 01:17:42.000000000,2015-06-10 08:33:09.000000000,2015-06-10 08:33:07.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10607}, {'_account_id': 14046}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-08 01:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ea66673ff904aa1f176390959a6503260f648466', 'message': '[networking-guide] TCP/UDP/ICMP\n\nAdd TCP/UDP/ICMP overview to the ""intro to basic networking"" section of\nnetworking guide.\n\nChange-Id: I2c75f5728f6c5daeb9f9381d8e3e0e69767b4ac3\n'}, {'number': 2, 'created': '2015-06-08 13:30:18.000000000', 'files': ['doc/networking-guide/source/intro_tunnel_technologies.rst', 'doc/networking-guide/source/intro_basic_networking.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9771ce9b0c8269893966a870cd20432ce0361e40', 'message': '[networking-guide] TCP/UDP/ICMP\n\nAdd TCP/UDP/ICMP overview to the ""intro to basic networking"" section of\nnetworking guide.\n\nChanged some text in other parts of ""intro to basic networking"" from future\ntense to present tense.\n\nChange-Id: I2c75f5728f6c5daeb9f9381d8e3e0e69767b4ac3\n'}]",3,189167,9771ce9b0c8269893966a870cd20432ce0361e40,14,8,2,321,,,0,"[networking-guide] TCP/UDP/ICMP

Add TCP/UDP/ICMP overview to the ""intro to basic networking"" section of
networking guide.

Changed some text in other parts of ""intro to basic networking"" from future
tense to present tense.

Change-Id: I2c75f5728f6c5daeb9f9381d8e3e0e69767b4ac3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/67/189167/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/intro_tunnel_technologies.rst', 'doc/networking-guide/source/intro_basic_networking.rst']",2,ea66673ff904aa1f176390959a6503260f648466,tcp-udp-icmp,"TCP/UDP/ICMP For networked software applications to communicate over an IP network, they must use a protocol layered atop IP. These protocols occupy the fourth layer of the OSI model known as the *transport layer* or *layer 4*. See the `Protocol Numbers`_ web page maintained by the Internet Assigned Numbers Authority (IANA) for a list of protocols that layer atop IP, and their associated numbers. .. _Protocol Numbers: http://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml The *Transmission Control Protocol* (TCP) is the most commonly used layer 4 protocol in networked applications. TCP is a *connection-oriented* protocol: it uses a client-server model where a client connects to a server, where *server* refers to the application that receives connections. The typical interaction in a TCP-based application proceeds as follows: 1. Client connects to server. 2. Client and server exchange data. 3. Client or server disconnects. Because a network host may have multiple TCP-based applications running, TCP uses an addressing scheme called *ports* to uniquely identify TCP-based applications. A TCP port is associated with a number in the range 1-65535, and only one application on a host can be associated with a TCP port at a time, a restriction that is enforced by the operating system. A TCP server is said to *listen* on a port. For example, an SSH server typically listens on port 22. For a client to connect to a server using TCP, the client must know both the IP address of a server's host and the server's TCP port. The operating system of the TCP client application will automatically assign a port number to the client. The client will own this port number until the TCP connection is terminated, after which time the operating system will reclaim the port number. These types of ports are referred to as *ephemeral ports*. IANA maintains a `registry of port numbers`_ for many TCP-based services, as well as services that use other layer 4 protocols that employ ports. Registering a TCP port number is not required, but registering a port number is helpful to avoid collisions with other services. See `Appendix B. Firewalls and default ports`_ of the `OpenStack Configuration Reference`_ for the default TCP ports used by various services involved in an OpenStack deployment. .. _registry of port numbers: http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml .. _Appendix B. Firewalls and default ports: http://docs.openstack.org/kilo/config-reference/content/firewalls-default-ports.html .. _OpenStack Configuration Reference: http://docs.openstack.org/kilo/config-reference/content/index.html The most common application programming interface (API) for writing TCP-based applications is called *Berkeley sockets*, also known as *BSD sockets* or, simply, *sockets*. The sockets API exposes a *stream oriented* interface for writing TCP applications: from the perspective of a programmer, sending data over a TCP connection is similar to writing a stream of bytes to a file. It is the responsibility of the operating system's TCP/IP implementation to break up the stream of data into IP packets. The operating system is also responsible for automatically retransmitting dropped packets, and for handling flow control to enusre that transmitted data does not overrun the sender's data buffers, receiver's data buffers, and network capacity. Finally, the operating system is responsible for re-assembling the packets in the correct order into a stream of data on the receiver's side. Because TCP detects and retransmits lost packets, it is said to be a *reliable* protocol. The *User Datagram Protocol* (UDP) is another layer 4 protocol that is the basis of several well-known networking protocols. UDP is a *connectionless* protocol: two applications that communicate over UDP do not need to establish a connection before exchanging data. UDP is also an *unreliable* protocol. The operating system will not attempt to retransmit or even detect lost UDP packets. The operating system also does not provide any guarantee that the receiving application will see the UDP packets in the same order that they were sent in. UDP, like TCP, uses the notion of ports to distinguish between different applications running on the same system. Note, however, that operating systems treat UDP ports separately from TCP ports. For example, it is possible for one application to be associated with TCP port 16543 and a separate application to be associated with UDP port 16543. Like TCP, the sockets API is the most common API for writing UDP-based applications. The sockets API provides a *message-oriented* interface for writing UDP applications: a programmer sends data over UDP by transmitting a fixed-sized message. If an application requires retransmissions of lost packets or a well-defined ordering of received packets, the programmer is responsible for implementing this functionality in the application code. DHCP_, the Domain Name System (DNS), the Network Time Protocol (NTP) and :ref:`VXLAN` are examples of UDP-based protocols used in OpenStack deployments. UDP has support for one-to-many communication: sending a single packet to multiple hosts. An application can broadcast a UDP packet to all of the network hosts on a local network by setting the receiver IP address as the special IP broadcast address ``255.255.255.255``. An application can also send a UDP packet to a set of receivers using *IP multicast*. The intended receiver applications join a multicast group by binding a UDP socket to a special IP address that is one of the valid multicast group addresses. The receiving hosts do not have to be on the same local network as the sender, but the intervening routers must be configured to support IP multicast routing. VXLAN is an example of a UDP-based protocol that uses IP multicast. The *Internet Control Message Protocol* (ICMP) is a protocol used for sending control messages over an IP network. For example, a router that receives an IP packet may send an ICMP packet back to the source if there is no route in the router's routing table that corresponds to the destination address (ICMP code 1, destination host unreachable) or if the IP packet is too large for the router to handle (ICMP code 4, fragmentation required and ""don't fragment"" flag is set). The *ping* and *mtr* Linux command-line tools are two examples of network utilities that use ICMP.",ICMP/TCP/UDP,110,1
openstack%2Fheat~master~I782e682b80f3247b189a2aed73e9f51911f224f7,openstack/heat,master,I782e682b80f3247b189a2aed73e9f51911f224f7,Updated from global requirements,MERGED,2015-06-09 19:57:55.000000000,2015-06-10 08:27:44.000000000,2015-06-10 08:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9751}]","[{'number': 1, 'created': '2015-06-09 19:57:55.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/bc8c527f45d39c26c0950c35352467db138c5d96', 'message': 'Updated from global requirements\n\nChange-Id: I782e682b80f3247b189a2aed73e9f51911f224f7\n'}]",0,189896,bc8c527f45d39c26c0950c35352467db138c5d96,9,4,1,11131,,,0,"Updated from global requirements

Change-Id: I782e682b80f3247b189a2aed73e9f51911f224f7
",git fetch https://review.opendev.org/openstack/heat refs/changes/96/189896/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,bc8c527f45d39c26c0950c35352467db138c5d96,openstack/requirements,"oslo.concurrency>=2.0.0 # Apache-2.0oslo.middleware>=1.2.0,!=2.0.0 # Apache-2.0",oslo.concurrency>=1.8.0 # Apache-2.0oslo.middleware>=1.2.0 # Apache-2.0,4,4
openstack%2Fsahara~master~I1c04dd74077624cb75d00cbd65692af1246b4d69,openstack/sahara,master,I1c04dd74077624cb75d00cbd65692af1246b4d69,Transform configuration values into int or float when needed,MERGED,2015-06-02 03:27:02.000000000,2015-06-10 08:27:19.000000000,2015-06-10 08:27:18.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13662}, {'_account_id': 13919}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-06-02 03:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0bd0ee8209d92967a01f9b8221c3990914766bce', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthen into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 2, 'created': '2015-06-02 03:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/318544cfce52f32641f1f2c2e898c98456c5b756', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthen into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 3, 'created': '2015-06-02 14:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/86089b437860fdd9ce8b2fb36fc98f231cb15374', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthen into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 4, 'created': '2015-06-03 06:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3faadfe7c7edbf0b422f08917caf3658fe3695ae', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthen into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 5, 'created': '2015-06-05 03:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ab214dd2e33c05b6100c534e17967e1c8042f646', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthem into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 6, 'created': '2015-06-08 03:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d5b670267e268d8cdddd75195eb0d32267a6fa08', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthem into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 7, 'created': '2015-06-09 00:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/693f1d5b30b66743030ceaac3caeb748a76755d3', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthem into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}, {'number': 8, 'created': '2015-06-09 00:52:10.000000000', 'files': ['sahara/plugins/cdh/plugin_utils.py', 'sahara/utils/types.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/41a38a981dd0307439473324048c6347e00d180c', 'message': 'Transform configuration values into int or float when needed\n\nAll configuration values from Horizon are read as string. We turn\nthem into int or float.\n\nCloses-Bug: #1460763\nChange-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69\n'}]",22,187444,41a38a981dd0307439473324048c6347e00d180c,48,12,8,13662,,,0,"Transform configuration values into int or float when needed

All configuration values from Horizon are read as string. We turn
them into int or float.

Closes-Bug: #1460763
Change-Id: I1c04dd74077624cb75d00cbd65692af1246b4d69
",git fetch https://review.opendev.org/openstack/sahara refs/changes/44/187444/8 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/plugin_utils.py', 'sahara/utils/types.py']",2,0bd0ee8209d92967a01f9b8221c3990914766bce,Bug1460763, def transform(s): try: return int(s) except Exception: try: return float(s) except Exception: return s,,13,2
openstack%2Ffuel-web~master~Icd2030a3077211b408dc117eadd3961be90ac8b9,openstack/fuel-web,master,Icd2030a3077211b408dc117eadd3961be90ac8b9,Add xfsprogs to Ubuntu image,ABANDONED,2015-05-19 12:52:22.000000000,2015-06-10 08:11:36.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8797}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11082}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 14543}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-05-19 12:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1c75fbef1deab5623f3c1d394cb1d1e3c704770a', 'message': 'Added xfsprogs to Ubuntu image\n\nChange-Id: Icd2030a3077211b408dc117eadd3961be90ac8b9\nPartial-Bug: #1456325\n'}, {'number': 2, 'created': '2015-05-19 12:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/137966fcf3dbe86e456c1c530d2cae0483bf362d', 'message': 'Added xfsprogs to Ubuntu image\n\nChange-Id: Icd2030a3077211b408dc117eadd3961be90ac8b9\nPartial-Bug: #1456325\n'}, {'number': 3, 'created': '2015-05-23 06:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/41fd57be83b50c133fe12d59e73534aee4a312a9', 'message': 'Added xfsprogs to Ubuntu image\n\nChange-Id: Icd2030a3077211b408dc117eadd3961be90ac8b9\nPartial-Bug: #1456325\n'}, {'number': 4, 'created': '2015-05-26 08:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/71ec7ea001660c7e486f18ab2d964557df6ee8ff', 'message': 'Add xfsprogs to Ubuntu image\n\nChange-Id: Icd2030a3077211b408dc117eadd3961be90ac8b9\nPartial-Bug: #1456325\n'}, {'number': 5, 'created': '2015-05-26 08:23:20.000000000', 'files': ['fuel_agent/fuel_agent/tests/test_nailgun_build_image.py', 'fuel_agent/fuel_agent/drivers/nailgun.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e15ea2b4c9b46e15248fa23e13909016b765bc75', 'message': 'Add xfsprogs to Ubuntu image\n\nChange-Id: Icd2030a3077211b408dc117eadd3961be90ac8b9\nPartial-Bug: #1456325\n'}]",0,184238,e15ea2b4c9b46e15248fa23e13909016b765bc75,41,12,5,12200,,,0,"Add xfsprogs to Ubuntu image

Change-Id: Icd2030a3077211b408dc117eadd3961be90ac8b9
Partial-Bug: #1456325
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/38/184238/3 && git format-patch -1 --stdout FETCH_HEAD,['fuel_agent/fuel_agent/drivers/nailgun.py'],1,1c75fbef1deab5623f3c1d394cb1d1e3c704770a,bug/1456325," ""xfsprogs"",",,1,0
openstack%2Ffuel-main~master~I60e74e4a4b17f24593502e32144e1500e300ffe2,openstack/fuel-main,master,I60e74e4a4b17f24593502e32144e1500e300ffe2,Added xfsprogs to Centos image,ABANDONED,2015-05-19 12:52:22.000000000,2015-06-10 08:11:18.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7227}, {'_account_id': 8003}, {'_account_id': 8797}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-05-19 12:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0d01b6cfad561f05c7f6b7b2890a6a03f44a4cf4', 'message': 'Added xfsprogs to Centos image\n\nChange-Id: I60e74e4a4b17f24593502e32144e1500e300ffe2\nPartial-Bugs: #1456325\n'}, {'number': 2, 'created': '2015-05-20 13:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bdfef782a0c5fd0d3c0e5f800d91ae6866d24023', 'message': 'Added xfsprogs to Centos image\n\nChange-Id: I60e74e4a4b17f24593502e32144e1500e300ffe2\nPartial-Bugs: #1456325\n'}, {'number': 3, 'created': '2015-05-23 06:06:01.000000000', 'files': ['image/centos/centos.ks', 'bootstrap/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/30f08cbbf0d1da286d21c733cd4048665d2ce674', 'message': 'Added xfsprogs to Centos image\n\nChange-Id: I60e74e4a4b17f24593502e32144e1500e300ffe2\nPartial-Bugs: #1456325\n'}]",0,184237,30f08cbbf0d1da286d21c733cd4048665d2ce674,19,8,3,12200,,,0,"Added xfsprogs to Centos image

Change-Id: I60e74e4a4b17f24593502e32144e1500e300ffe2
Partial-Bugs: #1456325
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/37/184237/2 && git format-patch -1 --stdout FETCH_HEAD,['image/centos/centos.ks'],1,0d01b6cfad561f05c7f6b7b2890a6a03f44a4cf4,bug/1456325,xfsprogs,,1,0
openstack%2Fha-guide~master~I9c565ccdbeea12bf0d1d67194a9891db791b7c38,openstack/ha-guide,master,I9c565ccdbeea12bf0d1d67194a9891db791b7c38,Updated from openstack-manuals,MERGED,2015-06-10 07:55:46.000000000,2015-06-10 08:11:00.000000000,2015-06-10 08:10:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-10 07:55:46.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/d96861207d7afd35c4611b78e7a0f063ef680cff', 'message': 'Updated from openstack-manuals\n\nChange-Id: I9c565ccdbeea12bf0d1d67194a9891db791b7c38\n'}]",0,190059,d96861207d7afd35c4611b78e7a0f063ef680cff,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I9c565ccdbeea12bf0d1d67194a9891db791b7c38
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/59/190059/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,d96861207d7afd35c4611b78e7a0f063ef680cff,openstack/openstack-manuals,"""POT-Creation-Date: 2015-06-10 05:08+0000\n"" ""PO-Revision-Date: 2015-06-10 05:38+0000\n""""A number within a database that is incremented each time a change is made. "" ""Used by Object Storage when replicating."" msgstr """" ""変更が行われる度に増加するデータベース内の数値。Object Storage が複製を行う際"" ""に使用する。"" msgid """"msgid """" ""A personality that a user assumes to perform a specific set of operations. A "" ""role includes a set of rights and privileges. A user assuming that role "" ""inherits those rights and privileges."" msgstr """" ""ユーザーが特定の操作の組を実行すると仮定する人格。ロールは一組の権利と権限を"" ""含みます。そのロールを仮定しているユーザーは、それらの権利と権限を継承しま"" ""す。"" ""A process that is created when a RPC call is executed; used to push the "" ""message to the topic exchange."" msgstr """" ""RPC コールが実行されるときに作成されるプロセス。メッセージをトピック交換者に"" ""プッシュするために使用される。"" msgid """"""A routing table that is created within the Compute RabbitMQ during RPC "" ""calls; one is created for each RPC call that is invoked."" msgstr """" ""RPC コール中に Compute RabbitMQ 内で作成されるルーティングテーブル。関連する"" ""各 RPC コールに対して作成されるもの。"" msgid """"""An IP address that is associated with the same instance each time that "" ""instance boots, is generally not accessible to end users or the public "" ""Internet, and is used for management of the instance."" msgstr """" ""インスタンス起動時に毎回同じインスタンスに割当られるIPアドレス（一般に、エン"" ""ドユーザやパブリックインターネットからはアクセス出来ない）。インスタンスの管"" ""理に使用される。"" msgid """"msgid """" ""An element of the Compute capacity cache that is calculated based on the "" ""number of build, snapshot, migrate, and resize operations currently in "" ""progress on a given host."" msgstr """" ""指定されたホスト上で現在進行中の build, snapshot, migrate, resize の操作数を"" ""元に計算される、Compute のキャパシティキャッシュの１要素。"" msgid """" ""An entity that maps Object Storage data to partitions. A separate ring "" ""exists for each service, such as account, object, and container."" msgstr """" ""Object Storage データのパーティションへのマッピングを行う。アカウント、オブ"" ""ジェクト、コンテナーというサービス単位に別々のリングが存在する。"" msgid ""Bare metal service"" msgstr ""Bare metal service"" msgid """" ""Builds and manages rings within Object Storage, assigns partitions to "" ""devices, and pushes the configuration to other storage nodes."" msgstr """" ""Object Storage のリングの作成、管理を行い、パーティションのデバイスへの割り当"" ""てを行い、他のストレージノードに設定を転送する。"" msgid """" ""Describes the parameters of the various virtual machine images that are "" ""available to users; includes parameters such as CPU, storage, and memory. "" ""Alternative term for flavor."" msgstr """" ""ユーザが利用可能な様々な仮想マシンイメージのパラメーター（CPU、ストレージ、メ"" ""モリ等を含む）を示す。フレーバーの別名。"" msgid """" ""Extension to iptables that allows creation of firewall rules that match "" ""entire \""sets\"" of IP addresses simultaneously. These sets reside in indexed "" ""data structures to increase efficiency, particularly on systems with a large "" ""quantity of rules."" msgstr """" ""連続する IP アドレスの全体に一致するファイアウォールルールを作成できる、"" ""iptables の拡張。これらのセットは、効率化するためにインデックス化されたデータ"" ""構造、とくに大量のルールを持つシステムにあります。"" ""Generally, extra properties on an Image service image to which only cloud "" ""administrators have access. Limits which user roles can perform CRUD "" ""operations on that property. The cloud administrator can configure any image "" ""property as protected."" msgstr """" ""クラウド管理者のみがアクセスできる、Image service のイメージの追加プロパ"" ""ティー。どのユーザーロールがそのプロパティーにおいて CRUD 操作を実行できるか"" ""を制限する。クラウド管理者は、保護されたイメージのプロパティーをすべて設定で"" ""きる。"" msgid """"msgid ""Governance service"" msgstr ""Governance service"" ""If Object Storage finds objects, containers, or accounts that are corrupt, "" ""they are placed in this state, are not replicated, cannot be read by "" ""clients, and a correct copy is re-replicated."" msgstr """" ""Object Storage が壊れたオブジェクト、コンテナー、アカウントを見つけた際に、そ"" ""のデータはこの状態にセットされる。この状態にセットされたデータは、複製され"" ""ず、クライアントが読み出すこともできなくなり、正しいコピーが再複製される。"" msgid """"""In Object Storage, tools to test and ensure dispersion of objects and "" ""containers to ensure fault tolerance."" msgstr """" ""Object Storage で、フォールトトレラントの確認の為に、オブジェクトとコンテナ"" ""の分散をテスト、確認するツール。"" msgid """"msgid ""Key-Value Store as a Service"" msgstr ""Key-Value Store as a Service"" msgid """" ""Modular system that allows the underlying message queue software of Compute "" ""to be changed. For example, from RabbitMQ to ZeroMQ or Qpid."" msgstr """" ""Compute が利用するメッセージキューソフトウェアを変更できるようにする仕組み。"" ""例えば、 RabbitMQ を ZeroMQ や Qpid に変更できる。"" msgid """" ""OpenStack project that provides a Key-Value Store as a Service for OpenStack "" ""users."" msgstr """" ""OpenStack ユーザーに Key-Value Store as a Service を提供する OpenStack のプロ"" ""ジェクト。"" msgid """" ""OpenStack project that provides a scalable data-processing stack and "" ""associated management interfaces. The code name for the project is sahara."" msgstr """" ""スケールアウト可能なデータ処理基盤と関連する管理インターフェースを提供する、"" ""OpenStack のプロジェクト。プロジェクトのコード名は sahara です。"" msgid """" ""OpenStack project that provides a set of services for management of "" ""application containers in a multi-tenant cloud environment. The code name of "" ""the project name is magnum."" msgstr """" ""マルチテナントクラウド環境において、アプリケーションコンテナーの管理サービス"" ""を提供する、OpenStack のプロジェクト。プロジェクトのコード名は magnum です。"" msgid ""OpenStack project that provides an Application catalog."" msgstr ""アプリケーションカタログを提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides shared file systems as service to "" ""applications."" msgstr """" ""共有ファイルシステムをアプリケーションに提供する OpenStack のプロジェクト。"" msgid ""OpenStack project that provides the Benchmark service."" msgstr ""Benchmark service を提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides the Governance service."" msgstr ""Governance service を提供する OpenStack プロジェクト。"" msgid """" ""OpenStack project that provisions bare metal, as opposed to virtual, "" ""machines. The code name for the project is ironic."" msgstr """" ""マシンを仮想とみなして、ベアメタルに展開する OpenStack のプロジェクト。このプ"" ""ロジェクトのコード名は ironic です。"" msgid """" ""Organizes and stores objects in Object Storage. Similar to the concept of a "" ""Linux directory but cannot be nested. Alternative term for an Image service "" ""container format."" msgstr """" ""Object Storage でオブジェクトを整理して保存する。Linux のディレクトリと似てい"" ""るが、入れ子にできない。Image service のコンテナー形式の別名。"" msgid """" ""Provides data redundancy and fault tolerance by creating copies of Object "" ""Storage objects, accounts, and containers so that they are not lost when the "" ""underlying storage fails."" msgstr """" ""Object Storage のオブジェクト、アカウント、コンテナーのコピーを作成すること"" ""で、データ冗長性や耐障害性を実現する。これにより、バックエンドのストレージが"" ""故障した場合でもデータは失わない。"" msgid """" ""Provides logical partitioning of Compute resources in a child and parent "" ""relationship. Requests are passed from parent cells to child cells if the "" ""parent cannot provide the requested resource."" msgstr """" ""親子関係で Compute リソースの論理パーティションを提供する。親セルが要求された"" ""リソースを提供できない場合、親セルからのリクエストは子セルに渡される。"" msgid """" ""Setting for the Compute RabbitMQ message delivery mode; can be set to either "" ""transient or persistent."" msgstr """" ""Compute RabbitMQ メッセージ配信モード用設定。transient（一時）又は persistent"" ""（永続）のいずれかを設定できる。"" msgid """" ""The code name for the twelfth release of OpenStack. The design summit will "" ""take place in Vancouver, Canada and Liberty is the name of a village in the "" ""Canadian province of Saskatchewan."" msgstr """" ""OpenStack の 12 番目のリリースのコード名。デザインサミットは、カナダのバン"" ""クーバーで開催された。Liberty は、サスカチュワン州にある村の名前。"" ""Used along with arptables and ebtables, iptables create firewalls in "" ""Compute. iptables are the tables provided by the Linux kernel firewall "" ""(implemented as different Netfilter modules) and the chains and rules it "" ""stores. Different kernel modules and programs are currently used for "" ""different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables "" ""to ARP, and ebtables to Ethernet frames. Requires root privilege to "" ""manipulate."" msgstr """" ""Compute においてファイアウォールを作成する、arptables、ebtables、iptables と"" ""一緒に使用される。iptables は、Linux カーネルファイアウォール (別の "" ""Netfilter モジュール) により提供されるテーブル、それを保存するチェインやルー"" ""ル。複数のカーネルモジュールとプログラムが、別々のプロトコルに対して使用され"" ""る。iptables は IPv4、ip6tables は IPv6、arptables は ARP、ebtables は "" ""Ethernet フレームに適用される。操作すうために root 権限が必要になる。"" msgid """"msgid """" ""Within RabbitMQ and Compute, it is the messaging interface that is used by "" ""the scheduler service to receive capability messages from the compute, "" ""volume, and network nodes."" msgstr """" ""RabbitMQ と Compute の中で、コンピュートノード、ボリュームノード、ネットワー"" ""クノードからのメッセージを受け付ける機能のために、スケジューラーサービスによ"" ""り使用されるメッセージングインターフェース。"" ","""POT-Creation-Date: 2015-06-07 17:25+0000\n"" ""PO-Revision-Date: 2015-06-07 10:10+0000\n""",233,2
openstack%2Foperations-guide~master~I4c6e6023cc964985308847d221360f5b73e3e916,openstack/operations-guide,master,I4c6e6023cc964985308847d221360f5b73e3e916,Updated from openstack-manuals,MERGED,2015-06-10 07:55:51.000000000,2015-06-10 08:08:34.000000000,2015-06-10 08:08:34.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-10 07:55:51.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/7588c8f3c8146d1091868aac46a1034f93bddfd9', 'message': 'Updated from openstack-manuals\n\nChange-Id: I4c6e6023cc964985308847d221360f5b73e3e916\n'}]",0,190060,7588c8f3c8146d1091868aac46a1034f93bddfd9,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I4c6e6023cc964985308847d221360f5b73e3e916
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/60/190060/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,7588c8f3c8146d1091868aac46a1034f93bddfd9,openstack/openstack-manuals,"""POT-Creation-Date: 2015-06-10 05:08+0000\n"" ""PO-Revision-Date: 2015-06-10 05:38+0000\n""""A number within a database that is incremented each time a change is made. "" ""Used by Object Storage when replicating."" msgstr """" ""変更が行われる度に増加するデータベース内の数値。Object Storage が複製を行う際"" ""に使用する。"" msgid """"msgid """" ""A personality that a user assumes to perform a specific set of operations. A "" ""role includes a set of rights and privileges. A user assuming that role "" ""inherits those rights and privileges."" msgstr """" ""ユーザーが特定の操作の組を実行すると仮定する人格。ロールは一組の権利と権限を"" ""含みます。そのロールを仮定しているユーザーは、それらの権利と権限を継承しま"" ""す。"" ""A process that is created when a RPC call is executed; used to push the "" ""message to the topic exchange."" msgstr """" ""RPC コールが実行されるときに作成されるプロセス。メッセージをトピック交換者に"" ""プッシュするために使用される。"" msgid """"""A routing table that is created within the Compute RabbitMQ during RPC "" ""calls; one is created for each RPC call that is invoked."" msgstr """" ""RPC コール中に Compute RabbitMQ 内で作成されるルーティングテーブル。関連する"" ""各 RPC コールに対して作成されるもの。"" msgid """"""An IP address that is associated with the same instance each time that "" ""instance boots, is generally not accessible to end users or the public "" ""Internet, and is used for management of the instance."" msgstr """" ""インスタンス起動時に毎回同じインスタンスに割当られるIPアドレス（一般に、エン"" ""ドユーザやパブリックインターネットからはアクセス出来ない）。インスタンスの管"" ""理に使用される。"" msgid """"msgid """" ""An element of the Compute capacity cache that is calculated based on the "" ""number of build, snapshot, migrate, and resize operations currently in "" ""progress on a given host."" msgstr """" ""指定されたホスト上で現在進行中の build, snapshot, migrate, resize の操作数を"" ""元に計算される、Compute のキャパシティキャッシュの１要素。"" msgid """" ""An entity that maps Object Storage data to partitions. A separate ring "" ""exists for each service, such as account, object, and container."" msgstr """" ""Object Storage データのパーティションへのマッピングを行う。アカウント、オブ"" ""ジェクト、コンテナーというサービス単位に別々のリングが存在する。"" msgid ""Bare metal service"" msgstr ""Bare metal service"" msgid """" ""Builds and manages rings within Object Storage, assigns partitions to "" ""devices, and pushes the configuration to other storage nodes."" msgstr """" ""Object Storage のリングの作成、管理を行い、パーティションのデバイスへの割り当"" ""てを行い、他のストレージノードに設定を転送する。"" msgid """" ""Describes the parameters of the various virtual machine images that are "" ""available to users; includes parameters such as CPU, storage, and memory. "" ""Alternative term for flavor."" msgstr """" ""ユーザが利用可能な様々な仮想マシンイメージのパラメーター（CPU、ストレージ、メ"" ""モリ等を含む）を示す。フレーバーの別名。"" msgid """" ""Extension to iptables that allows creation of firewall rules that match "" ""entire \""sets\"" of IP addresses simultaneously. These sets reside in indexed "" ""data structures to increase efficiency, particularly on systems with a large "" ""quantity of rules."" msgstr """" ""連続する IP アドレスの全体に一致するファイアウォールルールを作成できる、"" ""iptables の拡張。これらのセットは、効率化するためにインデックス化されたデータ"" ""構造、とくに大量のルールを持つシステムにあります。"" ""Generally, extra properties on an Image service image to which only cloud "" ""administrators have access. Limits which user roles can perform CRUD "" ""operations on that property. The cloud administrator can configure any image "" ""property as protected."" msgstr """" ""クラウド管理者のみがアクセスできる、Image service のイメージの追加プロパ"" ""ティー。どのユーザーロールがそのプロパティーにおいて CRUD 操作を実行できるか"" ""を制限する。クラウド管理者は、保護されたイメージのプロパティーをすべて設定で"" ""きる。"" msgid """"msgid ""Governance service"" msgstr ""Governance service"" ""If Object Storage finds objects, containers, or accounts that are corrupt, "" ""they are placed in this state, are not replicated, cannot be read by "" ""clients, and a correct copy is re-replicated."" msgstr """" ""Object Storage が壊れたオブジェクト、コンテナー、アカウントを見つけた際に、そ"" ""のデータはこの状態にセットされる。この状態にセットされたデータは、複製され"" ""ず、クライアントが読み出すこともできなくなり、正しいコピーが再複製される。"" msgid """"""In Object Storage, tools to test and ensure dispersion of objects and "" ""containers to ensure fault tolerance."" msgstr """" ""Object Storage で、フォールトトレラントの確認の為に、オブジェクトとコンテナ"" ""の分散をテスト、確認するツール。"" msgid """"msgid ""Key-Value Store as a Service"" msgstr ""Key-Value Store as a Service"" msgid """" ""Modular system that allows the underlying message queue software of Compute "" ""to be changed. For example, from RabbitMQ to ZeroMQ or Qpid."" msgstr """" ""Compute が利用するメッセージキューソフトウェアを変更できるようにする仕組み。"" ""例えば、 RabbitMQ を ZeroMQ や Qpid に変更できる。"" msgid """" ""OpenStack project that provides a Key-Value Store as a Service for OpenStack "" ""users."" msgstr """" ""OpenStack ユーザーに Key-Value Store as a Service を提供する OpenStack のプロ"" ""ジェクト。"" msgid """" ""OpenStack project that provides a scalable data-processing stack and "" ""associated management interfaces. The code name for the project is sahara."" msgstr """" ""スケールアウト可能なデータ処理基盤と関連する管理インターフェースを提供する、"" ""OpenStack のプロジェクト。プロジェクトのコード名は sahara です。"" msgid """" ""OpenStack project that provides a set of services for management of "" ""application containers in a multi-tenant cloud environment. The code name of "" ""the project name is magnum."" msgstr """" ""マルチテナントクラウド環境において、アプリケーションコンテナーの管理サービス"" ""を提供する、OpenStack のプロジェクト。プロジェクトのコード名は magnum です。"" msgid ""OpenStack project that provides an Application catalog."" msgstr ""アプリケーションカタログを提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides shared file systems as service to "" ""applications."" msgstr """" ""共有ファイルシステムをアプリケーションに提供する OpenStack のプロジェクト。"" msgid ""OpenStack project that provides the Benchmark service."" msgstr ""Benchmark service を提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides the Governance service."" msgstr ""Governance service を提供する OpenStack プロジェクト。"" msgid """" ""OpenStack project that provisions bare metal, as opposed to virtual, "" ""machines. The code name for the project is ironic."" msgstr """" ""マシンを仮想とみなして、ベアメタルに展開する OpenStack のプロジェクト。このプ"" ""ロジェクトのコード名は ironic です。"" msgid """" ""Organizes and stores objects in Object Storage. Similar to the concept of a "" ""Linux directory but cannot be nested. Alternative term for an Image service "" ""container format."" msgstr """" ""Object Storage でオブジェクトを整理して保存する。Linux のディレクトリと似てい"" ""るが、入れ子にできない。Image service のコンテナー形式の別名。"" msgid """" ""Provides data redundancy and fault tolerance by creating copies of Object "" ""Storage objects, accounts, and containers so that they are not lost when the "" ""underlying storage fails."" msgstr """" ""Object Storage のオブジェクト、アカウント、コンテナーのコピーを作成すること"" ""で、データ冗長性や耐障害性を実現する。これにより、バックエンドのストレージが"" ""故障した場合でもデータは失わない。"" msgid """" ""Provides logical partitioning of Compute resources in a child and parent "" ""relationship. Requests are passed from parent cells to child cells if the "" ""parent cannot provide the requested resource."" msgstr """" ""親子関係で Compute リソースの論理パーティションを提供する。親セルが要求された"" ""リソースを提供できない場合、親セルからのリクエストは子セルに渡される。"" msgid """" ""Setting for the Compute RabbitMQ message delivery mode; can be set to either "" ""transient or persistent."" msgstr """" ""Compute RabbitMQ メッセージ配信モード用設定。transient（一時）又は persistent"" ""（永続）のいずれかを設定できる。"" msgid """" ""The code name for the twelfth release of OpenStack. The design summit will "" ""take place in Vancouver, Canada and Liberty is the name of a village in the "" ""Canadian province of Saskatchewan."" msgstr """" ""OpenStack の 12 番目のリリースのコード名。デザインサミットは、カナダのバン"" ""クーバーで開催された。Liberty は、サスカチュワン州にある村の名前。"" ""Used along with arptables and ebtables, iptables create firewalls in "" ""Compute. iptables are the tables provided by the Linux kernel firewall "" ""(implemented as different Netfilter modules) and the chains and rules it "" ""stores. Different kernel modules and programs are currently used for "" ""different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables "" ""to ARP, and ebtables to Ethernet frames. Requires root privilege to "" ""manipulate."" msgstr """" ""Compute においてファイアウォールを作成する、arptables、ebtables、iptables と"" ""一緒に使用される。iptables は、Linux カーネルファイアウォール (別の "" ""Netfilter モジュール) により提供されるテーブル、それを保存するチェインやルー"" ""ル。複数のカーネルモジュールとプログラムが、別々のプロトコルに対して使用され"" ""る。iptables は IPv4、ip6tables は IPv6、arptables は ARP、ebtables は "" ""Ethernet フレームに適用される。操作すうために root 権限が必要になる。"" msgid """"msgid """" ""Within RabbitMQ and Compute, it is the messaging interface that is used by "" ""the scheduler service to receive capability messages from the compute, "" ""volume, and network nodes."" msgstr """" ""RabbitMQ と Compute の中で、コンピュートノード、ボリュームノード、ネットワー"" ""クノードからのメッセージを受け付ける機能のために、スケジューラーサービスによ"" ""り使用されるメッセージングインターフェース。"" ","""POT-Creation-Date: 2015-06-07 17:25+0000\n"" ""PO-Revision-Date: 2015-06-07 10:10+0000\n""",233,2
openstack%2Fsecurity-doc~master~I75da18f9b2cc04d85fdcae9eda82c398c3f06699,openstack/security-doc,master,I75da18f9b2cc04d85fdcae9eda82c398c3f06699,Updated from openstack-manuals,MERGED,2015-06-10 07:55:55.000000000,2015-06-10 08:07:36.000000000,2015-06-10 08:07:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-10 07:55:55.000000000', 'files': ['glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/43604eb4c1cb085c01c9cff3fea69f7fae7ebeed', 'message': 'Updated from openstack-manuals\n\nChange-Id: I75da18f9b2cc04d85fdcae9eda82c398c3f06699\n'}]",0,190061,43604eb4c1cb085c01c9cff3fea69f7fae7ebeed,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I75da18f9b2cc04d85fdcae9eda82c398c3f06699
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/61/190061/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/locale/ja.po'],1,43604eb4c1cb085c01c9cff3fea69f7fae7ebeed,openstack/openstack-manuals,"""POT-Creation-Date: 2015-06-10 05:08+0000\n"" ""PO-Revision-Date: 2015-06-10 05:38+0000\n""""A number within a database that is incremented each time a change is made. "" ""Used by Object Storage when replicating."" msgstr """" ""変更が行われる度に増加するデータベース内の数値。Object Storage が複製を行う際"" ""に使用する。"" msgid """"msgid """" ""A personality that a user assumes to perform a specific set of operations. A "" ""role includes a set of rights and privileges. A user assuming that role "" ""inherits those rights and privileges."" msgstr """" ""ユーザーが特定の操作の組を実行すると仮定する人格。ロールは一組の権利と権限を"" ""含みます。そのロールを仮定しているユーザーは、それらの権利と権限を継承しま"" ""す。"" ""A process that is created when a RPC call is executed; used to push the "" ""message to the topic exchange."" msgstr """" ""RPC コールが実行されるときに作成されるプロセス。メッセージをトピック交換者に"" ""プッシュするために使用される。"" msgid """"""A routing table that is created within the Compute RabbitMQ during RPC "" ""calls; one is created for each RPC call that is invoked."" msgstr """" ""RPC コール中に Compute RabbitMQ 内で作成されるルーティングテーブル。関連する"" ""各 RPC コールに対して作成されるもの。"" msgid """"""An IP address that is associated with the same instance each time that "" ""instance boots, is generally not accessible to end users or the public "" ""Internet, and is used for management of the instance."" msgstr """" ""インスタンス起動時に毎回同じインスタンスに割当られるIPアドレス（一般に、エン"" ""ドユーザやパブリックインターネットからはアクセス出来ない）。インスタンスの管"" ""理に使用される。"" msgid """"msgid """" ""An element of the Compute capacity cache that is calculated based on the "" ""number of build, snapshot, migrate, and resize operations currently in "" ""progress on a given host."" msgstr """" ""指定されたホスト上で現在進行中の build, snapshot, migrate, resize の操作数を"" ""元に計算される、Compute のキャパシティキャッシュの１要素。"" msgid """" ""An entity that maps Object Storage data to partitions. A separate ring "" ""exists for each service, such as account, object, and container."" msgstr """" ""Object Storage データのパーティションへのマッピングを行う。アカウント、オブ"" ""ジェクト、コンテナーというサービス単位に別々のリングが存在する。"" msgid ""Bare metal service"" msgstr ""Bare metal service"" msgid """" ""Builds and manages rings within Object Storage, assigns partitions to "" ""devices, and pushes the configuration to other storage nodes."" msgstr """" ""Object Storage のリングの作成、管理を行い、パーティションのデバイスへの割り当"" ""てを行い、他のストレージノードに設定を転送する。"" msgid """" ""Describes the parameters of the various virtual machine images that are "" ""available to users; includes parameters such as CPU, storage, and memory. "" ""Alternative term for flavor."" msgstr """" ""ユーザが利用可能な様々な仮想マシンイメージのパラメーター（CPU、ストレージ、メ"" ""モリ等を含む）を示す。フレーバーの別名。"" msgid """" ""Extension to iptables that allows creation of firewall rules that match "" ""entire \""sets\"" of IP addresses simultaneously. These sets reside in indexed "" ""data structures to increase efficiency, particularly on systems with a large "" ""quantity of rules."" msgstr """" ""連続する IP アドレスの全体に一致するファイアウォールルールを作成できる、"" ""iptables の拡張。これらのセットは、効率化するためにインデックス化されたデータ"" ""構造、とくに大量のルールを持つシステムにあります。"" ""Generally, extra properties on an Image service image to which only cloud "" ""administrators have access. Limits which user roles can perform CRUD "" ""operations on that property. The cloud administrator can configure any image "" ""property as protected."" msgstr """" ""クラウド管理者のみがアクセスできる、Image service のイメージの追加プロパ"" ""ティー。どのユーザーロールがそのプロパティーにおいて CRUD 操作を実行できるか"" ""を制限する。クラウド管理者は、保護されたイメージのプロパティーをすべて設定で"" ""きる。"" msgid """"msgid ""Governance service"" msgstr ""Governance service"" ""If Object Storage finds objects, containers, or accounts that are corrupt, "" ""they are placed in this state, are not replicated, cannot be read by "" ""clients, and a correct copy is re-replicated."" msgstr """" ""Object Storage が壊れたオブジェクト、コンテナー、アカウントを見つけた際に、そ"" ""のデータはこの状態にセットされる。この状態にセットされたデータは、複製され"" ""ず、クライアントが読み出すこともできなくなり、正しいコピーが再複製される。"" msgid """"""In Object Storage, tools to test and ensure dispersion of objects and "" ""containers to ensure fault tolerance."" msgstr """" ""Object Storage で、フォールトトレラントの確認の為に、オブジェクトとコンテナ"" ""の分散をテスト、確認するツール。"" msgid """"msgid ""Key-Value Store as a Service"" msgstr ""Key-Value Store as a Service"" msgid """" ""Modular system that allows the underlying message queue software of Compute "" ""to be changed. For example, from RabbitMQ to ZeroMQ or Qpid."" msgstr """" ""Compute が利用するメッセージキューソフトウェアを変更できるようにする仕組み。"" ""例えば、 RabbitMQ を ZeroMQ や Qpid に変更できる。"" msgid """" ""OpenStack project that provides a Key-Value Store as a Service for OpenStack "" ""users."" msgstr """" ""OpenStack ユーザーに Key-Value Store as a Service を提供する OpenStack のプロ"" ""ジェクト。"" msgid """" ""OpenStack project that provides a scalable data-processing stack and "" ""associated management interfaces. The code name for the project is sahara."" msgstr """" ""スケールアウト可能なデータ処理基盤と関連する管理インターフェースを提供する、"" ""OpenStack のプロジェクト。プロジェクトのコード名は sahara です。"" msgid """" ""OpenStack project that provides a set of services for management of "" ""application containers in a multi-tenant cloud environment. The code name of "" ""the project name is magnum."" msgstr """" ""マルチテナントクラウド環境において、アプリケーションコンテナーの管理サービス"" ""を提供する、OpenStack のプロジェクト。プロジェクトのコード名は magnum です。"" msgid ""OpenStack project that provides an Application catalog."" msgstr ""アプリケーションカタログを提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides shared file systems as service to "" ""applications."" msgstr """" ""共有ファイルシステムをアプリケーションに提供する OpenStack のプロジェクト。"" msgid ""OpenStack project that provides the Benchmark service."" msgstr ""Benchmark service を提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides the Governance service."" msgstr ""Governance service を提供する OpenStack プロジェクト。"" msgid """" ""OpenStack project that provisions bare metal, as opposed to virtual, "" ""machines. The code name for the project is ironic."" msgstr """" ""マシンを仮想とみなして、ベアメタルに展開する OpenStack のプロジェクト。このプ"" ""ロジェクトのコード名は ironic です。"" msgid """" ""Organizes and stores objects in Object Storage. Similar to the concept of a "" ""Linux directory but cannot be nested. Alternative term for an Image service "" ""container format."" msgstr """" ""Object Storage でオブジェクトを整理して保存する。Linux のディレクトリと似てい"" ""るが、入れ子にできない。Image service のコンテナー形式の別名。"" msgid """" ""Provides data redundancy and fault tolerance by creating copies of Object "" ""Storage objects, accounts, and containers so that they are not lost when the "" ""underlying storage fails."" msgstr """" ""Object Storage のオブジェクト、アカウント、コンテナーのコピーを作成すること"" ""で、データ冗長性や耐障害性を実現する。これにより、バックエンドのストレージが"" ""故障した場合でもデータは失わない。"" msgid """" ""Provides logical partitioning of Compute resources in a child and parent "" ""relationship. Requests are passed from parent cells to child cells if the "" ""parent cannot provide the requested resource."" msgstr """" ""親子関係で Compute リソースの論理パーティションを提供する。親セルが要求された"" ""リソースを提供できない場合、親セルからのリクエストは子セルに渡される。"" msgid """" ""Setting for the Compute RabbitMQ message delivery mode; can be set to either "" ""transient or persistent."" msgstr """" ""Compute RabbitMQ メッセージ配信モード用設定。transient（一時）又は persistent"" ""（永続）のいずれかを設定できる。"" msgid """" ""The code name for the twelfth release of OpenStack. The design summit will "" ""take place in Vancouver, Canada and Liberty is the name of a village in the "" ""Canadian province of Saskatchewan."" msgstr """" ""OpenStack の 12 番目のリリースのコード名。デザインサミットは、カナダのバン"" ""クーバーで開催された。Liberty は、サスカチュワン州にある村の名前。"" ""Used along with arptables and ebtables, iptables create firewalls in "" ""Compute. iptables are the tables provided by the Linux kernel firewall "" ""(implemented as different Netfilter modules) and the chains and rules it "" ""stores. Different kernel modules and programs are currently used for "" ""different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables "" ""to ARP, and ebtables to Ethernet frames. Requires root privilege to "" ""manipulate."" msgstr """" ""Compute においてファイアウォールを作成する、arptables、ebtables、iptables と"" ""一緒に使用される。iptables は、Linux カーネルファイアウォール (別の "" ""Netfilter モジュール) により提供されるテーブル、それを保存するチェインやルー"" ""ル。複数のカーネルモジュールとプログラムが、別々のプロトコルに対して使用され"" ""る。iptables は IPv4、ip6tables は IPv6、arptables は ARP、ebtables は "" ""Ethernet フレームに適用される。操作すうために root 権限が必要になる。"" msgid """"msgid """" ""Within RabbitMQ and Compute, it is the messaging interface that is used by "" ""the scheduler service to receive capability messages from the compute, "" ""volume, and network nodes."" msgstr """" ""RabbitMQ と Compute の中で、コンピュートノード、ボリュームノード、ネットワー"" ""クノードからのメッセージを受け付ける機能のために、スケジューラーサービスによ"" ""り使用されるメッセージングインターフェース。"" ","""POT-Creation-Date: 2015-06-07 17:25+0000\n"" ""PO-Revision-Date: 2015-06-07 10:10+0000\n""",233,2
openstack%2Fopenstack-manuals~master~I89731b7f5ead5a42c1920aefe76c8c55c1777001,openstack/openstack-manuals,master,I89731b7f5ead5a42c1920aefe76c8c55c1777001,Converts ch_orchestration.xml to RST,MERGED,2015-06-09 13:44:45.000000000,2015-06-10 08:06:19.000000000,2015-06-10 08:06:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 14046}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-09 13:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/511237fbdecaf43218ef62c971ced30a70e90efb', 'message': 'Converts ch_orchestration.xml to RST\n\nChange-Id: I89731b7f5ead5a42c1920aefe76c8c55c1777001\nImplements: blueprint reorganise-user-guides\n'}, {'number': 2, 'created': '2015-06-09 13:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/38783883e3c22bc0f1f1ab3de00887d16f191305', 'message': 'Converts ch_orchestration.xml to RST\n\nChange-Id: I89731b7f5ead5a42c1920aefe76c8c55c1777001\nImplements: blueprint reorganise-user-guides\n'}, {'number': 3, 'created': '2015-06-09 15:16:30.000000000', 'files': ['doc/admin-guide-cloud-rst/source/orchestration.rst', 'doc/admin-guide-cloud-rst/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/979f7c88020c031637b6a8b6667d0274a7677764', 'message': 'Converts ch_orchestration.xml to RST\n\nChange-Id: I89731b7f5ead5a42c1920aefe76c8c55c1777001\nImplements: blueprint reorganise-user-guides\n'}]",5,189722,979f7c88020c031637b6a8b6667d0274a7677764,15,6,3,14962,,,0,"Converts ch_orchestration.xml to RST

Change-Id: I89731b7f5ead5a42c1920aefe76c8c55c1777001
Implements: blueprint reorganise-user-guides
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/22/189722/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud-rst/source/index.rst'],1,511237fbdecaf43218ef62c971ced30a70e90efb,bp/reorganise-user-guides, orchestration.rst,,1,0
openstack%2Fpython-ceilometerclient~master~I01ba4f0c0db40c95ef72dadaa34b3fafc034e417,openstack/python-ceilometerclient,master,I01ba4f0c0db40c95ef72dadaa34b3fafc034e417,Add capability for creating array of samples,MERGED,2015-05-19 12:22:25.000000000,2015-06-10 08:01:42.000000000,2015-06-10 08:01:40.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 7729}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 14347}]","[{'number': 1, 'created': '2015-05-19 12:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/e5ba2f2657c8e34f0bac6e83ea220822f9b82fd1', 'message': 'Add capability for creating array of samples\n\nAdded method for creating array of samples to samples manager.\nAdded shell command for creating array of samples.\nAdded tests for this changes.\n\nChange-Id: I01ba4f0c0db40c95ef72dadaa34b3fafc034e417\n'}, {'number': 2, 'created': '2015-05-21 08:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/1fd4747310049952a425042d2d30ef7e78a3706e', 'message': 'Add capability for creating array of samples\n\nAdded method for creating array of samples to samples manager.\nAdded shell command for creating array of samples.\nAdded tests for this changes.\nIt is made for Rally tests that use big data arrays. So now only one function may be called instead of numerous calls simple create function.\n\nChange-Id: I01ba4f0c0db40c95ef72dadaa34b3fafc034e417\n'}, {'number': 3, 'created': '2015-05-21 08:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/1d4a373fa8744eb4118b48b7446ef617b5111a5a', 'message': 'Add capability for creating array of samples\n\nAdded method for creating array of samples to samples manager.\nAdded shell command for creating array of samples.\nAdded tests for this changes.\nIt is made for Rally tests that use big data arrays. So now only one\nfunction may be called instead of numerous calls simple create function.\n\nChange-Id: I01ba4f0c0db40c95ef72dadaa34b3fafc034e417\n'}, {'number': 4, 'created': '2015-06-08 14:42:23.000000000', 'files': ['ceilometerclient/v2/samples.py', 'ceilometerclient/v2/shell.py', 'ceilometerclient/tests/unit/v2/test_samples.py', 'ceilometerclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/6add8c4fbf42be369b464489e204fea8655e2acf', 'message': 'Add capability for creating array of samples\n\nAdded method for creating array of samples to samples manager.\nAdded shell command for creating array of samples.\nAdded tests for this changes.\nIt is made for Rally tests that use big data arrays. So now only one\nfunction may be called instead of numerous calls simple create function.\n\nChange-Id: I01ba4f0c0db40c95ef72dadaa34b3fafc034e417\n'}]",0,184233,6add8c4fbf42be369b464489e204fea8655e2acf,32,8,4,14347,,,0,"Add capability for creating array of samples

Added method for creating array of samples to samples manager.
Added shell command for creating array of samples.
Added tests for this changes.
It is made for Rally tests that use big data arrays. So now only one
function may be called instead of numerous calls simple create function.

Change-Id: I01ba4f0c0db40c95ef72dadaa34b3fafc034e417
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/33/184233/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometerclient/v2/samples.py', 'ceilometerclient/v2/shell.py', 'ceilometerclient/tests/unit/v2/test_samples.py', 'ceilometerclient/tests/unit/v2/test_shell.py']",4,e5ba2f2657c8e34f0bac6e83ea220822f9b82fd1,create_sample_list,"import jsonclass ShellSampleCreateListCommandTest(utils.BaseTestCase): SAMPLE = { u'counter_name': u'image', u'user_id': u'21b442b8101d407d8242b6610e0ed0eb', u'resource_id': u'0564c64c-3545-4e34-abfb-9d18e5f2f2f9', u'timestamp': u'2015-05-19T12:00:08.368574', u'source': u'384260c6987b451d8290e66e1f108082: openstack', u'counter_unit': u'image', u'counter_volume': 1.0, u'project_id': u'384260c6987b451d8290e66e1f108082', u'resource_metadata': {}, u'counter_type': u'cumulative' } def setUp(self): super(ShellSampleCreateListCommandTest, self).setUp() self.cc = mock.Mock() self.cc.samples = mock.Mock() self.cc.samples.create_list = mock.Mock() self.args = mock.Mock() self.samples = [self.SAMPLE] * 5 self.args.samples_list = json.dumps(self.samples) @mock.patch('sys.stdout', new=six.StringIO()) def test_sample_create_list(self): ret_samples = [samples.OldSample(mock.Mock(), sample) for sample in self.samples] self.cc.samples.create_list.return_value = ret_samples ceilometer_shell.do_sample_create_list(self.cc, self.args) self.cc.samples.create_list.assert_called_with(self.samples) self.assertEqual('''\ +--------------------------------------+-------+------------+--------+-------\ +----------------------------+ | Resource ID | Name | Type | Volume | Unit \ | Timestamp | +--------------------------------------+-------+------------+--------+-------\ +----------------------------+ | 0564c64c-3545-4e34-abfb-9d18e5f2f2f9 | image | cumulative | 1.0 | image \ | 2015-05-19T12:00:08.368574 | | 0564c64c-3545-4e34-abfb-9d18e5f2f2f9 | image | cumulative | 1.0 | image \ | 2015-05-19T12:00:08.368574 | | 0564c64c-3545-4e34-abfb-9d18e5f2f2f9 | image | cumulative | 1.0 | image \ | 2015-05-19T12:00:08.368574 | | 0564c64c-3545-4e34-abfb-9d18e5f2f2f9 | image | cumulative | 1.0 | image \ | 2015-05-19T12:00:08.368574 | | 0564c64c-3545-4e34-abfb-9d18e5f2f2f9 | image | cumulative | 1.0 | image \ | 2015-05-19T12:00:08.368574 | +--------------------------------------+-------+------------+--------+-------\ +----------------------------+ ''', sys.stdout.getvalue()) ",,105,0
openstack%2Fheat-specs~master~I27f071fa1bd79038875918aa32d276c16216a729,openstack/heat-specs,master,I27f071fa1bd79038875918aa32d276c16216a729,Monasca resource plugin for Alarm and Notification,MERGED,2015-04-16 09:00:40.000000000,2015-06-10 08:01:08.000000000,2015-06-10 08:01:06.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 8246}, {'_account_id': 9542}, {'_account_id': 10068}, {'_account_id': 10487}, {'_account_id': 10511}, {'_account_id': 12259}, {'_account_id': 12404}, {'_account_id': 13323}]","[{'number': 1, 'created': '2015-04-16 09:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/29ff9c7787cec0c57e1cf5b3ec22b21e8fc69ca2', 'message': 'Support Monasca alarms and notifications\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n'}, {'number': 2, 'created': '2015-04-16 09:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/3a04eb6925c8466a780cc8f0f1184c1d25463e14', 'message': 'Support Monasca alarms and notifications\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\nSigned-off-by: Gary Duan <duanlg@live.cn>\n'}, {'number': 3, 'created': '2015-05-07 06:25:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/e26460abe00399e9e77694b51a23ce7f4e86aa0c', 'message': 'Support Monasca alarms and notifications\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\nSigned-off-by: Gary Duan <duanlg@live.cn>\n'}, {'number': 4, 'created': '2015-05-07 06:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/e7acab2c9de77e863165fe6bdfb8bef2c7476647', 'message': 'Support Monasca alarms and notifications\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\nSigned-off-by: Gary Duan <duanlg@live.cn>\n'}, {'number': 5, 'created': '2015-05-07 09:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/dba0fd8f219d1ff80170a2f33bfc13ef626f19ab', 'message': 'Monasca resource plugin for Alarm and Notification\n\nAdds following contrib resource plugins:\n- OS::Monasca::Alarm\n- OS::Monasca::Notification\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n'}, {'number': 6, 'created': '2015-05-07 11:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/cc2fb7b9fc4b503e48e7996fb7b7ee3f5e530fc4', 'message': ""Monasca resource plugin for Alarm and Notification\n\nAdds following contrib resource plugins:\n- OS::Monasca::Alarm\n- OS::Monasca::Notification\n- Custom constrain 'monasca.notification'\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n""}, {'number': 7, 'created': '2015-05-08 04:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/f6f9c9838003148301195f1d35bfbe11cdb9a230', 'message': ""Monasca resource plugin for Alarm and Notification\n\nAdds following contrib resource plugins:\n- OS::Monasca::Alarm\n- OS::Monasca::Notification\n- OS::Monasca::AlarmI\n- Custom constrain 'monasca.notification'\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n""}, {'number': 8, 'created': '2015-05-12 04:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/a2d641f59d9e9c237776705a084f5c1aae59e7eb', 'message': ""Monasca resource plugin for Alarm and Notification\n\nAdds following contrib resource plugins:\n- OS::Monasca::Alarm\n- OS::Monasca::Notification\n- OS::Monasca::AlarmI\n- Custom constrain 'monasca.notification'\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n""}, {'number': 9, 'created': '2015-05-13 01:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/076f3aff7a3cf763356860bdcc5fd6ce359472e5', 'message': ""Monasca resource plugin for Alarm and Notification\n\nAdds following contrib resource plugins:\n- OS::Monasca::Alarm\n- OS::Monasca::Notification\n- OS::Monasca::AlarmI\n- Custom constrain 'monasca.notification'\n\nblueprint support-monasca-alarm-notification\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n""}, {'number': 10, 'created': '2015-05-29 05:47:41.000000000', 'files': ['specs/liberty/heat-monasca-alarm-notification.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/d70ae63967ae5ac5e638b620ef266a3618ae597f', 'message': ""Monasca resource plugin for Alarm and Notification\n\nAdds following resource plugins:\n- OS::Monasca::Alarm\n- OS::Monasca::Notification\n- OS::Monasca::AlarmI\n- Custom constrain 'monasca.notification'\n\nblueprint support-monasca-alarm-notification\n\nChange-Id: I27f071fa1bd79038875918aa32d276c16216a729\n""}]",29,174262,d70ae63967ae5ac5e638b620ef266a3618ae597f,52,11,10,10511,,,0,"Monasca resource plugin for Alarm and Notification

Adds following resource plugins:
- OS::Monasca::Alarm
- OS::Monasca::Notification
- OS::Monasca::AlarmI
- Custom constrain 'monasca.notification'

blueprint support-monasca-alarm-notification

Change-Id: I27f071fa1bd79038875918aa32d276c16216a729
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/62/174262/9 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/support-monasca-alarm-notification.rst'],1,29ff9c7787cec0c57e1cf5b3ec22b21e8fc69ca2,bp/support-monasca-alarm-notification,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================================================== Support to create Monasca alarms and notifications =============================================================== https://blueprints.launchpad.net/heat/+spec/support-monasca-alarm-notification This Blueprint will support to create or delete Monasca alarms and notifications. Problem description =================== Monasca is an open-source multi-tenant, highly scalable, performant, fault-tolerant monitoring-as-a-service solution that integrates with OpenStack. Currently it is not possible to create Monasca resources(alarms and notifications) by launching a Heat template. Proposed change =============== This proposal is to address this problem by supporting to create or delete Monasca alarms and notifications. In order to achieve this goal, this proposal needs to implement the following items: Creates Monasca client Exposes a new resource type, OS::Monasca::Alarm, to user, which will be interpreted into Monasca operation via Heat engine. The elements of OS::Monasca::Alarm are as follows: name {type: string, required: true, update_allowed: false} description {type: string, required: false, update_allowed: true} expression {type: string, required: true, update_allowed: true} match_by {type: list, required: false, update_allowed: true} severity {type: string, required: false, update_allowed: true, constraints: {'low', 'medium', 'high', 'critical'}, default: 'low'} alarm_actions {type: list, required: false, update_allowed: true} ok_actions {type: list, required: false, update_allowed: true} undetermined_actions {type: list, required: false, update_allowed: true} Exposes a new resource type, OS::Monasca::Notification, to user, which will be interpreted into Monasca operation via Heat engine. The elements of OS::Monasca::Notification are as follows: name {type: string, required: true, update_allowed: false} type {type: string, required: true, update_allowed: true, constraints: {'email', 'webhook'}} address {type: string, required: true, update_allowed: true} Alternatives ------------ Monasca supports REST APIs and user can directly invoke Monasca REST API to create or delete Monasca alarms and notifications. None Implementation ============== Assignee(s) ----------- Primary assignee: duanlg Milestones ---------- Target Milestone for completion: Liberty-2 Work Items ---------- * Creates Monasca client for Heat. * Creates Heat engine plugin to parse Monasca alarms and notifications. * Add related tests for changes. Dependencies ============ None ",,85,0
openstack%2Fcookbook-openstack-identity~master~I5eb1aec1cbf50edb88fa75b6fd487c5ef93cac0d,openstack/cookbook-openstack-identity,master,I5eb1aec1cbf50edb88fa75b6fd487c5ef93cac0d,Check if user already exists before create_user,ABANDONED,2015-06-10 07:52:11.000000000,2015-06-10 07:55:00.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2015-06-10 07:52:11.000000000', 'files': ['spec/register_spec.rb', 'providers/register.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/0ae9b0177000a070086326f0473f3e6d2159b32e', 'message': 'Check if user already exists before create_user\n\nBefore create user, call ""keystone user-list"" command instead of\n""keystone user-list --tenant-id <tenant=id>"" command to check if user\nalready exists\n\nChange-Id: I5eb1aec1cbf50edb88fa75b6fd487c5ef93cac0d\nCloses-Bug: #1457533\n'}]",0,190054,0ae9b0177000a070086326f0473f3e6d2159b32e,3,1,1,8989,,,0,"Check if user already exists before create_user

Before create user, call ""keystone user-list"" command instead of
""keystone user-list --tenant-id <tenant=id>"" command to check if user
already exists

Change-Id: I5eb1aec1cbf50edb88fa75b6fd487c5ef93cac0d
Closes-Bug: #1457533
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/54/190054/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/register_spec.rb', 'providers/register.rb']",2,0ae9b0177000a070086326f0473f3e6d2159b32e,bug/1457533," output = identity_command(new_resource, 'user-list')"," output = identity_command(new_resource, 'user-list', 'tenant-id' => tenant_uuid)",4,8
openstack%2Fironic~master~Idd0917d237b0977fe4c4dce01c82dfe4178a40eb,openstack/ironic,master,Idd0917d237b0977fe4c4dce01c82dfe4178a40eb,Updated from global requirements,MERGED,2015-06-09 19:58:34.000000000,2015-06-10 07:53:09.000000000,2015-06-10 04:14:39.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 9751}, {'_account_id': 10343}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-06-09 19:58:34.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/08a8eae722996f67538c14a6a5c5a6cf9805341d', 'message': 'Updated from global requirements\n\nChange-Id: Idd0917d237b0977fe4c4dce01c82dfe4178a40eb\n'}]",0,189899,08a8eae722996f67538c14a6a5c5a6cf9805341d,11,5,1,11131,,,0,"Updated from global requirements

Change-Id: Idd0917d237b0977fe4c4dce01c82dfe4178a40eb
",git fetch https://review.opendev.org/openstack/ironic refs/changes/99/189899/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,08a8eae722996f67538c14a6a5c5a6cf9805341d,openstack/requirements,oslo.concurrency>=2.0.0 # Apache-2.0oslo.rootwrap>=2.0.0 # Apache-2.0,oslo.concurrency>=1.8.0 # Apache-2.0oslo.rootwrap>=1.6.0 # Apache-2.0,2,2
openstack%2Fopenstack-manuals~master~I7d23266555b181eaa2e3306921bf2bcca6323a57,openstack/openstack-manuals,master,I7d23266555b181eaa2e3306921bf2bcca6323a57,Imported Translations from Transifex,MERGED,2015-06-10 06:15:03.000000000,2015-06-10 07:52:57.000000000,2015-06-10 07:52:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-10 06:15:03.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/install-guide/locale/zh_CN.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/user-guide-admin/source/locale/user-guide-admin.pot', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/user-guide-admin.po', 'doc/glossary/locale/vi_VN.po', 'doc/common/locale/common.pot', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ae1c5406ee4687fd60217326bba20aeada46daed', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I7d23266555b181eaa2e3306921bf2bcca6323a57\n'}]",0,190035,ae1c5406ee4687fd60217326bba20aeada46daed,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I7d23266555b181eaa2e3306921bf2bcca6323a57
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/35/190035/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/config-reference/locale/config-reference.pot', 'doc/install-guide/locale/zh_CN.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/user-guide-admin/source/locale/user-guide-admin.pot', 'doc/glossary/locale/vi_VN.po', 'doc/user-guide-admin/source/locale/ja/LC_MESSAGES/user-guide-admin.po', 'doc/common/locale/common.pot', 'doc/glossary/locale/ja.po']",9,ae1c5406ee4687fd60217326bba20aeada46daed,transifex/translations,"""POT-Creation-Date: 2015-06-10 05:08+0000\n"" ""PO-Revision-Date: 2015-06-10 05:38+0000\n""""A number within a database that is incremented each time a change is made. "" ""Used by Object Storage when replicating."" msgstr """" ""変更が行われる度に増加するデータベース内の数値。Object Storage が複製を行う際"" ""に使用する。"" msgid """"msgid """" ""A personality that a user assumes to perform a specific set of operations. A "" ""role includes a set of rights and privileges. A user assuming that role "" ""inherits those rights and privileges."" msgstr """" ""ユーザーが特定の操作の組を実行すると仮定する人格。ロールは一組の権利と権限を"" ""含みます。そのロールを仮定しているユーザーは、それらの権利と権限を継承しま"" ""す。"" ""A process that is created when a RPC call is executed; used to push the "" ""message to the topic exchange."" msgstr """" ""RPC コールが実行されるときに作成されるプロセス。メッセージをトピック交換者に"" ""プッシュするために使用される。"" msgid """"""A routing table that is created within the Compute RabbitMQ during RPC "" ""calls; one is created for each RPC call that is invoked."" msgstr """" ""RPC コール中に Compute RabbitMQ 内で作成されるルーティングテーブル。関連する"" ""各 RPC コールに対して作成されるもの。"" msgid """"""An IP address that is associated with the same instance each time that "" ""instance boots, is generally not accessible to end users or the public "" ""Internet, and is used for management of the instance."" msgstr """" ""インスタンス起動時に毎回同じインスタンスに割当られるIPアドレス（一般に、エン"" ""ドユーザやパブリックインターネットからはアクセス出来ない）。インスタンスの管"" ""理に使用される。"" msgid """"msgid """" ""An element of the Compute capacity cache that is calculated based on the "" ""number of build, snapshot, migrate, and resize operations currently in "" ""progress on a given host."" msgstr """" ""指定されたホスト上で現在進行中の build, snapshot, migrate, resize の操作数を"" ""元に計算される、Compute のキャパシティキャッシュの１要素。"" msgid """" ""An entity that maps Object Storage data to partitions. A separate ring "" ""exists for each service, such as account, object, and container."" msgstr """" ""Object Storage データのパーティションへのマッピングを行う。アカウント、オブ"" ""ジェクト、コンテナーというサービス単位に別々のリングが存在する。"" msgid ""Bare metal service"" msgstr ""Bare metal service"" msgid """" ""Builds and manages rings within Object Storage, assigns partitions to "" ""devices, and pushes the configuration to other storage nodes."" msgstr """" ""Object Storage のリングの作成、管理を行い、パーティションのデバイスへの割り当"" ""てを行い、他のストレージノードに設定を転送する。"" msgid """" ""Describes the parameters of the various virtual machine images that are "" ""available to users; includes parameters such as CPU, storage, and memory. "" ""Alternative term for flavor."" msgstr """" ""ユーザが利用可能な様々な仮想マシンイメージのパラメーター（CPU、ストレージ、メ"" ""モリ等を含む）を示す。フレーバーの別名。"" msgid """" ""Extension to iptables that allows creation of firewall rules that match "" ""entire \""sets\"" of IP addresses simultaneously. These sets reside in indexed "" ""data structures to increase efficiency, particularly on systems with a large "" ""quantity of rules."" msgstr """" ""連続する IP アドレスの全体に一致するファイアウォールルールを作成できる、"" ""iptables の拡張。これらのセットは、効率化するためにインデックス化されたデータ"" ""構造、とくに大量のルールを持つシステムにあります。"" ""Generally, extra properties on an Image service image to which only cloud "" ""administrators have access. Limits which user roles can perform CRUD "" ""operations on that property. The cloud administrator can configure any image "" ""property as protected."" msgstr """" ""クラウド管理者のみがアクセスできる、Image service のイメージの追加プロパ"" ""ティー。どのユーザーロールがそのプロパティーにおいて CRUD 操作を実行できるか"" ""を制限する。クラウド管理者は、保護されたイメージのプロパティーをすべて設定で"" ""きる。"" msgid """"msgid ""Governance service"" msgstr ""Governance service"" ""If Object Storage finds objects, containers, or accounts that are corrupt, "" ""they are placed in this state, are not replicated, cannot be read by "" ""clients, and a correct copy is re-replicated."" msgstr """" ""Object Storage が壊れたオブジェクト、コンテナー、アカウントを見つけた際に、そ"" ""のデータはこの状態にセットされる。この状態にセットされたデータは、複製され"" ""ず、クライアントが読み出すこともできなくなり、正しいコピーが再複製される。"" msgid """"""In Object Storage, tools to test and ensure dispersion of objects and "" ""containers to ensure fault tolerance."" msgstr """" ""Object Storage で、フォールトトレラントの確認の為に、オブジェクトとコンテナ"" ""の分散をテスト、確認するツール。"" msgid """"msgid ""Key-Value Store as a Service"" msgstr ""Key-Value Store as a Service"" msgid """" ""Modular system that allows the underlying message queue software of Compute "" ""to be changed. For example, from RabbitMQ to ZeroMQ or Qpid."" msgstr """" ""Compute が利用するメッセージキューソフトウェアを変更できるようにする仕組み。"" ""例えば、 RabbitMQ を ZeroMQ や Qpid に変更できる。"" msgid """" ""OpenStack project that provides a Key-Value Store as a Service for OpenStack "" ""users."" msgstr """" ""OpenStack ユーザーに Key-Value Store as a Service を提供する OpenStack のプロ"" ""ジェクト。"" msgid """" ""OpenStack project that provides a scalable data-processing stack and "" ""associated management interfaces. The code name for the project is sahara."" msgstr """" ""スケールアウト可能なデータ処理基盤と関連する管理インターフェースを提供する、"" ""OpenStack のプロジェクト。プロジェクトのコード名は sahara です。"" msgid """" ""OpenStack project that provides a set of services for management of "" ""application containers in a multi-tenant cloud environment. The code name of "" ""the project name is magnum."" msgstr """" ""マルチテナントクラウド環境において、アプリケーションコンテナーの管理サービス"" ""を提供する、OpenStack のプロジェクト。プロジェクトのコード名は magnum です。"" msgid ""OpenStack project that provides an Application catalog."" msgstr ""アプリケーションカタログを提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides shared file systems as service to "" ""applications."" msgstr """" ""共有ファイルシステムをアプリケーションに提供する OpenStack のプロジェクト。"" msgid ""OpenStack project that provides the Benchmark service."" msgstr ""Benchmark service を提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides the Governance service."" msgstr ""Governance service を提供する OpenStack プロジェクト。"" msgid """" ""OpenStack project that provisions bare metal, as opposed to virtual, "" ""machines. The code name for the project is ironic."" msgstr """" ""マシンを仮想とみなして、ベアメタルに展開する OpenStack のプロジェクト。このプ"" ""ロジェクトのコード名は ironic です。"" msgid """" ""Organizes and stores objects in Object Storage. Similar to the concept of a "" ""Linux directory but cannot be nested. Alternative term for an Image service "" ""container format."" msgstr """" ""Object Storage でオブジェクトを整理して保存する。Linux のディレクトリと似てい"" ""るが、入れ子にできない。Image service のコンテナー形式の別名。"" msgid """" ""Provides data redundancy and fault tolerance by creating copies of Object "" ""Storage objects, accounts, and containers so that they are not lost when the "" ""underlying storage fails."" msgstr """" ""Object Storage のオブジェクト、アカウント、コンテナーのコピーを作成すること"" ""で、データ冗長性や耐障害性を実現する。これにより、バックエンドのストレージが"" ""故障した場合でもデータは失わない。"" msgid """" ""Provides logical partitioning of Compute resources in a child and parent "" ""relationship. Requests are passed from parent cells to child cells if the "" ""parent cannot provide the requested resource."" msgstr """" ""親子関係で Compute リソースの論理パーティションを提供する。親セルが要求された"" ""リソースを提供できない場合、親セルからのリクエストは子セルに渡される。"" msgid """" ""Setting for the Compute RabbitMQ message delivery mode; can be set to either "" ""transient or persistent."" msgstr """" ""Compute RabbitMQ メッセージ配信モード用設定。transient（一時）又は persistent"" ""（永続）のいずれかを設定できる。"" msgid """" ""The code name for the twelfth release of OpenStack. The design summit will "" ""take place in Vancouver, Canada and Liberty is the name of a village in the "" ""Canadian province of Saskatchewan."" msgstr """" ""OpenStack の 12 番目のリリースのコード名。デザインサミットは、カナダのバン"" ""クーバーで開催された。Liberty は、サスカチュワン州にある村の名前。"" ""Used along with arptables and ebtables, iptables create firewalls in "" ""Compute. iptables are the tables provided by the Linux kernel firewall "" ""(implemented as different Netfilter modules) and the chains and rules it "" ""stores. Different kernel modules and programs are currently used for "" ""different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables "" ""to ARP, and ebtables to Ethernet frames. Requires root privilege to "" ""manipulate."" msgstr """" ""Compute においてファイアウォールを作成する、arptables、ebtables、iptables と"" ""一緒に使用される。iptables は、Linux カーネルファイアウォール (別の "" ""Netfilter モジュール) により提供されるテーブル、それを保存するチェインやルー"" ""ル。複数のカーネルモジュールとプログラムが、別々のプロトコルに対して使用され"" ""る。iptables は IPv4、ip6tables は IPv6、arptables は ARP、ebtables は "" ""Ethernet フレームに適用される。操作すうために root 権限が必要になる。"" msgid """"msgid """" ""Within RabbitMQ and Compute, it is the messaging interface that is used by "" ""the scheduler service to receive capability messages from the compute, "" ""volume, and network nodes."" msgstr """" ""RabbitMQ と Compute の中で、コンピュートノード、ボリュームノード、ネットワー"" ""クノードからのメッセージを受け付ける機能のために、スケジューラーサービスによ"" ""り使用されるメッセージングインターフェース。"" ","""POT-Creation-Date: 2015-06-07 17:25+0000\n"" ""PO-Revision-Date: 2015-06-07 10:10+0000\n""",2029,56
openstack%2Fopenstack-ansible~master~I57f78dac8b433f4bab5f7865326329a5e9474073,openstack/openstack-ansible,master,I57f78dac8b433f4bab5f7865326329a5e9474073,Use latest version of python-cinderclient,ABANDONED,2015-06-09 17:11:29.000000000,2015-06-10 07:48:37.000000000,,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-09 17:11:29.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_clients.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9f5ff0a4702e50c7e685d8c5ef105799c822fde3', 'message': 'Use latest version of python-cinderclient\n\nPre v1.2.2 of python-cinderclient a bug was introduced that meant\ncinderclient was not using the ""endpoint-type"" option.\n\nBumping this to 1.2.2 ensures endpoint-type will work again for cinder.\n\nChange-Id: I57f78dac8b433f4bab5f7865326329a5e9474073\nCloses-Bug: #1463493\n'}]",0,189817,9f5ff0a4702e50c7e685d8c5ef105799c822fde3,8,4,1,2799,,,0,"Use latest version of python-cinderclient

Pre v1.2.2 of python-cinderclient a bug was introduced that meant
cinderclient was not using the ""endpoint-type"" option.

Bumping this to 1.2.2 ensures endpoint-type will work again for cinder.

Change-Id: I57f78dac8b433f4bab5f7865326329a5e9474073
Closes-Bug: #1463493
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/17/189817/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_clients.yml'],1,9f5ff0a4702e50c7e685d8c5ef105799c822fde3,bug/1463493,cinderclient_git_install_branch: 1.2.2,cinderclient_git_install_branch: 1.2.1,1,1
openstack%2Fgovernance~master~I3be126b424f8e4da533b7a79b1b749d11f31bdeb,openstack/governance,master,I3be126b424f8e4da533b7a79b1b749d11f31bdeb,Add manila-image-elements to manila,MERGED,2015-06-03 11:29:39.000000000,2015-06-10 07:38:25.000000000,2015-06-10 07:38:24.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2417}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11865}]","[{'number': 1, 'created': '2015-06-03 11:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/462275e3c4c6b345f3797b8a8a4d7d256e0af919', 'message': 'Add manila-image to manila\n\nThis adds the manila-image as a subproject of manila.\n\nChange-Id: I3be126b424f8e4da533b7a79b1b749d11f31bdeb\n'}, {'number': 2, 'created': '2015-06-03 13:49:38.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/5d026d9c88f8c4fe15d85add6c072d04a4edc450', 'message': 'Add manila-image-elements to manila\n\nThis adds the manila-image-elements as a subproject of manila.\n\nChange-Id: I3be126b424f8e4da533b7a79b1b749d11f31bdeb\n'}]",0,187952,5d026d9c88f8c4fe15d85add6c072d04a4edc450,16,11,2,14232,,,0,"Add manila-image-elements to manila

This adds the manila-image-elements as a subproject of manila.

Change-Id: I3be126b424f8e4da533b7a79b1b749d11f31bdeb
",git fetch https://review.opendev.org/openstack/governance refs/changes/52/187952/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,462275e3c4c6b345f3797b8a8a4d7d256e0af919,, - repo: openstack/manila-image tags: - name: release:independent,,3,0
openstack%2Fgovernance~master~If6dbd44266b95a189cd1746bfb245cf1c31616d0,openstack/governance,master,If6dbd44266b95a189cd1746bfb245cf1c31616d0,Add a reference for User Committee repos,MERGED,2015-06-02 20:39:30.000000000,2015-06-10 07:38:16.000000000,2015-06-10 07:38:16.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-06-02 20:39:30.000000000', 'files': ['reference/user-committee-repos.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/405f6f5fb8896e6b64c0412b9324409c1df9d651', 'message': ""Add a reference for User Committee repos\n\nCurrently the User Committee doesn't have a place to track the\nrepos it owns. This patch adds a yaml file to track User\nCommittee repos.\n\nA User Committee repo was created prior to this patch and is\ncurrently in stackforge. The repo will be renamed to live in\nthe openstack/ namespace and the contents of this yaml file\nwill be updated to reflect its location when it changes.\n\nChange-Id: If6dbd44266b95a189cd1746bfb245cf1c31616d0\nReference: https://review.openstack.org/#/c/185106/\n""}]",0,187767,405f6f5fb8896e6b64c0412b9324409c1df9d651,11,5,1,6316,,,0,"Add a reference for User Committee repos

Currently the User Committee doesn't have a place to track the
repos it owns. This patch adds a yaml file to track User
Committee repos.

A User Committee repo was created prior to this patch and is
currently in stackforge. The repo will be renamed to live in
the openstack/ namespace and the contents of this yaml file
will be updated to reflect its location when it changes.

Change-Id: If6dbd44266b95a189cd1746bfb245cf1c31616d0
Reference: https://review.openstack.org/#/c/185106/
",git fetch https://review.opendev.org/openstack/governance refs/changes/67/187767/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/user-committee-repos.yaml'],1,405f6f5fb8896e6b64c0412b9324409c1df9d651,,# List of repositories owned by the User Committee and subcommittees Ops Tags Team: - repo: stackforge/ops-tags-team ,,3,0
openstack%2Fneutron~master~I69e520148633c8f1ec1be019ec83f06f11b84060,openstack/neutron,master,I69e520148633c8f1ec1be019ec83f06f11b84060,Merge tag '2015.1.0',MERGED,2015-04-30 23:23:21.000000000,2015-06-10 07:37:56.000000000,2015-06-10 07:37:53.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5263}, {'_account_id': 6609}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-04-30 23:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc9cea13a31f923bc28b7d02c532fe12cf86300c', 'message': ""Merge tag '2015.1.0'\n\nNeutron 2015.1.0\n\nChange-Id: I69e520148633c8f1ec1be019ec83f06f11b84060\n""}, {'number': 2, 'created': '2015-06-09 17:48:41.000000000', 'files': ['neutron/locale/neutron-log-error.pot', '.gitreview', 'neutron/db/db_base_plugin_v2.py', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'requirements.txt', 'neutron/locale/neutron.pot', 'neutron/agent/linux/ipset_manager.py', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/tests/unit/scheduler/test_l3_agent_scheduler.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/tests/unit/agent/test_securitygroups_rpc.py', 'neutron/tests/unit/plugins/ml2/test_rpc.py', 'neutron/tests/unit/agent/linux/test_ipset_manager.py', 'setup.cfg', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8a09568b5bde8b71ad00468c27b757c98d9c0da', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I69e520148633c8f1ec1be019ec83f06f11b84060\n""}]",2,179286,b8a09568b5bde8b71ad00468c27b757c98d9c0da,74,33,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I69e520148633c8f1ec1be019ec83f06f11b84060
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/179286/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', '.gitreview', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/scheduler/test_l3_agent_scheduler.py', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/tests/unit/plugins/ml2/test_plugin.py', 'requirements.txt', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/agent/linux/ipset_manager.py', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po']",18,bc9cea13a31f923bc28b7d02c532fe12cf86300c,merge/release-tag,,"<<<<<<< HEAD (8c7bc3 Merge ""Disembowel register_l3_agent code duplication in test)======= >>>>>>> BRANCH (7260e0 Run radvd as root)",6,636
openstack%2Fgovernance~master~If7e812dd03285fdcb50ea220bfdcc7450803a221,openstack/governance,master,If7e812dd03285fdcb50ea220bfdcc7450803a221,Add networking-midonet repo to Neutron,MERGED,2015-06-02 08:27:08.000000000,2015-06-10 07:35:52.000000000,2015-06-10 07:35:52.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 6598}]","[{'number': 1, 'created': '2015-06-02 08:27:08.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/cf3fb6f84926ed9b84166fe7bf6957b9ab085042', 'message': 'Add networking-midonet repo to Neutron\n\nAccording to procedure defined in [1], this patch proposes Neutron\nto embrace networking-midonet within its fold. This project provides\nNeutron support for MidoNet. [2]\n\nFor more information on networking-midonet:\n    https://github.com/stackforge/networking-midonet\n\n[1] https://github.com/openstack/neutron/blob/master/doc/source/devref/sub_projects.rst\n[2] http://midonet.org/\n\nChange-Id: If7e812dd03285fdcb50ea220bfdcc7450803a221\n'}]",0,187494,cf3fb6f84926ed9b84166fe7bf6957b9ab085042,15,8,1,6854,,,0,"Add networking-midonet repo to Neutron

According to procedure defined in [1], this patch proposes Neutron
to embrace networking-midonet within its fold. This project provides
Neutron support for MidoNet. [2]

For more information on networking-midonet:
    https://github.com/stackforge/networking-midonet

[1] https://github.com/openstack/neutron/blob/master/doc/source/devref/sub_projects.rst
[2] http://midonet.org/

Change-Id: If7e812dd03285fdcb50ea220bfdcc7450803a221
",git fetch https://review.opendev.org/openstack/governance refs/changes/94/187494/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,cf3fb6f84926ed9b84166fe7bf6957b9ab085042,networking-midonet, - repo: openstack/networking-midonet tags: - name: release:independent,,3,0
openstack%2Fgovernance~master~Iaae173a301e8ea64a4271f0f49349363ac3a9553,openstack/governance,master,Iaae173a301e8ea64a4271f0f49349363ac3a9553,Add puppet-stackalytics to infra,MERGED,2015-06-02 15:48:59.000000000,2015-06-10 07:35:51.000000000,2015-06-10 07:35:49.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1561}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 5263}, {'_account_id': 16051}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-02 15:48:59.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/a9a10342209db87fdc68a59dac39857934afd7e7', 'message': 'Add puppet-stackalytics to infra\n\nChange-Id: Iaae173a301e8ea64a4271f0f49349363ac3a9553\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,187645,a9a10342209db87fdc68a59dac39857934afd7e7,16,9,1,4162,,,0,"Add puppet-stackalytics to infra

Change-Id: Iaae173a301e8ea64a4271f0f49349363ac3a9553
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/45/187645/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,a9a10342209db87fdc68a59dac39857934afd7e7,puppet-stackalytics, - repo: openstack-infra/puppet-stackalytics,,1,0
openstack%2Frequirements~master~I06281979b42b72b26d2cdcfbcb12affadd490a4e,openstack/requirements,master,I06281979b42b72b26d2cdcfbcb12affadd490a4e,Add babel-django plugin for Horizon,ABANDONED,2015-06-10 07:25:22.000000000,2015-06-10 07:32:07.000000000,,[{'_account_id': 10881}],"[{'number': 1, 'created': '2015-06-10 07:25:22.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fbfac614f791985da59390d66d78b82c2b3f5b32', 'message': ""Add babel-django plugin for Horizon\n\nHorizon is migrating to babel to allow translation of AngularJS\nbased pages.\n\nRather than use a mix of Django's builtin i18n and babel Horizon\nwill also use the babel-django plugin for legacy i18n.\n\nbabel-django is available on the cheeseshop but will require\npackaging.\n\nIt is in active maintenance (last updated 2015-04-22 for the Django\n1.8 release).\n\nLicense is BSD\n\nHaving this package available will simplify translation for\nHorizon's new AngularJS based components and mean that Horizon is\nmore closely in line with other projects' i18n processes.\n\nChange-Id: I06281979b42b72b26d2cdcfbcb12affadd490a4e\n""}]",0,190050,fbfac614f791985da59390d66d78b82c2b3f5b32,3,1,1,10881,,,0,"Add babel-django plugin for Horizon

Horizon is migrating to babel to allow translation of AngularJS
based pages.

Rather than use a mix of Django's builtin i18n and babel Horizon
will also use the babel-django plugin for legacy i18n.

babel-django is available on the cheeseshop but will require
packaging.

It is in active maintenance (last updated 2015-04-22 for the Django
1.8 release).

License is BSD

Having this package available will simplify translation for
Horizon's new AngularJS based components and mean that Horizon is
more closely in line with other projects' i18n processes.

Change-Id: I06281979b42b72b26d2cdcfbcb12affadd490a4e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/50/190050/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,fbfac614f791985da59390d66d78b82c2b3f5b32,babel-django,babel-django>=0.4.0,,1,0
openstack%2Fopenstack-ansible~master~I4b357ff7099a4c1c63c85ac9560aefc8d56709be,openstack/openstack-ansible,master,I4b357ff7099a4c1c63c85ac9560aefc8d56709be,Updated upgrade and deployment processes for https,MERGED,2015-06-08 20:41:41.000000000,2015-06-10 07:23:26.000000000,2015-06-10 03:33:09.000000000,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2015-06-08 20:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/29ff0af527ade6c28a9313d91d12fa12ef4ded4c', 'message': ""Updated upgrade and deployment processes for https\n\nThis change simply makes sure that all containers and hosts have the\n`apt-transport-https` package installed. this package is absolutly\nrequired everywhere because we've changed all of the repo endpoints\nto https and not all systems have this package installed on a base\nkick. Furthermore an entry was added into the upgrade script to\nensure that upon upgrade everything will converge and remain\nconsistent.\n\nChange-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be\nCloses-Bug: #1463155\n""}, {'number': 2, 'created': '2015-06-09 04:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1e915a0d3dc01e8c20d45d242edbb4a87a0cdecb', 'message': ""Updated upgrade and deployment processes for https\n\nThis change simply makes sure that all containers and hosts have the\n`apt-transport-https` package installed. this package is absolutly\nrequired everywhere because we've changed all of the repo endpoints\nto https and not all systems have this package installed on a base\nkick. Furthermore an entry was added into the upgrade script to\nensure that upon upgrade everything will converge and remain\nconsistent.\n\nChange-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be\nCloses-Bug: #1463155\n""}, {'number': 3, 'created': '2015-06-09 05:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b109649bfd4e460bbd712dab1c236cc961eb02aa', 'message': ""Updated upgrade and deployment processes for https\n\nThis change simply makes sure that all containers and hosts have the\n`apt-transport-https` package installed. this package is absolutly\nrequired everywhere because we've changed all of the repo endpoints\nto https and not all systems have this package installed on a base\nkick. Furthermore an entry was added into the upgrade script to\nensure that upon upgrade everything will converge and remain\nconsistent.\n\nChange-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be\nCloses-Bug: #1463155\n""}, {'number': 4, 'created': '2015-06-10 01:58:31.000000000', 'files': ['playbooks/roles/openstack_hosts/defaults/main.yml', 'scripts/run-upgrade.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8bcaac5702f3ed29d74a3f49690cf2d6e3655828', 'message': ""Updated upgrade and deployment processes for https\n\nThis change simply makes sure that all containers and hosts have the\n`apt-transport-https` package installed. this package is absolutly\nrequired everywhere because we've changed all of the repo endpoints\nto https and not all systems have this package installed on a base\nkick. Furthermore an entry was added into the upgrade script to\nensure that upon upgrade everything will converge and remain\nconsistent.\n\nChange-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be\nCloses-Bug: #1463155\n""}]",0,189435,8bcaac5702f3ed29d74a3f49690cf2d6e3655828,34,5,4,7353,,,0,"Updated upgrade and deployment processes for https

This change simply makes sure that all containers and hosts have the
`apt-transport-https` package installed. this package is absolutly
required everywhere because we've changed all of the repo endpoints
to https and not all systems have this package installed on a base
kick. Furthermore an entry was added into the upgrade script to
ensure that upon upgrade everything will converge and remain
consistent.

Change-Id: I4b357ff7099a4c1c63c85ac9560aefc8d56709be
Closes-Bug: #1463155
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/35/189435/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/openstack_hosts/defaults/main.yml', 'playbooks/roles/lxc_container_create/defaults/main.yml', 'scripts/run-upgrade.sh']",3,29ff0af527ade6c28a9313d91d12fa12ef4ded4c,bug/1463155," # Ensure that apt-transport-https is installed everywhere before doing anything else. ansible ""hosts:all_containers"" \ -m shell \ -a ""apt-get update && apt-get install -y apt-transport-https"" ",,9,0
openstack%2Fkeystone~master~I4de3eead9851a5ab2d0f1ecba41a4541cbcf801b,openstack/keystone,master,I4de3eead9851a5ab2d0f1ecba41a4541cbcf801b,Updated from global requirements,MERGED,2015-06-09 19:58:53.000000000,2015-06-10 07:22:26.000000000,2015-06-10 07:22:24.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 6486}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-06-09 19:58:53.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6a917f0ea658e0f58a6bc04b5f35ff1103457b3b', 'message': 'Updated from global requirements\n\nChange-Id: I4de3eead9851a5ab2d0f1ecba41a4541cbcf801b\n'}]",0,189901,6a917f0ea658e0f58a6bc04b5f35ff1103457b3b,8,5,1,11131,,,0,"Updated from global requirements

Change-Id: I4de3eead9851a5ab2d0f1ecba41a4541cbcf801b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/01/189901/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,6a917f0ea658e0f58a6bc04b5f35ff1103457b3b,openstack/requirements,"oslo.concurrency>=2.0.0 # Apache-2.0oslo.middleware>=1.2.0,!=2.0.0 # Apache-2.0",oslo.concurrency>=1.8.0 # Apache-2.0oslo.middleware>=1.2.0 # Apache-2.0,4,4
openstack%2Ftempest~master~I3fdfa1101b966015798a61aa6ba5acfdf4649831,openstack/tempest,master,I3fdfa1101b966015798a61aa6ba5acfdf4649831,Apply a naming rule of GET to compute clients(f*),MERGED,2015-05-22 20:42:45.000000000,2015-06-10 07:22:20.000000000,2015-06-10 07:22:17.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-05-22 20:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2c5aa688d112ac6095712345e02f7fe1d779a962', 'message': 'Apply a naming rule of GET to compute clients(f*)\n\n[GET /resources] methods should be ""list_<resource name>s""\nor ""show_<resource name>"", so this patch applies the rule\nto compute clients which names are ""f*"".\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I3fdfa1101b966015798a61aa6ba5acfdf4649831\n'}, {'number': 2, 'created': '2015-06-08 05:32:33.000000000', 'files': ['tempest/api/compute/servers/test_create_server.py', 'tempest/stress/actions/ssh_floating.py', 'tempest/api/compute/admin/test_flavors_extra_specs.py', 'tempest/api/compute/admin/test_fixed_ips_negative.py', 'tempest/scenario/test_baremetal_basic_ops.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/scenario/utils.py', 'tempest/api/compute/admin/test_flavors_extra_specs_negative.py', 'tempest/api/compute/admin/test_servers_negative.py', 'tempest/api/compute/flavors/test_flavors.py', 'tempest/api/compute/floating_ips/test_list_floating_ips_negative.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions.py', 'tempest/services/compute/json/floating_ips_client.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/services/compute/json/fixed_ips_client.py', 'tempest/api/compute/images/test_images_oneserver.py', 'tempest/stress/actions/volume_attach_verify.py', 'tempest/api/compute/floating_ips/test_list_floating_ips.py', 'tempest/api/compute/admin/test_flavors.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5628f3f8bde588990499e88a8e344eac89322493', 'message': 'Apply a naming rule of GET to compute clients(f*)\n\n[GET /resources] methods should be ""list_<resource name>s""\nor ""show_<resource name>"", so this patch applies the rule\nto compute clients which names are ""f*"".\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I3fdfa1101b966015798a61aa6ba5acfdf4649831\n'}]",3,185137,5628f3f8bde588990499e88a8e344eac89322493,20,6,2,6167,,,0,"Apply a naming rule of GET to compute clients(f*)

[GET /resources] methods should be ""list_<resource name>s""
or ""show_<resource name>"", so this patch applies the rule
to compute clients which names are ""f*"".

Partially implements blueprint consistent-service-method-names

Change-Id: I3fdfa1101b966015798a61aa6ba5acfdf4649831
",git fetch https://review.opendev.org/openstack/tempest refs/changes/37/185137/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_create_server.py', 'tempest/stress/actions/ssh_floating.py', 'tempest/api/compute/admin/test_flavors_extra_specs.py', 'tempest/api/compute/admin/test_fixed_ips_negative.py', 'tempest/scenario/test_baremetal_basic_ops.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/scenario/utils.py', 'tempest/api/compute/admin/test_flavors_extra_specs_negative.py', 'tempest/api/compute/admin/test_servers_negative.py', 'tempest/api/compute/flavors/test_flavors.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions.py', 'tempest/services/compute/json/floating_ips_client.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/services/compute/json/fixed_ips_client.py', 'tempest/api/compute/images/test_images_oneserver.py', 'tempest/stress/actions/volume_attach_verify.py', 'tempest/api/compute/floating_ips/test_list_floating_ips.py', 'tempest/api/compute/admin/test_flavors.py']",18,2c5aa688d112ac6095712345e02f7fe1d779a962,bp/consistent-service-method-names, flavor = self.client.show_flavor(flavor['id']) flavor = self.client.show_flavor(new_flavor_id), flavor = self.client.get_flavor_details(flavor['id']) flavor = self.client.get_flavor_details(new_flavor_id),35,35
openstack%2Fpython-openstackclient~master~I6d662ce8daafd7576504d70487187b764f916013,openstack/python-openstackclient,master,I6d662ce8daafd7576504d70487187b764f916013,telemetry: add support for alarm creation,ABANDONED,2015-02-13 17:02:10.000000000,2015-06-10 07:21:47.000000000,,"[{'_account_id': 3}, {'_account_id': 595}, {'_account_id': 970}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 4715}, {'_account_id': 6482}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 8052}, {'_account_id': 8736}, {'_account_id': 9562}]","[{'number': 1, 'created': '2015-02-13 17:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6c879528ad03c97b32d8a62accd85f2387e1da7c', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}, {'number': 2, 'created': '2015-02-14 08:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/12d52bdbe129e8f2435ef7a6995df951fdfda1ab', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}, {'number': 3, 'created': '2015-02-16 14:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8a54e176ffd9ffa2e829ed43e9c15e98d8088deb', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}, {'number': 4, 'created': '2015-03-03 12:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aac330451ceb26fea0bbff2c715c63e9737bfbb6', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}, {'number': 5, 'created': '2015-03-03 14:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3d465fb5d2c70c62e87dd4caa8ea493b4487bbbe', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}, {'number': 6, 'created': '2015-03-03 16:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/510598e0ecefb71d49923cec9ba8b9f24cfef094', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}, {'number': 7, 'created': '2015-03-04 13:35:50.000000000', 'files': ['requirements.txt', 'openstackclient/telemetry/client.py', 'openstackclient/telemetry/v2/alarm.py', 'setup.cfg', 'doc/source/command-objects/alarm.rst', 'openstackclient/telemetry/__init__.py', 'openstackclient/telemetry/v2/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b46d7af1302026c4fc55661a9c7e0760bcf76018', 'message': 'telemetry: add support for alarm creation\n\nThis adds a first telemetry operation which is alarm creation, using\nopenstacksdk.\n\nChange-Id: I6d662ce8daafd7576504d70487187b764f916013\n'}]",7,155822,b46d7af1302026c4fc55661a9c7e0760bcf76018,25,16,7,1669,,,0,"telemetry: add support for alarm creation

This adds a first telemetry operation which is alarm creation, using
openstacksdk.

Change-Id: I6d662ce8daafd7576504d70487187b764f916013
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/22/155822/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'openstackclient/telemetry/client.py', 'openstackclient/telemetry/v2/alarm.py', 'setup.cfg', 'openstackclient/telemetry/__init__.py', 'openstackclient/telemetry/v2/__init__.py']",6,6c879528ad03c97b32d8a62accd85f2387e1da7c,jd/openstacksdk,,,152,0
openstack%2Ffuel-qa~stable%2F6.1~I59adbf00b6065c4e0dfc153d9a45a64afc513a53,openstack/fuel-qa,stable/6.1,I59adbf00b6065c4e0dfc153d9a45a64afc513a53,"Revert ""Use timeout varibale for assert_task_success""",MERGED,2015-06-10 06:46:37.000000000,2015-06-10 07:13:56.000000000,2015-06-10 07:13:56.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}]","[{'number': 1, 'created': '2015-06-10 06:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/92f40dd04543170d355ffd8949c672584c4d81d9', 'message': 'Revert ""Use timeout varibale for assert_task_success""\n\nThis reverts commit 754044b3abdad7575f0859dd9db231a1a9536f16.\n\nChange-Id: I59adbf00b6065c4e0dfc153d9a45a64afc513a53\n'}, {'number': 2, 'created': '2015-06-10 06:57:15.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/39c983a390f5a8daaa173dddef8c639510f1537e', 'message': 'Revert ""Use timeout varibale for assert_task_success""\n\nThis reverts commit 754044b3abdad7575f0859dd9db231a1a9536f16.\n\nCloses-bug: #1463601\nChange-Id: I59adbf00b6065c4e0dfc153d9a45a64afc513a53\n'}]",0,190040,39c983a390f5a8daaa173dddef8c639510f1537e,15,4,2,8882,,,0,"Revert ""Use timeout varibale for assert_task_success""

This reverts commit 754044b3abdad7575f0859dd9db231a1a9536f16.

Closes-bug: #1463601
Change-Id: I59adbf00b6065c4e0dfc153d9a45a64afc513a53
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/40/190040/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,92f40dd04543170d355ffd8949c672584c4d81d9,," self.assert_task_success(task, interval=interval)"," self.assert_task_success(task, timeout=timeout, interval=interval)",1,1
openstack%2Ftrove~master~I2cf1e60c1c1633885c683c1f8eedb44882e8b276,openstack/trove,master,I2cf1e60c1c1633885c683c1f8eedb44882e8b276,Updated from global requirements,MERGED,2015-06-08 21:21:06.000000000,2015-06-10 07:06:40.000000000,2015-06-10 07:06:38.000000000,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 10215}]","[{'number': 1, 'created': '2015-06-08 21:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f40e330d578cfab984f66b8e1c39273fe631c5ad', 'message': 'Updated from global requirements\n\nChange-Id: I2cf1e60c1c1633885c683c1f8eedb44882e8b276\n'}, {'number': 2, 'created': '2015-06-08 23:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7395c5fbcef9bd7c901127dab99b9a5382704161', 'message': 'Updated from global requirements\n\nChange-Id: I2cf1e60c1c1633885c683c1f8eedb44882e8b276\n'}, {'number': 3, 'created': '2015-06-09 20:05:52.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/66a1c8990905563179bf3f0513f962f1ed4387f0', 'message': 'Updated from global requirements\n\nChange-Id: I2cf1e60c1c1633885c683c1f8eedb44882e8b276\n'}]",0,189466,66a1c8990905563179bf3f0513f962f1ed4387f0,22,5,3,11131,,,0,"Updated from global requirements

Change-Id: I2cf1e60c1c1633885c683c1f8eedb44882e8b276
",git fetch https://review.opendev.org/openstack/trove refs/changes/66/189466/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f40e330d578cfab984f66b8e1c39273fe631c5ad,openstack/requirements,"jsonschema>=2.0.0,<3.0.0,!=2.5.0","jsonschema>=2.0.0,<3.0.0",1,1
openstack%2Fsenlin~master~I9d57e1f9be4f1394ab5f80edf5e0faa18d748e56,openstack/senlin,master,I9d57e1f9be4f1394ab5f80edf5e0faa18d748e56,Add action_update interface to db_api,MERGED,2015-06-10 04:48:54.000000000,2015-06-10 07:05:58.000000000,2015-06-10 07:05:56.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-10 04:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e48abb9b8760b89a091b1cbdf578c4d70d946a85', 'message': 'Add action_update interface to db_api\n\nThis patch added action_update interface to db_api.\n\nChange-Id: I9d57e1f9be4f1394ab5f80edf5e0faa18d748e56\n'}, {'number': 2, 'created': '2015-06-10 06:06:38.000000000', 'files': ['senlin/tests/db/test_action_api.py', 'senlin/db/api.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a23eb7bf1642f9c1fa0f9209042282df88cb4b8d', 'message': 'Add action_update interface to db_api\n\nThis patch added action_update interface to db_api.\n\nChange-Id: I9d57e1f9be4f1394ab5f80edf5e0faa18d748e56\n'}]",2,190020,a23eb7bf1642f9c1fa0f9209042282df88cb4b8d,16,4,2,11034,,,0,"Add action_update interface to db_api

This patch added action_update interface to db_api.

Change-Id: I9d57e1f9be4f1394ab5f80edf5e0faa18d748e56
",git fetch https://review.opendev.org/openstack/senlin refs/changes/20/190020/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/db/test_action_api.py', 'senlin/db/api.py', 'senlin/db/sqlalchemy/api.py']",3,e48abb9b8760b89a091b1cbdf578c4d70d946a85,db-api-add-action-update,"def action_update(context, action_id, values): action = action_get(context, action_id) if not action: raise exception.ActionNotFound(cluster=action_id) action.update(values) action.save(_session(context)) ",,29,0
openstack%2Ftrove-integration~master~I4df6490c437deecfe3c2723d5e7965b2114adc9f,openstack/trove-integration,master,I4df6490c437deecfe3c2723d5e7965b2114adc9f,Enhance 'stop' and 'start' calls,MERGED,2015-03-26 22:26:22.000000000,2015-06-10 07:05:37.000000000,2015-06-10 07:05:35.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 9750}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10440}, {'_account_id': 14576}, {'_account_id': 14619}, {'_account_id': 14829}, {'_account_id': 14912}, {'_account_id': 14991}, {'_account_id': 15321}]","[{'number': 1, 'created': '2015-03-26 22:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/cc99144814db90b4699309e817f9a53dd58ab166', 'message': ""Enhance 'stop' and 'start' calls\n\nIf you run 'restack start' no check is made to see if the processes\nare already running.  This can potentially cause multiple sets of\nthe Trove services to be running at the same time.\n\nBy the same token, calling 'stop' when several sets are running will\nonly remove one set, potentially leaving multiple sets still executing.\n\n'start' now checks to make sure that no Trove process are running; if\nso, a warning is emitted.  'stop' tries to remove up to 5 instances\nof Trove processes.  If more than 5 are found a warning is emitted.\n\nA 'restart' command was also added, which just calls 'stop' then\n'start.'\n\nA few of the help messages were also cleaned up.\n\nChange-Id: I4df6490c437deecfe3c2723d5e7965b2114adc9f\n""}, {'number': 2, 'created': '2015-06-04 14:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/113563fe52e0e12952816725b808c799fa13bd94', 'message': ""Enhance 'stop' and 'start' calls\n\nIf you run 'restack start' no check is made to see if the processes\nare already running.  This can potentially cause multiple sets of\nthe Trove services to be running at the same time.\n\nBy the same token, calling 'stop' when several sets are running will\nonly remove one set, potentially leaving multiple sets still executing.\n\n'start' now checks to make sure that no Trove process are running; if\nso, a warning is emitted.  'stop' tries to remove up to 5 instances\nof Trove processes.  If more than 5 are found a warning is emitted.\n(5 was chosen arbitrarily so that failing to stop the processes\nwouldn't result in an endless loop.)\n\nA 'restart' command was also added, which just calls 'stop' then\n'start.'\n\nA few of the help messages were also cleaned up.\n\nChange-Id: I4df6490c437deecfe3c2723d5e7965b2114adc9f\n""}, {'number': 3, 'created': '2015-06-05 14:58:17.000000000', 'files': ['scripts/redstack'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/28b3f29f2f1c384641768047328ded57ba7b9d33', 'message': ""Enhance 'stop' and 'start' calls\n\nIf you run 'redstack start' no check is made to see if the processes\nare already running.  This can potentially cause multiple sets of\nthe Trove services to be running at the same time.\n\nBy the same token, calling 'stop' when several sets are running will\nonly remove one set, potentially leaving multiple sets still executing.\n\n'start' now checks to make sure that no Trove process are running; if\nso, a warning is emitted.  'stop' tries to remove up to 5 instances\nof Trove processes.  If more than 5 are found a warning is emitted.\n(5 was chosen arbitrarily so that failing to stop the processes\nwouldn't result in an endless loop.)\n\nA 'restart' command was also added, which just calls 'stop' then\n'start.'\n\nChange-Id: I4df6490c437deecfe3c2723d5e7965b2114adc9f\n""}]",22,168178,28b3f29f2f1c384641768047328ded57ba7b9d33,39,14,3,10215,,,0,"Enhance 'stop' and 'start' calls

If you run 'redstack start' no check is made to see if the processes
are already running.  This can potentially cause multiple sets of
the Trove services to be running at the same time.

By the same token, calling 'stop' when several sets are running will
only remove one set, potentially leaving multiple sets still executing.

'start' now checks to make sure that no Trove process are running; if
so, a warning is emitted.  'stop' tries to remove up to 5 instances
of Trove processes.  If more than 5 are found a warning is emitted.
(5 was chosen arbitrarily so that failing to stop the processes
wouldn't result in an endless loop.)

A 'restart' command was also added, which just calls 'stop' then
'start.'

Change-Id: I4df6490c437deecfe3c2723d5e7965b2114adc9f
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/78/168178/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/redstack'],1,cc99144814db90b4699309e817f9a53dd58ab166,enhance_stop_start," RUNNING=$(screen -S stack -Q windows) if [[ ""$RUNNING"" =~ "" tr-"" ]]; then exclaim ""${COLOR_RED}WARNING: Trove services appear to be running. Please run 'stop' or 'restart'${COLOR_NONE}"" else source /dev/stdin < <(sed -n '/^function start_trove\(\)/,/^}/p' $PATH_DEVSTACK_SRC/lib/trove) start_trove fi MAX_RETRY=5 COUNT=1 while true; do RUNNING=$(screen -S stack -Q windows) if [[ ""$RUNNING"" =~ "" tr-"" ]]; then stop_trove else break fi ((COUNT++)) if [ ""$COUNT"" -gt ""$MAX_RETRY"" ]; then exclaim ""${COLOR_RED}WARNING: Could not stop Trove services after ${MAX_RETRY} attempts${COLOR_NONE}"" break fi done kick-start - Kick start the setup of Trove. restart - Runs stop then start for Trove services. update-projects - Git pull on all the daemons' Trove dependencies. ""restart"" ) cmd_stop; cmd_start;;"," source /dev/stdin < <(sed -n '/^function start_trove\(\)/,/^}/p' $PATH_DEVSTACK_SRC/lib/trove) start_trove stop_trove kick-start - kick start the setup of trove. update-projects - Git pull on all the daemons trove dependencies.",26,5
openstack%2Fneutron~master~I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79,openstack/neutron,master,I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79,Defer segment lookup in NetworkContext object,MERGED,2015-06-04 20:43:24.000000000,2015-06-10 07:04:25.000000000,2015-06-10 04:14:24.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11114}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-06-04 20:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d7609539485f05f60f9289a255fe42d0c43f8fa', 'message': 'Defer segment lookup in port context object\n\nAvoid call to get network segments for port context object until a caller\nactually tries to lookup the segments. This optimizes cases where the user of a\nport context never looks at the segments (e.g. update_port_status).\n\nChange-Id: I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79\n'}, {'number': 2, 'created': '2015-06-08 07:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae3eec2f5bd22e2ce1145ed026f39414115b0992', 'message': 'Defer segment lookup in NetworkContext object\n\nAvoid call to get network segments for network context objects until a caller\nactually tries to lookup the segments. This optimizes cases where the user of a\nport context never looks at the segments of the associated network context\n(e.g. update_port_status).\n\nChange-Id: I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79\n'}, {'number': 3, 'created': '2015-06-08 07:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55d0c9ee3e96e76407e96c8a5b767b8cfe05a033', 'message': 'Defer segment lookup in NetworkContext object\n\nAvoid call to get network segments for network context objects until\na caller actually tries to lookup the segments. This optimizes cases\nwhere the user of a port context never looks at the segments of the\nassociated network context (e.g. update_port_status).\n\nChange-Id: I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79\n'}, {'number': 4, 'created': '2015-06-09 04:47:07.000000000', 'files': ['neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/plugins/ml2/test_driver_context.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e61865807c4c8ff959a7746fe3e17f1ae574c9d0', 'message': 'Defer segment lookup in NetworkContext object\n\nAvoid call to get network segments for network context objects until\na caller actually tries to lookup the segments. This optimizes cases\nwhere the user of a port context never looks at the segments of the\nassociated network context (e.g. update_port_status).\n\nCloses-Bug: #1463254\nChange-Id: I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79\n'}]",2,188584,e61865807c4c8ff959a7746fe3e17f1ae574c9d0,91,30,4,7787,,,0,"Defer segment lookup in NetworkContext object

Avoid call to get network segments for network context objects until
a caller actually tries to lookup the segments. This optimizes cases
where the user of a port context never looks at the segments of the
associated network context (e.g. update_port_status).

Closes-Bug: #1463254
Change-Id: I7e95f81d9a3ef26ccdb18c6bfdf9adc29523aa79
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/188584/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/driver_context.py'],1,9d7609539485f05f60f9289a255fe42d0c43f8fa,bug/1463254," self._segments = None self._session = plugin_context.session if not self._segments: self._segments = db.get_network_segments(self._session, self._network['id'])"," self._segments = db.get_network_segments(plugin_context.session, network['id'])",5,2
openstack%2Fneutron~master~I05010d375545b5d819702f367a8c180715bfd17b,openstack/neutron,master,I05010d375545b5d819702f367a8c180715bfd17b,Remove unused exceptions,ABANDONED,2015-06-06 07:11:19.000000000,2015-06-10 07:01:14.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2023}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14249}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15444}, {'_account_id': 15696}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-06-06 07:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb91821fad641d7c6cec06abf53e0bf56366d949', 'message': 'Remove unused exceptions\n\nRemove unused exceptions, validated in neutron,\nneutron-lbaas, neutron-fwaas and neutron-vpnaas\n\nChange-Id: I05010d375545b5d819702f367a8c180715bfd17b\n'}, {'number': 2, 'created': '2015-06-06 17:54:55.000000000', 'files': ['neutron/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/95c0e0f85ec9b5494a8a891e1dae71e232e1a624', 'message': 'Remove unused exceptions\n\nRemove unused exceptions, validated in neutron,\nneutron-lbaas, neutron-fwaas and neutron-vpnaas\n\nChange-Id: I05010d375545b5d819702f367a8c180715bfd17b\n'}]",5,189009,95c0e0f85ec9b5494a8a891e1dae71e232e1a624,73,33,2,11343,,,0,"Remove unused exceptions

Remove unused exceptions, validated in neutron,
neutron-lbaas, neutron-fwaas and neutron-vpnaas

Change-Id: I05010d375545b5d819702f367a8c180715bfd17b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/189009/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/common/exceptions.py'],1,fb91821fad641d7c6cec06abf53e0bf56366d949,,,"class PortNotFoundOnNetwork(NotFound): message = _(""Port %(port_id)s could not be found "" ""on network %(net_id)s"") class PolicyFileNotFound(NotFound): message = _(""Policy configuration policy.json could not be found"") class InvalidConfigurationOption(NeutronException): message = _(""An invalid value was provided for %(opt_name)s: "" ""%(opt_value)s"") class MissingMinSubnetPoolPrefix(BadRequest): message = _(""Unspecified minimum subnet pool prefix"") ",0,18
openstack%2Fbarbican~master~Ie05e8ae82718a7f1c749c0a920546d0158c36cd1,openstack/barbican,master,Ie05e8ae82718a7f1c749c0a920546d0158c36cd1,Updated from global requirements,MERGED,2015-06-09 19:56:31.000000000,2015-06-10 06:50:46.000000000,2015-06-10 06:50:43.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 9234}]","[{'number': 1, 'created': '2015-06-09 19:56:31.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican/commit/7ff32039c867dc1eab3c63f15b0c4fd2ce974514', 'message': 'Updated from global requirements\n\nChange-Id: Ie05e8ae82718a7f1c749c0a920546d0158c36cd1\n'}]",0,189893,7ff32039c867dc1eab3c63f15b0c4fd2ce974514,10,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ie05e8ae82718a7f1c749c0a920546d0158c36cd1
",git fetch https://review.opendev.org/openstack/barbican refs/changes/93/189893/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7ff32039c867dc1eab3c63f15b0c4fd2ce974514,openstack/requirements,oslo.concurrency>=2.0.0 # Apache-2.0,oslo.concurrency>=1.8.0 # Apache-2.0,1,1
openstack%2Fglance~master~Ie124fc47fec8219401e9d0d1b3f17394af30089e,openstack/glance,master,Ie124fc47fec8219401e9d0d1b3f17394af30089e,Fix schema type of `additionalProperties` to support null values,ABANDONED,2015-03-18 11:11:57.000000000,2015-06-10 06:47:22.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 7575}, {'_account_id': 7939}, {'_account_id': 13161}]","[{'number': 1, 'created': '2015-03-18 11:11:57.000000000', 'files': ['glance/schema.py', 'glance/tests/unit/test_schema.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/ba7aa5c6501858c35bf0e169690852e0a9cfccc3', 'message': ""Fix schema type of `additionalProperties` to support null values\n\nRight now the `additionalProperties` field in permissive schema has type\nset to 'string'. It's invalid behaviour, because additional\nproperties can contain null values as well, so we are changing it to\nsupport ['null', 'string'] types.\n\nChange-Id: Ie124fc47fec8219401e9d0d1b3f17394af30089e\nCloses-Bug: 1419823\n""}]",3,165360,ba7aa5c6501858c35bf0e169690852e0a9cfccc3,13,5,1,13161,,,0,"Fix schema type of `additionalProperties` to support null values

Right now the `additionalProperties` field in permissive schema has type
set to 'string'. It's invalid behaviour, because additional
properties can contain null values as well, so we are changing it to
support ['null', 'string'] types.

Change-Id: Ie124fc47fec8219401e9d0d1b3f17394af30089e
Closes-Bug: 1419823
",git fetch https://review.opendev.org/openstack/glance refs/changes/60/165360/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/schema.py', 'glance/tests/unit/test_schema.py']",2,ba7aa5c6501858c35bf0e169690852e0a9cfccc3,bug/1419823," def test_validate_with_none_property(self): obj = {'juice': None} self.schema.validate(obj) 'additionalProperties': {'type': ['null', 'string']},"," 'additionalProperties': {'type': 'string'},",6,2
openstack%2Ffuel-qa~stable%2F6.1~I97ea23601f9acf3060b9b59bbd95c96e9aa4cc4b,openstack/fuel-qa,stable/6.1,I97ea23601f9acf3060b9b59bbd95c96e9aa4cc4b,Use timeout varibale for assert_task_success,MERGED,2015-06-09 12:11:14.000000000,2015-06-10 06:46:37.000000000,2015-06-09 13:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 16106}, {'_account_id': 16414}]","[{'number': 1, 'created': '2015-06-09 12:11:14.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/754044b3abdad7575f0859dd9db231a1a9536f16', 'message': ""Use timeout varibale for assert_task_success\n\nIn huge_environments test we set bigger timeout variable for\n    deploy_cluster_wait but don't set when invoke assert_task_success\n    method. Because of this behavior assert_task_success uses default\n    timeout 7800 sec\n\nChange-Id: I97ea23601f9acf3060b9b59bbd95c96e9aa4cc4b\nCloses-bug: #1449596\n(cherry picked from commit ec2544ac85f63bdb55237bb17c9acd21d5f00f16)\n""}]",0,189675,754044b3abdad7575f0859dd9db231a1a9536f16,12,12,1,12867,,,0,"Use timeout varibale for assert_task_success

In huge_environments test we set bigger timeout variable for
    deploy_cluster_wait but don't set when invoke assert_task_success
    method. Because of this behavior assert_task_success uses default
    timeout 7800 sec

Change-Id: I97ea23601f9acf3060b9b59bbd95c96e9aa4cc4b
Closes-bug: #1449596
(cherry picked from commit ec2544ac85f63bdb55237bb17c9acd21d5f00f16)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/75/189675/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,754044b3abdad7575f0859dd9db231a1a9536f16,," self.assert_task_success(task, timeout=timeout, interval=interval)"," self.assert_task_success(task, interval=interval)",1,1
openstack%2Ffuel-qa~master~Ia921f744d8fed764544badc1cb641ebe63728ced,openstack/fuel-qa,master,Ia921f744d8fed764544badc1cb641ebe63728ced,"Revert ""Use timeout varibale for assert_task_success""",MERGED,2015-06-09 22:59:49.000000000,2015-06-10 06:43:22.000000000,2015-06-10 06:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 12867}]","[{'number': 1, 'created': '2015-06-09 22:59:49.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/2b3dcc8dea5deff1d1a71fdda0ada0994c4c1088', 'message': 'Revert ""Use timeout varibale for assert_task_success""\n\nThis reverts commit ec2544ac85f63bdb55237bb17c9acd21d5f00f16.\n\nChange-Id: Ia921f744d8fed764544badc1cb641ebe63728ced\nCloses-bug: #1463601\n'}]",0,189971,2b3dcc8dea5deff1d1a71fdda0ada0994c4c1088,10,5,1,8829,,,0,"Revert ""Use timeout varibale for assert_task_success""

This reverts commit ec2544ac85f63bdb55237bb17c9acd21d5f00f16.

Change-Id: Ia921f744d8fed764544badc1cb641ebe63728ced
Closes-bug: #1463601
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/71/189971/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,2b3dcc8dea5deff1d1a71fdda0ada0994c4c1088,bug/1463601," self.assert_task_success(task, interval=interval)"," self.assert_task_success(task, timeout=timeout, interval=interval)",1,1
openstack%2Fpython-keystoneclient-kerberos~master~Ica4c4574f7a0980a22fc17da5a44d2d0ac0a548d,openstack/python-keystoneclient-kerberos,master,Ica4c4574f7a0980a22fc17da5a44d2d0ac0a548d,Updated from global requirements,MERGED,2015-06-04 16:24:27.000000000,2015-06-10 06:27:59.000000000,2015-06-10 06:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2015-06-04 16:24:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient-kerberos/commit/4b3ce88f9538cad669cd89e40e1aa79e0bbd0872', 'message': 'Updated from global requirements\n\nChange-Id: Ica4c4574f7a0980a22fc17da5a44d2d0ac0a548d\n'}]",0,188496,4b3ce88f9538cad669cd89e40e1aa79e0bbd0872,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ica4c4574f7a0980a22fc17da5a44d2d0ac0a548d
",git fetch https://review.opendev.org/openstack/python-keystoneclient-kerberos refs/changes/96/188496/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4b3ce88f9538cad669cd89e40e1aa79e0bbd0872,openstack/requirements,python-keystoneclient>=1.6.0,python-keystoneclient>=1.3.0,1,1
openstack%2Fkeystoneauth-saml2~master~I78e4b77115eabbae30628ef3dfa84466f41848ff,openstack/keystoneauth-saml2,master,I78e4b77115eabbae30628ef3dfa84466f41848ff,Updated from global requirements,MERGED,2015-06-04 16:24:28.000000000,2015-06-10 06:27:28.000000000,2015-06-10 06:27:27.000000000,"[{'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2015-06-04 16:24:28.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/6ef3dc46e0ced3be69fc6a7430587b48d318c021', 'message': 'Updated from global requirements\n\nChange-Id: I78e4b77115eabbae30628ef3dfa84466f41848ff\n'}]",0,188497,6ef3dc46e0ced3be69fc6a7430587b48d318c021,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I78e4b77115eabbae30628ef3dfa84466f41848ff
",git fetch https://review.opendev.org/openstack/keystoneauth-saml2 refs/changes/97/188497/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6ef3dc46e0ced3be69fc6a7430587b48d318c021,openstack/requirements,python-keystoneclient>=1.6.0,python-keystoneclient>=1.3.0,1,1
openstack%2Fironic~master~I051d6703194231712f0234f31b0b49208bf0e6ec,openstack/ironic,master,I051d6703194231712f0234f31b0b49208bf0e6ec,Fix DRAC driver job completion detection,MERGED,2015-06-08 19:30:03.000000000,2015-06-10 06:03:35.000000000,2015-06-10 04:14:43.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 7419}, {'_account_id': 9751}, {'_account_id': 10250}, {'_account_id': 10343}, {'_account_id': 11076}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-06-08 19:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/55c5d0692052af8b7c095f5cd97a884b9746bc5a', 'message': 'Fix DRAC driver job completion detection\n\nThe DRAC driver code determined job completion by comparing the\nreturned JobStatus to ""completed"" and ""failed"".  Testing with hardware\nshowed that JobStatus can also return ""Completed with Errors"".\n\nThis change updates the DRAC driver so that it recognizes a job with\n""Completed with Errors"" for the JobStatus as a completed job.\n\nChange-Id: I051d6703194231712f0234f31b0b49208bf0e6ec\nCloses-Bug: 1462513\n'}, {'number': 2, 'created': '2015-06-09 18:19:35.000000000', 'files': ['ironic/drivers/modules/drac/management.py', 'ironic/tests/drivers/drac/test_management.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5704227cf0c1adf6c1d8a321b60eb6c5e8461ced', 'message': 'Fix DRAC driver job completion detection\n\nThe DRAC driver code determined job completion by comparing the\nreturned JobStatus to ""completed"" and ""failed"".  Testing with hardware\nshowed that JobStatus can also return ""Completed with Errors"".\n\nThis change updates the DRAC driver so that it recognizes a job with\n""Completed with Errors"" for the JobStatus as a completed job.\n\nChange-Id: I051d6703194231712f0234f31b0b49208bf0e6ec\nCloses-Bug: 1462513\n'}]",2,189409,5704227cf0c1adf6c1d8a321b60eb6c5e8461ced,20,8,2,10250,,,0,"Fix DRAC driver job completion detection

The DRAC driver code determined job completion by comparing the
returned JobStatus to ""completed"" and ""failed"".  Testing with hardware
showed that JobStatus can also return ""Completed with Errors"".

This change updates the DRAC driver so that it recognizes a job with
""Completed with Errors"" for the JobStatus as a completed job.

Change-Id: I051d6703194231712f0234f31b0b49208bf0e6ec
Closes-Bug: 1462513
",git fetch https://review.opendev.org/openstack/ironic refs/changes/09/189409/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/drac/management.py', 'ironic/tests/drivers/drac/test_management.py']",2,55c5d0692052af8b7c095f5cd97a884b9746bc5a,bug/1462513," def test__check_for_config_job_not_exist(self, mock_client_pywsman): job_statuses = [""Completed"", ""Completed with Errors"", ""Failed""] for job_status in job_statuses: result_xml = test_utils.build_soap_xml( [{'DCIM_LifecycleJob': {'Name': 'BIOS.Setup.1-1', 'JobStatus': job_status, 'InstanceID': 'fake'}}], resource_uris.DCIM_LifecycleJob) mock_xml = test_utils.mock_wsman_root(result_xml) mock_pywsman = mock_client_pywsman.Client.return_value mock_pywsman.enumerate.return_value = mock_xml try: drac_mgmt._check_for_config_job(self.node) except (exception.DracClientError, exception.DracPendingConfigJobExists): self.fail(""Failed to detect completed job due to "" ""\""{}\"" job status"".format(job_status)) ",,22,1
openstack%2Fproject-config~master~I1fb6b299c6577cfe37ac756ffafc29cfab927cef,openstack/project-config,master,I1fb6b299c6577cfe37ac756ffafc29cfab927cef,Remove novnc service from congress-dsvm-api jenkins job,MERGED,2015-06-09 23:02:01.000000000,2015-06-10 05:58:09.000000000,2015-06-10 05:58:08.000000000,"[{'_account_id': 3}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-09 23:02:01.000000000', 'files': ['jenkins/jobs/congress.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/84686d9b5dc193e76e7b12af7aecfd757d157c8c', 'message': 'Remove novnc service from congress-dsvm-api jenkins job\n\ndevstack is not able to clone the novnc repo, and causes\na test failure.\n\nChange-Id: I1fb6b299c6577cfe37ac756ffafc29cfab927cef\n'}]",0,189972,84686d9b5dc193e76e7b12af7aecfd757d157c8c,7,3,1,12875,,,0,"Remove novnc service from congress-dsvm-api jenkins job

devstack is not able to clone the novnc repo, and causes
a test failure.

Change-Id: I1fb6b299c6577cfe37ac756ffafc29cfab927cef
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/189972/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/congress.yaml'],1,84686d9b5dc193e76e7b12af7aecfd757d157c8c,,," ENABLED_SERVICES+=n-novnc,n-xvnc,",0,1
openstack%2Fdevstack~master~Ice057eb80e7ab6e917ca972abe7eaae7d635e8a5,openstack/devstack,master,Ice057eb80e7ab6e917ca972abe7eaae7d635e8a5,Fix sample multinode configuration,MERGED,2015-06-01 16:08:59.000000000,2015-06-10 05:48:10.000000000,2015-06-09 22:16:50.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 7350}]","[{'number': 1, 'created': '2015-06-01 16:08:59.000000000', 'files': ['doc/source/guides/multinode-lab.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/25cb34606eb25ad2760e4ac50fa4d08036afbc96', 'message': 'Fix sample multinode configuration\n\nThere should not be c-sch and c-api services on compute node.\n\nChange-Id: Ice057eb80e7ab6e917ca972abe7eaae7d635e8a5\nCloses-Bug: 1393721\n'}]",2,187242,25cb34606eb25ad2760e4ac50fa4d08036afbc96,12,6,1,7369,,,0,"Fix sample multinode configuration

There should not be c-sch and c-api services on compute node.

Change-Id: Ice057eb80e7ab6e917ca972abe7eaae7d635e8a5
Closes-Bug: 1393721
",git fetch https://review.opendev.org/openstack/devstack refs/changes/42/187242/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/guides/multinode-lab.rst'],1,25cb34606eb25ad2760e4ac50fa4d08036afbc96,bug/1393721," ENABLED_SERVICES=n-cpu,n-net,n-api,c-vol"," ENABLED_SERVICES=n-cpu,n-net,n-api,c-sch,c-api,c-vol",1,1
openstack%2Ftrove-specs~master~I63bb32f5b05f7319c231ea5164fa375c115f8e74,openstack/trove-specs,master,I63bb32f5b05f7319c231ea5164fa375c115f8e74,Database and User Functions for Cassandra,MERGED,2015-05-06 21:15:08.000000000,2015-06-10 05:30:32.000000000,2015-06-10 05:30:29.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 7806}, {'_account_id': 8415}, {'_account_id': 9664}, {'_account_id': 9782}, {'_account_id': 10295}, {'_account_id': 14576}, {'_account_id': 14912}, {'_account_id': 15321}]","[{'number': 1, 'created': '2015-05-06 21:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/209c9ce5248bc9131d1659af2151c6ce80baef5a', 'message': 'Database and User Functions for Cassandra\n\nChange-Id: I63bb32f5b05f7319c231ea5164fa375c115f8e74\nBlueprint: cassandra-database-user-functions\n'}, {'number': 2, 'created': '2015-05-08 19:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/a9764ad7f5ab872bdb614a8a319d2ae8683874fc', 'message': 'Database and User Functions for Cassandra\n\nChange-Id: I63bb32f5b05f7319c231ea5164fa375c115f8e74\nBlueprint: cassandra-database-user-functions\n'}, {'number': 3, 'created': '2015-05-27 21:54:42.000000000', 'files': ['doc/source/index.rst', 'specs/liberty/cassandra-database-user-functions.rst'], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/5b8c6c62dec11c3eba9f57c1c64991e5088e0fae', 'message': 'Database and User Functions for Cassandra\n\nChange-Id: I63bb32f5b05f7319c231ea5164fa375c115f8e74\nBlueprint: cassandra-database-user-functions\n'}]",19,180748,5b8c6c62dec11c3eba9f57c1c64991e5088e0fae,22,10,3,14576,,,0,"Database and User Functions for Cassandra

Change-Id: I63bb32f5b05f7319c231ea5164fa375c115f8e74
Blueprint: cassandra-database-user-functions
",git fetch https://review.opendev.org/openstack/trove-specs refs/changes/48/180748/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/liberty/cassandra-database-user-functions.rst']",2,209c9ce5248bc9131d1659af2151c6ce80baef5a,bp/cassandra-database-user-functions,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode Sections of this template were taken directly from the Nova spec template at: https://github.com/openstack/nova-specs/blob/master/specs/template.rst ===================================== Cassandra Database and User Functions ===================================== Launchpad blueprint: https://blueprints.launchpad.net/trove/+spec/cassandra-database-user-functions Problem Description =================== The Cassandra datastore currently does not support keyspace [*]_ and user management features. .. [*] A keyspace is the outermost container for data in Cassandra, corresponding closely to a relational database. Proposed Change =============== The patch set will implement the following keyspace and user related functionality for Cassandra 2.1 datastore: User Functions: - create/delete/get user - list users - change password - grant/revoke/list access - update attributes Keyspace Functions: - create/delete database - list databases Configuration ------------- Cassandra stores its configuration in 'cassandra.yaml' file (commonly in '/etc/cassandra'). The node (datastore service) has to be restarted for any changes to the configuration file to take effect. The configuration template will have to be updated to enable authentication and authorization in order to support datastore users and related functions. Client-specific settings (authentication defaults) are stored in '~/.cassandra/cqlshrc' where '~' is the home directory of the Trove user. Database -------- None Public API ---------- None Public API Security ------------------- The current implementation allows original anonymous connections therefore making the datastore wide open for anybody with connection URL. This has to be changed first as the user functions are not even enabled in this setting. In Cassandra only SUPERUSERS can create other users and grant permissions to database resources. Trove uses the 'cassandra' superuser to perform its administrative tasks. The users it creates are all 'normal' (NOSUPERUSER) accounts. The permissions it can grant are also limited to non-superuser operations. This is to prevent anybody from creating a new superuser via the Trove API. Similarly, all list operations include only non-superuser accounts. Updatable attributes include username and password. The datastore configuration template had to be updated to enable authentication and authorization support (original configuration allowed anonymous connections). Default implementations used are: * *authenticator: org.apache.cassandra.auth.PasswordAuthenticator* * *authorizer: org.apache.cassandra.auth.CassandraAuthorizer* The superuser password needs to be changed from the default 'cassandra' to a random Trove password which is then stored in a Trove-read-only file in '~/.cassandra/cqlshrc' which is also the default location for client settings. Internal API ------------ None Guest Agent ----------- The current implementation uses the CQLSH command line client to interface with the underlying database. Trove talks to the tool via the available shell and relies on parsing the output of the tool to determine the current state of the datastore and status of the last operation. It also requires Trove to provide the input as a formatted (and sanitized) string accepted by the installed version of the client. This is not very portable and poses numerous potential compatibility issues in the future when the guest agent gets ported to other platforms. It also completely bypasses the native exception handling implemented by the Python client. In order to make the guestagent communicate via the native Python API and avoid future portability issues we reimplement the communication interface using the the official open-source Python driver for Cassandra. The native interface will be implemented in CassandraConnection and will also be used to obtain the database status leveraging Python exceptions framework. User-related functions require having the authorization and authentication support enabled on the server. The configuration template will be updated to reflect this requirement (see the section on 'Public API Security'). The following section elaborates on keyspace *(""database"")* functions. Cassandra stores replicas on multiple nodes to ensure reliability and fault tolerance. All replicas are equally important; there is no primary or master. A replication strategy determines the nodes where replicas are placed. The total number of replicas across the cluster is referred to as the replication factor. The 'create database' implementation will be using 'SimpleStrategy' with just a single replica on the guest machine. This is a very simplistic configuration only good for the most basic applications and demonstration purposes. SimpleStrategy is for a single data center only. The following system keyspaces will be excluded from all database operations including listing (default) in order to prevent standard Trove users from undermining the system operation or gaining access to other user's data: 'system', 'system_auth', 'system_traces' Alternatives ------------ None Implementation ============== Assignee(s) ----------- Petr Malik <pmalik@tesora.com> Milestones ---------- Liberty Work Items ---------- 1. Implement native-driver-based connection for Cassandra datastore. 2. Enable authentication and authorization on server. 3. Implement user-function API calls. Upgrade Implications ==================== None Dependencies ============ Trove uses the official open-source Python driver [1]_ for Cassandra to connect to the database and execute queries. The driver already exists in OpenStack global requirements. It does not have to be included in the 'requirements.txt' file, but it will need to be added to 'test-requirements.txt' file to enable unit tests. The image provider will be required to install it ('cassandra-driver') in the Cassandra images. The current Trove integration images will be updated to do that. Testing ======= Unittests will be added to validate implemented functions and non-trivial codepaths. Documentation Impact ==================== The datastore documentation should be updated to reflect the enabled features. References ========== .. [1] Native Python Driver for Cassandra: http://docs.datastax.com/en/developer/python-driver/2.5/common/drivers/introduction/introArchOverview_c.html .. [2] Documentation on Cassandra 2.1: http://docs.datastax.com/en/cassandra/2.1/cassandra/gettingStartedCassandraIntro.html .. [3] CQL Reference: http://docs.datastax.com/en/cql/3.1/cql/cql_reference/cqlReferenceTOC.html ",,213,0
openstack%2Fhorizon~master~I7670d2cfdbb6c0ee3638c5a2783cb234b6f5267f,openstack/horizon,master,I7670d2cfdbb6c0ee3638c5a2783cb234b6f5267f,Launch Instance NG - Create Volume if Nova Ext,MERGED,2015-06-05 22:51:14.000000000,2015-06-10 05:27:31.000000000,2015-06-10 05:27:29.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 13805}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-06-05 22:51:14.000000000', 'files': ['openstack_dashboard/static/dashboard/launch-instance/source/source.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0b60758e7d26a926febeb92ecf769f5c355b5fd9', 'message': 'Launch Instance NG - Create Volume if Nova Ext\n\nThe new angular launch instance does not look at\nallowCreateVolumeFromImage property to determine whether\nor not to show ""create from volume"". That property is\nbeing set based on if the nova extension is enabled that\nsupports it.\n\nChange-Id: I7670d2cfdbb6c0ee3638c5a2783cb234b6f5267f\nCloses-Bug: #1462547\n'}]",0,188963,0b60758e7d26a926febeb92ecf769f5c355b5fd9,17,9,1,7665,,,0,"Launch Instance NG - Create Volume if Nova Ext

The new angular launch instance does not look at
allowCreateVolumeFromImage property to determine whether
or not to show ""create from volume"". That property is
being set based on if the nova extension is enabled that
supports it.

Change-Id: I7670d2cfdbb6c0ee3638c5a2783cb234b6f5267f
Closes-Bug: #1462547
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/188963/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/launch-instance/source/source.html'],1,0b60758e7d26a926febeb92ecf769f5c355b5fd9,bug/1435869," ng-if=""model.newInstanceSpec.source_type.type === 'image' && model.allowCreateVolumeFromImage"">"," ng-if=""model.newInstanceSpec.source_type.type === 'image'"">",2,1
openstack%2Fheat~master~I167edf7b063f66c835a07d5143f02bd07f62e0a0,openstack/heat,master,I167edf7b063f66c835a07d5143f02bd07f62e0a0,Split engine service test cases (5),MERGED,2015-05-29 08:24:34.000000000,2015-06-10 05:27:10.000000000,2015-06-10 05:27:08.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 12404}]","[{'number': 1, 'created': '2015-05-29 08:24:34.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/engine/test_stack_delete.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e08fdbb95b5e62fed8555516c2346cbdecac3d2c', 'message': 'Split engine service test cases (5)\n\nThis patch separates out test cases related to stack create and\nvalidation. The patch also replaced the existing mox calls with mock\ncalls.\n\nChange-Id: I167edf7b063f66c835a07d5143f02bd07f62e0a0\n'}]",3,186673,e08fdbb95b5e62fed8555516c2346cbdecac3d2c,12,6,1,8246,,,0,"Split engine service test cases (5)

This patch separates out test cases related to stack create and
validation. The patch also replaced the existing mox calls with mock
calls.

Change-Id: I167edf7b063f66c835a07d5143f02bd07f62e0a0
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/186673/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/engine/test_stack_delete.py']",2,e08fdbb95b5e62fed8555516c2346cbdecac3d2c,split-eng-test,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from oslo_messaging.rpc import dispatcher from heat.common import exception from heat.engine import service from heat.engine import stack as parser from heat.engine import stack_lock from heat.objects import stack as stack_object from heat.objects import stack_lock as stack_lock_object from heat.tests import common from heat.tests.engine import tools from heat.tests import utils class StackDeleteTest(common.HeatTestCase): def setUp(self): super(StackDeleteTest, self).setUp() self.ctx = utils.dummy_context() self.man = service.EngineService('a-host', 'a-topic') self.man.create_periodic_tasks() @mock.patch.object(parser.Stack, 'load') def test_stack_delete(self, mock_load): stack_name = 'service_delete_test_stack' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() mock_load.return_value = stack s = stack_object.Stack.get_by_id(self.ctx, sid) self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) self.man.thread_group_mgr.groups[sid].wait() mock_load.assert_called_once_with(self.ctx, stack=s) def test_stack_delete_nonexist(self): stack_name = 'service_delete_nonexist_test_stack' stack = tools.get_stack(stack_name, self.ctx) ex = self.assertRaises(dispatcher.ExpectedException, self.man.delete_stack, self.ctx, stack.identifier()) self.assertEqual(exception.StackNotFound, ex.exc_info[0]) @mock.patch.object(parser.Stack, 'load') @mock.patch.object(stack_lock.StackLock, 'try_acquire') def test_stack_delete_acquired_lock(self, mock_acquire, mock_load): mock_acquire.return_value = self.man.engine_id stack_name = 'service_delete_test_stack_acquired_lock' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() mock_load.return_value = stack st = stack_object.Stack.get_by_id(self.ctx, sid) self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) self.man.thread_group_mgr.groups[sid].wait() mock_acquire.assert_called_once_with() mock_load.assert_called_once_with(self.ctx, stack=st) @mock.patch.object(parser.Stack, 'load') @mock.patch.object(stack_lock.StackLock, 'try_acquire') def test_stack_delete_acquired_lock_stop_timers(self, mock_acquire, mock_load): mock_acquire.return_value = self.man.engine_id stack_name = 'service_delete_test_stack_stop_timers' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() mock_load.return_value = stack st = stack_object.Stack.get_by_id(self.ctx, sid) self.man.thread_group_mgr.add_timer(stack.id, 'test') self.assertEqual(1, len(self.man.thread_group_mgr.groups[sid].timers)) self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) self.assertEqual(0, len(self.man.thread_group_mgr.groups[sid].timers)) self.man.thread_group_mgr.groups[sid].wait() mock_acquire.assert_called_once_with() mock_load.assert_called_once_with(self.ctx, stack=st) @mock.patch.object(parser.Stack, 'load') @mock.patch.object(stack_lock.StackLock, 'try_acquire') @mock.patch.object(stack_lock.StackLock, 'acquire') def test_stack_delete_current_engine_active_lock(self, mock_acquire, mock_try, mock_load): self.man.start() stack_name = 'service_delete_test_stack_current_active_lock' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() # Insert a fake lock into the db stack_lock_object.StackLock.create(stack.id, self.man.engine_id) # Create a fake ThreadGroup too self.man.thread_group_mgr.groups[stack.id] = tools.DummyThreadGroup() st = stack_object.Stack.get_by_id(self.ctx, sid) mock_load.return_value = stack mock_try.return_value = self.man.engine_id mock_stop = self.patchobject(self.man.thread_group_mgr, 'stop') self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) mock_load.assert_called_with(self.ctx, stack=st) self.assertEqual(2, len(mock_load.mock_calls)) mock_try.assert_called_once_with() mock_acquire.assert_called_once_with() mock_stop.assert_called_once_with(stack.id) @mock.patch.object(parser.Stack, 'load') @mock.patch.object(stack_lock.StackLock, 'try_acquire') @mock.patch.object(stack_lock.StackLock, 'engine_alive') def test_stack_delete_other_engine_active_lock_failed(self, mock_alive, mock_try, mock_load): OTHER_ENGINE = ""other-engine-fake-uuid"" self.man.start() stack_name = 'service_delete_test_stack_other_engine_lock_fail' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() # Insert a fake lock into the db stack_lock_object.StackLock.create(stack.id, OTHER_ENGINE) st = stack_object.Stack.get_by_id(self.ctx, sid) mock_load.return_value = stack mock_try.return_value = OTHER_ENGINE mock_alive.return_value = True mock_call = self.patchobject(self.man, '_remote_call', return_value=False) ex = self.assertRaises(dispatcher.ExpectedException, self.man.delete_stack, self.ctx, stack.identifier()) self.assertEqual(exception.StopActionFailed, ex.exc_info[0]) mock_load.assert_called_once_with(self.ctx, stack=st) mock_try.assert_called_once_with() mock_alive.assert_called_once_with(self.ctx, OTHER_ENGINE) mock_call.assert_called_once_with(self.ctx, OTHER_ENGINE, ""stop_stack"", stack_identity=mock.ANY) @mock.patch.object(parser.Stack, 'load') @mock.patch.object(stack_lock.StackLock, 'try_acquire') @mock.patch.object(stack_lock.StackLock, 'engine_alive') @mock.patch.object(stack_lock.StackLock, 'acquire') def test_stack_delete_other_engine_active_lock_succeeded( self, mock_acquire, mock_alive, mock_try, mock_load): OTHER_ENGINE = ""other-engine-fake-uuid"" self.man.start() stack_name = 'service_delete_test_stack_other_engine_lock' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() # Insert a fake lock into the db stack_lock_object.StackLock.create(stack.id, OTHER_ENGINE) st = stack_object.Stack.get_by_id(self.ctx, sid) mock_load.return_value = stack mock_try.return_value = OTHER_ENGINE mock_alive.return_value = True mock_call = self.patchobject(self.man, '_remote_call', return_value=None) self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) self.man.thread_group_mgr.groups[sid].wait() self.assertEqual(2, len(mock_load.mock_calls)) mock_load.assert_called_with(self.ctx, stack=st) mock_try.assert_called_once_with() mock_alive.assert_called_once_with(self.ctx, OTHER_ENGINE) mock_call.assert_called_once_with(self.ctx, OTHER_ENGINE, ""stop_stack"", stack_identity=mock.ANY) mock_acquire.assert_called_once_with() @mock.patch.object(parser.Stack, 'load') @mock.patch.object(stack_lock.StackLock, 'try_acquire') @mock.patch.object(stack_lock.StackLock, 'engine_alive') @mock.patch.object(stack_lock.StackLock, 'acquire') def test_stack_delete_other_dead_engine_active_lock( self, mock_acquire, mock_alive, mock_try, mock_load): OTHER_ENGINE = ""other-engine-fake-uuid"" stack_name = 'service_delete_test_stack_other_dead_engine' stack = tools.get_stack(stack_name, self.ctx) sid = stack.store() # Insert a fake lock into the db stack_lock_object.StackLock.create(stack.id, ""other-engine-fake-uuid"") st = stack_object.Stack.get_by_id(self.ctx, sid) mock_load.return_value = stack mock_try.return_value = OTHER_ENGINE mock_alive.return_value = False self.assertIsNone(self.man.delete_stack(self.ctx, stack.identifier())) self.man.thread_group_mgr.groups[sid].wait() mock_load.assert_called_with(self.ctx, stack=st) mock_try.assert_called_once_with() mock_acquire.assert_called_once_with() mock_alive.assert_called_once_with(self.ctx, OTHER_ENGINE) ",,219,189
openstack%2Fkeystone~master~I46c0f42fde056803278f44797375812d605c2af0,openstack/keystone,master,I46c0f42fde056803278f44797375812d605c2af0,Merge tag '2014.2',MERGED,2014-10-16 14:05:57.000000000,2015-06-10 05:27:00.000000000,2015-06-10 05:26:58.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5263}, {'_account_id': 6486}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-10-16 14:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5e7a8e534e28e117fb6d00324856fd3aec870649', 'message': ""Merge tag '2014.2'\n\nKeystone 2014.2\n\nChange-Id: I46c0f42fde056803278f44797375812d605c2af0\n""}, {'number': 2, 'created': '2015-06-09 16:40:16.000000000', 'files': ['keystone/locale/keystone.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/tests/test_v3_auth.py', 'keystone/contrib/endpoint_filter/controllers.py', 'keystone/contrib/federation/migrate_repo/versions/001_add_identity_provider_table.py', 'keystone/tests/test_backend_ldap.py', 'keystone/identity/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b788121927abe04a1bbbd1d47eb04cd8d9311904', 'message': ""Merge tag '2014.2'\n\nThis is a null-merge of the 2014.2 release tag back into the\nmaster branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I46c0f42fde056803278f44797375812d605c2af0\n""}]",0,128930,b788121927abe04a1bbbd1d47eb04cd8d9311904,20,5,2,11131,,,0,"Merge tag '2014.2'

This is a null-merge of the 2014.2 release tag back into the
master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I46c0f42fde056803278f44797375812d605c2af0
",git fetch https://review.opendev.org/openstack/keystone refs/changes/30/128930/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/locale/keystone.pot', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po']",3,5e7a8e534e28e117fb6d00324856fd3aec870649,merge/release-tag,,"<<<<<<< HEAD (61ccca Merge ""wrong logic in assertValidRoleAssignmentListResponse )======= ""POT-Creation-Date: 2014-10-07 14:35+0000\n"" >>>>>>> BRANCH (ef8d9a updated translations)<<<<<<< HEAD (61ccca Merge ""wrong logic in assertValidRoleAssignmentListResponse )======= >>>>>>> BRANCH (ef8d9a updated translations)",0,25
openstack%2Fheat~master~I165d3a1f4e281debd8afb390520f18fc59084b87,openstack/heat,master,I165d3a1f4e281debd8afb390520f18fc59084b87,Fix wrong definition of assert,MERGED,2015-06-09 14:43:56.000000000,2015-06-10 05:26:50.000000000,2015-06-10 05:26:48.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8289}, {'_account_id': 9751}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-09 14:43:56.000000000', 'files': ['heat/engine/attributes.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/989c5c0bf728c41d9dceab9a62ce1cdc0ba0dcca', 'message': 'Fix wrong definition of assert\n\nFix warning error message in unittests log, which was added in patch\nIe881a1bdb88f4bcb1c03c037bcedf2a328d5d41c:\n\n""heat/engine/attributes.py:80: SyntaxWarning: assertion is always true,\nperhaps remove parentheses?""\n\nChange-Id: I165d3a1f4e281debd8afb390520f18fc59084b87\n'}]",0,189759,989c5c0bf728c41d9dceab9a62ce1cdc0ba0dcca,10,5,1,6577,,,0,"Fix wrong definition of assert

Fix warning error message in unittests log, which was added in patch
Ie881a1bdb88f4bcb1c03c037bcedf2a328d5d41c:

""heat/engine/attributes.py:80: SyntaxWarning: assertion is always true,
perhaps remove parentheses?""

Change-Id: I165d3a1f4e281debd8afb390520f18fc59084b87
",git fetch https://review.opendev.org/openstack/heat refs/changes/59/189759/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/attributes.py'],1,989c5c0bf728c41d9dceab9a62ce1cdc0ba0dcca,," msg = 'Old attribute schema is not supported' assert isinstance(schema_dict, cls), msg"," assert (isinstance(schema_dict, cls), 'Old attribute schema is not supported')",2,2
openstack%2Fkeystone~master~I7467bea4c34a852b4efd9ebb8178aa8c77e9a7f7,openstack/keystone,master,I7467bea4c34a852b4efd9ebb8178aa8c77e9a7f7,Merge tag '2015.1.0',MERGED,2015-04-30 23:26:33.000000000,2015-06-10 05:26:43.000000000,2015-06-10 05:26:40.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-04-30 23:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/801366154eb4830a3600d0dcfd252d2dccbd6fdd', 'message': ""Merge tag '2015.1.0'\n\nKeystone 2015.1.0\n\nChange-Id: I7467bea4c34a852b4efd9ebb8178aa8c77e9a7f7\n""}, {'number': 2, 'created': '2015-06-09 17:17:04.000000000', 'files': ['keystone/locale/de/LC_MESSAGES/keystone-log-info.po', '.gitreview', 'keystone/locale/fr/LC_MESSAGES/keystone-log-warning.po', 'test-requirements.txt', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-error.po', 'requirements.txt', 'keystone/locale/it/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-error.po', 'requirements-py3.txt', 'test-requirements-py3.txt', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-info.po'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9bc6043eb06199b8d4dbf6698e129d984a59cc11', 'message': ""Merge tag '2015.1.0'\n\nThis is a null-merge of the 2015.1.0 release tag back into the master\nbranch so that the 2015.1.0 tag will appear in the git commit history of\nthe master branch. It contains no actual changes to the master branch,\nregardless of how our code review system's UI represents it. Please\nask in #openstack-infra if you have any questions, and otherwise try\nto merge this as quickly as possible to avoid later conflicts on the\nmaster branch.\n\nChange-Id: I7467bea4c34a852b4efd9ebb8178aa8c77e9a7f7\n""}]",0,179288,9bc6043eb06199b8d4dbf6698e129d984a59cc11,13,3,2,11131,,,0,"Merge tag '2015.1.0'

This is a null-merge of the 2015.1.0 release tag back into the master
branch so that the 2015.1.0 tag will appear in the git commit history of
the master branch. It contains no actual changes to the master branch,
regardless of how our code review system's UI represents it. Please
ask in #openstack-infra if you have any questions, and otherwise try
to merge this as quickly as possible to avoid later conflicts on the
master branch.

Change-Id: I7467bea4c34a852b4efd9ebb8178aa8c77e9a7f7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/88/179288/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/locale/de/LC_MESSAGES/keystone-log-info.po', '.gitreview', 'keystone/locale/fr/LC_MESSAGES/keystone-log-warning.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone-log-info.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone-log-error.po', 'keystone/tests/unit/test_v3_federation.py', 'requirements.txt', 'keystone/locale/it/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/ja/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone-log-error.po', 'keystone/locale/es/LC_MESSAGES/keystone-log-error.po', 'requirements-py3.txt', 'keystone/locale/en_GB/LC_MESSAGES/keystone-log-info.po']",17,801366154eb4830a3600d0dcfd252d2dccbd6fdd,merge/release-tag,"# Translations template for keystone. # Copyright (C) 2015 OpenStack Foundation # This file is distributed under the same license as the keystone project. # # Translators: # Andi Chandler <andi@gowling.com>, 2014 msgid """" msgstr """" ""Project-Id-Version: Keystone\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/keystone\n"" ""POT-Creation-Date: 2015-03-09 06:03+0000\n"" ""PO-Revision-Date: 2015-03-07 04:31+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n"" ""Language-Team: English (United Kingdom) (http://www.transifex.com/projects/p/"" ""keystone/language/en_GB/)\n"" ""Language: en_GB\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""Generated-By: Babel 1.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1);\n"" #: keystone/assignment/core.py:250 #, python-format msgid ""Creating the default role %s because it does not exist."" msgstr """" #: keystone/assignment/core.py:258 #, python-format msgid ""Creating the default role %s failed because it was already created"" msgstr """" #: keystone/auth/controllers.py:64 msgid ""Loading auth-plugins by class-name is deprecated."" msgstr """" #: keystone/auth/controllers.py:106 #, python-format msgid """" ""\""expires_at\"" has conflicting values %(existing)s and %(new)s. Will use "" ""the earliest value."" msgstr """" ""\""expires_at\"" has conflicting values %(existing)s and %(new)s. Will use "" ""the earliest value."" #: keystone/common/openssl.py:81 #, python-format msgid ""Running command - %s"" msgstr """" #: keystone/common/wsgi.py:79 msgid ""No bind information present in token"" msgstr """" #: keystone/common/wsgi.py:83 #, python-format msgid ""Named bind mode %s not in bind information"" msgstr """" #: keystone/common/wsgi.py:90 msgid ""Kerberos credentials required and not present"" msgstr """" #: keystone/common/wsgi.py:94 msgid ""Kerberos credentials do not match those in bind"" msgstr """" #: keystone/common/wsgi.py:98 msgid ""Kerberos bind authentication successful"" msgstr """" #: keystone/common/wsgi.py:105 #, python-format msgid ""Couldn't verify unknown bind: {%(bind_type)s: %(identifier)s}"" msgstr """" #: keystone/common/environment/eventlet_server.py:103 #, python-format msgid ""Starting %(arg0)s on %(host)s:%(port)s"" msgstr """" #: keystone/common/kvs/core.py:138 #, python-format msgid ""Adding proxy '%(proxy)s' to KVS %(name)s."" msgstr """" #: keystone/common/kvs/core.py:188 #, python-format msgid ""Using %(func)s as KVS region %(name)s key_mangler"" msgstr """" #: keystone/common/kvs/core.py:200 #, python-format msgid ""Using default dogpile sha1_mangle_key as KVS region %s key_mangler"" msgstr """" #: keystone/common/kvs/core.py:210 #, python-format msgid ""KVS region %s key_mangler disabled."" msgstr """" #: keystone/contrib/example/core.py:64 keystone/contrib/example/core.py:73 #, python-format msgid """" ""Received the following notification: service %(service)s, resource_type: "" ""%(resource_type)s, operation %(operation)s payload %(payload)s"" msgstr """" #: keystone/openstack/common/eventlet_backdoor.py:146 #, python-format msgid ""Eventlet backdoor listening on %(port)s for process %(pid)d"" msgstr ""Eventlet backdoor listening on %(port)s for process %(pid)d"" #: keystone/openstack/common/service.py:173 #, python-format msgid ""Caught %s, exiting"" msgstr ""Caught %s, exiting"" #: keystone/openstack/common/service.py:231 msgid ""Parent process has died unexpectedly, exiting"" msgstr ""Parent process has died unexpectedly, exiting"" #: keystone/openstack/common/service.py:262 #, python-format msgid ""Child caught %s, exiting"" msgstr ""Child caught %s, exiting"" #: keystone/openstack/common/service.py:301 msgid ""Forking too fast, sleeping"" msgstr ""Forking too fast, sleeping"" #: keystone/openstack/common/service.py:320 #, python-format msgid ""Started child %d"" msgstr ""Started child %d"" #: keystone/openstack/common/service.py:330 #, python-format msgid ""Starting %d workers"" msgstr ""Starting %d workers"" #: keystone/openstack/common/service.py:347 #, python-format msgid ""Child %(pid)d killed by signal %(sig)d"" msgstr ""Child %(pid)d killed by signal %(sig)d"" #: keystone/openstack/common/service.py:351 #, python-format msgid ""Child %(pid)s exited with status %(code)d"" msgstr ""Child %(pid)s exited with status %(code)d"" #: keystone/openstack/common/service.py:390 #, python-format msgid ""Caught %s, stopping children"" msgstr ""Caught %s, stopping children"" #: keystone/openstack/common/service.py:399 msgid ""Wait called after thread killed. Cleaning up."" msgstr """" #: keystone/openstack/common/service.py:415 #, python-format msgid ""Waiting on %d children to exit"" msgstr ""Waiting on %d children to exit"" #: keystone/token/persistence/backends/sql.py:279 #, python-format msgid ""Total expired tokens removed: %d"" msgstr ""Total expired tokens removed: %d"" #: keystone/token/providers/fernet/utils.py:72 msgid """" ""[fernet_tokens] key_repository does not appear to exist; attempting to "" ""create it"" msgstr """" #: keystone/token/providers/fernet/utils.py:130 #, python-format msgid ""Created a new key: %s"" msgstr """" #: keystone/token/providers/fernet/utils.py:143 msgid ""Key repository is already initialized; aborting."" msgstr """" #: keystone/token/providers/fernet/utils.py:179 #, python-format msgid ""Starting key rotation with %(count)s key files: %(list)s"" msgstr """" #: keystone/token/providers/fernet/utils.py:185 #, python-format msgid ""Current primary key is: %s"" msgstr """" #: keystone/token/providers/fernet/utils.py:187 #, python-format msgid ""Next primary key will be: %s"" msgstr """" #: keystone/token/providers/fernet/utils.py:197 #, python-format msgid ""Promoted key 0 to be the primary: %s"" msgstr """" #: keystone/token/providers/fernet/utils.py:213 #, python-format msgid ""Excess keys to purge: %s"" msgstr """" #: keystone/token/providers/fernet/utils.py:237 #, python-format msgid ""Loaded %(count)s encryption keys from: %(dir)s"" msgstr """" ",,1734,57
openstack%2Frally~master~I06fdef2a176266ab37325a421c10d386045cc2b9,openstack/rally,master,I06fdef2a176266ab37325a421c10d386045cc2b9,Switch to plugin base deployengines and serverproviders,MERGED,2015-02-03 16:48:01.000000000,2015-06-10 05:18:23.000000000,2015-06-10 05:18:21.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8576}, {'_account_id': 9180}, {'_account_id': 9545}, {'_account_id': 14135}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-02-03 16:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fd876b166014f6d291c4995c61d2de99f7da8c97', 'message': 'Switch to plugin base, part2\n\nThis patch attempts to switch to plugin base\nand unify deploy engines, serverproviders and\nscenario classes plugins.\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 2, 'created': '2015-02-06 12:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bfb5050efefeee3a4d29d699e2b0fa03e1ffd9c1', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch attempts to switch to plugin base\nand unify deployengines and serverproviders plugins.\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 3, 'created': '2015-02-06 12:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b9ff35002ba092271d04eb80d86717a6748b245f', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch attempts to switch to plugin base\nand unify deployengines and serverproviders plugins.\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 4, 'created': '2015-03-08 11:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4c2851f17490728d9b66ef819fa5af59e39dda39', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch attempts to switch to plugin base\nand unify deployengines and serverproviders plugins.\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 5, 'created': '2015-06-09 12:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8cf523274290ef177e4695871429e3222cba95a8', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch switch to plugin base and unify\ndeployengines and serverproviders plugins.\n\nCo-authored-by: Olga Kopylova <olkonami@gmail.com>\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 6, 'created': '2015-06-09 13:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5c1af9133169c21011abfd4472785b5a5ea5293d', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch switch to plugin base and unify\ndeployengines and serverproviders plugins.\n\nCo-authored-by: Olga Kopylova <olkonami@gmail.com>\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 7, 'created': '2015-06-09 13:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/72e261f05d7e80153d3dde2d788a86d97afbee0f', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch switch to plugin base and unify\ndeployengines and serverproviders plugins.\n\nCo-authored-by: Olga Kopylova <olkonami@gmail.com>\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 8, 'created': '2015-06-09 13:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4305233ac744671c08b8866e89ca78d548b57bec', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch switch to plugin base and unify\ndeployengines and serverproviders plugins.\n\nCo-authored-by: Olga Kopylova <olkonami@gmail.com>\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}, {'number': 9, 'created': '2015-06-09 19:41:12.000000000', 'files': ['rally/deploy/engines/existing.py', 'rally/deploy/serverprovider/providers/openstack.py', 'tests/unit/deploy/serverprovider/test_provider.py', 'rally/deploy/serverprovider/providers/existing.py', 'rally/deploy/serverprovider/providers/lxc.py', 'tests/unit/test_docstrings.py', 'rally/deploy/engines/lxc.py', 'tests/unit/cli/commands/test_info.py', 'tests/unit/deploy/test_engine.py', 'rally/deploy/engines/devstack.py', 'rally/exceptions.py', 'rally/cli/commands/info.py', 'rally/deploy/engines/fuel.py', 'rally/deploy/engines/multihost.py', 'rally/deploy/serverprovider/providers/virsh.py', 'rally/deploy/serverprovider/provider.py', 'rally/deploy/engine.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6339d8c886e7970bb07c6cbbf81a72f558c404f7', 'message': 'Switch to plugin base deployengines and serverproviders\n\nThis patch switch to plugin base and unify\ndeployengines and serverproviders plugins.\n\nCo-authored-by: Olga Kopylova <olkonami@gmail.com>\nCo-authored-by: Boris Pavlovic <boris@pavlovic.me>\n\nChange-Id: I06fdef2a176266ab37325a421c10d386045cc2b9\n'}]",4,152612,6339d8c886e7970bb07c6cbbf81a72f558c404f7,42,7,9,9180,,,0,"Switch to plugin base deployengines and serverproviders

This patch switch to plugin base and unify
deployengines and serverproviders plugins.

Co-authored-by: Olga Kopylova <olkonami@gmail.com>
Co-authored-by: Boris Pavlovic <boris@pavlovic.me>

Change-Id: I06fdef2a176266ab37325a421c10d386045cc2b9
",git fetch https://review.opendev.org/openstack/rally refs/changes/12/152612/5 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/runners/base.py', 'rally/benchmark/scenarios/base.py', 'rally/common/plugin.py', 'rally/deploy/serverprovider/provider.py', 'rally/deploy/engine.py', 'rally/cmd/commands/info.py']",6,fd876b166014f6d291c4995c61d2de99f7da8c97,refactor_a_bit_plugins, scenario_group = scenario_base.Scenario.get(query) deploy_engine = deploy.EngineFactory.get(query) server_provider = serverprovider.ProviderFactory.get(query), scenario_group = scenario_base.Scenario.get_by_name(query) deploy_engine = deploy.EngineFactory.get_by_name(query) server_provider = serverprovider.ProviderFactory.get_by_name(query),17,52
openstack%2Fceilometer~master~I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138,openstack/ceilometer,master,I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138,Fix testing of agent manager with tooz,MERGED,2015-06-09 10:12:40.000000000,2015-06-10 05:17:38.000000000,2015-06-10 05:17:36.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 11564}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-06-09 10:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/79bb3d2c0a75c62aee77e9feb34e4472d8c8ecd4', 'message': 'Fix testing of agent manager with tooz\n\nChange-Id: I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138\n'}, {'number': 2, 'created': '2015-06-09 11:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0bd12af94708cdd85771a1a6f2833fea2d53f1bd', 'message': ""Fix testing of agent manager with tooz\n\nThe test test_load_plugins_pollster_list_forbidden is currently failing\nbecause the agent tries to load the tooz driver before doing the sanity\ncheck. That makes tooz trying to load an http driver that does not\nexist, and the test fails.\n\nLet's do the check before anything else to fix that.\n\nChange-Id: I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138\n""}, {'number': 3, 'created': '2015-06-09 13:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8791f37096e93d1aace0de6d1a65e6b684c3aeea', 'message': ""Fix testing of agent manager with tooz\n\nThe test test_load_plugins_pollster_list_forbidden is currently failing\nbecause the agent tries to load the tooz driver before doing the sanity\ncheck. That makes tooz trying to load an http driver that does not\nexist, and the test fails.\n\nLet's do the check before anything else to fix that.\n\nChange-Id: I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138\n""}, {'number': 4, 'created': '2015-06-10 01:52:50.000000000', 'files': ['ceilometer/tests/agent/test_manager.py', 'ceilometer/agent/base.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2354672910eb6491d10f86d7de5346b6d88189a9', 'message': ""Fix testing of agent manager with tooz\n\nThe test test_load_plugins_pollster_list_forbidden is currently failing\nbecause the agent tries to load the tooz driver before doing the sanity\ncheck. That makes tooz trying to load an http driver that does not\nexist, and the test fails.\n\nLet's do the check before anything else to fix that.\n\nCloses-Bug: #1463636\nChange-Id: I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138""}]",0,189633,2354672910eb6491d10f86d7de5346b6d88189a9,17,5,4,1669,,,0,"Fix testing of agent manager with tooz

The test test_load_plugins_pollster_list_forbidden is currently failing
because the agent tries to load the tooz driver before doing the sanity
check. That makes tooz trying to load an http driver that does not
exist, and the test fails.

Let's do the check before anything else to fix that.

Closes-Bug: #1463636
Change-Id: I646ac0ed0fb9db04fa81f10cd8da0ac7bff5c138",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/33/189633/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/agent/base.py'],1,79bb3d2c0a75c62aee77e9feb34e4472d8c8ecd4,jd/fix/coordination-override," # features of using coordination and pollster-list are exclusive, and # cannot be used at one moment to avoid both samples duplication and # samples being lost if pollster_list and cfg.CONF.coordination.backend_url: raise PollsterListForbidden() "," # features of using coordination and pollster-list are exclusive, and # cannot be used at one moment to avoid both samples duplication and # samples being lost if pollster_list and cfg.CONF.coordination.backend_url: raise PollsterListForbidden() ",6,6
