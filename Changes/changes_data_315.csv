id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I156f0cd32bf028a2027b6baa6c4c999c239ca746,openstack/tripleo-heat-templates,stable/train,I156f0cd32bf028a2027b6baa6c4c999c239ca746,Adding ReaR THT,MERGED,2019-11-25 10:00:55.000000000,2020-01-20 17:54:56.000000000,2020-01-20 17:52:43.000000000,"[{'_account_id': 7144}, {'_account_id': 8932}, {'_account_id': 9592}, {'_account_id': 11085}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-25 10:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fd92f5d3e567431af52f0e539726b91607a76f25', 'message': 'Adding ReaR THT\n\nAdding a THT to install and configure ReaR.\n\nDepends-On: I960e45f2162f8e1257f952a14e7f876468aa8fca\nCloses-Bug: #1853819\n\nChange-Id: I156f0cd32bf028a2027b6baa6c4c999c239ca746\n(cherry picked from commit 79bd7c447b11cc8d2eee9ed20e14dc575fd070a7)\n'}, {'number': 2, 'created': '2020-01-09 13:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc9858a9872ba158d55ee44702ed36829d2413f9', 'message': 'Adding ReaR THT\n\nAdding a THT to install and configure ReaR.\n\nDepends-On: I960e45f2162f8e1257f952a14e7f876468aa8fca\nCloses-Bug: #1853819\n\nChange-Id: I156f0cd32bf028a2027b6baa6c4c999c239ca746\n(cherry picked from commit 79bd7c447b11cc8d2eee9ed20e14dc575fd070a7)\n'}, {'number': 3, 'created': '2020-01-09 14:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f62c45048612b7bd268bbe70fd1ac89d46d5b2b8', 'message': 'Adding ReaR THT\n\nAdding a THT to install and configure ReaR.\n\nDepends-On: I960e45f2162f8e1257f952a14e7f876468aa8fca\nCloses-Bug: #1853819\n\nChange-Id: I156f0cd32bf028a2027b6baa6c4c999c239ca746\n(cherry picked from commit 79bd7c447b11cc8d2eee9ed20e14dc575fd070a7)\n'}, {'number': 4, 'created': '2020-01-09 14:19:26.000000000', 'files': ['roles/HciCephAll.yaml', 'roles/HciCephObject.yaml', 'environments/undercloud.yaml', 'roles/ComputeOvsDpdkRT.yaml', 'roles/ComputeOvsDpdk.yaml', 'roles_data.yaml', 'roles/ControllerStorageDashboard.yaml', 'roles/HciCephMon.yaml', 'roles/UndercloudMinion.yaml', 'environments/backup-and-restore/rear.yaml', 'releasenotes/notes/adding-rear-service-5fac71fa6fbd9c9e.yaml', 'environments/standalone/standalone-tripleo.yaml', 'roles/ComputeSriov.yaml', 'roles/ComputeSriovRT.yaml', 'roles/Controller.yaml', 'roles/ComputePPC64LE.yaml', 'roles/ComputeRealTime.yaml', 'roles_data_undercloud.yaml', 'environments/hyperconverged-ceph.yaml', 'roles/ControllerOpenstack.yaml', 'sample-env-generator/standalone.yaml', 'roles/Standalone.yaml', 'roles/ControllerStorageNfs.yaml', 'roles/HciCephFile.yaml', 'deployment/backup-and-restore/rear-baremetal-ansible.yaml', 'roles/ComputeLocalEphemeral.yaml', 'roles/BlockStorage.yaml', 'roles/Compute.yaml', 'roles/ComputeHCI.yaml', 'roles/ComputeHCIOvsDpdk.yaml', 'roles/ControllerNoCeph.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'roles/ComputeRBDEphemeral.yaml', 'roles/ObjectStorage.yaml', 'roles/Undercloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d7618097307c3480e73db1f310da0e848745e467', 'message': 'Adding ReaR THT\n\nAdding a THT to install and configure ReaR.\n\nDepends-On: I960e45f2162f8e1257f952a14e7f876468aa8fca\nCloses-Bug: #1853819\n\nChange-Id: I156f0cd32bf028a2027b6baa6c4c999c239ca746\n(cherry picked from commit 79bd7c447b11cc8d2eee9ed20e14dc575fd070a7)\n'}]",0,695872,d7618097307c3480e73db1f310da0e848745e467,26,8,4,20775,,,0,"Adding ReaR THT

Adding a THT to install and configure ReaR.

Depends-On: I960e45f2162f8e1257f952a14e7f876468aa8fca
Closes-Bug: #1853819

Change-Id: I156f0cd32bf028a2027b6baa6c4c999c239ca746
(cherry picked from commit 79bd7c447b11cc8d2eee9ed20e14dc575fd070a7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/695872/3 && git format-patch -1 --stdout FETCH_HEAD,"['roles/HciCephAll.yaml', 'roles/HciCephObject.yaml', 'environments/undercloud.yaml', 'roles/ComputeOvsDpdkRT.yaml', 'roles/ComputeOvsDpdk.yaml', 'roles_data.yaml', 'roles/HciCephMon.yaml', 'roles/UndercloudMinion.yaml', 'environments/backup-and-restore/rear.yaml', 'releasenotes/notes/adding-rear-service-5fac71fa6fbd9c9e.yaml', 'environments/standalone/standalone-tripleo.yaml', 'roles/ComputeSriov.yaml', 'roles/ComputeSriovRT.yaml', 'roles/Controller.yaml', 'roles/ComputePPC64LE.yaml', 'roles/ComputeRealTime.yaml', 'roles_data_undercloud.yaml', 'environments/hyperconverged-ceph.yaml', 'roles/ControllerOpenstack.yaml', 'sample-env-generator/standalone.yaml', 'roles/Standalone.yaml', 'roles/HciCephFile.yaml', 'deployment/backup-and-restore/rear-baremetal-ansible.yaml', 'roles/ComputeLocalEphemeral.yaml', 'roles/BlockStorage.yaml', 'roles/Compute.yaml', 'roles/ComputeHCI.yaml', 'roles/ComputeHCIOvsDpdk.yaml', 'roles/ControllerNoCeph.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'roles/ComputeRBDEphemeral.yaml', 'roles/ObjectStorage.yaml', 'roles/Undercloud.yaml']",33,fd92f5d3e567431af52f0e539726b91607a76f25,bug/1853819, - OS::TripleO::Services::Rear,,140,0
openstack%2Fmistral~master~I0eecec4b4e64381cac005622b16c6d9e4bed4df6,openstack/mistral,master,I0eecec4b4e64381cac005622b16c6d9e4bed4df6,Fix keycloak authentication,MERGED,2019-12-27 09:21:43.000000000,2020-01-20 17:20:01.000000000,2020-01-17 10:10:05.000000000,"[{'_account_id': 8731}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}, {'_account_id': 30755}]","[{'number': 1, 'created': '2019-12-27 09:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4564e95c0f687eaf0d15737af414813526daf6d2', 'message': 'WIP: fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 2, 'created': '2019-12-27 09:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bf9818d06094fb0f19381b86df5ddcd68305f4f0', 'message': 'WIP: fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 3, 'created': '2019-12-27 11:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/47d6f62d924f83ce0850bc7eabb64073e77b9bc5', 'message': 'WIP: fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 4, 'created': '2019-12-30 05:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a850841095db1dca26e1d7bc02c7288475f0c836', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 5, 'created': '2019-12-30 05:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/de4ea6b7058f61898cf4a4aac1ec28cd2f8489fb', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nCloses-bug: #1857871\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 6, 'created': '2019-12-30 07:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/df1090bf7435422a390ea40d2d6bda6f8efc3702', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nCloses-bug: #1857871\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 7, 'created': '2020-01-13 07:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f7fcac6eafe4b507d7223e8496e2024e5f6841e4', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nCloses-bug: #1857871\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 8, 'created': '2020-01-14 06:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/37cd3db07cf1a4eedd1a909110eda1072d204977', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nCloses-bug: #1857871\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 9, 'created': '2020-01-14 06:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/33dd3d121acfad607ee15bd72217481b18b33653', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nCloses-bug: #1857871\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}, {'number': 10, 'created': '2020-01-14 08:51:21.000000000', 'files': ['requirements.txt', 'mistral/context.py', 'mistral/config.py', 'mistral/tests/unit/api/v2/test_keycloak_auth.py', 'lower-constraints.txt', 'mistral/auth/keycloak.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/c888a46ccc46346deee8d483a706918341bc0a7f', 'message': 'Fix keycloak authentication\n\n* Implement offline access token validation using Keycloak public key.\n\nCloses-bug: #1857871\nChange-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6\n'}]",4,700695,c888a46ccc46346deee8d483a706918341bc0a7f,40,7,10,8731,,,0,"Fix keycloak authentication

* Implement offline access token validation using Keycloak public key.

Closes-bug: #1857871
Change-Id: I0eecec4b4e64381cac005622b16c6d9e4bed4df6
",git fetch https://review.opendev.org/openstack/mistral refs/changes/95/700695/8 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/config.py', 'mistral/auth/keycloak.py']",2,4564e95c0f687eaf0d15737af414813526daf6d2,bug/1857871,"from cachetools import cached from cachetools import LRUCache import jsonfrom jwt import algorithms as jwt_algos def authenticate(self, req): decoded = jwt.decode( access_token, algorithms=['RS256'], verify=False ) audience = decoded.get('aud') self.send_request_to_auth_server( url=user_info_endpoint_url, access_token=access_token else: public_key = self.get_public_key(realm_name) keycloak_iss = None try: if CONF.keycloak_oidc.keycloak_iss: keycloak_iss = CONF.keycloak_oidc.keycloak_iss % realm_name jwt.decode( access_token, public_key, audience=audience, issuer=keycloak_iss, algorithms=['RS256'], verify=True ) except Exception as e: LOG.exception('The request access token is invalid.') raise exc.UnauthorizedException() ca_path = [ '/etc/ssl/certs/ca-certificates.crt', '/etc/pki/tls/certs/ca-bundle.crt', '/etc/ssl/ca-bundle.pem', '/etc/ssl/cert.pem', '/System/Library/OpenSSL/certs/cacert.pem', requests.certs.where() ] @cached(LRUCache(maxsize=32)) def get_public_key(self, realm_name): keycloak_key_url = ( CONF.keycloak_oidc.auth_url + CONF.keycloak_oidc.public_cert_url % realm_name ) response_json = self.send_request_to_auth_server(keycloak_key_url) public_key = jwt_algos.RSAAlgorithm.from_jwk(json.dumps( response_json.get('keys')[0]) ) return public_key def send_request_to_auth_server(self, url, access_token=None): verify = None if urllib.parse.urlparse(url).scheme == ""https"": verify = False if self.insecure else self.cafile cert = (self.certfile, self.keyfile) \ if self.certfile and self.keyfile else None headers = {} if access_token: headers[""Authorization""] = ""Bearer %s"" % access_token try: resp = requests.get( url, headers=headers, verify=verify, cert=cert ) except requests.ConnectionError as e: msg = _( ""Can't connect to the keycloak server with address '%s'."" ) % url LOG.error(msg, e) raise exc.MistralException(message=msg) LOG.debug( ""HTTP response from the OIDC provider: %s"", pprint.pformat(resp.json()) ) if resp.status_code == 401: LOG.warning( ""HTTP response from OIDC provider:"" "" [%s] with WWW-Authenticate: [%s]"", pprint.pformat(resp.text), resp.headers.get(""WWW-Authenticate"") ) resp.raise_for_status() return resp.json()"," def authenticate(self, req): certfile = CONF.keycloak_oidc.certfile keyfile = CONF.keycloak_oidc.keyfile cafile = CONF.keycloak_oidc.cafile or self.get_system_ca_file() insecure = CONF.keycloak_oidc.insecure decoded = jwt.decode(access_token, algorithms=['RS256'], verify=False) user_info_endpoint = user_info_endpoint_url else: user_info_endpoint = ( (""%s"" + user_info_endpoint_url) % (CONF.keycloak_oidc.auth_url, realm_name)) verify = None if urllib.parse.urlparse(user_info_endpoint).scheme == ""https"": verify = False if insecure else cafile cert = (certfile, keyfile) if certfile and keyfile else None try: resp = requests.get( user_info_endpoint, headers={""Authorization"": ""Bearer %s"" % access_token}, verify=verify, cert=cert except requests.ConnectionError: msg = _(""Can't connect to keycloak server with address '%s'."" ) % CONF.keycloak_oidc.auth_url LOG.error(msg) raise exc.MistralException(message=msg) if resp.status_code == 401: LOG.warning(""HTTP response from OIDC provider:"" "" [%s] with WWW-Authenticate: [%s]"", pprint.pformat(resp.text), resp.headers.get(""WWW-Authenticate"")) else: LOG.debug(""HTTP response from OIDC provider: %s"", pprint.pformat(resp.text)) resp.raise_for_status() LOG.debug( ""HTTP response from OIDC provider: %s"", pprint.pformat(resp.json()) ) ca_path = ['/etc/ssl/certs/ca-certificates.crt', '/etc/pki/tls/certs/ca-bundle.crt', '/etc/ssl/ca-bundle.pem', '/etc/ssl/cert.pem', '/System/Library/OpenSSL/certs/cacert.pem', requests.certs.where()]",120,50
openstack%2Fpython-openstackclient~stable%2Ftrain~Ie7f49583835360fa531af46e3e70f3cae4f864d8,openstack/python-openstackclient,stable/train,Ie7f49583835360fa531af46e3e70f3cae4f864d8,DNM: test jobs health,ABANDONED,2019-11-20 16:23:25.000000000,2020-01-20 17:15:32.000000000,,"[{'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-20 16:23:25.000000000', 'files': ['openstackclient/tests/functional/common/test_help.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/861b5f9a5448a6bc60da268443b519fe3efd99ea', 'message': 'DNM: test jobs health\n\nChange-Id: Ie7f49583835360fa531af46e3e70f3cae4f864d8\n'}]",0,695236,861b5f9a5448a6bc60da268443b519fe3efd99ea,5,2,1,17685,,,0,"DNM: test jobs health

Change-Id: Ie7f49583835360fa531af46e3e70f3cae4f864d8
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/36/695236/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/common/test_help.py'],1,861b5f9a5448a6bc60da268443b519fe3efd99ea,do-not-merge," """"""Functional tests for openstackclient help output. Dummy change """""""," """"""Functional tests for openstackclient help output.""""""",3,1
openstack%2Fbifrost~master~I065b515e66ced54daaa7e607b89137bd10a1e2f7,openstack/bifrost,master,I065b515e66ced54daaa7e607b89137bd10a1e2f7,Define venv package for debian based distro,MERGED,2020-01-20 08:51:31.000000000,2020-01-20 17:14:54.000000000,2020-01-20 17:13:08.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-20 08:51:31.000000000', 'files': ['scripts/install-deps.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1a41d469edaa331fe90c56be31398f5bef22ef40', 'message': ""Define venv package for debian based distro\n\nOn L115 we ask to install the [venv] package in case we're unable\nto create the virtual environment.\nFor Ubuntu Bionic the package needed is python3-venv.\n\nChange-Id: I065b515e66ced54daaa7e607b89137bd10a1e2f7\n""}]",0,703343,1a41d469edaa331fe90c56be31398f5bef22ef40,9,4,1,23851,,,0,"Define venv package for debian based distro

On L115 we ask to install the [venv] package in case we're unable
to create the virtual environment.
For Ubuntu Bionic the package needed is python3-venv.

Change-Id: I065b515e66ced54daaa7e607b89137bd10a1e2f7
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/43/703343/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/install-deps.sh'],1,1a41d469edaa331fe90c56be31398f5bef22ef40,define-venv-deb-based, [venv]=python3-venv,,1,0
openstack%2Fpython-openstackclient~stable%2Fstein~I92ebcb8897630211a62f9682744f71be72c56fa8,openstack/python-openstackclient,stable/stein,I92ebcb8897630211a62f9682744f71be72c56fa8,DNM: test jobs health,ABANDONED,2020-01-09 17:41:21.000000000,2020-01-20 17:12:35.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 17:41:21.000000000', 'files': ['openstackclient/tests/functional/common/test_help.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a06715941e222180b8d863579153a913a7536dbc', 'message': 'DNM: test jobs health\n\nChange-Id: I92ebcb8897630211a62f9682744f71be72c56fa8\n'}]",0,701781,a06715941e222180b8d863579153a913a7536dbc,4,2,1,17685,,,0,"DNM: test jobs health

Change-Id: I92ebcb8897630211a62f9682744f71be72c56fa8
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/81/701781/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/common/test_help.py'],1,a06715941e222180b8d863579153a913a7536dbc,do-not-merge,# Dummy change,,1,0
openstack%2Ftripleo-common~master~Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8,openstack/tripleo-common,master,Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8,DNM: Testing element_path additions,ABANDONED,2019-11-21 21:56:06.000000000,2020-01-20 17:00:42.000000000,,"[{'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-11-21 21:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/70f2031b0f6957fcf9a8edfc7b79574c82939565', 'message': 'DNM: Testing element_path additions\n\nChange-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8\n'}, {'number': 2, 'created': '2019-11-21 22:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/801c96065af0da0c9b1228e628be934f29c15047', 'message': 'DNM: Testing element_path additions\n\nChange-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8\n'}, {'number': 3, 'created': '2019-11-21 22:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/49c23e814195ec3ca6d65bb8b2cacf99bc4636b4', 'message': 'DNM: Testing element_path additions\n\nChange-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8\n'}, {'number': 4, 'created': '2019-11-22 16:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/da3f0c4fd4d82c59b942581efd6372bf38bca0b9', 'message': 'DNM: Testing element_path additions\n\nChange-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8\n'}, {'number': 5, 'created': '2020-01-20 16:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e3aae82ddc24abd04a812f035948b76db69ce5ce', 'message': 'DNM: Testing element_path additions\n\nChange-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8\n'}, {'number': 6, 'created': '2020-01-20 16:50:30.000000000', 'files': ['tripleo_common/image/image_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/18d60dd28f32c579e588ec7822bca0666e3278f5', 'message': 'DNM: Testing element_path additions\n\nChange-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8\nStory: https://tree.taiga.io/project/tripleo-ci-board/task/1346?kanban-status=1447275\n'}]",2,695591,18d60dd28f32c579e588ec7822bca0666e3278f5,21,6,6,9976,,,0,"DNM: Testing element_path additions

Change-Id: Ic6e3fd4c4843f8963468c2f7693f5d054fdd5bb8
Story: https://tree.taiga.io/project/tripleo-ci-board/task/1346?kanban-status=1447275
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/91/695591/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_builder.py'],1,70f2031b0f6957fcf9a8edfc7b79574c82939565,image-builder-elements-path," additional_elements = [ '/usr/share/heat-agents', ] for element in additional_elements: if element not in elements_path: env['ELEMENTS_PATH'] += os.pathsep.join(element) os.environ.update(env)", if elements_path is None: env['ELEMENTS_PATH'] = os.pathsep.join([ ]) os.environ.update(env),7,4
openstack%2Fheat-dashboard~master~I95c81cfd6ab9bc7384c585ef5aa625dad9a57caf,openstack/heat-dashboard,master,I95c81cfd6ab9bc7384c585ef5aa625dad9a57caf,s/assertItemsEqual/assertCountEqual/g,MERGED,2020-01-20 15:44:14.000000000,2020-01-20 16:58:47.000000000,2020-01-20 16:56:16.000000000,"[{'_account_id': 841}, {'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 15:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/4b8fba282df17d7c00bccaed510541c325a05354', 'message': 's/assertItemsEqual/assertCountEqual/g\n\nassertItemsEqual was renamed to assertCountEqual in Python 3, and the\ntestsuite is failing now - rename it.\n\nChange-Id: I95c81cfd6ab9bc7384c585ef5aa625dad9a57caf\n'}, {'number': 2, 'created': '2020-01-20 15:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/accfa53aa27f0f8d355d9a790ad7124686280d8a', 'message': 's/assertItemsEqual/assertCountEqual/g\n\nassertItemsEqual was renamed to assertCountEqual in Python 3, and the\ntestsuite is failing now - rename it.\nSee also https://six.readthedocs.io/#six.assertCountEqual\n\nChange-Id: I95c81cfd6ab9bc7384c585ef5aa625dad9a57caf\n'}, {'number': 3, 'created': '2020-01-20 15:52:09.000000000', 'files': ['heat_dashboard/test/tests/api/test_heat.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/30c4992796f9abb9c4b9fa8aa1e6e7b893f9397f', 'message': 's/assertItemsEqual/assertCountEqual/g\n\nassertItemsEqual was renamed to assertCountEqual in Python 3, and the\ntestsuite is failing now - rename it.\nSee also https://six.readthedocs.io/#six.assertCountEqual\n\nThis unbreaks the testsuite.\n\nChange-Id: I95c81cfd6ab9bc7384c585ef5aa625dad9a57caf\n'}]",0,703430,30c4992796f9abb9c4b9fa8aa1e6e7b893f9397f,13,4,3,6547,,,0,"s/assertItemsEqual/assertCountEqual/g

assertItemsEqual was renamed to assertCountEqual in Python 3, and the
testsuite is failing now - rename it.
See also https://six.readthedocs.io/#six.assertCountEqual

This unbreaks the testsuite.

Change-Id: I95c81cfd6ab9bc7384c585ef5aa625dad9a57caf
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/30/703430/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_dashboard/test/tests/api/test_heat.py'],1,4b8fba282df17d7c00bccaed510541c325a05354,remove-six," self.assertCountEqual(stacks, api_stacks) self.assertCountEqual(stacks, api_stacks) self.assertCountEqual(stacks, expected_stacks) self.assertCountEqual(stacks, expected_stacks) self.assertCountEqual(stacks, api_stacks[:page_size]) self.assertCountEqual(stacks, api_stacks[:page_size]) self.assertCountEqual(returned_snapshots, snapshot_list) self.assertCountEqual(template_versions, api_template_versions) self.assertCountEqual(template_functions, api_template_functions)"," self.assertItemsEqual(stacks, api_stacks) self.assertItemsEqual(stacks, api_stacks) self.assertItemsEqual(stacks, expected_stacks) self.assertItemsEqual(stacks, expected_stacks) self.assertItemsEqual(stacks, api_stacks[:page_size]) self.assertItemsEqual(stacks, api_stacks[:page_size]) self.assertItemsEqual(returned_snapshots, snapshot_list) self.assertItemsEqual(template_versions, api_template_versions) self.assertItemsEqual(template_functions, api_template_functions)",9,9
openstack%2Fcinder~master~I300a830a4f3fa897b2d7c19cbb131c4675427096,openstack/cinder,master,I300a830a4f3fa897b2d7c19cbb131c4675427096,Add upgrade check for removed FusionStorage drivers,ABANDONED,2020-01-15 15:53:40.000000000,2020-01-20 16:55:39.000000000,,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22126}, {'_account_id': 22348}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30688}]","[{'number': 1, 'created': '2020-01-15 15:53:40.000000000', 'files': ['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3708c1b3702dda85be481809e7d84dbfd5920333', 'message': 'Add upgrade check for removed FusionStorage drivers\n\nThe FusionStorage drivers have been removed. This adds an upgrade check\nto warn if they are still configured.\n\nThis also addresses some minor issues with the driver removal unit test\nthat was originally implemented specifically for the Stein release and\nspecifically for single driver removal.\n\nChange-Id: I300a830a4f3fa897b2d7c19cbb131c4675427096\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",1,702688,3708c1b3702dda85be481809e7d84dbfd5920333,32,26,1,11904,,,0,"Add upgrade check for removed FusionStorage drivers

The FusionStorage drivers have been removed. This adds an upgrade check
to warn if they are still configured.

This also addresses some minor issues with the driver removal unit test
that was originally implemented specifically for the Stein release and
specifically for single driver removal.

Change-Id: I300a830a4f3fa897b2d7c19cbb131c4675427096
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/88/702688/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py']",2,3708c1b3702dda85be481809e7d84dbfd5920333,ci_unsupported," ""fusionstorage"", Checks start with drivers removed in past releases.", Checks start with drivers removed in the Stein release.,5,3
openstack%2Fgovernance~master~I599d84d2b75681449f357c316480772621a069ec,openstack/governance,master,I599d84d2b75681449f357c316480772621a069ec,Update charter for the TC elections date & Term clarification.,MERGED,2019-12-16 18:57:00.000000000,2020-01-20 16:52:17.000000000,2020-01-20 16:48:45.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 4257}, {'_account_id': 5263}, {'_account_id': 7198}, {'_account_id': 7353}, {'_account_id': 8556}, {'_account_id': 10343}, {'_account_id': 10607}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 13995}, {'_account_id': 16708}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-16 18:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/ae572797a8189849dab5855d0cc37bfabed8eb9f', 'message': 'Update charter for the TC & PTL elections date\n\nChange-Id: I599d84d2b75681449f357c316480772621a069ec\n'}, {'number': 2, 'created': '2019-12-18 19:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/268e459093063f839d08fc30e8d249a765b4d3aa', 'message': 'Update charter for the TC & PTL elections date\n\nChange-Id: I599d84d2b75681449f357c316480772621a069ec\n'}, {'number': 3, 'created': '2019-12-23 06:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a9dbc1f17a257d16bd9c07f8d32a03bdbc265007', 'message': 'Update charter for the TC & PTL elections date\n\nChange-Id: I599d84d2b75681449f357c316480772621a069ec\n'}, {'number': 4, 'created': '2020-01-07 12:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/4968f189804f1b639ca3bc6a0cfddc6782d52de5', 'message': 'Update charter for the TC & PTL elections date\n\nChange-Id: I599d84d2b75681449f357c316480772621a069ec\n'}, {'number': 5, 'created': '2020-01-14 19:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/11a1263020088bb986230c6a44f7dcdceadaf56d', 'message': 'Update charter for the TC elections date & Term clarification.\n\nThis change propose two changes in charter:\n\n1. Revise the TC election dates + Clarify the TC terms.\n2. Add election required for the vacancy if there\nare no candidates available to fill the vacant seats when needed.\n\nChange-Id: I599d84d2b75681449f357c316480772621a069ec\n'}, {'number': 6, 'created': '2020-01-14 20:04:04.000000000', 'files': ['reference/charter.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/a29b5721aaa69f7138b7c0f08ccd5b8b9c822e34', 'message': 'Update charter for the TC elections date & Term clarification.\n\nThis change propose two changes in charter:\n\n1. Revise the TC election dates + Clarify the TC terms.\n2. Add election required for the vacancy if there\nare no candidates available to fill the vacant seats when needed.\n\nChange-Id: I599d84d2b75681449f357c316480772621a069ec\n'}]",41,699277,a29b5721aaa69f7138b7c0f08ccd5b8b9c822e34,54,15,6,8556,,,0,"Update charter for the TC elections date & Term clarification.

This change propose two changes in charter:

1. Revise the TC election dates + Clarify the TC terms.
2. Add election required for the vacancy if there
are no candidates available to fill the vacant seats when needed.

Change-Id: I599d84d2b75681449f357c316480772621a069ec
",git fetch https://review.opendev.org/openstack/governance refs/changes/77/699277/6 && git format-patch -1 --stdout FETCH_HEAD,['reference/charter.rst'],1,ae572797a8189849dab5855d0cc37bfabed8eb9f,charter-change,"is run for each project team. These elections are collectively held during 4th week (R-4) prior to each cycle final release date and should be held open for no less than four business days. TC and PTL elections are held as combined election.Seats are valid for two development cycle terms. For this election we'll use a multiple-winner election system (see below). The election is held during 4th week (R-4) prior to each cycle final release date, with elections held open for no less than four business days. TC and PTL elections are held as combined election.","is run for each project team. These elections are collectively held no later than 3 weeks prior to each cycle final release date (on or before 'R-3' week) and should be held open for no less than four business days.Seats are valid for one-year terms. For this election we'll use a multiple-winner election system (see below). The election is held no later than 6 weeks prior to each OpenStack Summit (on or before 'S-6' week), with elections held open for no less than four business days.",10,7
openstack%2Fpaunch~master~I3f79a42da8798e24fad1a3ccc18efcc26e118c4d,openstack/paunch,master,I3f79a42da8798e24fad1a3ccc18efcc26e118c4d,Return an error if tripleo-ansible deployed containers,MERGED,2019-11-26 17:25:43.000000000,2020-01-20 16:25:08.000000000,2020-01-07 18:01:41.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-11-26 17:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/880e242f637a63f9edfc03f84819a983cf808cde', 'message': ""Return an error if tripleo-ansible deployed containers\n\nFor now, we assume that tripleo-ansible & paunch aren't playing well\ntogether. So let's make sure that when containers were deployed with\ntripleo-ansible, paunch CLI can't be used anymore.\n\nDepends-On: I722cb8faa3b7eee81b418da83451bf802351dd79\nChange-Id: I3f79a42da8798e24fad1a3ccc18efcc26e118c4d\n""}, {'number': 2, 'created': '2019-11-27 04:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/4d5d1e46f5d03c2274f8345404013c7dc5066990', 'message': ""Return an error if tripleo-ansible deployed containers\n\nFor now, we assume that tripleo-ansible & paunch aren't playing well\ntogether. So let's make sure that when containers were deployed with\ntripleo-ansible, paunch CLI can't be used anymore.\n\nDepends-On: I722cb8faa3b7eee81b418da83451bf802351dd79\nChange-Id: I3f79a42da8798e24fad1a3ccc18efcc26e118c4d\n""}, {'number': 3, 'created': '2019-12-03 15:47:49.000000000', 'files': ['paunch/builder/base.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/3e19521fd47d39c6069399e42aad832a78ebcb78', 'message': ""Return an error if tripleo-ansible deployed containers\n\nFor now, we assume that tripleo-ansible & paunch aren't playing well\ntogether. So let's make sure that when containers were deployed with\ntripleo-ansible, paunch CLI can't be used anymore.\n\nDepends-On: I722cb8faa3b7eee81b418da83451bf802351dd79\nChange-Id: I3f79a42da8798e24fad1a3ccc18efcc26e118c4d\n""}]",3,696141,3e19521fd47d39c6069399e42aad832a78ebcb78,25,7,3,3153,,,0,"Return an error if tripleo-ansible deployed containers

For now, we assume that tripleo-ansible & paunch aren't playing well
together. So let's make sure that when containers were deployed with
tripleo-ansible, paunch CLI can't be used anymore.

Depends-On: I722cb8faa3b7eee81b418da83451bf802351dd79
Change-Id: I3f79a42da8798e24fad1a3ccc18efcc26e118c4d
",git fetch https://review.opendev.org/openstack/paunch refs/changes/41/696141/3 && git format-patch -1 --stdout FETCH_HEAD,['paunch/builder/base.py'],1,880e242f637a63f9edfc03f84819a983cf808cde,warning_paunch," if os.path.isfile('/var/lib/tripleo-config/.ansible-managed'): self.log.error(""Containers were previously deployed with "" ""tripleo-ansible, paunch CLI can not be used"".) ",,4,0
openstack%2Fopenstack-zuul-jobs~master~Iebe51ede1e80ce256a1f6015746e8ed62a3d946b,openstack/openstack-zuul-jobs,master,Iebe51ede1e80ce256a1f6015746e8ed62a3d946b,Increase hacking version,MERGED,2020-01-19 16:04:34.000000000,2020-01-20 16:13:08.000000000,2020-01-20 16:11:35.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-19 16:04:34.000000000', 'files': ['test-requirements.txt', 'roles/prepare-zanata-client/files/get-modulename.py'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/3e151e98186d1a3e42a1ac1cd4db56881e18266b', 'message': ""Increase hacking version\n\nLet's use hacking 2.0 to get newer Python3 pep8.\nFix the one error found (E305: expected two lines...).\n\nChange-Id: Iebe51ede1e80ce256a1f6015746e8ed62a3d946b\n""}]",0,703298,3e151e98186d1a3e42a1ac1cd4db56881e18266b,8,3,1,6547,,,0,"Increase hacking version

Let's use hacking 2.0 to get newer Python3 pep8.
Fix the one error found (E305: expected two lines...).

Change-Id: Iebe51ede1e80ce256a1f6015746e8ed62a3d946b
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/98/703298/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/prepare-zanata-client/files/get-modulename.py', 'test-requirements.txt']",2,3e151e98186d1a3e42a1ac1cd4db56881e18266b,docs-building,"hacking>=2.0.0,<2.1 # Apache-2.0","hacking>=1.1.0,<1.2 # Apache-2.0",2,1
openstack%2Fopenstack-zuul-jobs~master~I199b8ceff5740c775804ff0db52704df8cbd7b86,openstack/openstack-zuul-jobs,master,I199b8ceff5740c775804ff0db52704df8cbd7b86,Update docs building,MERGED,2020-01-19 15:58:36.000000000,2020-01-20 16:10:09.000000000,2020-01-20 16:08:44.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-19 15:58:36.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/1dde1e30e9b6f571f3b765a14f3b7071294e8740', 'message': 'Update docs building\n\nSwitch from python setup.py to calling sphinx-build directly, add\na new doc requirements.txt file.\n\nChange-Id: I199b8ceff5740c775804ff0db52704df8cbd7b86\n'}]",0,703297,1dde1e30e9b6f571f3b765a14f3b7071294e8740,8,3,1,6547,,,0,"Update docs building

Switch from python setup.py to calling sphinx-build directly, add
a new doc requirements.txt file.

Change-Id: I199b8ceff5740c775804ff0db52704df8cbd7b86
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/97/703297/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",4,1dde1e30e9b6f571f3b765a14f3b7071294e8740,docs-building,deps = -r{toxinidir}/doc/requirements.txt commands = sphinx-build -W -b html -d doc/build/doctrees doc/source doc/build/html,commands = python setup.py build_sphinx,5,8
openstack%2Fcharm-swift-proxy~master~I1902bf0a138e0db7e4e01807e6e9c4dc08d5bcbc,openstack/charm-swift-proxy,master,I1902bf0a138e0db7e4e01807e6e9c4dc08d5bcbc,[DEBUG] Test with new zaza tests,ABANDONED,2020-01-16 19:00:18.000000000,2020-01-20 16:04:18.000000000,,"[{'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 19:00:18.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/ad3a1eb6cc8650931956e62d6a8b934f644b2cfc', 'message': '[DEBUG] Test with new zaza tests\n\nChange-Id: I1902bf0a138e0db7e4e01807e6e9c4dc08d5bcbc\n'}]",0,702955,ad3a1eb6cc8650931956e62d6a8b934f644b2cfc,13,3,1,17097,,,0,"[DEBUG] Test with new zaza tests

Change-Id: I1902bf0a138e0db7e4e01807e6e9c4dc08d5bcbc
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/55/702955/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ad3a1eb6cc8650931956e62d6a8b934f644b2cfc,,git+https://github.com/tpsilva/zaza-openstack-tests.git#egg=zaza.openstack,git+https://github.com/openstack-charmers/zaza-openstack-tests.git#egg=zaza.openstack,1,1
openstack%2Fcharm-neutron-api~master~I5763f1c5b01414d18b455bcbec89fe2d19e848b8,openstack/charm-neutron-api,master,I5763f1c5b01414d18b455bcbec89fe2d19e848b8,[DEBUG] Test with new zaza tests,ABANDONED,2020-01-16 18:59:33.000000000,2020-01-20 16:04:15.000000000,,"[{'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 18:59:33.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/ff209773a0da1f57d126027458f340e8ed61984c', 'message': '[DEBUG] Test with new zaza tests\n\nChange-Id: I5763f1c5b01414d18b455bcbec89fe2d19e848b8\n'}]",0,702954,ff209773a0da1f57d126027458f340e8ed61984c,14,3,1,17097,,,0,"[DEBUG] Test with new zaza tests

Change-Id: I5763f1c5b01414d18b455bcbec89fe2d19e848b8
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/54/702954/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ff209773a0da1f57d126027458f340e8ed61984c,,git+https://github.com/tpsilva/zaza-openstack-tests.git#egg=zaza.openstack,git+https://github.com/openstack-charmers/zaza-openstack-tests.git#egg=zaza.openstack,1,1
openstack%2Fcharm-nova-cloud-controller~master~Ic203d7d4013ade93999e3dc87e6a125539722e41,openstack/charm-nova-cloud-controller,master,Ic203d7d4013ade93999e3dc87e6a125539722e41,Disable Apache default ports,ABANDONED,2019-12-21 15:43:06.000000000,2020-01-20 16:04:12.000000000,,"[{'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-21 15:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/a410c1888713a8261c1872c948ca97558925f71a', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: Ic203d7d4013ade93999e3dc87e6a125539722e41\nCloses-bug: #1845665\n""}, {'number': 2, 'created': '2020-01-15 14:59:19.000000000', 'files': ['tests/basic_deployment.py', 'unit_tests/test_nova_cc_utils.py', 'templates/ports.conf', 'hooks/nova_cc_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/22882b9a3d27e7fea6d232004af6d501075833ea', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: Ic203d7d4013ade93999e3dc87e6a125539722e41\nCloses-bug: #1845665\n""}]",0,700280,22882b9a3d27e7fea6d232004af6d501075833ea,17,4,2,17097,,,0,"Disable Apache default ports

Openstack services don't use the default ports (80 and 443), so
change Apache to not open them.

Change-Id: Ic203d7d4013ade93999e3dc87e6a125539722e41
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/80/700280/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_utils.py', 'templates/ports.conf', 'hooks/nova_cc_utils.py']",3,a410c1888713a8261c1872c948ca97558925f71a,bug/1845665,"APACHE_PORTS_CONF = '/etc/apache2/ports.conf' (APACHE_PORTS_CONF, { 'contexts': [], 'services': ['apache2'], }), remove_apache2 = True remove_apache2 = False remove_apache2 = False remove_apache2 = False if remove_apache2 and (not hookenv.config('ssl_cert') and not hookenv.config('ssl_key')): for _, v in _resource_map.items(): if 'apache2' in v['services']: v['services'].remove('apache2') ",,18,13
openstack%2Fpuppet-swift~master~I271c218b45d10f15544077e93ded9d74d7842f65,openstack/puppet-swift,master,I271c218b45d10f15544077e93ded9d74d7842f65,Allow users to change container-replicator interval value.,MERGED,2019-10-31 20:51:58.000000000,2020-01-20 16:03:46.000000000,2020-01-20 16:03:46.000000000,"[{'_account_id': 597}, {'_account_id': 3153}, {'_account_id': 6968}, {'_account_id': 7130}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-31 20:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/bb40eaf3f4f8039cbd4cc1f75f2ce049a0903384', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 2, 'created': '2019-11-01 12:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/41371b67daabb502f6d2ddffb0386e1e5f724ca8', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 3, 'created': '2019-11-01 12:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/ad285cc01600f99180c3f133f40c115c4f01f385', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 4, 'created': '2019-11-01 12:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/604effadfc409af8b018a87639cd3414e4307405', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 5, 'created': '2019-11-04 14:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/6d9292ca749ed389d00395a3a490e4c549d2e82a', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 6, 'created': '2019-11-04 15:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/b5c7e07dc4ae747400869280f9b60d0f3aa2e5e3', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 7, 'created': '2019-11-04 15:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/9d5a2dca4ecc7cfc22124d353daa95b5f294d000', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 8, 'created': '2019-11-04 15:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/7c564b840799ab33501afa9e1d2ae4354d45da09', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 9, 'created': '2020-01-18 00:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/e7b3aec92135c4c8d2ef3439dd69e7958e474255', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 10, 'created': '2020-01-18 00:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/0ddf56032aa1977a49f18d7fad3796443ce99590', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 11, 'created': '2020-01-18 12:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/8e68136388f438017897a902706a823abefa0b13', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 12, 'created': '2020-01-18 13:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/4792edb2b3a369855ea8fc2f83aa15ab84ab8f64', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}, {'number': 13, 'created': '2020-01-18 13:18:11.000000000', 'files': ['spec/defines/swift_storage_server_spec.rb', 'templates/container-server.conf.erb', 'templates/account-server.conf.erb', 'manifests/storage/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/7d46d12b4103355a2bcb69395486631004ffe826', 'message': 'Allow users to change container-replicator interval value.\n\nThe default interval value is 30s and in some case, this is way\ntoo agressive and we need an automated way of tweaking this value.\n\nChange-Id: I271c218b45d10f15544077e93ded9d74d7842f65\nCloses-bug: #1850856\n'}]",2,692451,7d46d12b4103355a2bcb69395486631004ffe826,36,8,13,7130,,,0,"Allow users to change container-replicator interval value.

The default interval value is 30s and in some case, this is way
too agressive and we need an automated way of tweaking this value.

Change-Id: I271c218b45d10f15544077e93ded9d74d7842f65
Closes-bug: #1850856
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/51/692451/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/container-server.conf.erb', 'manifests/storage/server.pp']",2,bb40eaf3f4f8039cbd4cc1f75f2ce049a0903384,bug/1850856,"# [*replicator_interval*] # (optional) Minimum time for a pass to take # Defaults to 30. # $replicator_interval = 30,",,6,0
openstack%2Fcharm-swift-proxy~master~Ia0d99fd46e512b9d0cb1776afd6a5e520244ca67,openstack/charm-swift-proxy,master,Ia0d99fd46e512b9d0cb1776afd6a5e520244ca67,Disable Apache default ports,ABANDONED,2019-12-21 15:27:17.000000000,2020-01-20 16:02:53.000000000,,"[{'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-21 15:27:17.000000000', 'files': ['lib/swift_utils.py', 'unit_tests/test_swift_hooks.py', 'unit_tests/test_actions.py', 'templates/ports.conf'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/1ab1dcf8b97982e34c0a96de250addfe71f8f78c', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: Ia0d99fd46e512b9d0cb1776afd6a5e520244ca67\nCloses-bug: #1845665\n""}]",0,700279,1ab1dcf8b97982e34c0a96de250addfe71f8f78c,5,3,1,17097,,,0,"Disable Apache default ports

Openstack services don't use the default ports (80 and 443), so
change Apache to not open them.

Change-Id: Ia0d99fd46e512b9d0cb1776afd6a5e520244ca67
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/79/700279/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/swift_utils.py', 'unit_tests/test_swift_hooks.py', 'unit_tests/test_actions.py', 'templates/ports.conf']",4,1ab1dcf8b97982e34c0a96de250addfe71f8f78c,bug/1845665,,,14,2
openstack%2Fcharm-keystone~master~Ifccf09164e75558c87291a288565cd137bd2fbf6,openstack/charm-keystone,master,Ifccf09164e75558c87291a288565cd137bd2fbf6,Disable Apache default ports,ABANDONED,2019-12-21 14:22:06.000000000,2020-01-20 16:01:46.000000000,,"[{'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-21 14:22:06.000000000', 'files': ['hooks/keystone_utils.py', 'templates/ports.conf'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b4b32d645d4193d65d10d3ea63e66c6ee147b623', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: Ifccf09164e75558c87291a288565cd137bd2fbf6\nCloses-bug: #1845665\n""}]",0,700278,b4b32d645d4193d65d10d3ea63e66c6ee147b623,7,4,1,17097,,,0,"Disable Apache default ports

Openstack services don't use the default ports (80 and 443), so
change Apache to not open them.

Change-Id: Ifccf09164e75558c87291a288565cd137bd2fbf6
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/78/700278/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/keystone_utils.py', 'templates/ports.conf']",2,b4b32d645d4193d65d10d3ea63e66c6ee147b623,bug/1845665,,,10,0
openstack%2Fproject-config~master~Iee23f459c2f15051833337daa278cbb5f0cfab85,openstack/project-config,master,Iee23f459c2f15051833337daa278cbb5f0cfab85,Add ircbot and repo for Multi-Arch SIG,MERGED,2020-01-20 06:32:57.000000000,2020-01-20 16:01:18.000000000,2020-01-20 16:01:18.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 06:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9e9a72c4d3f4d1bd1f42afd15fd2ce076237eef1', 'message': 'Add ircbot and repo for Multi-Arch SIG\n\nChange-Id: Iee23f459c2f15051833337daa278cbb5f0cfab85\n'}, {'number': 2, 'created': '2020-01-20 14:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/150c31a8d65eb9ef5d8464af3de723a8a57064a5', 'message': 'Add ircbot and repo for Multi-Arch SIG\n\nChange-Id: Iee23f459c2f15051833337daa278cbb5f0cfab85\n'}, {'number': 3, 'created': '2020-01-20 15:24:52.000000000', 'files': ['gerritbot/channels.yaml', 'accessbot/channels.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack/multi-arch-sig.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/251d59bb0ebc7e7e2c771489a49b20e98936b4fc', 'message': 'Add ircbot and repo for Multi-Arch SIG\n\nNeeded-By: https://review.opendev.org/#/c/703326\nChange-Id: Iee23f459c2f15051833337daa278cbb5f0cfab85\n'}]",4,703323,251d59bb0ebc7e7e2c771489a49b20e98936b4fc,18,7,3,12404,,,0,"Add ircbot and repo for Multi-Arch SIG

Needed-By: https://review.opendev.org/#/c/703326
Change-Id: Iee23f459c2f15051833337daa278cbb5f0cfab85
",git fetch https://review.opendev.org/openstack/project-config refs/changes/23/703323/1 && git format-patch -1 --stdout FETCH_HEAD,"['accessbot/channels.yaml', 'gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/main.yaml', 'gerrit/acls/openstack/multi-arch-sig.config']",5,9e9a72c4d3f4d1bd1f42afd15fd2ce076237eef1,create-multi-arch-sig-infra,"[access ""refs/heads/*""] abandon = group multi-arch-sig-core label-Code-Review = -2..+2 group multi-arch-sig-core label-Workflow = -1..+1 group multi-arch-sig-core [receive] requireChangeId = true [submit] mergeContent = true ",,27,0
openstack%2Freleases~master~Ic87602814a6cf5d8f999c7e27210dd52d8fd92ce,openstack/releases,master,Ic87602814a6cf5d8f999c7e27210dd52d8fd92ce,Release Glance 19.0.1,MERGED,2020-01-20 07:09:37.000000000,2020-01-20 15:59:49.000000000,2020-01-20 15:59:49.000000000,"[{'_account_id': 308}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-20 07:09:37.000000000', 'files': ['deliverables/train/glance.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/66084445c66145462493d8fcfdcc4afb3b28833c', 'message': 'Release Glance 19.0.1\n\nPoint release of Train Glance; bugfixes\n\nChange-Id: Ic87602814a6cf5d8f999c7e27210dd52d8fd92ce\n'}]",0,703329,66084445c66145462493d8fcfdcc4afb3b28833c,8,7,1,9303,,,0,"Release Glance 19.0.1

Point release of Train Glance; bugfixes

Change-Id: Ic87602814a6cf5d8f999c7e27210dd52d8fd92ce
",git fetch https://review.opendev.org/openstack/releases refs/changes/29/703329/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/glance.yaml'],1,66084445c66145462493d8fcfdcc4afb3b28833c,glance-train, - version: 19.0.1 projects: - repo: openstack/glance hash: 8c2bc60820783f76c9421d615d3828a88008ca96,,4,0
openstack%2Fcharm-cinder~master~I16ccc5c2d292e37892ecdc73cde655d20b4cd887,openstack/charm-cinder,master,I16ccc5c2d292e37892ecdc73cde655d20b4cd887,Disable Apache default ports,ABANDONED,2019-12-20 16:54:45.000000000,2020-01-20 15:59:33.000000000,,"[{'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 16:54:45.000000000', 'files': ['unit_tests/test_cinder_utils.py', 'templates/ports.conf', 'hooks/cinder_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/9a5c247c6332aeaaebb8e254778647599d6b92cd', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I16ccc5c2d292e37892ecdc73cde655d20b4cd887\nCloses-bug: #1845665\n""}]",0,700210,9a5c247c6332aeaaebb8e254778647599d6b92cd,11,4,1,17097,,,0,"Disable Apache default ports

Openstack services don't use the default ports (80 and 443), so
change Apache to not open them.

Change-Id: I16ccc5c2d292e37892ecdc73cde655d20b4cd887
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/10/700210/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_cinder_utils.py', 'templates/ports.conf', 'hooks/cinder_utils.py']",3,9a5c247c6332aeaaebb8e254778647599d6b92cd,bug/1845665,"APACHE_PORTS_CONF = '/etc/apache2/ports.conf' (APACHE_PORTS_CONF, { 'contexts': [], 'services': ['apache2'], }), elif not (config()['ssl_cert'] or config()['ssl_key']): # apache not needed for _, v in resource_map.items(): if 'apache2' in v['services']: v['services'].remove('apache2')",,83,4
openstack%2Fcharm-glance~master~I3e259303b0d1b073693173d5c8f49cd5d988c640,openstack/charm-glance,master,I3e259303b0d1b073693173d5c8f49cd5d988c640,Disable Apache default ports,ABANDONED,2019-12-21 13:33:16.000000000,2020-01-20 15:57:54.000000000,,"[{'_account_id': 14567}, {'_account_id': 17097}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-21 13:33:16.000000000', 'files': ['hooks/glance_utils.py', 'templates/ports.conf', 'unit_tests/test_glance_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/b869e7961ccabc5256d22cb33cb965aa6416e93b', 'message': ""Disable Apache default ports\n\nOpenstack services don't use the default ports (80 and 443), so\nchange Apache to not open them.\n\nChange-Id: I3e259303b0d1b073693173d5c8f49cd5d988c640\nCloses-bug: #1845665\n""}]",0,700277,b869e7961ccabc5256d22cb33cb965aa6416e93b,9,4,1,17097,,,0,"Disable Apache default ports

Openstack services don't use the default ports (80 and 443), so
change Apache to not open them.

Change-Id: I3e259303b0d1b073693173d5c8f49cd5d988c640
Closes-bug: #1845665
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/77/700277/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/glance_utils.py', 'templates/ports.conf', 'unit_tests/test_glance_utils.py']",3,b869e7961ccabc5256d22cb33cb965aa6416e93b,bug/1845665," (utils.APACHE_PORTS_CONF, ['apache2']), (utils.APACHE_PORTS_CONF, ['apache2']), (utils.APACHE_PORTS_CONF, ['apache2']),",,14,1
openstack%2Freleases~master~Ifc81ac0c1185e4991f8f19d43dc4ed1b982122d6,openstack/releases,master,Ifc81ac0c1185e4991f8f19d43dc4ed1b982122d6,Release Glance 18.0.1,MERGED,2020-01-20 07:23:02.000000000,2020-01-20 15:30:31.000000000,2020-01-20 15:30:30.000000000,"[{'_account_id': 308}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-20 07:23:02.000000000', 'files': ['deliverables/stein/glance.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a6ce4fd2c5401169dd2616dc8574fc7c3de6dafb', 'message': 'Release Glance 18.0.1\n\nPoint release of Stein Glance; bugfixes\n\nChange-Id: Ifc81ac0c1185e4991f8f19d43dc4ed1b982122d6\n'}]",0,703331,a6ce4fd2c5401169dd2616dc8574fc7c3de6dafb,8,7,1,9303,,,0,"Release Glance 18.0.1

Point release of Stein Glance; bugfixes

Change-Id: Ifc81ac0c1185e4991f8f19d43dc4ed1b982122d6
",git fetch https://review.opendev.org/openstack/releases refs/changes/31/703331/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/glance.yaml'],1,a6ce4fd2c5401169dd2616dc8574fc7c3de6dafb,glance-stein, - projects: - hash: 149ea050cc58f39eaf9b4660bb8f0271b99d03da repo: openstack/glance version: 18.0.1,,4,0
openstack%2Ftripleo-common~master~I55af51e71f0593b2914aa108af43453fe553514b,openstack/tripleo-common,master,I55af51e71f0593b2914aa108af43453fe553514b,Handle stack not found during inventory generation,MERGED,2020-01-09 23:03:23.000000000,2020-01-20 15:26:49.000000000,2020-01-17 05:33:31.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-09 23:03:23.000000000', 'files': ['tripleo_common/inventory.py', 'tripleo_common/tests/test_inventory.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/08f5b6d18c193dcffa6d719b314f17978fcc4005', 'message': 'Handle stack not found during inventory generation\n\nIf the inventory generation is passed a non-existant stack name, a\nwarning is now logged. Additionally, the rest of the code that generates\nthe overcloud inventory is skipped by returning earlier so that the\ninventory generation finishes sooner.\n\nChange-Id: I55af51e71f0593b2914aa108af43453fe553514b\n'}]",0,701858,08f5b6d18c193dcffa6d719b314f17978fcc4005,17,5,1,7144,,,0,"Handle stack not found during inventory generation

If the inventory generation is passed a non-existant stack name, a
warning is now logged. Additionally, the rest of the code that generates
the overcloud inventory is skipped by returning earlier so that the
inventory generation finishes sooner.

Change-Id: I55af51e71f0593b2914aa108af43453fe553514b
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/58/701858/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/inventory.py', 'tripleo_common/tests/test_inventory.py']",2,08f5b6d18c193dcffa6d719b314f17978fcc4005,," self.outputs = StackOutputs(self.mock_stack) def test_stack_not_found(self): self.assertEqual(None, self.inventory._get_stack())"," self.outputs = StackOutputs('overcloud', self.hclient) def test_outputs_are_empty_if_stack_doesnt_exist(self): stack_outputs = StackOutputs('no-plan', self.hclient) self.assertEqual(list(stack_outputs), [])",40,29
openstack%2Ftripleo-common~master~Ic8da92d98656bcea7db5701b44eeadc1d5c87198,openstack/tripleo-common,master,Ic8da92d98656bcea7db5701b44eeadc1d5c87198,Improve error messaging around auth failures,MERGED,2020-01-16 21:54:59.000000000,2020-01-20 15:24:15.000000000,2020-01-20 14:29:46.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-16 21:54:59.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d15d8df6ce4ab2329c1161676e2ceb8bc4467497', 'message': ""Improve error messaging around auth failures\n\nRather than just dumping the raw HTTPError exception, we should provide\nsome additional guidance for the end user in the specific case that it's\nstill returning 401 when we attempt to authenticate. Because we retry\nauthentication to reissue tokens, if the authentication ultimately fails\nwith 401 then it points to bad credentials or the container/registry is\nnot actually available. Some registries return 401 instead of a 404.\n\nChange-Id: Ic8da92d98656bcea7db5701b44eeadc1d5c87198\nCloses-Bug: #1860040\n""}]",0,702994,d15d8df6ce4ab2329c1161676e2ceb8bc4467497,11,5,1,14985,,,0,"Improve error messaging around auth failures

Rather than just dumping the raw HTTPError exception, we should provide
some additional guidance for the end user in the specific case that it's
still returning 401 when we attempt to authenticate. Because we retry
authentication to reissue tokens, if the authentication ultimately fails
with 401 then it points to bad credentials or the container/registry is
not actually available. Some registries return 401 instead of a 404.

Change-Id: Ic8da92d98656bcea7db5701b44eeadc1d5c87198
Closes-Bug: #1860040
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/94/702994/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py']",2,d15d8df6ce4ab2329c1161676e2ceb8bc4467497,bug/1860040," try: session = self.authenticate( image_url, username=username, password=password) except requests.exceptions.HTTPError as e: if e.response.status_code == 401: raise ImageUploaderException( 'Unable to authenticate. This may indicate ' 'missing registry credentials or the provided ' 'container or namespace does not exist. %s' % e) raise try: session = self.authenticate( url, username=username, password=password) except requests.exceptions.HTTPError as e: if e.response.status_code == 401: raise ImageUploaderException( 'Unable to authenticate. This may indicate ' 'missing registry credentials or the provided ' 'container or namespace does not exist. %s' % e) raise try: target_session = self.authenticate( t.target_image_url, username=target_username, password=target_password ) except requests.exceptions.HTTPError as e: if e.response.status_code == 401: raise ImageUploaderException( 'Unable to authenticate. This may indicate ' 'missing registry credentials or the provided ' 'container or namespace does not exist. %s' % e) raise try: source_session = self.authenticate( t.source_image_url, username=source_username, password=source_password ) except requests.exceptions.HTTPError as e: if e.response.status_code == 401: raise ImageUploaderException( 'Unable to authenticate. This may indicate ' 'missing registry credentials or the provided ' 'container or namespace does not exist. %s' % e) raise try: session = self.authenticate( image_url, username=username, password=password) except requests.exceptions.HTTPError as e: if e.response.status_code == 401: raise ImageUploaderException( 'Unable to authenticate. This may indicate ' 'missing registry credentials or the provided ' 'container or namespace does not exist. %s' % e) raise"," session = self.authenticate( image_url, username=username, password=password) session = self.authenticate( url, username=username, password=password) target_session = self.authenticate( t.target_image_url, username=target_username, password=target_password ) source_session = self.authenticate( t.source_image_url, username=source_username, password=source_password ) session = self.authenticate( image_url, username=username, password=password)",94,16
openstack%2Fneutron~master~I607aa8fa399e72b037fd068ad4f02b6210e57e91,openstack/neutron,master,I607aa8fa399e72b037fd068ad4f02b6210e57e91,ovs agent: signal to plugin if tunnel refresh needed,MERGED,2019-12-06 12:14:34.000000000,2020-01-20 15:21:42.000000000,2020-01-20 15:17:01.000000000,"[{'_account_id': 2733}, {'_account_id': 4187}, {'_account_id': 4694}, {'_account_id': 7016}, {'_account_id': 9373}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-06 12:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ec739821cff0738735247f55875f5166aec5fc3', 'message': 'Keep setting agent_restarted flag until flooding entries received\n\nCurrently the ovs agent calls update_device_list with the\nagent_restarted flag set only on the first loop iteration. Then the\nserver knows to send the l2pop flooding entries for the network to\nthe agent. But when a compute node with many instances on many\nnetworks reboots, it takes time to readd all the active devices and\nsome may be readded after the first loop iteration. Then the server\ncan fail to send the flooding entries which means there will be no\nflood_to_tuns flow and broadcasts like dhcp will fail.\n\nThis patch fixes that by setting the agent_restarted flag if the\nagent has not yet received the flooding entries for the network.\n\nChange-Id: I607aa8fa399e72b037fd068ad4f02b6210e57e91\nCloses-Bug: #1853613\n'}, {'number': 2, 'created': '2020-01-03 13:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9270737b3beebef8ab30379424ebf7da0d5d5c99', 'message': 'Set agent_restarted flag if flooding entries not received\n\nCurrently the ovs agent calls update_device_list with the\nagent_restarted flag set only on the first loop iteration. Then the\nserver knows to send the l2pop flooding entries for the network to\nthe agent. But when a compute node with many instances on many\nnetworks reboots, it takes time to readd all the active devices and\nsome may be readded after the first loop iteration. Then the server\ncan fail to send the flooding entries which means there will be no\nflood_to_tuns flow and broadcasts like dhcp will fail.\n\nThis patch fixes that by setting the agent_restarted flag if the\nagent has not received the flooding entries for the netwok within\nthe first 100 loop iterations.\n\nChange-Id: I607aa8fa399e72b037fd068ad4f02b6210e57e91\nCloses-Bug: #1853613\n'}, {'number': 3, 'created': '2020-01-07 17:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe70bfc52927cca53eee6c7034ea76f4d8ee7622', 'message': 'ovs agent: signal to plugin if tunnel refresh needed\n\nCurrently the ovs agent calls update_device_list with the\nagent_restarted flag set only on the first loop iteration. Then the\nserver knows to send the l2pop flooding entries for the network to\nthe agent. But when a compute node with many instances on many\nnetworks reboots, it takes time to readd all the active devices and\nsome may be readded after the first loop iteration. Then the server\ncan fail to send the flooding entries which means there will be no\nflood_to_tuns flow and broadcasts like dhcp will fail.\n\nThis patch fixes that by renaming the agent_restarted flag to\nrefresh_tunnels and setting it if the agent has not received the\nflooding entries for the network.\n\nChange-Id: I607aa8fa399e72b037fd068ad4f02b6210e57e91\nCloses-Bug: #1853613\n'}, {'number': 4, 'created': '2020-01-09 14:50:02.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py', 'neutron/tests/functional/agent/l2/base.py', 'neutron/tests/unit/plugins/ml2/test_rpc.py', 'neutron/agent/rpc.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/93e9dc5426764b791ac69e62c6d60be7591c16ab', 'message': 'ovs agent: signal to plugin if tunnel refresh needed\n\nCurrently the ovs agent calls update_device_list with the\nagent_restarted flag set only on the first loop iteration. Then the\nserver knows to send the l2pop flooding entries for the network to\nthe agent. But when a compute node with many instances on many\nnetworks reboots, it takes time to readd all the active devices and\nsome may be readded after the first loop iteration. Then the server\ncan fail to send the flooding entries which means there will be no\nflood_to_tuns flow and broadcasts like dhcp will fail.\n\nThis patch fixes that by renaming the agent_restarted flag to\nrefresh_tunnels and setting it if the agent has not received the\nflooding entries for the network.\n\nChange-Id: I607aa8fa399e72b037fd068ad4f02b6210e57e91\nCloses-Bug: #1853613\n'}]",16,697655,93e9dc5426764b791ac69e62c6d60be7591c16ab,47,14,4,2733,,,0,"ovs agent: signal to plugin if tunnel refresh needed

Currently the ovs agent calls update_device_list with the
agent_restarted flag set only on the first loop iteration. Then the
server knows to send the l2pop flooding entries for the network to
the agent. But when a compute node with many instances on many
networks reboots, it takes time to readd all the active devices and
some may be readded after the first loop iteration. Then the server
can fail to send the flooding entries which means there will be no
flood_to_tuns flow and broadcasts like dhcp will fail.

This patch fixes that by renaming the agent_restarted flag to
refresh_tunnels and setting it if the agent has not received the
flooding entries for the network.

Change-Id: I607aa8fa399e72b037fd068ad4f02b6210e57e91
Closes-Bug: #1853613
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/697655/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py'],1,3ec739821cff0738735247f55875f5166aec5fc3,bug/1853613, tunnels_missing = False if (not tunnels_missing and lvm.network_type in constants.TUNNEL_NETWORK_TYPES and len(lvm.tun_ofports) == 0): tunnels_missing = True agent_restarted = (self.iter_num == 0) or tunnels_missing, agent_restarted = self.iter_num == 0,6,1
openstack%2Fheat-specs~master~I76a9e0e3259ec52564f31a239079cd91da897ee9,openstack/heat-specs,master,I76a9e0e3259ec52564f31a239079cd91da897ee9,[ussuri][goal] Drop python 2.7 support,MERGED,2019-12-13 22:21:47.000000000,2020-01-20 15:19:09.000000000,2020-01-20 15:13:28.000000000,"[{'_account_id': 4257}, {'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 22:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/ff4e19b0eb690042426fa4422062e0e70521f1ef', 'message': ""[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nDoc building still use deprcated oslosphinx and incompatible\nversion of yasfb which lead to error-\n\nsphinx.errors.ExtensionError: Could not import extension yasfb (exception: cannot import name 'logging')\n\nThis commit replace oslosphinx with openstackdocstheme ti fix the error.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I76a9e0e3259ec52564f31a239079cd91da897ee9\n""}, {'number': 2, 'created': '2019-12-17 18:41:29.000000000', 'files': ['requirements.txt', '.zuul.yaml', 'doc/source/conf.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/74ab95431cf6fcbb4f6e749a8db7d494a0f4387e', 'message': ""[ussuri][goal] Drop python 2.7 support\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nspecs repo either has py27 job or requirement or tox env.\n\nDoc building still use deprcated oslosphinx and incompatible\nversion of yasfb which lead to error-\n\nsphinx.errors.ExtensionError: Could not import extension yasfb (exception: cannot import name 'logging')\n\nThis commit replace oslosphinx with openstackdocstheme ti fix the error.\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I76a9e0e3259ec52564f31a239079cd91da897ee9\n""}]",2,699035,74ab95431cf6fcbb4f6e749a8db7d494a0f4387e,12,3,2,8556,,,0,"[ussuri][goal] Drop python 2.7 support

OpenStack is dropping the py2.7 support in ussuri cycle.

specs repo either has py27 job or requirement or tox env.

Doc building still use deprcated oslosphinx and incompatible
version of yasfb which lead to error-

sphinx.errors.ExtensionError: Could not import extension yasfb (exception: cannot import name 'logging')

This commit replace oslosphinx with openstackdocstheme ti fix the error.

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: I76a9e0e3259ec52564f31a239079cd91da897ee9
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/35/699035/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.zuul.yaml', 'doc/source/conf.py', 'tox.ini']",4,ff4e19b0eb690042426fa4422062e0e70521f1ef,drop-py27-support,"envlist = docs,pep8basepython = python3","envlist = docs,py27basepython = python3basepython = python3basepython = python3",9,10
openstack%2Fkolla~master~I02932857454bdb09b72f539038d394760457109d,openstack/kolla,master,I02932857454bdb09b72f539038d394760457109d,"Revert ""Debian/source: do not force tag in build jobs""",MERGED,2020-01-18 19:09:03.000000000,2020-01-20 15:18:41.000000000,2020-01-20 15:15:43.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-18 19:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/eeb7a57630d6b5359f2205bcc56f77d0723daed2', 'message': 'Revert ""Debian/source: do not force tag in build jobs""\n\nThis reverts commit ca4da16836e4b3ef1d84059a63378c3f5bb2517e.\n\nChange-Id: I02932857454bdb09b72f539038d394760457109d\n'}, {'number': 2, 'created': '2020-01-18 19:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/78b41f2aaa2332a9e783e4ac6efd6a1c28091c14', 'message': 'Revert ""Debian/source: do not force tag in build jobs""\n\nThis reverts commit ca4da16836e4b3ef1d84059a63378c3f5bb2517e.\n\nThis is adapted to revert only the missed part of\naarch64 publisher which now blocks publishing for debian.\n\nChange-Id: I02932857454bdb09b72f539038d394760457109d\n'}, {'number': 3, 'created': '2020-01-18 19:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4de9f1a12a1eec18ffaeb0602499a84e3a563255', 'message': 'Revert ""Debian/source: do not force tag in build jobs""\n\nThis reverts commit ca4da16836e4b3ef1d84059a63378c3f5bb2517e.\n\nThis is adapted to revert only the missed part of\naarch64 publisher which now blocks publishing for debian.\n\nChange-Id: I02932857454bdb09b72f539038d394760457109d\n'}, {'number': 4, 'created': '2020-01-20 08:17:54.000000000', 'files': ['tests/templates/kolla-build.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1cb4760b055bcc38380e6741273337c33c0b563c', 'message': 'Revert ""Debian/source: do not force tag in build jobs""\n\nThis reverts commit ca4da16836e4b3ef1d84059a63378c3f5bb2517e.\n\nThis is adapted to revert only the missed part of\naarch64 publisher which now blocks publishing for debian.\n\nChange-Id: I02932857454bdb09b72f539038d394760457109d\n'}]",0,703252,1cb4760b055bcc38380e6741273337c33c0b563c,20,6,4,30491,,,0,"Revert ""Debian/source: do not force tag in build jobs""

This reverts commit ca4da16836e4b3ef1d84059a63378c3f5bb2517e.

This is adapted to revert only the missed part of
aarch64 publisher which now blocks publishing for debian.

Change-Id: I02932857454bdb09b72f539038d394760457109d
",git fetch https://review.opendev.org/openstack/kolla refs/changes/52/703252/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_build.py', 'tests/templates/kolla-build.conf.j2']",2,eeb7a57630d6b5359f2205bcc56f77d0723daed2,,,{% set tag_suffix = '-' ~ base_arch if base_distro == 'debian' and install_type == 'source' else '' %},3,1
openstack%2Ftripleo-validations~master~I4f1be14cd952a467f8e06dd932483555334e99e6,openstack/tripleo-validations,master,I4f1be14cd952a467f8e06dd932483555334e99e6,Normalize role names when generating roles,ABANDONED,2020-01-20 15:06:59.000000000,2020-01-20 15:08:35.000000000,,[],"[{'number': 1, 'created': '2020-01-20 15:06:59.000000000', 'files': ['role-addition.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/360f1bbc426f16898a9dedd90eec667cfa5571a5', 'message': 'Normalize role names when generating roles\n\nRoles can no longer have a ""-"" in them according to the upstream ansible\ndocumentation[0]. This change ensures that we\'re no longer generating\nroles\nthat have a ""-"" within them. The role-addition.yml playbook will now\nnormalize the name and replace any ""-"" with an ""_"".\n\n[0] https://docs.ansible.com/ansible/devel/dev_guide/developing_collections.html#roles-directory\n\nChange-Id: I4f1be14cd952a467f8e06dd932483555334e99e6\nCo-Authozed-By: Kevin ""Cloudnull"" Karter <kecarter@redhat.com>\n'}]",0,703413,360f1bbc426f16898a9dedd90eec667cfa5571a5,2,0,1,28223,,,0,"Normalize role names when generating roles

Roles can no longer have a ""-"" in them according to the upstream ansible
documentation[0]. This change ensures that we're no longer generating
roles
that have a ""-"" within them. The role-addition.yml playbook will now
normalize the name and replace any ""-"" with an ""_"".

[0] https://docs.ansible.com/ansible/devel/dev_guide/developing_collections.html#roles-directory

Change-Id: I4f1be14cd952a467f8e06dd932483555334e99e6
Co-Authozed-By: Kevin ""Cloudnull"" Karter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/13/703413/1 && git format-patch -1 --stdout FETCH_HEAD,['role-addition.yml'],1,360f1bbc426f16898a9dedd90eec667cfa5571a5,normalize/role-creation," - name: Normalize role name set_fact: _role_name: ""{{ role_name | replace('-', '_') }}"" --init-path=roles {{ _role_name }} args: creates: ""roles/{{ _role_name }}"" {% set new_job_name = ""tripleo-validations-centos-7-molecule-"" ~ _role_name %} ""^roles/"" ~ _role_name ~ ""/.*"" ""tripleo_validations__role_name"": _role_name {{ _role_name | replace('-', '_') }}_debug: false roles: - {{ _role_name }} dest: ""playbooks/{{ _role_name }}.yaml"" {{ '=' * (_role_name | length) }} {{ _role_name }} {{ '=' * (_role_name | length) }} :role: roles/{{ _role_name }} dest: ""doc/source/roles/role-{{ _role_name }}.rst"""," --init-path=roles {{ role_name }} args: creates: ""roles/{{ role_name }}"" {% set new_job_name = ""tripleo-validations-centos-7-molecule-"" ~ role_name %} ""^roles/"" ~ role_name ~ ""/.*"" ""tripleo_validations_role_name"": role_name {{ role_name | replace('-', '_') }}_debug: false roles: - {{ role_name }} dest: ""playbooks/{{ role_name }}.yaml"" {{ '=' * (role_name | length) }} {{ role_name }} {{ '=' * (role_name | length) }} :role: roles/{{ role_name }} dest: ""doc/source/roles/role-{{ role_name }}.rst""",17,13
openstack%2Freleases~master~Ifee9c63b37563b0aab070d001b8dfd335868420c,openstack/releases,master,Ifee9c63b37563b0aab070d001b8dfd335868420c,Release OpenStack-Ansible Rocky,MERGED,2020-01-17 16:33:14.000000000,2020-01-20 14:51:45.000000000,2020-01-20 14:51:45.000000000,"[{'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-17 16:33:14.000000000', 'files': ['deliverables/rocky/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/353d7fb9108cacaa337d33ba1ee8edc9cb11b9ef', 'message': 'Release OpenStack-Ansible Rocky\n\nChange-Id: Ifee9c63b37563b0aab070d001b8dfd335868420c\n'}]",2,703119,353d7fb9108cacaa337d33ba1ee8edc9cb11b9ef,8,4,1,28619,,,0,"Release OpenStack-Ansible Rocky

Change-Id: Ifee9c63b37563b0aab070d001b8dfd335868420c
",git fetch https://review.opendev.org/openstack/releases refs/changes/19/703119/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/rocky/openstack-ansible.yaml'],1,353d7fb9108cacaa337d33ba1ee8edc9cb11b9ef,release_osa, - version: 18.1.17 projects: - repo: openstack/openstack-ansible hash: a38e6d5fed4da623f811f3d17bd1b3213746a5ab,,4,0
openstack%2Fpatrole~master~I863bc93ab65532c7ec3f02236198ac7c5d5b1329,openstack/patrole,master,I863bc93ab65532c7ec3f02236198ac7c5d5b1329,Add releasenote to tag the end of support for Queens,MERGED,2020-01-18 21:19:42.000000000,2020-01-20 14:36:28.000000000,2020-01-20 14:33:52.000000000,"[{'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 17896}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2020-01-18 21:19:42.000000000', 'files': ['releasenotes/notes/intermediate-ussuri-release-8f7bb2140bca827c.yaml'], 'web_link': 'https://opendev.org/openstack/patrole/commit/37d819201ccf53cc549c6862951260b49cef07c4', 'message': 'Add releasenote to tag the end of support for Queens\n\nThis relesenote mark end of support for Queens release\nin Patrole as Queens is in EM state[1].\n\n[1] https://releases.openstack.org/\n\nChange-Id: I863bc93ab65532c7ec3f02236198ac7c5d5b1329\n'}]",0,703256,37d819201ccf53cc549c6862951260b49cef07c4,9,5,1,8556,,,0,"Add releasenote to tag the end of support for Queens

This relesenote mark end of support for Queens release
in Patrole as Queens is in EM state[1].

[1] https://releases.openstack.org/

Change-Id: I863bc93ab65532c7ec3f02236198ac7c5d5b1329
",git fetch https://review.opendev.org/openstack/patrole refs/changes/56/703256/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/intermediate-ussuri-release-8f7bb2140bca827c.yaml'],1,37d819201ccf53cc549c6862951260b49cef07c4,,"--- prelude: > This is an intermediate release during the Ussuri development cycle to mark the end of support for EM Queens in Patrole. After this release, Patrole will support below OpenStack Releases: * Train * Stein * Rocky Current development of Patrole is for OpenStack Ussuri development cycle. This is the last release of Patrole to officially support python2.7. ",,14,0
openstack%2Freviewstats~master~I030707de6834bba183a472a5375d118e38e5c06f,openstack/reviewstats,master,I030707de6834bba183a472a5375d118e38e5c06f,Update ironic subprojects,MERGED,2020-01-02 12:44:05.000000000,2020-01-20 14:31:05.000000000,2020-01-20 14:29:32.000000000,"[{'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-02 12:44:05.000000000', 'files': ['projects/ironic.json'], 'web_link': 'https://opendev.org/openstack/reviewstats/commit/0ac67ac973aeec2522aca13bbc59e89d3b25b5dd', 'message': 'Update ironic subprojects\n\nironic-inspector-tempest-plugin has never been used, a few other\nhave been added.\n\nChange-Id: I030707de6834bba183a472a5375d118e38e5c06f\n'}]",0,700890,0ac67ac973aeec2522aca13bbc59e89d3b25b5dd,12,4,1,10239,,,0,"Update ironic subprojects

ironic-inspector-tempest-plugin has never been used, a few other
have been added.

Change-Id: I030707de6834bba183a472a5375d118e38e5c06f
",git fetch https://review.opendev.org/openstack/reviewstats refs/changes/90/700890/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/ironic.json'],1,0ac67ac973aeec2522aca13bbc59e89d3b25b5dd,," ""openstack/ironic-prometheus-exporter"", ""openstack/metalsmith"", ""openstack/networking-generic-switch"","," ""openstack/ironic-inspector-tempest-plugin"",",3,1
openstack%2Fansible-role-tripleo-modify-image~master~Ifbcaa07bb80dd612e85f0d7cf8d99131fb739c84,openstack/ansible-role-tripleo-modify-image,master,Ifbcaa07bb80dd612e85f0d7cf8d99131fb739c84,Dockerfile-yum.j2 doesn't copy the RPMs so yum_update.sh fails,MERGED,2020-01-17 22:28:10.000000000,2020-01-20 14:29:43.000000000,2020-01-20 14:29:43.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 9592}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 22:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/1409eafca5a6a135c91f1d3fd2ddc664c57106e2', 'message': 'Dockerfile-yum.j2 doesn\'t copy the RPMs so yum_update.sh fails\n\nAfter implementing ""yum localinstall"", a critical part of the\nprocess wasn\'t merged in the code which consists of copying\nthe actual RPMs through the Dockerfile-yum.j2 file.\n\nChange-Id: Ifbcaa07bb80dd612e85f0d7cf8d99131fb739c84\nCloses-bug: #1860184\n'}, {'number': 2, 'created': '2020-01-17 22:47:28.000000000', 'files': ['templates/Dockerfile-yum.j2'], 'web_link': 'https://opendev.org/openstack/ansible-role-tripleo-modify-image/commit/58d7a5bc9d73daf8fda032c5c19110ec298e5bbd', 'message': 'Dockerfile-yum.j2 doesn\'t copy the RPMs so yum_update.sh fails\n\nAfter implementing ""yum localinstall"", a critical part of the\nprocess wasn\'t merged in the code which consists of copying\nthe actual RPMs through the Dockerfile-yum.j2 file.\n\nChange-Id: Ifbcaa07bb80dd612e85f0d7cf8d99131fb739c84\nCloses-bug: #1860184\n'}]",0,703202,58d7a5bc9d73daf8fda032c5c19110ec298e5bbd,8,5,2,7130,,,0,"Dockerfile-yum.j2 doesn't copy the RPMs so yum_update.sh fails

After implementing ""yum localinstall"", a critical part of the
process wasn't merged in the code which consists of copying
the actual RPMs through the Dockerfile-yum.j2 file.

Change-Id: Ifbcaa07bb80dd612e85f0d7cf8d99131fb739c84
Closes-bug: #1860184
",git fetch https://review.opendev.org/openstack/ansible-role-tripleo-modify-image refs/changes/02/703202/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/Dockerfile-yum.j2'],1,1409eafca5a6a135c91f1d3fd2ddc664c57106e2,bug/1860184,{% if rpms_path is defined %} {% for rpm in rpms_list %} COPY {{ rpm | basename }} /tmp/ {% endfor %} {% endif %} ,,7,0
openstack%2Ftripleo-operator-ansible~master~Ic75fb5bbdaaafb30dc90637edbbc169196ed8886,openstack/tripleo-operator-ansible,master,Ic75fb5bbdaaafb30dc90637edbbc169196ed8886,Add tripleo-repos role,MERGED,2019-12-16 20:51:39.000000000,2020-01-20 14:13:48.000000000,2020-01-20 14:13:48.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-16 20:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/6dc9f1679351e6e516c7955ad361291cd45c078d', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 2, 'created': '2019-12-16 21:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9128a94e5b4a1d4f63b77c1d96ab419f2608487e', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 3, 'created': '2019-12-16 23:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/f3b13a2a0468301cc9157ae6138ece0888ff27af', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 4, 'created': '2020-01-07 23:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/7eb7292cd6e1732cd45ce9c2db720fb393549c36', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 5, 'created': '2020-01-08 17:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/ec60d442158d1f54a5343e88b58b61993544f8af', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 6, 'created': '2020-01-08 18:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/a76cc291a58add1c3e92c7dac15d284571c7036c', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 7, 'created': '2020-01-08 21:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/3cdfdfd570f88936a262294a28df57106fc7a5b2', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 8, 'created': '2020-01-09 16:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/e30876cf8554bb45c8303828957b157e8f833b71', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 9, 'created': '2020-01-09 17:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/6d06f73025e04a6e92149db1dddc593bea28cb12', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 10, 'created': '2020-01-14 14:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/0f2d8ca1cd3993c29e65029e9fbe1ae31a4a6611', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}, {'number': 11, 'created': '2020-01-14 14:59:41.000000000', 'files': ['roles/tripleo-repos/defaults/main.yml', 'roles/tripleo-repos/vars/main.yml', 'roles/tripleo-repos/tasks/main.yml', 'roles/tripleo-repos/meta/main.yml', 'roles/tripleo-repos/handlers/main.yml', 'roles/tripleo-repos/README.md', 'roles/tripleo-repos/tests/inventory', 'roles/tripleo-repos/tests/test.yml', 'roles/tripleo-repos/tasks/install.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9ea41192a1674192a5eee2c077ca95bab9f64065', 'message': 'Add tripleo-repos role\n\nAdd a role to install/run tripleo-repos\n\nChange-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886\n'}]",0,699288,9ea41192a1674192a5eee2c077ca95bab9f64065,36,6,11,14985,,,0,"Add tripleo-repos role

Add a role to install/run tripleo-repos

Change-Id: Ic75fb5bbdaaafb30dc90637edbbc169196ed8886
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/88/699288/8 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-repos/defaults/main.yml', 'roles/tripleo-repos/vars/main.yml', 'roles/tripleo-repos/meta/main.yml', 'roles/tripleo-repos/tasks/main.yml', 'roles/tripleo-repos/README.md', 'roles/tripleo-repos/handlers/main.yml', 'roles/tripleo-repos/tests/inventory', 'roles/tripleo-repos/tests/test.yml', 'roles/tripleo-repos/tasks/install.yml']",9,6dc9f1679351e6e516c7955ad361291cd45c078d,tripleo-undercloud,"--- - name: Build distro string set_fact: _tripleo_repos_distro: ""{{ (ansible_facts.distribution == 'RedHat') | ternary('rhel', 'centos') }}{{ ansible_facts.distribution_major_version }}"" - name: Build RDO repo url set_fact: _tripleo_repos_repo_url: ""{{ tripleo_repos_repo_base }}/{{ _tripleo_repos_distro }}-{{ tripleo_repos_branch }}/current/"" - name: Find available tripleo-repos rpm block: - name: Grab repo package list command: curl -s ""{{ _tripleo_repos_repo_url }}"" retries: 10 delay: 3 register: _tripleo_repos_repo_data - name: Find rpm name set_fact: _tripleo_repos_rpm: ""{{ _tripleo_repos_repo_data.stdout | regex_search('python[0-9]-tripleo-repos-[a-z0-9-.]+\\.rpm') }}"" - name: Fail if rpm is missing fail: msg: Unable to find tripleo-repos rpm when: _tripleo_repos_rpm|length == 0 - name: Install tripleo-repos yum: name: ""{{ _tripleo_repos_repo_url }}{{ _tripleo_repos_rpm }}"" state: present become: true ",,155,0
openstack%2Fironic~master~Ibd93bb255d5664a431f9be9c39c9fc8c67ff7608,openstack/ironic,master,Ibd93bb255d5664a431f9be9c39c9fc8c67ff7608,Fix entry paths for cleaning and deployment,MERGED,2020-01-17 19:16:04.000000000,2020-01-20 14:00:36.000000000,2020-01-20 05:19:12.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 19:16:04.000000000', 'files': ['releasenotes/notes/fix-fast-track-entry-path-467c20f97aeb2f4b.yaml', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0a94391e34b7d1caa4e99c81ddf4f651f457795e', 'message': 'Fix entry paths for cleaning and deployment\n\nThe explicit removal of agent_url to prevent conflicts...\nturned out to be another issue with fast_track.\n\nChange-Id: Ibd93bb255d5664a431f9be9c39c9fc8c67ff7608\nStory: 2007080\nTask: 37991\n'}]",0,703160,0a94391e34b7d1caa4e99c81ddf4f651f457795e,12,5,1,11655,,,0,"Fix entry paths for cleaning and deployment

The explicit removal of agent_url to prevent conflicts...
turned out to be another issue with fast_track.

Change-Id: Ibd93bb255d5664a431f9be9c39c9fc8c67ff7608
Story: 2007080
Task: 37991
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/703160/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-fast-track-entry-path-467c20f97aeb2f4b.yaml', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py']",3,0a94391e34b7d1caa4e99c81ddf4f651f457795e,691413," @mock.patch('ironic.drivers.modules.fake.FakeDeploy.deploy') @mock.patch('ironic.conductor.utils.remove_agent_url') @mock.patch('ironic.conductor.utils.is_fast_track') def test_do_node_deploy_fast_track(self, mock_is_fast_track, mock_remove_agent_url, mock_deploy, mock_iwdi): # TODO(rloo): delete this after the deprecation period for supporting # non deploy_steps. # Mocking FakeDeploy.deploy before starting the service, causes # it not to be a deploy_step. mock_iwdi.return_value = False mock_is_fast_track.return_value = True self._start_service() mock_deploy.return_value = states.DEPLOYDONE node = obj_utils.create_test_node( self.context, driver='fake-hardware', driver_internal_info={'agent_url': 'meow'}, provision_state=states.AVAILABLE, target_provision_state=states.NOSTATE) self.service.do_node_deploy(self.context, node.uuid) self._stop_service() node.refresh() self.assertEqual(states.ACTIVE, node.provision_state) self.assertEqual(states.NOSTATE, node.target_provision_state) # last_error should be None. self.assertIsNone(node.last_error) # Verify reservation has been cleared. self.assertIsNone(node.reservation) mock_deploy.assert_called_once_with(mock.ANY) mock_iwdi.assert_called_once_with(self.context, node.instance_info) self.assertFalse(node.driver_internal_info['is_whole_disk_image']) mock_is_fast_track.assert_called_once_with(mock.ANY) mock_remove_agent_url.assert_not_called() @mock.patch('ironic.conductor.utils.remove_agent_url') @mock.patch('ironic.conductor.utils.is_fast_track') @mock.patch('ironic.conductor.manager.ConductorManager._spawn_worker', autospec=True) @mock.patch('ironic.drivers.modules.network.flat.FlatNetwork.validate', autospec=True) @mock.patch('ironic.drivers.modules.fake.FakePower.validate', autospec=True) def test_do_node_clean_ok_fast_track( self, mock_power_valid, mock_network_valid, mock_spawn, mock_is_fast_track, mock_remove_agent_url): node = obj_utils.create_test_node( self.context, driver='fake-hardware', provision_state=states.MANAGEABLE, driver_internal_info={'agent_url': 'meow'}) mock_is_fast_track.return_value = True self._start_service() clean_steps = [self.deploy_raid] self.service.do_node_clean(self.context, node.uuid, clean_steps) mock_power_valid.assert_called_once_with(mock.ANY, mock.ANY) mock_network_valid.assert_called_once_with(mock.ANY, mock.ANY) mock_spawn.assert_called_with( self.service, self.service._do_node_clean, mock.ANY, clean_steps) node.refresh() # Node will be moved to CLEANING self.assertEqual(states.CLEANING, node.provision_state) self.assertEqual(states.MANAGEABLE, node.target_provision_state) self.assertNotIn('clean_steps', node.driver_internal_info) mock_is_fast_track.assert_called_once_with(mock.ANY) mock_remove_agent_url.assert_not_called() ",,81,3
openstack%2Fnova~master~I9a59afb80da994fca59748c65470bdd888e8c95c,openstack/nova,master,I9a59afb80da994fca59748c65470bdd888e8c95c,ironic: Support resize and cold migration,ABANDONED,2017-09-05 05:35:31.000000000,2020-01-20 14:00:34.000000000,,"[{'_account_id': 3}, {'_account_id': 2033}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13689}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 18320}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 26576}]","[{'number': 1, 'created': '2017-09-05 05:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c6ad547e69f0790281541652d452856dbee47b5', 'message': '[WIP] ironic: Support cold migration\n\nThis patch implements driver API which is necessary for supporting\ncold migration with ironic virt driver. The migration is allowed only\nfor a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint baremetal-migration-evacuation\n'}, {'number': 2, 'created': '2017-09-05 08:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7495c4543104da2ee4924ae10dbf2255bd493282', 'message': '[WIP] ironic: Support cold migration\n\nThis patch implements driver API which is necessary for supporting\ncold migration with ironic virt driver. The migration is allowed only\nfor a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint baremetal-migration-evacuation\n'}, {'number': 3, 'created': '2017-10-11 09:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66c8e0b2b0f4e4c7b8c5e0d4156953137a56c9da', 'message': 'ironic: Support resize and cold migration\n\nThis patch implements driver API which is necessary for supporting\nresize and cold migration with ironic virt driver. The migration is\nallowed only for a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint baremetal-migration-evacuation\n'}, {'number': 4, 'created': '2017-10-12 12:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a0835ba35da0b9984721d5f8777d161e5bccba0', 'message': 'ironic: Support resize and cold migration\n\nThis patch implements driver API which is necessary for supporting\nresize and cold migration with ironic virt driver. The migration is\nallowed only for a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint baremetal-migration-evacuation\n'}, {'number': 5, 'created': '2018-02-23 11:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f9818b110e93f1489b0029af425cab8bf180d86', 'message': 'ironic: Support resize and cold migration\n\nThis patch implements driver API which is necessary for supporting\nresize and cold migration with ironic virt driver. The migration is\nallowed only for a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint ironic-instance-switchover\n'}, {'number': 6, 'created': '2018-03-23 08:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0e5ec34df5ccd623063f686d6c485b911d38c63', 'message': 'ironic: Support resize and cold migration\n\nThis patch implements driver API which is necessary for supporting\nresize and cold migration with ironic virt driver. The migration is\nallowed only for a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint ironic-instance-switchover\n'}, {'number': 7, 'created': '2018-05-10 12:53:24.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py', 'releasenotes/notes/bp-baremetal-migration-evacuation-a45e521d230e50fc.yaml', 'nova/compute/manager.py', 'doc/source/user/support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/445ef27a3a48a0cf0aa18c1e4ac80b655f081bc8', 'message': 'ironic: Support resize and cold migration\n\nThis patch implements driver API which is necessary for supporting\nresize and cold migration with ironic virt driver. The migration is\nallowed only for a instance booted from a remote volume.\n\nThe following methods are implemented:\n- migrate_disk_and_power_off()\n  This method powers off the source node.\n- finish_migration()\n  This method asks ironic to deploy a new node with the same volume\n  as the source node.\n- confirm_migration()\n  When the migration is confirmed, this method undeploy the source\n  node.\n- finish_revert_migration()\n  For reverting the migration, this method reboot the source node.\n\nChange-Id: I9a59afb80da994fca59748c65470bdd888e8c95c\nImplements: blueprint ironic-instance-switchover\n'}]",9,500677,445ef27a3a48a0cf0aa18c1e4ac80b655f081bc8,109,22,7,13689,,,0,"ironic: Support resize and cold migration

This patch implements driver API which is necessary for supporting
resize and cold migration with ironic virt driver. The migration is
allowed only for a instance booted from a remote volume.

The following methods are implemented:
- migrate_disk_and_power_off()
  This method powers off the source node.
- finish_migration()
  This method asks ironic to deploy a new node with the same volume
  as the source node.
- confirm_migration()
  When the migration is confirmed, this method undeploy the source
  node.
- finish_revert_migration()
  For reverting the migration, this method reboot the source node.

Change-Id: I9a59afb80da994fca59748c65470bdd888e8c95c
Implements: blueprint ironic-instance-switchover
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/500677/4 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/ironic/driver.py'],1,8c6ad547e69f0790281541652d452856dbee47b5,bp/ironic-instance-switchover,"from nova.virt import block_device as driver_block_devicefrom nova.volume import cinder ""supports_migrate_to_same_host"": True, def _cleanup_volume_target_info(self, node, instance): node.uuid, detail=True) 'node': node.uuid, self._cleanup_volume_target_info(node, instance) def get_host_ip_addr(self): """"""Retrieves the IP address of the host running compute service."""""" return CONF.my_ip def migrate_disk_and_power_off(self, context, instance, dest, flavor, network_info, block_device_info=None, timeout=0, retry_interval=0): """"""Transfers the disk of a running instance in multiple phases, turning off the instance before the end. :param nova.objects.instance.Instance instance: The instance whose disk should be migrated. :param str dest: The IP address of the destination host. Ignored by this driver. :param nova.objects.flavor.Flavor flavor: The flavor of the instance whose disk get migrated. Ignored by this driver. :param nova.network.model.NetworkInfo network_info: The network information of the given `instance`. :param dict block_device_info: Information about the block devices. :param int timeout: The time in seconds to wait for the guest OS to shutdown. Ignored by this driver. :param int retry_interval: How often to signal guest while waiting for it to shutdown. Ignored by this driver. :return: A list of disk information dicts in JSON format. :rtype: str """""" if not self._is_booted_from_volume(block_device_info): # Bare metal migration is available only when the instance is # booted from a remote volume. raise NotImplementedError() LOG.debug(""Starting migrate_disk_and_power_off"", instance=instance) self.power_off(instance) node = self._get_node(instance.node) self._unplug_vifs(node, instance, network_info) # Remove instance UUID from the source node so that the UUID can be # set to the destination node. patch = [{'path': '/instance_uuid', 'op': 'remove'}] try: self.ironicclient.call('node.update', instance.node, patch) except ironic.exc.ClientException as e: LOG.error(""Failed to remove deploy parameters from node "" ""%(node)s when stooping the instance "" ""%(instance)s for migration: %(reason)s"", {'node': instance.node, 'instance': instance.uuid, 'reason': e}, instance=instance) raise exception.MigrationError(reason=e) # disk_info is not used return """" def finish_migration(self, context, migration, instance, disk_info, network_info, image_meta, resize_instance, block_device_info=None, power_on=True): """"""Completes a resize/migration. :param context: the context for the migration/resize :param migration: the migrate/resize information :param instance: nova.objects.instance.Instance being migrated/resized :param disk_info: the newly transferred disk information :param network_info: instance network information :param nova.objects.ImageMeta image_meta: The metadata of the image of the instance. :param resize_instance: True if the instance is being resized, False otherwise :param block_device_info: instance volume block device info :param power_on: True if the instance should be powered on, False otherwise. Ignored by this driver. """""" # Deploy the destination node. mapping = virt_driver.block_device_info_get_mapping(block_device_info) driver_block_device.attach_block_devices( mapping, context, instance, cinder.API(), self) self.spawn(context, instance, image_meta, None, None, network_info, block_device_info) def confirm_migration(self, context, migration, instance, network_info): """"""Confirms a resize/migration, destroying the source VM. :param context: the context for the migration/resize :param migration: the migrate/resize information :param instance: nova.objects.instance.Instance being migrated/resized :param network_info: instance network information """""" node = self._get_node(migration.source_node) # Unprovision the source node self._unprovision_migration_source(instance, node.uuid) # Delete volume targets from the source node. self._cleanup_volume_target_info(node, instance) def _unprovision_migration_source(self, instance, node_uuid): """"""Unprovision a node which is a migration source. :param instance: Instance being migrated. :param node_uuid: UUID of the source node to be unprovisioned. """""" try: self.ironicclient.call(""node.set_provision_state"", node_uuid, ""deleted"") except ironic.exc.ClientException as e: LOG.error(""Error unprovisioning migration source node "" ""%(node)s when stooping the instance "" ""%(instance)s for migration: %(reason)s"", {'node': node_uuid, 'instance': instance.uuid, 'reason': e}, instance=instance) raise exception.MigrationError(reason=e) # using a dict because this is modified in the local method data = {'tries': 0} def _wait_for_provision_state(): node = self._get_node(node_uuid) if node.provision_state in (ironic_states.NOSTATE, ironic_states.CLEANING, ironic_states.CLEANWAIT, ironic_states.CLEANFAIL, ironic_states.AVAILABLE): LOG.debug(""Ironic node %(node)s is in state %(state)s, "" ""migration source node is unprovisioned."", dict(node=node.uuid, state=node.provision_state), instance=instance) raise loopingcall.LoopingCallDone() if data['tries'] >= CONF.ironic.api_max_retries + 1: msg = (_(""Error unprovisioning migration source node "" ""%(node)s. Provision state still '%(state)s'."") % {'state': node.provision_state, 'node': node.uuid}) LOG.error(msg, instance=instance) raise exception.MigrationError(reason=msg) else: data['tries'] += 1 _log_ironic_polling('unprovision', node, instance) # wait for the state transition to finish timer = loopingcall.FixedIntervalLoopingCall(_wait_for_provision_state) timer.start(interval=CONF.ironic.api_retry_interval).wait() def finish_revert_migration(self, context, instance, network_info, block_device_info=None, power_on=True): """"""Finish reverting a resize/migration. :param context: the context for the finish_revert_migration :param instance: nova.objects.instance.Instance being migrated/resized :param network_info: instance network information :param block_device_info: instance volume block device info :param power_on: True if the instance should be powered on, False otherwise """""" # Set instance UUID to the source node. patch = [{'path': '/instance_uuid', 'op': 'add', 'value': instance.uuid}] try: self.ironicclient.call('node.update', instance.node, patch) except ironic.exc.ClientException as e: LOG.error(""Failed to add deploy parameters to node "" ""%(node)s when reverting the instance "" ""%(instance)s for migration: %(reason)s"", {'node': instance.node, 'instance': instance.uuid, 'reason': e}) raise exception.MigrationError(reason=e) self.plug_vifs(instance, network_info) mapping = virt_driver.block_device_info_get_mapping(block_device_info) driver_block_device.attach_block_devices( mapping, context, instance, cinder.API(), self) if power_on: self.power_on(context, instance, network_info, block_device_info) @staticmethod def _is_booted_from_volume(block_device_info): """"""Determines whether the instance is booting from volume Determines whether the block device info indicates that the instance is booting from a volume. """""" block_device_mapping = virt_driver.block_device_info_get_mapping( block_device_info) return bool(block_device.get_root_bdm(block_device_mapping))"," ""supports_migrate_to_same_host"": False, def _cleanup_volume_target_info(self, instance): instance.node, detail=True) 'node': instance.node, self._cleanup_volume_target_info(instance)",200,5
openstack%2Fnova~master~I139cb71a58bba7cfcb71f9b712a520945f77dcbc,openstack/nova,master,I139cb71a58bba7cfcb71f9b712a520945f77dcbc,Add destination MSP IP address to PowerVM migrate data,ABANDONED,2018-07-02 20:05:52.000000000,2020-01-20 14:00:29.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10608}, {'_account_id': 13557}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-07-02 20:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/26aaebaff245af403d0526419d7702b1a7d06964', 'message': 'Add destination MSP IP address to PowerVM migrate data\n\nChange-Id: I139cb71a58bba7cfcb71f9b712a520945f77dcbc\n'}, {'number': 2, 'created': '2018-07-02 21:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b119af24c040a9c1ee5355c8fea63619d6fc0f11', 'message': ""Add destination MSP IP address to PowerVM migrate data\n\nThis change adds the destination host's mover service partition\n(MSP) IP addresses to the PowerVM migrate data. The MSP is what\nhosts the live migration I/O. During a live migration the destination\nnode will save its MSP IP addresses as a comma separated list of\nIPs to this field, to be consumed by the driver come time for the\nmigration.\n\nChange-Id: I139cb71a58bba7cfcb71f9b712a520945f77dcbc\n""}, {'number': 3, 'created': '2018-07-10 20:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64f64a2f2d92a61b4c691d4fc909564a7328604d', 'message': ""Add destination MSP IP address to PowerVM migrate data\n\nThis change adds the destination host's mover service partition\n(MSP) IP addresses to the PowerVM migrate data. The MSP is what\nhosts the live migration I/O. During a live migration the destination\nnode will save its MSP IP addresses as a comma separated list of\nIPs to this field, to be consumed by the driver come time for the\nmigration.\n\nChange-Id: I139cb71a58bba7cfcb71f9b712a520945f77dcbc\n""}, {'number': 4, 'created': '2018-07-11 16:33:44.000000000', 'files': ['nova/tests/unit/objects/test_migrate_data.py', 'nova/objects/migrate_data.py', 'nova/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/23e158d90580ba56eb4d2e891cb8a1effbc75f8f', 'message': ""Add destination MSP IP address to PowerVM migrate data\n\nThis change adds the destination host's mover service partition\n(MSP) IP addresses to the PowerVM migrate data. The MSP is what\nhosts the live migration I/O. During a live migration the destination\nnode will save its MSP IP addresses as a comma separated list of\nIPs to this field, to be consumed by the driver come time for the\nmigration.\n\nChange-Id: I139cb71a58bba7cfcb71f9b712a520945f77dcbc\n""}]",4,579676,23e158d90580ba56eb4d2e891cb8a1effbc75f8f,48,17,4,13557,,,0,"Add destination MSP IP address to PowerVM migrate data

This change adds the destination host's mover service partition
(MSP) IP addresses to the PowerVM migrate data. The MSP is what
hosts the live migration I/O. During a live migration the destination
node will save its MSP IP addresses as a comma separated list of
IPs to this field, to be consumed by the driver come time for the
migration.

Change-Id: I139cb71a58bba7cfcb71f9b712a520945f77dcbc
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/579676/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/migrate_data.py', 'nova/tests/unit/objects/test_migrate_data.py']",2,26aaebaff245af403d0526419d7702b1a7d06964,add_pvm_msp_ip_to_mig_data," wait_for_vif_plugged=True dest_msp_ips = '1.1.1.1,2.2.2.2') 'wait_for_vif_plugged': True, 'dest_msp_ips': '1.1.1.1,2.2.2.2' primitive = data(obj.obj_to_primitive(target_version='1.3')) self.assertNotIn('dest_msp_ips', primitive)", wait_for_vif_plugged=True) 'wait_for_vif_plugged': True,11,3
openstack%2Ftripleo-heat-templates~master~Ia41bf10ea65edd51cafee5416697628f972c693e,openstack/tripleo-heat-templates,master,Ia41bf10ea65edd51cafee5416697628f972c693e,clustercheck: use fqdn instead of ip for bind address,MERGED,2020-01-17 13:05:50.000000000,2020-01-20 13:56:46.000000000,2020-01-20 13:44:42.000000000,"[{'_account_id': 6926}, {'_account_id': 13861}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-17 13:05:50.000000000', 'files': ['deployment/pacemaker/clustercheck-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/643c4028b89e5ede856c85fbba83a8acdc39af20', 'message': 'clustercheck: use fqdn instead of ip for bind address\n\nClustercheck service is accessible via port 9200 on the Mysql network\n(e.g. internal API). The bind address specified in the config currently\nuses IP address. This breaks the OpenStack healthcheck because curl\nrefuses to fetch a URI with unquoted IPv6 address.\n\nUse an fqdn as the bind address in the config to make sure the service\nis reachable no matter the type of network used.\n\nChange-Id: Ia41bf10ea65edd51cafee5416697628f972c693e\nCloses-Bug: #1860124\n'}]",0,703070,643c4028b89e5ede856c85fbba83a8acdc39af20,14,7,1,20778,,,0,"clustercheck: use fqdn instead of ip for bind address

Clustercheck service is accessible via port 9200 on the Mysql network
(e.g. internal API). The bind address specified in the config currently
uses IP address. This breaks the OpenStack healthcheck because curl
refuses to fetch a URI with unquoted IPv6 address.

Use an fqdn as the bind address in the config to make sure the service
is reachable no matter the type of network used.

Change-Id: Ia41bf10ea65edd51cafee5416697628f972c693e
Closes-Bug: #1860124
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/70/703070/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/pacemaker/clustercheck-container-puppet.yaml'],1,643c4028b89e5ede856c85fbba83a8acdc39af20,bug/1860124," config_settings: map_merge: - get_attr: [MysqlPuppetBase, role_data, config_settings] - tripleo::profile::pacemaker::clustercheck::bind_address: str_replace: template: ""%{hiera('fqdn_$NETWORK')}"" params: $NETWORK: {get_param: [ServiceNetMap, MysqlNetwork]}"," config_settings: {get_attr: [MysqlPuppetBase, role_data, config_settings]}",9,1
openstack%2Fnova~master~I0e2d90d83180e91c3217f5a806a48e518ab235e8,openstack/nova,master,I0e2d90d83180e91c3217f5a806a48e518ab235e8,Set instance CPU policy to 'share' through image property,MERGED,2019-10-15 02:22:56.000000000,2020-01-20 13:52:38.000000000,2020-01-20 13:49:07.000000000,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 30209}]","[{'number': 1, 'created': '2019-10-15 02:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de896dc34fabf5221caeb1f5fc9d47d91acf87dd', 'message': ""Set instance CPU policy to 'share' when 'hw_cpu_policy==share'\n\nBefore the introduce of 'CPU resource'_, a 'cpu_policy' of None\nis the same as a 'cpu_policy' of 'shared' effectively.\n\nBut these two CPU policies ('shared' and None) have some difference now,\nchecking the 'cpu_policy code here'_, if 'cpu_policy' variable is not set,\nwhich means 'cpu_policy==None', it still possible to get the instance\nCPU policy through the setting of 'resources:VCPU' and 'resources:PCPU'.\n\nWe should return the 'cpu_policy==shared' if 'hw_cpu_policy==share' and\n'hw:cpu_policy' is not defined.\n\nReferences:\n'cpu_policy code here'_ : https://opendev.org/openstack/nova/src/branch/master/nova/virt/hardware.py#L1810-L1816,\nCPU resource: http://specs.openstack.org/openstack/nova-specs/specs/train/approved/cpu-resources.html\n\nChange-Id: I0e2d90d83180e91c3217f5a806a48e518ab235e8\n""}, {'number': 2, 'created': '2019-10-16 09:31:30.000000000', 'files': ['nova/tests/unit/virt/test_hardware.py', 'nova/virt/hardware.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/569ad1402e2447ef72672934947541c81b3d5ef7', 'message': ""Set instance CPU policy to 'share' through image property\n\nBefore the introduce of 'CPU resource', a 'cpu_policy' of None\nis same as a 'cpu_policy' of 'shared' effectively.\n\nBut these two CPU policies ('shared' and None) have some difference now,\nchecking the code in 'hardware.numa_get_constraints', if the variable\n'cpu_policy' is not set, which means 'cpu_policy==None', it still possible\nto get the instance CPU policy through the setting of 'resources:VCPU' and\n'resources:PCPU'.\n\nWe should return the 'cpu_policy==shared' if 'hw_cpu_policy==share' and\n'hw:cpu_policy' is not defined. Otherwise, if you want to set a 'shared'\npolicy through 'hw_cpu_policy', but it might be alerted by the setting\nof 'resources:PCPU'.\n\nChange-Id: I0e2d90d83180e91c3217f5a806a48e518ab235e8\nCloses-Bug: #1848308\n""}]",5,688603,569ad1402e2447ef72672934947541c81b3d5ef7,32,13,2,30209,,,0,"Set instance CPU policy to 'share' through image property

Before the introduce of 'CPU resource', a 'cpu_policy' of None
is same as a 'cpu_policy' of 'shared' effectively.

But these two CPU policies ('shared' and None) have some difference now,
checking the code in 'hardware.numa_get_constraints', if the variable
'cpu_policy' is not set, which means 'cpu_policy==None', it still possible
to get the instance CPU policy through the setting of 'resources:VCPU' and
'resources:PCPU'.

We should return the 'cpu_policy==shared' if 'hw_cpu_policy==share' and
'hw:cpu_policy' is not defined. Otherwise, if you want to set a 'shared'
policy through 'hw_cpu_policy', but it might be alerted by the setting
of 'resources:PCPU'.

Change-Id: I0e2d90d83180e91c3217f5a806a48e518ab235e8
Closes-Bug: #1848308
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/688603/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/hardware.py'],1,de896dc34fabf5221caeb1f5fc9d47d91acf87dd,bug/1848308, elif image_policy in fields.CPUAllocationPolicy.ALL:, elif image_policy == fields.CPUAllocationPolicy.DEDICATED:,1,1
openstack%2Fproject-config~master~I3fa4c26b0c8aeacf1af76f9046ea98edb2fcdbd0,openstack/project-config,master,I3fa4c26b0c8aeacf1af76f9046ea98edb2fcdbd0,"Bye, Bye, Trusty",MERGED,2020-01-17 20:12:16.000000000,2020-01-20 13:50:58.000000000,2020-01-20 13:50:58.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 20:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ffef9c6e94e022e5a576b4ee4c08cad649b8deeb', 'message': 'Set ubuntu-trusty in nodepool to -1\n\nTo start removing ubuntu-trusty from nodepool, set min-ready to -1.\n\nDepends-On: https://review.opendev.org/702771\nDepends-On: https://review.opendev.org/702818\nChange-Id: I3fa4c26b0c8aeacf1af76f9046ea98edb2fcdbd0\n'}, {'number': 2, 'created': '2020-01-19 15:02:39.000000000', 'files': ['tools/build-image.sh', 'nodepool/elements/nodepool-base/finalise.d/89-boot-settings', 'nodepool/elements/nodepool-base/post-install.d/20-iptables', 'nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'playbooks/wheel/release.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml', 'grafana/create-nodepool-dib.sh', 'grafana/nodepool-dib.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/398adb791fb3a00a0550c9822f513fba13022b47', 'message': 'Bye, Bye, Trusty\n\nThis removes trusty from the repo and thus from OpenDev.\n\nAfterwards the AFS volume mirror.wheel.trustyx64 can be deleted.\n\nDepends-On: https://review.opendev.org/702771\nDepends-On: https://review.opendev.org/702818\nChange-Id: I3fa4c26b0c8aeacf1af76f9046ea98edb2fcdbd0\n'}]",0,703189,398adb791fb3a00a0550c9822f513fba13022b47,10,4,2,6547,,,0,"Bye, Bye, Trusty

This removes trusty from the repo and thus from OpenDev.

Afterwards the AFS volume mirror.wheel.trustyx64 can be deleted.

Depends-On: https://review.opendev.org/702771
Depends-On: https://review.opendev.org/702818
Change-Id: I3fa4c26b0c8aeacf1af76f9046ea98edb2fcdbd0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/89/703189/2 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nl01.openstack.org.yaml'],1,ffef9c6e94e022e5a576b4ee4c08cad649b8deeb,trusty-removal, min-ready: -1, min-ready: 1,1,1
openstack%2Fcinder~master~I3198cf17ba87c61802d0897ec9a64838628c59e9,openstack/cinder,master,I3198cf17ba87c61802d0897ec9a64838628c59e9,Remove unused exception catch in revert,MERGED,2019-11-22 07:28:17.000000000,2020-01-20 13:49:27.000000000,2020-01-20 13:44:14.000000000,"[{'_account_id': 5997}, {'_account_id': 8037}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 26693}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30590}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-11-22 07:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/81468044beaa105f48d3db4b50992dd496562c77', 'message': ""Remove unused exception catch in revert\n\nVolumeSizeExceedsAvailableQuota Excepiton\nwon't be raised because volume size don't\nbe changed.\n\nChange-Id: I3198cf17ba87c61802d0897ec9a64838628c59e9\nRelated-Change: https://review.opendev.org/#/c/613664/\n""}, {'number': 2, 'created': '2019-11-22 10:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/90e0fe85a89a311420456a1c1c9f5478c65be016', 'message': ""Remove unused exception catch in revert\n\nVolumeSizeExceedsAvailableQuota exception\nwon't be raised because volume size does\nnot change.\n\nChange-Id: I3198cf17ba87c61802d0897ec9a64838628c59e9\nRelated-Change: https://review.opendev.org/#/c/613664/\n""}, {'number': 3, 'created': '2019-12-23 06:56:40.000000000', 'files': ['cinder/api/v3/volumes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/19a4f505f48d590710e0342992e1da1fd34c220c', 'message': ""Remove unused exception catch in revert\n\nVolumeSizeExceedsAvailableQuota exception\nwon't be raised because volume size does\nnot change.\n\nChange-Id: I3198cf17ba87c61802d0897ec9a64838628c59e9\nRelated-Change: https://review.opendev.org/#/c/613664/\n""}]",2,695633,19a4f505f48d590710e0342992e1da1fd34c220c,108,35,3,8037,,,0,"Remove unused exception catch in revert

VolumeSizeExceedsAvailableQuota exception
won't be raised because volume size does
not change.

Change-Id: I3198cf17ba87c61802d0897ec9a64838628c59e9
Related-Change: https://review.opendev.org/#/c/613664/
",git fetch https://review.opendev.org/openstack/cinder refs/changes/33/695633/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/v3/volumes.py'],1,81468044beaa105f48d3db4b50992dd496562c77,remove_unuse_exception_in_revert,, except exception.VolumeSizeExceedsAvailableQuota as e: raise exc.HTTPForbidden(explanation=six.text_type(e)),0,2
openstack%2Fcharm-cinder-backup-swift-proxy~master~Id58e501ae9270fe4f3c593a6d01a9d3654c9b598,openstack/charm-cinder-backup-swift-proxy,master,Id58e501ae9270fe4f3c593a6d01a9d3654c9b598,Update tox and fix broken url,MERGED,2020-01-14 14:48:59.000000000,2020-01-20 13:47:04.000000000,2020-01-20 13:47:03.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 22799}]","[{'number': 1, 'created': '2020-01-14 14:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/8121fee9af6ee6bb11108651c7f0ffca7d0a2ada', 'message': 'Update tox and fix broken url\n\nRemove python2 tests and point .gitreview at the correct repo\n\nChange-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598\n'}, {'number': 2, 'created': '2020-01-14 14:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/2450d38fcb68923c97ae3f94ce3382a4cc361a85', 'message': 'Update tox and fix broken url\n\nRemove python2 tests and point .gitreview at the correct repo\n\nChange-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598\n'}, {'number': 3, 'created': '2020-01-17 14:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/c4ae160a5cf156a0ddb8a29e1b2a90de8062c2ac', 'message': 'Update tox and fix broken url\n\nRemove python2 tests\nPoint .gitreview at the correct repo\nAdd .zuul.yaml\n\nChange-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598\n'}, {'number': 4, 'created': '2020-01-17 16:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/a9ca2509e3d8f1951c985904825e880e626467b1', 'message': 'Update tox and fix broken url\n\nRemove python2 tests\nPoint .gitreview at the correct repo\nAdd .zuul.yaml\nFix .coveragerc\n\nChange-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598\n'}, {'number': 5, 'created': '2020-01-17 16:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/a00f72ff99278dd052f12ecf8af681bead27968e', 'message': 'Update tox and fix broken url\n\nRemove python2 tests\nPoint .gitreview at the correct repo\nAdd .zuul.yaml\nRemove .coveragerc\n\nChange-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598\n'}, {'number': 6, 'created': '2020-01-17 16:27:27.000000000', 'files': ['.gitignore', '.gitreview', '.zuul.yaml', '.coveragerc', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/def2eab79a8f422aaf05227ea4c6303ddaf0ce97', 'message': 'Update tox and fix broken url\n\nRemove python2 tests\nPoint .gitreview at the correct repo\nAdd .zuul.yaml\nRemove .coveragerc\n\nChange-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598\n'}]",0,702449,def2eab79a8f422aaf05227ea4c6303ddaf0ce97,33,4,6,22799,,,0,"Update tox and fix broken url

Remove python2 tests
Point .gitreview at the correct repo
Add .zuul.yaml
Remove .coveragerc

Change-Id: Id58e501ae9270fe4f3c593a6d01a9d3654c9b598
",git fetch https://review.opendev.org/openstack/charm-cinder-backup-swift-proxy refs/changes/49/702449/2 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'tox.ini']",2,8121fee9af6ee6bb11108651c7f0ffca7d0a2ada,update-tox,"# Classic charm: ./tox.inienvlist = pep8,py37 CHARM_DIR={envdir} AMULET_SETUP_TIMEOUT=5400whitelist_externals = juju passenv = HOME TERM AMULET_* CS_API_* OS_*deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txtdeps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt [testenv:py37] basepython = python3.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt [testenv:py3] basepython = python3 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txtdeps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = flake8 {posargs} hooks unit_tests tests actions lib charm-proof [testenv:cover] # Technique based heavily upon # https://github.com/openstack/nova/blob/master/tox.ini basepython = python3 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt setenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage report [coverage:run] branch = True concurrency = multiprocessing parallel = True source = . omit = .tox/* */charmhelpers/* unit_tests/*[testenv:func] basepython = python3 commands = functest-run-suite --keep-model [testenv:func-smoke] basepython = python3 commands = functest-run-suite --keep-model --smoke [testenv:func-dev] basepython = python3 commands = functest-run-suite --keep-model --dev [testenv:func-target] basepython = python3 commands = functest-run-suite --keep-model --bundle {posargs} ignore = E402,E226 exclude = */charmhelpers","# Source charm: ./tox.inienvlist = pep8,py35,py36 skip_missing_interpreters = True TERM=linux CHARM_LAYERS_DIR={toxinidir}/layers CHARM_INTERFACES_DIR={toxinidir}/interfaces JUJU_REPOSITORY={toxinidir}/build passenv = http_proxy https_proxydeps = -r{toxinidir}/requirements.txt [testenv:build] basepython = python2.7 commands = charm build --log-level DEBUG -o {toxinidir}/build src {posargs} [testenv:py27] basepython = python2.7 # Reactive source charms are Python3-only, but a py27 unit test target # is required by OpenStack Governance. Remove this shim as soon as # permitted. http://governance.openstack.org/reference/cti/python_cti.html whitelist_externals = true commands = true [testenv:py3] basepython = python3 deps = -r{toxinidir}/test-requirements.txt [testenv:py34] basepython = python3.4commands = stestr run {posargs}deps = -r{toxinidir}/test-requirements.txt commands = stestr run {posargs}deps = -r{toxinidir}/test-requirements.txt commands = stestr run {posargs}deps = -r{toxinidir}/test-requirements.txt commands = flake8 {posargs} src unit_tests# E402 ignore necessary for path append before sys module import in actions ignore = E402 ",75,40
openstack%2Fnova~master~I72c2c16ae0441ee605b834ad146513e98f84c632,openstack/nova,master,I72c2c16ae0441ee605b834ad146513e98f84c632,Make removal of host from aggregate consistent,MERGED,2019-11-27 19:29:28.000000000,2020-01-20 13:46:54.000000000,2020-01-20 13:44:02.000000000,"[{'_account_id': 4393}, {'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 9542}, {'_account_id': 10118}, {'_account_id': 12356}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 21813}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-27 19:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/535392cb2cfbbf0ab7b3c5fe8b39e4a1dc071454', 'message': 'Make removal of host from aggregate consistent\n\nIt should allow the same conditions as addition of host allows, for\nexample in case of HostMapping missing for the host being removed.\n\nCloses-Bug: 1854212\nChange-Id: I72c2c16ae0441ee605b834ad146513e98f84c632\n'}, {'number': 2, 'created': '2019-11-27 23:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/244fc8e5453f8addf4e3bfadf09d96230e5f7611', 'message': 'Make removal of host from aggregate consistent\n\nIt should allow the same conditions as addition of host allows, for\nexample in case of HostMapping missing for the host being removed.\n\nCloses-Bug: 1854212\nChange-Id: I72c2c16ae0441ee605b834ad146513e98f84c632\n'}, {'number': 3, 'created': '2020-01-16 17:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63d2b9b9ddd5209b5f9c2f06a026f6662a2d3cb7', 'message': 'Make removal of host from aggregate consistent\n\nIt should allow the same conditions as addition of host allows, for\nexample in case of HostMapping missing for the host being removed.\n\nCloses-Bug: 1854212\nChange-Id: I72c2c16ae0441ee605b834ad146513e98f84c632\n'}, {'number': 4, 'created': '2020-01-17 14:01:40.000000000', 'files': ['nova/api/openstack/compute/aggregates.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6f1e43f831a5418d6202eed9875d4284557a4969', 'message': 'Make removal of host from aggregate consistent\n\nIt should allow the same conditions as addition of host allows, for\nexample in case of HostMapping missing for the host being removed.\n\nCloses-Bug: 1854212\nChange-Id: I72c2c16ae0441ee605b834ad146513e98f84c632\n'}]",8,696392,6f1e43f831a5418d6202eed9875d4284557a4969,57,14,4,12356,,,0,"Make removal of host from aggregate consistent

It should allow the same conditions as addition of host allows, for
example in case of HostMapping missing for the host being removed.

Closes-Bug: 1854212
Change-Id: I72c2c16ae0441ee605b834ad146513e98f84c632
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/696392/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute.py', 'nova/compute/api.py']",2,535392cb2cfbbf0ab7b3c5fe8b39e4a1dc071454,consistent-add-remove-host-from-agg,"def _get_service_in_cell_by_host(context, host_name): # validates the host; HostMappingNotFound or ComputeHostNotFound # is raised if invalid try: mapping = objects.HostMapping.get_by_host(context, host_name) nova_context.set_target_cell(context, mapping.cell_mapping) service = objects.Service.get_by_compute_host(context, host_name) except exception.HostMappingNotFound: try: # NOTE(danms): This targets our cell service = _find_service_in_cell(context, service_host=host_name) except exception.NotFound: raise exception.ComputeHostNotFound(host=host_name) return service service = _get_service_in_cell_by_host(context, host_name) _get_service_in_cell_by_host(context, host_name)"," # validates the host; HostMappingNotFound or ComputeHostNotFound # is raised if invalid try: mapping = objects.HostMapping.get_by_host(context, host_name) nova_context.set_target_cell(context, mapping.cell_mapping) service = objects.Service.get_by_compute_host(context, host_name) except exception.HostMappingNotFound: try: # NOTE(danms): This targets our cell service = _find_service_in_cell(context, service_host=host_name) except exception.NotFound: raise exception.ComputeHostNotFound(host=host_name) # validates the host; HostMappingNotFound or ComputeHostNotFound # is raised if invalid mapping = objects.HostMapping.get_by_host(context, host_name) nova_context.set_target_cell(context, mapping.cell_mapping) objects.Service.get_by_compute_host(context, host_name)",56,26
openstack%2Fcinder~master~I5d98ffec74057b7e33fc6f645d3f7aaf622aff2b,openstack/cinder,master,I5d98ffec74057b7e33fc6f645d3f7aaf622aff2b,Hedvig: Migration to py37,MERGED,2019-08-09 00:09:39.000000000,2020-01-20 13:46:49.000000000,2020-01-20 13:43:58.000000000,"[{'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24757}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26028}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 29756}]","[{'number': 1, 'created': '2019-08-09 00:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3abf78bf88241369778f68a4194e378e12c67927', 'message': 'Migration to py37\nRemove the encode and decode calls to avoid conversion to and from bytes\n\nChange-Id: I5d98ffec74057b7e33fc6f645d3f7aaf622aff2b\nSigned-off-by: Swathi Hrishikesh swathi@hedviginc.com\n'}, {'number': 2, 'created': '2019-08-09 01:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/223b383d4835017fcf9484b158b4e2088c76152f', 'message': 'Hedvig: Migration to py37\n\nRemove the encode and decode calls to avoid conversion to and from bytes\n\nChange-Id: I5d98ffec74057b7e33fc6f645d3f7aaf622aff2b\nSigned-off-by: Swathi Hrishikesh swathi@hedviginc.com\n'}, {'number': 3, 'created': '2019-08-15 23:00:20.000000000', 'files': ['cinder/volume/drivers/hedvig/hedvig_cinder.py', 'cinder/volume/drivers/hedvig/rest_client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a80661608178c8fac1232fd354c72c993e4b9af6', 'message': 'Hedvig: Migration to py37\n\nRemove the encode and decode calls to avoid conversion to and from bytes\n\nChange-Id: I5d98ffec74057b7e33fc6f645d3f7aaf622aff2b\nSigned-off-by: Swathi Hrishikesh swathi@hedviginc.com\n'}]",1,675499,a80661608178c8fac1232fd354c72c993e4b9af6,106,38,3,24757,,,0,"Hedvig: Migration to py37

Remove the encode and decode calls to avoid conversion to and from bytes

Change-Id: I5d98ffec74057b7e33fc6f645d3f7aaf622aff2b
Signed-off-by: Swathi Hrishikesh swathi@hedviginc.com
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/675499/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/hedvig/hedvig_cinder.py', 'cinder/volume/drivers/hedvig/rest_client.py']",2,3abf78bf88241369778f68a4194e378e12c67927,hedvig-train-fixes," return (obj['result']['sessionId']) LOG.debug(""Rest call output %s "", obj) msg = _('REST call status - Retry limit reached') 'virtualDisks': [vDiskName], 'virtualDisks': [vDiskName], 'virtualDisk': vDiskName, 'target': target, 'host': host, 'virtualDisks': [vDiskName], 'targets': [tgtHost], 'virtualDisk': vDiskName, 'target': target, 'virtualDisks': [vDiskName], 'host': host, 'type': type, 'address': address 'virtualDisks': [vDiskName], param['openstackSID'] = snapshotId return obj['result'][0]['snapshotName'] 'srcVolName': srcVolName, 'cloneVolName': dstVolName, total_unit = capacity['total']['units'] used_unit = capacity['used']['units'] 'cloneVolName': dstVolName, 'openstackSID': snapshotID, 'srcVolName': srcVolName, 'snapshotName': snapshotName, 'openstackSID': snapshotId, 'openstackVolName': vDiskName return random.choice(list(self.nodeMap.keys()))"," return (obj['result']['sessionId']).encode('utf-8') LOG.debug(""Rest call output %s "", json_str) msg = _('REST call status - %s') % obj['status'] 'virtualDisks': [vDiskName.encode('utf-8')], 'virtualDisks': [vDiskName.encode('utf-8')], 'virtualDisk': vDiskName.encode('utf-8'), 'target': target.encode('utf-8'), 'host': host.encode('utf-8'), 'virtualDisks': [vDiskName.encode('utf-8')], 'targets': [tgtHost.encode('utf-8')], 'virtualDisk': vDiskName.encode('utf-8'), 'target': target.encode('utf-8'), 'virtualDisks': [vDiskName.encode('utf-8')], 'host': host.encode('utf-8'), 'type': type.encode('utf-8'), 'address': address.encode('utf-8') 'virtualDisks': [vDiskName.encode('utf-8')], param['openstackSID'] = snapshotId.encode('utf-8') return obj['result'][0]['snapshotName'].encode('utf-8') 'srcVolName': srcVolName.encode('utf-8'), 'cloneVolName': dstVolName.encode('utf-8'), total_unit = capacity['total']['units'].encode('utf-8') used_unit = capacity['used']['units'].encode('utf-8') 'cloneVolName': dstVolName.encode('utf-8'), 'openstackSID': snapshotID.encode('utf-8'), 'srcVolName': srcVolName.encode('utf-8'), 'snapshotName': snapshotName.encode('utf-8'), 'openstackSID': snapshotId.encode('utf-8'), 'openstackVolName': vDiskName.encode('utf-8') return random.choice(self.nodeMap.keys())",35,35
openstack%2Fdevstack~master~If3aec9fd1c61e2bb53233be437b97b811dc82414,openstack/devstack,master,If3aec9fd1c61e2bb53233be437b97b811dc82414,Fix DevStack to configure tempest's service_availability,MERGED,2018-11-26 07:57:18.000000000,2020-01-20 13:46:34.000000000,2020-01-20 13:44:18.000000000,"[{'_account_id': 5803}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13252}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2018-11-26 07:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ad4af303cd54b4501a5d5fa91f2e4d186b352803', 'message': ""Fix DevStack to configure tempest's service_availability\n\nTempest's service_availability config option includes all the service\navailability which is further used by tests to take decision of skip\nor run the test.\n\nFor example, [service_availability].nova is true then, compute test will run\nor if [service_availability].aodh is false then, all aodh related tests either\nin aodh tempest plugin or any other plugins will be skipped.\n\nNow question is what is the best way to set the each service availability for\ntempest or tempest plugins tests. We have 2 category of service here-\n1. Service tested by Tempest (nova, cinder, keystone, glance, swift, neutron)\n   (let's say type1 service)\n2. Services tested by Tempest plugins (all other than above list)\n   (let's say type2 service)\n\nWe need the standard way to set both type of service so that we can maintain\nthe setting of service_availability config options in consistent way.\n\nAs discussed on bug#1743688/ and review https://review.openstack.org/#/c/536723/,\nwe will use devstack lib/tempest to set the type1 service which is services test\nowned by Tempest and type2 service setting will be done by devstack plugins of\nthose service.\n\nFor example - [service_availability].ironic will be set by ironic's devstack plugin.\nbecause that is best place we know ironic is installed and available.\n\nTo do that we need:\n1. Add setting of [service_availability].* in devstack plugins\n2. Remove setting of type2 service from devstack lib/tempest\n\nThis commit does the second part and all depends-on patches handle the first part.\nCloses-Bug: #1743688\n\nChange-Id: If3aec9fd1c61e2bb53233be437b97b811dc82414\n""}, {'number': 2, 'created': '2018-11-26 09:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a9a9685e8ff422ffffa757b742cb0fe0428da4b6', 'message': ""Fix DevStack to configure tempest's service_availability\n\nTempest's service_availability config option includes all the service\navailability which is further used by tests to take decision of skip\nor run the test.\n\nFor example, [service_availability].nova is true then, compute test will run\nor if [service_availability].aodh is false then, all aodh related tests either\nin aodh tempest plugin or any other plugins will be skipped.\n\nNow question is what is the best way to set the each service availability for\ntempest or tempest plugins tests. We have 2 category of service here-\n1. Service tested by Tempest (nova, cinder, keystone, glance, swift, neutron)\n   (let's say type1 service)\n2. Services tested by Tempest plugins (all other than above list)\n   (let's say type2 service)\n\nWe need the standard way to set both type of service so that we can maintain\nthe setting of service_availability config options in consistent way.\n\nAs discussed on bug#1743688/ and review https://review.openstack.org/#/c/536723/,\nwe will use devstack lib/tempest to set the type1 service which is services test\nowned by Tempest and type2 service setting will be done by devstack plugins of\nthose service.\n\nFor example - [service_availability].ironic will be set by ironic's devstack plugin.\nbecause that is best place we know ironic is installed and available.\n\nTo do that we need:\n1. Add setting of [service_availability].* in devstack plugins\n2. Remove setting of type2 service from devstack lib/tempest\n\nThis commit does the second part and all depends-on patches handle the first part.\nCloses-Bug: #1743688\n\nIronic[1], Shahra[2] already set those options.\n\nDepends-On: https://review.openstack.org/#/c/619984/\nDepends-On: https://review.openstack.org/#/c/619985/\nDepends-On: https://review.openstack.org/#/c/619992/\n\n[1] http://git.openstack.org/cgit/openstack/ironic/tree/devstack/lib/ironic#n2434\n[2] http://git.openstack.org/cgit/openstack/sahara/tree/devstack/plugin.sh#n257\n\nChange-Id: If3aec9fd1c61e2bb53233be437b97b811dc82414\n""}, {'number': 3, 'created': '2018-11-27 08:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/49647b7c3bfdcca0d540e1692e3737a604f7700d', 'message': ""Fix DevStack to configure tempest's service_availability\n\nTempest's service_availability config option includes all the service\navailability which is further used by tests to take decision of skip\nor run the test.\n\nFor example, [service_availability].nova is true then, compute test will run\nor if [service_availability].aodh is false then, all aodh related tests either\nin aodh tempest plugin or any other plugins will be skipped.\n\nNow question is what is the best way to set the each service availability for\ntempest or tempest plugins tests. We have 2 category of service here-\n1. Service tested by Tempest (nova, cinder, keystone, glance, swift, neutron)\n   (let's say type1 service)\n2. Services tested by Tempest plugins (all other than above list)\n   (let's say type2 service)\n\nWe need the standard way to set both type of service so that we can maintain\nthe setting of service_availability config options in consistent way.\n\nAs discussed on bug#1743688/ and review https://review.openstack.org/#/c/536723/,\nwe will use devstack lib/tempest to set the type1 service which is services test\nowned by Tempest and type2 service setting will be done by devstack plugins of\nthose service.\n\nFor example - [service_availability].ironic will be set by ironic's devstack plugin.\nbecause that is best place we know ironic is installed and available.\n\nTo do that we need:\n1. Add setting of [service_availability].* in devstack plugins\n2. Remove setting of type2 service from devstack lib/tempest\n\nThis commit does the second part and all depends-on patches handle the first part.\nCloses-Bug: #1743688\n\nIronic[1], Shahra[2] already set those options.\n\nDepends-On: https://review.openstack.org/#/c/619984/\nDepends-On: https://review.openstack.org/#/c/619985/\nDepends-On: https://review.openstack.org/#/c/619992/\n\n[1] http://git.openstack.org/cgit/openstack/ironic/tree/devstack/lib/ironic#n2434\n[2] http://git.openstack.org/cgit/openstack/sahara/tree/devstack/plugin.sh#n257\n\nChange-Id: If3aec9fd1c61e2bb53233be437b97b811dc82414\n""}, {'number': 4, 'created': '2019-12-20 18:05:03.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f0dd9996cc635709276f51e4d94c5ebbf5d5b49f', 'message': ""Fix DevStack to configure tempest's service_availability\n\nTempest's service_availability config option includes all the service\navailability which is further used by tests to take decision of skip\nor run the test.\n\nFor example, [service_availability].nova is true then, compute test will run\nor if [service_availability].aodh is false then, all aodh related tests either\nin aodh tempest plugin or any other plugins will be skipped.\n\nNow question is what is the best way to set the each service availability for\ntempest or tempest plugins tests. We have 2 category of service here-\n1. Service tested by Tempest (nova, cinder, keystone, glance, swift, neutron)\n   (let's say type1 service)\n2. Services tested by Tempest plugins (all other than above list)\n   (let's say type2 service)\n\nWe need the standard way to set both type of service so that we can maintain\nthe setting of service_availability config options in consistent way.\n\nAs discussed on bug#1743688/ and review https://review.openstack.org/#/c/536723/,\nwe will use devstack lib/tempest to set the type1 service which is services test\nowned by Tempest and type2 service setting will be done by devstack plugins of\nthose service.\n\nFor example - [service_availability].ironic will be set by ironic's devstack plugin.\nbecause that is best place we know ironic is installed and available.\n\nTo do that we need:\n1. Add setting of [service_availability].* in devstack plugins\n2. Remove setting of type2 service from devstack lib/tempest\n\nThis commit does the second part and all depends-on patches handle the first part.\n\nRelated-Bug: #1743688\n\nChange-Id: If3aec9fd1c61e2bb53233be437b97b811dc82414\n""}]",0,619973,f0dd9996cc635709276f51e4d94c5ebbf5d5b49f,35,10,4,8556,,,0,"Fix DevStack to configure tempest's service_availability

Tempest's service_availability config option includes all the service
availability which is further used by tests to take decision of skip
or run the test.

For example, [service_availability].nova is true then, compute test will run
or if [service_availability].aodh is false then, all aodh related tests either
in aodh tempest plugin or any other plugins will be skipped.

Now question is what is the best way to set the each service availability for
tempest or tempest plugins tests. We have 2 category of service here-
1. Service tested by Tempest (nova, cinder, keystone, glance, swift, neutron)
   (let's say type1 service)
2. Services tested by Tempest plugins (all other than above list)
   (let's say type2 service)

We need the standard way to set both type of service so that we can maintain
the setting of service_availability config options in consistent way.

As discussed on bug#1743688/ and review https://review.openstack.org/#/c/536723/,
we will use devstack lib/tempest to set the type1 service which is services test
owned by Tempest and type2 service setting will be done by devstack plugins of
those service.

For example - [service_availability].ironic will be set by ironic's devstack plugin.
because that is best place we know ironic is installed and available.

To do that we need:
1. Add setting of [service_availability].* in devstack plugins
2. Remove setting of type2 service from devstack lib/tempest

This commit does the second part and all depends-on patches handle the first part.

Related-Bug: #1743688

Change-Id: If3aec9fd1c61e2bb53233be437b97b811dc82414
",git fetch https://review.opendev.org/openstack/devstack refs/changes/73/619973/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,ad4af303cd54b4501a5d5fa91f2e4d186b352803,bug/1743688," # this tempest service list needs to be the services that # tempest own, otherwise we can have an erroneous set of # services tested by tempest plugins needs to be set on service devstack # plugin side as devstack cannot keep track of all the tempest plugins # services. Refer Bug#1743688 for more details. local tempest_services=""key,glance,nova,neutron,cinder,swift"""," # this tempest service list needs to be all the services that # tempest supports, otherwise we can have an erroneous set of local tempest_services=""key,glance,nova,neutron,cinder,swift,heat,ceilometer,horizon,sahara,ironic,trove""",6,3
openstack%2Fcinder~master~Id48da546d43e769ebf6ca71a38d9b03ca6167f7e,openstack/cinder,master,Id48da546d43e769ebf6ca71a38d9b03ca6167f7e,Tests: Remove unused rbd mock_driver_configuration,MERGED,2019-11-19 19:30:39.000000000,2020-01-20 13:44:12.000000000,2020-01-20 13:44:12.000000000,"[{'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30590}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-11-19 19:30:39.000000000', 'files': ['cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc76367cdf81a8b49cb4a6d332f8fba4b123c33f', 'message': 'Tests: Remove unused rbd mock_driver_configuration\n\nThis is unused as of f33baccc3.\n\nChange-Id: Id48da546d43e769ebf6ca71a38d9b03ca6167f7e\n'}]",0,695067,fc76367cdf81a8b49cb4a6d332f8fba4b123c33f,32,29,1,4523,,,0,"Tests: Remove unused rbd mock_driver_configuration

This is unused as of f33baccc3.

Change-Id: Id48da546d43e769ebf6ca71a38d9b03ca6167f7e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/67/695067/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/volume/drivers/test_rbd.py'],1,fc76367cdf81a8b49cb4a6d332f8fba4b123c33f,,,def mock_driver_configuration(value): if value == 'max_over_subscription_ratio': return 1.0 if value == 'reserved_percentage': return 0 return 'RBD' ,0,8
openstack%2Fcinder~master~I1dedc0b31f78f518c2ab5dee5ed7abda1c1d9296,openstack/cinder,master,I1dedc0b31f78f518c2ab5dee5ed7abda1c1d9296,Enable flake8-logging-format extension,MERGED,2019-12-19 16:51:44.000000000,2020-01-20 13:44:09.000000000,2020-01-20 13:44:09.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-19 16:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8326e635d7ff33ea60f283194aa68cc891668357', 'message': ""Enable flake8-logging-format extension\n\nThe flake8-logging-format extension includes several checks for things\nwe've had to try to catch in code reviews until now. This enables the\nextension and fixes the few cases where things had slipped through code\nreview.\n\nG200: Logging statements should not include the exception in logged string\nis disabled since that triggers a lot more issues, some of which may be\nacceptable. That can be left as a follow up exercise if we want to clean\nthose up and enable all checks.\n\nDepends-on: https://review.opendev.org/700024\n\nChange-Id: I1dedc0b31f78f518c2ab5dee5ed7abda1c1d9296\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}, {'number': 2, 'created': '2020-01-09 20:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bdd069085ef3e91b1468fc01b6bf9677660fb76d', 'message': ""Enable flake8-logging-format extension\n\nThe flake8-logging-format extension includes several checks for things\nwe've had to try to catch in code reviews until now. This enables the\nextension and fixes the few cases where things had slipped through code\nreview.\n\nG200: Logging statements should not include the exception in logged string\nis disabled since that triggers a lot more issues, some of which may be\nacceptable. That can be left as a follow up exercise if we want to clean\nthose up and enable all checks.\n\nChange-Id: I1dedc0b31f78f518c2ab5dee5ed7abda1c1d9296\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}, {'number': 3, 'created': '2020-01-09 20:35:25.000000000', 'files': ['cinder/api/extensions.py', 'cinder/volume/flows/api/create_volume.py', 'test-requirements.txt', 'cinder/volume/drivers/stx/client.py', 'cinder/privsep/hscli.py', 'cinder/volume/flows/api/manage_existing.py', 'cinder/tests/hacking/checks.py', 'lower-constraints.txt', 'cinder/volume/drivers/linstordrv.py', 'tox.ini', 'cinder/api/openstack/wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/1f7b0efdcca65d1940f0e982d481651de003710e', 'message': ""Enable flake8-logging-format extension\n\nThe flake8-logging-format extension includes several checks for things\nwe've had to try to catch in code reviews until now. This enables the\nextension and fixes the few cases where things had slipped through code\nreview.\n\nG200: Logging statements should not include the exception in logged string\nis disabled since that triggers a lot more issues, some of which may be\nacceptable. That can be left as a follow up exercise if we want to clean\nthose up and enable all checks.\n\nChange-Id: I1dedc0b31f78f518c2ab5dee5ed7abda1c1d9296\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}]",0,700026,1f7b0efdcca65d1940f0e982d481651de003710e,70,30,3,11904,,,0,"Enable flake8-logging-format extension

The flake8-logging-format extension includes several checks for things
we've had to try to catch in code reviews until now. This enables the
extension and fixes the few cases where things had slipped through code
review.

G200: Logging statements should not include the exception in logged string
is disabled since that triggers a lot more issues, some of which may be
acceptable. That can be left as a follow up exercise if we want to clean
those up and enable all checks.

Change-Id: I1dedc0b31f78f518c2ab5dee5ed7abda1c1d9296
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/700026/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/extensions.py', 'cinder/volume/drivers/stx/client.py', 'cinder/volume/flows/api/create_volume.py', 'test-requirements.txt', 'cinder/privsep/hscli.py', 'cinder/volume/flows/api/manage_existing.py', 'cinder/tests/hacking/checks.py', 'lower-constraints.txt', 'cinder/volume/drivers/linstordrv.py', 'tox.ini', 'cinder/api/openstack/wsgi.py']",11,8326e635d7ff33ea60f283194aa68cc891668357,flake8, LOG.exception('Exception handling resource:') raise," exc_info = (ex_type, ex_value, ex_traceback) LOG.error('Exception handling resource: %s', ex_value, exc_info=exc_info) raise ex_value",13,21
openstack%2Fcinder~master~I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5,openstack/cinder,master,I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5,PowerMax Docs -  corrections and improvements,MERGED,2019-10-18 18:52:31.000000000,2020-01-20 13:44:07.000000000,2020-01-20 13:44:06.000000000,"[{'_account_id': 5997}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12670}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-10-18 18:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71b7d244069e23dab904a45c987ae3ec42c89288', 'message': 'PowerMax Docs -  corrections and improvements\n\n1.  Corrections to PowerMaxOS versions\n2.  Clarifying licensing information\n3.  Clarifying upgrade scenarios\n4.  Formatting\n\nChange-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5\n'}, {'number': 2, 'created': '2019-10-29 16:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5efb5a5a2519a6a1a7a7304b6a5d562008f03f17', 'message': 'PowerMax Docs -  corrections and improvements\n\n1.  Corrections to PowerMaxOS versions\n2.  Clarifying licensing information\n3.  Clarifying upgrade scenarios\n4.  Formatting\n\nChange-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5\n'}, {'number': 3, 'created': '2019-11-04 11:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba737a61bce008323891d60cd70d3a10de1f6bfc', 'message': 'PowerMax Docs -  corrections and improvements\n\n1.  Corrections to PowerMaxOS versions\n2.  Clarifying licensing information\n3.  Clarifying upgrade scenarios\n4.  Formatting\n5.  Failover/failback clarification\n6.  Array OS support\n\nChange-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5\n'}, {'number': 4, 'created': '2019-11-05 14:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f13609136a79d0788cb9de234dfa60717ba2f21a', 'message': 'PowerMax Docs -  corrections and improvements\n\n1.  Corrections to PowerMaxOS versions\n2.  Clarifying licensing information\n3.  Clarifying upgrade scenarios\n4.  Formatting\n5.  Failover/failback clarification\n6.  Array OS support\n\nChange-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5\n'}, {'number': 5, 'created': '2019-12-17 16:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c828b41026dcd369384bde35a1a0a4ea6407285c', 'message': 'PowerMax Docs -  corrections and improvements\n\n1.  Corrections to PowerMaxOS versions\n2.  Clarifying licensing information\n3.  Clarifying upgrade scenarios\n4.  Formatting\n5.  Failover/failback clarification\n6.  Array OS support\n\nChange-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5\n'}, {'number': 6, 'created': '2019-12-19 14:26:27.000000000', 'files': ['doc/source/configuration/block-storage/drivers/dell-emc-powermax-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5ccf4856c70742c5ad1f9a3986499c28ae4a5be7', 'message': 'PowerMax Docs -  corrections and improvements\n\n1.  Corrections to PowerMaxOS versions\n2.  Clarifying licensing information\n3.  Clarifying upgrade scenarios\n4.  Formatting\n5.  Failover/failback clarification\n6.  Array OS support\n\nChange-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5\n'}]",64,689564,5ccf4856c70742c5ad1f9a3986499c28ae4a5be7,118,30,6,12670,,,0,"PowerMax Docs -  corrections and improvements

1.  Corrections to PowerMaxOS versions
2.  Clarifying licensing information
3.  Clarifying upgrade scenarios
4.  Formatting
5.  Failover/failback clarification
6.  Array OS support

Change-Id: I9a7d4bb0810bf47f93eb0f82bfc0e99e7a939af5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/64/689564/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/block-storage/drivers/dell-emc-powermax-driver.rst'],1,71b7d244069e23dab904a45c987ae3ec42c89288,doc_improvements,"The storage system requires a Unisphere for PowerMax (SMC) eLicence PowerMax ~~~~~~~~ There are two licences for the PowerMax 2000 and 8000 - Essentials software package - Pro software package The Dell EMC PowerMax cinder driver requires the Pro software package All Flash ~~~~~~~~~ For full functionality including SRDF for the VMAX All Flash, the FX package, or the F package plus the SRDF a la carte add on is required Hybrid ~~~~~~ .. note:: Each are licensed separately. For further details on how to get the relevant license(s), reference eLicensing Support below.- Rapid TDEV deallocation of deletes 5. Join the first 8 characters and last 8 characters of 3. together 5. Join the first 6 characters and last 6 characters of 3. together explicitly enabled. See the compression `11. All Flash compression support`_ and replication `Volume replication support`_ sections below. if set will be ignored and set to NONE- Make sure the ``open-iscsi`` package is installed on all Compute nodes. specific tags have also changed. Legacy tags like ``vmax_srp``, `` vmax_array``, ``vmax_service_level`` and ``vmax_port_group``, as well as the old driver location, will continue to work until the 'V' release. PowerMax and Hybrid support ``Optimized``, ``Diamond``, ``Platinum``, ``Gold``, ``Silver``, ``Bronze``, and ``NONE`` service levels. VMAX All Flash supports ``Diamond`` and `None. Hybrid and All Flash support ``DSS_REP``, ``DSS``, ``OLTP_REP``, ``OLTP``, and NoneThe storage array looks for this credential and CHAP secret which stored in and 950F and PowerMax 2000 and 8000. It was first introduced Solutions Enabler 8.3.0.11 or later and is enabled by default when associated with a Service Level. This means volumes added to any newly created storage groups will be compressed.https://docs.openstack.org/nova/latest/admin/configuring-migrations.html and | 5978.444 | 5978.444 | Y | Y | Y | | 5978.444 | 5978.221 | Y | Y | N | | 5978.221 | 5978.221 | Y | Y | N | R1 and R2 arrays are not PowerMax OS 5978.444 or newer. to functionality of that of the lowest uCode level, i.e. if R1 is 5978.444 and R2 is 5978.221, expanding a metro volume is not supported, both R1 and R2 need to be on 5978.444 uCode.Group type, Group and Group replication operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Please refer to the following section for the most up to date group type group and group replication operations https://docs.openstack.org/cinder/latest/admin/blockstorage-groups.html legacy volumes without first migrating the volumes to the new REST masking view structure. This can be done by running the migrate.py script in PyU4V. Please refer to the accompanying ``OpenStack`` section of the accompanying README.rst .. code-block:: text $ pip install PyU4V ","For full functionality including SRDF for the VMAX All Flash, the FX package, or the F package plus the SRDF ``a la carte`` add on is required. The storage system also requires a Unisphere for PowerMax (SMC) eLicence. Each are licensed separately. For further details on how to get the relevant license(s), reference eLicensing Support below.- Rapid tdev deallocation of deletes .. note:: VMAX All Flash array with Solutions Enabler 8.3.0.11 or later have compression enabled by default when associated with Diamond Service Level. This means volumes added to any newly created storage groups will be compressed. 5. Add the first 8 characters and last 8 characters together 5. Add the first 6 characters and last 6 characters together explicitly enabled. See the compression and replication sections below. is NONE- Make sure the ``iscsi-initiator-utils`` package is installed on all Compute nodes. specific tags have also changed. Legacy tags like vmax_srp, vmax_array, vmax_service_level and vmax_port_group, as well as the old driver location, will continue to work until the 'V' release. For security and backend uniformity, the use of the XML file for PowerMax backend configuration was deprecated in Queens and removed entirely in Rocky. .. note:: PowerMax and Hybrid support Optimized, Diamond, Platinum, Gold, Silver, Bronze, and NONE service levels. VMAX All Flash supports Diamond and None. Hybrid and All Flash support DSS_REP, DSS, OLTP_REP, OLTP, and NoneThe storagearray looks for this credential and CHAP secret which stored in and 950F and PowerMax 2000 and 8000.and https://docs.openstack.org/nova/latest/admin/configuring-migrations.html.. note:: Known issue - the multi-attach flag is still false after a retype. This is being addressed in https://bugs.launchpad.net/cinder/+bug/1790840 | 5979 | 5979 | Y | Y | Y | | 5979 | 5978 | Y | Y | N | | 5978 | 5978 | Y | Y | N | R1 and R2 arrays are not PowerMax OS 5979 or newer. to functionality of that of the lowest uCode level, i.e. if R1 is 5979 and R2 is 5978, expanding a metro volume is not supported, both R1 and R2 need to be on 5979 uCode.Group type operations ~~~~~~~~~~~~~~~~~~~~~ - Create a group type .. code-block:: console cinder --os-volume-api-version 3.11 group-type-create GROUP_TYPE - Show a group type .. code-block:: console cinder --os-volume-api-version 3.11 group-type-show GROUP_TYPE - List group types .. code-block:: console cinder --os-volume-api-version 3.11 group-type-list - Delete group type .. code-block:: console cinder --os-volume-api-version 3.11 group-type-delete GROUP_TYPE - Set/unset a group spec .. code-block:: console cinder --os-volume-api-version 3.11 group-type-key GROUP_TYPE set consistent_group_snapshot_enabled=""<is> True"" - List group types and group specs: .. code-block:: console cinder --os-volume-api-version 3.11 group-specs-list Group operations ~~~~~~~~~~~~~~~~ - Create a group: .. code-block:: console cinder --os-volume-api-version 3.13 group-create --name GROUP GROUP_TYPE VOLUME_TYPE1,VOLUME_TYPE2 - Show a group: .. code-block:: console cinder --os-volume-api-version 3.13 group-show GROUP - List all groups: .. code-block:: console cinder --os-volume-api-version 3.13 group-list - Create a volume and add it to a group at the time of creation: .. code-block:: console cinder --os-volume-api-version 3.13 create --volume-type VOLUME_TYPE1 --group-id GROUP_ID 1 - Modify a group to add or remove volumes: .. code-block:: console cinder --os-volume-api-version 3.13 group-update --add-volumes UUID1,UUID2 --remove-volumes UUID3,UUID4 GROUP - Delete a group .. code-block:: console cinder --os-volume-api-version 3.13 group-delete --delete-volumes GROUP Group snapshot operations ~~~~~~~~~~~~~~~~~~~~~~~~~ - Create a group snapshot: .. code-block:: console cinder --os-volume-api-version 3.14 group-snapshot-create --name GROUP_SNAPSHOT GROUP - Delete group snapshot(s): .. code-block:: console cinder --os-volume-api-version 3.14 group-snapshot-delete GROUP_SNAPSHOT - Create a group from a group snapshot: .. code-block:: console $ cinder --os-volume-api-version 3.14 group-create-from-src --group-snapshot GROUP_SNAPSHOT --name GROUP - Create a group from a source snapshot: .. code-block:: console $ cinder --os-volume-api-version 3.14 group-create-from-src --source-group SOURCE_GROUP --name GROUP Group replication operations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - Enable group replication .. code-block:: console cinder --os-volume-api-version 3.38 group-enable-replication GROUP - Disable group replication .. code-block:: console cinder --os-volume-api-version 3.38 group-disable-replication GROUP - Failover group .. code-block:: console cinder --os-volume-api-version 3.38 group-failover-replication GROUP - Failback group .. code-block:: console cinder --os-volume-api-version 3.38 group-failover-replication GROUP / --secondary-backend-id default legacy volumes. These volumes will first need to be detached and reattached using the RESTAPI based driver. This is because we have changed the masking view architecture from Pike to better support this functionality.",65,183
openstack%2Fhorizon~stable%2Frocky~I519e15afc975e6da2afb9c72a05448541572bd10,openstack/horizon,stable/rocky,I519e15afc975e6da2afb9c72a05448541572bd10,Fix typo in publicize_image policy name,MERGED,2020-01-09 16:25:20.000000000,2020-01-20 13:42:56.000000000,2020-01-20 13:40:35.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 16:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4cb909088324e27e60f49df13e5dec72a65def84', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/rain because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n(cherry picked from commit d7e392a77f59ec8d14dc433b93ec017262d7b74a)\n'}, {'number': 2, 'created': '2020-01-09 16:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/72c56ac8e13466062b35472209e8c2814cfd63bd', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/train because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n(cherry picked from commit 1fdde52f0b46963703ca786b45d1efa66d0e1f6e)\n'}, {'number': 3, 'created': '2020-01-17 11:11:58.000000000', 'files': ['openstack_dashboard/static/app/core/images/steps/edit-image/edit-image.controller.js', 'releasenotes/notes/publicize-image-policy-name-5d7fd5ecbdcfa893.yaml'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ed23eb60d4674e7d50f9f13cc926d3e3bb4f1121', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/train because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n(cherry picked from commit fe61f2358a6e16ea462630747180b83337eb5b55)\n'}]",0,701766,ed23eb60d4674e7d50f9f13cc926d3e3bb4f1121,13,4,3,1736,,,0,"Fix typo in publicize_image policy name

This patch is not cherry-picked from stable/train because if was fixed
in a scope of a new feature implementation with
https://review.opendev.org/#/c/602468/ commit.

Change-Id: I519e15afc975e6da2afb9c72a05448541572bd10
Closes-Bug: 1859041
(cherry picked from commit fe61f2358a6e16ea462630747180b83337eb5b55)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/66/701766/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/app/core/images/steps/edit-image/edit-image.controller.js'],1,4cb909088324e27e60f49df13e5dec72a65def84,bug/1859041," ctrl.allowPublicizeImage = { rules: [['image', 'publicize_image']] };"," ctrl.allowPublicizeImage = { rules: [['image', 'image:publicize_image']] };",1,1
openstack%2Fkolla~stable%2Fstein~I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,openstack/kolla,stable/stein,I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,config: make kolla work with oslo.config 7.0.0+,MERGED,2020-01-17 13:34:11.000000000,2020-01-20 13:34:18.000000000,2020-01-20 13:32:09.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 13:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6452b60c41d85b05d20b19ae5b3a696a5d922ee8', 'message': ""config: make kolla work with oslo.config 7.0.0+\n\nFrom oslo.config 7.0.0 release notes:\n\n> Positional options are now required by default, to match argparses\n> default behavior. To revert this behavior (and maintain optional\n> positional arguments), you need to explicitly specify positional=True,\n> required=False as part of the options definition.\n\nSo let's follow.\n\nChange-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5\n(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)\n""}, {'number': 2, 'created': '2020-01-20 11:02:24.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/45497837cdb1e239b3a7a69db632aa3b8b6b4224', 'message': ""config: make kolla work with oslo.config 7.0.0+\n\nFrom oslo.config 7.0.0 release notes:\n\n> Positional options are now required by default, to match argparses\n> default behavior. To revert this behavior (and maintain optional\n> positional arguments), you need to explicitly specify positional=True,\n> required=False as part of the options definition.\n\nSo let's follow.\n\nChange-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5\n(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)\n""}]",0,703078,45497837cdb1e239b3a7a69db632aa3b8b6b4224,17,4,2,28374,,,0,"config: make kolla work with oslo.config 7.0.0+

From oslo.config 7.0.0 release notes:

> Positional options are now required by default, to match argparses
> default behavior. To revert this behavior (and maintain optional
> positional arguments), you need to explicitly specify positional=True,
> required=False as part of the options definition.

So let's follow.

Change-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5
(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/78/703078/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,6452b60c41d85b05d20b19ae5b3a696a5d922ee8,," cfg.MultiOpt('regex', types.String(), positional=True, required=False,"," cfg.MultiOpt('regex', types.String(), positional=True,",1,1
openstack%2Fheat~master~I01514d8639e7604cca9846e05904ebe062393550,openstack/heat,master,I01514d8639e7604cca9846e05904ebe062393550,Remove image upload dependency on g-reg,MERGED,2020-01-17 16:21:15.000000000,2020-01-20 13:33:43.000000000,2020-01-20 13:30:47.000000000,"[{'_account_id': 8833}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 16:21:15.000000000', 'files': ['devstack/lib/heat'], 'web_link': 'https://opendev.org/openstack/heat/commit/a32cadd637e2c7acef0ae7cfc9f5a97069012a03', 'message': ""Remove image upload dependency on g-reg\n\nIt's not enabled by default[1] in devstack, is\ndeprecated and not needed for glance v2.\n\n[1] https://review.opendev.org/#/c/702709/\n\nChange-Id: I01514d8639e7604cca9846e05904ebe062393550\n""}]",0,703113,a32cadd637e2c7acef0ae7cfc9f5a97069012a03,15,3,1,8833,,,0,"Remove image upload dependency on g-reg

It's not enabled by default[1] in devstack, is
deprecated and not needed for glance v2.

[1] https://review.opendev.org/#/c/702709/

Change-Id: I01514d8639e7604cca9846e05904ebe062393550
",git fetch https://review.opendev.org/openstack/heat refs/changes/13/703113/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/heat'],1,a32cadd637e2c7acef0ae7cfc9f5a97069012a03,, if is_service_enabled g-api; then, if is_service_enabled g-reg; then,1,1
openstack%2Fcharm-barbican-vault~master~I39d761dfbe1500f06abd617dd97eced671971b7d,openstack/charm-barbican-vault,master,I39d761dfbe1500f06abd617dd97eced671971b7d,Use system CA bundle when verifying Vault certificate,MERGED,2020-01-13 20:16:45.000000000,2020-01-20 13:15:04.000000000,2020-01-20 12:06:47.000000000,"[{'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-13 20:16:45.000000000', 'files': ['src/lib/charm/vault_utils.py', 'unit_tests/test_vault_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-barbican-vault/commit/e23f232a6883d9629c8ed6cf1a103f1cff455a44', 'message': 'Use system CA bundle when verifying Vault certificate\n\nChange-Id: I39d761dfbe1500f06abd617dd97eced671971b7d\nCloses-Bug: #1859092\n'}]",0,702289,e23f232a6883d9629c8ed6cf1a103f1cff455a44,10,4,1,13686,,,0,"Use system CA bundle when verifying Vault certificate

Change-Id: I39d761dfbe1500f06abd617dd97eced671971b7d
Closes-Bug: #1859092
",git fetch https://review.opendev.org/openstack/charm-barbican-vault refs/changes/89/702289/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/vault_utils.py', 'unit_tests/test_vault_utils.py']",2,e23f232a6883d9629c8ed6cf1a103f1cff455a44,bug/1859092," self.hvac.Client.assert_called_once_with( token='token', url='url', verify=vault_utils.SYSTEM_CA_BUNDLE)",,8,1
openstack%2Fnova~master~I67f5b00541c9f72d50c6fe626987872a0930e982,openstack/nova,master,I67f5b00541c9f72d50c6fe626987872a0930e982,functional: Add '_delete_server' to 'InstanceHelperMixin',MERGED,2019-12-05 17:57:20.000000000,2020-01-20 12:49:08.000000000,2020-01-20 12:42:22.000000000,"[{'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-05 17:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/29ece271948ccf9e43579ac2b9b3aa48467079c5', 'message': ""functional: Add '_delete_server' to 'InstanceHelperMixin'\n\nAnother broadly useful helper.\n\nChange-Id: I67f5b00541c9f72d50c6fe626987872a0930e982\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-12-06 16:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa39ef335ac9fa4a84a64e58a054cceef071cc34', 'message': ""functional: Add '_delete_server' to 'InstanceHelperMixin'\n\nAnother broadly useful helper.\n\nChange-Id: I67f5b00541c9f72d50c6fe626987872a0930e982\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-12-10 11:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c31113b1fe6f7f6062aad9ecc7e35e8b10e5856e', 'message': ""functional: Add '_delete_server' to 'InstanceHelperMixin'\n\nAnother broadly useful helper.\n\nChange-Id: I67f5b00541c9f72d50c6fe626987872a0930e982\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2019-12-12 09:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e76bb75f7064e16f4fba2ae035422f5a585eb4b2', 'message': ""functional: Add '_delete_server' to 'InstanceHelperMixin'\n\nAnother broadly useful helper.\n\nChange-Id: I67f5b00541c9f72d50c6fe626987872a0930e982\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2020-01-15 10:31:49.000000000', 'files': ['nova/tests/functional/test_nova_manage.py', 'nova/tests/functional/regressions/test_bug_1679750.py', 'nova/tests/functional/regressions/test_bug_1849409.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/regressions/test_bug_1806064.py', 'nova/tests/functional/regressions/test_bug_1848343.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a436266a416f9e7f8381141a1ae243a3bef18000', 'message': ""functional: Add '_delete_server' to 'InstanceHelperMixin'\n\nAnother broadly useful helper.\n\nChange-Id: I67f5b00541c9f72d50c6fe626987872a0930e982\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",14,697539,a436266a416f9e7f8381141a1ae243a3bef18000,46,11,5,15334,,,0,"functional: Add '_delete_server' to 'InstanceHelperMixin'

Another broadly useful helper.

Change-Id: I67f5b00541c9f72d50c6fe626987872a0930e982
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/697539/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/test_nova_manage.py', 'nova/tests/functional/regressions/test_bug_1679750.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/regressions/test_bug_1806064.py']",6,29ece271948ccf9e43579ac2b9b3aa48467079c5,functional-test-cleanup, self._delete_server(server), self.api.delete_server(server['id']) self._wait_until_deleted(server),15,23
openstack%2Fkolla~stable%2Frocky~I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,openstack/kolla,stable/rocky,I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,config: make kolla work with oslo.config 7.0.0+,MERGED,2020-01-17 13:34:35.000000000,2020-01-20 12:48:01.000000000,2020-01-20 12:48:01.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 13:34:35.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7b99d88ad7d654e22a9a3f1f2a12bed1095dcf33', 'message': ""config: make kolla work with oslo.config 7.0.0+\n\nFrom oslo.config 7.0.0 release notes:\n\n> Positional options are now required by default, to match argparses\n> default behavior. To revert this behavior (and maintain optional\n> positional arguments), you need to explicitly specify positional=True,\n> required=False as part of the options definition.\n\nSo let's follow.\n\nChange-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5\n(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)\n""}]",0,703079,7b99d88ad7d654e22a9a3f1f2a12bed1095dcf33,13,4,1,28374,,,0,"config: make kolla work with oslo.config 7.0.0+

From oslo.config 7.0.0 release notes:

> Positional options are now required by default, to match argparses
> default behavior. To revert this behavior (and maintain optional
> positional arguments), you need to explicitly specify positional=True,
> required=False as part of the options definition.

So let's follow.

Change-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5
(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/79/703079/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,7b99d88ad7d654e22a9a3f1f2a12bed1095dcf33,," cfg.MultiOpt('regex', types.String(), positional=True, required=False,"," cfg.MultiOpt('regex', types.String(), positional=True,",1,1
openstack%2Fnova~master~I91fa2f73185fef48e9aae9b7f61389c374e06676,openstack/nova,master,I91fa2f73185fef48e9aae9b7f61389c374e06676,functional: Add unified '_build_server' helper function,MERGED,2019-12-05 17:57:20.000000000,2020-01-20 12:45:57.000000000,2020-01-20 12:42:09.000000000,"[{'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-05 17:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bea0c03e7d7fe2bc7d2e770632ef2342e42d0987', 'message': ""functional: Add unified '_build_server' helper function\n\n'_IntegratedTestBase' has subclassed 'InstanceHelperMixin' since change\nI0d21cb94c932e6e556eca964c57868c705b2d120, which means both now provide\na '_build_minimal_create_server_request' function. However, only\n'_IntegratedTestBase' provides a '_build_server' function. The\n'_build_minimal_create_server_request' and '_build_server' functions do\npretty much the same thing but there are some differences. Combine these\nunder the '_build_server' alias.\n\nChange-Id: I91fa2f73185fef48e9aae9b7f61389c374e06676\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-12-06 16:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fec29ff6f12de02c4be70dd187a09690bbc9eab', 'message': ""functional: Add unified '_build_server' helper function\n\n'_IntegratedTestBase' has subclassed 'InstanceHelperMixin' since change\nI0d21cb94c932e6e556eca964c57868c705b2d120, which means both now provide\na '_build_minimal_create_server_request' function. However, only\n'_IntegratedTestBase' provides a '_build_server' function. The\n'_build_minimal_create_server_request' and '_build_server' functions do\npretty much the same thing but there are some differences. Combine these\nunder the '_build_server' alias.\n\nChange-Id: I91fa2f73185fef48e9aae9b7f61389c374e06676\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-12-10 11:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/248edbaba6ac1fe3d623c9db3b20ebfc9c0c2fbe', 'message': ""functional: Add unified '_build_server' helper function\n\n'_IntegratedTestBase' has subclassed 'InstanceHelperMixin' since change\nI0d21cb94c932e6e556eca964c57868c705b2d120, which means both now provide\na '_build_minimal_create_server_request' function. However, only\n'_IntegratedTestBase' provides a '_build_server' function. The\n'_build_minimal_create_server_request' and '_build_server' functions do\npretty much the same thing but there are some differences. Combine these\nunder the '_build_server' alias.\n\nChange-Id: I91fa2f73185fef48e9aae9b7f61389c374e06676\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2020-01-15 10:31:49.000000000', 'files': ['nova/tests/functional/test_multiattach.py', 'nova/tests/functional/regressions/test_bug_1849409.py', 'nova/tests/functional/wsgi/test_interfaces.py', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/tests/functional/test_servers_provider_tree.py', 'nova/tests/functional/api_sample_tests/test_multinic.py', 'nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/functional/test_boot_from_volume.py', 'nova/tests/functional/wsgi/test_secgroup.py', 'nova/tests/functional/regressions/test_bug_1852458.py', 'nova/tests/functional/regressions/test_bug_1830747.py', 'nova/tests/functional/libvirt/test_vpmem.py', 'nova/tests/functional/libvirt/test_rt_servers.py', 'nova/tests/functional/regressions/test_bug_1837955.py', 'nova/tests/functional/test_aggregates.py', 'nova/tests/functional/regressions/test_bug_1848343.py', 'nova/tests/functional/test_cross_az_attach.py', 'nova/tests/functional/test_nova_manage.py', 'nova/tests/functional/wsgi/test_servers.py', 'nova/tests/functional/notification_sample_tests/notification_sample_base.py', 'nova/tests/functional/regressions/test_bug_1843090.py', 'nova/tests/functional/regressions/test_bug_1741307.py', 'nova/tests/functional/regressions/test_bug_1764556.py', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/compute/test_init_host.py', 'nova/tests/functional/test_server_group.py', 'nova/tests/functional/test_availability_zones.py', 'nova/tests/functional/test_cross_cell_migrate.py', 'nova/tests/functional/wsgi/test_services.py', 'nova/tests/functional/regressions/test_bug_1718455.py', 'nova/tests/functional/regressions/test_bug_1689692.py', 'nova/tests/functional/regressions/test_bug_1713783.py', 'nova/tests/functional/test_external_networks.py', 'nova/tests/functional/test_instance_actions.py', 'nova/tests/functional/test_server_faults.py', 'nova/tests/functional/regressions/test_bug_1679750.py', 'nova/tests/functional/test_policy.py', 'nova/tests/functional/regressions/test_bug_1797580.py', 'nova/tests/functional/regressions/test_bug_1823370.py', 'nova/tests/functional/regressions/test_bug_1718512.py', 'nova/tests/functional/regressions/test_bug_1669054.py', 'nova/tests/functional/regressions/test_bug_1682693.py', 'nova/tests/functional/regressions/test_bug_1702454.py', 'nova/tests/functional/db/test_archive.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/test_images.py', 'nova/tests/functional/test_legacy_v2_compatible_wrapper.py', 'nova/tests/functional/test_scheduler.py', 'nova/tests/functional/regressions/test_bug_1741125.py', 'nova/tests/functional/test_json_filter.py', 'nova/tests/functional/regressions/test_bug_1780373.py', 'nova/tests/functional/regressions/test_bug_1781286.py', 'nova/tests/functional/regressions/test_bug_1781710.py', 'nova/tests/functional/libvirt/test_reshape.py', 'nova/tests/functional/regressions/test_bug_1815153.py', 'nova/tests/functional/test_server_external_events.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/458d37fceb931be37b8615bc47f3f3d888a7f8ca', 'message': ""functional: Add unified '_build_server' helper function\n\n'_IntegratedTestBase' has subclassed 'InstanceHelperMixin' since change\nI0d21cb94c932e6e556eca964c57868c705b2d120, which means both now provide\na '_build_minimal_create_server_request' function. However, only\n'_IntegratedTestBase' provides a '_build_server' function. The\n'_build_minimal_create_server_request' and '_build_server' functions do\npretty much the same thing but there are some differences. Combine these\nunder the '_build_server' alias.\n\nChange-Id: I91fa2f73185fef48e9aae9b7f61389c374e06676\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",3,697537,458d37fceb931be37b8615bc47f3f3d888a7f8ca,40,12,4,15334,,,0,"functional: Add unified '_build_server' helper function

'_IntegratedTestBase' has subclassed 'InstanceHelperMixin' since change
I0d21cb94c932e6e556eca964c57868c705b2d120, which means both now provide
a '_build_minimal_create_server_request' function. However, only
'_IntegratedTestBase' provides a '_build_server' function. The
'_build_minimal_create_server_request' and '_build_server' functions do
pretty much the same thing but there are some differences. Combine these
under the '_build_server' alias.

Change-Id: I91fa2f73185fef48e9aae9b7f61389c374e06676
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/697537/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/test_multiattach.py', 'nova/tests/functional/regressions/test_bug_1849409.py', 'nova/tests/functional/wsgi/test_interfaces.py', 'nova/tests/functional/libvirt/test_numa_servers.py', 'nova/tests/functional/test_servers_provider_tree.py', 'nova/tests/functional/api_sample_tests/test_multinic.py', 'nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/functional/test_boot_from_volume.py', 'nova/tests/functional/wsgi/test_secgroup.py', 'nova/tests/functional/regressions/test_bug_1830747.py', 'nova/tests/functional/libvirt/test_vpmem.py', 'nova/tests/functional/libvirt/test_rt_servers.py', 'nova/tests/functional/regressions/test_bug_1837955.py', 'nova/tests/functional/test_aggregates.py', 'nova/tests/functional/regressions/test_bug_1848343.py', 'nova/tests/functional/test_cross_az_attach.py', 'nova/tests/functional/test_nova_manage.py', 'nova/tests/functional/wsgi/test_servers.py', 'nova/tests/functional/notification_sample_tests/notification_sample_base.py', 'nova/tests/functional/regressions/test_bug_1843090.py', 'nova/tests/functional/regressions/test_bug_1741307.py', 'nova/tests/functional/regressions/test_bug_1764556.py', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/compute/test_init_host.py', 'nova/tests/functional/test_server_group.py', 'nova/tests/functional/test_availability_zones.py', 'nova/tests/functional/test_cross_cell_migrate.py', 'nova/tests/functional/wsgi/test_services.py', 'nova/tests/functional/regressions/test_bug_1718455.py', 'nova/tests/functional/regressions/test_bug_1689692.py', 'nova/tests/functional/regressions/test_bug_1713783.py', 'nova/tests/functional/test_instance_actions.py', 'nova/tests/functional/test_server_faults.py', 'nova/tests/functional/regressions/test_bug_1679750.py', 'nova/tests/functional/test_policy.py', 'nova/tests/functional/regressions/test_bug_1797580.py', 'nova/tests/functional/regressions/test_bug_1823370.py', 'nova/tests/functional/regressions/test_bug_1718512.py', 'nova/tests/functional/regressions/test_bug_1669054.py', 'nova/tests/functional/regressions/test_bug_1682693.py', 'nova/tests/functional/regressions/test_bug_1702454.py', 'nova/tests/functional/db/test_archive.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/test_images.py', 'nova/tests/functional/test_legacy_v2_compatible_wrapper.py', 'nova/tests/functional/test_scheduler.py', 'nova/tests/functional/regressions/test_bug_1741125.py', 'nova/tests/functional/test_json_filter.py', 'nova/tests/functional/regressions/test_bug_1780373.py', 'nova/tests/functional/regressions/test_bug_1781286.py', 'nova/tests/functional/regressions/test_bug_1781710.py', 'nova/tests/functional/libvirt/test_reshape.py', 'nova/tests/functional/regressions/test_bug_1815153.py', 'nova/tests/functional/test_server_external_events.py']",54,bea0c03e7d7fe2bc7d2e770632ef2342e42d0987,functional-test-cleanup," server_req = self._build_server( image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6',"," flavors = self.api.get_flavors() server_req = self._build_minimal_create_server_request( self.api, ""some-server"", flavor_id=flavors[0][""id""], image_uuid=""155d900f-4e14-4e4c-a73d-069cbf4541e6"",",255,394
openstack%2Fcinder~master~I36c23cc0f61d67e70fe6302c2d0d2501959b28fc,openstack/cinder,master,I36c23cc0f61d67e70fe6302c2d0d2501959b28fc,Add note that block-box is not supported,MERGED,2020-01-10 14:40:00.000000000,2020-01-20 12:45:53.000000000,2020-01-20 12:42:27.000000000,"[{'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}]","[{'number': 1, 'created': '2020-01-10 14:40:00.000000000', 'files': ['contrib/block-box/README.md'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a4d8f761639d63172814a593a32da4167150c600', 'message': 'Add note that block-box is not supported\n\nThe block-box files were added to show a proof of concept for running\nCinder as a containerized service and has not been maintained. Some of\nthe files may still be useful for someone that is looking for some\npointers on how to do this, but there are other projects now that are\nfocused on containerizing OpenStack services.\n\nThis adds a note to the README to make it clear it is not supported.\n\nCloses-bug: #1859158\n\nChange-Id: I36c23cc0f61d67e70fe6302c2d0d2501959b28fc\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,701974,a4d8f761639d63172814a593a32da4167150c600,29,23,1,11904,,,0,"Add note that block-box is not supported

The block-box files were added to show a proof of concept for running
Cinder as a containerized service and has not been maintained. Some of
the files may still be useful for someone that is looking for some
pointers on how to do this, but there are other projects now that are
focused on containerizing OpenStack services.

This adds a note to the README to make it clear it is not supported.

Closes-bug: #1859158

Change-Id: I36c23cc0f61d67e70fe6302c2d0d2501959b28fc
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/74/701974/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/block-box/README.md'],1,a4d8f761639d63172814a593a32da4167150c600,block-box,** This was a proof of concept for running Cinder services in containers and is no longer supported.** There are several projects that support containerized services now. A good place to start may be the [LOCI Project](https://opendev.org/openstack/loci). ,,6,0
openstack%2Fneutron~stable%2Fstein~Ie7ea79cb753f360bb0bca7df8484710b5d32ccf7,openstack/neutron,stable/stein,Ie7ea79cb753f360bb0bca7df8484710b5d32ccf7,Check mtu on network update,MERGED,2020-01-07 14:31:31.000000000,2020-01-20 12:45:15.000000000,2020-01-20 12:42:05.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26106}, {'_account_id': 26622}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-07 14:31:31.000000000', 'files': ['neutron/tests/fullstack/test_mtu.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ecd0fa1a10dc87df248095888948fcec27c1c0d', 'message': 'Check mtu on network update\n\nWhen creating a network the mtu of the network is\nchecked against the maximum mtu value.\nThis should also be done on network update.\n\nChange-Id: Ie7ea79cb753f360bb0bca7df8484710b5d32ccf7\nCloses-Bug: #1848152\n(cherry picked from commit f711090ed3d9b6c449a4fbc8ffe2eac7df6da193)\n'}]",0,701370,7ecd0fa1a10dc87df248095888948fcec27c1c0d,28,8,1,30523,,,0,"Check mtu on network update

When creating a network the mtu of the network is
checked against the maximum mtu value.
This should also be done on network update.

Change-Id: Ie7ea79cb753f360bb0bca7df8484710b5d32ccf7
Closes-Bug: #1848152
(cherry picked from commit f711090ed3d9b6c449a4fbc8ffe2eac7df6da193)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/701370/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/fullstack/test_mtu.py', 'neutron/plugins/ml2/plugin.py']",2,7ecd0fa1a10dc87df248095888948fcec27c1c0d,, db_network.mtu = self._get_network_mtu(db_network)," db_network.mtu = self._get_network_mtu(db_network, validate=False)",12,5
openstack%2Fnova~master~I475ea0fa5f2d5b197118f0ced5a0ff6907411972,openstack/nova,master,I475ea0fa5f2d5b197118f0ced5a0ff6907411972,functional: Add unified '_(build|create)_flavor' helper functions,MERGED,2019-12-05 17:57:20.000000000,2020-01-20 12:42:15.000000000,2020-01-20 12:42:15.000000000,"[{'_account_id': 5754}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-05 17:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/44aff98fc0ce89feb0b0f47c280fb9620cc7de34', 'message': ""functional: Add unified '_(build|create)_flavor' helper functions\n\nAnother one that helps avoid having to provide multiple implementations\nof a thing.\n\nChange-Id: I475ea0fa5f2d5b197118f0ced5a0ff6907411972\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-12-06 16:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1957298a6fa77f42421cb0ffe7b5228a879dff46', 'message': ""functional: Add unified '_(build|create)_flavor' helper functions\n\nAnother one that helps avoid having to provide multiple implementations\nof a thing.\n\nChange-Id: I475ea0fa5f2d5b197118f0ced5a0ff6907411972\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-12-10 11:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14204177ad4116691c5af66ca74cbd96334316e0', 'message': ""functional: Add unified '_(build|create)_flavor' helper functions\n\nAnother one that helps avoid having to provide multiple implementations\nof a thing.\n\nChange-Id: I475ea0fa5f2d5b197118f0ced5a0ff6907411972\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2019-12-12 09:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63fd2f3cfb07bd8136afeaa6ee0d9c8e2b62affe', 'message': ""functional: Add unified '_(build|create)_flavor' helper functions\n\nAnother one that helps avoid having to provide multiple implementations\nof a thing.\n\nChange-Id: I475ea0fa5f2d5b197118f0ced5a0ff6907411972\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2020-01-15 10:31:49.000000000', 'files': ['nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/libvirt/test_vpmem.py', 'nova/tests/functional/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b572dbe904d63cd693de94045c6e0ef97acd3052', 'message': ""functional: Add unified '_(build|create)_flavor' helper functions\n\nAnother one that helps avoid having to provide multiple implementations\nof a thing.\n\nChange-Id: I475ea0fa5f2d5b197118f0ced5a0ff6907411972\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",6,697538,b572dbe904d63cd693de94045c6e0ef97acd3052,44,11,5,15334,,,0,"functional: Add unified '_(build|create)_flavor' helper functions

Another one that helps avoid having to provide multiple implementations
of a thing.

Change-Id: I475ea0fa5f2d5b197118f0ced5a0ff6907411972
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/697538/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/integrated_helpers.py', 'nova/tests/functional/libvirt/test_vpmem.py', 'nova/tests/functional/test_servers.py']",3,44aff98fc0ce89feb0b0f47c280fb9620cc7de34,functional-test-cleanup,," def _create_flavor(self): body = { 'flavor': { 'id': 'vbst', 'name': 'special', 'ram': 512, 'vcpus': 1, 'disk': 10, 'OS-FLV-EXT-DATA:ephemeral': 20, 'swap': 5 * 1024, 'rxtx_factor': 1.0, 'os-flavor-access:is_public': True, }, } self.admin_api.post_flavor(body) return body['flavor']['id'] ",64,71
openstack%2Fkolla~stable%2Fstein~Iacd75261d14dc7d9fe89d0db7502831976a6b894,openstack/kolla,stable/stein,Iacd75261d14dc7d9fe89d0db7502831976a6b894,[stein] Bump versions and pin vmware-nsx,MERGED,2020-01-20 09:47:02.000000000,2020-01-20 12:22:21.000000000,2020-01-20 12:20:32.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-20 09:47:02.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8bc3b193642b68c7070a32f6887dfb070c451011', 'message': '[stein] Bump versions and pin vmware-nsx\n\nFor some reason vmware-nsx releases outside openstack/releases\nkeeping the neutron version in sync.\nSomehow we missed the pin in stein (it is pinned in rocky and train).\n\nChange-Id: Iacd75261d14dc7d9fe89d0db7502831976a6b894\n'}]",0,703351,8bc3b193642b68c7070a32f6887dfb070c451011,9,5,1,30491,,,0,"[stein] Bump versions and pin vmware-nsx

For some reason vmware-nsx releases outside openstack/releases
keeping the neutron version in sync.
Somehow we missed the pin in stein (it is pinned in rocky and train).

Change-Id: Iacd75261d14dc7d9fe89d0db7502831976a6b894
",git fetch https://review.opendev.org/openstack/kolla refs/changes/51/703351/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,8bc3b193642b68c7070a32f6887dfb070c451011,bump-versions-and-pin-vmware-nsx," 'neutron-fwaas-14.0.1.tar.gz')}, 'vmware-nsx-14.0.0.tar.gz')},"," 'neutron-fwaas-14.0.0.tar.gz')}, 'vmware-nsx-master.tar.gz')},",2,2
openstack%2Fironic-python-agent~master~I5f326db2d37b2a15090ec84e477e63f7d92e7447,openstack/ironic-python-agent,master,I5f326db2d37b2a15090ec84e477e63f7d92e7447,Search for efi partition,MERGED,2019-12-04 19:10:30.000000000,2020-01-20 12:17:21.000000000,2019-12-06 02:03:06.000000000,"[{'_account_id': 10239}, {'_account_id': 15064}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-04 19:10:30.000000000', 'files': ['ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/966356e58c786fab1b176767615c481d449076a2', 'message': 'Search for efi partition\n\nThis patch adds a function that will be responsible to identify\nthe efi partition on a give device, this is necessary on the Software\nRaid scenario and when installing bootloader.\n\nChange-Id: I5f326db2d37b2a15090ec84e477e63f7d92e7447\nCo-Authored-By: Raphael Glon <raphael.glon@corp.ovh.com>\n'}]",0,697345,966356e58c786fab1b176767615c481d449076a2,17,6,1,15519,,,0,"Search for efi partition

This patch adds a function that will be responsible to identify
the efi partition on a give device, this is necessary on the Software
Raid scenario and when installing bootloader.

Change-Id: I5f326db2d37b2a15090ec84e477e63f7d92e7447
Co-Authored-By: Raphael Glon <raphael.glon@corp.ovh.com>
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/45/697345/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py']",2,966356e58c786fab1b176767615c481d449076a2,utils,"PARTED_ESP_PATTERN = re.compile(r'^\s*(\d+)\s.*\sfat\d*\s.*esp(,|\s|$).*$') def get_efi_part_on_device(device): """"""Looks for the efi partition on a given device :param device: lock device upon which to check for the efi partition :return: the efi partition or None """""" efi_part = None out, _u = execute('parted', '-s', device, '--', 'print') for line in out.splitlines(): m = PARTED_ESP_PATTERN.match(line) if m: efi_part = m.group(1) LOG.debug(""Found efi partition %s on device %s."", efi_part, device) break else: LOG.debug(""No efi partition found on device %s"", device) return efi_part",,68,0
openstack%2Fopenstack-ansible~stable%2Ftrain~I4b855429b95772b71316760b8873d8feca9c2780,openstack/openstack-ansible,stable/train,I4b855429b95772b71316760b8873d8feca9c2780,Set fixed version for networking-calico,MERGED,2020-01-18 08:54:59.000000000,2020-01-20 12:07:26.000000000,2020-01-20 12:05:15.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-01-18 08:54:59.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8b1682dd3b5065677f6bee11000ec2fd24c0f55f', 'message': ""Set fixed version for networking-calico\n\nCalico plugin installation fails, as they tend to tag the same SHA\nseveral times, which breaks PBR. This results in non-working deployments\nTo avoid it we set fixed calico version and will be maintaining it's\nupdate manualy from time to time. Their codebase don't change frequently\n\nChange-Id: I4b855429b95772b71316760b8873d8feca9c2780\n(cherry picked from commit aa79d8186665899070c94f8e94cf76e95bc62ce6)\n""}]",0,703228,8b1682dd3b5065677f6bee11000ec2fd24c0f55f,10,4,1,25023,,,0,"Set fixed version for networking-calico

Calico plugin installation fails, as they tend to tag the same SHA
several times, which breaks PBR. This results in non-working deployments
To avoid it we set fixed calico version and will be maintaining it's
update manualy from time to time. Their codebase don't change frequently

Change-Id: I4b855429b95772b71316760b8873d8feca9c2780
(cherry picked from commit aa79d8186665899070c94f8e94cf76e95bc62ce6)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/28/703228/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,8b1682dd3b5065677f6bee11000ec2fd24c0f55f,bump_calico-stable/train,networking_calico_git_install_branch: 3.11.1 # HEAD as of 12.01.2020networking_calico_git_track_branch: None,networking_calico_git_install_branch: 594cf28fb0359c1abf6da1022574be5ddd710a7b # HEAD as of 12.01.2020networking_calico_git_track_branch: master,2,2
openstack%2Fneutron~master~I9788d0c853f915326de904a805607bfd0b73405c,openstack/neutron,master,I9788d0c853f915326de904a805607bfd0b73405c,Fix invalid assertFalse statements,MERGED,2019-12-26 09:38:09.000000000,2020-01-20 11:59:06.000000000,2020-01-20 11:55:43.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-26 09:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/feed8a64bfc470d46bf4ebd235b6ca05c33eefd8', 'message': 'Fix invalid assertFalse statements\n\nThis is to fix invalid assertFalse statements of\n  * self.assertFalse([], tun_br.mock_calls)\n  * self.assertFalse([], phys_br.mock_calls)\nwhich will never raise exception.\n\nChange-Id: I9788d0c853f915326de904a805607bfd0b73405c\n'}, {'number': 2, 'created': '2020-01-17 10:07:06.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/13f1015809a71e68b912c9b41f685b822db4c666', 'message': 'Fix invalid assertFalse statements\n\nThis is to fix invalid assertFalse statements of\n  * self.assertFalse([], tun_br.mock_calls)\n  * self.assertFalse([], phys_br.mock_calls)\nwhich will never raise exception.\n\nThis patch also changes all assertions of not called\nand assertions that mock has some specific calls to use\nassert_not_called() and assert_has_calls() methods.\n\nChange-Id: I9788d0c853f915326de904a805607bfd0b73405c\n'}]",6,700608,13f1015809a71e68b912c9b41f685b822db4c666,27,9,2,20190,,,0,"Fix invalid assertFalse statements

This is to fix invalid assertFalse statements of
  * self.assertFalse([], tun_br.mock_calls)
  * self.assertFalse([], phys_br.mock_calls)
which will never raise exception.

This patch also changes all assertions of not called
and assertions that mock has some specific calls to use
assert_not_called() and assert_has_calls() methods.

Change-Id: I9788d0c853f915326de904a805607bfd0b73405c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/700608/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'],1,feed8a64bfc470d46bf4ebd235b6ca05c33eefd8,assertFalse, self.assertFalse(tun_br.mock_calls) self.assertFalse(phys_br.mock_calls)," self.assertFalse([], tun_br.mock_calls) self.assertFalse([], phys_br.mock_calls)",2,2
openstack%2Fsushy-cli~master~I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b,openstack/sushy-cli,master,I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b,Update tox.ini file,MERGED,2020-01-17 17:48:04.000000000,2020-01-20 11:54:11.000000000,2020-01-20 11:54:11.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 26340}]","[{'number': 1, 'created': '2020-01-17 17:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-cli/commit/f1782a565d80997381fd8e470578b1ea24f57c56', 'message': 'Update toxi.ini file\n\nadding pep8 test\n\nChange-Id: I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b\n'}, {'number': 2, 'created': '2020-01-20 10:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-cli/commit/d2af3961b361dee715c1b79df98ae746947e9bd4', 'message': 'Update toxi.ini file\n\nadding pep8 test\n\nChange-Id: I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b\n'}, {'number': 3, 'created': '2020-01-20 11:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy-cli/commit/96b249f26bee4d3f497bc1805253365e44dce5e2', 'message': 'Update toxi.ini file\n\nadding pep8 test\n\nChange-Id: I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b\n'}, {'number': 4, 'created': '2020-01-20 11:47:28.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sushy-cli/commit/f1bfcef80637faa085db5f48824c3dbde1925fb6', 'message': 'Update tox.ini file\n\nadding pep8 test\n\nChange-Id: I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b\n'}]",5,703139,f1bfcef80637faa085db5f48824c3dbde1925fb6,18,3,4,31182,,,0,"Update tox.ini file

adding pep8 test

Change-Id: I753e5b07a5a2fd2bf2daf004d9af97bd952adf0b
",git fetch https://review.opendev.org/openstack/sushy-cli refs/changes/39/703139/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'tox.ini']",3,f1782a565d80997381fd8e470578b1ea24f57c56,,"minversion = 3.1.0 envlist = py3, pep8 skipsdist = True ignore_basepython_conflict = trueusedevelop = True install_command = pip install {opts} {packages} basepython = python3 VIRTUAL_ENV = {envdir} PYTHONWARNINGS = default::DeprecationWarning deps = -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt commands = stestr run {posargs} stestr slowest [testenv:pep8] commands = flake8 {posargs} [flake8] # E123, E125 skipped as they are invalid PEP-8. show-source = True ignore = E123, E125 builtins = _ exclude = .venv, .git, .tox, dist, doc, *lib/python*, *egg,build","envlist = py35, py36, py37, py38, flake8 [travis] python = 3.8: py38 3.7: py37 3.6: py36 3.5: py35 [testenv:flake8] basepython = python deps = flake8 commands = flake8 sushycli PYTHONPATH = {toxinidir} commands = python setup.py test",27,15
openstack%2Fgovernance~master~I2d5b15031299bf9f64afa99775cc9b7d363c4c09,openstack/governance,master,I2d5b15031299bf9f64afa99775cc9b7d363c4c09,Add RBAC investment opportunity for 2019,MERGED,2019-09-16 14:57:26.000000000,2020-01-20 11:51:58.000000000,2020-01-20 11:50:02.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 4257}, {'_account_id': 5046}, {'_account_id': 6935}, {'_account_id': 8482}, {'_account_id': 9003}, {'_account_id': 10607}, {'_account_id': 13995}, {'_account_id': 16708}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-16 14:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/9f64c6c86a7fbc1a9e7aa78a12dc48ea109196a2', 'message': 'Add RBAC investment opportunity for 2019\n\nRework the 2018 entry for RBAC into the new ""Upstream Investment\nOpportunity"" format and add it to the 2019 list.\n\nChange-Id: I2d5b15031299bf9f64afa99775cc9b7d363c4c09\n'}, {'number': 2, 'created': '2019-09-16 15:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/75c9c26c482bc27f66f41225d61f562fa20f6f0b', 'message': 'Add RBAC investment opportunity for 2019\n\nRework the 2018 entry for RBAC into the new ""Upstream Investment\nOpportunity"" format and add it to the 2019 list.\n\nDepends-on: https://review.opendev.org/#/c/682392/\nChange-Id: I2d5b15031299bf9f64afa99775cc9b7d363c4c09\n'}, {'number': 3, 'created': '2019-12-05 04:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/8aee2e343e943dfc4325b63f889c09b129830644', 'message': 'Add RBAC investment opportunity for 2019\n\nRework the 2018 entry for RBAC into the new ""Upstream Investment\nOpportunity"" format and add it to the 2019 list.\n\nChange-Id: I2d5b15031299bf9f64afa99775cc9b7d363c4c09\n'}, {'number': 4, 'created': '2020-01-07 10:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/c56035c86664296ff9d92846bc060be57ef0488c', 'message': 'Add RBAC investment opportunity for 2019\n\nRework the 2018 entry for RBAC into the new ""Upstream Investment\nOpportunity"" format and add it to the 2019 list.\n\nChange-Id: I2d5b15031299bf9f64afa99775cc9b7d363c4c09\n'}, {'number': 5, 'created': '2020-01-07 12:43:24.000000000', 'files': ['reference/upstream-investment-opportunities/2019/rbac.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/995bbae70a7bea4faeefb99bf09ba37fa13946f1', 'message': 'Add RBAC investment opportunity for 2019\n\nRework the 2018 entry for RBAC into the new ""Upstream Investment\nOpportunity"" format and add it to the 2019 list.\n\nChange-Id: I2d5b15031299bf9f64afa99775cc9b7d363c4c09\n'}]",7,682380,995bbae70a7bea4faeefb99bf09ba37fa13946f1,53,12,5,9003,,,0,"Add RBAC investment opportunity for 2019

Rework the 2018 entry for RBAC into the new ""Upstream Investment
Opportunity"" format and add it to the 2019 list.

Change-Id: I2d5b15031299bf9f64afa99775cc9b7d363c4c09
",git fetch https://review.opendev.org/openstack/governance refs/changes/80/682380/5 && git format-patch -1 --stdout FETCH_HEAD,['reference/upstream-investment-opportunities/2019/rbac.rst'],1,9f64c6c86a7fbc1a9e7aa78a12dc48ea109196a2,formal-vote,"=========================================== Consistent Role Based Access Control (RBAC) =========================================== Summary ------- The OpenStack community is seeking contributors to the Keystone consistent RBAC (Role-Based Access Control) initiative. This ongoing initiative aims to provide set of common roles that will enable secure enforcement of authorization policies across OpenStack projects and deployments. Business Case ------------- Sponsorship of contributors to this RBAC initiative positions them to influence direction and drive implementation choices on critical infrastructure used by every OpenStack project and every OpenStack deployment -- ensuring that an organization's downstream requirements are fully understood and taken into account. Because of its use in every OpenStack project, work on this RBAC initiative is a good way to build reputation and influence upstream, and at the same time gain vital in-house expertise for an organization's downstream deployments or software distributions. Technical Details ----------------- Currently, most OpenStack services have a very binary approach to Role Based Access Control (RBAC) enforcement. This approach usually handicaps new functionality from being exposed to users because users typically do not fall in one of two camps. Contributors either need to lock down the feature to only system administrators, or open it up to nearly every user in the deployment. This is especially true for APIs that expose details about multiple tenants. Implementing better API protection allows contributors to expose more functionality to end users and operators by default. Lowering the bar for users to access a feature means more opportunities for feedback loops, more end users getting access to the functionality they need, and makes OpenStack more usable overall. Enhanced Security ~~~~~~~~~~~~~~~~~ OpenStack has a wide variety of users. Auditing APIs and adjusting default access control increases security across the entire OpenStack platform. This exercise gives contributors the ability to provide secure defaults for new deployments. Reasonable default values that are inherently secure makes it easier for organizations with strict security requirement to deploy OpenStack. Reduced Operational Complexity ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Today's RBAC enforcement implementation lacks secure defaults, but it is somewhat configurable. Deployments that must have a more secure enforcement implementation are forced to maintain arduously complex configuration files. Furthermore, many organizations re-implement similar use cases. Interoperability ~~~~~~~~~~~~~~~~ Because policy configuration gives deployments the flexibility to maintain complicated policies at their own expense, it is common to see many organizations solve the same problem. Unfortunately, it's unlikely organizations are sharing the same solution. This pattern impedes interoperability between deployments, making it frustrating for users interacting with different OpenStack clouds. Offering a reasonable set of roles and implementing basic RBAC improves interoperability by not requiring each organization to solve the same problem individually. ----------------- Contact ------- For more information on how to contribute to this initiative, please read the `authorization documentation`_ dedicated to describing the problem. For questions about getting involved with this initiative, you may use the Keystone IRC channel (``#openstack-keystone`` on `Freenode <https://freenode.net>`_) and on the OpenStack-discuss `mailing list`_ using the ``[keystone]`` tag in the subject line. .. _authorization documentation: https://docs.openstack.org/keystone/latest/contributor/services.html#why-are-authorization-scopes-important .. _mailing list: http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-discuss ",,88,0
openstack%2Fgovernance~master~Iba68b49c1eedd29afaca67bc3c2ed2f716da7a57,openstack/governance,master,Iba68b49c1eedd29afaca67bc3c2ed2f716da7a57,New charm for watcher,MERGED,2020-01-11 10:27:42.000000000,2020-01-20 11:49:39.000000000,2020-01-20 11:46:27.000000000,"[{'_account_id': 308}, {'_account_id': 935}, {'_account_id': 4257}, {'_account_id': 7353}, {'_account_id': 8099}, {'_account_id': 10607}, {'_account_id': 13686}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 30442}]","[{'number': 1, 'created': '2020-01-11 10:27:42.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/99f3b3ad653ad43c7f814d59d8e16f405fbf2340', 'message': 'New charm for watcher\n\nAdd watcher charm to support charmed OpenStack Watcher\n\nDepends-On: Ic526595e4eac0e530eeb7603a88165b9616e0d17\nChange-Id: Iba68b49c1eedd29afaca67bc3c2ed2f716da7a57\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}]",0,702072,99f3b3ad653ad43c7f814d59d8e16f405fbf2340,18,10,1,28014,,,0,"New charm for watcher

Add watcher charm to support charmed OpenStack Watcher

Depends-On: Ic526595e4eac0e530eeb7603a88165b9616e0d17
Change-Id: Iba68b49c1eedd29afaca67bc3c2ed2f716da7a57
Signed-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>
",git fetch https://review.opendev.org/openstack/governance refs/changes/72/702072/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,99f3b3ad653ad43c7f814d59d8e16f405fbf2340,project-update, charm-watcher: release-management: external repos: - openstack/charm-watcher,,4,0
openstack%2Freleases~master~I0c9f97cb12a429d2e54d94df2b3e110156278bc1,openstack/releases,master,I0c9f97cb12a429d2e54d94df2b3e110156278bc1,Add signature links for independent deliverables,MERGED,2019-12-18 22:56:48.000000000,2020-01-20 11:35:32.000000000,2020-01-20 11:35:32.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-18 22:56:48.000000000', 'files': ['doc/source/_exts/deliverables.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/2925d575547205a8d4047268de1cf0fabc222252', 'message': ""Add signature links for independent deliverables\n\nWe have been filtering whether to include pgp links for deliverables if\nthe series was >= 'O', which resulted in filtering out any independent\ndeliverables.\n\nThis updates the check to account for independent deliverables. It also\nmakes the table format consistent for pre- and post-Ocata, just leaving\nthe column blank for series where we did not generate signatures.\n\nChange-Id: I0c9f97cb12a429d2e54d94df2b3e110156278bc1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}]",0,699885,2925d575547205a8d4047268de1cf0fabc222252,11,5,1,11904,,,0,"Add signature links for independent deliverables

We have been filtering whether to include pgp links for deliverables if
the series was >= 'O', which resulted in filtering out any independent
deliverables.

This updates the check to account for independent deliverables. It also
makes the table format consistent for pre- and post-Ocata, just leaving
the column blank for series where we did not generate signatures.

Change-Id: I0c9f97cb12a429d2e54d94df2b3e110156278bc1
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/85/699885/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/_exts/deliverables.py'],1,2925d575547205a8d4047268de1cf0fabc222252,pgp," headers = ['Version', 'Signature', 'Repo', 'Git Commit'] data = ((links.artifact_link(r.version, p, deliv), links.artifact_signature_link(r.version, 'pgp', p, deliv) if (series and series[0] >= 'o') or deliv.is_independent else '', p.repo, p.hash) for r in reversed(deliv.releases) for p in r.projects if not (r.is_eol or r.is_em)) columns = [10, 10, 40, 50]"," # We have signatures for artifacts only after newton if series and series[0] >= 'o': headers = ['Version', 'Signature', 'Repo', 'Git Commit'] data = ((links.artifact_link(r.version, p, deliv), links.artifact_signature_link(r.version, 'pgp', p, deliv), p.repo, p.hash) for r in reversed(deliv.releases) for p in r.projects if not (r.is_eol or r.is_em)) columns = [10, 10, 40, 50] else: headers = ['Version', 'Repo', 'Git Commit'] data = ((links.artifact_link(r.version, p, deliv), p.repo, p.hash) for r in reversed(deliv.releases) for p in r.projects if not (r.is_eol or r.is_em)) columns = [10, 40, 50]",12,21
openstack%2Freleases~master~I828715f30695fac1036b982b180a6fdaec03bc43,openstack/releases,master,I828715f30695fac1036b982b180a6fdaec03bc43,Add openstack-tox-bashate job for scripts,MERGED,2020-01-13 17:42:42.000000000,2020-01-20 11:30:34.000000000,2020-01-20 11:30:34.000000000,"[{'_account_id': 308}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-13 17:42:42.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/da4076a42a6b1fd380244d220d3e270f048afcce', 'message': ""Add openstack-tox-bashate job for scripts\n\nWe have had a bashate target in tox.ini for quite awhile, but we haven't\nhad a Zuul job run it on changes. Manual fixes have been needed from\ntime to time when someone has decided to run the linting on their own.\n\nRather than needing periodic cleanup, let's just have this job run on\nany *.sh file changes.\n\nChange-Id: I828715f30695fac1036b982b180a6fdaec03bc43\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}]",0,702272,da4076a42a6b1fd380244d220d3e270f048afcce,8,4,1,11904,,,0,"Add openstack-tox-bashate job for scripts

We have had a bashate target in tox.ini for quite awhile, but we haven't
had a Zuul job run it on changes. Manual fixes have been needed from
time to time when someone has decided to run the linting on their own.

Rather than needing periodic cleanup, let's just have this job run on
any *.sh file changes.

Change-Id: I828715f30695fac1036b982b180a6fdaec03bc43
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/72/702272/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,da4076a42a6b1fd380244d220d3e270f048afcce,bashate, - openstack-tox-bashate: files: - ^.*\.sh$,,3,0
openstack%2Fnetworking-midonet~master~Ie95a528f4431d51cc551380d4d7066e4b6f299fa,openstack/networking-midonet,master,Ie95a528f4431d51cc551380d4d7066e4b6f299fa,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2020-01-06 12:16:14.000000000,2020-01-20 11:15:59.000000000,2020-01-20 11:11:59.000000000,"[{'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 8556}, {'_account_id': 13995}, {'_account_id': 15334}, {'_account_id': 19307}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-06 12:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/1cb1229b3b030059a37ff68244139d3e5c02685e', 'message': ""[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the Python 2.7 support in Ussuri cycle.\n\nThe networking-midonet project is ready with Python 3 and therefore it's okay\nto drop Python 2.7 support.\n\nThe complete discussion nad schedule can be found in\n\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nThe Ussuri community-wide goal can be found here:\n\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Ie95a528f4431d51cc551380d4d7066e4b6f299fa\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-01-06 12:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/c2e15634e0225b6c086d0e934056ac12ec3ee92c', 'message': ""[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the Python 2.7 support in Ussuri cycle.\n\nThe networking-midonet project is ready with Python 3 and therefore it's\nokay to drop Python 2.7 support. The only significant change we need to\nmake is to drop the centos7-based jobs since centos7 doesn't support\nPython 3. These were non-voting and have been for some time, so this is\nlikely the best thing to do right now.\n\nThe complete discussion nad schedule can be found in\n\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nThe Ussuri community-wide goal can be found here:\n\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Ie95a528f4431d51cc551380d4d7066e4b6f299fa\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-01-20 09:33:29.000000000', 'files': ['playbooks/grenade-ml2/run.yaml', '.zuul.yaml', 'releasenotes/notes/drop-python2-support-69426c4772d17f4b.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/662611547a37a73b148d7f293c2f2b4a234f2df5', 'message': ""[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the Python 2.7 support in Ussuri cycle.\n\nThe networking-midonet project is ready with Python 3 and therefore it's\nokay to drop Python 2.7 support. The only significant change we need to\nmake is to drop the centos7-based jobs since centos7 doesn't support\nPython 3. These were non-voting and have been for some time, so this is\nlikely the best thing to do right now.\n\nThe complete discussion nad schedule can be found in\n\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nThe Ussuri community-wide goal can be found here:\n\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: Ie95a528f4431d51cc551380d4d7066e4b6f299fa\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nCo-authored-by: Ghanshyam Mann <gmann@ghanshyammann.com>\n""}]",2,701210,662611547a37a73b148d7f293c2f2b4a234f2df5,19,8,3,15334,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the Python 2.7 support in Ussuri cycle.

The networking-midonet project is ready with Python 3 and therefore it's
okay to drop Python 2.7 support. The only significant change we need to
make is to drop the centos7-based jobs since centos7 doesn't support
Python 3. These were non-voting and have been for some time, so this is
likely the best thing to do right now.

The complete discussion nad schedule can be found in

- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

The Ussuri community-wide goal can be found here:

https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: Ie95a528f4431d51cc551380d4d7066e4b6f299fa
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Co-authored-by: Ghanshyam Mann <gmann@ghanshyammann.com>
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/10/701210/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,1cb1229b3b030059a37ff68244139d3e5c02685e,drop-py27-support,"envlist = docs,py37,pep8 minversion = 3.1ignore_basepython_conflict = Truebasepython = python3","envlist = docs,py27,py37,pep8 minversion = 2.0basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",7,25
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae,openstack/tripleo-heat-templates,stable/train,Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae,Don't disable compute cell in scale down tasks for additional cells,MERGED,2020-01-17 04:53:44.000000000,2020-01-20 11:10:03.000000000,2020-01-20 11:10:03.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-17 04:53:44.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/90ed42da142c876d88b1314ebdbdc99ffb84c660', 'message': ""Don't disable compute cell in scale down tasks for additional cells\n\nWhen we scale down a compute in an additional cell, disabling the compute\nservice fails in scale down tasks as the workflow of scale down a compute\nfrom an additional cell is [1]:\n\n- migrate off instances from the compute or delete them\n- remove the compute from the cell (nova-manage command)\n- scale down the cell stack\n\nUntil we have fully automated scale down of a compute from an additional\ncell, don't run disable of compute service as we have already removed it from\ncell in pre steps.\n\n[1] https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/deploy_cellv2_manage_cell.html#delete-a-compute-from-a-cell\n\nChange-Id: Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae\nCloses-Bug: #1859825\n(cherry picked from commit ee778fc245f787f721fad35abf1744f9c6f71906)\n""}]",0,703015,90ed42da142c876d88b1314ebdbdc99ffb84c660,14,8,1,17216,,,0,"Don't disable compute cell in scale down tasks for additional cells

When we scale down a compute in an additional cell, disabling the compute
service fails in scale down tasks as the workflow of scale down a compute
from an additional cell is [1]:

- migrate off instances from the compute or delete them
- remove the compute from the cell (nova-manage command)
- scale down the cell stack

Until we have fully automated scale down of a compute from an additional
cell, don't run disable of compute service as we have already removed it from
cell in pre steps.

[1] https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/deploy_cellv2_manage_cell.html#delete-a-compute-from-a-cell

Change-Id: Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae
Closes-Bug: #1859825
(cherry picked from commit ee778fc245f787f721fad35abf1744f9c6f71906)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/703015/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-compute-container-puppet.yaml'],1,90ed42da142c876d88b1314ebdbdc99ffb84c660,1859825-stable/train, - name: is additional Cell? set_fact: is_additional_cell: {get_param: NovaAdditionalCell} - not is_additional_cell|bool,,4,0
openstack%2Fhorizon~stable%2Fstein~I519e15afc975e6da2afb9c72a05448541572bd10,openstack/horizon,stable/stein,I519e15afc975e6da2afb9c72a05448541572bd10,Fix typo in publicize_image policy name,MERGED,2020-01-09 16:13:11.000000000,2020-01-20 10:53:26.000000000,2020-01-17 13:19:49.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-09 16:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cac749520590d55c84a94609e22fca46eb33dac5', 'message': 'WIP. Fix typo in publicize_image policy name\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: ###\n'}, {'number': 2, 'created': '2020-01-09 16:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d7e392a77f59ec8d14dc433b93ec017262d7b74a', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/rain because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n'}, {'number': 3, 'created': '2020-01-09 16:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1fdde52f0b46963703ca786b45d1efa66d0e1f6e', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/train because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n'}, {'number': 4, 'created': '2020-01-13 12:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9f276adfce0aa98fc66e318020e67d6e8706f601', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/train because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n'}, {'number': 5, 'created': '2020-01-14 00:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5e09f56c473fc6c7c48b69e212325ee46931916', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/train because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n'}, {'number': 6, 'created': '2020-01-15 10:23:17.000000000', 'files': ['openstack_dashboard/static/app/core/images/steps/edit-image/edit-image.controller.js', 'releasenotes/notes/publicize-image-policy-name-5d7fd5ecbdcfa893.yaml'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fe61f2358a6e16ea462630747180b83337eb5b55', 'message': 'Fix typo in publicize_image policy name\n\nThis patch is not cherry-picked from stable/train because if was fixed\nin a scope of a new feature implementation with\nhttps://review.opendev.org/#/c/602468/ commit.\n\nChange-Id: I519e15afc975e6da2afb9c72a05448541572bd10\nCloses-Bug: 1859041\n'}]",4,701762,fe61f2358a6e16ea462630747180b83337eb5b55,37,7,6,1736,,,0,"Fix typo in publicize_image policy name

This patch is not cherry-picked from stable/train because if was fixed
in a scope of a new feature implementation with
https://review.opendev.org/#/c/602468/ commit.

Change-Id: I519e15afc975e6da2afb9c72a05448541572bd10
Closes-Bug: 1859041
",git fetch https://review.opendev.org/openstack/horizon refs/changes/62/701762/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/app/core/images/steps/edit-image/edit-image.controller.js'],1,cac749520590d55c84a94609e22fca46eb33dac5,bug/1859041," ctrl.allowPublicizeImage = { rules: [['image', 'publicize_image']] };"," ctrl.allowPublicizeImage = { rules: [['image', 'image:publicize_image']] };",1,1
openstack%2Fmonasca-api~master~Ib0b966c0d7db993802b5372156c41b3ebdf1a77f,openstack/monasca-api,master,Ib0b966c0d7db993802b5372156c41b3ebdf1a77f,Upgrade Elkstack in new API,MERGED,2019-12-03 16:01:00.000000000,2020-01-20 10:52:55.000000000,2020-01-20 10:51:00.000000000,"[{'_account_id': 10311}, {'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 30221}]","[{'number': 1, 'created': '2019-12-03 16:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/92bf2b1203e88aab8cca3c3b5ec647751ffbbdf3', 'message': 'Upgrade Elkstack in new API\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 2, 'created': '2019-12-03 16:32:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/d9f011c613612b2b44bb4dceb96cd901f14f2e87', 'message': 'Upgrade Elkstack in new API\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 3, 'created': '2019-12-04 09:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/f2d357df29d764902693168791ab6a3b2d68b316', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 4, 'created': '2019-12-04 15:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/ec67312f6e1b94d72ee7d1ad1105af66a89505dd', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 5, 'created': '2019-12-05 12:20:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/de1467c4d26eadf12f7534063dd79c09de646eeb', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 6, 'created': '2019-12-05 12:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/2bdae6606a0b73bfd3b52e03b51d18655235e23c', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 7, 'created': '2019-12-05 13:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/c922c48427dda6676bbc882b34fe9511a33eaecb', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 8, 'created': '2019-12-06 10:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/f067f76545ce052f5410a2bced67426289904ea3', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 9, 'created': '2019-12-06 15:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/8b679e952821e3f977fef692756ec8df0f0a0b13', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 10, 'created': '2019-12-11 10:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/22e4d462266f7e14d3c293b07819c2f54c5f47bb', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 11, 'created': '2020-01-07 12:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/a2d12565707e34746f59a4a1189ba6101a14c2b7', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 12, 'created': '2020-01-07 14:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/52b04257d850b6dc15ef86f9045d1409c6765c33', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 13, 'created': '2020-01-13 16:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3a8ee009dbbb0d5d60ccc0599c1fb10b67317b7d', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}, {'number': 14, 'created': '2020-01-15 11:33:23.000000000', 'files': ['devstack/files/monasca-log-transformer/transformer.conf', 'devstack/files/monasca-agent/http_check.yaml', 'devstack/files/monasca-log-metrics/log-metrics.conf', 'devstack/lib/monasca-log.sh', 'devstack/files/monasca-agent/elastic.yaml', 'devstack/files/monasca-log-agent/agent.conf', 'devstack/files/monasca-log-persister/persister.conf', 'devstack/files/kibana/kibana.yml', 'releasenotes/notes/elasticsearch-cluster-upgrade-4b7bdc9c17e0169f.yaml', 'devstack/files/elasticsearch/elasticsearch.yml', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/ce0e62584f57e84b3d1c1abfa17b9b7d6c68ba8c', 'message': 'Upgrade Elkstack in new API\n\nThe commit contains upgrade of Elk components, default index pattern\ncreation in new API.\n\nStory: 2006376\nTask: 38125\n\nDepends-On: https://review.opendev.org/#/c/679781\n\nChange-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f\n'}]",8,697123,ce0e62584f57e84b3d1c1abfa17b9b7d6c68ba8c,80,6,14,30221,,,0,"Upgrade Elkstack in new API

The commit contains upgrade of Elk components, default index pattern
creation in new API.

Story: 2006376
Task: 38125

Depends-On: https://review.opendev.org/#/c/679781

Change-Id: Ib0b966c0d7db993802b5372156c41b3ebdf1a77f
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/23/697123/13 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/files/monasca-log-transformer/transformer.conf', 'devstack/files/monasca-agent/http_check.yaml', 'devstack/files/monasca-log-metrics/log-metrics.conf', 'devstack/lib/monasca-log.sh', 'devstack/files/monasca-agent/elastic.yaml', 'devstack/files/monasca-log-agent/agent.conf', 'devstack/files/kibana/kibana.yml', 'devstack/files/monasca-log-persister/persister.conf', 'devstack/files/elasticsearch/elasticsearch.yml', 'devstack/settings']",10,92bf2b1203e88aab8cca3c3b5ec647751ffbbdf3,merge-api-elkstack,KIBANA_VERSION=${KIBANA_VERSION:-7.3.0-linux-x86_64} LOGSTASH_VERSION=${LOGSTASH_VERSION:-7.3.0} ELASTICSEARCH_VERSION=${ELASTICSEARCH_VERSION:-7.3.0} LOGSTASH_OUTPUT_MONASCA_VERSION=${LOGSTASH_OUTPUT_MONASCA_VERSION:-2.0.0} #Settings needed for Elasticsearch LIMIT_NOFILE=${LIMIT_NOFILE:-65535} VM_MAX_MAP_COUNT=${VM_MAX_MAP_COUNT:-262144},KIBANA_VERSION=${KIBANA_VERSION:-4.6.3-linux-x86_64} LOGSTASH_VERSION=${LOGSTASH_VERSION:-2.4.1} ELASTICSEARCH_VERSION=${ELASTICSEARCH_VERSION:-2.4.6} LOGSTASH_OUTPUT_MONASCA_VERSION=${LOGSTASH_OUTPUT_MONASCA_VERSION:-1.0.4}MONASCA_KIBANA_PLUGIN_REPO=${MONASCA_KIBANA_PLUGIN_REPO:-${GIT_BASE}/openstack/monasca-kibana-plugin.git} MONASCA_KIBANA_PLUGIN_BRANCH=${MONASCA_KIBANA_PLUGIN_BRANCH:-master} MONASCA_KIBANA_PLUGIN_DIR=${DEST}/monasca-kibana-plugin ,250,481
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I402db858526def9dfd33f954f1ecd885c01f4367,openstack/tripleo-heat-templates,stable/train,I402db858526def9dfd33f954f1ecd885c01f4367,Modify import_role to include_role for boot params service,MERGED,2020-01-14 04:59:49.000000000,2020-01-20 10:29:34.000000000,2020-01-20 10:29:34.000000000,"[{'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-14 04:59:49.000000000', 'files': ['deployment/kernel/kernel-boot-params-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dada512485fc5472eededc8407db657a0ceaeb3c', 'message': 'Modify import_role to include_role for boot params service\n\nUsing static import_role, make the vars defined under the\nimport_role task to be available for the whole PLAY itself,\nwhich is causing the role-specific parameter to be available\nin other roles. Move to dynamic include_role, which will\ndefine these variables only for the included ansible role.\nCloses-Bug: #1859129\n\nChange-Id: I402db858526def9dfd33f954f1ecd885c01f4367\n(cherry picked from commit 8d6edac63708d0f40e7f7db75f86a2013efbbc39)\n'}]",0,702344,dada512485fc5472eededc8407db657a0ceaeb3c,12,5,1,18575,,,0,"Modify import_role to include_role for boot params service

Using static import_role, make the vars defined under the
import_role task to be available for the whole PLAY itself,
which is causing the role-specific parameter to be available
in other roles. Move to dynamic include_role, which will
define these variables only for the included ansible role.
Closes-Bug: #1859129

Change-Id: I402db858526def9dfd33f954f1ecd885c01f4367
(cherry picked from commit 8d6edac63708d0f40e7f7db75f86a2013efbbc39)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/702344/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/kernel/kernel-boot-params-baremetal-ansible.yaml'],1,dada512485fc5472eededc8407db657a0ceaeb3c,bug/1859129/import_role_issue-stable/train, include_role: include_role:, import_role: import_role:,2,2
openstack%2Fmetalsmith~stable%2Ftrain~I4460755ee66b4aa0b8a651b6bd142c769d669ee2,openstack/metalsmith,stable/train,I4460755ee66b4aa0b8a651b6bd142c769d669ee2,Stop requiring root size for whole disk images,MERGED,2019-11-13 07:59:13.000000000,2020-01-20 10:27:44.000000000,2020-01-20 10:25:45.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-11-13 07:59:13.000000000', 'files': ['releasenotes/notes/whole-disk-root-gb-bd8ee3600de9ec8d.yaml', 'metalsmith/_utils.py', 'metalsmith/test/test_sources.py', 'metalsmith/_provisioner.py', 'playbooks/integration/run.yaml', 'metalsmith/sources.py'], 'web_link': 'https://opendev.org/openstack/metalsmith/commit/0afed7462dfd962ce7061b662ace72132b475c4d', 'message': 'Stop requiring root size for whole disk images\n\nThis requirement has been fixed in newer versions of ironic.\n\nChange-Id: I4460755ee66b4aa0b8a651b6bd142c769d669ee2\n(cherry picked from commit 2d801e2526f4d1dd9968a4a3e4ab6a8603e1416d)\n'}]",0,693999,0afed7462dfd962ce7061b662ace72132b475c4d,7,3,1,10239,,,0,"Stop requiring root size for whole disk images

This requirement has been fixed in newer versions of ironic.

Change-Id: I4460755ee66b4aa0b8a651b6bd142c769d669ee2
(cherry picked from commit 2d801e2526f4d1dd9968a4a3e4ab6a8603e1416d)
",git fetch https://review.opendev.org/openstack/metalsmith refs/changes/99/693999/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/whole-disk-root-gb-bd8ee3600de9ec8d.yaml', 'metalsmith/_utils.py', 'metalsmith/test/test_sources.py', 'metalsmith/_provisioner.py', 'playbooks/integration/run.yaml', 'metalsmith/sources.py']",6,0afed7462dfd962ce7061b662ace72132b475c4d,root-size-stable/train," def _validate(self, connection, root_size_gb): def _validate(self, connection, root_size_gb): if (root_size_gb is None and any(getattr(self._image_obj, x, None) is not None for x in ('kernel_id', 'ramdisk_id'))): raise exceptions.UnknownRootDiskSize( 'Partition images require root partition size') def _node_updates(self, connection): def _validate(self, connection, root_size_gb): def _validate(self, connection, root_size_gb): super(HttpPartitionImage, self)._validate(connection, root_size_gb) if root_size_gb is None: raise exceptions.UnknownRootDiskSize( 'Partition images require root partition size') def _validate(self, connection, root_size_gb): super(FilePartitionImage, self)._validate(connection, root_size_gb) if root_size_gb is None: raise exceptions.UnknownRootDiskSize( 'Partition images require root partition size') "," def _validate(self, connection): def _validate(self, connection): def _node_updates(self, connection): self._validate(connection) def _validate(self, connection): self._validate(connection)",89,11
openstack%2Fopenstack-ansible~master~I81211e8c1d767ce55fc41fe37babe52d19de36e0,openstack/openstack-ansible,master,I81211e8c1d767ce55fc41fe37babe52d19de36e0,Remove log compression before upload,MERGED,2020-01-15 15:47:46.000000000,2020-01-20 10:26:50.000000000,2020-01-18 01:44:59.000000000,"[{'_account_id': 22348}, {'_account_id': 25591}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-15 15:47:46.000000000', 'files': ['scripts/log-collect.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/75879a02d3dfb2643412343bc69e1a210ec6ba10', 'message': 'Remove log compression before upload\n\nFrom #openstack-infra:\nfungi> jrosser: there was a necessary change in handling of\ncompressed log files, jobs should not compress logs on their\nown now if you want them to be viewable in a browser (this\nwas to solve a problem where tarballs were getting silently\ndecompressed on download without changing their filenames to\ndrop the .gz extension)\n\nChange-Id: I81211e8c1d767ce55fc41fe37babe52d19de36e0\n'}]",0,702686,75879a02d3dfb2643412343bc69e1a210ec6ba10,19,4,1,25023,,,0,"Remove log compression before upload

From #openstack-infra:
fungi> jrosser: there was a necessary change in handling of
compressed log files, jobs should not compress logs on their
own now if you want them to be viewable in a browser (this
was to solve a problem where tarballs were getting silently
decompressed on download without changing their filenames to
drop the .gz extension)

Change-Id: I81211e8c1d767ce55fc41fe37babe52d19de36e0
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/702686/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/log-collect.sh'],1,75879a02d3dfb2643412343bc69e1a210ec6ba10,,,"function compress_files { # We use 'command' to ensure that we're not executing with an alias. GZIP_CMD=""command gzip --force --best"" find_files |\ while read filename; do \ ${GZIP_CMD} ${filename} || echo ""WARNING: Could not gzip ${filename}""; \ done } # Compress the files gathered so that they do not take up too much space. compress_files ",0,12
openstack%2Ftripleo-upgrade~master~I295f927b2e4504d0ba2bbd952021f5ef70476027,openstack/tripleo-upgrade,master,I295f927b2e4504d0ba2bbd952021f5ef70476027,Adapt overcloud upgrade workflow to Train.,MERGED,2019-12-16 17:49:21.000000000,2020-01-20 10:09:51.000000000,2020-01-17 15:53:47.000000000,"[{'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-12-16 17:49:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/a334fce36dec5a135847087d784145994bf4f066', 'message': 'WIP: Adapt overcloud upgrade workflow to Train.\n\nChange-Id: I295f927b2e4504d0ba2bbd952021f5ef70476027\n'}, {'number': 2, 'created': '2019-12-17 15:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9b03dbe751aa25bd2cf2f1b64ae913278a57fe36', 'message': 'Adapt overcloud upgrade workflow to Train.\n\nThe upgrade from Stein to Train does not include any\nOS upgrade inbetween, therefore the workflow used can\nbe as it used to be up to Queens to Rocky upgade. This\nworkflow consists on upgrading role by role, always\nstarting by the Controller.\n\nChange-Id: I295f927b2e4504d0ba2bbd952021f5ef70476027\n'}, {'number': 3, 'created': '2019-12-19 10:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/5b68646d7701474a86a5c122af366b83bff57589', 'message': 'Adapt overcloud upgrade workflow to Train.\n\nThe upgrade from Stein to Train does not include any\nOS upgrade inbetween, therefore the workflow used can\nbe as it used to be up to Queens to Rocky upgade. This\nworkflow consists on upgrading role by role, always\nstarting by the Controller.\n\nChange-Id: I295f927b2e4504d0ba2bbd952021f5ef70476027\n'}, {'number': 4, 'created': '2020-01-09 15:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/ea78fc54ef7ae21281a47fc9614dc78664f1aa09', 'message': 'Adapt overcloud upgrade workflow to Train.\n\nThe upgrade from Stein to Train does not include any\nOS upgrade inbetween, therefore the workflow used can\nbe as it used to be up to Queens to Rocky upgade. This\nworkflow consists on upgrading role by role, always\nstarting by the Controller.\n\nChange-Id: I295f927b2e4504d0ba2bbd952021f5ef70476027\n'}, {'number': 5, 'created': '2020-01-15 09:50:26.000000000', 'files': ['tasks/upgrade/create-overcloud-upgrade-hosts-scripts.yaml', 'tasks/upgrade/overcloud_upgrade_hosts.yaml', 'templates/overcloud_upgrade_run.sh.j2', 'templates/overcloud_upgrade_prepare.sh.j2', 'tasks/upgrade/overcloud_upgrade_roles.yaml', 'tasks/upgrade/create-overcloud-upgrade-scripts.yaml', 'tasks/upgrade/overcloud_upgrade_run.yml', 'tasks/upgrade/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/601b0b4a0821313ada03e001e792ae21709b255a', 'message': 'Adapt overcloud upgrade workflow to Train.\n\nThe upgrade from Stein to Train does not include any\nOS upgrade inbetween, therefore the workflow used can\nbe as it used to be up to Queens to Rocky upgade. This\nworkflow consists on upgrading role by role, always\nstarting by the Controller.\n\nChange-Id: I295f927b2e4504d0ba2bbd952021f5ef70476027\n'}]",0,699256,601b0b4a0821313ada03e001e792ae21709b255a,23,5,5,26343,,,0,"Adapt overcloud upgrade workflow to Train.

The upgrade from Stein to Train does not include any
OS upgrade inbetween, therefore the workflow used can
be as it used to be up to Queens to Rocky upgade. This
workflow consists on upgrading role by role, always
starting by the Controller.

Change-Id: I295f927b2e4504d0ba2bbd952021f5ef70476027
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/56/699256/5 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/upgrade/create-overcloud-upgrade-hosts-scripts.yaml', 'templates/overcloud_upgrade_run.sh.j2', 'tasks/upgrade/create-overcloud-upgrade-scripts.yaml', 'tasks/upgrade/overcloud_upgrade_run.yml', 'tasks/upgrade/main.yml']",5,a334fce36dec5a135847087d784145994bf4f066,," - name: apply pre overcloud upgrade workarounds shell: | set -o pipefail bash {{ working_dir }}/pre_overcloud_upgrade_workarounds.sh 2>&1 {{ timestamper_cmd }} > pre_overcloud_upgrade_workarounds.log args: chdir: ""{{ working_dir }}"" when: upgrade_workarounds tags: overcloud_upgrade_run - name: launch workload shell: | set -o pipefail bash {{ workload_launch_script }} 2>&1 {{ timestamper_cmd }} > workload_launch.log args: chdir: ""{{ working_dir }}"" when: workload_launch|bool - import_tasks: overcloud_upgrade_run.yml tags: overcloud_upgrade_run - name: apply post overcloud upgrade workarounds shell: | set -o pipefail bash {{ working_dir }}/post_overcloud_upgrade_workarounds.sh 2>&1 {{ timestamper_cmd }} > post_overcloud_upgrade_workarounds.log args: chdir: ""{{ working_dir }}"" when: upgrade_workarounds tags: overcloud_upgrade_run"," ######## OS upgrade + Overcloud node upgrade run ####### - include_tasks: overcloud_upgrade_roles.yaml loop: ""{{ oc_roles }}"" loop_control: loop_var: role tags: - always",48,59
openstack%2Fkolla~stable%2Ftrain~I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,openstack/kolla,stable/train,I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,config: make kolla work with oslo.config 7.0.0+,MERGED,2020-01-17 13:13:05.000000000,2020-01-20 09:32:09.000000000,2020-01-20 09:30:44.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 13:13:05.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9adfb291184ec30a0aeaf2f4b792735e02980b00', 'message': ""config: make kolla work with oslo.config 7.0.0+\n\nFrom oslo.config 7.0.0 release notes:\n\n> Positional options are now required by default, to match argparses\n> default behavior. To revert this behavior (and maintain optional\n> positional arguments), you need to explicitly specify positional=True,\n> required=False as part of the options definition.\n\nSo let's follow.\n\nChange-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5\n(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)\n""}]",0,703071,9adfb291184ec30a0aeaf2f4b792735e02980b00,13,4,1,28374,,,0,"config: make kolla work with oslo.config 7.0.0+

From oslo.config 7.0.0 release notes:

> Positional options are now required by default, to match argparses
> default behavior. To revert this behavior (and maintain optional
> positional arguments), you need to explicitly specify positional=True,
> required=False as part of the options definition.

So let's follow.

Change-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5
(cherry picked from commit aaa472bfa257aea53abcb3642ad4beeaed1b99a8)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/71/703071/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,9adfb291184ec30a0aeaf2f4b792735e02980b00,," cfg.MultiOpt('regex', types.String(), positional=True, required=False,"," cfg.MultiOpt('regex', types.String(), positional=True,",1,1
openstack%2Fironic-ui~stable%2Frocky~I9a310446743cfe6bca5480455b91a7cd74da8785,openstack/ironic-ui,stable/rocky,I9a310446743cfe6bca5480455b91a7cd74da8785,Fix horizon dependency,MERGED,2020-01-09 08:41:46.000000000,2020-01-20 09:16:00.000000000,2020-01-20 09:13:13.000000000,"[{'_account_id': 841}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-09 08:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/e4f840c454717752ad3a960d75f40b4db4bb71a6', 'message': ""Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to uper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don't know why it works for stable/train\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop.\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit 50475021dbe9a643043cdb39f57c01aede008dbb)\n""}, {'number': 2, 'created': '2020-01-09 11:58:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/f7be6873b84303dabe1890d8bbe77c8c14986ad3', 'message': ""Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to uper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don't know why it works for stable/train\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop.\n\nsphinx entry in test-requirements.txt did not match global-requirements.\nThis commit updates it to match the current global-requirements.\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit 864c78b30cb740ac4e2cd0eb42e846215c64fc18)\n(cherry picked from commit 9069658480a6ccd58f0d462033c86ece366820a6)\n""}, {'number': 3, 'created': '2020-01-18 17:22:23.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/ca94a7661ef76f752e533e386ba929bb2a94b539', 'message': 'Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to upper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don\'t know why it works for stable/train\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop [1].\n\nThe way to specify upper-constraints.txt is also update to follow the\nconvention used widely in the OpenStack community. The contraints file is\nnow specified in ""deps"" section. This allows us to use the lower-constraints\nfile correctly. Previously upper-constraints.txt was actually used in the\nlower-constraints job unexpectedly.\n\nsphinx entry in test-requirements.txt did not match global-requirements.\nThis commit updates it to match the current global-requirements.\n\n[1] https://review.opendev.org/#/c/700845/\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit efa4927bb7baeb918fad3734b21b0223e0958404)\n(cherry picked from commit 5c593fd34a149c62e4153a1456bb5bc1ae366ea7)\n'}]",1,701687,ca94a7661ef76f752e533e386ba929bb2a94b539,18,4,3,841,,,0,"Fix horizon dependency

This commit moves horizon to requirements.txt.

horizon was added to upper-constraints in stable branches recently,
so installing from the tarball no longer works. upper-constraints
in stable branches picks up the right version of horizon, so there
is no need for the upper bound of the horizon version.

In addition, the link of the horizon tarball was not updated after
the stable branch was created. I don't know why it works for stable/train
but I believe this commit mitigates the situation as the upper-constraints
file in the requirements repo picks up the right version of horizon.

This commit is proposed directly as the similar change in the master
branch happened as part of Django 1.11 drop [1].

The way to specify upper-constraints.txt is also update to follow the
convention used widely in the OpenStack community. The contraints file is
now specified in ""deps"" section. This allows us to use the lower-constraints
file correctly. Previously upper-constraints.txt was actually used in the
lower-constraints job unexpectedly.

sphinx entry in test-requirements.txt did not match global-requirements.
This commit updates it to match the current global-requirements.

[1] https://review.opendev.org/#/c/700845/

Change-Id: I9a310446743cfe6bca5480455b91a7cd74da8785
(cherry picked from commit efa4927bb7baeb918fad3734b21b0223e0958404)
(cherry picked from commit 5c593fd34a149c62e4153a1456bb5bc1ae366ea7)
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/87/701687/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,e4f840c454717752ad3a960d75f40b4db4bb71a6,requirements-fix,horizon==14.0.0,,2,2
openstack%2Fnetworking-sfc~master~I6fe5748a88de4d8ef49e9bff60a0a85a539e6a51,openstack/networking-sfc,master,I6fe5748a88de4d8ef49e9bff60a0a85a539e6a51,Stop testing Python 2,ABANDONED,2019-11-20 00:44:33.000000000,2020-01-20 08:42:48.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-20 00:44:33.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/5f57f7923b06f7dfa461f6780a13e38cd2afeb8a', 'message': 'Stop testing Python 2\n\nChange-Id: I6fe5748a88de4d8ef49e9bff60a0a85a539e6a51\n'}]",0,695120,5f57f7923b06f7dfa461f6780a13e38cd2afeb8a,4,2,1,24061,,,0,"Stop testing Python 2

Change-Id: I6fe5748a88de4d8ef49e9bff60a0a85a539e6a51
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/20/695120/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,5f57f7923b06f7dfa461f6780a13e38cd2afeb8a,,"envlist = py37,pep8","envlist = py27,py37,pep8",1,3
openstack%2Fmistral~master~I8db642afbb637ac21dcd6526dd89039c6840d169,openstack/mistral,master,I8db642afbb637ac21dcd6526dd89039c6840d169,Fix typo,MERGED,2020-01-19 12:14:09.000000000,2020-01-20 08:35:57.000000000,2020-01-20 08:34:22.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-19 12:14:09.000000000', 'files': ['mistral/actions/openstack/mapping.json'], 'web_link': 'https://opendev.org/openstack/mistral/commit/7f92cc8f5b704b5af8d430e5e7372756bbbc4d87', 'message': 'Fix typo\n\nChange-Id: I8db642afbb637ac21dcd6526dd89039c6840d169\n'}]",0,703289,7f92cc8f5b704b5af8d430e5e7372756bbbc4d87,7,2,1,19134,,,0,"Fix typo

Change-Id: I8db642afbb637ac21dcd6526dd89039c6840d169
",git fetch https://review.opendev.org/openstack/mistral refs/changes/89/703289/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/actions/openstack/mapping.json'],1,7f92cc8f5b704b5af8d430e5e7372756bbbc4d87,gnocchi," ""archive_policy_rule_list"": ""archive_policy_rule.list"","," ""archive_polociy_rule_list"": ""archive_policy_rule.list"",",1,1
openstack%2Ftripleo-ansible~stable%2Ftrain~I0ce554651916f2b942dc0fd9f647d5a348042203,openstack/tripleo-ansible,stable/train,I0ce554651916f2b942dc0fd9f647d5a348042203,Allow comments in variable files to be rendered in docs,MERGED,2020-01-20 01:38:19.000000000,2020-01-20 08:32:15.000000000,2020-01-20 08:30:13.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-20 01:38:19.000000000', 'files': ['doc/source/_exts/ansible-autodoc.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/07d2548395ac6f82f19aa89f58c95fa47b847dd3', 'message': 'Allow comments in variable files to be rendered in docs\n\nThis change will allow all comments in our variable files to be rendered\nnormally within our documentation. This will allow folks reading our\ndocumentation to benifit from information we may put in the various\nfiles.\n\nChange-Id: I0ce554651916f2b942dc0fd9f647d5a348042203\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n(cherry picked from commit d5a26bd7e7be99f7757b3f8ffbd66b437dad9344)\n'}]",0,703316,07d2548395ac6f82f19aa89f58c95fa47b847dd3,7,3,1,3153,,,0,"Allow comments in variable files to be rendered in docs

This change will allow all comments in our variable files to be rendered
normally within our documentation. This will allow folks reading our
documentation to benifit from information we may put in the various
files.

Change-Id: I0ce554651916f2b942dc0fd9f647d5a348042203
Signed-off-by: Kevin Carter <kecarter@redhat.com>
(cherry picked from commit d5a26bd7e7be99f7757b3f8ffbd66b437dad9344)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/16/703316/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/_exts/ansible-autodoc.py'],1,07d2548395ac6f82f19aa89f58c95fa47b847dd3,,"from ruamel.yaml import YAML as RYAML try: import io StringIO = io.StringIO except ImportError: import StringIO class DocYaml(RYAML): def _license_filter(self, data): """"""This will filter out our boilerplate license heading in return data. The filter is used to allow documentation we're creating in variable files to be rendered more beautifully. """""" lines = list() mark = True for line in data.splitlines(): if '# Copyright' in line: mark = False if mark: lines.append(line) if '# under the License' in line: mark = True return '\n'.join(lines) def dump(self, data, stream=None, **kw): if not stream: stream = StringIO() try: RYAML.dump(self, data, stream, **kw) return self._license_filter(stream.getvalue().strip()) finally: stream.close() DOCYAML = DocYaml() DOCYAML.default_flow_style = False docs = DOCYAML.load(module.DOCUMENTATION) examples = DOCYAML.load(module.EXAMPLES) return_examples.append(DOCYAML.dump([example])) text=DOCYAML.dump(data) role_defaults = DOCYAML.load(f.read()) vars_values = DOCYAML.load(f.read()) molecule_conf = DOCYAML.load(f.read()) molecule_playbook = DOCYAML.load(f.read())"," docs = yaml.safe_load(module.DOCUMENTATION) examples = yaml.safe_load(module.EXAMPLES) return_examples.append( yaml.safe_dump([example], default_flow_style=False) ) text=yaml.safe_dump( data, default_flow_style=False ) role_defaults = yaml.safe_load(f.read()) vars_values = yaml.safe_load(f.read()) molecule_conf = yaml.safe_load(f.read()) molecule_playbook = yaml.safe_load(f.read())",47,13
openstack%2Fneutron~master~I472d2f07f27e9162089d08d416fb02ae8b5544e7,openstack/neutron,master,I472d2f07f27e9162089d08d416fb02ae8b5544e7,Move tripleo standalone job to ostempest,MERGED,2019-12-12 15:19:26.000000000,2020-01-20 08:03:12.000000000,2020-01-20 07:59:50.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 12393}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-12 15:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f5f050c703d9563fc4a8134cdabe762218f804d', 'message': 'Move tripleo standalone job to ostempest\n\nSince validate-tempest is deprecated in favor of ostempest\nunified ansible role. All the tripleo jobs are already moved\nto that, having a unified job will help to get consistent\nresult and avoid issues.\n\nChange-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 2, 'created': '2019-12-13 17:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c6ae09df130c6bdfb1c68d9e38d03856ecd32b6', 'message': 'Move tripleo standalone job to ostempest\n\nSince validate-tempest is deprecated in favor of ostempest\nunified ansible role. All the tripleo jobs are already moved\nto that, having a unified job will help to get consistent\nresult and avoid issues.\n\nDepends-On: https://review.opendev.org/#/c/698589/\n\nChange-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 3, 'created': '2019-12-16 05:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba31d123b5e06abc71de9c102f99a8b5fa58c4f1', 'message': 'Move tripleo standalone job to ostempest\n\nSince validate-tempest is deprecated in favor of ostempest\nunified ansible role. All the tripleo jobs are already moved\nto that, having a unified job will help to get consistent\nresult and avoid issues.\n\nDepends-On: https://review.opendev.org/#/c/698589/\n\nChange-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 4, 'created': '2019-12-16 11:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/baac14b556cb07c247afc6ec958f4a651805da2e', 'message': 'Move tripleo standalone job to ostempest\n\nSince validate-tempest is deprecated in favor of ostempest\nunified ansible role. All the tripleo jobs are already moved\nto that, having a unified job will help to get consistent\nresult and avoid issues.\n\nDepends-On: https://review.opendev.org/#/c/698589/\n\nChange-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 5, 'created': '2019-12-17 12:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11a2b022332da0b7a1ba6ecabbaf3f517512dc89', 'message': 'Move tripleo standalone job to ostempest\n\nSince validate-tempest is deprecated in favor of ostempest\nunified ansible role. All the tripleo jobs are already moved\nto that, having a unified job will help to get consistent\nresult and avoid issues.\n\nDepends-On: https://review.opendev.org/#/c/698589/\n\nChange-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 6, 'created': '2019-12-19 06:51:03.000000000', 'files': ['zuul.d/tripleo.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/52787dd4a40d2dbc04f4df6e8683376a8aed74c1', 'message': 'Move tripleo standalone job to ostempest\n\nSince validate-tempest is deprecated in favor of ostempest\nunified ansible role. All the tripleo jobs are already moved\nto that, having a unified job will help to get consistent\nresult and avoid issues.\n\nDepends-On: https://review.opendev.org/#/c/698589/\n\nChange-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}]",2,698737,52787dd4a40d2dbc04f4df6e8683376a8aed74c1,22,6,6,12393,,,0,"Move tripleo standalone job to ostempest

Since validate-tempest is deprecated in favor of ostempest
unified ansible role. All the tripleo jobs are already moved
to that, having a unified job will help to get consistent
result and avoid issues.

Depends-On: https://review.opendev.org/#/c/698589/

Change-Id: I472d2f07f27e9162089d08d416fb02ae8b5544e7
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/698737/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/tripleo.yaml'],1,0f5f050c703d9563fc4a8134cdabe762218f804d,triplestandalone, run_tempest: false tempest_format: container tempest_run_concurrency: 2 tempest_tempest_conf_overrides: auth.use_dynamic_credentials: true use_os_tempest: true,,6,0
openstack%2Ftripleo-common~master~I26bb26411f22c34ead1b2bfb2a616ddf65f69489,openstack/tripleo-common,master,I26bb26411f22c34ead1b2bfb2a616ddf65f69489,Derive network config fails,MERGED,2019-12-12 05:45:21.000000000,2020-01-20 07:23:05.000000000,2020-01-15 04:28:38.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 18575}, {'_account_id': 18904}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-12 05:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bf6339c394e0ca46290ae221f602bf3003eea0c7', 'message': 'Derive network config fails\n\nDerive network config fails for a role when using\nany interface routes with list_concat_unique in network\nconfiguration and no user inputs provided.\n\nChange-Id: I26bb26411f22c34ead1b2bfb2a616ddf65f69489\nCloses-Bug: #1856124\n'}, {'number': 2, 'created': '2019-12-12 05:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/874f0de1e2dadd3381c754e84f205837ea67569b', 'message': 'Derive network config fails\n\nDerive network config fails for a role when using\nany interface routes with list_concat_unique in network\nconfiguration and no user inputs provided.\n\nChange-Id: I26bb26411f22c34ead1b2bfb2a616ddf65f69489\nCloses-Bug: #1856124\n'}, {'number': 3, 'created': '2020-01-02 10:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/23720b363b8db4a9b72162d3f899ab221251fbfd', 'message': 'Derive network config fails\n\nDerive network config fails for a role when using\nany interface routes with list_concat_unique in network\nconfiguration and no user inputs provided.\n\nChange-Id: I26bb26411f22c34ead1b2bfb2a616ddf65f69489\nCloses-Bug: #1856124\n'}, {'number': 4, 'created': '2020-01-08 21:12:54.000000000', 'files': ['tripleo_common/tests/actions/test_parameters.py', 'tripleo_common/actions/parameters.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/81e823c6222b580ca78f4cfa92008e08b9926e1e', 'message': 'Derive network config fails\n\nDerive network config fails for a role when using\nany interface routes with list_concat_unique in network\nconfiguration and no user inputs provided.\n\nChange-Id: I26bb26411f22c34ead1b2bfb2a616ddf65f69489\nCloses-Bug: #1856124\n'}]",4,698623,81e823c6222b580ca78f4cfa92008e08b9926e1e,25,8,4,22865,,,0,"Derive network config fails

Derive network config fails for a role when using
any interface routes with list_concat_unique in network
configuration and no user inputs provided.

Change-Id: I26bb26411f22c34ead1b2bfb2a616ddf65f69489
Closes-Bug: #1856124
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/23/698623/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/actions/parameters.py'],1,bf6339c394e0ca46290ae221f602bf3003eea0c7,derive-network-config-issue," # Default temporary value is used when no user input for any # interface routes for all the roles to find network config. routes = ['TenantInterfaceRoutes', 'InternalApiInterfaceRoutes', 'StorageInterfaceRoutes', 'StorageMgmtInterfaceRoutes'] for rt in routes: if rt not in processed_data['environment']['parameter_defaults']: processed_data['environment']['parameter_defaults'][rt] = [[]] ",,8,0
openstack%2Ftripleo-common~master~I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,openstack/tripleo-common,master,I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3,Derive new nova compute parameters,MERGED,2020-01-07 18:48:07.000000000,2020-01-20 07:21:22.000000000,2020-01-16 23:07:30.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-07 18:48:07.000000000', 'files': ['workbooks/derive_params_formulas.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/95138e9d4e8ee012616fcb7ad89be0eef1632960', 'message': 'Derive new nova compute parameters\n\nDerive NovaComputeCpuDedicatedSet and NovaComputeCpuSharedSet\nparameters based on host introspection and remove the deriving\nNovaVcpuPinSet parameter.\n\nChange-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3\nCloses-Bug: #1858678\n'}]",0,701421,95138e9d4e8ee012616fcb7ad89be0eef1632960,15,8,1,22865,,,0,"Derive new nova compute parameters

Derive NovaComputeCpuDedicatedSet and NovaComputeCpuSharedSet
parameters based on host introspection and remove the deriving
NovaVcpuPinSet parameter.

Change-Id: I6bd73fde6f1d78ceb89eb5cd04ac06d1b95263a3
Closes-Bug: #1858678
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/21/701421/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/derive_params_formulas.yaml'],1,95138e9d4e8ee012616fcb7ad89be0eef1632960,derive-nova-conf-params," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaComputeCpuDedicatedSet' => $.get('nova_cpus', ''), 'NovaComputeCpuSharedSet' => $.get('host_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>"," host_parameters: <% dict(concat($.role_name, 'Parameters') => dict('NovaVcpuPinSet' => $.get('nova_cpus', ''), 'NovaReservedHostMemory' => $.get('host_mem', ''), 'KernelArgs' => $.get('kernel_args', ''), 'IsolCpusList' => $.get('isol_cpus', ''))) %>",1,1
openstack%2Fansible-collections-openstack~master~Icf988005258b260b51e8de7e70b344275948b40b,openstack/ansible-collections-openstack,master,Icf988005258b260b51e8de7e70b344275948b40b,Make collection tar file path version independent,MERGED,2020-01-19 21:06:47.000000000,2020-01-20 07:04:55.000000000,2020-01-20 07:04:55.000000000,"[{'_account_id': 2}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 10239}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2020-01-19 21:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0aa8d05e3f16b8a631105b19bc9f1c6657082bd2', 'message': 'Make colleciton tar patch version independent\n\nChange-Id: Icf988005258b260b51e8de7e70b344275948b40b\n'}, {'number': 2, 'created': '2020-01-19 21:19:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/57b76835c905d33d4efe030e162fdf2321d91fda', 'message': 'Make collection tar file path version independent\n\n\nFind collection TAR file by ""ls"".\nChange-Id: Icf988005258b260b51e8de7e70b344275948b40b\n'}]",0,703306,57b76835c905d33d4efe030e162fdf2321d91fda,9,7,2,10969,,,0,"Make collection tar file path version independent


Find collection TAR file by ""ls"".
Change-Id: Icf988005258b260b51e8de7e70b344275948b40b
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/06/703306/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0aa8d05e3f16b8a631105b19bc9f1c6657082bd2,," /bin/bash -c ""ansible-galaxy collection install $(ls {toxinidir}/build_artifact/openstack-cloud-*) --force -p {toxinidir}""", ansible-galaxy collection install {toxinidir}/build_artifact/openstack-cloud-1.0.0.tar.gz --force -p {toxinidir},1,1
openstack%2Foctavia-dashboard~stable%2Fstein~I4a479513b79388ec172b134e3762a3eeb41c8f1c,openstack/octavia-dashboard,stable/stein,I4a479513b79388ec172b134e3762a3eeb41c8f1c,Imported Translations from Zanata,MERGED,2019-12-12 10:16:21.000000000,2020-01-20 06:45:20.000000000,2020-01-20 06:42:32.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-12 10:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/c42d50f943b8752a48b701fa78af8f2970a4e20f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4a479513b79388ec172b134e3762a3eeb41c8f1c\n'}, {'number': 2, 'created': '2020-01-16 19:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/73d4a74b1deca9ac0b6ac1ce5a522cf231398730', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4a479513b79388ec172b134e3762a3eeb41c8f1c\n'}, {'number': 3, 'created': '2020-01-18 08:02:11.000000000', 'files': ['octavia_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/433de456cd8f6627e4c8b78914c982ebe0a1c85a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4a479513b79388ec172b134e3762a3eeb41c8f1c\n'}]",0,698679,433de456cd8f6627e4c8b78914c982ebe0a1c85a,24,6,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4a479513b79388ec172b134e3762a3eeb41c8f1c
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/79/698679/2 && git format-patch -1 --stdout FETCH_HEAD,['octavia_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'],1,c42d50f943b8752a48b701fa78af8f2970a4e20f,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-05-26 08:41+0000\n""""PO-Revision-Date: 2019-12-11 12:50+0000\n""msgid ""Flavor Description"" msgstr ""Flavour Description"" msgid ""Flavor ID"" msgstr ""Flavour ID"" msgid ""Unable to create flavor profile."" msgstr ""Unable to create flavour profile."" msgid ""Unable to create flavor."" msgstr ""Unable to create flavour."" msgid ""Unable to delete flavor profile."" msgstr ""Unable to delete flavour profile."" msgid ""Unable to delete flavor."" msgstr ""Unable to delete flavour."" msgid ""Unable to retrieve flavor profile."" msgstr ""Unable to retrieve flavour profile."" msgid ""Unable to retrieve flavor profiles."" msgstr ""Unable to retrieve flavour profiles."" msgid ""Unable to retrieve flavor."" msgstr ""Unable to retrieve flavour."" msgid ""Unable to retrieve flavors."" msgstr ""Unable to retrieve flavours."" msgid ""Unable to update flavor profile."" msgstr ""Unable to update flavour profile."" msgid ""Unable to update flavor."" msgstr ""Unable to update flavour."" msgid """" ""You have selected \""%s\"". Deleted load balancer is not recoverable and this "" ""deletion will delete all of the sub-resources."" msgid_plural """" ""You have selected \""%s\"". Deleted load balancers are not recoverable and "" ""this deletion will delete all of the sub-resources."" msgstr[0] """" ""You have selected \""%s\"". Deleted load balancer is not recoverable and this "" ""deletion will delete all of the sub-resources."" msgstr[1] """" ""You have selected \""%s\"". Deleted load balancers are not recoverable and "" ""this deletion will delete all of the sub-resources."" #, python-format","""POT-Creation-Date: 2019-02-17 22:34+0000\n""""PO-Revision-Date: 2018-12-18 11:21+0000\n""",53,2
openstack%2Fneutron~master~I00bb39af04dc814bfc570f2a164cca4d1b39fc59,openstack/neutron,master,I00bb39af04dc814bfc570f2a164cca4d1b39fc59,Add Dongcan Ye as neutron-vpnaas lieutenant and bug contact person,MERGED,2020-01-08 11:44:07.000000000,2020-01-20 06:30:15.000000000,2020-01-20 06:22:32.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-08 11:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b707f4dd02acb97a4881edee6907facc59be400', 'message': 'Add Dongcan Ye as neutron-vpnaas lieutenant\n\nChange-Id: I00bb39af04dc814bfc570f2a164cca4d1b39fc59\n'}, {'number': 2, 'created': '2020-01-10 07:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4dd5cc53d8fc491be5a70fa449352c07ffc52eac', 'message': 'Add Dongcan Ye as neutron-vpnaas lieutenant and bug contact person\n\nChange-Id: I00bb39af04dc814bfc570f2a164cca4d1b39fc59\n'}, {'number': 3, 'created': '2020-01-10 11:20:34.000000000', 'files': ['doc/source/contributor/policies/bugs.rst', 'doc/source/contributor/policies/neutron-teams.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/30a0333f6406d1657ede0585eba364a1c2a51e20', 'message': 'Add Dongcan Ye as neutron-vpnaas lieutenant and bug contact person\n\nChange-Id: I00bb39af04dc814bfc570f2a164cca4d1b39fc59\n'}]",7,701537,30a0333f6406d1657ede0585eba364a1c2a51e20,26,9,3,11975,,,0,"Add Dongcan Ye as neutron-vpnaas lieutenant and bug contact person

Change-Id: I00bb39af04dc814bfc570f2a164cca4d1b39fc59
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/701537/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/policies/neutron-teams.rst'],1,7b707f4dd02acb97a4881edee6907facc59be400,add-vpnaas-lieutenant,| +-----------------------------+-------------------+ | | Dongcan Ye | yedongcan |,,2,0
openstack%2Fneutron~master~Ic3eda36e7e79726fb2f22aa015539c7d47ab7430,openstack/neutron,master,Ic3eda36e7e79726fb2f22aa015539c7d47ab7430,Remove neutron-rootwrap-xen-dom0 script,MERGED,2020-01-08 21:06:53.000000000,2020-01-20 06:26:11.000000000,2020-01-20 06:22:26.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-08 21:06:53.000000000', 'files': ['setup.cfg', 'bin/neutron-rootwrap-xen-dom0'], 'web_link': 'https://opendev.org/openstack/neutron/commit/668f582f8df78089eef44a15a81c970c26c97dc4', 'message': 'Remove neutron-rootwrap-xen-dom0 script\n\nIt was marked for deprecation in the Pike release, enough\ntime has passed so remove it.\n\nChange-Id: Ic3eda36e7e79726fb2f22aa015539c7d47ab7430\n'}]",0,701617,668f582f8df78089eef44a15a81c970c26c97dc4,9,4,1,1131,,,0,"Remove neutron-rootwrap-xen-dom0 script

It was marked for deprecation in the Pike release, enough
time has passed so remove it.

Change-Id: Ic3eda36e7e79726fb2f22aa015539c7d47ab7430
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/701617/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'bin/neutron-rootwrap-xen-dom0']",2,668f582f8df78089eef44a15a81c970c26c97dc4,neutron-rootwrap-xen-dom0,,"#!/usr/bin/env python # Copyright (c) 2012 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Neutron root wrapper for dom0. Executes networking commands in dom0. The XenAPI plugin is responsible determining whether a command is safe to execute. """""" from __future__ import print_function from six.moves import configparser as ConfigParser from oslo_serialization import jsonutils as json import os import select import sys from os_xenapi.client import XenAPI RC_UNAUTHORIZED = 99 RC_NOCOMMAND = 98 RC_BADCONFIG = 97 RC_XENAPI_ERROR = 96 def parse_args(): # Split arguments, require at least a command exec_name = sys.argv.pop(0) # argv[0] required; path to conf file if len(sys.argv) < 2: sys.stderr.write(""%s: No command specified"" % exec_name) sys.exit(RC_NOCOMMAND) config_file = sys.argv.pop(0) user_args = sys.argv[:] return exec_name, config_file, user_args def _xenapi_section_name(config): sections = [sect for sect in config.sections() if sect.lower() == ""xenapi""] if len(sections) == 1: return sections[0] sys.stderr.write(""Multiple [xenapi] sections or no [xenapi] section found!"") sys.exit(RC_BADCONFIG) def load_configuration(exec_name, config_file): config = ConfigParser.RawConfigParser() config.read(config_file) try: exec_dirs = config.get(""DEFAULT"", ""exec_dirs"").split("","") filters_path = config.get(""DEFAULT"", ""filters_path"").split("","") section = _xenapi_section_name(config) url = config.get(section, ""xenapi_connection_url"") username = config.get(section, ""xenapi_connection_username"") password = config.get(section, ""xenapi_connection_password"") except ConfigParser.Error: sys.stderr.write(""%s: Incorrect configuration file: %s"" % (exec_name, config_file)) sys.exit(RC_BADCONFIG) if not url or not password: msg = (""%s: Must specify xenapi_connection_url, "" ""xenapi_connection_username (optionally), and "" ""xenapi_connection_password in %s"") % (exec_name, config_file) sys.stderr.write(msg) sys.exit(RC_BADCONFIG) return dict( filters_path=filters_path, url=url, username=username, password=password, exec_dirs=exec_dirs, ) def filter_command(exec_name, filters_path, user_args, exec_dirs): # Add ../ to sys.path to allow running from branch possible_topdir = os.path.normpath(os.path.join(os.path.abspath(exec_name), os.pardir, os.pardir)) if os.path.exists(os.path.join(possible_topdir, ""neutron"", ""__init__.py"")): sys.path.insert(0, possible_topdir) from oslo_rootwrap import wrapper # Execute command if it matches any of the loaded filters filters = wrapper.load_filters(filters_path) filter_match = wrapper.match_filter( filters, user_args, exec_dirs=exec_dirs) if not filter_match: sys.stderr.write(""Unauthorized command: %s"" % ' '.join(user_args)) sys.exit(RC_UNAUTHORIZED) def run_command(url, username, password, user_args, cmd_input): try: session = XenAPI.Session(url) session.login_with_password(username, password) try: host = session.xenapi.session.get_this_host(session.handle) result = session.xenapi.host.call_plugin( host, 'netwrap.py', 'run_command', {'cmd': json.dumps(user_args), 'cmd_input': json.dumps(cmd_input)}) result_dict = json.loads(result) returncode = result_dict.get('returncode') captured_stdout = result_dict.get('out') captured_stderr = result_dict.get('err') sys.stdout.write(captured_stdout) sys.stderr.write(captured_stderr) sys.exit(returncode) finally: session.xenapi.session.logout() except Exception as e: sys.stderr.write(""Failed to execute command in Dom0, %s"" % e) sys.exit(RC_XENAPI_ERROR) def main(): # Deprecated: This script is deprecated and will be deleted in next release sys.stderr.write(""Deprecated: neutron-rootwrap-xen-dom0 is deprecated, "" ""will be deleted in next release."") exec_name, config_file, user_args = parse_args() config = load_configuration(exec_name, config_file) filter_command(exec_name, config['filters_path'], user_args, config['exec_dirs']) # If data is available on the standard input, we need to pass it to the # command executed in dom0 cmd_input = None if select.select([sys.stdin,],[],[],0.0)[0]: cmd_input = """".join(sys.stdin) return run_command(config['url'], config['username'], config['password'], user_args, cmd_input) if __name__ == '__main__': main() ",0,156
openstack%2Fneutron~master~I133574c759d02843591e7448753d72cc4fd75491,openstack/neutron,master,I133574c759d02843591e7448753d72cc4fd75491,Update TOX_ENV_SRC_MODULES example,MERGED,2019-12-18 16:41:13.000000000,2020-01-20 06:22:29.000000000,2020-01-20 06:22:29.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 16:41:13.000000000', 'files': ['TESTING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d484bbec2ee4878326cc0448dcbd5f85457d616c', 'message': 'Update TOX_ENV_SRC_MODULES example\n\nTESTING.rst describes how to use TOX_ENV_SRC_MODULES\nto use a local copy of library source code while\ntesting, but included pep8 when only unit testing\nis supported.\n\nTrivialfix\n\nChange-Id: I133574c759d02843591e7448753d72cc4fd75491\n'}]",0,699728,d484bbec2ee4878326cc0448dcbd5f85457d616c,7,3,1,1131,,,0,"Update TOX_ENV_SRC_MODULES example

TESTING.rst describes how to use TOX_ENV_SRC_MODULES
to use a local copy of library source code while
testing, but included pep8 when only unit testing
is supported.

Trivialfix

Change-Id: I133574c759d02843591e7448753d72cc4fd75491
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/699728/1 && git format-patch -1 --stdout FETCH_HEAD,['TESTING.rst'],1,d484bbec2ee4878326cc0448dcbd5f85457d616c,tox-env-src-modules," env TOX_ENV_SRC_MODULES=$SRC/neutron-lib tox -r -e py37 env TOX_ENV_SRC_MODULES=$SRC/neutron-lib tox -r -e py37 env TOX_ENV_SRC_MODULES=""$SRC/neutron-lib $SRC/oslo.db"" tox -r -e py37"," env TOX_ENV_SRC_MODULES=$SRC/neutron-lib tox -r -e pep8,py37 env TOX_ENV_SRC_MODULES=$SRC/neutron-lib tox -r -e pep8,py37 env TOX_ENV_SRC_MODULES=""$SRC/neutron-lib $SRC/oslo.db"" tox -r -e pep8,py37",3,3
openstack%2Fproject-config~master~I683811b5e71e5741dfeabd33a5e7332c05dde0f9,openstack/project-config,master,I683811b5e71e5741dfeabd33a5e7332c05dde0f9,Add an openstack/auto-scaling-sig repository,MERGED,2019-02-15 04:46:21.000000000,2020-01-20 04:54:12.000000000,2019-03-05 15:09:28.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-15 04:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/44f01e8b110b8d8c6a423bf741c498d6adb4b057', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\n'}, {'number': 2, 'created': '2019-02-15 05:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5e1c7a9503bdfa07966e607c5225d9dfcb5a4664', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\nNeeded-By: https://review.openstack.org/#/c/637126\n'}, {'number': 3, 'created': '2019-02-15 05:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/310d4afcaf9c8f34cbc535e181639d83e2f60ddc', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\n'}, {'number': 4, 'created': '2019-02-15 05:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bc08045502ce1e15bf499a6e2fda39454cd84799', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\n'}, {'number': 5, 'created': '2019-03-04 10:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/08590d9e4f2d52c2c26a735e80a6c16b5c37e722', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\n'}, {'number': 6, 'created': '2019-03-04 15:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e80b23127a9503d3e896f5340ad2f09453295340', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\n'}, {'number': 7, 'created': '2019-03-05 09:08:44.000000000', 'files': ['gerrit/acls/openstack/auto-scaling-sig.config', 'gerritbot/channels.yaml', 'accessbot/channels.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a51e81b8a9005d56466db9a8cc6b8227730a7b93', 'message': 'Add an openstack/auto-scaling-sig repository\n\nSetup config for Auto-scaling SIG\n\nhttps://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21\n\nChange-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9\n'}]",4,637125,a51e81b8a9005d56466db9a8cc6b8227730a7b93,39,6,7,12404,,,0,"Add an openstack/auto-scaling-sig repository

Setup config for Auto-scaling SIG

https://github.com/openstack/governance-sigs/blob/master/sigs.yaml#L21

Change-Id: I683811b5e71e5741dfeabd33a5e7332c05dde0f9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/637125/6 && git format-patch -1 --stdout FETCH_HEAD,"['accessbot/channels.yaml', 'gerrit/acls/openstack/auto-scaling-sig.config', 'gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/main.yaml']",5,44f01e8b110b8d8c6a423bf741c498d6adb4b057,create-auto-scaling-sig, - openstack/auto-scaling-sig,,24,0
openstack%2Ftripleo-ansible~master~I4c76071083bf5cb4f876d3b78c379822a8bd8db1,openstack/tripleo-ansible,master,I4c76071083bf5cb4f876d3b78c379822a8bd8db1,Fix substitution in kill-script,MERGED,2020-01-17 16:48:02.000000000,2020-01-20 04:19:47.000000000,2020-01-20 04:19:47.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 11082}, {'_account_id': 11975}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-17 16:48:02.000000000', 'files': ['tripleo_ansible/roles/tripleo-systemd-wrapper/templates/service_kill.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b45d4c6d219e8e27219bca341acdfd634155d6f6', 'message': 'Fix substitution in kill-script\n\nIn the kill-script there is a string ""Unknown action ${SIG} for\n${$CT_NAME} ${CT_ID}"" which results in a ""bad substitution"" error, as\nthere is no variable named with what the contents of the CT_NAME\nenvironment variable contains.  Remove the extraneous \'$\'.\n\nChange-Id: I4c76071083bf5cb4f876d3b78c379822a8bd8db1\nFixes-Bug: #1860155\n'}]",0,703123,b45d4c6d219e8e27219bca341acdfd634155d6f6,9,9,1,13995,,,0,"Fix substitution in kill-script

In the kill-script there is a string ""Unknown action ${SIG} for
${$CT_NAME} ${CT_ID}"" which results in a ""bad substitution"" error, as
there is no variable named with what the contents of the CT_NAME
environment variable contains.  Remove the extraneous '$'.

Change-Id: I4c76071083bf5cb4f876d3b78c379822a8bd8db1
Fixes-Bug: #1860155
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/23/703123/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-systemd-wrapper/templates/service_kill.j2'],1,b45d4c6d219e8e27219bca341acdfd634155d6f6,bug/1860155," add_date ""Unknown action ${SIG} for ${CT_NAME} ${CT_ID}"""," add_date ""Unknown action ${SIG} for ${$CT_NAME} ${CT_ID}""",1,1
openstack%2Fdevstack~master~I4557a737cb13b9c2406056be08ab8a32ddd45162,openstack/devstack,master,I4557a737cb13b9c2406056be08ab8a32ddd45162,do not gzip legacy service logs,MERGED,2020-01-14 15:52:25.000000000,2020-01-20 04:04:03.000000000,2020-01-16 03:22:18.000000000,"[{'_account_id': 5263}, {'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-14 15:52:25.000000000', 'files': ['roles/export-devstack-journal/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d02fa6f856ac5951b8a879c23b57d5a752f28918', 'message': 'do not gzip legacy service logs\n\nThis change removes the .gz extension from the\nservice and syslog logs exported via journalctl.\nThis change nolonger gzip compresses the exported\nlogs so that they can be rendered in the browser\ndirectly when served from swift.\n\nChange-Id: I4557a737cb13b9c2406056be08ab8a32ddd45162\n'}]",0,702465,d02fa6f856ac5951b8a879c23b57d5a752f28918,17,7,1,11604,,,0,"do not gzip legacy service logs

This change removes the .gz extension from the
service and syslog logs exported via journalctl.
This change nolonger gzip compresses the exported
logs so that they can be rendered in the browser
directly when served from swift.

Change-Id: I4557a737cb13b9c2406056be08ab8a32ddd45162
",git fetch https://review.opendev.org/openstack/devstack refs/changes/65/702465/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/export-devstack-journal/tasks/main.yaml'],1,d02fa6f856ac5951b8a879c23b57d5a752f28918,do-not-compress-service-logs, journalctl -o short-precise --unit $u > {{ stage_dir }}/logs/$name.txt > {{ stage_dir }}/logs/syslog.txt, journalctl -o short-precise --unit $u | gzip - > {{ stage_dir }}/logs/$name.txt.gz | gzip - > {{ stage_dir }}/logs/syslog.txt.gz,2,2
openstack%2Fhorizon~master~I0672a516083727c245f1d4fa5b10eed9cd81a726,openstack/horizon,master,I0672a516083727c245f1d4fa5b10eed9cd81a726,Remove six.reraise usage,MERGED,2020-01-16 22:31:41.000000000,2020-01-20 02:50:01.000000000,2020-01-20 02:48:23.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-16 22:31:41.000000000', 'files': ['horizon/tabs/base.py', 'openstack_dashboard/utils/config_types.py', 'horizon/exceptions.py', 'requirements.txt', 'horizon/tables/base.py', 'horizon/tables/formset.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4fc1b9c4249a788fb1d59510096f72033eb85328', 'message': 'Remove six.reraise usage\n\nsix.reraise can be converted into ""raise new_exc from original_exc""\nintroduced in python3.\n\nIn case of horizon.exceptions.handle(), six.reraise was used to\nraise the original exception again, so we can convert it into ""raise"".\n\nsix is removed from requirements.txt.\nNote that we need to keep six in lower-constraints.txt\nas dependent libraries still use six.\n\nChange-Id: I0672a516083727c245f1d4fa5b10eed9cd81a726\n'}]",2,702998,4fc1b9c4249a788fb1d59510096f72033eb85328,15,4,1,841,,,0,"Remove six.reraise usage

six.reraise can be converted into ""raise new_exc from original_exc""
introduced in python3.

In case of horizon.exceptions.handle(), six.reraise was used to
raise the original exception again, so we can convert it into ""raise"".

six is removed from requirements.txt.
Note that we need to keep six in lower-constraints.txt
as dependent libraries still use six.

Change-Id: I0672a516083727c245f1d4fa5b10eed9cd81a726
",git fetch https://review.opendev.org/openstack/horizon refs/changes/98/702998/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/tabs/base.py', 'horizon/exceptions.py', 'openstack_dashboard/utils/config_types.py', 'requirements.txt', 'horizon/tables/base.py', 'horizon/tables/formset.py']",6,4fc1b9c4249a788fb1d59510096f72033eb85328,remove-six, except Exception as e: raise template.TemplateSyntaxError from e,"import sys import six except Exception: exc_info = sys.exc_info() raise six.reraise(template.TemplateSyntaxError, exc_info[1], exc_info[2])",13,31
openstack%2Fnova~master~Ic293e6f20df1b92a7e6d37c870f5abe95b4f2cdb,openstack/nova,master,Ic293e6f20df1b92a7e6d37c870f5abe95b4f2cdb,"libvirt: Remove MIN_{LIBVIRT,QEMU}_FILE_BACKED_VERSION",MERGED,2019-11-25 16:21:55.000000000,2020-01-20 02:48:25.000000000,2020-01-20 02:46:25.000000000,"[{'_account_id': 6962}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-25 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5fa4d815a0f86ed2c57ce3a5a8b143ae4c34e31f', 'message': 'libvirt: Remove MIN_{LIBVIRT,QEMU}_FILE_BACKED_VERSION\n\nThe updated minimum required libvirt (5.0.0) and QEMU (4.0.0) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the two version constants:\n\n    MIN_LIBVIRT_FILE_BACKED_VERSION,\n    MIN_QEMU_FILE_BACKED_VERSION\n\n... and related, now-needless, compatibility code.  Plus, remove the\nfollowing three tests:\n\n    test_min_version_file_backed_ok()\n    test_min_version_file_backed_old_libvirt()\n    test_min_version_file_backed_old_qemu()\n\nAnd tweak this one:\n\n    test_min_version_file_backed_bad_ram_allocation_ratio()\n\nChange-Id: Ic293e6f20df1b92a7e6d37c870f5abe95b4f2cdb\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2019-12-06 14:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/720302b5d26b685d3b62ebb46610acf13c42805c', 'message': 'libvirt: Remove MIN_{LIBVIRT,QEMU}_FILE_BACKED_VERSION\n\nThe updated minimum required libvirt (4.0.0) and QEMU (2.11) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the two version constants:\n\n    MIN_LIBVIRT_FILE_BACKED_VERSION,\n    MIN_QEMU_FILE_BACKED_VERSION\n\n... and related, now-needless, compatibility code.  Plus, remove the\nfollowing three tests:\n\n    test_min_version_file_backed_old_libvirt()\n    test_min_version_file_backed_old_qemu()\n\nAnd tweak these two:\n\n    test_min_version_file_backed_ok()\n    test_min_version_file_backed_bad_ram_allocation_ratio()\n\nChange-Id: Ic293e6f20df1b92a7e6d37c870f5abe95b4f2cdb\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2019-12-10 09:00:06.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/631c4657da443307126bb6e9adb23d8370ce3377', 'message': 'libvirt: Remove MIN_{LIBVIRT,QEMU}_FILE_BACKED_VERSION\n\nThe updated minimum required libvirt (4.0.0) and QEMU (2.11) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the two version constants:\n\n    MIN_LIBVIRT_FILE_BACKED_VERSION,\n    MIN_QEMU_FILE_BACKED_VERSION\n\n... and related, now-needless, compatibility code.  Plus, remove the\nfollowing three tests:\n\n    test_min_version_file_backed_old_libvirt()\n    test_min_version_file_backed_old_qemu()\n\nAnd tweak these two:\n\n    test_min_version_file_backed_ok()\n    test_min_version_file_backed_bad_ram_allocation_ratio()\n\nChange-Id: Ic293e6f20df1b92a7e6d37c870f5abe95b4f2cdb\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",6,695942,631c4657da443307126bb6e9adb23d8370ce3377,85,12,3,6962,,,0,"libvirt: Remove MIN_{LIBVIRT,QEMU}_FILE_BACKED_VERSION

The updated minimum required libvirt (4.0.0) and QEMU (2.11) for
""Ussuri"" satisfy the version requirements; this was done in Change-Id:
Ia18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for
""Ussuri"", 2019-11-19).

Drop the two version constants:

    MIN_LIBVIRT_FILE_BACKED_VERSION,
    MIN_QEMU_FILE_BACKED_VERSION

... and related, now-needless, compatibility code.  Plus, remove the
following three tests:

    test_min_version_file_backed_old_libvirt()
    test_min_version_file_backed_old_qemu()

And tweak these two:

    test_min_version_file_backed_ok()
    test_min_version_file_backed_bad_ram_allocation_ratio()

Change-Id: Ic293e6f20df1b92a7e6d37c870f5abe95b4f2cdb
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/695942/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,5fa4d815a0f86ed2c57ce3a5a8b143ae4c34e31f,Bump_min_libvirt_and_QEMU_for_Ussuri, def test_min_version_file_backed_bad_ram_allocation_ratio(self):," @mock.patch.object(fakelibvirt.Connection, 'getLibVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_LIBVIRT_FILE_BACKED_VERSION)) @mock.patch.object(fakelibvirt.Connection, 'getVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_VERSION)) def test_min_version_file_backed_ok(self, mock_libv, mock_qemu): self.flags(file_backed_memory=1024, group='libvirt') self.flags(ram_allocation_ratio=1.0) drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) drvr._check_file_backed_memory_support() @mock.patch.object(fakelibvirt.Connection, 'getLibVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_LIBVIRT_FILE_BACKED_VERSION) - 1) @mock.patch.object(fakelibvirt.Connection, 'getVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_VERSION)) def test_min_version_file_backed_old_libvirt(self, mock_libv, mock_qemu): self.flags(file_backed_memory=1024, group=""libvirt"") self.flags(ram_allocation_ratio=1.0) drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) self.assertRaises(exception.InternalError, drvr._check_file_backed_memory_support) @mock.patch.object(fakelibvirt.Connection, 'getLibVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_LIBVIRT_FILE_BACKED_VERSION)) @mock.patch.object(fakelibvirt.Connection, 'getVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_VERSION) - 1) def test_min_version_file_backed_old_qemu(self, mock_libv, mock_qemu): self.flags(file_backed_memory=1024, group=""libvirt"") self.flags(ram_allocation_ratio=1.0) drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) self.assertRaises(exception.InternalError, drvr._check_file_backed_memory_support) @mock.patch.object(fakelibvirt.Connection, 'getLibVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_LIBVIRT_FILE_BACKED_VERSION)) @mock.patch.object(fakelibvirt.Connection, 'getVersion', return_value=versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_VERSION)) def test_min_version_file_backed_bad_ram_allocation_ratio(self, mock_libv, mock_qemu):",1,60
openstack%2Fnova-specs~master~Icfa3ad78498dedf9cb7dc95de8d2f0ddfca31d20,openstack/nova-specs,master,Icfa3ad78498dedf9cb7dc95de8d2f0ddfca31d20,expose auto converge in rest api,ABANDONED,2019-03-29 06:28:51.000000000,2020-01-20 02:43:18.000000000,,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8768}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 15888}, {'_account_id': 19124}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 27614}]","[{'number': 1, 'created': '2019-03-29 06:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a9840f1deea0d9c9a86816a313a12df53daf7f99', 'message': 'expose auto converge in rest api\n\nChange-Id: Icfa3ad78498dedf9cb7dc95de8d2f0ddfca31d20\n'}, {'number': 2, 'created': '2019-04-01 08:01:12.000000000', 'files': ['specs/train/approved/expose-auto-converge-in-rest-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c4137a0af26c9b1c640a170b7a219de10eb6bf86', 'message': 'expose auto converge in rest api\n\nChange-Id: Icfa3ad78498dedf9cb7dc95de8d2f0ddfca31d20\n'}]",6,648619,c4137a0af26c9b1c640a170b7a219de10eb6bf86,15,10,2,27614,,,0,"expose auto converge in rest api

Change-Id: Icfa3ad78498dedf9cb7dc95de8d2f0ddfca31d20
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/19/648619/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/train/approved/expose-auto-converge-in-rest-api.rst'],1,a9840f1deea0d9c9a86816a313a12df53daf7f99,bp/expose-auto-converge-in-rest-api,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Expose auto converge in rest api ========================================== https://blueprints.launchpad.net/nova/+spec/expose-auto-converge-in-rest-api Problem description =================== Auto converge allows the guest to be live migrated without service interruption. Currently, this function can only be enabled by configured in the configuration file, nova will automatically check whether the live migration supports auto converge. The problem is that end user can't use auto converge on a specify instance which the host didn't configured it. Use Cases --------- * The guest is writing to memory faster than libvirt can transfer the memory changes to the destination host, and the auto converge didn't configured in nova. As an end user, i'd like to use auto converge to make migration work well. * The guest is writing to memory faster than libvirt can transfer the memory changes to the destination host, and the auto converge was enabled. But the business on the guest is sensitive to cpu and memory, as an end user, I wouldn't use auto converge. Proposed change =============== * Add ``auto_converge`` to the REST API ``POST /servers/{server_id}/action``, for what the action is ``os-migrateLive``. :: { ""os-migrateLive"": { ...; ""auto_converge"": true } } * Add object: ``auto_converge`` into database table: ``migrations``. * Libvirt driver: recalculate ``_live_migration_flags`` before doing ``_live_migration``. If the configuration conflicts with the API sent, we use the value of api to datermine whether to use auto converge. Alternatives ------------ None. Data model impact ----------------- An ``auto_converge`` column will be added to the ``migrations`` table with type Boolean. The column will be nullable, and it will be updated when performing another migration. REST API impact --------------- In a new microversion add the ``auto_converge`` flag from the API: * POST /servers/{server_id}/action Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Update python-novaclient and python-openstackclient to support the new microversion. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Upgrade impact -------------- Since there will be a change in the nova DB schema, the ``nova-manage db sync`` command will have to be run to update the migrations table. The online data migration tool that will be added to populate the new column will have to be run. Implementation ============== Assignee(s) ----------- Primary assignee: Ya Wang Work Items ---------- * Add a new column ``auto_converge`` to the ``nova.migrations`` table. * Modify the api controller. * Recalculate ``_live_migration_flags`` before live migration start in libvirt driver. * Add functional tests and unit tests. * Add microversion related test to tempest. Dependencies ============ None Testing ======= Unit tests and functional tests will be included to test the new functionality. Documentation Impact ==================== * The API document should be changed to introduce this new feature. * The live migration document should be changed to introduce this new feature. References ========== None History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Train - Introduced ",,171,0
openstack%2Fneutron~stable%2Ftrain~I7599be8b7459c44db8e34d0de536154dccb19134,openstack/neutron,stable/train,I7599be8b7459c44db8e34d0de536154dccb19134,Fix bug number in release note,MERGED,2020-01-16 14:38:48.000000000,2020-01-20 02:09:37.000000000,2020-01-20 02:06:10.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-16 14:38:48.000000000', 'files': ['releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/135e37ea52aa7598a00afbed8c8184eac94da74d', 'message': 'Fix bug number in release note\n\nI mixed up the bug number and the gerrit change number in a previous\nrelease note.\n\nTrivialChange\n\nChange-Id: I7599be8b7459c44db8e34d0de536154dccb19134\nRelated-Bug: #1853840\n(cherry picked from commit 03ad5bf19c916d50b04dbcfb552ddbf96e243b54)\n'}]",0,702877,135e37ea52aa7598a00afbed8c8184eac94da74d,10,5,1,15554,,,0,"Fix bug number in release note

I mixed up the bug number and the gerrit change number in a previous
release note.

TrivialChange

Change-Id: I7599be8b7459c44db8e34d0de536154dccb19134
Related-Bug: #1853840
(cherry picked from commit 03ad5bf19c916d50b04dbcfb552ddbf96e243b54)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/702877/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml'],1,135e37ea52aa7598a00afbed8c8184eac94da74d,bug/1853840, `bug 1853840 <https://launchpad.net/bugs/1853840>`_. For users affected by `bug 1853840, `bug 696600 <https://launchpad.net/bugs/1853840>`_. For users affected by `bug 696600,2,2
openstack%2Fneutron~stable%2Fstein~I7599be8b7459c44db8e34d0de536154dccb19134,openstack/neutron,stable/stein,I7599be8b7459c44db8e34d0de536154dccb19134,Fix bug number in release note,MERGED,2020-01-16 14:39:28.000000000,2020-01-20 02:09:22.000000000,2020-01-20 02:06:16.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-16 14:39:28.000000000', 'files': ['releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cde3c76ec093d82c6287dbabbe64d4ba021d7a85', 'message': 'Fix bug number in release note\n\nI mixed up the bug number and the gerrit change number in a previous\nrelease note.\n\nTrivialChange\n\nChange-Id: I7599be8b7459c44db8e34d0de536154dccb19134\nRelated-Bug: #1853840\n(cherry picked from commit 03ad5bf19c916d50b04dbcfb552ddbf96e243b54)\n(cherry picked from commit 135e37ea52aa7598a00afbed8c8184eac94da74d)\n'}]",0,702878,cde3c76ec093d82c6287dbabbe64d4ba021d7a85,10,5,1,15554,,,0,"Fix bug number in release note

I mixed up the bug number and the gerrit change number in a previous
release note.

TrivialChange

Change-Id: I7599be8b7459c44db8e34d0de536154dccb19134
Related-Bug: #1853840
(cherry picked from commit 03ad5bf19c916d50b04dbcfb552ddbf96e243b54)
(cherry picked from commit 135e37ea52aa7598a00afbed8c8184eac94da74d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/702878/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml'],1,cde3c76ec093d82c6287dbabbe64d4ba021d7a85,bug/1853840, `bug 1853840 <https://launchpad.net/bugs/1853840>`_. For users affected by `bug 1853840, `bug 696600 <https://launchpad.net/bugs/1853840>`_. For users affected by `bug 696600,2,2
openstack%2Fneutron~stable%2Fstein~I9b08a3a9c20b702b745b41d4885fb5120fd665ce,openstack/neutron,stable/stein,I9b08a3a9c20b702b745b41d4885fb5120fd665ce,Locate RP-tree parent by hypervisor name,MERGED,2019-12-16 11:39:37.000000000,2020-01-20 02:08:05.000000000,2020-01-20 02:06:13.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 15554}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-16 11:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/746ac15f867dd6a2b0b1b5b15ab1256552d396d7', 'message': ""Locate RP-tree parent by hypervisor name\n\nPreviously we assumed that we can look up the resource provider (created\nby nova) to be used as the parent of the agent and physical NIC resource\nprovider tree by the name set in the config option DEFAULT.host. This\nassumption was wrong.\n\nWhile nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host\nmust match for port binding to work, the root resource provider created\nby nova does not belong to the compute host (where nova-compute runs)\nbut it belongs to the compute nodes (i.e. hypervisors). Actually there\nmay be multiple compute nodes managed by a single nova-compute (think\nof ironic). Plus the value of DEFAULT.host and the compute node's ID\nmay be different even when nova-compute manages a hypervisor on the\nsame host because of various deployment considerations. For example\nwhen tripleo does not manage the undercloud (so a libvirt hypervisor\nreturns the plain hostname), but the same tripleo enforces it's host\nnaming conventions in nova's and neutron's DEFAULT.host settings.\n\nThis change enables neutron to use the hypervisor name to locate the\nroot of the resource provider tree.\n\nWe introduce a new configuration option for\n\n(1) ovs-agent: resource_provider_hypervisors, for example:\n\n[ovs]\nbridge_mappings = physnet0:br-physnet0,...\nresource_provider_bandwidths = br-physnet0:10000000:10000000,...\nresource_provider_hypervisors = br-physnet0:hypervisor0,...\n\n(2) sriov-agent: resource_provider_hypervisors, for example:\n\n[sriov_nic]\nbridge_mappings = physnet1:ens5,...\nresource_provider_bandwidths = ens5:10000000:10000000,...\nresource_provider_hypervisors = ens5:hypervisor1,...\n\nFor both agents 'resource_provider_hypervisors' values default to\nsocket.gethostname() for each key in resource_provider_bandwidths.\n\nWe try to not block later developments in which one neutron\nagent may manage devices on multiple hosts. That's why we allow\nthe each physdev to be associated with a different hypervisor.\n\nBut here we do not try to solve the problem that the natural physdev\nidentifiers may not be unique accross multiple hosts. We leave solving\nthis problem to whoever wants to implement an agent handling devices of\nmultiple hosts.\n\n(3) We extend report_state message's configurations field alike:\n\n{\n'bridge_mappings': {'physnet0': 'br-physnet0'},\n'resource_provider_bandwidths': {\n    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},\n'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},\n...\n}\n\n(4) In neutron-server we use\nreport_state.configurations.resource_provider_hypervisors.PHYSDEV\nwhen selecting parent resource provider for agent and physdev\nRP-tree. When not available in the message we fall back to using\nreport_state.host as before.\n\nSince we only changed the free-format configurations field of the\nreport_state message rpc version is not bumped and we expect this\nchange to be backported to stein and train.\n\nRemoved unapplicable TODO note from backport.\n\nConflicts:\n  neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py\n  neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py\n\nChange-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce\nCloses-Bug: #1853840\n(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)\n(cherry picked from commit c975b76abe3b0cd8349e4621beb97f89865f0c0e)\n""}, {'number': 2, 'created': '2019-12-20 12:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/73626646fad4570da0fff54dcc31d9c2353ef3af', 'message': ""Locate RP-tree parent by hypervisor name\n\nPreviously we assumed that we can look up the resource provider (created\nby nova) to be used as the parent of the agent and physical NIC resource\nprovider tree by the name set in the config option DEFAULT.host. This\nassumption was wrong.\n\nWhile nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host\nmust match for port binding to work, the root resource provider created\nby nova does not belong to the compute host (where nova-compute runs)\nbut it belongs to the compute nodes (i.e. hypervisors). Actually there\nmay be multiple compute nodes managed by a single nova-compute (think\nof ironic). Plus the value of DEFAULT.host and the compute node's ID\nmay be different even when nova-compute manages a hypervisor on the\nsame host because of various deployment considerations. For example\nwhen tripleo does not manage the undercloud (so a libvirt hypervisor\nreturns the plain hostname), but the same tripleo enforces it's host\nnaming conventions in nova's and neutron's DEFAULT.host settings.\n\nThis change enables neutron to use the hypervisor name to locate the\nroot of the resource provider tree.\n\nWe introduce a new configuration option for\n\n(1) ovs-agent: resource_provider_hypervisors, for example:\n\n[ovs]\nbridge_mappings = physnet0:br-physnet0,...\nresource_provider_bandwidths = br-physnet0:10000000:10000000,...\nresource_provider_hypervisors = br-physnet0:hypervisor0,...\n\n(2) sriov-agent: resource_provider_hypervisors, for example:\n\n[sriov_nic]\nbridge_mappings = physnet1:ens5,...\nresource_provider_bandwidths = ens5:10000000:10000000,...\nresource_provider_hypervisors = ens5:hypervisor1,...\n\nFor both agents 'resource_provider_hypervisors' values default to\nsocket.gethostname() for each key in resource_provider_bandwidths.\n\nWe try to not block later developments in which one neutron\nagent may manage devices on multiple hosts. That's why we allow\nthe each physdev to be associated with a different hypervisor.\n\nBut here we do not try to solve the problem that the natural physdev\nidentifiers may not be unique accross multiple hosts. We leave solving\nthis problem to whoever wants to implement an agent handling devices of\nmultiple hosts.\n\n(3) We extend report_state message's configurations field alike:\n\n{\n'bridge_mappings': {'physnet0': 'br-physnet0'},\n'resource_provider_bandwidths': {\n    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},\n'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},\n...\n}\n\n(4) In neutron-server we use\nreport_state.configurations.resource_provider_hypervisors.PHYSDEV\nwhen selecting parent resource provider for agent and physdev\nRP-tree. When not available in the message we fall back to using\nreport_state.host as before.\n\nSince we only changed the free-format configurations field of the\nreport_state message rpc version is not bumped and we expect this\nchange to be backported to stein and train.\n\nRemoved unapplicable TODO notes from backport.\n\nConflicts:\n  neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py\n  neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py\n\nChange-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce\nCloses-Bug: #1853840\n(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)\n(cherry picked from commit 9a6766470ef127ee5495a5b74b7156bd5a80f03c)\n""}, {'number': 3, 'created': '2019-12-23 11:12:30.000000000', 'files': ['neutron/conf/plugins/ml2/drivers/mech_sriov/agent_common.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/services/placement_report/test_plugin.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py', 'neutron/tests/unit/agent/common/test_utils.py', 'neutron/agent/common/utils.py', 'neutron/conf/plugins/ml2/drivers/ovs_conf.py', 'neutron/agent/common/placement_report.py', 'releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml', 'neutron/tests/unit/agent/common/test_placement_report.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py', 'neutron/services/placement_report/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b99dee2df6045e5fe0896acefc591798953d375d', 'message': ""Locate RP-tree parent by hypervisor name\n\nPreviously we assumed that we can look up the resource provider (created\nby nova) to be used as the parent of the agent and physical NIC resource\nprovider tree by the name set in the config option DEFAULT.host. This\nassumption was wrong.\n\nWhile nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host\nmust match for port binding to work, the root resource provider created\nby nova does not belong to the compute host (where nova-compute runs)\nbut it belongs to the compute nodes (i.e. hypervisors). Actually there\nmay be multiple compute nodes managed by a single nova-compute (think\nof ironic). Plus the value of DEFAULT.host and the compute node's ID\nmay be different even when nova-compute manages a hypervisor on the\nsame host because of various deployment considerations. For example\nwhen tripleo does not manage the undercloud (so a libvirt hypervisor\nreturns the plain hostname), but the same tripleo enforces it's host\nnaming conventions in nova's and neutron's DEFAULT.host settings.\n\nThis change enables neutron to use the hypervisor name to locate the\nroot of the resource provider tree.\n\nWe introduce a new configuration option for\n\n(1) ovs-agent: resource_provider_hypervisors, for example:\n\n[ovs]\nbridge_mappings = physnet0:br-physnet0,...\nresource_provider_bandwidths = br-physnet0:10000000:10000000,...\nresource_provider_hypervisors = br-physnet0:hypervisor0,...\n\n(2) sriov-agent: resource_provider_hypervisors, for example:\n\n[sriov_nic]\nbridge_mappings = physnet1:ens5,...\nresource_provider_bandwidths = ens5:10000000:10000000,...\nresource_provider_hypervisors = ens5:hypervisor1,...\n\nFor both agents 'resource_provider_hypervisors' values default to\nsocket.gethostname() for each key in resource_provider_bandwidths.\n\nWe try to not block later developments in which one neutron\nagent may manage devices on multiple hosts. That's why we allow\nthe each physdev to be associated with a different hypervisor.\n\nBut here we do not try to solve the problem that the natural physdev\nidentifiers may not be unique accross multiple hosts. We leave solving\nthis problem to whoever wants to implement an agent handling devices of\nmultiple hosts.\n\n(3) We extend report_state message's configurations field alike:\n\n{\n'bridge_mappings': {'physnet0': 'br-physnet0'},\n'resource_provider_bandwidths': {\n    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},\n'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},\n...\n}\n\n(4) In neutron-server we use\nreport_state.configurations.resource_provider_hypervisors.PHYSDEV\nwhen selecting parent resource provider for agent and physdev\nRP-tree. When not available in the message we fall back to using\nreport_state.host as before.\n\nSince we only changed the free-format configurations field of the\nreport_state message rpc version is not bumped and we expect this\nchange to be backported to stein and train.\n\nRemoved unapplicable TODO notes from backport.\n\nConflicts:\n  neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py\n  neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py\n\nChange-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce\nCloses-Bug: #1853840\n(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)\n(cherry picked from commit 9a6766470ef127ee5495a5b74b7156bd5a80f03c)\n""}]",0,699196,b99dee2df6045e5fe0896acefc591798953d375d,21,7,3,15554,,,0,"Locate RP-tree parent by hypervisor name

Previously we assumed that we can look up the resource provider (created
by nova) to be used as the parent of the agent and physical NIC resource
provider tree by the name set in the config option DEFAULT.host. This
assumption was wrong.

While nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host
must match for port binding to work, the root resource provider created
by nova does not belong to the compute host (where nova-compute runs)
but it belongs to the compute nodes (i.e. hypervisors). Actually there
may be multiple compute nodes managed by a single nova-compute (think
of ironic). Plus the value of DEFAULT.host and the compute node's ID
may be different even when nova-compute manages a hypervisor on the
same host because of various deployment considerations. For example
when tripleo does not manage the undercloud (so a libvirt hypervisor
returns the plain hostname), but the same tripleo enforces it's host
naming conventions in nova's and neutron's DEFAULT.host settings.

This change enables neutron to use the hypervisor name to locate the
root of the resource provider tree.

We introduce a new configuration option for

(1) ovs-agent: resource_provider_hypervisors, for example:

[ovs]
bridge_mappings = physnet0:br-physnet0,...
resource_provider_bandwidths = br-physnet0:10000000:10000000,...
resource_provider_hypervisors = br-physnet0:hypervisor0,...

(2) sriov-agent: resource_provider_hypervisors, for example:

[sriov_nic]
bridge_mappings = physnet1:ens5,...
resource_provider_bandwidths = ens5:10000000:10000000,...
resource_provider_hypervisors = ens5:hypervisor1,...

For both agents 'resource_provider_hypervisors' values default to
socket.gethostname() for each key in resource_provider_bandwidths.

We try to not block later developments in which one neutron
agent may manage devices on multiple hosts. That's why we allow
the each physdev to be associated with a different hypervisor.

But here we do not try to solve the problem that the natural physdev
identifiers may not be unique accross multiple hosts. We leave solving
this problem to whoever wants to implement an agent handling devices of
multiple hosts.

(3) We extend report_state message's configurations field alike:

{
'bridge_mappings': {'physnet0': 'br-physnet0'},
'resource_provider_bandwidths': {
    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},
'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},
...
}

(4) In neutron-server we use
report_state.configurations.resource_provider_hypervisors.PHYSDEV
when selecting parent resource provider for agent and physdev
RP-tree. When not available in the message we fall back to using
report_state.host as before.

Since we only changed the free-format configurations field of the
report_state message rpc version is not bumped and we expect this
change to be backported to stein and train.

Removed unapplicable TODO notes from backport.

Conflicts:
  neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py
  neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py

Change-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce
Closes-Bug: #1853840
(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)
(cherry picked from commit 9a6766470ef127ee5495a5b74b7156bd5a80f03c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/699196/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/conf/plugins/ml2/drivers/mech_sriov/agent_common.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/services/placement_report/test_plugin.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py', 'neutron/tests/unit/agent/common/test_utils.py', 'neutron/agent/common/utils.py', 'neutron/conf/plugins/ml2/drivers/ovs_conf.py', 'neutron/agent/common/placement_report.py', 'releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml', 'neutron/tests/unit/agent/common/test_placement_report.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py', 'neutron/services/placement_report/plugin.py']",12,746ac15f867dd6a2b0b1b5b15ab1256552d396d7,bug/1853840," if 'resource_provider_hypervisors' in configurations: # When the agent has the fix for # https://bugs.launchpad.net/neutron/+bug/1853840 # it sends us hypervisor names (compute nodes in nova terminology). hypervisors = configurations['resource_provider_hypervisors'] else: # For older agents without the fix we have to assume the old # buggy behavior. There we assumed DEFAULT.host is the same as the # hypervisor name, which is true in many deployments, but not # always. (In nova terminology: The compute host's DEFAULT.host is # not neccessarily the same as the compute node name. We may even # have multiple compute nodes behind a compute host.) # TODO(bence romsics): This else branch can be removed when we no # longer want to support pre-Ussuri agents. hypervisors = { device: agent['host'] for device in configurations['resource_provider_bandwidths'].keys() } name2uuid = {} for name in hypervisors.values(): name2uuid[name] = self._get_rp_by_name(name=name)['uuid'] hypervisor_rps = {} for device, hypervisor in hypervisors.items(): hypervisor_rps[device] = { 'name': hypervisor, 'uuid': name2uuid[hypervisor], } hypervisor_rps=hypervisor_rps,"," agent_host_rp_uuid = self._get_rp_by_name( name=agent['host'])['uuid'] agent_host=agent['host'], agent_host_rp_uuid=agent_host_rp_uuid,",251,52
openstack%2Fneutron~stable%2Ftrain~I9b08a3a9c20b702b745b41d4885fb5120fd665ce,openstack/neutron,stable/train,I9b08a3a9c20b702b745b41d4885fb5120fd665ce,Locate RP-tree parent by hypervisor name,MERGED,2019-12-16 09:47:16.000000000,2020-01-20 02:08:04.000000000,2020-01-20 02:06:08.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 15554}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-16 09:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c975b76abe3b0cd8349e4621beb97f89865f0c0e', 'message': ""Locate RP-tree parent by hypervisor name\n\nPreviously we assumed that we can look up the resource provider (created\nby nova) to be used as the parent of the agent and physical NIC resource\nprovider tree by the name set in the config option DEFAULT.host. This\nassumption was wrong.\n\nWhile nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host\nmust match for port binding to work, the root resource provider created\nby nova does not belong to the compute host (where nova-compute runs)\nbut it belongs to the compute nodes (i.e. hypervisors). Actually there\nmay be multiple compute nodes managed by a single nova-compute (think\nof ironic). Plus the value of DEFAULT.host and the compute node's ID\nmay be different even when nova-compute manages a hypervisor on the\nsame host because of various deployment considerations. For example\nwhen tripleo does not manage the undercloud (so a libvirt hypervisor\nreturns the plain hostname), but the same tripleo enforces it's host\nnaming conventions in nova's and neutron's DEFAULT.host settings.\n\nThis change enables neutron to use the hypervisor name to locate the\nroot of the resource provider tree.\n\nWe introduce a new configuration option for\n\n(1) ovs-agent: resource_provider_hypervisors, for example:\n\n[ovs]\nbridge_mappings = physnet0:br-physnet0,...\nresource_provider_bandwidths = br-physnet0:10000000:10000000,...\nresource_provider_hypervisors = br-physnet0:hypervisor0,...\n\n(2) sriov-agent: resource_provider_hypervisors, for example:\n\n[sriov_nic]\nbridge_mappings = physnet1:ens5,...\nresource_provider_bandwidths = ens5:10000000:10000000,...\nresource_provider_hypervisors = ens5:hypervisor1,...\n\nFor both agents 'resource_provider_hypervisors' values default to\nsocket.gethostname() for each key in resource_provider_bandwidths.\n\nWe try to not block later developments in which one neutron\nagent may manage devices on multiple hosts. That's why we allow\nthe each physdev to be associated with a different hypervisor.\n\nBut here we do not try to solve the problem that the natural physdev\nidentifiers may not be unique accross multiple hosts. We leave solving\nthis problem to whoever wants to implement an agent handling devices of\nmultiple hosts.\n\n(3) We extend report_state message's configurations field alike:\n\n{\n'bridge_mappings': {'physnet0': 'br-physnet0'},\n'resource_provider_bandwidths': {\n    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},\n'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},\n...\n}\n\n(4) In neutron-server we use\nreport_state.configurations.resource_provider_hypervisors.PHYSDEV\nwhen selecting parent resource provider for agent and physdev\nRP-tree. When not available in the message we fall back to using\nreport_state.host as before.\n\nSince we only changed the free-format configurations field of the\nreport_state message rpc version is not bumped and we expect this\nchange to be backported to stein and train.\n\nRemoved unapplicable TODO note from backport.\n\nChange-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce\nCloses-Bug: #1853840\n(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)\n""}, {'number': 2, 'created': '2019-12-20 13:30:47.000000000', 'files': ['neutron/conf/plugins/ml2/drivers/mech_sriov/agent_common.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/services/placement_report/test_plugin.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py', 'neutron/tests/unit/agent/common/test_utils.py', 'neutron/agent/common/utils.py', 'neutron/conf/plugins/ml2/drivers/ovs_conf.py', 'neutron/agent/common/placement_report.py', 'releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml', 'neutron/tests/unit/agent/common/test_placement_report.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py', 'neutron/services/placement_report/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9a6766470ef127ee5495a5b74b7156bd5a80f03c', 'message': ""Locate RP-tree parent by hypervisor name\n\nPreviously we assumed that we can look up the resource provider (created\nby nova) to be used as the parent of the agent and physical NIC resource\nprovider tree by the name set in the config option DEFAULT.host. This\nassumption was wrong.\n\nWhile nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host\nmust match for port binding to work, the root resource provider created\nby nova does not belong to the compute host (where nova-compute runs)\nbut it belongs to the compute nodes (i.e. hypervisors). Actually there\nmay be multiple compute nodes managed by a single nova-compute (think\nof ironic). Plus the value of DEFAULT.host and the compute node's ID\nmay be different even when nova-compute manages a hypervisor on the\nsame host because of various deployment considerations. For example\nwhen tripleo does not manage the undercloud (so a libvirt hypervisor\nreturns the plain hostname), but the same tripleo enforces it's host\nnaming conventions in nova's and neutron's DEFAULT.host settings.\n\nThis change enables neutron to use the hypervisor name to locate the\nroot of the resource provider tree.\n\nWe introduce a new configuration option for\n\n(1) ovs-agent: resource_provider_hypervisors, for example:\n\n[ovs]\nbridge_mappings = physnet0:br-physnet0,...\nresource_provider_bandwidths = br-physnet0:10000000:10000000,...\nresource_provider_hypervisors = br-physnet0:hypervisor0,...\n\n(2) sriov-agent: resource_provider_hypervisors, for example:\n\n[sriov_nic]\nbridge_mappings = physnet1:ens5,...\nresource_provider_bandwidths = ens5:10000000:10000000,...\nresource_provider_hypervisors = ens5:hypervisor1,...\n\nFor both agents 'resource_provider_hypervisors' values default to\nsocket.gethostname() for each key in resource_provider_bandwidths.\n\nWe try to not block later developments in which one neutron\nagent may manage devices on multiple hosts. That's why we allow\nthe each physdev to be associated with a different hypervisor.\n\nBut here we do not try to solve the problem that the natural physdev\nidentifiers may not be unique accross multiple hosts. We leave solving\nthis problem to whoever wants to implement an agent handling devices of\nmultiple hosts.\n\n(3) We extend report_state message's configurations field alike:\n\n{\n'bridge_mappings': {'physnet0': 'br-physnet0'},\n'resource_provider_bandwidths': {\n    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},\n'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},\n...\n}\n\n(4) In neutron-server we use\nreport_state.configurations.resource_provider_hypervisors.PHYSDEV\nwhen selecting parent resource provider for agent and physdev\nRP-tree. When not available in the message we fall back to using\nreport_state.host as before.\n\nSince we only changed the free-format configurations field of the\nreport_state message rpc version is not bumped and we expect this\nchange to be backported to stein and train.\n\nRemoved unapplicable TODO notes from backport.\n\nChange-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce\nCloses-Bug: #1853840\n(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)\n""}]",4,699174,9a6766470ef127ee5495a5b74b7156bd5a80f03c,20,7,2,15554,,,0,"Locate RP-tree parent by hypervisor name

Previously we assumed that we can look up the resource provider (created
by nova) to be used as the parent of the agent and physical NIC resource
provider tree by the name set in the config option DEFAULT.host. This
assumption was wrong.

While nova-compute's DEFAULT.host and neutron-agent's DEFAULT.host
must match for port binding to work, the root resource provider created
by nova does not belong to the compute host (where nova-compute runs)
but it belongs to the compute nodes (i.e. hypervisors). Actually there
may be multiple compute nodes managed by a single nova-compute (think
of ironic). Plus the value of DEFAULT.host and the compute node's ID
may be different even when nova-compute manages a hypervisor on the
same host because of various deployment considerations. For example
when tripleo does not manage the undercloud (so a libvirt hypervisor
returns the plain hostname), but the same tripleo enforces it's host
naming conventions in nova's and neutron's DEFAULT.host settings.

This change enables neutron to use the hypervisor name to locate the
root of the resource provider tree.

We introduce a new configuration option for

(1) ovs-agent: resource_provider_hypervisors, for example:

[ovs]
bridge_mappings = physnet0:br-physnet0,...
resource_provider_bandwidths = br-physnet0:10000000:10000000,...
resource_provider_hypervisors = br-physnet0:hypervisor0,...

(2) sriov-agent: resource_provider_hypervisors, for example:

[sriov_nic]
bridge_mappings = physnet1:ens5,...
resource_provider_bandwidths = ens5:10000000:10000000,...
resource_provider_hypervisors = ens5:hypervisor1,...

For both agents 'resource_provider_hypervisors' values default to
socket.gethostname() for each key in resource_provider_bandwidths.

We try to not block later developments in which one neutron
agent may manage devices on multiple hosts. That's why we allow
the each physdev to be associated with a different hypervisor.

But here we do not try to solve the problem that the natural physdev
identifiers may not be unique accross multiple hosts. We leave solving
this problem to whoever wants to implement an agent handling devices of
multiple hosts.

(3) We extend report_state message's configurations field alike:

{
'bridge_mappings': {'physnet0': 'br-physnet0'},
'resource_provider_bandwidths': {
    'br-physnet0': {'egress': 10000000, 'ingress': 10000000}},
'resource_provider_hypervisors': {'br-physnet0': 'hypervisor0'},
...
}

(4) In neutron-server we use
report_state.configurations.resource_provider_hypervisors.PHYSDEV
when selecting parent resource provider for agent and physdev
RP-tree. When not available in the message we fall back to using
report_state.host as before.

Since we only changed the free-format configurations field of the
report_state message rpc version is not bumped and we expect this
change to be backported to stein and train.

Removed unapplicable TODO notes from backport.

Change-Id: I9b08a3a9c20b702b745b41d4885fb5120fd665ce
Closes-Bug: #1853840
(cherry picked from commit 258eebea71b1cac37badf429a90d5cf57e4c455c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/699174/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/conf/plugins/ml2/drivers/mech_sriov/agent_common.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/services/placement_report/test_plugin.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py', 'neutron/tests/unit/agent/common/test_utils.py', 'neutron/agent/common/utils.py', 'neutron/conf/plugins/ml2/drivers/ovs_conf.py', 'neutron/agent/common/placement_report.py', 'releasenotes/notes/locate-rp-tree-parent-by-hypervisor-name-3244ed87dc57f950.yaml', 'neutron/tests/unit/agent/common/test_placement_report.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py', 'neutron/services/placement_report/plugin.py']",12,c975b76abe3b0cd8349e4621beb97f89865f0c0e,bug/1853840," if 'resource_provider_hypervisors' in configurations: # When the agent has the fix for # https://bugs.launchpad.net/neutron/+bug/1853840 # it sends us hypervisor names (compute nodes in nova terminology). hypervisors = configurations['resource_provider_hypervisors'] else: # For older agents without the fix we have to assume the old # buggy behavior. There we assumed DEFAULT.host is the same as the # hypervisor name, which is true in many deployments, but not # always. (In nova terminology: The compute host's DEFAULT.host is # not neccessarily the same as the compute node name. We may even # have multiple compute nodes behind a compute host.) # TODO(bence romsics): This else branch can be removed when we no # longer want to support pre-Ussuri agents. hypervisors = { device: agent['host'] for device in configurations['resource_provider_bandwidths'].keys() } name2uuid = {} for name in hypervisors.values(): name2uuid[name] = self._get_rp_by_name(name=name)['uuid'] hypervisor_rps = {} for device, hypervisor in hypervisors.items(): hypervisor_rps[device] = { 'name': hypervisor, 'uuid': name2uuid[hypervisor], } hypervisor_rps=hypervisor_rps,"," agent_host_rp_uuid = self._get_rp_by_name( name=agent['host'])['uuid'] agent_host=agent['host'], agent_host_rp_uuid=agent_host_rp_uuid,",251,52
openstack%2Fstorlets~master~Id148885190bfca694e1fa00439c8a20eff3e4da4,openstack/storlets,master,Id148885190bfca694e1fa00439c8a20eff3e4da4,Raise timeout value for zuul job execution.,MERGED,2020-01-17 11:42:37.000000000,2020-01-20 01:56:00.000000000,2020-01-20 01:53:51.000000000,"[{'_account_id': 4608}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 11:42:37.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/storlets/commit/821570021bb8a2eb0795b8bc6bde0d344bbeeeab', 'message': 'Raise timeout value for zuul job execution.\n\nWe recently observe that functional tests often fail because of\ntimeout in gate.\nThis patch raises timeout from 30 min to 40 min to avoild\ntimeouts and unnecessory rechecks.\n\nChange-Id: Id148885190bfca694e1fa00439c8a20eff3e4da4\n'}]",0,703057,821570021bb8a2eb0795b8bc6bde0d344bbeeeab,7,2,1,9816,,,0,"Raise timeout value for zuul job execution.

We recently observe that functional tests often fail because of
timeout in gate.
This patch raises timeout from 30 min to 40 min to avoild
timeouts and unnecessory rechecks.

Change-Id: Id148885190bfca694e1fa00439c8a20eff3e4da4
",git fetch https://review.opendev.org/openstack/storlets refs/changes/57/703057/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,821570021bb8a2eb0795b8bc6bde0d344bbeeeab,job-timeout, timeout: 2400 timeout: 2400, timeout: 1800 timeout: 1800,2,2
openstack%2Fbifrost~master~Iae4248acec0b3bdf48be62134f64356d40375dde,openstack/bifrost,master,Iae4248acec0b3bdf48be62134f64356d40375dde,Switch to use a venv by default for testing,MERGED,2020-01-09 00:30:00.000000000,2020-01-20 01:47:06.000000000,2020-01-16 14:03:28.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-09 00:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/42300e959b4d2bfcef21940a2575ec8f242e5ddc', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 2, 'created': '2020-01-09 04:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/98b4d40fb40c8526888da5162e95012e9705ef7c', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 3, 'created': '2020-01-09 05:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5dfc5542275c7ff238ea0474f7ae0f329964cce1', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 4, 'created': '2020-01-09 16:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/7b5ff6b5e3658d4222748e65ee984eee2aa63bf4', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 5, 'created': '2020-01-09 16:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e9cc57bb803c177d765561015f0f436149b09353', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 6, 'created': '2020-01-09 17:38:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3a49a02aa41b8de4dfd146197e1ab0ceb2f69cda', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 7, 'created': '2020-01-09 22:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e76f51a30778153d539ae337eae21e0895cbf7d9', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 8, 'created': '2020-01-09 23:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/415b8f12051c09499911d9193366965f8abe202b', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 9, 'created': '2020-01-09 23:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b6825333b148911b6f0d835932360c81134dbeba', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 10, 'created': '2020-01-09 23:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1e23118984c8d41d1ac2f03a77411cfe60842d69', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 11, 'created': '2020-01-10 00:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6e2e4eea851d891dac7f49336d93a6aee6bdee1d', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 12, 'created': '2020-01-10 00:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/81aaf0b2ce9d15925c333ecee50809c751091c0a', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 13, 'created': '2020-01-10 00:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/504a7c2fce56c7558dcd21708faa9eecd6ed716e', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 14, 'created': '2020-01-10 14:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/c729157e27a816618221eba59952a230a342a7b4', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 15, 'created': '2020-01-10 15:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e5745360a603622f564d838d68eb06a30cb0a946', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 16, 'created': '2020-01-10 16:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/655bd9c467653aa59c76bd32662e0df20f2007ab', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 17, 'created': '2020-01-10 16:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/09ea44d4eebe1bbd75d3fa21a9ef33e9e9f816e3', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 18, 'created': '2020-01-10 16:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/406e85b807e7e63db2767971beaa6b1452914db8', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 19, 'created': '2020-01-10 17:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0410cab28d636a62914636a7ef4b83755daadff9', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 20, 'created': '2020-01-10 17:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/23797511f4aa300b8751617cdb5b19af6cc60f76', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 21, 'created': '2020-01-10 18:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e936ad8d63647029ea8219e8f7ceace861c250f8', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 22, 'created': '2020-01-10 19:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6f9d34d949fcc672b57983501d515137d7367bba', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 23, 'created': '2020-01-10 22:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/252af05444dfc1d7bb193f7ccb1052a0156a1b69', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 24, 'created': '2020-01-13 23:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/26d81353bded094c048f74cf5a5e3eba79174d30', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 25, 'created': '2020-01-14 14:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/38ebda6bd96847de125686023ceee3d8e6b1a4b4', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}, {'number': 26, 'created': '2020-01-15 17:18:56.000000000', 'files': ['tools/vagrant_dev_env/vagrant.yml', 'bindep.txt', 'playbooks/roles/bifrost-create-vm-nodes/tasks/prepare_libvirt.yml', 'scripts/install-deps.sh', 'playbooks/ci/run.yaml', 'playbooks/roles/bifrost-keystone-install/tasks/pip_install.yml', 'scripts/env-setup.sh', 'scripts/test-bifrost.sh', 'playbooks/roles/bifrost-ironic-install/tasks/pip_install.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/44196ea91bbb8dbd5f55bc01f1401b2c47f10f07', 'message': 'Switch to use a venv by default for testing\n\nAlso updates the method to use the python3 native\nvenv module instead of the virtualenv module.\n\nChange-Id: Iae4248acec0b3bdf48be62134f64356d40375dde\n'}]",21,701641,44196ea91bbb8dbd5f55bc01f1401b2c47f10f07,64,4,26,11655,,,0,"Switch to use a venv by default for testing

Also updates the method to use the python3 native
venv module instead of the virtualenv module.

Change-Id: Iae4248acec0b3bdf48be62134f64356d40375dde
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/41/701641/11 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'scripts/install-deps.sh', 'playbooks/roles/bifrost-keystone-install/tasks/pip_install.yml', 'scripts/env-setup.sh', 'scripts/test-bifrost.sh', 'playbooks/roles/bifrost-ironic-install/tasks/pip_install.yml']",6,42300e959b4d2bfcef21940a2575ec8f242e5ddc,700912," venv_command: ""python3 -m venv"""," venv_command: ""{{ hostvars[inventory_hostname].ansible_python.executable }} -m virtualenv""",13,11
openstack%2Fbifrost~master~Icb063d38b28887e99050cab79fff4782750fc11d,openstack/bifrost,master,Icb063d38b28887e99050cab79fff4782750fc11d,DNM? Disable IPv6 for vagrant test VM,NEW,2020-01-09 22:09:33.000000000,2020-01-20 01:45:25.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-09 22:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/38ac33a3ed840aca77d6996df9ff9eb75f15f892', 'message': ""DNM? Disable IPv6 for vagrant test VM\n\nMy local vagrant doesn't have IPv6 connectivity\nyet it gets what it thinks is a routable address.\n\nThis results in things timing out when installing,\nand generally making me grumpy... So someone might\nfind this useful.\n\nChange-Id: Icb063d38b28887e99050cab79fff4782750fc11d\n""}, {'number': 2, 'created': '2020-01-10 19:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/c35ff9ce5392c19da025552f6cef5fdc6c29fced', 'message': ""DNM? Disable IPv6 for vagrant test VM\n\nMy local vagrant doesn't have IPv6 connectivity\nyet it gets what it thinks is a routable address.\n\nThis results in things timing out when installing,\nand generally making me grumpy... So someone might\nfind this useful.\n\nChange-Id: Icb063d38b28887e99050cab79fff4782750fc11d\n""}, {'number': 3, 'created': '2020-01-20 01:33:47.000000000', 'files': ['tools/vagrant_dev_env/Vagrantfile'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b0b028856d52fb594df2f0fc221feacafbc2371f', 'message': ""DNM? Disable IPv6 for vagrant test VM\n\nMy local vagrant doesn't have IPv6 connectivity\nyet it gets what it thinks is a routable address.\n\nThis results in things timing out when installing,\nand generally making me grumpy... So someone might\nfind this useful.\n\nChange-Id: Icb063d38b28887e99050cab79fff4782750fc11d\n""}]",0,701847,b0b028856d52fb594df2f0fc221feacafbc2371f,6,1,3,11655,,,0,"DNM? Disable IPv6 for vagrant test VM

My local vagrant doesn't have IPv6 connectivity
yet it gets what it thinks is a routable address.

This results in things timing out when installing,
and generally making me grumpy... So someone might
find this useful.

Change-Id: Icb063d38b28887e99050cab79fff4782750fc11d
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/47/701847/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/vagrant_dev_env/Vagrantfile'],1,38ac33a3ed840aca77d6996df9ff9eb75f15f892,700912, sysctl net.ipv6.conf.all.disable_ipv6=1 sysctl net.ipv6.conf.default.disable_ipv6=1,,2,0
openstack%2Ftripleo-heat-templates~master~I35230c6dfd8bc7ea2c45f7d2e1e5b5f4316a9375,openstack/tripleo-heat-templates,master,I35230c6dfd8bc7ea2c45f7d2e1e5b5f4316a9375,depends_on: add .service to avoid errors in logs,MERGED,2020-01-14 03:51:36.000000000,2020-01-20 01:40:21.000000000,2020-01-15 04:28:37.000000000,"[{'_account_id': 3153}, {'_account_id': 11085}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-14 03:51:36.000000000', 'files': ['deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/neutron/neutron-l3-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/openvswitch/openvswitch-dpdk-netcontrold-container-ansible.yaml', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5bfbcd32e044e2016065eab503063af507ff979a', 'message': 'depends_on: add .service to avoid errors in logs\n\nMake sure we depends on a systemd service by having the .service in the\nservice name that we depend on.\n\nOtherwise it leads to errors in /var/log/messages:\n  Failed to add dependency on openvswitch, ignoring: Invalid argument\n\nChange-Id: I35230c6dfd8bc7ea2c45f7d2e1e5b5f4316a9375\n'}]",0,702332,5bfbcd32e044e2016065eab503063af507ff979a,12,6,1,3153,,,0,"depends_on: add .service to avoid errors in logs

Make sure we depends on a systemd service by having the .service in the
service name that we depend on.

Otherwise it leads to errors in /var/log/messages:
  Failed to add dependency on openvswitch, ignoring: Invalid argument

Change-Id: I35230c6dfd8bc7ea2c45f7d2e1e5b5f4316a9375
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/32/702332/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/neutron/neutron-l3-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/openvswitch/openvswitch-dpdk-netcontrold-container-ansible.yaml', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml']",6,5bfbcd32e044e2016065eab503063af507ff979a,wants, - openvswitch.service, - openvswitch,6,6
openstack%2Ftripleo-ansible~master~I0ce554651916f2b942dc0fd9f647d5a348042203,openstack/tripleo-ansible,master,I0ce554651916f2b942dc0fd9f647d5a348042203,Allow comments in variable files to be rendered in docs,MERGED,2020-01-08 21:54:12.000000000,2020-01-20 01:38:19.000000000,2020-01-16 05:57:20.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-08 21:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/092d298b5d0db114ee0c0a3dd766ea055db9891a', 'message': 'Allow comments in variable files to be rendered in docs\n\nThis change will allow all comments in our variable files to be rendered\nnormally within our documentation. This will allow folks reading our\ndocumentation to benifit from information we may put in the various\nfiles.\n\nChange-Id: I0ce554651916f2b942dc0fd9f647d5a348042203\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2020-01-15 17:55:02.000000000', 'files': ['doc/source/_exts/ansible-autodoc.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/d5a26bd7e7be99f7757b3f8ffbd66b437dad9344', 'message': 'Allow comments in variable files to be rendered in docs\n\nThis change will allow all comments in our variable files to be rendered\nnormally within our documentation. This will allow folks reading our\ndocumentation to benifit from information we may put in the various\nfiles.\n\nChange-Id: I0ce554651916f2b942dc0fd9f647d5a348042203\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,701631,d5a26bd7e7be99f7757b3f8ffbd66b437dad9344,13,4,2,7353,,,0,"Allow comments in variable files to be rendered in docs

This change will allow all comments in our variable files to be rendered
normally within our documentation. This will allow folks reading our
documentation to benifit from information we may put in the various
files.

Change-Id: I0ce554651916f2b942dc0fd9f647d5a348042203
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/31/701631/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/_exts/ansible-autodoc.py'],1,092d298b5d0db114ee0c0a3dd766ea055db9891a,,"from ruamel.yaml import YAML as RYAML try: import io StringIO = io.StringIO except ImportError: import StringIO class DocYaml(RYAML): def _license_filter(self, data): """"""This will filter out our boilerplate license heading in return data. The filter is used to allow documentation we're creating in variable files to be rendered more beautifully. """""" lines = list() mark = True for line in data.splitlines(): if '# Copyright' in line: mark = False if mark: lines.append(line) if '# under the License' in line: mark = True return '\n'.join(lines) def dump(self, data, stream=None, **kw): if not stream: stream = StringIO() try: RYAML.dump(self, data, stream, **kw) return self._license_filter(stream.getvalue().strip()) finally: stream.close() DOCYAML = DocYaml() DOCYAML.default_flow_style=False docs = DOCYAML.load(module.DOCUMENTATION) examples = DOCYAML.load(module.EXAMPLES) return_examples.append(DOCYAML.dump([example])) text=DOCYAML.dump(data) role_defaults = DOCYAML.load(f.read()) vars_values = DOCYAML.load(f.read()) molecule_conf = DOCYAML.load(f.read()) molecule_playbook = DOCYAML.load(f.read())"," docs = yaml.safe_load(module.DOCUMENTATION) examples = yaml.safe_load(module.EXAMPLES) return_examples.append( yaml.safe_dump([example], default_flow_style=False) ) text=yaml.safe_dump( data, default_flow_style=False ) role_defaults = yaml.safe_load(f.read()) vars_values = yaml.safe_load(f.read()) molecule_conf = yaml.safe_load(f.read()) molecule_playbook = yaml.safe_load(f.read())",47,13
openstack%2Fsenlin-dashboard~master~I369af0d8c1cddc6c89079b1a24067b8131cb8b47,openstack/senlin-dashboard,master,I369af0d8c1cddc6c89079b1a24067b8131cb8b47,Imported Translations from Zanata,MERGED,2020-01-17 09:29:34.000000000,2020-01-20 00:35:37.000000000,2020-01-20 00:33:41.000000000,"[{'_account_id': 16352}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 09:29:34.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'senlin_dashboard/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/fec9412e22c843bdbcc23606baaa3a56feeee4ee', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I369af0d8c1cddc6c89079b1a24067b8131cb8b47\n'}]",0,703042,fec9412e22c843bdbcc23606baaa3a56feeee4ee,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I369af0d8c1cddc6c89079b1a24067b8131cb8b47
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/42/703042/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'senlin_dashboard/locale/de/LC_MESSAGES/django.po']",2,fec9412e22c843bdbcc23606baaa3a56feeee4ee,zanata/translations,"# Andreas Jaeger <jaegerandi@gmail.com>, 2020. #zanata""POT-Creation-Date: 2020-01-08 15:19+0000\n""""PO-Revision-Date: 2020-01-16 04:08+0000\n""msgid ""Unable to attach policy: %s"" msgstr ""Nicht mglich Policy hinzuzufgen: %s"" #, python-formatmsgid ""Unable to retrieve receiver: %s"" msgstr ""Der Empfnger konnte nicht abgerufen werden: %s"" #, python-format msgid ""Unable to retrieve receivers: %s"" msgstr ""Die Empfnger konnten nicht abgerufen werden: %s"" #, python-format","""POT-Creation-Date: 2019-11-26 05:00+0000\n""""PO-Revision-Date: 2019-11-17 05:04+0000\n""",16,6
openstack%2Fkuryr-kubernetes~master~I09f3803edffbe2ea5f1913238adc23212a323100,openstack/kuryr-kubernetes,master,I09f3803edffbe2ea5f1913238adc23212a323100,Add requests.ConnectionError to watcher retries,MERGED,2019-11-22 15:05:53.000000000,2020-01-19 23:46:10.000000000,2020-01-19 23:44:57.000000000,"[{'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-11-22 15:05:53.000000000', 'files': ['kuryr_kubernetes/k8s_client.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/22f3030443bb4750792c91fb699b6c75ab2ff88e', 'message': ""Add requests.ConnectionError to watcher retries\n\nApparently with switch to Python 3, requests library raises a different\nexception when read time out occurrs and it's quite general\nrequests.ConnectionError. This causes tracebacks like [1] to show up in\nlogs.\n\nThis is pretty scary for the user, so this commit suppresses those exceptions\nand adds them to the list of exceptions K8sClient restarts watching.\n\n[1] http://paste.openstack.org/show/786574/\n\nChange-Id: I09f3803edffbe2ea5f1913238adc23212a323100\n""}]",4,695705,22f3030443bb4750792c91fb699b6c75ab2ff88e,24,5,1,11600,,,0,"Add requests.ConnectionError to watcher retries

Apparently with switch to Python 3, requests library raises a different
exception when read time out occurrs and it's quite general
requests.ConnectionError. This causes tracebacks like [1] to show up in
logs.

This is pretty scary for the user, so this commit suppresses those exceptions
and adds them to the list of exceptions K8sClient restarts watching.

[1] http://paste.openstack.org/show/786574/

Change-Id: I09f3803edffbe2ea5f1913238adc23212a323100
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/05/695705/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/k8s_client.py'],1,22f3030443bb4750792c91fb699b6c75ab2ff88e,catch-conn-error," except (requests.ReadTimeout, requests.ConnectionError, ssl.SSLError) as e:"," except (requests.ReadTimeout, ssl.SSLError) as e:",2,1
openstack%2Fnova~master~Ica9f217d0318fc7c2db4bcdea12d00aad749c30c,openstack/nova,master,Ica9f217d0318fc7c2db4bcdea12d00aad749c30c,Add NovaEphemeralObject class for non-persistent objects,MERGED,2020-01-10 22:07:38.000000000,2020-01-19 23:20:51.000000000,2020-01-19 23:18:59.000000000,"[{'_account_id': 4393}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-10 22:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dba23a8b83e049ba8ab91e902304e4ab2a529a21', 'message': 'Add NovaEphemeralObject class for non-persistent objects\n\nThis adds a NovaEphemeralObject class, which inherits from NovaObject\nand also from EphemeralObject. The latter is proposed against o.vo,\nand is copied here for expediency.\n\nIn the past, all of our objects were representations of rows of columns\nin the database and thus it was very important to not default fields\nin objects when working on a record remotely that may have values in\nthe database for those fields which we did not wish to overwrite. Lately,\nwe have a lot of objects that are used purely over RPC, or which are stored\nin the database as a blob and for which the explicit defaulting nature\nis annoying. This is an attempt to classify such objects in a single\nhierarchy and allow them to behave differently.\n\nWe already have some objects in the tree which do their own defaulting\nin __init__, against what should be our policy. Some of those can be\nmade to inherit from the new class and continue, while others need to\nbe fixed. This patch adds a test to ensure that things comply with the\npolicy henceforth.\n\nSpecific object changes are:\n\n- Diagnostics: Not persisted, can be converted to ephemeral\n- InstanceNUMACell: Stored as a blob, can be converted to ephemeral.\n                    Removes a test that asserted no dirty fields left\n                    after init, but for no reason and not compatible\n                    with the base class.\n- PCIDevice: Persited row-based, so cannot be ephemeral. Converts it\n             to set default for the one field on lazy-load\n- Quotas, QuotasNoOp: Stored row-based, so cannot be ephemeral.\n                      Converts it to set default on lazy-load,\n                      and persists the resetting of dirty fields for\n                      compatibility with what is there (even though it\n                      is probably not needed).\n- RequestGroup: Not persisted, can be converted to ephemeral.\n- Service: Does defaulting in init, but specifically because we *want*\n           to always overwrite what is in the database on save. This is\n           part of how service version works to always know the version of\n           compute (et al) services once they start up.\n\nFor the objects that were converted to Ephemeral, hashes changed but only\nbecause the inheritance did, so no need to bump the version, just update\nthe hash.\n\nChange-Id: Ica9f217d0318fc7c2db4bcdea12d00aad749c30c\n'}, {'number': 2, 'created': '2020-01-10 22:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5c9ab878632aaf3daf1f40398774d1160e47088', 'message': 'Add NovaEphemeralObject class for non-persistent objects\n\nThis adds a NovaEphemeralObject class, which inherits from NovaObject\nand also from EphemeralObject. The latter is proposed against o.vo,\nand is copied here for expediency.\n\nIn the past, all of our objects were representations of rows of columns\nin the database and thus it was very important to not default fields\nin objects when working on a record remotely that may have values in\nthe database for those fields which we did not wish to overwrite. Lately,\nwe have a lot of objects that are used purely over RPC, or which are stored\nin the database as a blob and for which the explicit defaulting nature\nis annoying. This is an attempt to classify such objects in a single\nhierarchy and allow them to behave differently.\n\nWe already have some objects in the tree which do their own defaulting\nin __init__, against what should be our policy. Some of those can be\nmade to inherit from the new class and continue, while others need to\nbe fixed. This patch adds a test to ensure that things comply with the\npolicy henceforth.\n\nSpecific object changes are:\n\n- Diagnostics: Not persisted, can be converted to ephemeral\n- InstanceNUMACell: Stored as a blob, can be converted to ephemeral.\n                    Removes a test that asserted no dirty fields left\n                    after init, but for no reason and not compatible\n                    with the base class.\n- PCIDevice: Persited row-based, so cannot be ephemeral. Converts it\n             to set default for the one field on lazy-load\n- Quotas, QuotasNoOp: Stored row-based, so cannot be ephemeral.\n                      Converts it to set default on lazy-load,\n                      and persists the resetting of dirty fields for\n                      compatibility with what is there (even though it\n                      is probably not needed).\n- RequestGroup: Not persisted, can be converted to ephemeral.\n- Service: Does defaulting in init, but specifically because we *want*\n           to always overwrite what is in the database on save. This is\n           part of how service version works to always know the version of\n           compute (et al) services once they start up.\n\nFor the objects that were converted to Ephemeral, hashes changed but only\nbecause the inheritance did, so no need to bump the version, just update\nthe hash.\n\nChange-Id: Ica9f217d0318fc7c2db4bcdea12d00aad749c30c\n'}, {'number': 3, 'created': '2020-01-13 20:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1261980d52b5d0bb1825d83accbcd5fa339ebd95', 'message': 'Add NovaEphemeralObject class for non-persistent objects\n\nThis adds a NovaEphemeralObject class, which inherits from NovaObject\nand also from EphemeralObject. The latter is proposed against o.vo,\nand is copied here for expediency.\n\nIn the past, all of our objects were representations of rows of columns\nin the database and thus it was very important to not default fields\nin objects when working on a record remotely that may have values in\nthe database for those fields which we did not wish to overwrite. Lately,\nwe have a lot of objects that are used purely over RPC, or which are stored\nin the database as a blob and for which the explicit defaulting nature\nis annoying. This is an attempt to classify such objects in a single\nhierarchy and allow them to behave differently.\n\nWe already have some objects in the tree which do their own defaulting\nin __init__, against what should be our policy. Some of those can be\nmade to inherit from the new class and continue, while others need to\nbe fixed. This patch adds a test to ensure that things comply with the\npolicy henceforth.\n\nSpecific object changes are:\n\n- Diagnostics: Not persisted, can be converted to ephemeral\n- InstanceNUMACell: Stored as a blob, can be converted to ephemeral.\n                    Removes a test that asserted no dirty fields left\n                    after init, but for no reason and not compatible\n                    with the base class.\n- PCIDevice: Persited row-based, so cannot be ephemeral. Converts it\n             to set default for the one field on lazy-load\n- Quotas, QuotasNoOp: Stored row-based, so cannot be ephemeral.\n                      Converts it to set default on lazy-load,\n                      and persists the resetting of dirty fields for\n                      compatibility with what is there (even though it\n                      is probably not needed).\n- RequestGroup: Not persisted, can be converted to ephemeral.\n- Service: Does defaulting in init, but specifically because we *want*\n           to always overwrite what is in the database on save. This is\n           part of how service version works to always know the version of\n           compute (et al) services once they start up.\n\nFor the objects that were converted to Ephemeral, hashes changed but only\nbecause the inheritance did, so no need to bump the version, just update\nthe hash.\n\nChange-Id: Ica9f217d0318fc7c2db4bcdea12d00aad749c30c\n'}, {'number': 4, 'created': '2020-01-14 16:14:45.000000000', 'files': ['nova/objects/base.py', 'nova/objects/pci_device.py', 'nova/objects/request_spec.py', 'nova/tests/unit/objects/test_objects.py', 'nova/objects/diagnostics.py', 'nova/tests/unit/objects/test_instance_numa.py', 'nova/objects/instance_numa.py', 'nova/objects/quotas.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c2ba0ef21e60474d48733b4869b54327bcb413e3', 'message': 'Add NovaEphemeralObject class for non-persistent objects\n\nThis adds a NovaEphemeralObject class, which inherits from NovaObject\nand also from EphemeralObject. The latter is proposed against o.vo,\nand is copied here for expediency.\n\nIn the past, all of our objects were representations of rows of columns\nin the database and thus it was very important to not default fields\nin objects when working on a record remotely that may have values in\nthe database for those fields which we did not wish to overwrite. Lately,\nwe have a lot of objects that are used purely over RPC, or which are stored\nin the database as a blob and for which the explicit defaulting nature\nis annoying. This is an attempt to classify such objects in a single\nhierarchy and allow them to behave differently.\n\nWe already have some objects in the tree which do their own defaulting\nin __init__, against what should be our policy. Some of those can be\nmade to inherit from the new class and continue, while others need to\nbe fixed. This patch adds a test to ensure that things comply with the\npolicy henceforth. Objects that had to be changed in the same patch as\nthe test are fixed here.\n\nSpecific object changes are:\n\n- Diagnostics: Not persisted, can be converted to ephemeral\n- InstanceNUMACell: Stored as a blob, can be converted to ephemeral.\n                    Removes a test that asserted no dirty fields left\n                    after init, but for no reason and not compatible\n                    with the base class.\n- PCIDevice: Persited row-based, so cannot be ephemeral. Converts it\n             to set default for the one field on lazy-load\n- Quotas, QuotasNoOp: Stored row-based, so cannot be ephemeral.\n                      Converts it to set default on lazy-load,\n                      and persists the resetting of dirty fields for\n                      compatibility with what is there (even though it\n                      is probably not needed).\n- RequestGroup: Not persisted, can be converted to ephemeral.\n- Service: Does defaulting in init, but specifically because we *want*\n           to always overwrite what is in the database on save. This is\n           part of how service version works to always know the version of\n           compute (et al) services once they start up.\n\nFor the objects that were converted to Ephemeral, some hashes changed but\nonly because defaults were added, so no need to bump the version, just update\nthe hash. The hash checker is trying to make sure we bump the version when\nnecessary, but in this case, a default does not affect RPC or object behavior\nin an incompatible way, so no bump is needed.\n\nChange-Id: Ica9f217d0318fc7c2db4bcdea12d00aad749c30c\n'}]",36,702049,c2ba0ef21e60474d48733b4869b54327bcb413e3,63,13,4,4393,,,0,"Add NovaEphemeralObject class for non-persistent objects

This adds a NovaEphemeralObject class, which inherits from NovaObject
and also from EphemeralObject. The latter is proposed against o.vo,
and is copied here for expediency.

In the past, all of our objects were representations of rows of columns
in the database and thus it was very important to not default fields
in objects when working on a record remotely that may have values in
the database for those fields which we did not wish to overwrite. Lately,
we have a lot of objects that are used purely over RPC, or which are stored
in the database as a blob and for which the explicit defaulting nature
is annoying. This is an attempt to classify such objects in a single
hierarchy and allow them to behave differently.

We already have some objects in the tree which do their own defaulting
in __init__, against what should be our policy. Some of those can be
made to inherit from the new class and continue, while others need to
be fixed. This patch adds a test to ensure that things comply with the
policy henceforth. Objects that had to be changed in the same patch as
the test are fixed here.

Specific object changes are:

- Diagnostics: Not persisted, can be converted to ephemeral
- InstanceNUMACell: Stored as a blob, can be converted to ephemeral.
                    Removes a test that asserted no dirty fields left
                    after init, but for no reason and not compatible
                    with the base class.
- PCIDevice: Persited row-based, so cannot be ephemeral. Converts it
             to set default for the one field on lazy-load
- Quotas, QuotasNoOp: Stored row-based, so cannot be ephemeral.
                      Converts it to set default on lazy-load,
                      and persists the resetting of dirty fields for
                      compatibility with what is there (even though it
                      is probably not needed).
- RequestGroup: Not persisted, can be converted to ephemeral.
- Service: Does defaulting in init, but specifically because we *want*
           to always overwrite what is in the database on save. This is
           part of how service version works to always know the version of
           compute (et al) services once they start up.

For the objects that were converted to Ephemeral, some hashes changed but
only because defaults were added, so no need to bump the version, just update
the hash. The hash checker is trying to make sure we bump the version when
necessary, but in this case, a default does not affect RPC or object behavior
in an incompatible way, so no bump is needed.

Change-Id: Ica9f217d0318fc7c2db4bcdea12d00aad749c30c
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/702049/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/objects/pci_device.py', 'nova/objects/request_spec.py', 'nova/tests/unit/objects/test_objects.py', 'nova/objects/diagnostics.py', 'nova/tests/unit/objects/test_instance_numa.py', 'nova/objects/instance_numa.py', 'nova/objects/quotas.py']",8,dba23a8b83e049ba8ab91e902304e4ab2a529a21,ephemeral-object," 'reservations': fields.ListOfStringsField(nullable=True, default=[]), 'project_id': fields.StringField(nullable=True, default=None), 'user_id': fields.StringField(nullable=True, default=None), } def obj_load_attr(self, attr): self.obj_set_defaults(attr) # NOTE(danms): This is strange because resetting these would cause # them not to be saved to the database. I would imagine this is # from overzealous defaulting and that all three fields ultimately # get set all the time. However, quotas are weird, so replicate the # longstanding behavior of setting defaults and clearing their # dirty bit. self.obj_reset_changes(fields=[attr])"," 'reservations': fields.ListOfStringsField(nullable=True), 'project_id': fields.StringField(nullable=True), 'user_id': fields.StringField(nullable=True), } def __init__(self, *args, **kwargs): super(Quotas, self).__init__(*args, **kwargs) # Set up defaults. self.reservations = [] self.project_id = None self.user_id = None self.obj_reset_changes()",141,51
openstack%2Fnova~stable%2Fpike~I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a,openstack/nova,stable/pike,I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a,Error out interrupted builds,MERGED,2019-10-10 14:36:37.000000000,2020-01-19 23:19:04.000000000,2020-01-19 23:19:04.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-10 14:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d61d19775c6d394fd773031d6cf0888cfe31bfb', 'message': 'Error out interrupted builds\n\nIf the compute service is restarted while build requests are\nexecuting the instance_claim or waiting for the COMPUTE_RESOURCE_SEMAPHORE\nthen those instances will be stuck forever in BUILDING state. If the instance\nalready finished instance_claim then instance.host is set and when the\ncompute restarts the instance is put to ERROR state.\n\nThis patch changes compute service startup to put instances into\nERROR state if they a) are in the BUILDING state, and b) have\nallocations on the compute resource provider, but c) do not have\ninstance.host set to that compute.\n\nConflicts:\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/compute/manager.py\n\nConflict due to Ia1b3ab0b66fdaf569f6c7a09510f208ee28725b2 and\nI020e7dc47efc79f8907b7bfb753ec779a8da69a1 is not in stable/rocky\n\nstable/pike: compute/manager.py change is due to\nI7891b98f225f97ad47f189afb9110ef31c810717 is missing from stable/pike\n\nChange-Id: I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a\nCloses-Bug: #1833581\n(cherry picked from commit a1a735bc6efa40d8277c9fc5339f3b74f968b58e)\n(cherry picked from commit 06fd7c730172190d7bf7d52bc9062eecba8d7d27)\n(cherry picked from commit cb951cbcb246221e04a063cd7b5ae2e83ddfe6dd)\n(cherry picked from commit 80ffcfae3a9fefb3f8b7181907bfeed5566974e0)\n(cherry picked from commit ded463cf9544c2ed167676da077df373e2b38d80)\n'}, {'number': 2, 'created': '2019-10-11 11:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9966baa6e76c14f8559b2ce472266477447eec89', 'message': 'Error out interrupted builds\n\nIf the compute service is restarted while build requests are\nexecuting the instance_claim or waiting for the COMPUTE_RESOURCE_SEMAPHORE\nthen those instances will be stuck forever in BUILDING state. If the instance\nalready finished instance_claim then instance.host is set and when the\ncompute restarts the instance is put to ERROR state.\n\nThis patch changes compute service startup to put instances into\nERROR state if they a) are in the BUILDING state, and b) have\nallocations on the compute resource provider, but c) do not have\ninstance.host set to that compute.\n\nConflicts:\n      nova/tests/unit/compute/test_compute_mgr.py\n      nova/compute/manager.py\n\nConflict due to Ia1b3ab0b66fdaf569f6c7a09510f208ee28725b2 and\nI020e7dc47efc79f8907b7bfb753ec779a8da69a1 is not in stable/rocky\n\nstable/pike:\n* the signature change of the get_allocations_for_resource_provider\ncall is due to I7891b98f225f97ad47f189afb9110ef31c810717 is missing from\nstable/pike.\n* the VirtDriverNotReady exception does not exists in pike as\nIb0ec1012b74e9a9e74c8879f3feed5f9332b711f is missing. In pike ironic\nreturns an empty node list instead of raising an exception so the bugfix\nand the test is adapted accordingly.\n\nChange-Id: I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a\nCloses-Bug: #1833581\n(cherry picked from commit a1a735bc6efa40d8277c9fc5339f3b74f968b58e)\n(cherry picked from commit 06fd7c730172190d7bf7d52bc9062eecba8d7d27)\n(cherry picked from commit cb951cbcb246221e04a063cd7b5ae2e83ddfe6dd)\n(cherry picked from commit 80ffcfae3a9fefb3f8b7181907bfeed5566974e0)\n(cherry picked from commit ded463cf9544c2ed167676da077df373e2b38d80)\n'}, {'number': 3, 'created': '2019-11-13 17:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5c9a657cc3458cc7fbaed8588bc70c405fa2ed4', 'message': 'Error out interrupted builds\n\nIf the compute service is restarted while build requests are\nexecuting the instance_claim or waiting for the COMPUTE_RESOURCE_SEMAPHORE\nthen those instances will be stuck forever in BUILDING state. If the instance\nalready finished instance_claim then instance.host is set and when the\ncompute restarts the instance is put to ERROR state.\n\nThis patch changes compute service startup to put instances into\nERROR state if they a) are in the BUILDING state, and b) have\nallocations on the compute resource provider, but c) do not have\ninstance.host set to that compute.\n\nNote: changes in manager.py and test_compute_mgr.py compared to Queens:\n* the signature change of the get_allocations_for_resource_provider\n  call is due to I7891b98f225f97ad47f189afb9110ef31c810717 is missing from\n  stable/pike.\n* the VirtDriverNotReady exception does not exists in pike as\n  Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f is missing. In pike ironic\n  returns an empty node list instead of raising an exception so the bugfix\n  and the test is adapted accordingly.\n\nChange-Id: I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a\nCloses-Bug: #1833581\n(cherry picked from commit a1a735bc6efa40d8277c9fc5339f3b74f968b58e)\n(cherry picked from commit 06fd7c730172190d7bf7d52bc9062eecba8d7d27)\n(cherry picked from commit cb951cbcb246221e04a063cd7b5ae2e83ddfe6dd)\n(cherry picked from commit 13bb7ed701121955ba015103c2e44429927e78d4)\n(cherry picked from commit 4164b96de9f62fdc35a12adf514d767460187d55)\n'}, {'number': 4, 'created': '2019-12-17 20:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/35f2823610a9a2e269439779c9bc22efa16cd8c8', 'message': 'Error out interrupted builds\n\nIf the compute service is restarted while build requests are\nexecuting the instance_claim or waiting for the COMPUTE_RESOURCE_SEMAPHORE\nthen those instances will be stuck forever in BUILDING state. If the instance\nalready finished instance_claim then instance.host is set and when the\ncompute restarts the instance is put to ERROR state.\n\nThis patch changes compute service startup to put instances into\nERROR state if they a) are in the BUILDING state, and b) have\nallocations on the compute resource provider, but c) do not have\ninstance.host set to that compute.\n\nNote: changes in manager.py and test_compute_mgr.py compared to Queens:\n* the signature change of the get_allocations_for_resource_provider\n  call is due to I7891b98f225f97ad47f189afb9110ef31c810717 is missing from\n  stable/pike.\n* the VirtDriverNotReady exception does not exists in pike as\n  Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f is missing. In pike ironic\n  returns an empty node list instead of raising an exception so the bugfix\n  and the test is adapted accordingly.\n\nChange-Id: I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a\nCloses-Bug: #1833581\n(cherry picked from commit a1a735bc6efa40d8277c9fc5339f3b74f968b58e)\n(cherry picked from commit 06fd7c730172190d7bf7d52bc9062eecba8d7d27)\n(cherry picked from commit cb951cbcb246221e04a063cd7b5ae2e83ddfe6dd)\n(cherry picked from commit 13bb7ed701121955ba015103c2e44429927e78d4)\n(cherry picked from commit 4164b96de9f62fdc35a12adf514d767460187d55)\n'}, {'number': 5, 'created': '2020-01-16 16:06:11.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/tests/functional/compute/test_init_host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e5892ed61b5f4f4f581384e245d5052e7bf840b2', 'message': 'Error out interrupted builds\n\nIf the compute service is restarted while build requests are\nexecuting the instance_claim or waiting for the COMPUTE_RESOURCE_SEMAPHORE\nthen those instances will be stuck forever in BUILDING state. If the instance\nalready finished instance_claim then instance.host is set and when the\ncompute restarts the instance is put to ERROR state.\n\nThis patch changes compute service startup to put instances into\nERROR state if they a) are in the BUILDING state, and b) have\nallocations on the compute resource provider, but c) do not have\ninstance.host set to that compute.\n\nNote: changes in manager.py and test_compute_mgr.py compared to Queens:\n* the signature change of the get_allocations_for_resource_provider\n  call is due to I7891b98f225f97ad47f189afb9110ef31c810717 is missing from\n  stable/pike.\n* the VirtDriverNotReady exception does not exists in pike as\n  Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f is missing. In pike ironic\n  returns an empty node list instead of raising an exception so the bugfix\n  and the test is adapted accordingly.\n\nChange-Id: I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a\nCloses-Bug: #1833581\n(cherry picked from commit a1a735bc6efa40d8277c9fc5339f3b74f968b58e)\n(cherry picked from commit 06fd7c730172190d7bf7d52bc9062eecba8d7d27)\n(cherry picked from commit cb951cbcb246221e04a063cd7b5ae2e83ddfe6dd)\n(cherry picked from commit 13bb7ed701121955ba015103c2e44429927e78d4)\n(cherry picked from commit 4164b96de9f62fdc35a12adf514d767460187d55)\n'}]",4,687918,e5892ed61b5f4f4f581384e245d5052e7bf840b2,57,13,5,9708,,,0,"Error out interrupted builds

If the compute service is restarted while build requests are
executing the instance_claim or waiting for the COMPUTE_RESOURCE_SEMAPHORE
then those instances will be stuck forever in BUILDING state. If the instance
already finished instance_claim then instance.host is set and when the
compute restarts the instance is put to ERROR state.

This patch changes compute service startup to put instances into
ERROR state if they a) are in the BUILDING state, and b) have
allocations on the compute resource provider, but c) do not have
instance.host set to that compute.

Note: changes in manager.py and test_compute_mgr.py compared to Queens:
* the signature change of the get_allocations_for_resource_provider
  call is due to I7891b98f225f97ad47f189afb9110ef31c810717 is missing from
  stable/pike.
* the VirtDriverNotReady exception does not exists in pike as
  Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f is missing. In pike ironic
  returns an empty node list instead of raising an exception so the bugfix
  and the test is adapted accordingly.

Change-Id: I856a3032c83fc2f605d8c9b6e5aa3bcfa415f96a
Closes-Bug: #1833581
(cherry picked from commit a1a735bc6efa40d8277c9fc5339f3b74f968b58e)
(cherry picked from commit 06fd7c730172190d7bf7d52bc9062eecba8d7d27)
(cherry picked from commit cb951cbcb246221e04a063cd7b5ae2e83ddfe6dd)
(cherry picked from commit 13bb7ed701121955ba015103c2e44429927e78d4)
(cherry picked from commit 4164b96de9f62fdc35a12adf514d767460187d55)
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/687918/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/tests/functional/compute/test_init_host.py']",3,6d61d19775c6d394fd773031d6cf0888cfe31bfb,bug/1833581," with mock.patch('nova.compute.manager.LOG.debug') as mock_log: self.restart_compute_service(self.compute1) self._wait_for_state_change(self.admin_api, server, 'ERROR') mock_log.assert_called_with( 'Instance spawn was interrupted before instance_claim, setting ' 'instance to ERROR state', instance=mock.ANY)"," self.restart_compute_service(self.compute1) # This is bug 1833581 as the server remains in BUILD state after the # compute restart. self._wait_for_state_change(self.admin_api, server, 'BUILD') # Not even the periodic task push this server to ERROR because the # server host is still None since the instance_claim didn't set it. self.flags(instance_build_timeout=1) self.compute1.manager._check_instance_build_time( nova_context.get_admin_context()) server = self.admin_api.get_server(server['id']) self.assertEqual('BUILD', server['status']) self.assertIsNone(server['OS-EXT-SRV-ATTR:host']) # self._wait_for_state_change(self.admin_api, server, 'ERROR')",278,27
openstack%2Fzun~master~I2e1a20b47fec5af1f4977148431e1135abd49812,openstack/zun,master,I2e1a20b47fec5af1f4977148431e1135abd49812,Add python CRI client,MERGED,2020-01-12 18:18:01.000000000,2020-01-19 22:57:16.000000000,2020-01-19 22:55:53.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-12 18:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/999c63d6707cf72a3c9de49d469c1e17b1ae4c7c', 'message': 'Add python CRI client\n\nThis commit introduce the python-binding for iteracting with\nCRI runtime via GRPC.\nThe client code is generated by protocol buffer [1] by using api.proto\nin kubernetes/cri-api repo.\n\n[1] https://developers.google.com/protocol-buffers/docs/pythontutorial\n\nChange-Id: I2e1a20b47fec5af1f4977148431e1135abd49812\n'}, {'number': 2, 'created': '2020-01-12 18:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/e924b7a2ff111eea2558bffffb598048d3b49f96', 'message': 'Add python CRI client\n\nThis commit introduce the python-binding for iteracting with\nCRI runtime via GRPC.\nThe client code is generated by protocol buffer [1] by using api.proto\nin kubernetes/cri-api repo.\n\n[1] https://developers.google.com/protocol-buffers/docs/pythontutorial\n\nChange-Id: I2e1a20b47fec5af1f4977148431e1135abd49812\n'}, {'number': 3, 'created': '2020-01-12 18:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c35fb8346e0844bed0e8ce5ad369af6570bfb80c', 'message': 'Add python CRI client\n\nThis commit introduce the python-binding for iteracting with\nCRI runtime via GRPC.\nThe client code is generated by protocol buffer [1] by using api.proto\nin kubernetes/cri-api repo.\n\n[1] https://developers.google.com/protocol-buffers/docs/pythontutorial\n\nChange-Id: I2e1a20b47fec5af1f4977148431e1135abd49812\n'}, {'number': 4, 'created': '2020-01-12 18:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/6ddd721d8c3a7d0aa7878ac38989964f819441e6', 'message': 'Add python CRI client\n\nThis commit introduce the python-binding for iteracting with\nCRI runtime via GRPC.\nThe client code is generated by protocol buffer [1] by using api.proto\nin kubernetes/cri-api repo.\n\n[1] https://developers.google.com/protocol-buffers/docs/pythontutorial\n\nImplements: blueprint add-support-cri-runtime\nChange-Id: I2e1a20b47fec5af1f4977148431e1135abd49812\n'}, {'number': 5, 'created': '2020-01-18 20:37:13.000000000', 'files': ['zun/criapi/api_pb2.py', 'zun/criapi/gogo_pb2.py', 'requirements.txt', 'zun/criapi/api_pb2_grpc.py', 'tools/gen-criapi', 'lower-constraints.txt', 'tools/flake8wrap.sh', 'zun/criapi/__init__.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/7c7ee59026c38a4aa0761a24ab91669085a639ff', 'message': ""Add python CRI client\n\nThis commit introduce the python-binding for iteracting with\nCRI runtime via GRPC.\nThe client code is generated by protocol buffer [1] by using api.proto\nin kubernetes/cri-api repo.\n\nThe generated CRI client code couldn't pass the pep8 check so this\ncommit also configure flake8 to skip the zun/criapi directory.\n\n[1] https://developers.google.com/protocol-buffers/docs/pythontutorial\n\nImplements: blueprint add-support-cri-runtime\nChange-Id: I2e1a20b47fec5af1f4977148431e1135abd49812\n""}]",0,702137,7c7ee59026c38a4aa0761a24ab91669085a639ff,14,2,5,11536,,,0,"Add python CRI client

This commit introduce the python-binding for iteracting with
CRI runtime via GRPC.
The client code is generated by protocol buffer [1] by using api.proto
in kubernetes/cri-api repo.

The generated CRI client code couldn't pass the pep8 check so this
commit also configure flake8 to skip the zun/criapi directory.

[1] https://developers.google.com/protocol-buffers/docs/pythontutorial

Implements: blueprint add-support-cri-runtime
Change-Id: I2e1a20b47fec5af1f4977148431e1135abd49812
",git fetch https://review.opendev.org/openstack/zun refs/changes/37/702137/3 && git format-patch -1 --stdout FETCH_HEAD,"['zun/criapi/api_pb2.py', 'zun/criapi/gogo_pb2.py', 'zun/container/cri/driver.py', 'tools/gen-criapi', 'zun/criapi/api_pb2_grpc.py', 'zun/criapi/__init__.py']",6,999c63d6707cf72a3c9de49d469c1e17b1ae4c7c,,,,8270,2
openstack%2Fcharm-watcher~master~Id09cbce851dcc6be9e452b5c0ea82c24673404d8,openstack/charm-watcher,master,Id09cbce851dcc6be9e452b5c0ea82c24673404d8,Basic functional test for bionic train,MERGED,2020-01-17 20:52:15.000000000,2020-01-19 20:51:41.000000000,2020-01-19 20:51:41.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 20:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-watcher/commit/6e38325bdbcb076c5d097562b5643900afcbdb9d', 'message': 'Basic functional test for bionic train\n\nThis patch adds a bare minimum bundle.yaml for deploying watcher\ncharm and running a noop basic test.\n\nChange-Id: Id09cbce851dcc6be9e452b5c0ea82c24673404d8\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}, {'number': 2, 'created': '2020-01-18 18:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-watcher/commit/5a1c83156a76514a18b0d2477d819496346d8da6', 'message': 'Basic functional test for bionic train\n\nThis patch adds a bare minimum bundle.yaml for deploying watcher\ncharm and running a noop basic test.\n\nChange-Id: Id09cbce851dcc6be9e452b5c0ea82c24673404d8\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}, {'number': 3, 'created': '2020-01-18 20:30:23.000000000', 'files': ['src/lib/charm/openstack/watcher.py', 'src/tests/tests.yaml', 'src/tests/bundles/bionic-train.yaml'], 'web_link': 'https://opendev.org/openstack/charm-watcher/commit/48027a822a2353e228fd4d6be2bf9ff5761ea490', 'message': 'Basic functional test for bionic train\n\nThis patch adds a bare minimum bundle.yaml for deploying watcher\ncharm and running a noop basic test.\n\nChange-Id: Id09cbce851dcc6be9e452b5c0ea82c24673404d8\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}]",0,703194,48027a822a2353e228fd4d6be2bf9ff5761ea490,14,4,3,28014,,,0,"Basic functional test for bionic train

This patch adds a bare minimum bundle.yaml for deploying watcher
charm and running a noop basic test.

Change-Id: Id09cbce851dcc6be9e452b5c0ea82c24673404d8
Signed-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>
",git fetch https://review.opendev.org/openstack/charm-watcher refs/changes/94/703194/3 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/tests.yaml', 'src/tests/bundles/bionic-train.yaml']",2,6e38325bdbcb076c5d097562b5643900afcbdb9d,,"series: bionic relations: - - mysql:shared-db - keystone:shared-db - - mysql:shared-db - watcher:shared-db - - keystone:identity-service - watcher:identity-service - - rabbitmq-server:amqp - watcher:amqp applications: keystone: charm: cs:~openstack-charmers-next/keystone num_units: 1 options: openstack-origin: cloud:bionic-train mysql: constraints: mem=3072M charm: cs:~openstack-charmers-next/percona-cluster num_units: 1 rabbitmq-server: charm: cs:~openstack-charmers-next/rabbitmq-server num_units: 1 watcher: series: bionic charm: ../../../watcher num_units: 1 options: openstack-origin: cloud:bionic-train datasources: gnocchi planner: weight planner-config: | { weights: change_node_power_state:9,change_nova_service_state:50,migrate:30,nop:70,resize:20,sleep:40,turn_host_to_acpi_s3_state:10,volume_migrate:60 parallelization: change_node_power_state:2,change_nova_service_state:1,migrate:2,nop:1,resize:2,sleep:1,turn_host_to_acpi_s3_state:2,volume_migrate:2 } ",,45,0
openstack%2Fzun~master~Id43690767c9e980b603a5fbe2a0d0695684f4c9a,openstack/zun,master,Id43690767c9e980b603a5fbe2a0d0695684f4c9a,[WIP] Refactor container driver,ABANDONED,2020-01-19 02:41:02.000000000,2020-01-19 20:16:19.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-19 02:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c62cb009ae019ca6b5e776ba7821a89282aa4d65', 'message': '[WIP] Refactor container driver\n\nChange-Id: Id43690767c9e980b603a5fbe2a0d0695684f4c9a\n'}, {'number': 2, 'created': '2020-01-19 05:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c4f7f4a7ce42511f6be600b5cdb4756f810465a5', 'message': '[WIP] Refactor container driver\n\nChange-Id: Id43690767c9e980b603a5fbe2a0d0695684f4c9a\n'}, {'number': 3, 'created': '2020-01-19 05:31:55.000000000', 'files': ['zun/container/driver.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/52f625ce2e3d8c424201d52196820012fa95cfac', 'message': '[WIP] Refactor container driver\n\nChange-Id: Id43690767c9e980b603a5fbe2a0d0695684f4c9a\n'}]",0,703273,52f625ce2e3d8c424201d52196820012fa95cfac,6,1,3,11536,,,0,"[WIP] Refactor container driver

Change-Id: Id43690767c9e980b603a5fbe2a0d0695684f4c9a
",git fetch https://review.opendev.org/openstack/zun refs/changes/73/703273/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/container/driver.py'],1,c62cb009ae019ca6b5e776ba7821a89282aa4d65,,"from zun.volume import driver as vol_driverdef load_capsule_driver(): driver = stevedore_driver.DriverManager( ""zun.capsule.driver"", CONF.capsule_driver, invoke_on_load=True).driver if not isinstance(driver, ContainerDriver): raise Exception(_('Expected driver of type: %s') % str(ContainerDriver)) return driver class BaseDriver(object): """"""Base class for drivers."""""" def __init__(self): self.volume_drivers = {} for driver_name in CONF.volume.driver_list: driver = vol_driver.driver(driver_name) self.volume_drivers[driver_name] = driver return numa_topo_obj def get_pci_resources(self): return os_capability_linux.LinuxHost().get_pci_resources() def _get_volume_driver(self, volume_mapping): driver_name = volume_mapping.volume_provider driver = self.volume_drivers.get(driver_name) if not driver: msg = _(""The volume provider '%s' is not supported"") % driver_name raise exception.ZunException(msg) return driver def attach_volume(self, context, volume_mapping): volume_driver = self._get_volume_driver(volume_mapping) volume_driver.attach(context, volume_mapping) def detach_volume(self, context, volume_mapping): volume_driver = self._get_volume_driver(volume_mapping) volume_driver.detach(context, volume_mapping) def delete_volume(self, context, volume_mapping): volume_driver = self._get_volume_driver(volume_mapping) volume_driver.delete(context, volume_mapping) def is_volume_available(self, context, volume_mapping): volume_driver = self._get_volume_driver(volume_mapping) return volume_driver.is_volume_available(context, volume_mapping) def is_volume_deleted(self, context, volume_mapping): volume_driver = self._get_volume_driver(volume_mapping) return volume_driver.is_volume_deleted(context, volume_mapping) def get_available_resources(self): """"""Retrieve resource information. This method is called when zun-compute launches, and as part of a periodic task that records the results in the DB. :returns: dictionary containing resource info """""" #TODO data = {} numa_topo_obj = self.get_host_numa_topology() data['numa_topology'] = numa_topo_obj meminfo = self.get_host_mem() (mem_total, mem_free, mem_ava, mem_used) = meminfo data['mem_total'] = mem_total // units.Ki data['mem_free'] = mem_free // units.Ki data['mem_available'] = mem_ava // units.Ki data['mem_used'] = mem_used // units.Ki info = self.get_host_info() data['total_containers'] = info['total_containers'] data['running_containers'] = info['running_containers'] data['paused_containers'] = info['paused_containers'] data['stopped_containers'] = info['stopped_containers'] data['cpus'] = info['cpus'] data['architecture'] = info['architecture'] data['os_type'] = info['os_type'] data['os'] = info['os'] data['kernel_version'] = info['kernel_version'] data['labels'] = info['labels'] disk_total, disk_reserved = self.get_total_disk_for_container() data['disk_total'] = disk_total - disk_reserved disk_quota_supported = self.node_support_disk_quota() data['disk_quota_supported'] = disk_quota_supported data['runtimes'] = info['runtimes'] data['enable_cpu_pinning'] = info['enable_cpu_pinning'] return data def node_is_available(self, nodename): """"""Return whether this compute service manages a particular node."""""" if nodename in self.get_available_nodes(): return True return False def update_provider_tree(self, provider_tree, nodename): """"""Update a ProviderTree object with current resource provider, inventory information. :param zun.compute.provider_tree.ProviderTree provider_tree: A zun.compute.provider_tree.ProviderTree object representing all the providers in the tree associated with the compute node, and any sharing providers (those with the ``MISC_SHARES_VIA_AGGREGATE`` trait) associated via aggregate with any of those providers (but not *their* tree- or aggregate-associated providers), as currently known by placement. :param nodename: String name of the compute node (i.e. ComputeNode.hostname) for which the caller is requesting updated provider information. """""" def _get_local_gb_info(): return self.get_total_disk_for_container()[0] def _get_memory_mb_total(): mem_total, mem_free, mem_ava, mem_used = self.get_host_mem() return mem_total // units.Ki def _get_vcpu_total(): return self.get_host_info()['cpus'] disk_gb = _get_local_gb_info() memory_mb = _get_memory_mb_total() vcpus = _get_vcpu_total() # NOTE(yikun): If the inv record does not exists, the allocation_ratio # will use the CONF.xxx_allocation_ratio value if xxx_allocation_ratio # is set, and fallback to use the initial_xxx_allocation_ratio # otherwise. inv = provider_tree.data(nodename).inventory ratios = self._get_allocation_ratios(inv) result = { orc.VCPU: { 'total': vcpus, 'min_unit': 1, 'max_unit': vcpus, 'step_size': 1, 'allocation_ratio': ratios[orc.VCPU], # TODO(hongbin): handle the case that the zun's reserved value # override the nova's one 'reserved': CONF.compute.reserved_host_cpus, }, orc.MEMORY_MB: { 'total': memory_mb, 'min_unit': 1, 'max_unit': memory_mb, 'step_size': 1, 'allocation_ratio': ratios[orc.MEMORY_MB], # TODO(hongbin): handle the case that the zun's reserved value # override the nova's one 'reserved': CONF.compute.reserved_host_memory_mb, }, } # If a sharing DISK_GB provider exists in the provider tree, then our # storage is shared, and we should not report the DISK_GB inventory in # the compute node provider. # TODO(efried): Reinstate non-reporting of shared resource by the # compute RP once the issues from bug #1784020 have been resolved. if provider_tree.has_sharing_provider(orc.DISK_GB): LOG.debug('Ignoring sharing provider - see bug #1784020') result[orc.DISK_GB] = { 'total': disk_gb, 'min_unit': 1, 'max_unit': disk_gb, 'step_size': 1, 'allocation_ratio': ratios[orc.DISK_GB], # TODO(hongbin): handle the case that the zun's reserved value # override the nova's one 'reserved': self._get_reserved_host_disk_gb_from_config(), } provider_tree.update_inventory(nodename, result) # Now that we updated the ProviderTree, we want to store it locally # so that spawn() or other methods can access it thru a getter self.provider_tree = copy.deepcopy(provider_tree) @staticmethod def _get_allocation_ratios(inventory): """"""Get the cpu/ram/disk allocation ratios for the given inventory. This utility method is used to get the inventory allocation ratio for VCPU, MEMORY_MB and DISK_GB resource classes based on the following precedence: * Use ``[DEFAULT]/*_allocation_ratio`` if set - this overrides everything including externally set allocation ratios on the inventory via the placement API * Use ``[DEFAULT]/initial_*_allocation_ratio`` if a value does not exist for a given resource class in the ``inventory`` dict * Use what is already in the ``inventory`` dict for the allocation ratio if the above conditions are false :param inventory: dict, keyed by resource class, of inventory information. :returns: Return a dict, keyed by resource class, of allocation ratio """""" keys = {'cpu': orc.VCPU, 'ram': orc.MEMORY_MB, 'disk': orc.DISK_GB} result = {} for res, rc in keys.items(): attr = '%s_allocation_ratio' % res conf_ratio = getattr(CONF.compute, attr) if conf_ratio: result[rc] = conf_ratio elif rc not in inventory: result[rc] = getattr(CONF.compute, 'initial_%s' % attr) else: result[rc] = inventory[rc]['allocation_ratio'] return result @staticmethod def _get_reserved_host_disk_gb_from_config(): return utils.convert_mb_to_ceil_gb(CONF.compute.reserved_host_disk_mb) def capabilities_as_traits(self): """"""Returns this driver's capabilities dict where the keys are traits Traits can only be standard compute capabilities traits from the os-traits library. :returns: dict, keyed by trait, of this driver's capabilities where the values are booleans indicating if the driver supports the trait """""" traits = {} for capability, supported in self.capabilities.items(): if capability in CAPABILITY_TRAITS_MAP: traits[CAPABILITY_TRAITS_MAP[capability]] = supported return traits def __init__(self): self.volume_drivers = {} for driver_name in CONF.volume.driver_list: driver = vol_driver.driver(driver_name) self.volume_drivers[driver_name] = driver def _get_volume_driver(self, volume_mapping): driver_name = volume_mapping.volume_provider driver = self.volume_drivers.get(driver_name) if not driver: msg = _(""The volume provider '%s' is not supported"") % driver_name raise exception.ZunException(msg) return driver def attach_volume(self, context, volume_mapping): volume_driver = self._get_volume_driver(volume_mapping) volume_driver.attach(context, volume_mapping) volume_driver = self._get_volume_driver(volume_mapping) volume_driver.detach(context, volume_mapping) volume_driver = self._get_volume_driver(volume_mapping) volume_driver.delete(context, volume_mapping) volume_driver = self._get_volume_driver(volume_mapping) return volume_driver.is_volume_available(context, volume_mapping) volume_driver = self._get_volume_driver(volume_mapping) return volume_driver.is_volume_deleted(context, volume_mapping)"," def attach_volume(self, context, volume_mapping): raise NotImplementedError() raise NotImplementedError() raise NotImplementedError() raise NotImplementedError() raise NotImplementedError()",264,5
openstack%2Fnova~master~I076b84d46e5b2ff3bb6ed4d0c361683097c4c014,openstack/nova,master,I076b84d46e5b2ff3bb6ed4d0c361683097c4c014,Remove dict compat from populate_filter_properties,MERGED,2019-12-06 14:34:41.000000000,2020-01-19 20:00:47.000000000,2020-01-19 19:58:20.000000000,"[{'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-06 14:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/209fb9cf2b659f28c318e097e1f3cf29f78cf680', 'message': ""Remove dict compat from populate_filter_properties\n\nThe only callers of populate_filter_properties are conductor\nmethods and they all pass a Selection object so we can fulfill\nthe TODO and remove the dict compat. Note that the callers have\nto pass a Selection object because they ask select_destinations\nto return_objects=True and if there was a pinned RPC version the\nselect_destinations call would fail with\nSelectionObjectsWithOldRPCVersionNotSupported. Point being, we\ndon't need to worry about old RPC compat code passing a dict rather\nthan a Selection object.\n\nChange-Id: I076b84d46e5b2ff3bb6ed4d0c361683097c4c014\n""}, {'number': 2, 'created': '2019-12-06 16:26:08.000000000', 'files': ['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ec59ab52054691aa8fc2a93de055d95b06b945f6', 'message': ""Remove dict compat from populate_filter_properties\n\nThe only callers of populate_filter_properties are conductor\nmethods and they all pass a Selection object so we can fulfill\nthe TODO and remove the dict compat. Note that the callers have\nto pass a Selection object because they ask select_destinations\nto return_objects=True and if there was a pinned RPC version the\nselect_destinations call would fail with\nSelectionObjectsWithOldRPCVersionNotSupported. Point being, we\ndon't need to worry about old RPC compat code passing a dict rather\nthan a Selection object.\n\nChange-Id: I076b84d46e5b2ff3bb6ed4d0c361683097c4c014\n""}]",0,697669,ec59ab52054691aa8fc2a93de055d95b06b945f6,68,13,2,6873,,,0,"Remove dict compat from populate_filter_properties

The only callers of populate_filter_properties are conductor
methods and they all pass a Selection object so we can fulfill
the TODO and remove the dict compat. Note that the callers have
to pass a Selection object because they ask select_destinations
to return_objects=True and if there was a pinned RPC version the
select_destinations call would fail with
SelectionObjectsWithOldRPCVersionNotSupported. Point being, we
don't need to worry about old RPC compat code passing a dict rather
than a Selection object.

Change-Id: I076b84d46e5b2ff3bb6ed4d0c361683097c4c014
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/697669/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py']",2,209fb9cf2b659f28c318e097e1f3cf29f78cf680,bp/request-spec-use-by-compute," def _test_populate_filter_props(self,"," def _test_populate_filter_props(self, selection_obj=True, if not selection_obj: selection = selection.to_dict() fake_limits = fake_limits.to_dict() def test_populate_filter_props_host_dict(self): self._test_populate_filter_props(selection_obj=False) ",11,19
openstack%2Fopenstack-zuul-jobs~master~I8d84b952dd92dd33b0ac41b3dc82873dd0441097,openstack/openstack-zuul-jobs,master,I8d84b952dd92dd33b0ac41b3dc82873dd0441097,Jenkins plugins to xenial for java 8,ABANDONED,2017-11-07 10:29:47.000000000,2020-01-19 18:45:45.000000000,,"[{'_account_id': 2475}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-07 10:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/aee4f5ecfb101d37f55e5ba23e70fe49da279af8', 'message': 'Jenkins plugins to xenial for java 8\n\nThe gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now\nrequires Java 8 which is not available in Trusty.\n\nThe repositories will then have a bindep.txt to install Maven and the\nJava 8 JDK:\n\n maven [test]\n openjdk-8-jdk-headless [test]\n\nChange-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n'}, {'number': 2, 'created': '2017-11-07 13:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/c7b9d35ee1876099c81df04ff365939d85cd5918', 'message': 'Jenkins plugins to xenial for java 8\n\nThe gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now\nrequires Java 8 which is not available in Trusty.\n\nThe repositories will then have a bindep.txt to install Maven and the\nJava 8 JDK:\n\n maven [test]\n openjdk-8-jdk-headless [test]\n\nChange-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n'}, {'number': 3, 'created': '2017-11-07 13:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/4402771b918753f663cec99e069ba9e06b5cffcb', 'message': 'Jenkins plugins to xenial for java 8\n\nThe gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now\nrequires Java 8 which is not available in Trusty.\n\nThe repositories will then have a bindep.txt to install Maven and the\nJava 8 JDK:\n\n maven [test]\n openjdk-8-jdk-headless [test]\n\nDepends-On: Idf13dbe29c59b040ad5aee26ee853202dede6a69\nChange-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n'}, {'number': 4, 'created': '2017-11-20 11:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/d0a21bbc57bcb17288c9a95f6d2564417165d95d', 'message': ""Jenkins plugins to xenial for java 8\n\nThe gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now\nrequires Java 8 which is not available on Trusty.\n\nCreate new jobs based on xenial.\nRename the playbooks to strip the '-ubuntu-trusty' suffix.\nAdjust the trusty jobs to use the renamed playbooks.\n\nThe repositories will then have a bindep.txt to install Maven and the\nJava 8 JDK:\n\n maven [test]\n openjdk-8-jdk-headless [test]\n\nZuul layout change is Idf13dbe29c59b040ad5aee26ee853202dede6a69\nLater the ubuntu-trusty jobs will be removed entirely.\n\nChange-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n""}, {'number': 5, 'created': '2017-11-20 13:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/fed38b183d94572ba3c5e78077d9de2fb4f0dcc2', 'message': ""Jenkins plugins to xenial for java 8\n\nThe gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now\nrequires Java 8 which is not available on Trusty.\n\nCreate new jobs based on xenial.\nRename the playbooks to strip the '-ubuntu-trusty' suffix.\nAdjust the trusty jobs to use the renamed playbooks.\n\nThe repositories will then have a bindep.txt to install Maven and the\nJava 8 JDK:\n\n maven [test]\n openjdk-8-jdk-headless [test]\n\nZuul layout change is Idf13dbe29c59b040ad5aee26ee853202dede6a69\nLater the ubuntu-trusty jobs will be removed entirely.\n\nNeeded-by: Idf13dbe29c59b040ad5aee26ee853202dede6a69\nChange-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n""}, {'number': 6, 'created': '2017-11-20 13:19:32.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/gearman-plugin-maven-build/run.yaml', 'playbooks/legacy/zmq-event-publisher-maven-build/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/4e9847d9dee1c2f4490655fc1f2458a5ea39bb86', 'message': ""Jenkins plugins to xenial for java 8\n\nThe gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now\nrequires Java 8 which is not available on Trusty.\n\nCreate new jobs based on xenial.\nRename the playbooks to strip the '-ubuntu-trusty' suffix.\nAdjust the trusty jobs to use the renamed playbooks.\n\nThe repositories will then have a bindep.txt to install Maven and the\nJava 8 JDK:\n\n maven [test]\n openjdk-8-jdk-headless [test]\n\nZuul layout change is Idf13dbe29c59b040ad5aee26ee853202dede6a69\nLater the ubuntu-trusty jobs will be removed entirely.\n\nNeeded-by: Idf13dbe29c59b040ad5aee26ee853202dede6a69\nChange-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n""}]",0,518287,4e9847d9dee1c2f4490655fc1f2458a5ea39bb86,22,3,6,2475,,,0,"Jenkins plugins to xenial for java 8

The gearman and zmq-event-publisher are Jenkins plugins, Jenkins LTS now
requires Java 8 which is not available on Trusty.

Create new jobs based on xenial.
Rename the playbooks to strip the '-ubuntu-trusty' suffix.
Adjust the trusty jobs to use the renamed playbooks.

The repositories will then have a bindep.txt to install Maven and the
Java 8 JDK:

 maven [test]
 openjdk-8-jdk-headless [test]

Zuul layout change is Idf13dbe29c59b040ad5aee26ee853202dede6a69
Later the ubuntu-trusty jobs will be removed entirely.

Needed-by: Idf13dbe29c59b040ad5aee26ee853202dede6a69
Change-Id: I8d84b952dd92dd33b0ac41b3dc82873dd0441097
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/87/518287/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/gearman-plugin-maven-build/run.yaml', 'playbooks/legacy/zmq-event-publisher-maven-build/run.yaml']",2,aee4f5ecfb101d37f55e5ba23e70fe49da279af8,,,,0,0
openstack%2Fproject-config~master~Idf13dbe29c59b040ad5aee26ee853202dede6a69,openstack/project-config,master,Idf13dbe29c59b040ad5aee26ee853202dede6a69,Switch Jenkins plugins to xenial for java 8,ABANDONED,2017-11-07 13:56:38.000000000,2020-01-19 18:45:18.000000000,,"[{'_account_id': 2475}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-11-07 13:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a509116cd0db5108b58d6bcf261010850cc0906d', 'message': 'Switch Jenkins plugins to Xenial based jobs\n\nSo we can get Java 8 installed.\n\nJobs are provided by I8d84b952dd92dd33b0ac41b3dc82873dd0441097\n\nChange-Id: Idf13dbe29c59b040ad5aee26ee853202dede6a69\n'}, {'number': 2, 'created': '2017-11-20 11:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/058f7510542ea018e2a4e7232e04acef826e6cbf', 'message': 'Experimental Xenial jobs for Jenkins plugins\n\nSo we can get Java 8 installed.  Added to experimental since the source\nrepository needs bindeps.txt to be added and further tweaks will\nprobably be needed.\n\nDepends-On: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\nChange-Id: Idf13dbe29c59b040ad5aee26ee853202dede6a69\n'}, {'number': 3, 'created': '2017-11-20 12:52:32.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/450318e5e34992cef4b601a7e66b5cd24e60baed', 'message': 'Switch Jenkins plugins to xenial for java 8\n\nSo we can get Java 8 installed.\n\nDepends-On: I8d84b952dd92dd33b0ac41b3dc82873dd0441097\nChange-Id: Idf13dbe29c59b040ad5aee26ee853202dede6a69\n'}]",0,518333,450318e5e34992cef4b601a7e66b5cd24e60baed,13,2,3,2475,,,0,"Switch Jenkins plugins to xenial for java 8

So we can get Java 8 installed.

Depends-On: I8d84b952dd92dd33b0ac41b3dc82873dd0441097
Change-Id: Idf13dbe29c59b040ad5aee26ee853202dede6a69
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/518333/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,a509116cd0db5108b58d6bcf261010850cc0906d,, - legacy-gearman-plugin-maven-build - legacy-gearman-plugin-maven-build - legacy-zmq-event-publisher-maven-build - legacy-zmq-event-publisher-maven-build, - legacy-gearman-plugin-maven-build-ubuntu-trusty - legacy-gearman-plugin-maven-build-ubuntu-trusty - legacy-zmq-event-publisher-maven-build-ubuntu-trusty - legacy-zmq-event-publisher-maven-build-ubuntu-trusty,4,4
openstack%2Fcyborg-specs~master~Ib226cbf9fc1fb7d3146083d65c33d9e0b90e4d5b,openstack/cyborg-specs,master,Ib226cbf9fc1fb7d3146083d65c33d9e0b90e4d5b,Move basepython variable to the [testenv],MERGED,2020-01-17 06:30:38.000000000,2020-01-19 17:50:05.000000000,2020-01-19 17:48:54.000000000,"[{'_account_id': 14107}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 28748}]","[{'number': 1, 'created': '2020-01-17 06:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/96b3804cb11243febc6b1a232769faf371211246', 'message': ""Move basepython variable to the [testenv]\n\nIn tox.ini, while we add a new test class, we need default\ndepends on python3, this patch move 'basepython = python3'\nto the [testenv] as the default configuration.\n\nChange-Id: Ib226cbf9fc1fb7d3146083d65c33d9e0b90e4d5b\n""}, {'number': 2, 'created': '2020-01-17 06:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/24b636801c6ecb8c402ad83476b6e47d25fe8593', 'message': ""Move basepython variable to the [testenv]\n\nIn tox.ini, while we add a new test class, we need default\ndepends on python3, this patch move 'basepython = python3'\nto the [testenv] as the default configuration.\n\nChange-Id: Ib226cbf9fc1fb7d3146083d65c33d9e0b90e4d5b\n""}, {'number': 3, 'created': '2020-01-17 06:49:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/452028b602913a191a819bc2158c0595caf85628', 'message': ""Move basepython variable to the [testenv]\n\nIn tox.ini, while we add a new test class, we need default\ndepends on python3, this patch move 'basepython = python3'\nto the [testenv] as the default configuration.\n\nThe py35,py27 in envlist are unused in this project, so I\nwas also removed that in this patch.\n\nChange-Id: Ib226cbf9fc1fb7d3146083d65c33d9e0b90e4d5b\n""}]",2,703017,452028b602913a191a819bc2158c0595caf85628,13,6,3,26458,,,0,"Move basepython variable to the [testenv]

In tox.ini, while we add a new test class, we need default
depends on python3, this patch move 'basepython = python3'
to the [testenv] as the default configuration.

The py35,py27 in envlist are unused in this project, so I
was also removed that in this patch.

Change-Id: Ib226cbf9fc1fb7d3146083d65c33d9e0b90e4d5b
",git fetch https://review.opendev.org/openstack/cyborg-specs refs/changes/17/703017/3 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,96b3804cb11243febc6b1a232769faf371211246,default_basepython_variable,basepython = python3,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,1,6
openstack%2Fpython-cyborgclient~master~I4f55d2abd3f58acbbeda397dcefbd9a699cf9cdb,openstack/python-cyborgclient,master,I4f55d2abd3f58acbbeda397dcefbd9a699cf9cdb,Bump the openstackdocstheme extension to 1.20,MERGED,2019-07-29 06:56:11.000000000,2020-01-19 17:49:51.000000000,2020-01-19 17:48:42.000000000,"[{'_account_id': 14107}, {'_account_id': 18955}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 23168}, {'_account_id': 25738}, {'_account_id': 28748}, {'_account_id': 30759}]","[{'number': 1, 'created': '2019-07-29 06:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/524d128de65e15a6cc605910bab2abea2edc8fa4', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I4f55d2abd3f58acbbeda397dcefbd9a699cf9cdb\n'}, {'number': 2, 'created': '2019-08-01 02:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/075d5cc25a0b2af9228c910a1d12b9c61ae359d4', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I4f55d2abd3f58acbbeda397dcefbd9a699cf9cdb\n'}, {'number': 3, 'created': '2019-09-16 05:53:27.000000000', 'files': ['test-requirements.txt', 'doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-cyborgclient/commit/3d37b448e1520ed9cf71cdc3aef50766fe4673b4', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I4f55d2abd3f58acbbeda397dcefbd9a699cf9cdb\n'}]",1,673213,3d37b448e1520ed9cf71cdc3aef50766fe4673b4,14,8,3,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: I4f55d2abd3f58acbbeda397dcefbd9a699cf9cdb
",git fetch https://review.opendev.org/openstack/python-cyborgclient refs/changes/13/673213/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/conf.py', 'releasenotes/source/conf.py']",3,524d128de65e15a6cc605910bab2abea2edc8fa4,openstackdocstheme,,"project = u'cyborgclient Release Notes'# The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. # The full version, including alpha/beta/rc tags. release = '' # The short X.Y version. version = '' latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } ",1,24
openstack%2Fdevstack~master~I847a873d833a4dbee96afa1d2726fea2b8045eeb,openstack/devstack,master,I847a873d833a4dbee96afa1d2726fea2b8045eeb,Stop configuring '[DEFAULT] use_neutron' for nova,MERGED,2020-01-16 10:53:43.000000000,2020-01-19 17:45:02.000000000,2020-01-19 17:42:44.000000000,"[{'_account_id': 13252}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-16 10:53:43.000000000', 'files': ['lib/neutron', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f9ff151549bfa57cfeec524cf06ae3d65c8ab0a8', 'message': ""Stop configuring '[DEFAULT] use_neutron' for nova\n\nThis has now been removed and even prior to removal defaulted to True.\n\nChange-Id: I847a873d833a4dbee96afa1d2726fea2b8045eeb\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,702840,f9ff151549bfa57cfeec524cf06ae3d65c8ab0a8,10,4,1,15334,,,0,"Stop configuring '[DEFAULT] use_neutron' for nova

This has now been removed and even prior to removal defaulted to True.

Change-Id: I847a873d833a4dbee96afa1d2726fea2b8045eeb
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/40/702840/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron', 'lib/neutron-legacy']",2,f9ff151549bfa57cfeec524cf06ae3d65c8ab0a8,bp/remove-nova-network-ussuri,, iniset $conf DEFAULT use_neutron True,0,2
openstack%2Fdevstack~master~I4dbc0015cf26d7edf51d0d5fd978ccd3a1ad1b79,openstack/devstack,master,I4dbc0015cf26d7edf51d0d5fd978ccd3a1ad1b79,Stop configuring '[DEFAULT] firewall_driver' for nova,MERGED,2019-12-05 15:53:27.000000000,2020-01-19 17:43:59.000000000,2020-01-19 17:42:43.000000000,"[{'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-12-05 15:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/32b3772708a0f5c604da6ec5d3b93887d8433952', 'message': ""Stop configuring '[DEFAULT] firewall_driver' for nova\n\nThis option has default to the 'NoopFirewallDriver' for some time and\nwill soon be removed. Stop configuring it entirely.\n\nChange-Id: I4dbc0015cf26d7edf51d0d5fd978ccd3a1ad1b79\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2020-01-16 10:53:43.000000000', 'files': ['lib/nova_plugins/hypervisor-xenserver', 'lib/neutron', 'lib/nova_plugins/hypervisor-openvz', 'lib/nova_plugins/hypervisor-libvirt', 'lib/neutron_plugins/nuage', 'lib/nova_plugins/hypervisor-ironic', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/248d4bb8d2205de38e56ef1f92a4bf0870400a85', 'message': ""Stop configuring '[DEFAULT] firewall_driver' for nova\n\nThis option has default to the 'NoopFirewallDriver' for some time and\nwill soon be removed. Stop configuring it entirely.\n\nChange-Id: I4dbc0015cf26d7edf51d0d5fd978ccd3a1ad1b79\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",3,697508,248d4bb8d2205de38e56ef1f92a4bf0870400a85,25,5,2,15334,,,0,"Stop configuring '[DEFAULT] firewall_driver' for nova

This option has default to the 'NoopFirewallDriver' for some time and
will soon be removed. Stop configuring it entirely.

Change-Id: I4dbc0015cf26d7edf51d0d5fd978ccd3a1ad1b79
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/08/697508/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/nova_plugins/hypervisor-xenserver', 'lib/neutron', 'lib/nova_plugins/hypervisor-openvz', 'lib/nova_plugins/hypervisor-libvirt', 'lib/neutron_plugins/nuage', 'lib/nova_plugins/hypervisor-ironic', 'lib/neutron-legacy']",7,32b3772708a0f5c604da6ec5d3b93887d8433952,bp/remove-nova-network-ussuri,," if [[ ""$Q_USE_SECGROUP"" == ""True"" ]]; then LIBVIRT_FIREWALL_DRIVER=nova.virt.firewall.NoopFirewallDriver iniset $conf DEFAULT firewall_driver $LIBVIRT_FIREWALL_DRIVER fi ",0,18
openstack%2Ftempest~master~Ic38c74c245fddf29826e6ca0cc469f919076355e,openstack/tempest,master,Ic38c74c245fddf29826e6ca0cc469f919076355e,Create default network for more compute tests,MERGED,2020-01-14 23:14:14.000000000,2020-01-19 16:53:11.000000000,2020-01-19 16:51:48.000000000,"[{'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 23:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a8ab56cd13588dccc8c6ac2d94854243c9f8b9b', 'message': 'Create default network for more compute tests\n\nChipping away at the referenced bug, this commit uses the\ncreate_default_network class-level variable introduced via [1] to\ntrigger setup_credentials to create a default network for\nInstanceActionsV221TestJSON.\n\n[1] Ia34fe3b41261de02918713c2a948e6c56554bf6f\nPartial-Bug: #1844568\n\nChange-Id: Ic38c74c245fddf29826e6ca0cc469f919076355e\n'}, {'number': 2, 'created': '2020-01-16 13:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3a7901ece987888b8669bae1f9d43f76ac7c0be0', 'message': 'Create default network for more compute tests\n\nChipping away at the referenced bug, this commit uses the\ncreate_default_network class-level variable introduced via [1] to\ntrigger setup_credentials to create a default network for\na handful more test cases in which the problem was observed.\n\n[1] Ia34fe3b41261de02918713c2a948e6c56554bf6f\nPartial-Bug: #1844568\n\nChange-Id: Ic38c74c245fddf29826e6ca0cc469f919076355e\n'}, {'number': 3, 'created': '2020-01-16 14:10:46.000000000', 'files': ['tempest/api/compute/servers/test_instance_actions.py', 'tempest/api/compute/servers/test_server_password.py', 'tempest/api/compute/volumes/test_attach_volume_negative.py', 'tempest/api/compute/volumes/test_attach_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1f546532c32a1cade765685eaac180c57258f352', 'message': 'Create default network for more compute tests\n\nChipping away at the referenced bug, this commit uses the\ncreate_default_network class-level variable introduced via [1] to\ntrigger setup_credentials to create a default network for\na handful more test cases in which the problem was observed.\n\n[1] Ia34fe3b41261de02918713c2a948e6c56554bf6f\nPartial-Bug: #1844568\n\nChange-Id: Ic38c74c245fddf29826e6ca0cc469f919076355e\n'}]",3,702553,1f546532c32a1cade765685eaac180c57258f352,28,5,3,14070,,,0,"Create default network for more compute tests

Chipping away at the referenced bug, this commit uses the
create_default_network class-level variable introduced via [1] to
trigger setup_credentials to create a default network for
a handful more test cases in which the problem was observed.

[1] Ia34fe3b41261de02918713c2a948e6c56554bf6f
Partial-Bug: #1844568

Change-Id: Ic38c74c245fddf29826e6ca0cc469f919076355e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/53/702553/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_instance_actions.py'],1,7a8ab56cd13588dccc8c6ac2d94854243c9f8b9b,bug/1844568, create_default_network = True,,1,0
openstack%2Fdiskimage-builder~master~I0d328f4d1125be7e3801a9dd2c9374086024b903,openstack/diskimage-builder,master,I0d328f4d1125be7e3801a9dd2c9374086024b903,Remove trusty jobs,MERGED,2020-01-17 08:23:15.000000000,2020-01-19 15:07:08.000000000,2020-01-19 15:04:49.000000000,"[{'_account_id': 5263}, {'_account_id': 6469}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 08:23:15.000000000', 'files': ['.zuul.d/project.yaml', '.zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/71ef0a8b3c29747d196c5ae0882f0c57536d12cc', 'message': 'Remove trusty jobs\n\nOpenDev is removing trusty from the infrastructure, remove the jobs\nusing ubuntu-trusty.\n\nDepends-On: https://review.opendev.org/702817\nChange-Id: I0d328f4d1125be7e3801a9dd2c9374086024b903\n'}]",0,703030,71ef0a8b3c29747d196c5ae0882f0c57536d12cc,12,6,1,6547,,,0,"Remove trusty jobs

OpenDev is removing trusty from the infrastructure, remove the jobs
using ubuntu-trusty.

Depends-On: https://review.opendev.org/702817
Change-Id: I0d328f4d1125be7e3801a9dd2c9374086024b903
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/30/703030/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.d/project.yaml', '.zuul.d/jobs.yaml']",2,71ef0a8b3c29747d196c5ae0882f0c57536d12cc,trusty-removal,,"# Trusty / Python 2 tests - job: name: dib-functests-trusty-python2 description: | Run the default tests on a Trusty build host with Python 2 parent: dib-functests-default nodeset: ubuntu-trusty vars: dib_python: python2 - job: name: dib-functests-trusty-python2-image description: | The image tests on a Trusty build host with Python 2 parent: dib-functests-image nodeset: ubuntu-trusty vars: dib_python: python2 - job: name: dib-functests-trusty-python2-extras description: | The extras tests on a Trusty build host with Python 2 parent: dib-functests-extras nodeset: ubuntu-trusty vars: dib_python: python2 name: dib-nodepool-functional-openstack-ubuntu-trusty-src description: | Test building and booting an Ubuntu trusty image with Nodepool and OpenStack parent: dib-nodepool-functional-src-base pre-run: playbooks/dib-nodepool/debootstrap.yaml vars: nodepool_extra_packages: - debootstrap nodepool_diskimage: base_element: ubuntu-minimal release: 'trusty' mirror: ""http://{{ zuul_site_mirror_fqdn }}/ubuntu"" - job:",0,49
openstack%2Fproject-config~master~Icb5774be8f89234cb1fd95454ec7f003e0d3208b,openstack/project-config,master,Icb5774be8f89234cb1fd95454ec7f003e0d3208b,"Bye, Bye, Trusty",ABANDONED,2020-01-17 20:12:16.000000000,2020-01-19 15:02:26.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-17 20:12:16.000000000', 'files': ['tools/build-image.sh', 'nodepool/elements/nodepool-base/finalise.d/89-boot-settings', 'nodepool/elements/nodepool-base/post-install.d/20-iptables', 'nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'playbooks/wheel/release.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml', 'grafana/create-nodepool-dib.sh', 'grafana/nodepool-dib.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fabdd4bccdbc1778e9f83161a050d700fc8f852b', 'message': 'Bye, Bye, Trusty\n\nThis removes trusty from the repo and thus from OpenDev.\n\nAfterwards the AFS volume mirror.wheel.trustyx64 can be deleted.\n\nChange-Id: Icb5774be8f89234cb1fd95454ec7f003e0d3208b\n'}]",0,703190,fabdd4bccdbc1778e9f83161a050d700fc8f852b,3,1,1,6547,,,0,"Bye, Bye, Trusty

This removes trusty from the repo and thus from OpenDev.

Afterwards the AFS volume mirror.wheel.trustyx64 can be deleted.

Change-Id: Icb5774be8f89234cb1fd95454ec7f003e0d3208b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/703190/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/build-image.sh', 'nodepool/elements/nodepool-base/finalise.d/89-boot-settings', 'nodepool/elements/nodepool-base/post-install.d/20-iptables', 'nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'playbooks/wheel/release.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'grafana/create-nodepool-dib.sh', 'nodepool/nl01.openstack.org.yaml', 'grafana/nodepool-dib.yaml']",11,fabdd4bccdbc1778e9f83161a050d700fc8f852b,trusty-removal,,"# AUTOGENERATED : Ubuntu Trusty - title: Ubuntu Trusty showTitle: true height: 200px panels: - title: Build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-trusty.status.rc"" valueFontSize: ""50%"" - title: Last build type: singlestat span: 2 format: dateTimeFromNow targets: - target: ""stats.gauges.nodepool.dib_image_build.ubuntu-trusty.status.last_build"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.ubuntu-trusty.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: alias(keepLastValue(stats.timers.nodepool.dib_image_build.ubuntu-trusty.status.duration.mean, 'None'), ""Time"") refId: A",2,161
openstack%2Fdevstack~master~Idc07764d6ba3a828f19691f56c73cbe9179c2673,openstack/devstack,master,Idc07764d6ba3a828f19691f56c73cbe9179c2673,Init Glance database only on the node with the database backend,MERGED,2020-01-16 19:03:04.000000000,2020-01-19 09:48:28.000000000,2020-01-18 19:41:17.000000000,"[{'_account_id': 4690}, {'_account_id': 8556}, {'_account_id': 8864}, {'_account_id': 10135}, {'_account_id': 13252}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-16 19:03:04.000000000', 'files': ['lib/glance'], 'web_link': 'https://opendev.org/openstack/devstack/commit/ec3543a02883c3d9b288128e0a6cb941315e72cc', 'message': 'Init Glance database only on the node with the database backend\n\nSince [1] Glance init depends on either g-api or g-reg being\nenabled.\nThis broke multinode g-api deployments with singlenode database\nbackend.\nThis commit aligns Glance with other services w.r.t when to\napply database init.\n\n[1] d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a\n\nChange-Id: Idc07764d6ba3a828f19691f56c73cbe9179c2673\nCloses-bug: #1860021\n'}]",3,702960,ec3543a02883c3d9b288128e0a6cb941315e72cc,24,8,1,30491,,,0,"Init Glance database only on the node with the database backend

Since [1] Glance init depends on either g-api or g-reg being
enabled.
This broke multinode g-api deployments with singlenode database
backend.
This commit aligns Glance with other services w.r.t when to
apply database init.

[1] d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a

Change-Id: Idc07764d6ba3a828f19691f56c73cbe9179c2673
Closes-bug: #1860021
",git fetch https://review.opendev.org/openstack/devstack refs/changes/60/702960/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/glance'],1,ec3543a02883c3d9b288128e0a6cb941315e72cc,bug/1860021," if is_service_enabled $DATABASE_BACKENDS; then # (Re)create glance database recreate_database glance time_start ""dbsync"" # Migrate glance database $GLANCE_BIN_DIR/glance-manage --config-file $GLANCE_CONF_DIR/glance-api.conf db_sync # Load metadata definitions $GLANCE_BIN_DIR/glance-manage --config-file $GLANCE_CONF_DIR/glance-api.conf db_load_metadefs time_stop ""dbsync"" fi"," # (Re)create glance database recreate_database glance time_start ""dbsync"" # Migrate glance database $GLANCE_BIN_DIR/glance-manage --config-file $GLANCE_CONF_DIR/glance-api.conf db_sync # Load metadata definitions $GLANCE_BIN_DIR/glance-manage --config-file $GLANCE_CONF_DIR/glance-api.conf db_load_metadefs time_stop ""dbsync""",10,8
openstack%2Fdevstack~master~I58baa3b6c63c648836ae8152c2d6d7ceff11a388,openstack/devstack,master,I58baa3b6c63c648836ae8152c2d6d7ceff11a388,"Revert ""Run Glance initialization when Glance is enabled, not just registry""",MERGED,2020-01-17 17:26:11.000000000,2020-01-19 09:46:33.000000000,2020-01-19 08:43:34.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 17:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/271d91e62051651b7327270244e1b93ff4e0ce22', 'message': 'Revert ""Run Glance initialization when Glance is enabled, not just registry""\n\nThis reverts commit d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a. This has\nknock on effects for devstack-gate, which configures g-api on subnodes\nnode but not mysql, resulting in failures. A longer term fix would be to\neither a) stop configuring g-api on subnodes if we can determine it\'s\nnot necessary or b) only configure the database if on the main node.\nHowever, both options are subject to debate so for now just unclog the\ngate.\n\nChange-Id: I58baa3b6c63c648836ae8152c2d6d7ceff11a388\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-bug: #1860021\n'}, {'number': 2, 'created': '2020-01-17 17:42:35.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/48d1f028c43dd26aab852715e451e1ec08421a2f', 'message': 'Revert ""Run Glance initialization when Glance is enabled, not just registry""\n\nThis reverts commit d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a. This has\nknock on effects for devstack-gate, which configures g-api on subnodes\nnode but not mysql, resulting in failures. A longer term fix would be to\neither a) stop configuring g-api on subnodes if we can determine it\'s\nnot necessary or b) only configure the database if on the main node.\nHowever, both options are subject to debate so for now just unclog the\ngate.\n\nChange-Id: I58baa3b6c63c648836ae8152c2d6d7ceff11a388\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-bug: #1860021\n'}]",0,703131,48d1f028c43dd26aab852715e451e1ec08421a2f,31,6,2,15334,,,0,"Revert ""Run Glance initialization when Glance is enabled, not just registry""

This reverts commit d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a. This has
knock on effects for devstack-gate, which configures g-api on subnodes
node but not mysql, resulting in failures. A longer term fix would be to
either a) stop configuring g-api on subnodes if we can determine it's
not necessary or b) only configure the database if on the main node.
However, both options are subject to debate so for now just unclog the
gate.

Change-Id: I58baa3b6c63c648836ae8152c2d6d7ceff11a388
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Closes-bug: #1860021
",git fetch https://review.opendev.org/openstack/devstack refs/changes/31/703131/2 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,271d91e62051651b7327270244e1b93ff4e0ce22,bug/1860021,if is_service_enabled g-reg; thenif is_service_enabled g-reg; then,if is_glance_enabled; thenif is_glance_enabled; then,2,2
openstack%2Ftrove~master~Ib4dc349ab7ed4193189ed6bc2bae699d51064998,openstack/trove,master,Ib4dc349ab7ed4193189ed6bc2bae699d51064998,Config admin clients as default,MERGED,2020-01-13 02:48:39.000000000,2020-01-19 09:39:03.000000000,2020-01-19 09:37:31.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-13 02:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1191bc8ccd463c8769e67478d64bf5b7847c6eb2', 'message': 'Config admin clients as default\n\nChange-Id: Ib4dc349ab7ed4193189ed6bc2bae699d51064998\n'}, {'number': 2, 'created': '2020-01-14 08:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6ebc4e3b55898d496a9f231e2641fcd391422d7b', 'message': 'Config admin clients as default\n\nChange-Id: Ib4dc349ab7ed4193189ed6bc2bae699d51064998\n'}, {'number': 3, 'created': '2020-01-14 20:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/74f858e7e6ecaffa2ea21e4a45e682279fafaf86', 'message': 'Config admin clients as default\n\nChange-Id: Ib4dc349ab7ed4193189ed6bc2bae699d51064998\n'}, {'number': 4, 'created': '2020-01-19 04:36:14.000000000', 'files': ['releasenotes/notes/ussuri-database-instance-healthy.yaml', 'releasenotes/notes/ussuri-admin-clients-a14514a835ae11ea.yaml', 'releasenotes/notes/ussuri-service-credential-config.yaml', 'releasenotes/notes/ussuri-add-service-status-updated.yaml', 'trove/common/cfg.py', 'devstack/plugin.sh', 'releasenotes/notes/ussuri-delete-datastoredad784e2345711ea.yaml', 'trove/tests/unittests/taskmanager/test_models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/dfe826402b8216650d86a70bf2c3a6d478e9048b', 'message': 'Config admin clients as default\n\nChange-Id: Ib4dc349ab7ed4193189ed6bc2bae699d51064998\n'}]",0,702156,dfe826402b8216650d86a70bf2c3a6d478e9048b,24,2,4,6732,,,0,"Config admin clients as default

Change-Id: Ib4dc349ab7ed4193189ed6bc2bae699d51064998
",git fetch https://review.opendev.org/openstack/trove refs/changes/56/702156/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ussuri-04-admin-clients-a14514a835ae11ea.yaml', 'trove/common/cfg.py', 'devstack/plugin.sh']",3,1191bc8ccd463c8769e67478d64bf5b7847c6eb2,default-remote-clients,, iniset $TROVE_CONF DEFAULT remote_nova_client trove.common.clients_admin.nova_client_trove_admin iniset $TROVE_CONF DEFAULT remote_cinder_client trove.common.clients_admin.cinder_client_trove_admin iniset $TROVE_CONF DEFAULT remote_neutron_client trove.common.clients_admin.neutron_client_trove_admin iniset $TROVE_CONF DEFAULT remote_glance_client trove.common.clients_admin.glance_client_trove_admin iniset $TROVE_GUESTAGENT_CONF DEFAULT remote_nova_client trove.common.clients_admin.nova_client_trove_admin iniset $TROVE_GUESTAGENT_CONF DEFAULT remote_cinder_client trove.common.clients_admin.cinder_client_trove_admin iniset $TROVE_GUESTAGENT_CONF DEFAULT remote_neutron_client trove.common.clients_admin.neutron_client_trove_admin iniset $TROVE_GUESTAGENT_CONF DEFAULT remote_glance_client trove.common.clients_admin.glance_client_trove_admin ,14,14
openstack%2Ffreezer-web-ui~master~I176d97ee1a76bd91569cad69ac87e82fa96c265f,openstack/freezer-web-ui,master,I176d97ee1a76bd91569cad69ac87e82fa96c265f,Imported Translations from Zanata,MERGED,2020-01-17 07:32:08.000000000,2020-01-19 08:14:07.000000000,2020-01-19 08:14:07.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 07:32:08.000000000', 'files': ['disaster_recovery/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/75b145a459a544b4a0b769e4364703da4a87f856', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I176d97ee1a76bd91569cad69ac87e82fa96c265f\n'}]",0,703026,75b145a459a544b4a0b769e4364703da4a87f856,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I176d97ee1a76bd91569cad69ac87e82fa96c265f
",git fetch https://review.opendev.org/openstack/freezer-web-ui refs/changes/26/703026/1 && git format-patch -1 --stdout FETCH_HEAD,['disaster_recovery/locale/de/LC_MESSAGES/django.po'],1,75b145a459a544b4a0b769e4364703da4a87f856,zanata/translations,"# Andreas Jaeger <jaegerandi@gmail.com>, 2020. #zanata""POT-Creation-Date: 2020-01-06 02:54+0000\n""""PO-Revision-Date: 2020-01-16 04:01+0000\n"" ""Last-Translator: Andreas Jaeger <jaegerandi@gmail.com>\n""msgid ""osbrick"" msgstr ""osbrick"" ","""POT-Creation-Date: 2018-06-07 23:06+0000\n""""PO-Revision-Date: 2018-06-13 01:35+0000\n"" ""Last-Translator: Robert Simai <robert.simai@suse.com>\n""",7,3
openstack%2Frequirements~master~I53701224298eb3abc6c2e261b1a7bcd51b8e6b43,openstack/requirements,master,I53701224298eb3abc6c2e261b1a7bcd51b8e6b43,Updated from generate-constraints,MERGED,2020-01-09 09:01:10.000000000,2020-01-19 07:21:58.000000000,2020-01-19 07:20:29.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 09:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/cfea28e93dda04ccd8a4e0391ce956178e47fbbe', 'message': 'Updated from generate-constraints\n\nChange-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43\n'}, {'number': 2, 'created': '2020-01-10 06:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/cb122dc6db12010b0d56ad9e7a02eb92aa990db3', 'message': 'Updated from generate-constraints\n\nChange-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43\n'}, {'number': 3, 'created': '2020-01-11 21:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/dab5ee20d78d83f4d07b5bcf222da389a5f6c499', 'message': 'Updated from generate-constraints\n\nChange-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43\n'}, {'number': 4, 'created': '2020-01-12 08:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/fcd39b5ec013ebc5f0b6ba6a9abd7fcccdcfae1b', 'message': 'Updated from generate-constraints\n\nChange-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43\n'}, {'number': 5, 'created': '2020-01-12 08:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/42fbe7d7302b9b9b03b94cf0876f76c2691c4bdf', 'message': 'Updated from generate-constraints\n\nChange-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43\n'}, {'number': 6, 'created': '2020-01-12 08:32:13.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/88825ffa4716d9fde812eae9edaea49843552e69', 'message': 'Updated from generate-constraints\n\nChange-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43\n'}]",0,701692,88825ffa4716d9fde812eae9edaea49843552e69,30,2,6,11131,,,0,"Updated from generate-constraints

Change-Id: I53701224298eb3abc6c2e261b1a7bcd51b8e6b43
",git fetch https://review.opendev.org/openstack/requirements refs/changes/92/701692/6 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,cfea28e93dda04ccd8a4e0391ce956178e47fbbe,openstack/requirements/constraints/noclob,pytest===4.6.9;python_version=='2.7'Pint===0.10.1;python_version=='3.4' Pint===0.10.1;python_version=='3.5' Pint===0.10.1;python_version=='3.6' Pint===0.10.1;python_version=='3.7' Pint===0.9;python_version=='2.7'pymongo===3.10.1PyYAML===5.3django-compressor===2.4tinyrpc===1.0.4cliff===2.18.0enmerkar===0.7.1;python_version=='3.4' enmerkar===0.7.1;python_version=='3.5' enmerkar===0.7.1;python_version=='3.6' enmerkar===0.7.1;python_version=='3.7'coverage===5.0.2nodeenv===1.3.4django-babel===0.6.2boto3===1.10.49packaging===20.0SecretStorage===3.1.2;python_version=='3.4' SecretStorage===3.1.2;python_version=='3.5' SecretStorage===3.1.2;python_version=='3.6' SecretStorage===3.1.2;python_version=='3.7'sympy===1.5.1numpy===1.18.1;python_version=='3.4' numpy===1.18.1;python_version=='3.5' numpy===1.18.1;python_version=='3.6' numpy===1.18.1;python_version=='3.7'oslo.config===7.0.0botocore===1.13.49stomp.py===5.0.1pyrsistent===0.15.7Paste===3.2.4,pytest===4.6.8;python_version=='2.7'Pint===0.9pymongo===3.10.0PyYAML===5.2django-compressor===2.3tinyrpc===1.0.3cliff===2.16.0coverage===5.0.1nodeenv===1.3.3enmerkar===0.7.1;python_version=='3.4' enmerkar===0.7.1;python_version=='3.5' enmerkar===0.7.1;python_version=='3.6' enmerkar===0.7.1;python_version=='3.7'boto3===1.10.46packaging===19.2asgiref===3.2.3;python_version=='3.4' asgiref===3.2.3;python_version=='3.5' asgiref===3.2.3;python_version=='3.6' asgiref===3.2.3;python_version=='3.7'SecretStorage===3.1.1;python_version=='3.4' SecretStorage===3.1.1;python_version=='3.5' SecretStorage===3.1.1;python_version=='3.6' SecretStorage===3.1.1;python_version=='3.7'sympy===1.5numpy===1.18.0;python_version=='3.4' numpy===1.18.0;python_version=='3.5' numpy===1.18.0;python_version=='3.6' numpy===1.18.0;python_version=='3.7'oslo.config===6.12.0botocore===1.13.46stomp.py===5.0.0pyrsistent===0.15.6Paste===3.2.3,34,33
openstack%2Ftrove~master~Icf6a0ece18c5614b68a0015814faedf0cc7be61f,openstack/trove,master,Icf6a0ece18c5614b68a0015814faedf0cc7be61f,Fix missing parameter in log message,MERGED,2020-01-03 09:46:17.000000000,2020-01-19 06:02:54.000000000,2020-01-19 06:01:01.000000000,"[{'_account_id': 6732}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 25254}, {'_account_id': 27822}]","[{'number': 1, 'created': '2020-01-03 09:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6c424006cfebdfab649f43c5c5b54632945900fc', 'message': 'Fix missing parameter in log message\n\nThis is to fix a missing parameter issue in the log message.\n\nChange-Id: Icf6a0ece18c5614b68a0015814faedf0cc7be61f\n'}, {'number': 2, 'created': '2020-01-14 20:37:24.000000000', 'files': ['trove/guestagent/datastore/experimental/redis/manager.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/eb6cea16ecfeb8401c53f1f0c209d44e6089c488', 'message': 'Fix missing parameter in log message\n\nThis is to fix a missing parameter issue in the log message.\n\nChange-Id: Icf6a0ece18c5614b68a0015814faedf0cc7be61f\n'}]",0,701005,eb6cea16ecfeb8401c53f1f0c209d44e6089c488,36,5,2,20190,,,0,"Fix missing parameter in log message

This is to fix a missing parameter issue in the log message.

Change-Id: Icf6a0ece18c5614b68a0015814faedf0cc7be61f
",git fetch https://review.opendev.org/openstack/trove refs/changes/05/701005/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/datastore/experimental/redis/manager.py'],1,6c424006cfebdfab649f43c5c5b54632945900fc,log_format," LOG.info(""Waiting on repl offset '%s'."", txn)"," LOG.info(""Waiting on repl offset '%s'.""), txn",1,1
openstack%2Frally-openstack~master~I7cfd1dedaef7b79ee20e5d0fe3183abdf4d3a64f,openstack/rally-openstack,master,I7cfd1dedaef7b79ee20e5d0fe3183abdf4d3a64f,"Fix duplicated words issue like ""the the volume type""",MERGED,2020-01-06 09:40:24.000000000,2020-01-19 04:20:14.000000000,2020-01-19 04:20:14.000000000,"[{'_account_id': 9545}, {'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-06 09:40:24.000000000', 'files': ['rally_openstack/services/loadbalancer/octavia.py', 'rally_openstack/services/storage/cinder_common.py', 'rally_openstack/services/storage/cinder_v3.py'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/6b70b966f44affbb208da7b53b82abb07abdc1d6', 'message': 'Fix duplicated words issue like ""the the volume type""\n\nThis is to fix the duplicated words issue like\n""Description of the the volume type"".\n\nChange-Id: I7cfd1dedaef7b79ee20e5d0fe3183abdf4d3a64f\n'}]",0,701182,6b70b966f44affbb208da7b53b82abb07abdc1d6,46,3,1,20190,,,0,"Fix duplicated words issue like ""the the volume type""

This is to fix the duplicated words issue like
""Description of the the volume type"".

Change-Id: I7cfd1dedaef7b79ee20e5d0fe3183abdf4d3a64f
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/82/701182/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally_openstack/services/loadbalancer/octavia.py', 'rally_openstack/services/storage/cinder_common.py', 'rally_openstack/services/storage/cinder_v3.py']",3,6b70b966f44affbb208da7b53b82abb07abdc1d6,duplicated, :param description: Description of the volume type., :param description: Description of the the volume type.,7,7
openstack%2Fcyborg~master~I791ef5ee95d6dd9ff9271dc01c72075631a3efaa,openstack/cyborg,master,I791ef5ee95d6dd9ff9271dc01c72075631a3efaa,Remove useless get_test_accelerator method and fix uuid error,MERGED,2020-01-16 02:59:11.000000000,2020-01-19 03:27:38.000000000,2020-01-19 03:26:09.000000000,"[{'_account_id': 14107}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 26458}]","[{'number': 1, 'created': '2020-01-16 02:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/afac940058146c945f26ca3866b975fea6388a5d', 'message': 'Remove useless code for V1\n\nChange-Id: I791ef5ee95d6dd9ff9271dc01c72075631a3efaa\n'}, {'number': 2, 'created': '2020-01-16 11:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/61458d1cbf24f5922e94c9622ab34ccf131a7ec6', 'message': 'Remove useless code for V1 and fix uuid error\n\nuuid lack one num.\n\nChange-Id: I791ef5ee95d6dd9ff9271dc01c72075631a3efaa\n'}, {'number': 3, 'created': '2020-01-16 12:20:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/c9e764e05999fad01a2b292f062d546410115bc4', 'message': 'Remove useless get_test_accelerator method and fix uuid error\n\nFor method get_test_accelerator(), it will not be used in V2.\nSo we should remove it.\n\nFor uuid in cyborg/tests/unit/db/utils.py, it lacks of one num.\nThe length of uuid should be 36 instead of 35.\n\nChange-Id: I791ef5ee95d6dd9ff9271dc01c72075631a3efaa\n'}, {'number': 4, 'created': '2020-01-16 12:24:25.000000000', 'files': ['cyborg/tests/unit/db/utils.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/298ab6cc8688fcae310030f4019e012d12cb10e5', 'message': 'Remove useless get_test_accelerator method and fix uuid error\n\nFor method get_test_accelerator(), it will not be used in V2.\nSo we should remove it.\n\nFor uuid in cyborg/tests/unit/db/utils.py, it lacks of one num.\nThe length of uuid should be 36 instead of 35.\n\nChange-Id: I791ef5ee95d6dd9ff9271dc01c72075631a3efaa\n'}]",0,702785,298ab6cc8688fcae310030f4019e012d12cb10e5,14,6,4,28748,,,0,"Remove useless get_test_accelerator method and fix uuid error

For method get_test_accelerator(), it will not be used in V2.
So we should remove it.

For uuid in cyborg/tests/unit/db/utils.py, it lacks of one num.
The length of uuid should be 36 instead of 35.

Change-Id: I791ef5ee95d6dd9ff9271dc01c72075631a3efaa
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/85/702785/3 && git format-patch -1 --stdout FETCH_HEAD,['cyborg/tests/unit/db/utils.py'],1,afac940058146c945f26ca3866b975fea6388a5d,improve_dp_db_ut,,"def get_test_accelerator(**kw): return { 'name': kw.get('name', 'name'), 'description': kw.get('description', 'description'), 'device_type': kw.get('device_type', 'device_type'), 'acc_type': kw.get('acc_type', 'acc_type'), 'acc_capability': kw.get('acc_capability', 'acc_capability'), 'vendor_id': kw.get('vendor_id', 'vendor_id'), 'product_id': kw.get('product_id', 'product_id'), 'remotable': kw.get('remotable', 1), 'project_id': kw.get('project_id', 'b492a6fb12964ae3bd291ce585107d48'), 'user_id': kw.get('user_id', '7009409e21614d1db1ef7a8c5ee101d8'), } ",0,15
openstack%2Fcyborg~master~I0f515f0884848081e466bc61aa24e8f93fe1b5c5,openstack/cyborg,master,I0f515f0884848081e466bc61aa24e8f93fe1b5c5,Set default value in get fpga trait,MERGED,2020-01-14 06:21:01.000000000,2020-01-19 02:47:01.000000000,2020-01-19 02:45:51.000000000,"[{'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 28748}]","[{'number': 1, 'created': '2020-01-14 06:21:01.000000000', 'files': ['cyborg/accelerator/drivers/fpga/intel/sysinfo.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/801df7426607f985687e103ebff7ab82ee5ff3c2', 'message': ""Set default value in get fpga trait\n\nThis patch sets default value []. Because Line325 will iterator this values.\nIf None, will raise TypeError: 'NoneType' object is not iterable.\n\nChange-Id: I0f515f0884848081e466bc61aa24e8f93fe1b5c5\n""}]",0,702353,801df7426607f985687e103ebff7ab82ee5ff3c2,10,3,1,24872,,,0,"Set default value in get fpga trait

This patch sets default value []. Because Line325 will iterator this values.
If None, will raise TypeError: 'NoneType' object is not iterable.

Change-Id: I0f515f0884848081e466bc61aa24e8f93fe1b5c5
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/53/702353/1 && git format-patch -1 --stdout FETCH_HEAD,['cyborg/accelerator/drivers/fpga/intel/sysinfo.py'],1,801df7426607f985687e103ebff7ab82ee5ff3c2,fix_trait_get_none_error," values = fpga.get(k, [])"," values = fpga.get(k, None)",1,1
openstack%2Fcyborg-specs~master~Ib226cbf9fc1fb7d3146083d65c44d8e0b80e2a7b,openstack/cyborg-specs,master,Ib226cbf9fc1fb7d3146083d65c44d8e0b80e2a7b,add doc8 check,MERGED,2020-01-16 08:39:47.000000000,2020-01-19 02:14:24.000000000,2020-01-19 02:13:10.000000000,"[{'_account_id': 14107}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 25738}, {'_account_id': 26458}, {'_account_id': 28748}]","[{'number': 1, 'created': '2020-01-16 08:39:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/133f30561371932d9033b35e90ae7a008862a0f7', 'message': 'add doc8 check\n\nCurrent cyborg-specs has no check for trailing whitespace, which is found in\npatch[0]. Trailing whitespace is a big deal,we should avoid that. This\npatch added doc8 check that.\n\n[0]:https://review.opendev.org/#/c/699099/7/specs/ussuri/policy-defaults-refresh.rst\n\nChange-Id: Ib226cbf9fc1fb7d3146083d65c44d8e0b80e2a7b\n'}, {'number': 2, 'created': '2020-01-17 03:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/43b8c0266065cf6fedf5721e1b85553fb84ca692', 'message': 'add doc8 check\n\nCurrent cyborg-specs has no check for trailing whitespace, which is found in\npatch[0]. Trailing whitespace is a big deal,we should avoid that. This\npatch added doc8 check that.\n\n[0]:https://review.opendev.org/#/c/699099/7/specs/ussuri/policy-defaults-refresh.rst\n\nChange-Id: Ib226cbf9fc1fb7d3146083d65c44d8e0b80e2a7b\n'}, {'number': 3, 'created': '2020-01-17 03:57:00.000000000', 'files': ['requirements.txt', 'specs/stein/approved/cyborg-database-model-proposal.rst', 'specs/train/approved/device-profiles.rst', 'tox.ini', 'specs/train/approved/cyborg-accelerator-driver.rst'], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/6a764dc418b4f14eb450b48c70bf4b1634408cc6', 'message': 'add doc8 check\n\nCurrent cyborg-specs has no check for trailing whitespace, which is\nfound in patch[0]. Trailing whitespace is a big deal,we should avoid\nthat. This patch\n1. added doc8 check\n2. fixed doc8 failures caused by previous merged specs\n\n[0]:https://review.opendev.org/#/c/699099/7/specs/ussuri/policy-defaults-refresh.rst\n\nChange-Id: Ib226cbf9fc1fb7d3146083d65c44d8e0b80e2a7b\n'}]",2,702819,6a764dc418b4f14eb450b48c70bf4b1634408cc6,11,6,3,24872,,,0,"add doc8 check

Current cyborg-specs has no check for trailing whitespace, which is
found in patch[0]. Trailing whitespace is a big deal,we should avoid
that. This patch
1. added doc8 check
2. fixed doc8 failures caused by previous merged specs

[0]:https://review.opendev.org/#/c/699099/7/specs/ussuri/policy-defaults-refresh.rst

Change-Id: Ib226cbf9fc1fb7d3146083d65c44d8e0b80e2a7b
",git fetch https://review.opendev.org/openstack/cyborg-specs refs/changes/19/702819/2 && git format-patch -1 --stdout FETCH_HEAD,"['specs/stein/approved/cyborg-database-model-proposal.rst', 'specs/train/approved/device-profiles.rst', 'tox.ini', 'specs/train/approved/cyborg-accelerator-driver.rst']",4,133f30561371932d9033b35e90ae7a008862a0f7,add_doc8_check,"In general, these generic devices are the specific accelerators in some specific scenarios. For example:- As a security accelerator vendor, I want add the driver in Cyborg with security accelerator configure and device stats query","In general, these generic devices are the specific accelerators in some specific scenarios. For example:- As a security accelerator vendor, I want add the driver in Cyborg with security accelerator configure and device stats query",418,408
openstack%2Fironic-python-agent~master~I7167e71e5d2352a045565289b200e5530d0ba11d,openstack/ironic-python-agent,master,I7167e71e5d2352a045565289b200e5530d0ba11d,Avoid grub2-install when on UEFI boot mode,MERGED,2019-12-02 16:37:09.000000000,2020-01-19 02:10:09.000000000,2020-01-19 02:06:41.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-12-02 16:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fb8cee7225b400b40bdc133d3391e391e3fca90c', 'message': ""[WIP] Secure Boot\n\nTo avoid problems where we won't have the secure boot signatures we can\nrun with grub2, let's try to identify if secure boot is enable and\nif yes we will use a different workflow.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 2, 'created': '2019-12-06 15:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/15cd37ce66d0a329b4a753731b54e4a815110fda', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 3, 'created': '2019-12-09 14:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9b1fc6a3f4133b32cfb2682849d94460a38d302e', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 4, 'created': '2019-12-10 16:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/79edac9f8c8c3917a25da2f313543beaaf147297', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 5, 'created': '2019-12-11 09:48:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8e6bd3eeaaef9b878b127878e5024b6039d31384', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 6, 'created': '2019-12-11 15:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d597dbe4cae8d8f521e5dec03eff6fd7cf1cf510', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 7, 'created': '2019-12-12 13:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8048a17e94a6d1e2bf9405e8be8838dc961108b2', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 8, 'created': '2020-01-02 15:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/3602daad1d43f673f10eadc72546210e5ba27482', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 9, 'created': '2020-01-06 09:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b79c93fdd2ef836553930a2d491681473ceadcbb', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 10, 'created': '2020-01-07 10:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/709948603279a8b131248b846dc636d587cced5e', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 11, 'created': '2020-01-08 17:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/126e1a93138b29283b5601a8966819f5cc90bc7c', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 12, 'created': '2020-01-10 14:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a7e7ced1d0cb157825ff5272819b3b499dd3b0cb', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 13, 'created': '2020-01-10 15:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c057f6a7778a7429ac22c8a934f62578e6e24d49', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 14, 'created': '2020-01-13 10:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c0e3030572926762866e2a5aa075ba0214e2d515', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 15, 'created': '2020-01-15 20:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1a8c3b88727d500206e4cd5494969cfdde718810', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}, {'number': 16, 'created': '2020-01-16 10:23:49.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_image.py', 'ironic_python_agent/extensions/image.py', 'ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py', 'releasenotes/notes/avoid-grub2-using-efibootmgr-bd27c0978d1cf71b.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b6210be196fea271b2c49f89d3e1638517c1198c', 'message': ""Avoid grub2-install when on UEFI boot mode\n\nThis patch changes the workflow for whole disk images when using uefi.\nIf we can identify the bootloader and it's valid we can update using\nefibootmgr since grub2-install have problems specially on secure boot\nmode.\nWe also updated the regex to search for the uefi partition on the disk,\nsince in some cases the parted command output can be without the FS\nfor the partition with esp Flag.\n\nChange-Id: I7167e71e5d2352a045565289b200e5530d0ba11d\nStory: #2006847\nTask: #37435\n""}]",103,696914,b6210be196fea271b2c49f89d3e1638517c1198c,139,7,16,15519,,,0,"Avoid grub2-install when on UEFI boot mode

This patch changes the workflow for whole disk images when using uefi.
If we can identify the bootloader and it's valid we can update using
efibootmgr since grub2-install have problems specially on secure boot
mode.
We also updated the regex to search for the uefi partition on the disk,
since in some cases the parted command output can be without the FS
for the partition with esp Flag.

Change-Id: I7167e71e5d2352a045565289b200e5530d0ba11d
Story: #2006847
Task: #37435
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/14/696914/16 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/extensions/test_image.py', 'ironic_python_agent/extensions/image.py']",2,fb8cee7225b400b40bdc133d3391e391e3fca90c,uefi_workflow,"def _verify_secure_boot(device, root_uuid, efi_system_part_uuid): if efi_system_part_uuid: root_partition = _get_partition(device, uuid=root_uuid) efi_partition = None efi_partition_mount_point = None efi_mounted = False try: # Mount the partition and binds path = tempfile.mkdtemp() if efi_system_part_uuid: efi_partition = _get_partition(device, uuid=efi_system_part_uuid) efi_partition_mount_point = os.path.join(path, ""boot/efi"") utils.execute('mount', root_partition, path) utils.execute('mount', '-t', 'sysfs', 'none', path + '/sys') if efi_partition: if not os.path.exists(efi_partition_mount_point): os.makedirs(efi_partition_mount_point) utils.execute('mount', efi_partition, efi_partition_mount_point) efi_mounted = True sb_efivar = utils.execute('find', '/sys/firmware/efi/efivars', '-name', 'SecureBoot*') sb_files = sb_efivar[0].rstrip().split('\n') for sb_file in sb_files: od_output = utils.execute('od', '--address-radix=n', '--format=u1', sb_file) if od_output[0].rstrip().split('\n')[0].endswith('1'): return True return False except processutils.ProcessExecutionError as e: error_msg = ('Could not verify secure boot on device %(dev)s' 'failed with %(err)s.' % {'dev': device, 'err': e}) LOG.error(error_msg) raise errors.CommandExecutionError(error_msg) finally: umount_warn_msg = ""Unable to umount %(path)s. Error: %(error)s"" # Umount binds and partition umount_binds_fail = False try: if efi_mounted: utils.execute('umount', efi_partition_mount_point, attempts=3, delay_on_retry=True) except processutils.ProcessExecutionError as e: error_msg = ('Umounting efi system partition failed. ' 'Attempted 3 times. Error: %s' % e) LOG.error(error_msg) raise errors.CommandExecutionError(error_msg) try: utils.execute('umount', path + '/sys', attempts=3, delay_on_retry=True) except processutils.ProcessExecutionError as e: umount_binds_fail = True LOG.warning(umount_warn_msg, {'path': path + '/sys', 'error': e}) try: utils.execute('umount', path + '/sys', attempts=3, delay_on_retry=True) except processutils.ProcessExecutionError as e: umount_binds_fail = True LOG.warning(umount_warn_msg, {'path': path + '/sys', 'error': e}) # If umounting the binds succeed then we can try to delete it if not umount_binds_fail: try: utils.execute('umount', path, attempts=3, delay_on_retry=True) except processutils.ProcessExecutionError as e: LOG.warning(umount_warn_msg, {'path': path, 'error': e}) else: # After everything is umounted we can then remove the # temporary directory shutil.rmtree(path) else: return False def _install_uefi_secure_boot(device, root_uuid, efi_system_part_uuid): # TODO(iurygregory): Add workflow to use efibootmgr pass if _verify_secure_boot(device, root_uuid, efi_system_part_uuid): _install_uefi_secure_boot(device, root_uuid, efi_system_part_uuid) else: _install_grub2(device, root_uuid=root_uuid, efi_system_part_uuid=efi_system_part_uuid, prep_boot_part_uuid=prep_boot_part_uuid)"," _install_grub2(device, root_uuid=root_uuid, efi_system_part_uuid=efi_system_part_uuid, prep_boot_part_uuid=prep_boot_part_uuid)",108,5
openstack%2Fneutron~master~I0ce2c53c3c48dc74827ab14ceb7d3f9549b0dd38,openstack/neutron,master,I0ce2c53c3c48dc74827ab14ceb7d3f9549b0dd38,Disallow networks with first ip :: with dhcp enabled,ABANDONED,2020-01-17 07:24:35.000000000,2020-01-19 01:45:22.000000000,,"[{'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-17 07:24:35.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/319e668f7781be46603cbcbc00d61f9b6f708761', 'message': 'Disallow networks with first ip :: with dhcp enabled\n\nfixes dhcp-agent errors due to establishing ::1 as default gw\n\nChange-Id: I0ce2c53c3c48dc74827ab14ceb7d3f9549b0dd38\n'}]",0,703024,319e668f7781be46603cbcbc00d61f9b6f708761,6,4,1,30380,,,0,"Disallow networks with first ip :: with dhcp enabled

fixes dhcp-agent errors due to establishing ::1 as default gw

Change-Id: I0ce2c53c3c48dc74827ab14ceb7d3f9549b0dd38
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/703024/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,319e668f7781be46603cbcbc00d61f9b6f708761,," elif net.first == 0: error_message = _(""First IP '0.0.0.0' or '::' of network is "" ""not supported if enable_dhcp is True."")"," elif ip_ver == constants.IP_VERSION_4 and net.first == 0: error_message = _(""First IP '0.0.0.0' of network is not "" ""supported if enable_dhcp is True."")",3,3
openstack%2Fneutron~master~Ie2b5f85a9c0fc26676d44074424cf5a699303805,openstack/neutron,master,Ie2b5f85a9c0fc26676d44074424cf5a699303805,Add MariaDB 10.3 repository for Ubuntu Bionic,MERGED,2020-01-14 13:25:39.000000000,2020-01-19 01:41:24.000000000,2020-01-19 01:39:05.000000000,"[{'_account_id': 841}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-14 13:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e66c843dbdee00fe0a3f215e6f73d54aca2e0a56', 'message': 'Add MariaDB 10.4 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}, {'number': 2, 'created': '2020-01-14 13:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e42d772903429737a86712c7959c7acc0a27d78', 'message': 'Add MariaDB 10.4 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}, {'number': 3, 'created': '2020-01-14 13:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad6ae9b8d50c71cbed5b61c6d59d699274b35591', 'message': 'Add MariaDB 10.4 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}, {'number': 4, 'created': '2020-01-15 08:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f512ceaf672454b49b139dc5afbff49387e720d', 'message': 'Add MariaDB 10.3 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}, {'number': 5, 'created': '2020-01-15 11:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/25badfdc1f3b06e4fb60e6956806d03b5f30b4e4', 'message': 'Add MariaDB 10.3 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}, {'number': 6, 'created': '2020-01-16 10:05:39.000000000', 'files': ['playbooks/add_mariadb_repo.yaml', 'zuul.d/tempest-singlenode.yaml', 'roles/add_mariadb_repo/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1986865bd5587d303f79f54ff525b38b0bf98bb6', 'message': 'Add MariaDB 10.3 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}]",7,702416,1986865bd5587d303f79f54ff525b38b0bf98bb6,62,6,6,16688,,,0,"Add MariaDB 10.3 repository for Ubuntu Bionic

In order to execute the periodic job ""neutron-tempest-mariadb-full"",
using Ubuntu Bionic and MariaDB, a newer version is needed than the
default package version distributed (10.1).

Devstack gates are tested with MySQL 5.7. Current Neutron DB schema
is not working with the reported version 10.1.

Change-Id: Ie2b5f85a9c0fc26676d44074424cf5a699303805
Related-Bug: #1855912
Related-Bug: #1841907
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/702416/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/add_mariadb_repo.yaml', 'roles/add_mariadb_repo/tasks/main.yaml']",2,e66c843dbdee00fe0a3f215e6f73d54aca2e0a56,bug/1855912,"- name: Add apt key from hkp://keyserver.ubuntu.com:80 shell: cmd: apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xF1656F24C74CD1D8 executable: /bin/bash become: yes when: - ansible_facts['distribution_release'] == ""bionic"" - ansible_facts['distribution'] == ""Ubuntu"" - name: Add MariaBD 10.4 repository (https://bugs.launchpad.net/neutron/+bug/1855912) apt_repository: repo: deb [arch=amd64,arm64,ppc64el] http://ftp.hosteurope.de/mirror/mariadb.org/repo/10.4/ubuntu bionic main state: present ",,16,0
openstack%2Fcyborg~master~Iab7ad181ce52848182f3295a8e14afb605c7382e,openstack/cyborg,master,Iab7ad181ce52848182f3295a8e14afb605c7382e,Add Cyborg quickstart reference in devstack,ABANDONED,2019-12-05 07:51:05.000000000,2020-01-19 01:15:13.000000000,,"[{'_account_id': 13629}, {'_account_id': 14107}, {'_account_id': 14131}, {'_account_id': 17813}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 25738}, {'_account_id': 26458}, {'_account_id': 28748}]","[{'number': 1, 'created': '2019-12-05 07:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/2c516d942d4bd24f6df58842965aa59b21405237', 'message': 'Add cyborg quickstart reference in devstack\n\nWhile deploy the cyborg in devstack, cannot enable the cyborg\nservice precise, so add a quick guide to enable cyborg service in\ndevstack.\n\nChange-Id: Iab7ad181ce52848182f3295a8e14afb605c7382e\n'}, {'number': 2, 'created': '2019-12-09 03:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f6249677c53b1d7d0b4504e5b11cd1f6d7d42a53', 'message': 'Add cyborg quickstart reference in devstack\n\nWhile deploy the cyborg in devstack, cannot enable the cyborg\nservice precise, so add a quick guide to enable cyborg service in\ndevstack.\n\nChange-Id: Iab7ad181ce52848182f3295a8e14afb605c7382e\n'}, {'number': 3, 'created': '2020-01-07 06:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/b522813c067a360d09ea2229c675baf074bc4090', 'message': 'Add cyborg quickstart reference in devstack\n\nWhile deploy the cyborg in devstack, cannot enable the cyborg\nservice precise, so add a quick guide to enable cyborg service in\ndevstack.\n\nChange-Id: Iab7ad181ce52848182f3295a8e14afb605c7382e\n'}, {'number': 4, 'created': '2020-01-16 00:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/b7a7fc64bf659b4e504061f75ae43a852068e20f', 'message': 'Add cyborg quickstart reference in devstack\n\nWhile deploy the Cyborg in devstack, cannot enable the cyborg\nservice precise, so add a quick guide to enable cyborg service in\ndevstack.\n\nChange-Id: Iab7ad181ce52848182f3295a8e14afb605c7382e\n'}, {'number': 5, 'created': '2020-01-16 03:06:18.000000000', 'files': ['devstack/README.rst'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/57dfe1d84fb2ac36395bc77669258c02a7843923', 'message': 'Add Cyborg quickstart reference in devstack\n\nWhile deploy the Cyborg in devstack, cannot enable the Cyborg\nservice precise, so add a quick guide to enable Cyborg service in\ndevstack.\n\nChange-Id: Iab7ad181ce52848182f3295a8e14afb605c7382e\n'}]",9,697419,57dfe1d84fb2ac36395bc77669258c02a7843923,30,9,5,26458,,,0,"Add Cyborg quickstart reference in devstack

While deploy the Cyborg in devstack, cannot enable the Cyborg
service precise, so add a quick guide to enable Cyborg service in
devstack.

Change-Id: Iab7ad181ce52848182f3295a8e14afb605c7382e
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/19/697419/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/README.rst'],1,2c516d942d4bd24f6df58842965aa59b21405237,setup_cyborg_in_devstack,==================== Enabling in Devstack ==================== We can enable the cyborg service in DevStack by the following steps can be used as a quickstart reference: 1. Download DevStack 2. Add this repo as an external repository:: > cat local.conf [[local|localrc]] # Enable cyborg enable_plugin cyborg https://git.openstack.org/openstack/cyborg 3. run ``stack.sh`` ,,17,0
openstack%2Ffreezer-tempest-plugin~master~Ia76bae610434c49a164b30c5c66cbd62accdb9c5,openstack/freezer-tempest-plugin,master,Ia76bae610434c49a164b30c5c66cbd62accdb9c5,Update freezer-tempest-agent job to voting job,MERGED,2020-01-16 05:42:18.000000000,2020-01-19 01:04:37.000000000,2020-01-19 01:04:37.000000000,"[{'_account_id': 21069}, {'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 05:42:18.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/3daaebe4f89d4b69915757eb5b43c212b5ba103b', 'message': 'Update freezer-tempest-agent job to voting job\n\nUpdate freezer-tempets-agent job to voting job\n\nChange-Id: Ia76bae610434c49a164b30c5c66cbd62accdb9c5\n'}]",0,702800,3daaebe4f89d4b69915757eb5b43c212b5ba103b,10,3,1,21069,,,0,"Update freezer-tempest-agent job to voting job

Update freezer-tempets-agent job to voting job

Change-Id: Ia76bae610434c49a164b30c5c66cbd62accdb9c5
",git fetch https://review.opendev.org/openstack/freezer-tempest-plugin refs/changes/00/702800/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3daaebe4f89d4b69915757eb5b43c212b5ba103b,Recover  freezer-tempest-agent job, - freezer-tempest-agent - freezer-tempest-agent, - freezer-tempest-agent: voting: false - freezer-tempest-agent: voting: false,2,4
openstack%2Fpatrole~master~If7c6ae7fc57a4ac256cf668c4075ee86143202ea,openstack/patrole,master,If7c6ae7fc57a4ac256cf668c4075ee86143202ea,Add skip check to tests that modify the user source,MERGED,2019-08-23 15:43:26.000000000,2020-01-19 00:13:59.000000000,2020-01-19 00:12:37.000000000,"[{'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8911}, {'_account_id': 16274}, {'_account_id': 17887}, {'_account_id': 17896}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23185}, {'_account_id': 23186}, {'_account_id': 23625}, {'_account_id': 30745}]","[{'number': 1, 'created': '2019-08-23 15:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/441c40bf919fc764a920ffe2920552d5502b85ef', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 2, 'created': '2019-08-29 14:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/adbc709df624ccc4961829e75fa43014a679db22', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 3, 'created': '2019-09-03 19:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/2d5747eb16a595f2bfaf1c6a67b885ee87f6e1c8', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 4, 'created': '2019-09-04 18:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/c01682cef65811b268837d776062eeaf2ab0b40a', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 5, 'created': '2019-09-10 20:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/cf998f3e85a6a53887e53faca39a96f5545b2755', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 6, 'created': '2019-09-19 13:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/a913d68b430a47207d2070bbe08ed36f0adcc32f', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 7, 'created': '2019-09-19 19:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/a858411a3fb7e7aff101d49765ca60b24ff5c501', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating, and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 8, 'created': '2020-01-10 21:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/b6e3afc50e64f2f166fd66f9822c4fd220b8edfb', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}, {'number': 9, 'created': '2020-01-13 15:03:07.000000000', 'files': ['patrole_tempest_plugin/tests/api/identity/v3/test_roles_rbac.py', 'patrole_tempest_plugin/tests/api/identity/v3/test_groups_rbac.py', 'patrole_tempest_plugin/tests/api/identity/v3/test_credentials_rbac.py', 'patrole_tempest_plugin/tests/api/identity/v3/test_users_rbac.py', 'patrole_tempest_plugin/tests/api/identity/v3/test_trusts_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/39ad28a2a881531939c471b8c8127ca571eb40ab', 'message': 'Add skip check to tests that modify the user source\n\nWhen using an immutable user source, test should skip if the\ntest tries to modify the user source. This includes creating,\nupdating and deleting users. A similar change was merged here:\nhttps://review.opendev.org/#/c/670590/\n\nChange-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea\n'}]",14,678260,39ad28a2a881531939c471b8c8127ca571eb40ab,50,17,9,17896,,,0,"Add skip check to tests that modify the user source

When using an immutable user source, test should skip if the
test tries to modify the user source. This includes creating,
updating and deleting users. A similar change was merged here:
https://review.opendev.org/#/c/670590/

Change-Id: If7c6ae7fc57a4ac256cf668c4075ee86143202ea
",git fetch https://review.opendev.org/openstack/patrole refs/changes/60/678260/9 && git format-patch -1 --stdout FETCH_HEAD,"['patrole_tempest_plugin/tests/api/identity/v3/test_users_rbac.py', 'patrole_tempest_plugin/tests/api/identity/v3/test_trusts_rbac.py']",2,441c40bf919fc764a920ffe2920552d5502b85ef,skip_check_to_tests_that_modify_user_source, if CONF.identity_feature_enabled.immutable_user_source: raise cls.skipException('Skipped because environment has an ' 'immutable user source and solely ' 'provides read-only access to users.'),,15,0
openstack%2Fironic~master~I4433c72c9dd0315f1e25a6f3f8fcc7a2cffd3a22,openstack/ironic,master,I4433c72c9dd0315f1e25a6f3f8fcc7a2cffd3a22,DNM try further reducing RAM in DIB jobs,ABANDONED,2020-01-15 16:58:29.000000000,2020-01-18 21:40:41.000000000,,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 16:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/11de6561b820a94f03ce6513b57b73308d1920dd', 'message': 'DNM try further reducing RAM in DIB jobs\n\nChange-Id: I4433c72c9dd0315f1e25a6f3f8fcc7a2cffd3a22\n'}, {'number': 2, 'created': '2020-01-17 22:34:27.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6bad9ca31aa801782483ac8b2e82d0682aaaf4c2', 'message': 'DNM try further reducing RAM in DIB jobs\n\nChange-Id: I4433c72c9dd0315f1e25a6f3f8fcc7a2cffd3a22\n'}]",0,702702,6bad9ca31aa801782483ac8b2e82d0682aaaf4c2,12,5,2,10239,,,0,"DNM try further reducing RAM in DIB jobs

Change-Id: I4433c72c9dd0315f1e25a6f3f8fcc7a2cffd3a22
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/702702/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,11de6561b820a94f03ce6513b57b73308d1920dd,temp, IRONIC_VM_SPECS_RAM: 1536, IRONIC_VM_SPECS_RAM: 2048,1,1
openstack%2Fneutron~master~I9825fbf69c9e1cd543794daadad2c43826fab8d5,openstack/neutron,master,I9825fbf69c9e1cd543794daadad2c43826fab8d5,"Revert ""Subnet gateway should be a valid IP""",ABANDONED,2020-01-10 11:48:14.000000000,2020-01-18 19:16:26.000000000,,"[{'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 13252}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26106}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-10 11:48:14.000000000', 'files': ['neutron/db/ipam_backend_mixin.py', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/tests/unit/extensions/test_network_ip_availability.py', 'neutron/tests/fullstack/resources/client.py', 'neutron/tests/fullstack/test_subnet.py', 'neutron/tests/unit/db/test_ipam_pluggable_backend.py', 'neutron/ipam/utils.py', 'neutron/tests/unit/services/ovn_l3/test_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7d4ad3fd4ddc12159c52aa33ee6065d533e4e4c', 'message': 'Revert ""Subnet gateway should be a valid IP""\n\nThis causes a regression when updating non-router ports, see [0].\n\n[0] https://bugs.launchpad.net/neutron/+bug/1859163\n\nThis reverts commit 505be9e18f0b5f46662fb030754e6c15192186d8.\n\nChange-Id: I9825fbf69c9e1cd543794daadad2c43826fab8d5\n'}]",1,701939,d7d4ad3fd4ddc12159c52aa33ee6065d533e4e4c,8,12,1,13252,,,0,"Revert ""Subnet gateway should be a valid IP""

This causes a regression when updating non-router ports, see [0].

[0] https://bugs.launchpad.net/neutron/+bug/1859163

This reverts commit 505be9e18f0b5f46662fb030754e6c15192186d8.

Change-Id: I9825fbf69c9e1cd543794daadad2c43826fab8d5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/701939/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/ipam_backend_mixin.py', 'neutron/tests/unit/db/test_db_base_plugin_v2.py', 'neutron/tests/unit/extensions/test_network_ip_availability.py', 'neutron/tests/fullstack/resources/client.py', 'neutron/tests/fullstack/test_subnet.py', 'neutron/tests/unit/db/test_ipam_pluggable_backend.py', 'neutron/ipam/utils.py', 'neutron/tests/unit/services/ovn_l3/test_plugin.py']",8,d7d4ad3fd4ddc12159c52aa33ee6065d533e4e4c,bug/1856726," mock.call(mock.ANY, ip_prefix='::/0', nexthop='2001:db8::1')]"," mock.call(mock.ANY, ip_prefix='::/0', nexthop='2001:db8::')]",31,128
openstack%2Fkolla~master~I1af17edc9671237d270c5c6fe70e4420199bdb02,openstack/kolla,master,I1af17edc9671237d270c5c6fe70e4420199bdb02,Debian/source: do not force tag in build jobs,MERGED,2020-01-14 14:28:03.000000000,2020-01-18 19:09:03.000000000,2020-01-15 11:19:52.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-14 14:28:03.000000000', 'files': ['tests/test_build.py', 'tests/templates/kolla-build.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ca4da16836e4b3ef1d84059a63378c3f5bb2517e', 'message': ""Debian/source: do not force tag in build jobs\n\nMultiarch publisher uses 'branch-arch' so set it in kolla-build.conf\nfile.\n\nChange-Id: I1af17edc9671237d270c5c6fe70e4420199bdb02\n""}]",2,702442,ca4da16836e4b3ef1d84059a63378c3f5bb2517e,13,3,1,24072,,,0,"Debian/source: do not force tag in build jobs

Multiarch publisher uses 'branch-arch' so set it in kolla-build.conf
file.

Change-Id: I1af17edc9671237d270c5c6fe70e4420199bdb02
",git fetch https://review.opendev.org/openstack/kolla refs/changes/42/702442/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_build.py', 'tests/templates/kolla-build.conf.j2']",2,ca4da16836e4b3ef1d84059a63378c3f5bb2517e,,{% set tag_suffix = '-' ~ base_arch if base_distro == 'debian' and install_type == 'source' else '' %},,1,3
openstack%2Fdevstack~master~I6f4a1cde921b687d527a4098cd2db39b422f6257,openstack/devstack,master,I6f4a1cde921b687d527a4098cd2db39b422f6257,Move OVN DevStack logic into Neutron,ABANDONED,2019-11-26 15:26:20.000000000,2020-01-18 18:52:24.000000000,,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-11-26 15:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/359b1acc2d54d3ba02446b7ece08aa67a1dde4a9', 'message': 'Move OVN DevStack logic into Neutron\n\nThe Neutron and networking-ovn projects are getting merged and the code\nused to setup networkig-ovn will now co-exist with the Neutron DevStack\nplugin.\n\nThis patch moves the logic to install and setup networking-ovn to the\nNeutron DevStack plugin.\n\nNote that neutron-legacy is used here since the ""new"" neutron module\ndoes not work properly (I was told).\n\nAs a first step, this plugin will continue to use the\nopenstack/networking-ovn repository and, as we advance into the mergings\nsteps we will modify this plugin (just few lines) to use the code in\nthe Neutron repository itself.\n\nTODO\'s where left in the code on top of all the bits that will change\nonce the networking-ovn code is merged into Neutron.\n\nBelow is a snippet of the what needs to be enabled in local.conf to get\nOVN deployed:\n\n[[local|localrc]]\n\nQ_AGENT=ovn\nQ_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger\nQ_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve\nQ_ML2_TENANT_NETWORK_TYPE=""geneve""\nQ_ML2_PLUGIN_EXT_DRIVERS=port_security,dns\n\nImplements: blueprint neutron-ovn-merge\nChange-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 2, 'created': '2019-11-26 15:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a9cf8c928fb43579beaa95a44adf8177825542c5', 'message': 'Move OVN DevStack logic into Neutron\n\nThe Neutron and networking-ovn projects are getting merged and the code\nused to setup networkig-ovn will now co-exist with the Neutron DevStack\nplugin.\n\nThis patch moves the logic to install and setup networking-ovn to the\nNeutron DevStack plugin.\n\nNote that neutron-legacy is used here since the ""new"" neutron module\ndoes not work properly (I was told).\n\nAs a first step, this plugin will continue to use the\nopenstack/networking-ovn repository and, as we advance into the mergings\nsteps we will modify this plugin (just few lines) to use the code in\nthe Neutron repository itself.\n\nTODO\'s where left in the code on top of all the bits that will change\nonce the networking-ovn code is merged into Neutron.\n\nBelow is a snippet of the what needs to be enabled in local.conf to get\nOVN deployed:\n\n[[local|localrc]]\n\nQ_AGENT=ovn\nQ_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger\nQ_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve\nQ_ML2_TENANT_NETWORK_TYPE=""geneve""\nQ_ML2_PLUGIN_EXT_DRIVERS=port_security,dns\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 3, 'created': '2019-11-26 20:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/5c2bb5d1043ff44d75c3ad53a1203f3081cad7d1', 'message': 'Move OVN DevStack logic into Neutron\n\nThe Neutron and networking-ovn projects are getting merged and the code\nused to setup networkig-ovn will now co-exist with the Neutron DevStack\nplugin.\n\nThis patch moves the logic to install and setup networking-ovn to the\nNeutron DevStack plugin.\n\nNote that neutron-legacy is used here since the ""new"" neutron module\ndoes not work properly (I was told).\n\nAs a first step, this plugin will continue to use the\nopenstack/networking-ovn repository and, as we advance into the mergings\nsteps we will modify this plugin (just few lines) to use the code in\nthe Neutron repository itself.\n\nTODO\'s where left in the code on top of all the bits that will change\nonce the networking-ovn code is merged into Neutron.\n\nBelow is a snippet of the what needs to be enabled in local.conf to get\nOVN deployed:\n\n[[local|localrc]]\n\nQ_AGENT=ovn\nQ_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger\nQ_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve\nQ_ML2_TENANT_NETWORK_TYPE=""geneve""\nQ_ML2_PLUGIN_EXT_DRIVERS=port_security,dns\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 4, 'created': '2019-11-27 10:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b6613a3675e1318d5b937abd1cef0cbe81652da9', 'message': 'Move OVN DevStack logic into Neutron\n\nThe Neutron and networking-ovn projects are getting merged and the code\nused to setup networkig-ovn will now co-exist with the Neutron DevStack\nplugin.\n\nThis patch moves the logic to install and setup networking-ovn to the\nNeutron DevStack plugin.\n\nNote that neutron-legacy is used here since the ""new"" neutron module\ndoes not work properly (I was told).\n\nAs a first step, this plugin will continue to use the\nopenstack/networking-ovn repository and, as we advance into the mergings\nsteps we will modify this plugin (just few lines) to use the code in\nthe Neutron repository itself.\n\nTODO\'s where left in the code on top of all the bits that will change\nonce the networking-ovn code is merged into Neutron.\n\nBelow is a snippet of the what needs to be enabled in local.conf to get\nOVN deployed:\n\n[[local|localrc]]\n\nQ_AGENT=ovn\nQ_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger\nQ_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve\nQ_ML2_TENANT_NETWORK_TYPE=""geneve""\nQ_ML2_PLUGIN_EXT_DRIVERS=port_security,dns\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 5, 'created': '2019-11-27 11:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/abe4684e8a9699b310d0c2c52a9954bc1ce0cc6c', 'message': 'Move OVN DevStack logic into Neutron\n\nThe Neutron and networking-ovn projects are getting merged and the code\nused to setup networkig-ovn will now co-exist with the Neutron DevStack\nplugin.\n\nThis patch moves the logic to install and setup networking-ovn to the\nNeutron DevStack plugin.\n\nNote that neutron-legacy is used here since the ""new"" neutron module\ndoes not work properly (I was told).\n\nAs a first step, this plugin will continue to use the\nopenstack/networking-ovn repository and, as we advance into the mergings\nsteps we will modify this plugin (just few lines) to use the code in\nthe Neutron repository itself.\n\nTODO\'s where left in the code on top of all the bits that will change\nonce the networking-ovn code is merged into Neutron.\n\nBelow is a snippet of the what needs to be enabled in local.conf to get\nOVN deployed:\n\n[[local|localrc]]\n\nQ_AGENT=ovn\nQ_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger\nQ_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve\nQ_ML2_TENANT_NETWORK_TYPE=""geneve""\nQ_ML2_PLUGIN_EXT_DRIVERS=port_security,dns\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 6, 'created': '2019-11-27 14:05:09.000000000', 'files': ['lib/neutron_plugins/ovn', 'tests/test_libs_from_pypi.sh', 'stackrc', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9113e051544ebed98175d9c4807b4736e9967ec0', 'message': 'Move OVN DevStack logic into Neutron\n\nThe Neutron and networking-ovn projects are getting merged and the code\nused to setup networkig-ovn will now co-exist with the Neutron DevStack\nplugin.\n\nThis patch moves the logic to install and setup networking-ovn to the\nNeutron DevStack plugin.\n\nNote that neutron-legacy is used here since the ""new"" neutron module\ndoes not work properly (I was told).\n\nAs a first step, this plugin will continue to use the\nopenstack/networking-ovn repository and, as we advance into the mergings\nsteps we will modify this plugin (just few lines) to use the code in\nthe Neutron repository itself.\n\nTODO\'s where left in the code on top of all the bits that will change\nonce the networking-ovn code is merged into Neutron.\n\nBelow is a snippet of the what needs to be enabled in local.conf to get\nOVN deployed:\n\n[[local|localrc]]\n\nQ_AGENT=ovn\nQ_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger\nQ_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve\nQ_ML2_TENANT_NETWORK_TYPE=""geneve""\nQ_ML2_PLUGIN_EXT_DRIVERS=port_security,dns\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",6,696109,9113e051544ebed98175d9c4807b4736e9967ec0,25,7,6,6773,,,0,"Move OVN DevStack logic into Neutron

The Neutron and networking-ovn projects are getting merged and the code
used to setup networkig-ovn will now co-exist with the Neutron DevStack
plugin.

This patch moves the logic to install and setup networking-ovn to the
Neutron DevStack plugin.

Note that neutron-legacy is used here since the ""new"" neutron module
does not work properly (I was told).

As a first step, this plugin will continue to use the
openstack/networking-ovn repository and, as we advance into the mergings
steps we will modify this plugin (just few lines) to use the code in
the Neutron repository itself.

TODO's where left in the code on top of all the bits that will change
once the networking-ovn code is merged into Neutron.

Below is a snippet of the what needs to be enabled in local.conf to get
OVN deployed:

[[local|localrc]]

Q_AGENT=ovn
Q_ML2_PLUGIN_MECHANISM_DRIVERS=ovn,logger
Q_ML2_PLUGIN_TYPE_DRIVERS=local,flat,vlan,geneve
Q_ML2_TENANT_NETWORK_TYPE=""geneve""
Q_ML2_PLUGIN_EXT_DRIVERS=port_security,dns

Related-Blueprint: neutron-ovn-merge
Change-Id: I6f4a1cde921b687d527a4098cd2db39b422f6257
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/09/696109/3 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron_plugins/ovn', 'stackrc', 'lib/neutron-legacy']",3,359b1acc2d54d3ba02446b7ece08aa67a1dde4a9,bp/neutron-ovn-merge,# OVN driver functions source $TOP_DIR/lib/neutron_plugins/ovn if is_ovn_enabled; then configure_ovn fi if is_ovn_enabled; then init_ovn fi # OVN driver sanity check and installation if is_ovn_enabled; then install_ovn fi if is_ovn_enabled; then start_ovn fi if is_ovn_enabled; then stop_ovn fi if is_ovn_enabled; then cleanup_ovn fi,,758,0
openstack%2Fgovernance-uc~master~I47d3eec9f779589a3e1f7268ef77ff13232469d3,openstack/governance-uc,master,I47d3eec9f779589a3e1f7268ef77ff13232469d3,"Revert ""UC Feb 2019 Election""",ABANDONED,2020-01-18 17:56:56.000000000,2020-01-18 17:59:57.000000000,,"[{'_account_id': 2033}, {'_account_id': 8181}, {'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 30855}]","[{'number': 1, 'created': '2020-01-18 17:56:56.000000000', 'files': ['doc/source/index.rst', 'reference/uc-election-feb2020.rst'], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/b48376fac48fad1d936af3a36a59c23e506eb0b0', 'message': 'Revert ""UC Feb 2019 Election""\n\nThis reverts commit 6dcfb3437ec4502ffba18dcb13bc0ddc6ce264f7.\n\nIncorrectly says 2019 instead of 2020\nIncorrectly says Sept instead of Feb\n\nChange-Id: I47d3eec9f779589a3e1f7268ef77ff13232469d3\n'}]",0,703250,b48376fac48fad1d936af3a36a59c23e506eb0b0,2,5,1,24100,,,0,"Revert ""UC Feb 2019 Election""

This reverts commit 6dcfb3437ec4502ffba18dcb13bc0ddc6ce264f7.

Incorrectly says 2019 instead of 2020
Incorrectly says Sept instead of Feb

Change-Id: I47d3eec9f779589a3e1f7268ef77ff13232469d3
",git fetch https://review.opendev.org/openstack/governance-uc refs/changes/50/703250/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'reference/uc-election-feb2020.rst']",2,b48376fac48fad1d936af3a36a59c23e506eb0b0,UC Feb 2019 Election,,"========================== UC Elections February 2020 ========================== We expect all members of our community to adhere to the highest standards of behavior during User Committee elections. Officials ========= | TBD Election System =============== Elections will be held using CIVS and a Condorcet algorithm (Schulze/Beatpath/CSSD variant). Any tie will be broken using `Governance/TieBreaking <https://wiki.openstack.org/wiki/Governance/TieBreaking>`_. Timeline ======== | February 03 - February 16, 05:59 UTC: Open candidacy for UC positions | February 17 - February 23, 11:59 UTC: UC elections (voting) Elected Positions ================= Under the rules of the UC charter, we need to elect 3 UC seats for this election. Seats are valid for one-year term. Electorate ========== The electorate for this election are the Foundation individual members that are also Active User Contributors (AUC) over the last six months. The electorate is requested to confirm their email address and (if applicable) IRC handle in their `Foundation Member Profile <https://openstack.org/profile>`_, prior to February 16, 2019 05:59 UTC so that the emailed ballots are mailed to the correct email address. Candidates ========== Any individual member of the foundation who is an Active User Contributor (AUC) can propose their candidacy (except two of the three recently elected members). Self-nomination is common, no third party nomination is required. Nominate by sending an email to the openstack-discuss@lists.openstack.org mailing-list, with the subject: ""UC Candidacy"" by February 17, 05:59 UTC. The email can include a description of the candidate platform. The candidacy is then confirmed by one of the election officials, after verification of the electorate status of the candidate. Result ====== | TBD",0,54
openstack%2Fgovernance-uc~master~Ic853b74b1d5d09ca0804d43813511415f225762a,openstack/governance-uc,master,Ic853b74b1d5d09ca0804d43813511415f225762a,UC Feb 2019 Election,MERGED,2019-12-28 19:57:56.000000000,2020-01-18 17:56:56.000000000,2020-01-18 17:28:49.000000000,"[{'_account_id': 2033}, {'_account_id': 8181}, {'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 24100}, {'_account_id': 30855}]","[{'number': 1, 'created': '2019-12-28 19:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/5c8b6219acd43d89b65d7e98db9e33adee022d38', 'message': 'UC Feb 2019 Election\n\nChange-Id: Ic853b74b1d5d09ca0804d43813511415f225762a\n'}, {'number': 2, 'created': '2019-12-28 20:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/e1fdb59c350ea539ab442fcc80cb804b41fcc25a', 'message': 'UC Feb 2019 Election\n\nChange-Id: Ic853b74b1d5d09ca0804d43813511415f225762a\n'}, {'number': 3, 'created': '2019-12-28 20:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/32412839d9b7964229867f0f4d17d324b97756a9', 'message': 'UC Feb 2019 Election\n\nWorking on the assumption that there will be 2 members up for election \ndown from the usual 3.\nChange-Id: Ic853b74b1d5d09ca0804d43813511415f225762a\n'}, {'number': 4, 'created': '2019-12-30 02:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/13ab0d9ed287ab2ef2f6be37c351dd72b9d20c89', 'message': 'UC Feb 2019 Election\n\nWorking on the assumption that there will be 1 members up for election \ndown from the usual 3 for a total of 3 elected officials at any one\ntime. One elected in Feb and two in September.\nChange-Id: Ic853b74b1d5d09ca0804d43813511415f225762a\n'}, {'number': 5, 'created': '2020-01-16 14:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/c4c0b6f84a79cedcc81c10e02c7656017ab82515', 'message': 'UC Feb 2019 Election\n\nThere will be the usual 3 members up for election.\n\nChange-Id: Ic853b74b1d5d09ca0804d43813511415f225762a\n'}, {'number': 6, 'created': '2020-01-16 14:34:19.000000000', 'files': ['doc/source/index.rst', 'reference/uc-election-feb2020.rst'], 'web_link': 'https://opendev.org/openstack/governance-uc/commit/6dcfb3437ec4502ffba18dcb13bc0ddc6ce264f7', 'message': 'UC Feb 2019 Election\n\nThere will be the usual 3 members up for election.\n\nChange-Id: Ic853b74b1d5d09ca0804d43813511415f225762a\n'}]",1,700732,6dcfb3437ec4502ffba18dcb13bc0ddc6ce264f7,35,6,6,24100,,,0,"UC Feb 2019 Election

There will be the usual 3 members up for election.

Change-Id: Ic853b74b1d5d09ca0804d43813511415f225762a
",git fetch https://review.opendev.org/openstack/governance-uc refs/changes/32/700732/5 && git format-patch -1 --stdout FETCH_HEAD,[],0,5c8b6219acd43d89b65d7e98db9e33adee022d38,UC Feb 2019 Election,,,0,0
openstack%2Fopenstack-zuul-jobs~master~I8473ee74dcbf9d97c1de13f8a3a203935c62b73e,openstack/openstack-zuul-jobs,master,I8473ee74dcbf9d97c1de13f8a3a203935c62b73e,Remove legacy-ubuntu-trusty nodeset,MERGED,2020-01-15 23:07:11.000000000,2020-01-18 15:44:29.000000000,2020-01-18 15:42:47.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 23:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/9a91cda97460d738517ec01e5f5ec31e6a2f367a', 'message': 'Remove legacy-ubuntu-trusty nodeset\n\nRemove the now unused legacy-gearman-plugin-mavin-build-ubuntu-trusty\njob from dependent change, and remove now unused legacy-ubuntu-trusty\nnodeset.\n\nChange-Id: I8473ee74dcbf9d97c1de13f8a3a203935c62b73e\nDepends-On: https://review.opendev.org/702769\n'}, {'number': 2, 'created': '2020-01-15 23:09:46.000000000', 'files': ['playbooks/legacy/gearman-plugin-maven-build-ubuntu-trusty/run.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'zuul.d/nodesets.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/1a4dcb03d29a2c019dac8c4a4c3a34d814549097', 'message': 'Remove legacy-ubuntu-trusty nodeset\n\nRemove the now unused legacy-gearman-plugin-mavin-build-ubuntu-trusty\njob from dependent change, and remove now unused legacy-ubuntu-trusty\nnodeset.\n\nChange-Id: I8473ee74dcbf9d97c1de13f8a3a203935c62b73e\nDepends-On: https://review.opendev.org/702769\n'}]",0,702771,1a4dcb03d29a2c019dac8c4a4c3a34d814549097,11,3,2,7118,,,0,"Remove legacy-ubuntu-trusty nodeset

Remove the now unused legacy-gearman-plugin-mavin-build-ubuntu-trusty
job from dependent change, and remove now unused legacy-ubuntu-trusty
nodeset.

Change-Id: I8473ee74dcbf9d97c1de13f8a3a203935c62b73e
Depends-On: https://review.opendev.org/702769
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/71/702771/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'zuul.d/nodesets.yaml']",2,9a91cda97460d738517ec01e5f5ec31e6a2f367a,trusty-removal,, name: legacy-ubuntu-trusty nodes: - name: primary label: ubuntu-trusty - nodeset:,0,13
openstack%2Fdevstack~master~Ic5402f57052648e10eacf3c3de67d2cdd2d42f63,openstack/devstack,master,Ic5402f57052648e10eacf3c3de67d2cdd2d42f63,"Revert ""Stop enabling g-reg by default""",MERGED,2020-01-17 17:42:35.000000000,2020-01-18 15:41:17.000000000,2020-01-18 07:05:08.000000000,"[{'_account_id': 8556}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-17 17:42:35.000000000', 'files': ['.zuul.yaml', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/98f3bbe509c2de9efaf4f3fc1b5dbc42d7a67987', 'message': 'Revert ""Stop enabling g-reg by default""\n\nThis reverts commit d7dfcdb4674daae8a294848b1de6fa87c5d7d4eb. A\nsubsquent change that depends on this,\nd8dec362baa2bf7f6ffe1c47352fdbe032eaf20a, has knock on effects for\ndevstack-gate and needs to be reverted. Revert this first.\n\nChange-Id: Ic5402f57052648e10eacf3c3de67d2cdd2d42f63\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nPartial-bug: #1860021\n'}]",0,703137,98f3bbe509c2de9efaf4f3fc1b5dbc42d7a67987,11,4,1,15334,,,0,"Revert ""Stop enabling g-reg by default""

This reverts commit d7dfcdb4674daae8a294848b1de6fa87c5d7d4eb. A
subsquent change that depends on this,
d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a, has knock on effects for
devstack-gate and needs to be reverted. Revert this first.

Change-Id: Ic5402f57052648e10eacf3c3de67d2cdd2d42f63
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Partial-bug: #1860021
",git fetch https://review.opendev.org/openstack/devstack refs/changes/37/703137/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'stackrc']",2,98f3bbe509c2de9efaf4f3fc1b5dbc42d7a67987,bug/1860021," ENABLED_SERVICES+=,g-api,g-reg"," ENABLED_SERVICES+=,g-api",2,1
openstack%2Fproject-config~master~I9b272782c83cff4e456958be2eb3a38ec60aca6a,openstack/project-config,master,I9b272782c83cff4e456958be2eb3a38ec60aca6a,Remove trusty wheel jobs,MERGED,2020-01-15 23:19:50.000000000,2020-01-18 15:25:34.000000000,2020-01-18 15:25:34.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 23:19:50.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ca52e809bdfb8ec2e9433b925e232d8f2dd2a9ea', 'message': 'Remove trusty wheel jobs\n\nRemove trusty wheel jobs in preparation for node removal.  No jobs\nshould be using the wheels any more.\n\nDepends-On: https://review.opendev.org/702773\nChange-Id: I9b272782c83cff4e456958be2eb3a38ec60aca6a\n'}]",0,702774,ca52e809bdfb8ec2e9433b925e232d8f2dd2a9ea,14,3,1,7118,,,0,"Remove trusty wheel jobs

Remove trusty wheel jobs in preparation for node removal.  No jobs
should be using the wheels any more.

Depends-On: https://review.opendev.org/702773
Change-Id: I9b272782c83cff4e456958be2eb3a38ec60aca6a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/74/702774/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",2,ca52e809bdfb8ec2e9433b925e232d8f2dd2a9ea,trusty-removal,, name: build-wheel-mirror-ubuntu-trusty parent: build-wheel-mirror-base description: | Build Ubuntu Trusty wheels for OpenStack CI mirrors. nodeset: nodes: - name: wheel-mirror-ubuntu-trusty-python2 label: ubuntu-trusty - name: wheel-mirror-ubuntu-trusty-python3 label: ubuntu-trusty host-vars: wheel-mirror-ubuntu-trusty-python2: wheel_python: python2 wheel-mirror-ubuntu-trusty-python3: wheel_python: python3 - job: name: publish-wheel-mirror-ubuntu-trusty parent: build-wheel-mirror-ubuntu-trusty description: | Publish Ubuntu Trusty wheels for OpenStack CI mirrors. pre-run: playbooks/openafs-client/setup.yaml post-run: playbooks/publish/wheel-mirror.yaml final: true secrets: - name: afs secret: wheel_keytab - job:,0,31
openstack%2Fneutron~stable%2Fstein~I7a3f20a795c89ab1ab037d046a1101cd5c0287d6,openstack/neutron,stable/stein,I7a3f20a795c89ab1ab037d046a1101cd5c0287d6,[Functional tests] Fix SIGHUP handling tests,MERGED,2020-01-15 09:27:12.000000000,2020-01-18 14:34:20.000000000,2020-01-18 14:32:32.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 8863}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-15 09:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f27aaa2a31ae4bd3796d1c5591312825bce2afc', 'message': '[Functional tests] Fix SIGHUP handling tests\n\nTests in neutron.functional.test_server module are testing how\nPluginWorker, WSGIWorker and RPCWorker are handling SIGHUP signal.\n\nRecently this was changed in Oslo.service with [1] and our tests\nwere failing because they were still expecting that after sending\nSIGHUP to the process, stop() and than start() method will be called.\n\nBut as our services uses ""mutate"" as restart method, since [1] such\nprocess don\'t executes stop() and start() after SIGHUP. It now executes\nonly reset() method.\nThis patch reflects that change in Neutron functional tests.\n\n[1] https://review.opendev.org/#/c/641907/\n\nChange-Id: I7a3f20a795c89ab1ab037d046a1101cd5c0287d6\nCloses-Bug: #1842659\n(cherry picked from commit bacc7abf83f18825a49af2c14cebbeb312615c1d)\n'}, {'number': 2, 'created': '2020-01-15 13:11:05.000000000', 'files': ['neutron/tests/functional/test_server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9f4ce07d6d2b0e2ef4c7899a814862a13e07f45', 'message': '[Functional tests] Fix SIGHUP handling tests\n\nTests in neutron.functional.test_server module are testing how\nPluginWorker, WSGIWorker and RPCWorker are handling SIGHUP signal.\n\nRecently this was changed in Oslo.service with [1] and our tests\nwere failing because they were still expecting that after sending\nSIGHUP to the process, stop() and than start() method will be called.\n\nBut as our services uses ""mutate"" as restart method, since [1] such\nprocess don\'t executes stop() and start() after SIGHUP. It now executes\nonly reset() method.\nThis patch reflects that change in Neutron functional tests.\n\nNOTE: this patch was merged in master combined with another bug\nresolution [2] due to the existing problems in the CI. The other part\nwas already backported in [3].\n\n[1] https://review.opendev.org/#/c/641907/\n[2] https://review.opendev.org/#/c/680001/\n[3] https://review.opendev.org/#/c/680803/\n\nChange-Id: I7a3f20a795c89ab1ab037d046a1101cd5c0287d6\nCloses-Bug: #1842659\n(cherry picked from commit bacc7abf83f18825a49af2c14cebbeb312615c1d)\n'}]",3,702603,b9f4ce07d6d2b0e2ef4c7899a814862a13e07f45,25,9,2,21798,,,0,"[Functional tests] Fix SIGHUP handling tests

Tests in neutron.functional.test_server module are testing how
PluginWorker, WSGIWorker and RPCWorker are handling SIGHUP signal.

Recently this was changed in Oslo.service with [1] and our tests
were failing because they were still expecting that after sending
SIGHUP to the process, stop() and than start() method will be called.

But as our services uses ""mutate"" as restart method, since [1] such
process don't executes stop() and start() after SIGHUP. It now executes
only reset() method.
This patch reflects that change in Neutron functional tests.

NOTE: this patch was merged in master combined with another bug
resolution [2] due to the existing problems in the CI. The other part
was already backported in [3].

[1] https://review.opendev.org/#/c/641907/
[2] https://review.opendev.org/#/c/680001/
[3] https://review.opendev.org/#/c/680803/

Change-Id: I7a3f20a795c89ab1ab037d046a1101cd5c0287d6
Closes-Bug: #1842659
(cherry picked from commit bacc7abf83f18825a49af2c14cebbeb312615c1d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/03/702603/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/test_server.py'],1,4f27aaa2a31ae4bd3796d1c5591312825bce2afc,bug/1842659,"# Those messages will be written to temporary file each time # start/reset methods are called.FAKE_RESET_MSG = b""reset"" def _fake_reset(self): with open(self.temp_file, 'ab') as f: f.write(FAKE_RESET_MSG) # After sending SIGHUP it is expected that there will be as many # FAKE_RESET_MSG as number of workers + one additional for main # process expected_msg = ( FAKE_START_MSG * workers + FAKE_RESET_MSG * (workers + 1)) with mock.patch(""neutron.wsgi.WorkerService.start"") as start_method,\ mock.patch(""neutron.wsgi.WorkerService.reset"") as reset_method: reset_method.side_effect = self._fake_reset with mock.patch(""neutron.service.RpcWorker.start"") as start_method,\ mock.patch( ""neutron.service.RpcWorker.reset"") as reset_method,\ mock.patch( ""neutron_lib.plugins.directory.get_plugin"") as get_plugin: start_method.side_effect = self._fake_start reset_method.side_effect = self._fake_reset get_plugin.return_value = self.plugin CONF.set_override(""rpc_workers"", workers) # not interested in state report workers specifically CONF.set_override(""rpc_state_report_workers"", 0) rpc_workers_launcher = service.start_rpc_workers() rpc_workers_launcher.wait() FakeWorker.reset = self._fake_reset","# This message will be written to temporary file each time # start method is called. expected_msg = FAKE_START_MSG * workers * 2 with mock.patch(""neutron.wsgi.WorkerService.start"") as start_method: with mock.patch(""neutron.service.RpcWorker.start"") as start_method: with mock.patch( ""neutron_lib.plugins.directory.get_plugin"" ) as get_plugin: start_method.side_effect = self._fake_start get_plugin.return_value = self.plugin CONF.set_override(""rpc_workers"", workers) # not interested in state report workers specifically CONF.set_override(""rpc_state_report_workers"", 0) rpc_workers_launcher = service.start_rpc_workers() rpc_workers_launcher.wait()",29,15
openstack%2Fpuppet-tripleo~stable%2Ftrain~I442b190b6fa429ee3a81fd2ea84ada6ed9bca7d2,openstack/puppet-tripleo,stable/train,I442b190b6fa429ee3a81fd2ea84ada6ed9bca7d2,Add support to configure pcsd bind address,MERGED,2019-12-21 23:30:00.000000000,2020-01-18 13:45:56.000000000,2020-01-18 13:45:55.000000000,"[{'_account_id': 3153}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-21 23:30:00.000000000', 'files': ['manifests/profile/base/pacemaker_remote.pp', 'manifests/profile/base/pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/95111e6ca86e80fbf0f2b5d166bc7f5b230b4154', 'message': 'Add support to configure pcsd bind address\n\nAdd support to configure pcsd bind address so that we can\nmake pcsd listen on specific address instead of all interfaces\non the node.\n\nRelated-Bug: #1856626\nDepends-on: https://review.opendev.org/697942\nChange-Id: I442b190b6fa429ee3a81fd2ea84ada6ed9bca7d2\n(cherry picked from commit b5ee4bacacd3b63d98b7cf37d526c460f8113dcb)\n'}]",1,700287,95111e6ca86e80fbf0f2b5d166bc7f5b230b4154,23,5,1,9816,,,0,"Add support to configure pcsd bind address

Add support to configure pcsd bind address so that we can
make pcsd listen on specific address instead of all interfaces
on the node.

Related-Bug: #1856626
Depends-on: https://review.opendev.org/697942
Change-Id: I442b190b6fa429ee3a81fd2ea84ada6ed9bca7d2
(cherry picked from commit b5ee4bacacd3b63d98b7cf37d526c460f8113dcb)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/87/700287/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/pacemaker_remote.pp', 'manifests/profile/base/pacemaker.pp']",2,95111e6ca86e80fbf0f2b5d166bc7f5b230b4154,bug/1856626-train,"# [*pcsd_bind_addr*] # (Optional) List of IP addresses pcsd should bind to # Defaults to undef # $pcsd_bind_addr = undef, pcsd_bind_addr => $pcsd_bind_addr,",,12,0
openstack%2Fswift~master~I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e,openstack/swift,master,I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e,Have slo tell the object-server that it wants whole manifests,MERGED,2019-12-06 23:27:50.000000000,2020-01-18 13:33:01.000000000,2020-01-18 13:31:31.000000000,"[{'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-06 23:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/090ee47bb02f5aee2e294838f6f6e55c19c339b0', 'message': ""WIP: Have slo tell the object-server that it wants whole manifests\n\nOtherwise, we waste a request on some 416/206 response that won't be\nhelpful.\n\nChange-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e\n""}, {'number': 2, 'created': '2019-12-07 17:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1cf576ce8ed1d08281c627367f58dc7549399277', 'message': ""WIP: Have slo tell the object-server that it wants whole manifests\n\nOtherwise, we waste a request on some 416/206 response that won't be\nhelpful.\n\nChange-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e\n""}, {'number': 3, 'created': '2019-12-10 23:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6c13664f6ebc6b8c60cba1448d2cae3568e90c27', 'message': ""Have slo tell the object-server that it wants whole manifests\n\nOtherwise, we waste a request on some 416/206 response that won't be\nhelpful.\n\nTo do this, add a new X-Backend-Ignore-Range-If-Metadata-Present header\nwhose value is a comma-separated list of header names. Middlewares may\ninclude this header to tell object-servers to send the whole object\n(rather than a 206 or 416) if *any* of the metadata are present.\n\nNote that the proxy-server may drop the Range header from the request\nenvironment; if a middleware cares about the client-requested range, it\nwill need to save off a copy before calling into the app.\n\nChange-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e\n""}, {'number': 4, 'created': '2019-12-20 05:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/372407af33628ba8bf614901ec88dd5229dde215', 'message': ""Have slo tell the object-server that it wants whole manifests\n\nOtherwise, we waste a request on some 416/206 response that won't be\nhelpful.\n\nTo do this, add a new X-Backend-Ignore-Range-If-Metadata-Present header\nwhose value is a comma-separated list of header names. Middlewares may\ninclude this header to tell object-servers to send the whole object\n(rather than a 206 or 416) if *any* of the metadata are present.\n\nChange-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e\n""}, {'number': 5, 'created': '2019-12-20 06:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3b0c4cc7eafb51288a98e8a868418337ac260320', 'message': ""Have slo tell the object-server that it wants whole manifests\n\nOtherwise, we waste a request on some 416/206 response that won't be\nhelpful.\n\nTo do this, add a new X-Backend-Ignore-Range-If-Metadata-Present header\nwhose value is a comma-separated list of header names. Middlewares may\ninclude this header to tell object-servers to send the whole object\n(rather than a 206 or 416) if *any* of the metadata are present.\n\nChange-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e\n""}, {'number': 6, 'created': '2020-01-03 00:09:09.000000000', 'files': ['swift/obj/server.py', 'swift/common/middleware/symlink.py', 'test/unit/common/middleware/test_symlink.py', 'test/unit/proxy/test_server.py', 'swift/common/middleware/slo.py', 'test/unit/common/middleware/test_slo.py', 'test/unit/obj/test_server.py', 'swift/proxy/controllers/obj.py', 'swift/common/request_helpers.py', 'swift/common/middleware/dlo.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e8b654f318cfab485a772e19db33cb2fe4c3d858', 'message': ""Have slo tell the object-server that it wants whole manifests\n\nOtherwise, we waste a request on some 416/206 response that won't be\nhelpful.\n\nTo do this, add a new X-Backend-Ignore-Range-If-Metadata-Present header\nwhose value is a comma-separated list of header names. Middlewares may\ninclude this header to tell object-servers to send the whole object\n(rather than a 206 or 416) if *any* of the metadata are present.\n\nHave dlo and symlink use it, too; it won't save us any round-trips, but\nit should clean up some object-server logging.\n\nChange-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e\n""}]",6,697739,e8b654f318cfab485a772e19db33cb2fe4c3d858,55,5,6,15343,,,0,"Have slo tell the object-server that it wants whole manifests

Otherwise, we waste a request on some 416/206 response that won't be
helpful.

To do this, add a new X-Backend-Ignore-Range-If-Metadata-Present header
whose value is a comma-separated list of header names. Middlewares may
include this header to tell object-servers to send the whole object
(rather than a 206 or 416) if *any* of the metadata are present.

Have dlo and symlink use it, too; it won't save us any round-trips, but
it should clean up some object-server logging.

Change-Id: I4ff2a178d0456e7e37d561109ef57dd0d92cbd4e
",git fetch https://review.opendev.org/openstack/swift refs/changes/39/697739/5 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'swift/common/middleware/slo.py', 'swift/common/request_helpers.py', 'swift/proxy/controllers/obj.py']",4,090ee47bb02f5aee2e294838f6f6e55c19c339b0,697739," self._fix_ranges(req, resp) def _fix_ranges(self, req, resp): # Has to be called *before* kickoff()! if is_success(resp.status_int): ignore_range_headers = set( h.strip().lower() for h in req.headers.get( 'X-Backend-Ignore-Range-If-Metadata-Present', '').split(',')) if ignore_range_headers.intersection( h.lower() for h in resp.headers): req.headers.pop('Range', None) resp.app_iter.range_specs = [] ",,43,1
openstack%2Fopenstack-helm-infra~master~I402365a45b8c2a92420c68689c97cb2e9f2d7c0e,openstack/openstack-helm-infra,master,I402365a45b8c2a92420c68689c97cb2e9f2d7c0e,[CEPH] check ceph version from daemon,MERGED,2020-01-16 17:28:10.000000000,2020-01-18 11:19:22.000000000,2020-01-18 11:17:58.000000000,"[{'_account_id': 17119}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 29106}, {'_account_id': 29974}]","[{'number': 1, 'created': '2020-01-16 17:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b344c3aac32c36f6417fcbfd95356a0b012393b5', 'message': '[CEPH] check ceph version from daemon\n\nThis is to update scripts to check ceph versiom from daemon directly\ninstead of client.\n\nChange-Id: I402365a45b8c2a92420c68689c97cb2e9f2d7c0e\n'}, {'number': 2, 'created': '2020-01-16 17:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/59b1c1dde640cb9c00e622c6352eb908a8cc6496', 'message': '[CEPH] check ceph version from daemon\n\nThis is to update scripts to check ceph version from daemon directly\ninstead of client.\n\nChange-Id: I402365a45b8c2a92420c68689c97cb2e9f2d7c0e\n'}, {'number': 3, 'created': '2020-01-17 17:47:08.000000000', 'files': ['ceph-client/templates/bin/pool/_init.sh.tpl', 'ceph-client/templates/bin/mgr/_start.sh.tpl', 'ceph-client/templates/bin/_helm-tests.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6898fa7f9ecd44f4b17968803e5f44dda7d5c1f5', 'message': '[CEPH] check ceph version from daemon\n\nThis is to update scripts to check ceph version from daemon directly\ninstead of client.\n\nChange-Id: I402365a45b8c2a92420c68689c97cb2e9f2d7c0e\n'}]",2,702933,6898fa7f9ecd44f4b17968803e5f44dda7d5c1f5,17,7,3,28372,,,0,"[CEPH] check ceph version from daemon

This is to update scripts to check ceph version from daemon directly
instead of client.

Change-Id: I402365a45b8c2a92420c68689c97cb2e9f2d7c0e
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/33/702933/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-client/templates/bin/pool/_init.sh.tpl', 'ceph-client/templates/bin/mgr/_start.sh.tpl', 'ceph-client/templates/bin/_helm-tests.sh.tpl']",3,b344c3aac32c36f6417fcbfd95356a0b012393b5,," if [[ $(ceph tell mon.* version | egrep -q ""nautilus""; echo $?) -eq 0 ]]; then"," if [[ $(ceph -v | egrep -q ""nautilus""; echo $?) -eq 0 ]]; then",5,5
openstack%2Fopenstack-ansible~master~I4b855429b95772b71316760b8873d8feca9c2780,openstack/openstack-ansible,master,I4b855429b95772b71316760b8873d8feca9c2780,Set fixed version for networking-calico,MERGED,2020-01-14 17:20:35.000000000,2020-01-18 08:54:59.000000000,2020-01-18 02:46:08.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-14 17:20:35.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aa79d8186665899070c94f8e94cf76e95bc62ce6', 'message': ""Set fixed version for networking-calico\n\nCalico plugin installation fails, as they tend to tag the same SHA\nseveral times, which breaks PBR. This results in non-working deployments\nTo avoid it we set fixed calico version and will be maintaining it's\nupdate manualy from time to time. Their codebase don't change frequently\n\nChange-Id: I4b855429b95772b71316760b8873d8feca9c2780\n""}]",0,702488,aa79d8186665899070c94f8e94cf76e95bc62ce6,11,4,1,28619,,,0,"Set fixed version for networking-calico

Calico plugin installation fails, as they tend to tag the same SHA
several times, which breaks PBR. This results in non-working deployments
To avoid it we set fixed calico version and will be maintaining it's
update manualy from time to time. Their codebase don't change frequently

Change-Id: I4b855429b95772b71316760b8873d8feca9c2780
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/88/702488/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,aa79d8186665899070c94f8e94cf76e95bc62ce6,bump_calico,networking_calico_git_install_branch: 3.11.1 # HEAD as of 12.01.2020networking_calico_git_track_branch: None,networking_calico_git_install_branch: 594cf28fb0359c1abf6da1022574be5ddd710a7b # HEAD as of 12.01.2020networking_calico_git_track_branch: master,2,2
openstack%2Fneutron~master~Id499bcc49d27f13f7f03481922a3383b4a255da1,openstack/neutron,master,Id499bcc49d27f13f7f03481922a3383b4a255da1,Use effective MAC address for macvtap assigned VFs,MERGED,2019-08-15 14:46:06.000000000,2020-01-18 08:33:30.000000000,2020-01-18 08:31:43.000000000,"[{'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11604}, {'_account_id': 11975}, {'_account_id': 12171}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 28714}]","[{'number': 1, 'created': '2019-08-15 14:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c0e907a423f46a5fc3820ed9d560e15bdd61522', 'message': '[WIP] Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nTODO: sort out unit tests\nTODO: reference some commits in libvirt / nova that express the\n      ""evolution"" of setting mac for VF\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}, {'number': 2, 'created': '2019-08-15 14:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf01a33cf95196945bcebeee71bc58838fb404ba', 'message': '[WIP] Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nTODO: sort out unit tests\nTODO: reference some commits in libvirt / nova that express the\n      ""evolution"" of setting mac for VF\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}, {'number': 3, 'created': '2019-08-18 17:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e76da0ec64e3e7e667789740643b8bd73e73054', 'message': '[WIP] Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nTODO: sort out unit tests\nTODO: reference some commits in libvirt / nova that express the\n      ""evolution"" of setting mac for VF\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}, {'number': 4, 'created': '2019-11-17 07:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0dff25cd38aed982003a9d5fd1a0e0519d6371d7', 'message': '[WIP] Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nTODO: sort out unit tests\nTODO: reference some commits in libvirt / nova that express the\n      ""evolution"" of setting mac for VF\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}, {'number': 5, 'created': '2019-12-22 16:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2d2eee70fb13b18257aa9648088b4a96b1942d6', 'message': 'Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}, {'number': 6, 'created': '2019-12-24 13:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9a753cd3a112abd5c19669c3ae03fa9e07c9c6f', 'message': 'Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}, {'number': 7, 'created': '2020-01-07 15:25:05.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_eswitch_manager.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/agent/test_sriov_nic_agent.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/eswitch_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f7b88d0808bee36b9d089ce8d3c0f98ae0b2dea', 'message': 'Use effective MAC address for macvtap assigned VFs\n\nThis commit modifies the way sriov agent retrieves mac\naddresses for macvtap assigned VFs to use the effective\nmac taken from the macvtap net device instead of the\nadministrative mac set on the PF.\n\nThis commit rids sriov agent from depending on hypervisor/nova\nto set both administrative and effective mac for macvtap ports.\n\nRelated-Bug: #1841067\n\nChange-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1\n'}]",22,676713,6f7b88d0808bee36b9d089ce8d3c0f98ae0b2dea,79,11,7,28714,,,0,"Use effective MAC address for macvtap assigned VFs

This commit modifies the way sriov agent retrieves mac
addresses for macvtap assigned VFs to use the effective
mac taken from the macvtap net device instead of the
administrative mac set on the PF.

This commit rids sriov agent from depending on hypervisor/nova
to set both administrative and effective mac for macvtap ports.

Related-Bug: #1841067

Change-Id: Id499bcc49d27f13f7f03481922a3383b4a255da1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/676713/1 && git format-patch -1 --stdout FETCH_HEAD,"['2000-mac-vtap.patch', 'neutron/plugins/ml2/drivers/mech_sriov/agent/eswitch_manager.py', 'neutron/plugins/ml2/drivers/mech_sriov/agent/pci_lib.py']",3,7c0e907a423f46a5fc3820ed9d560e15bdd61522,macvtap-use-effective-mac," MACVTAP_PATTERN = ( r""\d+:\s+(?P<macvtap_interface>macvtap[0-9]+)@"" r""(?P<vf_interface>[a-zA-Z0-9_]+):"") def get_macvtap_devices(self, ip_link_show_output): """"""retrieve macvtap upper devices upper_devs = [] for line in ip_link_show_output.splitlines(): pattern_match = PciDeviceIPWrapper.MACVTAP_REG_EX.match(line) if pattern_match: if self.dev_name == pattern_match.group('vf_interface'): upper_devs.append(pattern_match.group('macvtap_interface')) return upper_devs def is_macvtap_assigned(self, ip_link_show_output): """"""Check if device has any macvtap upper interfaces"""""" return len(self.get_macvtap_devices(ip_link_show_output)) > 0"," MACVTAP_PATTERN = r"".*macvtap[0-9]+@(?P<vf_interface>[a-zA-Z0-9_]+):"" @classmethod def is_macvtap_assigned(cls, ifname, ip_link_show_output): """"""Check if vf has macvtap interface assigned @param ifname: vf interface name for line in ip_link_show_output.splitlines(): pattern_match = cls.MACVTAP_REG_EX.match(line) if pattern_match: if ifname == pattern_match.group('vf_interface'): return True return False",291,38
openstack%2Fkolla-ansible~master~I14df39d611d39ad1f6184ab92d628cb010881fbb,openstack/kolla-ansible,master,I14df39d611d39ad1f6184ab92d628cb010881fbb,Ansible lint: disable some checks,MERGED,2020-01-16 15:38:01.000000000,2020-01-18 08:32:32.000000000,2020-01-18 08:30:57.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-16 15:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3011218b7df35f5271778684708501af488535fa', 'message': 'Ansible lint: disable some checks\n\nChange-Id: I14df39d611d39ad1f6184ab92d628cb010881fbb\n'}, {'number': 2, 'created': '2020-01-17 13:51:47.000000000', 'files': ['ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/haproxy/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/934fea1aac2eedb683b8c39b60a921c06cf8d293', 'message': 'Ansible lint: disable some checks\n\n204 for very long url which is hard to break safely\n306 for ""echo | docker"" as echo should not fall\n\nChange-Id: I14df39d611d39ad1f6184ab92d628cb010881fbb\n'}]",0,702898,934fea1aac2eedb683b8c39b60a921c06cf8d293,16,3,2,24072,,,0,"Ansible lint: disable some checks

204 for very long url which is hard to break safely
306 for ""echo | docker"" as echo should not fall

Change-Id: I14df39d611d39ad1f6184ab92d628cb010881fbb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/98/702898/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/haproxy/tasks/precheck.yml']",2,3011218b7df35f5271778684708501af488535fa,," shell: echo ""show stat"" | docker exec -i haproxy socat unix-connect:/var/lib/kolla/haproxy/haproxy.sock stdio # noqa 306"," shell: echo ""show stat"" | docker exec -i haproxy socat unix-connect:/var/lib/kolla/haproxy/haproxy.sock stdio",2,2
openstack%2Frequirements~stable%2Fstein~I2df9cfbe872cbba8abc31f24fe3428eb4ce7f7be,openstack/requirements,stable/stein,I2df9cfbe872cbba8abc31f24fe3428eb4ce7f7be,update constraint for tempest to new release 20.0.0,MERGED,2020-01-14 20:56:12.000000000,2020-01-18 08:31:46.000000000,2020-01-18 08:31:45.000000000,"[{'_account_id': 11131}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-14 20:56:12.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d8a6ded46d02410ade16837c1bb9d7b2f0d5ac67', 'message': 'update constraint for tempest to new release 20.0.0\n\nmeta:version: 20.0.0\nmeta:diff-start: -\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: yes\nmeta:release:Author: ghanshyam <gmann@ghanshyammann.com>\nmeta:release:Commit: Ghanshyam Mann <gmann@ghanshyammann.com>\nmeta:release:Change-Id: I7340fbc122667a431eacd4936e5c1f703edd929e\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Code-Review+1: Chandan Kumar (raukadah) <chkumar@redhat.com>\nmeta:release:Code-Review+1: yatin <ykarel@redhat.com>\nmeta:release:Code-Review+1: Masayuki Igawa <masayuki@igawa.io>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n\nMerged to master (start of train) after stein requirements had branched.\n\nChange-Id: I2df9cfbe872cbba8abc31f24fe3428eb4ce7f7be\n(cherry picked from commit 6d80e4a040ce642ad38d7f6e49fe4e5f22afb50c)\n'}]",0,702529,d8a6ded46d02410ade16837c1bb9d7b2f0d5ac67,15,5,1,11904,,,0,"update constraint for tempest to new release 20.0.0

meta:version: 20.0.0
meta:diff-start: -
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: yes
meta:release:Author: ghanshyam <gmann@ghanshyammann.com>
meta:release:Commit: Ghanshyam Mann <gmann@ghanshyammann.com>
meta:release:Change-Id: I7340fbc122667a431eacd4936e5c1f703edd929e
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Code-Review+1: Chandan Kumar (raukadah) <chkumar@redhat.com>
meta:release:Code-Review+1: yatin <ykarel@redhat.com>
meta:release:Code-Review+1: Masayuki Igawa <masayuki@igawa.io>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>

Merged to master (start of train) after stein requirements had branched.

Change-Id: I2df9cfbe872cbba8abc31f24fe3428eb4ce7f7be
(cherry picked from commit 6d80e4a040ce642ad38d7f6e49fe4e5f22afb50c)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/29/702529/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d8a6ded46d02410ade16837c1bb9d7b2f0d5ac67,,tempest===20.0.0,tempest===19.0.0,1,1
openstack%2Ftripleo-heat-templates~master~I7766a75414bf8db75ccd233677e9ffe13ff28e23,openstack/tripleo-heat-templates,master,I7766a75414bf8db75ccd233677e9ffe13ff28e23,Fix deployment on pacemaker remote nodes,MERGED,2020-01-16 09:18:15.000000000,2020-01-18 07:46:41.000000000,2020-01-18 00:51:57.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30126}]","[{'number': 1, 'created': '2020-01-16 09:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/76c2da484824d072570396e786947ad7614f5b93', 'message': 'Fix deployment on pacemaker remote nodes\n\nCurrently an HA deployment making use of PacemakerRemote for any HA role\nwill fail with the following:\n2020-01-16 08:40:22.707 33489 DEBUG paunch [  ] Start container mysql_restart_bundle as mysql_restart_bundle.\n2020-01-16 08:40:22.708 33489 DEBUG paunch [  ] Path seperator found in volume (/etc/corosync/corosync.conf), but did not exist on the file system\n2020-01-16 08:40:22.708 33489 ERROR paunch [  ] /etc/corosync/corosync.conf is not a valid volume source\n...\n2020-01-16 08:40:53.026 33489 ERROR paunch [  ] The following containers failed validations and were not started: mysql_restart_bundle\n\nThe reason for this is that via I92d4ddf2feeac06ce14468ae928c283f3fd04f45 (HA: fix\n<service>_restart_bundle with minor update workflow), we consolidated\nall the restart bundles into a single place inside\ncontainers-common.yaml but we forgot to conditionalize the inclusion of\nthe /etc/corosync/corosync.conf bind mount. In fact this bind mount is\nnot needed since we started using RHEL/CentOS 8 (i.e. since the podman\nintroduction). See I399098bf734aa3b2862e1713d4b1f429d180afbc (Fix pcmk\nremote podman bundle restarts) for more context\n\nChange-Id: I7766a75414bf8db75ccd233677e9ffe13ff28e23\nCloses-Bug: #1859945\n'}, {'number': 2, 'created': '2020-01-16 10:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8ca350e1a02ab367f235ae41ed8ec8dff88192c6', 'message': 'Fix deployment on pacemaker remote nodes\n\nCurrently an HA deployment making use of PacemakerRemote for any HA role\nwill fail with the following:\n2020-01-16 08:40:22.707 33489 DEBUG paunch [  ] Start container mysql_restart_bundle as mysql_restart_bundle.\n2020-01-16 08:40:22.708 33489 DEBUG paunch [  ] Path seperator found in volume (/etc/corosync/corosync.conf), but did not exist on the file system\n2020-01-16 08:40:22.708 33489 ERROR paunch [  ] /etc/corosync/corosync.conf is not a valid volume source\n...\n2020-01-16 08:40:53.026 33489 ERROR paunch [  ] The following containers failed validations and were not started: mysql_restart_bundle\n\nThe reason for this is that via I92d4ddf2feeac06ce14468ae928c283f3fd04f45 (HA: fix\n<service>_restart_bundle with minor update workflow), we consolidated\nall the restart bundles into a single place inside\ncontainers-common.yaml but we forgot to conditionalize the inclusion of\nthe /etc/corosync/corosync.conf bind mount. In fact this bind mount is\nnot needed since we started using RHEL/CentOS 8 (i.e. since the podman\nintroduction). See I399098bf734aa3b2862e1713d4b1f429d180afbc (Fix pcmk\nremote podman bundle restarts) for more context\n\nChange-Id: I7766a75414bf8db75ccd233677e9ffe13ff28e23\nCloses-Bug: #1859945\n'}, {'number': 3, 'created': '2020-01-16 11:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/82c97f41fbbde9dabdc75d12a87bb349d0fdddc0', 'message': 'Fix deployment on pacemaker remote nodes\n\nCurrently an HA deployment making use of PacemakerRemote for any HA role\nwill fail with the following:\n2020-01-16 08:40:22.707 33489 DEBUG paunch [  ] Start container mysql_restart_bundle as mysql_restart_bundle.\n2020-01-16 08:40:22.708 33489 DEBUG paunch [  ] Path seperator found in volume (/etc/corosync/corosync.conf), but did not exist on the file system\n2020-01-16 08:40:22.708 33489 ERROR paunch [  ] /etc/corosync/corosync.conf is not a valid volume source\n...\n2020-01-16 08:40:53.026 33489 ERROR paunch [  ] The following containers failed validations and were not started: mysql_restart_bundle\n\nThe reason for this is that via I92d4ddf2feeac06ce14468ae928c283f3fd04f45 (HA: fix\n<service>_restart_bundle with minor update workflow), we consolidated\nall the restart bundles into a single place inside\ncontainers-common.yaml but we forgot to conditionalize the inclusion of\nthe /etc/corosync/corosync.conf bind mount. In fact this bind mount is\nnot needed since we started using RHEL/CentOS 8 (i.e. since the podman\nintroduction). See I399098bf734aa3b2862e1713d4b1f429d180afbc (Fix pcmk\nremote podman bundle restarts) for more context\n\nTested in a composable HA deployment where the Messaging and the\nDatabase roles were using PacemakerRemote and correctly deployed the\nenvironment (which would previously fail):\n[root@messaging-0 ~]# crm_mon -1 |grep -e database -e messaging\nRemoteOnline: [ database-0 database-1 database-2 messaging-0 messaging-1 messaging-2 ]\n database-0     (ocf::pacemaker:remote):        Started controller-0\n database-1     (ocf::pacemaker:remote):        Started controller-1\n database-2     (ocf::pacemaker:remote):        Started controller-2\n messaging-0    (ocf::pacemaker:remote):        Started controller-0\n messaging-1    (ocf::pacemaker:remote):        Started controller-1\n messaging-2    (ocf::pacemaker:remote):        Started controller-2\n galera-bundle-0      (ocf::heartbeat:galera):        Master database-0\n galera-bundle-1      (ocf::heartbeat:galera):        Master database-1\n galera-bundle-2      (ocf::heartbeat:galera):        Master database-2\n rabbitmq-bundle-0    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-0\n rabbitmq-bundle-1    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-1\n rabbitmq-bundle-2    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-2\n\nChange-Id: I7766a75414bf8db75ccd233677e9ffe13ff28e23\nCloses-Bug: #1859945\n'}, {'number': 4, 'created': '2020-01-16 11:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f256733b299a75ffc12e0c48dfd08b9fa76c62e5', 'message': 'Fix deployment on pacemaker remote nodes\n\nCurrently an HA deployment making use of PacemakerRemote for any HA role\nwill fail with the following:\n2020-01-16 08:40:22.707 33489 DEBUG paunch [  ] Start container mysql_restart_bundle as mysql_restart_bundle.\n2020-01-16 08:40:22.708 33489 DEBUG paunch [  ] Path seperator found in volume (/etc/corosync/corosync.conf), but did not exist on the file system\n2020-01-16 08:40:22.708 33489 ERROR paunch [  ] /etc/corosync/corosync.conf is not a valid volume source\n...\n2020-01-16 08:40:53.026 33489 ERROR paunch [  ] The following containers failed validations and were not started: mysql_restart_bundle\n\nThe reason for this is that via I92d4ddf2feeac06ce14468ae928c283f3fd04f45 (HA: fix\n<service>_restart_bundle with minor update workflow), we consolidated\nall the restart bundles into a single place inside\ncontainers-common.yaml but we forgot to conditionalize the inclusion of\nthe /etc/corosync/corosync.conf bind mount. In fact this bind mount is\nnot needed since we started using RHEL/CentOS 8 (i.e. since the podman\nintroduction). See I399098bf734aa3b2862e1713d4b1f429d180afbc (Fix pcmk\nremote podman bundle restarts) for more context\n\nTested in a composable HA deployment where the Messaging and the\nDatabase roles were using PacemakerRemote and correctly deployed the\nenvironment (which would previously fail):\n[root@messaging-0 ~]# crm_mon -1 |grep -e database -e messaging\nRemoteOnline: [ database-0 database-1 database-2 messaging-0 messaging-1 messaging-2 ]\n database-0     (ocf::pacemaker:remote):        Started controller-0\n database-1     (ocf::pacemaker:remote):        Started controller-1\n database-2     (ocf::pacemaker:remote):        Started controller-2\n messaging-0    (ocf::pacemaker:remote):        Started controller-0\n messaging-1    (ocf::pacemaker:remote):        Started controller-1\n messaging-2    (ocf::pacemaker:remote):        Started controller-2\n galera-bundle-0      (ocf::heartbeat:galera):        Master database-0\n galera-bundle-1      (ocf::heartbeat:galera):        Master database-1\n galera-bundle-2      (ocf::heartbeat:galera):        Master database-2\n rabbitmq-bundle-0    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-0\n rabbitmq-bundle-1    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-1\n rabbitmq-bundle-2    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-2\n\nChange-Id: I7766a75414bf8db75ccd233677e9ffe13ff28e23\nCloses-Bug: #1859945\n'}, {'number': 5, 'created': '2020-01-16 15:58:57.000000000', 'files': ['deployment/containers-common.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a30342f253bf63db00a9545aebe50187b9c0324a', 'message': 'Fix deployment on pacemaker remote nodes\n\nCurrently an HA deployment making use of PacemakerRemote for any HA role\nwill fail with the following:\n2020-01-16 08:40:22.707 33489 DEBUG paunch [  ] Start container mysql_restart_bundle as mysql_restart_bundle.\n2020-01-16 08:40:22.708 33489 DEBUG paunch [  ] Path seperator found in volume (/etc/corosync/corosync.conf), but did not exist on the file system\n2020-01-16 08:40:22.708 33489 ERROR paunch [  ] /etc/corosync/corosync.conf is not a valid volume source\n...\n2020-01-16 08:40:53.026 33489 ERROR paunch [  ] The following containers failed validations and were not started: mysql_restart_bundle\n\nThe reason for this is that via I92d4ddf2feeac06ce14468ae928c283f3fd04f45 (HA: fix\n<service>_restart_bundle with minor update workflow), we consolidated\nall the restart bundles into a single place inside\ncontainers-common.yaml but we forgot to conditionalize the inclusion of\nthe /etc/corosync/corosync.conf bind mount. In fact this bind mount is\nnot needed since we started using RHEL/CentOS 8 (i.e. since the podman\nintroduction). See I399098bf734aa3b2862e1713d4b1f429d180afbc (Fix pcmk\nremote podman bundle restarts) for more context\n\nTested in a composable HA deployment where the Messaging and the\nDatabase roles were using PacemakerRemote and correctly deployed the\nenvironment (which would previously fail):\n[root@messaging-0 ~]# crm_mon -1 |grep -e database -e messaging\nRemoteOnline: [ database-0 database-1 database-2 messaging-0 messaging-1 messaging-2 ]\n database-0     (ocf::pacemaker:remote):        Started controller-0\n database-1     (ocf::pacemaker:remote):        Started controller-1\n database-2     (ocf::pacemaker:remote):        Started controller-2\n messaging-0    (ocf::pacemaker:remote):        Started controller-0\n messaging-1    (ocf::pacemaker:remote):        Started controller-1\n messaging-2    (ocf::pacemaker:remote):        Started controller-2\n galera-bundle-0      (ocf::heartbeat:galera):        Master database-0\n galera-bundle-1      (ocf::heartbeat:galera):        Master database-1\n galera-bundle-2      (ocf::heartbeat:galera):        Master database-2\n rabbitmq-bundle-0    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-0\n rabbitmq-bundle-1    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-1\n rabbitmq-bundle-2    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-2\n\nChange-Id: I7766a75414bf8db75ccd233677e9ffe13ff28e23\nCloses-Bug: #1859945\n'}]",1,702826,a30342f253bf63db00a9545aebe50187b9c0324a,25,6,5,20172,,,0,"Fix deployment on pacemaker remote nodes

Currently an HA deployment making use of PacemakerRemote for any HA role
will fail with the following:
2020-01-16 08:40:22.707 33489 DEBUG paunch [  ] Start container mysql_restart_bundle as mysql_restart_bundle.
2020-01-16 08:40:22.708 33489 DEBUG paunch [  ] Path seperator found in volume (/etc/corosync/corosync.conf), but did not exist on the file system
2020-01-16 08:40:22.708 33489 ERROR paunch [  ] /etc/corosync/corosync.conf is not a valid volume source
...
2020-01-16 08:40:53.026 33489 ERROR paunch [  ] The following containers failed validations and were not started: mysql_restart_bundle

The reason for this is that via I92d4ddf2feeac06ce14468ae928c283f3fd04f45 (HA: fix
<service>_restart_bundle with minor update workflow), we consolidated
all the restart bundles into a single place inside
containers-common.yaml but we forgot to conditionalize the inclusion of
the /etc/corosync/corosync.conf bind mount. In fact this bind mount is
not needed since we started using RHEL/CentOS 8 (i.e. since the podman
introduction). See I399098bf734aa3b2862e1713d4b1f429d180afbc (Fix pcmk
remote podman bundle restarts) for more context

Tested in a composable HA deployment where the Messaging and the
Database roles were using PacemakerRemote and correctly deployed the
environment (which would previously fail):
[root@messaging-0 ~]# crm_mon -1 |grep -e database -e messaging
RemoteOnline: [ database-0 database-1 database-2 messaging-0 messaging-1 messaging-2 ]
 database-0     (ocf::pacemaker:remote):        Started controller-0
 database-1     (ocf::pacemaker:remote):        Started controller-1
 database-2     (ocf::pacemaker:remote):        Started controller-2
 messaging-0    (ocf::pacemaker:remote):        Started controller-0
 messaging-1    (ocf::pacemaker:remote):        Started controller-1
 messaging-2    (ocf::pacemaker:remote):        Started controller-2
 galera-bundle-0      (ocf::heartbeat:galera):        Master database-0
 galera-bundle-1      (ocf::heartbeat:galera):        Master database-1
 galera-bundle-2      (ocf::heartbeat:galera):        Master database-2
 rabbitmq-bundle-0    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-0
 rabbitmq-bundle-1    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-1
 rabbitmq-bundle-2    (ocf::heartbeat:rabbitmq-cluster):      Started messaging-2

Change-Id: I7766a75414bf8db75ccd233677e9ffe13ff28e23
Closes-Bug: #1859945
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/702826/5 && git format-patch -1 --stdout FETCH_HEAD,['deployment/containers-common.yaml'],1,76c2da484824d072570396e786947ad7614f5b93,fix_pcmk_remote," ContainerCli: type: string default: 'podman' description: CLI tool used to manage containers. constraints: - allowed_values: ['docker', 'podman'] docker_enabled: {equals: [{get_param: ContainerCli}, 'docker']} - if: - docker_enabled - /etc/corosync/corosync.conf:/etc/corosync/corosync.conf:ro - null", - /etc/corosync/corosync.conf:/etc/corosync/corosync.conf:ro,12,1
openstack%2Fneutron~master~I3b0ca77b677fe335161b9a649b4ac397e64eacaa,openstack/neutron,master,I3b0ca77b677fe335161b9a649b4ac397e64eacaa,Initialize nova_notifier for only port data changes,MERGED,2019-09-16 20:56:26.000000000,2020-01-18 07:01:38.000000000,2020-01-18 06:59:20.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 7016}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-09-16 20:56:26.000000000', 'files': ['neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab75405708ffdbe2d7630166c13744d4848909c0', 'message': 'Initialize nova_notifier for only port data changes\n\nIf notify_nova_on_port_status_changes is False, but\nnotify_nova_on_port_data_changes is True, the nova_notifier\nobject in the plugin will not be initialized correctly.\nThis was never noticed because these two options are\ntypically configured identically.\n\nChange-Id: I3b0ca77b677fe335161b9a649b4ac397e64eacaa\nRelated-bug: #1843269\n'}]",0,682483,ab75405708ffdbe2d7630166c13744d4848909c0,71,8,1,1131,,,0,"Initialize nova_notifier for only port data changes

If notify_nova_on_port_status_changes is False, but
notify_nova_on_port_data_changes is True, the nova_notifier
object in the plugin will not be initialized correctly.
This was never noticed because these two options are
typically configured identically.

Change-Id: I3b0ca77b677fe335161b9a649b4ac397e64eacaa
Related-bug: #1843269
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/682483/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/db_base_plugin_v2.py'],1,ab75405708ffdbe2d7630166c13744d4848909c0,fix-port-data-notifier," if (cfg.CONF.notify_nova_on_port_status_changes or cfg.CONF.notify_nova_on_port_data_changes): self.nova_notifier = nova.Notifier.get_instance() if cfg.CONF.notify_nova_on_port_status_changes: db_api.sqla_listen(models_v2.Port, 'after_insert', self.nova_notifier.send_port_status) db_api.sqla_listen(models_v2.Port, 'after_update', self.nova_notifier.send_port_status) db_api.sqla_listen( models_v2.Port.status, 'set', self.nova_notifier.record_port_status_changed)"," if cfg.CONF.notify_nova_on_port_status_changes: self.nova_notifier = nova.Notifier.get_instance() db_api.sqla_listen(models_v2.Port, 'after_insert', self.nova_notifier.send_port_status) db_api.sqla_listen(models_v2.Port, 'after_update', self.nova_notifier.send_port_status) db_api.sqla_listen( models_v2.Port.status, 'set', self.nova_notifier.record_port_status_changed)",11,9
openstack%2Fhorizon~master~Ia865a6c02e206fa49efc3095e8d3488f5638d0e3,openstack/horizon,master,Ia865a6c02e206fa49efc3095e8d3488f5638d0e3,Allow to evacuate without specifying a target host,MERGED,2020-01-15 10:48:17.000000000,2020-01-18 06:25:02.000000000,2020-01-18 06:21:33.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 8988}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-15 10:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/975b8a65d9672701831cd496610e4e330e5f9814', 'message': 'Allow to evacuate without specifying a target host\n\nWhen the evacuate is run without specifying a target host, horizon\nsets an empty character for target host. But the evacuate api doesn\'t\nallow an empty character. As a result, nova returns ""HTTP 400 Bad\nrequest"".\n\nSo this patch sets None as the target host when it isn\'t specified.\n\nChange-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3\nCloses-Bug: 1793694\n'}, {'number': 2, 'created': '2020-01-17 08:47:02.000000000', 'files': ['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f9e0f8a976b82088ef095a69cd1fa892cddde3ba', 'message': 'Allow to evacuate without specifying a target host\n\nWhen the evacuate is run without specifying a target host, horizon\nsets an empty string for target host. But the evacuate api doesn\'t\nallow an empty string. As a result, nova returns ""HTTP 400 Bad\nrequest"".\n\nSo this patch sets None as the target host when it isn\'t specified.\n\nChange-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3\nCloses-Bug: 1793694\n'}]",2,702642,f9e0f8a976b82088ef095a69cd1fa892cddde3ba,17,6,2,8988,,,0,"Allow to evacuate without specifying a target host

When the evacuate is run without specifying a target host, horizon
sets an empty string for target host. But the evacuate api doesn't
allow an empty string. As a result, nova returns ""HTTP 400 Bad
request"".

So this patch sets None as the target host when it isn't specified.

Change-Id: Ia865a6c02e206fa49efc3095e8d3488f5638d0e3
Closes-Bug: 1793694
",git fetch https://review.opendev.org/openstack/horizon refs/changes/42/702642/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/hypervisors/compute/forms.py'],1,975b8a65d9672701831cd496610e4e330e5f9814,bug/1793694, # The target_host value will be an empty character when the target # host wasn't specified. But the evacuate api doesn't allow # an empty character. So set None as the target_host value. if not target_host: target_host = None,,5,0
openstack%2Fcinder~master~I2ebff8a8657cacaf6402136cd1168c1091f006ec,openstack/cinder,master,I2ebff8a8657cacaf6402136cd1168c1091f006ec,Add upgrade check for removed VZStorage driver,MERGED,2020-01-15 15:53:40.000000000,2020-01-18 04:37:17.000000000,2020-01-18 03:53:56.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22126}, {'_account_id': 22348}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30688}]","[{'number': 1, 'created': '2020-01-15 15:53:40.000000000', 'files': ['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bb3846b28d238d54760a046e9878849e0ed3bd4c', 'message': 'Add upgrade check for removed VZStorage driver\n\nThe VZStorage driver has been removed. This adds an upgrade check to\nwarn if it is still configured.\n\nChange-Id: I2ebff8a8657cacaf6402136cd1168c1091f006ec\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",2,702687,bb3846b28d238d54760a046e9878849e0ed3bd4c,33,26,1,11904,,,0,"Add upgrade check for removed VZStorage driver

The VZStorage driver has been removed. This adds an upgrade check to
warn if it is still configured.

Change-Id: I2ebff8a8657cacaf6402136cd1168c1091f006ec
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/702687/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py']",2,bb3846b28d238d54760a046e9878849e0ed3bd4c,ci_unsupported," ""vzstorage"",",,3,1
openstack%2Fpython-openstackclient~master~I04834b2874ec2a70da456a380b5bef03a392effa,openstack/python-openstackclient,master,I04834b2874ec2a70da456a380b5bef03a392effa,Add support for app cred access rules,MERGED,2019-08-22 00:39:52.000000000,2020-01-18 04:35:45.000000000,2020-01-18 04:34:08.000000000,"[{'_account_id': 2}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 2472}, {'_account_id': 6873}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-08-22 00:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/218eda9e93f9a9d9ce0d0dee04cc6d9fc8ae08f6', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 2, 'created': '2019-08-22 20:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7d4e4192a3cbbecfe1aeaa82c24d2a897694df28', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 3, 'created': '2019-08-23 15:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c47d5be0d0cb1cf9f4c6a011344d64d061099b74', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 4, 'created': '2019-10-22 19:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b2f2ecb1b1cbebcd3cc609dacb4a35684d07c0a2', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 5, 'created': '2019-10-23 17:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c6643b773dd9b19861316fd1301d1d155cd083c1', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 6, 'created': '2019-10-24 17:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/201c1f4ba923623c6031a2111c350e7a8d62de2f', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 7, 'created': '2019-12-04 21:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/26c53215674eaffecbc6f1c2556950f5484fe476', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\nDepends-on: https://review.opendev.org/677585\n""}, {'number': 8, 'created': '2020-01-08 23:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/66fb4ec5be206bcf1bfb6d9337ff96abdee74a32', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\n""}, {'number': 9, 'created': '2020-01-09 18:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8d02041ad34eb5421228d6fb8a1d27551523a811', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\n""}, {'number': 10, 'created': '2020-01-17 19:15:06.000000000', 'files': ['doc/source/cli/command-objects/access-rules.rst', 'doc/source/cli/command-objects/application-credentials.rst', 'requirements.txt', 'openstackclient/tests/unit/identity/v3/test_application_credential.py', 'openstackclient/tests/unit/identity/v3/test_access_rule.py', 'openstackclient/identity/v3/access_rule.py', 'lower-constraints.txt', 'openstackclient/identity/v3/application_credential.py', 'openstackclient/tests/unit/identity/v3/fakes.py', 'setup.cfg', 'releasenotes/notes/bp-whitelist-extension-for-app-creds-9afd5009b374190b.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/70ab3f9dd56a638cdff516ca85baa5ebd64c888b', 'message': ""Add support for app cred access rules\n\nThis commit introduces the --access-rules option for 'application\ncredential create' as well as new 'access rule' commands for listing,\nshowing, and deleting access rules.\n\nbp whitelist-extension-for-app-creds\n\nChange-Id: I04834b2874ec2a70da456a380b5bef03a392effa\n""}]",17,677857,70ab3f9dd56a638cdff516ca85baa5ebd64c888b,45,10,10,8482,,,0,"Add support for app cred access rules

This commit introduces the --access-rules option for 'application
credential create' as well as new 'access rule' commands for listing,
showing, and deleting access rules.

bp whitelist-extension-for-app-creds

Change-Id: I04834b2874ec2a70da456a380b5bef03a392effa
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/57/677857/10 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/cli/command-objects/access-rules.rst', 'doc/source/cli/command-objects/application-credentials.rst', 'openstackclient/tests/unit/identity/v3/test_application_credential.py', 'openstackclient/tests/unit/identity/v3/test_access_rule.py', 'openstackclient/identity/v3/access_rule.py', 'openstackclient/identity/v3/application_credential.py', 'openstackclient/tests/unit/identity/v3/fakes.py', 'setup.cfg', 'releasenotes/notes/bp-whitelist-extension-for-app-creds-9afd5009b374190b.yaml']",9,218eda9e93f9a9d9ce0d0dee04cc6d9fc8ae08f6,bp/whitelist-extension-for-app-creds,"--- features: - | [`blueprint whitelist-extension-for-app-creds <https://blueprints.launchpad.net/keystone/+spec/whitelist-extension-for-app-creds>`_] Adds support for creating access rules as an attribute of application credentials as well as for listing, showing, and deleting access rules. ",,476,2
openstack%2Fironic-inspector~master~Ie21e5beeec6188e3b979c28167e575e1c37087ee,openstack/ironic-inspector,master,Ie21e5beeec6188e3b979c28167e575e1c37087ee,Respect driver_info.force_persistent_boot_device,MERGED,2020-01-15 14:28:30.000000000,2020-01-18 03:57:10.000000000,2020-01-18 03:55:46.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-01-15 14:28:30.000000000', 'files': ['ironic_inspector/test/unit/test_introspect.py', 'releasenotes/notes/persistent-boot-207b32257a97451e.yaml', 'ironic_inspector/introspect.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/f8e26aa088032761e9b521e96b439d9c6a80b050', 'message': 'Respect driver_info.force_persistent_boot_device\n\nThis option has been created to work around flacky hardware that\ndoes not work correctly with temporary boot. However, ironic-inspector\nunconditionally uses persistent=False. This change fixes it.\n\nStory: #2007093\nTask: #38126\nChange-Id: Ie21e5beeec6188e3b979c28167e575e1c37087ee\n'}]",6,702670,f8e26aa088032761e9b521e96b439d9c6a80b050,23,6,1,10239,,,0,"Respect driver_info.force_persistent_boot_device

This option has been created to work around flacky hardware that
does not work correctly with temporary boot. However, ironic-inspector
unconditionally uses persistent=False. This change fixes it.

Story: #2007093
Task: #38126
Change-Id: Ie21e5beeec6188e3b979c28167e575e1c37087ee
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/70/702670/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/test/unit/test_introspect.py', 'releasenotes/notes/persistent-boot-207b32257a97451e.yaml', 'ironic_inspector/introspect.py']",3,f8e26aa088032761e9b521e96b439d9c6a80b050,story/2007093/persistent,"from oslo_utils import strutilsdef _persistent_ramdisk_boot(node): """"""If the ramdisk should be configured as a persistent boot device."""""" value = node.driver_info.get('force_persistent_boot_device', 'Default') if value in {'Always', 'Default', 'Never'}: return value == 'Always' else: return strutils.bool_from_string(value, False) ironic.node.set_boot_device( node_info.uuid, 'pxe', persistent=_persistent_ramdisk_boot(node_info.node()))"," ironic.node.set_boot_device(node_info.uuid, 'pxe', persistent=False)",70,2
openstack%2Fcinder~master~I7f8912a01cb12c4bb98e076b5def70f040a5f466,openstack/cinder,master,I7f8912a01cb12c4bb98e076b5def70f040a5f466,Add upgrade check for removed ProphetStor driver,MERGED,2019-12-21 10:22:28.000000000,2020-01-18 03:55:52.000000000,2020-01-18 03:53:49.000000000,"[{'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-21 10:22:28.000000000', 'files': ['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/91bca92252277324120c1a94a4fc443f3b2a906c', 'message': 'Add upgrade check for removed ProphetStor driver\n\nThe ProphetStor driver has been removed. This adds an upgrade check to\nwarn if it is still configured.\n\nChange-Id: I7f8912a01cb12c4bb98e076b5def70f040a5f466\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,700270,91bca92252277324120c1a94a4fc443f3b2a906c,30,21,1,11904,,,0,"Add upgrade check for removed ProphetStor driver

The ProphetStor driver has been removed. This adds an upgrade check to
warn if it is still configured.

Change-Id: I7f8912a01cb12c4bb98e076b5def70f040a5f466
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/700270/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py']",2,91bca92252277324120c1a94a4fc443f3b2a906c,ci_unsupported," ""prophetstor"",",,4,1
openstack%2Fcinder~master~I5a9e1f46a000d8df6e025c1674254a09074014eb,openstack/cinder,master,I5a9e1f46a000d8df6e025c1674254a09074014eb,Add upgrade check for removed Sheepdog driver,MERGED,2019-12-21 10:22:28.000000000,2020-01-18 03:53:54.000000000,2020-01-18 03:53:53.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-21 10:22:28.000000000', 'files': ['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d5e9e1046ead6db898c84d767413864b8ce08734', 'message': 'Add upgrade check for removed Sheepdog driver\n\nThe Sheepdog driver has been removed. This adds an upgrade check to warn\nif it is still configured.\n\nChange-Id: I5a9e1f46a000d8df6e025c1674254a09074014eb\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,700272,d5e9e1046ead6db898c84d767413864b8ce08734,28,22,1,11904,,,0,"Add upgrade check for removed Sheepdog driver

The Sheepdog driver has been removed. This adds an upgrade check to warn
if it is still configured.

Change-Id: I5a9e1f46a000d8df6e025c1674254a09074014eb
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/72/700272/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py']",2,d5e9e1046ead6db898c84d767413864b8ce08734,ci_unsupported," ""sheepdog"",",,3,1
openstack%2Fcinder~master~Id025033a9c1885ba3e3d7c9158d8ce1c6f376d1a,openstack/cinder,master,Id025033a9c1885ba3e3d7c9158d8ce1c6f376d1a,Add upgrade check for removed Nimble driver,MERGED,2019-12-21 10:22:28.000000000,2020-01-18 03:53:51.000000000,2020-01-18 03:53:51.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-21 10:22:28.000000000', 'files': ['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3ab6aae33160594115f357361392ad966ece7b19', 'message': 'Add upgrade check for removed Nimble driver\n\nThe Nimble driver has been removed. This adds an upgrade check to warn\nif it is still configured.\n\nChange-Id: Id025033a9c1885ba3e3d7c9158d8ce1c6f376d1a\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,700271,3ab6aae33160594115f357361392ad966ece7b19,29,22,1,11904,,,0,"Add upgrade check for removed Nimble driver

The Nimble driver has been removed. This adds an upgrade check to warn
if it is still configured.

Change-Id: Id025033a9c1885ba3e3d7c9158d8ce1c6f376d1a
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/71/700271/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py']",2,3ab6aae33160594115f357361392ad966ece7b19,ci_unsupported," ""nimble"",",,4,1
openstack%2Fcinder~master~I2b8396252fd4306a0eceb344bfe45a9a94813630,openstack/cinder,master,I2b8396252fd4306a0eceb344bfe45a9a94813630,Add upgrade check for removed Huawei driver,MERGED,2019-12-21 10:22:28.000000000,2020-01-18 03:47:43.000000000,2020-01-18 03:46:06.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-21 10:22:28.000000000', 'files': ['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e010634fb96e5dea3484015bd2f3fd02609fcd9f', 'message': 'Add upgrade check for removed Huawei driver\n\nThe Huawei Fusionstorage driver has been removed. This adds an upgrade\ncheck to warn if it is still configured.\n\nChange-Id: I2b8396252fd4306a0eceb344bfe45a9a94813630\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,700269,e010634fb96e5dea3484015bd2f3fd02609fcd9f,30,22,1,11904,,,0,"Add upgrade check for removed Huawei driver

The Huawei Fusionstorage driver has been removed. This adds an upgrade
check to warn if it is still configured.

Change-Id: I2b8396252fd4306a0eceb344bfe45a9a94813630
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/700269/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/cmd/test_status.py', 'cinder/cmd/status.py']",2,e010634fb96e5dea3484015bd2f3fd02609fcd9f,ci_unsupported,"REMOVED_DRVRS = [ ""coprhd"", ""drbdmanage"", ""disco"", ""hgst"", ""fusionstorage"", ]","REMOVED_DRVRS = [""coprhd"", ""drbdmanage"", ""disco"", ""hgst"", ]",9,5
openstack%2Frequirements~master~I605115b0c2f4ea7dcf147238e9f6234e92c7d7ca,openstack/requirements,master,I605115b0c2f4ea7dcf147238e9f6234e92c7d7ca,Cap Pint version for python 3.5 or older,MERGED,2020-01-14 21:29:36.000000000,2020-01-18 03:43:56.000000000,2020-01-18 03:41:27.000000000,"[{'_account_id': 841}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 21:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4a63f4e0c1526b33b63db9126d59bcaea9841dfb', 'message': 'Cap Pint version for python 3.5 or older\n\nPython <3.6 support was dropped in Pint 0.10 [1].\nPint in upper-constraints.txt was updated to 0.10 recently and it causes\na failure in the translation jobs which run with python 3.5 [2].\nThis commit caps Pint version to 0.9 for python 3.4 and 3.5.\n\n[1] https://github.com/hgrecco/pint/issues/906\n[2] http://zuul.openstack.org/build/2ba794496679447a97537e82857eba0e\n\nChange-Id: I605115b0c2f4ea7dcf147238e9f6234e92c7d7ca\n'}, {'number': 2, 'created': '2020-01-14 21:39:02.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7e31225827ad6f1296bdfdb0a199c22f6a9ccbf2', 'message': 'Cap Pint version for python 3.5 or older\n\nPython <3.6 support was dropped in Pint 0.10 [1].\nPint in upper-constraints.txt was updated to 0.10 recently and it causes\na failure in the translation jobs which run with python 3.5 [2].\nThis commit caps Pint version to 0.9 for python 3.4 and 3.5.\n\n[1] https://github.com/hgrecco/pint/issues/906\n[2] http://zuul.openstack.org/build/2ba794496679447a97537e82857eba0e\n\nChange-Id: I605115b0c2f4ea7dcf147238e9f6234e92c7d7ca\n'}]",2,702538,7e31225827ad6f1296bdfdb0a199c22f6a9ccbf2,20,5,2,841,,,0,"Cap Pint version for python 3.5 or older

Python <3.6 support was dropped in Pint 0.10 [1].
Pint in upper-constraints.txt was updated to 0.10 recently and it causes
a failure in the translation jobs which run with python 3.5 [2].
This commit caps Pint version to 0.9 for python 3.4 and 3.5.

[1] https://github.com/hgrecco/pint/issues/906
[2] http://zuul.openstack.org/build/2ba794496679447a97537e82857eba0e

Change-Id: I605115b0c2f4ea7dcf147238e9f6234e92c7d7ca
",git fetch https://review.opendev.org/openstack/requirements refs/changes/38/702538/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,4a63f4e0c1526b33b63db9126d59bcaea9841dfb,cap-pint-py35,Pint===0.9;python_version=='3.4' Pint===0.9;python_version=='3.5',Pint===0.10.1;python_version=='3.4' Pint===0.10.1;python_version=='3.5',4,3
openstack%2Fcinder-tempest-plugin~master~I3ff7a714d5fd61edd72e00c7a454c81724844f99,openstack/cinder-tempest-plugin,master,I3ff7a714d5fd61edd72e00c7a454c81724844f99,Drop python 2.7 support and testing,MERGED,2020-01-16 20:19:47.000000000,2020-01-18 03:41:28.000000000,2020-01-18 03:41:28.000000000,"[{'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2020-01-16 20:19:47.000000000', 'files': ['test-requirements.txt', '.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder-tempest-plugin/commit/e0622ed5b8ae42829341aa12d58abfd70ab68d92', 'message': 'Drop python 2.7 support and testing\n\nChange-Id: I3ff7a714d5fd61edd72e00c7a454c81724844f99\nCloses-bug: #1853372\n'}]",0,702977,e0622ed5b8ae42829341aa12d58abfd70ab68d92,9,4,1,5314,,,0,"Drop python 2.7 support and testing

Change-Id: I3ff7a714d5fd61edd72e00c7a454c81724844f99
Closes-bug: #1853372
",git fetch https://review.opendev.org/openstack/cinder-tempest-plugin refs/changes/77/702977/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', '.zuul.yaml', 'setup.cfg', 'tox.ini']",4,e0622ed5b8ae42829341aa12d58abfd70ab68d92,bug/1853372,minversion = 3.1.0# this allows tox to infer the base python from the environment name # and override any basepython configured in this file ignore_basepython_conflict=truebasepython = python3,minversion = 2.0basepython = python3basepython = python3,9,8
openstack%2Frequirements~stable%2Frocky~I8f76b6b486993637228e6893c792cfa6ffada3bd,openstack/requirements,stable/rocky,I8f76b6b486993637228e6893c792cfa6ffada3bd,Remove trusty wheel build jobs,MERGED,2020-01-16 16:25:01.000000000,2020-01-18 03:41:26.000000000,2020-01-18 03:41:26.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 16:25:01.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5176ef6fd80bfb9eacb84e2951447ae6ea8dada3', 'message': 'Remove trusty wheel build jobs\n\nIn prepartion for Trusty node removal, stop testing wheel builds in\nrequirements.\n\nChange-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd\n(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)\n'}]",0,702914,5176ef6fd80bfb9eacb84e2951447ae6ea8dada3,11,5,1,6547,,,0,"Remove trusty wheel build jobs

In prepartion for Trusty node removal, stop testing wheel builds in
requirements.

Change-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd
(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/14/702914/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,5176ef6fd80bfb9eacb84e2951447ae6ea8dada3,trusty-removal,, - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt,0,6
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I6d97a9dcf5609003663920e8762e07ceea2e7933,openstack/tripleo-heat-templates,stable/train,I6d97a9dcf5609003663920e8762e07ceea2e7933,Ovn upgrade - test if db already exist,MERGED,2020-01-10 09:48:28.000000000,2020-01-18 03:35:06.000000000,2020-01-18 03:35:06.000000000,"[{'_account_id': 5756}, {'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-10 09:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e68fe2ead432ce53230fb5d109ea07c354e66680', 'message': 'Ovn upgrade - test if db already exist\n\nTest if db already exist before doing the ovstool create.\nIf not it will failed during upgrade\n\nChange-Id: I6d97a9dcf5609003663920e8762e07ceea2e7933\nCloses-Bug: #1853012\n'}, {'number': 2, 'created': '2020-01-12 08:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6837a399497930c8ddde8b6f6f04845278951ac9', 'message': 'Ovn upgrade - test if db already exist\n\nTest if db already exist before doing the ovstool create.\nIf not it will failed during upgrade\n\nDepends-On: I03f0171a289f42437c3c9239f05d22168f5e2e87\n\nChange-Id: I6d97a9dcf5609003663920e8762e07ceea2e7933\nCloses-Bug: #1853012\n'}, {'number': 3, 'created': '2020-01-15 10:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2d58dc3715f471bb7c2c83c14c8433d724a1f392', 'message': 'Ovn upgrade - test if db already exist\n\nTest if db already exist before doing the ovstool create.\nIf not it will failed during upgrade\n\nDepends-On: I03f0171a289f42437c3c9239f05d22168f5e2e87\n\nChange-Id: I6d97a9dcf5609003663920e8762e07ceea2e7933\nCloses-Bug: #1853012\n'}, {'number': 4, 'created': '2020-01-15 15:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6f874e8068fa5a59e21f48c3db275b9c6ea3b5b1', 'message': 'Ovn upgrade - test if db already exist\n\nTest if db already exist before doing the ovstool create.\nIf not it will failed during upgrade\n\nDepends-On: I03f0171a289f42437c3c9239f05d22168f5e2e87\n\nChange-Id: I6d97a9dcf5609003663920e8762e07ceea2e7933\nCloses-Bug: #1853012\n'}, {'number': 5, 'created': '2020-01-17 10:19:32.000000000', 'files': ['deployment/ovn/ovn-dbs-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f9b6c40f329fb69606c03b6a99c19d8762c8f46', 'message': 'Ovn upgrade - test if db already exist\n\nTest if db already exist before doing the ovstool create.\nIf not it will failed during upgrade\n\nCloses-Bug: #1853012\nChange-Id: I6d97a9dcf5609003663920e8762e07ceea2e7933\n'}]",6,701920,7f9b6c40f329fb69606c03b6a99c19d8762c8f46,41,12,5,16515,,,0,"Ovn upgrade - test if db already exist

Test if db already exist before doing the ovstool create.
If not it will failed during upgrade

Closes-Bug: #1853012
Change-Id: I6d97a9dcf5609003663920e8762e07ceea2e7933
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/20/701920/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-dbs-container-puppet.yaml'],1,e68fe2ead432ce53230fb5d109ea07c354e66680,bug/1853012," command: bash -c $* -- eval if [ ! -z $(ovsdb-tool db-name) ]; then exec ovsdb-tool create ""/var/lib/openvswitch/ovnsb.db"" ""/usr/share/openvswitch/ovn-sb.ovsschema""; fi command: bash -c $* -- eval if [ ! -z $(ovsdb-tool db-name) ]; then exec ovsdb-tool create ""/var/lib/openvswitch/ovnsb.db"" ""/usr/share/openvswitch/ovn-sb.ovsschema""; fi"," command: ""ovsdb-tool create /var/lib/openvswitch/ovnnb.db /usr/share/openvswitch/ovn-nb.ovsschema"" command: ""ovsdb-tool create /var/lib/openvswitch/ovnsb.db /usr/share/openvswitch/ovn-sb.ovsschema""",2,2
openstack%2Ftripleo-quickstart~master~Iac061507cbb2a8756f8a0e124eb7d43afa7b318f,openstack/tripleo-quickstart,master,Iac061507cbb2a8756f8a0e124eb7d43afa7b318f,[fs052] use plain smoke tag for tempest tests in seperate var,MERGED,2020-01-17 04:53:42.000000000,2020-01-18 03:16:59.000000000,2020-01-18 03:15:03.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-17 04:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/36a49a9303a2890c48c44ee9bbd54e00aa6074a7', 'message': ""[fs052] use plain smoke tag for tempest tests\n\nIn fs052, for running smoke tests, we are using a ugly smoke regex\nwhich is not properly parsed by stestr regex processor, let' use\nplain smoke tag to trigger the smoke tests.\n\nCloses-Bug: #1860016\n\nChange-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}, {'number': 2, 'created': '2020-01-17 07:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e7272e46717b35e5da2f538e515f26cd39d642bc', 'message': ""[fs052] use plain smoke tag for tempest tests\n\nIn fs052, for running smoke tests, we are using a ugly smoke regex\nwhich is not properly parsed by stestr regex processor, let' use\nplain smoke tag to trigger the smoke tests.\n\nCloses-Bug: #1860016\n\nChange-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}, {'number': 3, 'created': '2020-01-17 08:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2b88cc9ab8dc24d1221487e25fb775b9efb1e60d', 'message': ""[fs052] use plain smoke tag for tempest tests\n\nIn fs052 periodic, for running smoke tests, we are using a ugly\nsmoke regex which is not properly parsed by stestr regex processor,\nlet' use plain smoke tag to trigger the smoke tests and also fix\nthe conditional for the same.\n\nCloses-Bug: #1860016\n\nChange-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}, {'number': 4, 'created': '2020-01-17 12:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/78377fc3bcbfdfe1ace5194a60453140b241df01', 'message': ""[fs052] use plain smoke tag for tempest tests\n\nIn fs052 periodic, for running smoke tests, we are using a ugly\nsmoke regex which is not properly parsed by stestr regex processor,\nlet' use plain smoke tag to trigger the smoke tests and also fix\nthe conditional for the same.\n\nCloses-Bug: #1860016\n\nChange-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}, {'number': 5, 'created': '2020-01-17 15:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/0307a42cca787a9503180b7f6b3456ad4e68544f', 'message': ""[fs052] use plain smoke tag for tempest tests in seperate var\n\nIn fs052 periodic, for running smoke tests, we are using a ugly\nsmoke regex which is not properly parsed by stestr regex processor,\nlet' use plain smoke tag to trigger the smoke tests from a seperate var\nand also fix the conditional to run smoke test only in periodic.\n\nCloses-Bug: #1860016\n\nChange-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}, {'number': 6, 'created': '2020-01-17 16:19:28.000000000', 'files': ['config/general_config/featureset052.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d91806291d4a94cc3356f87018b8041fd209c0b8', 'message': ""[fs052] use plain smoke tag for tempest tests in seperate var\n\nIn fs052 periodic, for running smoke tests, we are using a ugly\nsmoke regex which is not properly parsed by stestr regex processor,\nlet' use plain smoke tag to trigger the smoke tests from a seperate var\nand also fix the conditional to run smoke test only in periodic.\n\nCloses-Bug: #1860016\n\nChange-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n""}]",0,703014,d91806291d4a94cc3356f87018b8041fd209c0b8,19,5,6,12393,,,0,"[fs052] use plain smoke tag for tempest tests in seperate var

In fs052 periodic, for running smoke tests, we are using a ugly
smoke regex which is not properly parsed by stestr regex processor,
let' use plain smoke tag to trigger the smoke tests from a seperate var
and also fix the conditional to run smoke test only in periodic.

Closes-Bug: #1860016

Change-Id: Iac061507cbb2a8756f8a0e124eb7d43afa7b318f
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/14/703014/4 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset052.yml'],1,36a49a9303a2890c48c44ee9bbd54e00aa6074a7,fix_tempest,test_white_regex: 'smoke',test_white_regex: '\[.*\bsmoke\b.*\]',1,1
openstack%2Ftripleo-ci~master~I5ccc1e853c34f13a1c0cb3e93af2dd88e4824a89,openstack/tripleo-ci,master,I5ccc1e853c34f13a1c0cb3e93af2dd88e4824a89,reduce scope of standalone-upgrade(stein/train),MERGED,2020-01-16 17:27:12.000000000,2020-01-18 03:15:02.000000000,2020-01-18 03:15:02.000000000,"[{'_account_id': 6816}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-16 17:27:12.000000000', 'files': ['zuul.d/standalone-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4796b3e3931eb3d390cff26e38a97f8bcd6a3e39', 'message': 'reduce scope of standalone-upgrade(stein/train)\n\ntoo many errors atm to enable these as voting\nand running across multple branches\n\nChange-Id: I5ccc1e853c34f13a1c0cb3e93af2dd88e4824a89\n'}]",2,702932,4796b3e3931eb3d390cff26e38a97f8bcd6a3e39,24,8,1,9592,,,0,"reduce scope of standalone-upgrade(stein/train)

too many errors atm to enable these as voting
and running across multple branches

Change-Id: I5ccc1e853c34f13a1c0cb3e93af2dd88e4824a89
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/32/702932/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/standalone-jobs.yaml'],1,4796b3e3931eb3d390cff26e38a97f8bcd6a3e39,, branches: ^(stable/stein).* voting: false branches: ^(stable/train).*, branches: ^(stable/(rocky|stein)).* voting: true branches: ^(stable/(stein|train)).*,3,3
openstack%2Ftripleo-validations~master~I0fac174ef4ac801f6bb96e06eed0a29e3a064d27,openstack/tripleo-validations,master,I0fac174ef4ac801f6bb96e06eed0a29e3a064d27,Remove default ansible option in test runs,MERGED,2020-01-17 15:22:46.000000000,2020-01-18 02:51:55.000000000,2020-01-18 02:51:55.000000000,"[{'_account_id': 11491}, {'_account_id': 22348}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-17 15:22:46.000000000', 'files': ['zuul.d/playbooks/run.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/3928fb6691cf8247c629b56521b408bf8448e011', 'message': 'Remove default ansible option in test runs\n\nThis change removes the default ansible option in test runs. This is being\nremoved because if any args are presnet the test job will only run one\nscenario, which is ""default"", unless otherwise defined.\n\nChange-Id: I0fac174ef4ac801f6bb96e06eed0a29e3a064d27\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",0,703101,3928fb6691cf8247c629b56521b408bf8448e011,9,4,1,7353,,,0,"Remove default ansible option in test runs

This change removes the default ansible option in test runs. This is being
removed because if any args are presnet the test job will only run one
scenario, which is ""default"", unless otherwise defined.

Change-Id: I0fac174ef4ac801f6bb96e06eed0a29e3a064d27
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/01/703101/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/playbooks/run.yml'],1,3928fb6691cf8247c629b56521b408bf8448e011,," --ansible-args='{{ tripleo_job_ansible_args | default("""") }}' \"," --ansible-args='{{ tripleo_job_ansible_args | default(""-v"") }}' \",1,1
openstack%2Fopenstack-ansible~master~I7093cf9ebe9b92ed6566ba413fae50d147043f25,openstack/openstack-ansible,master,I7093cf9ebe9b92ed6566ba413fae50d147043f25,Bump SHAs for master,MERGED,2020-01-12 14:02:55.000000000,2020-01-18 02:48:53.000000000,2020-01-18 02:46:07.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27822}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-01-12 14:02:55.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'releasenotes/notes/add-iptables-5ff8c4317e2e8498.yaml', 'releasenotes/notes/session_engine-54753c41d355e34e.yaml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6c6f25f81701e141ce9b8365d37cb04511e105ce', 'message': 'Bump SHAs for master\n\nChange-Id: I7093cf9ebe9b92ed6566ba413fae50d147043f25\n'}]",0,702133,6c6f25f81701e141ce9b8365d37cb04511e105ce,17,5,1,28619,,,0,"Bump SHAs for master

Change-Id: I7093cf9ebe9b92ed6566ba413fae50d147043f25
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/33/702133/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'releasenotes/notes/add-iptables-5ff8c4317e2e8498.yaml', 'releasenotes/notes/session_engine-54753c41d355e34e.yaml', 'playbooks/defaults/repo_packages/openstack_testing.yml']",6,6c6f25f81701e141ce9b8365d37cb04511e105ce,bump_osa,tempest_git_install_branch: b63725301488a910d2ad5e1a3f8a11b45b187845 # HEAD as of 12.01.2020,tempest_git_install_branch: 3e42d81b7205078bd167fa8921cc18f11bd68224 # HEAD as of 29.12.2019,60,49
openstack%2Ftripleo-upgrade~master~Ie31a66c13cdc0c778baf0e28516344aeced8ee38,openstack/tripleo-upgrade,master,Ie31a66c13cdc0c778baf0e28516344aeced8ee38,add standalone jobs to tripleo-upgrade,MERGED,2020-01-17 13:51:47.000000000,2020-01-18 02:38:11.000000000,2020-01-18 02:38:10.000000000,"[{'_account_id': 8297}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-01-17 13:51:47.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/38d0e721f27724ef315d87d3fa1be71fd3341167', 'message': 'add standalone jobs to tripleo-upgrade\n\nrun master as non-voting\nrun n-1 as voting and gating\n\nChange-Id: Ie31a66c13cdc0c778baf0e28516344aeced8ee38\n'}]",0,703082,38d0e721f27724ef315d87d3fa1be71fd3341167,7,8,1,9592,,,0,"add standalone jobs to tripleo-upgrade

run master as non-voting
run n-1 as voting and gating

Change-Id: Ie31a66c13cdc0c778baf0e28516344aeced8ee38
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/82/703082/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,38d0e721f27724ef315d87d3fa1be71fd3341167,, voting: false files: - ^ci-scripts\/.*$ - ^defaults\/.*$ - ^files\/.*$ - ^meta\/.*$ - ^tasks\/.*$ - ^templates\/.*$ - ^zuul.d\/.*$ - tripleo-ci-centos-7-standalone-upgrade-train: voting: true dependencies: - tripleo-upgrade-centos-7-molecule files: - ^ci-scripts\/.*$ - ^defaults\/.*$ - ^files\/.*$ - ^meta\/.*$ - ^tasks\/.*$ - ^templates\/.*$ - ^zuul.d\/.*$ - tripleo-ci-centos-7-standalone-upgrade-train: voting: true dependencies: - tripleo-upgrade-centos-7-molecule files: - ^ci-scripts\/.*$ - ^defaults\/.*$ - ^files\/.*$ - ^meta\/.*$ - ^tasks\/.*$ - ^templates\/.*$,,32,0
openstack%2Ftrove~stable%2Ftrain~I922a1c5469309704cc6dd60a1ef57e43a98a3c00,openstack/trove,stable/train,I922a1c5469309704cc6dd60a1ef57e43a98a3c00,Check network conflict,MERGED,2020-01-14 08:31:46.000000000,2020-01-18 02:34:24.000000000,2020-01-18 02:32:10.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 08:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cc9eda0242d3e650f17eb9ec1f0ce0a4a76561e1', 'message': ""Check network conflict\n\nThe user's network to create instance should not conflict with the\nmanagement network.\n\nChange-Id: I922a1c5469309704cc6dd60a1ef57e43a98a3c00\n(cherry picked from commit 263339b4db0fb8e1d10c9933b71a0d5b7140cc68)\n""}, {'number': 2, 'created': '2020-01-14 20:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ec238727ea90142e5ac3843a1150cb92244f675f', 'message': ""Check network conflict\n\nThe user's network to create instance should not conflict with the\nmanagement network.\n\nChange-Id: I922a1c5469309704cc6dd60a1ef57e43a98a3c00\n(cherry picked from commit 263339b4db0fb8e1d10c9933b71a0d5b7140cc68)\n""}, {'number': 3, 'created': '2020-01-16 11:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e9ff417a0daf54d2f25089194184ed82db850a8a', 'message': ""Check network conflict\n\nThe user's network to create instance should not conflict with the\nmanagement network.\n\nChange-Id: I922a1c5469309704cc6dd60a1ef57e43a98a3c00\n(cherry picked from commit 263339b4db0fb8e1d10c9933b71a0d5b7140cc68)\n""}, {'number': 4, 'created': '2020-01-16 20:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d6d88cdd2891e1941c76b02502fb67d2a7e3045e', 'message': ""Check network conflict\n\nThe user's network to create instance should not conflict with the\nmanagement network.\n\nThis patch also fixes the bug in trove-guestagent:\nAttributeError: 'TroveContext' object has no attribute 'notification'\nwhich has been merged in master branch in\nhttps://review.opendev.org/#/c/697225/\n\nChange-Id: I922a1c5469309704cc6dd60a1ef57e43a98a3c00\n(cherry picked from commit 263339b4db0fb8e1d10c9933b71a0d5b7140cc68)\n""}, {'number': 5, 'created': '2020-01-17 04:21:37.000000000', 'files': ['trove/common/exception.py', 'trove/common/neutron.py', 'integration/scripts/trovestack', 'trove/instance/models.py', '.zuul.yaml', 'trove/instance/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/095a5b0514f800258a3e3cccc94c94135cab8ac5', 'message': ""Check network conflict\n\nThe user's network to create instance should not conflict with the\nmanagement network.\n\nThis patch also fixes the bug in trove-guestagent:\nAttributeError: 'TroveContext' object has no attribute 'notification'\nwhich has been merged in master branch in\nhttps://review.opendev.org/#/c/697225/\n\nChange-Id: I922a1c5469309704cc6dd60a1ef57e43a98a3c00\n(cherry picked from commit 263339b4db0fb8e1d10c9933b71a0d5b7140cc68)\n""}]",0,702371,095a5b0514f800258a3e3cccc94c94135cab8ac5,22,2,5,6732,,,0,"Check network conflict

The user's network to create instance should not conflict with the
management network.

This patch also fixes the bug in trove-guestagent:
AttributeError: 'TroveContext' object has no attribute 'notification'
which has been merged in master branch in
https://review.opendev.org/#/c/697225/

Change-Id: I922a1c5469309704cc6dd60a1ef57e43a98a3c00
(cherry picked from commit 263339b4db0fb8e1d10c9933b71a0d5b7140cc68)
",git fetch https://review.opendev.org/openstack/trove refs/changes/71/702371/2 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/exception.py', 'trove/common/neutron.py', 'trove/instance/service.py']",3,cc9eda0242d3e650f17eb9ec1f0ce0a4a76561e1,stable-train-check-network-conflict,"import ipaddress from trove.common import clientsfrom trove.common import neutron def _check_network_overlap(self, context, user_network): neutron_client = clients.create_neutron_client(context) user_cidrs = neutron.get_subnet_cidrs(neutron_client, user_network) mgmt_cidrs = neutron.get_mamangement_subnet_cidrs(neutron_client) LOG.debug(""Cidrs of the user network: %s, cidrs of the management "" ""network: %s"", user_cidrs, mgmt_cidrs) for user_cidr in user_cidrs: user_net = ipaddress.ip_network(user_cidr) for mgmt_cidr in mgmt_cidrs: mgmt_net = ipaddress.ip_network(mgmt_cidr) if user_net.overlaps(mgmt_net): raise exception.NetworkConflict() if len(nics) > 0: self._check_network_overlap(context, nics[0].get('net-id')) client = clients.create_guest_client(context, id) client = clients.create_guest_client(context, id) client = clients.create_guest_client(context, id) client = clients.create_guest_client(context, id) client = clients.create_guest_client(context, id) client = clients.create_guest_client(context, id)","from trove.common.clients import create_guest_client client = create_guest_client(context, id) client = create_guest_client(context, id) client = create_guest_client(context, id) client = create_guest_client(context, id) client = create_guest_client(context, id) client = create_guest_client(context, id)",55,7
openstack%2Frequirements~stable%2Fqueens~I8f76b6b486993637228e6893c792cfa6ffada3bd,openstack/requirements,stable/queens,I8f76b6b486993637228e6893c792cfa6ffada3bd,Remove trusty wheel build jobs,MERGED,2020-01-16 16:26:26.000000000,2020-01-18 01:49:58.000000000,2020-01-18 01:49:58.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 16:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/afa32fc7aa07343000b5a381ac61020b436bc369', 'message': 'Remove trusty wheel build jobs\n\nIn prepartion for Trusty node removal, stop testing wheel builds in\nrequirements.\n\nChange-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd\n(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)\n'}, {'number': 2, 'created': '2020-01-17 09:32:48.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f7b45b47bfc5f9b635eb5fa6613482c8c253b091', 'message': 'Remove trusty wheel build jobs\n\nIn prepartion for Trusty node removal, stop testing wheel builds in\nrequirements.\n\nChange-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd\n(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)\n'}]",0,702915,f7b45b47bfc5f9b635eb5fa6613482c8c253b091,15,5,2,6547,,,0,"Remove trusty wheel build jobs

In prepartion for Trusty node removal, stop testing wheel builds in
requirements.

Change-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd
(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/15/702915/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,afa32fc7aa07343000b5a381ac61020b436bc369,trusty-removal,, - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt,0,6
openstack%2Frequirements~stable%2Fqueens~I7420dca0b3a1bd11db634629ef92e275368f50bc,openstack/requirements,stable/queens,I7420dca0b3a1bd11db634629ef92e275368f50bc,Fix testsuite: pep8 and requirements-integration,MERGED,2020-01-17 07:17:58.000000000,2020-01-18 01:49:57.000000000,2020-01-18 01:49:57.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 07:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/97678b269ecbc2557b85bf6bae8f2b0306b761e7', 'message': ""Fix testsuite: pep8\n\nfix pep8:\nCap hacking, a newer hacking version includes newer pep8 and includes\nmore warnings that break build. There's no reason to update hacking in a\nstable branch.\n\nChange-Id: I7420dca0b3a1bd11db634629ef92e275368f50bc\n""}, {'number': 2, 'created': '2020-01-17 07:51:56.000000000', 'files': ['global-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/requirements/commit/bb70fa451f366db180202cb6a778d6208713a2cc', 'message': ""Fix testsuite: pep8 and requirements-integration\n\nfix pep8:\nCap hacking, a newer hacking version includes newer pep8 and includes\nmore warnings that break build. There's no reason to update hacking in a\nstable branch.\n\nfix requirements-integration:\nCap gunicorn, version 20 is only supporting Python 3.5 and newer (see\nalso I81658ed225d6da3b98fc63d8454562a2f27a2995 for train).\n\nFailures can be seen in\nhttps://review.opendev.org/702915 and https://review.opendev.org/702462.\n\nChange-Id: I7420dca0b3a1bd11db634629ef92e275368f50bc\n""}]",0,703023,bb70fa451f366db180202cb6a778d6208713a2cc,10,3,2,6547,,,0,"Fix testsuite: pep8 and requirements-integration

fix pep8:
Cap hacking, a newer hacking version includes newer pep8 and includes
more warnings that break build. There's no reason to update hacking in a
stable branch.

fix requirements-integration:
Cap gunicorn, version 20 is only supporting Python 3.5 and newer (see
also I81658ed225d6da3b98fc63d8454562a2f27a2995 for train).

Failures can be seen in
https://review.opendev.org/702915 and https://review.opendev.org/702462.

Change-Id: I7420dca0b3a1bd11db634629ef92e275368f50bc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/23/703023/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,97678b269ecbc2557b85bf6bae8f2b0306b761e7,fix-queens," hacking>=1.0.0,<=1.1.0", hacking>=1.0.0,1,1
openstack%2Floci~master~I6746236f5ad743f62b22910686831409d7b724a1,openstack/loci,master,I6746236f5ad743f62b22910686831409d7b724a1,Add purestorage to requirements image,ABANDONED,2020-01-17 23:48:21.000000000,2020-01-18 00:33:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-17 23:48:21.000000000', 'files': ['scripts/requirements.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/4fdef1df1057c7fdb7ed654b11496bd87c31698a', 'message': 'Add purestorage to requirements image\n\nChange-Id: I6746236f5ad743f62b22910686831409d7b724a1\n'}]",0,703209,4fdef1df1057c7fdb7ed654b11496bd87c31698a,3,1,1,8863,,,0,"Add purestorage to requirements image

Change-Id: I6746236f5ad743f62b22910686831409d7b724a1
",git fetch https://review.opendev.org/openstack/loci refs/changes/09/703209/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/requirements.sh'],1,4fdef1df1057c7fdb7ed654b11496bd87c31698a,,echo uwsgi enum-compat purestorage ${PIP_PACKAGES} | xargs -n1 | split -l1 -a3,echo uwsgi enum-compat ${PIP_PACKAGES} | xargs -n1 | split -l1 -a3,1,1
openstack%2Fwhitebox-tempest-plugin~master~I0b1786dd6cfa74d7ed315b0b3a92968a10a2c3e9,openstack/whitebox-tempest-plugin,master,I0b1786dd6cfa74d7ed315b0b3a92968a10a2c3e9,Increase service restart sleep from 5 to 15s,MERGED,2020-01-15 17:51:57.000000000,2020-01-17 23:02:22.000000000,2020-01-17 23:02:22.000000000,"[{'_account_id': 7020}, {'_account_id': 8864}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 27478}, {'_account_id': 31033}]","[{'number': 1, 'created': '2020-01-15 17:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/b7d9a3aafaf6e3eb927102b98c988b63c905af39', 'message': 'Increase service restart sleep from 5 to 15s\n\nCurrent sleep time of 5 seconds after restarting a service is not always\nsufficient enough for the service to become fully active in certain\nenvironments. Increasing the sleep time from 5 seconds to 15. This\nshould be considered an interim fix, long term a more elegant solution\nshould be utilized for handling graceful service restarts.\n\nChange-Id: I0b1786dd6cfa74d7ed315b0b3a92968a10a2c3e9\n'}, {'number': 2, 'created': '2020-01-15 17:54:41.000000000', 'files': ['whitebox_tempest_plugin/services/clients.py'], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/d9746f18b6366ba3346db8c0a307608d66311572', 'message': 'Increase service restart sleep from 5 to 15s\n\nCurrent sleep time of 5 seconds after restarting a service is not always\nsufficient enough for the service to become fully active in certain\nenvironments. Increasing the sleep time from 5 seconds to 15. This\nshould be considered an interim fix, long term a more elegant solution\nshould be utilized for handling graceful service restarts.\n\nChange-Id: I0b1786dd6cfa74d7ed315b0b3a92968a10a2c3e9\n'}]",1,702710,d9746f18b6366ba3346db8c0a307608d66311572,13,6,2,31033,,,0,"Increase service restart sleep from 5 to 15s

Current sleep time of 5 seconds after restarting a service is not always
sufficient enough for the service to become fully active in certain
environments. Increasing the sleep time from 5 seconds to 15. This
should be considered an interim fix, long term a more elegant solution
should be utilized for handling graceful service restarts.

Change-Id: I0b1786dd6cfa74d7ed315b0b3a92968a10a2c3e9
",git fetch https://review.opendev.org/openstack/whitebox-tempest-plugin refs/changes/10/702710/1 && git format-patch -1 --stdout FETCH_HEAD,['whitebox_tempest_plugin/services/clients.py'],1,b7d9a3aafaf6e3eb927102b98c988b63c905af39,sysctl_reset_time," time.sleep(15) def get_nic_cpu_affinity(self, nic): cmd = 'numactl -a -N netdev:{} grep allowed ' \ '/proc/self/status'.format(nic) numactl = self.execute(cmd, sudo=True) for line in StringIO(numactl).readlines(): if 'cpus_allowed_list:' in line.lower(): cpus_str = line.split(':')[1].strip() return cpus_str.split(',') return [] ", time.sleep(5),11,1
openstack%2Fnetworking-ovn~stable%2Frocky~Iddd89725e617b22c35e30ae7f20a7f87de296cdb,openstack/networking-ovn,stable/rocky,Iddd89725e617b22c35e30ae7f20a7f87de296cdb,Fix revision number race condition with attaching router interfaces,MERGED,2020-01-10 12:55:14.000000000,2020-01-17 22:05:59.000000000,2020-01-17 22:05:59.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-10 12:55:14.000000000', 'files': ['networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/unit/db/test_revision.py', 'networking_ovn/db/revision.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/64ac6d274e8f3534924546bc1054404236f89f95', 'message': 'Fix revision number race condition with attaching router interfaces\n\nThere\'s a special case in the update_port_precommit() method to handle\nthe case where an existing port is being added to a router. The method\nwill try to create an entry in the ovn_revision_numbers table but, if\nthat entry is already present a DBDuplicateEntry exception will be\nraised and the whole update method will fail.\n\nThe update_port_precommit() is the only method at present that have this\nspecial handler, for all other resources creating a new record in the\novn_revision_numbers table happens at the create_*_precommit() methods\n(this include create_port_precommit() as well).\n\nThis patch is fixing the problem by adding a new parameter to the\nreate_initial_revision() method called ""may_exist"". When set to True the\ncode will not raise an DBDuplicateEntry if the record already exists. By\ndefault this method is False.\n\nCloses-Bug: #1800875\nChange-Id: Iddd89725e617b22c35e30ae7f20a7f87de296cdb\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit b5642d93a6c0ce0141fb5f61a3d853b026b7b67d)\n'}]",0,701949,64ac6d274e8f3534924546bc1054404236f89f95,13,4,1,8655,,,0,"Fix revision number race condition with attaching router interfaces

There's a special case in the update_port_precommit() method to handle
the case where an existing port is being added to a router. The method
will try to create an entry in the ovn_revision_numbers table but, if
that entry is already present a DBDuplicateEntry exception will be
raised and the whole update method will fail.

The update_port_precommit() is the only method at present that have this
special handler, for all other resources creating a new record in the
ovn_revision_numbers table happens at the create_*_precommit() methods
(this include create_port_precommit() as well).

This patch is fixing the problem by adding a new parameter to the
reate_initial_revision() method called ""may_exist"". When set to True the
code will not raise an DBDuplicateEntry if the record already exists. By
default this method is False.

Closes-Bug: #1800875
Change-Id: Iddd89725e617b22c35e30ae7f20a7f87de296cdb
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit b5642d93a6c0ce0141fb5f61a3d853b026b7b67d)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/49/701949/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/ml2/mech_driver.py', 'networking_ovn/tests/unit/db/test_revision.py', 'networking_ovn/db/revision.py']",3,64ac6d274e8f3534924546bc1054404236f89f95,bug/1800875-stable/rocky," revision_number=ovn_const.INITIAL_REV_NUM, may_exist=False): db_func = session.merge if may_exist else session.add db_func(row)", revision_number=ovn_const.INITIAL_REV_NUM): session.add(row),21,3
openstack%2Fdesignate~stable%2Ftrain~If57d79e0ac70189f0e387830e5a2473eb472eb12,openstack/designate,stable/train,If57d79e0ac70189f0e387830e5a2473eb472eb12,Use stable branch scenario job,MERGED,2020-01-17 11:34:32.000000000,2020-01-17 21:22:52.000000000,2020-01-17 21:18:54.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2020-01-17 11:34:32.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/designate/commit/4871561dd05b084e72042ef6bfeeaab8b5f3212b', 'message': 'Use stable branch scenario job\n\nWe need to use neutron-tempest-plugin-designate-scenario from the\nmatching stable branch.\n\nChange-Id: If57d79e0ac70189f0e387830e5a2473eb472eb12\n'}]",0,703056,4871561dd05b084e72042ef6bfeeaab8b5f3212b,9,2,1,13252,,,0,"Use stable branch scenario job

We need to use neutron-tempest-plugin-designate-scenario from the
matching stable branch.

Change-Id: If57d79e0ac70189f0e387830e5a2473eb472eb12
",git fetch https://review.opendev.org/openstack/designate refs/changes/56/703056/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,4871561dd05b084e72042ef6bfeeaab8b5f3212b,fix-scenarion-job-train, - neutron-tempest-plugin-designate-scenario-train, - neutron-tempest-plugin-designate-scenario,1,1
openstack%2Fmonasca-tempest-plugin~master~I2d25afe3ad4e29efa540381450ba71405f36ff5c,openstack/monasca-tempest-plugin,master,I2d25afe3ad4e29efa540381450ba71405f36ff5c,Change headers in requests to Kibana,MERGED,2019-09-03 13:40:46.000000000,2020-01-17 19:35:55.000000000,2020-01-17 19:33:29.000000000,"[{'_account_id': 16222}, {'_account_id': 21922}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-09-03 13:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/693658f6896124171fd9c314c15722729f4c82ae', 'message': '[WIP] Change headers in requests to Kibana\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 2, 'created': '2019-09-12 09:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/02901a587631795c2e2a190b57a5e864d350802b', 'message': 'Change headers in requests to Kibana\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 3, 'created': '2019-09-16 22:48:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/a3b3eb7b92889638aeedce39fa31bc4c2cd33e26', 'message': 'Change headers in requests to Kibana\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 4, 'created': '2019-09-19 09:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/e6a5822053dcbf3537c8f9194b22096c4f6c2e8c', 'message': 'Change headers in requests to Kibana\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 5, 'created': '2020-01-08 08:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/c73c4feed0310adca64dd324a572af0e2675ae6b', 'message': 'Change headers in requests to Kibana\n\nThis is related to changed behavior in newer Kibana versions.\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 6, 'created': '2020-01-09 08:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/202a23c61ba6019c5117ac90e29606ea3da0a235', 'message': 'Change headers in requests to Kibana\n\nThis is related to changed behavior in newer Kibana versions.\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 7, 'created': '2020-01-09 11:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/49f6f2adf5ef3bec0cb5b3c4a5ec54cd6af353f8', 'message': 'Change headers in requests to Kibana\n\nThis is related to changed behavior in newer Kibana versions.\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 8, 'created': '2020-01-14 12:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/81ecd74fdac7e0383d1aec2ee882d98dd8479326', 'message': 'Change headers in requests to Kibana\n\nThis is related to changed behavior in newer Kibana versions.\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}, {'number': 9, 'created': '2020-01-17 16:26:11.000000000', 'files': ['monasca_tempest_tests/tests/api/test_dimensions.py', 'monasca_tempest_tests/services/elasticsearch_client.py', 'monasca_tempest_tests/tests/log_api/base.py', 'monasca_tempest_tests/config.py'], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/6f2f401bd54c8cee72f42bc58d3d06d416f86798', 'message': 'Change headers in requests to Kibana\n\nThis is related to changed behavior in newer Kibana versions.\n\nStory: 2006376\nTask: 36165\n\nChange-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c\n'}]",0,679781,6f2f401bd54c8cee72f42bc58d3d06d416f86798,32,4,9,30221,,,0,"Change headers in requests to Kibana

This is related to changed behavior in newer Kibana versions.

Story: 2006376
Task: 36165

Change-Id: I2d25afe3ad4e29efa540381450ba71405f36ff5c
",git fetch https://review.opendev.org/openstack/monasca-tempest-plugin refs/changes/81/679781/5 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_tempest_tests/services/elasticsearch_client.py', 'monasca_tempest_tests/tests/log_api/base.py', 'monasca_tempest_tests/config.py']",3,693658f6896124171fd9c314c15722729f4c82ae,upgrade_elkstack," default='7.3.0',"," default='4.6.3',",8,4
openstack%2Fswift~master~I8cf5d51a5384496fc85e43deb76603a8b620ba6e,openstack/swift,master,I8cf5d51a5384496fc85e43deb76603a8b620ba6e,"Revert ""bulk: Use make_subrequest to make subrequests""",ABANDONED,2019-12-26 18:51:12.000000000,2020-01-17 19:35:40.000000000,,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 18:51:12.000000000', 'files': ['swift/common/middleware/bulk.py', 'test/unit/common/middleware/test_bulk.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b4bb7c62f77bf41de69ad4f69954a674938af2e6', 'message': 'Revert ""bulk: Use make_subrequest to make subrequests""\n\nThis reverts commit 6f00d42f56d38e6267b819fdf06b7264feb50683.\n\nHowever, we *should* clear the swift.proxy_access_log_made flag for\nsubrequests.\n\nAlso, since we ported bulk to py3 *after* the above commit, adda few\nmore unicode test cases and guards.\n\nCloses-Bug: 1857546\nRelated-Bug: 1486193\nChange-Id: I8cf5d51a5384496fc85e43deb76603a8b620ba6e\n'}]",0,700652,b4bb7c62f77bf41de69ad4f69954a674938af2e6,7,3,1,15343,,,0,"Revert ""bulk: Use make_subrequest to make subrequests""

This reverts commit 6f00d42f56d38e6267b819fdf06b7264feb50683.

However, we *should* clear the swift.proxy_access_log_made flag for
subrequests.

Also, since we ported bulk to py3 *after* the above commit, adda few
more unicode test cases and guards.

Closes-Bug: 1857546
Related-Bug: 1486193
Change-Id: I8cf5d51a5384496fc85e43deb76603a8b620ba6e
",git fetch https://review.opendev.org/openstack/swift refs/changes/52/700652/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/bulk.py', 'test/unit/common/middleware/test_bulk.py']",2,b4bb7c62f77bf41de69ad4f69954a674938af2e6,bug/1857546," self.put_paths = [] if env.get('swift.source') in ('EA', 'BD'): assert env['swift.proxy_access_log_made'] is False if not six.PY2: # Check that it's valid WSGI assert all(0 <= ord(c) <= 255 for c in env['PATH_INFO']) if env['REQUEST_METHOD'] == 'PUT': self.put_paths.append(env['PATH_INFO']) # Since there should be a proxy-logging left of us... req.environ['swift.proxy_access_log_made'] = True req.headers.update({ 'transfer-encoding': 'chunked', 'accept': 'application/json;q=1.0', 'X-Delete-At': '1577383915', }) self.assertEqual(put1_headers.get('X-Delete-At'), '1577383915') self.assertEqual(put2_headers.get('X-Delete-At'), '1577383915') {b'good_\xe2\x98\x83': [{'still_good': b'\xe2\x98\x83'}]}, self.assertEqual(self.app.calls, 6) self.assertEqual(resp_data['Number Files Created'], 3) self.assertEqual(self.app.put_paths, [ '/tar_works/acc/sub_dir1/sub1_file1', '/tar_works/acc/sub_dir2/sub2_file2', '/tar_works/acc/good_\xe2\x98\x83/still_good/\xe2\x98\x83', ])"," req.headers['transfer-encoding'] = 'chunked' req.headers['accept'] = 'application/json;q=1.0' self.assertEqual(self.app.calls, 4) self.assertEqual(resp_data['Number Files Created'], 2)",61,31
openstack%2Fopenstack-helm-addons~master~I36c36faa0be1f9e9ea4e5479e219dc14c205d853,openstack/openstack-helm-addons,master,I36c36faa0be1f9e9ea4e5479e219dc14c205d853,Remove ssh configurations,MERGED,2019-09-27 16:14:55.000000000,2020-01-17 19:26:51.000000000,2020-01-17 19:26:51.000000000,"[{'_account_id': 8898}, {'_account_id': 17966}, {'_account_id': 19391}, {'_account_id': 20466}, {'_account_id': 20469}, {'_account_id': 21111}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22786}, {'_account_id': 23928}, {'_account_id': 24999}, {'_account_id': 26686}, {'_account_id': 27772}, {'_account_id': 29585}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-09-27 16:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/cf26cb3718010da013c7f882c3b3bbf2d74e85c3', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 2, 'created': '2019-09-30 14:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/cca68dd5fdd8eb6c2e6ef5327d37f1c11c8ea552', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 3, 'created': '2019-09-30 15:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/be809d7647f34aa411fae94e098d135d8074c20d', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 4, 'created': '2019-10-02 17:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/79a7b4b926db610f07b2dd03faf00d8c5b412f07', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 5, 'created': '2019-10-08 18:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/be7eed8e1d26577f41a467ab186c49b3d7285e39', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 6, 'created': '2019-11-14 16:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/0fe0d93785dcdb77cb7b481d8fbbd4671055752d', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 7, 'created': '2019-11-18 15:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/dedc8074730de1a3ec25b2b5114f1626d9072fa2', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 8, 'created': '2019-11-25 20:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/f9552f4ff651ddf88d0ba64a26f24380c6ad0f3a', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 9, 'created': '2020-01-03 03:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/66752edf2000794d2e8502288a5c18ed7d007838', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 10, 'created': '2020-01-03 21:57:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/74a3333cbef49fbd674f3218b19ddbbc1ad8dca1', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 11, 'created': '2020-01-04 01:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6ceb9bc19b73d896a52c8900e8c673036cf8b75b', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 12, 'created': '2020-01-14 00:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6957755c7c0420b2e45c01aca4cc8f9b84d42bf9', 'message': 'Remove ssh configurations\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}, {'number': 13, 'created': '2020-01-16 17:09:40.000000000', 'files': ['ranger-agent/templates/configmap-etc.yaml', 'ranger/templates/configmap-etc.yaml', 'ranger/templates/deployment-ranger-services.yaml', 'ranger-agent/values.yaml', 'ranger-agent/templates/deployment-ranger-agent-engine.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/80b8ec444afb6be4861c1a536420b02bb5a1bb40', 'message': 'Remove ssh configurations\n\nNewer versions (2.x) of Ranger is removing git repo support When\nOlder versions (1.x) still using it, this patch is to attempt to flag to\nnot use repo in case not supported repo and do cleanup\n\nChange-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853\n'}]",11,685395,80b8ec444afb6be4861c1a536420b02bb5a1bb40,71,15,13,24999,,,0,"Remove ssh configurations

Newer versions (2.x) of Ranger is removing git repo support When
Older versions (1.x) still using it, this patch is to attempt to flag to
not use repo in case not supported repo and do cleanup

Change-Id: I36c36faa0be1f9e9ea4e5479e219dc14c205d853
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/95/685395/1 && git format-patch -1 --stdout FETCH_HEAD,"['ranger/values.yaml', 'ranger-agent/templates/bin/_ranger-agent-engine.sh.tpl', 'ranger-agent/templates/secret-ssh-key.yaml', 'ranger/templates/configmap-etc.yaml', 'ranger/templates/deployment-ranger-services.yaml', 'ranger/templates/bin/_ranger-services.sh.tpl', 'ranger/templates/secret-ssh-key.yaml', 'ranger-agent/values.yaml', 'ranger-agent/templates/deployment-ranger-agent-engine.yaml']",9,cf26cb3718010da013c7f882c3b3bbf2d74e85c3,git,, env: - name: USER valueFrom: secretKeyRef: name: ranger-agent-ssh-secret key: USER - name: USER_HOME valueFrom: secretKeyRef: name: ranger-agent-ssh-secret key: USER_HOME - name: SSH_KEY_FILE valueFrom: secretKeyRef: name: ranger-agent-ssh-secret key: SSH_KEY_FILE - name: SSH_KEY valueFrom: secretKeyRef: name: ranger-agent-ssh-secret key: RANGER_AGENT_PRIVATE_KEY - name: SSH_KEY_CONFIGURATION valueFrom: secretKeyRef: name: ranger-agent-ssh-secret key: RANGER_AGENT_SSH_CONFIG,1,179
openstack%2Fnova~master~I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0,openstack/nova,master,I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0,nova-net: Remove unused exceptions,MERGED,2019-12-03 18:31:13.000000000,2020-01-17 19:25:07.000000000,2020-01-15 20:33:56.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-03 18:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c0f5bfe86a5076571e9e6097a986309280e3a05', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e928c62571f7791068358a4ef57ddd635574a2e8', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74d88f695e080aa9760413f1967000078ec28169', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 4, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bc24e8b75965b0b65e8d0a93d8cbc719f6e7478', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 5, 'created': '2019-12-16 10:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e765e35194e935b02f296c9f574a50ca77a351bc', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 6, 'created': '2019-12-24 12:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c6f4d95097810ac4e2c4aacabc7c2d73a957962', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 7, 'created': '2020-01-06 13:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b60bb60dcc6957bf808762cffe4679047b0fa7ec', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 8, 'created': '2020-01-06 14:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/369ec9d85557eb5b16f9e9e38319f3f8e5cbfd90', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 9, 'created': '2020-01-06 17:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e98dd9c401334701b3a52269de0b83f2775406e0', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 10, 'created': '2020-01-08 13:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c935cd21dfbf738d207f02c277d3504136d67a8d', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 11, 'created': '2020-01-15 10:54:52.000000000', 'files': ['nova/exception.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ab0ea353725577c43deda02f7573687a0ce8dcf4', 'message': 'nova-net: Remove unused exceptions\n\nNot all of these are nova-network related, but all are unused\n\nChange-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",2,697149,ab0ea353725577c43deda02f7573687a0ce8dcf4,107,13,11,15334,,,0,"nova-net: Remove unused exceptions

Not all of these are nova-network related, but all are unused

Change-Id: I6fd027fb51823b8a8a24ed7b864a2191c4e8e8c0
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/697149/6 && git format-patch -1 --stdout FETCH_HEAD,['nova/exception.py'],1,3c0f5bfe86a5076571e9e6097a986309280e3a05,bp/remove-nova-network-ussuri,"class InvalidInventory(Invalid): msg_fmt = _(""Inventory for '%(resource_class)s' on "" ""resource provider '%(resource_provider)s' invalid."") ","class DecryptionFailure(NovaException): msg_fmt = _(""Failed to decrypt text: %(reason)s"") class RevokeCertFailure(NovaException): msg_fmt = _(""Failed to revoke certificate for %(project_id)s"") class ProjectNotFound(NotFound): msg_fmt = _(""Project %(project_id)s could not be found."") class NetworkDhcpReleaseFailed(NovaException): msg_fmt = _(""Failed to release IP %(address)s with MAC %(mac_address)s"") class NetworkNotCreated(Invalid): msg_fmt = _(""%(req)s is required to create a network."") class LabelTooLong(Invalid): msg_fmt = _(""Maximum allowed length for 'label' is 255."") class InvalidIntValue(Invalid): msg_fmt = _(""%(key)s must be an integer."") class InvalidAddress(Invalid): msg_fmt = _(""%(address)s is not a valid IP address."") class AddressOutOfRange(Invalid): msg_fmt = _(""%(address)s is not within %(cidr)s."") class CidrConflict(NovaException): msg_fmt = _('Requested cidr (%(cidr)s) conflicts ' 'with existing cidr (%(other)s)') code = 409 class NetworkHasProject(NetworkInUse): msg_fmt = _('Network must be disassociated from project ' '%(project_id)s before it can be deleted.') class OVSConfigurationFailure(NovaException): msg_fmt = _(""OVS configuration failed with: %(inner_exception)s."") class PortNotFree(Invalid): msg_fmt = _(""No free port available for instance %(instance)s."") class FloatingIpDNSExists(Invalid): msg_fmt = _(""The DNS entry %(name)s already exists in domain %(domain)s."") class InvalidReservationExpiration(Invalid): msg_fmt = _(""Invalid reservation expiration %(expire)s."") class QuotaUsageNotFound(QuotaNotFound): msg_fmt = _(""Quota usage for project %(project_id)s could not be found."") class QuotaUsageRefreshNotAllowed(Invalid): msg_fmt = _(""Quota usage refresh of resource %(resource)s for project "" ""%(project_id)s, user %(user_id)s, is not allowed. "" ""The allowed resources are %(syncable)s."") class ReservationNotFound(QuotaNotFound): msg_fmt = _(""Quota reservation %(uuid)s could not be found."") class RPCPinnedToOldVersion(NovaException): msg_fmt = _(""RPC is pinned to old version"") class CryptoCAFileNotFound(FileNotFound): msg_fmt = _(""The CA file for %(project)s could not be found"") class CryptoCRLFileNotFound(FileNotFound): msg_fmt = _(""The CRL file for %(project)s could not be found"") class InstanceGroupMemberNotFound(NotFound): msg_fmt = _(""Instance group %(group_uuid)s has no member with "" ""id %(instance_id)s."") class CPUPinningNotSupported(Invalid): msg_fmt = _(""CPU pinning is not supported by the host: "" ""%(reason)s"") class InvalidResourceAmount(Invalid): msg_fmt = _(""Resource amounts must be integers. Received '%(amount)s'."") class InvalidInventory(Invalid): msg_fmt = _(""Inventory for '%(resource_class)s' on "" ""resource provider '%(resource_provider)s' invalid."") class GetPMEMNamespaceFailed(NovaException): msg_fmt = _(""Get PMEM namespaces on host failed: %(reason)s."") ",5,112
openstack%2Fnova~master~Ibd97a0be22e0a894f3b1fdea052ee6359753457c,openstack/nova,master,Ibd97a0be22e0a894f3b1fdea052ee6359753457c,nova-net: Remove unnecessary 'neutronv2' prefixes,MERGED,2019-11-30 16:04:16.000000000,2020-01-17 19:19:12.000000000,2020-01-15 20:34:01.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-30 16:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2027f43d642a182769bfc7b951c66ea7739258e', 'message': ""Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2019-11-30 18:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4d545a9f1b980c2be7b3ab80f21f469e4691a36', 'message': ""Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2019-12-03 18:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/579d0c64037259738677cf0add29c4f396dd4d0b', 'message': ""Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 4, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8bf1b192e55b93ef53c56bb145fc5c07a8df5b2', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 5, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7622f166a0b11ed387c9adca28e1da5e51efb4b', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 6, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3261ead1d297a26aceb8b01ffb5438e5d1c44ff', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 7, 'created': '2019-12-16 10:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1ba46d2df5a28f970a34fd9ae74a0d1755cf8ed', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 8, 'created': '2019-12-24 12:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/976c6df6a2489233899429222c71241a0126e6fb', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 9, 'created': '2020-01-06 13:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d23018c4358449529c52cbca59243d226abfbe4', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 10, 'created': '2020-01-06 14:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19c9b61af3b67e90461970e0d798650b549aeb22', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 11, 'created': '2020-01-06 17:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b87476a449dfcdb79874191fe8623dd42758a44d', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 12, 'created': '2020-01-08 13:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/583492daefeb972b9e8e2ef1d0783a1e5c6b1c99', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 13, 'created': '2020-01-15 10:54:52.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_serversV21.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bf7ea80c4d50e61dca349ccf7ca8d72cf5fa071e', 'message': ""nova-net: Remove unnecessary 'neutronv2' prefixes\n\nThere's only one networking solution now. No need to keep these around.\n\nChange-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",2,696776,bf7ea80c4d50e61dca349ccf7ca8d72cf5fa071e,101,12,13,15334,,,0,"nova-net: Remove unnecessary 'neutronv2' prefixes

There's only one networking solution now. No need to keep these around.

Change-Id: Ibd97a0be22e0a894f3b1fdea052ee6359753457c
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/696776/13 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/test_serversV21.py'],1,f2027f43d642a182769bfc7b951c66ea7739258e,bp/remove-nova-network-ussuri," def test_requested_networks_enabled_with_port(self): def test_requested_networks_enabled_with_network(self): def test_requested_networks_enabled_with_network_and_port(self): def test_requested_networks_with_and_duplicate_networks(self): def test_requested_networks_enabled_conflict_on_fixed_ip(self): def test_create_instance_with_port_in_use(self, mock_create): def test_create_multiple_instance_with_port(self, mock_create): def test_create_instance_with_not_found_network(self, mock_create): def test_create_instance_with_port_not_found(self, mock_create): def test_create_instance_with_fixed_ip_already_in_use(self, create_mock): def test_create_instance_with_invalid_fixed_ip(self, create_mock):"," def test_requested_networks_neutronv2_enabled_with_port(self): def test_requested_networks_neutronv2_enabled_with_network(self): def test_requested_networks_neutronv2_enabled_with_network_and_port(self): def test_requested_networks_with_neutronv2_and_duplicate_networks(self): def test_requested_networks_neutronv2_enabled_conflict_on_fixed_ip(self): def test_create_instance_with_neutronv2_port_in_use(self, mock_create): def test_create_multiple_instance_with_neutronv2_port(self, mock_create): def test_create_instance_with_neutronv2_not_found_network( self, mock_create): def test_create_instance_with_neutronv2_port_not_found(self, mock_create): def test_create_instance_with_neutronv2_fixed_ip_already_in_use(self, create_mock): def test_create_instance_with_neutronv2_invalid_fixed_ip(self, create_mock):",11,14
openstack%2Fneutron-tempest-plugin~master~If937a1901316b1906968013a159c0961c34e2563,openstack/neutron-tempest-plugin,master,If937a1901316b1906968013a159c0961c34e2563,DNM: TEST for bug 1860033,ABANDONED,2020-01-16 21:12:24.000000000,2020-01-17 18:51:53.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 21:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/5af2eaf9948fd894879a9159d0090c0a08cf7f41', 'message': 'DNM: TEST for bug 1860033\n\nDepends-on: https://review.opendev.org/702986\nChange-Id: If937a1901316b1906968013a159c0961c34e2563\n'}, {'number': 2, 'created': '2020-01-16 21:24:56.000000000', 'files': ['neutron_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/ff4c6a3c7be9689926e0f5546c03d95d13066739', 'message': 'DNM: TEST for bug 1860033\n\nTest #2\n\nDepends-on: https://review.opendev.org/702986\nChange-Id: If937a1901316b1906968013a159c0961c34e2563\n'}]",0,702987,ff4c6a3c7be9689926e0f5546c03d95d13066739,6,2,2,1131,,,0,"DNM: TEST for bug 1860033

Test #2

Depends-on: https://review.opendev.org/702986
Change-Id: If937a1901316b1906968013a159c0961c34e2563
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/87/702987/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/config.py'],1,5af2eaf9948fd894879a9159d0090c0a08cf7f41,bug/1860033,# TEST,,1,0
openstack%2Fneutron~stable%2Frocky~Ic488802037f41a90768dedb6b27a3da7dd109817,openstack/neutron,stable/rocky,Ic488802037f41a90768dedb6b27a3da7dd109817,Pin neutron-lib in stable/rocky to <2.0.0,ABANDONED,2020-01-16 20:33:18.000000000,2020-01-17 18:48:30.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-16 20:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/31f028b8f7ac05d21f8de595b4e4b80be247aa08', 'message': ""Pin neutron-lib in stable/rocky to <2.0.0\n\nneutron-tempest-plugin is pulling in the latest version\notherwise, which will fail since it doesn't support\npython2.\n\nChange-Id: Ic488802037f41a90768dedb6b27a3da7dd109817\nCloses-bug: #1860033\n""}, {'number': 2, 'created': '2020-01-16 22:17:35.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd93c609fc42a47f4c4873948a0853878869f1a9', 'message': ""Pin neutron-lib in stable/rocky to <2.0.0\n\nneutron-tempest-plugin is pulling in the latest version\notherwise, which will fail since it doesn't support\npython2.\n\nDepends-on: https://review.opendev.org/702986\nChange-Id: Ic488802037f41a90768dedb6b27a3da7dd109817\nCloses-bug: #1860033\n""}]",0,702979,dd93c609fc42a47f4c4873948a0853878869f1a9,12,4,2,1131,,,0,"Pin neutron-lib in stable/rocky to <2.0.0

neutron-tempest-plugin is pulling in the latest version
otherwise, which will fail since it doesn't support
python2.

Depends-on: https://review.opendev.org/702986
Change-Id: Ic488802037f41a90768dedb6b27a3da7dd109817
Closes-bug: #1860033
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/702979/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,31f028b8f7ac05d21f8de595b4e4b80be247aa08,bug/1860033,"neutron-lib>=1.18.0,<2.0.0 # Apache-2.0",neutron-lib>=1.18.0 # Apache-2.0,1,1
openstack%2Fdesignate-dashboard~master~I68ab10b4ac0e09b7d850e7c8f855a7e95c22d141,openstack/designate-dashboard,master,I68ab10b4ac0e09b7d850e7c8f855a7e95c22d141,Drop Django 1.11 support,MERGED,2020-01-01 20:14:19.000000000,2020-01-17 18:30:03.000000000,2020-01-17 18:27:38.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2020-01-01 20:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/84ca78be896207fe9211e2beaf012b3ca5277d8c', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: I68ab10b4ac0e09b7d850e7c8f855a7e95c22d141\n'}, {'number': 2, 'created': '2020-01-01 20:28:03.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/4609ad1b51fa6b240639fe058c2e59618656a542', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: I68ab10b4ac0e09b7d850e7c8f855a7e95c22d141\n'}]",0,700842,4609ad1b51fa6b240639fe058c2e59618656a542,12,4,2,29313,,,0,"Drop Django 1.11 support

Django 1.11 ends its extended support in April 2020 (which is before
Ussuri release), so horizon drops Django 1.11 support in Ussuri.

tox envs for non-primary Django versions are no longer needed in tox.ini
as testing environments for non-primary Django versions are setup in
the zuul jobs now.

horizon>=17.1.0 is required to use Django 2.2. requirements.txt and
lower-constraints.txt are updated accordingly. for more info. please
refer [1].
Depends-On: https://review.opendev.org/#/c/700733/
[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin

Change-Id: I68ab10b4ac0e09b7d850e7c8f855a7e95c22d141
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/42/700842/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt', 'tox.ini']",3,84ca78be896207fe9211e2beaf012b3ca5277d8c,drop-django111-support,"envlist = py37,pep8","envlist = py37,py3-{dj111,dj22},pep8 dj111: pip install django>=1.11,<2 dj22: pip install django>=2.2,<2.3",4,6
openstack%2Fhorizon~master~I6672ab5970178bc5526012f557f0f59a712f0a07,openstack/horizon,master,I6672ab5970178bc5526012f557f0f59a712f0a07,Restore IMAGE_RESERVED_CUSTOM_PROPERTIES behaviour,ABANDONED,2019-08-14 03:10:52.000000000,2020-01-17 18:13:14.000000000,,"[{'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 25089}]","[{'number': 1, 'created': '2019-08-14 03:10:52.000000000', 'files': ['openstack_dashboard/api/rest/glance.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4d41902dae1ff848424a25fdae280cdbd09de49c', 'message': 'Restore IMAGE_RESERVED_CUSTOM_PROPERTIES behaviour\n\nAs a result of commit 3c2ce866 (""Angularize metadata update modals""),\nthe capability to define image custom properties that should not be\ndisplayed in the Image Custom Properties table was lost. The setting\nremained in the sample file and documentation, but it no longer had\nany effect.\n\nThis change restores the original behaviour. Image properties are\nfiltered before they are returned to the client.\n\nChange-Id: I6672ab5970178bc5526012f557f0f59a712f0a07\nPartial-Bug: 1830301\n'}]",0,676313,4d41902dae1ff848424a25fdae280cdbd09de49c,7,3,1,25089,,,0,"Restore IMAGE_RESERVED_CUSTOM_PROPERTIES behaviour

As a result of commit 3c2ce866 (""Angularize metadata update modals""),
the capability to define image custom properties that should not be
displayed in the Image Custom Properties table was lost. The setting
remained in the sample file and documentation, but it no longer had
any effect.

This change restores the original behaviour. Image properties are
filtered before they are returned to the client.

Change-Id: I6672ab5970178bc5526012f557f0f59a712f0a07
Partial-Bug: 1830301
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/676313/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/api/rest/glance.py'],1,4d41902dae1ff848424a25fdae280cdbd09de49c,bug/1830301,"from django.conf import settings reserved_properties = getattr(settings, 'IMAGE_RESERVED_CUSTOM_PROPERTIES', []) properties = api.glance.image_get(request, image_id).properties properties = {k: v for k, v in properties.items() if k not in reserved_properties} return properties"," return api.glance.image_get(request, image_id).properties",8,1
openstack%2Fcharm-specs~master~I70f22d8af3881d17cd8dd87b3540f1d1af96364f,openstack/charm-specs,master,I70f22d8af3881d17cd8dd87b3540f1d1af96364f,Add audit middleware to the charms,MERGED,2019-12-20 16:36:58.000000000,2020-01-17 17:37:39.000000000,2020-01-17 17:36:10.000000000,"[{'_account_id': 9247}, {'_account_id': 11805}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 16:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/8fc5e1b705774a142e653c0074af8c590dc79b9b', 'message': 'Add audit middleware to the charms\n\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}, {'number': 2, 'created': '2020-01-15 15:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/65b0f047489fb334666a086b53dfd6ca12dffbbf', 'message': 'Add audit middleware to the charms\n\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}, {'number': 3, 'created': '2020-01-16 17:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/ae106d2729e67369e4e7bba8f71bd251502c3f0f', 'message': 'Add audit middleware to the charms\n\nRelated-Bug: #1856555\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}, {'number': 4, 'created': '2020-01-16 17:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/a830c864e02a81d053672ba25c44a8f2bb96de53', 'message': 'Add audit middleware to the charms\n\nRelated-Bug: #1856555\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}, {'number': 5, 'created': '2020-01-16 18:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/798f6018361fd020a5135cbca169da6e08628e04', 'message': 'Add audit middleware to the charms\n\nRelated-Bug: #1856555\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}, {'number': 6, 'created': '2020-01-16 22:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/7d5f0d866d4684b2d07a2c03dc9cd606bb986f60', 'message': 'Add audit middleware to the charms\n\nRelated-Bug: #1856555\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}, {'number': 7, 'created': '2020-01-17 10:59:14.000000000', 'files': ['specs/ussuri/backlog/audit-middleware.rst'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/958a432bca211e7384589fd58a916beb790d6a36', 'message': 'Add audit middleware to the charms\n\nRelated-Bug: #1856555\nChange-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f\n'}]",31,700199,958a432bca211e7384589fd58a916beb790d6a36,27,5,7,9247,,,0,"Add audit middleware to the charms

Related-Bug: #1856555
Change-Id: I70f22d8af3881d17cd8dd87b3540f1d1af96364f
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/99/700199/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/audit-middleware.rst'],1,8fc5e1b705774a142e653c0074af8c590dc79b9b,bug/1856555,".. Copyright 2019 Canonical UK Ltd This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: ""None"". For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ========================================================== Enable Audit Middleware that comes with keystonemiddleware ========================================================== This is a requirement from one of the customers to enable audit middleware Problem Description =================== Currently we have to make manual changes to the configuration to enable audit middleware, this will enable us to automate this process across all the OpenStack projects Proposed Change =============== Update existing charms to enable this feature The customer in question is currently running bionic queens, this spec is a basis for that request Alternatives ------------ Do it manually, which is not feasible Implementation ============== #. Understand the changes required for each project, maybe by changing by hand #. If there are common changes, then charmhelpers may be used to make these changes #. Write tests in charmhelpers for these changes #. For each of the projects #. sync the new charmhelpers #. Add the relevant updated templates - ``/etc/<project>/<project>.conf`` - ``/etc/<project>/api-paste.ini`` - ``/etc/<project>/api_audit_map.conf`` #. write the amulet or zaza tests to ensure that the changes are good Assignee(s) ----------- Primary assignee: None Gerrit Topic ------------ Use Gerrit topic ""audit-middleware"" for all patches related to this spec. .. code-block:: bash git-review -t audit-middleware Work Items ---------- Same as Implementation above Repositories ------------ No new git repositories will need to be created. However, multiple git repositories will need to be touched for this implementation to work It will depend on the following repo, which will have the `api_audit_map.conf` file https://github.com/openstack/pycadf/tree/master/etc/pycadf At first glance the following repositories will be affected that are part of the OpenStack projects, this is based on the files that are listed in the above repository * https://github.com/openstack/charm-nova-cloud-controller * https://github.com/openstack/charm-glance * https://github.com/openstack/charm-cinder * https://github.com/openstack/charm-gnocchi * https://github.com/openstack/charm-heat * https://github.com/openstack/charm-ironic * https://github.com/openstack/charm-neutron-api * https://github.com/openstack/charm-panko The following repo may also need to be updated, so ensure that similar information is stored in one central plae, rather than duplicating the contents in the above repositories * https://github.com/juju/charm-helpers Initial work was tried in the following commits * https://github.com/arif-ali/charm-nova-cloud-controller/commit/3743f00384de56efe8b0a4ee2ab2e40de68b5e7f * https://github.com/arif-ali/charm-helpers/commit/258cf87c83cca2faf601dd99285cd226e2e67b48 Documentation ------------- Will this require a documentation change? If so, which documents? Will it impact developer workflow? Will additional communication need to be made? Identify the surface area of doc updates explicitly, ie. charm-guide, deployment-guide, charm README, wiki page links. Security -------- Unknown Testing ------- charmhelpers: tests will be needed to ensure that the extra options that are added will work All the projects, functional amulet/zaza tests will need to be added for the new option, and ensuring the the configuration is changed correctly, and the audit messaging is getting through to the message bus and/or being logged Dependencies ============ Other than the ones specified above, further dependencies are unknown ",,149,0
openstack%2Fopenstack-helm~master~I7e149c96ee4ae090e47f775000dc1e3e55a3efc2,openstack/openstack-helm,master,I7e149c96ee4ae090e47f775000dc1e3e55a3efc2,Imported Translations from Zanata,MERGED,2020-01-16 07:54:11.000000000,2020-01-17 17:29:14.000000000,2020-01-17 17:26:53.000000000,"[{'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 07:54:11.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc-testing.po'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1258061410908f62c247b437fcb12d2e478ac42d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I7e149c96ee4ae090e47f775000dc1e3e55a3efc2\n'}]",0,702811,1258061410908f62c247b437fcb12d2e478ac42d,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I7e149c96ee4ae090e47f775000dc1e3e55a3efc2
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/11/702811/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/locale/en_GB/LC_MESSAGES/doc-testing.po'],1,1258061410908f62c247b437fcb12d2e478ac42d,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata # Andi Chandler <andi@gowling.com>, 2020. #zanata msgid """" msgstr """" ""Project-Id-Version: openstack-helm\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2020-01-13 21:14+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2020-01-15 10:36+0000\n"" ""Last-Translator: Andi Chandler <andi@gowling.com>\n"" ""Language-Team: English (United Kingdom)\n"" ""Language: en_GB\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" msgid """" ""1) Initial Ceph and OpenStack deployment: Install Ceph and OpenStack charts "" ""on 3 nodes (mnode1, mnode2 and mnode3). Capture Ceph cluster status as well "" ""as K8s PODs status."" msgstr """" ""1) Initial Ceph and OpenStack deployment: Install Ceph and OpenStack charts "" ""on 3 nodes (mnode1, mnode2 and mnode3). Capture Ceph cluster status as well "" ""as K8s PODs status."" msgid """" ""1) Node reduction: Shutdown 1 of 3 nodes to simulate node failure. Capture "" ""effect of node failure on Ceph as well as other OpenStack services that are "" ""using Ceph."" msgstr """" ""1) Node reduction: Shutdown 1 of 3 nodes to simulate node failure. Capture "" ""effect of node failure on Ceph as well as other OpenStack services that are "" ""using Ceph."" msgid ""1) Remove out of quorum MON:"" msgstr ""1) Remove out of quorum MON:"" msgid """" ""2) Node expansion: Apply Ceph and OpenStack related labels to another unused "" ""k8 node. Node expansion should provide more resources for k8 to schedule "" ""PODs for Ceph and OpenStack services."" msgstr """" ""2) Node expansion: Apply Ceph and OpenStack related labels to another unused "" ""k8 node. Node expansion should provide more resources for k8 to schedule "" ""PODs for Ceph and OpenStack services."" msgid """" ""2) Node reduction (failure): Shutdown 1 of 3 nodes (mnode3) to test node "" ""failure. This should cause Ceph cluster to go in HEALTH_WARN state as it has "" ""lost 1 MON and 1 OSD. Capture Ceph cluster status as well as K8s PODs status."" msgstr """" ""2) Node reduction (failure): Shutdown 1 of 3 nodes (mnode3) to test node "" ""failure. This should cause Ceph cluster to go in HEALTH_WARN state as it has "" ""lost 1 MON and 1 OSD. Capture Ceph cluster status as well as K8s PODs status."" msgid ""2) Remove down OSD from Ceph cluster:"" msgstr ""2) Remove down OSD from Ceph cluster:"" msgid """" ""3) Fix Ceph Cluster: After node expansion, perform maintenance on Ceph "" ""cluster to ensure quorum is reached and Ceph is HEALTH_OK."" msgstr """" ""3) Fix Ceph Cluster: After node expansion, perform maintenance on Ceph "" ""cluster to ensure quorum is reached and Ceph is HEALTH_OK."" msgid """" ""3) Node expansion: Add Ceph and OpenStack related labels to 4th node "" ""(mnode4) for expansion. Ceph cluster would show new MON and OSD being added "" ""to cluster. However Ceph cluster would continue to show HEALTH_WARN because "" ""1 MON and 1 OSD are still missing."" msgstr """" ""3) Node expansion: Add Ceph and OpenStack related labels to 4th node "" ""(mnode4) for expansion. Ceph cluster would show new MON and OSD being added "" ""to cluster. However Ceph cluster would continue to show HEALTH_WARN because "" ""1 MON and 1 OSD are still missing."" msgid """" ""4) Ceph cluster recovery: Perform Ceph maintenance to make Ceph cluster "" ""HEALTH_OK. Remove lost MON and OSD from Ceph cluster."" msgstr """" ""4) Ceph cluster recovery: Perform Ceph maintenance to make Ceph cluster "" ""HEALTH_OK. Remove lost MON and OSD from Ceph cluster."" msgid """" ""4. Replace the failed disk with a new one. If you repair (not replace) the "" ""failed disk, you may need to run the following:"" msgstr """" ""4. Replace the failed disk with a new one. If you repair (not replace) the "" ""failed disk, you may need to run the following:"" msgid ""6 Nodes (VM based) env"" msgstr ""6 Nodes (VM based) env"" msgid """" ""Above output shows Ceph cluster in HEALTH_OK with all OSDs and MONs up and "" ""running."" msgstr """" ""Above output shows Ceph cluster in HEALTH_OK with all OSDs and MONs up and "" ""running."" msgid ""Above output shows that ``osd.1`` is down."" msgstr ""Above output shows that ``osd.1`` is down."" msgid ""Adding Tests"" msgstr ""Adding Tests"" msgid """" ""Additional information on Helm tests for OpenStack-Helm and how to execute "" ""these tests locally via the scripts used in the gate can be found in the "" ""gates_ directory."" msgstr """" ""Additional information on Helm tests for OpenStack-Helm and how to execute "" ""these tests locally via the scripts used in the gate can be found in the "" ""gates_ directory."" msgid """" ""After 10+ miniutes, Ceph starts rebalancing with one node lost (i.e., 6 osds "" ""down) and the status stablizes with 18 osds."" msgstr """" ""After 10+ miniutes, Ceph starts rebalancing with one node lost (i.e., 6 osds "" ""down) and the status stablises with 18 osds."" msgid ""After applying labels, let's check status"" msgstr ""After applying labels, let's check status"" msgid ""After reboot (node voyager3), the node status changes to ``NotReady``."" msgstr ""After reboot (node voyager3), the node status changes to ``NotReady``."" msgid ""All PODs are in running state."" msgstr ""All PODs are in running state."" msgid """" ""All tests should be added to the gates during development, and are required "" ""for any new service charts prior to merging. All Helm tests should be "" ""included as part of the deployment script. An example of this can be seen "" ""in this script_."" msgstr """" ""All tests should be added to the gates during development, and are required "" ""for any new service charts prior to merging. All Helm tests should be "" ""included as part of the deployment script. An example of this can be seen "" ""in this script_."" msgid ""Any Helm tests associated with a chart can be run by executing:"" msgstr ""Any Helm tests associated with a chart can be run by executing:"" msgid """" ""Any templates for Helm tests submitted should follow the philosophies "" ""applied in the other templates. These include: use of overrides where "" ""appropriate, use of endpoint lookups and other common functionality in helm-"" ""toolkit, and mounting any required scripting templates via the configmap-bin "" ""template for the service chart. If Rally tests are not appropriate or "" ""adequate for a service chart, any additional tests should be documented "" ""appropriately and adhere to the same expectations."" msgstr """" ""Any templates for Helm tests submitted should follow the philosophies "" ""applied in the other templates. These include: use of overrides where "" ""appropriate, use of endpoint lookups and other common functionality in helm-"" ""toolkit, and mounting any required scripting templates via the configmap-bin "" ""template for the service chart. If Rally tests are not appropriate or "" ""adequate for a service chart, any additional tests should be documented "" ""appropriately and adhere to the same expectations."" msgid """" ""As shown above, Ceph status is now HEALTH_OK and shows 3 MONs available."" msgstr """" ""As shown above, Ceph status is now HEALTH_OK and shows 3 MONs available."" msgid """" ""As shown in Ceph status above, ``osd: 4 osds: 3 up, 3 in`` 1 of 4 OSDs is "" ""still down. Let's remove that OSD."" msgstr """" ""As shown in Ceph status above, ``osd: 4 osds: 3 up, 3 in`` 1 of 4 OSDs is "" ""still down. Let's remove that OSD."" msgid ""Capture Ceph pods statuses."" msgstr ""Capture Ceph pods statuses."" msgid ""Capture Openstack pods statuses."" msgstr ""Capture Openstack pods statuses."" msgid ""Capture final Ceph pod statuses:"" msgstr ""Capture final Ceph pod statuses:"" msgid ""Capture final Openstack pod statuses:"" msgstr ""Capture final Openstack pod statuses:"" msgid ""Case: A disk fails"" msgstr ""Case: A disk fails"" msgid ""Case: One host machine where ceph-mon is running is rebooted"" msgstr ""Case: One host machine where ceph-mon is running is rebooted"" msgid ""Caveats:"" msgstr ""Caveats:"" msgid ""Ceph - Node Reduction, Expansion and Ceph Recovery"" msgstr ""Ceph - Node Reduction, Expansion and Ceph Recovery"" msgid ""Ceph Cephfs provisioner docker images."" msgstr ""Ceph Cephfs provisioner docker images."" msgid ""Ceph Luminous point release images for Ceph components"" msgstr ""Ceph Luminous point release images for Ceph components"" msgid ""Ceph MON and OSD PODs got scheduled on mnode4 node."" msgstr ""Ceph MON and OSD PODs got scheduled on mnode4 node."" msgid ""Ceph RBD provisioner docker images."" msgstr ""Ceph RBD provisioner docker images."" msgid """" ""Ceph can be upgraded without downtime for Openstack components in a "" ""multinode env."" msgstr """" ""Ceph can be upgraded without downtime for Openstack components in a "" ""multinode env."" msgid ""Ceph cluster is in HEALTH_OK state with 3 MONs and 3 OSDs."" msgstr ""Ceph cluster is in HEALTH_OK state with 3 MONs and 3 OSDs."" msgid ""Ceph status shows 1 Ceph MON and 1 Ceph OSD missing."" msgstr ""Ceph status shows 1 Ceph MON and 1 Ceph OSD missing."" msgid ""Ceph status shows HEALTH_WARN as expected"" msgstr ""Ceph status shows HEALTH_WARN as expected"" msgid ""Ceph status shows that MON and OSD count has been increased."" msgstr ""Ceph status shows that MON and OSD count has been increased."" msgid """" ""Ceph status shows that ceph-mon running on ``voyager3`` becomes out of "" ""quorum. Also, six osds running on ``voyager3`` are down; i.e., 18 osds are "" ""up out of 24 osds."" msgstr """" ""Ceph status shows that ceph-mon running on ``voyager3`` becomes out of "" ""quorum. Also, six osds running on ``voyager3`` are down; i.e., 18 osds are "" ""up out of 24 osds."" msgid ""Ceph status still shows HEALTH_WARN as one MON and OSD are still down."" msgstr ""Ceph status still shows HEALTH_WARN as one MON and OSD are still down."" msgid ""Ceph version: 12.2.3"" msgstr ""Ceph version: 12.2.3"" msgid ""Check Ceph Pods"" msgstr ""Check Ceph Pods"" msgid ""Check version of each Ceph components."" msgstr ""Check version of each Ceph components."" msgid ""Check which images Provisionors and Mon-Check PODs are using"" msgstr ""Check which images Provisionors and Mon-Check PODs are using"" msgid ""Cluster size: 4 host machines"" msgstr ""Cluster size: 4 host machines"" msgid ""Conclusion:"" msgstr ""Conclusion:"" msgid ""Confirm Ceph component's version."" msgstr ""Confirm Ceph component's version."" msgid ""Continue with OSH multinode guide to install other Openstack charts."" msgstr ""Continue with OSH multinode guide to install other Openstack charts."" msgid ""Deploy and Validate Ceph"" msgstr ""Deploy and Validate Ceph"" msgid ""Disk Failure"" msgstr ""Disk Failure"" msgid ""Docker Images:"" msgstr ""Docker Images:"" msgid """" ""Every OpenStack-Helm chart should include any required Helm tests necessary "" ""to provide a sanity check for the OpenStack service. Information on using "" ""the Helm testing framework can be found in the Helm repository_. Currently, "" ""the Rally testing framework is used to provide these checks for the core "" ""services. The Keystone Helm test template can be used as a reference, and "" ""can be found here_."" msgstr """" ""Every OpenStack-Helm chart should include any required Helm tests necessary "" ""to provide a sanity check for the OpenStack service. Information on using "" ""the Helm testing framework can be found in the Helm repository_. Currently, "" ""the Rally testing framework is used to provide these checks for the core "" ""services. The Keystone Helm test template can be used as a reference, and "" ""can be found here_."" msgid ""Find that Ceph is healthy with a lost OSD (i.e., a total of 23 OSDs):"" msgstr ""Find that Ceph is healthy with a lost OSD (i.e., a total of 23 OSDs):"" msgid ""First, run ``ceph osd tree`` command to get list of OSDs."" msgstr ""First, run ``ceph osd tree`` command to get list of OSDs."" msgid ""Follow all steps from OSH multinode guide with below changes."" msgstr ""Follow all steps from OSH multinode guide with below changes."" msgid """" ""Followed OSH multinode guide steps to install Ceph and OpenStack charts up "" ""to Cinder."" msgstr """" ""Followed OSH multinode guide steps to install Ceph and OpenStack charts up "" ""to Cinder."" msgid """" ""Followed OSH multinode guide steps to setup nodes and install K8s cluster"" msgstr """" ""Followed OSH multinode guide steps to setup nodes and install K8s cluster"" msgid ""Following is a partial part from script to show changes."" msgstr ""Following is a partial part from script to show changes."" msgid """" ""From the Kubernetes cluster, remove the failed OSD pod, which is running on "" ""``voyager4``:"" msgstr """" ""From the Kubernetes cluster, remove the failed OSD pod, which is running on "" ""``voyager4``:"" msgid ""Hardware Failure"" msgstr ""Hardware Failure"" msgid ""Helm Tests"" msgstr ""Helm Tests"" msgid ""Host Failure"" msgstr ""Host Failure"" msgid """" ""In this test env, MariaDB chart is deployed with only 1 replica. In order to "" ""test properly, the node with MariaDB server POD (mnode2) should not be "" ""shutdown."" msgstr """" ""In this test env, MariaDB chart is deployed with only 1 replica. In order to "" ""test properly, the node with MariaDB server POD (mnode2) should not be "" ""shutdown."" msgid ""In this test env, ``mnode3`` is out of quorum."" msgstr ""In this test env, ``mnode3`` is out of quorum."" msgid """" ""In this test env, each node has Ceph and OpenStack related PODs. Due to "" ""this, shutting down a Node will cause issue with Ceph as well as OpenStack "" ""services. These PODs level failures are captured following subsequent "" ""screenshots."" msgstr """" ""In this test env, each node has Ceph and OpenStack related PODs. Due to "" ""this, shutting down a Node will cause issue with Ceph as well as OpenStack "" ""services. These PODs level failures are captured following subsequent "" ""screenshots."" msgid ""In this test env, let's shutdown ``mnode3`` node."" msgstr ""In this test env, let's shutdown ``mnode3`` node."" msgid """" ""In this test env, let's use ``mnode4`` and apply Ceph and OpenStack related "" ""labels."" msgstr """" ""In this test env, let's use ``mnode4`` and apply Ceph and OpenStack related "" ""labels."" msgid """" ""In this test env, since out of quorum MON is no longer available due to node "" ""failure, we can processed with removing it from Ceph cluster."" msgstr """" ""In this test env, since out of quorum MON is no longer available due to node "" ""failure, we can processed with removing it from Ceph cluster."" msgid ""Install Ceph charts (version 12.2.4)"" msgstr ""Install Ceph charts (version 12.2.4)"" msgid ""Install OSH components as per OSH multinode guide."" msgstr ""Install OSH components as per OSH multinode guide."" msgid ""Install Openstack charts"" msgstr ""Install Openstack charts"" msgid ""Kubernetes version: 1.10.5"" msgstr ""Kubernetes version: 1.10.5"" msgid ""Let's add more resources for K8s to schedule PODs on."" msgstr ""Let's add more resources for K8s to schedule PODs on."" msgid """" ""Make sure only 3 nodes (mnode1, mnode2, mnode3) have Ceph and OpenStack "" ""related labels. K8s would only schedule PODs on these 3 nodes."" msgstr """" ""Make sure only 3 nodes (mnode1, mnode2, mnode3) have Ceph and OpenStack "" ""related labels. K8s would only schedule PODs on these 3 nodes."" msgid ""Mission"" msgstr ""Mission"" msgid """" ""Note: To find the daemonset associated with a failed OSD, check out the "" ""followings:"" msgstr """" ""Note: To find the daemonset associated with a failed OSD, check out the "" ""followings:"" msgid """" ""Now that we have added new node for Ceph and OpenStack PODs, let's perform "" ""maintenance on Ceph cluster."" msgstr """" ""Now that we have added new node for Ceph and OpenStack PODs, let's perform "" ""maintenance on Ceph cluster."" msgid ""Number of disks: 24 (= 6 disks per host * 4 hosts)"" msgstr ""Number of disks: 24 (= 6 disks per host * 4 hosts)"" msgid ""OSD count is set to 3 based on env setup."" msgstr ""OSD count is set to 3 based on env setup."" msgid """" ""Only 3 nodes will have Ceph and OpenStack related labels. Each of these 3 "" ""nodes will have one MON and one OSD running on them."" msgstr """" ""Only 3 nodes will have Ceph and OpenStack related labels. Each of these 3 "" ""nodes will have one MON and one OSD running on them."" msgid ""OpenStack PODs that were scheduled mnode3 also shows NodeLost/Unknown."" msgstr ""OpenStack PODs that were scheduled mnode3 also shows NodeLost/Unknown."" msgid ""OpenStack-Helm commit: 25e50a34c66d5db7604746f4d2e12acbdd6c1459"" msgstr ""OpenStack-Helm commit: 25e50a34c66d5db7604746f4d2e12acbdd6c1459"" msgid """" ""Our focus lies on resiliency for various failure scenarios but not on "" ""performance or stress testing."" msgstr """" ""Our focus lies on resiliency for various failure scenarios but not on "" ""performance or stress testing."" msgid ""PODs that were scheduled on mnode3 node has status of NodeLost/Unknown."" msgstr """" ""PODs that were scheduled on mnode3 node has status of NodeLost/Unknown."" msgid ""Recovery:"" msgstr ""Recovery:"" msgid """" ""Remove the failed OSD (OSD ID = 2 in this example) from the Ceph cluster:"" msgstr """" ""Remove the failed OSD (OSD ID = 2 in this example) from the Ceph cluster:"" msgid ""Resiliency Tests for OpenStack-Helm/Ceph"" msgstr ""Resiliency Tests for OpenStack-Helm/Ceph"" msgid ""Run ``ceph osd purge`` command to remove OSD from ceph cluster."" msgstr ""Run ``ceph osd purge`` command to remove OSD from Ceph cluster."" msgid ""Running Tests"" msgstr ""Running Tests"" msgid ""Setup:"" msgstr ""Setup:"" msgid """" ""Showing partial output from kubectl describe command to show which image is "" ""Docker container is using"" msgstr """" ""Showing partial output from kubectl describe command to show which image is "" ""Docker container is using"" msgid """" ""Shutdown 1 of 3 nodes (mnode1, mnode2, mnode3) to simulate node failure/lost."" msgstr """" ""Shutdown 1 of 3 nodes (mnode1, mnode2, mnode3) to simulate node failure/lost."" msgid """" ""Since the node that was shutdown earlier had both Ceph and OpenStack PODs, "" ""mnode4 should get Ceph and OpenStack related labels as well."" msgstr """" ""Since the node that was shutdown earlier had both Ceph and OpenStack PODs, "" ""mnode4 should get Ceph and OpenStack related labels as well."" msgid ""Software Failure"" msgstr ""Software Failure"" msgid ""Solution:"" msgstr ""Solution:"" msgid ""Start a new OSD pod on ``voyager4``:"" msgstr ""Start a new OSD pod on ``voyager4``:"" msgid ""Step 1: Initial Ceph and OpenStack deployment"" msgstr ""Step 1: Initial Ceph and OpenStack deployment"" msgid ""Step 2: Node reduction (failure):"" msgstr ""Step 2: Node reduction (failure):"" msgid ""Step 3: Node Expansion"" msgstr ""Step 3: Node Expansion"" msgid ""Step 4: Ceph cluster recovery"" msgstr ""Step 4: Ceph cluster recovery"" msgid ""Steps:"" msgstr ""Steps:"" msgid ""Symptom:"" msgstr ""Symptom:"" msgid ""Test Environment"" msgstr ""Test Environment"" msgid ""Test Scenarios:"" msgstr ""Test Scenarios:"" msgid ""Testing"" msgstr ""Testing"" msgid ""Testing Expectations"" msgstr ""Testing Expectations"" msgid """" ""The goal of our resiliency tests for `OpenStack-Helm/Ceph <https://github."" ""com/openstack/openstack-helm/tree/master/ceph>`_ is to show symptoms of "" ""software/hardware failure and provide the solutions."" msgstr """" ""The goal of our resiliency tests for `OpenStack-Helm/Ceph <https://github."" ""com/openstack/openstack-helm/tree/master/ceph>`_ is to show symptoms of "" ""software/hardware failure and provide the solutions."" msgid """" ""The node status of ``voyager3`` changes to ``Ready`` after the node is up "" ""again. Also, Ceph pods are restarted automatically. The Ceph status shows "" ""that the monitor running on ``voyager3`` is now in quorum and 6 osds gets "" ""back up (i.e., a total of 24 osds are up)."" msgstr """" ""The node status of ``voyager3`` changes to ``Ready`` after the node is up "" ""again. Also, Ceph pods are restarted automatically. The Ceph status shows "" ""that the monitor running on ``voyager3`` is now in quorum and 6 osds gets "" ""back up (i.e., a total of 24 osds are up)."" msgid """" ""The output of the Helm tests can be seen by looking at the logs of the pod "" ""created by the Helm tests. These logs can be viewed with:"" msgstr """" ""The output of the Helm tests can be seen by looking at the logs of the pod "" ""created by the Helm tests. These logs can be viewed with:"" msgid ""The pod status of ceph-mon and ceph-osd shows as ``NodeLost``."" msgstr ""The pod status of ceph-mon and ceph-osd shows as ``NodeLost``."" msgid """" ""This document captures steps and result from node reduction and expansion as "" ""well as ceph recovery."" msgstr """" ""This document captures steps and result from node reduction and expansion as "" ""well as Ceph recovery."" msgid """" ""This is to test a scenario when a disk failure happens. We monitor the ceph "" ""status and notice one OSD (osd.2) on voyager4 which has ``/dev/sdh`` as a "" ""backend is down."" msgstr """" ""This is to test a scenario when a disk failure happens. We monitor the ceph "" ""status and notice one OSD (osd.2) on voyager4 which has ``/dev/sdh`` as a "" ""backend is down."" msgid ""To replace the failed OSD, execute the following procedure:"" msgstr ""To replace the failed OSD, execute the following procedure:"" msgid ""Update Ceph Client chart with new overrides:"" msgstr ""Update Ceph Client chart with new overrides:"" msgid ""Update Ceph Mon chart with new overrides"" msgstr ""Update Ceph Mon chart with new overrides"" msgid ""Update Ceph OSD chart with new overrides:"" msgstr ""Update Ceph OSD chart with new overrides:"" msgid ""Update Ceph Provisioners chart with new overrides:"" msgstr ""Update Ceph Provisioners chart with new overrides:"" msgid """" ""Update ceph install script ``./tools/deployment/multinode/030-ceph.sh`` to "" ""add ``images:`` section in overrides as shown below."" msgstr """" ""Update Ceph install script ``./tools/deployment/multinode/030-ceph.sh`` to "" ""add ``images:`` section in overrides as shown below."" msgid """" ""Update, image section in new overrides ``ceph-update.yaml`` as shown below"" msgstr """" ""Update, image section in new overrides ``ceph-update.yaml`` as shown below"" msgid ""Upgrade Ceph charts to update version"" msgstr ""Upgrade Ceph charts to update version"" msgid """" ""Upgrade Ceph charts to version 12.2.5 by updating docker images in overrides."" msgstr """" ""Upgrade Ceph charts to version 12.2.5 by updating Docker images in overrides."" msgid """" ""Use Ceph override file ``ceph.yaml`` that was generated previously and "" ""update images section as below"" msgstr """" ""Use Ceph override file ``ceph.yaml`` that was generated previously and "" ""update images section as below"" msgid """" ""Using ``ceph mon_status`` and ``ceph -s`` commands, confirm ID of MON that "" ""is out of quorum."" msgstr """" ""Using ``ceph mon_status`` and ``ceph -s`` commands, confirm ID of MON that "" ""is out of quorum."" msgid """" ""Validate the Ceph status (i.e., one OSD is added, so the total number of "" ""OSDs becomes 24):"" msgstr """" ""Validate the Ceph status (i.e., one OSD is added, so the total number of "" ""OSDs becomes 24):"" msgid ""`Disk failure <./disk-failure.html>`_"" msgstr ""`Disk failure <./disk-failure.html>`_"" msgid ""`Host failure <./host-failure.html>`_"" msgstr ""`Host failure <./host-failure.html>`_"" msgid ""`Monitor failure <./monitor-failure.html>`_"" msgstr ""`Monitor failure <./monitor-failure.html>`_"" msgid ""`OSD failure <./osd-failure.html>`_"" msgstr ""`OSD failure <./osd-failure.html>`_"" msgid ""``Ceph MON Status:``"" msgstr ""``Ceph MON Status:``"" msgid ""``Ceph MON Status``"" msgstr ""``Ceph MON Status``"" msgid ""``Ceph PODs:``"" msgstr ""``Ceph PODs:``"" msgid ""``Ceph PODs``"" msgstr ""``Ceph PODs``"" msgid ""``Ceph Status:``"" msgstr ""``Ceph Status:``"" msgid ""``Ceph quorum status:``"" msgstr ""``Ceph quorum status:``"" msgid ""``Ceph quorum status``"" msgstr ""``Ceph quorum status``"" msgid ""``Ceph status:``"" msgstr ""``Ceph status:``"" msgid ""``Ceph status``"" msgstr ""``Ceph status``"" msgid ""``Check node status:``"" msgstr ""``Check node status:``"" msgid ""``Following are PODs scheduled on mnode3 before shutdown:``"" msgstr ""``Following are PODs scheduled on mnode3 before shutdown:``"" msgid ""``OpenStack PODs:``"" msgstr ""``OpenStack PODs:``"" msgid ""``OpenStack PODs``"" msgstr ""``OpenStack PODs``"" msgid ""``Remove MON from Ceph cluster``"" msgstr ""``Remove MON from Ceph cluster``"" msgid ""``Result/Observation:``"" msgstr ""``Result/Observation:``"" msgid """" ""``Results:`` All provisioner pods got terminated at once (same time). Other "" ""ceph pods are running. No interruption to OSH pods."" msgstr """" ""``Results:`` All provisioner pods got terminated at once (same time). Other "" ""Ceph pods are running. No interruption to OSH pods."" msgid """" ""``Results:`` Mon pods got updated one by one (rolling updates). Each Mon pod "" ""got respawn and was in 1/1 running state before next Mon pod got updated. "" ""Each Mon pod got restarted. Other ceph pods were not affected with this "" ""update. No interruption to OSH pods."" msgstr """" ""``Results:`` Mon pods got updated one by one (rolling updates). Each Mon pod "" ""got respawn and was in 1/1 running state before next Mon pod got updated. "" ""Each Mon pod got restarted. Other ceph pods were not affected with this "" ""update. No interruption to OSH pods."" msgid """" ""``Results:`` Rolling updates (one pod at a time). Other ceph pods are "" ""running. No interruption to OSH pods."" msgstr """" ""``Results:`` Rolling updates (one pod at a time). Other ceph pods are "" ""running. No interruption to OSH pods."" msgid """" ""``ceph_bootstrap``, ``ceph-config_helper`` and ``ceph_rbs_pool`` images are "" ""used for jobs. ``ceph_mon_check`` has one script that is stable so no need "" ""to upgrade."" msgstr """" ""``ceph_bootstrap``, ``ceph-config_helper`` and ``ceph_rbs_pool`` images are "" ""used for jobs. ``ceph_mon_check`` has one script that is stable so no need "" ""to upgrade."" msgid ""``cp /tmp/ceph.yaml ceph-update.yaml``"" msgstr ""``cp /tmp/ceph.yaml ceph-update.yaml``"" msgid ""``helm upgrade ceph-client ./ceph-client --values=ceph-update.yaml``"" msgstr ""``helm upgrade ceph-client ./ceph-client --values=ceph-update.yaml``"" msgid ""``helm upgrade ceph-mon ./ceph-mon --values=ceph-update.yaml``"" msgstr ""``helm upgrade ceph-mon ./ceph-mon --values=ceph-update.yaml``"" msgid ""``helm upgrade ceph-osd ./ceph-osd --values=ceph-update.yaml``"" msgstr ""``helm upgrade ceph-osd ./ceph-osd --values=ceph-update.yaml``"" msgid """" ""``helm upgrade ceph-provisioners ./ceph-provisioners --values=ceph-update."" ""yaml``"" msgstr """" ""``helm upgrade ceph-provisioners ./ceph-provisioners --values=ceph-update."" ""yaml``"" msgid ""``series of console outputs:``"" msgstr ""``series of console outputs:``"" ",,731,0
openstack%2Ftempest~master~Ibd60a7b2dfde4e70dcbcb03e640b7a9eb6fbae68,openstack/tempest,master,Ibd60a7b2dfde4e70dcbcb03e640b7a9eb6fbae68,"Revert ""Add response schema validation for volume quota_set""",ABANDONED,2019-09-12 15:10:30.000000000,2020-01-17 17:09:31.000000000,,"[{'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 17887}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-09-12 15:10:30.000000000', 'files': ['tempest/tests/lib/services/volume/v3/test_quotas_client.py', 'tempest/api/volume/admin/test_volume_quotas.py', 'tempest/lib/api_schema/response/volume/quotas.py', 'tempest/lib/services/volume/v3/quotas_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/624588abb5d10a9e59095ce78ce68afd3a2a092d', 'message': 'Revert ""Add response schema validation for volume quota_set""\n\nThis reverts commit 6cd8b61c641bf2ac6621898183860a0c2222f432.\n\nThis breaks tempest runs for cinder stable/ocata.\nCloses-Bug: #1843762\n\nChange-Id: Ibd60a7b2dfde4e70dcbcb03e640b7a9eb6fbae68\n'}]",0,681776,624588abb5d10a9e59095ce78ce68afd3a2a092d,8,11,1,4523,,,0,"Revert ""Add response schema validation for volume quota_set""

This reverts commit 6cd8b61c641bf2ac6621898183860a0c2222f432.

This breaks tempest runs for cinder stable/ocata.
Closes-Bug: #1843762

Change-Id: Ibd60a7b2dfde4e70dcbcb03e640b7a9eb6fbae68
",git fetch https://review.opendev.org/openstack/tempest refs/changes/76/681776/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/lib/services/volume/v3/test_quotas_client.py', 'tempest/api/volume/admin/test_volume_quotas.py', 'tempest/lib/api_schema/response/volume/quotas.py', 'tempest/lib/services/volume/v3/quotas_client.py']",4,624588abb5d10a9e59095ce78ce68afd3a2a092d,bp/volume-response-schema-validation," self.expected_success(200, resp.status) self.expected_success(200, resp.status) self.expected_success(200, resp.status) self.expected_success(200, resp.status)","from tempest.lib.api_schema.response.volume import quotas as schema self.validate_response(schema.show_quota_set, resp, body) if params and params.get('usage', False): self.validate_response(schema.show_quota_set_usage, resp, body) else: self.validate_response(schema.show_quota_set, resp, body) self.validate_response(schema.update_quota_set, resp, body) self.validate_response(schema.delete_quota_set, resp, body)",24,122
openstack%2Floci~master~Ifc81fd0a6b53d84133dd2c8eb6bb915f7357fb3d,openstack/loci,master,Ifc81fd0a6b53d84133dd2c8eb6bb915f7357fb3d,check negative scenario for sort check,ABANDONED,2019-11-12 17:31:52.000000000,2020-01-17 16:54:09.000000000,,"[{'_account_id': 22348}, {'_account_id': 29911}]","[{'number': 1, 'created': '2019-11-12 17:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/51161ec4a1231340ce638f9912d7e9ed35cfe1f0', 'message': 'check negative scenario for sort check\n\nChange-Id: Ifc81fd0a6b53d84133dd2c8eb6bb915f7357fb3d\n'}, {'number': 2, 'created': '2019-11-12 17:32:11.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/loci/commit/18700892358444ba5b0b3281a003de5aa925289e', 'message': 'check negative scenario for sort check\n\nChange-Id: Ifc81fd0a6b53d84133dd2c8eb6bb915f7357fb3d\n'}]",0,693891,18700892358444ba5b0b3281a003de5aa925289e,4,2,2,8863,,,0,"check negative scenario for sort check

Change-Id: Ifc81fd0a6b53d84133dd2c8eb6bb915f7357fb3d
",git fetch https://review.opendev.org/openstack/loci refs/changes/91/693891/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,51161ec4a1231340ce638f9912d7e9ed35cfe1f0,,,,0,0
openstack%2Fmonasca-tempest-plugin~master~I4e679ca48a971bf39231688b57d03fc0ccd48183,openstack/monasca-tempest-plugin,master,I4e679ca48a971bf39231688b57d03fc0ccd48183,Update Zuul job name for tempest tests,MERGED,2020-01-08 11:37:06.000000000,2020-01-17 16:28:11.000000000,2020-01-17 16:23:48.000000000,"[{'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 30221}]","[{'number': 1, 'created': '2020-01-08 11:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/135c79dec8c94152bdc34c34b611ad6efd9dec85', 'message': 'Update Zuul job name for tempest tests\n\nWe should run the job testing the new merged API.\n\nChange-Id: I4e679ca48a971bf39231688b57d03fc0ccd48183\nStory: 2003881\nTask: 37984\n'}, {'number': 2, 'created': '2020-01-09 11:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/3996c8a1383acf9f79bcdc910958c72b530bf513', 'message': 'Update Zuul job name for tempest tests\n\nWe should run the job testing the new merged API.\n\nAdditionally, set the job as non-voting to allow merging cross-dependant\nchanges in API and tempest test related to ELK upgrade.\n\nChange-Id: I4e679ca48a971bf39231688b57d03fc0ccd48183\nStory: 2003881\nTask: 37984\n'}, {'number': 3, 'created': '2020-01-13 09:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/0c35c1e7f55b4ed25018a35f93c34fd4b52585df', 'message': 'Update Zuul job name for tempest tests\n\nWe should run the job testing the new merged API.\n\nAdditionally, temporarily set the job as non-voting to allow merging\ncross-dependant changes in API and tempest test related to ELK upgrade.\n\nChange-Id: I4e679ca48a971bf39231688b57d03fc0ccd48183\nStory: 2003881\nTask: 37984\n'}, {'number': 4, 'created': '2020-01-14 08:22:32.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/dc7c893d332c9f7c44cf402e29142b592dd6588b', 'message': 'Update Zuul job name for tempest tests\n\nWe should run the job testing the new merged API.\n\nThe change also removes Pyhon 2 tempest tests which are not supported\nanymore.\n\nAdditionally, temporarily set the job as non-voting to allow merging\ncross-dependant changes in API and tempest test related to ELK upgrade.\n\nChange-Id: I4e679ca48a971bf39231688b57d03fc0ccd48183\nStory: 2003881\nTask: 37984\n'}]",0,701536,dc7c893d332c9f7c44cf402e29142b592dd6588b,18,5,4,16222,,,0,"Update Zuul job name for tempest tests

We should run the job testing the new merged API.

The change also removes Pyhon 2 tempest tests which are not supported
anymore.

Additionally, temporarily set the job as non-voting to allow merging
cross-dependant changes in API and tempest test related to ELK upgrade.

Change-Id: I4e679ca48a971bf39231688b57d03fc0ccd48183
Story: 2003881
Task: 37984
",git fetch https://review.opendev.org/openstack/monasca-tempest-plugin refs/changes/36/701536/4 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,135c79dec8c94152bdc34c34b611ad6efd9dec85,, - monasca-tempest-log-python3-influxdb - monasca-tempest-log-python3-influxdb, - monascalog-python2-tempest - monascalog-python3-tempest - monascalog-python2-tempest - monascalog-python3-tempest,2,4
openstack%2Fopenstack-ansible-ceph_client~master~I07db988f607b8f4ab041437edff2903a8e07e381,openstack/openstack-ansible-ceph_client,master,I07db988f607b8f4ab041437edff2903a8e07e381,Use print function,MERGED,2020-01-15 12:44:44.000000000,2020-01-17 16:22:34.000000000,2020-01-17 16:04:28.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-15 12:44:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/59666d0c2770fa0b028d60bbe28966208f4b8c4c', 'message': 'Use print function\n\nIn py3 usage of print as a fucntion instead of a stetement is a\nhard requirement. This patch fixes symlink of python ceph libraries.\n\nChange-Id: I07db988f607b8f4ab041437edff2903a8e07e381\n'}, {'number': 2, 'created': '2020-01-15 16:45:57.000000000', 'files': ['tasks/ceph_install_python_libs.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/b9610ff808381319644cbcd84229b239f54435b8', 'message': 'Use print function\n\nIn py3 usage of print as a fucntion instead of a stetement is a\nhard requirement. This patch fixes symlink of python ceph libraries.\n\nChange-Id: I07db988f607b8f4ab041437edff2903a8e07e381\n'}]",0,702659,b9610ff808381319644cbcd84229b239f54435b8,22,4,2,28619,,,0,"Use print function

In py3 usage of print as a fucntion instead of a stetement is a
hard requirement. This patch fixes symlink of python ceph libraries.

Change-Id: I07db988f607b8f4ab041437edff2903a8e07e381
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/59/702659/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/ceph_install_python_libs.yml'],1,59666d0c2770fa0b028d60bbe28966208f4b8c4c,," command: ""{{ ceph_python_interp }} -c 'import cephfs; print(cephfs.__file__)"" command: ""{{ ceph_python_interp }} -c 'import ceph_volume_client; print(ceph_volume_client.__file__)'"" command: ""{{ ceph_python_interp }} -c 'import ceph_argparse; print(ceph_argparse.__file__)'"""," command: ""{{ ceph_python_interp }} -c 'import cephfs; print cephfs.__file__'"" command: ""{{ ceph_python_interp }} -c 'import ceph_volume_client; print ceph_volume_client.__file__'"" command: ""{{ ceph_python_interp }} -c 'import ceph_argparse; print ceph_argparse.__file__'""",3,3
openstack%2Fansible-collections-openstack~master~Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520,openstack/ansible-collections-openstack,master,Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520,Migrate openstack modules as a collection,MERGED,2020-01-16 11:49:57.000000000,2020-01-17 15:57:05.000000000,2020-01-17 15:57:05.000000000,"[{'_account_id': 2}, {'_account_id': 1004}, {'_account_id': 3153}, {'_account_id': 4162}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 10239}, {'_account_id': 10969}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 25877}, {'_account_id': 27900}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-16 11:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/7eb39ea36c3bde8b2d56205e5eda6506503faec0', 'message': 'Migrate openstack modules as a collection\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 2, 'created': '2020-01-16 12:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/983de0c0836c88414571dbf202c73ca2b54cd21d', 'message': 'Migrate openstack modules as a collection\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 3, 'created': '2020-01-16 12:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f9473cc2385446f5e98343235517da6ab021dd27', 'message': 'Migrate openstack modules as a collection\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 4, 'created': '2020-01-16 14:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cc392a90de631e5159759003d9cf21a125016161', 'message': 'Migrate openstack modules as a collection\n\nAlso fixed ALL ansible-test sanity issues\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 5, 'created': '2020-01-16 14:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8632060174aa89fabf1badb0ae7d1491db126f60', 'message': 'Migrate openstack modules as a collection\n\nMigrate accordin to Ansible guidelines [1[]] and tool\nmigrate.py [2]\nAlso fixed ALL ansible-test sanity issues\n\n[1] https://etherpad.openstack.org/p/openstack-ansible-modules\n[2] https://github.com/ansible-community/collection_migration\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 6, 'created': '2020-01-16 17:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/576bd02fdf2c0c7de3d54de9a2a34e970b0b69ad', 'message': 'Migrate openstack modules as a collection\n\nMigrate accordin to Ansible guidelines [1[]] and tool\nmigrate.py [2]\nAlso fixed ALL ansible-test sanity issues\n\n[1] https://etherpad.openstack.org/p/openstack-ansible-modules\n[2] https://github.com/ansible-community/collection_migration\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 7, 'created': '2020-01-16 20:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c93915e993d973fb1d5f2391468312c3db262c53', 'message': 'Migrate openstack modules as a collection\n\nMigrate accordin to Ansible guidelines [1[]] and tool\nmigrate.py [2]\nAlso fixed ALL ansible-test sanity issues\n\nAdd pep8 and linter job with runs ansible-test sanity test.\n\n[1] https://etherpad.openstack.org/p/openstack-ansible-modules\n[2] https://github.com/ansible-community/collection_migration\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}, {'number': 8, 'created': '2020-01-17 14:07:30.000000000', 'files': ['plugins/modules/os_keystone_domain_info.py', 'plugins/modules/os_loadbalancer.py', 'plugins/modules/os_volume.py', 'test-requirements.txt', 'plugins/modules/os_ironic_inspect.py', 'plugins/modules/os_server_action.py', 'plugins/modules/os_project.py', 'plugins/modules/os_volume_snapshot.py', 'plugins/modules/os_coe_cluster_template.py', 'plugins/inventory/__init__.py', 'plugins/modules/os_floating_ip.py', 'plugins/modules/os_server_info.py', 'tests/unit/modules/cloud/__init__.py', 'plugins/inventory/openstack.py', 'plugins/modules/os_listener.py', 'tests/.gitignore', 'plugins/modules/os_router.py', 'plugins/modules/os_user_group.py', 'plugins/modules/os_stack.py', 'plugins/modules/os_flavor_info.py', 'plugins/modules/os_group_info.py', 'plugins/modules/os_port.py', 'plugins/modules/os_networks_info.py', 'plugins/modules/os_nova_flavor.py', 'tests/unit/modules/conftest.py', 'plugins/modules/os_project_info.py', 'LICENSE', 'plugins/modules/os_ironic.py', 'plugins/modules/os_keystone_service.py', 'plugins/modules/os_network.py', 'tests/unit/compat/__init__.py', 'plugins/modules/os_user.py', 'plugins/doc_fragments/openstack.py', 'plugins/modules/os_keypair.py', 'plugins/modules/os_nova_host_aggregate.py', 'tests/unit/compat/mock.py', 'README.md', 'plugins/modules/os_client_config.py', 'plugins/modules/os_keystone_role.py', 'tests/unit/plugins/__init__.py', 'plugins/module_utils/openstack.py', 'plugins/modules/os_user_role.py', 'tests/unit/__init__.py', 'tox.ini', 'plugins/modules/os_image.py', 'galaxy.yml', 'plugins/modules/os_zone.py', 'plugins/modules/os_server_volume.py', 'tests/unit/mock/path.py', 'tests/unit/plugins/inventory/test_openstack.py', 'zuul.yaml', 'tests/unit/modules/utils.py', 'tests/unit/mock/procenv.py', 'plugins/modules/os_subnet.py', 'plugins/modules/os_image_info.py', 'tests/unit/compat/unittest.py', 'plugins/modules/os_pool.py', 'plugins/modules/os_port_info.py', 'plugins/modules/os_ironic_node.py', 'plugins/modules/os_user_info.py', 'plugins/modules/os_subnets_info.py', 'tests/sanity/ignore-2.9.txt', 'plugins/modules/os_auth.py', 'plugins/modules/os_quota.py', 'tests/sanity/ignore-2.10.txt', 'plugins/modules/__init__.py', 'tests/unit/requirements.txt', 'plugins/module_utils/__init__.py', 'plugins/modules/os_server_group.py', 'tests/unit/modules/__init__.py', 'tests/unit/compat/builtins.py', 'plugins/modules/os_member.py', 'plugins/modules/os_coe_cluster.py', 'plugins/modules/os_server.py', 'tests/unit/plugins/inventory/__init__.py', 'plugins/modules/os_keystone_endpoint.py', 'tests/unit/modules/cloud/openstack/__init__.py', 'plugins/modules/os_project_access.py', 'plugins/modules/os_recordset.py', 'tests/unit/mock/__init__.py', 'tests/unit/mock/loader.py', 'plugins/modules/os_security_group.py', 'plugins/modules/os_server_metadata.py', 'plugins/doc_fragments/__init__.py', 'tests/sanity/requirements.txt', 'tests/unit/modules/cloud/openstack/test_os_server.py', 'plugins/modules/os_group.py', 'plugins/modules/os_keystone_domain.py', 'plugins/modules/os_security_group_rule.py', 'tests/unit/mock/vault_helper.py', 'plugins/modules/os_object.py', 'tests/unit/mock/yaml_helper.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6ac08e7f0e0eab70b90b3c21c70116c2cccc57ea', 'message': 'Migrate openstack modules as a collection\n\nMigrate accordin to Ansible guidelines [1[]] and tool\nmigrate.py [2]\nAlso fixed ALL ansible-test sanity issues\n\nAdd pep8 and linter job with runs ansible-test sanity test.\n\n[1] https://etherpad.openstack.org/p/openstack-ansible-modules\n[2] https://github.com/ansible-community/collection_migration\n\nChange-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520\n'}]",6,702850,6ac08e7f0e0eab70b90b3c21c70116c2cccc57ea,21,14,8,10969,,,0,"Migrate openstack modules as a collection

Migrate accordin to Ansible guidelines [1[]] and tool
migrate.py [2]
Also fixed ALL ansible-test sanity issues

Add pep8 and linter job with runs ansible-test sanity test.

[1] https://etherpad.openstack.org/p/openstack-ansible-modules
[2] https://github.com/ansible-community/collection_migration

Change-Id: Ib2b1c8f23aacfca95304132bfe5c4cdedbea0520
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/50/702850/6 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/os_keystone_domain_info.py', 'plugins/modules/os_loadbalancer.py', 'plugins/modules/os_volume.py', 'plugins/modules/os_ironic_inspect.py', 'plugins/modules/os_server_action.py', 'plugins/modules/os_project.py', 'plugins/modules/os_volume_snapshot.py', 'plugins/modules/os_coe_cluster_template.py', 'plugins/inventory/__init__.py', 'plugins/modules/os_floating_ip.py', 'plugins/modules/os_server_info.py', 'tests/unit/modules/cloud/__init__.py', 'plugins/inventory/openstack.py', 'plugins/modules/os_listener.py', 'tests/.gitignore', 'plugins/modules/os_router.py', 'plugins/modules/os_user_group.py', 'plugins/modules/os_stack.py', 'plugins/modules/os_flavor_info.py', 'plugins/modules/os_group_info.py', 'plugins/modules/os_port.py', 'plugins/modules/os_networks_info.py', 'plugins/modules/os_nova_flavor.py', 'tests/unit/modules/conftest.py', 'plugins/modules/os_project_info.py', 'plugins/modules/os_ironic.py', 'plugins/modules/os_keystone_service.py', 'plugins/modules/os_network.py', 'tests/unit/compat/__init__.py', 'plugins/modules/os_user.py', 'plugins/doc_fragments/openstack.py', 'plugins/modules/os_keypair.py', 'plugins/modules/os_nova_host_aggregate.py', 'tests/unit/compat/mock.py', 'README.md', 'plugins/modules/os_client_config.py', 'plugins/modules/os_keystone_role.py', 'tests/unit/plugins/__init__.py', 'plugins/module_utils/openstack.py', 'plugins/modules/os_user_role.py', 'tests/unit/__init__.py', 'plugins/modules/os_image.py', 'galaxy.yml', 'plugins/modules/os_zone.py', 'plugins/modules/os_server_volume.py', 'tests/unit/mock/path.py', 'tests/unit/plugins/inventory/test_openstack.py', 'tests/unit/modules/utils.py', 'tests/unit/mock/procenv.py', 'plugins/modules/os_subnet.py', 'plugins/modules/os_image_info.py', 'tests/unit/compat/unittest.py', 'plugins/modules/os_pool.py', 'plugins/modules/os_port_info.py', 'plugins/modules/os_ironic_node.py', 'plugins/modules/os_user_info.py', 'plugins/modules/os_subnets_info.py', 'tests/sanity/ignore-2.9.txt', 'plugins/modules/os_auth.py', 'plugins/modules/os_quota.py', 'tests/sanity/ignore-2.10.txt', 'plugins/modules/__init__.py', 'tests/unit/requirements.txt', 'plugins/module_utils/__init__.py', 'plugins/modules/os_server_group.py', 'tests/unit/modules/__init__.py', 'tests/unit/compat/builtins.py', 'plugins/modules/os_member.py', 'plugins/modules/os_coe_cluster.py', 'plugins/modules/os_server.py', 'tests/unit/plugins/inventory/__init__.py', 'plugins/modules/os_keystone_endpoint.py', 'tests/unit/modules/cloud/openstack/__init__.py', 'plugins/modules/os_project_access.py', 'plugins/modules/os_recordset.py', 'tests/unit/mock/__init__.py', 'tests/unit/mock/loader.py', 'plugins/modules/os_security_group.py', 'plugins/modules/os_server_metadata.py', 'plugins/doc_fragments/__init__.py', 'tests/sanity/requirements.txt', 'tests/unit/modules/cloud/openstack/test_os_server.py', 'plugins/modules/os_group.py', 'plugins/modules/os_keystone_domain.py', 'plugins/modules/os_security_group_rule.py', 'tests/unit/mock/vault_helper.py', 'plugins/modules/os_object.py', 'tests/unit/mock/yaml_helper.py']",88,7eb39ea36c3bde8b2d56205e5eda6506503faec0,move,"import io import yaml from ansible.module_utils.six import PY3 from ansible.parsing.yaml.loader import AnsibleLoader from ansible.parsing.yaml.dumper import AnsibleDumper class YamlTestUtils(object): """"""Mixin class to combine with a unittest.TestCase subclass."""""" def _loader(self, stream): """"""Vault related tests will want to override this. Vault cases should setup a AnsibleLoader that has the vault password."""""" return AnsibleLoader(stream) def _dump_stream(self, obj, stream, dumper=None): """"""Dump to a py2-unicode or py3-string stream."""""" if PY3: return yaml.dump(obj, stream, Dumper=dumper) else: return yaml.dump(obj, stream, Dumper=dumper, encoding=None) def _dump_string(self, obj, dumper=None): """"""Dump to a py2-unicode or py3-string"""""" if PY3: return yaml.dump(obj, Dumper=dumper) else: return yaml.dump(obj, Dumper=dumper, encoding=None) def _dump_load_cycle(self, obj): # Each pass though a dump or load revs the 'generation' # obj to yaml string string_from_object_dump = self._dump_string(obj, dumper=AnsibleDumper) # wrap a stream/file like StringIO around that yaml stream_from_object_dump = io.StringIO(string_from_object_dump) loader = self._loader(stream_from_object_dump) # load the yaml stream to create a new instance of the object (gen 2) obj_2 = loader.get_data() # dump the gen 2 objects directory to strings string_from_object_dump_2 = self._dump_string(obj_2, dumper=AnsibleDumper) # The gen 1 and gen 2 yaml strings self.assertEqual(string_from_object_dump, string_from_object_dump_2) # the gen 1 (orig) and gen 2 py object self.assertEqual(obj, obj_2) # again! gen 3... load strings into py objects stream_3 = io.StringIO(string_from_object_dump_2) loader_3 = self._loader(stream_3) obj_3 = loader_3.get_data() string_from_object_dump_3 = self._dump_string(obj_3, dumper=AnsibleDumper) self.assertEqual(obj, obj_3) # should be transitive, but... self.assertEqual(obj_2, obj_3) self.assertEqual(string_from_object_dump, string_from_object_dump_3) def _old_dump_load_cycle(self, obj): '''Dump the passed in object to yaml, load it back up, dump again, compare.''' stream = io.StringIO() yaml_string = self._dump_string(obj, dumper=AnsibleDumper) self._dump_stream(obj, stream, dumper=AnsibleDumper) yaml_string_from_stream = stream.getvalue() # reset stream stream.seek(0) loader = self._loader(stream) # loader = AnsibleLoader(stream, vault_password=self.vault_password) obj_from_stream = loader.get_data() stream_from_string = io.StringIO(yaml_string) loader2 = self._loader(stream_from_string) # loader2 = AnsibleLoader(stream_from_string, vault_password=self.vault_password) obj_from_string = loader2.get_data() stream_obj_from_stream = io.StringIO() stream_obj_from_string = io.StringIO() if PY3: yaml.dump(obj_from_stream, stream_obj_from_stream, Dumper=AnsibleDumper) yaml.dump(obj_from_stream, stream_obj_from_string, Dumper=AnsibleDumper) else: yaml.dump(obj_from_stream, stream_obj_from_stream, Dumper=AnsibleDumper, encoding=None) yaml.dump(obj_from_stream, stream_obj_from_string, Dumper=AnsibleDumper, encoding=None) yaml_string_stream_obj_from_stream = stream_obj_from_stream.getvalue() yaml_string_stream_obj_from_string = stream_obj_from_string.getvalue() stream_obj_from_stream.seek(0) stream_obj_from_string.seek(0) if PY3: yaml_string_obj_from_stream = yaml.dump(obj_from_stream, Dumper=AnsibleDumper) yaml_string_obj_from_string = yaml.dump(obj_from_string, Dumper=AnsibleDumper) else: yaml_string_obj_from_stream = yaml.dump(obj_from_stream, Dumper=AnsibleDumper, encoding=None) yaml_string_obj_from_string = yaml.dump(obj_from_string, Dumper=AnsibleDumper, encoding=None) assert yaml_string == yaml_string_obj_from_stream assert yaml_string == yaml_string_obj_from_stream == yaml_string_obj_from_string assert (yaml_string == yaml_string_obj_from_stream == yaml_string_obj_from_string == yaml_string_stream_obj_from_stream == yaml_string_stream_obj_from_string) assert obj == obj_from_stream assert obj == obj_from_string assert obj == yaml_string_obj_from_stream assert obj == yaml_string_obj_from_string assert obj == obj_from_stream == obj_from_string == yaml_string_obj_from_stream == yaml_string_obj_from_string return {'obj': obj, 'yaml_string': yaml_string, 'yaml_string_from_stream': yaml_string_from_stream, 'obj_from_stream': obj_from_stream, 'obj_from_string': obj_from_string, 'yaml_string_obj_from_string': yaml_string_obj_from_string} ",,15062,0
openstack%2Frpm-packaging~master~Id72f2053e28021404a4514fe7d3806e81891ab01,openstack/rpm-packaging,master,Id72f2053e28021404a4514fe7d3806e81891ab01,Bump oslo.vmware to 2.35.0,MERGED,2020-01-15 10:26:42.000000000,2020-01-17 15:51:35.000000000,2020-01-17 15:51:35.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-15 10:26:42.000000000', 'files': ['openstack/oslo.vmware/oslo.vmware.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c5ef523e1192b06da5e84cc2d12d67de22138195', 'message': 'Bump oslo.vmware to 2.35.0\n\nhttps://github.com/openstack/releases/commit/ea335281b258f4ec867c185f34e08b220cfce094\n\nChange-Id: Id72f2053e28021404a4514fe7d3806e81891ab01\n'}]",0,702635,c5ef523e1192b06da5e84cc2d12d67de22138195,11,6,1,28522,,,0,"Bump oslo.vmware to 2.35.0

https://github.com/openstack/releases/commit/ea335281b258f4ec867c185f34e08b220cfce094

Change-Id: Id72f2053e28021404a4514fe7d3806e81891ab01
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/35/702635/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.vmware/oslo.vmware.spec.j2'],1,c5ef523e1192b06da5e84cc2d12d67de22138195,,{% set upstream_version = upstream_version('2.35.0') %},{% set upstream_version = upstream_version('2.34.1') %},1,1
openstack%2Ftripleo-upgrade~stable%2Ftrain~I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e,openstack/tripleo-upgrade,stable/train,I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e,Force OS_COMPUTE_API_VERSION to a lower one on workload test.,MERGED,2020-01-16 14:08:14.000000000,2020-01-17 15:48:45.000000000,2020-01-17 15:48:45.000000000,"[{'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 17216}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-01-16 14:08:14.000000000', 'files': ['templates/workload_launch.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/f51912d50ef0e40e8fc80b6b06b901642a66b7c5', 'message': 'Force OS_COMPUTE_API_VERSION to a lower one on workload test.\n\nAfter the upgrade prepare and right before the upgrade run\ncommand a workload test is executed, which creates an instance\nand performs a pingtest during the whole upgrade procedure.\nThe generated rc file for the OC has the OS_COMPUTE_API_VERSION\npointing to 2.latest which provokes a conflict in this situation\nas we have a OSP16 Undercloud and a OSP15 overcloud, failing with\nthe error: Version 2.79 is not supported by the API. Minimum is\nMinimum is 2.1 and maximum is 2.72.\n\nThis patch forces the maximum version on the script launch to be\n2.72 at max.\n\nChange-Id: I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e\n(cherry picked from commit b717d4f08933c341d375e3ad43ec10768d0a7d04)\n'}]",0,702869,f51912d50ef0e40e8fc80b6b06b901642a66b7c5,8,6,1,26343,,,0,"Force OS_COMPUTE_API_VERSION to a lower one on workload test.

After the upgrade prepare and right before the upgrade run
command a workload test is executed, which creates an instance
and performs a pingtest during the whole upgrade procedure.
The generated rc file for the OC has the OS_COMPUTE_API_VERSION
pointing to 2.latest which provokes a conflict in this situation
as we have a OSP16 Undercloud and a OSP15 overcloud, failing with
the error: Version 2.79 is not supported by the API. Minimum is
Minimum is 2.1 and maximum is 2.72.

This patch forces the maximum version on the script launch to be
2.72 at max.

Change-Id: I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e
(cherry picked from commit b717d4f08933c341d375e3ad43ec10768d0a7d04)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/69/702869/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/workload_launch.sh.j2'],1,f51912d50ef0e40e8fc80b6b06b901642a66b7c5,,export OS_COMPUTE_API_VERSION=2.72 ,,2,0
openstack%2Fnova~master~If7d8c43a503ca3fbe252e98b68bca0bb8c4f1cc4,openstack/nova,master,If7d8c43a503ca3fbe252e98b68bca0bb8c4f1cc4,DNM Test the removal of g-api from subnodes,ABANDONED,2020-01-17 15:10:36.000000000,2020-01-17 15:39:29.000000000,,"[{'_account_id': 14070}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-01-17 15:10:36.000000000', 'files': ['.DNM'], 'web_link': 'https://opendev.org/openstack/nova/commit/ebae291ff5dd81dd0c3d55e5eb9682e7dbe3b04f', 'message': 'DNM Test the removal of g-api from subnodes\n\nChange-Id: If7d8c43a503ca3fbe252e98b68bca0bb8c4f1cc4\nDepends-On: https://review.opendev.org/703099\n'}]",0,703100,ebae291ff5dd81dd0c3d55e5eb9682e7dbe3b04f,4,2,1,10135,,,0,"DNM Test the removal of g-api from subnodes

Change-Id: If7d8c43a503ca3fbe252e98b68bca0bb8c4f1cc4
Depends-On: https://review.opendev.org/703099
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/703100/1 && git format-patch -1 --stdout FETCH_HEAD,['.DNM'],1,ebae291ff5dd81dd0c3d55e5eb9682e7dbe3b04f,,,,0,0
openstack%2Fdevstack-gate~master~I02bff11495f29822f1b5d0123d26df7c9bb76b30,openstack/devstack-gate,master,I02bff11495f29822f1b5d0123d26df7c9bb76b30,WIP Remove g-api from subnodes,ABANDONED,2020-01-17 15:09:34.000000000,2020-01-17 15:39:17.000000000,,[{'_account_id': 14070}],"[{'number': 1, 'created': '2020-01-17 15:09:34.000000000', 'files': ['test-features.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/711b7d38f76a50bb7bba0800e3db53765e7434c9', 'message': 'WIP Remove g-api from subnodes\n\nChange-Id: I02bff11495f29822f1b5d0123d26df7c9bb76b30\n'}]",0,703099,711b7d38f76a50bb7bba0800e3db53765e7434c9,2,1,1,10135,,,0,"WIP Remove g-api from subnodes

Change-Id: I02bff11495f29822f1b5d0123d26df7c9bb76b30
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/99/703099/1 && git format-patch -1 --stdout FETCH_HEAD,['test-features.sh'],1,711b7d38f76a50bb7bba0800e3db53765e7434c9,,"GRENADE_SUBNODE_MASTER=""n-api-meta,n-cpu,c-vol,dstat,peakmem_tracker,placement-client""","GRENADE_SUBNODE_MASTER=""n-api-meta,n-cpu,g-api,c-vol,dstat,peakmem_tracker,placement-client""",1,1
openstack%2Fmonasca-persister~master~Id878cd56e16f0d2b10ecdc060901ba6343e72dc2,openstack/monasca-persister,master,Id878cd56e16f0d2b10ecdc060901ba6343e72dc2,Change README.rst with a better title,MERGED,2019-12-26 02:06:17.000000000,2020-01-17 15:30:30.000000000,2020-01-17 15:30:30.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 02:06:17.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/3ed12b9d2c64607be407b8e7c36b95c61174cfe1', 'message': 'Change README.rst with a better title\n\nChange-Id: Id878cd56e16f0d2b10ecdc060901ba6343e72dc2\n'}]",0,700576,3ed12b9d2c64607be407b8e7c36b95c61174cfe1,6,2,1,27399,,,0,"Change README.rst with a better title

Change-Id: Id878cd56e16f0d2b10ecdc060901ba6343e72dc2
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/76/700576/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3ed12b9d2c64607be407b8e7c36b95c61174cfe1,developer,Monasca Persister =================,Team and repository tags ========================monasca-persister ================= ,2,5
openstack%2Fmonasca-ui~master~I3cd4ad5c3fe590cb1522b2be1b2059d7c70b45cc,openstack/monasca-ui,master,I3cd4ad5c3fe590cb1522b2be1b2059d7c70b45cc,Drop Django 1.11 support,MERGED,2020-01-02 19:40:52.000000000,2020-01-17 15:30:05.000000000,2020-01-17 15:30:05.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2020-01-02 19:40:52.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/f8d3417d0b6f081f28f87e0049daab01b20d161a', 'message': 'Drop Django 1.11 support\n\nDjango 1.11 ends its extended support in April 2020 (which is before\nUssuri release), so horizon drops Django 1.11 support in Ussuri.\n\ntox envs for non-primary Django versions are no longer needed in tox.ini\nas testing environments for non-primary Django versions are setup in\nthe zuul jobs now.\n\nhorizon>=17.1.0 is required to use Django 2.2. requirements.txt and\nlower-constraints.txt are updated accordingly. for more info. please\nrefer [1].\nDepends-On: https://review.opendev.org/#/c/700733/\n[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin\n\nChange-Id: I3cd4ad5c3fe590cb1522b2be1b2059d7c70b45cc\n'}]",0,700929,f8d3417d0b6f081f28f87e0049daab01b20d161a,9,3,1,29313,,,0,"Drop Django 1.11 support

Django 1.11 ends its extended support in April 2020 (which is before
Ussuri release), so horizon drops Django 1.11 support in Ussuri.

tox envs for non-primary Django versions are no longer needed in tox.ini
as testing environments for non-primary Django versions are setup in
the zuul jobs now.

horizon>=17.1.0 is required to use Django 2.2. requirements.txt and
lower-constraints.txt are updated accordingly. for more info. please
refer [1].
Depends-On: https://review.opendev.org/#/c/700733/
[1] https://etherpad.openstack.org/p/Enable_Django22_support_in_Horizon_Plugin

Change-Id: I3cd4ad5c3fe590cb1522b2be1b2059d7c70b45cc
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/29/700929/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt', 'tox.ini']",3,f8d3417d0b6f081f28f87e0049daab01b20d161a,drop-django111-support,"envlist = py37,pep8","envlist = py37,py3-{dj111,dj22},pep8 dj111: pip install django>=1.11,<2 dj22: pip install django>=2.2,<2.3",5,7
openstack%2Foslo.db~master~I40882f14ff2ac121764b432fc745b21ae751e321,openstack/oslo.db,master,I40882f14ff2ac121764b432fc745b21ae751e321,Drop unittest2 usage,MERGED,2020-01-12 08:39:28.000000000,2020-01-17 15:21:22.000000000,2020-01-17 15:18:03.000000000,"[{'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-12 08:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/3975885ce9daf37d8cb561ed75fad92b755d99a5', 'message': 'Drop unittest2 usage\n\nunittest2 was needed for Python versions <= 2.6, so it has not been\nneeded for quite some time now. See unittest2 note on:\n\nhttps://docs.python.org/2.7/library/unittest.html\n\nThis drops unittest2 in favor of the standard unittest package.\n\nChange-Id: I40882f14ff2ac121764b432fc745b21ae751e321\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2020-01-12 17:37:01.000000000', 'files': ['oslo_db/tests/sqlalchemy/test_async_eventlet.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/82098f63bc51971ce87cb240a6ef0f146d3de3ed', 'message': 'Drop unittest2 usage\n\nunittest2 was needed for Python versions <= 2.6, so it has not been\nneeded for quite some time now. See unittest2 note on:\n\nhttps://docs.python.org/2.7/library/unittest.html\n\nThis drops unittest2 in favor of the standard unittest package.\n\nChange-Id: I40882f14ff2ac121764b432fc745b21ae751e321\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,702115,82098f63bc51971ce87cb240a6ef0f146d3de3ed,12,4,2,11904,,,0,"Drop unittest2 usage

unittest2 was needed for Python versions <= 2.6, so it has not been
needed for quite some time now. See unittest2 note on:

https://docs.python.org/2.7/library/unittest.html

This drops unittest2 in favor of the standard unittest package.

Change-Id: I40882f14ff2ac121764b432fc745b21ae751e321
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/15/702115/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/tests/sqlalchemy/test_async_eventlet.py', 'lower-constraints.txt']",2,3975885ce9daf37d8cb561ed75fad92b755d99a5,unittest2,,unittest2==1.1.0,2,3
openstack%2Foslo.log~master~Idd5df4c8068810bbbd2bd5058ca38df9f5416a62,openstack/oslo.log,master,Idd5df4c8068810bbbd2bd5058ca38df9f5416a62,Drop use of unittest2,MERGED,2020-01-12 08:37:38.000000000,2020-01-17 15:15:30.000000000,2020-01-17 15:12:58.000000000,"[{'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-12 08:37:38.000000000', 'files': ['oslo_log/tests/unit/test_versionutils.py', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/80a6e26650302329fa9aff26efa389bd99e397c5', 'message': 'Drop use of unittest2\n\nunittest2 was needed for Python version <= 2.6, so it has not been\nneeded for quite some time now. See unittest2 note on:\n\nhttps://docs.python.org/2.7/library/unittest.html\n\nThis replaces unittest2 in favor of the standard unittest package.\n\nChange-Id: Idd5df4c8068810bbbd2bd5058ca38df9f5416a62\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,702114,80a6e26650302329fa9aff26efa389bd99e397c5,12,4,1,11904,,,0,"Drop use of unittest2

unittest2 was needed for Python version <= 2.6, so it has not been
needed for quite some time now. See unittest2 note on:

https://docs.python.org/2.7/library/unittest.html

This replaces unittest2 in favor of the standard unittest package.

Change-Id: Idd5df4c8068810bbbd2bd5058ca38df9f5416a62
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/14/702114/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/tests/unit/test_versionutils.py', 'lower-constraints.txt']",2,80a6e26650302329fa9aff26efa389bd99e397c5,unittest2,,unittest2==1.1.0,3,3
openstack%2Fironic-python-agent~master~I52f52119a5f3175b1723fde291eb26d4f86c8223,openstack/ironic-python-agent,master,I52f52119a5f3175b1723fde291eb26d4f86c8223,Skip nic numa_node discovery if it's not assigned to a numa_node,MERGED,2020-01-16 21:38:08.000000000,2020-01-17 14:54:44.000000000,2020-01-17 14:26:42.000000000,"[{'_account_id': 7130}, {'_account_id': 10239}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-16 21:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5b14dcf302fbf1eb9f486443e46c3b9db33ec7b3', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\n""}, {'number': 2, 'created': '2020-01-16 22:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/65ac96b5c19e6934a82ae1ca8657ddf1bb566d96', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nCloses-story: #2007105\n""}, {'number': 3, 'created': '2020-01-16 22:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0d80ca920bc39be79351400e4972c7a874ad92bc', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nCloses-bug: #2007105\n""}, {'number': 4, 'created': '2020-01-17 00:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/2f96c319197231df5083192094575a8157b559c0', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nStory: 2007105\n""}, {'number': 5, 'created': '2020-01-17 00:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9cbea5d48e9832f6912e0e1ba9dbb6b683b011f5', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nStory: 2007105\nTask: 38151\n""}, {'number': 6, 'created': '2020-01-17 00:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0427bfb8ed3af826e1d7898e1f8b793f8230395f', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nStory: 2007105\nTask: 38151\n""}, {'number': 7, 'created': '2020-01-17 01:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ce61183ea91701118c89bee0db72ef1ef368272a', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nStory: 2007105\nTask: 38151\n""}, {'number': 8, 'created': '2020-01-17 10:15:44.000000000', 'files': ['releasenotes/notes/fix-nic-without-numa-node-b401f97c46afa4a1.yaml', 'ironic_python_agent/numa_inspector.py', 'ironic_python_agent/tests/unit/test_numa_inspector.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a1a121fbf8f982d87efdb2417524603063e38968', 'message': ""Skip nic numa_node discovery if it's not assigned to a numa_node\n\nIn some rare case, such as a VM with virtual numa node, nics might\nnot be in a numa node and this breaks numa-topology discovery.\n\nChange-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223\nStory: 2007105\nTask: 38151\n""}]",2,702990,a1a121fbf8f982d87efdb2417524603063e38968,28,6,8,7130,,,0,"Skip nic numa_node discovery if it's not assigned to a numa_node

In some rare case, such as a VM with virtual numa node, nics might
not be in a numa node and this breaks numa-topology discovery.

Change-Id: I52f52119a5f3175b1723fde291eb26d4f86c8223
Story: 2007105
Task: 38151
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/90/702990/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/numa_inspector.py'],1,5b14dcf302fbf1eb9f486443e46c3b9db33ec7b3,bug/2007105," if not os.path.isdir(os.path.join(nic_device_path, nic_dir, 'device')) or not os.path.isfile(os.path.join(nic_device_path, nic_dir, 'device', 'numa_node')):"," if not os.path.isdir(os.path.join(nic_device_path, nic_dir, 'device')):",3,1
openstack%2Fneutron~master~I62e12c1319f4f805c790b33963a76c5d7ea79d07,openstack/neutron,master,I62e12c1319f4f805c790b33963a76c5d7ea79d07,[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests,MERGED,2019-12-04 16:32:52.000000000,2020-01-17 14:42:45.000000000,2020-01-17 14:40:15.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-04 16:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f21ca774b399d60bb52a1be115890d70360f2b44', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 2, 'created': '2019-12-10 14:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e91a902250574fc21abfa85676cecdf0d42dfde3', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 3, 'created': '2019-12-14 19:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15c69e02f1734db0d2bb349cebc9bfec59e3eeb2', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 4, 'created': '2019-12-19 12:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d056ba8ec4c4b1dfbbe948328ee82c930ce3529', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 5, 'created': '2019-12-19 14:30:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab99f944a7795dff2db945ba6474bc98f6720d3b', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 6, 'created': '2019-12-20 10:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0003b89e610a157e196b75ed34c0bee3940484b0', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 7, 'created': '2019-12-20 10:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d395f2cf90ec79578c7dc7246f4473a36cb99997', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 8, 'created': '2020-01-06 09:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b006d655e48e29486e853d5520f09f4fee19f7d5', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 9, 'created': '2020-01-09 16:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/936c1993403c480cda7d5830285ebf8d2ed92aa9', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nTODO: OVNMechanismDriverTestCase still not implemented\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}, {'number': 10, 'created': '2020-01-14 13:32:45.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c8e520b3723bcea216ab0fe8c3f62a9468a8784', 'message': '[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests\n\nCo-Authored-By: Richard Theis <rtheis@us.ibm.com>\nCo-Authored-By: John Kasperski <jckasper@us.ibm.com>\nCo-Authored-By: Numan Siddique <nusiddiq@redhat.com>\nCo-Authored-By: Terry Wilson <twilson@redhat.com>\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\n\nRelated-Blueprint: neutron-ovn-merge\nChange-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07\n'}]",2,697317,0c8e520b3723bcea216ab0fe8c3f62a9468a8784,60,8,10,16688,,,0,"[OVN] Add missing OvnSbIdl and OvnNbIdl unit tests

Co-Authored-By: Richard Theis <rtheis@us.ibm.com>
Co-Authored-By: John Kasperski <jckasper@us.ibm.com>
Co-Authored-By: Numan Siddique <nusiddiq@redhat.com>
Co-Authored-By: Terry Wilson <twilson@redhat.com>
Co-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>

Related-Blueprint: neutron-ovn-merge
Change-Id: I62e12c1319f4f805c790b33963a76c5d7ea79d07
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/697317/10 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py'],1,f21ca774b399d60bb52a1be115890d70360f2b44,bp/neutron-ovn-merge,"import copyfrom neutron_lib.plugins import constants as n_const from neutron_lib.plugins import directoryfrom neutron.tests.unit.plugins.ml2.drivers.ovn.mech_driver import \ test_mech_driverclass TestOvnNbIdlNotifyHandler(test_mech_driver.OVNMechanismDriverTestCase): def setUp(self): super(TestOvnNbIdlNotifyHandler, self).setUp() helper = ovs_idl.SchemaHelper(schema_json=OVN_NB_SCHEMA) helper.register_all() self.idl = ovsdb_monitor.OvnNbIdl(self.driver, ""remote"", helper) self.lp_table = self.idl.tables.get('Logical_Switch_Port') self.driver.set_port_status_up = mock.Mock() self.driver.set_port_status_down = mock.Mock() def _test_lsp_helper(self, event, new_row_json, old_row_json=None, table=None): row_uuid = uuidutils.generate_uuid() if not table: table = self.lp_table lp_row = ovs_idl.Row.from_json(self.idl, table, row_uuid, new_row_json) if old_row_json: old_row = ovs_idl.Row.from_json(self.idl, table, row_uuid, old_row_json) else: old_row = None self.idl.notify(event, lp_row, updates=old_row) # Add a STOP EVENT to the queue self.idl.notify_handler.shutdown() # Execute the notifications queued self.idl.notify_handler.notify_loop() def test_lsp_up_create_event(self): row_data = {""up"": True, ""name"": ""foo-name""} self._test_lsp_helper('create', row_data) self.driver.set_port_status_up.assert_called_once_with(""foo-name"") self.assertFalse(self.driver.set_port_status_down.called) def test_lsp_down_create_event(self): row_data = {""up"": False, ""name"": ""foo-name""} self._test_lsp_helper('create', row_data) self.driver.set_port_status_down.assert_called_once_with(""foo-name"") self.assertFalse(self.driver.set_port_status_up.called) def test_lsp_up_not_set_event(self): row_data = {""up"": ['set', []], ""name"": ""foo-name""} self._test_lsp_helper('create', row_data) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) def test_unwatch_logical_switch_port_create_events(self): self.idl.unwatch_logical_switch_port_create_events() row_data = {""up"": True, ""name"": ""foo-name""} self._test_lsp_helper('create', row_data) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) row_data[""up""] = False self._test_lsp_helper('create', row_data) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) def test_post_connect(self): self.idl.post_connect() self.assertIsNone(self.idl._lsp_create_up_event) self.assertIsNone(self.idl._lsp_create_down_event) def test_lsp_up_update_event(self): new_row_json = {""up"": True, ""name"": ""foo-name""} old_row_json = {""up"": False} self._test_lsp_helper('update', new_row_json, old_row_json=old_row_json) self.driver.set_port_status_up.assert_called_once_with(""foo-name"") self.assertFalse(self.driver.set_port_status_down.called) def test_lsp_down_update_event(self): new_row_json = {""up"": False, ""name"": ""foo-name""} old_row_json = {""up"": True} self._test_lsp_helper('update', new_row_json, old_row_json=old_row_json) self.driver.set_port_status_down.assert_called_once_with(""foo-name"") self.assertFalse(self.driver.set_port_status_up.called) def test_lsp_up_update_event_no_old_data(self): new_row_json = {""up"": True, ""name"": ""foo-name""} self._test_lsp_helper('update', new_row_json, old_row_json=None) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) def test_lsp_down_update_event_no_old_data(self): new_row_json = {""up"": False, ""name"": ""foo-name""} self._test_lsp_helper('update', new_row_json, old_row_json=None) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) def test_lsp_other_column_update_event(self): new_row_json = {""up"": False, ""name"": ""foo-name"", ""addresses"": [""10.0.0.2""]} old_row_json = {""addresses"": [""10.0.0.3""]} self._test_lsp_helper('update', new_row_json, old_row_json=old_row_json) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) def test_notify_other_table(self): new_row_json = {""name"": ""foo-name""} self._test_lsp_helper('create', new_row_json, table=self.idl.tables.get(""Logical_Switch"")) self.assertFalse(self.driver.set_port_status_up.called) self.assertFalse(self.driver.set_port_status_down.called) @mock.patch('networking_ovn.common.hash_ring_manager.' 'HashRingManager.get_node') def test_notify_different_target_node(self, mock_get_node): mock_get_node.return_value = 'this-is-a-different-node' row = fakes.FakeOvsdbRow.create_one_ovsdb_row() self.idl.notify_handler.notify = mock.Mock() self.idl.notify(""create"", row) # Assert that if the target_node returned by the ring is different # than this driver's node_uuid, notify() won't be called self.assertFalse(self.idl.notify_handler.notify.called) class TestOvnSbIdlNotifyHandler(test_mech_driver.OVNMechanismDriverTestCase): l3_plugin = 'networking_ovn.l3.l3_ovn.OVNL3RouterPlugin' def setUp(self): super(TestOvnSbIdlNotifyHandler, self).setUp() sb_helper = ovs_idl.SchemaHelper(schema_json=OVN_SB_SCHEMA) sb_helper.register_table('Chassis') self.sb_idl = ovsdb_monitor.OvnSbIdl(self.driver, ""remote"", sb_helper) self.sb_idl.post_connect() self.chassis_table = self.sb_idl.tables.get('Chassis') self.driver.update_segment_host_mapping = mock.Mock() self.l3_plugin = directory.get_plugin(n_const.L3) self.l3_plugin.schedule_unhosted_gateways = mock.Mock() self.row_json = { ""name"": ""fake-name"", ""hostname"": ""fake-hostname"", ""external_ids"": ['map', [[""ovn-bridge-mappings"", ""fake-phynet1:fake-br1""]]] } def _test_chassis_helper(self, event, new_row_json, old_row_json=None): row_uuid = uuidutils.generate_uuid() table = self.chassis_table row = ovs_idl.Row.from_json(self.sb_idl, table, row_uuid, new_row_json) if old_row_json: old_row = ovs_idl.Row.from_json(self.sb_idl, table, row_uuid, old_row_json) else: old_row = None self.sb_idl.notify(event, row, updates=old_row) # Add a STOP EVENT to the queue self.sb_idl.notify_handler.shutdown() # Execute the notifications queued self.sb_idl.notify_handler.notify_loop() def test_chassis_create_event(self): self._test_chassis_helper('create', self.row_json) self.driver.update_segment_host_mapping.assert_called_once_with( 'fake-hostname', ['fake-phynet1']) self.assertEqual( 1, self.l3_plugin.schedule_unhosted_gateways.call_count) def test_chassis_delete_event(self): self._test_chassis_helper('delete', self.row_json) self.driver.update_segment_host_mapping.assert_called_once_with( 'fake-hostname', []) self.assertEqual( 1, self.l3_plugin.schedule_unhosted_gateways.call_count) def test_chassis_update_event(self): old_row_json = copy.deepcopy(self.row_json) old_row_json['external_ids'][1][0][1] = ( ""fake-phynet2:fake-br2"") self._test_chassis_helper('update', self.row_json, old_row_json) self.driver.update_segment_host_mapping.assert_called_once_with( 'fake-hostname', ['fake-phynet1']) self.assertEqual( 1, self.l3_plugin.schedule_unhosted_gateways.call_count)","# NOTE(ralonsoh): once the OVN mech driver is implemented, we'll be able to # test OvnNbIdl and OvnSbIdl properly.",190,2
openstack%2Fcharm-glance~stable%2F19.10~I274441966f15f66341adf30c07c625cc76b2ecb6,openstack/charm-glance,stable/19.10,I274441966f15f66341adf30c07c625cc76b2ecb6,Remove deprecated glance-registry from nrpe checks,MERGED,2020-01-14 14:35:14.000000000,2020-01-17 14:37:37.000000000,2020-01-17 14:37:37.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 28014}]","[{'number': 1, 'created': '2020-01-14 14:35:14.000000000', 'files': ['hooks/glance_utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/glance_relations.py'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/d2cba57eb3ce959408912996f85dd8ef0e198073', 'message': 'Remove deprecated glance-registry from nrpe checks\n\nThis patch removes the deprecated glance-registry service from nrpe\nchecks after an openstack upgrade to an openstack version greater than\nRocky\n\nCloses-Bug: #1849896\nDepends-On: https://github.com/juju/charm-helpers/pull/409\n\nChange-Id: I274441966f15f66341adf30c07c625cc76b2ecb6\nSigned-off-by: Alexandros Soumplis <soumplis@admin.grnet.gr>\n(cherry picked from commit b5e6a3e03a1a8756f545a47e413dbe1a27f92407)\n'}]",0,702444,d2cba57eb3ce959408912996f85dd8ef0e198073,10,5,1,30442,,,0,"Remove deprecated glance-registry from nrpe checks

This patch removes the deprecated glance-registry service from nrpe
checks after an openstack upgrade to an openstack version greater than
Rocky

Closes-Bug: #1849896
Depends-On: https://github.com/juju/charm-helpers/pull/409

Change-Id: I274441966f15f66341adf30c07c625cc76b2ecb6
Signed-off-by: Alexandros Soumplis <soumplis@admin.grnet.gr>
(cherry picked from commit b5e6a3e03a1a8756f545a47e413dbe1a27f92407)
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/44/702444/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/glance_utils.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/glance_relations.py']",3,d2cba57eb3ce959408912996f85dd8ef0e198073,fix_glance_registry_nrpe-stable/19.10," deprecated_services, nrpe.remove_deprecated_check(nrpe_setup, deprecated_services())",,21,0
openstack%2Fcharm-gnocchi~stable%2F19.10~Ie8b10209daa4de74427e175ef21ddf306a17a0ae,openstack/charm-gnocchi,stable/19.10,Ie8b10209daa4de74427e175ef21ddf306a17a0ae,Add binary_prefix=true argument to mysql uri,MERGED,2019-10-31 11:55:37.000000000,2020-01-17 14:35:46.000000000,2020-01-17 14:35:46.000000000,"[{'_account_id': 935}, {'_account_id': 5112}, {'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 28014}]","[{'number': 1, 'created': '2019-10-31 11:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/fbc8c1e97558be614cc1d036c382d1d7a8a4529b', 'message': ""Add binary_prefix=true argument to mysql uri\n\nThis patch adds the argument binary_prefix=true to MySQL uri if\nOpenStack version is equal or greater than Rocky due to Python\nupper-constraints [1]. This argument is required because of PyMySQL's\nchange from version 0.8 and on [2], in order to fix Gnocchi API\nwarnings like this [3].\n\n[1] https://github.com/openstack/requirements/blob/stable/rocky/upper-constraints.txt#L377\n[2] https://github.com/PyMySQL/PyMySQL/blob/master/CHANGELOG#L61-L64\n[3] https://github.com/gnocchixyz/gnocchi/issues/847\n\nChange-Id: Ie8b10209daa4de74427e175ef21ddf306a17a0ae\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n(cherry picked from commit bf7ac78d07a313651e486196309140517d9ad861)\n""}, {'number': 2, 'created': '2019-12-20 12:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/b27abe2e5c81243745215136c5fb9a0c2a022969', 'message': ""Add binary_prefix=true argument to mysql uri\n\nThis patch adds the argument binary_prefix=true to MySQL uri if\nOpenStack version is equal or greater than Rocky due to Python\nupper-constraints [1]. This argument is required because of PyMySQL's\nchange from version 0.8 and on [2], in order to fix Gnocchi API\nwarnings like this [3].\n\n[1] https://github.com/openstack/requirements/blob/stable/rocky/upper-constraints.txt#L377\n[2] https://github.com/PyMySQL/PyMySQL/blob/master/CHANGELOG#L61-L64\n[3] https://github.com/gnocchixyz/gnocchi/issues/847\n\nChanging condition release from rocky to queens for mysql uri\n\nAs Queens also has PyMySQL 0.8.0 dependency so it has the same issue[1][2][3][4],\nchanging condition release from rocky to queens to fix warning flood.\n\n[1] https://github.com/openstack/charm-gnocchi/commit/bf7ac78d07a313651e486196309140517d9ad861\n[2] https://github.com/openstack/requirements/blob/stable/rocky/upper-constraints.txt#L377\n[3] https://github.com/openstack/requirements/blob/stable/queens/upper-constraints.txt#L374\n[4] gnocchixyz/gnocchi#847\n\nChange-Id: Ie8b10209daa4de74427e175ef21ddf306a17a0ae\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n(cherry picked from commit bf7ac78d07a313651e486196309140517d9ad861)\n(cherry picked from commit 408bf97a36bd9538d07e92398a8278b567b78fc3)\n""}, {'number': 3, 'created': '2020-01-14 03:15:53.000000000', 'files': ['src/lib/charm/openstack/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/d3980909ad460b78f2c0788a37a414238bb2ae66', 'message': ""Add binary_prefix=true argument to mysql uri\n\nThis patch adds the argument binary_prefix=true to MySQL uri if\nOpenStack version is equal or greater than Rocky due to Python\nupper-constraints [1]. This argument is required because of PyMySQL's\nchange from version 0.8 and on [2], in order to fix Gnocchi API\nwarnings like this [3].\n\n[1] https://github.com/openstack/requirements/blob/stable/rocky/upper-constraints.txt#L377\n[2] https://github.com/PyMySQL/PyMySQL/blob/master/CHANGELOG#L61-L64\n[3] https://github.com/gnocchixyz/gnocchi/issues/847\n\nChange-Id: Ie8b10209daa4de74427e175ef21ddf306a17a0ae\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n(cherry picked from commit bf7ac78d07a313651e486196309140517d9ad861)\n""}]",0,692350,d3980909ad460b78f2c0788a37a414238bb2ae66,23,8,3,30442,,,0,"Add binary_prefix=true argument to mysql uri

This patch adds the argument binary_prefix=true to MySQL uri if
OpenStack version is equal or greater than Rocky due to Python
upper-constraints [1]. This argument is required because of PyMySQL's
change from version 0.8 and on [2], in order to fix Gnocchi API
warnings like this [3].

[1] https://github.com/openstack/requirements/blob/stable/rocky/upper-constraints.txt#L377
[2] https://github.com/PyMySQL/PyMySQL/blob/master/CHANGELOG#L61-L64
[3] https://github.com/gnocchixyz/gnocchi/issues/847

Change-Id: Ie8b10209daa4de74427e175ef21ddf306a17a0ae
Signed-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>
(cherry picked from commit bf7ac78d07a313651e486196309140517d9ad861)
",git fetch https://review.opendev.org/openstack/charm-gnocchi refs/changes/50/692350/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/gnocchi.py'],1,fbc8c1e97558be614cc1d036c382d1d7a8a4529b,,"class GnocchiCharmDatabaseRelationAdapter(adapters.DatabaseRelationAdapter): """""" Overrides default class to add binary_prefix option to solve 'Invalid utf8 character' warnings """""" def get_uri(self, prefix=None): uri = super(GnocchiCharmDatabaseRelationAdapter, self).get_uri(prefix) release = ch_utils.get_os_codename_install_source( self.config['openstack-origin']) if (ch_utils.OPENSTACK_RELEASES.index(release) >= ch_utils.OPENSTACK_RELEASES.index('rocky')): if '?' in uri: uri += '&binary_prefix=true' else: uri += '?binary_prefix=true' return uri 'shared_db': GnocchiCharmDatabaseRelationAdapter,"," 'shared_db': adapters.DatabaseRelationAdapter,",20,1
openstack%2Fansible-hardening~stable%2Focata~I72ee5ee865d346124e5591939956bb0a610f59e0,openstack/ansible-hardening,stable/ocata,I72ee5ee865d346124e5591939956bb0a610f59e0,Remove trusty testing,MERGED,2020-01-17 09:55:13.000000000,2020-01-17 14:15:32.000000000,2020-01-17 14:12:55.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-17 09:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/04e031e8c72d2cc321f5432db2497abf22a8fb2b', 'message': 'Remove trusty testing\n\nOpenDev is removing trusty nodes, stop testing on it with removing\na job that used trusty.\n\nChange-Id: I72ee5ee865d346124e5591939956bb0a610f59e0\n'}, {'number': 2, 'created': '2020-01-17 10:27:20.000000000', 'files': ['zuul.d/project.yaml', 'tox.ini', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/48e217792e9c84a72cc965803b20bf35644425fc', 'message': 'Remove trusty testing\n\nOpenDev is removing trusty nodes, stop testing on it with removing\na job that used trusty.\n\nto fix test failures:\n* Use python2 as basepython so that we do not use python3\n\nChange-Id: I72ee5ee865d346124e5591939956bb0a610f59e0\n'}]",0,703048,48e217792e9c84a72cc965803b20bf35644425fc,10,3,2,6547,,,0,"Remove trusty testing

OpenDev is removing trusty nodes, stop testing on it with removing
a job that used trusty.

to fix test failures:
* Use python2 as basepython so that we do not use python3

Change-Id: I72ee5ee865d346124e5591939956bb0a610f59e0
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/48/703048/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,04e031e8c72d2cc321f5432db2497abf22a8fb2b,trusty-removal,, name: openstack-ansible-rhel_6-ubuntu-trusty parent: openstack-ansible-functional nodeset: ubuntu-trusty vars: tox_env: func_rhel6 - job:,0,9
openstack%2Ftripleo-upgrade~stable%2Ftrain~I71b566bd38ab190613f4d934301243065133d562,openstack/tripleo-upgrade,stable/train,I71b566bd38ab190613f4d934301243065133d562,Add --stack option in system upgrade commands.,MERGED,2020-01-15 09:44:56.000000000,2020-01-17 14:05:20.000000000,2020-01-17 13:16:12.000000000,"[{'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 09:44:56.000000000', 'files': ['templates/overcloud_system_upgrade.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/5d864384291428d20b24fd2c3dbc458e56ea346b', 'message': ""Add --stack option in system upgrade commands.\n\nNow that most of our CI jobs have a customized stack name,\nwe need to pass it in the system upgrade steps. Otherwise\nthe upgrade will fail as it can't locate the stack.\n\nChange-Id: I71b566bd38ab190613f4d934301243065133d562\n(cherry picked from commit 596254e5d8ff7e170803169d5796f392354b9faa)\n""}]",0,702615,5d864384291428d20b24fd2c3dbc458e56ea346b,9,6,1,26343,,,0,"Add --stack option in system upgrade commands.

Now that most of our CI jobs have a customized stack name,
we need to pass it in the system upgrade steps. Otherwise
the upgrade will fail as it can't locate the stack.

Change-Id: I71b566bd38ab190613f4d934301243065133d562
(cherry picked from commit 596254e5d8ff7e170803169d5796f392354b9faa)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/15/702615/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/overcloud_system_upgrade.sh.j2'],1,5d864384291428d20b24fd2c3dbc458e56ea346b,, --stack {{ overcloud_stack_name }} \ --stack {{ overcloud_stack_name }} \ --stack {{ overcloud_stack_name }} \ --stack {{ overcloud_stack_name }} \,,4,0
openstack%2Fopenstack-ansible-ops~stable%2Fstein~Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8,openstack/openstack-ansible-ops,stable/stein,Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8,Remove trusty job,MERGED,2020-01-16 17:33:08.000000000,2020-01-17 14:04:45.000000000,2020-01-17 14:01:59.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-16 17:33:08.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/505a82d2119c02b5846b1318d7afb53a7308d13c', 'message': 'Remove trusty job\n\nUbuntu Trusty is getting removed from OpenDev Infrastructure, remove the\nnon-voting trusty job.\n\nChange-Id: Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8\n(cherry picked from commit 77cd091b6d0aea58f4a840e1730ea7b435318e47)\n'}]",0,702936,505a82d2119c02b5846b1318d7afb53a7308d13c,9,3,1,6547,,,0,"Remove trusty job

Ubuntu Trusty is getting removed from OpenDev Infrastructure, remove the
non-voting trusty job.

Change-Id: Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8
(cherry picked from commit 77cd091b6d0aea58f4a840e1730ea7b435318e47)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/36/702936/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,505a82d2119c02b5846b1318d7afb53a7308d13c,trusty-removal,," name: ""openstack-ansible-ops:elk_metrics_6x-ubuntu-trusty"" parent: ""openstack-ansible-ops:elk_metrics_6x-ubuntu-xenial"" nodeset: ubuntu-trusty voting: false - job:",0,7
openstack%2Ftripleo-upgrade~stable%2Ftrain~I864f3f2ca90416f567f94bff34a34bdbcea9237e,openstack/tripleo-upgrade,stable/train,I864f3f2ca90416f567f94bff34a34bdbcea9237e,Run upgrade for previous hosts only in Controller role.,MERGED,2020-01-15 09:51:26.000000000,2020-01-17 14:04:20.000000000,2020-01-17 13:28:53.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-15 09:51:26.000000000', 'files': ['templates/overcloud_upgrade_run.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/254015b750c84273fee6df4288b072e5528ce8c3', 'message': 'Run upgrade for previous hosts only in Controller role.\n\nThe upgrade from Rocky to Stein is quite special as it\nneeds to handle the OS upgrade. In the case of the Controllers\nwe create progressively a new cluster with the upgraded nodes.\nTherefore we need to pass the already upgraded nodes everytime\nwe upgrade one (pass controller-0 and controller-1 when running\nthe upgrade of controller-1). However, this is not needed for\nany other role and the current logic was implementing it for\nall. The result was that we were running the upgrade of the\nfirst compute twice (first compute-0 upgrade and second time when\nrunning upgrade for compute-0 and compute-1).\n\nThis patch limits the HA dance only to the Controller role.\n\nChange-Id: I864f3f2ca90416f567f94bff34a34bdbcea9237e\n(cherry picked from commit 9ad387cb783409c7ccc0e08e25b005d43081d6ab)\n'}]",0,702617,254015b750c84273fee6df4288b072e5528ce8c3,9,7,1,26343,,,0,"Run upgrade for previous hosts only in Controller role.

The upgrade from Rocky to Stein is quite special as it
needs to handle the OS upgrade. In the case of the Controllers
we create progressively a new cluster with the upgraded nodes.
Therefore we need to pass the already upgraded nodes everytime
we upgrade one (pass controller-0 and controller-1 when running
the upgrade of controller-1). However, this is not needed for
any other role and the current logic was implementing it for
all. The result was that we were running the upgrade of the
first compute twice (first compute-0 upgrade and second time when
running upgrade for compute-0 and compute-1).

This patch limits the HA dance only to the Controller role.

Change-Id: I864f3f2ca90416f567f94bff34a34bdbcea9237e
(cherry picked from commit 9ad387cb783409c7ccc0e08e25b005d43081d6ab)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/17/702617/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/overcloud_upgrade_run.sh.j2'],1,254015b750c84273fee6df4288b072e5528ce8c3,,"otherwise we upgrade item.{% if role == ""Controller"" %}{% else %} {% set elements = [item] %} {% endif %}",,5,0
openstack%2Fhorizon~stable%2Frocky~I10a6eeb96dd1418449e1d15b1a3869cd4de9cafa,openstack/horizon,stable/rocky,I10a6eeb96dd1418449e1d15b1a3869cd4de9cafa,Avoid forced logout when 403 error encountered,MERGED,2019-09-12 18:16:11.000000000,2020-01-17 13:52:26.000000000,2019-10-01 06:57:29.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 6825}, {'_account_id': 11880}, {'_account_id': 12156}, {'_account_id': 14892}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 27861}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-09-12 18:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/08ae5d76e19ca76d277943b532d7a94dc9ddcce3', 'message': 'Avoid forced logout when 403 error encountered\n\nBefore this change when a 403 error was encountered, such as failure to\nhave the permission to perform an operation, the user would get logged\nout from UI pages written in the AngularJS framework. For example, if an\nadmin user lacks the get_project permission and tries to access the\nimages page, project->compute->images, the 403 will forcibly log out\nthe user.\n\nThis change keeps the user logged in when a 403 error is encountered and\ndisplays an error message. The change only affects AngularJS pages.\n\nChange-Id: I10a6eeb96dd1418449e1d15b1a3869cd4de9cafa\nCloses-bug: #1840844\n'}, {'number': 2, 'created': '2019-09-14 03:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d4bf57ccb5e3d61bb7bfd74a70984ca43eb9713a', 'message': 'Avoid forced logout when 403 error encountered\n\nBefore this change when a 403 error was encountered, such as failure to\nhave the permission to perform an operation, the user would get logged\nout from UI pages written in the AngularJS framework. For example, if an\nadmin user lacks the get_project permission and tries to access the\nimages page, project->compute->images, the 403 will forcibly log out\nthe user.\n\nThis change keeps the user logged in when a 403 error is encountered and\ndisplays an error message. The change only affects AngularJS pages.\n\nChange-Id: I10a6eeb96dd1418449e1d15b1a3869cd4de9cafa\nCloses-bug: #1840844\n'}, {'number': 3, 'created': '2019-09-25 18:55:28.000000000', 'files': ['horizon/static/framework/framework.module.js', 'horizon/static/framework/widgets/wizard/wizard.controller.js', 'horizon/static/framework/widgets/wizard/wizard.controller.spec.js', 'horizon/static/framework/framework.module.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/81740d310f7078a10435ecbeb3e7a31bc62c7497', 'message': 'Avoid forced logout when 403 error encountered\n\nBefore this change when a 403 error was encountered, such as failure to\nhave the permission to perform an operation, the user would get logged\nout from UI pages written in the AngularJS framework. For example, if an\nadmin user lacks the get_project permission and tries to access the\nimages page, project->compute->images, the 403 will forcibly log out\nthe user.\n\nThis change keeps the user logged in when a 403 error is encountered and\ndisplays an error message. The change only affects AngularJS pages.\n\nChange-Id: I10a6eeb96dd1418449e1d15b1a3869cd4de9cafa\nCloses-bug: #1840844\n(cherry picked from commit ab0e96df9506fb6f1783e0ee79b63934dabe0cbe)\n'}]",0,681868,81740d310f7078a10435ecbeb3e7a31bc62c7497,28,10,3,11880,,,0,"Avoid forced logout when 403 error encountered

Before this change when a 403 error was encountered, such as failure to
have the permission to perform an operation, the user would get logged
out from UI pages written in the AngularJS framework. For example, if an
admin user lacks the get_project permission and tries to access the
images page, project->compute->images, the 403 will forcibly log out
the user.

This change keeps the user logged in when a 403 error is encountered and
displays an error message. The change only affects AngularJS pages.

Change-Id: I10a6eeb96dd1418449e1d15b1a3869cd4de9cafa
Closes-bug: #1840844
(cherry picked from commit ab0e96df9506fb6f1783e0ee79b63934dabe0cbe)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/68/681868/3 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/framework.module.js', 'horizon/static/framework/widgets/wizard/wizard.controller.js', 'horizon/static/framework/widgets/wizard/wizard.controller.spec.js', 'horizon/static/framework/framework.module.spec.js']",4,08ae5d76e19ca76d277943b532d7a94dc9ddcce3,rocky_nologout," it('should add a forbidden toast message ', inject("," it('should redirect to /auth/logout and add a forbidden toast message ', inject( expect($window.location.replace).toHaveBeenCalledWith('/dashboard/auth/logout');",17,15
openstack%2Fkolla~master~I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,openstack/kolla,master,I77fdbcb905b1a7f2d535c3a37b2899118d1442c5,config: make kolla work with oslo.config 7.0.0+,MERGED,2020-01-10 12:20:24.000000000,2020-01-17 13:34:35.000000000,2020-01-10 15:51:17.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-10 12:20:24.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/aaa472bfa257aea53abcb3642ad4beeaed1b99a8', 'message': ""config: make kolla work with oslo.config 7.0.0+\n\nFrom oslo.config 7.0.0 release notes:\n\n> Positional options are now required by default, to match argparses\n> default behavior. To revert this behavior (and maintain optional\n> positional arguments), you need to explicitly specify positional=True,\n> required=False as part of the options definition.\n\nSo let's follow.\n\nChange-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5\n""}]",0,701946,aaa472bfa257aea53abcb3642ad4beeaed1b99a8,15,5,1,24072,,,0,"config: make kolla work with oslo.config 7.0.0+

From oslo.config 7.0.0 release notes:

> Positional options are now required by default, to match argparses
> default behavior. To revert this behavior (and maintain optional
> positional arguments), you need to explicitly specify positional=True,
> required=False as part of the options definition.

So let's follow.

Change-Id: I77fdbcb905b1a7f2d535c3a37b2899118d1442c5
",git fetch https://review.opendev.org/openstack/kolla refs/changes/46/701946/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,aaa472bfa257aea53abcb3642ad4beeaed1b99a8,," cfg.MultiOpt('regex', types.String(), positional=True, required=False,"," cfg.MultiOpt('regex', types.String(), positional=True,",1,1
openstack%2Ftripleo-upgrade~stable%2Ftrain~Id9d50979e747ab5717a05b41fa594459089a150b,openstack/tripleo-upgrade,stable/train,Id9d50979e747ab5717a05b41fa594459089a150b,Move undercloud_os_upgrade.yaml to tasks/common.,MERGED,2020-01-15 09:32:58.000000000,2020-01-17 13:28:53.000000000,2020-01-17 13:28:53.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 09:32:58.000000000', 'files': ['tasks/common/undercloud_os_upgrade.yaml', 'tasks/upgrade/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/5379a3651f400d9fed4a4d3228da21c4a813723b', 'message': ""Move undercloud_os_upgrade.yaml to tasks/common.\n\nIn FFWD2 an upgrade of the Undercloud's operating system will\nbe also needed. So let's move the playbook into tasks/common\nso we can leverage from the existing code when implementing\nthe undercloud upgrade in FFWD2.\n\nChange-Id: Id9d50979e747ab5717a05b41fa594459089a150b\n(cherry picked from commit 4a6ccae840f99f4e5367935ce536dc64b3f1e13b)\n""}]",0,702606,5379a3651f400d9fed4a4d3228da21c4a813723b,6,5,1,26343,,,0,"Move undercloud_os_upgrade.yaml to tasks/common.

In FFWD2 an upgrade of the Undercloud's operating system will
be also needed. So let's move the playbook into tasks/common
so we can leverage from the existing code when implementing
the undercloud upgrade in FFWD2.

Change-Id: Id9d50979e747ab5717a05b41fa594459089a150b
(cherry picked from commit 4a6ccae840f99f4e5367935ce536dc64b3f1e13b)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/06/702606/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/common/undercloud_os_upgrade.yaml', 'tasks/upgrade/main.yml']",2,5379a3651f400d9fed4a4d3228da21c4a813723b,, import_tasks: ../common/undercloud_os_upgrade.yaml, import_tasks: undercloud_os_upgrade.yaml,2,2
openstack%2Fmonasca-agent~stable%2Frocky~If779ebad11926594961577e0744093a8ba691610,openstack/monasca-agent,stable/rocky,If779ebad11926594961577e0744093a8ba691610,Update hacking version to 1.1.x,MERGED,2020-01-16 19:20:24.000000000,2020-01-17 13:15:01.000000000,2020-01-17 13:15:01.000000000,"[{'_account_id': 10311}, {'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 25553}]","[{'number': 1, 'created': '2020-01-16 19:20:24.000000000', 'files': ['monasca_setup/detection/plugins/influxdb.py', 'test-requirements.txt', 'monasca_agent/collector/checks/collector.py', 'monasca_setup/detection/plugins/influxdb_relay.py', 'monasca_setup/detection/plugins/ovs.py', 'monasca_agent/collector/checks_d/lxc.py', 'monasca_setup/detection/plugins/vcenter.py', 'monasca_agent/collector/checks/utils.py', 'monasca_agent/collector/checks_d/disk.py', 'monasca_agent/forwarder/daemon.py', 'monasca_agent/common/util.py', 'monasca_setup/detection/plugins/kafka_consumer.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/2c7abb09dbadb1986886498dc23c9378ee127395', 'message': 'Update hacking version to 1.1.x\n\nThis commit updates hacking version in test-requirements\nand fixes some related pep8 issues\n\nAlso ignores false positive bandit test\nB105: hardcoded_password_string,\nB106: hardcoded_password_funcarg\nbased on variable or argument names.\nFor more info refer [1][2]\n\n[1] https://bandit.readthedocs.io/en/latest/plugins/b105_hardcoded_password_string.html\n[2] https://bandit.readthedocs.io/en/latest/plugins/b106_hardcoded_password_funcarg.html\n\nChange-Id: If779ebad11926594961577e0744093a8ba691610\nStory: 2004930\nTask: 29314\n(cherry picked from commit 3404a6df722b8f85c425d15769a0e831891cdc2c)\n'}]",0,702964,2c7abb09dbadb1986886498dc23c9378ee127395,7,4,1,1916,,,0,"Update hacking version to 1.1.x

This commit updates hacking version in test-requirements
and fixes some related pep8 issues

Also ignores false positive bandit test
B105: hardcoded_password_string,
B106: hardcoded_password_funcarg
based on variable or argument names.
For more info refer [1][2]

[1] https://bandit.readthedocs.io/en/latest/plugins/b105_hardcoded_password_string.html
[2] https://bandit.readthedocs.io/en/latest/plugins/b106_hardcoded_password_funcarg.html

Change-Id: If779ebad11926594961577e0744093a8ba691610
Story: 2004930
Task: 29314
(cherry picked from commit 3404a6df722b8f85c425d15769a0e831891cdc2c)
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/64/702964/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_setup/detection/plugins/influxdb.py', 'test-requirements.txt', 'monasca_agent/collector/checks/collector.py', 'monasca_setup/detection/plugins/influxdb_relay.py', 'monasca_setup/detection/plugins/ovs.py', 'monasca_agent/collector/checks_d/lxc.py', 'monasca_setup/detection/plugins/vcenter.py', 'monasca_agent/collector/checks/utils.py', 'monasca_agent/collector/checks_d/disk.py', 'monasca_agent/forwarder/daemon.py', 'monasca_agent/common/util.py', 'monasca_setup/detection/plugins/kafka_consumer.py', 'tox.ini']",13,2c7abb09dbadb1986886498dc23c9378ee127395,,"# E402 module level import not at top of file # reason: there are numerous places where we import modules # later for legitimate reasons # C901 MongoDb.check function in monasca_agent/collector/checks_d/mongo.py # is too complex. Need to be simplified with less if, for loops and then # C901 can be removed from here. ignore = C901,E402,H405",ignore = H405,31,25
openstack%2Fmistral~master~Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6,openstack/mistral,master,Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6,Add 'interface' field to Workflow resource,MERGED,2020-01-09 10:32:25.000000000,2020-01-17 12:30:25.000000000,2020-01-17 12:27:16.000000000,"[{'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 29124}, {'_account_id': 30755}]","[{'number': 1, 'created': '2020-01-09 10:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f126bb4f2fdb2f2aba41b5234d5f038e781760df', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 2, 'created': '2020-01-09 10:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9bd99ab02a7e6fed577eec381ae080ff1d80639e', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 3, 'created': '2020-01-09 11:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ac81cb11a8229a212c19251895a50a05f15ada97', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 4, 'created': '2020-01-09 11:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c79ee0d7bb683d4ad47215bf7fb68629f10b21b5', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 5, 'created': '2020-01-12 10:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5ad5150f53ce3b12933800e4f16582bc4ec91399', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 6, 'created': '2020-01-12 14:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6a8f858f93e91046a83d54c7ef02255aa6486edc', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 7, 'created': '2020-01-14 07:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/26b5c2cb5870b6bccdd6b4d5f85a7029151b8b97', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 8, 'created': '2020-01-15 10:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e8ed76cdfb411955721df57ecf4ee859138dceeb', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 9, 'created': '2020-01-16 06:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d05f5cb5f9713a192575b12d894d7e1e8a1ee541', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 10, 'created': '2020-01-16 11:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6c43fecac5a622e883453dec7cdddcc601af92d4', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 11, 'created': '2020-01-16 11:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e79d7c92d9572d285335c47d2be01abdb00b45f3', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 12, 'created': '2020-01-16 11:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/34cd98e209719dee44dc033ce3954bb1a6b098ad', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 13, 'created': '2020-01-16 12:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/23190774707e8feda60f8e1b94a5b7bd9a3974b6', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 14, 'created': '2020-01-16 12:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/4ffc254b24afe1a2ec01a9741b1ce17a4289c87b', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 15, 'created': '2020-01-16 12:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fc086b7122b5af6ab99d47a34da6c59d4e26ec06', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}, {'number': 16, 'created': '2020-01-16 14:13:49.000000000', 'files': ['mistral/tests/unit/policies/test_workflows.py', 'mistral/api/controllers/v2/resources.py', 'mistral/tests/unit/api/v2/test_keycloak_auth.py', 'mistral/tests/unit/api/v2/test_workflows.py', 'mistral/tests/unit/api/test_resource_base.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/504243bcef5482d450c8ebec75c0e42292a01e46', 'message': 'Add \'interface\' field to Workflow resource\n\n* Workflow resource(returned by workflow-get APIs) has a new JSON field\n called \'interface\', it contains the inputs and the outputs.\n\n  -Both input and output are lists.\n  -The output list contains the output param names.\n  -The input list contains the inputs, if the input has a default value,\n   the entry in the list will be a JSON object, with the name of the\n   input and the default value, otherwise its the input param name.\n\n   For example:\n     {""input"": [ ""input_with_no_default_value"",\n   { ""string_input"": ""some_string"" },\n   {""json_input"": {\n     ""defaultKey"": ""defaultValue""\n    }}],\n     ""output"":[""output1"",""output2""]}\n\nChange-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6\nImplements: blueprint mistral-workflow-outputs-in-wf-apis\nSigned-off-by: ali <ali.abdelal@nokia.com>\n'}]",21,701703,504243bcef5482d450c8ebec75c0e42292a01e46,51,6,16,30755,,,0,"Add 'interface' field to Workflow resource

* Workflow resource(returned by workflow-get APIs) has a new JSON field
 called 'interface', it contains the inputs and the outputs.

  -Both input and output are lists.
  -The output list contains the output param names.
  -The input list contains the inputs, if the input has a default value,
   the entry in the list will be a JSON object, with the name of the
   input and the default value, otherwise its the input param name.

   For example:
     {""input"": [ ""input_with_no_default_value"",
   { ""string_input"": ""some_string"" },
   {""json_input"": {
     ""defaultKey"": ""defaultValue""
    }}],
     ""output"":[""output1"",""output2""]}

Change-Id: Id9be6c1d9bbe4a4c965530364833e71f8b7cacc6
Implements: blueprint mistral-workflow-outputs-in-wf-apis
Signed-off-by: ali <ali.abdelal@nokia.com>
",git fetch https://review.opendev.org/openstack/mistral refs/changes/03/701703/16 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/api/controllers/v2/resources.py', 'mistral/tests/unit/api/test_resource_base.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py']",3,f126bb4f2fdb2f2aba41b5234d5f038e781760df,bp/mistral-workflow-outputs-in-wf-apis, def test_filter_workflow_definition_by_not_equal_value(self):, def test_filter_workflow_definition_by_not_equal_valiue(self):,87,5
openstack%2Fheat-tempest-plugin~master~I8504db7c6f416959a1d6dd3ed0734c3e6b94a1f5,openstack/heat-tempest-plugin,master,I8504db7c6f416959a1d6dd3ed0734c3e6b94a1f5,Skip tests when neutron extension trunk is absent,ABANDONED,2018-02-21 16:22:44.000000000,2020-01-17 11:13:02.000000000,,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 22636}]","[{'number': 1, 'created': '2018-02-21 16:22:44.000000000', 'files': ['heat_tempest_plugin/tests/functional/test_create_update_neutron_trunk.py'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/2ca6d61ec9990370a28e98ebda74f43234744901', 'message': ""Skip tests when neutron extension trunk is absent\n\nWe need to skip tests if some feature doesn't exist on environment. These tests are failing now:\nheat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_add_a_second_sub_port\nheat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_add_first_sub_port\nheat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_remove_last_sub_port_from_trunk\nheat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_remove_sub_port_from_trunk\nheat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_update_existing_sub_port_on_trunk\nheat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_update_trunk_name_and_description\n\nChange-Id: I8504db7c6f416959a1d6dd3ed0734c3e6b94a1f5\n""}]",5,546685,2ca6d61ec9990370a28e98ebda74f43234744901,15,6,1,20675,,,0,"Skip tests when neutron extension trunk is absent

We need to skip tests if some feature doesn't exist on environment. These tests are failing now:
heat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_add_a_second_sub_port
heat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_add_first_sub_port
heat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_remove_last_sub_port_from_trunk
heat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_remove_sub_port_from_trunk
heat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_update_existing_sub_port_on_trunk
heat_tempest_plugin.tests.functional.test_create_update_neutron_trunk.UpdateTrunkTest.test_update_trunk_name_and_description

Change-Id: I8504db7c6f416959a1d6dd3ed0734c3e6b94a1f5
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/85/546685/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_tempest_plugin/tests/functional/test_create_update_neutron_trunk.py'],1,2ca6d61ec9990370a28e98ebda74f43234744901,,"from tempest.common import utils @utils.requires_ext(extension=""trunk"", service=""network"") @utils.requires_ext(extension=""trunk"", service=""network"") @utils.requires_ext(extension=""trunk"", service=""network"") @utils.requires_ext(extension=""trunk"", service=""network"") @utils.requires_ext(extension=""trunk"", service=""network"") @utils.requires_ext(extension=""trunk"", service=""network"")",,7,0
openstack%2Fneutron~stable%2Fstein~I99074444a5ce20f13ff58416b8f45f43f8946256,openstack/neutron,stable/stein,I99074444a5ce20f13ff58416b8f45f43f8946256,Imported Translations from Zanata,MERGED,2020-01-02 07:19:55.000000000,2020-01-17 11:08:58.000000000,2020-01-17 11:05:35.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-02 07:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9065d0647abdc3fd39f9da0debda14ed0685ae59', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I99074444a5ce20f13ff58416b8f45f43f8946256\n'}, {'number': 2, 'created': '2020-01-10 09:16:31.000000000', 'files': ['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d08d3042ca819bcb9b6fb50dc412f0e46583550f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I99074444a5ce20f13ff58416b8f45f43f8946256\n'}]",0,700870,d08d3042ca819bcb9b6fb50dc412f0e46583550f,13,4,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I99074444a5ce20f13ff58416b8f45f43f8946256
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/700870/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po']",14,9065d0647abdc3fd39f9da0debda14ed0685ae59,zanata/translations,"""POT-Creation-Date: 2019-12-20 12:47+0000\n""","""POT-Creation-Date: 2018-03-02 16:32+0000\n""msgid ""%(id)s is not a valid %(type)s identifier"" msgstr ""%(id)s     %(type)s"" #, python-formatmsgid ""%s is not a valid VLAN tag"" msgstr ""%s     VLAN"" #, python-formatmsgid ""API for retrieving service providers for Neutron advanced services"" msgstr ""API        Neutron"" msgid ""Aborting periodic_sync_routers_task due to an error."" msgstr "" periodic_sync_routers_task  - ."" #, python-format msgid ""Agent %(id)s is not a valid DHCP Agent or has been disabled"" msgstr "" %(id)s       DHCP"" msgid ""An interface driver must be specified"" msgstr ""   "" msgid ""Both network_id and router_id are None. One must be provided."" msgstr """" "" network_id,  router_id   None.     "" "" ."" #, python-format msgid ""Bridge %(bridge)s does not exist."" msgstr "" %(bridge)s  ."" msgid ""Cannot mix IPv4 and IPv6 prefixes in a subnet pool."" msgstr ""   IPv4  IPv6   ."" #, python-format msgid """" ""Change would make usage less than 0 for the following resources: %(unders)s."" msgstr """" ""        0   "" "": %(unders)s."" #, python-format msgid """" ""Current gateway ip %(ip_address)s already in use by port %(port_id)s. Unable "" ""to update."" msgstr """" "" ip-  %(ip_address)s    %(port_id)s. "" "" ."" #, python-format msgid ""Device name %(dev_name)s is missing from physical_device_mappings"" msgstr ""  %(dev_name)s    physical_device_mappings"" msgid ""Duplicate segment entry in request."" msgstr ""    ."" msgid ""Empty physical network name."" msgstr ""   ."" msgid ""Empty subnet pool prefix list."" msgstr ""    ."" msgid ""End of VLAN range is less than start of VLAN range"" msgstr ""   VLAN    "" msgid ""End of tunnel range is less than start of tunnel range"" msgstr ""       "" msgid ""Extensions not found: %(extensions)s."" msgstr ""  : %(extensions)s."" #, python-formatmsgid ""Failed to allocate subnet: %(reason)s."" msgstr ""   : %(reason)s."" msgid """" ""Failed to associate address scope: subnetpools within an address scope must "" ""have unique prefixes."" msgstr """" ""    :       "" ""  ."" #, python-format#, python-format msgid ""Found duplicate extension: %(alias)s."" msgstr ""  : %(alias)s."" #, python-format msgid """" ""Found overlapping allocation pools: %(pool_1)s %(pool_2)s for subnet "" ""%(subnet_cidr)s."" msgstr """" ""    %(pool_1)s %(pool_2)s   "" ""%(subnet_cidr)s."" #, python-format msgid ""Gateway ip %(ip_address)s conflicts with allocation pool %(pool)s."" msgstr ""IP-  %(ip_address)s     %(pool)s."" msgid ""IPtables conntrack zones exhausted, iptables rules cannot be applied."" msgstr """" ""    IPtables conntrack ,  "" ""iptables    ."" #, python-format msgid """" ""Illegal prefix bounds: %(prefix_type)s=%(prefixlen)s, %(base_prefix_type)s="" ""%(base_prefixlen)s."" msgstr """" ""  : %(prefix_type)s=%(prefixlen)s, "" ""%(base_prefix_type)s=%(base_prefixlen)s."" #, python-format msgid """" ""Illegal subnetpool association: subnetpool %(subnetpool_id)s cannot "" ""associate with address scope %(address_scope_id)s because subnetpool "" ""ip_version is not %(ip_version)s."" msgstr """" ""   :   %(subnetpool_id)s   "" ""     %(address_scope_id)s,  ip_version "" ""     %(ip_version)s."" #, python-format msgid """" ""Illegal subnetpool association: subnetpool %(subnetpool_id)s cannot be "" ""associated with address scope %(address_scope_id)s."" msgstr """" ""   :   %(subnetpool_id)s   "" ""     %(address_scope_id)s."" #, python-format msgid ""Illegal subnetpool update : %(reason)s."" msgstr ""   : %(reason)s."" #, python-format msgid ""Illegal update to prefixes: %(msg)s."" msgstr ""  : %(msg)s."" msgid ""Invalid CIDR %(input)s given as IP prefix."" msgstr ""  CIDR %(input)s   IP-."" #, python-formatmsgid ""Invalid network VLAN range: '%(vlan_range)s' - '%(error)s'."" msgstr ""  VLAN : '%(vlan_range)s' - '%(error)s'."" #, python-format msgid ""Invalid network VXLAN port range: '%(vxlan_range)s'."" msgstr ""    VXLAN: '%(vxlan_range)s'."" #, python-formatmsgid ""Location to store keepalived/conntrackd config files"" msgstr ""     keepalived/conntrackd"" #, python-format msgid ""Malformed request body: %(reason)s."" msgstr ""   : %(reason)s."" msgid ""Multiple plugins for service %s were configured"" msgstr ""  %s   "" #, python-formatmsgid ""Network types supported by the agent (gre and/or vxlan)."" msgstr "" ,   (gre  vxlan)."" msgid ""Neutron Service Type Management"" msgstr ""   Neutron"" ""Number of separate API worker processes for service. If not specified, the "" ""default is equal to the number of CPUs available for best performance."" msgstr """" ""    API  .   ,  "" ""         "" ""."" msgid """"#, python-format msgid ""Object action %(action)s failed because: %(reason)s."" msgstr ""  %(action)s  , : %(reason)s."" msgid """" ""Operation %(op)s is not supported for device_owner %(device_owner)s on port "" ""%(port_id)s."" msgstr """" "" %(op)s    device_owner %(device_owner)s, : "" ""%(port_id)s."" #, python-formatmsgid ""Per-tenant subnet pool prefix quota exceeded."" msgstr ""     ."" msgid ""Plugin does not support updating provider attributes"" msgstr ""     "" msgid ""Port %(port_id)s is already acquired by another DHCP agent"" msgstr "" %(port_id)s     DHCP. "" #, python-format#, python-format msgid ""Prefix '%(prefix)s' not supported in IPv%(version)s pool."" msgstr "" %(prefix)s     IPv%(version)s."" msgid ""QoS Policy %(policy_id)s is used by %(object_type)s %(object_id)s."" msgstr """" "" QoS %(policy_id)s  %(object_type)s %(object_id)s."" #, python-format msgid """" ""QoS binding for network %(net_id)s and policy %(policy_id)s could not be "" ""found."" msgstr """" ""   QoS   %(net_id)s   %(policy_id)s."" #, python-format msgid """" ""QoS binding for port %(port_id)s and policy %(policy_id)s could not be found."" msgstr """" ""   QoS   %(port_id)s   %(policy_id)s."" #, python-format msgid ""QoS policy %(policy_id)s could not be found."" msgstr ""   QoS %(policy_id)s."" #, python-format msgid ""QoS rule %(rule_id)s for policy %(policy_id)s could not be found."" msgstr ""   QoS %(rule_id)s   %(policy_id)s."" #, python-format""Received type '%(type)s' and value '%(value)s'. Expecting netaddr.EUI type."" msgstr """" "":  '%(type)s',  '%(value)s'.   netaddr.EUI."" #, python-format msgid """" ""Received type '%(type)s' and value '%(value)s'. Expecting netaddr.IPAddress "" ""type."" msgstr """" "":  '%(type)s',  '%(value)s'.   netaddr."" ""IPAddress."" #, python-format msgid """" ""Received type '%(type)s' and value '%(value)s'. Expecting netaddr.IPNetwork "" ""type."" msgstr """" "":  '%(type)s',  '%(value)s'.   netaddr."" ""IPNetwork."" #, python-format msgid """"msgid ""Router '%(router_id)s' is not compatible with this agent."" msgstr "" '%(router_id)s'    ."" #, python-formatmsgid ""Segments and provider values cannot both be set."" msgstr ""      ."" #, python-format msgid ""Subnet pool %(subnetpool_id)s could not be found."" msgstr ""    %(subnetpool_id)s."" ""Subnets hosted on the same network must be allocated from the same subnet "" ""pool."" msgstr """" ""            ."" msgid """"msgid ""Tenant network creation is not enabled."" msgstr ""    ."" msgid ""Tenant-id was missing from quota request."" msgstr ""     ."" msgid """" ""The 'gateway_external_network_id' option must be configured for this agent "" ""as Neutron has more than one external network."" msgstr """" ""      'gateway_external_network_id', "" ""  Neutron    ."" msgid """" ""The DHCP agent will resync its state with Neutron to recover from any "" ""transient notification or RPC errors. The interval is number of seconds "" ""between attempts."" msgstr """" "" DHCP       Neutron  "" ""    RPC.     "" "" ."" #, python-format msgid ""The allocation pool %(pool)s is not valid."" msgstr ""  %(pool)s ."" #, python-format msgid """" ""The allocation pool %(pool)s spans beyond the subnet cidr %(subnet_cidr)s."" msgstr """" ""  %(pool)s    cidr  %(subnet_cidr)s."" #, python-format msgid """" ""The following device_id %(device_id)s is not owned by your tenant or matches "" ""another tenants router."" msgstr """" "" device_id %(device_id)s      "" ""   ."" msgid ""The interface for interacting with the OVSDB"" msgstr ""    OVSDB"" #, python-format msgid """" ""The network %(network_id)s has been already hosted by the DHCP Agent "" ""%(agent_id)s."" msgstr "" %(network_id)s     DHCP %(agent_id)s."" #, python-format msgid """" ""The network %(network_id)s is not hosted by the DHCP agent %(agent_id)s."" msgstr "" %(network_id)s    DHCP %(agent_id)s."" ""Too long prefix provided. New name would exceed given length for an "" ""interface name."" msgstr """" ""  .         "" ""."" msgid """"msgid """" ""Unable to allocate subnet with prefix length %(prefixlen)s, maximum allowed "" ""prefix is %(max_prefixlen)s."" msgstr """" ""      %(prefixlen)s,  "" ""  - %(max_prefixlen)s."" #, python-format msgid """" ""Unable to allocate subnet with prefix length %(prefixlen)s, minimum allowed "" ""prefix is %(min_prefixlen)s."" msgstr """" ""      %(prefixlen)s,  "" ""  - %(min_prefixlen)s."" #, python-formatmsgid """" ""Unable to complete operation for %(subnet_id)s. The number of DNS "" ""nameservers exceeds the limit %(quota)s."" msgstr """" ""    %(subnet_id)s.    DNS "" ""   %(quota)s."" #, python-format msgid """" ""Unable to complete operation for %(subnet_id)s. The number of host routes "" ""exceeds the limit %(quota)s."" msgstr """" ""    %(subnet_id)s.    "" ""   %(quota)s."" #, python-formatmsgid ""Unable to create the Agent Gateway Port"" msgstr ""     "" msgid """" ""Unable to create the flat network. Physical network %(physical_network)s is "" ""in use."" msgstr """" ""   .   %(physical_network)s "" ""."" msgid """" ""Unable to create the network. No available network found in maximum allowed "" ""attempts."" msgstr """" ""   .        "" ""."" #, python-format msgid ""Unable to delete subnet pool: %(reason)s."" msgstr ""   : %(reason)s."" #, python-formatmsgid ""Unable to generate unique mac on network %(net_id)s."" msgstr ""   mac   %(net_id)s."" #, python-format""Unable to reconfigure sharing settings for network %(network)s. Multiple "" ""tenants are using it."" msgstr """" ""        %(network)s.  "" ""  ."" #, python-format msgid """"#, python-format msgid ""Unknown quota resources %(unknown)s."" msgstr ""  : %(unknown)s."" #, python-format msgid ""Unrecognized attribute(s) '%s'"" msgstr ""  '%s'"" #, python-format msgid ""Unsupported port state: %(port_state)s."" msgstr ""  : %(port_state)s."" msgid ""VXLAN network unsupported."" msgstr "" VXLAN  ."" ""When external_network_bridge is set, each L3 agent can be associated with no "" ""more than one external network. This value should be set to the UUID of that "" ""external network. To allow L3 agent support multiple external networks, both "" ""the external_network_bridge and gateway_external_network_id must be left "" ""empty."" msgstr """" ""   external_network_bridge,    L3   "" ""       .    UUID "" ""  .     L3    "" "",  , external_network_bridge  gateway_external_network_id, "" ""  ."" msgid """"",21,4912
openstack%2Fhorizon~master~I26a59176be9e9f213128e4945a58b9459334b626,openstack/horizon,master,I26a59176be9e9f213128e4945a58b9459334b626,Remove six usage from openstack_dashboard package,MERGED,2020-01-09 14:49:49.000000000,2020-01-17 10:31:12.000000000,2020-01-17 10:27:48.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-09 14:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/db81db13eff1ae47d963d1f8fd90eba558c5a4d3', 'message': ""Remove six usage from openstack_dashboard package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I26a59176be9e9f213128e4945a58b9459334b626\n""}, {'number': 2, 'created': '2020-01-10 08:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/86c608fedf7d401448e50a7cc119ce07a06c77ef', 'message': ""Remove six usage from openstack_dashboard package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I26a59176be9e9f213128e4945a58b9459334b626\n""}, {'number': 3, 'created': '2020-01-10 10:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9c7629e8b7e2c0bde2243a9c83fc7e8526df78c5', 'message': ""Remove six usage from openstack_dashboard package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I26a59176be9e9f213128e4945a58b9459334b626\n""}, {'number': 4, 'created': '2020-01-10 10:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4acc6fbf024f4c9f89334cf07fc8ea7c228afaec', 'message': ""Remove six usage from openstack_dashboard package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I26a59176be9e9f213128e4945a58b9459334b626\n""}, {'number': 5, 'created': '2020-01-15 10:48:13.000000000', 'files': ['openstack_dashboard/test/integration_tests/regions/forms.py', 'openstack_dashboard/utils/config.py', 'openstack_dashboard/utils/config_types.py', 'openstack_dashboard/test/unit/api/test_keystone.py', 'openstack_dashboard/test/integration_tests/pages/pageobject.py', 'openstack_dashboard/test/unit/api/test_neutron.py', 'openstack_dashboard/contrib/developer/profiler/middleware.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/templatetags/themes.py', 'openstack_dashboard/dashboards/admin/images/views.py', 'openstack_dashboard/dashboards/project/images/images/forms.py', 'openstack_dashboard/api/keystone.py', 'openstack_dashboard/api/glance.py', 'openstack_dashboard/dashboards/admin/volume_types/qos_specs/tables.py', 'openstack_dashboard/dashboards/project/images/images/tests.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/settings/password/tests.py', 'openstack_dashboard/management/commands/horizon.wsgi.template', 'openstack_dashboard/dashboards/project/key_pairs/tests.py', 'openstack_dashboard/dashboards/project/security_groups/tests.py', 'openstack_dashboard/test/test_data/exceptions.py', 'openstack_dashboard/api/rest/glance.py', 'openstack_dashboard/test/integration_tests/pages/navigation.py', 'openstack_dashboard/dashboards/identity/application_credentials/tests.py', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/test/integration_tests/helpers.py', 'openstack_dashboard/contrib/developer/profiler/api.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/security_groups/tables.py', 'openstack_dashboard/management/commands/make_web_conf.py', 'openstack_dashboard/api/rest/swift.py', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/dashboards/project/floating_ips/tests.py', 'openstack_dashboard/test/unit/test_views.py', 'openstack_dashboard/views.py', 'openstack_dashboard/api/rest/json_encoder.py', 'openstack_dashboard/dashboards/project/images/tests.py', 'openstack_dashboard/dashboards/project/instances/forms.py', 'openstack_dashboard/dashboards/admin/metadata_defs/tests.py', 'openstack_dashboard/test/helpers.py', 'openstack_dashboard/dashboards/project/key_pairs/tables.py', 'openstack_dashboard/dashboards/project/instances/utils.py', 'openstack_dashboard/dashboards/project/routers/tests.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'openstack_dashboard/dashboards/project/api_access/tests.py', 'openstack_dashboard/dashboards/project/security_groups/forms.py', 'openstack_dashboard/api/base.py', 'openstack_dashboard/dashboards/admin/group_types/specs/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d870b40583b2b735e43a061110380717929598ed', 'message': ""Remove six usage from openstack_dashboard package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I26a59176be9e9f213128e4945a58b9459334b626\n""}]",13,701743,d870b40583b2b735e43a061110380717929598ed,34,5,5,1736,,,0,"Remove six usage from openstack_dashboard package

We don't support Python 2 anymore so we don't need this
compatibility library.

six.reraise usages are left as is until it'll be moved to some
base lib like oslo.utils to not re-implenent this method in
Horizon.

This patch also removes Python2-specific base test case methods
assertItemsEqual and assertNotRegexpMatches in flavor of new
Python 3 analogues.

Change-Id: I26a59176be9e9f213128e4945a58b9459334b626
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/701743/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/integration_tests/regions/forms.py', 'openstack_dashboard/utils/config.py', 'openstack_dashboard/utils/config_types.py', 'openstack_dashboard/test/unit/api/test_keystone.py', 'openstack_dashboard/test/integration_tests/pages/pageobject.py', 'openstack_dashboard/test/unit/api/test_neutron.py', 'openstack_dashboard/contrib/developer/profiler/middleware.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/templatetags/themes.py', 'openstack_dashboard/dashboards/admin/images/views.py', 'openstack_dashboard/dashboards/project/images/images/forms.py', 'openstack_dashboard/api/keystone.py', 'openstack_dashboard/api/glance.py', 'openstack_dashboard/dashboards/admin/volume_types/qos_specs/tables.py', 'openstack_dashboard/dashboards/project/images/images/tests.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/settings/password/tests.py', 'openstack_dashboard/management/commands/horizon.wsgi.template', 'openstack_dashboard/dashboards/project/key_pairs/tests.py', 'openstack_dashboard/dashboards/project/security_groups/tests.py', 'openstack_dashboard/test/test_data/exceptions.py', 'openstack_dashboard/api/rest/glance.py', 'openstack_dashboard/test/integration_tests/pages/navigation.py', 'openstack_dashboard/dashboards/identity/application_credentials/tests.py', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/test/integration_tests/helpers.py', 'openstack_dashboard/contrib/developer/profiler/api.py', 'openstack_dashboard/dashboards/project/instances/workflows/create_instance.py', 'openstack_dashboard/dashboards/project/security_groups/tables.py', 'openstack_dashboard/management/commands/make_web_conf.py', 'openstack_dashboard/api/rest/swift.py', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/dashboards/project/floating_ips/tests.py', 'openstack_dashboard/test/unit/test_views.py', 'openstack_dashboard/views.py', 'openstack_dashboard/api/rest/json_encoder.py', 'openstack_dashboard/dashboards/project/images/tests.py', 'openstack_dashboard/dashboards/project/instances/forms.py', 'openstack_dashboard/dashboards/admin/metadata_defs/tests.py', 'openstack_dashboard/test/helpers.py', 'openstack_dashboard/dashboards/project/key_pairs/tables.py', 'openstack_dashboard/dashboards/project/instances/utils.py', 'openstack_dashboard/dashboards/project/routers/tests.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'openstack_dashboard/dashboards/project/api_access/tests.py', 'openstack_dashboard/dashboards/project/security_groups/forms.py', 'openstack_dashboard/api/base.py', 'openstack_dashboard/dashboards/admin/group_types/specs/tables.py']",48,db81db13eff1ae47d963d1f8fd90eba558c5a4d3,remove-six,from urllib import parse ,from six.moves.urllib import parse,104,207
openstack%2Freleases~master~I0c3828d47fa3869f43b921b91a0a6a47ec18f51b,openstack/releases,master,I0c3828d47fa3869f43b921b91a0a6a47ec18f51b,Change mistral-dashboard to a separate deliverable,MERGED,2020-01-16 17:09:17.000000000,2020-01-17 10:18:17.000000000,2020-01-17 10:18:17.000000000,"[{'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 17:09:17.000000000', 'files': ['deliverables/ussuri/mistral-dashboard.yaml', 'deliverables/ussuri/mistral.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/faf5678b951c8986b5bb4876672cab5b0909c84a', 'message': 'Change mistral-dashboard to a separate deliverable\n\nmistral-dashboard is now a separate deliverable in the\ngovernance repo [1]. This commit moves mistral-dashboard\ninto a separate deliverable file.\n\n[1] https://review.opendev.org/700368\n\nChange-Id: I0c3828d47fa3869f43b921b91a0a6a47ec18f51b\n'}]",0,702925,faf5678b951c8986b5bb4876672cab5b0909c84a,7,3,1,841,,,0,"Change mistral-dashboard to a separate deliverable

mistral-dashboard is now a separate deliverable in the
governance repo [1]. This commit moves mistral-dashboard
into a separate deliverable file.

[1] https://review.opendev.org/700368

Change-Id: I0c3828d47fa3869f43b921b91a0a6a47ec18f51b
",git fetch https://review.opendev.org/openstack/releases refs/changes/25/702925/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/ussuri/mistral-dashboard.yaml', 'deliverables/ussuri/mistral.yaml']",2,faf5678b951c8986b5bb4876672cab5b0909c84a,mistral-dashboard,, openstack/mistral-dashboard: {} - repo: openstack/mistral-dashboard hash: dcd4303c4b7ddd249f1b15db735f28482d3e944c,13,3
openstack%2Fstorlets~master~Ic33bb339339e9ff446fd308663c692db834f2a81,openstack/storlets,master,Ic33bb339339e9ff446fd308663c692db834f2a81,Use Python 3 by default to run storlet applications,MERGED,2020-01-05 11:48:23.000000000,2020-01-17 10:05:55.000000000,2020-01-17 10:04:38.000000000,"[{'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-05 11:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/a37fefbb407c5bd406ee8a19ff255a63362b2c8a', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\nAlso, deprecate Python 2 support because Python2 is not EOL.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 2, 'created': '2020-01-05 11:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/489b30ccc2af0619136654a6164b50eeca5d882f', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 3, 'created': '2020-01-05 11:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b1913b71aad0f5ed156bdf0f53c75fc4c7e8f096', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 4, 'created': '2020-01-05 12:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/e4567162485ede92f2085f9e08693505f9282f49', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 5, 'created': '2020-01-05 12:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/0f1bea75ee8fe88ce6ad69c9cb66b4d3b03b3d10', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 6, 'created': '2020-01-06 12:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/88c289edece1903216c0752956bd7163ea730027', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 7, 'created': '2020-01-06 13:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/f24c9d66de99d0f299cdc055675f9e60b103e0d8', 'message': 'Use Python 3 default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 8, 'created': '2020-01-06 13:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/ef93ba0242fd58c2f27d23b089c50c5e2ff977ad', 'message': 'Use Python 3 by default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\nAlso fix py3 compatibility for some python storlet applications used\nfor functional tests.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 9, 'created': '2020-01-06 13:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/48f24fe6a8e7f7e1d9e1152c967e5e97616a6c8f', 'message': 'Use Python 3 by default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\nAlso fix py3 compatibility for some python storlet applications used\nfor functional tests.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 10, 'created': '2020-01-06 14:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/e423c64226863f3275a43496ff3d84a9aef70f44', 'message': 'Use Python 3 by default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\nAlso fix py3 compatibility for some python storlet applications used\nfor functional tests.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}, {'number': 11, 'created': '2020-01-07 01:13:05.000000000', 'files': ['StorletSamples/python/storlet_samples/test/test.py', 'storlets/gateway/gateways/docker/gateway.py', 'tests/functional/python/test_simple_storlet.py', 'tests/functional/python/test_broken_storlet.py', 'tests/unit/agent/daemon_factory/test_server.py', 'devstack/plugin.sh', 'storlets/agent/daemon_factory/server.py', 'StorletSamples/python/storlet_samples/multi_input/multi_input_mime.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/55d9c282534101e1eb6ef804bd68381aa14c4245', 'message': 'Use Python 3 by default to run storlet applications\n\nUse Python 3 to run storlet application when runtime version is not\nspecified.\nAlso fix py3 compatibility for some python storlet applications used\nfor functional tests.\n\nChange-Id: Ic33bb339339e9ff446fd308663c692db834f2a81\n'}]",0,701109,55d9c282534101e1eb6ef804bd68381aa14c4245,34,3,11,9816,,,0,"Use Python 3 by default to run storlet applications

Use Python 3 to run storlet application when runtime version is not
specified.
Also fix py3 compatibility for some python storlet applications used
for functional tests.

Change-Id: Ic33bb339339e9ff446fd308663c692db834f2a81
",git fetch https://review.opendev.org/openstack/storlets refs/changes/09/701109/5 && git format-patch -1 --stdout FETCH_HEAD,"['storlets/gateway/gateways/docker/gateway.py', 'tests/functional/python/test_simple_storlet.py', 'tests/functional/python/test_broken_storlet.py', 'storlets/agent/daemon_factory/server.py']",4,a37fefbb407c5bd406ee8a19ff255a63362b2c8a,default-py3, daemon_language_version = daemon_language_version or 3 #TODO(takashi): Drop Py2 support if int(float(daemon_language_version)) == 2: else: daemon_language_version = DEFAULT_PY3, daemon_language_version = daemon_language_version or 2 if int(float(daemon_language_version)) == 3: daemon_language_version = DEFAULT_PY3 else: # TODO(takashi): Switch default python version to 3 once we drop # python2 support.,13,14
openstack%2Fovn-octavia-provider~master~Ia5e4aa81213f34654e21e65ab44f4eea03851a9a,openstack/ovn-octavia-provider,master,Ia5e4aa81213f34654e21e65ab44f4eea03851a9a,Initialize repository,MERGED,2020-01-10 12:23:47.000000000,2020-01-17 09:58:30.000000000,2020-01-17 09:52:37.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2020-01-10 12:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/7bf74ea6535d0b167f797090868f9ad054eee1b7', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}, {'number': 2, 'created': '2020-01-10 13:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/7cd5b1fc4697e66eddd7eec3750879571516c98b', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}, {'number': 3, 'created': '2020-01-10 13:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/d10474bd24c692e557f59a14182e66f5226b953b', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}, {'number': 4, 'created': '2020-01-10 14:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/798465e4a37fb3d55d6bdc676aac3c845fefaef7', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}, {'number': 5, 'created': '2020-01-10 15:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/f71d78cec250cf8f7f57a729a6b46522250066c0', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}, {'number': 6, 'created': '2020-01-10 20:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/b39fa69ea35281278ead4a8976d6843e757bbd9c', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}, {'number': 7, 'created': '2020-01-15 14:42:35.000000000', 'files': ['.gitignore', '.pylintrc', 'ovn_octavia_provider/tests/unit/test_hacking.py', 'test-requirements.txt', 'README.rst', 'ovn_octavia_provider/hacking/__init__.py', 'setup.py', 'releasenotes/source/_templates/.placeholder', 'ovn_octavia_provider/tests/functional/__init__.py', 'CONTRIBUTING.rst', 'requirements.txt', 'doc/source/pdf-index.rst', 'releasenotes/source/_static/.placeholder', 'LICENSE', '.stestr.conf', 'tools/coding-checks.sh', 'doc/source/conf.py', 'lower-constraints.txt', 'tools/pip_install_src_modules.sh', 'ovn_octavia_provider/hacking/checks.py', 'releasenotes/source/index.rst', 'ovn_octavia_provider/tests/unit/__init__.py', 'releasenotes/source/unreleased.rst', 'doc/source/index.rst', 'doc/source/_static/.placeholder', 'ovn_octavia_provider/tests/__init__.py', 'ovn_octavia_provider/tests/functional/requirements.txt', 'tools/check_unit_test_structure.sh', 'ovn_octavia_provider/__init__.py', 'releasenotes/notes/new-repository-for-ovn-octavia-provider-driver-dd81c4414c529c4e.yaml', 'zuul.d/project.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini', 'HACKING.rst', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/184f629f17a0ddba55d502c95f1493930d599677', 'message': 'Initialize repository\n\nThis commit adds basic project configuration.\n\nChange-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a\n'}]",45,701947,184f629f17a0ddba55d502c95f1493930d599677,38,6,7,24791,,,0,"Initialize repository

This commit adds basic project configuration.

Change-Id: Ia5e4aa81213f34654e21e65ab44f4eea03851a9a
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/47/701947/4 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'README.rst', 'setup.py', 'octavia_ovn_provider/__init__.py', 'setup.cfg', 'LICENSE', 'HACKING.rst']",7,7bf74ea6535d0b167f797090868f9ad054eee1b7,,ovn-octavia-provider Style Commandments =============================================== Read the OpenStack Style Commandments https://docs.openstack.org/hacking/latest/ ,,272,0
openstack%2Fnova~master~Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96,openstack/nova,master,Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96,nova-net: Kill it,MERGED,2019-11-28 11:02:05.000000000,2020-01-17 09:54:18.000000000,2020-01-15 02:12:30.000000000,"[{'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-28 11:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8def088a922cae47317e0661a8e071382f42797', 'message': ""WIP: Remove 'nova-network'\n\nFinish the job by removing all the now-unused modules.\n\nWIP because this isn't complete and I'm probably going to have to split\nthis up somehow. We also need a release note.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 2, 'created': '2019-11-28 12:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c72d0e291acf72d86ca82f02ffd444aa4ed7495', 'message': ""WIP: Remove 'nova-network'\n\nFinish the job by removing all the now-unused modules.\n\nWIP because this isn't complete and I'm probably going to have to split\nthis up somehow. We also need a release note.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 3, 'created': '2019-11-28 13:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a148d9ee482dc3386f1ecffae12ebbe818325b7', 'message': ""WIP: Remove 'nova-network'\n\nFinish the job by removing all the now-unused modules.\n\nWIP because this isn't complete and I'm probably going to have to split\nthis up somehow. We also need a release note.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 5, 'created': '2019-11-29 17:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ae57e3f9c1673a8443305b72bc12a38fcbb7470', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 6, 'created': '2019-11-29 17:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57d48b1c17d1bd6b2ac43b61a057ab21f93106ac', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 7, 'created': '2019-11-30 11:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46aaa705716a4a0499a26e79861319bb33a9a55e', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 8, 'created': '2019-12-03 18:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b94662f69f1c673c0b62a25edb41c10c5f4141a9', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 9, 'created': '2019-12-06 19:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78de43861654bace6860bff16b2fcc683ccefe59', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 10, 'created': '2019-12-10 11:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2290ee809fe377be08b21fa66675d8b1c241bac', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 11, 'created': '2019-12-12 10:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a72fb72690f8a3057ed202e22948148583ee365', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 12, 'created': '2019-12-16 10:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb3d110e26f42252e0ad3c6cdd0e245ffe219cc1', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 13, 'created': '2019-12-24 12:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/306b8514ebabca9eb99309b1f5646a6ddc9ea389', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 14, 'created': '2020-01-06 13:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/553b7e2f9da2d2aee1b0ba16499903241ca3403f', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 15, 'created': '2020-01-06 14:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e5999c55f0cdb10dc1054fe21c5ed876d30b32a', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 16, 'created': '2020-01-06 17:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c73f5615c9ad716a04a31c820d10bf0b4f8af52', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 17, 'created': '2020-01-08 13:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b123f052141bf8e0e9e5e8339822f97c3c5b9083', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}, {'number': 18, 'created': '2020-01-14 21:25:59.000000000', 'files': ['nova/conf/upgrade_levels.py', 'etc/nova/rootwrap.d/network.filters', 'nova/tests/unit/test_ipv6.py', 'nova/tests/unit/network/test_api.py', 'test-requirements.txt', 'nova/network/ldapdns.py', 'nova/network/manager.py', 'etc/nova/rootwrap.d/api-metadata.filters', 'nova/ipv6/account_identifier.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/db/sqlalchemy/api.py', 'nova/network/rpcapi.py', 'nova/tests/unit/test_iptables_network.py', 'nova/network/api.py', 'nova/conf/netconf.py', 'nova/tests/unit/utils.py', 'nova/network/driver.py', 'nova/network/dns_driver.py', 'nova/tests/unit/test_fixtures.py', 'nova/network/minidns.py', 'lower-constraints.txt', 'nova/objects/__init__.py', 'nova/network/__init__.py', 'nova/tests/unit/test_profiler.py', 'nova/ipv6/__init__.py', 'nova/ipv6/rfc2462.py', 'nova/tests/unit/network/test_l3.py', 'nova/db/sqlalchemy/models.py', 'nova/tests/unit/privsep/test_utils.py', 'nova/conf/__init__.py', 'nova/privsep/utils.py', 'setup.cfg', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/network/test_manager.py', 'nova/tests/unit/fake_network.py', 'nova/tests/unit/network/test_linux_net.py', 'nova/objects/dns_domain.py', 'nova/tests/unit/README.rst', 'nova/network/linux_net.py', 'nova/network/l3.py', 'nova/ipv6/api.py', 'nova/conf/network.py', 'nova/network/neutronv2/api.py', 'nova/tests/unit/objects/test_dns_domain.py', 'nova/network/base_api.py', 'nova/test.py', 'releasenotes/notes/remove-nova-network-c02953ba72a1795d.yaml', 'nova/network/noop_dns_driver.py', 'nova/tests/unit/conf_fixture.py', 'nova/utils.py', 'nova/tests/unit/privsep/test_linux_net.py', 'nova/db/api.py', 'nova/network/floating_ips.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/fixtures.py', 'nova/objects/network.py', 'nova/objects/network_request.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f5f73b4c4e00164d3ced8f9def5c9084397bc591', 'message': ""nova-net: Kill it\n\nFinish the job by removing all the now-unused modules. This also allows\nus to - wait for it - kill mox at long last. It's a great day in the\nparish.\n\nPartial-Implements: blueprint remove-nova-network-ussuri\nPartial-Implements: blueprint mox-removal-ussuri\n\nChange-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96\n""}]",4,696518,f5f73b4c4e00164d3ced8f9def5c9084397bc591,120,11,17,15334,,,0,"nova-net: Kill it

Finish the job by removing all the now-unused modules. This also allows
us to - wait for it - kill mox at long last. It's a great day in the
parish.

Partial-Implements: blueprint remove-nova-network-ussuri
Partial-Implements: blueprint mox-removal-ussuri

Change-Id: Ia33ec2604b2fc2d3b6830b596cac669cc3ad6c96
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/696518/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/fake_network.py', 'nova/tests/unit/network/test_linux_net.py', 'nova/tests/unit/test_ipv6.py', 'nova/tests/unit/network/test_api.py', 'nova/network/ldapdns.py', 'nova/network/manager.py', 'nova/tests/unit/virt/xenapi/stubs.py', 'nova/network/linux_net.py', 'nova/ipv6/account_identifier.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/network/l3.py', 'nova/ipv6/api.py', 'nova/conf/network.py', 'nova/network/rpcapi.py', 'nova/tests/unit/test_iptables_network.py', 'nova/network/api.py', 'nova/test.py', 'nova/network/noop_dns_driver.py', 'nova/network/driver.py', 'nova/network/dns_driver.py', 'nova/network/minidns.py', 'nova/ipv6/__init__.py', 'nova/ipv6/rfc2462.py', 'nova/network/floating_ips.py', 'nova/tests/unit/network/test_l3.py', 'nova/tests/fixtures.py', 'nova/api/manager.py', 'setup.cfg', 'nova/tests/unit/network/test_manager.py', 'nova/tests/unit/network/test_rpcapi.py']",30,e8def088a922cae47317e0661a8e071382f42797,bp/remove-nova-network-ussuri,,"# Copyright 2013 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Unit Tests for nova.network.rpcapi """""" import collections import mock from oslo_config import cfg from nova import context from nova import exception from nova.network import rpcapi as network_rpcapi from nova.objects import base as objects_base from nova import test from nova.tests.unit import fake_instance from nova.tests.unit import fake_network CONF = cfg.CONF class NetworkRpcAPITestCase(test.NoDBTestCase): def setUp(self): super(NetworkRpcAPITestCase, self).setUp() self.flags(multi_host=True) # Used to specify the default value expected if no real value is passed DefaultArg = collections.namedtuple('DefaultArg', ['value']) def _test_network_api(self, method, rpc_method, **kwargs): ctxt = context.RequestContext('fake_user', 'fake_project') rpcapi = network_rpcapi.NetworkAPI() self.assertIsNotNone(rpcapi.client) self.assertEqual(network_rpcapi.RPC_TOPIC, rpcapi.client.target.topic) expected_retval = 'foo' if rpc_method == 'call' else None expected_version = kwargs.pop('version', None) expected_fanout = kwargs.pop('fanout', None) expected_kwargs = kwargs.copy() for k, v in expected_kwargs.items(): if isinstance(v, self.DefaultArg): expected_kwargs[k] = v.value kwargs.pop(k) prepare_kwargs = {} if expected_version: prepare_kwargs['version'] = expected_version if expected_fanout: prepare_kwargs['fanout'] = True if 'source_compute' in expected_kwargs: # Fix up for migrate_instance_* calls. expected_kwargs['source'] = expected_kwargs.pop('source_compute') expected_kwargs['dest'] = expected_kwargs.pop('dest_compute') targeted_methods = [ 'lease_fixed_ip', 'release_fixed_ip', 'rpc_setup_network_on_host', '_rpc_allocate_fixed_ip', 'deallocate_fixed_ip', 'update_dns', '_associate_floating_ip', '_disassociate_floating_ip', 'lease_fixed_ip', 'release_fixed_ip', 'migrate_instance_start', 'migrate_instance_finish', 'allocate_for_instance', 'deallocate_for_instance', ] targeted_by_instance = ['deallocate_for_instance'] if method in targeted_methods and ('host' in expected_kwargs or 'instance' in expected_kwargs): if method in targeted_by_instance: host = expected_kwargs['instance']['host'] else: host = expected_kwargs['host'] if method not in ['allocate_for_instance', 'deallocate_fixed_ip']: expected_kwargs.pop('host') if CONF.multi_host: prepare_kwargs['server'] = host with test.nested( mock.patch.object(rpcapi.client, rpc_method), mock.patch.object(rpcapi.client, 'prepare'), mock.patch.object(rpcapi.client, 'can_send_version'), ) as ( rpc_mock, prepare_mock, csv_mock ): version_check = [ 'deallocate_for_instance', 'deallocate_fixed_ip', 'allocate_for_instance', 'release_fixed_ip', 'set_network_host', 'setup_networks_on_host' ] if method in version_check: csv_mock.return_value = True if prepare_kwargs: prepare_mock.return_value = rpcapi.client if rpc_method == 'call': rpc_mock.return_value = 'foo' else: rpc_mock.return_value = None retval = getattr(rpcapi, method)(ctxt, **kwargs) self.assertEqual(expected_retval, retval) if method in version_check: csv_mock.assert_called_once_with(mock.ANY) if prepare_kwargs: prepare_mock.assert_called_once_with(**prepare_kwargs) rpc_mock.assert_called_once_with(ctxt, method, **expected_kwargs) def test_create_networks(self): self._test_network_api('create_networks', rpc_method='call', arg1='arg', arg2='arg') def test_delete_network(self): self._test_network_api('delete_network', rpc_method='call', uuid='fake_uuid', fixed_range='range') def test_allocate_for_instance(self): self._test_network_api('allocate_for_instance', rpc_method='call', instance_id='fake_id', project_id='fake_id', host='fake_host', rxtx_factor='fake_factor', vpn=False, requested_networks={}, macs=[], version='1.13') def test_deallocate_for_instance(self): instance = fake_instance.fake_instance_obj(context.get_admin_context()) self._test_network_api('deallocate_for_instance', rpc_method='call', requested_networks=self.DefaultArg(None), instance=instance, version='1.11') def test_deallocate_for_instance_with_expected_networks(self): instance = fake_instance.fake_instance_obj(context.get_admin_context()) self._test_network_api('deallocate_for_instance', rpc_method='call', instance=instance, requested_networks={}, version='1.11') def test_release_dhcp(self): ctxt = context.RequestContext('fake_user', 'fake_project') dev = 'eth0' address = '192.168.65.158' vif_address = '00:0c:29:2c:b2:64' host = 'fake-host' rpcapi = network_rpcapi.NetworkAPI() call_mock = mock.Mock() cctxt_mock = mock.Mock(call=call_mock) with test.nested( mock.patch.object(rpcapi.client, 'can_send_version', return_value=True), mock.patch.object(rpcapi.client, 'prepare', return_value=cctxt_mock) ) as ( can_send_mock, prepare_mock ): rpcapi.release_dhcp(ctxt, host, dev, address, vif_address) can_send_mock.assert_called_once_with('1.17') prepare_mock.assert_called_once_with(server=host, version='1.17') call_mock.assert_called_once_with(ctxt, 'release_dhcp', dev=dev, address=address, vif_address=vif_address) def test_release_dhcp_v116(self): ctxt = context.RequestContext('fake_user', 'fake_project') dev = 'eth0' address = '192.168.65.158' vif_address = '00:0c:29:2c:b2:64' host = 'fake-host' rpcapi = network_rpcapi.NetworkAPI() with mock.patch.object(rpcapi.client, 'can_send_version', return_value=False) as can_send_mock: self.assertRaises(exception.RPCPinnedToOldVersion, rpcapi.release_dhcp, ctxt, host, dev, address, vif_address) can_send_mock.assert_called_once_with('1.17') def test_add_fixed_ip_to_instance(self): self._test_network_api('add_fixed_ip_to_instance', rpc_method='call', instance_id='fake_id', rxtx_factor='fake_factor', host='fake_host', network_id='fake_id', version='1.9') def test_remove_fixed_ip_from_instance(self): self._test_network_api('remove_fixed_ip_from_instance', rpc_method='call', instance_id='fake_id', rxtx_factor='fake_factor', host='fake_host', address='fake_address', version='1.9') def test_get_instance_nw_info(self): self._test_network_api('get_instance_nw_info', rpc_method='call', instance_id='fake_id', rxtx_factor='fake_factor', host='fake_host', project_id='fake_id', version='1.9') def test_validate_networks(self): self._test_network_api('validate_networks', rpc_method='call', networks={}) def test_get_dns_domains(self): self._test_network_api('get_dns_domains', rpc_method='call') def test_add_dns_entry(self): self._test_network_api('add_dns_entry', rpc_method='call', address='addr', name='name', dns_type='foo', domain='domain') def test_modify_dns_entry(self): self._test_network_api('modify_dns_entry', rpc_method='call', address='addr', name='name', domain='domain') def test_delete_dns_entry(self): self._test_network_api('delete_dns_entry', rpc_method='call', name='name', domain='domain') def test_delete_dns_domain(self): self._test_network_api('delete_dns_domain', rpc_method='call', domain='fake_domain') def test_get_dns_entries_by_address(self): self._test_network_api('get_dns_entries_by_address', rpc_method='call', address='fake_address', domain='fake_domain') def test_get_dns_entries_by_name(self): self._test_network_api('get_dns_entries_by_name', rpc_method='call', name='fake_name', domain='fake_domain') def test_create_private_dns_domain(self): self._test_network_api('create_private_dns_domain', rpc_method='call', domain='fake_domain', av_zone='fake_zone') def test_create_public_dns_domain(self): self._test_network_api('create_public_dns_domain', rpc_method='call', domain='fake_domain', project='fake_project') def test_setup_networks_on_host(self): ctxt = context.RequestContext('fake_user', 'fake_project') instance = fake_instance.fake_instance_obj(ctxt) self._test_network_api('setup_networks_on_host', rpc_method='call', instance_id=instance.id, host='fake_host', teardown=False, instance=instance, version='1.16') def test_setup_networks_on_host_v1_0(self): ctxt = context.RequestContext('fake_user', 'fake_project') instance = fake_instance.fake_instance_obj(ctxt) host = 'fake_host' teardown = True rpcapi = network_rpcapi.NetworkAPI() call_mock = mock.Mock() cctxt_mock = mock.Mock(call=call_mock) with test.nested( mock.patch.object(rpcapi.client, 'can_send_version', return_value=False), mock.patch.object(rpcapi.client, 'prepare', return_value=cctxt_mock) ) as ( can_send_mock, prepare_mock ): rpcapi.setup_networks_on_host(ctxt, instance.id, host, teardown, instance) # assert our mocks were called as expected can_send_mock.assert_called_once_with('1.16') prepare_mock.assert_called_once_with(version='1.0') call_mock.assert_called_once_with(ctxt, 'setup_networks_on_host', host=host, teardown=teardown, instance_id=instance.id) def test_lease_fixed_ip(self): self._test_network_api('lease_fixed_ip', rpc_method='cast', host='fake_host', address='fake_addr') def test_release_fixed_ip(self): self._test_network_api('release_fixed_ip', rpc_method='cast', host='fake_host', address='fake_addr', mac='fake_mac', version='1.14') def test_release_fixed_ip_no_mac_support(self): # Tests that the mac kwarg is not passed when we can't send version # 1.14 to the network manager. ctxt = context.RequestContext('fake_user', 'fake_project') address = '192.168.65.158' host = 'fake-host' mac = '00:0c:29:2c:b2:64' rpcapi = network_rpcapi.NetworkAPI() cast_mock = mock.Mock() cctxt_mock = mock.Mock(cast=cast_mock) with test.nested( mock.patch.object(rpcapi.client, 'can_send_version', return_value=False), mock.patch.object(rpcapi.client, 'prepare', return_value=cctxt_mock) ) as ( can_send_mock, prepare_mock ): rpcapi.release_fixed_ip(ctxt, address, host, mac) # assert our mocks were called as expected 232 can_send_mock.assert_called_once_with('1.14') prepare_mock.assert_called_once_with(server=host, version='1.0') cast_mock.assert_called_once_with(ctxt, 'release_fixed_ip', address=address) def test_set_network_host(self): network = fake_network.fake_network_obj(context.get_admin_context()) self._test_network_api('set_network_host', rpc_method='call', network_ref=network, version='1.15') def test_set_network_host_network_object_to_primitive(self): # Tests that the network object is converted to a primitive if it # can't send version 1.15. ctxt = context.RequestContext('fake_user', 'fake_project') network = fake_network.fake_network_obj(ctxt) network_dict = objects_base.obj_to_primitive(network) rpcapi = network_rpcapi.NetworkAPI() call_mock = mock.Mock() cctxt_mock = mock.Mock(call=call_mock) with test.nested( mock.patch.object(rpcapi.client, 'can_send_version', return_value=False), mock.patch.object(rpcapi.client, 'prepare', return_value=cctxt_mock) ) as ( can_send_mock, prepare_mock ): rpcapi.set_network_host(ctxt, network) # assert our mocks were called as expected can_send_mock.assert_called_once_with('1.15') prepare_mock.assert_called_once_with(version='1.0') call_mock.assert_called_once_with(ctxt, 'set_network_host', network_ref=network_dict) def test_rpc_setup_network_on_host(self): self._test_network_api('rpc_setup_network_on_host', rpc_method='call', network_id='fake_id', teardown=False, host='fake_host') def test_rpc_allocate_fixed_ip(self): self._test_network_api('_rpc_allocate_fixed_ip', rpc_method='call', instance_id='fake_id', network_id='fake_id', address='addr', vpn=True, host='fake_host') def test_deallocate_fixed_ip(self): instance = fake_instance.fake_db_instance() self._test_network_api('deallocate_fixed_ip', rpc_method='call', address='fake_addr', host='fake_host', instance=instance, version='1.12') def test_update_dns(self): self._test_network_api('update_dns', rpc_method='cast', fanout=True, network_ids='fake_id', version='1.3') def test__associate_floating_ip(self): self._test_network_api('_associate_floating_ip', rpc_method='call', floating_address='fake_addr', fixed_address='fixed_address', interface='fake_interface', host='fake_host', instance_uuid='fake_uuid', version='1.6') def test__disassociate_floating_ip(self): self._test_network_api('_disassociate_floating_ip', rpc_method='call', address='fake_addr', interface='fake_interface', host='fake_host', instance_uuid='fake_uuid', version='1.6') def test_migrate_instance_start(self): self._test_network_api('migrate_instance_start', rpc_method='call', instance_uuid='fake_instance_uuid', rxtx_factor='fake_factor', project_id='fake_project', source_compute='fake_src_compute', dest_compute='fake_dest_compute', floating_addresses='fake_floating_addresses', host=self.DefaultArg(None), version='1.2') def test_migrate_instance_start_multi_host(self): self._test_network_api('migrate_instance_start', rpc_method='call', instance_uuid='fake_instance_uuid', rxtx_factor='fake_factor', project_id='fake_project', source_compute='fake_src_compute', dest_compute='fake_dest_compute', floating_addresses='fake_floating_addresses', host='fake_host', version='1.2') def test_migrate_instance_finish(self): self._test_network_api('migrate_instance_finish', rpc_method='call', instance_uuid='fake_instance_uuid', rxtx_factor='fake_factor', project_id='fake_project', source_compute='fake_src_compute', dest_compute='fake_dest_compute', floating_addresses='fake_floating_addresses', host=self.DefaultArg(None), version='1.2') def test_migrate_instance_finish_multi_host(self): self._test_network_api('migrate_instance_finish', rpc_method='call', instance_uuid='fake_instance_uuid', rxtx_factor='fake_factor', project_id='fake_project', source_compute='fake_src_compute', dest_compute='fake_dest_compute', floating_addresses='fake_floating_addresses', host='fake_host', version='1.2') ",2,14964
openstack%2Fironic-ui~stable%2Fstein~I9a310446743cfe6bca5480455b91a7cd74da8785,openstack/ironic-ui,stable/stein,I9a310446743cfe6bca5480455b91a7cd74da8785,Fix horizon dependency,MERGED,2020-01-09 08:38:17.000000000,2020-01-17 09:39:48.000000000,2020-01-17 09:36:05.000000000,"[{'_account_id': 841}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-09 08:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/9ccf95cb1a0575df7a737d7730b7d66da7682e6c', 'message': ""Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to uper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don't know why it works for stable/train\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop.\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit 50475021dbe9a643043cdb39f57c01aede008dbb)\n""}, {'number': 2, 'created': '2020-01-09 11:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/9069658480a6ccd58f0d462033c86ece366820a6', 'message': ""Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to uper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don't know why it works for stable/train\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop.\n\nstable/stein only:\nsphinx entry in test-requirements.txt did not match global-requirements.\nThis commit updates it to match the current global-requirements.\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit 864c78b30cb740ac4e2cd0eb42e846215c64fc18)\n""}, {'number': 3, 'created': '2020-01-16 07:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/10cee0a3f55b1983341c0aa4284ad425f8ebdece', 'message': 'Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to upper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don\'t know why it works for stable/stein\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop [1].\n\nIn addition, ironic-ui tox.ini specified install_command with the\nupper-constraints.txt. The contraints file is now specified in ""deps""\nsection to follow the convention used widely in the OpenStack community.\ndoc/requirements.txt is cleanup and the runtime and test requirements\nare now added to ""deps"" of the ""docs"" env to generate the module index\nproperly.\n\nstable/stein only:\nsphinx entry in test-requirements.txt did not match global-requirements.\nThis commit updates it to match the current global-requirements.\n\n[1] https://review.opendev.org/#/c/700845/\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit efa4927bb7baeb918fad3734b21b0223e0958404)\n'}, {'number': 4, 'created': '2020-01-16 09:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/6a1395cec208342efcdc5a565a20a8b26f49c209', 'message': 'Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to upper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don\'t know why it works for stable/stein\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop [1].\n\nIn addition, ironic-ui tox.ini specified install_command with the\nupper-constraints.txt. The contraints file is now specified in ""deps""\nsection to follow the convention used widely in the OpenStack community.\ndoc/requirements.txt is cleanup and the runtime and test requirements\nare now added to ""deps"" of the ""docs"" env to generate the module index\nproperly.\n\nstable/stein only:\nsphinx entry in test-requirements.txt did not match global-requirements.\nThis commit updates it to match the current global-requirements.\n\n[1] https://review.opendev.org/#/c/700845/\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit efa4927bb7baeb918fad3734b21b0223e0958404)\n'}, {'number': 5, 'created': '2020-01-16 16:19:44.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-ui/commit/5c593fd34a149c62e4153a1456bb5bc1ae366ea7', 'message': 'Fix horizon dependency\n\nThis commit moves horizon to requirements.txt.\n\nhorizon was added to upper-constraints in stable branches recently,\nso installing from the tarball no longer works. upper-constraints\nin stable branches picks up the right version of horizon, so there\nis no need for the upper bound of the horizon version.\n\nIn addition, the link of the horizon tarball was not updated after\nthe stable branch was created. I don\'t know why it works for stable/stein\nbut I believe this commit mitigates the situation as the upper-constraints\nfile in the requirements repo picks up the right version of horizon.\n\nThis commit is proposed directly as the similar change in the master\nbranch happened as part of Django 1.11 drop [1].\n\nIn addition, ironic-ui tox.ini specified install_command with the\nupper-constraints.txt. The contraints file is now specified in ""deps""\nsection to follow the convention used widely in the OpenStack community.\ndoc/requirements.txt is cleanup and the runtime and test requirements\nare now added to ""deps"" of the ""docs"" env to generate the module index\nproperly.\n\nstable/stein only:\nsphinx entry in test-requirements.txt did not match global-requirements.\nThis commit updates it to match the current global-requirements.\n\n[1] https://review.opendev.org/#/c/700845/\n\nChange-Id: I9a310446743cfe6bca5480455b91a7cd74da8785\n(cherry picked from commit efa4927bb7baeb918fad3734b21b0223e0958404)\n'}]",1,701686,5c593fd34a149c62e4153a1456bb5bc1ae366ea7,22,4,5,841,,,0,"Fix horizon dependency

This commit moves horizon to requirements.txt.

horizon was added to upper-constraints in stable branches recently,
so installing from the tarball no longer works. upper-constraints
in stable branches picks up the right version of horizon, so there
is no need for the upper bound of the horizon version.

In addition, the link of the horizon tarball was not updated after
the stable branch was created. I don't know why it works for stable/stein
but I believe this commit mitigates the situation as the upper-constraints
file in the requirements repo picks up the right version of horizon.

This commit is proposed directly as the similar change in the master
branch happened as part of Django 1.11 drop [1].

In addition, ironic-ui tox.ini specified install_command with the
upper-constraints.txt. The contraints file is now specified in ""deps""
section to follow the convention used widely in the OpenStack community.
doc/requirements.txt is cleanup and the runtime and test requirements
are now added to ""deps"" of the ""docs"" env to generate the module index
properly.

stable/stein only:
sphinx entry in test-requirements.txt did not match global-requirements.
This commit updates it to match the current global-requirements.

[1] https://review.opendev.org/#/c/700845/

Change-Id: I9a310446743cfe6bca5480455b91a7cd74da8785
(cherry picked from commit efa4927bb7baeb918fad3734b21b0223e0958404)
",git fetch https://review.opendev.org/openstack/ironic-ui refs/changes/86/701686/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt']",3,9ccf95cb1a0575df7a737d7730b7d66da7682e6c,requirements-fix,horizon==15.0.0,,2,2
openstack%2Fmistral-extra~master~Ie32028c901831185d9694db8b9fd35829759a1ac,openstack/mistral-extra,master,Ie32028c901831185d9694db8b9fd35829759a1ac,"Fix requirements, tox , zuul",MERGED,2020-01-15 12:15:51.000000000,2020-01-17 09:38:07.000000000,2020-01-17 09:38:07.000000000,"[{'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 29124}]","[{'number': 1, 'created': '2020-01-15 12:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/ae41c2dda1f848a5bc94135fbef062e8062e307d', 'message': 'Fix requirements, tox , zuul\n\nChange-Id: Ie32028c901831185d9694db8b9fd35829759a1ac\n'}, {'number': 2, 'created': '2020-01-16 09:55:24.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'doc/source/_static/.placeholder', '.zuul.yaml', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/57afe0a3f46e7ea86db1b04e59b0d78f4d9af99f', 'message': 'Fix requirements, tox , zuul\n\nChange-Id: Ie32028c901831185d9694db8b9fd35829759a1ac\n'}]",2,702655,57afe0a3f46e7ea86db1b04e59b0d78f4d9af99f,11,4,2,19134,,,0,"Fix requirements, tox , zuul

Change-Id: Ie32028c901831185d9694db8b9fd35829759a1ac
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/55/702655/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'doc/source/_static/.placeholder', '.zuul.yaml', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini']",7,ae41c2dda1f848a5bc94135fbef062e8062e307d,requirements,"ignore_basepython_conflict = Truesetenv = VIRTUAL_ENV={envdir} PYTHONDONTWRITEBYTECODE = 1 PYTHONWARNINGS=default::DeprecationWarning passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXYcommands = rm -f .testrepository/times.dbm find . -type f -name ""*.pyc"" -delete stestr run --slowest {posargs} whitelist_externals = rm find doc8 doc/sourcesetenv = PYTHONHASHSEED=0 {[testenv]setenv} PYTHON=coverage run --source mistral --parallel-modedeps = -r{toxinidir}/doc/requirements.txt setenv = PYTHONHASHSEED=0 commands = rm -rf doc/build sphinx-build -E -W --keep-going -b html doc/source doc/build/html[doc8] extensions = .rst, .yaml, .mistral # Maximal line length should be 80. max-line-length = 80 [testenv:lower-constraints] deps = -c{toxinidir}/lower-constraints.txt -r{toxinidir}/test-requirements.txt -r{toxinidir}/requirements.txt",commands = stestr run --slowest {posargs} PYTHON=coverage run --source $project --parallel-modecommands = python setup.py build_sphinx,231,18
openstack%2Fwatcher~master~I11211b606afd55dfa46a0942132be58dc30e28a4,openstack/watcher,master,I11211b606afd55dfa46a0942132be58dc30e28a4,doc for event type audit,MERGED,2020-01-14 06:57:09.000000000,2020-01-17 09:36:07.000000000,2020-01-17 09:33:29.000000000,"[{'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 24501}, {'_account_id': 28748}, {'_account_id': 29911}, {'_account_id': 30623}]","[{'number': 1, 'created': '2020-01-14 06:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/2d4945a52397953479d84b4b4c5d7784e59baf4f', 'message': 'doc for event type audit\n\nPartially Implements: blueprint event-driven-optimization-based\n\nChange-Id: I11211b606afd55dfa46a0942132be58dc30e28a4\n'}, {'number': 2, 'created': '2020-01-14 09:07:43.000000000', 'files': ['doc/source/user/index.rst', 'doc/source/user/event_type_audit.rst'], 'web_link': 'https://opendev.org/openstack/watcher/commit/ae83ef02e76ba5e7f763f270f0deab2cfe38cc65', 'message': 'doc for event type audit\n\nPartially Implements: blueprint event-driven-optimization-based\n\nChange-Id: I11211b606afd55dfa46a0942132be58dc30e28a4\n'}]",2,702357,ae83ef02e76ba5e7f763f270f0deab2cfe38cc65,12,6,2,21692,,,0,"doc for event type audit

Partially Implements: blueprint event-driven-optimization-based

Change-Id: I11211b606afd55dfa46a0942132be58dc30e28a4
",git fetch https://review.opendev.org/openstack/watcher refs/changes/57/702357/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/index.rst', 'doc/source/user/event_type_audit.rst']",2,2d4945a52397953479d84b4b4c5d7784e59baf4f,bp/event-driven-optimization-based,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. ====================== Audit using Aodh alarm ====================== Audit with EVENT type can be triggered by special alarm. This guide walks you through the steps to build an event-driven optimization solution by integrating Watcher with Ceilometer/Aodh. Step 1: Create an audit with EVENT type ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The first step is to create an audit with EVENT type, you can create an audit template firstly: .. code-block:: bash $ openstack optimize audittemplate create your_template_name <your_goal> \ --strategy <your_strategy> or create an audit directly with special goal and strategy: .. code-block:: bash $ openstack optimize audit create --goal <your_goal> \ --strategy <your_strategy> --audit_type EVENT This is an example for creating an audit with dummy strategy: .. code-block:: bash $ openstack optimize audit create --goal dummy \ --strategy dummy --audit_type EVENT +---------------+--------------------------------------+ | Field | Value | +---------------+--------------------------------------+ | UUID | a3326a6a-c18e-4e8e-adba-d0c61ad404c5 | | Name | dummy-2020-01-14T03:21:19.168467 | | Created At | 2020-01-14T03:21:19.200279+00:00 | | Updated At | None | | Deleted At | None | | State | PENDING | | Audit Type | EVENT | | Parameters | {u'para2': u'hello', u'para1': 3.2} | | Interval | None | | Goal | dummy | | Strategy | dummy | | Audit Scope | [] | | Auto Trigger | False | | Next Run Time | None | | Hostname | None | | Start Time | None | | End Time | None | | Force | False | +---------------+--------------------------------------+ We need to build Aodh action url using Watcher webhook API. For convenience We export the url into an environment variable: .. code-block:: bash $ export AUDIT_UUID=a3326a6a-c18e-4e8e-adba-d0c61ad404c5 $ export ALARM_URL=""trust+http://localhost/infra-optim/v1/webhooks/$AUDIT_UUID"" Step 2: Create Aodh Alarm ~~~~~~~~~~~~~~~~~~~~~~~~~ Once we have the audit created, we can continue to create Aodh alarm and set the alarm action to Watcher webhook API. The alarm type can be event( i.e. ``compute.instance.create.end``) or gnocchi_resources_threshold(i.e. ``cpu_util``), more info refer to alarm-creation_ For example: .. code-block:: bash $ openstack alarm create \ --type event --name instance_create \ --event-type ""compute.instance.create.end"" \ --enable True --repeat-actions False \ --alarm-action $ALARM_URL +---------------------------+------------------------------------------------------------------------------------------+ | Field | Value | +---------------------------+------------------------------------------------------------------------------------------+ | alarm_actions | [u'trust+http://localhost/infra-optim/v1/webhooks/a3326a6a-c18e-4e8e-adba-d0c61ad404c5'] | | alarm_id | b9e381fc-8e3e-4943-82ee-647e7a2ef644 | | description | Alarm when compute.instance.create.end event occurred. | | enabled | True | | event_type | compute.instance.create.end | | insufficient_data_actions | [] | | name | instance_create | | ok_actions | [] | | project_id | 728d66e18c914af1a41e2a585cf766af | | query | | | repeat_actions | False | | severity | low | | state | insufficient data | | state_reason | Not evaluated yet | | state_timestamp | 2020-01-14T03:56:26.894416 | | time_constraints | [] | | timestamp | 2020-01-14T03:56:26.894416 | | type | event | | user_id | 88c40156af7445cc80580a1e7e3ba308 | +---------------------------+------------------------------------------------------------------------------------------+ .. _alarm-creation: https://docs.openstack.org/aodh/latest/admin/telemetry-alarms.html#alarm-creation Step 3: Trigger the alarm ~~~~~~~~~~~~~~~~~~~~~~~~~ In this example, you can create a new instance to trigger the alarm. The alarm state will translate from ``insufficient data`` to ``alarm``. .. code-block:: bash $ openstack alarm show b9e381fc-8e3e-4943-82ee-647e7a2ef644 +---------------------------+-------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------------+-------------------------------------------------------------------------------------------------------------------+ | alarm_actions | [u'trust+http://localhost/infra-optim/v1/webhooks/a3326a6a-c18e-4e8e-adba-d0c61ad404c5'] | | alarm_id | b9e381fc-8e3e-4943-82ee-647e7a2ef644 | | description | Alarm when compute.instance.create.end event occurred. | | enabled | True | | event_type | compute.instance.create.end | | insufficient_data_actions | [] | | name | instance_create | | ok_actions | [] | | project_id | 728d66e18c914af1a41e2a585cf766af | | query | | | repeat_actions | False | | severity | low | | state | alarm | | state_reason | Event <id=67dd0afa-2082-45a4-8825-9573b2cc60e5,event_type=compute.instance.create.end> hits the query <query=[]>. | | state_timestamp | 2020-01-14T03:56:26.894416 | | time_constraints | [] | | timestamp | 2020-01-14T06:17:40.350649 | | type | event | | user_id | 88c40156af7445cc80580a1e7e3ba308 | +---------------------------+-------------------------------------------------------------------------------------------------------------------+ Step 4: Verify the audit ~~~~~~~~~~~~~~~~~~~~~~~~ This can be verified to check if the state was ``SUCCEEDED``: .. code-block:: bash $ openstack optimize audit show a3326a6a-c18e-4e8e-adba-d0c61ad404c5 +---------------+--------------------------------------+ | Field | Value | +---------------+--------------------------------------+ | UUID | a3326a6a-c18e-4e8e-adba-d0c61ad404c5 | | Name | dummy-2020-01-14T03:21:19.168467 | | Created At | 2020-01-14T03:21:19+00:00 | | Updated At | 2020-01-14T06:26:40+00:00 | | Deleted At | None | | State | SUCCEEDED | | Audit Type | EVENT | | Parameters | {u'para2': u'hello', u'para1': 3.2} | | Interval | None | | Goal | dummy | | Strategy | dummy | | Audit Scope | [] | | Auto Trigger | False | | Next Run Time | None | | Hostname | ubuntudbs | | Start Time | None | | End Time | None | | Force | False | +---------------+--------------------------------------+ and you can use the following command to check if the action plan was created: .. code-block:: bash $ openstack optimize actionplan list --audit a3326a6a-c18e-4e8e-adba-d0c61ad404c5 +--------------------------------------+--------------------------------------+-------------+------------+-----------------+ | UUID | Audit | State | Updated At | Global efficacy | +--------------------------------------+--------------------------------------+-------------+------------+-----------------+ | 673b3fcb-8c16-4a41-9ee3-2956d9f6ca9e | a3326a6a-c18e-4e8e-adba-d0c61ad404c5 | RECOMMENDED | None | | +--------------------------------------+--------------------------------------+-------------+------------+-----------------+ ",,196,0
openstack%2Foctavia-dashboard~stable%2Fstein~I7f8db57600b39e4f230261e15d103b1d32968b38,openstack/octavia-dashboard,stable/stein,I7f8db57600b39e4f230261e15d103b1d32968b38,Fix Django version in lower-constraints,MERGED,2019-12-28 14:04:09.000000000,2020-01-17 09:32:20.000000000,2020-01-17 09:30:40.000000000,"[{'_account_id': 841}, {'_account_id': 2245}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-12-28 14:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/2c718784bb5b3e7ff55e7411b6d868135db00932', 'message': ""Fix Django version in lower-constraints\n\nhorizon requires Django>=1.11 but lower-constraints.txt in ocatavia-dashboard\nuses Django 1.8. As a result, the latest Django 3.0.1 which is not supported\nin horizon yet is installed when installing horizon as sibling.\nThis leads to a failure in lower-constraints job like [1].\n\n[1] https://zuul.opendev.org/t/openstack/build/5ad97e34d5674d00af0713d57c02f616\n\n[Differences from the cherry-picked commit in the master branch]\nrequiremens.txt and lower-constraints.txt are updated to match\nhorizon's requirements in stable/train.\n\nNote that there is no difference from the stable/train backport.\n\nChange-Id: I7f8db57600b39e4f230261e15d103b1d32968b38\n(cherry picked from commit 86fb321f340fea70e5c0ef77e96197815ff0be92)\n(cherry picked from commit 64221cd6ababd298018f9ebbdaae9410e1cec4a7)\n""}, {'number': 2, 'created': '2019-12-28 15:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/ac232a7fe211aa7294dc770c6c8eee23a0179773', 'message': ""Fix Django version in lower-constraints\n\nhorizon requires Django>=1.11 but lower-constraints.txt in ocatavia-dashboard\nuses Django 1.8. As a result, the latest Django 3.0.1 which is not supported\nin horizon yet is installed when installing horizon as sibling.\nThis leads to a failure in lower-constraints job like [1].\n\n[1] https://zuul.opendev.org/t/openstack/build/5ad97e34d5674d00af0713d57c02f616\n\nDifferences from the master branch\n----------------------------------\n\nrequiremens.txt and lower-constraints.txt are updated to match\nhorizon's requirements in stable/train.\n\nDifferences from the stable/train branch\n----------------------------------------\n\nsphinx in doc/requirements.txt is upated to match global-requirements.txt\n\nChange-Id: I7f8db57600b39e4f230261e15d103b1d32968b38\n(cherry picked from commit 86fb321f340fea70e5c0ef77e96197815ff0be92)\n(cherry picked from commit 64221cd6ababd298018f9ebbdaae9410e1cec4a7)\n""}, {'number': 3, 'created': '2020-01-15 06:30:41.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/97c10411a69dfd2464fa03f18ea075c08b7330df', 'message': ""Fix Django version in lower-constraints\n\nhorizon requires Django>=1.11 but lower-constraints.txt in ocatavia-dashboard\nuses Django 1.8. As a result, the latest Django 3.0.1 which is not supported\nin horizon yet is installed when installing horizon as sibling.\nThis leads to a failure in lower-constraints job like [1].\n\n[1] https://zuul.opendev.org/t/openstack/build/5ad97e34d5674d00af0713d57c02f616\n\nDifferences from the master branch\n----------------------------------\n\nrequiremens.txt and lower-constraints.txt are updated to match\nhorizon's requirements in stable/stein.\n\nDifferences from the stable/train branch\n----------------------------------------\n\nsphinx in doc/requirements.txt is upated to match global-requirements.txt\n\nChange-Id: I7f8db57600b39e4f230261e15d103b1d32968b38\n(cherry picked from commit 86fb321f340fea70e5c0ef77e96197815ff0be92)\n(cherry picked from commit 64221cd6ababd298018f9ebbdaae9410e1cec4a7)\n""}]",1,700721,97c10411a69dfd2464fa03f18ea075c08b7330df,20,5,3,841,,,0,"Fix Django version in lower-constraints

horizon requires Django>=1.11 but lower-constraints.txt in ocatavia-dashboard
uses Django 1.8. As a result, the latest Django 3.0.1 which is not supported
in horizon yet is installed when installing horizon as sibling.
This leads to a failure in lower-constraints job like [1].

[1] https://zuul.opendev.org/t/openstack/build/5ad97e34d5674d00af0713d57c02f616

Differences from the master branch
----------------------------------

requiremens.txt and lower-constraints.txt are updated to match
horizon's requirements in stable/stein.

Differences from the stable/train branch
----------------------------------------

sphinx in doc/requirements.txt is upated to match global-requirements.txt

Change-Id: I7f8db57600b39e4f230261e15d103b1d32968b38
(cherry picked from commit 86fb321f340fea70e5c0ef77e96197815ff0be92)
(cherry picked from commit 64221cd6ababd298018f9ebbdaae9410e1cec4a7)
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/21/700721/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,2c718784bb5b3e7ff55e7411b6d868135db00932,lower-constraints,Django==1.11django-babel==0.6.2horizon==16.0.0oslo.concurrency==3.26.0osprofiler==2.3.0python-cinderclient==4.0.1,Django==1.8django-babel==0.5.1horizon==13.0.0oslo.concurrency==3.25.0osprofiler==1.4.0python-cinderclient==3.3.0,7,7
openstack%2Ftripleo-ci~master~I7dcd1cf569fea5e536926f7188af953c3301af0f,openstack/tripleo-ci,master,I7dcd1cf569fea5e536926f7188af953c3301af0f,Removed several gzip operations,MERGED,2020-01-16 17:41:58.000000000,2020-01-17 09:27:08.000000000,2020-01-17 09:27:08.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-16 17:41:58.000000000', 'files': ['scripts/te-broker/destroy-env', 'scripts/common_vars.bash', 'roles/build-containers/tasks/post.yaml', 'toci_quickstart.sh', 'roles/run-test/templates/common_vars.bash.j2', 'roles/run-test/templates/oooq_common_functions.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f54d582f284a39170d7ddb32878c9b6338d34363', 'message': 'Removed several gzip operations\n\nAs log storage takes care of compression is better to avoid performing\nany gzip activity on *text* files that we want to access with the\nbrowser.\n\nChange-Id: I7dcd1cf569fea5e536926f7188af953c3301af0f\n'}]",0,702937,f54d582f284a39170d7ddb32878c9b6338d34363,15,5,1,24162,,,0,"Removed several gzip operations

As log storage takes care of compression is better to avoid performing
any gzip activity on *text* files that we want to access with the
browser.

Change-Id: I7dcd1cf569fea5e536926f7188af953c3301af0f
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/37/702937/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/te-broker/destroy-env', 'scripts/common_vars.bash', 'roles/build-containers/tasks/post.yaml', 'toci_quickstart.sh', 'roles/run-test/templates/common_vars.bash.j2', 'roles/run-test/templates/oooq_common_functions.sh.j2']",6,f54d582f284a39170d7ddb32878c9b6338d34363,gzip,"sudo unbound-control dump_cache > $LOGS_DIR/dns_cache.txtfind $LOCAL_WORKING_DIR -maxdepth 1 -type f -not -name ""*sqlite"" | while read i; do cp -l \$i $LOGS_DIR/quickstart_files/\$(basename \$i); done","sudo unbound-control dump_cache > /tmp/dns_cache.txt sudo chown {{ ansible_user_id }}: /tmp/dns_cache.txt cat /tmp/dns_cache.txt | gzip - > $LOGS_DIR/dns_cache.txt.gzfind $LOCAL_WORKING_DIR -maxdepth 1 -type f -not -name ""*sqlite"" | while read i; do gzip -cf \$i > $LOGS_DIR/quickstart_files/\$(basename \$i).txt.gz; done",7,23
openstack%2Fopenstack-zuul-jobs~master~I26168a240b9731982ef51fa534a0cc91c856d864,openstack/openstack-zuul-jobs,master,I26168a240b9731982ef51fa534a0cc91c856d864,Remove jobs and templates used by js-openstack-lib,MERGED,2020-01-08 08:43:08.000000000,2020-01-17 09:09:35.000000000,2020-01-17 09:04:10.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-08 08:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e9906cd668131c07317c8abba8347d6781239f1d', 'message': 'Retire js-openstack-lib: Remove jobs and templates\n\nRemove the jobs and template that are used only by the js-openstack-lib\nrepository since that is getting retired now.\n\nDepends-On: https://review.opendev.org/701509\nChange-Id: I26168a240b9731982ef51fa534a0cc91c856d864\n'}, {'number': 2, 'created': '2020-01-10 20:55:51.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs4-npm-run-functional-test/run.yaml', 'zuul.d/project-templates.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs6-npm-run-functional-test/run.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs4-npm-run-functional-test/post.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs6-npm-run-functional-test/post.yaml', 'playbooks/legacy/js-openstack-lib-nodejs6-npm-sdk-docs/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ba7729181fe5f524a8ff4d9a928c5d051ce247cd', 'message': 'Remove jobs and templates used by js-openstack-lib\n\nRemove the jobs and template that are used only by the js-openstack-lib\nrepository, they need to be rewritten\n\nDepends-On: https://review.opendev.org/702030\nChange-Id: I26168a240b9731982ef51fa534a0cc91c856d864\n'}]",3,701510,ba7729181fe5f524a8ff4d9a928c5d051ce247cd,21,4,2,6547,,,0,"Remove jobs and templates used by js-openstack-lib

Remove the jobs and template that are used only by the js-openstack-lib
repository, they need to be rewritten

Depends-On: https://review.opendev.org/702030
Change-Id: I26168a240b9731982ef51fa534a0cc91c856d864
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/10/701510/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs4-npm-run-functional-test/run.yaml', 'zuul.d/project-templates.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs6-npm-run-functional-test/run.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs4-npm-run-functional-test/post.yaml', 'playbooks/legacy/js-openstack-lib-dsvm-nodejs6-npm-run-functional-test/post.yaml', 'playbooks/legacy/js-openstack-lib-nodejs6-npm-sdk-docs/run.yaml']",7,e9906cd668131c07317c8abba8347d6781239f1d,retire-js-openstack-lib,,"- hosts: all name: Autoconverted job legacy-js-openstack-lib-nodejs6-npm-sdk-docs from old job js-openstack-lib-nodejs6-npm-sdk-docs roles: - bindep tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ https://opendev.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -u set -e set -x # Prerequisites sudo apt-get update sudo apt-get install -y apt-transport-https lsb-release curl DISTRO=$(lsb_release -c -s) # Install via nodesource curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | sudo apt-key add - echo ""deb https://deb.nodesource.com/node_6.x $DISTRO main"" | sudo tee /etc/apt/sources.list.d/nodesource.list echo ""deb-src https://deb.nodesource.com/node_6.x $DISTRO main"" | sudo tee -a /etc/apt/sources.list.d/nodesource.list sudo apt-get update sudo apt-get install -y nodejs # Output to the log for debugging sake. node --version npm --version executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -u set -e set -x export DISPLAY=:99 npm install --verbose # Try running as a standard lifecycle script, otherwise try custom. npm_lifecycle_phases=""publish install version test stop start restart pack"" if [[ $npm_lifecycle_phases =~ (^| )docs($| ) ]]; then npm docs --verbose else npm run docs --verbose fi # If no shrinkwrap exists, generate it. if [ ! -f ./npm-shrinkwrap.json ]; then npm prune # https://github.com/npm/npm/issues/6298 npm shrinkwrap fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | OUT=`git ls-files --other --exclude-standard --directory` if [ -z ""$OUT"" ]; then echo ""No extra files created during test."" exit 0 else echo ""The following un-ignored files were created during the test:"" echo ""$OUT"" exit 0 # TODO: change to 1 to fail tests. fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x MARKER_TEXT=""Project: $ZUUL_PROJECT Ref: $ZUUL_REFNAME Build: $ZUUL_UUID Revision: $ZUUL_NEWREV"" echo $MARKER_TEXT > doc/build/html/.root-marker executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,598
openstack%2Fdevstack~master~I20740b468e4b310ac07e77f3930cae92026942fb,openstack/devstack,master,I20740b468e4b310ac07e77f3930cae92026942fb,Fix MySQL log collection,MERGED,2019-08-22 16:15:34.000000000,2020-01-17 09:04:36.000000000,2019-08-30 16:12:09.000000000,"[{'_account_id': 6873}, {'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-22 16:15:34.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f92c346131db2c89b930b1a23f8489419a2217dc', 'message': ""Fix MySQL log collection\n\nThe mysql logs weren't being copied to logs and published.\n\nChange-Id: I20740b468e4b310ac07e77f3930cae92026942fb\n""}]",0,678053,f92c346131db2c89b930b1a23f8489419a2217dc,14,5,1,6873,,,0,"Fix MySQL log collection

The mysql logs weren't being copied to logs and published.

Change-Id: I20740b468e4b310ac07e77f3930cae92026942fb
",git fetch https://review.opendev.org/openstack/devstack refs/changes/53/678053/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f92c346131db2c89b930b1a23f8489419a2217dc,fix-mysql-log-collection, /var/log/mysql: logs, /var/log/mysql.err: logs /var/log/mysql.log: logs,1,2
openstack%2Fproject-config~master~I34cf69ee118010aa62a4bd3c601b6038a871bfea,openstack/project-config,master,I34cf69ee118010aa62a4bd3c601b6038a871bfea,Remove old openstack/js-openstack-lib jobs,MERGED,2020-01-10 19:29:35.000000000,2020-01-17 08:34:27.000000000,2020-01-17 08:34:27.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-10 19:29:35.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a234f9ed1d4fdf09d260aa9866a2d952bb688076', 'message': 'Remove old openstack/js-openstack-lib jobs\n\nLegacy jobs are failing and block gating.\nThe other jobs are using legacy nodejs which is not\nof interest either.\nThe plan is to move all job definitions into the\ndeliverable repository and port them to Zuul v3 format\nand current nodejs (10, 12).\n\nDepends-on: https://review.opendev.org/701854\nChange-Id: I34cf69ee118010aa62a4bd3c601b6038a871bfea\n'}]",0,702030,a234f9ed1d4fdf09d260aa9866a2d952bb688076,11,5,1,30491,,,0,"Remove old openstack/js-openstack-lib jobs

Legacy jobs are failing and block gating.
The other jobs are using legacy nodejs which is not
of interest either.
The plan is to move all job definitions into the
deliverable repository and port them to Zuul v3 format
and current nodejs (10, 12).

Depends-on: https://review.opendev.org/701854
Change-Id: I34cf69ee118010aa62a4bd3c601b6038a871bfea
",git fetch https://review.opendev.org/openstack/project-config refs/changes/30/702030/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,a234f9ed1d4fdf09d260aa9866a2d952bb688076,adopt-js-openstack-lib-into-openstacksdk-project,, - nodejs4-jobs - nodejs6-jobs - nodejs6-docs check: jobs: - legacy-js-openstack-lib-dsvm-nodejs6-npm-run-functional-test - legacy-js-openstack-lib-dsvm-nodejs4-npm-run-functional-test gate: jobs: - legacy-js-openstack-lib-dsvm-nodejs6-npm-run-functional-test - legacy-js-openstack-lib-dsvm-nodejs4-npm-run-functional-test pre-release: jobs: - legacy-js-openstack-lib-nodejs6-npm-sdk-docs release: jobs: - legacy-js-openstack-lib-nodejs6-npm-sdk-docs,0,17
openstack%2Fgovernance~master~I794167a5a830398bd1f5c0055aa51ebaa80e5e6e,openstack/governance,master,I794167a5a830398bd1f5c0055aa51ebaa80e5e6e,Adopt js-openstack-lib into openstacksdk team,MERGED,2020-01-09 22:27:15.000000000,2020-01-17 08:29:13.000000000,2020-01-17 08:23:08.000000000,"[{'_account_id': 308}, {'_account_id': 4146}, {'_account_id': 4257}, {'_account_id': 6547}, {'_account_id': 8099}, {'_account_id': 10607}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-09 22:27:15.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/cc22d6d74151ed0b3c16056de28151adde2d2c80', 'message': ""Adopt js-openstack-lib into openstacksdk team\n\nThe openstack javascript client library has been over in Infra\nland for reasons I'm not sure any of us understand. Radosaw\nPiliszek expressed interest in moving it forward. Since it has\nsupport for sdk concepts such as clouds.yaml, and is a client\nlibrary, it seems that it would benefit from maintaining a home\nalong with like-minded people inside of openstack.\n\nMove the project from Infra to OpenStackSDK.\n\nChange-Id: I794167a5a830398bd1f5c0055aa51ebaa80e5e6e\n""}]",0,701854,cc22d6d74151ed0b3c16056de28151adde2d2c80,18,9,1,2,,,0,"Adopt js-openstack-lib into openstacksdk team

The openstack javascript client library has been over in Infra
land for reasons I'm not sure any of us understand. Radosaw
Piliszek expressed interest in moving it forward. Since it has
support for sdk concepts such as clouds.yaml, and is a client
library, it seems that it would benefit from maintaining a home
along with like-minded people inside of openstack.

Move the project from Infra to OpenStackSDK.

Change-Id: I794167a5a830398bd1f5c0055aa51ebaa80e5e6e
",git fetch https://review.opendev.org/openstack/governance refs/changes/54/701854/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,cc22d6d74151ed0b3c16056de28151adde2d2c80,project-update, js-openstack-lib: repos: - openstack/js-openstack-lib, js-openstack-lib: repos: - openstack/js-openstack-lib,3,3
openstack%2Fgovernance~master~I0ccc08b7aa7ffe4e7a3320d261f2467691ff2eee,openstack/governance,master,I0ccc08b7aa7ffe4e7a3320d261f2467691ff2eee,doc nit: remove unnecessary space,MERGED,2020-01-16 14:45:47.000000000,2020-01-17 08:24:47.000000000,2020-01-17 08:23:07.000000000,"[{'_account_id': 308}, {'_account_id': 7198}, {'_account_id': 8556}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 14:45:47.000000000', 'files': ['goals/selected/ussuri/project-ptl-and-contrib-docs.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/3fb2997b290942b9cf7c74bc907e8eb9cee80e10', 'message': 'doc nit: remove unnecessary space\n\nAn unnecesary space at the beginning of line leads to\nan unexpected vertical line and the text is rendered as\nblockquote with a different style.\n\nChange-Id: I0ccc08b7aa7ffe4e7a3320d261f2467691ff2eee\n'}]",0,702879,3fb2997b290942b9cf7c74bc907e8eb9cee80e10,11,5,1,841,,,0,"doc nit: remove unnecessary space

An unnecesary space at the beginning of line leads to
an unexpected vertical line and the text is rendered as
blockquote with a different style.

Change-Id: I0ccc08b7aa7ffe4e7a3320d261f2467691ff2eee
",git fetch https://review.opendev.org/openstack/governance refs/changes/79/702879/1 && git format-patch -1 --stdout FETCH_HEAD,['goals/selected/ussuri/project-ptl-and-contrib-docs.rst'],1,3fb2997b290942b9cf7c74bc907e8eb9cee80e10,typo-fix,#. `Nova PTL Guide <https://docs.openstack.org/nova/latest/contributor/ptl-guide.html>`_, #. `Nova PTL Guide <https://docs.openstack.org/nova/latest/contributor/ptl-guide.html>`_ ,1,2
openstack%2Fopenstack-manuals~master~I78118deee407e5abc3488debbce9259b806c1fe9,openstack/openstack-manuals,master,I78118deee407e5abc3488debbce9259b806c1fe9,Imported Translations from Zanata,MERGED,2020-01-17 06:34:04.000000000,2020-01-17 08:06:11.000000000,2020-01-17 07:40:35.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-17 06:34:04.000000000', 'files': ['doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8f5c873edb5d037d910711523209227eeeec846c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I78118deee407e5abc3488debbce9259b806c1fe9\n'}]",0,703018,8f5c873edb5d037d910711523209227eeeec846c,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I78118deee407e5abc3488debbce9259b806c1fe9
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/703018/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po']",2,8f5c873edb5d037d910711523209227eeeec846c,zanata/translations,"# Andreas Jaeger <jaegerandi@gmail.com>, 2020. #zanata""POT-Creation-Date: 2020-01-16 07:28+0000\n""""PO-Revision-Date: 2020-01-16 07:18+0000\n"" ""Last-Translator: Andreas Jaeger <jaegerandi@gmail.com>\n""msgid """" ""Block Storage service  `cinder installation for Train <https://docs."" ""openstack.org/cinder/train/install/>`_"" msgstr """" ""Block Storage Dienst  `Cinder Installation fr Train <https://docs."" ""openstack.org/cinder/train/install/>`_"" msgid """" ""Compute service  `nova installation for Train <https://docs.openstack.org/"" ""nova/train/install/>`_"" msgstr """" ""Computedienst  `Nova Installation fr Train <https://docs.openstack.org/"" ""nova/train/install/>`_"" msgid """" ""Dashboard  `horizon installation for Train <https://docs.openstack.org/"" ""horizon/train/install/>`_"" msgstr """" ""Dashboard  `Horizon Installation fr Train <https://docs.openstack.org/"" ""horizon/train/install/>`_"" msgid """" ""Edit the ``chrony.conf`` file and add, change, or remove the following keys "" ""as necessary for your environment."" msgstr """" ""Bearbeiten Sie die Datei ``chrony.conf`` und ergnzen, ndern oder entfernen "" ""die folgenden Schlssel aus Ihrer Umgebung wenn erforderlich:"" msgid ""Enable and restart the etcd service:"" msgstr ""Aktivieren und starten des etcd Dienstes:"" ""Identity service  `keystone installation for Train <https://docs.openstack."" ""org/keystone/train/install/>`_"" msgstr """" ""Identittsdienst  `Keystone Installation fr Train <https://docs.openstack."" ""org/keystone/train/install/>`_"" msgid """"""Image service  `glance installation for Train <https://docs.openstack.org/"" ""glance/train/install/>`_"" msgstr """" ""Abbilddienst  `Glance Installation fr Train <https://docs.openstack.org/"" ""glance/train/install/>`_"" msgid """"msgid ""Minimal deployment for Train"" msgstr ""Minimale Installation fr Train"" ""Networking service  `neutron installation for Train <https://docs.openstack."" ""org/neutron/train/install/>`_"" msgstr """" ""Netzwerkdienst  `Neutron Installation fr Train <https://docs.openstack.org/"" ""neutron/train/install/>`_"" msgid """"msgid """" ""Placement service  `placement installation for Train <https://docs."" ""openstack.org/placement/train/install/>`_"" msgstr """" ""Placement Dienst  `Placement Installation fr Train <https://docs.openstack."" ""org/placement/train/install/>`_"" ""To enable other nodes to connect to the chrony daemon on the controller "" ""node, add this key to the same ``chrony.conf`` file mentioned above:"" msgstr """" ""Um anderen Knoten die Verbindung zum Chrony Daemon zu ermglichen, fgen Sie "" ""diesen Schlssel zur oben genannten ``chrony.conf`` Datei hinzu:"" msgid """"msgid ""Upgrade packages on all nodes:"" msgstr ""Aktualisieren Sie die Pakete auf allen Knoten:"" msgid """" ""Use a deployment tool such as Ansible, Chef, Puppet, or Salt to automate "" ""deployment and management of the production environment. The OpenStack "" ""project has a couple of deployment projects with specific guides per version:"" msgstr """" ""Benutzen Sie ein Bereitstellungswerkzeug wie Ansible, Chef, Puppet oder "" ""Salt, um die Bereitstellung und Verwaltung der Produktivumgebung zu "" ""automatisieren. Das OpenStack Projekt hat eine Reihe von Projekten fr "" ""Bereitstellungswerkzeuge mit spezifischen Guides per Version:"" msgid ""`Pike release <https://docs.openstack.org/pike/deploy/>`_"" msgstr ""`Pike Release <https://docs.openstack.org/pike/deploy/>`_"" msgid ""`Queens release <https://docs.openstack.org/queens/deploy/>`_"" msgstr ""`Queens Release <https://docs.openstack.org/queens/deploy/>`_"" msgid ""`Rocky release <https://docs.openstack.org/rocky/deploy/>`_"" msgstr ""`Rocky Release <https://docs.openstack.org/rocky/deploy/>`_"" msgid ""`Stein release <https://docs.openstack.org/stein/deploy/>`_"" msgstr ""`Stein Release <https://docs.openstack.org/stein/deploy/>`_"" msgid ""`Train release <https://docs.openstack.org/train/deploy/>`_"" msgstr ""`Train Release <https://docs.openstack.org/train/deploy/>`_"" ","""POT-Creation-Date: 2020-01-15 15:42+0000\n""""PO-Revision-Date: 2019-09-19 01:35+0000\n"" ""Last-Translator: Robert Simai <robert.simai@suse.com>\n""",137,8
openstack%2Fneutron~master~I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965,openstack/neutron,master,I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965,[OVN] Import ovsdb related code (part 2),MERGED,2019-11-28 15:40:49.000000000,2020-01-17 07:54:06.000000000,2019-12-10 09:41:50.000000000,"[{'_account_id': 6773}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}, {'_account_id': 27336}]","[{'number': 1, 'created': '2019-11-28 15:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/abe832a1ea8bcabe935d12edeac09d27695212cc', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py -> ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py -> ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 2, 'created': '2019-11-29 13:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/18bfa392c6c2fda6fc99e8bff08d3f4ba3e0159a', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py -> ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py -> ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 3, 'created': '2019-11-29 17:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/101816c50157f4d6a29aaec94f201f704e63e355', 'message': '[WIP] [OVN] Import ovsdb related code (part 2)\n\nTODO: we need to move networking-ovn/agent/stats first\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 4, 'created': '2019-11-29 18:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/628a3e1389b4a336b00cf821c6138422a5c75a9d', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 5, 'created': '2019-12-02 14:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/66fbaf7dea15d6c192d1747ce4108169feb5ef27', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 6, 'created': '2019-12-02 15:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4832db24b5323296025c0a2ed7a9ffdd164bf6e6', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 7, 'created': '2019-12-03 09:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ddbb4e1ba219ab038f4176de61f4a04e5f4e8718', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 8, 'created': '2019-12-06 11:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5b0ca4f6193de38328240c33c1238d7c5bf0929', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 9, 'created': '2019-12-08 22:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39d45f06ab783362a7c7db225812fdd6127ec0d5', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}, {'number': 10, 'created': '2019-12-09 10:07:55.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/schemas/ovn-nb.ovsschema', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/schemas/ovn-sb.ovsschema', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fdb3f050553455ec199b32f43ec0a551ba3d1d1c', 'message': '[OVN] Import ovsdb related code (part 2)\n\nThis patch imports ovsdb related code from networking_ovn.\n\nPrevious paths in networking-ovn tree:\n./networking_ovn/ovsdb/ovsdb_monitor.py ->\n  ./neutron/ovsdb/ovn/ovsdb_monitor.py\n./networking_ovn/ovsdb/impl_idl_ovn.py ->\n  ./neutron/ovsdb/ovn/impl_idl_ovn.py\n\nChange-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965\nRelated-Blueprint: neutron-ovn-merge\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>\n'}]",2,696604,fdb3f050553455ec199b32f43ec0a551ba3d1d1c,67,9,10,6773,,,0,"[OVN] Import ovsdb related code (part 2)

This patch imports ovsdb related code from networking_ovn.

Previous paths in networking-ovn tree:
./networking_ovn/ovsdb/ovsdb_monitor.py ->
  ./neutron/ovsdb/ovn/ovsdb_monitor.py
./networking_ovn/ovsdb/impl_idl_ovn.py ->
  ./neutron/ovsdb/ovn/impl_idl_ovn.py

Change-Id: I5fe40a3b3e62e8c2adeb6660d1673dee49fe4965
Related-Blueprint: neutron-ovn-merge
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
Co-Authored-By: Rodolfo Alonso Hernandez <ralonsoh@redhat.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/696604/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/ovsdb/ovn/impl_idl_ovn.py', 'neutron/ovsdb/ovn/ovsdb_monitor.py']",2,abe832a1ea8bcabe935d12edeac09d27695212cc,bp/neutron-ovn-merge,"# Copyright 2016 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import abc import datetime from neutron.conf import ovn as ovn_config from neutron.common.ovn import constants as ovn_const from neutron.common.ovn import exceptions from neutron.common.ovn import hash_ring_manager from neutron.common.ovn import utils from neutron.db import ovn_hash_ring_db from neutron_lib.plugins import constants from neutron_lib.plugins import directory from neutron_lib.utils import helpers from oslo_config import cfg from oslo_log import log from oslo_utils import timeutils from ovs.stream import Stream from ovsdbapp.backend.ovs_idl import connection from ovsdbapp.backend.ovs_idl import event as row_event from ovsdbapp.backend.ovs_idl import idlutils from ovsdbapp import event CONF = cfg.CONF LOG = log.getLogger(__name__) class BaseEvent(row_event.RowEvent): table = None events = tuple() def __init__(self): self.event_name = self.__class__.__name__ super(BaseEvent, self).__init__(self.events, self.table, None) @abc.abstractmethod def match_fn(self, event, row, old=None): """"""Define match criteria other than table/event"""""" def matches(self, event, row, old=None): if row._table.name != self.table or event not in self.events: return False if not self.match_fn(event, row, old): return False LOG.debug(""%s : Matched %s, %s, %s %s"", self.event_name, self.table, event, self.conditions, self.old_conditions) return True class ChassisEvent(row_event.RowEvent): """"""Chassis create update delete event."""""" def __init__(self, driver): self.driver = driver self.l3_plugin = directory.get_plugin(constants.L3) table = 'Chassis' events = (self.ROW_CREATE, self.ROW_UPDATE, self.ROW_DELETE) super(ChassisEvent, self).__init__(events, table, None) self.event_name = 'ChassisEvent' def run(self, event, row, old): host = row.hostname phy_nets = [] if event != self.ROW_DELETE: bridge_mappings = row.external_ids.get('ovn-bridge-mappings', '') mapping_dict = helpers.parse_mappings(bridge_mappings.split(','), unique_values=False) phy_nets = list(mapping_dict) self.driver.update_segment_host_mapping(host, phy_nets) if utils.is_ovn_l3(self.l3_plugin): self.l3_plugin.schedule_unhosted_gateways() class PortBindingChassisUpdateEvent(row_event.RowEvent): """"""Event for matching a port moving chassis If the LSP is up and the Port_Binding chassis has just changed, there is a good chance the host died without cleaning up the chassis column on the Port_Binding. The port never goes down, so we won't see update the driver with the LogicalSwitchPortUpdateUpEvent which only monitors for transitions from DOWN to UP. """""" def __init__(self, driver): self.driver = driver table = 'Port_Binding' events = (self.ROW_UPDATE,) super(PortBindingChassisUpdateEvent, self).__init__( events, table, None) self.event_name = self.__class__.__name__ def match_fn(self, event, row, old=None): # NOTE(twilson) ROW_UPDATE events always pass old, but chassis will # only be set if chassis has changed old_chassis = getattr(old, 'chassis', None) if not (row.chassis and old_chassis) or row.chassis == old_chassis: return False if row.type == ovn_const.OVN_CHASSIS_REDIRECT: return False try: lsp = self.driver._nb_ovn.lookup('Logical_Switch_Port', row.logical_port) except idlutils.RowNotFound: LOG.warning(""Logical Switch Port %(port)s not found for "" ""Port_Binding %(binding)s"", {'port': row.logical_port, 'binding': row.uuid}) return False return bool(lsp.up) def run(self, event, row, old=None): self.driver.set_port_status_up(row.logical_port) class PortBindingChassisEvent(row_event.RowEvent): """"""Port_Binding update event - set chassis for chassisredirect port. When a chassisredirect port is updated with chassis, this event get generated. We will update corresponding router's gateway port with the chassis's host_id. Later, users can check router's gateway port host_id to find the location of master HA router. """""" def __init__(self, driver): self.driver = driver self.l3_plugin = directory.get_plugin(constants.L3) table = 'Port_Binding' events = (self.ROW_UPDATE,) super(PortBindingChassisEvent, self).__init__( events, table, (('type', '=', ovn_const.OVN_CHASSIS_REDIRECT),)) self.event_name = 'PortBindingChassisEvent' def run(self, event, row, old): if not utils.is_ovn_l3(self.l3_plugin): return router = host = None chassis = getattr(row, 'chassis', None) if chassis: router = row.datapath.external_ids.get('name', '').replace( 'neutron-', '') host = chassis[0].hostname LOG.info(""Router %(router)s is bound to host %(host)s"", {'router': router, 'host': host}) self.l3_plugin.update_router_gateway_port_bindings( router, host) class LogicalSwitchPortCreateUpEvent(row_event.RowEvent): """"""Row create event - Logical_Switch_Port 'up' = True. On connection, we get a dump of all ports, so if there is a neutron port that is down that has since been activated, we'll catch it here. This event will not be generated for new ports getting created. """""" def __init__(self, driver): self.driver = driver table = 'Logical_Switch_Port' events = (self.ROW_CREATE,) super(LogicalSwitchPortCreateUpEvent, self).__init__( events, table, (('up', '=', True),)) self.event_name = 'LogicalSwitchPortCreateUpEvent' def run(self, event, row, old): self.driver.set_port_status_up(row.name) class LogicalSwitchPortCreateDownEvent(row_event.RowEvent): """"""Row create event - Logical_Switch_Port 'up' = False On connection, we get a dump of all ports, so if there is a neutron port that is up that has since been deactivated, we'll catch it here. This event will not be generated for new ports getting created. """""" def __init__(self, driver): self.driver = driver table = 'Logical_Switch_Port' events = (self.ROW_CREATE,) super(LogicalSwitchPortCreateDownEvent, self).__init__( events, table, (('up', '=', False),)) self.event_name = 'LogicalSwitchPortCreateDownEvent' def run(self, event, row, old): self.driver.set_port_status_down(row.name) class LogicalSwitchPortUpdateUpEvent(row_event.RowEvent): """"""Row update event - Logical_Switch_Port 'up' going from False to True This happens when the VM goes up. New value of Logical_Switch_Port 'up' will be True and the old value will be False. """""" def __init__(self, driver): self.driver = driver table = 'Logical_Switch_Port' events = (self.ROW_UPDATE,) super(LogicalSwitchPortUpdateUpEvent, self).__init__( events, table, (('up', '=', True),), old_conditions=(('up', '=', False),)) self.event_name = 'LogicalSwitchPortUpdateUpEvent' def run(self, event, row, old): self.driver.set_port_status_up(row.name) class LogicalSwitchPortUpdateDownEvent(row_event.RowEvent): """"""Row update event - Logical_Switch_Port 'up' going from True to False This happens when the VM goes down. New value of Logical_Switch_Port 'up' will be False and the old value will be True. """""" def __init__(self, driver): self.driver = driver table = 'Logical_Switch_Port' events = (self.ROW_UPDATE,) super(LogicalSwitchPortUpdateDownEvent, self).__init__( events, table, (('up', '=', False),), old_conditions=(('up', '=', True),)) self.event_name = 'LogicalSwitchPortUpdateDownEvent' def run(self, event, row, old): self.driver.set_port_status_down(row.name) class FIPAddDeleteEvent(row_event.RowEvent): """"""Row event - NAT 'dnat_and_snat' entry added or deleted This happens when a FIP is created or removed. """""" def __init__(self, driver): self.driver = driver table = 'NAT' events = (self.ROW_CREATE, self.ROW_DELETE) super(FIPAddDeleteEvent, self).__init__( events, table, (('type', '=', 'dnat_and_snat'),)) self.event_name = 'FIPAddDeleteEvent' def run(self, event, row, old): # When a FIP is added or deleted, we will delete all entries in the # MAC_Binding table of SB OVSDB corresponding to that IP Address. # TODO(dalvarez): Remove this workaround once fixed in core OVN: # https://mail.openvswitch.org/pipermail/ovs-discuss/2018-October/047604.html self.driver.delete_mac_binding_entries(row.external_ip) class OvnDbNotifyHandler(event.RowEventHandler): def __init__(self, driver): super(OvnDbNotifyHandler, self).__init__() self.driver = driver class BaseOvnIdl(connection.OvsdbIdl): @classmethod def from_server(cls, connection_string, schema_name): _check_and_set_ssl_files(schema_name) helper = idlutils.get_schema_helper(connection_string, schema_name) helper.register_all() return cls(connection_string, helper) class BaseOvnSbIdl(connection.OvsdbIdl): @classmethod def from_server(cls, connection_string, schema_name): _check_and_set_ssl_files(schema_name) helper = idlutils.get_schema_helper(connection_string, schema_name) helper.register_table('Chassis') helper.register_table('Encap') helper.register_table('Port_Binding') helper.register_table('Datapath_Binding') return cls(connection_string, helper) class OvnIdl(BaseOvnIdl): def __init__(self, driver, remote, schema): super(OvnIdl, self).__init__(remote, schema) self.driver = driver self.notify_handler = OvnDbNotifyHandler(driver) # ovsdb lock name to acquire. # This event lock is used to handle the notify events sent by idl.Idl # idl.Idl will call notify function for the ""update"" rpc method it # receives from the ovsdb-server. # This event lock is required for the following reasons # - If there are multiple neutron servers running, OvnWorkers of # these neutron servers would receive the notify events from # idl.Idl # # - we do not want all the neutron servers to handle these events # # - only the neutron server which has the lock will handle the # notify events. # # - In case the neutron server which owns this lock goes down, # ovsdb server would assign the lock to one of the other neutron # servers. self.event_lock_name = ""neutron_ovn_event_lock"" def notify(self, event, row, updates=None): # Do not handle the notification if the event lock is requested, # but not granted by the ovsdb-server. if self.is_lock_contended: return self.notify_handler.notify(event, row, updates) @abc.abstractmethod def post_connect(self): """"""Should be called after the idl has been initialized"""""" class OvnIdlDistributedLock(BaseOvnIdl): def __init__(self, driver, remote, schema): super(OvnIdlDistributedLock, self).__init__(remote, schema) self.driver = driver self.notify_handler = OvnDbNotifyHandler(driver) self._node_uuid = self.driver.node_uuid self._hash_ring = hash_ring_manager.HashRingManager( self.driver.hash_ring_group) self._last_touch = None def notify(self, event, row, updates=None): try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ovn_hash_ring_db.touch_node(self._node_uuid) self._last_touch = time_now except Exception as e: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates) @abc.abstractmethod def post_connect(self): """"""Should be called after the idl has been initialized"""""" class OvnNbIdl(OvnIdlDistributedLock): def __init__(self, driver, remote, schema): super(OvnNbIdl, self).__init__(driver, remote, schema) self._lsp_update_up_event = LogicalSwitchPortUpdateUpEvent(driver) self._lsp_update_down_event = LogicalSwitchPortUpdateDownEvent(driver) self._lsp_create_up_event = LogicalSwitchPortCreateUpEvent(driver) self._lsp_create_down_event = LogicalSwitchPortCreateDownEvent(driver) self._fip_create_delete_event = FIPAddDeleteEvent(driver) self.notify_handler.watch_events([self._lsp_create_up_event, self._lsp_create_down_event, self._lsp_update_up_event, self._lsp_update_down_event, self._fip_create_delete_event]) @classmethod def from_server(cls, connection_string, schema_name, driver): _check_and_set_ssl_files(schema_name) helper = idlutils.get_schema_helper(connection_string, schema_name) helper.register_all() return cls(driver, connection_string, helper) def unwatch_logical_switch_port_create_events(self): """"""Unwatch the logical switch port create events. When the ovs idl client connects to the ovsdb-server, it gets a dump of all logical switch ports as events and we need to process them at start up. After the startup, there is no need to watch these events. So unwatch these events. """""" self.notify_handler.unwatch_events([self._lsp_create_up_event, self._lsp_create_down_event]) self._lsp_create_up_event = None self._lsp_create_down_event = None def post_connect(self): self.unwatch_logical_switch_port_create_events() class OvnSbIdl(OvnIdlDistributedLock): @classmethod def from_server(cls, connection_string, schema_name, driver): _check_and_set_ssl_files(schema_name) helper = idlutils.get_schema_helper(connection_string, schema_name) helper.register_table('Chassis') helper.register_table('Encap') helper.register_table('Port_Binding') helper.register_table('Datapath_Binding') helper.register_table('MAC_Binding') return cls(driver, connection_string, helper) def post_connect(self): """"""Watch Chassis events. When the ovs idl client connects to the ovsdb-server, it gets a dump of all Chassis create event. We don't need to process them because there will be sync up at startup. After that, we will watch the events to make notify work. """""" self._chassis_event = ChassisEvent(self.driver) self._portbinding_event = PortBindingChassisEvent(self.driver) self.notify_handler.watch_events( [self._chassis_event, self._portbinding_event, PortBindingChassisUpdateEvent(self.driver)]) def _check_and_set_ssl_files(schema_name): if schema_name == 'OVN_Southbound': priv_key_file = ovn_config.get_ovn_sb_private_key() cert_file = ovn_config.get_ovn_sb_certificate() ca_cert_file = ovn_config.get_ovn_sb_ca_cert() else: priv_key_file = ovn_config.get_ovn_nb_private_key() cert_file = ovn_config.get_ovn_nb_certificate() ca_cert_file = ovn_config.get_ovn_nb_ca_cert() if priv_key_file: Stream.ssl_set_private_key_file(priv_key_file) if cert_file: Stream.ssl_set_certificate_file(cert_file) if ca_cert_file: Stream.ssl_set_ca_cert_file(ca_cert_file) ",,1301,0
openstack%2Fmanila~stable%2Frocky~Ia52c7aa40a4625efd5763ff6025726d0f0d39087,openstack/manila,stable/rocky,Ia52c7aa40a4625efd5763ff6025726d0f0d39087,Totalcount returned by pagination query is wrong and filters should before pagination query,ABANDONED,2020-01-17 07:02:28.000000000,2020-01-17 07:31:16.000000000,,[],"[{'number': 1, 'created': '2020-01-17 07:02:28.000000000', 'files': ['manila/db/api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/api/v1/shares.py', 'manila/utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f271c3db582290c54a5e19eb7f68ea003bb314bf', 'message': ""Totalcount returned by pagination query is wrong and filters should before pagination query\n\n1.In this bugfix(https://review.opendev.org/#/c/688542/), totalcount returned\nby pagination query is param 'limit'(should be total count of satisfy conditions).\n2.Display_name,status,share_type_id,project_id and so on should filter out\nbefore pagination query, rather than filter out in the result of pagination query.\n3.Fuzzy matching of diaplay_name should use database.\n\nChange-Id: Ia52c7aa40a4625efd5763ff6025726d0f0d39087\n""}]",0,703021,f271c3db582290c54a5e19eb7f68ea003bb314bf,2,0,1,31027,,,0,"Totalcount returned by pagination query is wrong and filters should before pagination query

1.In this bugfix(https://review.opendev.org/#/c/688542/), totalcount returned
by pagination query is param 'limit'(should be total count of satisfy conditions).
2.Display_name,status,share_type_id,project_id and so on should filter out
before pagination query, rather than filter out in the result of pagination query.
3.Fuzzy matching of diaplay_name should use database.

Change-Id: Ia52c7aa40a4625efd5763ff6025726d0f0d39087
",git fetch https://review.opendev.org/openstack/manila refs/changes/21/703021/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/db/api.py', 'manila/share/api.py', 'manila/db/sqlalchemy/api.py', 'manila/api/v1/shares.py', 'manila/utils.py']",5,f271c3db582290c54a5e19eb7f68ea003bb314bf,mrocky,"def get_bool_param(param_string, params, default=False): param = params.get(param_string, default) if not strutils.is_valid_boolstr(param): msg = _(""Value '%(param)s' for '%(param_string)s' is not "" ""a boolean."") % {'param': param, 'param_string': param_string} raise exception.InvalidParameterValue(err=msg) return strutils.bool_from_string(param, strict=True) ",,201,11
openstack%2Frpm-packaging~master~I75c7d968ec91a71386042bb7179a7af07ec85d32,openstack/rpm-packaging,master,I75c7d968ec91a71386042bb7179a7af07ec85d32,Fix monday's list of build failures,MERGED,2019-12-09 09:31:43.000000000,2020-01-17 07:28:08.000000000,2020-01-17 07:28:08.000000000,"[{'_account_id': 7102}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 22595}, {'_account_id': 23181}, {'_account_id': 23851}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-09 09:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/21a24dedca6cc4b8c4995e9a83f4e0f81fce0152', 'message': ""Fix monday's list of build failures\n\nVarious adjustments for current master tree\n\nChange-Id: I75c7d968ec91a71386042bb7179a7af07ec85d32\n""}, {'number': 2, 'created': '2019-12-10 18:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fcffaa4f354cc934cbb7b95953c40dc9598ef454', 'message': ""Fix monday's list of build failures\n\nVarious adjustments for current master tree\n\nChange-Id: I75c7d968ec91a71386042bb7179a7af07ec85d32\n""}, {'number': 3, 'created': '2019-12-20 20:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a11098de2b208747c7bffc2791fa687112a93842', 'message': ""Fix monday's list of build failures\n\nVarious adjustments for current master tree\n\nChange-Id: I75c7d968ec91a71386042bb7179a7af07ec85d32\n""}, {'number': 4, 'created': '2020-01-13 12:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/083d81e436199b4214ced90bdc62247db3d853d4', 'message': ""Fix monday's list of build failures\n\nVarious adjustments for current master tree\n\nChange-Id: I75c7d968ec91a71386042bb7179a7af07ec85d32\n""}, {'number': 5, 'created': '2020-01-13 13:03:00.000000000', 'files': ['openstack/magnum/magnum.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/52a8f870c682a77c3494fd307586264005cc1545', 'message': ""Fix monday's list of build failures\n\nVarious adjustments for current master tree\n\nChange-Id: I75c7d968ec91a71386042bb7179a7af07ec85d32\n""}]",6,697961,52a8f870c682a77c3494fd307586264005cc1545,38,8,5,6593,,,0,"Fix monday's list of build failures

Various adjustments for current master tree

Change-Id: I75c7d968ec91a71386042bb7179a7af07ec85d32
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/61/697961/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/ironic-python-agent/ironic-python-agent.spec.j2', 'openstack/magnum/magnum.spec.j2', 'openstack/os-faults/os-faults.spec.j2']",3,21a24dedca6cc4b8c4995e9a83f4e0f81fce0152,remove-nova-console,"python3 -m pytest --durations=10 ""os_faults/tests/unit""","py.test-3 -vvvv --durations=10 ""os_faults/tests/unit""",4,1
openstack%2Fmasakari-specs~master~I86753c3210ef38cf954fdd175dceb5b77aa31913,openstack/masakari-specs,master,I86753c3210ef38cf954fdd175dceb5b77aa31913,Create specs directory for Ussuri,ABANDONED,2020-01-14 13:44:29.000000000,2020-01-17 07:10:31.000000000,,"[{'_account_id': 3085}, {'_account_id': 8716}, {'_account_id': 22348}, {'_account_id': 24501}]","[{'number': 1, 'created': '2020-01-14 13:44:29.000000000', 'files': ['doc/source/specs/ussuri/redirects', 'specs/ussuri/approved/ussuri-template.rst', 'specs/ussuri/implemented/ussuri-template.rst', 'doc/source/index.rst', 'doc/source/specs/ussuri/approved', 'doc/source/specs/ussuri/implemented', 'doc/source/specs/ussuri/index.rst', 'specs/ussuri/redirects'], 'web_link': 'https://opendev.org/openstack/masakari-specs/commit/91f0c894d03a2cfeaae5e8a8d735edca7bbd7928', 'message': 'Create specs directory for Ussuri\n\nChange-Id: I86753c3210ef38cf954fdd175dceb5b77aa31913\n'}]",0,702426,91f0c894d03a2cfeaae5e8a8d735edca7bbd7928,6,4,1,27302,,,0,"Create specs directory for Ussuri

Change-Id: I86753c3210ef38cf954fdd175dceb5b77aa31913
",git fetch https://review.opendev.org/openstack/masakari-specs refs/changes/26/702426/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/ussuri/redirects', 'specs/ussuri/approved/ussuri-template.rst', 'specs/ussuri/implemented/ussuri-template.rst', 'doc/source/index.rst', 'doc/source/specs/ussuri/approved', 'doc/source/specs/ussuri/implemented', 'doc/source/specs/ussuri/index.rst', 'specs/ussuri/redirects']",8,91f0c894d03a2cfeaae5e8a8d735edca7bbd7928,bp/evacuate-non-recovery-instances-in-shutoff-status-at-host-failure-except-specified-tenants,,,801,0
openstack%2Fpuppet-tripleo~master~I6a06269f55a38071c34d2a95109d213fe7e2452c,openstack/puppet-tripleo,master,I6a06269f55a38071c34d2a95109d213fe7e2452c,HA: Honour all hiera override variables in mysql_bundle,MERGED,2020-01-16 11:57:29.000000000,2020-01-17 06:09:53.000000000,2020-01-17 04:59:15.000000000,"[{'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 11166}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-16 11:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1d8cc853f4bd55a73aadff853f463d6038f7d238', 'message': 'HA: Honour all hiera override variables in mysql_bundle\n\nDuring a major upgrade, upgrade tasks can rebuild a new pacemaker\ncluster by adding nodes one at a time. This is implemented by\nusing two special hiera variables mysql_node_names_override and\nmysql_short_node_names_override.\n\nMake sure the mysql_bundle puppet module uses both variables\nwhen such cluster rebuild is in progress.\n\nChange-Id: I6a06269f55a38071c34d2a95109d213fe7e2452c\nCloses-Bug: #1859961\nCo-Authored-By: Jose Luis Franco Arza <jfrancoa@redhat.com>\n'}, {'number': 2, 'created': '2020-01-16 14:37:30.000000000', 'files': ['manifests/profile/pacemaker/database/mysql_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/0a64eebb6454483e823c4cf12c55832935c2319f', 'message': 'HA: Honour all hiera override variables in mysql_bundle\n\nDuring a major upgrade, upgrade tasks can rebuild a new pacemaker\ncluster by adding nodes one at a time. This is implemented by\nusing two special hiera variables mysql_node_names_override and\nmysql_short_node_names_override.\n\nMake sure the mysql_bundle puppet module uses both variables\nwhen such cluster rebuild is in progress.\n\nChange-Id: I6a06269f55a38071c34d2a95109d213fe7e2452c\nCloses-Bug: #1859961\nCo-Authored-By: Jose Luis Franco Arza <jfrancoa@redhat.com>\n'}]",4,702851,0a64eebb6454483e823c4cf12c55832935c2319f,22,9,2,20778,,,0,"HA: Honour all hiera override variables in mysql_bundle

During a major upgrade, upgrade tasks can rebuild a new pacemaker
cluster by adding nodes one at a time. This is implemented by
using two special hiera variables mysql_node_names_override and
mysql_short_node_names_override.

Make sure the mysql_bundle puppet module uses both variables
when such cluster rebuild is in progress.

Change-Id: I6a06269f55a38071c34d2a95109d213fe7e2452c
Closes-Bug: #1859961
Co-Authored-By: Jose Luis Franco Arza <jfrancoa@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/51/702851/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/database/mysql_bundle.pp'],1,1d8cc853f4bd55a73aadff853f463d6038f7d238,bug/1859961," $galera_node_names_lookup = downcase(hiera('mysql_short_node_names_override', hiera('mysql_short_node_names', $::hostname)))"," $galera_node_names_lookup = downcase(hiera('mysql_short_node_names', $::hostname))",2,1
openstack%2Fcinder~master~I9f11ce7a3600917f60130cfb79b5efd5dd580366,openstack/cinder,master,I9f11ce7a3600917f60130cfb79b5efd5dd580366,Remove the Veritas Access Driver,MERGED,2020-01-02 17:08:14.000000000,2020-01-17 06:04:36.000000000,2020-01-15 15:31:27.000000000,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2020-01-02 17:08:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a194eee87da1fa5f20848fa58cfc3a35efc1d722', 'message': ""Remove the Veritas Access Driver\n\nThe Veritas Access driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: I9f11ce7a3600917f60130cfb79b5efd5dd580366\n""}, {'number': 2, 'created': '2020-01-02 20:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/31d8ef5167a648ab8ca5636afd22666cfef407c5', 'message': ""Remove the Veritas Access Driver\n\nThe Veritas Access driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: I9f11ce7a3600917f60130cfb79b5efd5dd580366\n""}, {'number': 3, 'created': '2020-01-13 19:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1c6bf9aca217340d94ea32c49fc74026b97fd21c', 'message': ""Remove the Veritas Access Driver\n\nThe Veritas Access driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: I9f11ce7a3600917f60130cfb79b5efd5dd580366\n""}, {'number': 4, 'created': '2020-01-14 15:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/cda90b85ccd7312a1ba22d413edd341fa3c39aa0', 'message': ""Remove the Veritas Access Driver\n\nThe Veritas Access driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: I9f11ce7a3600917f60130cfb79b5efd5dd580366\n""}, {'number': 5, 'created': '2020-01-14 15:43:10.000000000', 'files': ['cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'cinder/tests/unit/volume/drivers/veritas_access/__init__.py', 'doc/source/reference/support-matrix.rst', 'cinder/volume/drivers/veritas_access/__init__.py', 'cinder/tests/unit/volume/drivers/veritas_access/test_veritas_iscsi.py', 'releasenotes/notes/veritas-access-driver-removal-dd9f0bc34c798c84.yaml', 'cinder/volume/drivers/veritas_access/veritas_iscsi.py', 'doc/source/configuration/block-storage/drivers/veritas-access-iscsi-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5649da137bccbb6c27c4aa17d0bbd902fefcc114', 'message': ""Remove the Veritas Access Driver\n\nThe Veritas Access driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: I9f11ce7a3600917f60130cfb79b5efd5dd580366\n""}]",1,700917,5649da137bccbb6c27c4aa17d0bbd902fefcc114,749,30,5,7198,,,0,"Remove the Veritas Access Driver

The Veritas Access driver was marked
unsupported during the Train release.  Since
then, the 3rd Party CI hasn't been fixed and
there has been no sign of activity from the
vendor.  As a result the driver is being removed.

Change-Id: I9f11ce7a3600917f60130cfb79b5efd5dd580366
",git fetch https://review.opendev.org/openstack/cinder refs/changes/17/700917/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'cinder/tests/unit/volume/drivers/veritas_access/__init__.py', 'doc/source/reference/support-matrix.rst', 'cinder/volume/drivers/veritas_access/__init__.py', 'cinder/tests/unit/volume/drivers/veritas_access/test_veritas_iscsi.py', 'releasenotes/notes/veritas-access-driver-removal-dd9f0bc34c798c84.yaml', 'cinder/volume/drivers/veritas_access/veritas_iscsi.py', 'doc/source/configuration/block-storage/drivers/veritas-access-iscsi-driver.rst']",9,a194eee87da1fa5f20848fa58cfc3a35efc1d722,ci_unsupported,,"=========================== Veritas ACCESS iSCSI driver =========================== Veritas Access is a software-defined scale-out network-attached storage (NAS) solution for unstructured data that works on commodity hardware and takes advantage of placing data on premise or in the cloud based on intelligent policies. Through Veritas Access iSCSI Driver, OpenStack Block Storage can use Veritas Access backend as a block storage resource. The driver enables you to create iSCSI volumes that an OpenStack Block Storage server can allocate to any virtual machine running on a compute host. Requirements ~~~~~~~~~~~~ The Veritas ACCESS iSCSI Driver, version ``1.0.0`` and later, supports Veritas ACCESS release ``7.4`` and later. Supported operations ~~~~~~~~~~~~~~~~~~~~ - Create and delete volumes. - Create and delete snapshots. - Create volume from snapshot. - Extend a volume. - Attach and detach volumes. - Clone volumes. Configuration ~~~~~~~~~~~~~ #. Enable RESTful service on the Veritas Access Backend. #. Create Veritas Access iSCSI target, add store and portal IP to it. You can create target and add portal IP, store to it as follows: .. code-block:: console Target> iscsi target create iqn.2018-02.com.veritas:target02 Target> iscsi target store add target_fs iqn.2018-02.com.veritas:target02 Target> iscsi target portal add iqn.2018-02.com.veritas:target02 10.10.10.1 ... You can add authentication to target as follows: .. code-block:: console Target> iscsi target auth incominguser add iqn.2018-02.com.veritas:target02 user1 ... #. Ensure that the Veritas Access iSCSI target service is online. If the Veritas Access iSCSI target service is not online, enable the service by using the CLI or REST API. .. code-block:: console Target> iscsi service start Target> iscsi service status ... Define the following required properties in the ``cinder.conf`` file: .. code-block:: ini volume_driver = cinder.volume.drivers.veritas_access.veritas_iscsi.ACCESSIscsiDriver san_ip = va_console_ip san_api_port = 14161 san_login = master san_password = password target_port = 3260 vrts_lun_sparse = True vrts_target_config = /etc/cinder/vrts_target.xml #. Define Veritas Access Target details in ``/etc/cinder/vrts_target.xml``: .. code-block:: console <?xml version=""1.0"" ?> <VRTS> <VrtsTargets> <Target> <Name>iqn.2018-02.com.veritas:target02</Name> <PortalIP>10.10.10.1</PortalIP> <Authentication>0</Authentication> </Target> </VrtsTargets> </VRTS> ... ",8,1665
openstack%2Fkolla-ansible~master~I70f692f125739b5119c71a554a37b5c21d4164f6,openstack/kolla-ansible,master,I70f692f125739b5119c71a554a37b5c21d4164f6,Ansible lint: Variables should have spaces before and after,MERGED,2020-01-16 15:37:38.000000000,2020-01-17 06:02:59.000000000,2020-01-17 06:00:52.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-16 15:37:38.000000000', 'files': ['ansible/roles/ceph/tasks/stop.yml', 'ansible/roles/nova/tasks/refresh_scheduler_cell_cache.yml', 'ansible/roles/manila/tasks/fix_cephfs_owner.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1453474c65b03030373a8102d87ec7fcf96df5bb', 'message': 'Ansible lint: Variables should have spaces before and after\n\nChange-Id: I70f692f125739b5119c71a554a37b5c21d4164f6\n'}]",0,702897,1453474c65b03030373a8102d87ec7fcf96df5bb,10,4,1,24072,,,0,"Ansible lint: Variables should have spaces before and after

Change-Id: I70f692f125739b5119c71a554a37b5c21d4164f6
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/97/702897/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ceph/tasks/stop.yml', 'ansible/roles/nova/tasks/refresh_scheduler_cell_cache.yml', 'ansible/roles/manila/tasks/fix_cephfs_owner.yml']",3,1453474c65b03030373a8102d87ec7fcf96df5bb,," command: ""docker exec -u 0 manila_share mount -t ceph {{ cephfs_addr }} /tmp/cephfs -o name=manila,secret={{ manila_keyring.stdout }}"""," command: ""docker exec -u 0 manila_share mount -t ceph {{cephfs_addr}} /tmp/cephfs -o name=manila,secret={{ manila_keyring.stdout }}""",3,3
openstack%2Fkolla-ansible~master~I83deeb2d8cb483050b41b72233006323aae2b256,openstack/kolla-ansible,master,I83deeb2d8cb483050b41b72233006323aae2b256,Configure disabling verification of CA certificates.,ABANDONED,2020-01-03 19:09:36.000000000,2020-01-17 06:02:18.000000000,,"[{'_account_id': 14826}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 29543}, {'_account_id': 30491}, {'_account_id': 30810}]","[{'number': 1, 'created': '2020-01-03 19:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7efa2e26902e8c6f56c52d4b4d936ecfa6eadd08', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nDepends on: https://review.opendev.org/#/c/699888\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 2, 'created': '2020-01-04 02:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/01ebebb4ffa87f9b0a435694f7a34986add13225', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nDepends on: https://review.opendev.org/#/c/699888\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 3, 'created': '2020-01-06 19:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f113cfc74de2680ca105d0ad131e21b2e7675cdc', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 4, 'created': '2020-01-14 20:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/968fe50fbf7249683e02bf216b864dce37b6c17e', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 5, 'created': '2020-01-14 20:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/671423cf5a5bd663f31c0ff386ff4d050681a3f7', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 6, 'created': '2020-01-14 22:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/521f2d8be38a32fbda2fc658882e23836e44b127', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 7, 'created': '2020-01-15 01:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6d55019e417e268a179bbcd125a5a905e9b04095', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}, {'number': 8, 'created': '2020-01-15 04:15:14.000000000', 'files': ['ansible/roles/elasticsearch/tasks/upgrade.yml', 'ansible/roles/grafana/tasks/post_config.yml', 'ansible/group_vars/all.yml', 'ansible/roles/kibana/tasks/post_config.yml', 'etc/kolla/globals.yml', 'ansible/roles/monasca/tasks/post_config.yml', 'ansible/roles/ironic/handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b95a1b43c7043b50f6aa6c1bbeb8c387afc9f9ba', 'message': 'Configure disabling verification of CA certificates.\n\nAdd configuration variable to disable the verification of the CA cert\nreturned from service REST API. When self signed certificates are\ngenerated for the openstack deployment, the certificates are not\nverifiable. In this case, REST execution for services will fail unless\nverification is disabled. Certificate verification is enabled by\ndefault.\n\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n\nChange-Id: I83deeb2d8cb483050b41b72233006323aae2b256\n'}]",3,701056,b95a1b43c7043b50f6aa6c1bbeb8c387afc9f9ba,29,6,8,30810,,,0,"Configure disabling verification of CA certificates.

Add configuration variable to disable the verification of the CA cert
returned from service REST API. When self signed certificates are
generated for the openstack deployment, the certificates are not
verifiable. In this case, REST execution for services will fail unless
verification is disabled. Certificate verification is enabled by
default.

Partially-Implements: blueprint support-trusted-ca-certificate-file

Change-Id: I83deeb2d8cb483050b41b72233006323aae2b256
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/56/701056/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/elasticsearch/tasks/upgrade.yml', 'ansible/roles/grafana/tasks/post_config.yml', 'ansible/group_vars/all.yml', 'ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/monasca/tasks/post_config.yml', 'ansible/roles/ironic/handlers/main.yml']",6,7efa2e26902e8c6f56c52d4b4d936ecfa6eadd08,bp/add-internal-network/configure-cacert-verification," validate_certs: ""{{ kolla_verify_internal_ca_certs }}""",,19,0
openstack%2Ftripleo-ansible~master~Ibf06ec25e4fea4faaa4534a48d62aa68b0a642a6,openstack/tripleo-ansible,master,Ibf06ec25e4fea4faaa4534a48d62aa68b0a642a6,Quote PermitRootLogin string for the search.,MERGED,2020-01-16 21:28:43.000000000,2020-01-17 05:40:09.000000000,2020-01-17 05:40:09.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-16 21:28:43.000000000', 'files': ['tripleo_ansible/roles/tripleo-sshd/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/61290176d7d3c6baee5db366ec919e804b71b07c', 'message': ""Quote PermitRootLogin string for the search.\n\nThis avoids the error:\n'PermitRootLogin' is undefined\n\nChange-Id: Ibf06ec25e4fea4faaa4534a48d62aa68b0a642a6\nSigned-off-by: Luke Short <ekultails@gmail.com>\n""}]",0,702988,61290176d7d3c6baee5db366ec919e804b71b07c,9,4,1,25877,,,0,"Quote PermitRootLogin string for the search.

This avoids the error:
'PermitRootLogin' is undefined

Change-Id: Ibf06ec25e4fea4faaa4534a48d62aa68b0a642a6
Signed-off-by: Luke Short <ekultails@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/88/702988/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-sshd/tasks/main.yml'],1,61290176d7d3c6baee5db366ec919e804b71b07c,, not ('PermitRootLogin' in tripleo_sshd_server_options), not (PermitRootLogin in tripleo_sshd_server_options),1,1
openstack%2Fzaqar~master~I1d2cdc802ecd76c01671cd5660ae79dd39505d43,openstack/zaqar,master,I1d2cdc802ecd76c01671cd5660ae79dd39505d43,Support query queues with count,MERGED,2020-01-09 04:11:08.000000000,2020-01-17 05:18:12.000000000,2020-01-17 05:16:27.000000000,"[{'_account_id': 8846}, {'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 04:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ec1365ad9d2c270ea1aa68a460191a6704d8df42', 'message': ""Support query queues with count\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 2, 'created': '2020-01-09 05:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bdb34bf33f9cc70d9c53169b5daa01af07d9d6cd', 'message': ""Support query queues with count\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 3, 'created': '2020-01-09 06:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0a76e74dbbbc6f7c2ca5e8138c9a926529d63a94', 'message': ""Support query queues with count\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 4, 'created': '2020-01-09 08:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7b6cf871456933d06924b22b0c8d6762e31ea439', 'message': ""Support query queues with count\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 5, 'created': '2020-01-10 02:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b131b4996b57e6abf3556a6c63b5c7e51cb4ecee', 'message': ""Support query queues with count\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}, {'number': 6, 'created': '2020-01-10 06:53:00.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/queues.inc', 'zaqar/storage/redis/queues.py', 'releasenotes/notes/support-query-quques-with-count-4453825671bb5298.yaml', 'api-ref/source/samples/queues-list-response.json', 'zaqar/storage/sqlalchemy/queues.py', 'zaqar/storage/base.py', 'zaqar/tests/unit/transport/wsgi/v2_0/test_queue_lifecycle.py', 'zaqar/tests/faulty_storage.py', 'zaqar/transport/wsgi/v2_0/queues.py', 'zaqar/storage/pooling.py', 'zaqar/storage/mongodb/queues.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/7aa2522e3d370a70882d07d7641741679616fa55', 'message': ""Support query queues with count\n\nZaqar will support query queues with 'with_count' to\nreturn the amount of the queues. This will help users to\nquickly get the exact total number of queues which they own.\n\nChange-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43\nImplements: blueprint query-queues-with-count\nSigned-off-by: wanghao <sxmatch1986@gmail.com>\n""}]",0,701664,7aa2522e3d370a70882d07d7641741679616fa55,17,3,6,8846,,,0,"Support query queues with count

Zaqar will support query queues with 'with_count' to
return the amount of the queues. This will help users to
quickly get the exact total number of queues which they own.

Change-Id: I1d2cdc802ecd76c01671cd5660ae79dd39505d43
Implements: blueprint query-queues-with-count
Signed-off-by: wanghao <sxmatch1986@gmail.com>
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/64/701664/6 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/redis/queues.py', 'zaqar/storage/sqlalchemy/queues.py', 'zaqar/storage/base.py', 'zaqar/transport/wsgi/v2_0/queues.py', 'zaqar/storage/pooling.py', 'zaqar/storage/mongodb/queues.py']",6,ec1365ad9d2c270ea1aa68a460191a6704d8df42,bp/query-queues-with-count," @utils.raises_conn_error @utils.retries_on_autoreconnect def _calculate_resource_count(self, project=None): query = utils.scoped_query(None, project, None, None) projection = {'p_q': 1, '_id': 0} return self._collection.find(query, projection=projection).count() ",,50,5
openstack%2Fpuppet-tripleo~master~I985d0d192ef3accf7fdd31503348de80713fded4,openstack/puppet-tripleo,master,I985d0d192ef3accf7fdd31503348de80713fded4,Make the bundle user configurable via hiera,MERGED,2019-12-19 07:53:29.000000000,2020-01-17 05:15:40.000000000,2020-01-17 05:15:40.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-12-19 07:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/eb7b4eedf8bdfc479e3dbccdc57fbdc5ffc55293', 'message': 'WIP Make the bundle user configurable via hiera\n\nAllow all bundles --user option to be overridden as some of them might\nprefer switching to a non-root user when possible.\nThe ovn-dbs bundle is a bit special because it never specified any user.\nHence we default that user to undef and do not set anything.\n\nChange-Id: I985d0d192ef3accf7fdd31503348de80713fded4\n'}, {'number': 2, 'created': '2019-12-19 13:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8021a9c19f24c41f69b0b3d07ffba8045603e1a3', 'message': 'WIP Make the bundle user configurable via hiera\n\nAllow all bundles --user option to be overridden as some of them might\nprefer switching to a non-root user when possible.\nThe ovn-dbs bundle is a bit special because it never specified any user.\nHence we default that user to undef and do not set anything.\n\nChange-Id: I985d0d192ef3accf7fdd31503348de80713fded4\n'}, {'number': 3, 'created': '2020-01-11 09:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e082a28f5a56eb221cf264ca01dabf04ec0d95bd', 'message': 'WIP Make the bundle user configurable via hiera\n\nAllow all bundles --user option to be overridden as some of them might\nprefer switching to a non-root user when possible.\nThe ovn-dbs bundle is a bit special because it never specified any user.\nHence we default that user to undef and do not set anything.\n\nChange-Id: I985d0d192ef3accf7fdd31503348de80713fded4\n'}, {'number': 4, 'created': '2020-01-13 12:29:38.000000000', 'files': ['manifests/profile/pacemaker/database/redis_bundle.pp', 'manifests/profile/pacemaker/rabbitmq_bundle.pp', 'manifests/profile/pacemaker/haproxy_bundle.pp', 'manifests/profile/pacemaker/cinder/volume_bundle.pp', 'manifests/profile/pacemaker/manila/share_bundle.pp', 'manifests/profile/pacemaker/database/mysql_bundle.pp', 'manifests/profile/pacemaker/cinder/backup_bundle.pp', 'manifests/profile/pacemaker/ovn_dbs_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d766eb81a3eb1864aa9c6d4b3b4d5fb978282219', 'message': ""Make the bundle user configurable via hiera\n\nAllow all bundles --user option to be overridden as some of them might\nprefer switching to a non-root user when possible.\nThe ovn-dbs bundle is a bit special because it never specified any user.\nHence we default that user to undef and do not set anything.\n\nTested as follows:\n1. deployed an overcloud\n2. patched it with this change\n3. redeployed and and then observed that no HA container has restarted at all\n4. verified cinder-volume runs with root by default:\nUSER  PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot    1  0.0  0.0   4204   716 ?        Ss   09:01   0:00 dumb-init --single-child -- /bin/bash /usr/local/bin/kolla_start\nroot    7  0.7  0.7 912976 145760 ?       S    09:01   1:04 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf\nroot   71  0.1  0.6 925800 124640 ?       S    09:01   0:14 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf\n5. added 'tripleo::profile::pacemaker::cinder::volume_bundle::bundle_user: cinder' to\n   the templates and redeployed\n6. Observed that cinder-volume got restarted and now runs with cinder\n   user:\nUSER   PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\ncinder   1  0.0  0.0   4204   804 ?        Ss   12:23   0:00 dumb-init --single-child -- /bin/bash /usr/local/bin/kolla_start\ncinder   7  2.1  0.7 912976 145432 ?       S    12:23   0:04 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf\ncinder  64  0.3  0.5 919908 118452 ?       S    12:23   0:00 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf\n\nChange-Id: I985d0d192ef3accf7fdd31503348de80713fded4\n""}]",0,699926,d766eb81a3eb1864aa9c6d4b3b4d5fb978282219,28,5,4,20172,,,0,"Make the bundle user configurable via hiera

Allow all bundles --user option to be overridden as some of them might
prefer switching to a non-root user when possible.
The ovn-dbs bundle is a bit special because it never specified any user.
Hence we default that user to undef and do not set anything.

Tested as follows:
1. deployed an overcloud
2. patched it with this change
3. redeployed and and then observed that no HA container has restarted at all
4. verified cinder-volume runs with root by default:
USER  PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root    1  0.0  0.0   4204   716 ?        Ss   09:01   0:00 dumb-init --single-child -- /bin/bash /usr/local/bin/kolla_start
root    7  0.7  0.7 912976 145760 ?       S    09:01   1:04 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf
root   71  0.1  0.6 925800 124640 ?       S    09:01   0:14 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf
5. added 'tripleo::profile::pacemaker::cinder::volume_bundle::bundle_user: cinder' to
   the templates and redeployed
6. Observed that cinder-volume got restarted and now runs with cinder
   user:
USER   PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
cinder   1  0.0  0.0   4204   804 ?        Ss   12:23   0:00 dumb-init --single-child -- /bin/bash /usr/local/bin/kolla_start
cinder   7  2.1  0.7 912976 145432 ?       S    12:23   0:04 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf
cinder  64  0.3  0.5 919908 118452 ?       S    12:23   0:00 /usr/bin/python3 /usr/bin/cinder-volume --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf

Change-Id: I985d0d192ef3accf7fdd31503348de80713fded4
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/26/699926/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/pacemaker/database/redis_bundle.pp', 'manifests/profile/pacemaker/rabbitmq_bundle.pp', 'manifests/profile/pacemaker/haproxy_bundle.pp', 'manifests/profile/pacemaker/cinder/volume_bundle.pp', 'manifests/profile/pacemaker/manila/share_bundle.pp', 'manifests/profile/pacemaker/database/mysql_bundle.pp', 'manifests/profile/pacemaker/cinder/backup_bundle.pp', 'manifests/profile/pacemaker/ovn_dbs_bundle.pp']",8,eb7b4eedf8bdfc479e3dbccdc57fbdc5ffc55293,no_privileges,"# [*bundle_user*] # (optional) Set the --user= switch to be passed to pcmk # Defaults to undef # $bundle_user = undef, if $bundle_user == undef { $bundle_user_real = '' } else { $bundle_user_real = ""--user=${bundle_user} "" } options => ""${bundle_user_real}--log-driver=${log_driver_real} -e KOLLA_CONFIG_STRATEGY=COPY_ALWAYS${tls_priorities_real}"","," options => ""--log-driver=${log_driver_real} -e KOLLA_CONFIG_STRATEGY=COPY_ALWAYS${tls_priorities_real}"",",53,8
openstack%2Frequirements~stable%2Fstein~I8f76b6b486993637228e6893c792cfa6ffada3bd,openstack/requirements,stable/stein,I8f76b6b486993637228e6893c792cfa6ffada3bd,Remove trusty wheel build jobs,MERGED,2020-01-16 16:24:33.000000000,2020-01-17 05:06:54.000000000,2020-01-17 05:06:54.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 16:24:33.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/267a994024e702aa1c76dd878d35436a04d361d3', 'message': 'Remove trusty wheel build jobs\n\nIn prepartion for Trusty node removal, stop testing wheel builds in\nrequirements.\n\nChange-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd\n(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)\n'}]",0,702913,267a994024e702aa1c76dd878d35436a04d361d3,10,5,1,6547,,,0,"Remove trusty wheel build jobs

In prepartion for Trusty node removal, stop testing wheel builds in
requirements.

Change-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd
(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/702913/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,267a994024e702aa1c76dd878d35436a04d361d3,trusty-removal,, - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt,0,6
openstack%2Ftripleo-heat-templates~master~Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae,openstack/tripleo-heat-templates,master,Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae,Don't disable compute cell in scale down tasks for additional cells,MERGED,2020-01-15 12:57:57.000000000,2020-01-17 04:53:44.000000000,2020-01-16 23:14:48.000000000,"[{'_account_id': 3153}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 25877}, {'_account_id': 30133}]","[{'number': 1, 'created': '2020-01-15 12:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9417f380212b4e910952aec6846fd9d0dc84ac5b', 'message': ""Don't disable compute cell in scale down tasks for additional cells\n\nWhen we scale down a compute in an additional cell, disabling the compute\nservice fails in scale down tasks as the workflow of scale down a compute\nfrom an additional cell is:\n\n- migrate off instances from the compute or delete them\n- remove the compute from the cell (nova-manage command)\n- scale down the cell stack\n\nUntil we have not fully automated scale down of a compute from an additional\ncell, don't run disable of compute service as we have already removed it from\ncell in pre steps.\n\nChange-Id: Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae\nCloses-Bug: #1859825\n""}, {'number': 2, 'created': '2020-01-15 15:58:24.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee778fc245f787f721fad35abf1744f9c6f71906', 'message': ""Don't disable compute cell in scale down tasks for additional cells\n\nWhen we scale down a compute in an additional cell, disabling the compute\nservice fails in scale down tasks as the workflow of scale down a compute\nfrom an additional cell is [1]:\n\n- migrate off instances from the compute or delete them\n- remove the compute from the cell (nova-manage command)\n- scale down the cell stack\n\nUntil we have fully automated scale down of a compute from an additional\ncell, don't run disable of compute service as we have already removed it from\ncell in pre steps.\n\n[1] https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/deploy_cellv2_manage_cell.html#delete-a-compute-from-a-cell\n\nChange-Id: Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae\nCloses-Bug: #1859825\n""}]",3,702661,ee778fc245f787f721fad35abf1744f9c6f71906,16,10,2,17216,,,0,"Don't disable compute cell in scale down tasks for additional cells

When we scale down a compute in an additional cell, disabling the compute
service fails in scale down tasks as the workflow of scale down a compute
from an additional cell is [1]:

- migrate off instances from the compute or delete them
- remove the compute from the cell (nova-manage command)
- scale down the cell stack

Until we have fully automated scale down of a compute from an additional
cell, don't run disable of compute service as we have already removed it from
cell in pre steps.

[1] https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/features/deploy_cellv2_manage_cell.html#delete-a-compute-from-a-cell

Change-Id: Ie699d7d3367652f4a4dfcb5bf7e52b81c4325aae
Closes-Bug: #1859825
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/61/702661/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-compute-container-puppet.yaml'],1,9417f380212b4e910952aec6846fd9d0dc84ac5b,1859825, - name: is additional Cell? set_fact: is_additional_cell: {get_param: NovaAdditionalCell} - not is_additional_cell|bool,,4,0
openstack%2Fopenstack-ansible~stable%2Ftrain~Ia01ccc6e0cc360d4ed521200afca12c10d730613,openstack/openstack-ansible,stable/train,Ia01ccc6e0cc360d4ed521200afca12c10d730613,Update ansible to 2.8.7,MERGED,2020-01-13 15:35:49.000000000,2020-01-17 04:52:33.000000000,2020-01-17 04:50:26.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-01-13 15:35:49.000000000', 'files': ['scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e9384b686a968d35526a2a432db410fa926e9826', 'message': 'Update ansible to 2.8.7\n\nChange-Id: Ia01ccc6e0cc360d4ed521200afca12c10d730613\n(cherry picked from commit be1bf308498904d56c4ce49ec46f188f23ee5aa4)\n'}]",0,702243,e9384b686a968d35526a2a432db410fa926e9826,12,4,1,28619,,,0,"Update ansible to 2.8.7

Change-Id: Ia01ccc6e0cc360d4ed521200afca12c10d730613
(cherry picked from commit be1bf308498904d56c4ce49ec46f188f23ee5aa4)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/43/702243/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/bootstrap-ansible.sh'],1,e9384b686a968d35526a2a432db410fa926e9826,,"export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible==2.8.7""}","export ANSIBLE_PACKAGE=${ANSIBLE_PACKAGE:-""ansible==2.8.5""}",1,1
openstack%2Fcookiecutter~master~I41381f2ae8a641b8d9052ee8872a460e65c56630,openstack/cookiecutter,master,I41381f2ae8a641b8d9052ee8872a460e65c56630,Update CONTRIBUTING.rst template,MERGED,2019-11-26 01:04:47.000000000,2020-01-17 03:50:20.000000000,2020-01-16 19:30:59.000000000,"[{'_account_id': 2}, {'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 7198}, {'_account_id': 8556}, {'_account_id': 15334}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-11-26 01:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/89c61d38b7e9c17b099f0ec8db4dc28bd9fad375', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 2, 'created': '2019-12-05 00:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/3f2bc58f4ceee1e055808befc2b14d93772769c0', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 3, 'created': '2019-12-05 22:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/02fc1467b85a550c84d3bb8363a9795fd47a4b10', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 4, 'created': '2019-12-09 18:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/093d5ac4dd93403c49b3690da201bd838104d059', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 5, 'created': '2019-12-11 01:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/0fe75da2abb1d19377b96ca6f92bb7154c975f05', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 6, 'created': '2019-12-17 23:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/b6a13691c74e644d974fb7f8a5c3dcbc4004f637', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 7, 'created': '2019-12-17 23:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/8221847eab643aa81e1f2efea4e94b6e621d6947', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 8, 'created': '2019-12-18 18:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/a010e9859ace588be0551f2408832a943b63fff8', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 9, 'created': '2020-01-07 15:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/867e3b618b3a324be5f19c1b159d560c53f676f1', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}, {'number': 10, 'created': '2020-01-07 15:31:05.000000000', 'files': ['{{cookiecutter.repo_name}}/doc/source/contributor/contributing.rst'], 'web_link': 'https://opendev.org/openstack/cookiecutter/commit/2eab7591ef0ed33e563dc7f02a45e6bc2c5eb1d1', 'message': 'Update CONTRIBUTING.rst template\n\nAs a part of the Ussuri Community Goal, the template here needs to\nexpanded to outline the things that are consistenly different between\nprojects or different from the norm that should be documented so that\nnew contributors can more easy onboard themselves to a given project.\n\nGoal Patch: https://review.opendev.org/#/c/691737/2\n\nChange-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630\n'}]",66,696001,2eab7591ef0ed33e563dc7f02a45e6bc2c5eb1d1,55,10,10,16708,,,0,"Update CONTRIBUTING.rst template

As a part of the Ussuri Community Goal, the template here needs to
expanded to outline the things that are consistenly different between
projects or different from the norm that should be documented so that
new contributors can more easy onboard themselves to a given project.

Goal Patch: https://review.opendev.org/#/c/691737/2

Change-Id: I41381f2ae8a641b8d9052ee8872a460e65c56630
",git fetch https://review.opendev.org/openstack/cookiecutter refs/changes/01/696001/7 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,89c61d38b7e9c17b099f0ec8db4dc28bd9fad375,community-goal-template,"####################### So You Want to Contribute.. ####################### For general information on contributing to OpenStack, please check out the `contributor guide <https://docs.openstack.org/contributors/>`_ to get started. It covers all the basics that are common to all OpenStack projects: the accounts you need, the basics of interacting with our Gerrit review system, how we communicate as a community, etc. Below will cover the more project specific information you need to get started with $PROJECT. Communication -------------------- .. This would be a good place to put the channel you chat in as a project; when/ where your meeting is, the tags you prepend to your ML threads, etc. New Feature Planning ---------------------------- .. This section is for talking about the process to get a new feature in. Some projects use blueprints, some want specs, some want both! Some projects stick to a strict schedule when selecting what new features will be reviewed for a release. Task Tracking ------------------ .. This section is about where you track tasks- launchpad? storyboard? is there more than one launchpad project? what's the name of the project group in storyboard? We track our tasks in $LOCATION. Getting a +W on your Patch ------------------------------------ .. This section should have info about what it takes to get something merged. Do you require one or two +2's before +W? Do some of your repos require unit test changes with all patches? etc. Project Team Lead Duties ==================== .. this section is where you can put PTL specific duties not already listed in the PTL guide: https://docs.openstack.org/project-team-guide/ptl.html ","If you would like to contribute to the development of OpenStack, you must follow the steps in this page: https://docs.openstack.org/infra/manual/developers.html If you already have a good understanding of how the system works and your OpenStack accounts are set up, you can skip to the development workflow section of this documentation to learn how changes to OpenStack should be submitted for review via the Gerrit tool: https://docs.openstack.org/infra/manual/developers.html#development-workflow Pull requests submitted through GitHub will be ignored. Bugs should be filed on Launchpad, not GitHub: https://bugs.launchpad.net/oslo",39,11
openstack%2Frequirements~stable%2Ftrain~I8f76b6b486993637228e6893c792cfa6ffada3bd,openstack/requirements,stable/train,I8f76b6b486993637228e6893c792cfa6ffada3bd,Remove trusty wheel build jobs,MERGED,2020-01-16 16:24:08.000000000,2020-01-17 03:24:08.000000000,2020-01-17 03:24:08.000000000,"[{'_account_id': 7118}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 16:24:08.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7d964de99c6bb0481f48b98ce32fe19b52697032', 'message': 'Remove trusty wheel build jobs\n\nIn prepartion for Trusty node removal, stop testing wheel builds in\nrequirements.\n\nChange-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd\n(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)\n'}]",0,702911,7d964de99c6bb0481f48b98ce32fe19b52697032,8,4,1,6547,,,0,"Remove trusty wheel build jobs

In prepartion for Trusty node removal, stop testing wheel builds in
requirements.

Change-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd
(cherry picked from commit 5ba28d145c535fc1ce6efb18e45da9269cf9138a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/11/702911/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,7d964de99c6bb0481f48b98ce32fe19b52697032,trusty-removal,, - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt,0,6
openstack%2Fhorizon~master~I0b567382edf4d68674a7b8d0b02333fb57293958,openstack/horizon,master,I0b567382edf4d68674a7b8d0b02333fb57293958,Remove six usage from horizon package,MERGED,2020-01-08 22:18:06.000000000,2020-01-17 02:59:04.000000000,2020-01-17 02:57:38.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-01-08 22:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9348e4ea50b8ac7797fccb379a89b3ab0398dde9', 'message': ""Remove six usage from openstack_auth package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I0b567382edf4d68674a7b8d0b02333fb57293958\n""}, {'number': 2, 'created': '2020-01-09 10:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5ebf27d7ab583ac529e50b6b7c7091aa21a1f75c', 'message': ""Remove six usage from horizon package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I0b567382edf4d68674a7b8d0b02333fb57293958\n""}, {'number': 3, 'created': '2020-01-10 08:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3a9eff62a140dceca6f816244960800874925fb2', 'message': ""Remove six usage from horizon package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I0b567382edf4d68674a7b8d0b02333fb57293958\n""}, {'number': 4, 'created': '2020-01-15 10:36:27.000000000', 'files': ['horizon/tables/base.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/admin/networks/tests.py', 'horizon/forms/fields.py', 'horizon/test/unit/tabs/test_tabs.py', 'horizon/base.py', 'horizon/exceptions.py', 'openstack_dashboard/dashboards/admin/volumes/tests.py', 'horizon/tables/actions.py', 'horizon/utils/csvbase.py', 'horizon/test/unit/utils/test_babel_extract_angular.py', 'openstack_dashboard/dashboards/identity/mappings/tests.py', 'horizon/utils/functions.py', 'horizon/middleware/operation_log.py', 'horizon/tables/formset.py', 'openstack_dashboard/dashboards/admin/snapshots/tests.py', 'horizon/test/unit/test_base.py', 'horizon/test/unit/test_messages.py', 'openstack_dashboard/dashboards/admin/aggregates/tests.py', 'openstack_dashboard/dashboards/identity/projects/tests.py', 'openstack_dashboard/dashboards/admin/images/tests.py', 'openstack_dashboard/dashboards/identity/domains/tests.py', 'horizon/utils/settings.py', 'horizon/test/helpers.py', 'horizon/workflows/views.py', 'openstack_dashboard/dashboards/identity/groups/tests.py', 'openstack_dashboard/dashboards/project/key_pairs/tests.py', 'openstack_dashboard/dashboards/project/security_groups/tests.py', 'openstack_dashboard/dashboards/admin/rbac_policies/tests.py', 'horizon/test/unit/workflows/test_workflows.py', 'horizon/templatetags/angular.py', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'horizon/workflows/base.py', 'openstack_dashboard/dashboards/admin/routers/tests.py', 'openstack_dashboard/dashboards/project/backups/tests.py', 'openstack_dashboard/dashboards/project/networks/ports/tests.py', 'horizon/test/unit/test_exceptions.py', 'openstack_dashboard/dashboards/identity/users/tests.py', 'openstack_dashboard/dashboards/admin/flavors/tests.py', 'openstack_dashboard/dashboards/project/snapshots/tests.py', 'horizon/tabs/base.py', 'openstack_dashboard/dashboards/identity/roles/tests.py', 'openstack_dashboard/test/unit/usage/test_quotas.py', 'horizon/utils/babel_extract_angular.py', 'openstack_dashboard/dashboards/project/routers/tests.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'horizon/utils/scss_filter.py', 'horizon/test/unit/tables/test_tables.py', 'openstack_dashboard/dashboards/admin/hypervisors/tests.py', 'openstack_dashboard/dashboards/admin/volume_types/tests.py', 'openstack_dashboard/dashboards/admin/networks/subnets/tests.py', 'openstack_dashboard/dashboards/identity/identity_providers/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e976461d85f370762798316dbcc1d156ef8d4feb', 'message': ""Remove six usage from horizon package\n\nWe don't support Python 2 anymore so we don't need this\ncompatibility library.\n\nsix.reraise usages are left as is until it'll be moved to some\nbase lib like oslo.utils to not re-implenent this method in\nHorizon.\n\nThis patch also removes Python2-specific base test case methods\nassertItemsEqual and assertNotRegexpMatches in flavor of new\nPython 3 analogues.\n\nChange-Id: I0b567382edf4d68674a7b8d0b02333fb57293958\n""}]",7,701632,e976461d85f370762798316dbcc1d156ef8d4feb,19,4,4,1736,,,0,"Remove six usage from horizon package

We don't support Python 2 anymore so we don't need this
compatibility library.

six.reraise usages are left as is until it'll be moved to some
base lib like oslo.utils to not re-implenent this method in
Horizon.

This patch also removes Python2-specific base test case methods
assertItemsEqual and assertNotRegexpMatches in flavor of new
Python 3 analogues.

Change-Id: I0b567382edf4d68674a7b8d0b02333fb57293958
",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/701632/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/tables/base.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/admin/networks/tests.py', 'horizon/forms/fields.py', 'horizon/test/unit/tabs/test_tabs.py', 'horizon/base.py', 'horizon/exceptions.py', 'openstack_dashboard/dashboards/admin/volumes/tests.py', 'horizon/tables/actions.py', 'horizon/utils/csvbase.py', 'horizon/test/unit/utils/test_babel_extract_angular.py', 'openstack_dashboard/dashboards/identity/mappings/tests.py', 'horizon/utils/functions.py', 'horizon/middleware/operation_log.py', 'horizon/tables/formset.py', 'openstack_dashboard/dashboards/admin/snapshots/tests.py', 'horizon/test/unit/test_base.py', 'horizon/test/unit/test_messages.py', 'openstack_dashboard/dashboards/admin/aggregates/tests.py', 'openstack_dashboard/dashboards/identity/projects/tests.py', 'openstack_dashboard/dashboards/admin/images/tests.py', 'openstack_dashboard/dashboards/identity/domains/tests.py', 'horizon/utils/settings.py', 'horizon/test/helpers.py', 'horizon/workflows/views.py', 'openstack_dashboard/dashboards/identity/groups/tests.py', 'openstack_dashboard/dashboards/project/key_pairs/tests.py', 'openstack_dashboard/dashboards/project/security_groups/tests.py', 'openstack_dashboard/dashboards/admin/rbac_policies/tests.py', 'horizon/test/unit/workflows/test_workflows.py', 'horizon/templatetags/angular.py', 'openstack_dashboard/dashboards/project/networks/tests.py', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'horizon/workflows/base.py', 'openstack_dashboard/dashboards/admin/routers/tests.py', 'openstack_dashboard/dashboards/project/backups/tests.py', 'openstack_dashboard/dashboards/project/networks/ports/tests.py', 'horizon/test/unit/test_exceptions.py', 'openstack_dashboard/dashboards/identity/users/tests.py', 'openstack_dashboard/dashboards/admin/flavors/tests.py', 'openstack_dashboard/dashboards/project/snapshots/tests.py', 'horizon/tabs/base.py', 'openstack_dashboard/dashboards/identity/roles/tests.py', 'openstack_dashboard/test/unit/usage/test_quotas.py', 'horizon/utils/babel_extract_angular.py', 'openstack_dashboard/dashboards/project/routers/tests.py', 'openstack_dashboard/dashboards/project/volumes/tests.py', 'horizon/utils/scss_filter.py', 'horizon/test/unit/tables/test_tables.py', 'openstack_dashboard/dashboards/admin/hypervisors/tests.py', 'openstack_dashboard/dashboards/admin/volume_types/tests.py', 'openstack_dashboard/dashboards/admin/networks/subnets/tests.py', 'openstack_dashboard/dashboards/identity/identity_providers/tests.py']",53,9348e4ea50b8ac7797fccb379a89b3ab0398dde9,remove-six," self.assertCountEqual(res.context['table'].data, self.assertCountEqual(res.context['idp_protocols_table'].data,"," self.assertItemsEqual(res.context['table'].data, self.assertItemsEqual(res.context['idp_protocols_table'].data,",234,306
openstack%2Frequirements~master~I904fa65a5fc677f513df92b0afac233e78607bc3,openstack/requirements,master,I904fa65a5fc677f513df92b0afac233e78607bc3,update constraint for sphinx-feature-classification to new release 1.0.0,MERGED,2020-01-16 17:59:23.000000000,2020-01-17 02:52:44.000000000,2020-01-17 02:51:00.000000000,"[{'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 17:59:23.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/49a4f96a69e5de21e07b51584f06493681cff4cf', 'message': 'update constraint for sphinx-feature-classification to new release 1.0.0\n\nChange-Id: I904fa65a5fc677f513df92b0afac233e78607bc3\nmeta:version: 1.0.0\nmeta:diff-start: -\nmeta:series: independent\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Eric Fried <openstack@fried.cc>\nmeta:release:Commit: Eric Fried <openstack@fried.cc>\nmeta:release:Change-Id: I5c80a42fc61f2af7f18510f8275e25693b36e09f\nmeta:release:Code-Review+1: Ben Nemec <openstack@nemebean.com>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,702941,49a4f96a69e5de21e07b51584f06493681cff4cf,8,3,1,11131,,,0,"update constraint for sphinx-feature-classification to new release 1.0.0

Change-Id: I904fa65a5fc677f513df92b0afac233e78607bc3
meta:version: 1.0.0
meta:diff-start: -
meta:series: independent
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Eric Fried <openstack@fried.cc>
meta:release:Commit: Eric Fried <openstack@fried.cc>
meta:release:Change-Id: I5c80a42fc61f2af7f18510f8275e25693b36e09f
meta:release:Code-Review+1: Ben Nemec <openstack@nemebean.com>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/41/702941/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,49a4f96a69e5de21e07b51584f06493681cff4cf,new-release,sphinx-feature-classification===1.0.0,sphinx-feature-classification===0.4.2,1,1
openstack%2Fopenstack-ansible~stable%2Frocky~I2bc1860de022f044fee83d36effd4c5e1ee713ec,openstack/openstack-ansible,stable/rocky,I2bc1860de022f044fee83d36effd4c5e1ee713ec,Bump SHAs for stable/rocky,MERGED,2020-01-12 14:03:37.000000000,2020-01-17 02:18:53.000000000,2020-01-17 02:18:53.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-01-12 14:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f9fdaeb7c04c91b06a91ea59db7de72551ccfe5e', 'message': 'Bump SHAs for stable/rocky\n\nChange-Id: I2bc1860de022f044fee83d36effd4c5e1ee713ec\n'}, {'number': 2, 'created': '2020-01-16 14:30:14.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f698e34e507ff2699055b1e03b4eb898415fba29', 'message': 'Bump SHAs for stable/rocky\n\nChange-Id: I2bc1860de022f044fee83d36effd4c5e1ee713ec\n'}]",0,702136,f698e34e507ff2699055b1e03b4eb898415fba29,13,4,2,28619,,,0,"Bump SHAs for stable/rocky

Change-Id: I2bc1860de022f044fee83d36effd4c5e1ee713ec
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/36/702136/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml']",3,f9fdaeb7c04c91b06a91ea59db7de72551ccfe5e,bump_osa, version: ea2c68945e26cf46e551e45286810362e3e97068 version: f6c829902dc224cd8bed6946a58ed86965fa261e version: 39e1064599cc553628c6a1197fda63f8b973dcb5, version: 013542e42bf99067c4db6a32a2aee1a30134bcba version: 2ab5296868ab4d5cc7d7dc682125cb6ff2dccf79 version: 8fc682756ffe16b3d826a2de8ad1b782bdf8c671,42,42
openstack%2Fcyborg-specs~master~I2a4475592b7c3153eb34a13eb37479287f876d78,openstack/cyborg-specs,master,I2a4475592b7c3153eb34a13eb37479287f876d78,Update device section in Cyborg V2 APIs specification.,MERGED,2019-11-26 02:48:37.000000000,2020-01-17 02:18:15.000000000,2019-12-16 03:48:50.000000000,"[{'_account_id': 14107}, {'_account_id': 14131}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 23168}, {'_account_id': 25738}, {'_account_id': 26297}, {'_account_id': 26458}, {'_account_id': 28748}, {'_account_id': 30759}]","[{'number': 1, 'created': '2019-11-26 02:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/d779ee1ba8a8e8c5225ba5cd247549703ab5a244', 'message': 'Update device section in Cyborg V2 APIs specification.\n\nChange-Id: I2a4475592b7c3153eb34a13eb37479287f876d78\n'}, {'number': 2, 'created': '2019-12-02 14:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/6af30685e7ce5a21bc4d034f1ab82eabfd768158', 'message': 'Update device section in Cyborg V2 APIs specification.\n\nChange-Id: I2a4475592b7c3153eb34a13eb37479287f876d78\n'}, {'number': 3, 'created': '2019-12-10 07:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/a446617c0e4d0cd4265b25a7c84d98fbcf2f0cfd', 'message': 'Update device section in Cyborg V2 APIs specification.\n\nChange-Id: I2a4475592b7c3153eb34a13eb37479287f876d78\nCo-Authored-By: Shogo Saito <shogo.saito.ac@hco.ntt.co.jp>\n'}, {'number': 4, 'created': '2019-12-15 08:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/65889f7d0e69e301cf86259a22f0cf3308d9c93c', 'message': 'Update device section in Cyborg V2 APIs specification.\n\nChange-Id: I2a4475592b7c3153eb34a13eb37479287f876d78\nCo-Authored-By: Shogo Saito <shogo.saito.ac@hco.ntt.co.jp>\n'}, {'number': 5, 'created': '2019-12-16 02:59:28.000000000', 'files': ['specs/ussuri/approved/cyborg-api.rst'], 'web_link': 'https://opendev.org/openstack/cyborg-specs/commit/e31656063ae8d44f8fed8b62c4ccca9b8dc241a3', 'message': 'Update device section in Cyborg V2 APIs specification.\n\nChange-Id: I2a4475592b7c3153eb34a13eb37479287f876d78\nCo-Authored-By: Shogo Saito <shogo.saito.ac@hco.ntt.co.jp>\n'}]",16,696012,e31656063ae8d44f8fed8b62c4ccca9b8dc241a3,31,10,5,25738,,,0,"Update device section in Cyborg V2 APIs specification.

Change-Id: I2a4475592b7c3153eb34a13eb37479287f876d78
Co-Authored-By: Shogo Saito <shogo.saito.ac@hco.ntt.co.jp>
",git fetch https://review.opendev.org/openstack/cyborg-specs refs/changes/12/696012/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/cyborg-api.rst'],1,d779ee1ba8a8e8c5225ba5cd247549703ab5a244,696012,"* hostname: hosename of the compute node where devices are located. * type: type of devices. For example, we call get all FPGA devices by add ""FPGA"" as the query parameter. * vendor: vendor ID of devices. For example, we call get all Intel devices by add ""0x8086"" as the query parameter.METHOD: ``GET`` ROLE: Admin or any tenant Proposed JSON response:: { ""vendor"": ""0x8086"", ""uuid"": ""1c6c9033-560d-4a7a-bb8e-94455d1e7825"", ""links"": [ {""href"": ""http://10.238.145.73/accelerator/v2/devices/1c6c9033-560d-4a7a-bb8e-94455d1e7825"", ""rel"": ""self"" } ], ""created_at"": ""2019-11-12T07:38:55+00:00"", ""hostname"": ""host1"", ""updated_at"": null, ""vendor_board_info"": ""fake_vendor_info"", ""model"": ""fake_model_info"", ""type"": ""FPGA"", ""id"": 2, ""std_board_info"": ""{""class"": ""Fake class"", ""device_id"": ""0x09c4""} } URL: ``/accelerator/v2/devices/{uuid}`` URL: ``/accelerator/v2/devices/{uuid}/enabled`` METHOD: ``PUT`` ROLE: Admin or any tenant with RBAC authorization. Action: Update the device status as ``enabled``. This request will invoke placement API to set all resource provider under this device to available. Proposed JSON response: None. URL: ``/accelerator/v2/devices/{uuid}/disable`` METHOD: ``PUT`` ROLE: Admin or any tenant with RBAC authorization. Action: Update the device status as ``disable``. This request will invoke placement API to update the ``reserved`` field of inventories of all resource providers under this device to disable this devices from the point of view of end-users. Proposed JSON response: None. ",,58,0
openstack%2Ftripleo-common~master~I71436313098f513c200ecc3f862a2b851fb1060a,openstack/tripleo-common,master,I71436313098f513c200ecc3f862a2b851fb1060a,"Image uploader: use HTTPS for ""no verify"" registries",MERGED,2020-01-07 17:48:23.000000000,2020-01-17 01:55:35.000000000,2020-01-16 23:14:57.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-07 17:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dcd0225267b170e27d57810da53b6127c60e13cd', 'message': 'Image uploader: use HTTPS for ""no verify"" registries\n\nRegistries with an invalid SSL certificate are insecure, but still\nneed to be accessed via HTTPS. This patch updates the URL builder\nto take this into consideration.\n\nCloses-Bug: #1858672\nChange-Id: I71436313098f513c200ecc3f862a2b851fb1060a\n'}, {'number': 2, 'created': '2020-01-16 16:44:10.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dcf99e7167b7827b6edaf10b460a0dd5e57cdddb', 'message': 'Image uploader: use HTTPS for ""no verify"" registries\n\nRegistries with an invalid SSL certificate are insecure, but still\nneed to be accessed via HTTPS. This patch updates the URL builder\nto take this into consideration.\n\nCloses-Bug: #1858672\nChange-Id: I71436313098f513c200ecc3f862a2b851fb1060a\n'}]",17,701411,dcf99e7167b7827b6edaf10b460a0dd5e57cdddb,24,5,2,21129,,,0,"Image uploader: use HTTPS for ""no verify"" registries

Registries with an invalid SSL certificate are insecure, but still
need to be accessed via HTTPS. This patch updates the URL builder
to take this into consideration.

Closes-Bug: #1858672
Change-Id: I71436313098f513c200ecc3f862a2b851fb1060a
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/11/701411/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/image_uploader.py']",2,dcd0225267b170e27d57810da53b6127c60e13cd,bug/1858672, if (cls.is_insecure_registry(registry_host=netloc) and netloc not in cls.no_verify_registries): else: scheme = 'https', if not cls.is_insecure_registry(registry_host=netloc): scheme = 'https' else:,12,3
openstack%2Ffreezer~master~Id60e75b5f999b70626addaf47b4abd1ad15555d6,openstack/freezer,master,Id60e75b5f999b70626addaf47b4abd1ad15555d6,Fix parsing config file for freezer job,MERGED,2019-12-11 16:42:14.000000000,2020-01-17 01:41:45.000000000,2020-01-17 01:40:29.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 27339}]","[{'number': 1, 'created': '2019-12-11 16:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ecb7df291f8b01f2b1310f3575e5400c7877b7f1', 'message': 'Fix parsing config file for freezer job\n\nConfig parsers do not guess datatypes of values\nin configuration files, always storing them internally\nas strings. This means that we need to convert booleans, as\nthey are parsed as Strings from config file.\n\nChange-Id: Id60e75b5f999b70626addaf47b4abd1ad15555d6\n'}, {'number': 2, 'created': '2020-01-16 11:40:16.000000000', 'files': ['freezer/utils/config.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/bcaac1e3c1e1951ac37ce65b68b5920a6bca6911', 'message': 'Fix parsing config file for freezer job\n\nConfig parsers do not guess datatypes of values\nin configuration files, always storing them internally\nas strings. This means that we need to convert booleans, as\nthey are parsed as Strings from config file.\n\nThis patch is fixing typo from my previous commit where\nNone is needed to remove from second if clause as it is\nalready in first if clause and option_value should be False.\n\nChange-Id: Id60e75b5f999b70626addaf47b4abd1ad15555d6\n'}]",0,698534,bcaac1e3c1e1951ac37ce65b68b5920a6bca6911,13,3,2,27339,,,0,"Fix parsing config file for freezer job

Config parsers do not guess datatypes of values
in configuration files, always storing them internally
as strings. This means that we need to convert booleans, as
they are parsed as Strings from config file.

This patch is fixing typo from my previous commit where
None is needed to remove from second if clause as it is
already in first if clause and option_value should be False.

Change-Id: Id60e75b5f999b70626addaf47b4abd1ad15555d6
",git fetch https://review.opendev.org/openstack/freezer refs/changes/34/698534/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/utils/config.py'],1,ecb7df291f8b01f2b1310f3575e5400c7877b7f1,fix-configparser-boolean-values," if option_value in ('False', 'false', 'None'): if option_value in ('True', 'true'): option_value = True"," if option_value in ('False', 'None'):",3,1
openstack%2Fswift~master~I0c850b8ae40d1ab477d0f5d18f92579c457da54e,openstack/swift,master,I0c850b8ae40d1ab477d0f5d18f92579c457da54e,account-server: Add test for leading delimiter,MERGED,2020-01-03 00:27:02.000000000,2020-01-17 01:39:49.000000000,2020-01-17 01:38:06.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-03 00:27:02.000000000', 'files': ['test/unit/account/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/55ab08a5fadda87ffc904d9fe0ba1d1e09612ae3', 'message': 'account-server: Add test for leading delimiter\n\nRelated-Change: I27701a31bfa22842c272b7781738e8c546b82cbc\nRelated-Change: If912f71d8b0d03369680374e8233da85d8d38f85\nChange-Id: I0c850b8ae40d1ab477d0f5d18f92579c457da54e\nRelated-Bug: 1475018\n'}]",0,700964,55ab08a5fadda87ffc904d9fe0ba1d1e09612ae3,7,2,1,15343,,,0,"account-server: Add test for leading delimiter

Related-Change: I27701a31bfa22842c272b7781738e8c546b82cbc
Related-Change: If912f71d8b0d03369680374e8233da85d8d38f85
Change-Id: I0c850b8ae40d1ab477d0f5d18f92579c457da54e
Related-Bug: 1475018
",git fetch https://review.opendev.org/openstack/swift refs/changes/64/700964/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/account/test_server.py'],1,55ab08a5fadda87ffc904d9fe0ba1d1e09612ae3,bug/1475018," def test_GET_leading_delimiter(self): req = Request.blank('/sda1/p/a', environ={'REQUEST_METHOD': 'PUT', 'HTTP_X_TIMESTAMP': '0'}) resp = req.get_response(self.controller) for first in range(3): req = Request.blank( '/sda1/p/a/.sub.%s' % first, environ={'REQUEST_METHOD': 'PUT'}, headers={'X-Put-Timestamp': '1', 'X-Delete-Timestamp': '0', 'X-Object-Count': '0', 'X-Bytes-Used': '0', 'X-Timestamp': normalize_timestamp(0)}) req.get_response(self.controller) for second in range(3): req = Request.blank( '/sda1/p/a/.sub.%s.%s' % (first, second), environ={'REQUEST_METHOD': 'PUT'}, headers={'X-Put-Timestamp': '1', 'X-Delete-Timestamp': '0', 'X-Object-Count': '0', 'X-Bytes-Used': '0', 'X-Timestamp': normalize_timestamp(0)}) req.get_response(self.controller) req = Request.blank('/sda1/p/a?delimiter=.', environ={'REQUEST_METHOD': 'GET'}) resp = req.get_response(self.controller) self.assertEqual(resp.status_int, 200) self.assertEqual(resp.body.strip().split(b'\n'), [b'.']) req = Request.blank('/sda1/p/a?prefix=.&delimiter=.', environ={'REQUEST_METHOD': 'GET'}) resp = req.get_response(self.controller) self.assertEqual(resp.status_int, 200) self.assertEqual(resp.body.strip().split(b'\n'), [b'.sub.']) req = Request.blank('/sda1/p/a?prefix=.sub.&delimiter=.', environ={'REQUEST_METHOD': 'GET'}) resp = req.get_response(self.controller) self.assertEqual(resp.status_int, 200) self.assertEqual( resp.body.strip().split(b'\n'), [b'.sub.0', b'.sub.0.', b'.sub.1', b'.sub.1.', b'.sub.2', b'.sub.2.']) req = Request.blank('/sda1/p/a?prefix=.sub.1.&delimiter=.', environ={'REQUEST_METHOD': 'GET'}) resp = req.get_response(self.controller) self.assertEqual(resp.status_int, 200) self.assertEqual(resp.body.strip().split(b'\n'), [b'.sub.1.0', b'.sub.1.1', b'.sub.1.2']) ",,51,0
openstack%2Frequirements~master~I89e03023465907038d0d4edcc2a671ae8235fec6,openstack/requirements,master,I89e03023465907038d0d4edcc2a671ae8235fec6,update constraint for cliff to new release 2.18.0,MERGED,2020-01-08 20:42:41.000000000,2020-01-17 01:39:39.000000000,2020-01-17 01:38:05.000000000,"[{'_account_id': 11904}, {'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-08 20:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c5904748d033d63bb0005b7ad5871b4180de453e', 'message': 'update constraint for cliff to new release 2.18.0\n\nChange-Id: I89e03023465907038d0d4edcc2a671ae8235fec6\nmeta:version: 2.18.0\nmeta:diff-start: -\nmeta:series: ussuri\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Stephen Finucane <sfinucan@redhat.com>\nmeta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Change-Id: I291eb02489d7587cd0a8dd9145dd3cf6c667015f\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2020-01-16 15:25:50.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/82b26e903c573d334deb1b2486a34d3377f90d8b', 'message': 'update constraint for cliff to new release 2.18.0\n\nChange-Id: I89e03023465907038d0d4edcc2a671ae8235fec6\nmeta:version: 2.18.0\nmeta:diff-start: -\nmeta:series: ussuri\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Stephen Finucane <sfinucan@redhat.com>\nmeta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Change-Id: I291eb02489d7587cd0a8dd9145dd3cf6c667015f\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,701613,82b26e903c573d334deb1b2486a34d3377f90d8b,27,4,2,11131,,,0,"update constraint for cliff to new release 2.18.0

Change-Id: I89e03023465907038d0d4edcc2a671ae8235fec6
meta:version: 2.18.0
meta:diff-start: -
meta:series: ussuri
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Stephen Finucane <sfinucan@redhat.com>
meta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Change-Id: I291eb02489d7587cd0a8dd9145dd3cf6c667015f
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/701613/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,c5904748d033d63bb0005b7ad5871b4180de453e,new-release,cliff===2.18.0,cliff===2.16.0,1,1
openstack%2Ftripleo-operator-ansible~master~I5c0b95a7037eeca0f849fb24248a0ffd16dc82c0,openstack/tripleo-operator-ansible,master,I5c0b95a7037eeca0f849fb24248a0ffd16dc82c0,Update docs around output variables,MERGED,2020-01-15 18:29:38.000000000,2020-01-17 00:54:07.000000000,2020-01-17 00:54:07.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 18:29:38.000000000', 'files': ['roles/tripleo-undercloud-upgrade/tasks/main.yml', 'roles/tripleo-container-image-delete/README.md', 'roles/tripleo-undercloud-install/README.md', 'roles/tripleo-undercloud-minion-upgrade/README.md', 'roles/tripleo-undercloud-install/tasks/main.yml', 'roles/tripleo-undercloud-backup/tasks/main.yml', 'roles/tripleo-undercloud-minion-upgrade/tasks/main.yml', 'roles/tripleo-undercloud-upgrade/README.md', 'roles/tripleo-container-image-push/README.md', 'roles/tripleo-undercloud-minion-install/README.md', 'roles/tripleo-undercloud-minion-install/tasks/main.yml', 'roles/tripleo-undercloud-backup/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/c8f6348079b92f6ae67b2db5aa2219e3703b6ce2', 'message': ""Update docs around output variables\n\nPer the comments in\nhttps://review.opendev.org/#/c/702284/6/roles/tripleo-container-image-list/tasks/main.yml,\nwe should have a consistent result naming convention. I'm proposing that\nwe return the shell exection results always via\n<underscored role name>_result. If there is output that a user might\nwant to use in ansible then we can also return the stdout via\n<underscored role name>_output.\n\nChange-Id: I5c0b95a7037eeca0f849fb24248a0ffd16dc82c0\n""}]",0,702717,c8f6348079b92f6ae67b2db5aa2219e3703b6ce2,7,3,1,14985,,,0,"Update docs around output variables

Per the comments in
https://review.opendev.org/#/c/702284/6/roles/tripleo-container-image-list/tasks/main.yml,
we should have a consistent result naming convention. I'm proposing that
we return the shell exection results always via
<underscored role name>_result. If there is output that a user might
want to use in ansible then we can also return the stdout via
<underscored role name>_output.

Change-Id: I5c0b95a7037eeca0f849fb24248a0ffd16dc82c0
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/17/702717/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-undercloud-upgrade/tasks/main.yml', 'roles/tripleo-container-image-delete/README.md', 'roles/tripleo-undercloud-install/README.md', 'roles/tripleo-undercloud-minion-upgrade/README.md', 'roles/tripleo-undercloud-install/tasks/main.yml', 'roles/tripleo-undercloud-backup/tasks/main.yml', 'roles/tripleo-undercloud-minion-upgrade/tasks/main.yml', 'roles/tripleo-undercloud-upgrade/README.md', 'roles/tripleo-container-image-push/README.md', 'roles/tripleo-undercloud-minion-install/README.md', 'roles/tripleo-undercloud-minion-install/tasks/main.yml', 'roles/tripleo-undercloud-backup/README.md']",12,c8f6348079b92f6ae67b2db5aa2219e3703b6ce2,execution-results,Output Variables ---------------- * `tripleo_undercloud_backup_result`: Ansible shell execution results ,,32,2
openstack%2Fswift~master~Iadc61a1c3bcbfbc47f65ec65df36d8da3694ee74,openstack/swift,master,Iadc61a1c3bcbfbc47f65ec65df36d8da3694ee74,Early-return on non-Swift get_info requests,MERGED,2019-12-14 01:38:46.000000000,2020-01-17 00:07:37.000000000,2020-01-17 00:06:13.000000000,"[{'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-14 01:38:46.000000000', 'files': ['test/unit/proxy/controllers/test_base.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b65d8b10c5ea1c897bcb02c97943af82fd27d578', 'message': 'Early-return on non-Swift get_info requests\n\nChange-Id: Iadc61a1c3bcbfbc47f65ec65df36d8da3694ee74\n'}]",7,699055,b65d8b10c5ea1c897bcb02c97943af82fd27d578,17,4,1,15343,,,0,"Early-return on non-Swift get_info requests

Change-Id: Iadc61a1c3bcbfbc47f65ec65df36d8da3694ee74
",git fetch https://review.opendev.org/openstack/swift refs/changes/55/699055/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/controllers/test_base.py', 'swift/proxy/controllers/base.py']",2,b65d8b10c5ea1c897bcb02c97943af82fd27d578,fix-drop-priv," if not constraints.valid_api_version(version): # Not a valid Swift request; return 0 like we do # if there's an account failure return headers_to_container_info({}, 0) if not constraints.valid_api_version(version): return headers_to_account_info({}, 0) ",,68,0
openstack%2Fswift~master~Ib10f7e045df6c4889d127be7194ea4544d098543,openstack/swift,master,Ib10f7e045df6c4889d127be7194ea4544d098543,squash: flesh out object-versioning probe test a bit,ABANDONED,2020-01-09 00:54:33.000000000,2020-01-17 00:01:20.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 00:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/afce9c65c30dfa9d0513bddd1124aae1a1b3b17d', 'message': 'squash: flesh out object-versioning probe test a bit\n\nChange-Id: Ib10f7e045df6c4889d127be7194ea4544d098543\n'}, {'number': 2, 'created': '2020-01-15 00:27:46.000000000', 'files': ['test/probe/test_object_versioning.py', 'swift/common/middleware/versioned_writes/object_versioning.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d0300e542b9cd611fe1a60d0002752ce0523745c', 'message': 'squash: flesh out object-versioning probe test a bit\n\nChange-Id: Ib10f7e045df6c4889d127be7194ea4544d098543\n'}]",1,701643,d0300e542b9cd611fe1a60d0002752ce0523745c,6,2,2,15343,,,0,"squash: flesh out object-versioning probe test a bit

Change-Id: Ib10f7e045df6c4889d127be7194ea4544d098543
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/701643/2 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_object_versioning.py'],1,afce9c65c30dfa9d0513bddd1124aae1a1b3b17d,more_tests," # Create container1 client.delete_object(self.url, self.token, container_name, obj_name) _headers, current_versions = client.get_container( self.url, self.token, container_name) self.assertEqual(len(current_versions), 0) _headers, all_versions = client.get_container( self.url, self.token, container_name, query_string='versions') self.assertEqual(len(all_versions), 3) # Can't HEAD or list anything, though with self.assertRaises(client.ClientException) as caught: client.head_container(self.url, self.token, container_name) self.assertEqual(caught.exception.http_status, 404) with self.assertRaises(client.ClientException) as caught: client.get_container(self.url, self.token, container_name) self.assertEqual(caught.exception.http_status, 404) with self.assertRaises(client.ClientException) as caught: client.get_container(self.url, self.token, container_name, query_string='versions') self.assertEqual(caught.exception.http_status, 404) with self.assertRaises(client.ClientException) as caught: client.get_object( self.url, self.token, container_name, all_versions[1]['name'], query_string='version-id=%s' % all_versions[1]['version_id']) # XXX: or should this 404? self.assertEqual(caught.exception.http_status, 400) # Fix isn't too bad -- just make the container again! client.put_container(self.url, self.token, container_name) _headers, current_versions = client.get_container( self.url, self.token, container_name) self.assertEqual(len(current_versions), 0) _headers, all_versions = client.get_container( self.url, self.token, container_name, query_string='versions') self.assertEqual(len(all_versions), 3) # ... but to actually *access* the versions, you have to enable # versioning again with self.assertRaises(client.ClientException) as caught: client.get_object( self.url, self.token, container_name, all_versions[1]['name'], query_string='version-id=%s' % all_versions[1]['version_id']) self.assertEqual(caught.exception.http_status, 400) self.assertIn(b'version-aware operations require', caught.exception.http_body) client.post_container(self.url, self.token, container_name, headers={'X-Versions-Enabled': 'true'}) client.get_object( self.url, self.token, container_name, all_versions[1]['name'], query_string='version-id=%s' % all_versions[1]['version_id']) "," # Create container1 and container2 client.delete_object(self.url, self.token, container_name, obj_name)",51,2
openstack%2Fopenstack-helm~master~I138ff243fc1946173491a5d07339940dc18b4946,openstack/openstack-helm,master,I138ff243fc1946173491a5d07339940dc18b4946,Add barbican installation script to developer installation,ABANDONED,2020-01-16 23:48:10.000000000,2020-01-16 23:56:36.000000000,,[],"[{'number': 1, 'created': '2020-01-16 23:48:10.000000000', 'files': ['tools/deployment/common/get-values-overrides.sh', 'tools/deployment/developer/common/085-barbican.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e3e9e3f9d2ff218c0a905075ea02bd5a98b20851', 'message': 'Add barbican installation script to developer installation\n\nChange-Id: I138ff243fc1946173491a5d07339940dc18b4946\n'}]",0,703004,e3e9e3f9d2ff218c0a905075ea02bd5a98b20851,2,0,1,8863,,,0,"Add barbican installation script to developer installation

Change-Id: I138ff243fc1946173491a5d07339940dc18b4946
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/04/703004/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/common/get-values-overrides.sh', 'tools/deployment/developer/common/085-barbican.sh']",2,e3e9e3f9d2ff218c0a905075ea02bd5a98b20851,,"#!/bin/bash # Copyright 2019 The Openstack-Helm Authors. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. set -xe #NOTE: Get the over-rides to use : ${OSH_EXTRA_HELM_ARGS_BARBICAN:=""$(./tools/deployment/common/get-values-overrides.sh barbican)""} #NOTE: Lint and package chart make barbican #NOTE: Deploy command helm upgrade --install barbican ./barbican \ --namespace=openstack \ ${OSH_EXTRA_HELM_ARGS:=} \ ${OSH_EXTRA_HELM_ARGS_BARBICAN} #NOTE: Wait for deploy ./tools/deployment/common/wait-for-pods.sh openstack #NOTE: Validate Deployment info helm status barbican helm test barbican ",,39,9
openstack%2Fcinder~master~Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13,openstack/cinder,master,Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13,Clean up test requirements,MERGED,2019-06-03 20:11:29.000000000,2020-01-16 23:54:48.000000000,2020-01-16 23:52:59.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 10459}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-06-03 20:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce18a61329ed91048940c450e0d7c4d034450344', 'message': 'Clean up test requirements\n\ntestresources and testscenarios were added in ec40c3b6 to address an\nissue with oslo.db not pulling in its own requirements.\n\ntempest was used when we had the tempest plugin in the main cinder repo\nand was not removed when the plugin switched to its own repo.\n\nos-api-ref is used for building the API reference and was a leftover\nfrom before doc/requirements.txt was added.\n\nChange-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2019-07-10 19:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d13c22c3800f0e06eb3ad9215d18a90f8005212e', 'message': 'Clean up test requirements\n\ntestresources and testscenarios were added in ec40c3b6 to address an\nissue with oslo.db not pulling in its own requirements.\n\ntempest was used when we had the tempest plugin in the main cinder repo\nand was not removed when the plugin switched to its own repo.\n\nos-api-ref is used for building the API reference and was a leftover\nfrom before doc/requirements.txt was added.\n\nChange-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 3, 'created': '2019-11-27 19:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2453c5976da85bbe0cba4837dcdfc8bf3acb0679', 'message': 'Clean up test requirements\n\ntestresources and testscenarios were added in ec40c3b6 to address an\nissue with oslo.db not pulling in its own requirements.\n\ntempest was used when we had the tempest plugin in the main cinder repo\nand was not removed when the plugin switched to its own repo.\n\nos-api-ref is used for building the API reference and was a leftover\nfrom before doc/requirements.txt was added.\n\nChange-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 4, 'created': '2019-11-27 21:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d06c52e8ae3a790eb44d27ab0ebbc71439539096', 'message': 'Clean up test requirements\n\ntestresources and testscenarios were added in ec40c3b6 to address an\nissue with oslo.db not pulling in its own requirements.\n\ntempest was used when we had the tempest plugin in the main cinder repo\nand was not removed when the plugin switched to its own repo.\n\nos-api-ref is used for building the API reference and was a leftover\nfrom before doc/requirements.txt was added.\n\nChange-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 5, 'created': '2020-01-02 20:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3392ffe807d9a48b43bebb265a177288d0a14d37', 'message': 'Clean up test requirements\n\ntestresources and testscenarios were added in ec40c3b6 to address an\nissue with oslo.db not pulling in its own requirements.\n\ntempest was used when we had the tempest plugin in the main cinder repo\nand was not removed when the plugin switched to its own repo.\n\nos-api-ref is used for building the API reference and was a leftover\nfrom before doc/requirements.txt was added.\n\nChange-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 6, 'created': '2020-01-08 19:33:57.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a90970da156158f82e3f45b4d70329f6fd4cddba', 'message': 'Clean up test requirements\n\ntestresources and testscenarios were added in ec40c3b6 to address an\nissue with oslo.db not pulling in its own requirements.\n\ntempest was used when we had the tempest plugin in the main cinder repo\nand was not removed when the plugin switched to its own repo.\n\nos-api-ref is used for building the API reference and was a leftover\nfrom before doc/requirements.txt was added.\n\nChange-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",6,662850,a90970da156158f82e3f45b4d70329f6fd4cddba,161,44,6,11904,,,0,"Clean up test requirements

testresources and testscenarios were added in ec40c3b6 to address an
issue with oslo.db not pulling in its own requirements.

tempest was used when we had the tempest plugin in the main cinder repo
and was not removed when the plugin switched to its own repo.

os-api-ref is used for building the API reference and was a leftover
from before doc/requirements.txt was added.

Change-Id: Ib4fc7cb6199c9581c19d34ea43a2d15ec9003f13
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/50/662850/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ce18a61329ed91048940c450e0d7c4d034450344,testreqs,,os-api-ref>=1.4.0 # Apache-2.0testresources>=2.0.0 # Apache-2.0/BSD testscenarios>=0.4 # Apache-2.0/BSDtempest>=17.1.0 # Apache-2.0,1,4
openstack%2Fnova~stable%2Frocky~I613ad054f77b1a0a9d2e7718c0c531d11525283c,openstack/nova,stable/rocky,I613ad054f77b1a0a9d2e7718c0c531d11525283c,Join migration_context and flavor in Migration.instance,MERGED,2019-11-28 13:33:13.000000000,2020-01-16 23:52:54.000000000,2020-01-16 23:52:54.000000000,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-28 13:33:13.000000000', 'files': ['nova/tests/unit/objects/test_migration.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/objects/migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e48fb84e1246aae8c7f7fd22a9c72ccbfa92d9ee', 'message': ""Join migration_context and flavor in Migration.instance\n\nThis builds on Ifc7dcde8a659710acecb1967da15c632c69d675c\nby joining the Migration.instance migration_context and\nflavor to avoid lazy-loading those later.\n\nWhen tracking an incoming migration, the ResourceTracker\n_pair_instances_to_migrations can hit a KeyError since it's\nnot yet tracking the instance on that dest host yet. Then\n_update_usage_from_migrations will lazy-load the Migration.instance\nfield and access the migration_context and flavor fields on the\ninstance, which get lazy-loaded, which kind of defeats part of\nthe purpose of that optimization.\n\nChange-Id: I613ad054f77b1a0a9d2e7718c0c531d11525283c\nRelated-Bug: #1540526\n(cherry picked from commit c15e36e5849b6baddebb4b39475a6bf03ec5908b)\n(cherry picked from commit e2b4e3346e20615473328e7ae90b5083500961ca)\n(cherry picked from commit 603171bd5c5ce354086ce32e980f9bb8383069bf)\n""}]",0,696572,e48fb84e1246aae8c7f7fd22a9c72ccbfa92d9ee,36,6,1,6873,,,0,"Join migration_context and flavor in Migration.instance

This builds on Ifc7dcde8a659710acecb1967da15c632c69d675c
by joining the Migration.instance migration_context and
flavor to avoid lazy-loading those later.

When tracking an incoming migration, the ResourceTracker
_pair_instances_to_migrations can hit a KeyError since it's
not yet tracking the instance on that dest host yet. Then
_update_usage_from_migrations will lazy-load the Migration.instance
field and access the migration_context and flavor fields on the
instance, which get lazy-loaded, which kind of defeats part of
the purpose of that optimization.

Change-Id: I613ad054f77b1a0a9d2e7718c0c531d11525283c
Related-Bug: #1540526
(cherry picked from commit c15e36e5849b6baddebb4b39475a6bf03ec5908b)
(cherry picked from commit e2b4e3346e20615473328e7ae90b5083500961ca)
(cherry picked from commit 603171bd5c5ce354086ce32e980f9bb8383069bf)
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/696572/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_migration.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/objects/migration.py']",3,e48fb84e1246aae8c7f7fd22a9c72ccbfa92d9ee,bug/1540526," self._context, self.instance_uuid, expected_attrs=['migration_context', 'flavor'])"," self._context, self.instance_uuid)",11,6
openstack%2Fpython-tripleoclient~master~I16d23faca6d8c2d0abf13dbdf91b810717ac585e,openstack/python-tripleoclient,master,I16d23faca6d8c2d0abf13dbdf91b810717ac585e,Add tripleo launch heat command,MERGED,2019-10-29 20:09:14.000000000,2020-01-16 23:16:40.000000000,2020-01-16 23:14:44.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2019-10-29 20:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8ce563818171645527201ee62d6439d2fda5e676', 'message': 'Add tripleo launch heat command\n\nAdds a new command under the tripleo namespace for launching the all in\none heat-all process in the foreground. The new command reuses the code\nfrom heat_launcher.py already in place for the tripleo deploy commands.\n\nLaunching the heat-all process separately from tripleo deploy allows for\neasily spinning up a heat-all environment for stack creation and\ngenerating the config-download ansible content for development and test.\n\nChange-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e\n'}, {'number': 2, 'created': '2019-11-08 18:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ee45433af9f8138ed839675021a0dca8c9662c17', 'message': 'Add tripleo launch heat command\n\nAdds a new command under the tripleo namespace for launching the all in\none heat-all process in the foreground. The new command reuses the code\nfrom heat_launcher.py already in place for the tripleo deploy commands.\n\nLaunching the heat-all process separately from tripleo deploy allows for\neasily spinning up a heat-all environment for stack creation and\ngenerating the config-download ansible content for development and test.\n\nChange-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e\n'}, {'number': 3, 'created': '2019-12-05 19:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/97fcebc69849b8f845d4a4708419b7792c2186e1', 'message': 'Add tripleo launch heat command\n\nAdds a new command under the tripleo namespace for launching the all in\none heat-all process in the foreground. The new command reuses the code\nfrom heat_launcher.py already in place for the tripleo deploy commands.\n\nLaunching the heat-all process separately from tripleo deploy allows for\neasily spinning up a heat-all environment for stack creation and\ngenerating the config-download ansible content for development and test.\n\nChange-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e\n'}, {'number': 4, 'created': '2019-12-10 20:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bbe8e439fddd2c43595a4fc4381bf7dabb9c6615', 'message': 'Add tripleo launch heat command\n\nAdds a new command under the tripleo namespace for launching the all in\none heat-all process in the foreground. The new command reuses the code\nfrom heat_launcher.py already in place for the tripleo deploy commands.\n\nLaunching the heat-all process separately from tripleo deploy allows for\neasily spinning up a heat-all environment for stack creation and\ngenerating the config-download ansible content for development and test.\n\nChange-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e\n'}, {'number': 5, 'created': '2020-01-09 12:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5dfccb6ccf83be9e88b967ae6b291df86bf815df', 'message': 'Add tripleo launch heat command\n\nAdds a new command under the tripleo namespace for launching the all in\none heat-all process in the foreground. The new command reuses the code\nfrom heat_launcher.py already in place for the tripleo deploy commands.\n\nLaunching the heat-all process separately from tripleo deploy allows for\neasily spinning up a heat-all environment for stack creation and\ngenerating the config-download ansible content for development and test.\n\nChange-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e\n'}, {'number': 6, 'created': '2020-01-10 14:06:28.000000000', 'files': ['tripleoclient/v1/tripleo_launch_heat.py', 'releasenotes/notes/tripleo-launch-heat-e0067a994d63ffed.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/085e6fc55e4a1c01d82513064a2b040fee1f8174', 'message': 'Add tripleo launch heat command\n\nAdds a new command under the tripleo namespace for launching the all in\none heat-all process in the foreground. The new command reuses the code\nfrom heat_launcher.py already in place for the tripleo deploy commands.\n\nLaunching the heat-all process separately from tripleo deploy allows for\neasily spinning up a heat-all environment for stack creation and\ngenerating the config-download ansible content for development and test.\n\nChange-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e\n'}]",6,691963,085e6fc55e4a1c01d82513064a2b040fee1f8174,42,10,6,7144,,,0,"Add tripleo launch heat command

Adds a new command under the tripleo namespace for launching the all in
one heat-all process in the foreground. The new command reuses the code
from heat_launcher.py already in place for the tripleo deploy commands.

Launching the heat-all process separately from tripleo deploy allows for
easily spinning up a heat-all environment for stack creation and
generating the config-download ansible content for development and test.

Change-Id: I16d23faca6d8c2d0abf13dbdf91b810717ac585e
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/63/691963/4 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/tripleo_launch_heat.py', 'releasenotes/notes/tripleo-launch-heat-e0067a994d63ffed.yaml', 'setup.cfg']",3,8ce563818171645527201ee62d6439d2fda5e676,691963, tripleo_launch_heat = tripleoclient.v1.tripleo_launch_heat:LaunchHeat,,157,0
openstack%2Ftripleo-heat-templates~master~I7145d5cbf9f982757513b34050c9030c7448263e,openstack/tripleo-heat-templates,master,I7145d5cbf9f982757513b34050c9030c7448263e,Remove environments/services/neutron-server.yaml,MERGED,2019-10-22 20:08:35.000000000,2020-01-16 23:16:30.000000000,2020-01-16 23:14:46.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-10-22 20:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2cf004cbf386b0fc306180068d7284ca518cd984', 'message': 'Remove environments/services/neutron-server.yaml\n\nThis environment file was deprecated and only used to enable the old\nservice mapping for NeutronServer which was deprecated in train[1].\n\n[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28\n\nChange-Id: I7145d5cbf9f982757513b34050c9030c7448263e\n'}, {'number': 2, 'created': '2019-10-23 15:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/405c970a47287f2001e7b86943a3a27ead9e22b9', 'message': 'Remove environments/services/neutron-server.yaml\n\nThis environment file was deprecated and only used to enable the old\nservice mapping for NeutronServer which was deprecated in train[1].\n\n[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28\n\nChange-Id: I7145d5cbf9f982757513b34050c9030c7448263e\n'}, {'number': 3, 'created': '2019-11-14 16:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f68fbbb566e4e61ae73015b6279cc054ba3af2d7', 'message': 'Remove environments/services/neutron-server.yaml\n\nThis environment file was deprecated and only used to enable the old\nservice mapping for NeutronServer which was deprecated in train[1].\n\n[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28\n\nChange-Id: I7145d5cbf9f982757513b34050c9030c7448263e\n'}, {'number': 4, 'created': '2019-12-05 19:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8ea649101e3174ffb191ca25bcdcb56b967d41a', 'message': 'Remove environments/services/neutron-server.yaml\n\nThis environment file was deprecated and only used to enable the old\nservice mapping for NeutronServer which was deprecated in train[1].\n\n[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28\n\nChange-Id: I7145d5cbf9f982757513b34050c9030c7448263e\n'}, {'number': 5, 'created': '2019-12-10 21:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7b27b81b76a133848cc2d8062072514f8ee3e83', 'message': 'Remove environments/services/neutron-server.yaml\n\nThis environment file was deprecated and only used to enable the old\nservice mapping for NeutronServer which was deprecated in train[1].\n\n[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28\n\nChange-Id: I7145d5cbf9f982757513b34050c9030c7448263e\n'}, {'number': 6, 'created': '2020-01-06 22:23:25.000000000', 'files': ['environments/services/neutron-server.yaml', 'releasenotes/notes/remove-neutron-server-mapping-211ca9751dec268d.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e6d63a90bf7c7f844f6c08465352d78bb2e1bc97', 'message': 'Remove environments/services/neutron-server.yaml\n\nThis environment file was deprecated and only used to enable the old\nservice mapping for NeutronServer which was deprecated in train[1].\n\n[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28\n\nChange-Id: I7145d5cbf9f982757513b34050c9030c7448263e\n'}]",0,690397,e6d63a90bf7c7f844f6c08465352d78bb2e1bc97,36,6,6,7144,,,0,"Remove environments/services/neutron-server.yaml

This environment file was deprecated and only used to enable the old
service mapping for NeutronServer which was deprecated in train[1].

[1] ce0ee4df3c56dff2236a15eabcc4a736bab02e28

Change-Id: I7145d5cbf9f982757513b34050c9030c7448263e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/97/690397/2 && git format-patch -1 --stdout FETCH_HEAD,"['environments/services/neutron-server.yaml', 'releasenotes/notes/remove-neutron-server-mapping-211ca9751dec268d.yaml']",2,2cf004cbf386b0fc306180068d7284ca518cd984,686299,--- deprecations: - | The environment file at environments/service/neutron-server.yaml has been removed in ussuri as it was previously deprecated in train. ,,5,5
openstack%2Fansible-role-collect-logs~master~Ibabec573937ac1bf098be650c2a162740ca80be3,openstack/ansible-role-collect-logs,master,Ibabec573937ac1bf098be650c2a162740ca80be3,add the log README back to the base log dir,MERGED,2020-01-13 19:40:59.000000000,2020-01-16 23:14:57.000000000,2020-01-16 23:14:57.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-13 19:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/17fd3d4df65b5ed8e58a492c9c2e2f8b2e3af39b', 'message': 'add the log README back to the base log dir\n\nThe footer was removed from the logs.\n\nCloses-Bug: #1840818\nChange-Id: Ibabec573937ac1bf098be650c2a162740ca80be3\n'}, {'number': 2, 'created': '2020-01-16 16:53:23.000000000', 'files': ['tasks/publish.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/d8801e7dc0abbc756303ead7a7a141be5b64b861', 'message': 'add the log README back to the base log dir\n\nThe footer was removed from the logs.\n\nCloses-Bug: #1840818\nChange-Id: Ibabec573937ac1bf098be650c2a162740ca80be3\n'}]",0,702286,d8801e7dc0abbc756303ead7a7a141be5b64b861,11,4,2,9592,,,0,"add the log README back to the base log dir

The footer was removed from the logs.

Closes-Bug: #1840818
Change-Id: Ibabec573937ac1bf098be650c2a162740ca80be3
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/86/702286/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/publish.yml'],1,17fd3d4df65b5ed8e58a492c9c2e2f8b2e3af39b,,# the doc footer for logging has been removed. # copy the log readme into the base directory. - name: copy in the logs README.html shell: > if [ -f src/opendev.org/openstack/tripleo-ci/docs/tripleo-quickstart-logs.html ]; then cp src/opendev.org/openstack/tripleo-ci/docs/tripleo-quickstart-logs.html {{ artcl_collect_dir }}/README.html; fi; ignore_errors: true changed_when: true ,,10,0
openstack%2Ftripleo-quickstart-extras~master~If97dd12ebe994cfed859309653d6fbd2987d2a92,openstack/tripleo-quickstart-extras,master,If97dd12ebe994cfed859309653d6fbd2987d2a92,add useful debug info for change and builds,MERGED,2020-01-15 19:41:15.000000000,2020-01-16 23:14:56.000000000,2020-01-16 23:14:55.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-15 19:41:15.000000000', 'files': ['roles/build-test-packages/tasks/dlrn-build.yml', 'roles/build-test-packages/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0e3bc4879481d3e2a768ab47a1d66b5e3bb33bed', 'message': ""add useful debug info for change and builds\n\nThe zuul change needs to built at the right\ntime in upgrades.  If the change is rocky\nand it's a standalone-upgrade job.  The change\nneeds to be built on the appropriate branch\nat the right time.\n\nChange-Id: If97dd12ebe994cfed859309653d6fbd2987d2a92\n""}]",1,702737,0e3bc4879481d3e2a768ab47a1d66b5e3bb33bed,9,5,1,9592,,,0,"add useful debug info for change and builds

The zuul change needs to built at the right
time in upgrades.  If the change is rocky
and it's a standalone-upgrade job.  The change
needs to be built on the appropriate branch
at the right time.

Change-Id: If97dd12ebe994cfed859309653d6fbd2987d2a92
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/37/702737/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/build-test-packages/tasks/dlrn-build.yml', 'roles/build-test-packages/tasks/main.yml']",2,0e3bc4879481d3e2a768ab47a1d66b5e3bb33bed,,- name: Print out the change list debug: var: artg_change_list ,,8,0
openstack%2Fpaunch~stable%2Fqueens~Ib0685eb72becb867452bef17f17ab8e3d5b7d931,openstack/paunch,stable/queens,Ib0685eb72becb867452bef17f17ab8e3d5b7d931,"Log to a file by default, unless debugging",MERGED,2020-01-14 14:04:50.000000000,2020-01-16 23:14:55.000000000,2020-01-16 23:14:55.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-14 14:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/a5223cf1649ccedac34917ec7344ebf2864b46b7', 'message': 'Log to a file by default, unless debugging\n\nBy default, log paunch to /var/log/paunch.log.\n\nRelated-Bug: #1799182\n\nChange-Id: Ib0685eb72becb867452bef17f17ab8e3d5b7d931\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit 791766596c49278787226c6de6fea576098d8b45)\n'}, {'number': 2, 'created': '2020-01-15 13:45:50.000000000', 'files': ['paunch/constants.py', 'paunch/cmd.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/1c590fc76d62200cdf247e2a6638873f1430b353', 'message': 'Log to a file by default, unless debugging\n\nBy default, log paunch to /var/log/paunch.log.\n\nRelated-Bug: #1799182\n\nChange-Id: Ib0685eb72becb867452bef17f17ab8e3d5b7d931\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit 791766596c49278787226c6de6fea576098d8b45)\n'}]",0,702438,1c590fc76d62200cdf247e2a6638873f1430b353,12,7,2,6926,,,0,"Log to a file by default, unless debugging

By default, log paunch to /var/log/paunch.log.

Related-Bug: #1799182

Change-Id: Ib0685eb72becb867452bef17f17ab8e3d5b7d931
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit 791766596c49278787226c6de6fea576098d8b45)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/38/702438/2 && git format-patch -1 --stdout FETCH_HEAD,"['paunch/constants.py', 'paunch/cmd.py']",2,a5223cf1649ccedac34917ec7344ebf2864b46b7,1790792_maybe,"from paunch import constants from paunch import utils log_file = self.app_args.log_file or constants.LOG_FILE self.log = utils.common.configure_logging( __name__, log_level, log_file) log_file=log_file log_file = self.app_args.log_file or constants.LOG_FILE self.log = utils.common.configure_logging( __name__, log_level, log_file) log_file=log_file log_file = self.app_args.log_file or constants.LOG_FILE self.log = utils.common.configure_logging( __name__, log_level, log_file) log_file=log_file # Only log to a file if explicitely set via CLI args log_file = self.app_args.log_file self.log = utils.common.configure_logging( __name__, log_level, log_file) log_file=log_file log_file = self.app_args.log_file or constants.LOG_FILE self.log = utils.common.configure_logging( __name__, log_level, log_file) log_file=log_file"," self.log = paunch.utils.common.configure_logging( __name__, log_level, self.app_args.log_file) log_file=self.app_args.log_file self.log = paunch.utils.common.configure_logging( __name__, log_level, self.app_args.log_file) log_file=self.app_args.log_file self.log = paunch.utils.common.configure_logging( __name__, log_level, self.app_args.log_file) log_file=self.app_args.log_file self.log = paunch.utils.common.configure_logging( __name__, log_level, self.app_args.log_file) log_file=self.app_args.log_file self.log = paunch.utils.common.configure_logging( __name__, log_level, self.app_args.log_file) log_file=self.app_args.log_file",40,15
openstack%2Ftripleo-upgrade~stable%2Fstein~I916c3ed394f54561fff2a106288a667c0b877360,openstack/tripleo-upgrade,stable/stein,I916c3ed394f54561fff2a106288a667c0b877360,Clean up roles data adjustment,MERGED,2020-01-15 10:02:35.000000000,2020-01-16 23:14:54.000000000,2020-01-16 23:14:54.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 10:02:35.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/53377cdb144374693827bdfc5ec817239d2b78a1', 'message': ""Clean up roles data adjustment\n\n1. The python_bin var is unused, so it should be removed.\n2. Tasks should be seperated by a newline in order to easily see\n   that they are seperate tasks.\n3. The return code of 2 was in the wrong place. It should have been\n   where the data was changed, as per the changed_when condition.\n4. With the return code adjusted, the final task's condition also\n   needed adjusting to match.\n\nRelated-Bug: #1856865\nChange-Id: I916c3ed394f54561fff2a106288a667c0b877360\n(cherry picked from commit 967f3805d356c180835dba680d86af1b66ebe8f1)\n(cherry picked from commit 6c5631bb3d128f79a7d114d8a19f928828c27138)\n""}]",0,702623,53377cdb144374693827bdfc5ec817239d2b78a1,8,7,1,26343,,,0,"Clean up roles data adjustment

1. The python_bin var is unused, so it should be removed.
2. Tasks should be seperated by a newline in order to easily see
   that they are seperate tasks.
3. The return code of 2 was in the wrong place. It should have been
   where the data was changed, as per the changed_when condition.
4. With the return code adjusted, the final task's condition also
   needed adjusting to match.

Related-Bug: #1856865
Change-Id: I916c3ed394f54561fff2a106288a667c0b877360
(cherry picked from commit 967f3805d356c180835dba680d86af1b66ebe8f1)
(cherry picked from commit 6c5631bb3d128f79a7d114d8a19f928828c27138)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/23/702623/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,53377cdb144374693827bdfc5ec817239d2b78a1,bug/1856865-stable/train-stable/stein, exit 2 when: modified_roles_data.rc == 2," vars: python_bin: ""{{ ansible_python_interpreter | default('python') }}"" exit 2 when: modified_roles_data.rc == 0",3,4
openstack%2Ftripleo-upgrade~stable%2Fstein~I8b2cacd4271a59dfda948462146c0866b8b7725f,openstack/tripleo-upgrade,stable/stein,I8b2cacd4271a59dfda948462146c0866b8b7725f,Fix python command and fix python3 compatiblity.,MERGED,2020-01-15 09:57:46.000000000,2020-01-16 23:14:54.000000000,2020-01-16 23:14:54.000000000,"[{'_account_id': 6816}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-15 09:57:46.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/bceafc0ab4a638fac5ae9b061b09f19654cb4cdd', 'message': ""Fix python command and fix python3 compatiblity.\n\nThe python binary is not available in rhel8, add a variable with the\nbinary. In stein on, we deal python3 by default and print isn't\nsupported anymore now print is a function. This patch defines python_bin\nbased on OS version (python in RHEL7 or python3 in RHEL8). Output is\nassigned as ansible registered variable to save it to file later on.\nAdditionally this patch moves all pipes to jq to minimize number of forks\n\nCo-Authored-By: Sergii Golovatiuk <sgolovat@redhat.com>\nCloses-Bug: #1856865\n\nChange-Id: I8b2cacd4271a59dfda948462146c0866b8b7725f\n(cherry picked from commit 614322b9f63ce9ec240129b22e60772d1b34ce02)\n""}]",0,702621,bceafc0ab4a638fac5ae9b061b09f19654cb4cdd,10,5,1,26343,,,0,"Fix python command and fix python3 compatiblity.

The python binary is not available in rhel8, add a variable with the
binary. In stein on, we deal python3 by default and print isn't
supported anymore now print is a function. This patch defines python_bin
based on OS version (python in RHEL7 or python3 in RHEL8). Output is
assigned as ansible registered variable to save it to file later on.
Additionally this patch moves all pipes to jq to minimize number of forks

Co-Authored-By: Sergii Golovatiuk <sgolovat@redhat.com>
Closes-Bug: #1856865

Change-Id: I8b2cacd4271a59dfda948462146c0866b8b7725f
(cherry picked from commit 614322b9f63ce9ec240129b22e60772d1b34ce02)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/21/702621/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,bceafc0ab4a638fac5ae9b061b09f19654cb4cdd,bug/1856865-stable/train-stable/stein," - name: copy roles_data in a variable command: ""cat {{ roles_data }}"" register: roles_data_yaml - name: save roles_data into json file copy: content: ""{{ roles_data_yaml.stdout | from_yaml | to_nice_json }}"" dest: ""{{ roles_data }}.json"" vars: python_bin: ""{{ ansible_python_interpreter | default('python') }}"" if grep -q OS::TripleO::Services::Pacemaker ""{{ roles_data }}.json""; then cat {{ roles_data }}.json |\ jq 'del(.[] | .update_serial ) | map(. |= (. += {update_serial: 25} )) | map( if .ServicesDefault | contains ([""OS::TripleO::Services::Pacemaker""]) then . += {update_serial: 1} else . += {update_serial: 25} end )' exit 2 register: modified_roles_data failed_when: modified_roles_data.rc not in [0,2] changed_when: modified_roles_data.rc == 2 - name: ""Dump the modified roles_data into {{ roles_data }}"" copy: content: ""{{ modified_roles_data.stdout | from_json | to_nice_yaml(indent=2) | trim}}"" dest: ""{{ roles_data }}"" when: modified_roles_data.rc == 0"," if grep -q OS::TripleO::Services::Pacemaker ""{{ roles_data }}"" ; then cp -f ""{{ roles_data }}"" ""{{ roles_data }}_update_serial"" python -c 'import sys, yaml, simplejson as json; json.dump(yaml.load(sys.stdin), sys.stdout, indent=4)' < ""{{roles_data}}_update_serial"" |\ jq 'del(.[] | .update_serial)' |\ jq 'map(. |= (. += {update_serial: 25} ))' |\ jq 'map( if .ServicesDefault | contains ([""OS::TripleO::Services::Pacemaker""]) then .update_serial = 1 else . end)' |\ python -c 'import simplejson, sys, yaml; print yaml.dump(simplejson.loads(str(sys.stdin.read())), default_flow_style=False)' > ""{{ roles_data }}""",26,11
openstack%2Ftripleo-upgrade~stable%2Ftrain~I41cc780a1a40330a801f015faa81c56f1abdd5ea,openstack/tripleo-upgrade,stable/train,I41cc780a1a40330a801f015faa81c56f1abdd5ea,Remove Panko service from roles_data.,MERGED,2020-01-15 09:37:06.000000000,2020-01-16 23:14:53.000000000,2020-01-16 23:14:53.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-01-15 09:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/ca3327662dd536ad14f7e7b2b2f1d29387f5a83b', 'message': 'Remove Panko service from roles_data.\n\nPanko templates where removed completely in Train [0].\nTherefore, there is no need to keep the service inside\nany customized roles_data.\n\nThis patch parses the customized roles_data passed during\nthe upgrade prepare step and removes the PankoApi service.\n\n[0] - I590c889f838482d00cae596fcba2796f99d1e5b5\n\nChange-Id: I41cc780a1a40330a801f015faa81c56f1abdd5ea\n(cherry picked from commit 8212b6a168ed4ae2b0f6ef6eb946d3716e0edd39)\n'}, {'number': 2, 'created': '2020-01-15 11:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/b75e63fa2a93e2c0464b7eee451263d4b739b1e1', 'message': 'Remove Panko service from roles_data.\n\nPanko templates where removed completely in Train [0].\nTherefore, there is no need to keep the service inside\nany customized roles_data.\n\nThis patch parses the customized roles_data passed during\nthe upgrade prepare step and removes the PankoApi service.\n\n[0] - I590c889f838482d00cae596fcba2796f99d1e5b5\n\nChange-Id: I41cc780a1a40330a801f015faa81c56f1abdd5ea\n(cherry picked from commit 8212b6a168ed4ae2b0f6ef6eb946d3716e0edd39)\n'}, {'number': 3, 'created': '2020-01-16 11:24:06.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/b2fea42fbadd25f82b81cdbd3538d34c74e48ae2', 'message': 'Remove Panko service from roles_data.\n\nPanko templates where removed completely in Train [0].\nTherefore, there is no need to keep the service inside\nany customized roles_data.\n\nThis patch parses the customized roles_data passed during\nthe upgrade prepare step and removes the PankoApi service.\n\n[0] - I590c889f838482d00cae596fcba2796f99d1e5b5\n\nChange-Id: I41cc780a1a40330a801f015faa81c56f1abdd5ea\n(cherry picked from commit 8212b6a168ed4ae2b0f6ef6eb946d3716e0edd39)\n'}]",0,702612,b2fea42fbadd25f82b81cdbd3538d34c74e48ae2,11,6,3,26343,,,0,"Remove Panko service from roles_data.

Panko templates where removed completely in Train [0].
Therefore, there is no need to keep the service inside
any customized roles_data.

This patch parses the customized roles_data passed during
the upgrade prepare step and removes the PankoApi service.

[0] - I590c889f838482d00cae596fcba2796f99d1e5b5

Change-Id: I41cc780a1a40330a801f015faa81c56f1abdd5ea
(cherry picked from commit 8212b6a168ed4ae2b0f6ef6eb946d3716e0edd39)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/12/702612/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,ca3327662dd536ad14f7e7b2b2f1d29387f5a83b,,"- name: drop Panko service replace: dest: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::PankoApi$)' replace: '' ",,6,0
openstack%2Ftripleo-upgrade~stable%2Ftrain~Ieb7d49ece360073ef3881d5b903833ec61192c4c,openstack/tripleo-upgrade,stable/train,Ieb7d49ece360073ef3881d5b903833ec61192c4c,Remove Tacker service from roles_data.,MERGED,2020-01-15 09:41:02.000000000,2020-01-16 23:14:52.000000000,2020-01-16 23:14:52.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 09:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9beef3ca91cb88a9c76ecb29e14d99e6ed276dff', 'message': 'Remove Tacker service from roles_data.\n\nTacker templates where removed completely in Train [0] as\nthe service had been incomplete since Queens. Therefore,\nthere is no need to keep the service inside any customized\nroles_data.\n\nThis patch parses the customized roles_data passed during the\nupgrade prepare step and removes the Tacker service.\n\n[0] - I2856e894b58d50c2d3484ccd02bfb1d43625847f\n\nChange-Id: Ieb7d49ece360073ef3881d5b903833ec61192c4c\n(cherry picked from commit e77df3055e78c63d11993d6f5cdcc08207b4410b)\n'}, {'number': 2, 'created': '2020-01-15 11:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9c0ca889d32575d1977cff61d6d239e542138cb4', 'message': 'Remove Tacker service from roles_data.\n\nTacker templates where removed completely in Train [0] as\nthe service had been incomplete since Queens. Therefore,\nthere is no need to keep the service inside any customized\nroles_data.\n\nThis patch parses the customized roles_data passed during the\nupgrade prepare step and removes the Tacker service.\n\n[0] - I2856e894b58d50c2d3484ccd02bfb1d43625847f\n\nChange-Id: Ieb7d49ece360073ef3881d5b903833ec61192c4c\n(cherry picked from commit e77df3055e78c63d11993d6f5cdcc08207b4410b)\n'}, {'number': 3, 'created': '2020-01-16 11:24:06.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/7c6fc9a2880fc5d05a9bc06b4e3ce673614d7995', 'message': 'Remove Tacker service from roles_data.\n\nTacker templates where removed completely in Train [0] as\nthe service had been incomplete since Queens. Therefore,\nthere is no need to keep the service inside any customized\nroles_data.\n\nThis patch parses the customized roles_data passed during the\nupgrade prepare step and removes the Tacker service.\n\n[0] - I2856e894b58d50c2d3484ccd02bfb1d43625847f\n\nChange-Id: Ieb7d49ece360073ef3881d5b903833ec61192c4c\n(cherry picked from commit e77df3055e78c63d11993d6f5cdcc08207b4410b)\n'}]",0,702614,7c6fc9a2880fc5d05a9bc06b4e3ce673614d7995,10,6,3,26343,,,0,"Remove Tacker service from roles_data.

Tacker templates where removed completely in Train [0] as
the service had been incomplete since Queens. Therefore,
there is no need to keep the service inside any customized
roles_data.

This patch parses the customized roles_data passed during the
upgrade prepare step and removes the Tacker service.

[0] - I2856e894b58d50c2d3484ccd02bfb1d43625847f

Change-Id: Ieb7d49ece360073ef3881d5b903833ec61192c4c
(cherry picked from commit e77df3055e78c63d11993d6f5cdcc08207b4410b)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/14/702614/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,9beef3ca91cb88a9c76ecb29e14d99e6ed276dff,,"- name: drop Tacker service replace: dest: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::Tacker$)' replace: '' ",,6,0
openstack%2Ftripleo-upgrade~stable%2Ftrain~I543a885c9285e979b6c6826e834f8bb9d127e670,openstack/tripleo-upgrade,stable/train,I543a885c9285e979b6c6826e834f8bb9d127e670,Remove NeutronLbaas services from roles_data.,MERGED,2020-01-15 09:35:43.000000000,2020-01-16 23:14:52.000000000,2020-01-16 23:14:51.000000000,"[{'_account_id': 6469}, {'_account_id': 6816}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 26343}, {'_account_id': 27141}]","[{'number': 1, 'created': '2020-01-15 09:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/def59f36d1f6f192788257c6544d84c8d50bc4f6', 'message': 'Remove NeutronLbaas services from roles_data.\n\nNeutronLbaas templates have been removed in Train [0]. Therefore,\nthere is no need to keep the service in the roles_data passed for\nthe upgrade prepare.\n\nThis patch will parse the roles data file and remove the\nNeutronLbaasv2Api and NeutronLbaasv2Agent.\n\n[0] - If13bbcdea82045d816485412f252c9b52bcf45a7\nChange-Id: I543a885c9285e979b6c6826e834f8bb9d127e670\n(cherry picked from commit c5f596a272b0a9c54b61eff963d08dd43cc1545c)\n'}, {'number': 2, 'created': '2020-01-15 11:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/3b8bcbec0ed38cb981e9e53714771a7f5bd067bd', 'message': 'Remove NeutronLbaas services from roles_data.\n\nNeutronLbaas templates have been removed in Train [0]. Therefore,\nthere is no need to keep the service in the roles_data passed for\nthe upgrade prepare.\n\nThis patch will parse the roles data file and remove the\nNeutronLbaasv2Api and NeutronLbaasv2Agent.\n\n[0] - If13bbcdea82045d816485412f252c9b52bcf45a7\nChange-Id: I543a885c9285e979b6c6826e834f8bb9d127e670\n(cherry picked from commit c5f596a272b0a9c54b61eff963d08dd43cc1545c)\n'}, {'number': 3, 'created': '2020-01-16 11:24:06.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/e338e02f684fface729a263a8a227f4516a1f0d4', 'message': 'Remove NeutronLbaas services from roles_data.\n\nNeutronLbaas templates have been removed in Train [0]. Therefore,\nthere is no need to keep the service in the roles_data passed for\nthe upgrade prepare.\n\nThis patch will parse the roles data file and remove the\nNeutronLbaasv2Api and NeutronLbaasv2Agent.\n\n[0] - If13bbcdea82045d816485412f252c9b52bcf45a7\nChange-Id: I543a885c9285e979b6c6826e834f8bb9d127e670\n(cherry picked from commit c5f596a272b0a9c54b61eff963d08dd43cc1545c)\n'}]",2,702611,e338e02f684fface729a263a8a227f4516a1f0d4,16,8,3,26343,,,0,"Remove NeutronLbaas services from roles_data.

NeutronLbaas templates have been removed in Train [0]. Therefore,
there is no need to keep the service in the roles_data passed for
the upgrade prepare.

This patch will parse the roles data file and remove the
NeutronLbaasv2Api and NeutronLbaasv2Agent.

[0] - If13bbcdea82045d816485412f252c9b52bcf45a7
Change-Id: I543a885c9285e979b6c6826e834f8bb9d127e670
(cherry picked from commit c5f596a272b0a9c54b61eff963d08dd43cc1545c)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/11/702611/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,def59f36d1f6f192788257c6544d84c8d50bc4f6,,"- name: drop NeutronLBaas services replace: dest: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::{{ item }}$)' replace: '' loop: - NeutronLbaasv2Agent - NeutronLbaasv2Api",,8,0
openstack%2Ftripleo-upgrade~stable%2Ftrain~I114cbacdac9547ed523cc4cbb1853718cdb79b5a,openstack/tripleo-upgrade,stable/train,I114cbacdac9547ed523cc4cbb1853718cdb79b5a,Remove OpenDaylight services from roles_data.,MERGED,2020-01-15 09:35:03.000000000,2020-01-16 23:14:51.000000000,2020-01-16 23:14:51.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 11166}, {'_account_id': 16515}, {'_account_id': 18575}, {'_account_id': 20775}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 09:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/8e44ca1a243aaf19cb06489097e79e40d4cadf80', 'message': 'Remove OpenDaylight services from roles_data.\n\nOpenDaylight was deprecated from TripleO in Rocky and their\ntemplates got removed in Train [0]. Therefore, there is no\nneed to keep the service in the roles_data passed for the\nupgrade prepare.\n\nThis patch will parse the roles data file and remove the\nOpenDaylighApi and OpenDaylightOvs services.\n\n[0] - I9711ef977d045f1dbcdc631fe2655294109031b8\n\nChange-Id: I114cbacdac9547ed523cc4cbb1853718cdb79b5a\n(cherry picked from commit e7aed80713071fc21d637e6ca58e6cb109022810)\n'}, {'number': 2, 'created': '2020-01-15 11:17:30.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/cf64a0e0972dd88431066fbabfb9f4b030b43674', 'message': 'Remove OpenDaylight services from roles_data.\n\nOpenDaylight was deprecated from TripleO in Rocky and their\ntemplates got removed in Train [0]. Therefore, there is no\nneed to keep the service in the roles_data passed for the\nupgrade prepare.\n\nThis patch will parse the roles data file and remove the\nOpenDaylighApi and OpenDaylightOvs services.\n\n[0] - I9711ef977d045f1dbcdc631fe2655294109031b8\n\nChange-Id: I114cbacdac9547ed523cc4cbb1853718cdb79b5a\n(cherry picked from commit e7aed80713071fc21d637e6ca58e6cb109022810)\n'}]",0,702610,cf64a0e0972dd88431066fbabfb9f4b030b43674,8,7,2,26343,,,0,"Remove OpenDaylight services from roles_data.

OpenDaylight was deprecated from TripleO in Rocky and their
templates got removed in Train [0]. Therefore, there is no
need to keep the service in the roles_data passed for the
upgrade prepare.

This patch will parse the roles data file and remove the
OpenDaylighApi and OpenDaylightOvs services.

[0] - I9711ef977d045f1dbcdc631fe2655294109031b8

Change-Id: I114cbacdac9547ed523cc4cbb1853718cdb79b5a
(cherry picked from commit e7aed80713071fc21d637e6ca58e6cb109022810)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/10/702610/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,8e44ca1a243aaf19cb06489097e79e40d4cadf80,,"- name: drop OpenDaylight services replace: dest: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::{{ item }}$)' replace: '' loop: - OpenDaylightOvs - OpenDaylightApi ",,9,0
openstack%2Ftripleo-upgrade~stable%2Ftrain~I2cf778e100489566b6560196aa063fb4a6bc347e,openstack/tripleo-upgrade,stable/train,I2cf778e100489566b6560196aa063fb4a6bc347e,Remove NovaConsoleAuth from roles_data.,MERGED,2020-01-15 09:34:24.000000000,2020-01-16 23:14:50.000000000,2020-01-16 23:14:50.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 17216}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 09:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/7a55c9c417554ee85cee3ae8a069be9aa51571bc', 'message': 'Remove NovaConsoleAuth from roles_data.\n\nAs of Rocky [1], the nova-consoleauth service has been deprecated and\ncell databases are used for storing token authorizations. Therefore,\nthere is no need to keep the service in the roles_data passed for the\nupgrade prepare.\nThis patch will parse the roles data file and remove the service\nNovaConsoleAuth.\n\n[1] - https://docs.openstack.org/releasenotes/nova/rocky.html\n\nChange-Id: I2cf778e100489566b6560196aa063fb4a6bc347e\n(cherry picked from commit 493189680b10d7ab20967f02d757669acea48f50)\n'}, {'number': 2, 'created': '2020-01-15 11:17:30.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/08264d79c096d69867a83a2554d17c363d64220c', 'message': 'Remove NovaConsoleAuth from roles_data.\n\nAs of Rocky [1], the nova-consoleauth service has been deprecated and\ncell databases are used for storing token authorizations. Therefore,\nthere is no need to keep the service in the roles_data passed for the\nupgrade prepare.\nThis patch will parse the roles data file and remove the service\nNovaConsoleAuth.\n\n[1] - https://docs.openstack.org/releasenotes/nova/rocky.html\n\nChange-Id: I2cf778e100489566b6560196aa063fb4a6bc347e\n(cherry picked from commit 493189680b10d7ab20967f02d757669acea48f50)\n'}]",0,702609,08264d79c096d69867a83a2554d17c363d64220c,9,6,2,26343,,,0,"Remove NovaConsoleAuth from roles_data.

As of Rocky [1], the nova-consoleauth service has been deprecated and
cell databases are used for storing token authorizations. Therefore,
there is no need to keep the service in the roles_data passed for the
upgrade prepare.
This patch will parse the roles data file and remove the service
NovaConsoleAuth.

[1] - https://docs.openstack.org/releasenotes/nova/rocky.html

Change-Id: I2cf778e100489566b6560196aa063fb4a6bc347e
(cherry picked from commit 493189680b10d7ab20967f02d757669acea48f50)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/09/702609/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,7a55c9c417554ee85cee3ae8a069be9aa51571bc,,"- name: drop NovaConsoleAuth service replace: dest: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::NovaConsoleauth$)' replace: '' ",,6,0
openstack%2Ftripleo-upgrade~stable%2Ftrain~I996cd861a54ad1cc58288058c8a31e7562d93a41,openstack/tripleo-upgrade,stable/train,I996cd861a54ad1cc58288058c8a31e7562d93a41,Replace Fluentd and SensuClient from roles_data.,MERGED,2020-01-14 15:11:34.000000000,2020-01-16 23:14:49.000000000,2020-01-16 23:14:49.000000000,"[{'_account_id': 5241}, {'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 11166}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 27141}]","[{'number': 1, 'created': '2020-01-14 15:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/7c5d281c364382f00fbd36d059b251b0ef8ef75a', 'message': 'Replace Fluentd and SensuClient from roles_data.\n\nWhen using composable roles, we need to make sure that the roles_data file\ndoes not contain the deprecated services Fluentd [0] and SensuClient[1].\nThis services were replaced in Train by Rsyslog and Collectd respectively.\n\n[0] - I1e12470b4eea86d8b7a971875d28a2a5e50d5e07\n[1] - I4be68eb7319b2c92cc7d0fc9df7a5c87dfb5106c\n\nChange-Id: I996cd861a54ad1cc58288058c8a31e7562d93a41\n(cherry picked from commit b45a18ec4e0d84d39f42c5b1c15dded6d070ab6b)\n'}, {'number': 2, 'created': '2020-01-15 09:33:55.000000000', 'files': ['tasks/common/adjust-roles-data.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/30ca3cc43452c1ccab2604efdc20283db6408bda', 'message': 'Replace Fluentd and SensuClient from roles_data.\n\nWhen using composable roles, we need to make sure that the roles_data file\ndoes not contain the deprecated services Fluentd [0] and SensuClient[1].\nThis services were replaced in Train by Rsyslog and Collectd respectively.\n\n[0] - I1e12470b4eea86d8b7a971875d28a2a5e50d5e07\n[1] - I4be68eb7319b2c92cc7d0fc9df7a5c87dfb5106c\n\nChange-Id: I996cd861a54ad1cc58288058c8a31e7562d93a41\n(cherry picked from commit b45a18ec4e0d84d39f42c5b1c15dded6d070ab6b)\n'}]",0,702459,30ca3cc43452c1ccab2604efdc20283db6408bda,10,8,2,26343,,,0,"Replace Fluentd and SensuClient from roles_data.

When using composable roles, we need to make sure that the roles_data file
does not contain the deprecated services Fluentd [0] and SensuClient[1].
This services were replaced in Train by Rsyslog and Collectd respectively.

[0] - I1e12470b4eea86d8b7a971875d28a2a5e50d5e07
[1] - I4be68eb7319b2c92cc7d0fc9df7a5c87dfb5106c

Change-Id: I996cd861a54ad1cc58288058c8a31e7562d93a41
(cherry picked from commit b45a18ec4e0d84d39f42c5b1c15dded6d070ab6b)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/59/702459/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/adjust-roles-data.yaml'],1,7c5d281c364382f00fbd36d059b251b0ef8ef75a,,"- name: Replace Fluentd for Rsyslog service replace: path: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::Fluentd$)' replace: '\1- OS::TripleO::Services::Rsyslog' - name: Replace SensuClient for Collectd service replace: path: ""{{ roles_data }}"" regexp: '(\s+)(- OS::TripleO::Services::SensuClient$)' replace: '\1- OS::TripleO::Services::Collectd' ",,13,0
openstack%2Fstorlets~master~I936935d405da7f86e7828e528d0bfae76e50df00,openstack/storlets,master,I936935d405da7f86e7828e528d0bfae76e50df00,Py3: Encode log messages in StorletLogger,MERGED,2020-01-05 12:41:54.000000000,2020-01-16 23:14:06.000000000,2020-01-16 23:12:46.000000000,"[{'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-05 12:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b67504e8d405b2e64022393cbf1047dad23c122c', 'message': 'Py3: Encode log messages in StorletLogger\n\nChange-Id: I936935d405da7f86e7828e528d0bfae76e50df00\n'}, {'number': 2, 'created': '2020-01-06 14:08:03.000000000', 'files': ['storlets/agent/daemon/files.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/fe165a204727a3a952031f938039f7d7dfc96764', 'message': 'Py3: Encode log messages in StorletLogger\n\nChange-Id: I936935d405da7f86e7828e528d0bfae76e50df00\n'}]",0,701112,fe165a204727a3a952031f938039f7d7dfc96764,13,3,2,9816,,,0,"Py3: Encode log messages in StorletLogger

Change-Id: I936935d405da7f86e7828e528d0bfae76e50df00
",git fetch https://review.opendev.org/openstack/storlets refs/changes/12/701112/1 && git format-patch -1 --stdout FETCH_HEAD,['storlets/agent/daemon/files.py'],1,b67504e8d405b2e64022393cbf1047dad23c122c,default-py3, self.log_file.write(msg.encode('utf-8')), self.log_file.write(msg),1,1
openstack%2Fansible-role-openstack-operations~master~I2ff8eb4733c8707fd5a4647a202d521f7933b892,openstack/ansible-role-openstack-operations,master,I2ff8eb4733c8707fd5a4647a202d521f7933b892,Fixing the README RST formatting,MERGED,2020-01-15 18:36:47.000000000,2020-01-16 23:01:09.000000000,2020-01-16 23:01:09.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 18:36:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ansible-role-openstack-operations/commit/274739ee5b0ff702f67af59ec2ff42b78c495bce', 'message': 'Fixing the README RST formatting\n\nThis resolves the links, the subtitles and the markup literals\n\nChange-Id: I2ff8eb4733c8707fd5a4647a202d521f7933b892\nCloses-Bug: #1859860\n'}]",0,702719,274739ee5b0ff702f67af59ec2ff42b78c495bce,7,3,1,25820,,,0,"Fixing the README RST formatting

This resolves the links, the subtitles and the markup literals

Change-Id: I2ff8eb4733c8707fd5a4647a202d521f7933b892
Closes-Bug: #1859860
",git fetch https://review.opendev.org/openstack/ansible-role-openstack-operations refs/changes/19/702719/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,274739ee5b0ff702f67af59ec2ff42b78c495bce,bug/1859860,"This role uses a service map located in ``vars/main.yml``. The service map is a dictionary with one key per service name. Each service name key contains three additional keys that list the SystemD unit files, container names, and vhosts used by each service. It is possible to extend this list of services by defining custom services in ``operations_custom_service_map``. This will be combined with the default service map and passed to the ``service_map_facts`` module. The ``service_map_facts`` module will evalute the target system and return a list of services or containers that need to be restarted. Those lists will then be used in subsequent tasks to restart a service or a container.To fetch logs with this role, use the ``fetch_logs.yml`` tasks file. By default, every log file in ``/var/log`` matching the ``*.log`` pattern will be fetched from the remote and put into a folder adjacent to the playbook named for each host, preserving the directory structure as found on the remote host. See ``defaults/main.yml`` for the dictionary of options to control logs that are fetched.To perform the most common cleanup tasks --- delete dangling images and volumes and delete exited or dead containers --- use the ``container_cleanup.yml`` tasks file. This role includes modules for listing image, volume, and container IDs. The filtered lists (one each for images, containers, and volumes) returned by this module are used to determine which items to remove. Specifying multiple filters creates an ``and`` match, so all filters must match. If using Docker, see these guides for `images <https://docs.docker.com/engine/reference/commandline/images/#filtering>`_, `containers <https://docs.docker.com/engine/reference/commandline/ps/#filtering>`_, and `volumes <https://docs.docker.com/engine/reference/commandline/volume_ls/#filtering>`_ for filter options.See `Backup and Restore Operations`__ for more details. __ https://github.com/openstack/ansible-role-openstack-operations/blob/master/README-backup-ops.md----------------------------------------------------------------------------","This role uses a service map located in `vars/main.yml`. The service map is a dictionary with one key per service name. Each service name key contains three additional keys that list the SystemD unit files, container names, and vhosts used by each service. It is possible to extend this list of services by defining custom services in `operations_custom_service_map`. This will be combined with the default service map and passed to the `service_map_facts` module. The `service_map_facts` module will evalute the target system and return a list of services or containers that need to be restarted. Those lists will then be used in subsequent tasks to restart a service or a container.To fetch logs with this role, use the `fetch_logs.yml` tasks file. By default, every log file in `/var/log` matching the `*.log` pattern will be fetched from the remote and put into a folder adjacent to the playbook named for each host, preserving the directory structure as found on the remote host. See `defaults/main.yml` for the dictionary of options to control logs that are fetched.To perform the most common cleanup tasks --- delete dangling images and volumes and delete exited or dead containers --- use the `container_cleanup.yml` tasks file. This role includes modules for listing image, volume, and container IDs. The filtered lists (one each for images, containers, and volumes) returned by this module are used to determine which items to remove. Specifying multiple filters creates an `and` match, so all filters must match. If using Docker, see these guides for [images](https://docs.docker.com/engine/reference/commandline/images/#filtering), [containers](https://docs.docker.com/engine/reference/commandline/ps/#filtering), and [volumes](https://docs.docker.com/engine/reference/commandline/volume_ls/#filtering) for filter options.See [Backup and Restore Operations](README-backup-ops.md) for more details.~~~~~~~~~~~~~~~~---------~~~~~~~~~~~~~~~~~~~~~~~---------~~~~~~~~~~---------",13,11
openstack%2Fpython-senlinclient~master~Id86de6b06dbbf904976b6c845f6a843bbdd2a91b,openstack/python-senlinclient,master,Id86de6b06dbbf904976b6c845f6a843bbdd2a91b,Drop python 2.7 support and testing,MERGED,2019-10-31 07:54:56.000000000,2020-01-16 22:37:54.000000000,2020-01-16 22:34:31.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-10-31 07:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/adc754cc03e608f14b980c3c9438681abc62502c', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\npython-senlinclient is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: Id86de6b06dbbf904976b6c845f6a843bbdd2a91b\n'}, {'number': 2, 'created': '2019-12-13 23:43:25.000000000', 'files': ['releasenotes/notes/drop-py-2-7-cced38f13fd3b44c.yaml', '.zuul.yaml', 'playbooks/legacy/senlinclient-dsvm-functional/run.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/60202d8222b3063f156af9abe5500f7c5d04f3c4', 'message': 'Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\npython-senlinclient is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/\n\nChange-Id: Id86de6b06dbbf904976b6c845f6a843bbdd2a91b\n'}]",0,692286,60202d8222b3063f156af9abe5500f7c5d04f3c4,12,4,2,8556,,,0,"Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

python-senlinclient is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal - https://review.opendev.org/#/c/691178/

Change-Id: Id86de6b06dbbf904976b6c845f6a843bbdd2a91b
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/86/692286/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-py-2-7-cced38f13fd3b44c.yaml', '.zuul.yaml', 'playbooks/legacy/senlinclient-dsvm-functional/run.yaml', 'setup.cfg', 'tox.ini']",5,adc754cc03e608f14b980c3c9438681abc62502c,drop-py27-support,"envlist = py37,pep8,releasenotes","envlist = py27,py37,pep8,releasenotes",9,5
openstack%2Ftripleo-operator-ansible~master~I511b6ace42a08e8669d727aa19c5bc4b51c069a5,openstack/tripleo-operator-ansible,master,I511b6ace42a08e8669d727aa19c5bc4b51c069a5,Global role readme,MERGED,2020-01-15 18:01:47.000000000,2020-01-16 22:28:17.000000000,2020-01-16 22:28:17.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 18:01:47.000000000', 'files': ['roles/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/103fc86d72973ef511d81dc2fe3113605514ebd5', 'message': ""Global role readme\n\nWe're getting to the part where we should have a general readme for the\nroles that contains documentation about some global variables that might\nbe consumed across multiple roles by default. Currently this is limited\nto the auth related variables.  Additionally the readme has a basic\nexample undercloud install playbook to indicate how some of the roles\ncan be used.\n\nChange-Id: I511b6ace42a08e8669d727aa19c5bc4b51c069a5\n""}]",0,702711,103fc86d72973ef511d81dc2fe3113605514ebd5,7,3,1,14985,,,0,"Global role readme

We're getting to the part where we should have a general readme for the
roles that contains documentation about some global variables that might
be consumed across multiple roles by default. Currently this is limited
to the auth related variables.  Additionally the readme has a basic
example undercloud install playbook to indicate how some of the roles
can be used.

Change-Id: I511b6ace42a08e8669d727aa19c5bc4b51c069a5
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/11/702711/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/README.md'],1,103fc86d72973ef511d81dc2fe3113605514ebd5,tripleo-auth-file,"tripleo-operator-ansible roles ============================== These roles wrap tripleo cli functions for use in automation. Requirements ------------ None. Global Variables ---------------- Accross the roles, there are a few variables that can be defined and would be consumed by default. * `tripleo_os_cloud`: (String) OS_CLOUD name to use when a command requires authentication. By default this will be used to populate any role specific os_cloud variable that may be defined. If this is defined, it will take precedence over `tripleo_rc_file`. * `tripleo_rc_file`: (String) File path on the remote system that contains the authentication environment variables that will be used to perform actions that require authentication. Dependencies ------------ None. Example Playbooks ----------------- Example undercloud installation --- - hosts: undercloud gather_facts: true collections: - tripleo.operator tasks: - name: Create dummy interface command: ip link add prov type dummy become: true when: not 'prov' in ansible_facts.interfaces - name: Set hostname hostname: name: 'undercloud.localdomain' become: true - name: Configure tripleo repositories import_role: name: tripleo-repos - name: Install python2 tripleoclient package: name: python2-tripleoclient state: present become: true when: ansible_distribution_major_version|int <= 7 - name: Install python3 tripleoclient package: name: python3-tripleoclient state: present become: true when: ansible_distribution_major_version|int >= 8 # This uses https://opendev.org/openstack/ansible-config_template - name: Generate undercloud.conf become: True config_template: src: /usr/share/python-tripleoclient/undercloud.conf.sample dest: ""{{ ansible_env.HOME }}/undercloud.conf"" remote_src: true render_template: false config_overrides: 'DEFAULT': undercloud_debug: true enable_telemetry: false local_mtu: 1400 local_interface: prov undercloud_enable_selinux: false 'ctlplane-subnet': masquerade: true config_type: ini - name: Install undercloud import_role: name: tripleo-undercloud-install vars: tripleo_undercloud_install_debug: true License ------- Apache-2.0 ",,92,0
openstack%2Ftripleo-operator-ansible~master~I2367ac443d1d7b370f7c0744539a20031c598f7d,openstack/tripleo-operator-ansible,master,I2367ac443d1d7b370f7c0744539a20031c598f7d,Add role to cover ansible config generation,MERGED,2020-01-14 22:58:29.000000000,2020-01-16 22:28:17.000000000,2020-01-16 22:28:17.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 22:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/279bea712fcb000237a473bbb9dc90ed18b1d5da', 'message': 'Add role to cover ansible config generation\n\nAdds tripleo-config-generate-ansible role to run the command to generate\nthe default ansible config.\n\nChange-Id: I2367ac443d1d7b370f7c0744539a20031c598f7d\n'}, {'number': 2, 'created': '2020-01-15 18:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/b0a6abf248fc88ff738e427f385b3930a14a32ef', 'message': 'Add role to cover ansible config generation\n\nAdds tripleo-config-generate-ansible role to run the command to generate\nthe default ansible config.\n\nChange-Id: I2367ac443d1d7b370f7c0744539a20031c598f7d\n'}, {'number': 3, 'created': '2020-01-15 18:32:21.000000000', 'files': ['roles/tripleo-config-generate-ansible/README.md', 'roles/tripleo-config-generate-ansible/tests/inventory', 'roles/tripleo-config-generate-ansible/tests/test.yml', 'roles/tripleo-config-generate-ansible/defaults/main.yml', 'roles/tripleo-config-generate-ansible/meta/main.yml', 'roles/tripleo-config-generate-ansible/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/446cede0570c58dc43ae6408e377d2fbbcd7ec97', 'message': 'Add role to cover ansible config generation\n\nAdds tripleo-config-generate-ansible role to run the command to generate\nthe default ansible config.\n\nChange-Id: I2367ac443d1d7b370f7c0744539a20031c598f7d\n'}]",5,702548,446cede0570c58dc43ae6408e377d2fbbcd7ec97,17,4,3,14985,,,0,"Add role to cover ansible config generation

Adds tripleo-config-generate-ansible role to run the command to generate
the default ansible config.

Change-Id: I2367ac443d1d7b370f7c0744539a20031c598f7d
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/48/702548/3 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-config-generate-ansible/README.md', 'roles/tripleo-config-generate-ansible/tests/inventory', 'roles/tripleo-config-generate-ansible/tests/test.yml', 'roles/tripleo-config-generate-ansible/defaults/main.yml', 'roles/tripleo-config-generate-ansible/meta/main.yml', 'roles/tripleo-config-generate-ansible/tasks/main.yml']",6,279bea712fcb000237a473bbb9dc90ed18b1d5da,tripleo-auth-file,"--- - name: Setup config generate ansible facts set_fact: _generate_cmd: >- {{ tripleo_config_generate_ansible_os_cloud | ternary('', ""source "" ~ tripleo_config_generate_ansible_rc_file ~ ""; "") }} openstack tripleo config generate ansible {{ tripleo_config_generate_ansible_deployment_user | ternary(""--deployment_user "" ~ tripleo_config_generate_ansible_deployment_user, '') }} {{ tripleo_config_generate_ansible_output_dir | ternary(""--output-dir "" ~ tripleo_config_generate_ansible_output_dir, '') }} - name: Show the config generate ansible command debug: var: _generate_cmd when: tripleo_config_generate_ansible_debug|bool - name: tripleo config generate ansible shell: ""{{ _generate_cmd }}"" # noqa 305 args: warn: false environment: OS_CLOUD: ""{{ tripleo_config_generate_ansible_os_cloud | ternary(tripleo_config_generate_ansible_os_cloud, omit) }}"" changed_when: true ",,117,0
openstack%2Frequirements~master~Ia5b6d73817fe531c4f660c8afff4de3ec8cecf7f,openstack/requirements,master,Ia5b6d73817fe531c4f660c8afff4de3ec8cecf7f,Raise python-rsdclient upper constraint to 1.0.2,MERGED,2020-01-16 15:25:50.000000000,2020-01-16 22:02:52.000000000,2020-01-16 22:01:02.000000000,"[{'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 15:25:50.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/95cda74696f9ee443361dcf72df1df576e4e636f', 'message': 'Raise python-rsdclient upper constraint to 1.0.2\n\nThis contains an important fix to not import a private module from cliff\nthat has been changed in the latest release.\n\nChange-Id: Ia5b6d73817fe531c4f660c8afff4de3ec8cecf7f\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,702893,95cda74696f9ee443361dcf72df1df576e4e636f,8,3,1,11904,,,0,"Raise python-rsdclient upper constraint to 1.0.2

This contains an important fix to not import a private module from cliff
that has been changed in the latest release.

Change-Id: Ia5b6d73817fe531c4f660c8afff4de3ec8cecf7f
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/702893/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,95cda74696f9ee443361dcf72df1df576e4e636f,new-release,python-rsdclient===1.0.2,python-rsdclient===1.0.1,1,1
openstack%2Fproject-config~master~I65ffceb0e63b9c5dcbc995e9d9e52abf1f9ac4ee,openstack/project-config,master,I65ffceb0e63b9c5dcbc995e9d9e52abf1f9ac4ee,Add ovs and dpdk source to available repos,MERGED,2020-01-08 13:13:01.000000000,2020-01-16 21:59:12.000000000,2020-01-16 21:59:12.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-08 13:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9c3f4410d0f4f77ae07d4340534e716f8220d0e9', 'message': 'Add ovs and dpdk source to available repos\n\nThis change adds the upstream dpdk and ovs\ngithub repos to the openstack tenant to allow\nnetworking-ovs-dpdk to use zuul to prestage the\nrepos instead of git cloning them during devstack\ninstallation.\n\nChange-Id: I65ffceb0e63b9c5dcbc995e9d9e52abf1f9ac4ee\n'}, {'number': 2, 'created': '2020-01-08 13:17:03.000000000', 'files': ['zuul/main.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3f41d6be143a98d2848c42f9a0e42cc260d8817b', 'message': 'Add ovs and dpdk source to available repos\n\nThis change adds the upstream dpdk and ovs\ngithub repos to the openstack tenant to allow\nnetworking-ovs-dpdk to use zuul to prestage the\nrepos instead of git cloning them during devstack\ninstallation.\n\nChange-Id: I65ffceb0e63b9c5dcbc995e9d9e52abf1f9ac4ee\n'}]",1,701539,3f41d6be143a98d2848c42f9a0e42cc260d8817b,10,5,2,11604,,,0,"Add ovs and dpdk source to available repos

This change adds the upstream dpdk and ovs
github repos to the openstack tenant to allow
networking-ovs-dpdk to use zuul to prestage the
repos instead of git cloning them during devstack
installation.

Change-Id: I65ffceb0e63b9c5dcbc995e9d9e52abf1f9ac4ee
",git fetch https://review.opendev.org/openstack/project-config refs/changes/39/701539/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/main.yaml'],1,9c3f4410d0f4f77ae07d4340534e716f8220d0e9,networking-ovs-dpdk, - DPDK/dpdk - openvswitch/ovs,,2,0
openstack%2Fproject-config~master~Ia43e55145227bdc6f8cde740e104a954194b93c0,openstack/project-config,master,Ia43e55145227bdc6f8cde740e104a954194b93c0,"Revert ""Temporarily disable fortnebula""",MERGED,2020-01-16 21:37:33.000000000,2020-01-16 21:59:11.000000000,2020-01-16 21:59:11.000000000,"[{'_account_id': 2}, {'_account_id': 5263}, {'_account_id': 20754}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 21:37:33.000000000', 'files': ['nodepool/nl02.openstack.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/59699a14a6e56125d1c944705a03b31a8037fc48', 'message': 'Revert ""Temporarily disable fortnebula""\n\nThis reverts commit 23362bde1dbd5d40667a9b5a6c6003e6074dd7a6.\n\nThis cloud is back up again.\n\nChange-Id: Ia43e55145227bdc6f8cde740e104a954194b93c0\n'}]",0,702989,59699a14a6e56125d1c944705a03b31a8037fc48,8,4,1,4146,,,0,"Revert ""Temporarily disable fortnebula""

This reverts commit 23362bde1dbd5d40667a9b5a6c6003e6074dd7a6.

This cloud is back up again.

Change-Id: Ia43e55145227bdc6f8cde740e104a954194b93c0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/89/702989/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nl02.openstack.org.yaml'],1,59699a14a6e56125d1c944705a03b31a8037fc48,enable-fn, max-servers: 40 max-servers: 10, max-servers: 0 max-servers: 0,2,2
openstack%2Fproject-config~master~I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc,openstack/project-config,master,I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc,Add <build|publish>-wheel-mirror-centos-8 jobs,MERGED,2020-01-14 05:45:03.000000000,2020-01-16 21:53:03.000000000,2020-01-16 21:53:03.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 05:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/eb9677bbe6acc14c9c347831034fa1d03803e1f7', 'message': 'Add <build|publish>-wheel-mirror-centos-8 jobs\n\nChange-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc\n'}, {'number': 2, 'created': '2020-01-14 06:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0ebadc8059caf0193f0d6c55534dabe6da3b3b00', 'message': 'Add <build|publish>-wheel-mirror-centos-8 jobs\n\nChange-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc\n'}, {'number': 3, 'created': '2020-01-14 21:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0467cd0eb88756728091e41d94c628cf63026c06', 'message': 'Add <build|publish>-wheel-mirror-centos-8 jobs\n\nChange-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc\n'}, {'number': 4, 'created': '2020-01-14 21:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/025f39586176d925047e2aef1d1556e50e5a8af1', 'message': 'Add <build|publish>-wheel-mirror-centos-8 jobs\n\nChange-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc\n'}, {'number': 5, 'created': '2020-01-14 21:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/aa312dec590a329f1a3f5fd98497a34d1c4c3011', 'message': 'Add <build|publish>-wheel-mirror-centos-8 jobs\n\nChange-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc\n'}, {'number': 6, 'created': '2020-01-14 22:28:06.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3f3fa89d0ad4e7fa812a00407860a9559d097479', 'message': 'Add <build|publish>-wheel-mirror-centos-8 jobs\n\nChange-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc\n'}]",0,702350,3f3fa89d0ad4e7fa812a00407860a9559d097479,17,3,6,7118,,,0,"Add <build|publish>-wheel-mirror-centos-8 jobs

Change-Id: I4bff59d8d2b1ef8ea96ac1211774e1a01a536fbc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/702350/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,eb9677bbe6acc14c9c347831034fa1d03803e1f7,pep503-indexes, name: build-wheel-mirror-centos-8 parent: build-wheel-mirror-base description: | Build CentOS 8 wheels for OpenStack CI mirrors. nodeset: nodes: - name: wheel-mirror-centos-8-python3 label: centos-8 host-vars: wheel-mirror-centos-8-python3: wheel_python: python3 - job: name: publish-wheel-mirror-centos-8 description: | Publish CentOS 8 wheels for OpenStack CI mirrors. parent: build-wheel-mirror-centos-8 pre-run: playbooks/openafs-client/setup.yaml post-run: playbooks/publish/wheel-mirror.yaml final: true secrets: - name: afs secret: wheel_keytab - job:,,25,0
openstack%2Ftrove~stable%2Ftrain~I2fa79077660a45787b0e74799264b8533fc4e211,openstack/trove,stable/train,I2fa79077660a45787b0e74799264b8533fc4e211,Always use string for instance rpc encryption key,ABANDONED,2020-01-16 10:59:20.000000000,2020-01-16 21:45:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-16 10:59:20.000000000', 'files': ['trove/instance/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/26500c1085acefdc6e44a64a7fd7fa04557d676d', 'message': ""Always use string for instance rpc encryption key\n\nThis patch fixes the bug in trove-guestagent:\nAttributeError: 'TroveContext' object has no attribute 'notification'\n\nMaster branch has already fixed in\nhttps://review.opendev.org/#/c/697225/\n\nChange-Id: I2fa79077660a45787b0e74799264b8533fc4e211\n""}]",0,702842,26500c1085acefdc6e44a64a7fd7fa04557d676d,3,1,1,6732,,,0,"Always use string for instance rpc encryption key

This patch fixes the bug in trove-guestagent:
AttributeError: 'TroveContext' object has no attribute 'notification'

Master branch has already fixed in
https://review.opendev.org/#/c/697225/

Change-Id: I2fa79077660a45787b0e74799264b8533fc4e211
",git fetch https://review.opendev.org/openstack/trove refs/changes/42/702842/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/instance/models.py'],1,26500c1085acefdc6e44a64a7fd7fa04557d676d,fix-bytes-instance-key," # We need string anyway if isinstance(val, six.binary_type): val = encodeutils.safe_decode(val) ",,4,0
openstack%2Fcharm-deployment-guide~master~I8a0e55dd45d5a8a07f2adfb2b22c15d14b622496,openstack/charm-deployment-guide,master,I8a0e55dd45d5a8a07f2adfb2b22c15d14b622496,Install recent stable OpenStack,MERGED,2020-01-16 20:12:36.000000000,2020-01-16 21:20:38.000000000,2020-01-16 21:18:34.000000000,"[{'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 20:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/a415045cad977af95e9dddad961105a152ffcc1b', 'message': 'Install recent stable OpenStack\n\nThe deploy-guide policy is to track the latest\nstable OpenStack release.\n\nCloses-Bug: #1859089\n\nChange-Id: I8a0e55dd45d5a8a07f2adfb2b22c15d14b622496\n'}, {'number': 2, 'created': '2020-01-16 20:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/983e9da2c1428b3acf6d5e41a377515d624962d0', 'message': 'Install recent stable OpenStack\n\nThe deploy-guide policy is to track the latest\nstable OpenStack release.\n\nCloses-Bug: #1859089\n\nChange-Id: I8a0e55dd45d5a8a07f2adfb2b22c15d14b622496\n'}, {'number': 3, 'created': '2020-01-16 20:19:09.000000000', 'files': ['deploy-guide/source/install-openstack.rst', 'deploy-guide/source/app-upgrade-openstack.rst', 'deploy-guide/source/index.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/62df478906c6e67cc4868fd6e09d24837e7ba129', 'message': 'Install recent stable OpenStack\n\nThe deploy-guide policy is to track the latest\nstable OpenStack release.\n\nCloses-Bug: #1859089\n\nChange-Id: I8a0e55dd45d5a8a07f2adfb2b22c15d14b622496\n'}]",0,702976,62df478906c6e67cc4868fd6e09d24837e7ba129,10,2,3,30561,,,0,"Install recent stable OpenStack

The deploy-guide policy is to track the latest
stable OpenStack release.

Closes-Bug: #1859089

Change-Id: I8a0e55dd45d5a8a07f2adfb2b22c15d14b622496
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/76/702976/2 && git format-patch -1 --stdout FETCH_HEAD,"['deploy-guide/source/install-openstack.rst', 'deploy-guide/source/app-upgrade-openstack.rst', 'deploy-guide/source/index.rst']",3,a415045cad977af95e9dddad961105a152ffcc1b,bug/1859089,* **OpenStack Train**Table of contents ----------------- ,,102,10
openstack%2Fcinder~master~I82e5b9ef37ec097d088e1bbea97f48ecc0a2cdf2,openstack/cinder,master,I82e5b9ef37ec097d088e1bbea97f48ecc0a2cdf2,Snapshot does not expand after expanding volume,ABANDONED,2019-12-10 11:04:26.000000000,2020-01-16 21:18:50.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 18120}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2019-12-10 11:04:26.000000000', 'files': ['cinder/volume/drivers/macrosan/devop_client.py', 'cinder/volume/drivers/macrosan/driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/30d635125c22f8147d06f774ce8275827831cad6', 'message': 'Snapshot does not expand after expanding volume\n\nChange-Id: I82e5b9ef37ec097d088e1bbea97f48ecc0a2cdf2\nCloses-Bug: #1855850\n'}]",0,698217,30d635125c22f8147d06f774ce8275827831cad6,26,19,1,31331,,,0,"Snapshot does not expand after expanding volume

Change-Id: I82e5b9ef37ec097d088e1bbea97f48ecc0a2cdf2
Closes-Bug: #1855850
",git fetch https://review.opendev.org/openstack/cinder refs/changes/17/698217/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/macrosan/devop_client.py', 'cinder/volume/drivers/macrosan/driver.py']",2,30d635125c22f8147d06f774ce8275827831cad6,bug/1855850,"# Copyright (c) 2016 MacroSAN Technologies Co., Ltd. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Volume Drivers for MacroSAN SAN."""""" import base64 from collections import namedtuple from contextlib import contextmanager import math import re import socket import time from xml.etree.ElementTree import parse import uuid from os_brick.initiator import connector as cn from os_brick.initiator import linuxfc from oslo_config import cfg from oslo_concurrency.lockutils import lock from oslo_log import log as logging from oslo_utils import timeutils from oslo_utils import strutils from oslo_utils import excutils from cinder import context from cinder import exception from cinder import utils from cinder.volume import driver from cinder.volume.drivers.macrosan import devop_client from cinder.volume import qos_specs from cinder.volume import utils as volume_utils from cinder.volume import volume_types from cinder.zonemanager import utils as fczm_utils LOG = logging.getLogger(__name__) opts = [ cfg.StrOpt('cinder_macrosan_conf', default='/etc/cinder/cinder_macrosan.xml', help='The configuration file for the Cinder MacroSAN Driver')] CONF = cfg.CONF CONF.register_opts(opts) version = 'Cinder_R-V5.1.0' timing_on = False lock_name = 'MacroSAN' @contextmanager def ignored(*exceptions): try: yield except exceptions: pass def _synchronized(f): def inner(*args, **kwargs): t1 = time.time() t2 = None try: with lock(lock_name, None, True, None, do_log=False, semaphores=None, delay=0.01): t2 = time.time() LOG.debug('Lock ""%(name)s"" acquired by ""%(function)s"" :: ' 'waited %(wait_secs)0.3fs', {'name': lock_name, 'function': f.__name__, 'wait_secs': (t2 - t1)}) return f(*args, **kwargs) finally: t3 = time.time() if t2 is None: held_secs = ""N/A"" else: held_secs = ""%0.3fs"" % (t3 - t2) LOG.debug('Lock ""%(name)s"" released by ""%(function)s"" :: held ' '%(held_secs)s', {'name': lock_name, 'function': f.__name__, 'held_secs': held_secs}) return inner def _timing(fn): def __timing(*vargs, **kv): if timing_on: start = time.time() LOG.info('========== start %s', fn.__name__) result = fn(*vargs, **kv) if timing_on: end = time.time() LOG.info('========== end %(fname)s, cost: %(cost).2f secs', {'fname': fn.__name__, 'cost': end - start}) return result return __timing def record_request_id(fn): def _record_request_id(*vargs, **kv): ctx = context.context.get_current() devop_client.context_request_id = ctx.request_id return fn(*vargs, **kv) return _record_request_id LoginInfo = namedtuple('LoginInfo', ['sp1', 'sp2', 'username', 'passwd']) def replication_synced(params): return (params['replication_enabled'] and params['replication_mode'] == 'sync') class MacroSANBaseDriver(driver.VolumeDriver): """"""Base driver for MacroSAN SAN."""""" def __init__(self, *args, **kwargs): """"""Initialize the driver."""""" super(MacroSANBaseDriver, self).__init__(*args, **kwargs) self.configuration.append_config_values(opts) self._stats = {} self.use_multipath = True self.owners = ['SP1', 'SP2'] self.owner_idx = 0 self.volume_backend_name =\ self.configuration.safe_get('volume_backend_name') or 'MacroSAN' self.login_info = None self.sdas_login_info = None self.replica_login_info = None self.client = None self.replica_client = None self.sdas_client = None self.ubs_client = None self.lun_params = {} self.storage_protocol = None self.device_uuid = None self.force_unmap_itl_when_deleting = False self.config_path = self.configuration.cinder_macrosan_conf @property def _self_node_wwns(self): return [] def _sizestr(self, size_in_g): if int(size_in_g) == 0: return 1 return int(size_in_g) def _volume_name(self, volume): try: lun_uuid = re.search('macrosan uuid:(.+)', volume['provider_location']).group(1) return self.client.get_lun_name(lun_uuid) except Exception: return volume['id'] def _snapshot_name(self, snapshotid): return snapshotid.replace('-', '')[:31] def _parse_and_encrypt_config_storage_device(self, node): if node is None: return None username = node.get('username') passwd = node.get('passwd') if passwd.find('!$$$') > -1: username = base64.b64decode(username[4:]) passwd = base64.b64decode(passwd[4:]) else: encode_username = '!$$$' + base64.b64encode(username) encode_passwd = '!$$$' + base64.b64encode(passwd) node.set('username', encode_username) node.set('passwd', encode_passwd) return LoginInfo(node.get('sp1'), node.get('sp2'), username, passwd) def _parse_config(self): try: root = parse(self.config_path) backend = root.find('./volume_backend[@name=""%s""]' % self.volume_backend_name) if backend is None: LOG.error('backend: %s not found', self.volume_backend_name) self.lun_mode = backend.get('lun_mode') if self.lun_mode == 'normal': self.lun_mode = 'thick' self.pool = backend.get('pool') lun = root.find('./lun') param = lun.find('./parameters') self.lun_params = { 'extent-size': param.get('extent_size'), 'use-ssd': param.get('use_ssd', 'no'), 'low-watermark': param.get('low_watermark'), 'high-watermark': param.get('high_watermark')} try: delete = root.find('./lun/delete') self.force_unmap_itl_when_deleting = ( delete.get('force_unmap_itl').lower() == 'on') except Exception: pass snapshot = root.find('./snapshot') self.snapshot_resource_ratio = ( float(snapshot.get('resource_ratio'))) node = root.find('./copy_volume') self.dd_block_size = node.get('dd_block_size') node = root.find('./storage_device[@type=""default""]') self.login_info = ( self._parse_and_encrypt_config_storage_device(node)) node = root.find('./storage_device[@type=""replica""]') self.replica_login_info = ( self._parse_and_encrypt_config_storage_device(node)) node = root.find('./storage_device[@type=""sdas""]') self.sdas_login_info = ( self._parse_and_encrypt_config_storage_device(node)) dst_node = root.find('./replication/destination') self.replication_params = { 'destination': {'sp1': dst_node.get('sp1'), 'sp2': dst_node.get('sp2')}} node = root.find('./storage_device[@type=""ubs""]') self.ubs_login_info = ( self._parse_and_encrypt_config_storage_device(node)) global lock_name lock_name = 'MacroSAN(%s/%s)' % (self.login_info.sp1, self.login_info.sp2) with ignored(Exception): node = root.find('./debug') global timing_on timing_on = node.get('timing').lower() == 'on' try: utils.execute('chmod', '666', self.config_path, run_as_root=True) root.write(self.config_path, 'UTF-8') except Exception as err: LOG.info('write encoded passwd error: %s', err) except Exception as e: with excutils.save_and_reraise_exception(): msg = 'Parse %s error: %s' % (self.config_path, e) raise exception.VolumeBackendAPIException(data=msg) def _get_client_name(self, host): root = parse(self.config_path) try: return root.find('.//client[@host=""%s""]' % host).get('name') except Exception: return host @utils.synchronized('MacroSAN-Setup', external=True) @record_request_id def do_setup(self, context): """"""Any initialization the volume driver does while starting."""""" self._parse_config() self.client = devop_client.Client(self.login_info.sp1, self.login_info.sp2, self.login_info.username, self.login_info.passwd) if self.sdas_login_info: self.sdas_client = ( devop_client.Client(self.sdas_login_info.sp1, self.sdas_login_info.sp2, self.sdas_login_info.username, self.sdas_login_info.passwd)) if self.replica_login_info: self.replica_client = ( devop_client.Client(self.replica_login_info.sp1, self.replica_login_info.sp2, self.replica_login_info.username, self.replica_login_info.passwd)) if self.ubs_login_info: self.ubs_client = ( devop_client.Client(self.ubs_login_info.sp1, self.ubs_login_info.sp2, self.ubs_login_info.username, self.ubs_login_info.passwd)) self.device_uuid = self.client.get_device_uuid() self._do_setup() LOG.info('MacroSAN Cinder Driver setup complete.') def _do_setup(self): pass def _get_owner(self): owner = self.owners[self.owner_idx % 2] self.owner_idx += 1 return owner def check_for_setup_error(self): """"""Check any setup error."""""" pass def _check_volume_params(self, params): if params['sdas'] and params['replication_enabled']: msg = 'sdas and replication can not be enabled at same time' raise exception.VolumeBackendAPIException(data=msg) if params['sdas'] and self.sdas_client is None: msg = 'sdas is not configured, cannot use sdas' raise exception.VolumeBackendAPIException(data=msg) if params['replication_enabled'] and self.replica_client is None: msg = 'replica is not configured, cannot use replication' raise exception.VolumeBackendAPIException(data=msg) def _create_volume(self, name, size, params, owner=None, pool=None, nvf_type=""normal""): rmt_client = None if params['sdas']: rmt_client = self.sdas_client elif params['replication_enabled']: rmt_client = self.replica_client owner = self._get_owner() if owner is None else owner raids = [] pool = self.pool if pool is None else pool if params['lun_mode'] != 'thin': raids = self.client.get_raid_list_to_create_lun(pool, size) self.client.create_lun(name, owner, pool, raids, params['lun_mode'], size, self.lun_params) if params['qos-strategy']: try: self.client.enable_lun_qos(name, params['qos-strategy']) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_lun(name) if params['sdas'] or params['replication_enabled']: rmt_name = name + '-rmt' res_size = int(max(int(size) * self.snapshot_resource_ratio, 1)) try: raids = self.client.get_raid_list_to_create_lun(pool, res_size) self.client.setup_snapshot_resource(name, res_size, raids) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_lun(name) try: raids = [] if params['lun_mode'] != 'thin': raids = rmt_client.get_raid_list_to_create_lun( pool, size) rmt_client.create_lun(rmt_name, owner, pool, raids, params['lun_mode'], size, self.lun_params) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) try: raids = rmt_client.get_raid_list_to_create_lun(pool, res_size) rmt_client.setup_snapshot_resource(rmt_name, res_size, raids) except Exception: with ignored(Exception): rmt_client.delete_lun(rmt_name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) if params['sdas'] or replication_synced(params): nvf_type = ""sdas"" try: node_id = rmt_client.get_nodeid() if node_id == ""0"": self.client.create_dalun_out_cluster(name, rmt_name) else: self.client.create_dalun_in_cluster(name, rmt_name, node_id) except Exception: with ignored(Exception): rmt_client.delete_snapshot_resource(rmt_name) rmt_client.delete_lun(rmt_name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) elif params['replication_mode'] == 'async': nvf_type = ""async_rep"" destination = self.replication_params['destination'] sp1_ipaddr = rmt_client.get_port_ipaddr(destination['sp1']) sp2_ipaddr = rmt_client.get_port_ipaddr(destination['sp2']) try: self.client.enable_replication(name, rmt_name, sp1_ipaddr, sp2_ipaddr) self.client.startscan_replication(name) except Exception as e: LOG.error(""Enable replication failed: %s"" % e) with ignored(Exception): self.client.disable_replication(name, ""delete"") with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) lun_uuid = self.client.get_lun_uuid(name) return {'provider_location': 'macrosan uuid:%s' % lun_uuid, 'nvf_type': nvf_type} def _parse_qos_strategy(self, volume_type): qos_specs_id = volume_type.get('qos_specs_id') if qos_specs_id is None: return '' ctx = context.get_admin_context() specs = qos_specs.get_qos_specs(ctx, qos_specs_id)['specs'] return specs.pop('qos-strategy', '').strip() if specs else '' def _default_volume_params(self): params = { 'qos-strategy': '', 'replication_enabled': False, 'replication_mode': 'async', 'sdas': False, 'lun_mode': self.lun_mode } return params def _parse_volume_params(self, volume): params = self._default_volume_params() try: params['nvf_type'] = volume['nvf_type'] except Exception: name = self._volume_name(volume) if self.client.dalun_exists(name): params['nvf_type'] = 'sdas' elif self.client.replication_enabled(name): params['nvf_type'] = 'async_rep' else: params['nvf_type'] = 'normal' if volume.volume_type_id is None: return params ctx = context.get_admin_context() volume_type = volume_types.get_volume_type(ctx, volume.volume_type_id) params['qos-strategy'] = self._parse_qos_strategy(volume_type) specs = dict(volume_type).get('extra_specs') for k, val in specs.items(): ks = k.lower().split(':') if len(ks) == 2 and ks[0] != ""capabilities"": continue k = ks[-1] if k not in params: continue if k in params: v = val.split()[-1] val_type = type(params[k]).__name__ if val_type == 'int': v = int(v) elif val_type == 'bool': v = strutils.bool_from_string(v) params[k] = v if params['sdas']: params['lun_mode'] = 'thick' return params @_synchronized @record_request_id @_timing def create_volume(self, volume): """"""Create a volume."""""" LOG.debug(('========== create volume, name: %(name)s,' 'id: %(volume_id)s, size: %(size)s.'), {'name': volume['name'], 'volume_id': volume['id'], 'size': volume['size']}) name = volume['id'] size = self._sizestr(volume['size']) params = self._parse_volume_params(volume) self._check_volume_params(params) return self._create_volume(name, size, params) def _delete_volume(self, name, params=None): if not self.client.lun_exists(name): return if params is None: params = self._default_volume_params() if self.force_unmap_itl_when_deleting: self.force_terminate_connection(name, False) if (params['sdas'] or replication_synced(params) or params['nvf_type'] == 'sdas'): rmt_name = name + '-rmt' if self.client.dalun_exists(name): self.client.suspend_dalun(name) self.client.delete_dalun(name) with ignored(Exception): self.sdas_client.delete_snapshot_resource(rmt_name) self.sdas_client.delete_lun(rmt_name) self.client.delete_snapshot_resource(name) if ((params['replication_enabled'] and params['replication_mode'] == 'async') or params['nvf_type'] == 'async_rep'): if self.client.replication_enabled(name): with ignored(Exception): self.client.stopscan_replication(name) with ignored(Exception): self.client.pausereplicate(name) self.client.disable_replication(name, 'delete') self.client.delete_snapshot_resource(name) self.client.delete_lun(name) try: migrated_name = self.client.get_lun_name_from_rename_file(name) if not migrated_name: return rmt_name = name + '-rmt' rmt_mig_name = migrated_name + '-rmt' try: snp_res_name = self.client.get_snapshot_resource_name(migrated_name) self.client.rename_lun(migrated_name, name) if snp_res_name: self.client.rename_lun(snp_res_name, 'SR-%s' % name) if self.client.dalun_exists(name): rmt_snp_res_name = self.sdas_client.get_snapshot_resource_name( rmt_mig_name) if rmt_snp_res_name: self.sdas_client.rename_lun(rmt_snp_res_name, 'SR-%s' % rmt_name) self.sdas_client.rename_lun(rmt_mig_name, rmt_name) elif self.client.replication_enabled(name): rmt_snp_res_name = self.replica_client.get_snapshot_resource_name(rmt_mig_name) self.replica_client.rename_lun(rmt_mig_name, rmt_name) self.client.updatereplicate(name) if rmt_snp_res_name: self.replica_client.rename_lun(rmt_snp_res_name, 'SR-%s' % rmt_name) except Exception: LOG.warning('========== failed to rename %(migrated_name)s' ' to %(name)s', {'migrated_name': migrated_name, 'name': name}) except Exception: return @_synchronized @record_request_id @_timing def delete_volume(self, volume): """"""Delete a volume."""""" LOG.debug('========== delete volume, id: %s.', volume['id']) name = self._volume_name(volume) params = self._parse_volume_params(volume) self._delete_volume(name, params) @utils.synchronized('MacroSAN-Attach', external=True) def _attach_volume(self, context, volume, properties, remote=False): time.sleep(0.5) return super(MacroSANBaseDriver, self)._attach_volume(context, volume, properties, remote) @utils.synchronized('MacroSAN-Attach', external=True) def _detach_volume(self, context, attach_info, volume, properties, force=False, remote=False, ignore_errors=False): time.sleep(0.5) return super(MacroSANBaseDriver, self)._detach_volume(context, attach_info, volume, properties, force, remote, ignore_errors) @_synchronized def _create_snapshot_with_lock(self, snapshot_name, volume_name, volume_size): size = int(max(int(volume_size) * self.snapshot_resource_ratio, 1)) raids = self.client.get_raid_list_to_create_lun(self.pool, size) if not self.client.snapshot_resource_exists(volume_name): self.client.create_snapshot_resource(volume_name, raids, size) try: self.client.enable_snapshot_resource_autoexpand(volume_name) except exception.VolumeBackendAPIException: LOG.warning('========== Enable snapshot resource auto ' 'expand for volume: %s error', volume_name) if not self.client.snapshot_enabled(volume_name): try: self.client.enable_snapshot(volume_name) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(volume_name) try: self.client.create_snapshot_point(volume_name, snapshot_name) pointid = self.client.get_snapshot_pointid(volume_name, snapshot_name) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): with ignored(Exception): self.client.disable_snapshot(volume_name) self.client.delete_snapshot_resource(volume_name) return int(pointid) def _create_snapshot(self, snapshot_name, volume_name, volume_size): size = int(max(int(volume_size) * self.snapshot_resource_ratio, 1)) raids = self.client.get_raid_list_to_create_lun(self.pool, size) if not self.client.snapshot_resource_exists(volume_name): self.client.create_snapshot_resource(volume_name, raids, size) try: self.client.enable_snapshot_resource_autoexpand(volume_name) except exception.VolumeBackendAPIException: LOG.warning('========== Enable snapshot resource auto ' 'expand for volume: %s error', volume_name) if not self.client.snapshot_enabled(volume_name): try: self.client.enable_snapshot(volume_name) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(volume_name) try: self.client.create_snapshot_point(volume_name, snapshot_name) pointid = self.client.get_snapshot_pointid(volume_name, snapshot_name) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): with ignored(Exception): self.client.disable_snapshot(volume_name) self.client.delete_snapshot_resource(volume_name) return int(pointid) @_synchronized @record_request_id @_timing def create_snapshot(self, snapshot): """"""Create a snapshot."""""" volume = snapshot['volume'] LOG.debug(('========== create snapshot, snapshot id: %(snapshot_id)s,' ' volume id: %(volume_id)s, size: %(size)s.'), {'snapshot_id': snapshot['id'], 'volume_id': volume['id'], 'size': volume['size']}) snapshot_name = self._snapshot_name(snapshot['id']) volume_name = self._volume_name(volume) pointid = self._create_snapshot(snapshot_name, volume_name, volume['size']) return {'provider_location': 'pointid: %s' % pointid} def _delete_snapshot(self, snapshot_name, volume_name, pointid): if self.client.snapshot_point_exists(volume_name, pointid): self.client.delete_snapshot_point(volume_name, pointid) with ignored(Exception): n = self.client.get_snapshot_point_num(volume_name) if n != 0: return with ignored(Exception): self.client.disable_snapshot(volume_name) if not (self.client.dalun_exists(volume_name) or self.client.replication_enabled(volume_name)): self.client.delete_snapshot_resource(volume_name) @_synchronized @record_request_id @_timing def delete_snapshot(self, snapshot): """"""Delete a snapshot."""""" volume = snapshot['volume'] provider = snapshot['provider_location'] if not provider: return m = re.findall('pointid: (\d+)', provider) if m is None: return LOG.debug(('========== delete snapshot, snapshot id: %(snapshot_id)s,' ' pointid: %(point_id)s, volume id: %(volume_id)s.'), {'snapshot_id': snapshot['id'], 'point_id': m[0], 'volume_id': volume['id']}) snapshot_name = self._snapshot_name(snapshot['id']) volume_name = self._volume_name(volume) self._delete_snapshot(snapshot_name, volume_name, m[0]) def _initialize_connection(self, name, host, wwns): raise NotImplementedError def _terminate_connection(self, name, host, wwns): raise NotImplementedError def _connect(self, name): host = socket.gethostname() conn = self._initialize_connection(name, host, self._self_node_wwns) device_scan_attempts = self.configuration.num_volume_device_scan_tries protocol = conn['driver_volume_type'] connector = utils.brick_get_connector( protocol, use_multipath=self.use_multipath, device_scan_attempts=device_scan_attempts, conn=conn) try: device = connector.connect_volume(conn['data']) except Exception: with excutils.save_and_reraise_exception(): self._terminate_connection(name, host, self._self_node_wwns) return {'conn': conn, 'device': device, 'connector': connector} def _disconnect(self, conn, name): connector = conn['connector'] connector.disconnect_volume(conn['conn']['data'], conn['device']) self._terminate_connection(name, socket.gethostname(), self._self_node_wwns) def _create_volume_from_snapshot(self, vol_name, vol_size, vol_params, snp_name, pointid, snp_vol_name, snp_vol_size): sdas_active = False if vol_params['sdas']: sdas_active = True vol_params['sdas'] = False self._create_volume(vol_name, vol_size, vol_params) try: self.client.create_snapshot_view(snp_name, snp_vol_name, pointid) except Exception: with excutils.save_and_reraise_exception(): self._delete_volume(vol_name) try: self.client.copy_volume_from_view(vol_name, snp_name) while not self.client.snapshot_copy_task_completed(vol_name): time.sleep(2) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_view(snp_name) self._delete_volume(vol_name) else: self.client.delete_snapshot_view(snp_name) if sdas_active: vol_params['sdas'] = True self._active_sdas(vol_name, vol_size, vol_params) lun_uuid = self.client.get_lun_uuid(vol_name) return {'provider_location': 'macrosan uuid:%s' % lun_uuid} def _active_sdas(self, name, size, params, owner=None, pool=None): rmt_client = self.sdas_client rmt_name = name + '-rmt' owner = self._get_owner() if owner is None else owner pool = self.pool if pool is None else pool res_size = int(max(int(size) * self.snapshot_resource_ratio, 1)) try: raids = self.client.get_raid_list_to_create_lun(pool, res_size) self.client.setup_snapshot_resource(name, res_size, raids) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_lun(name) try: raids = [] if params['lun_mode'] != 'thin': raids = rmt_client.get_raid_list_to_create_lun( pool, size) rmt_client.create_lun(rmt_name, owner, pool, raids, params['lun_mode'], size, self.lun_params) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) try: raids = rmt_client.get_raid_list_to_create_lun(pool, res_size) rmt_client.setup_snapshot_resource(rmt_name, res_size, raids) except Exception: with ignored(Exception): rmt_client.delete_lun(rmt_name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) try: node_id = rmt_client.get_nodeid() if node_id == ""0"": self.client.create_dalun_out_cluster(name, rmt_name) else: self.client.create_dalun_in_cluster(name, rmt_name, node_id) except Exception: with ignored(Exception): rmt_client.delete_snapshot_resource(rmt_name) rmt_client.delete_lun(rmt_name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) @record_request_id @_timing def create_volume_from_snapshot(self, volume, snapshot): """"""Create a volume from a snapshot."""""" LOG.debug('========== create volume from snapshot.') snapshot_volume = snapshot['volume'] provider = snapshot['provider_location'] m = re.findall(r'pointid: (\d+)', provider) pointid = int(m[0]) vol_name = self._volume_name(volume) snp_name = self._snapshot_name(snapshot['id']) snp_vol_name = self._volume_name(snapshot_volume) params = self._parse_volume_params(volume) self._check_volume_params(params) return self._create_volume_from_snapshot(vol_name, volume['size'], params, snp_name, pointid, snp_vol_name, snapshot['volume_size']) def _create_cloned_volume(self, vol_name, vol_size, vol_params, src_vol_name, src_vol_size, snp_name): pointid = self._create_snapshot_with_lock(snp_name, src_vol_name, src_vol_size) try: return self._create_volume_from_snapshot(vol_name, vol_size, vol_params, snp_name, pointid, src_vol_name, src_vol_size) finally: self._delete_snapshot(snp_name, src_vol_name, pointid) @record_request_id @_timing def create_cloned_volume(self, volume, src_vref): """"""Create a clone of the specified volume."""""" LOG.debug('========== create cloned volume.') vol_name = volume['id'] src_vol_name = self._volume_name(src_vref) snapshotid =\ src_vref['id'][:12] + timeutils.utcnow().strftime('%Y%m%d%H%M%S%f') snp_name = self._snapshot_name(snapshotid) params = self._parse_volume_params(volume) self._check_volume_params(params) return self._create_cloned_volume(vol_name, volume['size'], params, src_vol_name, src_vref['size'], snp_name) def _extend_volume(self, name, moresize, params): if params['sdas']: self.client.suspend_dalun(name) raids = self.client.get_raid_list_to_create_lun(self.pool, moresize) self.client.extend_lun(name, raids, moresize) raids = self.sdas_client.get_raid_list_to_create_lun(self.pool, moresize) rmt_name = name + '-rmt' self.sdas_client.extend_lun(rmt_name, raids, moresize) self.client.resume_dalun(name) elif params['replication_enabled']: with ignored(Exception): self.client.stopscan_replication(name) with ignored(Exception): self.client.pausereplicate(name) self.client.disable_replication(name, 'promote') rmt_name = name + '-rmt' destination = self.replication_params['destination'] sp1_ipaddr = self.replica_client.get_port_ipaddr( destination['sp1']) sp2_ipaddr = self.replica_client.get_port_ipaddr( destination['sp2']) raids = self.client.get_raid_list_to_create_lun(self.pool, moresize) self.client.extend_lun(name, raids, moresize) raids = self.replica_client.get_raid_list_to_create_lun(self.pool, moresize) self.replica_client.extend_lun(rmt_name, raids, moresize) self.client.enable_replication(name, rmt_name, sp1_ipaddr, sp2_ipaddr) self.client.startscan_replication(name) else: raids = self.client.get_raid_list_to_create_lun(self.pool, moresize) self.client.extend_lun(name, raids, moresize) @_synchronized @record_request_id @_timing def extend_volume(self, volume, new_size): """"""Extend a volume."""""" LOG.debug(('========== extend volume, id: %(volume_id)s,' 'size: %(size)s.'), {'volume_id': volume['id'], 'size': new_size}) name = self._volume_name(volume) moresize = self._sizestr(new_size - int(volume['size'])) params = self._parse_volume_params(volume) self._extend_volume(name, moresize, params) def ensure_export(self, context, volume): """"""Synchronously recreates an export for a volume."""""" pass def create_export(self, context, volume, connector): """"""Export the volume."""""" pass def remove_export(self, context, volume): """"""Remove an export for a volume."""""" pass @record_request_id def get_volume_stats(self, refresh=False): """"""Get volume stats."""""" if refresh: self._update_volume_stats() return self._stats def _update_volume_stats(self): data = {} pool = {} total, free, thin_unalloced = self.client.get_pool_cap(self.pool) pool['location_info'] = self.device_uuid pool['pool_name'] = self.pool pool['total_capacity_gb'] = total pool['free_capacity_gb'] = free + thin_unalloced pool['reserved_percentage'] = self.configuration.safe_get( 'reserved_percentage') pool['max_over_subscription_ratio'] = self.configuration.safe_get( 'max_over_subscription_ratio') pool['QoS_support'] = True pool['multiattach'] = 'True' pool['lun_mode'] = ['thick', 'thin'] pool['replication_mode'] = [] if self.replica_client: pool['replication_enabled'] = 'True' pool['replication_mode'].append('async') if self.sdas_client: pool['replication_enabled'] = 'True' pool['sdas'] = 'True' pool['replication_mode'].append('sync') if len(pool['replication_mode']) == 0: del pool['replication_mode'] data['pools'] = [pool] data[""volume_backend_name""] = self.volume_backend_name data[""vendor_name""] = 'MacroSAN' data[""driver_version""] = version data[""storage_protocol""] = self.storage_protocol self._stats = data @record_request_id def update_migrated_volume(self, ctxt, volume, new_volume, original_volume_status=None): """"""Return model update for migrated volume."""""" original_name = self._volume_name(volume) cur_name = self._volume_name(new_volume) params = self._parse_volume_params(new_volume) LOG.debug(('========== update migrated volume,' 'volume: %(original_name)s, new_volume: %(cur_name)s'), {'original_name': original_name, 'cur_name': cur_name}) if self.client.lun_exists(original_name): self.client.backup_lun_name_to_rename_file(cur_name, original_name) else: try: snp_res_name = self.client.get_snapshot_resource_name(cur_name) self.client.rename_lun(cur_name, original_name) if snp_res_name: self.client.rename_lun(snp_res_name, 'SR-%s' % original_name) rmt_cur_name = cur_name + '-rmt' rmt_original_name = original_name + '-rmt' rmt_snp_res_name = None rmt_client = None if params['sdas']: rmt_client = self.sdas_client rmt_snp_res_name = rmt_client.get_snapshot_resource_name( rmt_cur_name) rmt_client.rename_lun(rmt_cur_name, rmt_original_name) elif params['replication_enabled']: rmt_client = self.replica_client rmt_snp_res_name = rmt_client.get_snapshot_resource_name( rmt_cur_name) rmt_client.rename_lun(rmt_cur_name, rmt_original_name) self.client.updatereplicate(original_name) if rmt_snp_res_name: rmt_client.rename_lun(rmt_snp_res_name, 'SR-%s' % rmt_original_name) except Exception: LOG.warning('========== failed to rename ' '%(cur_name)s to %(original_name)s', {'cur_name': cur_name, 'original_name': original_name}) name_id = new_volume['_name_id'] or new_volume['id'] return {'_name_id': name_id, 'provider_location': new_volume['provider_location']} @_synchronized @record_request_id @_timing def initialize_connection_snapshot(self, snapshot, connector, **kwargs): volume = snapshot['volume'] provider = snapshot['provider_location'] m = re.findall('pointid: (\d+)', provider) pointid = m[0] snp_name = self._snapshot_name(snapshot['id']) snp_vol_name = self._volume_name(volume) self.client.create_snapshot_view(snp_name, snp_vol_name, pointid) try: conn = self._initialize_connection_snapshot(snp_name, connector) conn['data']['volume_id'] = snapshot['id'] return conn except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_view(snp_name) def _initialize_connection_snapshot(self, snp_name, connector): raise NotImplementedError def terminate_connection_snapshot(self, snapshot, connector, **kwargs): snp_name = self._snapshot_name(snapshot['id']) self._terminate_connection_snapshot(snp_name, connector) self.client.delete_snapshot_view(snp_name) def _terminate_connection_snapshot(self, snp_name, connector): raise NotImplementedError @record_request_id def manage_existing_get_size(self, volume, external_ref): _, info, _ = self._get_existing_lun_info(external_ref) size = int(math.ceil(info['size'])) return size @_synchronized @record_request_id @_timing def manage_existing(self, volume, external_ref): vol_params = self._parse_volume_params(volume) self._check_volume_params(vol_params) if vol_params['qos-strategy']: msg = 'Not support to import qos-strategy' raise exception.VolumeBackendAPIException(data=msg) pool = volume_utils.extract_host(volume.host, 'pool') name, info, params = self._get_existing_lun_info(external_ref) if pool != info['pool']: msg = (""LUN %s does not belong to the pool: %s."" % (name, pool)) raise exception.ManageExistingInvalidReference( existing_ref=external_ref, reason=msg) if params['sdas'] and params['replication_enabled']: msg = 'LUN %s sdas and replication enabled at same time' % name raise exception.VolumeBackendAPIException(data=msg) def notequal(attr): return vol_params[attr] != params[attr] if (notequal('replication_enabled') or notequal('replication_mode') or notequal('sdas') or notequal('lun_mode')): msg = (""Volume type: %s doesn't equal to existing lun: %s"" % (vol_params, params)) raise exception.VolumeBackendAPIException(data=msg) if params['sdas']: rmt_client = self.sdas_client rmt_name = self.client.get_remote_dalun_name(name) elif params['replication_enabled']: rmt_client = self.replica_client rmt_name = self.client.get_remote_replun_name(name) snp_res_name = self.client.get_snapshot_resource_name(name) self.client.rename_lun(name, volume['id']) if snp_res_name: self.client.rename_lun(snp_res_name, 'SR-%s' % volume['id']) if params['sdas'] or params['replication_enabled']: snp_res_name = rmt_client.get_snapshot_resource_name(rmt_name) rmt_client.rename_lun(rmt_name, volume['id']+'-rmt') if params['replication_enabled']: self.client.updatereplicate(volume['id']) if snp_res_name: rmt_client.rename_lun(snp_res_name, 'SR-%s-rmt' % volume['id']) lun_uuid = self.client.get_lun_uuid(volume['id']) nvf_type = params['nvf_type'] return {'provider_location': 'macrosan uuid:%s' % lun_uuid, 'nvf_type': nvf_type} def _get_existing_lun_info(self, external_ref): name = external_ref.get('source-name') if not name: msg = 'No source-name to get existing lun' raise exception.ManageExistingInvalidReference( existing_ref=external_ref, reason=msg) info = self.client.get_lun_base_info(name) params = { 'qos-strategy': '', 'replication_enabled': False, 'replication_mode': 'async', 'sdas': False, 'lun_mode': 'thick', 'nvf_type': 'normal', } sdas = self.client.dalun_exists(name) if sdas: params['nvf_type'] = 'sdas' rep = self.client.replication_enabled(name) if rep: params['nvf_type'] = 'async_rep' params['replication_enabled'] = rep params['sdas'] = sdas params['lun_mode'] = info['lun_mode'] return name, info, params def unmanage(self, volume): pass @_synchronized @record_request_id @_timing def manage_existing_snapshot(self, snapshot, existing_ref): volume = snapshot['volume'] src_name = self._get_existing_snapname(existing_ref) pointid = self.client.get_snapshot_pointid(volume['id'], src_name) snap_name = self._snapshot_name(snapshot['id']) self.client.rename_snapshot_point(volume['id'], pointid, snap_name) return {'provider_location': 'pointid: %s' % pointid} @record_request_id def manage_existing_snapshot_get_size(self, snapshot, existing_ref): volume = snapshot['volume'] return volume['size'] def _get_existing_snapname(self, external_ref): name = external_ref.get('source-name') if not name: msg = 'No source-name to get existing snap' raise exception.ManageExistingInvalidReference( existing_ref=external_ref, reason=msg) return name def unmanage_snapshot(self, snapshot): pass def migration_valid(self, volume, host): if volume.volume_attachment: return False pool_name = host['capabilities'].get('pool_name', '') if pool_name == '': return False device_uuid = host['capabilities']['location_info'] if device_uuid != self.device_uuid: return False params = self._parse_volume_params(volume) if params['sdas'] or params['replication_enabled']: return False return True @_synchronized @record_request_id @_timing def migrate_volume(self, ctxt, volume, host): if not self.migration_valid(volume, host): return False, None size = self._sizestr(volume['size']) params = self._parse_volume_params(volume) name = str(uuid.uuid4()) src_name = self._volume_name(volume) owner = self.client.get_lun_sp(src_name) pool = host['capabilities'].get('pool_name', self.pool) self._create_volume(name, size, params, owner, pool) res_sz = int(max(int(size) * self.snapshot_resource_ratio, 1)) src_snp_res_exists = self.client.snapshot_resource_exists(src_name) snp_res_exists = self.client.snapshot_resource_exists(name) src_snp_res_ex = False snp_res_ex = False try: if not src_snp_res_exists: raids = self.client.get_raid_list_to_create_lun(self.pool, res_sz) self.client.create_snapshot_resource(src_name, raids, res_sz) src_snp_res_ex = True if not snp_res_exists: raids = self.client.get_raid_list_to_create_lun(pool, res_sz) self.client.create_snapshot_resource(name, raids, res_sz) snp_res_ex = True except Exception as e: if src_snp_res_ex: self.client.delete_snapshot_resource(src_name) if snp_res_ex: self.client.delete_snapshot_resource(name) self._delete_volume(name, params) LOG.error('Create snapshot resource failed: %s' % e) msg = '========== Migrate volume failed.' raise exception.VolumeBackendAPIException(data=msg) clone_success = False try: self.client.start_localclone_lun(src_name, name) while not self.client.localclone_completed(name): time.sleep(2) self.client.stop_localclone_lun(name) clone_success = True except exception.VolumeBackendAPIException as e: LOG.error('Start localclone lun failed: %s' % e) if not snp_res_exists: self.client.delete_snapshot_resource(name) if not src_snp_res_exists: self.client.delete_snapshot_resource(src_name) if clone_success: self._delete_volume(src_name, params) self.client.rename_lun(name, src_name) lun_uuid = self.client.get_lun_uuid(src_name) return True, {'provider_location': 'macrosan uuid:%s' % lun_uuid, 'nvf_type': params['nvf_type']} self._delete_volume(name, params) msg = '========== Migrate volume failed.' raise exception.VolumeBackendAPIException(data=msg) def force_terminate_connection(self, name, force_connected=False): it_list = self.client.get_lun_it(name) it_list = [it for it in it_list if (force_connected or not it['connected'])] if len(it_list) > 0: for it in it_list: self.client.unmap_lun_to_it(name, it['initiator'], it['port']) class MacroSANISCSIDriver(MacroSANBaseDriver, driver.ISCSIDriver): """"""ISCSI driver for MacroSAN SAN."""""" def __init__(self, *args, **kwargs): """"""Initialize the driver."""""" super(MacroSANISCSIDriver, self).__init__(*args, **kwargs) self.storage_protocol = 'iSCSI' def _do_setup(self): self.ports = self.client.get_iscsi_ports() for port in self.ports: if port['port_name'] == '' and port['ip'] != '0': self.client.create_target(port['port'], type='iscsi') if self.sdas_client: ports = self.sdas_client.get_iscsi_ports() for port in ports: if port['port_name'] == '' and port['ip'] != '0': self.sdas_client.create_target(port['port'], type='iscsi') def _get_unused_lun_id(self, wwn, dev_client, ports, sdas_client, sdas_ports): id_list = set(range(0, 511)) for p in ports: port_name = p['port_name'] tmp_list = dev_client.get_it_unused_id_list('iscsi', wwn, port_name) id_list = id_list.intersection(tmp_list) for p in sdas_ports: port_name = p['port_name'] tmp_list = sdas_client.get_it_unused_id_list('iscsi', wwn, port_name) id_list = id_list.intersection(tmp_list) return id_list.pop() def _get_iscsi_ports(self, dev_client, host): try: ha_state = dev_client.get_ha_state() root = parse(self.config_path) found = False for node in root.findall('./client_list/client'): if node.get('host') == host: found = True break if not found: default = root.find('./client_list') iscsi_sp1 = default.get('sp1') iscsi_sp2 = default.get('sp2') else: iscsi_sp1 = node.get('sp1') iscsi_sp2 = node.get('sp2') ports = [] if ha_state['sp1'] in ['single', 'double', 'idle']: ports.extend(iscsi_sp1.split(',')) if ha_state['sp2'] in ['single', 'double', 'idle']: ports.extend(iscsi_sp2.split(',')) all_ports = {p['port']: p for p in dev_client.get_iscsi_ports()} return [all_ports[p] for p in ports] except Exception as e: msg = 'Parse %s error, exception: %s' % (self.config_path, e) raise exception.VolumeBackendAPIException(data=msg) def _map_initr_tgt(self, dev_client, itl_client_name, initr, ports): targets = [i['target'] for i in ports] port_names = [i['port_name'] for i in ports] init_existence, client_existence, init_connection, tgt_connection, self.lun_id = \ dev_client.get_iscsi_client_itl(itl_client_name, initr, targets, port_names) if not client_existence: dev_client.create_client(itl_client_name) if not init_existence[initr]: dev_client.create_initiator(initr, itl_client_name, type='iscsi') if not init_connection[initr]: dev_client.map_initiator_to_client(initr, itl_client_name) for p in port_names: dev_client.map_target_to_initiator(p, initr) def _unmap_itl(self, dev_client, itl_client_name, wwns, ports, volume_name): wwn = wwns[0] for port_name in ports: node_id = dev_client.get_nodeid() if node_id == ""0"": dev_client.unmap_lun_to_it(volume_name, wwn, port_name) else: node_name = self.ubs_client.get_node_name(node_id) self.ubs_client.ubs_unmap_lun_to_it(volume_name, wwn, port_name, node_name) if not dev_client.has_initiators_mapped_any_lun(wwns, type='iscsi'): self._unmap_initr_tgt(dev_client, itl_client_name, wwn) def _map_itl(self, dev_client, wwn, ports, volume_name, hint_lun_id): lun_id = hint_lun_id exists = False for p in ports: port_name = p['port_name'] node_id = dev_client.get_nodeid() if node_id == ""0"": exists = dev_client.map_lun_to_it(volume_name, wwn, port_name, hint_lun_id) else: node_name = self.ubs_client.get_node_name(node_id) exists = self.ubs_client.ubs_map_lun_to_it(volume_name, wwn, port_name, hint_lun_id, node_name) if exists and lun_id == hint_lun_id: lun_id = self.client.get_lun_id(wwn, port_name, volume_name) return lun_id @property def _self_node_wwns(self): connector = cn.ISCSIConnector(utils.get_root_helper()) return [connector.get_initiator()] def _initialize_connection(self, name, vol_params, host, wwns): client_name = self._get_client_name(host) wwn = wwns[0] LOG.info('initialize_connection, initiator: %(wwpns)s,' 'volume name: %(volume)s.', {'wwpns': wwns, 'volume': name}) ports = self._get_iscsi_ports(self.client, host) self._map_initr_tgt(self.client, client_name, wwn, ports) if vol_params['sdas']: rmt_name = name + '-rmt' sdas_ports = self._get_iscsi_ports(self.sdas_client, host) self._map_initr_tgt(self.sdas_client, client_name, wwn, sdas_ports) lun_id = self._get_unused_lun_id(wwn, self.client, ports, self.sdas_client, sdas_ports) self._map_itl(self.sdas_client, wwn, sdas_ports, rmt_name, lun_id) lun_id = self._map_itl(self.client, wwn, ports, name, lun_id) ports = ports + sdas_ports else: lun_id = self._map_itl(self.client, wwn, ports, name, self.lun_id) properties = {'target_discovered': False, 'target_portal': '%s:3260' % ports[0]['ip'], 'target_iqn': ports[0]['target'], 'target_lun': lun_id, 'target_iqns': [p['target'] for p in ports], 'target_portals': ['%s:3260' % p['ip'] for p in ports], 'target_luns': [lun_id] * len(ports)} LOG.info('initialize_connection, iSCSI properties: %s', properties) return {'driver_volume_type': 'iscsi', 'data': properties} @_synchronized @record_request_id @_timing def initialize_connection(self, volume, connector): """"""Allow connection to connector and return connection info."""""" LOG.debug('========== initialize_connection connector: %s', connector) name = self._volume_name(volume) params = self._parse_volume_params(volume) conn = self._initialize_connection(name, params, connector['host'], [connector['initiator']]) conn['data']['volume_id'] = volume['id'] return conn def _unmap_initr_tgt(self, dev_client, itl_client_name, wwn): for p in dev_client.get_iscsi_ports(): port_name = p['port_name'] if dev_client.it_exists(wwn, port_name): dev_client.unmap_target_from_initiator(port_name, wwn) if dev_client.initiator_exists(wwn): dev_client.unmap_initiator_from_client(wwn, itl_client_name) dev_client.delete_initiator(wwn) def _terminate_connection(self, name, volume_params, host, wwns): client_name = self._get_client_name(host) ports = self._get_iscsi_ports(self.client, host) it_list = self.client.get_lun_it(name) port_names = set() for it in it_list: port_names.add(it['port']) self._unmap_itl(self.client, client_name, wwns, port_names, name) if volume_params['sdas']: rmt_name = name + '-rmt' self._unmap_itl(self.sdas_client, client_name, wwns, port_names, rmt_name) data = dict() data['ports'] = ports data['client'] = client_name return {'driver_volume_type': 'iSCSI', 'data': data} @_synchronized @record_request_id @_timing def terminate_connection(self, volume, connector, **kwargs): """"""Disallow connection from connector."""""" LOG.debug('========== terminate_connection %s', connector) name = self._volume_name(volume) conn = None if not connector: self.force_terminate_connection(name, True) else: params = self._parse_volume_params(volume) attachments = volume.volume_attachment hostnum = 0 for i in attachments: if connector['host'] == i['attached_host']: hostnum += 1 if hostnum > 1: pass else: conn = self._terminate_connection(name, params, connector['host'], [connector['initiator']]) return conn def _initialize_connection_snapshot(self, snp_name, connector): return self._initialize_connection(snp_name, None, connector['host'], [connector['initiator']]) def _terminate_connection_snapshot(self, snp_name, connector): return self._terminate_connection(snp_name, None, connector['host'], [connector['initiator']]) class MacroSANFCDriver(MacroSANBaseDriver, driver.FibreChannelDriver): """"""FC driver for MacroSAN SAN."""""" def __init__(self, *args, **kwargs): """"""Initialize the driver."""""" super(MacroSANFCDriver, self).__init__(*args, **kwargs) self.storage_protocol = 'FC' self.fcsan_lookup_service = None self.use_sp_port_nr = 1 self.keep_mapped_ports = True def _do_setup(self): self.fcsan_lookup_service = fczm_utils.create_lookup_service() ports = self.client.get_fc_ports() for port in ports: if port['port_name'] == '': self.client.create_target(port['port']) if self.sdas_client: ports = self.sdas_client.get_fc_ports() for port in ports: if port['port_name'] == '': self.sdas_client.create_target(port['port']) def _parse_config(self): super(MacroSANFCDriver, self)._parse_config() try: root = parse(self.config_path) fc_target = root.find('./fc_target') use_sp_port_nr = fc_target.get('use_sp_port_nr', 1) self.use_sp_port_nr = min(4, int(use_sp_port_nr)) self.keep_mapped_ports = ( fc_target.get('keep_mapped_ports', 'false').lower() == 'true') except Exception as e: LOG.error('Parse fc config %s error, exception: %s' % (self.config_path, e)) @property def _self_node_wwns(self): fc = linuxfc.LinuxFibreChannel(utils.get_root_helper()) return [self._format_wwn_with_colon(wwn) for wwn in fc.get_fc_wwpns()] def _strip_wwn_colon(self, wwn_str): return wwn_str.replace(':', '') def _format_wwn_with_colon(self, wwn_str): return (':'.join([wwn_str[i:i + 2] for i in range(0, len(wwn_str), 2)])).lower() def _select_fc_ports(self, ports_in_storage, ports_in_fabric): selected = [] for sp in [1, 2]: n = 0 for p in ports_in_storage: if (p['sp'] == sp and p['online'] == 1 and p['wwn'] in ports_in_fabric): selected.append({'port_name': p['port_name'], 'wwn': p['wwn']}) n += 1 if n >= self.use_sp_port_nr: break return selected def _get_initr_port_map(self, dev_client, wwns): initr_port_map = {} ports_in_storage = dev_client.get_fc_ports() if self.fcsan_lookup_service is not None: mapping = (self.fcsan_lookup_service .get_device_mapping_from_network( wwns, [p['wwn'] for p in ports_in_storage])) for fabric in mapping: wwns = mapping[fabric]['target_port_wwn_list'] mapping[fabric]['target_port_wwn_list'] = ( [self._format_wwn_with_colon(wwn) for wwn in wwns]) wwns = mapping[fabric]['initiator_port_wwn_list'] mapping[fabric]['initiator_port_wwn_list'] = ( [self._format_wwn_with_colon(wwn) for wwn in wwns]) for fabric in mapping: ports_in_fabric = mapping[fabric]['target_port_wwn_list'] selected_ports = self._select_fc_ports(ports_in_storage, ports_in_fabric) for initr in mapping[fabric]['initiator_port_wwn_list']: initr_port_map[initr] = selected_ports else: initr_port_map = {} for wwn in wwns: for port in ports_in_storage: if port['initr'] == wwn: initr_port_map[wwn] = [port] break return initr_port_map def _map_initr_tgt_do(self, dev_client, itl_client_name, initr_port_map, mapped_ports): for wwn in initr_port_map: if wwn in mapped_ports: continue if not dev_client.initiator_exists(wwn): dev_client.create_initiator(wwn, wwn) if not dev_client.is_initiator_mapped_to_client(wwn, itl_client_name): dev_client.map_initiator_to_client(wwn, itl_client_name) for p in initr_port_map[wwn]: port_name = p['port_name'] # if not dev_client.it_exists(wwn, port_name): dev_client.map_target_to_initiator(port_name, wwn) def _unmap_initr_tgt(self, dev_client, client_name, mapped_ports): for wwn in mapped_ports: for p in mapped_ports[wwn]: port_name = p['port_name'] if dev_client.it_exists(wwn, port_name): dev_client.unmap_target_from_initiator(port_name, wwn) if dev_client.initiator_exists(wwn): dev_client.unmap_initiator_from_client(wwn, client_name) dev_client.delete_initiator(wwn) def _map_initr_tgt(self, dev_client, itl_client_name, wwns): if not dev_client.client_exists(itl_client_name): dev_client.create_client(itl_client_name) initr_port_map = {} mapped_ports = dev_client.get_fc_initr_mapped_ports(wwns) has_port_not_mapped = not all(wwn in mapped_ports for wwn in wwns) if has_port_not_mapped: initr_port_map = self._get_initr_port_map(dev_client, wwns) initr_port_map.update(mapped_ports) if has_port_not_mapped: self._map_initr_tgt_do(dev_client, itl_client_name, initr_port_map, mapped_ports) return has_port_not_mapped, initr_port_map def _map_itl(self, dev_client, initr_port_map, volume_name, hint_lun_id): lun_id = hint_lun_id exists = False for wwn in initr_port_map: for p in initr_port_map[wwn]: port_name = p['port_name'] node_id = dev_client.get_nodeid() if node_id == ""0"": exists = dev_client.map_lun_to_it(volume_name, wwn, port_name, hint_lun_id) else: node_name = self.ubs_client.get_node_name(node_id) exists = self.ubs_client.ubs_map_lun_to_it(volume_name, wwn, port_name, hint_lun_id, node_name) if exists and lun_id == hint_lun_id: lun_id = dev_client.get_lun_id(wwn, port_name, volume_name) return lun_id def _get_unused_lun_id(self, dev_client, initr_port_map, sdas_client, sdas_initr_port_map): id_list = set(range(0, 511)) for wwn in initr_port_map: for p in initr_port_map[wwn]: port_name = p['port_name'] tmp_list = dev_client.get_it_unused_id_list('fc', wwn, port_name) id_list = id_list.intersection(tmp_list) for wwn in sdas_initr_port_map: for p in sdas_initr_port_map[wwn]: port_name = p['port_name'] tmp_list = sdas_client.get_it_unused_id_list('fc', wwn, port_name) id_list = id_list.intersection(tmp_list) return id_list.pop() def _initialize_connection(self, name, vol_params, host, wwns): client_name = self._get_client_name(host) LOG.info('initialize_connection, initiator: %(wwpns)s,' 'volume name: %(volume)s.', {'wwpns': wwns, 'volume': name}) has_port_not_mapped, initr_port_map = ( self._map_initr_tgt(self.client, client_name, wwns)) LOG.info('====================initr_port_map %s' % initr_port_map) if vol_params and vol_params['sdas']: rmt_name = name + '-rmt' sdas_has_port_not_mapped, sdas_initr_port_map = ( self._map_initr_tgt(self.sdas_client, client_name, wwns)) lun_id = self._get_unused_lun_id(self.client, initr_port_map, self.sdas_client, sdas_initr_port_map) LOG.info('====================sdas_initr_port_map %s' % sdas_initr_port_map) self._map_itl(self.sdas_client, sdas_initr_port_map, rmt_name, lun_id) lun_id = self._map_itl(self.client, initr_port_map, name, lun_id) for initr, ports in sdas_initr_port_map.items(): if len(ports): initr_port_map[initr].extend(ports) has_port_not_mapped = (has_port_not_mapped or sdas_has_port_not_mapped) else: lun_id = self._get_unused_lun_id(self.client, initr_port_map, None, {}) lun_id = self._map_itl(self.client, initr_port_map, name, lun_id) tgt_wwns = list(set(self._strip_wwn_colon(p['wwn']) for wwn in initr_port_map for p in initr_port_map[wwn])) properties = {'target_lun': lun_id, 'target_discovered': True, 'target_wwn': tgt_wwns} if has_port_not_mapped and self.fcsan_lookup_service is not None: initr_tgt_map = {} for initr, ports in initr_port_map.items(): initr = self._strip_wwn_colon(initr) initr_tgt_map[initr] = ( [self._strip_wwn_colon(p['wwn']) for p in ports]) properties['initiator_target_map'] = initr_tgt_map LOG.info('initialize_connection, FC properties: %s', properties) return {'driver_volume_type': 'fibre_channel', 'data': properties} @_synchronized @record_request_id @_timing def initialize_connection(self, volume, connector): """"""Allow connection to connector and return connection info."""""" LOG.debug('========== initialize_connection connector: %s', connector) name = self._volume_name(volume) params = self._parse_volume_params(volume) wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] conn = self._initialize_connection(name, params, connector['host'], wwns) conn['data']['volume_id'] = volume['id'] fczm_utils.add_fc_zone(conn) return conn def _unmap_itl(self, dev_client, name, itl_client_name, wwns): mapped_ports = dev_client.get_fc_initr_mapped_ports(wwns) if len(mapped_ports) == 0: return [], {} for wwn, ports in mapped_ports.items(): for p in ports: port_name = p['port_name'] node_id = dev_client.get_nodeid() if node_id == ""0"": dev_client.unmap_lun_to_it(name, wwn, port_name) else: node_name = self.ubs_client.get_node_name(node_id) self.ubs_client.ubs_unmap_lun_to_it(name, wwn, port_name, node_name) ports, initr_tgt_map = [], {} if (not self.keep_mapped_ports and not dev_client.has_initiators_mapped_any_lun(wwns)): mapped_ports = dev_client.get_fc_initr_mapped_ports(wwns) initr_tgt_map = {self._strip_wwn_colon(wwn): [self._strip_wwn_colon(p['wwn']) for p in mapped_ports[wwn]] for wwn in wwns} ports = list(set(self._strip_wwn_colon(p['wwn']) for ports in mapped_ports.values() for p in ports)) self._unmap_initr_tgt(dev_client, itl_client_name, mapped_ports) if self.fcsan_lookup_service is None: initr_tgt_map = {} return ports, initr_tgt_map def _terminate_connection(self, name, vol_params, host, wwns): client_name = self._get_client_name(host) ports, initr_tgt_map = self._unmap_itl(self.client, name, client_name, wwns) if vol_params and vol_params['sdas']: rmt_name = name + '-rmt' sdas_ports, sdas_initr_tgt_map = ( self._unmap_itl(self.sdas_client, rmt_name, client_name, wwns)) ports.extend(sdas_ports) for initr, tgt_wwns in sdas_initr_tgt_map.items(): if len(tgt_wwns): if initr in initr_tgt_map: initr_tgt_map[initr].extend(tgt_wwns) else: initr_tgt_map[initr] = tgt_wwns data = {} if ports: data['target_wwn'] = ports if initr_tgt_map: data['initiator_target_map'] = initr_tgt_map LOG.info('terminate_connection, data: %s', data) return {'driver_volume_type': 'fibre_channel', 'data': data} @_synchronized @record_request_id @_timing def terminate_connection(self, volume, connector, **kwargs): """"""Disallow connection from connector."""""" LOG.debug('========== terminate_connection %s', connector) name = self._volume_name(volume) conn = None if not connector: self.force_terminate_connection(name, True) conn = {'driver_volume_type': 'fibre_channel', 'data': {}} else: params = self._parse_volume_params(volume) wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] attachments = volume.volume_attachment hostnum = 0 for i in attachments: if connector['host'] == i['attached_host']: hostnum += 1 if hostnum > 1: pass else: conn = self._terminate_connection(name, params, connector['host'], wwns) fczm_utils.remove_fc_zone(conn) return conn def _initialize_connection_snapshot(self, snp_name, connector): wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] return self._initialize_connection(snp_name, None, connector['host'], wwns) def _terminate_connection_snapshot(self, snp_name, connector): wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] return self._terminate_connection(snp_name, None, connector['host'], wwns) ","# Copyright (c) 2019 MacroSAN Technologies Co., Ltd. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Volume Drivers for MacroSAN SAN."""""" from contextlib import contextmanager import math import re import socket import time import uuid from oslo_config import cfg from oslo_log import log as logging from oslo_utils import excutils from oslo_utils import strutils from oslo_utils import timeutils from cinder import context from cinder.coordination import synchronized from cinder import exception from cinder.i18n import _ from cinder import interface from cinder import utils from cinder.volume import configuration from cinder.volume import driver from cinder.volume.drivers.macrosan import config from cinder.volume.drivers.macrosan import devop_client from cinder.volume.drivers.san import san from cinder.volume import qos_specs from cinder.volume import volume_types from cinder.volume import volume_utils from cinder.zonemanager import utils as fczm_utils version = '1.0.1' lock_name = 'MacroSAN' LOG = logging.getLogger(__name__) CONF = cfg.CONF CONF.register_opts(config.macrosan_opts, group=configuration.SHARED_CONF_GROUP) @contextmanager def ignored(*exceptions): try: yield except exceptions: pass def record_request_id(fn): def _record_request_id(*vargs, **kv): ctx = context.context.get_current() devop_client.context_request_id = ctx.request_id return fn(*vargs, **kv) return _record_request_id def replication_synced(params): return (params['replication_enabled'] and params['replication_mode'] == 'sync') class MacroSANBaseDriver(driver.VolumeDriver): """"""Base driver for MacroSAN SAN."""""" CI_WIKI_NAME = 'MacroSAN Volume CI' def __init__(self, *args, **kwargs): """"""Initialize the driver."""""" super(MacroSANBaseDriver, self).__init__(*args, **kwargs) self.configuration.append_config_values(config.macrosan_opts) self.configuration.append_config_values(san.san_opts) self._stats = {} self.use_multipath = True self.owners = ['SP1', 'SP2'] self.owner_idx = 0 self.volume_backend_name = ( self.configuration.safe_get('volume_backend_name') or 'MacroSAN') self.username = self.configuration.san_login self.passwd = self.configuration.san_password self.sp1_ipaddr, self.sp2_ipaddr = ( self.configuration.san_ip.replace(' ', '').split("","")) self.login_info = self.username + self.passwd if self.configuration.macrosan_sdas_ipaddrs: self.sdas_username = self.configuration.macrosan_sdas_username self.sdas_passwd = self.configuration.macrosan_sdas_password self.sdas_sp1_ipaddr, self.sdas_sp2_ipaddr = ( self.configuration.macrosan_sdas_ipaddrs) self.sdas_sp1_ipaddr = ( self.sdas_sp1_ipaddr.replace('/', ',').replace(' ', '')) self.sdas_sp2_ipaddr = ( self.sdas_sp2_ipaddr.replace('/', ',').replace(' ', '')) self.sdas_login_info = self.sdas_username + self.sdas_passwd if self.configuration.macrosan_replication_ipaddrs: self.rep_username = ( self.configuration.macrosan_replication_username) self.rep_passwd = self.configuration.macrosan_replication_password self.rep_sp1_ipaddr, self.rep_sp2_ipaddr = ( self.configuration.macrosan_replication_ipaddrs) self.rep_sp1_ipaddr = ( self.rep_sp1_ipaddr.replace('/', ',').replace(' ', '')) self.rep_sp2_ipaddr = ( self.rep_sp2_ipaddr.replace('/', ',').replace(' ', '')) self.replica_login_info = self.rep_username + self.rep_passwd self.replication_params = { 'destination': {'sp1': self.configuration. macrosan_replication_destination_ports[0], 'sp2': self.configuration. macrosan_replication_destination_ports[1]}} self.client = None self.replica_client = None self.sdas_client = None self.storage_protocol = None self.device_uuid = None self.client_info = dict() self.lun_params = {} self.lun_mode = self.configuration.san_thin_provision if self.lun_mode: self.lun_params = ( {'extent-size': self.configuration.macrosan_thin_lun_extent_size, 'low-watermark': self.configuration.macrosan_thin_lun_low_watermark, 'high-watermark': self.configuration.macrosan_thin_lun_high_watermark}) self.pool = self.configuration.macrosan_pool self.force_unmap_itl_when_deleting = ( self.configuration.macrosan_force_unmap_itl) self.snapshot_resource_ratio = ( self.configuration.macrosan_snapshot_resource_ratio) global timing_on timing_on = self.configuration.macrosan_log_timing self.initialize_iscsi_info() def _size_str_to_int(self, size_in_g): if int(size_in_g) == 0: return 1 return int(size_in_g) def _volume_name(self, volume): try: lun_uuid = re.search(r'macrosan uuid:(.+)', volume['provider_location']).group(1) return self.client.get_lun_name(lun_uuid) except Exception: return volume['id'] def _snapshot_name(self, snapshotid): return snapshotid.replace('-', '')[:31] def initialize_iscsi_info(self): sp1_port, sp2_port = \ self.configuration.macrosan_client_default.split(';') host = socket.gethostname() self.client_info['default'] = {'client_name': host, 'sp1_port': sp1_port.replace(' ', ''), 'sp2_port': sp2_port.replace(' ', '')} client_list = self.configuration.macrosan_client if client_list: for i in client_list: client = i.strip('(').strip(')').split("";"") host, client_name, sp1_port, sp2_port = [j.strip() for j in client] self.client_info[host] = ( {'client_name': client_name, 'sp1_port': sp1_port.replace(' ', '').replace('/', ','), 'sp2_port': sp2_port.replace(' ', '').replace('/', ',')}) def _get_client_name(self, host): if host in self.client_info: return self.client_info[host]['client_name'] return self.client_info['default']['client_name'] @utils.synchronized('MacroSAN-Setup', external=True) @record_request_id def do_setup(self, context): """"""Any initialization the volume driver does while starting."""""" LOG.debug('Enter in Macrosan do_setup.') self.client = devop_client.Client(self.sp1_ipaddr, self.sp2_ipaddr, self.login_info) if self.configuration.macrosan_sdas_ipaddrs: self.sdas_client = ( devop_client.Client(self.sdas_sp1_ipaddr, self.sdas_sp2_ipaddr, self.sdas_login_info)) if self.configuration.macrosan_replication_ipaddrs: self.replica_client = ( devop_client.Client(self.rep_sp1_ipaddr, self.rep_sp2_ipaddr, self.replica_login_info)) self.device_uuid = self.client.get_device_uuid() self._do_setup() LOG.debug('MacroSAN Cinder Driver setup complete.') def _do_setup(self): pass def _get_owner(self): owner = self.owners[self.owner_idx % 2] self.owner_idx += 1 return owner def check_for_setup_error(self): """"""Check any setup error."""""" pass def _check_volume_params(self, params): if params['sdas'] and params['replication_enabled']: raise exception.VolumeBackendAPIException( data=_('sdas and replication can not be enabled at same time')) if params['sdas'] and self.sdas_client is None: raise exception.VolumeBackendAPIException( data=_('sdas is not configured, cannot use sdas')) if params['replication_enabled'] and self.replica_client is None: raise exception.VolumeBackendAPIException( data=_('replica is not configured, cannot use replication')) def get_raid_list(self, size): raids = self.client.get_raid_list(self.pool) free = sum(raid['free_cap'] for raid in raids) if size > free: raise exception.VolumeBackendAPIException(_('Pool has not enough' 'free capacity')) raids = sorted(raids, key=lambda x: x['free_cap'], reverse=True) selected = [] cap = 0 for raid in raids: if raid['free_cap']: cap += raid['free_cap'] selected.append(raid['name']) if cap >= size: break return selected def _create_volume(self, name, size, params, owner=None, pool=None): rmt_client = None if params['sdas']: rmt_client = self.sdas_client elif params['replication_enabled']: rmt_client = self.replica_client owner = self._get_owner() if owner is None else owner raids = [] pool = self.pool if pool is None else pool if not params['lun_mode']: raids = self.client.get_raid_list_to_create_lun(pool, size) self.client.create_lun(name, owner, pool, raids, params['lun_mode'], size, self.lun_params) if params['qos-strategy']: try: self.client.enable_lun_qos(name, params['qos-strategy']) except Exception: self.client.delete_lun(name) raise exception.VolumeBackendAPIException( _('Enable lun qos failed.')) if params['sdas'] or params['replication_enabled']: res_size = int(max(int(size) * self.snapshot_resource_ratio, 1)) try: raids = self.client.get_raid_list_to_create_lun(pool, res_size) self.client.setup_snapshot_resource(name, res_size, raids) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_lun(name) try: raids = [] if not params['lun_mode']: raids = rmt_client.get_raid_list_to_create_lun( pool, size) rmt_client.create_lun(name, owner, pool, raids, params['lun_mode'], size, self.lun_params) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) try: raids = rmt_client.get_raid_list_to_create_lun(pool, res_size) rmt_client.setup_snapshot_resource(name, res_size, raids) except Exception: with ignored(Exception): rmt_client.delete_lun(name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) if params['sdas'] or replication_synced(params): try: self.client.create_dalun(name) except Exception: with ignored(Exception): rmt_client.delete_snapshot_resource(name) rmt_client.delete_lun(name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) elif params['replication_mode'] == 'async': destination = self.replication_params['destination'] sp1_ipaddr = rmt_client.get_port_ipaddr(destination['sp1']) sp2_ipaddr = rmt_client.get_port_ipaddr(destination['sp2']) try: self.client.enable_replication(name, sp1_ipaddr, sp2_ipaddr) self.client.startscan_replication(name) except Exception: with ignored(Exception): rmt_client.delete_snapshot_resource(name) rmt_client.delete_lun(name) with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(name) self.client.delete_lun(name) lun_uuid = self.client.get_lun_uuid(name) return {'provider_location': 'macrosan uuid:%s' % lun_uuid} def _parse_qos_strategy(self, volume_type): qos_specs_id = volume_type.get('qos_specs_id') if qos_specs_id is None: return '' ctx = context.get_admin_context() specs = qos_specs.get_qos_specs(ctx, qos_specs_id)['specs'] return specs.pop('qos-strategy', '').strip() if specs else '' def _default_volume_params(self): params = { 'qos-strategy': '', 'replication_enabled': False, 'replication_mode': 'async', 'sdas': False, 'lun_mode': self.lun_mode } return params def _parse_volume_params(self, volume): params = self._default_volume_params() if volume.volume_type_id is None: return params ctx = context.get_admin_context() volume_type = volume_types.get_volume_type(ctx, volume.volume_type_id) params['qos-strategy'] = self._parse_qos_strategy(volume_type) specs = dict(volume_type).get('extra_specs') for k, val in specs.items(): ks = k.lower().split(':') if len(ks) == 2 and ks[0] != ""capabilities"": continue k = ks[-1] if k not in params: continue else: v = val.split()[-1] val_type = type(params[k]).__name__ if val_type == 'int': v = int(v) elif val_type == 'bool': v = strutils.bool_from_string(v) params[k] = v if params['sdas']: params['lun_mode'] = False return params @synchronized(lock_name) @record_request_id @utils.trace def create_volume(self, volume): """"""Create a volume."""""" name = volume['name'] size = self._size_str_to_int(volume['size']) params = self._parse_volume_params(volume) self._check_volume_params(params) return self._create_volume(name, size, params) def _delete_volume(self, name, params=None): if not self.client.lun_exists(name): return if params is None: params = self._default_volume_params() if self.force_unmap_itl_when_deleting: self.force_terminate_connection(name, False) if params['sdas'] or replication_synced(params): if self.client.dalun_exists(name): self.client.suspend_dalun(name) self.client.delete_dalun(name) with ignored(Exception): self.sdas_client.delete_snapshot_resource(name) self.sdas_client.delete_lun(name) self.client.delete_snapshot_resource(name) if (params['replication_enabled'] and params['replication_mode'] == 'async'): if self.client.replication_enabled(name): with ignored(Exception): self.client.stopscan_replication(name) self.client.pausereplicate(name) self.client.disable_replication(name) self.client.delete_snapshot_resource(name) self.client.delete_lun(name) try: migrated_name = self.client.get_lun_name_from_rename_file(name) if not migrated_name: return try: self.client.rename_lun(migrated_name, name) except Exception: LOG.warning('========== failed to rename %(migrated_name)s' ' to %(name)s', {'migrated_name': migrated_name, 'name': name}) except Exception: return @synchronized(lock_name) @record_request_id @utils.trace def delete_volume(self, volume): """"""Delete a volume."""""" name = self._volume_name(volume) params = self._parse_volume_params(volume) self._delete_volume(name, params) @utils.synchronized('MacroSAN-Attach-Detach', external=True) def _attach_volume(self, context, volume, properties, remote=False): return super(MacroSANBaseDriver, self)._attach_volume(context, volume, properties, remote) @utils.synchronized('MacroSAN-Attach-Detach', external=True) def _detach_volume(self, context, attach_info, volume, properties, force=False, remote=False, ignore_errors=True): return super(MacroSANBaseDriver, self)._detach_volume(context, attach_info, volume, properties, force, remote, ignore_errors) def _create_snapshot(self, snapshot_name, volume_name, volume_size): size = int(max(int(volume_size) * self.snapshot_resource_ratio, 1)) raids = self.client.get_raid_list_to_create_lun(self.pool, size) if not self.client.snapshot_resource_exists(volume_name): self.client.create_snapshot_resource(volume_name, raids, size) try: self.client.enable_snapshot_resource_autoexpand(volume_name) except exception.VolumeBackendAPIException: LOG.warning('========== Enable snapshot resource auto ' 'expand for volume: %(volume_name)s error', {'volume_name': volume_name}) if not self.client.snapshot_enabled(volume_name): try: self.client.enable_snapshot(volume_name) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_resource(volume_name) try: self.client.create_snapshot_point(volume_name, snapshot_name) pointid = self.client.get_snapshot_pointid(volume_name, snapshot_name) except exception.VolumeBackendAPIException: with ignored(Exception): self.client.disable_snapshot(volume_name) self.client.delete_snapshot_resource(volume_name) raise return int(pointid) @synchronized(lock_name) @record_request_id @utils.trace def create_snapshot(self, snapshot): """"""Create a snapshot."""""" volume = snapshot['volume'] snapshot_name = self._snapshot_name(snapshot['name']) volume_name = self._volume_name(volume) pointid = self._create_snapshot(snapshot_name, volume_name, volume['size']) return {'provider_location': 'pointid: %s' % pointid} def _delete_snapshot(self, snapshot_name, volume_name, pointid): if self.client.snapshot_point_exists(volume_name, pointid): self.client.delete_snapshot_point(volume_name, pointid) with ignored(Exception): n = self.client.get_snapshot_point_num(volume_name) if n != 0: return with ignored(Exception): self.client.disable_snapshot(volume_name) if not (self.client.dalun_exists(volume_name) or self.client.replication_enabled(volume_name)): self.client.delete_snapshot_resource(volume_name) @synchronized(lock_name) @record_request_id @utils.trace def delete_snapshot(self, snapshot): """"""Delete a snapshot."""""" volume = snapshot['volume'] provider = snapshot['provider_location'] if not provider: return m = re.findall(r'pointid: (\d+)', provider) if m is None: return snapshot_name = self._snapshot_name(snapshot['id']) volume_name = self._volume_name(volume) self._delete_snapshot(snapshot_name, volume_name, m[0]) def _initialize_connection(self, name, host, wwns): raise NotImplementedError def _terminate_connection(self, name, host, wwns): raise NotImplementedError def _create_volume_from_snapshot(self, vol_name, vol_size, vol_params, snp_name, pointid, snp_vol_name, snp_vol_size): self._create_volume(vol_name, vol_size, vol_params) try: self.client.create_snapshot_view(snp_name, snp_vol_name, pointid) except Exception: self._delete_volume(vol_name) raise exception.VolumeBackendAPIException( _('Create snapshot view failed.')) try: self.client.copy_volume_from_view(vol_name, snp_name) while not self.client.snapshot_copy_task_completed(vol_name): time.sleep(2) except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_view(snp_name) self._delete_volume(vol_name) else: self.client.delete_snapshot_view(snp_name) lun_uuid = self.client.get_lun_uuid(vol_name) return {'provider_location': 'macrosan uuid:%s' % lun_uuid} @synchronized(lock_name) @record_request_id @utils.trace def create_volume_from_snapshot(self, volume, snapshot): """"""Create a volume from a snapshot."""""" snapshot_volume = snapshot['volume'] provider = snapshot['provider_location'] m = re.findall(r'pointid: (\d+)', provider) pointid = int(m[0]) vol_name = self._volume_name(volume) snp_name = self._snapshot_name(snapshot['id']) snp_vol_name = self._volume_name(snapshot_volume) params = self._parse_volume_params(volume) self._check_volume_params(params) return self._create_volume_from_snapshot(vol_name, volume['size'], params, snp_name, pointid, snp_vol_name, snapshot['volume_size']) def _create_cloned_volume(self, vol_name, vol_size, vol_params, src_vol_name, src_vol_size, snp_name): pointid = self._create_snapshot(snp_name, src_vol_name, src_vol_size) try: return self._create_volume_from_snapshot(vol_name, vol_size, vol_params, snp_name, pointid, src_vol_name, src_vol_size) finally: self._delete_snapshot(snp_name, src_vol_name, pointid) @record_request_id @utils.trace def create_cloned_volume(self, volume, src_vref): """"""Create a clone of the specified volume."""""" vol_name = volume['id'] src_vol_name = self._volume_name(src_vref) snapshotid =\ src_vref['id'][:12] + timeutils.utcnow().strftime('%Y%m%d%H%M%S%f') snp_name = self._snapshot_name(snapshotid) params = self._parse_volume_params(volume) self._check_volume_params(params) return self._create_cloned_volume(vol_name, volume['size'], params, src_vol_name, src_vref['size'], snp_name) def _extend_volume(self, name, moresize, params): if params['replication_enabled']: raise Exception( 'Volume %s has replication enabled, cannot extend' % name) if params['sdas']: self.client.suspend_dalun(name) raids = self.client.get_raid_list_to_create_lun(self.pool, moresize) self.client.extend_lun(name, raids, moresize) raids = self.sdas_client.get_raid_list_to_create_lun(self.pool, moresize) self.sdas_client.extend_lun(name, raids, moresize) self.client.resume_dalun(name) else: raids = self.client.get_raid_list_to_create_lun(self.pool, moresize) self.client.extend_lun(name, raids, moresize) @synchronized(lock_name) @record_request_id @utils.trace def extend_volume(self, volume, new_size): """"""Extend a volume."""""" name = self._volume_name(volume) moresize = self._size_str_to_int(new_size - int(volume['size'])) params = self._parse_volume_params(volume) self._extend_volume(name, moresize, params) def ensure_export(self, context, volume): """"""Synchronously recreates an export for a volume."""""" pass def create_export(self, context, volume, connector): """"""Export the volume."""""" pass def remove_export(self, context, volume): """"""Remove an export for a volume."""""" pass @record_request_id def get_volume_stats(self, refresh=False): """"""Get volume stats."""""" if refresh: self._update_volume_stats() return self._stats def _update_volume_stats(self): data = {} pool = {} total, free, thin_unalloced = self.client.get_pool_cap(self.pool) pool['location_info'] = self.device_uuid pool['pool_name'] = self.pool pool['total_capacity_gb'] = total pool['free_capacity_gb'] = free + thin_unalloced pool['reserved_percentage'] = self.configuration.safe_get( 'reserved_percentage') pool['max_over_subscription_ratio'] = self.configuration.safe_get( 'max_over_subscription_ratio') pool['QoS_support'] = True pool['multiattach'] = True pool['lun_mode'] = True pool['replication_mode'] = [] if self.replica_client: pool['replication_enabled'] = 'True' pool['replication_mode'].append('async') if self.sdas_client: pool['replication_enabled'] = 'True' pool['sdas'] = 'True' pool['replication_mode'].append('sync') if len(pool['replication_mode']) == 0: del pool['replication_mode'] data['pools'] = [pool] data[""volume_backend_name""] = self.volume_backend_name data[""vendor_name""] = 'MacroSAN' data[""driver_version""] = version data[""storage_protocol""] = self.storage_protocol self._stats = data @record_request_id @utils.trace def update_migrated_volume(self, ctxt, volume, new_volume, original_volume_status=None): """"""Return model update for migrated volume."""""" original_name = self._volume_name(volume) cur_name = self._volume_name(new_volume) if self.client.lun_exists(original_name): self.client.backup_lun_name_to_rename_file(cur_name, original_name) else: if original_volume_status == 'available': try: self.client.rename_lun(cur_name, original_name) except Exception: LOG.warning('========== failed to rename ' '%(cur_name)s to %(original_name)s', {'cur_name': cur_name, 'original_name': original_name}) name_id = new_volume['_name_id'] or new_volume['id'] return {'_name_id': name_id, 'provider_location': new_volume['provider_location']} @synchronized(lock_name) @record_request_id @utils.trace def initialize_connection_snapshot(self, snapshot, connector, **kwargs): volume = snapshot['volume'] provider = snapshot['provider_location'] m = re.findall(r'pointid: (\d+)', provider) pointid = m[0] snp_name = self._snapshot_name(snapshot['id']) snp_vol_name = self._volume_name(volume) self.client.create_snapshot_view(snp_name, snp_vol_name, pointid) try: conn = self._initialize_connection_snapshot(snp_name, connector) conn['data']['volume_id'] = snapshot['id'] return conn except Exception: with excutils.save_and_reraise_exception(): self.client.delete_snapshot_view(snp_name) def _initialize_connection_snapshot(self, snp_name, connector): raise NotImplementedError def terminate_connection_snapshot(self, snapshot, connector, **kwargs): snp_name = self._snapshot_name(snapshot['id']) self._terminate_connection_snapshot(snp_name, connector) self.client.delete_snapshot_view(snp_name) def _terminate_connection_snapshot(self, snp_name, connector): raise NotImplementedError @record_request_id def manage_existing_get_size(self, volume, external_ref): __, info, __ = self._get_existing_lun_info(external_ref) size = int(math.ceil(info['size'])) return size @synchronized(lock_name) @record_request_id @utils.trace def manage_existing(self, volume, external_ref): vol_params = self._parse_volume_params(volume) self._check_volume_params(vol_params) if vol_params['qos-strategy']: raise exception.VolumeBackendAPIException( data=_('Import qos-strategy not supported')) pool = volume_utils.extract_host(volume.host, 'pool') name, info, params = self._get_existing_lun_info(external_ref) if pool != info['pool']: msg = _(""LUN %(name)s does not belong to the pool: "" ""%(pool)s.""), {'name': name, 'pool': pool} raise exception.ManageExistingInvalidReference( existing_ref=external_ref, reason=msg) if params['sdas'] and params['replication_enabled']: msg = _('LUN %(name)s sdas and replication ' 'enabled at same time'), {'name': name} raise exception.VolumeBackendAPIException(data=msg) if replication_synced(vol_params) and params['sdas']: params.update({'sdas': False, 'replication_mode': 'sync', 'replication_enabled': True}) def notequal(attr): return vol_params[attr] != params[attr] if (notequal('replication_enabled') or notequal('replication_mode') or notequal('sdas') or notequal('lun_mode')): msg = _(""Volume type: %(vol_params)s doesn't equal "" ""to existing lun: "" ""%(params)s""), {'vol_params': vol_params, 'params': params} raise exception.VolumeBackendAPIException(data=msg) rmt_client = None if params['sdas']: rmt_client = self.sdas_client elif params['replication_enabled']: rmt_client = self.replica_client snp_res_name = self.client.get_snapshot_resource_name(name) self.client.rename_lun(name, volume['name']) if snp_res_name: self.client.rename_lun(snp_res_name, 'SR-%s' % volume['id']) if params['sdas'] or params['replication_enabled']: snp_res_name = rmt_client.get_snapshot_resource_name(name) rmt_client.rename_lun(name, volume['name']) if snp_res_name: rmt_client.rename_lun(snp_res_name, 'SR-%s' % volume['id']) lun_uuid = self.client.get_lun_uuid(volume['name']) return {'provider_location': 'macrosan uuid:%s' % lun_uuid} def _get_existing_lun_info(self, external_ref): name = external_ref.get('source-name') if not name: raise exception.ManageExistingInvalidReference( existing_ref=external_ref, reason=_('No source-name to get existing lun')) info = self.client.get_lun_base_info(name) params = { 'qos-strategy': '', 'replication_enabled': False, 'replication_mode': 'async', 'sdas': False, 'lun_mode': False } sdas = self.client.dalun_exists(name) rep = self.client.replication_enabled(name) params['replication_enabled'] = rep params['sdas'] = sdas if info['lun_mode'] == 'thin': info['lun_mode'] = True else: info['lun_mode'] = False params['lun_mode'] = info['lun_mode'] return name, info, params def unmanage(self, volume): pass @synchronized(lock_name) @record_request_id @utils.trace def manage_existing_snapshot(self, snapshot, existing_ref): volume = snapshot['volume'] src_name = self._get_existing_snapname(existing_ref).lstrip('_') src_name = self._snapshot_name(src_name) pointid = self.client.get_snapshot_pointid(volume['name'], src_name) snap_name = self._snapshot_name(snapshot['id']) self.client.rename_snapshot_point(volume['name'], pointid, snap_name) return {'provider_location': 'pointid: %s' % pointid} @record_request_id def manage_existing_snapshot_get_size(self, snapshot, existing_ref): volume = snapshot['volume'] return volume['size'] def _get_existing_snapname(self, external_ref): name = external_ref.get('source-name') if not name: raise exception.ManageExistingInvalidReference( existing_ref=external_ref, reason=_('No source-name to get existing snap')) return name def unmanage_snapshot(self, snapshot): pass def migration_valid(self, volume, host): if volume.volume_attachment: return False pool_name = host['capabilities'].get('pool_name', '') if pool_name == '': return False device_uuid = host['capabilities']['location_info'] if device_uuid != self.device_uuid: return False params = self._parse_volume_params(volume) if params['sdas'] or params['replication_enabled']: return False return True @synchronized(lock_name) @record_request_id @utils.trace def migrate_volume(self, ctxt, volume, host): if not self.migration_valid(volume, host): return False, None size = self._size_str_to_int(volume['size']) params = self._parse_volume_params(volume) name = str(uuid.uuid4()) src_name = self._volume_name(volume) owner = self.client.get_lun_sp(src_name) pool = host['capabilities'].get('pool_name', self.pool) LOG.info('Migrating volume: %(volume)s, ' 'host: %(host)s, ' 'backend: %(volume_backend_name)s', {'volume': src_name, 'host': host, 'volume_backend_name': self.volume_backend_name}) self._create_volume(name, size, params, owner, pool) res_sz = int(max(int(size) * self.snapshot_resource_ratio, 1)) src_snp_res_exists = self.client.snapshot_resource_exists(src_name) if not src_snp_res_exists: raids = self.client.get_raid_list_to_create_lun(self.pool, res_sz) self.client.create_snapshot_resource(src_name, raids, res_sz) snp_res_exists = self.client.snapshot_resource_exists(name) if not snp_res_exists: raids = self.client.get_raid_list_to_create_lun(pool, res_sz) self.client.create_snapshot_resource(name, raids, res_sz) self.client.start_localclone_lun(src_name, name) while not self.client.localclone_completed(name): time.sleep(2) self.client.stop_localclone_lun(name) if not snp_res_exists: self.client.delete_snapshot_resource(name) if not src_snp_res_exists: self.client.delete_snapshot_resource(src_name) self._delete_volume(src_name, params) self.client.rename_lun(name, src_name) lun_uuid = self.client.get_lun_uuid(src_name) return True, {'provider_location': 'macrosan uuid:%s' % lun_uuid} def force_terminate_connection(self, name, force_connected=False): it_list = self.client.get_lun_it(name) it_list = [it for it in it_list if (force_connected or not it['connected'])] if len(it_list) > 0: for it in it_list: self.client.unmap_lun_to_it(name, it['initiator'], it['port']) @interface.volumedriver class MacroSANISCSIDriver(MacroSANBaseDriver, driver.ISCSIDriver): """"""ISCSI driver for MacroSan storage arrays. Version history: .. code-block:: none 1.0.0 - Initial driver 1.0.1 - Adjust some log level and text prompts; Remove some useless functions; Add Cinder trace decorator. #1837920 """""" VERSION = ""1.0.1"" def __init__(self, *args, **kwargs): """"""Initialize the driver."""""" super(MacroSANISCSIDriver, self).__init__(*args, **kwargs) self.storage_protocol = 'iSCSI' def _do_setup(self): ports = self.client.get_iscsi_ports() for port in ports: if port['port_name'] == '' and port['ip'] != '0': self.client.create_target(port['port'], type='iscsi') if self.sdas_client: ports = self.sdas_client.get_iscsi_ports() for port in ports: if port['port_name'] == '' and port['ip'] != '0': self.sdas_client.create_target(port['port'], type='iscsi') def _get_iscsi_ports(self, dev_client, host): ha_state = dev_client.get_ha_state() if host in self.client_info: iscsi_sp1 = self.client_info[host]['sp1_port'] iscsi_sp2 = self.client_info[host]['sp2_port'] else: iscsi_sp1 = self.client_info['default']['sp1_port'] iscsi_sp2 = self.client_info['default']['sp2_port'] ports = [] if ha_state['sp1'] in ['single', 'double', 'idle']: ports.extend(iscsi_sp1.split(',')) if ha_state['sp2'] in ['single', 'double', 'idle']: ports.extend(iscsi_sp2.split(',')) all_ports = {p['port']: p for p in dev_client.get_iscsi_ports()} return [all_ports[p] for p in ports] def _map_initr_tgt(self, dev_client, itl_client_name, initr, ports): if not dev_client.get_client(itl_client_name): dev_client.create_client(itl_client_name) if not dev_client.initiator_exists(initr): dev_client.create_initiator(initr, itl_client_name, type='iscsi') if not dev_client.is_initiator_mapped_to_client(initr, itl_client_name): dev_client.map_initiator_to_client(initr, itl_client_name) for p in ports: port_name = p['port_name'] dev_client.map_target_to_initiator(port_name, initr) def _unmap_itl(self, dev_client, itl_client_name, wwns, ports, volume_name): wwn = wwns[0] for p in ports: port_name = p['port_name'] dev_client.unmap_lun_to_it(volume_name, wwn, port_name) def _map_itl(self, dev_client, wwn, ports, volume_name, hint_lun_id): lun_id = hint_lun_id exists = False for p in ports: port_name = p['port_name'] exists = dev_client.map_lun_to_it(volume_name, wwn, port_name, hint_lun_id) if exists and lun_id == hint_lun_id: lun_id = self.client.get_lun_id(wwn, port_name, volume_name) return lun_id def _get_unused_lun_id(self, wwn, dev_client, ports, sdas_client, sdas_ports): id_list = set(range(0, 511)) for p in ports: port_name = p['port_name'] tmp_list = dev_client.get_it_unused_id_list('iscsi', wwn, port_name) id_list = id_list.intersection(tmp_list) for p in sdas_ports: port_name = p['port_name'] tmp_list = sdas_client.get_it_unused_id_list('iscsi', wwn, port_name) id_list = id_list.intersection(tmp_list) return id_list.pop() def _initialize_connection(self, name, vol_params, host, wwns): client_name = self._get_client_name(host) wwn = wwns[0] LOG.debug('initialize_connection, initiator: %(wwpns)s,' 'volume name: %(volume)s.', {'wwpns': wwns, 'volume': name}) ports = self._get_iscsi_ports(self.client, host) self._map_initr_tgt(self.client, client_name, wwn, ports) if vol_params['sdas']: sdas_ports = self._get_iscsi_ports(self.sdas_client, host) self._map_initr_tgt(self.sdas_client, client_name, wwn, sdas_ports) lun_id = self._get_unused_lun_id(wwn, self.client, ports, self.sdas_client, sdas_ports) self._map_itl(self.sdas_client, wwn, sdas_ports, name, lun_id) lun_id = self._map_itl(self.client, wwn, ports, name, lun_id) ports = ports + sdas_ports else: lun_id = self._get_unused_lun_id(wwn, self.client, ports, None, {}) lun_id = self._map_itl(self.client, wwn, ports, name, lun_id) properties = {'target_discovered': False, 'target_portal': '%s:3260' % ports[0]['ip'], 'target_iqn': ports[0]['target'], 'target_lun': lun_id, 'target_iqns': [p['target'] for p in ports], 'target_portals': ['%s:3260' % p['ip'] for p in ports], 'target_luns': [lun_id] * len(ports)} LOG.info('initialize_connection, iSCSI properties: %(properties)s', {'properties': properties}) return {'driver_volume_type': 'iscsi', 'data': properties} @synchronized(lock_name) @record_request_id @utils.trace def initialize_connection(self, volume, connector): """"""Allow connection to connector and return connection info."""""" name = self._volume_name(volume) params = self._parse_volume_params(volume) conn = self._initialize_connection(name, params, connector['host'], [connector['initiator']]) conn['data']['volume_id'] = volume['id'] return conn def _unmap_initr_tgt(self, dev_client, itl_client_name, wwn): for p in dev_client.get_iscsi_ports(): port_name = p['port_name'] if dev_client.it_exists(wwn, port_name): dev_client.unmap_target_from_initiator(port_name, wwn) if dev_client.initiator_exists(wwn): dev_client.unmap_initiator_from_client(wwn, itl_client_name) dev_client.delete_initiator(wwn) def _terminate_connection(self, name, volume_params, host, wwns): client_name = self._get_client_name(host) ports = self._get_iscsi_ports(self.client, host) self._unmap_itl(self.client, client_name, wwns, ports, name) if volume_params['sdas']: self._unmap_itl(self.sdas_client, client_name, wwns, ports, name) data = dict() data['ports'] = ports data['client'] = client_name return {'driver_volume_type': 'iSCSI', 'data': data} @synchronized(lock_name) @record_request_id @utils.trace def terminate_connection(self, volume, connector, **kwargs): """"""Disallow connection from connector."""""" name = self._volume_name(volume) conn = None if not connector: self.force_terminate_connection(name, True) else: params = self._parse_volume_params(volume) conn = self._terminate_connection(name, params, connector['host'], [connector['initiator']]) return conn def _initialize_connection_snapshot(self, snp_name, connector): return self._initialize_connection(snp_name, None, connector['host'], [connector['initiator']]) def _terminate_connection_snapshot(self, snp_name, connector): return self._terminate_connection(snp_name, None, connector['host'], [connector['initiator']]) @interface.volumedriver class MacroSANFCDriver(MacroSANBaseDriver, driver.FibreChannelDriver): """"""FC driver for MacroSan storage arrays. Version history: .. code-block:: none 1.0.0 - Initial driver 1.0.1 - Adjust some log level and text prompts; Remove some useless functions; Add Cinder trace decorator. #1837920 """""" VERSION = ""1.0.1"" def __init__(self, *args, **kwargs): """"""Initialize the driver."""""" super(MacroSANFCDriver, self).__init__(*args, **kwargs) self.storage_protocol = 'FC' self.fcsan_lookup_service = None self.use_sp_port_nr = self.configuration.macrosan_fc_use_sp_port_nr self.keep_mapped_ports = \ self.configuration.macrosan_fc_keep_mapped_ports def _do_setup(self): self.fcsan_lookup_service = fczm_utils.create_lookup_service() ports = self.client.get_fc_ports() for port in ports: if port['port_name'] == '': self.client.create_target(port['port']) if self.sdas_client: ports = self.sdas_client.get_fc_ports() for port in ports: if port['port_name'] == '': self.sdas_client.create_target(port['port']) def _strip_wwn_colon(self, wwn_str): return wwn_str.replace(':', '') def _format_wwn_with_colon(self, wwn_str): wwn_str = wwn_str.replace("":"", """") return (':'.join([wwn_str[i:i + 2] for i in range(0, len(wwn_str), 2)])).lower() def _select_fc_ports(self, ports_in_storage, ports_in_fabric): selected = [] for sp in [1, 2]: n = 0 for p in ports_in_storage: if (p['sp'] == sp and p['online'] == 1 and p['wwn'] in ports_in_fabric): selected.append({'port_name': p['port_name'], 'wwn': p['wwn']}) n += 1 if n >= self.use_sp_port_nr: break return selected def _get_initr_port_map(self, dev_client, wwns): initr_port_map = {} ports_in_storage = dev_client.get_fc_ports() if self.fcsan_lookup_service is not None: mapping = (self.fcsan_lookup_service .get_device_mapping_from_network( wwns, [p['wwn'] for p in ports_in_storage])) for fabric in mapping: wwns = mapping[fabric]['target_port_wwn_list'] mapping[fabric]['target_port_wwn_list'] = ( [self._format_wwn_with_colon(wwn) for wwn in wwns]) wwns = mapping[fabric]['initiator_port_wwn_list'] mapping[fabric]['initiator_port_wwn_list'] = ( [self._format_wwn_with_colon(wwn) for wwn in wwns]) for fabric in mapping: ports_in_fabric = mapping[fabric]['target_port_wwn_list'] selected_ports = self._select_fc_ports(ports_in_storage, ports_in_fabric) for initr in mapping[fabric]['initiator_port_wwn_list']: initr_port_map[initr] = selected_ports else: initr_port_map = {} for wwn in wwns: for port in ports_in_storage: if port['initr'] == wwn: initr_port_map[wwn] = [port] break return initr_port_map def _map_initr_tgt_do(self, dev_client, itl_client_name, initr_port_map, mapped_ports): for wwn in initr_port_map: if wwn in mapped_ports: continue if not dev_client.initiator_exists(wwn): dev_client.create_initiator(wwn, wwn) if not dev_client.is_initiator_mapped_to_client(wwn, itl_client_name): dev_client.map_initiator_to_client(wwn, itl_client_name) for p in initr_port_map[wwn]: port_name = p['port_name'] dev_client.map_target_to_initiator(port_name, wwn) def _unmap_initr_tgt(self, dev_client, client_name, mapped_ports): for wwn in mapped_ports: for p in mapped_ports[wwn]: port_name = p['port_name'] if dev_client.it_exists(wwn, port_name): dev_client.unmap_target_from_initiator(port_name, wwn) if dev_client.initiator_exists(wwn): dev_client.unmap_initiator_from_client(wwn, client_name) dev_client.delete_initiator(wwn) def _map_initr_tgt(self, dev_client, itl_client_name, wwns): if not dev_client.get_client(itl_client_name): dev_client.create_client(itl_client_name) initr_port_map = {} mapped_ports = dev_client.get_fc_initr_mapped_ports(wwns) has_port_not_mapped = not all(wwn in mapped_ports for wwn in wwns) if has_port_not_mapped: initr_port_map = self._get_initr_port_map(dev_client, wwns) initr_port_map.update(mapped_ports) if has_port_not_mapped: self._map_initr_tgt_do(dev_client, itl_client_name, initr_port_map, mapped_ports) return has_port_not_mapped, initr_port_map def _map_itl(self, dev_client, initr_port_map, volume_name, hint_lun_id): lun_id = hint_lun_id exists = False for wwn in initr_port_map: for p in initr_port_map[wwn]: port_name = p['port_name'] exists = dev_client.map_lun_to_it(volume_name, wwn, port_name, lun_id) if exists and lun_id == hint_lun_id: lun_id = dev_client.get_lun_id(wwn, port_name, volume_name) return lun_id def _get_unused_lun_id(self, dev_client, initr_port_map, sdas_client, sdas_initr_port_map): id_list = set(range(0, 511)) for wwn in initr_port_map: for p in initr_port_map[wwn]: port_name = p['port_name'] tmp_list = dev_client.get_it_unused_id_list('fc', wwn, port_name) id_list = id_list.intersection(tmp_list) for wwn in sdas_initr_port_map: for p in sdas_initr_port_map[wwn]: port_name = p['port_name'] tmp_list = sdas_client.get_it_unused_id_list('fc', wwn, port_name) id_list = id_list.intersection(tmp_list) return id_list.pop() def _initialize_connection(self, name, vol_params, host, wwns): client_name = self._get_client_name(host) LOG.info('initialize_connection, initiator: %(wwpns)s, ' 'volume name: %(volume)s.', {'wwpns': wwns, 'volume': name}) has_port_not_mapped, initr_port_map = ( self._map_initr_tgt(self.client, client_name, wwns)) LOG.debug('initr_port_map: %(initr_port_map)s', {'initr_port_map': initr_port_map}) if vol_params and vol_params['sdas']: sdas_has_port_not_mapped, sdas_initr_port_map = ( self._map_initr_tgt(self.sdas_client, client_name, wwns)) lun_id = self._get_unused_lun_id(self.client, initr_port_map, self.sdas_client, sdas_initr_port_map) LOG.debug('sdas_initr_port_map: %(sdas_initr_port_map)s', {'sdas_initr_port_map': sdas_initr_port_map}) self._map_itl(self.sdas_client, sdas_initr_port_map, name, lun_id) lun_id = self._map_itl(self.client, initr_port_map, name, lun_id) for initr, ports in sdas_initr_port_map.items(): if len(ports): initr_port_map[initr].extend(ports) has_port_not_mapped = (has_port_not_mapped or sdas_has_port_not_mapped) else: lun_id = self._get_unused_lun_id(self.client, initr_port_map, None, {}) lun_id = self._map_itl(self.client, initr_port_map, name, lun_id) tgt_wwns = list(set(self._strip_wwn_colon(p['wwn']) for wwn in initr_port_map for p in initr_port_map[wwn])) tgt_wwns.sort() properties = {'target_lun': lun_id, 'target_discovered': True, 'target_wwn': tgt_wwns} if has_port_not_mapped and self.fcsan_lookup_service is not None: initr_tgt_map = {} for initr, ports in initr_port_map.items(): initr = self._strip_wwn_colon(initr) initr_tgt_map[initr] = ( [self._strip_wwn_colon(p['wwn']) for p in ports]) properties['initiator_target_map'] = initr_tgt_map LOG.info('initialize_connection, FC properties: %(properties)s', {'properties': properties}) return {'driver_volume_type': 'fibre_channel', 'data': properties} @synchronized(lock_name) @record_request_id @utils.trace def initialize_connection(self, volume, connector): """"""Allow connection to connector and return connection info."""""" name = self._volume_name(volume) params = self._parse_volume_params(volume) wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwnns']] conn = self._initialize_connection(name, params, connector['host'], wwns) conn['data']['volume_id'] = volume['id'] fczm_utils.add_fc_zone(conn) return conn def _unmap_itl(self, dev_client, name, itl_client_name, wwns): mapped_ports = dev_client.get_fc_initr_mapped_ports(wwns) if len(mapped_ports) == 0: return [], {} for wwn, ports in mapped_ports.items(): for p in ports: port_name = p['port_name'] dev_client.unmap_lun_to_it(name, wwn, port_name) ports, initr_tgt_map = [], {} if (not self.keep_mapped_ports and not dev_client.has_initiators_mapped_any_lun(wwns)): mapped_ports = dev_client.get_fc_initr_mapped_ports(wwns) initr_tgt_map = {self._strip_wwn_colon(wwn): [self._strip_wwn_colon(p['wwn']) for p in mapped_ports[wwn]] for wwn in wwns} ports = list(set(self._strip_wwn_colon(p['wwn']) for ports in mapped_ports.values() for p in ports)) self._unmap_initr_tgt(dev_client, itl_client_name, mapped_ports) if self.fcsan_lookup_service is None: initr_tgt_map = {} return ports, initr_tgt_map def _terminate_connection(self, name, vol_params, host, wwns): client_name = self._get_client_name(host) ports, initr_tgt_map = self._unmap_itl(self.client, name, client_name, wwns) if vol_params and vol_params['sdas']: sdas_ports, sdas_initr_tgt_map = ( self._unmap_itl(self.sdas_client, name, client_name, wwns)) ports.extend(sdas_ports) for initr, tgt_wwns in sdas_initr_tgt_map.items(): if len(tgt_wwns): initr_tgt_map[initr].extend(tgt_wwns) data = {} if ports: data['target_wwn'] = ports if initr_tgt_map: data['initiator_target_map'] = initr_tgt_map LOG.info('terminate_connection, data: %(data)s', {'data': data}) return {'driver_volume_type': 'fibre_channel', 'data': data} @synchronized(lock_name) @record_request_id @utils.trace def terminate_connection(self, volume, connector, **kwargs): """"""Disallow connection from connector."""""" name = self._volume_name(volume) conn = None if not connector: self.force_terminate_connection(name, True) conn = {'driver_volume_type': 'fibre_channel', 'data': {}} else: params = self._parse_volume_params(volume) wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] attachments = volume.volume_attachment hostnum = 0 for i in attachments: if connector['host'] == i['attached_host']: hostnum += 1 if hostnum > 1: pass else: conn = self._terminate_connection(name, params, connector['host'], wwns) fczm_utils.remove_fc_zone(conn) return conn def _initialize_connection_snapshot(self, snp_name, connector): wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] return self._initialize_connection(snp_name, None, connector['host'], wwns) def _terminate_connection_snapshot(self, snp_name, connector): wwns = [self._format_wwn_with_colon(wwns) for wwns in connector['wwpns']] return self._terminate_connection(snp_name, None, connector['host'], wwns)",2744,2221
openstack%2Fnova~stable%2Frocky~I70e06c607045a1c0842f13069e51fef438012a9c,openstack/nova,stable/rocky,I70e06c607045a1c0842f13069e51fef438012a9c,Block deleting compute services with in-progress migrations,MERGED,2019-12-09 23:35:37.000000000,2020-01-16 21:02:35.000000000,2020-01-16 19:57:00.000000000,"[{'_account_id': 4690}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-09 23:35:37.000000000', 'files': ['nova/tests/functional/wsgi/test_services.py', 'nova/tests/functional/integrated_helpers.py', 'releasenotes/notes/bug-1852610-service-delete-with-migrations-ca0565fc0b503519.yaml', 'api-ref/source/os-services.inc', 'nova/api/openstack/compute/services.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/30a635068512be558acf0f9c83185dc1aaad560f', 'message': 'Block deleting compute services with in-progress migrations\n\nThis builds on I0bd63b655ad3d3d39af8d15c781ce0a45efc8e3a\nwhich made DELETE /os-services/{service_id} fail with a 409\nresponse if the host has instances on it. This change checks\nfor in-progress migrations involving the nodes on the host,\neither as the source or destination nodes, and returns a 409\nerror response if any are found.\n\nFailling to do this can lead to orphaned resource providers\nin placement and also failing to properly confirm or revert\na pending resize or cold migration.\n\nA release note is included for the (justified) behavior\nchange in the API. A new microversion should not be required\nfor this since admins should not have to opt out of broken\nbehavior.\n\nConflicts:\n      nova/tests/functional/integrated_helpers.py\n\nNOTE(mriedem): The conflict is due to not having change\nIe991d4b53e9bb5e7ec26da99219178ab7695abf6 in Rocky.\n\nChange-Id: I70e06c607045a1c0842f13069e51fef438012a9c\nCloses-Bug: #1852610\n(cherry picked from commit 92fed026103b47fa2a76ea09204a4ba24c21e191)\n(cherry picked from commit a9650b3cbfc674e283964090fb64ac6297be5b78)\n(cherry picked from commit a0290858b717b4cefd0d6fc17acc2b143ab12ac4)\n'}]",0,698113,30a635068512be558acf0f9c83185dc1aaad560f,31,6,1,6873,,,0,"Block deleting compute services with in-progress migrations

This builds on I0bd63b655ad3d3d39af8d15c781ce0a45efc8e3a
which made DELETE /os-services/{service_id} fail with a 409
response if the host has instances on it. This change checks
for in-progress migrations involving the nodes on the host,
either as the source or destination nodes, and returns a 409
error response if any are found.

Failling to do this can lead to orphaned resource providers
in placement and also failing to properly confirm or revert
a pending resize or cold migration.

A release note is included for the (justified) behavior
change in the API. A new microversion should not be required
for this since admins should not have to opt out of broken
behavior.

Conflicts:
      nova/tests/functional/integrated_helpers.py

NOTE(mriedem): The conflict is due to not having change
Ie991d4b53e9bb5e7ec26da99219178ab7695abf6 in Rocky.

Change-Id: I70e06c607045a1c0842f13069e51fef438012a9c
Closes-Bug: #1852610
(cherry picked from commit 92fed026103b47fa2a76ea09204a4ba24c21e191)
(cherry picked from commit a9650b3cbfc674e283964090fb64ac6297be5b78)
(cherry picked from commit a0290858b717b4cefd0d6fc17acc2b143ab12ac4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/698113/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/wsgi/test_services.py', 'nova/tests/functional/integrated_helpers.py', 'releasenotes/notes/bug-1852610-service-delete-with-migrations-ca0565fc0b503519.yaml', 'api-ref/source/os-services.inc', 'nova/api/openstack/compute/services.py']",5,30a635068512be558acf0f9c83185dc1aaad560f,bug/1852610,"from oslo_log import log as loggingLOG = logging.getLogger(__name__) # Similarly, check to see if the are any in-progress migrations # involving this host because if there are we need to block the # service delete since we could orphan resource providers and # break the ability to do things like confirm/revert instances # in VERIFY_RESIZE status. compute_nodes = objects.ComputeNodeList.get_all_by_host( context, service.host) self._assert_no_in_progress_migrations( context, id, compute_nodes) @staticmethod def _assert_no_in_progress_migrations(context, service_id, compute_nodes): """"""Ensures there are no in-progress migrations on the given nodes. :param context: nova auth RequestContext :param service_id: id of the Service being deleted :param compute_nodes: ComputeNodeList of nodes on a compute service :raises: HTTPConflict if there are any in-progress migrations on the nodes """""" for cn in compute_nodes: migrations = ( objects.MigrationList.get_in_progress_by_host_and_node( context, cn.host, cn.hypervisor_hostname)) if migrations: # Log the migrations for the operator and then raise # a 409 error. LOG.info('Unable to delete compute service with id %s ' 'for host %s. There are %i in-progress ' 'migrations involving the host. Migrations ' '(uuid:status): %s', service_id, cn.host, len(migrations), ','.join(['%s:%s' % (mig.uuid, mig.status) for mig in migrations])) raise webob.exc.HTTPConflict( explanation=_( 'Unable to delete compute service that has ' 'in-progress migrations. Complete the ' 'migrations or delete the instances first.')) "," compute_nodes = objects.ComputeNodeList.get_all_by_host( context, service.host)",112,25
openstack%2Fpython-openstackclient~master~Id0c34029e327de50c5fd2732bae5fbf45bbd16ee,openstack/python-openstackclient,master,Id0c34029e327de50c5fd2732bae5fbf45bbd16ee,Switch to using osc_lib.utils.tags,MERGED,2019-06-03 21:40:40.000000000,2020-01-16 21:01:10.000000000,2020-01-16 20:59:31.000000000,"[{'_account_id': 2}, {'_account_id': 970}, {'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-03 21:40:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9be2a8e6afa85d0bb8a7af2d601022d80cb7a2d6', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nThe linked patch moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\nDepends-On: https://review.opendev.org/662859\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 2, 'created': '2019-07-29 21:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/74e961c70282ca4d0ab00cf9f2626a2688c6b183', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nThe linked patch moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\nDepends-On: https://review.opendev.org/662859\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 3, 'created': '2019-07-30 16:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f502912d9012a527e2083e20c6ab68c20da4459e', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nThe linked patch moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 4, 'created': '2019-07-30 17:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7f0b675f87b0c9a0b21bd5d1857babe8d70d7b0d', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 5, 'created': '2019-07-30 23:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/940897c49f4b9b34f9274eb5cb8069a2b09510e9', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 6, 'created': '2019-09-19 16:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cc112e2a16f788134fdf1dc0b3353a5e56158482', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 7, 'created': '2019-11-06 21:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/edd72c22121f8244405c8f8ac97babe7d39b2350', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 8, 'created': '2019-11-06 23:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6581a049a9095f5d13dc315bd92f84ea860cc90a', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nDepends-On: https://review.opendev.org/#/c/693267\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 9, 'created': '2019-12-11 16:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5f1e42dc6f85d1cc37ea3e07c09b27718a243b04', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nDepends-On: https://review.opendev.org/#/c/693267\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}, {'number': 10, 'created': '2020-01-15 01:10:42.000000000', 'files': ['openstackclient/network/v2/router.py', 'openstackclient/network/v2/floating_ip.py', 'requirements.txt', 'openstackclient/network/v2/subnet_pool.py', 'openstackclient/network/v2/subnet.py', 'openstackclient/network/v2/_tag.py', 'openstackclient/network/v2/network.py', 'lower-constraints.txt', 'openstackclient/network/v2/port.py', 'openstackclient/network/v2/security_group.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/db29e28b7c1a6ef737f0c4cd459906379f59b252', 'message': 'Switch to using osc_lib.utils.tags\n\nThis patch updates the network modules to use the new\nosc_lib.utils.tags module and removes the in tree _tag.py version.\n\nA previous patch[1] moves the _tag.py code to osc-lib to allow other\nprojects to leverage the code.\n\n[1] https://review.opendev.org/662859\n\nChange-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee\n'}]",3,662864,db29e28b7c1a6ef737f0c4cd459906379f59b252,42,7,10,11628,,,0,"Switch to using osc_lib.utils.tags

This patch updates the network modules to use the new
osc_lib.utils.tags module and removes the in tree _tag.py version.

A previous patch[1] moves the _tag.py code to osc-lib to allow other
projects to leverage the code.

[1] https://review.opendev.org/662859

Change-Id: Id0c34029e327de50c5fd2732bae5fbf45bbd16ee
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/64/662864/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2/floating_ip.py', 'openstackclient/network/v2/router.py', 'openstackclient/network/v2/subnet_pool.py', 'openstackclient/network/v2/subnet.py', 'openstackclient/network/v2/_tag.py', 'openstackclient/network/v2/network.py', 'openstackclient/network/v2/port.py', 'openstackclient/network/v2/security_group.py']",8,9be2a8e6afa85d0bb8a7af2d601022d80cb7a2d6,osc-lib-tags,from osc_lib.utils import tags as _tag,from openstackclient.network.v2 import _tag,7,141
openstack%2Fcinder~master~I541cebdabc0799273f1bc241c4b30948939f2f5d,openstack/cinder,master,I541cebdabc0799273f1bc241c4b30948939f2f5d,Mark Veritas CNFS Driver Unsupported,MERGED,2020-01-02 20:35:51.000000000,2020-01-16 20:51:51.000000000,2020-01-14 10:08:33.000000000,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2020-01-02 20:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/25fd5d28d8699148b4069f87e8304ff2a928013b', 'message': ""Mark Veritas CNFS Driver Unsupported\n\nThe Veritas CNFS driver CI stopped reporting\na long time ago and there has been no activity\nfrom the vendor.\n\nAs a result this patch marks the driver\nunsupported.  It will be removed in the 'V'\nrelease if there is no change in support.\n\nChange-Id: I541cebdabc0799273f1bc241c4b30948939f2f5d\n""}, {'number': 2, 'created': '2020-01-14 02:47:16.000000000', 'files': ['doc/source/reference/support-matrix.ini', 'releasenotes/notes/veritas_cluster_nfs_unsupported-88ab3ea5cbb6cd88.yaml', 'cinder/volume/drivers/veritas_cnfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/38d3a7d87b40200a6b281abd89ed5b0d0428de2f', 'message': ""Mark Veritas CNFS Driver Unsupported\n\nThe Veritas CNFS driver CI stopped reporting\na long time ago and there has been no activity\nfrom the vendor.\n\nAs a result this patch marks the driver\nunsupported.  It will be removed in the 'V'\nrelease if there is no change in support.\n\nChange-Id: I541cebdabc0799273f1bc241c4b30948939f2f5d\n""}]",0,700937,38d3a7d87b40200a6b281abd89ed5b0d0428de2f,55,29,2,7198,,,0,"Mark Veritas CNFS Driver Unsupported

The Veritas CNFS driver CI stopped reporting
a long time ago and there has been no activity
from the vendor.

As a result this patch marks the driver
unsupported.  It will be removed in the 'V'
release if there is no change in support.

Change-Id: I541cebdabc0799273f1bc241c4b30948939f2f5d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/37/700937/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/support-matrix.ini', 'releasenotes/notes/veritas_cluster_nfs_unsupported-88ab3ea5cbb6cd88.yaml', 'cinder/volume/drivers/veritas_cnfs.py']",3,25fd5d28d8699148b4069f87e8304ff2a928013b,ci_unsupported, # TODO(jsbryant) Remove driver in the 'V' release if CI is not fixed. SUPPORTED = False ,,18,1
openstack%2Fswift~master~I6b4365c40ea8b606cb104cc92ab11cd40767aa78,openstack/swift,master,I6b4365c40ea8b606cb104cc92ab11cd40767aa78,squash: maybe clean up some func tests?,ABANDONED,2019-08-21 20:44:34.000000000,2020-01-16 20:44:40.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-08-21 20:44:34.000000000', 'files': ['test/functional/test_versioned_writes.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2fccc5f2375c7a24bd9d45129cd19e98fa13dd54', 'message': 'squash: maybe clean up some func tests?\n\nChange-Id: I6b4365c40ea8b606cb104cc92ab11cd40767aa78\n'}]",0,677824,2fccc5f2375c7a24bd9d45129cd19e98fa13dd54,3,1,1,15343,,,0,"squash: maybe clean up some func tests?

Change-Id: I6b4365c40ea8b606cb104cc92ab11cd40767aa78
",git fetch https://review.opendev.org/openstack/swift refs/changes/24/677824/1 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/test_versioned_writes.py'],1,2fccc5f2375c7a24bd9d45129cd19e98fa13dd54,bug/1840322," cls.use_symlinks = cluster_info.get( cls.use_symlinks = cluster_info.get( def assertTotalVersions(self, primary_container, count): primary_info = primary_container.info() versions_location = unquote(primary_info['versions']) archive_container = self.env.account.container(versions_location) count -= primary_info['object_count'] self.assertEqual(count, archive_container.info()['object_count']) written_content_types = [] def expected_content_types(): if self.env.use_symlinks: return written_content_types[:] return written_content_types[:-1] self.assertEqual(expected_content_types(), [ written_content_types.append('text/jibberish01') self.assertEqual(expected_content_types(), [ written_content_types.append('text/jibberish02') self.assertEqual(expected_content_types(), [ written_content_types.append('text/jibberish02') self.assertEqual(expected_content_types(), [ written_content_types.append('text/jibberish04') self.assertEqual(expected_content_types(), [ self.assertEqual(expected_content_types(), [ return (versioned_obj, expected_headers, expected_content_types()) self.assertTotalVersions(container, 4) versioned_obj_name = self._find_previous_version( versions_container, symlink_name)['name'] versioned_obj_name = self._find_previous_version( self.env.container, symlink.name)['name'] versioned_obj = self.env.versions_container.file(versioned_obj_name) self.use_symlinks = cluster_info.get("," cls.use_symlinks = cls.conn.cluster_info().get( cls.use_symlinks = cls.conn.cluster_info().get( def assertTotalVersions(self, versioned_container, count): versions_location = unquote(versioned_container.info()['versions']) versions_container = self.env.account.container(versions_location) count -= versioned_container.info()['object_count'] self.assertEqual(count, versions_container.info()['object_count']) expected_content_types = [] self.assertEqual(expected_content_types, [ if self.env.use_symlinks: expected_content_types.append('text/jibberish01') self.assertEqual(expected_content_types, [ if self.env.use_symlinks: expected_content_types.append('text/jibberish02') else: expected_content_types.append('text/jibberish01') self.assertEqual(expected_content_types, [ expected_content_types.append('text/jibberish02') self.assertEqual(expected_content_types, [ if self.env.use_symlinks: expected_content_types.append('text/jibberish04') else: expected_content_types.append('text/jibberish02') self.assertEqual(expected_content_types, [ self.assertEqual(expected_content_types, [ return (versioned_obj, expected_headers, expected_content_types) expected_count = 0 expected_count += 1 expected_count += 1 expected_count += 1 expected_count += 1 self.assertTotalVersions(container, expected_count) all_versions = versions_container.files(parms={'format': 'json'}) for version_info in all_versions: if version_info['name'][3:].startswith(symlink_name): versioned_obj_name = version_info['name'] break else: self.fail(""Couldn't find any versions of %s in %r"" % ( symlink_name, all_versions)) # find previous version version_container_files = self.env.versions_container.files() for obj in version_container_files: if obj[3:].startswith(symlink.name): versioned_obj = self.env.versions_container.file(obj) break else: self.fail('Unable to find a version of %s in %r' % ( symlink.name, version_container_files)) self.use_symlinks = self.conn.cluster_info().get(",33,50
openstack%2Fswift~master~I37a085886afc5e28e8e12532e1cbc62acde73570,openstack/swift,master,I37a085886afc5e28e8e12532e1cbc62acde73570,WIP: Add two more versioning modes that feature a new naming scheme,ABANDONED,2019-08-27 21:31:25.000000000,2020-01-16 20:44:29.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-27 21:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9dc1950b0210391b075ed056c8c20396777bc151', 'message': ""WIP: Add another versioning mode with a new naming scheme\n\nThis lets us have an index on (name, timestamp DESC) instead of the\nless-useful (len(name), name, timestamp) index we had before.\n\nAlso add some new APIs specific to this new versioning scheme:\n\n  GET    /v1/a/c?versions[&marker=o][&version_marker=v]\n  GET    /v1/a/c/o?version=v\n  HEAD   /v1/a/c/o?version=v\n  POST   /v1/a/c/o?version=v\n  DELETE /v1/a/c/o?version=v\n\nThe idea is to more-closely mirror S3's feature set. I *think* COPY\nshould Just Work?\n\nStill need to handle DELETE of the current version, though. And tests;\nso many tests.\n\nChange-Id: I37a085886afc5e28e8e12532e1cbc62acde73570\n""}, {'number': 2, 'created': '2019-09-04 23:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1b1913af93b200de1998d6bc86450ec59e3c4aa6', 'message': 'WIP: Add another versioning mode with a new naming scheme\n\nThis lets us have an index on (name, timestamp DESC) instead of the\nless-useful (len(name), name, timestamp) index we had before.\n\nAlso add some new APIs specific to this new versioning scheme:\n\n  GET    /v1/a/c?versions[&marker=o][&version_marker=v]\n  GET    /v1/a/c/o?version=v\n  HEAD   /v1/a/c/o?version=v\n  POST   /v1/a/c/o?version=v\n  DELETE /v1/a/c/o?version=v\n  COPY   /v1/a/c/o?version=v -H ""Destination: ...""\n\nThe idea is to more-closely mirror S3\'s feature set.\n\nStill needs more tests (particularly unit), but at least there are some\nfunc tests demonstrating the new API.\n\nChange-Id: I37a085886afc5e28e8e12532e1cbc62acde73570\n'}, {'number': 3, 'created': '2019-09-11 05:09:43.000000000', 'files': ['swift/common/middleware/versioned_writes.py', 'swift/obj/server.py', 'test/unit/common/middleware/test_symlink.py', 'swift/common/utils.py', 'test/unit/common/middleware/test_versioned_writes.py', 'swift/common/middleware/copy.py', 'test/functional/__init__.py', 'test/functional/swift_test_client.py', 'test/functional/test_versioned_writes.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8fe1eecadc06ded046d1066a2644e125949bdbda', 'message': 'WIP: Add two more versioning modes that feature a new naming scheme\n\nThe new namin scheme lets us have an index on (name, timestamp DESC)\ninstead of the less-useful (len(name), name, timestamp) index we had\nbefore.\n\nOne mode acts like history-mode but with the new naming scheme. The\nother is comparable to disabling versioning, but tracks a location where\nversions may previously have been stored.\n\nAlso add some new APIs specific to this new versioning scheme:\n\n  GET    /v1/a/c?versions[&marker=o][&version_marker=v]\n  GET    /v1/a/c/o?version=v\n  HEAD   /v1/a/c/o?version=v\n  POST   /v1/a/c/o?version=v\n  DELETE /v1/a/c/o?version=v\n  COPY   /v1/a/c/o?version=v -H ""Destination: ...""\n\nThe idea is to more-closely mirror S3\'s feature set.\n\nStill needs more tests (particularly unit), but at least there are some\nfunc tests demonstrating the new API.\n\nChange-Id: I37a085886afc5e28e8e12532e1cbc62acde73570\n'}]",10,678962,8fe1eecadc06ded046d1066a2644e125949bdbda,9,2,3,15343,,,0,"WIP: Add two more versioning modes that feature a new naming scheme

The new namin scheme lets us have an index on (name, timestamp DESC)
instead of the less-useful (len(name), name, timestamp) index we had
before.

One mode acts like history-mode but with the new naming scheme. The
other is comparable to disabling versioning, but tracks a location where
versions may previously have been stored.

Also add some new APIs specific to this new versioning scheme:

  GET    /v1/a/c?versions[&marker=o][&version_marker=v]
  GET    /v1/a/c/o?version=v
  HEAD   /v1/a/c/o?version=v
  POST   /v1/a/c/o?version=v
  DELETE /v1/a/c/o?version=v
  COPY   /v1/a/c/o?version=v -H ""Destination: ...""

The idea is to more-closely mirror S3's feature set.

Still needs more tests (particularly unit), but at least there are some
func tests demonstrating the new API.

Change-Id: I37a085886afc5e28e8e12532e1cbc62acde73570
",git fetch https://review.opendev.org/openstack/swift refs/changes/62/678962/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/versioned_writes.py', 'swift/common/utils.py', 'test/unit/common/middleware/test_symlink.py', 'test/unit/common/middleware/test_versioned_writes.py', 'swift/proxy/controllers/base.py']",5,9dc1950b0210391b075ed056c8c20396777bc151,bug/1840322," GreenAsyncPile, quorum_size, parse_content_type, close_if_possible, \ close_if_possible(resp.app_iter) close_if_possible(resp.app_iter)"," GreenAsyncPile, quorum_size, parse_content_type, \",370,194
openstack%2Fswift~master~I39acade850beb28dcb8a46e1e2c72dd9a428e269,openstack/swift,master,I39acade850beb28dcb8a46e1e2c72dd9a428e269,symlink-backed versioned_writes,ABANDONED,2019-01-30 01:55:58.000000000,2020-01-16 20:44:19.000000000,,"[{'_account_id': 1179}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-30 01:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ae7138acecf3a22e0373a6806a8519bd4bf85a56', 'message': 'WIP: symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n- cause the proxy to resolve the symlink on ?symlink=get GETs\n\nWIP because:\n- need to fix delete_pop behavior\n- follow 307s on POST\n- look for symlink=get on GET and manually follow\n- verify SLO/DLO/COPY behavior\n- add more checks that container listings look like they should be parse-able\n- fix up all the many, many tests I broke\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 2, 'created': '2019-07-12 17:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7078a89e7d694ecfa9afa70b3ce54c3a9093131f', 'message': 'WIP: symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n- cause the proxy to resolve the symlink on ?symlink=get GETs\n\nWIP because:\n- need to fix delete_pop behavior\n- follow 307s on POST\n- look for symlink=get on GET and manually follow\n- verify SLO/DLO/COPY behavior\n- add more checks that container listings look like they should be parse-able\n- fix up all the many, many tests I broke\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 3, 'created': '2019-07-15 20:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/54ef2aead698a88b87640aa49cb80c0b858668f0', 'message': 'WIP: symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n- cause the proxy to resolve the symlink on ?symlink=get GETs\n\nWIP because:\n- need to fix delete_pop behavior\n- follow 307s on POST\n- look for symlink=get on GET and manually follow\n- verify SLO/DLO/COPY behavior\n- add more checks that container listings look like they should be parse-able\n- fix up all the many, many tests I broke\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 4, 'created': '2019-07-17 22:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6a7c667304920fae07d4161e6430f4f641bc54b0', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 5, 'created': '2019-07-18 21:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/29ee9f17a2539fc681353cbeee8532e0cefbef98', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 6, 'created': '2019-07-19 15:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8f43dfd4f8e0b5b11740e75955deff478e89c409', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 7, 'created': '2019-07-24 18:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3db064a1df3d8f3ec64b1deaecd286c884d5e92c', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 8, 'created': '2019-07-25 20:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/10d64be4f9f63fa8af122aae2d9fee76027587f5', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 9, 'created': '2019-07-26 19:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/009ebede372747410b242e46c70d2ce431f9ad46', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 10, 'created': '2019-08-02 22:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3f59ad358bcadd886052acabc3d9d3e5ff0e68ac', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 11, 'created': '2019-08-15 20:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/05709816b1ac9a84de70e1fa20f2f631dc65a49b', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 12, 'created': '2019-08-15 20:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/333af4966beb7ed130099404776d75a397319401', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 13, 'created': '2019-08-15 21:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/26df5832d60feefa53525bd44ee6ee41ae56ec3d', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 14, 'created': '2019-08-15 21:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1ee505184c3b61d54fcfa7c8f6a949b43af0ede6', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 15, 'created': '2019-08-16 15:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b2a7005bc7d9ba0610957e73e3f507731b146d2a', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 16, 'created': '2019-08-21 17:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cbc9e052491a9dc36f6920489d6bb395d23d5533', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 17, 'created': '2019-08-22 12:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0141140aa6a4301a04cb4b292179f985bf7d82fe', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 18, 'created': '2019-08-22 12:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6081dca15047588197288dae5dceaf2d77113000', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 19, 'created': '2019-08-26 18:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/77ebb1754dbb521fc2b7cfe024d30c909090c8ac', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}, {'number': 20, 'created': '2019-09-11 05:09:43.000000000', 'files': ['swift/common/middleware/versioned_writes.py', 'test/unit/common/middleware/test_symlink.py', 'test/unit/proxy/test_server.py', 'swift/proxy/controllers/obj.py', 'test/functional/swift_test_client.py', 'test/functional/test_versioned_writes.py', 'swift/common/middleware/symlink.py', 'test/unit/common/middleware/test_versioned_writes.py', 'etc/proxy-server.conf-sample', 'test/functional/__init__.py', 'swift/common/swob.py', 'test/unit/common/middleware/helpers.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c5cab23ee349d6214b83d5b0c726c1fc4359aed8', 'message': 'symlink-backed versioned_writes\n\nPreviously, versioned_writes worked by copying data between the primary\nand archive containers, resulting in a lot of data movement even when no\ndata should actually be deleted or otherwise lost.\n\nFurther, this could lead to data loss: if two PUTs for the same name\narrive at approximately the same time, you could see\n\n- PUT at t101 archives the current object from t1\n- PUT at t102 archives the current object *which is still from t1*\n- Either:\n    - PUT at t101 completes\n    - PUT at t102 completes, and data from t101 *is lost*\n  -- or --\n    - PUT at t102 completes\n    - PUT at t101 completes, and data from t102 is lost\n\nBy using symlinks, we can direct client PUTs to directly their archive\nlocation. This has several benefits:\n\n- Less data movement. A new PUT or DELETE no longer requires that we\n  move as much as an extra 5GiB of data.\n- Fewer race conditions. In the above scenario, all three of t1, t101,\n  and t102 are saved to the archive container. There is still a race to\n  determine which of t101 or t102 is ""current"", but no data is lost.\n- Simplified notion of whether data is ""protected"". Now, any data PUT\n  while versioning is enabled will be saved by default.\n\nNote that we want to preserve some existing behaviors:\n\n- Listing the primary container should still give the ""current"" etag and\n  size for objects within it. (Though, to avoid double counting, the\n  X-Container-Bytes-Used should reflect the size of the symlink.)\n- User-created symlinks should still be versioned as normal (and as\n  already tested via functional tests).\n\nTo satisfy these, introduce the idea of a ""versioning symlink"" -- when\nencountered in a container with versioning enabled, it will\n\n- be ignored when archiving old versions\n- carry enough information to fix container listings\n- cause the proxy to follow 307s on POSTs\n\nThe use_symlinks option in [versioned_writes] must be enabled to take\nadvantage of these implementation improvements.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCloses-Bug: #1840322\nChange-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269\n'}]",144,633857,c5cab23ee349d6214b83d5b0c726c1fc4359aed8,65,4,20,15343,,,0,"symlink-backed versioned_writes

Previously, versioned_writes worked by copying data between the primary
and archive containers, resulting in a lot of data movement even when no
data should actually be deleted or otherwise lost.

Further, this could lead to data loss: if two PUTs for the same name
arrive at approximately the same time, you could see

- PUT at t101 archives the current object from t1
- PUT at t102 archives the current object *which is still from t1*
- Either:
    - PUT at t101 completes
    - PUT at t102 completes, and data from t101 *is lost*
  -- or --
    - PUT at t102 completes
    - PUT at t101 completes, and data from t102 is lost

By using symlinks, we can direct client PUTs to directly their archive
location. This has several benefits:

- Less data movement. A new PUT or DELETE no longer requires that we
  move as much as an extra 5GiB of data.
- Fewer race conditions. In the above scenario, all three of t1, t101,
  and t102 are saved to the archive container. There is still a race to
  determine which of t101 or t102 is ""current"", but no data is lost.
- Simplified notion of whether data is ""protected"". Now, any data PUT
  while versioning is enabled will be saved by default.

Note that we want to preserve some existing behaviors:

- Listing the primary container should still give the ""current"" etag and
  size for objects within it. (Though, to avoid double counting, the
  X-Container-Bytes-Used should reflect the size of the symlink.)
- User-created symlinks should still be versioned as normal (and as
  already tested via functional tests).

To satisfy these, introduce the idea of a ""versioning symlink"" -- when
encountered in a container with versioning enabled, it will

- be ignored when archiving old versions
- carry enough information to fix container listings
- cause the proxy to follow 307s on POSTs

The use_symlinks option in [versioned_writes] must be enabled to take
advantage of these implementation improvements.

Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
Closes-Bug: #1840322
Change-Id: I39acade850beb28dcb8a46e1e2c72dd9a428e269
",git fetch https://review.opendev.org/openstack/swift refs/changes/57/633857/12 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/versioned_writes.py', 'swift/common/swob.py', 'swift/proxy/controllers/obj.py']",3,ae7138acecf3a22e0373a6806a8519bd4bf85a56,bug/1840322, req.ensure_x_timestamp() req.ensure_x_timestamp() req.ensure_x_timestamp()," req.headers['X-Timestamp'] = Timestamp.now().internal def _update_x_timestamp(self, req): # The container sync feature includes an x-timestamp header with # requests. If present this is checked and preserved, otherwise a fresh # timestamp is added. if 'x-timestamp' in req.headers: try: req_timestamp = Timestamp(req.headers['X-Timestamp']) except ValueError: raise HTTPBadRequest( request=req, content_type='text/plain', body='X-Timestamp should be a UNIX timestamp float value; ' 'was %r' % req.headers['x-timestamp']) req.headers['X-Timestamp'] = req_timestamp.internal else: req.headers['X-Timestamp'] = Timestamp.now().internal return None self._update_x_timestamp(req) self._update_x_timestamp(req)",219,37
openstack%2Fovsdbapp~master~I434707bd798d6640f0ab25bc6e29b941230862b9,openstack/ovsdbapp,master,I434707bd798d6640f0ab25bc6e29b941230862b9,Make it possible to reference a newly created object within a transaction,MERGED,2020-01-10 23:06:12.000000000,2020-01-16 20:42:29.000000000,2020-01-16 20:41:04.000000000,"[{'_account_id': 5756}, {'_account_id': 8655}, {'_account_id': 11952}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-10 23:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/f53a311ca75856db794272ecb26b79e6b60b7160', 'message': 'Make it possible to reference a newly created object within a transaction\n\nThis is a continuation of https://review.opendev.org/#/c/358101/\n\nEnable the OVSDB API implementations to handle referencing a newly\ncreated object within the same transaction. This change extends the\nfunctionality for records that are actually commands from a previously\nadded transaction. Example:\n\n   with api.transaction(check_error=True) as txn:\n       sw = txn.add(api.db_create_row(\'Logical_Switch\', name=""sw0""))\n       prt = txn.add(api.db_create_row(\'Logical_Switch_Port\', name=""sw0-port1""))\n       txn.add(api.db_add(\'Logical_Switch\', sw, ""ports"", prt))\n       txn.add(api.db_add(\'Logical_Switch_Port\', prt, ""addresses"", ""50:54:00:00:00:01 10.0.0.10""))\n\nChange-Id: I434707bd798d6640f0ab25bc6e29b941230862b9\nCloses-Bug: #1615105\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nDepends-On: https://review.opendev.org/358101/\n'}, {'number': 2, 'created': '2020-01-14 21:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/5d0b5d2456e78d79dcf13ee79eaa5965780480ed', 'message': 'Make it possible to reference a newly created object within a transaction\n\nThis is a continuation of https://review.opendev.org/#/c/358101/\n\nEnable the OVSDB API implementations to handle referencing a newly\ncreated object within the same transaction. This change extends the\nfunctionality for records that are actually commands from a previously\nadded transaction. Example:\n\n   with api.transaction(check_error=True) as txn:\n       sw = txn.add(api.db_create_row(\'Logical_Switch\', name=""sw0""))\n       prt = txn.add(api.db_create_row(\'Logical_Switch_Port\', name=""sw0-port1""))\n       txn.add(api.db_add(\'Logical_Switch\', sw, ""ports"", prt))\n       txn.add(api.db_add(\'Logical_Switch_Port\', prt, ""addresses"", ""50:54:00:00:00:01 10.0.0.10""))\n\nAlso added functional test to exercise this codepath.\n\nChange-Id: I434707bd798d6640f0ab25bc6e29b941230862b9\nCloses-Bug: #1615105\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nDepends-On: https://review.opendev.org/358101/\n'}, {'number': 3, 'created': '2020-01-14 22:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/244ae5b66a3695d69999ab892d713f6c464b8842', 'message': 'Make it possible to reference a newly created object within a transaction\n\nThis is a continuation of https://review.opendev.org/#/c/358101/\n\nEnable the OVSDB API implementations to handle referencing a newly\ncreated object within the same transaction. This change extends the\nfunctionality for records that are actually commands from a previously\nadded transaction. Example:\n\n   with api.transaction(check_error=True) as txn:\n       sw = txn.add(api.db_create_row(\'Logical_Switch\', name=""sw0""))\n       prt = txn.add(api.db_create_row(\'Logical_Switch_Port\', name=""sw0-port1""))\n       txn.add(api.db_add(\'Logical_Switch\', sw, ""ports"", prt))\n       txn.add(api.db_add(\'Logical_Switch_Port\', prt, ""addresses"", ""50:54:00:00:00:01 10.0.0.10""))\n\nAlso added functional test to exercise this codepath.\n\nChange-Id: I434707bd798d6640f0ab25bc6e29b941230862b9\nCloses-Bug: #1615105\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nDepends-On: https://review.opendev.org/358101/\n'}, {'number': 4, 'created': '2020-01-15 15:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/48645eb7404d57455b61c1634c10dbb2a1389853', 'message': 'Make it possible to reference a newly created object within a transaction\n\nThis is a continuation of https://review.opendev.org/#/c/358101/\n\nEnable the OVSDB API implementations to handle referencing a newly\ncreated object within the same transaction. This change extends the\nfunctionality for records that are actually commands from a previously\nadded transaction. Example:\n\n   with api.transaction(check_error=True) as txn:\n       sw = txn.add(api.db_create_row(\'Logical_Switch\', name=""sw0""))\n       prt = txn.add(api.db_create_row(\'Logical_Switch_Port\', name=""sw0-port1""))\n       txn.add(api.db_add(\'Logical_Switch\', sw, ""ports"", prt))\n       txn.add(api.db_add(\'Logical_Switch_Port\', prt, ""addresses"", ""50:54:00:00:00:01 10.0.0.10""))\n\nAlso added functional test to exercise this codepath.\n\nChange-Id: I434707bd798d6640f0ab25bc6e29b941230862b9\nCloses-Bug: #1615105\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nDepends-On: https://review.opendev.org/358101/\n'}, {'number': 5, 'created': '2020-01-16 15:23:35.000000000', 'files': ['ovsdbapp/backend/ovs_idl/__init__.py', 'ovsdbapp/tests/functional/schema/ovn_northbound/test_impl_idl.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/910609cc99b57d779fcfe858a166dd5c420cb2c1', 'message': 'Make it possible to reference a newly created object within a transaction\n\nThis is a continuation of https://review.opendev.org/#/c/358101/\n\nEnable the OVSDB API implementations to handle referencing a newly\ncreated object within the same transaction. This change extends the\nfunctionality for records that are actually commands from a previously\nadded transaction. Example:\n\n   with api.transaction(check_error=True) as txn:\n       sw = txn.add(api.db_create_row(\'Logical_Switch\', name=""sw0""))\n       prt = txn.add(api.db_create_row(\'Logical_Switch_Port\', name=""sw0-port1""))\n       txn.add(api.db_add(\'Logical_Switch\', sw, ""ports"", prt))\n       txn.add(api.db_add(\'Logical_Switch_Port\', prt, ""addresses"", ""50:54:00:00:00:01 10.0.0.10""))\n\nAlso added functional test to exercise this codepath.\n\nChange-Id: I434707bd798d6640f0ab25bc6e29b941230862b9\nCloses-Bug: #1615105\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nDepends-On: https://review.opendev.org/358101/\n'}]",8,702054,910609cc99b57d779fcfe858a166dd5c420cb2c1,23,5,5,11952,,,0,"Make it possible to reference a newly created object within a transaction

This is a continuation of https://review.opendev.org/#/c/358101/

Enable the OVSDB API implementations to handle referencing a newly
created object within the same transaction. This change extends the
functionality for records that are actually commands from a previously
added transaction. Example:

   with api.transaction(check_error=True) as txn:
       sw = txn.add(api.db_create_row('Logical_Switch', name=""sw0""))
       prt = txn.add(api.db_create_row('Logical_Switch_Port', name=""sw0-port1""))
       txn.add(api.db_add('Logical_Switch', sw, ""ports"", prt))
       txn.add(api.db_add('Logical_Switch_Port', prt, ""addresses"", ""50:54:00:00:00:01 10.0.0.10""))

Also added functional test to exercise this codepath.

Change-Id: I434707bd798d6640f0ab25bc6e29b941230862b9
Closes-Bug: #1615105
Signed-off-by: Flavio Fernandes <flaviof@redhat.com>
Co-authored-by: Terry Wilson <twilson@redhat.com>
Depends-On: https://review.opendev.org/358101/
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/54/702054/4 && git format-patch -1 --stdout FETCH_HEAD,['ovsdbapp/backend/ovs_idl/__init__.py'],1,f53a311ca75856db794272ecb26b79e6b60b7160,bug/1615105," # Handle commands by simply returning its result if isinstance(record, cmd.BaseCommand): return record.result ",,4,0
openstack%2Fnetworking-ovn~stable%2Fqueens~I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c,openstack/networking-ovn,stable/queens,I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c,Set binding profile directly from OVNTrunkDriver (redo cont.),MERGED,2019-11-06 23:40:38.000000000,2020-01-16 20:21:42.000000000,2020-01-16 20:21:42.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-11-06 23:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e09b00d60211fd34bdfc242daca24e18f4df0566', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 2, 'created': '2019-11-06 23:41:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7c0718eba4c8b0a37b2abf69ddb63bdad273a54c', 'message': 'WIP: Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 3, 'created': '2019-11-22 20:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/843867cb01b600cee7897e8d1daa074b43958e07', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 4, 'created': '2019-11-25 10:40:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/fba109a2155d0213375903f20601c96f38d2aa73', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 5, 'created': '2019-11-25 10:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/64e3dd8eaeb302177685145c25d72e56634b1a38', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 6, 'created': '2019-12-04 11:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/624334cb37a26aad1adfeb689a6378606c248203', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to TODO_TBD for 50%ile\n  from 35.6 sec to TODO_TBD for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 7, 'created': '2019-12-09 12:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6246c3165210d1b55c3575599b7c248979e6a5e4', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n'}, {'number': 8, 'created': '2019-12-13 11:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4c1a2104520879255f663efecbbe82a1aee5a3d6', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 82efc6197a469e963d8a8105efbae0ff5a4dc82d)\n'}, {'number': 9, 'created': '2019-12-18 10:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/17946a43f141df4ad05556badf1b5ffae269ac9a', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 82efc6197a469e963d8a8105efbae0ff5a4dc82d)\n'}, {'number': 10, 'created': '2019-12-18 10:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/24794226c1696b995fd23a96c7d96c69f3f4c16e', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)\n'}, {'number': 11, 'created': '2020-01-14 18:32:06.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/ml2/trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4bed17daa762f9787391484945a445eabd617c04', 'message': ""Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nThis patch doesn't go to master networking-ovn. It\nhas been  migrated to master Neutron [1].\n\n[1]: https://review.opendev.org/#/c/701646/\n\nDepends-On: https://review.opendev.org/#/c/695693/\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)\n""}]",0,693270,4bed17daa762f9787391484945a445eabd617c04,37,7,11,11952,,,0,"Set binding profile directly from OVNTrunkDriver (redo cont.)

This is a tweak to changes done to fix bug 1834637. Specifically,
this change addresses scaling. The previous gerrit change had
modifications to all OVN sub-ports performed as a single
transaction. That did not account for race-condition on neutron
DB queries, which leads to timeouts under heavy loads.

Another cleanup done by this change is to fold an additional
update on neutron db into ovn trunk driver. That saves
update from doing another database transaction, thus making
it faster. The no longer needed function in mech_driver was
called _update_subport_host_if_needed

By breaking the iteration into multiple transactions, the
change in time is marginal:

  Service-level agreement
  NeutronTrunks :: neutron.create_trunk

  from 34.2 sec to 35.6 for 50%ile
  from 35.6 sec to 36.1 for 95%ile

This patch doesn't go to master networking-ovn. It
has been  migrated to master Neutron [1].

[1]: https://review.opendev.org/#/c/701646/

Depends-On: https://review.opendev.org/#/c/695693/
Change-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c
Closes-Bug: #1834637
Co-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>
(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/70/693270/10 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/ml2/trunk_driver.py'],1,e09b00d60211fd34bdfc242daca24e18f4df0566,bug/1834637,"from sqlalchemy.orm import exc as sql_exc tries = 10 for try_cnt in range(tries): try: self._set_sub_ports_try(parent_port, subports) break except sql_exc.StaleDataError as e: if try_cnt < tries - 1: LOG.debug(""Got StaleDataError exception %s"", e) continue else: # re-raise when all tries failed raise def _set_sub_ports_try(self, parent_port, subports): for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: tries = 10 for try_cnt in range(tries): try: self._unset_sub_ports_try(subports) break except sql_exc.StaleDataError as e: if try_cnt < tries - 1: LOG.debug(""Got StaleDataError exception %s"", e) continue else: # re-raise when all tries failed raise def _unset_sub_ports_try(self, subports): for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: LOG.debug(""Setting parent %s for subport %s"", parent_port, subport.port_id) LOG.debug(""Done setting parent %s for subport %s"", parent_port, subport.port_id) LOG.debug(""Unsetting parent for subport %s"", subport.port_id) LOG.debug(""Done unsetting parent for subport %s"", subport.port_id) def _update_trunk_status(self, trunk): tries = 10 for try_cnt in range(tries): try: trunk.update(status=trunk_consts.ACTIVE_STATUS) break except sql_exc.StaleDataError as e: if try_cnt < tries - 1: LOG.debug(""Got StaleDataError exception %s"", e) continue else: # re-raise when all tries failed raise self._update_trunk_status(trunk) self._update_trunk_status(trunk) self._update_trunk_status(trunk)"," with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: trunk.update(status=trunk_consts.ACTIVE_STATUS) trunk.update(status=trunk_consts.ACTIVE_STATUS) trunk.update(status=trunk_consts.ACTIVE_STATUS)",59,9
openstack%2Fansible-collections-openstack~master~I1209145d045e82501cfbf68311a6fcdb4b946a58,openstack/ansible-collections-openstack,master,I1209145d045e82501cfbf68311a6fcdb4b946a58,WIP: tox job for ansible-test sanity,ABANDONED,2020-01-16 16:12:03.000000000,2020-01-16 20:08:30.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-16 16:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4c0db7fc43d8b8547a1af7068c29a47ea503e952', 'message': 'WIP: tox job for ansible-test sanity\n\nChange-Id: I1209145d045e82501cfbf68311a6fcdb4b946a58\n'}, {'number': 2, 'created': '2020-01-16 16:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f66b52f102a20d2fc90639e96b95a26e80041377', 'message': 'WIP: tox job for ansible-test sanity\n\nChange-Id: I1209145d045e82501cfbf68311a6fcdb4b946a58\n'}, {'number': 3, 'created': '2020-01-16 17:43:37.000000000', 'files': ['galaxy.yml', 'test-requirements.txt', 'zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2867de589f6259c708296b49a68822ebd2bde870', 'message': 'WIP: tox job for ansible-test sanity\n\nChange-Id: I1209145d045e82501cfbf68311a6fcdb4b946a58\n'}]",0,702907,2867de589f6259c708296b49a68822ebd2bde870,6,1,3,10969,,,0,"WIP: tox job for ansible-test sanity

Change-Id: I1209145d045e82501cfbf68311a6fcdb4b946a58
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/07/702907/1 && git format-patch -1 --stdout FETCH_HEAD,"['galaxy.yml', 'test-requirements.txt', 'tox.ini']",3,4c0db7fc43d8b8547a1af7068c29a47ea503e952,toxjob,"[tox] minversion = 3.1 envlist = pep8 skipsdist = True ignore_basepython_conflict = True [testenv] skip_install = True install_command = pip3 install {opts} {packages} passenv = OS_* setenv = VIRTUAL_ENV={envdir} LANG=en_US.UTF-8 LANGUAGE=en_US:en LC_ALL=C OS_LOG_CAPTURE={env:OS_LOG_CAPTURE:true} OS_STDOUT_CAPTURE={env:OS_STDOUT_CAPTURE:true} OS_STDERR_CAPTURE={env:OS_STDERR_CAPTURE:true} deps = -r{toxinidir}/test-requirements.txt commands = stestr run {posargs} stestr slowest [testenv:pep8] commands = flake8 [testenv:ansible-test] passenv = * commands = ansible-galaxy collection build --force {toxinidir} --output-path {toxinidir}/build_artifact ansible-galaxy collection install {toxinidir}/build_artifact/openstack-cloud-1.0.0.tar.gz --force -p {toxinidir} /bin/bash -c ""cd ansible_collections/openstack/cloud && ansible-test sanity"" [testenv:venv] deps = -r{toxinidir}/test-requirements.txt commands = {posargs} [flake8] # W503 Is supposed to be off by default but in the latest pycodestyle isn't. # Also, both openstacksdk and Donald Knuth disagree with the rule. Line # breaks should occur before the binary operator for readability. # H4 are rules for docstrings. Maybe we should clean them? # E501,E402,H301,H236,F401,E128 are ignored so we can import the existing # modules unchanged and then clean them in subsequent patches. ignore = W503,H4,E501,E402,H301,H236,F401,E128 show-source = True exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,build ",,55,0
openstack%2Fansible-collections-openstack~master~Ice9ed47692403decf9fd93761d2f240810253c61,openstack/ansible-collections-openstack,master,Ice9ed47692403decf9fd93761d2f240810253c61,Add linters job to collection,ABANDONED,2020-01-16 19:52:18.000000000,2020-01-16 20:08:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-16 19:52:18.000000000', 'files': ['galaxy.yml', 'plugins/modules/os_stack.py', 'test-requirements.txt', 'plugins/module_utils/openstack.py', 'zuul.yaml', 'tests/unit/compat/mock.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/461f0e455bc6f9151d261db98497e57291216a81', 'message': 'Add linters job to collection\n\nRun ansible-test sanity on all collection files,\nwhich includes linters checks.\nChange-Id: Ice9ed47692403decf9fd93761d2f240810253c61\n'}]",0,702970,461f0e455bc6f9151d261db98497e57291216a81,3,1,1,10969,,,0,"Add linters job to collection

Run ansible-test sanity on all collection files,
which includes linters checks.
Change-Id: Ice9ed47692403decf9fd93761d2f240810253c61
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/70/702970/1 && git format-patch -1 --stdout FETCH_HEAD,"['galaxy.yml', 'plugins/modules/os_stack.py', 'test-requirements.txt', 'plugins/module_utils/openstack.py', 'zuul.yaml', 'tests/unit/compat/mock.py', 'tox.ini']",7,461f0e455bc6f9151d261db98497e57291216a81,next,[testenv:linters],# In progress [testenv:ansible-test],14,7
openstack%2Fnova~stable%2Frocky~Icacc763f19db6dc90e72af32e17d480775ad5edf,openstack/nova,stable/rocky,Icacc763f19db6dc90e72af32e17d480775ad5edf,Cache security group driver,MERGED,2019-12-05 15:39:38.000000000,2020-01-16 19:22:00.000000000,2020-01-16 19:22:00.000000000,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-05 15:39:38.000000000', 'files': ['nova/tests/unit/network/test_config.py', 'nova/test.py', 'nova/network/security_group/openstack_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/179b556a5bebb8c5810b6065cd992a0a81bf288c', 'message': ""Cache security group driver\n\nChange I0932c652fb455fe10239215a93e183ea947234e3 from Mitaka\nwas a performance improvement to cache the loaded security\ngroup driver since the API calls get_openstack_security_group_driver\na lot. That performance fix was regressed with change\nIa4a8d9954bf456253101b936f8b4ff513aaa73b2 in Newton.\n\nThis caches the loaded security group driver once again. This\nis pretty similar to the original change except simpler since\nwe don't have to account for the skip_policy_check flag.\n\nChange-Id: Icacc763f19db6dc90e72af32e17d480775ad5edf\nCloses-Bug: #1825018\n(cherry picked from commit 0461921d9e5313c3e92b039b90f713ed961e20c8)\n(cherry picked from commit 3ea6a7f79b0ad8a12c8ccfdeda838784c7922e63)\n(cherry picked from commit 99048af872743638b3628555e96351e00bf1eb7e)\n""}]",0,697505,179b556a5bebb8c5810b6065cd992a0a81bf288c,11,7,1,6873,,,0,"Cache security group driver

Change I0932c652fb455fe10239215a93e183ea947234e3 from Mitaka
was a performance improvement to cache the loaded security
group driver since the API calls get_openstack_security_group_driver
a lot. That performance fix was regressed with change
Ia4a8d9954bf456253101b936f8b4ff513aaa73b2 in Newton.

This caches the loaded security group driver once again. This
is pretty similar to the original change except simpler since
we don't have to account for the skip_policy_check flag.

Change-Id: Icacc763f19db6dc90e72af32e17d480775ad5edf
Closes-Bug: #1825018
(cherry picked from commit 0461921d9e5313c3e92b039b90f713ed961e20c8)
(cherry picked from commit 3ea6a7f79b0ad8a12c8ccfdeda838784c7922e63)
(cherry picked from commit 99048af872743638b3628555e96351e00bf1eb7e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/697505/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_config.py', 'nova/test.py', 'nova/network/security_group/openstack_driver.py']",3,179b556a5bebb8c5810b6065cd992a0a81bf288c,bug/1825018,DRIVER_CACHE = None # singleton of the driver once loaded global DRIVER_CACHE if DRIVER_CACHE is None: if is_neutron_security_groups(): DRIVER_CACHE = importutils.import_object(NEUTRON_DRIVER) else: DRIVER_CACHE = importutils.import_object(NOVA_DRIVER) return DRIVER_CACHE, if is_neutron_security_groups(): return importutils.import_object(NEUTRON_DRIVER) else: return importutils.import_object(NOVA_DRIVER),19,5
openstack%2Freleases~master~Iabda17eacffb294c8cb072aa28da3dee4bc69bad,openstack/releases,master,Iabda17eacffb294c8cb072aa28da3dee4bc69bad,Release OpenStack-Ansible Train,MERGED,2020-01-16 13:35:04.000000000,2020-01-16 19:16:40.000000000,2020-01-16 19:16:40.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 13:35:04.000000000', 'files': ['deliverables/train/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/faef3406e16d6dd2a8e3c1855b6416ed02023d60', 'message': 'Release OpenStack-Ansible Train\n\nChange-Id: Iabda17eacffb294c8cb072aa28da3dee4bc69bad\n'}]",0,702865,faef3406e16d6dd2a8e3c1855b6416ed02023d60,6,2,1,28619,,,0,"Release OpenStack-Ansible Train

Change-Id: Iabda17eacffb294c8cb072aa28da3dee4bc69bad
",git fetch https://review.opendev.org/openstack/releases refs/changes/65/702865/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/openstack-ansible.yaml'],1,faef3406e16d6dd2a8e3c1855b6416ed02023d60,release_osa, - projects: - hash: a44e36004372bd8b41607913945ed19d7eb9f204 repo: openstack/openstack-ansible version: 20.0.1,,4,0
openstack%2Freleases~master~Ifd731f2d46568ca0ddcc935e6b40319b4dfff9ce,openstack/releases,master,Ifd731f2d46568ca0ddcc935e6b40319b4dfff9ce,Release keystoneauth 3.13.2,ABANDONED,2020-01-10 14:52:17.000000000,2020-01-16 19:08:49.000000000,,"[{'_account_id': 1916}, {'_account_id': 8482}, {'_account_id': 11904}, {'_account_id': 14892}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-10 14:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/3d2b9137fc1fae46b7751c7c3836580711daac89', 'message': 'Release keystoneauth 3.13.2\n\nFrom stable/stein\n\nChange-Id: Ifd731f2d46568ca0ddcc935e6b40319b4dfff9ce\n'}, {'number': 2, 'created': '2020-01-10 16:06:40.000000000', 'files': ['deliverables/stein/keystoneauth.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/8f637f3ee0bd4ae0c2f1507d5b1f4c87816c25ee', 'message': 'Release keystoneauth 3.13.2\n\nFrom stable/stein\n\nChange-Id: Ifd731f2d46568ca0ddcc935e6b40319b4dfff9ce\n'}]",0,701979,8f637f3ee0bd4ae0c2f1507d5b1f4c87816c25ee,9,7,2,14892,,,0,"Release keystoneauth 3.13.2

From stable/stein

Change-Id: Ifd731f2d46568ca0ddcc935e6b40319b4dfff9ce
",git fetch https://review.opendev.org/openstack/releases refs/changes/79/701979/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/stein/keystoneauth.yaml'],1,3d2b9137fc1fae46b7751c7c3836580711daac89,update_keystoneauth_release, - projects: - hash: 51874630142d7de4cb8226f04f102402a0ed89ed repo: openstack/keystoneauth version: 3.13.2 - location: 3.13.2, - location: 3.13.1,5,1
openstack%2Fnetworking-bagpipe~master~Iac22d787af46ad57f24391eae2188b0c74c84299,openstack/networking-bagpipe,master,Iac22d787af46ad57f24391eae2188b0c74c84299,Remove references for unittest2,MERGED,2020-01-13 12:23:54.000000000,2020-01-16 19:04:48.000000000,2020-01-16 19:03:02.000000000,"[{'_account_id': 8313}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-13 12:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/6cfadd001b933b683812f564a214b5702416746e', 'message': 'Remove references for unittest2\n\nunittest2 was needed for python<=2.6, it is time to remove it from\nrequirements.\n\nChange-Id: Iac22d787af46ad57f24391eae2188b0c74c84299\n'}, {'number': 2, 'created': '2020-01-15 11:57:39.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/f0c6cc49d585d21de8be882f4f2d5649cd833a07', 'message': 'Remove references for unittest2\n\nunittest2 was needed for python<=2.6, it is time to remove it from\nrequirements.\n\nChange-Id: Iac22d787af46ad57f24391eae2188b0c74c84299\n'}]",0,702208,f0c6cc49d585d21de8be882f4f2d5649cd833a07,11,3,2,8313,,,0,"Remove references for unittest2

unittest2 was needed for python<=2.6, it is time to remove it from
requirements.

Change-Id: Iac22d787af46ad57f24391eae2188b0c74c84299
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/08/702208/2 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,6cfadd001b933b683812f564a214b5702416746e,unittest2,,unittest2==1.1.0,0,1
openstack%2Fneutron~master~I740b7674fd87552d2d2b005f37f172f78f883496,openstack/neutron,master,I740b7674fd87552d2d2b005f37f172f78f883496,wip,ABANDONED,2020-01-16 19:00:29.000000000,2020-01-16 19:03:22.000000000,,[],"[{'number': 1, 'created': '2020-01-16 19:00:29.000000000', 'files': ['tools/migrate_names.py', 'doc/source/ovn/tools.rst', 'tools/download_gerrit_change.py', 'tools/files_in_patch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/19f2e959000f318c4b7eadff9cccffb92d99993b', 'message': 'wip\n\nChange-Id: I740b7674fd87552d2d2b005f37f172f78f883496\n'}]",0,702959,19f2e959000f318c4b7eadff9cccffb92d99993b,2,0,1,11952,,,0,"wip

Change-Id: I740b7674fd87552d2d2b005f37f172f78f883496
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/702959/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/migrate_names.py', 'doc/source/ovn/tools.rst', 'tools/download_gerrit_change.py', 'tools/files_in_patch.py']",4,19f2e959000f318c4b7eadff9cccffb92d99993b,, for name in names: print(name), for currName in names: print(currName),4,7
openstack%2Fneutron~master~I63403aea33b656c1277c7d82e08bf94717869206,openstack/neutron,master,I63403aea33b656c1277c7d82e08bf94717869206,wip,ABANDONED,2020-01-16 19:00:29.000000000,2020-01-16 19:03:13.000000000,,[],"[{'number': 1, 'created': '2020-01-16 19:00:29.000000000', 'files': ['doc/source/ovn/tools.rst', 'tools/files_in_patch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d85d2f5a3e38463da0a6002ec7c31368acf6dfb', 'message': 'wip\n\nChange-Id: I63403aea33b656c1277c7d82e08bf94717869206\n'}]",0,702958,6d85d2f5a3e38463da0a6002ec7c31368acf6dfb,2,0,1,11952,,,0,"wip

Change-Id: I63403aea33b656c1277c7d82e08bf94717869206
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/702958/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/ovn/tools.rst', 'tools/files_in_patch.py']",2,6d85d2f5a3e38463da0a6002ec7c31368acf6dfb,, global file_names global file_names global file_names for currName in names: print(currName),"debug = 0 global debug, file_names # print line_buffer, # print curr_file_name global debug, file_names if debug: print(""unwanted name: {}"".format(currName)) global debug, file_names if debug: for currName in names: print(""{} ==> {}"".format(currName, file_names[currName])) else: for currName in names: print(currName) # print currInputName",8,18
openstack%2Fnetworking-ovn~stable%2Ftrain~Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03,openstack/networking-ovn,stable/train,Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03,Cache OvnProviderHelper object in OvnProviderDriver,MERGED,2020-01-10 11:08:29.000000000,2020-01-16 19:03:05.000000000,2020-01-16 18:59:59.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2020-01-10 11:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6024c0063b3a9000002a4bf6f057d17a85d46dd4', 'message': ""Cache OvnProviderHelper object in OvnProviderDriver\n\nEvery time when a request comes from Octavia API and\nis passed down to provider driver Octavia creates new\ninstance of Provider driver. This is good approach\nwhile an API layer don't want to wait for previous API\nactions to be end first, if centralized driver approach\nwill be used.\n\nOn different angle we have OvnProviderDriver and its\narchitecutre that was not created to work in dynamic\nthreads environment, but has centralized design.\nActual architecture looks like:\n\nOvnProviderDriver object starts OvnPrividerHelper object\nthat manipulates OVN Databases. In OvnProviderHelper there is\na Queue.Queue object that stores actions to be executed\non databases with proper order. In addition OvnProviderHelper\nstarts dedicated thread that picks up actions from Queue\nand execute those on OVN NorthBound database.\n\nThat solution does not scale while using it with Octavia\napproach. There is a problem with thread leaking, because\nin OvnProviderHelper we don't stop runner thread and we thread\nit as daemon.\n\nIn addition on each API call the OVN Driver and dependent\ncomponents objects are created, this is big overhead.\n\nTo mitigate those architectural issues there is a possibility\nto cache created OVNProviderHelper object and use one\ninstance of it for one Octavia API worker process.\n\nThis change must be cherry-picked to stable branches.\n\nAs next steps OVNProvider driver should be decomposed to:\n   * Provider Agent as described in [1]\n   * Provider Driver without Queue mechanism\n\n[1] https://docs.openstack.org/octavia/latest/contributor/guides/providers.html#provider-agents\n\nChange-Id: Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03\nCloses-Bug: 1856550\n""}, {'number': 2, 'created': '2020-01-14 17:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c96b69039c3cf36cdbdd331c56b11aad2e753ad1', 'message': ""Cache OvnProviderHelper object in OvnProviderDriver\n\nEvery time when a request comes from Octavia API and\nis passed down to provider driver Octavia creates new\ninstance of Provider driver. This is good approach\nwhile an API layer don't want to wait for previous API\nactions to be end first, if centralized driver approach\nwill be used.\n\nOn different angle we have OvnProviderDriver and its\narchitecutre that was not created to work in dynamic\nthreads environment, but has centralized design.\nActual architecture looks like:\n\nOvnProviderDriver object starts OvnPrividerHelper object\nthat manipulates OVN Databases. In OvnProviderHelper there is\na Queue.Queue object that stores actions to be executed\non databases with proper order. In addition OvnProviderHelper\nstarts dedicated thread that picks up actions from Queue\nand execute those on OVN NorthBound database.\n\nThat solution does not scale while using it with Octavia\napproach. There is a problem with thread leaking, because\nin OvnProviderHelper we don't stop runner thread and we thread\nit as daemon.\n\nIn addition on each API call the OVN Driver and dependent\ncomponents objects are created, this is big overhead.\n\nTo mitigate those architectural issues there is a possibility\nto cache created OVNProviderHelper object and use one\ninstance of it for one Octavia API worker process.\n\nThis change must be cherry-picked to stable branches.\n\nAs next steps OVNProvider driver should be decomposed to:\n   * Provider Agent as described in [1]\n   * Provider Driver without Queue mechanism\n\n[1] https://docs.openstack.org/octavia/latest/contributor/guides/providers.html#provider-agents\n\nChange-Id: Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03\nCloses-Bug: 1856550\n""}, {'number': 3, 'created': '2020-01-15 12:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0eaa8d2fc8b9e1fbddea4adac23a94da72ee0954', 'message': ""Cache OvnProviderHelper object in OvnProviderDriver\n\nEvery time when a request comes from Octavia API and\nis passed down to provider driver Octavia creates new\ninstance of Provider driver. This is good approach\nwhile an API layer don't want to wait for previous API\nactions to be end first, if centralized driver approach\nwill be used.\n\nOn different angle we have OvnProviderDriver and its\narchitecutre that was not created to work in dynamic\nthreads environment, but has centralized design.\nActual architecture looks like:\n\nOvnProviderDriver object starts OvnPrividerHelper object\nthat manipulates OVN Databases. In OvnProviderHelper there is\na Queue.Queue object that stores actions to be executed\non databases with proper order. In addition OvnProviderHelper\nstarts dedicated thread that picks up actions from Queue\nand execute those on OVN NorthBound database.\n\nThat solution does not scale while using it with Octavia\napproach. There is a problem with thread leaking, because\nin OvnProviderHelper we don't stop runner thread and we thread\nit as daemon.\n\nIn addition on each API call the OVN Driver and dependent\ncomponents objects are created, this is big overhead.\n\nTo mitigate those architectural issues there is a possibility\nto cache created OVNProviderHelper object and use one\ninstance of it for one Octavia API worker process.\n\nThis change must be cherry-picked to stable branches.\n\nAs next steps OVNProvider driver should be decomposed to:\n   * Provider Agent as described in [1]\n   * Provider Driver without Queue mechanism\n\n[1] https://docs.openstack.org/octavia/latest/contributor/guides/providers.html#provider-agents\n\nChange-Id: Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03\nCloses-Bug: 1856550\n""}, {'number': 4, 'created': '2020-01-15 18:15:18.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/functional/octavia/test_ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f57aa48d521d540811c50c2cebca05003ea44eb6', 'message': ""Cache OvnProviderHelper object in OvnProviderDriver\n\nEvery time when a request comes from Octavia API and\nis passed down to provider driver Octavia creates new\ninstance of Provider driver. This is good approach\nwhile an API layer don't want to wait for previous API\nactions to be end first, if centralized driver approach\nwill be used.\n\nOn different angle we have OvnProviderDriver and its\narchitecutre that was not created to work in dynamic\nthreads environment, but has centralized design.\nActual architecture looks like:\n\nOvnProviderDriver object starts OvnPrividerHelper object\nthat manipulates OVN Databases. In OvnProviderHelper there is\na Queue.Queue object that stores actions to be executed\non databases with proper order. In addition OvnProviderHelper\nstarts dedicated thread that picks up actions from Queue\nand execute those on OVN NorthBound database.\n\nThat solution does not scale while using it with Octavia\napproach. There is a problem with thread leaking, because\nin OvnProviderHelper we don't stop runner thread and we thread\nit as daemon.\n\nIn addition on each API call the OVN Driver and dependent\ncomponents objects are created, this is big overhead.\n\nTo mitigate those architectural issues there is a possibility\nto cache created OVNProviderHelper object and use one\ninstance of it for one Octavia API worker process.\n\nThis change must be cherry-picked to stable branches.\n\nAs next steps OVNProvider driver should be decomposed to:\n   * Provider Agent as described in [1]\n   * Provider Driver without Queue mechanism\n\n[1] https://docs.openstack.org/octavia/latest/contributor/guides/providers.html#provider-agents\n\nChange-Id: Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03\nCloses-Bug: 1856550\n""}]",0,701934,f57aa48d521d540811c50c2cebca05003ea44eb6,24,4,4,24791,,,0,"Cache OvnProviderHelper object in OvnProviderDriver

Every time when a request comes from Octavia API and
is passed down to provider driver Octavia creates new
instance of Provider driver. This is good approach
while an API layer don't want to wait for previous API
actions to be end first, if centralized driver approach
will be used.

On different angle we have OvnProviderDriver and its
architecutre that was not created to work in dynamic
threads environment, but has centralized design.
Actual architecture looks like:

OvnProviderDriver object starts OvnPrividerHelper object
that manipulates OVN Databases. In OvnProviderHelper there is
a Queue.Queue object that stores actions to be executed
on databases with proper order. In addition OvnProviderHelper
starts dedicated thread that picks up actions from Queue
and execute those on OVN NorthBound database.

That solution does not scale while using it with Octavia
approach. There is a problem with thread leaking, because
in OvnProviderHelper we don't stop runner thread and we thread
it as daemon.

In addition on each API call the OVN Driver and dependent
components objects are created, this is big overhead.

To mitigate those architectural issues there is a possibility
to cache created OVNProviderHelper object and use one
instance of it for one Octavia API worker process.

This change must be cherry-picked to stable branches.

As next steps OVNProvider driver should be decomposed to:
   * Provider Agent as described in [1]
   * Provider Driver without Queue mechanism

[1] https://docs.openstack.org/octavia/latest/contributor/guides/providers.html#provider-agents

Change-Id: Ifaed77bbe6c36a63c18e568ec1d6ec5450dc8e03
Closes-Bug: 1856550
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/34/701934/4 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/functional/octavia/test_ovn_driver.py']",2,6024c0063b3a9000002a4bf6f057d17a85d46dd4,ovn-provider-train, ovn_driver.OvnProviderDriver._ovn_helper = None,,5,1
openstack%2Fneutron~master~Ic958574a24f6a744f5fec712967cf92b705b8a0b,openstack/neutron,master,Ic958574a24f6a744f5fec712967cf92b705b8a0b,wip,ABANDONED,2020-01-16 19:00:29.000000000,2020-01-16 19:03:04.000000000,,[],"[{'number': 1, 'created': '2020-01-16 19:00:29.000000000', 'files': ['doc/source/ovn/tools.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5364e515239d2fdefcc5fba92449662a9524a35b', 'message': 'wip\n\nChange-Id: Ic958574a24f6a744f5fec712967cf92b705b8a0b\n'}]",0,702957,5364e515239d2fdefcc5fba92449662a9524a35b,2,0,1,11952,,,0,"wip

Change-Id: Ic958574a24f6a744f5fec712967cf92b705b8a0b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/702957/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/ovn/tools.rst'],1,5364e515239d2fdefcc5fba92449662a9524a35b,,^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^,----------------------------------------------------------------------------,6,3
openstack%2Fneutron~master~Iae19e370af4e5600c6cf7ee03da067f4765117a7,openstack/neutron,master,Iae19e370af4e5600c6cf7ee03da067f4765117a7,wip,ABANDONED,2020-01-16 19:00:29.000000000,2020-01-16 19:02:51.000000000,,[],"[{'number': 1, 'created': '2020-01-16 19:00:29.000000000', 'files': ['doc/source/ovn/tools.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e078af1f630c490df4a57e432e34579c0953a77', 'message': 'wip\n\nChange-Id: Iae19e370af4e5600c6cf7ee03da067f4765117a7\n'}]",0,702956,3e078af1f630c490df4a57e432e34579c0953a77,2,0,1,11952,,,0,"wip

Change-Id: Iae19e370af4e5600c6cf7ee03da067f4765117a7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/702956/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/ovn/tools.rst'],1,3e078af1f630c490df4a57e432e34579c0953a77,,Patches and Cherry-picks ------------------------ ^^^^^^^^,--------,4,1
openstack%2Fdevstack~master~Ie4a48ef3fb672fa441137ecb7d2017b7a1b50c02,openstack/devstack,master,Ie4a48ef3fb672fa441137ecb7d2017b7a1b50c02,Add MariaDB 10.4 repository for Ubuntu Bionic,ABANDONED,2019-12-13 17:47:59.000000000,2020-01-16 18:42:45.000000000,,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 17:47:59.000000000', 'files': ['tools/fixup_stuff.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7eb70ae46ab704522e609667b5313fa6d5486384', 'message': 'Add MariaDB 10.4 repository for Ubuntu Bionic\n\nIn order to execute the periodic job ""neutron-tempest-mariadb-full"",\nusing Ubuntu Bionic and MariaDB, a newer version is needed than the\ndefault package version distributed (10.1).\n\nDevstack gates are tested with MySQL 5.7. Current Neutron DB schema\nis not working with the reported version 10.1.\n\nChange-Id: Ie4a48ef3fb672fa441137ecb7d2017b7a1b50c02\nRelated-Bug: #1855912\nRelated-Bug: #1841907\n'}]",0,698980,7eb70ae46ab704522e609667b5313fa6d5486384,6,3,1,16688,,,0,"Add MariaDB 10.4 repository for Ubuntu Bionic

In order to execute the periodic job ""neutron-tempest-mariadb-full"",
using Ubuntu Bionic and MariaDB, a newer version is needed than the
default package version distributed (10.1).

Devstack gates are tested with MySQL 5.7. Current Neutron DB schema
is not working with the reported version 10.1.

Change-Id: Ie4a48ef3fb672fa441137ecb7d2017b7a1b50c02
Related-Bug: #1855912
Related-Bug: #1841907
",git fetch https://review.opendev.org/openstack/devstack refs/changes/80/698980/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/fixup_stuff.sh'],1,7eb70ae46ab704522e609667b5313fa6d5486384,bug/1855912," # Add MariaDB 10.4 repository (only for Ubuntu Bionic) until bug is fixed # https://bugs.launchpad.net/neutron/+bug/1855912 if [[ ""$MYSQL_SERVICE_NAME"" == ""mariadb"" ]]; then sudo apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xF1656F24C74CD1D8 sudo add-apt-repository ""deb [arch=amd64,arm64,ppc64el] http://ftp.hosteurope.de/mirror/mariadb.org/repo/10.4/ubuntu $(lsb_release -cs) main"" fi",,7,0
openstack%2Fopenstack-ansible-ops~stable%2Ftrain~Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8,openstack/openstack-ansible-ops,stable/train,Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8,Remove trusty job,MERGED,2020-01-16 17:31:37.000000000,2020-01-16 18:40:30.000000000,2020-01-16 18:35:55.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-16 17:31:37.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/f68a5437e3fc3ee94eb27c29bd33074cd5dad695', 'message': 'Remove trusty job\n\nUbuntu Trusty is getting removed from OpenDev Infrastructure, remove the\nnon-voting trusty job.\n\nChange-Id: Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8\n(cherry picked from commit 77cd091b6d0aea58f4a840e1730ea7b435318e47)\n'}]",0,702935,f68a5437e3fc3ee94eb27c29bd33074cd5dad695,8,3,1,6547,,,0,"Remove trusty job

Ubuntu Trusty is getting removed from OpenDev Infrastructure, remove the
non-voting trusty job.

Change-Id: Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8
(cherry picked from commit 77cd091b6d0aea58f4a840e1730ea7b435318e47)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/35/702935/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,f68a5437e3fc3ee94eb27c29bd33074cd5dad695,train/backport/702815,," name: ""openstack-ansible-ops:elk_metrics_6x-ubuntu-trusty"" parent: ""openstack-ansible-ops:elk_metrics_6x-ubuntu-xenial"" nodeset: ubuntu-trusty voting: false - job:",0,7
openstack%2Fplacement~master~I549a1ae99daa524ec881796f4442d781d4cf50bf,openstack/placement,master,I549a1ae99daa524ec881796f4442d781d4cf50bf,Update for os-traits 2.2.0,MERGED,2020-01-16 06:40:49.000000000,2020-01-16 18:32:59.000000000,2020-01-16 18:29:12.000000000,"[{'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 06:40:49.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'placement/tests/functional/gabbits/traits.yaml'], 'web_link': 'https://opendev.org/openstack/placement/commit/113da5934512ba6c35cb00b4b5d065510986de0b', 'message': 'Update for os-traits 2.2.0\n\nos-traits has a new release 2.2.0 with an additional trait; update tests\nand requirements accordingly.\n\nChange-Id: I549a1ae99daa524ec881796f4442d781d4cf50bf\n'}]",0,702803,113da5934512ba6c35cb00b4b5d065510986de0b,9,2,1,25625,,,0,"Update for os-traits 2.2.0

os-traits has a new release 2.2.0 with an additional trait; update tests
and requirements accordingly.

Change-Id: I549a1ae99daa524ec881796f4442d781d4cf50bf
",git fetch https://review.opendev.org/openstack/placement refs/changes/03/702803/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt', 'placement/tests/functional/gabbits/traits.yaml']",3,113da5934512ba6c35cb00b4b5d065510986de0b,update-trait-version, $.traits.`len`: 277 # Number of standard traits, $.traits.`len`: 275 # Number of standard traits,3,3
openstack%2Frequirements~master~I706e73505666e27dc409182db317f05284e6fe85,openstack/requirements,master,I706e73505666e27dc409182db317f05284e6fe85,Fix the warning to read the configuration file.,MERGED,2020-01-16 14:28:34.000000000,2020-01-16 18:31:29.000000000,2020-01-16 18:29:12.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-01-16 14:28:34.000000000', 'files': ['openstack_requirements/project.py'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4da6e47b8f7e2912de062d9e70f4fb3c06090b32', 'message': 'Fix the warning to read the configuration file.\n\nThe method readfp is deprecated and will be removed in future versions.\nUse read_file method instead.\n\nChange-Id: I706e73505666e27dc409182db317f05284e6fe85\n'}]",0,702874,4da6e47b8f7e2912de062d9e70f4fb3c06090b32,9,4,1,31245,,,0,"Fix the warning to read the configuration file.

The method readfp is deprecated and will be removed in future versions.
Use read_file method instead.

Change-Id: I706e73505666e27dc409182db317f05284e6fe85
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/702874/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_requirements/project.py'],1,4da6e47b8f7e2912de062d9e70f4fb3c06090b32,fix_warning_config_parser, c.read_file(io.StringIO(project['setup.cfg'])), c.readfp(io.StringIO(project['setup.cfg'])),1,1
openstack%2Fdevstack~master~If64d8d39c7b26928b9de954cee71cb083c0f2416,openstack/devstack,master,If64d8d39c7b26928b9de954cee71cb083c0f2416,WIP: add get-os-environment task to tox playbook,ABANDONED,2020-01-13 13:46:31.000000000,2020-01-16 18:30:12.000000000,,"[{'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-13 13:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7485ead88dc007b3371d3000641565b5ec1f9665', 'message': ""WIP: add get-os-environment task to tox playbook\n\nI'm trying to get the python-cinderclient functional tests to run\nusing devstack-tox-functional as a base instead of our own local\nplaybooks (which pretty much just repeat the devstack-tox-functional\nplaybook defined in this repo).  The jobs aren't working, I think\nbecause the get-os-environment task is missing.  So this patch adds\nit.  Let's see iff that fixes https://review.opendev.org/#/c/691467/.\n\nChange-Id: If64d8d39c7b26928b9de954cee71cb083c0f2416\n""}, {'number': 2, 'created': '2020-01-13 14:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3df6439fac0ef2bbbd37b8d9a6141e8e334fd163', 'message': ""WIP: add get-os-environment task to tox playbook\n\nI'm trying to get the python-cinderclient functional tests to run\nusing devstack-tox-functional as a base instead of our own local\nplaybooks (which pretty much just repeat the devstack-tox-functional\nplaybook defined in this repo).  The jobs aren't working, I think\nbecause the get-os-environment task is missing.  So this patch adds\nit.  Let's see iff that fixes https://review.opendev.org/#/c/691467/.\n\nChange-Id: If64d8d39c7b26928b9de954cee71cb083c0f2416\n""}, {'number': 3, 'created': '2020-01-13 21:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f770a9641bfc29f63d880bceacf1fc7622909ffc', 'message': ""WIP: add get-os-environment task to tox playbook\n\nI'm trying to get the python-cinderclient functional tests to run\nusing devstack-tox-functional as a base instead of our own local\nplaybooks (which pretty much just repeat the devstack-tox-functional\nplaybook defined in this repo).  The jobs aren't working, I think\nbecause the get-os-environment task is missing.  So this patch adds\nit.  Let's see iff that fixes https://review.opendev.org/#/c/691467/.\n\nChange-Id: If64d8d39c7b26928b9de954cee71cb083c0f2416\n""}, {'number': 4, 'created': '2020-01-13 21:38:21.000000000', 'files': ['playbooks/tox/run-both.yaml', 'roles/get-os-environment/tasks/main.yaml', 'roles/get-os-environment/README.rst', 'roles/get-os-environment/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/261173db0f7dc51cc4ebab612c2a0873b6643e60', 'message': ""WIP: add get-os-environment task to tox playbook\n\nI'm trying to get the python-cinderclient functional tests to run\nusing devstack-tox-functional as a base instead of our own local\nplaybooks (which pretty much just repeat the devstack-tox-functional\nplaybook defined in this repo).  The jobs aren't working, I think\nbecause the get-os-environment task is missing.  So this patch adds\nit.  Let's see if that fixes https://review.opendev.org/#/c/691467/.\n\nChange-Id: If64d8d39c7b26928b9de954cee71cb083c0f2416\n""}]",0,702217,261173db0f7dc51cc4ebab612c2a0873b6643e60,8,2,4,5314,,,0,"WIP: add get-os-environment task to tox playbook

I'm trying to get the python-cinderclient functional tests to run
using devstack-tox-functional as a base instead of our own local
playbooks (which pretty much just repeat the devstack-tox-functional
playbook defined in this repo).  The jobs aren't working, I think
because the get-os-environment task is missing.  So this patch adds
it.  Let's see if that fixes https://review.opendev.org/#/c/691467/.

Change-Id: If64d8d39c7b26928b9de954cee71cb083c0f2416
",git fetch https://review.opendev.org/openstack/devstack refs/changes/17/702217/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tox/run-both.yaml'],1,7485ead88dc007b3371d3000641565b5ec1f9665,get-os-env, - get-os-environment,,1,0
openstack%2Fnova~stable%2Fpike~I25616c5761ea625a15d725777ae58175651558f8,openstack/nova,stable/pike,I25616c5761ea625a15d725777ae58175651558f8,lxc: make use of filter python3 compatible,MERGED,2019-08-14 19:26:56.000000000,2020-01-16 18:29:09.000000000,2020-01-16 18:29:08.000000000,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-08-14 19:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69151e4cc4857a329b6c46fbf44dde013d9e3f59', 'message': 'lxc: make use of filter python3 compatible\n\n_detect_nbd_devices uses the filter\nbuiltin internally to filter valid devices.\n\nIn python 2, filter returns a list. In python 3,\nfilter returns an iterable or generator function.\nThis change eagerly converts the result of calling filter\nto a list to preserve the python 2 behaviour under python 3.\n\nCloses-Bug: #1840068\n\nChange-Id: I25616c5761ea625a15d725777ae58175651558f8\n(cherry picked from commit c730be194bfb10d812dcd6c4ee0857f3cd6029bf)\n'}, {'number': 2, 'created': '2019-08-21 01:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71e507435e5d50499fd0a0d648d1512d7257646f', 'message': 'lxc: make use of filter python3 compatible\n\n_detect_nbd_devices uses the filter\nbuiltin internally to filter valid devices.\n\nIn python 2, filter returns a list. In python 3,\nfilter returns an iterable or generator function.\nThis change eagerly converts the result of calling filter\nto a list to preserve the python 2 behaviour under python 3.\n\nCloses-Bug: #1840068\n\nChange-Id: I25616c5761ea625a15d725777ae58175651558f8\n(cherry picked from commit c730be194bfb10d812dcd6c4ee0857f3cd6029bf)\n'}, {'number': 3, 'created': '2019-12-17 19:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7596df81e00e9087db14919028606baa9cbaf92', 'message': 'lxc: make use of filter python3 compatible\n\n_detect_nbd_devices uses the filter\nbuiltin internally to filter valid devices.\n\nIn python 2, filter returns a list. In python 3,\nfilter returns an iterable or generator function.\nThis change eagerly converts the result of calling filter\nto a list to preserve the python 2 behaviour under python 3.\n\nCloses-Bug: #1840068\n\nChange-Id: I25616c5761ea625a15d725777ae58175651558f8\n(cherry picked from commit fc9fb383c16ecb98b1b546f21e7fabb5f00a42ac)\n(cherry picked from commit e135afec851e33148644d024a9d78e56f962efd4)\n(cherry picked from commit 944c08ff764c1cb598dbebbad8aa51bbdd0a692c)\n(cherry picked from commit 04bcb98678c1289810f5a8542b5bf9fe7aeeaa12)\n'}, {'number': 4, 'created': '2019-12-17 19:38:19.000000000', 'files': ['nova/virt/disk/mount/nbd.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0449fd1f89ab513059188427ff3bc5e9dbbc0546', 'message': 'lxc: make use of filter python3 compatible\n\n_detect_nbd_devices uses the filter\nbuiltin internally to filter valid devices.\n\nIn python 2, filter returns a list. In python 3,\nfilter returns an iterable or generator function.\nThis change eagerly converts the result of calling filter\nto a list to preserve the python 2 behaviour under python 3.\n\nNOTE(mriedem): In this backport the test module needs a mock\nimport since change Ib5e585fa4bfb99617cd3ca983674114d323a3cce\nis not in Pike.\n\nCloses-Bug: #1840068\n\nChange-Id: I25616c5761ea625a15d725777ae58175651558f8\n(cherry picked from commit fc9fb383c16ecb98b1b546f21e7fabb5f00a42ac)\n(cherry picked from commit e135afec851e33148644d024a9d78e56f962efd4)\n(cherry picked from commit 944c08ff764c1cb598dbebbad8aa51bbdd0a692c)\n(cherry picked from commit 04bcb98678c1289810f5a8542b5bf9fe7aeeaa12)\n'}]",4,676502,0449fd1f89ab513059188427ff3bc5e9dbbc0546,28,10,4,11604,,,0,"lxc: make use of filter python3 compatible

_detect_nbd_devices uses the filter
builtin internally to filter valid devices.

In python 2, filter returns a list. In python 3,
filter returns an iterable or generator function.
This change eagerly converts the result of calling filter
to a list to preserve the python 2 behaviour under python 3.

NOTE(mriedem): In this backport the test module needs a mock
import since change Ib5e585fa4bfb99617cd3ca983674114d323a3cce
is not in Pike.

Closes-Bug: #1840068

Change-Id: I25616c5761ea625a15d725777ae58175651558f8
(cherry picked from commit fc9fb383c16ecb98b1b546f21e7fabb5f00a42ac)
(cherry picked from commit e135afec851e33148644d024a9d78e56f962efd4)
(cherry picked from commit 944c08ff764c1cb598dbebbad8aa51bbdd0a692c)
(cherry picked from commit 04bcb98678c1289810f5a8542b5bf9fe7aeeaa12)
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/676502/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/disk/mount/nbd.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py']",2,69151e4cc4857a329b6c46fbf44dde013d9e3f59,bug/1840068,"def _fake_detect_nbd_devices_none():def _fake_detect_nbd_devices():class NbdTestCaseNoStub(test.NoDBTestCase): @mock.patch('os.listdir') def test_detect_nbd_devices(self, list_dir_mock): list_dir_mock.return_value = _fake_detect_nbd_devices() result = nbd.NbdMount._detect_nbd_devices() self.assertIsNotNone(result) self.assertIsInstance(result, list) self.assertEqual(len(list_dir_mock.return_value), len(result)) for path in list_dir_mock.return_value: self.assertIn(path, result) @mock.patch('os.listdir') def test_detect_nbd_devices_empty(self, list_dir_mock): list_dir_mock.return_value = [ ""nbdz"", ""fake0"", ""not-nbd1""] result = nbd.NbdMount._detect_nbd_devices() self.assertIsNotNone(result) self.assertIsInstance(result, list) self.assertEqual(0, len(result)) free_devices = _fake_detect_nbd_devices()[:]",def _fake_detect_nbd_devices_none(self):def _fake_detect_nbd_devices(self): free_devices = _fake_detect_nbd_devices(None)[:],28,5
openstack%2Ftripleo-quickstart-extras~master~I8117b99426dd69e734340d18ac35455ca9a43ab6,openstack/tripleo-quickstart-extras,master,I8117b99426dd69e734340d18ac35455ca9a43ab6,Use tripleo-operator-ansible for minion install,MERGED,2020-01-09 18:03:37.000000000,2020-01-16 18:28:25.000000000,2020-01-16 18:28:25.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-09 18:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e3d3600b0355fb2a7a8ef7f8582812a3f27560ad', 'message': 'Use tripleo-operator-ansible for minion install\n\nChange-Id: I8117b99426dd69e734340d18ac35455ca9a43ab6\nDepends-On: https://review.opendev.org/#/c/701775/\n'}, {'number': 2, 'created': '2020-01-09 22:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/eb020d940ee9f7a190dbb4e51ac0f678e9055194', 'message': 'Use tripleo-operator-ansible for minion install\n\nChange-Id: I8117b99426dd69e734340d18ac35455ca9a43ab6\nDepends-On: https://review.opendev.org/#/c/701775/\n'}, {'number': 3, 'created': '2020-01-14 16:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/33c86a704c34fd2614cb63ff9f2451b7560d0757', 'message': 'Use tripleo-operator-ansible for minion install\n\nChange-Id: I8117b99426dd69e734340d18ac35455ca9a43ab6\nDepends-On: https://review.opendev.org/#/c/701775/\n'}, {'number': 4, 'created': '2020-01-14 16:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e41073f1c3500f037f54cd3923c3832d4342822d', 'message': 'Use tripleo-operator-ansible for minion install\n\nChange-Id: I8117b99426dd69e734340d18ac35455ca9a43ab6\nDepends-On: https://review.opendev.org/#/c/701775/\n'}, {'number': 5, 'created': '2020-01-14 17:00:39.000000000', 'files': ['roles/undercloud-minion-deploy/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3d761a37c068d0d52e7b16c716d5ebfa1c5bb06c', 'message': 'Use tripleo-operator-ansible for minion install\n\nChange-Id: I8117b99426dd69e734340d18ac35455ca9a43ab6\nDepends-On: https://review.opendev.org/#/c/701775/\n'}]",3,701790,3d761a37c068d0d52e7b16c716d5ebfa1c5bb06c,37,5,5,14985,,,0,"Use tripleo-operator-ansible for minion install

Change-Id: I8117b99426dd69e734340d18ac35455ca9a43ab6
Depends-On: https://review.opendev.org/#/c/701775/
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/90/701790/3 && git format-patch -1 --stdout FETCH_HEAD,['roles/undercloud-minion-deploy/tasks/main.yml'],1,e3d3600b0355fb2a7a8ef7f8582812a3f27560ad,tripleo-operator-ansible,"- name: Run install via tripleo-operator-ansible when: - release in ['master'] - setup_install_minion|bool block: - name: Run dstat on the minion prior to minion install include_role: name: validate-perf - name: Install undercloud minion collections: - tripleo.operator import_role: name: tripleo-undercloud-minion-install vars: tripleo_undercloud_minion_install_debug: ""{{ minion_minion_debug }}"" - name: Run legacy install when: release not in ['master'] block: - include: install-minion.yml tags: - minion-install",- include: install-minion.yml,22,1
openstack%2Fcharm-specs~master~Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08,openstack/charm-specs,master,Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08,Ussuri opening,ABANDONED,2019-11-26 13:57:26.000000000,2020-01-16 18:26:31.000000000,,"[{'_account_id': 13686}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-11-26 13:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/81689346140ef944e148d0be6b9b72520ae8d33a', 'message': 'Ussuri opening\n\nRename ``cinder-backup-swift`` to ``cinder-backup-swift-proxy``\n\nChange-Id: Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08\n'}, {'number': 2, 'created': '2019-11-26 14:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/717b156423add2add1f61f7fa263819849d42de8', 'message': 'Ussuri opening\n\nRename ``cinder-backup-swift`` to ``cinder-backup-swift-proxy``\n\nFix lint.\n\nEnable py37 job (For lint checking).\n\nChange-Id: Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08\n'}, {'number': 3, 'created': '2019-11-26 14:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/aa087dca7b2e37b3b2f645d3b43ebd3a91c6d3e3', 'message': 'Ussuri opening\n\nRename ``cinder-backup-swift`` to ``cinder-backup-swift-proxy``\n\nFix lint.\n\nEnable py37 job (For lint checking).\n\nChange-Id: Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08\n'}, {'number': 4, 'created': '2019-11-26 14:53:57.000000000', 'files': ['specs/ussuri/backlog/service-discovery.rst', 'specs/ussuri/backlog/controlled-service-restarts.rst', '.zuul.yaml', 'doc/source/specs/ussuri/approved', 'specs/ussuri/approved/ceph-fs-nfs-with-manilla.rst', 'specs/ussuri/redirects', 'doc/source/specs/ussuri/redirects', 'specs/train/implemented/policy-d-override.rst', 'specs/ussuri/approved/ovn-charm.rst', 'specs/ussuri/backlog/openstack-load-balancer.rst', 'doc/source/index.rst', 'specs/ussuri/backlog/ceph-storage-action.rst', 'doc/source/specs/ussuri/template.rst', 'specs/ussuri/backlog/charm-panko.rst', 'specs/ussuri/backlog/swift-extended-cluster-operations.rst', 'doc/source/specs/ussuri/implemented', 'specs/ussuri/approved/cinder-backup-swift-proxy.rst', 'specs/ussuri/approved/mysql8.rst', 'doc/source/specs/ussuri/index.rst', 'specs/train/implemented/ceph-pg-autotune.rst', 'doc/source/specs/ussuri/backlog'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/96e56d2952f935a7df8aa2e995d27abf2b583324', 'message': 'Ussuri opening\n\nRename ``cinder-backup-swift`` to ``cinder-backup-swift-proxy``\n\nFix lint.\n\nEnable py37 job (For lint checking).\n\nChange-Id: Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08\n'}]",5,696087,96e56d2952f935a7df8aa2e995d27abf2b583324,11,3,4,13686,,,0,"Ussuri opening

Rename ``cinder-backup-swift`` to ``cinder-backup-swift-proxy``

Fix lint.

Enable py37 job (For lint checking).

Change-Id: Ia082c29dab9273bc84d6cb7a6f903ca0ac943a08
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/87/696087/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/ussuri/backlog/service-discovery.rst', 'specs/ussuri/backlog/controlled-service-restarts.rst', 'specs/ussuri/approved/ceph-fs-nfs-with-manilla.rst', 'specs/train/implemented/policy-d-override.rst', 'specs/ussuri/approved/ovn-charm.rst', 'specs/ussuri/backlog/openstack-load-balancer.rst', 'specs/ussuri/backlog/ceph-storage-action.rst', 'specs/ussuri/backlog/charm-panko.rst', 'specs/ussuri/backlog/swift-extended-cluster-operations.rst', 'specs/ussuri/approved/cinder-backup-swift-proxy.rst', 'specs/ussuri/approved/mysql8.rst', 'specs/train/implemented/ceph-pg-autotune.rst']",12,81689346140ef944e148d0be6b9b72520ae8d33a,ussuri,,,4,4
openstack%2Fansible-config_template~master~If226b4814a88b3bd7968b5e2ef64474710665ae0,openstack/ansible-config_template,master,If226b4814a88b3bd7968b5e2ef64474710665ae0,Add option to enable / disable the template engine,MERGED,2019-12-17 21:53:09.000000000,2020-01-16 18:21:43.000000000,2020-01-16 18:19:15.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25023}, {'_account_id': 25591}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-12-17 21:53:09.000000000', 'files': ['library/config_template', 'action/config_template.py'], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/abc807a70a5baf62ab34094b9c243a525ab0fe30', 'message': 'Add option to enable / disable the template engine\n\nThis change allows a deployer to selectively enable or disable the\ntemplate engine. This will allow folks to override the contents of\na configuration file via the `config_overrides` option but not render\nany jinja related content within the file, except for what is provided\nby the `config_overrides` option.\n\nChange-Id: If226b4814a88b3bd7968b5e2ef64474710665ae0\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",2,699506,abc807a70a5baf62ab34094b9c243a525ab0fe30,15,7,1,7353,,,0,"Add option to enable / disable the template engine

This change allows a deployer to selectively enable or disable the
template engine. This will allow folks to override the contents of
a configuration file via the `config_overrides` option but not render
any jinja related content within the file, except for what is provided
by the `config_overrides` option.

Change-Id: If226b4814a88b3bd7968b5e2ef64474710665ae0
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/ansible-config_template refs/changes/06/699506/1 && git format-patch -1 --stdout FETCH_HEAD,"['library/config_template', 'action/config_template.py']",2,abc807a70a5baf62ab34094b9c243a525ab0fe30,," def _check_templar(self, data): if boolean(self._task.args.get('render_template', True)): return self._templar.template( data, preserve_trailing_newlines=True, escape_backslashes=False, convert_data=False ) else: return data resultant = self._check_templar(data=template_data) resultant_dest = self._check_templar(data=dest_data) resultant = self._check_templar(data=resultant) # remove render enablement option new_module_args.pop('render_template', None) "," resultant = self._templar.template( template_data, preserve_trailing_newlines=True, escape_backslashes=False, convert_data=False ) resultant_dest = self._templar.template( dest_data, preserve_trailing_newlines=True, escape_backslashes=False, convert_data=False ) resultant = self._templar.template( resultant, preserve_trailing_newlines=True, escape_backslashes=False, convert_data=False )",26,19
openstack%2Ftripleo-heat-templates~master~I2aaa244618d384d9330184db6b6b754a48325efb,openstack/tripleo-heat-templates,master,I2aaa244618d384d9330184db6b6b754a48325efb,Add global ansible option for `EnablePackageInstall`,ABANDONED,2019-05-31 21:05:13.000000000,2020-01-16 18:10:42.000000000,,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-05-31 21:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7914afa0823d99b5030a6ab8a14c5ac4408bfc1b', 'message': 'Add global ansible option for `EnablePackageInstall`\n\nThis option is globally defined in the heat stack and is used to\ninstruct systems whether or not to install packages at the time of\ndeployment. This change adds the parameter to an ansible entry point\nallowing us to consume it via the package module allow us to have a\nconsistent experience across the heat, puppet, and ansible stacks.\n\nDepends-On: I9fc504944e2067d9f87a5ad6ca0fe19097d1dd2d\nChange-Id: I2aaa244618d384d9330184db6b6b754a48325efb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2019-06-06 16:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1d03c7ed527f593a237f1da0d4a36902494a064c', 'message': 'Add global ansible option for `EnablePackageInstall`\n\nThis option is globally defined in the heat stack and is used to\ninstruct systems whether or not to install packages at the time of\ndeployment. This change adds the parameter to an ansible entry point\nallowing us to consume it via the package module allow us to have a\nconsistent experience across the heat, puppet, and ansible stacks.\n\nDepends-On: I9fc504944e2067d9f87a5ad6ca0fe19097d1dd2d\nChange-Id: I2aaa244618d384d9330184db6b6b754a48325efb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 3, 'created': '2019-06-07 20:37:11.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/31f74dae6ccc85f9b707fc2b928a96fa8e9c5e1d', 'message': 'Add global ansible option for `EnablePackageInstall`\n\nThis option is globally defined in the heat stack and is used to\ninstruct systems whether or not to install packages at the time of\ndeployment. This change adds the parameter to an ansible entry point\nallowing us to consume it via the package module allow us to have a\nconsistent experience across the heat, puppet, and ansible stacks.\n\nDepends-On: I9fc504944e2067d9f87a5ad6ca0fe19097d1dd2d\nChange-Id: I2aaa244618d384d9330184db6b6b754a48325efb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",5,662580,31f74dae6ccc85f9b707fc2b928a96fa8e9c5e1d,26,6,3,7353,,,0,"Add global ansible option for `EnablePackageInstall`

This option is globally defined in the heat stack and is used to
instruct systems whether or not to install packages at the time of
deployment. This change adds the parameter to an ansible entry point
allowing us to consume it via the package module allow us to have a
consistent experience across the heat, puppet, and ansible stacks.

Depends-On: I9fc504944e2067d9f87a5ad6ca0fe19097d1dd2d
Change-Id: I2aaa244618d384d9330184db6b6b754a48325efb
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/80/662580/2 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,7914afa0823d99b5030a6ab8a14c5ac4408bfc1b,bug/1831246, EnablePackageInstall: {get_param: EnablePackageInstall},,1,0
openstack%2Fnetworking-ovn~stable%2Frocky~I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c,openstack/networking-ovn,stable/rocky,I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c,Set binding profile directly from OVNTrunkDriver (redo cont.),MERGED,2019-12-13 11:19:14.000000000,2020-01-16 17:56:54.000000000,2020-01-16 17:56:54.000000000,"[{'_account_id': 1131}, {'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 11:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c03ca83c8d5514a737b6708dfc75ebab4cb49d87', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 82efc6197a469e963d8a8105efbae0ff5a4dc82d)\n'}, {'number': 2, 'created': '2019-12-18 10:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/339e9c08fd381fc4020c87915bfa989020f40fbe', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 82efc6197a469e963d8a8105efbae0ff5a4dc82d)\n'}, {'number': 3, 'created': '2019-12-18 10:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3828f84b5a0a712c3d81e90b124ef18734bc1150', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)\n'}, {'number': 4, 'created': '2020-01-14 18:30:29.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/ml2/trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/7f03767fd2e1eb669e28a3261b253e3aa3f37486', 'message': ""Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nThis patch doesn't go to master networking-ovn. It\nhas been  migrated to master Neutron [1].\n\n[1]: https://review.opendev.org/#/c/701646/\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)\n""}]",0,698877,7f03767fd2e1eb669e28a3261b253e3aa3f37486,26,4,4,11952,,,0,"Set binding profile directly from OVNTrunkDriver (redo cont.)

This is a tweak to changes done to fix bug 1834637. Specifically,
this change addresses scaling. The previous gerrit change had
modifications to all OVN sub-ports performed as a single
transaction. That did not account for race-condition on neutron
DB queries, which leads to timeouts under heavy loads.

Another cleanup done by this change is to fold an additional
update on neutron db into ovn trunk driver. That saves
update from doing another database transaction, thus making
it faster. The no longer needed function in mech_driver was
called _update_subport_host_if_needed

By breaking the iteration into multiple transactions, the
change in time is marginal:

  Service-level agreement
  NeutronTrunks :: neutron.create_trunk

  from 34.2 sec to 35.6 for 50%ile
  from 35.6 sec to 36.1 for 95%ile

This patch doesn't go to master networking-ovn. It
has been  migrated to master Neutron [1].

[1]: https://review.opendev.org/#/c/701646/

Change-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c
Closes-Bug: #1834637
Co-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>
(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/77/698877/4 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/ml2/trunk_driver.py']",4,c03ca83c8d5514a737b6708dfc75ebab4cb49d87,bug/1834637," for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: LOG.debug(""Setting parent %s for subport %s"", parent_port, subport.port_id) # NOTE(flaviof): We expect binding's host to be set. Otherwise, # sub-port will not transition from DOWN to ACTIVE. db_port.device_owner = trunk_consts.TRUNK_SUBPORT_OWNER for binding in db_port.bindings: binding.profile['parent_name'] = parent_port binding.profile['tag'] = subport.segmentation_id context, {'profile': binding.profile, 'vif_type': portbindings.VIF_TYPE_OVS}, db_port.update() LOG.debug(""Done setting parent %s for subport %s"", parent_port, subport.port_id) LOG.debug(""Unsetting parent for subport %s"", subport.port_id) db_port.device_owner = '' 'vif_type': portbindings.VIF_TYPE_UNBOUND}, db_port.update() LOG.debug(""Done unsetting parent for subport %s"", subport.port_id)"," with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: for binding in db_port.bindings: binding.profile.update({ 'parent_name': parent_port, 'tag': subport.segmentation_id}) context, {'profile': binding.profile}, 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'vif_details': '', 'host': ''},",41,59
openstack%2Fpython-cinderclient~master~Ia978b692ade23ee6482957f41b17cb879c96fea7,openstack/python-cinderclient,master,Ia978b692ade23ee6482957f41b17cb879c96fea7,Drop support for python 2,MERGED,2019-10-26 06:31:54.000000000,2020-01-16 17:53:06.000000000,2020-01-16 17:48:26.000000000,"[{'_account_id': 1736}, {'_account_id': 4146}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 9535}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 30092}]","[{'number': 1, 'created': '2019-10-26 06:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/f193c4549461c15f02931cef5ec72283ab3b3612', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 2, 'created': '2019-10-27 11:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1dd74d42529fc18c1915587a068a293bae898d55', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 3, 'created': '2019-12-06 01:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b9787f732558a55c218ed7c36660c78b633e0f26', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 4, 'created': '2019-12-10 06:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1f509cd794949e9b18713a05298aef0c385385fe', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 5, 'created': '2019-12-20 01:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/e034657bb537d7f31569d2953f4a98249bb4672b', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 6, 'created': '2019-12-21 09:47:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1508290c558de43ccfc9bec23dd59ee8e715cd83', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 7, 'created': '2019-12-21 09:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/6f9eb12f3939ad6051af0e40093dc824ece561bf', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 8, 'created': '2020-01-09 13:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/1c37b326848b103c5cf774c4c3b50734404af3c9', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 9, 'created': '2020-01-10 13:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b48653ce88a540822f786ecf26eeb606c97e4f3f', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 10, 'created': '2020-01-10 14:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/bff2f1ba9be3f957c51f158e535008fe908c6139', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 11, 'created': '2020-01-13 02:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/44cf6598c17251bca8e3eb333ab6cd3a94328247', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 12, 'created': '2020-01-13 13:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0b0950fba34d089f0001d51f9d7b04d20579d52a', 'message': 'Drop support for python 2\n\nDepends-on: https://review.opendev.org/#/c/702217/\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 13, 'created': '2020-01-14 22:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d2e0c8748f3da335aeb8a6c585d4c518a3862821', 'message': 'Drop support for python 2\n\nDepends-on: https://review.opendev.org/#/c/702217/\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 14, 'created': '2020-01-15 02:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/4317335a3a066419216a325eec86174626c29a43', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 15, 'created': '2020-01-15 06:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/f6846b1f1825f7c7e56a06b78c4b49e399678909', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 16, 'created': '2020-01-15 17:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d345168752a95273149629aeee3b8d986f5e69e1', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 17, 'created': '2020-01-15 19:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/69222b147c97e632b9ac91a5f1ef32c2195e5441', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 18, 'created': '2020-01-15 20:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d2856cc0e2378e4f163542c56bb8adb814963e25', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 19, 'created': '2020-01-15 22:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/575cfc0718a4a662cea4480696d2b8507c0a4bd9', 'message': 'Drop support for python 2\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}, {'number': 20, 'created': '2020-01-16 13:38:16.000000000', 'files': ['releasenotes/notes/drop-python2-support-d3a1bedc75445edc.yaml', '.zuul.yaml', 'playbooks/python-cinderclient-functional.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/658de38c20e028898fe0641de2e18686703f7b70', 'message': 'Drop support for python 2\n\nAlso adds support for py3.6 and py3.7 check and gate jobs.\n\nCo-authored-by: xuanyandong <xuanyandong@inspur.com>\nCo-authored-by: Brian Rosmaita <rosmaita.fossdev@gmail.com>\n\nCloses-bug: #1853372\n\nChange-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7\n'}]",36,691467,658de38c20e028898fe0641de2e18686703f7b70,93,8,20,30092,,,0,"Drop support for python 2

Also adds support for py3.6 and py3.7 check and gate jobs.

Co-authored-by: xuanyandong <xuanyandong@inspur.com>
Co-authored-by: Brian Rosmaita <rosmaita.fossdev@gmail.com>

Closes-bug: #1853372

Change-Id: Ia978b692ade23ee6482957f41b17cb879c96fea7
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/67/691467/5 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-python2-support-d3a1bedc75445edc.yaml', '.zuul.yaml', 'setup.cfg', 'tox.ini']",4,f193c4549461c15f02931cef5ec72283ab3b3612,drop-py27-support,"envlist = py37,pep8basepython = python3","envlist = py27,py37,pep8basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",7,13
openstack%2Fproject-config~master~Ied4d243fd840f57301ab620c9a75a243bdc61eae,openstack/project-config,master,Ied4d243fd840f57301ab620c9a75a243bdc61eae,Remove retired x/js-* repos from gerritbot,MERGED,2020-01-10 19:05:28.000000000,2020-01-16 17:38:59.000000000,2020-01-16 17:38:59.000000000,"[{'_account_id': 4146}, {'_account_id': 22348}, {'_account_id': 24162}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-10 19:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0e548e171bf9da9bacb6c22df9599da65e8b1f50', 'message': 'Remove retired x/js-* repos from gerritbot\n\nRemove the following gerritbot notifications since those repos have\nbeen retired already but gerritbot was not updated:\n- x/js-afs-blob-store\n- x/js-generator-openstack\n- x/js-openstack-registry-hooks\n\nChange-Id: Ied4d243fd840f57301ab620c9a75a243bdc61eae\n'}, {'number': 2, 'created': '2020-01-16 15:24:47.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7e695eeb6470fc8d4bc298e7d6137aa49b9029d3', 'message': 'Remove retired x/js-* repos from gerritbot\n\nRemove the following gerritbot notifications since those repos have\nbeen retired already but gerritbot was not updated:\n- x/js-afs-blob-store\n- x/js-generator-openstack\n- x/js-openstack-registry-hooks\n\nChange-Id: Ied4d243fd840f57301ab620c9a75a243bdc61eae\n'}]",0,702028,7e695eeb6470fc8d4bc298e7d6137aa49b9029d3,11,4,2,6547,,,0,"Remove retired x/js-* repos from gerritbot

Remove the following gerritbot notifications since those repos have
been retired already but gerritbot was not updated:
- x/js-afs-blob-store
- x/js-generator-openstack
- x/js-openstack-registry-hooks

Change-Id: Ied4d243fd840f57301ab620c9a75a243bdc61eae
",git fetch https://review.opendev.org/openstack/project-config refs/changes/28/702028/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,0e548e171bf9da9bacb6c22df9599da65e8b1f50,gerritbot,, - x/js-afs-blob-store - x/js-generator-openstack - x/js-openstack-registry-hooks - x/js-afs-blob-store - x/js-generator-openstack - x/js-openstack-registry-hooks,0,6
openstack%2Freleases~master~I5c80a42fc61f2af7f18510f8275e25693b36e09f,openstack/releases,master,I5c80a42fc61f2af7f18510f8275e25693b36e09f,Release sphinx-feature-classification 1.0.0,MERGED,2020-01-16 16:33:07.000000000,2020-01-16 17:35:07.000000000,2020-01-16 17:35:07.000000000,"[{'_account_id': 6928}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 16:33:07.000000000', 'files': ['deliverables/_independent/sphinx-feature-classification.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c8b9716ccfb4ec10a57d58f2f1d7c339fb01912a', 'message': 'Release sphinx-feature-classification 1.0.0\n\nPick up support for feature.api [1].\n\nMajor bump as this is the first release since dropping py2 support [2].\n\n[1] I36bde39742f7f3ee60ee10240d836c7083cfa0fd\n[2] I5ab48fe70e49d104290f1c01014e4aa6420e300f\n\nChange-Id: I5c80a42fc61f2af7f18510f8275e25693b36e09f\n'}]",0,702917,c8b9716ccfb4ec10a57d58f2f1d7c339fb01912a,7,3,1,14070,,,0,"Release sphinx-feature-classification 1.0.0

Pick up support for feature.api [1].

Major bump as this is the first release since dropping py2 support [2].

[1] I36bde39742f7f3ee60ee10240d836c7083cfa0fd
[2] I5ab48fe70e49d104290f1c01014e4aa6420e300f

Change-Id: I5c80a42fc61f2af7f18510f8275e25693b36e09f
",git fetch https://review.opendev.org/openstack/releases refs/changes/17/702917/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/sphinx-feature-classification.yaml'],1,c8b9716ccfb4ec10a57d58f2f1d7c339fb01912a,sphinx-feature-classification_1.0.0, - version: 1.0.0 projects: - repo: openstack/sphinx-feature-classification hash: b7ae3661e0782a1254cd007fea2448fc3cb828bc,,4,0
openstack%2Fopenstack-ansible-ops~master~Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8,openstack/openstack-ansible-ops,master,Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8,Remove trusty job,MERGED,2020-01-16 08:11:44.000000000,2020-01-16 17:25:58.000000000,2020-01-16 17:21:59.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-01-16 08:11:44.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/77cd091b6d0aea58f4a840e1730ea7b435318e47', 'message': 'Remove trusty job\n\nUbuntu Trusty is getting removed from OpenDev Infrastructure, remove the\nnon-voting trusty job.\n\nChange-Id: Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8\n'}]",0,702815,77cd091b6d0aea58f4a840e1730ea7b435318e47,8,3,1,6547,,,0,"Remove trusty job

Ubuntu Trusty is getting removed from OpenDev Infrastructure, remove the
non-voting trusty job.

Change-Id: Ia7751e6ac51df49d49f0a7ef30f004865b44b2b8
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/15/702815/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,77cd091b6d0aea58f4a840e1730ea7b435318e47,trusty-removal,," name: ""openstack-ansible-ops:elk_metrics_6x-ubuntu-trusty"" parent: ""openstack-ansible-ops:elk_metrics_6x-ubuntu-xenial"" nodeset: ubuntu-trusty voting: false - job:",0,7
openstack%2Fneutron~master~Id3b8003f7c1f12f044276488e77d661a80916537,openstack/neutron,master,Id3b8003f7c1f12f044276488e77d661a80916537,DO NOT REVIEW: Test compiling OVS 2.12 from source in func tests,ABANDONED,2019-12-11 16:35:22.000000000,2020-01-16 16:53:35.000000000,,"[{'_account_id': 22348}, {'_account_id': 24791}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-12-11 16:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58c9e633002d7a9a656b98887f1e0048625b4df2', 'message': 'DO NOT REVIEW: Test compiling OVS 2.12 from source in func tests\n\nChange-Id: Id3b8003f7c1f12f044276488e77d661a80916537\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 2, 'created': '2019-12-12 09:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b0317b1554b0748faccb885dd8a4068ac6a783a', 'message': 'DO NOT REVIEW: Test compiling OVS 2.12 from source in func tests\n\nChange-Id: Id3b8003f7c1f12f044276488e77d661a80916537\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 3, 'created': '2019-12-12 09:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1f11d5b85fb437b49ddbc26f8ecfe55d20676c0', 'message': 'DO NOT REVIEW: Test compiling OVS 2.12 from source in func tests\n\nChange-Id: Id3b8003f7c1f12f044276488e77d661a80916537\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 4, 'created': '2019-12-12 10:18:29.000000000', 'files': ['tools/configure_for_func_testing.sh', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7306f72f3f3f006453f398d93c478dede550e81f', 'message': 'DO NOT REVIEW: Test compiling OVS 2.12 from source in func tests\n\nChange-Id: Id3b8003f7c1f12f044276488e77d661a80916537\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",1,698527,7306f72f3f3f006453f398d93c478dede550e81f,11,3,4,6773,,,0,"DO NOT REVIEW: Test compiling OVS 2.12 from source in func tests

Change-Id: Id3b8003f7c1f12f044276488e77d661a80916537
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/698527/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/configure_for_func_testing.sh', '.zuul.yaml']",2,58c9e633002d7a9a656b98887f1e0048625b4df2,test-ovs,," templates: - neutron-tempest-plugin-jobs - openstack-cover-jobs - openstack-lower-constraints-jobs - openstack-python3-ussuri-jobs - publish-openstack-docs-pti - periodic-stable-jobs - check-requirements - release-notes-jobs-python3 - neutron-fullstack - neutron-rally-task - neutron-tempest-dvr - neutron-tempest-linuxbridge - neutron-grenade-multinode - neutron-grenade-dvr-multinode - tempest-integrated-networking: # We don't run the job on things like neutron docs-only changes irrelevant-files: &tempest-irrelevant-files - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^neutron/locale/.*$ - ^neutron/tests/unit/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - ^vagrant/.*$ - ^migration/.*$ - tempest-multinode-full-py3: voting: false irrelevant-files: *tempest-irrelevant-files - neutron-tempest-dvr-ha-multinode-full - neutron-tempest-iptables_hybrid - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false irrelevant-files: *tempest-irrelevant-files - tempest-slow-py3: irrelevant-files: *tempest-irrelevant-files #- neutron-ovn-tempest-ovs-release - networking-midonet-tempest-aio-ml2-centos-7: voting: false irrelevant-files: *tempest-irrelevant-files - tempest-ipv6-only: irrelevant-files: *tempest-irrelevant-files - openstacksdk-functional-devstack-networking: voting: false - neutron-functional-with-uwsgi: voting: false - neutron-fullstack-with-uwsgi: voting: false - neutron-tempest-with-uwsgi: voting: false - neutron-centos-7-tripleo-standalone #- neutron-ovn-rally-task # TripleO jobs that deploy OVN. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # In Stein and beyond, fs010 will run using # networking-ovn-tripleo-ci-centos-7-containers-multinode. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. #- neutron-ovn-tripleo-ci-centos-7-containers-multinode - neutron-ovn-tempest-slow: voting: false - neutron-ovn-tempest-full-multinode-ovs-master: voting: false gate: jobs: - neutron-functional - neutron-fullstack - tempest-integrated-networking - neutron-tempest-dvr - neutron-tempest-linuxbridge - neutron-tempest-iptables_hybrid - neutron-grenade-multinode - neutron-grenade-dvr-multinode - tempest-slow-py3: irrelevant-files: *tempest-irrelevant-files - tempest-ipv6-only: irrelevant-files: *tempest-irrelevant-files #- neutron-ovn-tempest-ovs-release #- neutron-ovn-rally-task #- neutron-ovn-tripleo-ci-centos-7-containers-multinode experimental: jobs: - neutron-ovn-tempest-ovs-master - neutron-ovn-grenade periodic: jobs: - neutron-functional - neutron-tempest-postgres-full - neutron-tempest-mariadb-full - neutron-tempest-with-os-ken-master - neutron-ovn-tempest-ovs-master-fedora - job: name: neutron-fullstack parent: neutron-functional vars: tox_envlist: dsvm-fullstack zuul_copy_output: # We need to copy directory with logs to have it in job artifacts also, # /opt/stack/logs is default logs directory defined in neutron's # tox.ini file '{{ devstack_base_dir }}/logs/dsvm-fullstack-logs': logs - job: name: neutron-rally-task parent: rally-task-neutron timeout: 10800 vars: devstack_localrc: USE_PYTHON3: true OSPROFILER_COLLECTOR: redis OSPROFILER_HMAC_KEYS: ""neutron-hmac-key-used-in-zuul-ci"" rally_task: rally-jobs/task-neutron.yaml devstack_plugins: osprofiler: https://opendev.org/openstack/osprofiler rally-openstack: https://opendev.org/openstack/rally-openstack neutron: https://opendev.org/openstack/neutron devstack_services: neutron-trunk: true devstack_local_conf: post-config: $NEUTRON_CONF: DEFAULT: enable_code_profiling: True required-projects: - openstack/rally - openstack/rally-openstack - openstack/osprofiler irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^neutron/locale/.*$ - ^neutron/tests/unit/.*$ - ^releasenotes/.*$ - ^tools/.*$ - ^tox.ini$ - job: name: neutron-ovn-rally-task parent: rally-task-at-devstack required-projects: - name: openstack/devstack - name: openstack/devstack-gate - name: openstack/rally - name: openstack/rally-openstack - name: openstack/networking-ovn irrelevant-files: *tempest-irrelevant-files vars: devstack_plugins: rally-openstack: https://opendev.org/openstack/rally-openstack networking-ovn: https://opendev.org/openstack/networking-ovn zuul_copy_output: '{{ devstack_base_dir }}/data/ovs': 'logs' extensions_to_txt: db: true devstack_services: ovn-northd: true ovn-controller: true ovs-vswitchd: true ovsdb-server: true networking-ovn-metadata-agent: true br-ex-tcpdump: true br-int-flows: true q-dhcp: false q-l3: false q-agt: false q-meta: false q-metering: false devstack_localrc: USE_PYTHON3: true PHYSICAL_NETWORK: public Q_USE_PROVIDERNET_FOR_PUBLIC: true ENABLE_CHASSIS_AS_GW: true OVN_L3_CREATE_PUBLIC_NETWORK: true OVN_BRANCH: master devstack_local_conf: post-config: ""${RALLY_CONF_DIR}/${RALLY_CONF_FILE}"": openstack: neutron_bind_l2_agent_types: ""OVN Controller Gateway agent"" rally_task: rally-jobs/task-neutron.yaml timeout: 7800 - job: name: neutron-tempest-dvr parent: tempest-integrated-networking timeout: 10800 required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest vars: tempest_concurrency: 4 devstack_localrc: Q_DVR_MODE: dvr_snat irrelevant-files: *tempest-irrelevant-files - job: name: neutron-tempest-linuxbridge parent: tempest-integrated-networking timeout: 10800 required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest vars: tempest_concurrency: 4 devstack_localrc: Q_AGENT: linuxbridge irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^neutron/locale/.*$ - ^neutron/tests/.*$ - ^neutron/tests/unit/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - job: name: neutron-grenade-multinode parent: legacy-dsvm-base-multinode run: playbooks/legacy/neutron-grenade-multinode/run.yaml post-run: playbooks/legacy/neutron-grenade-multinode/post.yaml timeout: 10800 required-projects: - openstack/grenade - openstack/devstack-gate - openstack/neutron irrelevant-files: *tempest-irrelevant-files - job: name: neutron-grenade-dvr-multinode parent: legacy-dsvm-base-multinode run: playbooks/legacy/neutron-grenade-dvr-multinode/run.yaml post-run: playbooks/legacy/neutron-grenade-dvr-multinode/post.yaml timeout: 7500 required-projects: - openstack/grenade - openstack/devstack-gate - openstack/neutron irrelevant-files: *tempest-irrelevant-files - job: name: neutron-ovn-grenade parent: legacy-dsvm-base run: playbooks/legacy/neutron-ovn-grenade/run.yaml post-run: playbooks/legacy/neutron-ovn-grenade/post.yaml timeout: 9000 irrelevant-files: *tempest-irrelevant-files required-projects: - openstack/grenade - openstack/devstack-gate - openstack/neutron-tempest-plugin - openstack/tempest - openstack/networking-ovn - job: name: neutron-tempest-dvr-ha-multinode-full parent: tempest-multinode-full-py3 nodeset: openstack-three-node-bionic timeout: 10800 roles: - zuul: openstack/neutron-tempest-plugin required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest pre-run: playbooks/dvr-multinode-scenario-pre-run.yaml irrelevant-files: *tempest-irrelevant-files voting: false vars: devstack_local_conf: post-config: $NEUTRON_CONF: DEFAULT: router_distributed: True l3_ha: True # NOTE(slaweq): We can get rid of this hardcoded absolute path when # devstack-tempest job will be switched to use lib/neutron instead of # lib/neutron-legacy ""/$NEUTRON_CORE_PLUGIN_CONF"": ml2: mechanism_drivers: openvswitch,l2population agent: enable_distributed_routing: True l2_population: True tunnel_types: vxlan arp_responder: True ovs: tunnel_bridge: br-tun bridge_mappings: public:br-ex $NEUTRON_L3_CONF: DEFAULT: agent_mode: dvr agent: availability_zone: nova $NEUTRON_DHCP_CONF: agent: availability_zone: nova group-vars: subnode: devstack_services: q-agt: true q-l3: true q-meta: true devstack_localrc: USE_PYTHON3: true devstack_local_conf: post-config: $NEUTRON_CONF: DEFAULT: router_distributed: True # NOTE(slaweq): We can get rid of this hardcoded absolute path when # devstack-tempest job will be switched to use lib/neutron instead of # lib/neutron-legacy ""/$NEUTRON_CORE_PLUGIN_CONF"": agent: enable_distributed_routing: True l2_population: True tunnel_types: vxlan arp_responder: True ovs: tunnel_bridge: br-tun bridge_mappings: public:br-ex $NEUTRON_L3_CONF: DEFAULT: agent_mode: dvr_snat agent: availability_zone: nova - job: name: neutron-tempest-iptables_hybrid parent: tempest-integrated-networking timeout: 10800 required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest vars: tempest_concurrency: 4 devstack_plugins: neutron: https://opendev.org/openstack/neutron.git devstack_services: tls-proxy: false tempest: true neutron-dns: true neutron-qos: true neutron-segments: true neutron-trunk: true neutron-uplink-status-propagation: true devstack_local_conf: post-config: $NEUTRON_CONF: QUOTAS: quota_router: 100 quota_floatingip: 500 quota_security_group: 100 quota_security_group_rule: 1000 # NOTE(slaweq): We can get rid of this hardcoded absolute path when # devstack-tempest job will be switched to use lib/neutron instead of # lib/neutron-legacy ""/$NEUTRON_CORE_PLUGIN_CONF"": ml2_type_vlan: network_vlan_ranges: foo:1:10 agent: enable_distributed_routing: True l2_population: True tunnel_types: vxlan,gre arp_responder: True securitygroup: firewall_driver: iptables_hybrid $NEUTRON_L3_CONF: agent: availability_zone: nova $NEUTRON_DHCP_CONF: agent: availability_zone: nova test-config: $TEMPEST_CONFIG: neutron_plugin_options: provider_vlans: foo, agent_availability_zone: nova image_is_advanced: true available_type_drivers: flat,geneve,vlan,gre,local,vxlan irrelevant-files: *tempest-irrelevant-files - job: # TODO(slaweq): remove this job definition when all other projects will use # grenade-py3 instead name: neutron-grenade parent: legacy-dsvm-base run: playbooks/legacy/neutron-grenade/run.yaml post-run: playbooks/legacy/neutron-grenade/post.yaml timeout: 10800 required-projects: - openstack/grenade - openstack/devstack-gate - openstack/neutron irrelevant-files: *tempest-irrelevant-files - job: name: neutron-tempest-postgres-full parent: tempest-integrated-networking timeout: 7800 required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest vars: devstack_services: postgresql: true mysql: false irrelevant-files: *tempest-irrelevant-files - job: name: neutron-tempest-mariadb-full parent: tempest-integrated-networking timeout: 7800 required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest vars: devstack_localrc: MYSQL_SERVICE_NAME: mariadb irrelevant-files: *tempest-irrelevant-files - job: name: neutron-tempest-with-os-ken-master parent: tempest-integrated-networking timeout: 7800 required-projects: - openstack/devstack-gate - openstack/neutron - openstack/tempest - openstack/os-ken - job: name: neutron-fullstack-with-uwsgi parent: neutron-fullstack vars: devstack_localrc: NEUTRON_DEPLOY_MOD_WSGI: true - job: name: neutron-functional-with-uwsgi parent: neutron-functional vars: devstack_localrc: NEUTRON_DEPLOY_MOD_WSGI: true - job: name: neutron-tempest-with-uwsgi parent: tempest-integrated-networking description: Run neutron Tempest tests with uwsgi timeout: 8400 vars: devstack_localrc: NEUTRON_DEPLOY_MOD_WSGI: true irrelevant-files: *tempest-irrelevant-files - job: name: neutron-centos-7-tripleo-standalone parent: tripleo-ci-base-standalone nodeset: single-centos-7-node voting: false vars: featureset: '052' featureset_override: standalone_environment_files: - 'environments/services/neutron-ovs.yaml' tempest_test_whitelist: - 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_network_basic_ops' irrelevant-files: *tempest-irrelevant-files - job: name: neutron-ovn-tripleo-ci-centos-7-containers-multinode parent: tripleo-ci-base-multinode vars: nodes: 1ctlr featureset: '010' irrelevant-files: *tempest-irrelevant-files - job: name: neutron-ovn-grenade parent: legacy-dsvm-base run: playbooks/legacy/grenade-dsvm-networking-ovn/run.yaml post-run: playbooks/legacy/grenade-dsvm-networking-ovn/post.yaml timeout: 9000 irrelevant-files: *tempest-irrelevant-files required-projects: - openstack/grenade - openstack/devstack-gate - openstack/neutron-tempest-plugin - openstack/tempest - openstack/networking-ovn - job: name: neutron-ovn-base description: Base job for devstack/tempest to test Neutron with ovn driver. # TODO(slaweq): consider changing parent to be tempest-integrated-networking # job instead of devstack-tempest parent: devstack-tempest timeout: 10800 required-projects: - openstack/devstack-gate - openstack/networking-ovn - openstack/neutron - openstack/neutron-tempest-plugin - openstack/octavia - openstack/tempest irrelevant-files: *tempest-irrelevant-files vars: tox_envlist: all-plugin tempest_test_regex: ""^(?!.*\ (?:.*\\[.*slow.*\\])|\ (?:tempest.api.network.admin.test_quotas.QuotasTest.test_lbaas_quotas.*)|\ (?:tempest.api.network.test_load_balancer.*)|\ (?:tempest.scenario.test_load_balancer.*)|\ (?:tempest.api.network.admin.test_load_balancer.*)|\ (?:tempest.api.network.admin.test_lbaas.*)|\ (?:tempest.api.network.test_fwaas_extensions.*)|\ (?:tempest.api.network.test_metering_extensions.*)|\ (?:tempest.thirdparty.boto.test_s3.*)|\ (?:tempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_port_security_macspoofing_port)|\ (?:tempest.api.identity*)|\ (?:tempest.api.image*)|\ (?:tempest.api.volume*)|\ (?:tempest.api.compute.images*)|\ (?:tempest.api.compute.keypairs*)|\ (?:tempest.api.compute.certificates*)|\ (?:tempest.api.compute.flavors*)|\ (?:tempest.api.compute.test_quotas*)|\ (?:tempest.api.compute.test_versions*)|\ (?:tempest.api.compute.volumes*)|\ (?:tempest.api.compute.admin.test_flavor*)|\ (?:tempest.api.compute.admin.test_volume*)|\ (?:tempest.api.compute.admin.test_hypervisor*)|\ (?:tempest.api.compute.admin.test_aggregate*)|\ (?:tempest.api.compute.admin.test_quota*)|\ (?:tempest.scenario.test_volume*))\ ((^neutron_tempest_plugin.api)|\ (^neutron_tempest_plugin.scenario)|\ (tempest.(api|scenario|thirdparty))).*$"" tempest_concurrency: 2 devstack_localrc: Q_USE_PROVIDERNET_FOR_PUBLIC: true PHYSICAL_NETWORK: public ENABLE_CHASSIS_AS_GW: true OVN_L3_CREATE_PUBLIC_NETWORK: true OVN_DBS_LOG_LEVEL: dbg USE_PYTHON3: True DOWNLOAD_DEFAULT_IMAGES: false IMAGE_URLS: ""http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img,https://cloud-images.ubuntu.com/releases/xenial/release/ubuntu-16.04-server-cloudimg-amd64-disk1.img"" DEFAULT_IMAGE_NAME: cirros-0.4.0-x86_64-disk DEFAULT_IMAGE_FILE_NAME: cirros-0.4.0-x86_64-disk.img ADVANCED_IMAGE_NAME: ubuntu-16.04-server-cloudimg-amd64-disk1 ADVANCED_INSTANCE_TYPE: ds512M ADVANCED_INSTANCE_USER: ubuntu BUILD_TIMEOUT: 784 devstack_plugins: networking-ovn: https://opendev.org/openstack/networking-ovn neutron-tempest-plugin: https://opendev.org/openstack/neutron-tempest-plugin octavia: https://opendev.org/openstack/octavia zuul_copy_output: '{{ devstack_base_dir }}/data/ovs': 'logs' extensions_to_txt: db: true devstack_services: br-ex-tcpdump: true br-int-flows: true c-api: true c-sch: true c-vol: true dstat: true g-api: true g-reg: true keystone: true n-api-meta: true n-api: true n-cauth: true n-cond-cell1: true n-cpu: true n-novnc-cell1: true n-sch: true n-super-cond: true networking-ovn-metadata-agent: true o-api: true o-hk: true ovn-controller: true ovn-northd: true ovn-octavia: true ovs-vswitchd: true ovsdb-server: true placement-api: true q-svc: true q-dns: true c-bak: false etcd: false peakmem_tracker: false q-agt: false q-dhcp: false q-l3: false q-meta: false q-metering: false s-account: false s-container-sync: false s-container: false s-object: false s-proxy: false - job: name: neutron-ovn-tempest-ovs-master description: Job testing for devstack/tempest testing Neutron with ovn driver and OVN master branch parent: neutron-ovn-base vars: devstack_localrc: OVN_BRANCH: master - job: name: neutron-ovn-tempest-ovs-release description: Job testing for devstack/tempest testing Neutron with ovn driver and latest released OVN branch parent: neutron-ovn-base vars: devstack_localrc: OVN_BRANCH: branch-2.12 - job: name: neutron-ovn-tempest-ovs-master-fedora description: Job testing for devstack/tempest testing Neutron with ovn driver and OVN master branch and Fedora parent: neutron-ovn-tempest-ovs-master nodeset: devstack-single-node-fedora-latest - job: name: neutron-ovn-multinode-base description: Base multinode job for devstack/tempest to test Neutron with ovn driver. abstract: true parent: tempest-multinode-full-py3 timeout: 10800 required-projects: - openstack/devstack-gate - openstack/networking-ovn - openstack/neutron - openstack/neutron-tempest-plugin - openstack/octavia - openstack/tempest irrelevant-files: *tempest-irrelevant-files roles: - zuul: zuul/zuul-jobs - zuul: openstack/neutron-tempest-plugin pre-run: playbooks/multinode-setup.yaml vars: devstack_localrc: Q_USE_PROVIDERNET_FOR_PUBLIC: true PHYSICAL_NETWORK: public ENABLE_CHASSIS_AS_GW: true OVN_L3_CREATE_PUBLIC_NETWORK: true OVN_DBS_LOG_LEVEL: dbg DOWNLOAD_DEFAULT_IMAGES: false IMAGE_URLS: ""http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img,https://cloud-images.ubuntu.com/releases/xenial/release/ubuntu-16.04-server-cloudimg-amd64-disk1.img"" DEFAULT_IMAGE_NAME: cirros-0.4.0-x86_64-disk DEFAULT_IMAGE_FILE_NAME: cirros-0.4.0-x86_64-disk.img ADVANCED_IMAGE_NAME: ubuntu-16.04-server-cloudimg-amd64-disk1 ADVANCED_INSTANCE_TYPE: ds512M ADVANCED_INSTANCE_USER: ubuntu BUILD_TIMEOUT: 784 devstack_plugins: networking-ovn: https://opendev.org/openstack/networking-ovn neutron-tempest-plugin: https://opendev.org/openstack/neutron-tempest-plugin octavia: https://opendev.org/openstack/octavia zuul_copy_output: '{{ devstack_base_dir }}/data/ovs': 'logs' extensions_to_txt: db: true devstack_services: c-bak: false etcd: false br-ex-tcpdump: true br-int-flows: true networking-ovn-metadata-agent: true o-api: true o-hk: true ovn-controller: true ovn-northd: true ovn-octavia: true ovs-vswitchd: true ovsdb-server: true placement-api: true peakmem_tracker: false q-svc: true q-agt: false q-dhcp: false q-l3: false q-meta: false q-metering: false # When running python3 Swift should be disabled for now s-account: false s-container: false s-object: false s-proxy: false group-vars: subnode: devstack_services: ovn-controller: true ovn-northd: false ovn-octavia: false ovs-vswitchd: true ovsdb-server: true # NOTE(slaweq): it's just to check if this will force devstack to # configure neutron and ML2 plugin on subnodes q-fake: true q-svc: false q-agt: false q-dhcp: false q-l3: false q-meta: false q-metering: false networking-ovn-metadata-agent: true devstack_localrc: Q_USE_PROVIDERNET_FOR_PUBLIC: true PHYSICAL_NETWORK: public ENABLE_CHASSIS_AS_GW: false OVN_DBS_LOG_LEVEL: dbg USE_PYTHON3: True - job: name: neutron-ovn-tempest-slow parent: neutron-ovn-multinode-base vars: tox_envlist: slow-serial tempest_test_regex: """" # TODO(slaweq): remove test_port_security_macspoofing_port test from # blacklist when bug https://bugs.launchpad.net/tempest/+bug/1728886 # will be fixed tempest_black_regex: ""(?:tempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_port_security_macspoofing_port)"" - job: # TODO(slaweq): propose job with ovs-release and move -master one to # experimental queue name: neutron-ovn-tempest-full-multinode-ovs-master parent: neutron-ovn-multinode-base vars: tox_envlist: all-plugin tempest_test_regex: ""^(?!.*\ (?:.*\\[.*slow.*\\])|\ (?:tempest.api.network.admin.test_quotas.QuotasTest.test_lbaas_quotas.*)|\ (?:tempest.api.network.test_load_balancer.*)|\ (?:tempest.scenario.test_load_balancer.*)|\ (?:tempest.api.network.admin.test_load_balancer.*)|\ (?:tempest.api.network.admin.test_lbaas.*)|\ (?:tempest.api.network.test_fwaas_extensions.*)|\ (?:tempest.api.network.test_metering_extensions.*)|\ (?:tempest.thirdparty.boto.test_s3.*)|\ (?:tempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_port_security_macspoofing_port)|\ (?:tempest.api.identity*)|\ (?:tempest.api.image*)|\ (?:tempest.api.volume*)|\ (?:tempest.api.compute.images*)|\ (?:tempest.api.compute.keypairs*)|\ (?:tempest.api.compute.certificates*)|\ (?:tempest.api.compute.flavors*)|\ (?:tempest.api.compute.test_quotas*)|\ (?:tempest.api.compute.test_versions*)|\ (?:tempest.api.compute.volumes*)|\ (?:tempest.api.compute.admin.test_flavor*)|\ (?:tempest.api.compute.admin.test_volume*)|\ (?:tempest.api.compute.admin.test_hypervisor*)|\ (?:tempest.api.compute.admin.test_aggregate*)|\ (?:tempest.api.compute.admin.test_quota*)|\ (?:tempest.scenario.test_volume*))\ ((^neutron_tempest_plugin.api)|\ (^neutron_tempest_plugin.scenario)|\ (tempest.(api|scenario|thirdparty))).*$"" # TODO(slaweq): live_migration related test from the blacklist when bug # https://bugzilla.redhat.com/show_bug.cgi?id=1716335 will be fixed tempest_black_regex: ""\ (^tempest.api.compute.admin.test_live_migration.LiveAutoBlockMigrationV225Test)|\ (^tempest.api.compute.admin.test_live_migration.LiveMigrationTest)"" devstack_localrc: OVN_BRANCH: master group-vars: subnode: devstack_localrc: OVN_BRANCH: master",6,796
openstack%2Fsphinx-feature-classification~master~I7202d1b481ee9ec43dde25f735dde221abbc5360,openstack/sphinx-feature-classification,master,I7202d1b481ee9ec43dde25f735dde221abbc5360,Set ignore_basepython_conflict,ABANDONED,2020-01-14 19:35:34.000000000,2020-01-16 16:40:09.000000000,,"[{'_account_id': 6928}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 19:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sphinx-feature-classification/commit/f0f0580d39c791f9ae134fa8e57b26866c2b8af4', 'message': 'Set ignore_basepython_conflict\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nChange-Id: I7202d1b481ee9ec43dde25f735dde221abbc5360\n'}, {'number': 2, 'created': '2020-01-14 19:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sphinx-feature-classification/commit/811843e40361f24ffd819024991eab9a7b782869', 'message': 'Set ignore_basepython_conflict\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nChange-Id: I7202d1b481ee9ec43dde25f735dde221abbc5360\n'}, {'number': 3, 'created': '2020-01-14 21:28:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/sphinx-feature-classification/commit/2553d36ebb5eabdee9aa35368fda989e4a56cdce', 'message': 'Set ignore_basepython_conflict\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nChange-Id: I7202d1b481ee9ec43dde25f735dde221abbc5360\n'}]",2,702505,2553d36ebb5eabdee9aa35368fda989e4a56cdce,14,4,3,14070,,,0,"Set ignore_basepython_conflict

Automatic envs (pyXX) will only use the python version appropriate to
that env and ignore basepython inherited from [testenv] if we set
ignore_basepython_conflict.

Change-Id: I7202d1b481ee9ec43dde25f735dde221abbc5360
",git fetch https://review.opendev.org/openstack/sphinx-feature-classification refs/changes/05/702505/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f0f0580d39c791f9ae134fa8e57b26866c2b8af4,ignore_basepython_conflict,# Automatic envs (pyXX) will only use the python version appropriate to that # env and ignore basepython inherited from [testenv] if we set # ignore_basepython_conflict. ignore_basepython_conflict = True,,4,0
openstack%2Ftripleo-ansible~stable%2Ftrain~Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c,openstack/tripleo-ansible,stable/train,Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c,Remove dracut-config-generic package,MERGED,2020-01-16 00:50:23.000000000,2020-01-16 16:36:29.000000000,2020-01-16 16:36:29.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-16 00:50:23.000000000', 'files': ['tripleo_ansible/roles/tripleo-kernel/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b48ed8c834f5b470e50be3beba12d0d5f2745e61', 'message': ""Remove dracut-config-generic package\n\nIn LP#1830574, we introduce the dracut command to include necessary\nfile into initramfs. However, dracut in RHEL or CentOS doesn't include\nsysctl.conf or other specific module related confs at an installation\nof new kernel if dracut-config-generic package exists on the system.\n\nWe should remove the package to allow creating a host-specific initramfs\nat an installation of new kernel.\n\nCloses-bug: #1857493\n\nChange-Id: Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c\nCo-Authored-By: Keigo Noha <knoha@redhat.com>\n(cherry picked from commit 4586da96b4aab1cbbe22bb4619025dcfb03ab899)\n""}]",0,702779,b48ed8c834f5b470e50be3beba12d0d5f2745e61,10,6,1,25613,,,0,"Remove dracut-config-generic package

In LP#1830574, we introduce the dracut command to include necessary
file into initramfs. However, dracut in RHEL or CentOS doesn't include
sysctl.conf or other specific module related confs at an installation
of new kernel if dracut-config-generic package exists on the system.

We should remove the package to allow creating a host-specific initramfs
at an installation of new kernel.

Closes-bug: #1857493

Change-Id: Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c
Co-Authored-By: Keigo Noha <knoha@redhat.com>
(cherry picked from commit 4586da96b4aab1cbbe22bb4619025dcfb03ab899)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/79/702779/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-kernel/tasks/main.yml'],1,b48ed8c834f5b470e50be3beba12d0d5f2745e61,1857493-remove_dracut_config_generic-stable/train, - name: Remove dracut-config-generic package: name: 'dracut-config-generic' state: absent ,,5,0
openstack%2Fcharm-octavia~master~Ife892cf5f5fd1fdf277a29900620956a30a25761,openstack/charm-octavia,master,Ife892cf5f5fd1fdf277a29900620956a30a25761,Handle bad request in transition to TLS deployment,MERGED,2019-08-27 10:57:59.000000000,2020-01-16 16:32:02.000000000,2020-01-16 16:32:02.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-27 10:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/51457206241e49013716c28118de5dd007795c46', 'message': 'Handle bad request in transition to TLS deployment\n\nIn some situations it appears the Neutron service expects TLS\nconnections prior to updating the Keystone service catalog.\n\nWhile this is a transitional erroneous configuration of the\ndeployment, add the exception to the list of expected transient\nfailures to cope with the situation and avoid hook errors.\n\nChange-Id: Ife892cf5f5fd1fdf277a29900620956a30a25761\nCloses-Bug: #1819593\n'}, {'number': 2, 'created': '2019-08-28 06:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/e6ab00470cd2b4a04437d0cfe404d688132ce237', 'message': 'Handle bad request in transition to TLS deployment\n\nIn some situations it appears the Neutron service expects TLS\nconnections prior to updating the Keystone service catalog.\n\nWhile this is a transitional erroneous configuration of the\ndeployment, add the exception to the list of expected transient\nfailures to cope with the situation and avoid hook errors.\n\nChange-Id: Ife892cf5f5fd1fdf277a29900620956a30a25761\nCloses-Bug: #1819593\n'}, {'number': 3, 'created': '2019-09-03 10:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/5d63c472613d8d0587329b970db0074ba3d85d23', 'message': 'Handle bad request in transition to TLS deployment\n\nIn some situations it appears the Neutron service expects TLS\nconnections prior to updating the Keystone service catalog.\n\nWhile this is a transitional erroneous configuration of the\ndeployment, add the exception to the list of expected transient\nfailures to cope with the situation and avoid hook errors.\n\nChange-Id: Ife892cf5f5fd1fdf277a29900620956a30a25761\nCloses-Bug: #1819593\n'}, {'number': 4, 'created': '2020-01-15 10:44:54.000000000', 'files': ['src/lib/charm/openstack/api_crud.py'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/15e56091b2e2b1b1794e37697235f4313841c845', 'message': 'Handle bad request in transition to TLS deployment\n\nIn some situations it appears the Neutron service expects TLS\nconnections prior to updating the Keystone service catalog.\n\nWhile this is a transitional erroneous configuration of the\ndeployment, add the exception to the list of expected transient\nfailures to cope with the situation and avoid hook errors.\n\nChange-Id: Ife892cf5f5fd1fdf277a29900620956a30a25761\nCloses-Bug: #1819593\n'}]",0,678790,15e56091b2e2b1b1794e37697235f4313841c845,27,5,4,13686,,,0,"Handle bad request in transition to TLS deployment

In some situations it appears the Neutron service expects TLS
connections prior to updating the Keystone service catalog.

While this is a transitional erroneous configuration of the
deployment, add the exception to the list of expected transient
failures to cope with the situation and avoid hook errors.

Change-Id: Ife892cf5f5fd1fdf277a29900620956a30a25761
Closes-Bug: #1819593
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/90/678790/2 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/api_crud.py'],1,51457206241e49013716c28118de5dd007795c46,test-api-tls," neutronclient.common.exceptions.ServiceUnavailable, neutronclient.common.exceptions.BadRequest)", neutronclient.common.exceptions.ServiceUnavailable),2,1
openstack%2Fcharm-glance~master~I9544ecb2ecb5306be30d915835f60e48315858d3,openstack/charm-glance,master,I9544ecb2ecb5306be30d915835f60e48315858d3,Sync charmhelpers,MERGED,2020-01-16 15:01:36.000000000,2020-01-16 16:30:59.000000000,2020-01-16 16:30:59.000000000,"[{'_account_id': 12549}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 15:01:36.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/f3aafbb1829f4e9a3052a5104f1824ecacebafd7', 'message': 'Sync charmhelpers\n\nChange-Id: I9544ecb2ecb5306be30d915835f60e48315858d3\n'}]",0,702887,f3aafbb1829f4e9a3052a5104f1824ecacebafd7,9,4,1,12549,,,0,"Sync charmhelpers

Change-Id: I9544ecb2ecb5306be30d915835f60e48315858d3
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/87/702887/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/audits/openstack_security_guide.py', 'charmhelpers/contrib/openstack/vaultlocker.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/charmsupport/nrpe.py', 'charmhelpers/contrib/openstack/ha/utils.py', 'charmhelpers/contrib/openstack/templates/section-placement']",10,f3aafbb1829f4e9a3052a5104f1824ecacebafd7,ch-sync,"[placement] {% if auth_host -%} auth_url = {{ auth_protocol }}://{{ auth_host }}:{{ auth_port }} auth_type = password {% if api_version == ""3"" -%} project_domain_name = {{ admin_domain_name }} user_domain_name = {{ admin_domain_name }} {% else -%} project_domain_name = default user_domain_name = default {% endif -%} project_name = {{ admin_tenant_name }} username = {{ admin_user }} password = {{ admin_password }} {% endif -%} {% if region -%} os_region_name = {{ region }} {% endif -%} randomize_allocation_candidates = true ",,494,153
openstack%2Frequirements~master~I8f76b6b486993637228e6893c792cfa6ffada3bd,openstack/requirements,master,I8f76b6b486993637228e6893c792cfa6ffada3bd,Remove trusty wheel build jobs,MERGED,2020-01-15 23:16:33.000000000,2020-01-16 16:25:06.000000000,2020-01-16 16:20:40.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 23:16:33.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5ba28d145c535fc1ce6efb18e45da9269cf9138a', 'message': 'Remove trusty wheel build jobs\n\nIn prepartion for Trusty node removal, stop testing wheel builds in\nrequirements.\n\nChange-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd\n'}]",0,702773,5ba28d145c535fc1ce6efb18e45da9269cf9138a,12,4,1,7118,,,0,"Remove trusty wheel build jobs

In prepartion for Trusty node removal, stop testing wheel builds in
requirements.

Change-Id: I8f76b6b486993637228e6893c792cfa6ffada3bd
",git fetch https://review.opendev.org/openstack/requirements refs/changes/73/702773/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,5ba28d145c535fc1ce6efb18e45da9269cf9138a,trusty-removal,, - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt - build-wheel-mirror-ubuntu-trusty: files: - bindep.txt,0,6
openstack%2Fgovernance-sigs~master~Iefea4a0b69b7fb1937a896dcc9a9199ed7b0fc27,openstack/governance-sigs,master,Iefea4a0b69b7fb1937a896dcc9a9199ed7b0fc27,Add more details in 'advisory' SIG status,MERGED,2019-12-13 16:35:04.000000000,2020-01-16 16:22:51.000000000,2020-01-16 16:19:45.000000000,"[{'_account_id': 308}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-13 16:35:04.000000000', 'files': ['doc/source/reference/sig-status.rst'], 'web_link': 'https://opendev.org/openstack/governance-sigs/commit/f56c7e8542f0ca09010b0a69e81ec9857a72d2d3', 'message': ""Add more details in 'advisory' SIG status\n\nChange-Id: Iefea4a0b69b7fb1937a896dcc9a9199ed7b0fc27\n""}]",0,698956,f56c7e8542f0ca09010b0a69e81ec9857a72d2d3,10,5,1,8556,,,0,"Add more details in 'advisory' SIG status

Change-Id: Iefea4a0b69b7fb1937a896dcc9a9199ed7b0fc27
",git fetch https://review.opendev.org/openstack/governance-sigs refs/changes/56/698956/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/sig-status.rst'],1,f56c7e8542f0ca09010b0a69e81ec9857a72d2d3,,The SIG will keep the owned repository or documents up to date and will accept updates on-demand. ,,3,0
openstack%2Fgovernance-sigs~master~I0a6e396370b4e9a7d091fdda7c653ed4d4b61b88,openstack/governance-sigs,master,I0a6e396370b4e9a7d091fdda7c653ed4d4b61b88,Add Tony Breeds as Multi-Arch SIG chair,MERGED,2020-01-16 13:51:53.000000000,2020-01-16 16:20:48.000000000,2020-01-16 16:18:40.000000000,"[{'_account_id': 308}, {'_account_id': 8125}, {'_account_id': 12404}, {'_account_id': 12898}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2020-01-16 13:51:53.000000000', 'files': ['sigs.yaml'], 'web_link': 'https://opendev.org/openstack/governance-sigs/commit/c7dbdb5a2b5e3b6ead54b0ace13f8c61cc5097e5', 'message': 'Add Tony Breeds as Multi-Arch SIG chair\n\nChange-Id: I0a6e396370b4e9a7d091fdda7c653ed4d4b61b88\n'}]",0,702867,c7dbdb5a2b5e3b6ead54b0ace13f8c61cc5097e5,11,7,1,12404,,,0,"Add Tony Breeds as Multi-Arch SIG chair

Change-Id: I0a6e396370b4e9a7d091fdda7c653ed4d4b61b88
",git fetch https://review.opendev.org/openstack/governance-sigs refs/changes/67/702867/1 && git format-patch -1 --stdout FETCH_HEAD,['sigs.yaml'],1,c7dbdb5a2b5e3b6ead54b0ace13f8c61cc5097e5,update-sigs, - name: Tony Breeds irc: tonyb email: tony@bakeyournoodle.com,,3,0
openstack%2Foctavia~master~I6a550692ca229d259bfe8efe528c561e2f1c11bd,openstack/octavia,master,I6a550692ca229d259bfe8efe528c561e2f1c11bd,Fix certfs-ramfs on cryptsetup>=2.1.0,ABANDONED,2020-01-16 14:19:21.000000000,2020-01-16 16:15:38.000000000,,[{'_account_id': 6469}],"[{'number': 1, 'created': '2020-01-16 14:19:21.000000000', 'files': ['releasenotes/notes/fix-certfs-ramfs-new-cryptsetup-4227bf5d8d7a20c5.yaml', 'elements/certs-ramfs/static/usr/local/bin/certfs-ramfs'], 'web_link': 'https://opendev.org/openstack/octavia/commit/347035d0bff12d28e2962a897edda8aa18f47ad4', 'message': 'Fix certfs-ramfs on cryptsetup>=2.1.0\n\nhttps://mirrors.edge.kernel.org/pub/linux/utils/cryptsetup/v2.1/v2.1.0-ReleaseNotes\n\nChange-Id: I6a550692ca229d259bfe8efe528c561e2f1c11bd\n'}]",0,702871,347035d0bff12d28e2962a897edda8aa18f47ad4,3,1,1,6469,,,0,"Fix certfs-ramfs on cryptsetup>=2.1.0

https://mirrors.edge.kernel.org/pub/linux/utils/cryptsetup/v2.1/v2.1.0-ReleaseNotes

Change-Id: I6a550692ca229d259bfe8efe528c561e2f1c11bd
",git fetch https://review.opendev.org/openstack/octavia refs/changes/71/702871/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-certfs-ramfs-new-cryptsetup-4227bf5d8d7a20c5.yaml', 'elements/certs-ramfs/static/usr/local/bin/certfs-ramfs']",2,347035d0bff12d28e2962a897edda8aa18f47ad4,,"echo -n ""${passphrase}"" | cryptsetup --pbkdf-memory=262144 --offset 8192 luksFormat /dev/ram0 -","echo -n ""${passphrase}"" | cryptsetup --pbkdf-memory=262144 luksFormat /dev/ram0 -",6,1
openstack%2Fstorlets~master~Iba582c226f91456e95bae1aaf2a7b388f6e1388e,openstack/storlets,master,Iba582c226f91456e95bae1aaf2a7b388f6e1388e,Use https://repo.maven.apache.org/maven2/ to retrieve jar files,MERGED,2020-01-16 14:20:27.000000000,2020-01-16 16:08:22.000000000,2020-01-16 16:05:59.000000000,"[{'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 14:20:27.000000000', 'files': ['src/java/build.xml'], 'web_link': 'https://opendev.org/openstack/storlets/commit/62cf0e55c75495be685742d094d126111971bd00', 'message': 'Use https://repo.maven.apache.org/maven2/ to retrieve jar files\n\nThe Central Repository has migrated to new HTTPS version[1].\nUpdate urls to retrive jar packages accordingly.\n\n[1] https://support.sonatype.com/hc/en-us/articles/360041287334\n\nChange-Id: Iba582c226f91456e95bae1aaf2a7b388f6e1388e\n'}]",0,702872,62cf0e55c75495be685742d094d126111971bd00,9,3,1,9816,,,0,"Use https://repo.maven.apache.org/maven2/ to retrieve jar files

The Central Repository has migrated to new HTTPS version[1].
Update urls to retrive jar packages accordingly.

[1] https://support.sonatype.com/hc/en-us/articles/360041287334

Change-Id: Iba582c226f91456e95bae1aaf2a7b388f6e1388e
",git fetch https://review.opendev.org/openstack/storlets refs/changes/72/702872/1 && git format-patch -1 --stdout FETCH_HEAD,['src/java/build.xml'],1,62cf0e55c75495be685742d094d126111971bd00,mvn-central-repo," <get src=""https://repo1.maven.org/maven2/com/googlecode/json-simple/json-simple/1.1/json-simple-1.1.jar"" <get src=""https://repo1.maven.org/maven2/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar"" <get src=""https://repo1.maven.org/maven2/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar"" <get src=""https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.7/slf4j-api-1.7.7.jar"""," <get src=""http://central.maven.org/maven2/com/googlecode/json-simple/json-simple/1.1/json-simple-1.1.jar"" <get src=""http://central.maven.org/maven2/ch/qos/logback/logback-classic/1.1.2/logback-classic-1.1.2.jar"" <get src=""http://central.maven.org/maven2/ch/qos/logback/logback-core/1.1.2/logback-core-1.1.2.jar"" <get src=""http://central.maven.org/maven2/org/slf4j/slf4j-api/1.7.7/slf4j-api-1.7.7.jar""",4,4
openstack%2Fpuppet-nova~master~Icc5ca7dd9129d3bb61357baa1be7468cb7c842ed,openstack/puppet-nova,master,Icc5ca7dd9129d3bb61357baa1be7468cb7c842ed,Remove deprecated nova::network::neutron params,MERGED,2020-01-14 09:45:19.000000000,2020-01-16 16:03:26.000000000,2020-01-16 16:02:05.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 09:45:19.000000000', 'files': ['spec/classes/nova_network_neutron_spec.rb', 'releasenotes/notes/remove-deprecated-network-neutron-3e31bdda08e9068f.yaml', 'manifests/network/neutron.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7c7e07027a11b23c41f02e9f342b85825ca134bd', 'message': 'Remove deprecated nova::network::neutron params\n\nChange-Id: Icc5ca7dd9129d3bb61357baa1be7468cb7c842ed\n'}]",0,702382,7c7e07027a11b23c41f02e9f342b85825ca134bd,8,3,1,16137,,,0,"Remove deprecated nova::network::neutron params

Change-Id: Icc5ca7dd9129d3bb61357baa1be7468cb7c842ed
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/82/702382/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_network_neutron_spec.rb', 'releasenotes/notes/remove-deprecated-network-neutron-3e31bdda08e9068f.yaml', 'manifests/network/neutron.pp']",3,7c7e07027a11b23c41f02e9f342b85825ca134bd,, 'neutron/timeout': value => $neutron_timeout;," $neutron_url = undef, $neutron_url_timeout = undef, $firewall_driver = undef, if $neutron_url { warning('nova::network::neutron::neutron_url is deprecated, nova behaviour will be default to looking up \ the neutron endpoint in the keystone catalog, please use nova::network::neutron::neutron_endpoint_override to override') } if $neutron_url_timeout { warning('nova::network::neutron::neutron_url_timeout is deprecated, please use neutron_timeout instead.') } if $firewall_driver { warning('nova::network::neutron::firewall_driver is deprecated and will be removed in a future release') } # TODO(tobias-urdin): Remove these in the T release. nova_config { 'DEFAULT/firewall_driver': value => $firewall_driver; } nova_config { 'neutron/url': value => $neutron_url; } $neutron_timeout_real = pick($neutron_url_timeout, $neutron_timeout) 'neutron/timeout': value => $neutron_timeout_real;",11,39
openstack%2Fneutron~master~I911469d46fccf13bc7ead7a103a7d6e4e0ede7c3,openstack/neutron,master,I911469d46fccf13bc7ead7a103a7d6e4e0ede7c3,Complete dropping py27 support goal,MERGED,2020-01-07 17:43:13.000000000,2020-01-16 16:01:16.000000000,2020-01-16 15:57:37.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2020-01-07 17:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d10850ccb2f5102ff7e3fe081a806b101a47548', 'message': 'Complete dropping py27 support goal\n\nThis takes care of the last details for dropping py27 support by adding\na proper min version of python in setup.cfg and removing basepython =\npython3 lines in tox.ini.\n\nChange-Id: I911469d46fccf13bc7ead7a103a7d6e4e0ede7c3\n'}, {'number': 2, 'created': '2020-01-13 18:04:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efe94b7fd6a10ba70f242e6d187e2a66bf03f06b', 'message': 'Complete dropping py27 support goal\n\nThis takes care of the last details for dropping py27 support by adding\na proper min version of python in setup.cfg and removing basepython =\npython3 lines in tox.ini.\n\nChange-Id: I911469d46fccf13bc7ead7a103a7d6e4e0ede7c3\n'}, {'number': 3, 'created': '2020-01-15 08:25:51.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/620adfe75304c84b1e3433d0c3b1ba3ea3570172', 'message': 'Complete dropping py27 support goal\n\nThis takes care of the last details for dropping py27 support by adding\na proper min version of python in setup.cfg.\n\nChange-Id: I911469d46fccf13bc7ead7a103a7d6e4e0ede7c3\n'}]",6,701409,620adfe75304c84b1e3433d0c3b1ba3ea3570172,33,10,3,13995,,,0,"Complete dropping py27 support goal

This takes care of the last details for dropping py27 support by adding
a proper min version of python in setup.cfg.

Change-Id: I911469d46fccf13bc7ead7a103a7d6e4e0ede7c3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/701409/3 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,7d10850ccb2f5102ff7e3fe081a806b101a47548,drop-py27-support,,basepython = python3,1,1
openstack%2Fkolla-ansible~stable%2Fstein~I09844e0807a93d9edd8d014276b0174d77a993a0,openstack/kolla-ansible,stable/stein,I09844e0807a93d9edd8d014276b0174d77a993a0,Fix fernet-node-sync error catching,MERGED,2020-01-10 08:55:08.000000000,2020-01-16 15:54:48.000000000,2020-01-16 15:51:29.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-10 08:55:08.000000000', 'files': ['ansible/roles/keystone/templates/fernet-node-sync.sh.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a955f323afae93956795519c38f009ed003a3b14', 'message': 'Fix fernet-node-sync error catching\n\nChange-Id: I09844e0807a93d9edd8d014276b0174d77a993a0\n'}]",0,701906,a955f323afae93956795519c38f009ed003a3b14,13,4,1,30491,,,0,"Fix fernet-node-sync error catching

Change-Id: I09844e0807a93d9edd8d014276b0174d77a993a0
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/06/701906/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/keystone/templates/fernet-node-sync.sh.j2'],1,a955f323afae93956795519c38f009ed003a3b14,fetch_fernet_fail-stable/train-stable/stein,set -o errexit set -o pipefail ,,3,0
openstack%2Fcharm-octavia~master~I1d91741eeec9b20b80bbb907a8aeb9166831acbe,openstack/charm-octavia,master,I1d91741eeec9b20b80bbb907a8aeb9166831acbe,Add support for setting amphora ssh key,MERGED,2019-12-06 10:44:01.000000000,2020-01-16 15:52:40.000000000,2020-01-16 15:52:40.000000000,"[{'_account_id': 935}, {'_account_id': 2424}, {'_account_id': 6737}, {'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 30669}]","[{'number': 1, 'created': '2019-12-06 10:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/e2e67c8f601b9d5f81855f50096a05c148f68438', 'message': 'Add support for amp_ssh_key_name\n\nAllows a public key to be added to Amphora instances\nto allow ssh access for e.g. debug purposes.\n\nChange-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe\nCloses-Bug: #1843625\n'}, {'number': 2, 'created': '2020-01-08 16:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/65bb870f864fb63f3aabc527f3f98082bd1a3dde', 'message': 'Add support for setting amphora ssh key\n\nAllows a public key to be added to Amphora instances\nto allow ssh access for e.g. debug purposes.\n\nChange-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe\nCloses-Bug: #1843625\n'}, {'number': 3, 'created': '2020-01-09 18:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/404b8ee8a3d402cb76ac644e283cc79c0e6fada3', 'message': 'Add support for setting amphora ssh key\n\nAllows a public key to be added to Amphora instances\nto allow ssh access for e.g. debug purposes.\n\nChange-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe\nCloses-Bug: #1843625\n'}, {'number': 4, 'created': '2020-01-09 19:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/bf5de4ead6003a64f3eaeee1396a4ba5c7b6a00b', 'message': 'Add support for setting amphora ssh key\n\nAllows a public key to be added to Amphora instances\nto allow ssh access for e.g. debug purposes.\n\nChange-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe\nCloses-Bug: #1843625\n'}, {'number': 5, 'created': '2020-01-09 19:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/c3df877f1118ab13443eb9956b529efc592a3703', 'message': 'Add support for setting amphora ssh key\n\nAllows a public key to be added to Amphora instances\nto allow ssh access for e.g. debug purposes.\n\nWithout the ability to have amphora vms allow ssh access,\nit can be impossible to debug issues that occur inside\nthe vm since it is not possible to modify an existing\nimage or vm without the vm being recreated. Adding\nsupport for providing a key allows admins to have the\noption to access amphora vms should something go\nwrong. The default remains to not provide access.\n\nChange-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe\nCloses-Bug: #1843625\n'}, {'number': 6, 'created': '2020-01-10 10:16:24.000000000', 'files': ['src/config.yaml', 'src/reactive/octavia_handlers.py', 'src/templates/rocky/octavia.conf', 'unit_tests/test_octavia_handlers.py', 'src/lib/charm/openstack/api_crud.py'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/cbc884166139122af185f8ca970dcaf15f9f3f0a', 'message': 'Add support for setting amphora ssh key\n\nAllows a public key to be added to Amphora instances\nto allow ssh access for e.g. debug purposes.\n\nWithout the ability to have amphora vms allow ssh access,\nit can be impossible to debug issues that occur inside\nthe vm since it is not possible to modify an existing\nimage or vm without the vm being recreated. Adding\nsupport for providing a key allows admins to have the\noption to access amphora vms should something go\nwrong. The default remains to not provide access.\n\nChange-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe\nCloses-Bug: #1843625\n'}]",14,697645,cbc884166139122af185f8ca970dcaf15f9f3f0a,36,8,6,6737,,,0,"Add support for setting amphora ssh key

Allows a public key to be added to Amphora instances
to allow ssh access for e.g. debug purposes.

Without the ability to have amphora vms allow ssh access,
it can be impossible to debug issues that occur inside
the vm since it is not possible to modify an existing
image or vm without the vm being recreated. Adding
support for providing a key allows admins to have the
option to access amphora vms should something go
wrong. The default remains to not provide access.

Change-Id: I1d91741eeec9b20b80bbb907a8aeb9166831acbe
Closes-Bug: #1843625
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/45/697645/6 && git format-patch -1 --stdout FETCH_HEAD,"['src/config.yaml', 'src/lib/charm/openstack/octavia.py', 'src/reactive/octavia_handlers.py', 'src/templates/rocky/octavia.conf', 'unit_tests/test_octavia_handlers.py', 'src/lib/charm/openstack/api_crud.py']",6,e2e67c8f601b9d5f81855f50096a05c148f68438,bug/1843625,"def create_nova_keypair(identity_service, amp_key_name): """"""Create a nova keypair to use with Amphora images to allow ssh access e.g. for debug purposes. """""" pubkey = ch_core.hookenv.config.amp_ssh_pub_key if not pubkey: ch_core.hookenv.log('No pub key provided - cannot create amp-ssh-key ' 'keypair', level=ch_core.hookenv.WARNING) return try: session = session_from_identity_service(identity_service) nova = nova_client.Client('2', session=session, region_name=ch_core.hookenv.config('region')) keys = nova.keypairs.list() for key in keys: if key.name == amp_key_name: return # create keypair return nova.keypairs.create(name=amp_key_name, public_key=pubkey) except (keystone_exceptions.catalog.EndpointNotFound, keystone_exceptions.connection.ConnectFailure, nova_client.exceptions.ConnectionRefused, nova_client.exceptions.ClientException) as e: raise APIUnavailable('nova', 'keypairs', e) ",,89,0
openstack%2Fopenstack-helm-infra~master~I789da34104ac3cfb6a38bf4435a652da45c55e63,openstack/openstack-helm-infra,master,I789da34104ac3cfb6a38bf4435a652da45c55e63,OVS: enable setting threads for handler and revalidator,MERGED,2020-01-15 22:52:26.000000000,2020-01-16 15:49:10.000000000,2020-01-16 15:43:45.000000000,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 22:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6ce3584d9dd95f856d6bd4c6d46a84c86c21264a', 'message': 'WIP: OVS: set threads for handler and revalidator\n\nChange-Id: I789da34104ac3cfb6a38bf4435a652da45c55e63\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 2, 'created': '2020-01-15 23:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2238eef57d1feeaa7bcef2a17c7d0a3a1d23b6a8', 'message': 'OVS: enable setting threads for handler and revalidator\n\nThis PS enables the ability to configure the handler and\nrevalidator threads.\n\nSee: https://bugs.launchpad.net/ubuntu/+source/openvswitch/+bug/1827264/comments/6\nChange-Id: I789da34104ac3cfb6a38bf4435a652da45c55e63\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 3, 'created': '2020-01-15 23:07:39.000000000', 'files': ['openvswitch/values.yaml', 'openvswitch/templates/bin/_openvswitch-vswitchd.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/601e6ca47a3ec851acf25a76ba006117938f26df', 'message': 'OVS: enable setting threads for handler and revalidator\n\nThis PS enables the ability to configure the handler and\nrevalidator threads.\n\nSee: https://bugs.launchpad.net/ubuntu/+source/openvswitch/+bug/1827264/comments/6\nChange-Id: I789da34104ac3cfb6a38bf4435a652da45c55e63\nSigned-off-by: Pete Birley <pete@port.direct>\n'}]",0,702766,601e6ca47a3ec851acf25a76ba006117938f26df,11,4,3,23928,,,0,"OVS: enable setting threads for handler and revalidator

This PS enables the ability to configure the handler and
revalidator threads.

See: https://bugs.launchpad.net/ubuntu/+source/openvswitch/+bug/1827264/comments/6
Change-Id: I789da34104ac3cfb6a38bf4435a652da45c55e63
Signed-off-by: Pete Birley <pete@port.direct>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/66/702766/1 && git format-patch -1 --stdout FETCH_HEAD,['openvswitch/templates/bin/_openvswitch-vswitchd.sh.tpl'],1,6ce3584d9dd95f856d6bd4c6d46a84c86c21264a,701991, ovs-vsctl --db=unix:${OVS_SOCKET} --no-wait set Open_vSwitch . other_config:n-handler-threads=4 ovs-vsctl --db=unix:${OVS_SOCKET} --no-wait set Open_vSwitch . other_config:n-revalidator-threads=4 ,,3,0
openstack%2Fglance-specs~master~Id1c83aca9e9715811962cb45f198b5e6ca9feb6e,openstack/glance-specs,master,Id1c83aca9e9715811962cb45f198b5e6ca9feb6e,Copying existing image in multiple stores,MERGED,2019-11-18 08:03:59.000000000,2020-01-16 15:47:45.000000000,2020-01-16 15:43:25.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 30054}]","[{'number': 1, 'created': '2019-11-18 08:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/1b25e9979d939ff2f32a489c12f383de0dd11606', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 2, 'created': '2019-11-18 10:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/e323a2ca53dd64d190faad1f1a6fb40e546d4817', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 3, 'created': '2019-11-20 06:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/0a8656b004a39b413f159600c85fc97e71745284', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 4, 'created': '2019-11-25 10:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/3cffa69955e3765171cf1b8cff6f883a4021d7d8', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 5, 'created': '2019-11-29 06:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/67aa4da4a54559b4634fdf7bca1c4db00d7391e2', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 6, 'created': '2019-12-03 06:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/aa1ccf0ce1e81a97e698097eaa596f938f7d8cbe', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 7, 'created': '2019-12-20 07:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/a34f770c554e5dd1383e8e3746d510d31431387a', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 8, 'created': '2020-01-03 06:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/079ccffec8281be22715ce8ea4027918d058f8b5', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}, {'number': 9, 'created': '2020-01-07 06:23:14.000000000', 'files': ['specs/ussuri/approved/glance/copy-existing-image.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/f84ef0e2de4196820b873b35f9fad2b290f83584', 'message': 'Copying existing image in multiple stores\n\nChange-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e\nImplements: copy-existing-image\n'}]",38,694724,f84ef0e2de4196820b873b35f9fad2b290f83584,48,6,9,9303,,,0,"Copying existing image in multiple stores

Change-Id: Id1c83aca9e9715811962cb45f198b5e6ca9feb6e
Implements: copy-existing-image
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/24/694724/8 && git format-patch -1 --stdout FETCH_HEAD,"['specs/ussuri/approved/index.rst', 'specs/ussuri/approved/glance/copy-existing-image.rst']",2,1b25e9979d939ff2f32a489c12f383de0dd11606,specs/copy-existing-image,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================== Copy existing image in multiple stores ====================================== https://blueprints.launchpad.net/glance/+spec/copy-existing-image Despite the Image service supports several back ends for storing virtual machine image, there is no way at the moment to copy existing image bits into multiple stores and avoid the operator to manually copy data and update image locations. Problem description =================== At the moment, if cloud provider decided to upgrade their cloud to Train release to use the ability of glance of configuring multiple stores there is no way to replicate/copy existing image bits to newly added stores. As a result, operators today need to perform a number of manual steps in order to replicate/copy image bits on glance stores despite using the 'enabled_backends' configuration option. .. note:: Example An operator upgrades his existing setup of Openstack cloud to configure different sites, each with their local glance stores which nova hosts are accessing directly (Ceph). This operator use multiple stores support and want its images to be available in each store to prevent the images to be downloaded through glance each time a new virtual machine is created and let Nova use COW. For this purpose, he need to manually copy existing images data in store2 to storeN and register these others locations URL using the glance API. Since glance supports multi stores, it should propose a feature to copy existing image data into these stores at once to facilitate operators' work. Proposed change =============== This spec is depend on `Ability to import an image in multiple stores` [1] to import the image in multiple stores. In addition to above changes, this spec proposes to enhance the image import API to specify additional input `copy_image_from_id` in the json payload. If the image from which data needs to be copied in multiple stores is not in active state then the API should reject the request. New image state will be introduced which will be changed from `Active` to `Copying` to allow this operation to perform. Once image data is copied to all the specified stores, image state will be reinstated to `Active`. Introduce one additional Task which will allow us to copy the existing image to staging area, which will be then continued with existing import task to copy/import this data in specified multiple stores. To copy the existing image into staging area, we will traverse through the locations of the image, if image has multiple locations then preference will be given to the location which has file store associated with it. If image is does not associated with file store, then we will choose the first location and copy(download) image from that location to staging area. Failure mechanism will be same as dependent spec `Ability to import an image in multiple stores` [1]. * If an unavailable image is specified, the Api should reject the request. * If an unavailable store is specified, the Api should reject the request. * If base image deleted while copying the data to new stores, then the copying process will be terminated and copied data will be removed as well. * If `allowed_failure` is set to 'false' (default behavior) and an error occurs during copying data in at least one store, the request should be rejected, the data will be deleted, and the state of the image reinstated to `Active`. * If `allowed_failure` is set to 'true', the request will fail (data deleted, ...) only if the upload fails on all stores specified by the user. In case of a partial success, the locations added to the image will be the stores where the data has been correctly uploaded/copied. Image locations will be updated each time an upload/copy in a store succeed (with information from this store) but the status of the image will be set to `ACTIVE` from `copying` when the request is fully executed and successful. Current location strategies modules should'nt be affected by theses changes as we don't change the behavior of the image locations. It is currently possible to do the same by patching an image and specify a list of locations. In the same vein, as it is already an option to choose a store when using import workflow, there is no need to add a new policy to restrict the import in multiple stores. Alternatives ------------ Continue copying images manually to different stores and update the locations using Locations API. Data model impact ----------------- None REST API impact --------------- This spec proposes the following API changes: **Modified APIs** * Import an image. **Common Response Codes** * Normal http response code: 202 * 202: `Accepted` * Expected error http response codes: 400, 401, 403, 404, 405, 409, 410, 413, 415, 503 * 400: `Bad Request` with details. * 401: `Unauthorized` * 403: `Forbidden` * 404: `Not Found` (image doesn't exist or is not owned by the caller) * 405: `Method Not Allowed` (only POST supported for this call) * 409: `Conflict` (image is not in appropriate status) * 410: `Gone` (Image deleted while operation in progress) * 413: `Payload Too Large` * 415: `Unsupported Media Type` (must be ``application/json``) * 503: `Service Unavailable` **API Version** This change will require minor version bump. All URLS will be under the v2 Glance API. If it is not explicitly specified assume /v2/<url> **[Modified API] Import image to the store** Import image to the store:: POST /v2/images/{image_id}/import This modifies the existing REST API to add one new optional body field `copy_image_from_id`. New body field: * copy_image_from_id -- (UUID) If present, copy this image in multiple stores specified using `stores` option. Example curl usage:: curl -i -X POST -H ""X-Auth-Token: $token"" -H ""Content-Type: application/json"" -d '{""method"":{""name"":""glance-direct""}, ""copy_image_from_id"": ""existing-image-uuid"", ""stores"": [""ceph1"", ""ceph2""], ""allow_failure"": false}' $image_url/v2/images/{image_id}/import Security impact --------------- None Notifications impact -------------------- Notification will be logged for each of the successful copy of image. Other end user impact --------------------- **Glance client** The glance client (CLI + REST client) must be updated in accordance with this spec. Notably: * CLI / API support for specifying a existing image id for copying. Performance Impact ------------------ As we'll write data in multiple stores, this will increase the IO from the glance nodes in accordance of the number of stores specified. From the user point of view, the import workflow will also take more time depending on the stores where the upload are done. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * abhishekk Reviewers --------- Core reviewer(s): * jokke * rosmaita Work Items ---------- Implementation tasks may consist of: * Copy exiting image into staging area * Add python-glanceclient support Dependencies ============ None Testing ======= Appropriate unit and functional tests to ensure the changes to glance function correctly. Documentation Impact ==================== We'll need to ensure the glance docs are updated for: * New body field for image import. References ========== * [1] https://review.opendev.org/#/c/669201 ",,262,1
openstack%2Fglance-specs~master~Ia909ae1afab54242a1ca1a109a62a28131dc4dcf,openstack/glance-specs,master,Ia909ae1afab54242a1ca1a109a62a28131dc4dcf,Spec to import image in multi stores,MERGED,2019-07-04 15:16:06.000000000,2020-01-16 15:46:30.000000000,2020-01-16 15:41:48.000000000,"[{'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28595}, {'_account_id': 30054}]","[{'number': 1, 'created': '2019-07-04 15:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/47be7f48d938923aa1a5d66edc3e5539ce9715ab', 'message': 'Spec lite to import image in multi store\n\nDocImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 2, 'created': '2019-07-04 15:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/bfe0c6222a66fd046e6f6fc2d4b0c3f79f520a00', 'message': 'Spec lite to import image in multi stores\n\nDocImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 3, 'created': '2019-08-08 09:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/7daea92d1a4b54e7368e48db06759d9e212089e5', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 4, 'created': '2019-08-08 09:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/a15291fd53a95a5bb9de4924119952e35f40516e', 'message': 'Spec to import image in multi stores\n\nDocImpact\n\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 5, 'created': '2019-08-28 14:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/168227fde5d7a5991d8227620c384ad7dc40d551', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 6, 'created': '2019-09-06 09:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/eb7f10e65b76406243ad2932e973ef1c79528ffd', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 7, 'created': '2019-10-07 13:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/e45f212ec77b1b1736bf0a6bb8c196d599a28990', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 8, 'created': '2019-10-07 14:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/aa8da82dc753476a7d7fe2de87b2ad688bc726d7', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 9, 'created': '2019-10-15 13:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/4167e8628949bec7a5f7fc280da2e8a53a56fe5a', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 10, 'created': '2019-10-15 14:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/1afb1f618d3b7f68d133704913173b3216c0c273', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 11, 'created': '2019-11-15 16:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/59dca8d09356493f346b8892dbf87b108c0fb149', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 12, 'created': '2019-11-25 09:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/0ce1e3b47fbd172f2b0ddb88d59b70472f719af1', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 13, 'created': '2019-11-27 13:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/60a0e57197853d6af39edff6457869b83bc6ceb8', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 14, 'created': '2019-11-29 08:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d64d2cb39da67b084e25b287cde72cfe2f53ada8', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 15, 'created': '2019-12-06 14:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/c369e52559a2c9997e3d4599f74df7f665ad9f07', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 16, 'created': '2019-12-13 14:12:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/117279ada04cd5ca0cb40ca70c77de5c137e6320', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 17, 'created': '2019-12-20 10:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d817d71cb70c050a2d1b19ca224bd678ec30b8c4', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 18, 'created': '2020-01-03 14:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/973bbac83c1e1f5fc485200d9de6d30a210d235a', 'message': 'Spec to import image in multi stores\n\nDocImpact\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 19, 'created': '2020-01-03 15:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/571f5e860c42d9f3ecf65a0a638a7aad3179ab9e', 'message': 'Spec to import image in multi stores\n\nAPIImpact\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 20, 'created': '2020-01-03 15:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/d2d18b1ab6e8c389b024fad8c61230c552bcadbf', 'message': 'Spec to import image in multi stores\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 21, 'created': '2020-01-06 15:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/a5f63129c0a7114812ae452952388a367f1f9a2d', 'message': 'Spec to import image in multi stores\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}, {'number': 22, 'created': '2020-01-07 09:05:05.000000000', 'files': ['specs/ussuri/approved/glance/import-multi-stores.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/31b189a9278e82e0db4d0e11a69843985245360a', 'message': 'Spec to import image in multi stores\n\nChange-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf\n'}]",90,669201,31b189a9278e82e0db4d0e11a69843985245360a,102,7,22,30054,,,0,"Spec to import image in multi stores

Change-Id: Ia909ae1afab54242a1ca1a109a62a28131dc4dcf
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/01/669201/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/train/approved/spec-lite-import-multi-stores.rst'],1,47be7f48d938923aa1a5d66edc3e5539ce9715ab,bp/import-multi-stores,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== Spec Lite: Import multi stores ============================== .. Mandatory sections :project: glance :problem: When using multiple backend support, it is not possible to easily import image data in more than one store. The users have to manually import data in each backend and then patch locations on the image if they want to have an image stored in multiple backends. :solution: Accept multiple backend separated by a comma in the 'X-Image-Meta-Store' header (example: ceph_fast,ceph_cheap). If an unavailable store is submitted, the Api should reject the request. The data should be stored sequentially in each specified backend. If an error occurs during the upload in one backend, the request should be rejected and the state of the image remains the same. :impacts: DocImpact .. Optional sections -- delete any that don't apply to this spec lite :alternatives: Modify import method to allow importing data on an image in ""active"" status, in order to allow users to call it for each store. This would require a lot of refactoring and modify the glance import workflow. :timeline: Include in Train release. :link: https://review.opendev.org/#/c/667132/ :assignee: yebinama ",,48,0
openstack%2Fpaunch~stable%2Fqueens~I653ac4cc520e40f3eb4d029e8c99ab482b17a859,openstack/paunch,stable/queens,I653ac4cc520e40f3eb4d029e8c99ab482b17a859,Fix logging to stdout and file in classes/commands,MERGED,2020-01-14 13:56:02.000000000,2020-01-16 15:39:31.000000000,2020-01-16 15:37:28.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-14 13:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/40fc2048c049bed1123b35ec9a924e377ae336e1', 'message': 'Fix logging to stdout and file in classes/commands\n\nFix logging to console to depend on input CLI args. By default, keep\nlogging to stdout. Make --log-file argument working as well.\n\nUse the input verbosity parameters as a controlling switch for\nlogs verbosity.\n\nEvaluate log levels as:\n\n  * 1 (WARNING+) - the default log level if neither -v nor --debug used\n  * 2 (INFO+)    - applies if -v / --verbose\n  * 4 (DEBUG+)   - applies if --debug, dumps command results to file,\n    if --log-file is requested.\n  * 5 (DEBUG+)   - applies if --debug and -v. Like the latter mode, but\n    also dumps the executed commands results to console.\n\nThis is needed for better deployments troubleshootng.\n\nCloses-Bug: #1799182\n\nChange-Id: I653ac4cc520e40f3eb4d029e8c99ab482b17a859\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit d3c83259bfe59ed6713c7b5f7bb34128f39aae24)\n'}, {'number': 2, 'created': '2020-01-15 13:45:50.000000000', 'files': ['paunch/tests/test_builder_compose1.py', 'paunch/cmd.py', 'paunch/utils/common.py', 'paunch/runner.py', 'paunch/builder/compose1.py', 'releasenotes/notes/logging-1517682a7b0037cf.yaml', 'paunch/tests/test_paunch.py', 'paunch/__init__.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/059aa8c1f66337bc927db7aefde5639fc70ecf5f', 'message': 'Fix logging to stdout and file in classes/commands\n\nFix logging to console to depend on input CLI args. By default, keep\nlogging to stdout. Make --log-file argument working as well.\n\nUse the input verbosity parameters as a controlling switch for\nlogs verbosity.\n\nEvaluate log levels as:\n\n  * 1 (WARNING+) - the default log level if neither -v nor --debug used\n  * 2 (INFO+)    - applies if -v / --verbose\n  * 4 (DEBUG+)   - applies if --debug, dumps command results to file,\n    if --log-file is requested.\n  * 5 (DEBUG+)   - applies if --debug and -v. Like the latter mode, but\n    also dumps the executed commands results to console.\n\nThis is needed for better deployments troubleshootng.\n\nCloses-Bug: #1799182\n\nChange-Id: I653ac4cc520e40f3eb4d029e8c99ab482b17a859\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit d3c83259bfe59ed6713c7b5f7bb34128f39aae24)\n'}]",0,702434,059aa8c1f66337bc927db7aefde5639fc70ecf5f,13,8,2,6926,,,0,"Fix logging to stdout and file in classes/commands

Fix logging to console to depend on input CLI args. By default, keep
logging to stdout. Make --log-file argument working as well.

Use the input verbosity parameters as a controlling switch for
logs verbosity.

Evaluate log levels as:

  * 1 (WARNING+) - the default log level if neither -v nor --debug used
  * 2 (INFO+)    - applies if -v / --verbose
  * 4 (DEBUG+)   - applies if --debug, dumps command results to file,
    if --log-file is requested.
  * 5 (DEBUG+)   - applies if --debug and -v. Like the latter mode, but
    also dumps the executed commands results to console.

This is needed for better deployments troubleshootng.

Closes-Bug: #1799182

Change-Id: I653ac4cc520e40f3eb4d029e8c99ab482b17a859
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit d3c83259bfe59ed6713c7b5f7bb34128f39aae24)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/34/702434/2 && git format-patch -1 --stdout FETCH_HEAD,"['paunch/cmd.py', 'paunch/utils/common.py', 'paunch/runner.py', 'paunch/builder/compose1.py', 'releasenotes/notes/logging-1517682a7b0037cf.yaml', 'paunch/tests/test_paunch.py', 'paunch/__init__.py']",7,40fc2048c049bed1123b35ec9a924e377ae336e1,1790792_maybe,"from paunch.utils import common def apply(config_id, config, managed_by, labels=None, docker_cmd=None, log_level=None, log_file=None): :param int log_level: optional log level for loggers :param int log_file: optional log file for messages log = common.configure_logging(__name__, log_level, log_file) r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd, log=log) labels=labels, log=logdef cleanup(config_ids, managed_by, docker_cmd=None, log_level=None, log_file=None): :param int log_level: optional log level for loggers :param int log_file: optional log file for messages log = common.configure_logging(__name__, log_level, log_file) r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd, log=log)def list(managed_by, docker_cmd=None, log_level=None, log_file=None): :param int log_level: optional log level for loggers :param int log_file: optional log file for messages log = common.configure_logging(__name__, log_level, log_file) r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd, log=log) docker_cmd=None, log_level=None, log_file=None): :param int log_level: optional log level for loggers :param int log_file: optional log file for messages log = common.configure_logging(__name__, log_level, log_file) r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd, log=log) labels=labels, log=log return r.execute_interactive(cmd, log)def delete(config_ids, managed_by, docker_cmd=None, log_level=None, log_file=None): log = common.configure_logging(__name__, log_level, log_file) if not config_ids: log.warn('No config IDs specified') r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd, log=log)","import loggingLOG = logging.getLogger(__name__) def apply(config_id, config, managed_by, labels=None, docker_cmd=None): r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd) labels=labelsdef cleanup(config_ids, managed_by, docker_cmd=None): r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd)def list(managed_by, docker_cmd=None): r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd) docker_cmd=None): r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd) labels=labels return r.execute_interactive(cmd)def delete(config_ids, managed_by, docker_cmd=None): if not config_ids: LOG.warn('No config IDs specified') r = runner.DockerRunner(managed_by, docker_cmd=docker_cmd)",175,64
openstack%2Frpm-packaging~stable%2Fstein~Ia31aeef7183c30940f295bab4ff760633e9fcc29,openstack/rpm-packaging,stable/stein,Ia31aeef7183c30940f295bab4ff760633e9fcc29,add X.509 certificate check plugin for monasca-agent,ABANDONED,2019-12-12 16:47:57.000000000,2020-01-16 15:37:17.000000000,,"[{'_account_id': 1916}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-12 16:47:57.000000000', 'files': ['openstack/monasca-agent/monasca-agent.spec.j2', 'openstack/monasca-agent/0001-add-X.509-certificate-check-plugin.patch'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1d05207ef88aff14bfd72082209101dba3e41d42', 'message': 'add X.509 certificate check plugin for monasca-agent\n\nWe need this in order to monitor the internal TLS certificates. Since\nbackporting feature to stable/stein is not feasible, the next option is\nto patch RPM.\n\nChange-Id: Ia31aeef7183c30940f295bab4ff760633e9fcc29\n'}]",0,698755,1d05207ef88aff14bfd72082209101dba3e41d42,29,8,1,1916,,,0,"add X.509 certificate check plugin for monasca-agent

We need this in order to monitor the internal TLS certificates. Since
backporting feature to stable/stein is not feasible, the next option is
to patch RPM.

Change-Id: Ia31aeef7183c30940f295bab4ff760633e9fcc29
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/55/698755/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/monasca-agent/monasca-agent.spec.j2', 'openstack/monasca-agent/0001-add-X.509-certificate-check-plugin.patch']",2,1d05207ef88aff14bfd72082209101dba3e41d42,add_x509_cert_check_stein,"From a8c3a84750b6d1d941df448849279c94ec3e408d Mon Sep 17 00:00:00 2001 From: Guang Yee <guang.yee@suse.com> Date: Tue, 22 Oct 2019 23:44:32 -0700 Subject: [PATCH] add X.509 certificate check plugin Currently we don't have any capability to monitor the internal TLS/SSL certificates. i.e. SSL certificates used by MySQL for replication, RabbitMQ for distribution, etc. The cert_check plugin is not adequate for this purpose becaue it can only check on certficates over HTTPS endpoints. Furthermore, checking on these internal certificates over the network is cumbersome because the agent plugin would have to speak specific protocols. This patch adds a cert_file_check plugin to detect the certificate expiry (in days from now) for the given X.509 certificate file in PEM format. Similar to cert_check plugin, this plugin will a metric 'cert_file.cert_expire_days' which contains the number of days from now the given certificate will be expired. If the certificate has already expired, this will be a negative number. Change-Id: Id95cc7115823f972e234417223ab5906b57447cc Story: 2006753 --- docs/Plugins.md | 75 +++++++++ .../collector/checks_d/cert_file_check.py | 68 +++++++++ .../detection/plugins/cert_file_check.py | 73 +++++++++ setup.cfg | 2 + test-requirements.txt | 2 + tests/checks_d/test_cert_file_check.py | 144 ++++++++++++++++++ tests/detection/test_cert_file_check.py | 65 ++++++++ 7 files changed, 429 insertions(+) create mode 100644 monasca_agent/collector/checks_d/cert_file_check.py create mode 100644 monasca_setup/detection/plugins/cert_file_check.py create mode 100644 tests/checks_d/test_cert_file_check.py create mode 100644 tests/detection/test_cert_file_check.py diff --git a/docs/Plugins.md b/docs/Plugins.md index 1f66c46..6bd42c2 100644 --- a/docs/Plugins.md +++ b/docs/Plugins.md @@ -30,6 +30,7 @@ - [Check_MK_Local](#check_mk_local) - [Ceph](#ceph) - [Certificate Expiration (HTTPS)](#certificate-expiration-https) + - [Certificate Expiration (PEM File)](#certificate-expiration-file) - [Congestion](#congestion) - [Couch](#couch) - [Couchbase](#couchbase) @@ -143,6 +144,7 @@ The following plugins are delivered via setup as part of the standard plugin che | cacti | | | | cAdvisor_host | | | | cert_check | | | +| cert_file_check | | | | check_mk_local | | | | couch | | | | couchbase | | | @@ -323,6 +325,7 @@ These are the detection plugins included with the Monasca Agent. See [Customiza | ceilometer | ServicePlugin | | ceph | Plugin | | cert_check | ArgsPlugin | +| cert_file_check | ArgsPlugin | | check_mk_local | Plugin | | cinder | ServicePlugin | | cloudkitty | ServicePlugin | @@ -917,6 +920,78 @@ These options can be set if desired: * collect_period: Integer time in seconds between outputting the metric. Since the metric is in days, it makes sense to output it at a slower rate. The default is 3600, once per hour * timeout: Float time in seconds before timing out the connect to the url. Increase if needed for very slow servers, but making this too long will increase the time this plugin takes to run if the server for the url is down. The default is 1.0 seconds +## Certificate Expiration (PEM file) +An extension to the Agent provides the ability to determine the expiration date +of the PEM formatted X.509 certificate in a file. The metric is days until the +certificate expires. If the given certificate has already expired, it will +return a negative number. For example, if the certificate has already expired +5 days prior to the check, -5 will be returned. + +Notice that the days till expiration value is calculated based on every 24 +hours block, rounded down. For example, if the certificate will be expiring in +23 hours, the days till expiration value will be 0. Here are some more +examples. + +| Certificate Expiration Date | Plugin Execution Date | cert_file.cert_expire_days | +| --------------------------- | --------------------- | -------------------------- | +| Nov 1 23:00:50 2019 GMT | Oct 29 23:01:00 2019 GMT | 2 | +| Nov 1 23:00:50 2019 GMT | Oct 30 23:01:00 2019 GMT | 1 | +| Nov 1 23:00:50 2019 GMT | Nov 1 10:00:50 2019 GMT | 0 | +| Nov 1 23:00:50 2019 GMT | Nov 1 23:01:50 2019 GMT | 0 | +| Nov 1 23:00:50 2019 GMT | Nov 2 23:01:50 2019 GMT | -1 | +| Nov 1 23:00:50 2019 GMT | Nov 3 23:23:00 2019 GMT | -2 | + +The following dimensions are included with the metric by default: +``` + cert_file: cert_file +``` + +### Configuration +A YAML file (cert_file_check.yaml) contains the list of cert_files to check. + +The configuration of the certificate expiration check is done in YAML, and consists of two keys: + +* init_config +* instances + +The init_config section lists the global configuration settings, such as the +period (in seconds) at which to output the metric. The default value for +collect_period is 1 hour (3600 seconds). To change it to emit metric every +24 hours, set it to 86400. + +```yaml +init_config: + collect_period: 3600 +``` + +The instances section contains the urls to check. + +```yaml +instances: +- built_by: CertificateFileCheck + cert_file: /etc/myservice/myservice.pem +- built_by: CertificateFileCheck + cert_file: /etc/ssl/myotherservice.pem +``` + +The certicate expiration checks return the following metrics + +| Metric Name | Dimensions | Semantics | +| ----------- | ---------- | --------- | +| cert_file.cert_expire_days | cert_file=supplied certificate file being checked | The number of days until the certificate expires + + +There is a detection plugin that should be used to configure this extension. It is invoked as: + + $ monasca-setup -d CertificateFileCheck -a ""cert_files=/etc/myservice/myservice.pem,/etc/myotherservice/myotherservice.pem"" + +The cert_files option is a comma separated list of certificate files to check. + +These options can be set if desired: +* collect_period: Integer time in seconds between outputting the metric. +Since the metric is in days, it makes sense to output it at a slower rate. +The default is 3600, once per hour + ## Congestion This section describes the congestion check performed by monasca-agent. diff --git a/monasca_agent/collector/checks_d/cert_file_check.py b/monasca_agent/collector/checks_d/cert_file_check.py new file mode 100644 index 0000000..811e113 --- /dev/null +++ b/monasca_agent/collector/checks_d/cert_file_check.py @@ -0,0 +1,68 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +from datetime import datetime + +from cryptography.hazmat.backends import default_backend +from cryptography import x509 + +from monasca_agent.collector.checks import AgentCheck + + +class CertificateFileCheck(AgentCheck): + """"""Check the given certificate file and output a metric + which is the number of days until it expires + """""" + + def __init__(self, name, init_config, agent_config, instances=None): + super(CertificateFileCheck, self).__init__(name, init_config, + agent_config, instances) + + def check(self, instance): + cert_file = instance.get('cert_file', None) + + if cert_file is None: + self.log.warning('Instance have no ""cert_file"" configured.') + return + + dimensions = self._set_dimensions(None, instance) + dimensions['cert_file'] = cert_file + self.log.info('cert_file = %s' % cert_file) + expire_in_days = self.get_expire_in_days(cert_file) + if expire_in_days is not None: + self.gauge('cert_file.cert_expire_days', expire_in_days, + dimensions=dimensions) + self.log.debug('%d days till expiration for %s' % (expire_in_days, + cert_file)) + + def get_expire_in_days(self, cert_file): + """"""Take the path the the TLS certificate file and returns the number + of till the certificate expires. If the certificate has already + expired, it will return a negative number. For example, + if the certificate has already expired 5 days prior to the check, + -5 will be returned. + """""" + try: + with open(cert_file, 'r') as cf: + pem_data = cf.read().encode('ascii') + + cert = x509.load_pem_x509_certificate(pem_data, default_backend()) + return (cert.not_valid_after - datetime.utcnow()).days + except IOError: + self.log.warning( + 'Unable to read certificate from %s' % (cert_file)) + except ValueError: + self.log.warning( + 'Unable to load certificate from %s. Invalid content.' % ( + cert_file)) diff --git a/monasca_setup/detection/plugins/cert_file_check.py b/monasca_setup/detection/plugins/cert_file_check.py new file mode 100644 index 0000000..988f080 --- /dev/null +++ b/monasca_setup/detection/plugins/cert_file_check.py @@ -0,0 +1,73 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +import logging + +import monasca_setup.agent_config +import monasca_setup.detection + +log = logging.getLogger(__name__) + +DEFAULT_COLLECT_PERIOD = 3600 + + +class CertificateFileCheck(monasca_setup.detection.ArgsPlugin): + """"""Setup a X.509 certificate file check according to the passed in args. + + Outputs one metric: cert_file.cert_expire_days which is the number of + days until the certificate expires + + Despite being a detection plugin, this plugin does no detection and + will be a NOOP without arguments. Expects one argument, 'cert_files' + which is a comma-separated list of PEM-formatted X.509 certificate + files. + + Examples: + + monasca-setup -d CertificateFileCheck -a ""cert_files=cert1.pem,cert2.pem"" + + These arguments are optional: + collect_period: Integer time in seconds between outputting the metric. + Since the metric is in days, it makes sense to output + it at a slower rate. The default is once per hour + """""" + + def _detect(self): + """"""Run detection, set self.available True if cert_files are detected + """""" + self.available = self._check_required_args(['cert_files']) + + def build_config(self): + """"""Build the config as a Plugins object and return. + """""" + config = monasca_setup.agent_config.Plugins() + instances = [] + init_config = {'collect_period': DEFAULT_COLLECT_PERIOD} + if 'collect_period' in self.args: + collect_period = int(self.args['collect_period']) + init_config['collect_period'] = collect_period + for cert_file in self.args['cert_files'].split(','): + cert_file = cert_file.strip() + # Allow comma terminated lists + if not cert_file: + continue + log.info(""\tAdding X.509 Certificate expiration check for {}"".format(cert_file)) + instance = self._build_instance([]) + instance.update({'cert_file': cert_file, 'name': cert_file}) + instances.append(instance) + + config['cert_file_check'] = {'init_config': init_config, + 'instances': instances} + + return config diff --git a/setup.cfg b/setup.cfg index 0abaae4..a076e29 100644 --- a/setup.cfg +++ b/setup.cfg @@ -62,6 +62,8 @@ libvirt = ovs = python-novaclient>=9.1.0 # Apache-2.0 python-neutronclient>=6.3.0 # Apache-2.0 +cert_file_check = + cryptography>=2.6.1 # BSD/Apache-2.0 [global] setup-hooks = diff --git a/test-requirements.txt b/test-requirements.txt index 0c9982c..6f00bfc 100644 --- a/test-requirements.txt +++ b/test-requirements.txt @@ -9,3 +9,5 @@ oslotest>=3.2.0 # Apache-2.0 prometheus_client stestr>=1.0.0 # Apache-2.0 docutils>=0.11 # OSI-Approved Open Source, Public Domain +freezegun>=0.3.6 # Apache-2.0 + diff --git a/tests/checks_d/test_cert_file_check.py b/tests/checks_d/test_cert_file_check.py new file mode 100644 index 0000000..539159f --- /dev/null +++ b/tests/checks_d/test_cert_file_check.py @@ -0,0 +1,144 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +import datetime +import logging +import mock +import os +import shutil +import tempfile +import unittest + +from cryptography import x509 +from cryptography.x509.oid import NameOID +from cryptography.hazmat.primitives import hashes +from cryptography.hazmat.backends import default_backend +from cryptography.hazmat.primitives import serialization +from cryptography.hazmat.primitives.asymmetric import rsa +import freezegun + +from monasca_agent.collector.checks_d import cert_file_check + +LOG = logging.getLogger('monasca_agent.collector.checks.check.cert_file_check') + + +def generate_selfsigned_cert(expired_in): + key = rsa.generate_private_key( + public_exponent=65537, + key_size=1024, + backend=default_backend() + ) + issuer = subject = x509.Name([ + x509.NameAttribute(NameOID.COMMON_NAME, u'foo') + ]) + now = datetime.datetime.utcnow() + cert = ( + x509.CertificateBuilder() + .subject_name(issuer) + .issuer_name(subject) + .public_key(key.public_key()) + .serial_number(1) + .not_valid_before(now) + .not_valid_after(now + datetime.timedelta(days=expired_in)) + .sign(key, hashes.SHA256(), default_backend()) + ) + cert_pem = cert.public_bytes(encoding=serialization.Encoding.PEM) + + return cert_pem.decode('ascii') + + +class TestCertificateFileCheck(unittest.TestCase): + + def setUp(self): + super(TestCertificateFileCheck, self).setUp() + self.cert_file_check_obj = cert_file_check.CertificateFileCheck( + name='cert_file_check', + init_config={}, + instances=[], + agent_config={} + ) + + def test_cert_file_is_none(self): + with mock.patch.object(LOG, 'warning') as mock_log: + self.cert_file_check_obj.check({'foo': 'bar'}) + mock_log.assert_called_with( + 'Instance have no ""cert_file"" configured.') + + def test_unable_to_read_file(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + bogus_cert_file = os.path.join(tmp_certdir, 'foo') + with mock.patch.object(LOG, 'warning') as mock_log: + self.cert_file_check_obj.check({'cert_file': bogus_cert_file}) + mock_log.assert_called_with( + 'Unable to read certificate from %s' % (bogus_cert_file)) + finally: + shutil.rmtree(tmp_certdir) + + def test_unable_to_load_file(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + bogus_cert_file = os.path.join(tmp_certdir, 'foo') + # create a non-PEM formatted certificate file + with open(bogus_cert_file, 'w') as f: + f.write('foo') + + with mock.patch.object(LOG, 'warning') as mock_log: + self.cert_file_check_obj.check({'cert_file': bogus_cert_file}) + mock_log.assert_called_with( + 'Unable to load certificate from %s. Invalid content.' % ( + bogus_cert_file)) + finally: + shutil.rmtree(tmp_certdir) + + def test_check(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + cert_file = os.path.join(tmp_certdir, 'foo') + # create a self-signed cert that expires in 10 days from now + with open(cert_file, 'w') as f: + f.write(generate_selfsigned_cert(10)) + + with mock.patch.object(cert_file_check.CertificateFileCheck, + 'gauge') as mock_gauge: + self.cert_file_check_obj.check({'cert_file': cert_file}) + args, kwargs = mock_gauge.call_args + # make sure the plugin correctly detect the given cert will be + # expiring in equal or less than 10 days from now + self.assertEqual('cert_file.cert_expire_days', args[0]) + self.assertLessEqual(args[1], 10) + finally: + shutil.rmtree(tmp_certdir) + + def test_check_expired_cert(self): + tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') + try: + cert_file = os.path.join(tmp_certdir, 'foo') + # create a self-signed cert that has expired 10 days ago + with open(cert_file, 'w') as f: + f.write(generate_selfsigned_cert(10)) + + now = datetime.datetime.utcnow() + back_to_the_future = now + datetime.timedelta(days=20) + with freezegun.freeze_time(back_to_the_future): + with mock.patch.object(cert_file_check.CertificateFileCheck, + 'gauge') as mock_gauge: + self.cert_file_check_obj.check({'cert_file': cert_file}) + args, kwargs = mock_gauge.call_args + # make sure the plugin correctly detect that the given + # cert has already expired + self.assertEqual('cert_file.cert_expire_days', args[0]) + self.assertLessEqual(args[1], -9) + finally: + shutil.rmtree(tmp_certdir) diff --git a/tests/detection/test_cert_file_check.py b/tests/detection/test_cert_file_check.py new file mode 100644 index 0000000..ad1225e --- /dev/null +++ b/tests/detection/test_cert_file_check.py @@ -0,0 +1,65 @@ +# Copyright 2019 SUSE LLC +# +# Licensed under the Apache License, Version 2.0 (the ""License""); you may +# not use this file except in compliance with the License. You may obtain +# a copy of the License at +# +# http://www.apache.org/licenses/LICENSE-2.0 +# +# Unless required by applicable law or agreed to in writing, software +# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT +# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the +# License for the specific language governing permissions and limitations +# under the License. + +import logging +import unittest + +from mock import patch + +from monasca_setup.detection.plugins.cert_file_check import CertificateFileCheck + +LOG = logging.getLogger('monasca_setup.detection.plugins.cert_check') + + +class TestCertFileCheck(unittest.TestCase): + + def setUp(self): + unittest.TestCase.setUp(self) + with patch.object(CertificateFileCheck, '_detect') as mock_detect: + self.cert_obj = CertificateFileCheck('temp_dir') + self.assertTrue(mock_detect.called) + self.cert_obj.args = {'cert_files': '/etc/myservice/myserver.pem'} + + def test_detect(self): + self.cert_obj.available = False + with patch.object(self.cert_obj, '_check_required_args', + return_value=True) as mock_check_required_args: + self.cert_obj._detect() + self.assertTrue(self.cert_obj.available) + self.assertTrue(mock_check_required_args.called) + + def _build_config(self): + with patch.object(self.cert_obj, '_build_instance', + return_value={}) as mock_build_instance: + result = self.cert_obj.build_config() + self.assertTrue(mock_build_instance.called) + self.assertEqual( + result['cert_file_check']['instances'][0]['cert_file'], + '/etc/myservice/myserver.pem') + self.assertEqual(result['cert_file_check']['instances'][0]['name'], + '/etc/myservice/myserver.pem') + return result + + def test_build_config_without_args(self): + result = self._build_config() + self.assertEqual( + result['cert_file_check']['init_config']['collect_period'], + 3600) + + def test_build_config_with_args(self): + self.cert_obj.args.update({'collect_period': 1200}) + result = self._build_config() + self.assertEqual( + result['cert_file_check']['init_config']['collect_period'], + 1200) -- 2.17.1 ",,545,1
openstack%2Fmonasca-agent~stable%2Fstein~Id95cc7115823f972e234417223ab5906b57447cc,openstack/monasca-agent,stable/stein,Id95cc7115823f972e234417223ab5906b57447cc,add X.509 certificate check plugin,MERGED,2020-01-09 18:05:25.000000000,2020-01-16 15:34:49.000000000,2020-01-16 08:27:14.000000000,"[{'_account_id': 1916}, {'_account_id': 10311}, {'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 18:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6052f0b96f615da632af42ff6a26ebc30de5c2e7', 'message': ""add X.509 certificate check plugin\n\nCurrently we don't have any capability to monitor the internal TLS/SSL\ncertificates. i.e. SSL certificates used by MySQL for replication, RabbitMQ for\ndistribution, etc. The cert_check plugin is not adequate for this purpose\nbecaue it can only check on certficates over HTTPS endpoints. Furthermore,\nchecking on these internal certificates over the network is cumbersome\nbecause the agent plugin would have to speak specific protocols.\n\nThis patch adds a cert_file_check plugin to detect the certificate expiry\n(in days from now) for the given X.509 certificate file in PEM format.\nSimilar to cert_check plugin, this plugin will a metric\n'cert_file.cert_expire_days' which contains the number of days from now the\ngiven certificate will be expired. If the certificate has already expired,\nthis will be a negative number.\n\nChange-Id: Id95cc7115823f972e234417223ab5906b57447cc\nStory: 2006753\n(cherry picked from commit e1d73c4b5de577e663084bda9d3f5185c433af84)\n(cherry picked from commit bde37b3835d3329013b547b71af22b285332dbde)\n""}, {'number': 2, 'created': '2020-01-10 08:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/2abb8156499e5ade867750bd4347f81a5db6b2f4', 'message': ""add X.509 certificate check plugin\n\nCurrently we don't have any capability to monitor the internal TLS/SSL\ncertificates. i.e. SSL certificates used by MySQL for replication, RabbitMQ for\ndistribution, etc. The cert_check plugin is not adequate for this purpose\nbecaue it can only check on certficates over HTTPS endpoints. Furthermore,\nchecking on these internal certificates over the network is cumbersome\nbecause the agent plugin would have to speak specific protocols.\n\nThis patch adds a cert_file_check plugin to detect the certificate expiry\n(in days from now) for the given X.509 certificate file in PEM format.\nSimilar to cert_check plugin, this plugin will a metric\n'cert_file.cert_expire_days' which contains the number of days from now the\ngiven certificate will be expired. If the certificate has already expired,\nthis will be a negative number.\n\nChange-Id: Id95cc7115823f972e234417223ab5906b57447cc\nStory: 2006753\n(cherry picked from commit e1d73c4b5de577e663084bda9d3f5185c433af84)\n(cherry picked from commit bde37b3835d3329013b547b71af22b285332dbde)\n""}, {'number': 3, 'created': '2020-01-10 16:56:03.000000000', 'files': ['test-requirements.txt', 'monasca_setup/detection/plugins/cert_file_check.py', 'tests/detection/test_cert_file_check.py', 'docs/Plugins.md', 'setup.cfg', 'tests/checks_d/test_cert_file_check.py', 'monasca_agent/collector/checks_d/cert_file_check.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/583e5727c4b1a0e982e350ea781ac59b2250c4d8', 'message': ""add X.509 certificate check plugin\n\nCurrently we don't have any capability to monitor the internal TLS/SSL\ncertificates. i.e. SSL certificates used by MySQL for replication, RabbitMQ for\ndistribution, etc. The cert_check plugin is not adequate for this purpose\nbecaue it can only check on certficates over HTTPS endpoints. Furthermore,\nchecking on these internal certificates over the network is cumbersome\nbecause the agent plugin would have to speak specific protocols.\n\nThis patch adds a cert_file_check plugin to detect the certificate expiry\n(in days from now) for the given X.509 certificate file in PEM format.\nSimilar to cert_check plugin, this plugin will a metric\n'cert_file.cert_expire_days' which contains the number of days from now the\ngiven certificate will be expired. If the certificate has already expired,\nthis will be a negative number.\n\nChange-Id: Id95cc7115823f972e234417223ab5906b57447cc\nStory: 2006753\n(cherry picked from commit e1d73c4b5de577e663084bda9d3f5185c433af84)\n""}]",1,701791,583e5727c4b1a0e982e350ea781ac59b2250c4d8,14,4,3,1916,,,0,"add X.509 certificate check plugin

Currently we don't have any capability to monitor the internal TLS/SSL
certificates. i.e. SSL certificates used by MySQL for replication, RabbitMQ for
distribution, etc. The cert_check plugin is not adequate for this purpose
becaue it can only check on certficates over HTTPS endpoints. Furthermore,
checking on these internal certificates over the network is cumbersome
because the agent plugin would have to speak specific protocols.

This patch adds a cert_file_check plugin to detect the certificate expiry
(in days from now) for the given X.509 certificate file in PEM format.
Similar to cert_check plugin, this plugin will a metric
'cert_file.cert_expire_days' which contains the number of days from now the
given certificate will be expired. If the certificate has already expired,
this will be a negative number.

Change-Id: Id95cc7115823f972e234417223ab5906b57447cc
Story: 2006753
(cherry picked from commit e1d73c4b5de577e663084bda9d3f5185c433af84)
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/91/701791/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'monasca_setup/detection/plugins/cert_file_check.py', 'tests/detection/test_cert_file_check.py', 'docs/Plugins.md', 'setup.cfg', 'monasca_agent/collector/checks_d/cert_file_check.py', 'tests/checks_d/test_cert_file_check.py']",7,6052f0b96f615da632af42ff6a26ebc30de5c2e7,,"# Copyright 2019 SUSE LLC # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime import logging import mock import os import shutil import tempfile import unittest from cryptography import x509 from cryptography.x509.oid import NameOID from cryptography.hazmat.primitives import hashes from cryptography.hazmat.backends import default_backend from cryptography.hazmat.primitives import serialization from cryptography.hazmat.primitives.asymmetric import rsa import freezegun from monasca_agent.collector.checks_d import cert_file_check LOG = logging.getLogger('monasca_agent.collector.checks.check.cert_file_check') def generate_selfsigned_cert(expired_in): key = rsa.generate_private_key( public_exponent=65537, key_size=1024, backend=default_backend() ) issuer = subject = x509.Name([ x509.NameAttribute(NameOID.COMMON_NAME, u'foo') ]) now = datetime.datetime.utcnow() cert = ( x509.CertificateBuilder() .subject_name(issuer) .issuer_name(subject) .public_key(key.public_key()) .serial_number(1) .not_valid_before(now) .not_valid_after(now + datetime.timedelta(days=expired_in)) .sign(key, hashes.SHA256(), default_backend()) ) cert_pem = cert.public_bytes(encoding=serialization.Encoding.PEM) return cert_pem.decode('ascii') class TestCertificateFileCheck(unittest.TestCase): def setUp(self): super(TestCertificateFileCheck, self).setUp() self.cert_file_check_obj = cert_file_check.CertificateFileCheck( name='cert_file_check', init_config={}, instances=[], agent_config={} ) def test_cert_file_is_none(self): with mock.patch.object(LOG, 'warning') as mock_log: self.cert_file_check_obj.check({'foo': 'bar'}) mock_log.assert_called_with( 'Instance have no ""cert_file"" configured.') def test_unable_to_read_file(self): tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') try: bogus_cert_file = os.path.join(tmp_certdir, 'foo') with mock.patch.object(LOG, 'warning') as mock_log: self.cert_file_check_obj.check({'cert_file': bogus_cert_file}) mock_log.assert_called_with( 'Unable to read certificate from %s' % (bogus_cert_file)) finally: shutil.rmtree(tmp_certdir) def test_unable_to_load_file(self): tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') try: bogus_cert_file = os.path.join(tmp_certdir, 'foo') # create a non-PEM formatted certificate file with open(bogus_cert_file, 'w') as f: f.write('foo') with mock.patch.object(LOG, 'warning') as mock_log: self.cert_file_check_obj.check({'cert_file': bogus_cert_file}) mock_log.assert_called_with( 'Unable to load certificate from %s. Invalid content.' % ( bogus_cert_file)) finally: shutil.rmtree(tmp_certdir) def test_check(self): tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') try: cert_file = os.path.join(tmp_certdir, 'foo') # create a self-signed cert that expires in 10 days from now with open(cert_file, 'w') as f: f.write(generate_selfsigned_cert(10)) with mock.patch.object(cert_file_check.CertificateFileCheck, 'gauge') as mock_gauge: self.cert_file_check_obj.check({'cert_file': cert_file}) args, kwargs = mock_gauge.call_args # make sure the plugin correctly detect the given cert will be # expiring in equal or less than 10 days from now self.assertEqual('cert_file.cert_expire_days', args[0]) self.assertLessEqual(args[1], 10) finally: shutil.rmtree(tmp_certdir) def test_check_expired_cert(self): tmp_certdir = tempfile.mkdtemp(prefix='test-cert-file-check-') try: cert_file = os.path.join(tmp_certdir, 'foo') # create a self-signed cert that has expired 10 days ago with open(cert_file, 'w') as f: f.write(generate_selfsigned_cert(10)) now = datetime.datetime.utcnow() back_to_the_future = now + datetime.timedelta(days=20) with freezegun.freeze_time(back_to_the_future): with mock.patch.object(cert_file_check.CertificateFileCheck, 'gauge') as mock_gauge: self.cert_file_check_obj.check({'cert_file': cert_file}) args, kwargs = mock_gauge.call_args # make sure the plugin correctly detect that the given # cert has already expired self.assertEqual('cert_file.cert_expire_days', args[0]) self.assertLessEqual(args[1], -9) finally: shutil.rmtree(tmp_certdir) ",,429,0
openstack%2Fsphinx-feature-classification~master~I5ab48fe70e49d104290f1c01014e4aa6420e300f,openstack/sphinx-feature-classification,master,I5ab48fe70e49d104290f1c01014e4aa6420e300f,Drop py2 support and testing,MERGED,2020-01-14 16:56:54.000000000,2020-01-16 15:32:14.000000000,2020-01-16 15:29:14.000000000,"[{'_account_id': 6928}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 16:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sphinx-feature-classification/commit/f6c6b42fd36031331b632f1ffed53521ac4e5002', 'message': 'Drop py2 support and testing\n\n...per Ussuri Communtiy-wide goal:\n    https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I5ab48fe70e49d104290f1c01014e4aa6420e300f\n'}, {'number': 2, 'created': '2020-01-14 17:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sphinx-feature-classification/commit/a9222befaf0b548e1e799fde99f42f26b4862c52', 'message': 'Drop py2 support and testing\n\n...per Ussuri Communtiy-wide goal:\n    https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I5ab48fe70e49d104290f1c01014e4aa6420e300f\n'}, {'number': 3, 'created': '2020-01-16 13:44:55.000000000', 'files': ['.zuul.yaml', 'releasenotes/notes/drop-py2-support-3c3bb1055b271608.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sphinx-feature-classification/commit/b7ae3661e0782a1254cd007fea2448fc3cb828bc', 'message': 'Drop py2 support and testing\n\n...per Ussuri Communtiy-wide goal:\n    https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nAt the same time, set ignore_basepython_conflict\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nChange-Id: I5ab48fe70e49d104290f1c01014e4aa6420e300f\n'}]",9,702481,b7ae3661e0782a1254cd007fea2448fc3cb828bc,19,4,3,14070,,,0,"Drop py2 support and testing

...per Ussuri Communtiy-wide goal:
    https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

At the same time, set ignore_basepython_conflict

Automatic envs (pyXX) will only use the python version appropriate to
that env and ignore basepython inherited from [testenv] if we set
ignore_basepython_conflict.

Change-Id: I5ab48fe70e49d104290f1c01014e4aa6420e300f
",git fetch https://review.opendev.org/openstack/sphinx-feature-classification refs/changes/81/702481/2 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'releasenotes/notes/drop-py2-support-3c3bb1055b271608.yaml', 'setup.cfg', 'tox.ini']",4,f6c6b42fd36031331b632f1ffed53521ac4e5002,ignore_basepython_conflict,"envlist = py37,pep8basepython = python3","envlist = py27,py37,pep8basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",8,11
openstack%2Fpuppet-cinder~master~If6e71efb82a9a3d609f04a6b8725099e683756df,openstack/puppet-cinder,master,If6e71efb82a9a3d609f04a6b8725099e683756df,Remove excluded_domain_ip for DELL SC,MERGED,2020-01-14 09:32:19.000000000,2020-01-16 15:16:22.000000000,2020-01-16 15:16:22.000000000,"[{'_account_id': 3153}, {'_account_id': 10379}, {'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 09:32:19.000000000', 'files': ['manifests/backend/dellsc_iscsi.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/9b47a8ad04982caa99dbaeac9bbfd601a75ffc7e', 'message': 'Remove excluded_domain_ip for DELL SC\n\nThis code was only there in the last release\nto cleanup the config option and can be removed\nnow.\n\nChange-Id: If6e71efb82a9a3d609f04a6b8725099e683756df\n'}]",0,702379,9b47a8ad04982caa99dbaeac9bbfd601a75ffc7e,9,5,1,16137,,,0,"Remove excluded_domain_ip for DELL SC

This code was only there in the last release
to cleanup the config option and can be removed
now.

Change-Id: If6e71efb82a9a3d609f04a6b8725099e683756df
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/79/702379/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/backend/dellsc_iscsi.pp'],1,9b47a8ad04982caa99dbaeac9bbfd601a75ffc7e,,," # TODO(tobias-urdin): Remove this in U release. cinder_config { ""${name}/excluded_domain_ip"": ensure => absent; } ",0,5
openstack%2Fcharm-watcher~master~I85a113c21f756a614509fb7916f14065c23870b1,openstack/charm-watcher,master,I85a113c21f756a614509fb7916f14065c23870b1,Add gerrit and zuul config to enable CI,MERGED,2020-01-16 12:06:29.000000000,2020-01-16 15:12:28.000000000,2020-01-16 15:12:28.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 30442}]","[{'number': 1, 'created': '2020-01-16 12:06:29.000000000', 'files': ['.gitreview', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/charm-watcher/commit/663fad75525a86171ee6b7fa619460d13138fdc0', 'message': 'Add gerrit and zuul config to enable CI\n\nChange-Id: I85a113c21f756a614509fb7916f14065c23870b1\nSigned-off-by: Stamatis Katsaounis <katsaouniss@gmail.com>\n'}]",0,702852,663fad75525a86171ee6b7fa619460d13138fdc0,11,5,1,28014,,,0,"Add gerrit and zuul config to enable CI

Change-Id: I85a113c21f756a614509fb7916f14065c23870b1
Signed-off-by: Stamatis Katsaounis <katsaouniss@gmail.com>
",git fetch https://review.opendev.org/openstack/charm-watcher refs/changes/52/702852/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', '.zuul.yaml']",2,663fad75525a86171ee6b7fa619460d13138fdc0,,- project: templates: - python35-charm-jobs - openstack-python3-ussuri-jobs - openstack-cover-jobs ,,9,0
openstack%2Fkolla-ansible~master~Id40bbda0793a57ebf18321f3c15f02f316d36eb8,openstack/kolla-ansible,master,Id40bbda0793a57ebf18321f3c15f02f316d36eb8,Some ansible-lint fixes,ABANDONED,2019-11-18 15:45:41.000000000,2020-01-16 15:06:25.000000000,,"[{'_account_id': 12393}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 24162}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-11-18 15:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f56607f55d89abf45c145f025eccdbe8894f4ac7', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 2, 'created': '2019-11-19 11:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bd52daf7f2f4bddcedf8490e01988ce876f93881', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 3, 'created': '2019-11-20 10:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7ba43233c8c9248bb97af5ba315795676b9424d4', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 4, 'created': '2019-11-25 11:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3010a9f439a672c3927fc7600ff9ef05973c34b4', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 5, 'created': '2019-11-29 12:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9ccf1a50c194af48a90e0324a0591559c929385c', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 6, 'created': '2019-11-29 14:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d8997485df5f6f3772e86091cd350f0042908a88', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 7, 'created': '2019-11-29 15:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4e3ec98799b658337dc56e337d435810fba9c2b6', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 8, 'created': '2019-12-04 08:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b4d98ab48d4cbbd59344c8f4327a20ebacb72e2a', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 9, 'created': '2019-12-04 10:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e4c26dec5bc5f277a8c55790ce2e2c22fc3034c6', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 10, 'created': '2019-12-04 10:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6be1e27ece5ecd7da7ad8acd604d015e135017c4', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 11, 'created': '2019-12-04 14:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ccf6fd31d0102b63cf3a9e60a0d3a509176c2bc2', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 12, 'created': '2019-12-16 14:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c877b672bdadd54c39bffd72b6e2af46dd3147dd', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 13, 'created': '2020-01-04 07:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/aa972a06b08e6cc18e31008f3534c8a02386062a', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 14, 'created': '2020-01-04 09:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ac875d4fc8743cde8c7577301bef117794ae38c9', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}, {'number': 15, 'created': '2020-01-13 10:45:30.000000000', 'files': ['ansible/roles/ceph/tasks/stop.yml', 'ansible/roles/panko/tasks/bootstrap.yml', 'ansible/roles/nova-cell/tasks/create_cells.yml', 'ansible/roles/nova/tasks/map_cell0.yml', 'ansible/roles/monasca/tasks/bootstrap.yml', 'ansible/roles/monasca/tasks/post_config.yml', 'ansible/roles/ovs-dpdk/handlers/main.yml', 'ansible/roles/mongodb/tasks/bootstrap_cluster.yml', 'ansible/roles/nova/tasks/refresh_scheduler_cell_cache.yml', 'ansible/roles/manila/tasks/fix_cephfs_owner.yml', 'ansible/roles/nova-cell/tasks/external_ceph.yml', 'ansible/roles/ceph/tasks/upgrade.yml', 'ansible/roles/keystone/tasks/register.yml', 'ansible/roles/swift/tasks/precheck.yml', 'ansible/roles/ceph_pools.yml', 'ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/keystone/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5b82207796ab54ee00bf47dc86faccd74604a381', 'message': 'Some ansible-lint fixes\n\npip 19.3 is iirc the first to complain when run with Python 2\ndocker 2.4.2 is taken from requirements.txt file\n\nChange-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8\n'}]",49,694797,5b82207796ab54ee00bf47dc86faccd74604a381,69,8,15,24072,,,0,"Some ansible-lint fixes

pip 19.3 is iirc the first to complain when run with Python 2
docker 2.4.2 is taken from requirements.txt file

Change-Id: Id40bbda0793a57ebf18321f3c15f02f316d36eb8
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/97/694797/7 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/prechecks/tasks/package_checks.yml', 'ansible/roles/baremetal/tasks/install.yml', 'ansible/roles/prechecks/tasks/service_checks.yml', 'ansible/roles/prechecks/tasks/port_checks.yml']",4,f56607f55d89abf45c145f025eccdbe8894f4ac7,local_action_fix, when: hostvars[inventory_hostname]['ansible_' + api_interface]['active'], when: hostvars[inventory_hostname]['ansible_' + api_interface]['active'] != True,12,9
openstack%2Ftripleo-operator-ansible~master~If5e8e75f5a572660a5aeed13c1b60bc5ea27032f,openstack/tripleo-operator-ansible,master,If5e8e75f5a572660a5aeed13c1b60bc5ea27032f,Add image prepare default role,MERGED,2020-01-15 22:24:12.000000000,2020-01-16 15:04:32.000000000,2020-01-16 15:04:31.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 22:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/dcf1c4ede7c2d9304f44727a74e30df0c835ab22', 'message': 'Add image prepare default role\n\nAdds tripleo-container-image-prepare-default role to run the prepare\ndefault command to generate ContainerImageParameters.\n\nChange-Id: If5e8e75f5a572660a5aeed13c1b60bc5ea27032f\n'}, {'number': 2, 'created': '2020-01-16 13:26:57.000000000', 'files': ['roles/tripleo-container-image-prepare-default/tests/test.yml', 'roles/tripleo-container-image-prepare-default/README.md', 'roles/tripleo-container-image-prepare-default/defaults/main.yml', 'roles/tripleo-container-image-prepare-default/tasks/main.yml', 'roles/tripleo-container-image-prepare-default/tests/inventory', 'roles/tripleo-container-image-prepare-default/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/aadb9f4be302c1a584f068f7e192b0a56a3f7f76', 'message': 'Add image prepare default role\n\nAdds tripleo-container-image-prepare-default role to run the prepare\ndefault command to generate ContainerImageParameters.\n\nChange-Id: If5e8e75f5a572660a5aeed13c1b60bc5ea27032f\n'}]",0,702761,aadb9f4be302c1a584f068f7e192b0a56a3f7f76,9,3,2,14985,,,0,"Add image prepare default role

Adds tripleo-container-image-prepare-default role to run the prepare
default command to generate ContainerImageParameters.

Change-Id: If5e8e75f5a572660a5aeed13c1b60bc5ea27032f
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/61/702761/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-container-image-prepare-default/tests/test.yml', 'roles/tripleo-container-image-prepare-default/README.md', 'roles/tripleo-container-image-prepare-default/defaults/main.yml', 'roles/tripleo-container-image-prepare-default/tasks/main.yml', 'roles/tripleo-container-image-prepare-default/tests/inventory', 'roles/tripleo-container-image-prepare-default/meta/main.yml']",6,dcf1c4ede7c2d9304f44727a74e30df0c835ab22,tripleo-operator-ansible,"--- # Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. galaxy_info: author: OpenStack description: TripleO Operator Role -- tripleo-container-image-prepare-default company: Red Hat license: Apache-2.0 min_ansible_version: 2.8 # # Provide a list of supported platforms, and for each platform a list of versions. # If you don't wish to enumerate all versions for a particular platform, use 'all'. # To view available platforms and versions (or releases), visit: # https://galaxy.ansible.com/api/v1/platforms/ # platforms: - name: CentOS versions: - 7 - 8 galaxy_tags: - tripleo # List your role dependencies here, one per line. Be sure to remove the '[]' above, # if you add dependencies to this list. dependencies: [] ",,131,0
openstack%2Fkolla-ansible~stable%2Frocky~I09844e0807a93d9edd8d014276b0174d77a993a0,openstack/kolla-ansible,stable/rocky,I09844e0807a93d9edd8d014276b0174d77a993a0,Fix fernet-node-sync error catching,MERGED,2020-01-10 08:55:17.000000000,2020-01-16 14:57:57.000000000,2020-01-16 14:55:17.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-10 08:55:17.000000000', 'files': ['ansible/roles/keystone/templates/fernet-node-sync.sh.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d65317f6141832c05a869169066be564e7e4d754', 'message': 'Fix fernet-node-sync error catching\n\nChange-Id: I09844e0807a93d9edd8d014276b0174d77a993a0\n'}]",0,701907,d65317f6141832c05a869169066be564e7e4d754,13,4,1,30491,,,0,"Fix fernet-node-sync error catching

Change-Id: I09844e0807a93d9edd8d014276b0174d77a993a0
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/07/701907/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/keystone/templates/fernet-node-sync.sh.j2'],1,d65317f6141832c05a869169066be564e7e4d754,fetch_fernet_fail-stable/train-stable/stein-stable/rocky,set -o errexit set -o pipefail ,,3,0
openstack%2Fpuppet-placement~master~Ia4ded54763eecc0f2fc07fdfa92e9cc15dccd09b,openstack/puppet-placement,master,Ia4ded54763eecc0f2fc07fdfa92e9cc15dccd09b,Remove deprecated placement::config params,MERGED,2020-01-14 09:51:21.000000000,2020-01-16 14:52:02.000000000,2020-01-16 14:49:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 09:51:21.000000000', 'files': ['manifests/config.pp', 'releasenotes/notes/remove-faulty-config-4a133c8e8cf74868.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-placement/commit/3da70b1bbdff5d3de6cb197791e37d687f7704dd', 'message': 'Remove deprecated placement::config params\n\nThese were leftovers from the nova extraction that\nwas wrong and should not be there.\n\nChange-Id: Ia4ded54763eecc0f2fc07fdfa92e9cc15dccd09b\n'}]",0,702384,3da70b1bbdff5d3de6cb197791e37d687f7704dd,8,3,1,16137,,,0,"Remove deprecated placement::config params

These were leftovers from the nova extraction that
was wrong and should not be there.

Change-Id: Ia4ded54763eecc0f2fc07fdfa92e9cc15dccd09b
",git fetch https://review.opendev.org/openstack/puppet-placement refs/changes/84/702384/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/config.pp', 'releasenotes/notes/remove-faulty-config-4a133c8e8cf74868.yaml']",2,3da70b1bbdff5d3de6cb197791e37d687f7704dd,,"--- upgrade: - | The parameter password, auth_type, auth_url, region_name, valid_interfaces, project_domain_name, project_name, user_domain_name and username in the placement::config class is removed. This was faulty parameters that was leftovers from when placement was extracted out of the nova module. ",,10,76
openstack%2Fneutron~master~I7d55adc262280c0c2f13b9b81ecc582e1729afa0,openstack/neutron,master,I7d55adc262280c0c2f13b9b81ecc582e1729afa0,Remove references to unittest2 library,MERGED,2020-01-10 16:29:01.000000000,2020-01-16 14:32:15.000000000,2020-01-16 14:29:13.000000000,"[{'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2020-01-10 16:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63ee3cf1e62710cbb20bef9bf4ce7542b9740f64', 'message': 'Remove references to unittest2 library\n\nLibrary ""unittest2"" has not released a new version since\nJun 30 2015 [1]. Neutron should remove the references to\nthis library and point to ""unittest"" instead.\n\n[1] https://pypi.org/project/unittest2/#history\n\nChange-Id: I7d55adc262280c0c2f13b9b81ecc582e1729afa0\nCloses-Bug: #1859190\n'}, {'number': 2, 'created': '2020-01-10 17:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c7eae75c0ac40cca6fb1c44dad64ca99adb9486', 'message': 'Remove references to unittest2 library\n\nLibrary ""unittest2"" has not released a new version since\nJun 30 2015 [1]. Neutron should remove the references to\nthis library and point to ""unittest"" instead.\n\n[1] https://pypi.org/project/unittest2/#history\n\nChange-Id: I7d55adc262280c0c2f13b9b81ecc582e1729afa0\nCloses-Bug: #1859190\n'}, {'number': 3, 'created': '2020-01-12 18:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6cb27a6d2e0a97851cec0e830623096731cbc2d9', 'message': 'Remove references to unittest2 library\n\nLibrary ""unittest2"" has not released a new version since\nJun 30 2015 [1]. Neutron should remove the references to\nthis library and point to ""unittest"" instead.\n\n[1] https://pypi.org/project/unittest2/#history\n\nChange-Id: I7d55adc262280c0c2f13b9b81ecc582e1729afa0\nCloses-Bug: #1859190\n'}, {'number': 4, 'created': '2020-01-13 08:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aef447243b3c1d3154e9444ae2a3a23a17827dbf', 'message': 'Remove references to unittest2 library\n\nLibrary ""unittest2"" has not released a new version since\nJun 30 2015 [1]. Neutron should remove the references to\nthis library and point to ""unittest"" instead.\n\n[1] https://pypi.org/project/unittest2/#history\n\nChange-Id: I7d55adc262280c0c2f13b9b81ecc582e1729afa0\nCloses-Bug: #1859190\n'}, {'number': 5, 'created': '2020-01-14 09:03:47.000000000', 'files': ['neutron/tests/unit/tests/test_base.py', 'neutron/tests/tools.py', 'lower-constraints.txt', 'neutron/hacking/checks.py', 'neutron/tests/unit/hacking/test_checks.py', 'neutron/tests/functional/pecan_wsgi/__init__.py', 'neutron/tests/common/base.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e0c44e21fa387f8fa681e257bf8abebfdc29177', 'message': 'Remove references to unittest2 library\n\nLibrary ""unittest2"" has not released a new version since\nJun 30 2015 [1]. Neutron should remove the references to\nthis library and point to ""unittest"" instead.\n\n[1] https://pypi.org/project/unittest2/#history\n\nChange-Id: I7d55adc262280c0c2f13b9b81ecc582e1729afa0\nCloses-Bug: #1859190\n'}]",6,701997,7e0c44e21fa387f8fa681e257bf8abebfdc29177,46,8,5,16688,,,0,"Remove references to unittest2 library

Library ""unittest2"" has not released a new version since
Jun 30 2015 [1]. Neutron should remove the references to
this library and point to ""unittest"" instead.

[1] https://pypi.org/project/unittest2/#history

Change-Id: I7d55adc262280c0c2f13b9b81ecc582e1729afa0
Closes-Bug: #1859190
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/701997/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/tools.py', 'neutron/tests/unit/tests/test_base.py', 'neutron/tests/functional/pecan_wsgi/__init__.py', 'neutron/tests/common/base.py', 'HACKING.rst']",5,63ee3cf1e62710cbb20bef9bf4ce7542b9740f64,bug/1859190,neutron.tests.base.BaseTestCase.,- [N334] Use unittest2 uniformly across Neutron.neutron.tests.base.BaseTestCase. If the third party unittest library has to be used directly then it is recommended to use unittest2 as it contains bug fixes to unittest for all versions of Python prior to version 3.5.,9,13
openstack%2Fpuppet-sahara~master~I43cb3e526211faa2192b18287bfed62617dec4b2,openstack/puppet-sahara,master,I43cb3e526211faa2192b18287bfed62617dec4b2,Remove sahara::service::all,MERGED,2020-01-14 09:55:11.000000000,2020-01-16 14:28:38.000000000,2020-01-16 14:27:11.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 09:55:11.000000000', 'files': ['manifests/service/all.pp', 'manifests/params.pp', 'releasenotes/notes/remove-sahara-all-6baa65d6baf6b9dc.yaml', 'spec/classes/sahara_all_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/11def8c8d96f934ea1ee3cdc89b63fddbdf579d3', 'message': 'Remove sahara::service::all\n\nRemove the class to deploy all sahara services in favor\nof the specific classes for the API and engine.\n\nExample see removal from RDO here [1].\n\n[1] https://github.com/rdo-packages/sahara-distgit/commit/e5d05cc587b6b2a2f527480eefa8634e0d58202c\n\nChange-Id: I43cb3e526211faa2192b18287bfed62617dec4b2\n'}]",0,702387,11def8c8d96f934ea1ee3cdc89b63fddbdf579d3,9,4,1,16137,,,0,"Remove sahara::service::all

Remove the class to deploy all sahara services in favor
of the specific classes for the API and engine.

Example see removal from RDO here [1].

[1] https://github.com/rdo-packages/sahara-distgit/commit/e5d05cc587b6b2a2f527480eefa8634e0d58202c

Change-Id: I43cb3e526211faa2192b18287bfed62617dec4b2
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/87/702387/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/service/all.pp', 'manifests/params.pp', 'releasenotes/notes/remove-sahara-all-6baa65d6baf6b9dc.yaml', 'spec/classes/sahara_all_spec.rb']",4,11def8c8d96f934ea1ee3cdc89b63fddbdf579d3,,,"# TODO(tobias-urdin): Remove this when deprecated sahara-all is removed. require 'spec_helper' describe 'sahara::service::all' do shared_examples 'sahara::service::all' do context 'with default params' do it { should contain_class('sahara::deps') should contain_class('sahara::policy') should contain_class('sahara::params') } it { should contain_package('sahara-all').with( :ensure => 'present', :name => platform_params[:all_package_name], :tag => ['openstack', 'sahara-package'], )} it { should contain_service('sahara-all').with( :ensure => 'running', :name => platform_params[:all_service_name], :enable => true, :hasstatus => true, :hasrestart => true, :tag => 'sahara-service', )} end context 'with custom params' do let :params do { :enabled => false, :manage_service => false, :package_ensure => 'absent', } end it { should contain_package('sahara-all').with( :ensure => 'absent', :name => platform_params[:all_package_name], :tag => ['openstack', 'sahara-package'], )} it { should contain_service('sahara-all').with( :ensure => nil, :name => platform_params[:all_service_name], :enable => false, :hasstatus => true, :hasrestart => true, :tag => 'sahara-service', )} end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge(OSDefaults.get_facts) end case facts[:osfamily] when 'Debian' let (:platform_params) do { :all_package_name => 'sahara', :all_service_name => 'sahara' } end when 'RedHat' let (:platform_params) do { :all_package_name => 'openstack-sahara', :all_service_name => 'openstack-sahara-all' } end end it_behaves_like 'sahara::service::all' end end end ",5,143
openstack%2Fbifrost~master~I43c65b742616835662cf5bc3b87a22aa42b79185,openstack/bifrost,master,I43c65b742616835662cf5bc3b87a22aa42b79185,remove legacy ansible environment setup hint,MERGED,2020-01-09 22:50:48.000000000,2020-01-16 14:20:21.000000000,2020-01-16 14:17:09.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 22:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3ccacb0f5cdef44cb72d9bfaded2bcdaefb2aafd', 'message': 'remove legacy ansible environment setup hint\n\nOur ansible installation changed quite some time ago,\nand it is time to go ahead and remove the outdated reference.\n\nChange-Id: I43c65b742616835662cf5bc3b87a22aa42b79185\n'}, {'number': 2, 'created': '2020-01-16 13:52:33.000000000', 'files': ['scripts/env-setup.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3b859c83f5efe38b8c340e1211aad2a808d69cf0', 'message': 'remove legacy ansible environment setup hint\n\nOur ansible installation changed quite some time ago,\nand it is time to go ahead and remove the outdated reference.\n\nChange-Id: I43c65b742616835662cf5bc3b87a22aa42b79185\n'}]",0,701857,3b859c83f5efe38b8c340e1211aad2a808d69cf0,11,4,2,11655,,,0,"remove legacy ansible environment setup hint

Our ansible installation changed quite some time ago,
and it is time to go ahead and remove the outdated reference.

Change-Id: I43c65b742616835662cf5bc3b87a22aa42b79185
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/57/701857/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/env-setup.sh'],1,3ccacb0f5cdef44cb72d9bfaded2bcdaefb2aafd,700912,,"mkdir -p ${ANSIBLE_INSTALL_ROOT}/ansible/hacking echo ""echo Sourcing this file is no longer needed! Ansible is always installed from PyPI"" > ${ANSIBLE_INSTALL_ROOT}/ansible/hacking/env-setup ",0,3
openstack%2Fgovernance~master~I7d2a7e77585a0770b733168bd8c0b20074047335,openstack/governance,master,I7d2a7e77585a0770b733168bd8c0b20074047335,Reorder repos,MERGED,2020-01-09 08:01:20.000000000,2020-01-16 14:14:05.000000000,2020-01-16 14:08:26.000000000,"[{'_account_id': 308}, {'_account_id': 4257}, {'_account_id': 8099}, {'_account_id': 8556}, {'_account_id': 10607}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 08:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a8825de456197eb506a870e89e53c950aa07e7c9', 'message': 'Reorder repos\n\nOCD happening here.\n\nChange-Id: I7d2a7e77585a0770b733168bd8c0b20074047335\n'}, {'number': 2, 'created': '2020-01-16 13:43:40.000000000', 'files': ['reference/technical-committee-repos.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/6cc284a82bc1a4f1fe620097c5cd05955129e050', 'message': 'Reorder repos\n\nOCD happening here.\n\nChange-Id: I7d2a7e77585a0770b733168bd8c0b20074047335\n'}]",0,701679,6cc284a82bc1a4f1fe620097c5cd05955129e050,16,8,2,17068,,,0,"Reorder repos

OCD happening here.

Change-Id: I7d2a7e77585a0770b733168bd8c0b20074047335
",git fetch https://review.opendev.org/openstack/governance refs/changes/79/701679/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/technical-committee-repos.yaml'],1,a8825de456197eb506a870e89e53c950aa07e7c9,typo-fix, - repo: openstack/arch-wg - repo: openstack/election - repo: openstack/goal-tools - repo: openstack/governance-website - repo: openstack/ideas - repo: openstack/openstack, - repo: openstack/openstack - repo: openstack/election - repo: openstack/goal-tools - repo: openstack/governance-website - repo: openstack/arch-wg - repo: openstack/ideas,6,6
openstack%2Foctavia~master~I5e89a656d23e7bfe087c8d3e7443a77d469cb541,openstack/octavia,master,I5e89a656d23e7bfe087c8d3e7443a77d469cb541,Remove test calls to reset_mock(),MERGED,2020-01-07 22:01:35.000000000,2020-01-16 14:13:38.000000000,2020-01-16 14:10:32.000000000,"[{'_account_id': 6469}, {'_account_id': 10273}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-07 22:01:35.000000000', 'files': ['octavia/tests/unit/controller/worker/v1/test_controller_worker.py', 'octavia/tests/unit/controller/worker/v2/test_controller_worker.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e36c67b33d630901f10cd6dfdb70399a878ed207', 'message': 'Remove test calls to reset_mock()\n\ntest_failover_loadbalancer() has two calls to reset_mock()\nwhich do nothing, remove them.  In both v1 and v2 worker tests.\n\nChange-Id: I5e89a656d23e7bfe087c8d3e7443a77d469cb541\n'}]",0,701465,e36c67b33d630901f10cd6dfdb70399a878ed207,8,3,1,1131,,,0,"Remove test calls to reset_mock()

test_failover_loadbalancer() has two calls to reset_mock()
which do nothing, remove them.  In both v1 and v2 worker tests.

Change-Id: I5e89a656d23e7bfe087c8d3e7443a77d469cb541
",git fetch https://review.opendev.org/openstack/octavia refs/changes/65/701465/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/controller/worker/v1/test_controller_worker.py', 'octavia/tests/unit/controller/worker/v2/test_controller_worker.py']",2,e36c67b33d630901f10cd6dfdb70399a878ed207,reset-mock,, mock_perform.reset_mock() mock_perform.reset_mock(),0,4
openstack%2Fgovernance~master~I0f93bac85965e6774c500c3580d86ccad0b49f4e,openstack/governance,master,I0f93bac85965e6774c500c3580d86ccad0b49f4e,Make mistral-dashboard a separate deliverable,MERGED,2019-12-23 04:36:48.000000000,2020-01-16 14:11:52.000000000,2020-01-16 14:08:25.000000000,"[{'_account_id': 308}, {'_account_id': 841}, {'_account_id': 1004}, {'_account_id': 4257}, {'_account_id': 8556}, {'_account_id': 8731}, {'_account_id': 10607}, {'_account_id': 16708}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-23 04:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/c32c64471477ca70a437f43d682d49699eb99da8', 'message': 'Make mistral-dashboard a separate deliverable\n\nmistral-dashboard is the only horizon plugin which is not marked as\nhorizon plugin in the releases repo now as mistral-dashboard is released\nas part of the mistral deliverable.\n\nNote that deliverables defined in releases repo should match deliverables\ndefined in the governance repo and the release team suggested to update\nthe deliverable definition in the governance repo first (with ACK from\nthe mistral team).\n\nBy making mistral-dashboard a separate deliberable, we can mark\nmistral-dashboard as horizon plugin (via the release repo).\nConsumers can find mistral-dashboard in the ""Horizon Plugins"" section\nin releases.openstack.org.\nIn addition, the horizon team uses deliverable files in the release repo\nto recognize the list of the horizon plugins so making mistral-dashboard\na separate deliverable would help the horizon team.\n\nA dashboard implementation is usually not tightly coupled with\na corresponding server side implementation, so I believe changing it\nto a separate deliverable would have no side effect and the mistral team\ncan continue the current release model.\n\nChange-Id: I0f93bac85965e6774c500c3580d86ccad0b49f4e\n'}, {'number': 2, 'created': '2020-01-06 10:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/a73f3ea683de305ca7357985a0500e5d609505f4', 'message': 'Make mistral-dashboard a separate deliverable\n\nmistral-dashboard is the only horizon plugin which is not marked as\nhorizon plugin in the releases repo now as mistral-dashboard is released\nas part of the mistral deliverable.\n\nNote that deliverables defined in releases repo should match deliverables\ndefined in the governance repo and the release team suggested to update\nthe deliverable definition in the governance repo first (with ACK from\nthe mistral team).\n\nBy making mistral-dashboard a separate deliberable, we can mark\nmistral-dashboard as horizon plugin (via the release repo).\nConsumers can find mistral-dashboard in the ""Horizon Plugins"" section\nin releases.openstack.org.\nIn addition, the horizon team uses deliverable files in the release repo\nto recognize the list of the horizon plugins so making mistral-dashboard\na separate deliverable would help the horizon team.\n\nA dashboard implementation is usually not tightly coupled with\na corresponding server side implementation, so I believe changing it\nto a separate deliverable would have no side effect and the mistral team\ncan continue the current release model.\n\nChange-Id: I0f93bac85965e6774c500c3580d86ccad0b49f4e\n'}, {'number': 3, 'created': '2020-01-16 13:44:04.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/7402a6549dc59199b71b77c0f147748552e1b23d', 'message': 'Make mistral-dashboard a separate deliverable\n\nmistral-dashboard is the only horizon plugin which is not marked as\nhorizon plugin in the releases repo now as mistral-dashboard is released\nas part of the mistral deliverable.\n\nNote that deliverables defined in releases repo should match deliverables\ndefined in the governance repo and the release team suggested to update\nthe deliverable definition in the governance repo first (with ACK from\nthe mistral team).\n\nBy making mistral-dashboard a separate deliberable, we can mark\nmistral-dashboard as horizon plugin (via the release repo).\nConsumers can find mistral-dashboard in the ""Horizon Plugins"" section\nin releases.openstack.org.\nIn addition, the horizon team uses deliverable files in the release repo\nto recognize the list of the horizon plugins so making mistral-dashboard\na separate deliverable would help the horizon team.\n\nA dashboard implementation is usually not tightly coupled with\na corresponding server side implementation, so I believe changing it\nto a separate deliverable would have no side effect and the mistral team\ncan continue the current release model.\n\nChange-Id: I0f93bac85965e6774c500c3580d86ccad0b49f4e\n'}]",0,700368,7402a6549dc59199b71b77c0f147748552e1b23d,27,10,3,841,,,0,"Make mistral-dashboard a separate deliverable

mistral-dashboard is the only horizon plugin which is not marked as
horizon plugin in the releases repo now as mistral-dashboard is released
as part of the mistral deliverable.

Note that deliverables defined in releases repo should match deliverables
defined in the governance repo and the release team suggested to update
the deliverable definition in the governance repo first (with ACK from
the mistral team).

By making mistral-dashboard a separate deliberable, we can mark
mistral-dashboard as horizon plugin (via the release repo).
Consumers can find mistral-dashboard in the ""Horizon Plugins"" section
in releases.openstack.org.
In addition, the horizon team uses deliverable files in the release repo
to recognize the list of the horizon plugins so making mistral-dashboard
a separate deliverable would help the horizon team.

A dashboard implementation is usually not tightly coupled with
a corresponding server side implementation, so I believe changing it
to a separate deliverable would have no side effect and the mistral team
can continue the current release model.

Change-Id: I0f93bac85965e6774c500c3580d86ccad0b49f4e
",git fetch https://review.opendev.org/openstack/governance refs/changes/68/700368/3 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,c32c64471477ca70a437f43d682d49699eb99da8,project-update, mistral-dashboard: repos: - openstack/mistral-dashboard, - openstack/mistral-dashboard,3,1
openstack%2Ftripleo-upgrade~master~I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e,openstack/tripleo-upgrade,master,I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e,Force OS_COMPUTE_API_VERSION to a lower one on workload test.,MERGED,2020-01-10 17:01:48.000000000,2020-01-16 14:08:14.000000000,2020-01-16 13:58:30.000000000,"[{'_account_id': 11166}, {'_account_id': 17216}, {'_account_id': 20775}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-10 17:01:48.000000000', 'files': ['templates/workload_launch.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/b717d4f08933c341d375e3ad43ec10768d0a7d04', 'message': 'Force OS_COMPUTE_API_VERSION to a lower one on workload test.\n\nAfter the upgrade prepare and right before the upgrade run\ncommand a workload test is executed, which creates an instance\nand performs a pingtest during the whole upgrade procedure.\nThe generated rc file for the OC has the OS_COMPUTE_API_VERSION\npointing to 2.latest which provokes a conflict in this situation\nas we have a OSP16 Undercloud and a OSP15 overcloud, failing with\nthe error: Version 2.79 is not supported by the API. Minimum is\nMinimum is 2.1 and maximum is 2.72.\n\nThis patch forces the maximum version on the script launch to be\n2.72 at max.\n\nChange-Id: I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e\n'}]",0,702007,b717d4f08933c341d375e3ad43ec10768d0a7d04,9,4,1,26343,,,0,"Force OS_COMPUTE_API_VERSION to a lower one on workload test.

After the upgrade prepare and right before the upgrade run
command a workload test is executed, which creates an instance
and performs a pingtest during the whole upgrade procedure.
The generated rc file for the OC has the OS_COMPUTE_API_VERSION
pointing to 2.latest which provokes a conflict in this situation
as we have a OSP16 Undercloud and a OSP15 overcloud, failing with
the error: Version 2.79 is not supported by the API. Minimum is
Minimum is 2.1 and maximum is 2.72.

This patch forces the maximum version on the script launch to be
2.72 at max.

Change-Id: I8c949de2083fa6b251ad7c8c6a2e57d6b9c3465e
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/07/702007/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/workload_launch.sh.j2'],1,b717d4f08933c341d375e3ad43ec10768d0a7d04,,export OS_COMPUTE_API_VERSION=2.72 ,,2,0
openstack%2Fcinder~stable%2Ftrain~I6c87d75e61796943e570f8f98803e9135ce7d6ee,openstack/cinder,stable/train,I6c87d75e61796943e570f8f98803e9135ce7d6ee,Mark storwize driver supported,MERGED,2019-12-30 14:57:21.000000000,2020-01-16 13:58:04.000000000,2020-01-16 07:49:40.000000000,"[{'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29716}, {'_account_id': 30428}]","[{'number': 1, 'created': '2019-12-30 14:57:21.000000000', 'files': ['doc/source/reference/support-matrix.ini', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'releasenotes/notes/ibm-storwize-supported-6518628fb78d58a4.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/243299e3bcb3b7c763b38ccd664f17173894fe71', 'message': 'Mark storwize driver supported\n\nStorwize cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We plan to mark storwize cinder driver as supported\nagain. This commit updated Storwize driver, release notes and\nsupport-matrix.ini.\n\nChange-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee\n(cherry picked from commit e012113ca14cad7f1d8d8dcd43eb4053d541fe87)\n'}]",0,700775,243299e3bcb3b7c763b38ccd664f17173894fe71,39,14,1,30428,,,0,"Mark storwize driver supported

Storwize cinder driver has been marked as unsupported due to lack
of external CI running log. Now IBM new external CI system is up
and running. We plan to mark storwize cinder driver as supported
again. This commit updated Storwize driver, release notes and
support-matrix.ini.

Change-Id: I6c87d75e61796943e570f8f98803e9135ce7d6ee
(cherry picked from commit e012113ca14cad7f1d8d8dcd43eb4053d541fe87)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/75/700775/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/support-matrix.ini', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py', 'releasenotes/notes/ibm-storwize-supported-6518628fb78d58a4.yaml']",3,243299e3bcb3b7c763b38ccd664f17173894fe71,mark_storwize_supported-stable/train,--- upgrade: - | IBM Storwize drivers had been previously marked unsupported. Testing requirements have been addressed and they are now fully supported again. IBM Storwize drivers allow cinder to manage volumes both in iSCSI and FC environment. ,,8,4
openstack%2Fgovernance~master~I8aea45dbd4b52dfedd31965764aa2cf0673f6c3f,openstack/governance,master,I8aea45dbd4b52dfedd31965764aa2cf0673f6c3f,Add ideas for OpenStack repository,MERGED,2020-01-09 07:59:07.000000000,2020-01-16 13:56:39.000000000,2020-01-16 13:52:37.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 4257}, {'_account_id': 7353}, {'_account_id': 8099}, {'_account_id': 8556}, {'_account_id': 10343}, {'_account_id': 10607}, {'_account_id': 12404}, {'_account_id': 13995}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 07:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/f5d36524be17eca8b92540df482c50268d44e0ef', 'message': 'Add ideas for OpenStack repository\n\nThis is the starting point for the ""ideas"" project.\n""ideas"" is a repository where everyone can submit their ideas for\nglobal OpenStack changes.\n\nIt is the follow up of a discussion in the last summit in Shanghai,\nwhere we discussed the lack of an easy way to browse and search history\nof all the (crazy) ideas for OpenStack floated on the mailing lists.\nWe established (due to recurring topics) that the MLs are not really\nappropriate for this searching and revision control.\n\nChange-Id: I8aea45dbd4b52dfedd31965764aa2cf0673f6c3f\n'}, {'number': 2, 'created': '2020-01-09 08:04:59.000000000', 'files': ['reference/technical-committee-repos.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/460204480904a7ec336d3184c998b6a1b5b04f04', 'message': 'Add ideas for OpenStack repository\n\nThis is the starting point for the ""ideas"" project.\n""ideas"" is a repository where everyone can submit their ideas for\nglobal OpenStack changes.\n\nIt is the follow up of a discussion in the last summit in Shanghai,\nwhere we discussed the lack of an easy way to browse and search history\nof all the (crazy) ideas for OpenStack floated on the mailing lists.\nWe established (due to recurring topics) that the MLs are not really\nappropriate for this searching and revision control.\n\nDepends-On: https://review.opendev.org/#/c/701530\nChange-Id: I8aea45dbd4b52dfedd31965764aa2cf0673f6c3f\n'}]",0,701678,460204480904a7ec336d3184c998b6a1b5b04f04,21,12,2,17068,,,0,"Add ideas for OpenStack repository

This is the starting point for the ""ideas"" project.
""ideas"" is a repository where everyone can submit their ideas for
global OpenStack changes.

It is the follow up of a discussion in the last summit in Shanghai,
where we discussed the lack of an easy way to browse and search history
of all the (crazy) ideas for OpenStack floated on the mailing lists.
We established (due to recurring topics) that the MLs are not really
appropriate for this searching and revision control.

Depends-On: https://review.opendev.org/#/c/701530
Change-Id: I8aea45dbd4b52dfedd31965764aa2cf0673f6c3f
",git fetch https://review.opendev.org/openstack/governance refs/changes/78/701678/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/technical-committee-repos.yaml'],1,f5d36524be17eca8b92540df482c50268d44e0ef,project-update, - repo: openstack/ideas,,1,0
openstack%2Fcharm-openstack-dashboard~master~Ic15f60517ed8a7f67704b15f4b42baabe74f83c6,openstack/charm-openstack-dashboard,master,Ic15f60517ed8a7f67704b15f4b42baabe74f83c6,Add disable-instance-snapshot config item,MERGED,2020-01-09 15:44:00.000000000,2020-01-16 13:55:39.000000000,2020-01-16 13:55:39.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2020-01-09 15:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/76978557b531c56b5ef43a2aa7326bc8ea8808d8', 'message': 'Add disable-instance-snapshot config item\n\nThis patchset adds the disable-instance-snapshot config item that\ncontrols the ""disable_instance_snapshot"" dictionary item in the\nLAUNCH_INSTANCE_DEFAULTS setting in local_settings.py\n\nChange-Id: Ic15f60517ed8a7f67704b15f4b42baabe74f83c6\nCloses-Bug: #1818221\n'}, {'number': 2, 'created': '2020-01-13 12:02:01.000000000', 'files': ['hooks/horizon_contexts.py', 'templates/newton/local_settings.py', 'unit_tests/test_horizon_contexts.py', 'config.yaml', 'templates/ocata/local_settings.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/03cb557fc8afc9526cd32d13b0fe7162f10d8c24', 'message': 'Add disable-instance-snapshot config item\n\nThis patchset adds the disable-instance-snapshot config item that\ncontrols the ""disable_instance_snapshot"" dictionary item in the\nLAUNCH_INSTANCE_DEFAULTS setting in local_settings.py\n\nChange-Id: Ic15f60517ed8a7f67704b15f4b42baabe74f83c6\nCloses-Bug: #1818221\n'}]",3,701755,03cb557fc8afc9526cd32d13b0fe7162f10d8c24,18,5,2,20870,,,0,"Add disable-instance-snapshot config item

This patchset adds the disable-instance-snapshot config item that
controls the ""disable_instance_snapshot"" dictionary item in the
LAUNCH_INSTANCE_DEFAULTS setting in local_settings.py

Change-Id: Ic15f60517ed8a7f67704b15f4b42baabe74f83c6
Closes-Bug: #1818221
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/55/701755/2 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'templates/newton/local_settings.py', 'unit_tests/test_horizon_contexts.py', 'config.yaml', 'templates/ocata/local_settings.py']",5,76978557b531c56b5ef43a2aa7326bc8ea8808d8,bug/1818221," 'create_volume': {{ default_create_volume }}, 'disable_instance_snapshot': {{ disable_instance_snapshot }},", 'create_volume': {{ default_create_volume }},38,2
openstack%2Fpuppet-ovn~master~I9c9d8f6463efb09465092601a113b5e56d920883,openstack/puppet-ovn,master,I9c9d8f6463efb09465092601a113b5e56d920883,Fix 'RedHat' misspelled as 'Redhat',MERGED,2020-01-12 09:51:40.000000000,2020-01-16 13:43:45.000000000,2020-01-16 13:43:45.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-12 09:51:40.000000000', 'files': ['spec/classes/ovn_controller_spec.rb', 'manifests/params.pp', 'spec/classes/ovn_northd_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/3efd8af87aeed45a9444c3777cbf52b51614b4f9', 'message': ""Fix 'RedHat' misspelled as 'Redhat'\n\nIn tests, osfamily 'RedHat' was misspelled as 'Redhat', so no tests were\nrunning for this OS.\n\nFixing this typo also means that the File[] resource test is no longer\nvalid, since it is now a Augeas[] resource. Updated test accordingly.\n\nAlso added 'systemd env' test for Debian, since I am at it.\n\nThis change increases resource coverage from 75% to 81.82%, which means\nwe should be on the right track.\n\nTo reduce confusion, I will submit tests for Change\n82cadd3a280e60e12f6720b3842b9e1ffbd7c9b2 in a separate change.\n\nChange-Id: I9c9d8f6463efb09465092601a113b5e56d920883\n""}]",0,702125,3efd8af87aeed45a9444c3777cbf52b51614b4f9,8,4,1,8064,,,0,"Fix 'RedHat' misspelled as 'Redhat'

In tests, osfamily 'RedHat' was misspelled as 'Redhat', so no tests were
running for this OS.

Fixing this typo also means that the File[] resource test is no longer
valid, since it is now a Augeas[] resource. Updated test accordingly.

Also added 'systemd env' test for Debian, since I am at it.

This change increases resource coverage from 75% to 81.82%, which means
we should be on the right track.

To reduce confusion, I will submit tests for Change
82cadd3a280e60e12f6720b3842b9e1ffbd7c9b2 in a separate change.

Change-Id: I9c9d8f6463efb09465092601a113b5e56d920883
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/25/702125/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ovn_controller_spec.rb', 'manifests/params.pp', 'spec/classes/ovn_northd_spec.rb']",3,3efd8af87aeed45a9444c3777cbf52b51614b4f9,," is_expected.to contain_augeas('config-ovn-northd').with({ :context => platform_params[:ovn_northd_context], :changes => ""set "" + platform_params[:ovn_northd_option_name] + "" '\""--db-nb-addr=0.0.0.0 --db-sb-addr=0.0.0.0 --db-nb-create-insecure-remote=yes --db-sb-create-insecure-remote=yes \""'"", }) :ovn_northd_service_pattern => 'ovn-northd', :ovn_northd_context => '/files/etc/default/ovn-central', :ovn_northd_option_name => 'OVN_CTL_OPTS' it_behaves_like 'systemd env' when 'RedHat' :ovn_northd_service_pattern => nil, :ovn_northd_context => '/files/etc/sysconfig/ovn-northd', :ovn_northd_option_name => 'OVN_NORTHD_OPTS'"," is_expected.to contain_file('/etc/sysconfig/ovn-northd').with( :ensure => 'file', :mode => '0644', :owner => 'root', :group => 'root', :content => ""OVN_NORTHD_OPTS=--db-nb-addr=0.0.0.0 --db-sb-addr=0.0.0.0 --db-nb-create-insecure-remote=yes --db-sb-create-insecure-remote=yes"", :before => 'Service[northd]', ) :ovn_northd_service_pattern => 'ovn-northd' when 'Redhat' :ovn_northd_service_pattern => 'undef'",16,14
openstack%2Fopenstack-helm-infra~master~I167ff3bde282239a504375828f441a1a46e35598,openstack/openstack-helm-infra,master,I167ff3bde282239a504375828f441a1a46e35598,RFC: Add yamllint to zuul-linter playbook,ABANDONED,2018-09-17 20:08:42.000000000,2020-01-16 13:42:01.000000000,,"[{'_account_id': 8898}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 28701}]","[{'number': 1, 'created': '2018-09-17 20:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/989f7a19822c83f19d110b9dd5c7b13f00fc2d0d', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 2, 'created': '2018-09-17 20:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e5180bcab884c2af21cbdf8457ef1dcc9a5a5973', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 3, 'created': '2018-09-17 20:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/354c6584ff1fd09aeaf1265f4b6d05e4b38c32c4', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 4, 'created': '2018-09-17 20:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d1a81ac7ada0711369ea0e18846538d4e2b061c4', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 5, 'created': '2018-09-17 20:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5b5c030bc7be231ed87eecb6b6dc3c40dc564096', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 6, 'created': '2018-09-17 20:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9fb18d48ad33f55fc1e6fd838015a64c785df6d7', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 7, 'created': '2018-09-17 21:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/192de9e638b431a53b2fa71b18984ed2456a7b24', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 8, 'created': '2018-09-18 12:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a48ffdba0baa8205fb55648829b0e56f587a28ae', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 9, 'created': '2018-09-18 13:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/42b948ab3dfe10d909e879144fe793ec7cd3bb21', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 10, 'created': '2018-09-24 13:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/22a05e62974271fd76d13e616ca726bd7885b58b', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 11, 'created': '2018-10-02 13:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/230c0e7fad47f820a371c2024ca5e52606828ea7', 'message': 'WIP: Add yamllint to zuul-linter playbook\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n'}, {'number': 12, 'created': '2018-11-27 18:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/25dce3fba087c881a5726f1e176ed30fa7ac1cb5', 'message': ""RFC: Add yamllint to zuul-linter playbook\n\nThis proposes adding yamllint to the gates to provide a manner\nfor enforcing ordering of charts' values.yaml files\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n""}, {'number': 13, 'created': '2018-11-27 18:49:48.000000000', 'files': ['roles/deploy-yamllint/tasks/main.yaml', 'roles/lint-values/defaults/main.yml', '.yamllint', 'roles/lint-values/tasks/util-lint-chart.yaml', 'prometheus-node-exporter/values.yaml', 'roles/deploy-yamllint/defaults/main.yml', 'roles/lint-values/tasks/main.yaml', 'playbooks/zuul-linter.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/108022787f9509393bd5d013d2342a613fe1f8f0', 'message': ""RFC: Add yamllint to zuul-linter playbook\n\nThis proposes adding yamllint to the gates to provide a manner\nfor enforcing ordering of charts' values.yaml files\n\nStory: 2002206\nTask: 21742\n\nChange-Id: I167ff3bde282239a504375828f441a1a46e35598\n""}]",6,603222,108022787f9509393bd5d013d2342a613fe1f8f0,22,4,13,17591,,,0,"RFC: Add yamllint to zuul-linter playbook

This proposes adding yamllint to the gates to provide a manner
for enforcing ordering of charts' values.yaml files

Story: 2002206
Task: 21742

Change-Id: I167ff3bde282239a504375828f441a1a46e35598
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/22/603222/2 && git format-patch -1 --stdout FETCH_HEAD,"['roles/deploy-yamllint/tasks/main.yaml', 'roles/lint-values/defaults/main.yml', '.yamllint', 'prometheus-node-exporter/values.yaml', 'roles/deploy-yamllint/defaults/main.yml', 'roles/lint-values/tasks/main.yaml', 'playbooks/zuul-linter.yaml']",7,989f7a19822c83f19d110b9dd5c7b13f00fc2d0d,gate/add_yamllint_rules," vars_files: - vars.yaml vars: work_dir: ""{{ zuul.project.src_dir }}/{{ zuul_osh_infra_relative_path | default('') }}"" gather_facts: True become: yes roles: - deploy-python-pip - deploy-yamllint tags: - deploy-python-pip - deploy-yamllint - hosts: primary - hosts: primary vars_files: - vars.yaml vars: work_dir: ""{{ zuul.project.src_dir }}/{{ zuul_osh_infra_relative_path | default('') }}"" roles: - lint-values tags: - lint-values",,219,62
openstack%2Fopenstack-helm~master~Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084,openstack/openstack-helm,master,Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084,RFC: Add reference values.yaml template for new charts,ABANDONED,2018-06-21 16:45:28.000000000,2020-01-16 13:41:54.000000000,,"[{'_account_id': 1091}, {'_account_id': 22348}, {'_account_id': 28701}]","[{'number': 1, 'created': '2018-06-21 16:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/db7e0b75e44ce3e2a84208dd8a14883a4559cba3', 'message': 'RFC: Add reference values.yaml skeleton for new charts\n\nThis proposes adding a values.yaml skeleton to the devref docs to\nprovide a reference for creating new charts in openstack-helm.\n\nChange-Id: Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084\n'}, {'number': 2, 'created': '2018-09-04 20:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/51b756e907388a2ef0ee2ab3237febdcffad8ae7', 'message': 'RFC: Add reference values.yaml skeleton for new charts\n\nThis proposes adding a values.yaml skeleton to the devref docs to\nprovide a reference for creating new charts in openstack-helm.\n\nChange-Id: Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084\n'}, {'number': 3, 'created': '2018-09-04 20:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cfb00de2cd3c7b56ad63d24bcab26278f2df23c5', 'message': 'RFC: Add reference values.yaml template for new charts\n\nThis proposes adding an example values.yaml template, ordered in\nthe fashion outlined in the values ordering spec. That spec is\nlisted below as a dependency for this patchset\n\nDepends-On: https://review.openstack.org/552485\nStory: 2002206\nTask: 21742\n\nChange-Id: Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084\n'}, {'number': 4, 'created': '2018-09-19 01:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8bfb0bfe098a03679080e6960b5bb63f31a8861e', 'message': 'RFC: Add reference values.yaml template for new charts\n\nThis proposes adding an example values.yaml template, ordered in\nthe fashion outlined in the values ordering spec. That spec is\nlisted below as a dependency for this patchset\n\nDepends-On: https://review.openstack.org/552485\nStory: 2002206\nTask: 21742\n\nChange-Id: Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084\n'}, {'number': 5, 'created': '2018-11-27 18:49:01.000000000', 'files': ['doc/source/devref/values-template.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8317a47ee5903406337019578e22c744424f1ad0', 'message': 'RFC: Add reference values.yaml template for new charts\n\nThis proposes adding an example values.yaml template, ordered in\nthe fashion outlined in the values ordering spec. That spec is\nlisted below as a dependency for this patchset\n\nDepends-On: https://review.openstack.org/552485\nStory: 2002206\nTask: 21742\n\nChange-Id: Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084\n'}]",1,577234,8317a47ee5903406337019578e22c744424f1ad0,12,3,5,17591,,,0,"RFC: Add reference values.yaml template for new charts

This proposes adding an example values.yaml template, ordered in
the fashion outlined in the values ordering spec. That spec is
listed below as a dependency for this patchset

Depends-On: https://review.openstack.org/552485
Story: 2002206
Task: 21742

Change-Id: Idb77bdd6ad29082ac77ea14c1de7cd2669b5a084
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/34/577234/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/values_skeleton.yaml'],1,db7e0b75e44ce3e2a84208dd8a14883a4559cba3,update_developer_docs,"# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. #NOTE(srwilkers): This is an example values skeleton that highlights the top # level keys used in the charts in openstack-helm. These keys should account # for the majority, if not all, values to be exposed in any new charts added to # the openstack-helm, openstack-helm-infra, or openstack-helm-addons repos. # The creation of new top level keys (ie: keys at the level of labels, images, # etc) should be discussed. This prevents values sprawl, and ensures we are # maintaining consistent override mechanisms throughout all charts # These are the labels for the components of a service. The example given will # place the API pods for service Foo, the pods spawned by jobs (db jobs, rabbit, # etc) for service Foo, and the test pods for service Foo on nodes with the # labels defined here labels: api: node_selector_key: openstack-control-plane node_selector_value: enabled job: node_selector_key: openstack-control-plane node_selector_value: enabled test: node_selector_key: openstack-control-plane node_selector_value: enabled # Images required for the chart for service Foo. These are the images that are # common across most of the charts for openstack services. Note foo_db_sync # should be renamed, where foo is the name of the chart (service) being added images: tags: bootstrap: docker.io/openstackhelm/heat:newton dep_check: quay.io/stackanetes/kubernetes-entrypoint:v0.3.1 test: docker.io/kolla/ubuntu-source-rally:4.0.0 db_init: docker.io/openstackhelm/heat:newton foo_db_sync: docker.io/openstackhelm/foo:newton db_drop: docker.io/openstackhelm/heat:newton ks_user: docker.io/openstackhelm/heat:newton ks_service: docker.io/openstackhelm/heat:newton ks_endpoints: docker.io/openstackhelm/heat:newton rabbit_init: docker.io/rabbitmq:3.7-management image_repo_sync: docker.io/docker:17.07.0 pull_policy: ""IfNotPresent"" local_registry: active: false exclude: - dep_check - image_repo_sync # This section contains values tied to the aspects of pods we wish to control. # This includes things like: pod affinity/antiaffinity, additional volume # mounts, replicas, upgrade strategy, pod disruption budgets, and container # resources, pod: affinity: anti: type: default: preferredDuringSchedulingIgnoredDuringExecution topologyKey: default: kubernetes.io/hostname mounts: foo_api: init_container: null foo_api: foo_bootstrap: init_container: null foo_bootstrap: foo_tests: init_container: null foo_tests: replicas: api: 1 lifecycle: upgrades: deployments: revision_history: 3 pod_replacement_strategy: RollingUpdate rolling_update: max_unavailable: 1 max_surge: 3 disruption_budget: api: min_available: 0 resources: enabled: false api: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" jobs: bootstrap: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" db_init: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" db_sync: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" db_drop: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" rabbit_init: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" ks_endpoints: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" ks_service: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" ks_user: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" tests: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" image_repo_sync: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" # This section contains values specific to the networking aspects of the chart, # specifically the ingress configuration (if the service has an API that should # be exposed externally) and the node port for your service (if required). Note # that duplicate node ports will result in collisions, so be sure the node port # you're adding is unique across all charts network: api: ingress: public: true classes: namespace: ""nginx"" cluster: ""nginx-cluster"" annotations: nginx.ingress.kubernetes.io/rewrite-target: / external_policy_local: false node_port: enabled: false port: #Nodeport for your service # This section can be used to define the behavior of the bootstrap job for your # chart. This can be useful for ensuring your chart can perform the desired # bootstrapping behavior without needing to modify the chart template directly bootstrap: enabled: false ks_user: foo script: | openstack token issue # The dependencies for charts are defined here. The dynamic key holds the # dependencies that are dependent upon certain aspects of a chart being enabled # or not (eg: the local image registry fucntionality is disabled by default. If # enabled, all components of the chart will include this dependency in addition # to their static dependencies). The static key holds all dependencies that are # always required by the chart. For openstack services, these include things # like the completion of the database initialization and synchronization, the # rabbitmq cluster being deployed, the rabbitmq users being created, etc dependencies: dynamic: common: local_image_registry: jobs: - foo-image-repo-sync services: - endpoint: node service: local_image_registry static: api: jobs: - foo-db-sync - foo-ks-user - foo-ks-endpoints - foo-rabbit-init services: - endpoint: internal service: oslo_db - endpoint: internal service: identity - endpoint: internal service: oslo_messaging db_drop: services: - endpoint: internal service: oslo_db db_init: services: - endpoint: internal service: oslo_db db_sync: jobs: - foo-db-init services: - endpoint: internal service: oslo_db image_repo_sync: services: - endpoint: internal service: local_image_registry ks_endpoints: jobs: - foo-ks-service services: - endpoint: internal service: identity ks_service: services: - endpoint: internal service: identity ks_user: services: - endpoint: internal service: identity rabbit_init: services: - endpoint: internal service: oslo_messaging # This section is used for configuring the various components that make up the # chart. conf: # This section defines the paste.ini configuration file (if required by the # service being added), and will get loaded into the foot-etc configmap. This # allows for defining the paste configuration wholesale via the values file paste: composite:main: use: egg:Paste#urlmap /: foo_version /v1: foo-api-keystone pipeline:foo_version: pipeline: cors http_proxy_to_wsgi versionapp pipeline:foo_api: pipeline: cors http_proxy_to_wsgi unauthenticated-context apiapp # This section defines the policy.json file for the service, and will get # loaded into the foo-etc configmap. This allows for defining the policy for # service foo wholesale via the values file. policy: admin: role:admin observer: role:observer creator: role:creator # This section uwsgi for the service (if applicable), and will get # loaded into the foo-etc configmap foo_api: uwsgi: socket: null protocol: http processes: 1 lazy: true vacuum: true no-default-app: true memory-report: true plugins: python paste: ""config:/etc/foo/foo-api-paste.ini"" add-header: ""Connection: close"" # This section defines the configuration values for the service (those found # in /etc/foo/foo.conf typically), and allow us to use the to_oslo_conf helper # template in helm-toolkit to generate the desired configuration file. The # resulting configuration file is loaded into the foo-etc configmap and then # mounted into the pods that require it. foo: DEFAULT: transport_url: null keystone_authtoken: auth_type: password auth_version: v3 memcache_security_strategy: ENCRYPT memcache_secret_key: null database: max_retries: -1 foo_api: #NOTE(portdirect): the bind port should not be defined, and is manipulated # via the endpoints section. bind_port: null # Names of secrets used in the chart. For the openstack services, these are # typically sufficient, where foo is the name of the service being added secrets: identity: admin: foo-keystone-admin foo: foo-keystone-user oslo_db: admin: foo-db-admin foo: foo-db-user oslo_messaging: admin: foo-rabbitmq-admin foo: foo-rabbitmq-user # The endpoints section defines the endpoints a service requires. OpenStack-Helm # uses endpoint lookups to handle things like setting env variables for pods, # configuring URLs in configuration files via configmaps, etc. The endpoints # listed here are common across most openstack services, and include things like # the database endpoints (oslo_db), the messaging service (oslo_messaging), the # caching service (memcache), keystone (identity), # and the local docker registry (local_image_registry) endpoint. Any new chart # will require adding an entry for the new service. endpoints: cluster_domain_suffix: cluster.local local_image_registry: name: docker-registry namespace: docker-registry hosts: default: localhost internal: docker-registry node: localhost host_fqdn_override: default: null port: registry: node: 5000 identity: name: keystone auth: admin: region_name: RegionOne username: admin password: password project_name: admin user_domain_name: default project_domain_name: default foo: role: admin region_name: RegionOne username: foo password: password project_name: service user_domain_name: default project_domain_name: default hosts: default: keystone-api public: keystone host_fqdn_override: default: null path: default: /v3 scheme: default: http port: admin: default: 35357 api: default: 80 # This should be modified to configure the endpoint for any new service. The # occurences of foo can be changed here to match the name of the service, and # the top foo: key should be renamed to match the keystone catalog entry for # the service (eg: keystone's entry is identity) foo: name: foo hosts: default: foo-api public: foo host_fqdn_override: default: null path: default: / scheme: default: http port: api: default: #Port for service foo public: 80 oslo_db: auth: admin: username: root password: password foo: username: foo password: password hosts: default: mariadb host_fqdn_override: default: null path: /foo scheme: mysql+pymysql port: mysql: default: 3306 oslo_messaging: auth: admin: username: rabbitmq password: password foo: username: foo password: password hosts: default: rabbitmq host_fqdn_override: default: null path: /foo scheme: rabbit port: amqp: default: 5672 http: default: 15672 oslo_cache: auth: # NOTE(portdirect): this is used to define the value for keystone # authtoken cache encryption key, if not set it will be populated # automatically with a random value, but to take advantage of # this feature all services should be set to use the same key, # and memcache service. memcache_secret_key: null hosts: default: memcached host_fqdn_override: default: null port: memcache: default: 11211 # This section defines which components of a chart are enabled. Each template # in a chart for a service should include a toggle for enabling or disabling it. # The components below are typical across many openstack services, and can be # used as a starting point for identifying which templates should be included. manifests: configmap_bin: true configmap_etc: true deployment_api: true ingress_api: true job_bootstrap: true job_db_init: true job_db_sync: true job_db_drop: false job_image_repo_sync: true job_rabbit_init: true job_ks_endpoints: true job_ks_service: true job_ks_user: true pdb_api: true pod_test: true secret_db: true secret_keystone: true secret_rabbitmq: true service_ingress_api: true service_api: true ",,488,0
openstack%2Fopenstack-helm~master~I8bde424f11c0e5d5469df5cc9f7e13a4eecd1910,openstack/openstack-helm,master,I8bde424f11c0e5d5469df5cc9f7e13a4eecd1910,WIP: OVS prometheus exporter,ABANDONED,2018-03-02 13:51:43.000000000,2020-01-16 13:41:44.000000000,,"[{'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-03-02 13:51:43.000000000', 'files': ['openvswitch/values.yaml', 'openvswitch/templates/monitoring/prometheus/exporter-service.yaml', 'openvswitch/templates/monitoring/prometheus/exporter-configmap-bin.yaml', 'openvswitch/templates/monitoring/prometheus/bin/_openvswitch-exporter.sh.tpl', 'openvswitch/templates/monitoring/prometheus/exporter-daemonset.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fe37305ae5c38689b7cf8a0d515e0b504dfd99c8', 'message': 'WIP: OVS prometheus exporter\n\nChange-Id: I8bde424f11c0e5d5469df5cc9f7e13a4eecd1910\n'}]",1,549215,fe37305ae5c38689b7cf8a0d515e0b504dfd99c8,5,2,1,17591,,,0,"WIP: OVS prometheus exporter

Change-Id: I8bde424f11c0e5d5469df5cc9f7e13a4eecd1910
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/15/549215/1 && git format-patch -1 --stdout FETCH_HEAD,"['openvswitch/values.yaml', 'openvswitch/templates/monitoring/prometheus/exporter-service.yaml', 'openvswitch/templates/monitoring/prometheus/exporter-configmap-bin.yaml', 'openvswitch/templates/monitoring/prometheus/bin/_openvswitch-exporter.sh.tpl', 'openvswitch/templates/monitoring/prometheus/exporter-daemonset.yaml']",5,fe37305ae5c38689b7cf8a0d515e0b504dfd99c8,ovs_exporter,"{{/* Copyright 2017 The Openstack-Helm Authors. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} {{- if and .Values.manifests.monitoring.prometheus.daemonset_exporter .Values.monitoring.prometheus.enabled }} {{- $envAll := . }} {{- $dependencies := .Values.dependencies.static.prometheus_ovs_exporter }} {{- $prometheus_annotations := $envAll.Values.monitoring.prometheus.ovs_exporter }} {{- $serviceAccountName := ""prometheus-ovs-exporter""}} {{ tuple $envAll $dependencies $serviceAccountName | include ""helm-toolkit.snippets.kubernetes_pod_rbac_serviceaccount"" }} --- apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: openvswitch-exporter spec: {{ tuple $envAll ""prometheus_ovs_exporter"" | include ""helm-toolkit.snippets.kubernetes_upgrades_daemonset"" | indent 2 }} template: metadata: labels: {{ tuple $envAll ""prometheus_ovs_exporter"" ""exporter"" | include ""helm-toolkit.snippets.kubernetes_metadata_labels"" | indent 8 }} annotations: configmap-bin-hash: {{ tuple ""exporter-configmap-bin.yaml"" . | include ""helm-toolkit.utils.hash"" }} spec: serviceAccountName: {{ $serviceAccountName }} nodeSelector: {{ .Values.labels.ovs.node_selector_key }}: {{ .Values.labels.ovs.node_selector_value }} hostNetwork: true hostPID: true initContainers: {{ tuple $envAll $dependencies list | include ""helm-toolkit.snippets.kubernetes_entrypoint_init_container"" | indent 8 }} containers: - name: openvswitch-exporter image: {{ .Values.images.tags.prometheus_ovs_exporter }} imagePullPolicy: {{ .Values.images.pull_policy }} {{ tuple $envAll $envAll.Values.pod.resources.prometheus_ovs_exporter | include ""helm-toolkit.snippets.kubernetes_resources"" | indent 10 }} securityContext: runAsUser: 0 privileged: true command: - /tmp/openvswitch-exporter.sh - start ports: - name: metrics containerPort: {{ tuple ""prometheus_ovs_exporter"" ""internal"" ""metrics"" . | include ""helm-toolkit.endpoints.endpoint_port_lookup"" }} volumeMounts: - name: openvswitch-exporter-bin mountPath: /tmp/openvswitch-exporter.sh subPath: openvswitch-exporter.sh readOnly: true volumes: - name: openvswitch-exporter-bin configMap: name: openvswitch-exporter-bin defaultMode: 0555 {{- end }} ",,208,0
openstack%2Fopenstack-helm~master~Ib14b390207dcb13aa7ddfcc352e61bd6455a3391,openstack/openstack-helm,master,Ib14b390207dcb13aa7ddfcc352e61bd6455a3391,WIP: Remove and consolidate deployment tooling,ABANDONED,2019-12-17 17:32:13.000000000,2020-01-16 13:41:32.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-17 17:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/abb4cacc704878d25b7c7190de52ccd5b533d0b6', 'message': 'WIP: Remove and consolidate deployment tooling\n\nChange-Id: Ib14b390207dcb13aa7ddfcc352e61bd6455a3391\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-12-17 17:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bd652be8143bd62d23f09e3deb02e48670d1b84d', 'message': 'WIP: Remove and consolidate deployment tooling\n\nChange-Id: Ib14b390207dcb13aa7ddfcc352e61bd6455a3391\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-12-17 17:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f797b87c485cf197924804a2c532935abf892d36', 'message': 'WIP: Remove and consolidate deployment tooling\n\nChange-Id: Ib14b390207dcb13aa7ddfcc352e61bd6455a3391\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-12-17 17:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9f2981b84bbc653d7fe1034cb75dc62b654ff80b', 'message': 'WIP: Remove and consolidate deployment tooling\n\nChange-Id: Ib14b390207dcb13aa7ddfcc352e61bd6455a3391\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-12-18 16:08:56.000000000', 'files': ['doc/source/install/developer/deploy-with-ceph.rst', 'tools/deployment/common/setup-gateway.sh', 'tools/deployment/common/create-octavia-certs.sh', 'tools/deployment/developer/common/050-mariadb.sh', 'tools/deployment/developer/common/140-openvswitch.sh', 'zuul.d/jobs-openstack-helm.yaml', 'tools/deployment/developer/common/030-ingress.sh', 'tools/deployment/common/use-it.sh', 'tools/deployment/developer/common/090-heat.sh', 'doc/source/install/common-requirements.rst', 'tools/deployment/developer/common/010-deploy-k8s.sh', 'tools/deployment/developer/common/100-horizon.sh', 'tools/deployment/baremetal/040-mariadb.sh', 'tools/deployment/baremetal/100-heat.sh', 'tools/deployment/common/octavia.sh', 'tools/deployment/developer/common/060-rabbitmq.sh', 'tools/deployment/baremetal/070-keystone.sh', 'tools/deployment/developer/common/000-install-packages.sh', 'tools/deployment/baremetal/000-install-packages.sh', 'doc/source/install/developer/index.rst', 'tools/deployment/developer/common/080-keystone.sh', 'tools/deployment/baremetal/050-rabbitmq.sh', 'tools/deployment/common/create-resource-for-octavia.sh', 'tools/deployment/common/env-variables.sh', 'doc/source/install/developer/deploy-with-nfs.rst', 'zuul.d/project.yaml', 'tools/deployment/developer/common/020-setup-client.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0022f4cfaeaa77d2011a89254dab5b5b7e38a984', 'message': 'WIP: Remove and consolidate deployment tooling\n\nChange-Id: Ib14b390207dcb13aa7ddfcc352e61bd6455a3391\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,699470,0022f4cfaeaa77d2011a89254dab5b5b7e38a984,12,2,5,17591,,,0,"WIP: Remove and consolidate deployment tooling

Change-Id: Ib14b390207dcb13aa7ddfcc352e61bd6455a3391
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/70/699470/3 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/common/setup-gateway.sh', 'tools/deployment/baremetal/100-heat.sh', 'tools/deployment/common/create-octavia-certs.sh', 'tools/deployment/common/octavia.sh', 'tools/deployment/developer/common/060-rabbitmq.sh', 'tools/deployment/baremetal/070-keystone.sh', 'tools/deployment/developer/common/000-install-packages.sh', 'tools/deployment/developer/common/050-mariadb.sh', 'tools/deployment/baremetal/000-install-packages.sh', 'tools/deployment/developer/common/140-openvswitch.sh', 'zuul.d/jobs-openstack-helm.yaml', 'tools/deployment/developer/common/030-ingress.sh', 'tools/deployment/developer/common/080-keystone.sh', 'tools/deployment/baremetal/050-rabbitmq.sh', 'tools/deployment/common/use-it.sh', 'tools/deployment/common/create-resource-for-octavia.sh', 'tools/deployment/common/env-variables.sh', 'tools/deployment/developer/common/090-heat.sh', 'tools/deployment/developer/common/010-deploy-k8s.sh', 'tools/deployment/developer/common/100-horizon.sh', 'tools/deployment/baremetal/040-mariadb.sh', 'tools/deployment/developer/common/020-setup-client.sh']",22,abb4cacc704878d25b7c7190de52ccd5b533d0b6,repo-cleanup,,../../common/setup-client.sh,91,310
openstack%2Fopenstack-helm-infra~master~Iad140344bc760a8a006c0f6aa6def557d70e43aa,openstack/openstack-helm-infra,master,Iad140344bc760a8a006c0f6aa6def557d70e43aa,DNM: Test experimental job triggers,ABANDONED,2019-11-13 19:57:48.000000000,2020-01-16 13:41:23.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-13 19:57:48.000000000', 'files': ['elasticsearch/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7462b8293f5be0c794cf7c483b9883287d9f04fd', 'message': 'DNM: Test experimental job triggers\n\nChange-Id: Iad140344bc760a8a006c0f6aa6def557d70e43aa\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,694164,7462b8293f5be0c794cf7c483b9883287d9f04fd,5,2,1,17591,,,0,"DNM: Test experimental job triggers

Change-Id: Iad140344bc760a8a006c0f6aa6def557d70e43aa
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/64/694164/1 && git format-patch -1 --stdout FETCH_HEAD,['elasticsearch/values.yaml'],1,7462b8293f5be0c794cf7c483b9883287d9f04fd,test-experimental-jobs, data: 2, data: 3,1,1
openstack%2Fopenstack-helm-infra~master~Ic726e0386272a9b714e10c7d647a9becf2b7d77f,openstack/openstack-helm-infra,master,Ic726e0386272a9b714e10c7d647a9becf2b7d77f,DNM: Test ceph-mgr prometheus module config,ABANDONED,2019-11-11 14:38:32.000000000,2020-01-16 13:39:09.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-11 14:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bfd1e09756ebb3b75b316c1956be204ee7ff68e3', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-11-11 14:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/95106d62c46f7b2b8330b51aadf5f62164b50c6f', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-11-11 16:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/0c10cf704d282c9842d918dc2985992842d6f78b', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-11-11 17:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1f820745b74df16e6e8c348ca0d3330ffd0e8a4e', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-11-11 19:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e045256537354bd8f4db797cfbccd33cadfe6151', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 6, 'created': '2019-11-11 20:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/72353515cd11379e3eebf0522d9333a01c01a86e', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 7, 'created': '2019-11-12 12:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/21f68f30a04fb0686575117351c96641a504df06', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 8, 'created': '2019-11-12 14:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e6be7a35b4b91f33829a2c2213a7d820b288de0c', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 9, 'created': '2019-11-12 18:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6e486f579e86ce0eff848a811bd84e2ba9f162c1', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 10, 'created': '2019-11-12 18:29:23.000000000', 'files': ['tools/deployment/osh-infra-monitoring/050-prometheus.sh', 'nagios/values.yaml', 'roles/gather-prom-metrics/tasks/main.yaml', 'ceph-client/values.yaml', 'zuul.d/project.yaml', 'tools/deployment/multinode/030-ceph.sh', 'zuul.d/jobs.yaml', 'tools/deployment/osh-infra-monitoring/120-nagios.sh', 'tools/deployment/multinode/110-nagios.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1a8c26cc67fc77ccacb9f17ee1cf755516fabf29', 'message': 'DNM: Test ceph-mgr prometheus module config\n\nChange-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,693703,1a8c26cc67fc77ccacb9f17ee1cf755516fabf29,36,2,10,17591,,,0,"DNM: Test ceph-mgr prometheus module config

Change-Id: Ic726e0386272a9b714e10c7d647a9becf2b7d77f
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/03/693703/10 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/multinode/050-prometheus.sh', 'ceph-client/values.yaml', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml']",4,bfd1e09756ebb3b75b316c1956be204ee7ff68e3,test-ceph-mgr, # - ./tools/deployment/multinode/060-alertmanager.sh # - ./tools/deployment/multinode/070-kube-state-metrics.sh # - ./tools/deployment/multinode/080-node-exporter.sh # - ./tools/deployment/multinode/085-process-exporter.sh # - ./tools/deployment/multinode/090-openstack-exporter.sh # - ./tools/deployment/multinode/100-grafana.sh # - ./tools/deployment/multinode/110-nagios.sh # - ./tools/deployment/multinode/115-radosgw-osh-infra.sh # - ./tools/deployment/multinode/120-elasticsearch.sh # - ./tools/deployment/multinode/125-fluentbit.sh # - ./tools/deployment/multinode/130-fluentd-daemonset.sh # - ./tools/deployment/multinode/135-fluentd-deployment.sh # - ./tools/deployment/multinode/140-kibana.sh # - ./tools/deployment/multinode/600-grafana-selenium.sh || true # - ./tools/deployment/multinode/610-nagios-selenium.sh || true # - ./tools/deployment/multinode/620-prometheus-selenium.sh || true # - ./tools/deployment/multinode/630-kibana-selenium.sh || true, - ./tools/deployment/multinode/060-alertmanager.sh - ./tools/deployment/multinode/070-kube-state-metrics.sh - ./tools/deployment/multinode/080-node-exporter.sh - ./tools/deployment/multinode/085-process-exporter.sh - ./tools/deployment/multinode/090-openstack-exporter.sh - ./tools/deployment/multinode/100-grafana.sh - ./tools/deployment/multinode/110-nagios.sh - ./tools/deployment/multinode/115-radosgw-osh-infra.sh - ./tools/deployment/multinode/120-elasticsearch.sh - ./tools/deployment/multinode/125-fluentbit.sh - ./tools/deployment/multinode/130-fluentd-daemonset.sh - ./tools/deployment/multinode/135-fluentd-deployment.sh - ./tools/deployment/multinode/140-kibana.sh - ./tools/deployment/multinode/600-grafana-selenium.sh || true - ./tools/deployment/multinode/610-nagios-selenium.sh || true - ./tools/deployment/multinode/620-prometheus-selenium.sh || true - ./tools/deployment/multinode/630-kibana-selenium.sh || true,28,24
openstack%2Fopenstack-helm-infra~master~I3f2c93a9488bb0c0790914673f0ad67fc684770e,openstack/openstack-helm-infra,master,I3f2c93a9488bb0c0790914673f0ad67fc684770e,WIP/DNM: Test fluentd kafka outputs,ABANDONED,2019-09-18 20:31:45.000000000,2020-01-16 13:39:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-09-18 20:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/97533a0616f7cdd8d363601d65324078ef19db59', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-09-19 13:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ab00a5aae16fc61bb770cac6c52f9b468a7456b6', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-09-19 14:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/01463212a0dea3170bfb9e9822ee8137db7854b8', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-09-19 14:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bc6b5e720d2144a98840a506e8aee936a642e481', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-09-25 15:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/15f63fb8ad666a32105bdf3a9c4ff1991d58d39a', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 6, 'created': '2019-09-25 17:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cdf299a4f515e605650504de19f1e41189463375', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 7, 'created': '2019-09-25 20:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3b64bf3fdea611059303b708ed6e3ddb5caf45d3', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 8, 'created': '2019-09-25 20:24:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e7a058d535c2f2054e1bcee23962d296c830cdb1', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 9, 'created': '2019-09-25 22:05:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/70ffe8212ba54cc2301a758301711614aff4369b', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 10, 'created': '2019-10-24 18:17:48.000000000', 'files': ['tools/deployment/osh-infra-logging/100-fluentd-daemonset.sh', 'fluentd/templates/deployment-fluentd.yaml', 'playbooks/osh-infra-collect-logs.yaml', 'zookeeper/values.yaml', 'tools/deployment/osh-infra-logging/090-kafka.sh', 'zuul.d/jobs.yaml', 'tools/deployment/osh-infra-logging/080-zookeeper.sh', 'tools/deployment/common/fluentd-daemonset.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a6788abb09812998903753f90ff4bc8153e13931', 'message': 'WIP/DNM: Test fluentd kafka outputs\n\nChange-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,682990,a6788abb09812998903753f90ff4bc8153e13931,18,1,10,17591,,,0,"WIP/DNM: Test fluentd kafka outputs

Change-Id: I3f2c93a9488bb0c0790914673f0ad67fc684770e
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/90/682990/5 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/osh-infra-logging/100-fluentd-daemonset.sh', 'fluentd/templates/deployment-fluentd.yaml', 'zuul.d/jobs.yaml', 'tools/deployment/common/fluentd-daemonset.sh']",4,97533a0616f7cdd8d363601d65324078ef19db59,fluentd-kafka," <system> log_level error </system> <filter **> @type record_transformer <record> topic fjarnskaggle </record> </filter> @type kafka2 @log_level debug get_kafka_client_log true brokers ""#{ENV['KAFKA_BROKER']}"" use_event_time true <format> @type json </format> topic_key topic <buffer topic>"," <match libvirt.**> <buffer> chunk_limit_size 512K flush_interval 5s flush_thread_count 8 queue_limit_length 32 retry_forever false retry_max_interval 30 </buffer> host ""#{ENV['ELASTICSEARCH_HOST']}"" reload_connections false reconnect_on_error true reload_on_failure true include_tag_key true logstash_format true logstash_prefix libvirt password ""#{ENV['ELASTICSEARCH_PASSWORD']}"" port ""#{ENV['ELASTICSEARCH_PORT']}"" @type elasticsearch user ""#{ENV['ELASTICSEARCH_USERNAME']}"" </match> <match ceph.**> <buffer> chunk_limit_size 512K flush_interval 5s flush_thread_count 8 queue_limit_length 32 retry_forever false retry_max_interval 30 </buffer> host ""#{ENV['ELASTICSEARCH_HOST']}"" reload_connections false reconnect_on_error true reload_on_failure true include_tag_key true logstash_format true logstash_prefix ceph password ""#{ENV['ELASTICSEARCH_PASSWORD']}"" port ""#{ENV['ELASTICSEARCH_PORT']}"" @type elasticsearch user ""#{ENV['ELASTICSEARCH_USERNAME']}"" </match> <match kernel> <buffer> chunk_limit_size 512K flush_interval 5s flush_thread_count 8 queue_limit_length 32 retry_forever false disable_chunk_backup true </buffer> host ""#{ENV['ELASTICSEARCH_HOST']}"" reload_connections false reconnect_on_error true reload_on_failure true include_tag_key true logstash_format true logstash_prefix kernel password ""#{ENV['ELASTICSEARCH_PASSWORD']}"" port ""#{ENV['ELASTICSEARCH_PORT']}"" @type elasticsearch user ""#{ENV['ELASTICSEARCH_USERNAME']}"" </match> <match auth> <buffer> chunk_limit_size 512K flush_interval 5s flush_thread_count 8 queue_limit_length 32 retry_forever false retry_max_interval 30 </buffer> host ""#{ENV['ELASTICSEARCH_HOST']}"" reload_connections false reconnect_on_error true reload_on_failure true include_tag_key true logstash_format true logstash_prefix auth password ""#{ENV['ELASTICSEARCH_PASSWORD']}"" port ""#{ENV['ELASTICSEARCH_PORT']}"" @type elasticsearch user ""#{ENV['ELASTICSEARCH_USERNAME']}"" </match> <match journal.**> <buffer> chunk_limit_size 512K flush_interval 5s flush_thread_count 8 queue_limit_length 32 retry_forever false retry_max_interval 30 </buffer> host ""#{ENV['ELASTICSEARCH_HOST']}"" reload_connections false reconnect_on_error true reload_on_failure true include_tag_key true logstash_format true logstash_prefix journal password ""#{ENV['ELASTICSEARCH_PASSWORD']}"" port ""#{ENV['ELASTICSEARCH_PORT']}"" @type elasticsearch user ""#{ENV['ELASTICSEARCH_USERNAME']}"" </match> <buffer> host ""#{ENV['ELASTICSEARCH_HOST']}"" reload_connections false reconnect_on_error true reload_on_failure true include_tag_key true logstash_format true password ""#{ENV['ELASTICSEARCH_PASSWORD']}"" port ""#{ENV['ELASTICSEARCH_PORT']}"" @type elasticsearch user ""#{ENV['ELASTICSEARCH_USERNAME']}""",23,123
openstack%2Fopenstack-helm-infra~master~Ibb7cbf5011451a74831ad8e57b920fb03a7975bd,openstack/openstack-helm-infra,master,Ibb7cbf5011451a74831ad8e57b920fb03a7975bd,Nagios: Add support for PVC to store log archives,ABANDONED,2019-06-28 16:38:21.000000000,2020-01-16 13:38:32.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-06-28 16:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6e543b594c827e5682c052fd32b95a2fda31b101', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-06-28 17:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8ac98f352292669a9e1633e9a071d2db140683ac', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-06-28 17:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c5d7ba2403d3242e70ffc860c264ddc8d5fee4d8', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-07-01 13:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dc609c19606ba60cb3254283b322d5ec19658728', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-07-01 14:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3b175be8f354819cb343d2393405f209451b33d3', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 6, 'created': '2019-07-01 15:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7134f342bbd74dfea1dfc16157b9ff8550f5ccad', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 7, 'created': '2019-07-01 16:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dbf9faa82df3f8d58cfc500b0c02ee0d2999779e', 'message': 'WIP Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 8, 'created': '2019-07-05 14:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d88d18992fd81d0f1d3c2eab66ef0b36172d477a', 'message': 'Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 9, 'created': '2019-07-05 14:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/088df6558259b0bfb95b49b4feb7bbb8cc6b03d8', 'message': 'Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 10, 'created': '2019-07-08 13:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9d5d3272ab0c5e9bfbc65e7c5798bdac2fe47c24', 'message': 'Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 11, 'created': '2019-08-07 14:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b99d4e55104d0bd4533995afbedb1d1d69bff549', 'message': 'Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 12, 'created': '2019-11-11 07:43:07.000000000', 'files': ['nagios/templates/deployment.yaml', 'nagios/values.yaml', 'nagios/templates/pvc.yaml', 'tools/deployment/common/nagios.sh', 'nagios/templates/bin/_nagios-readiness.sh.tpl', 'tools/deployment/osh-infra-monitoring/120-nagios.sh', 'tools/deployment/multinode/110-nagios.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/66dc35f8a4be169cec17973828c57b34b87ca9a1', 'message': 'Nagios: Add support for PVC to store log archives\n\nThis adds support to the Nagios chart for supporting log archives\nto allow for the display of alert and notification history for\nservice checks. This adds in a pvc template for storing the log\nfiles and adds a conditional check to the readiness probe that\nwill avoid clearing out the log file when persistence is enabled\n\nChange-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",3,668202,66dc35f8a4be169cec17973828c57b34b87ca9a1,25,4,12,17591,,,0,"Nagios: Add support for PVC to store log archives

This adds support to the Nagios chart for supporting log archives
to allow for the display of alert and notification history for
service checks. This adds in a pvc template for storing the log
files and adds a conditional check to the readiness probe that
will avoid clearing out the log file when persistence is enabled

Change-Id: Ibb7cbf5011451a74831ad8e57b920fb03a7975bd
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/02/668202/1 && git format-patch -1 --stdout FETCH_HEAD,"['nagios/templates/deployment.yaml', 'nagios/values.yaml', 'nagios/templates/pvc.yaml', 'nagios/templates/bin/_nagios-readiness.sh.tpl']",4,6e543b594c827e5682c052fd32b95a2fda31b101,nagios-support-pvc,"# NOTE(sw5822): When storage is disabled, redirect no-op operator output to # Nagios log file to clean out Nagios's log file, since Nagios doesn't support # logging to /dev/null. This helps prevent Nagios's log file from growing so # large that it causes issues with the storage backing the host {{- if and (not .Values.storage.enabled) (not .Values.manifests.pvc_nagios) }}{{- end }}","# NOTE(sw5822): Redirect no-op operator output to Nagios log file to clean out # Nagios's log file, since Nagios doesn't support logging to /dev/null",58,6
openstack%2Fopenstack-helm-infra~master~Idade53dd383538ec4ac8ec2b59928a83e538bcbe,openstack/openstack-helm-infra,master,Idade53dd383538ec4ac8ec2b59928a83e538bcbe,Prometheus: Add selenium tests to helm test pod,ABANDONED,2019-06-04 18:43:22.000000000,2020-01-16 13:38:27.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 28849}]","[{'number': 1, 'created': '2019-06-04 18:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e73f93749a7404b2278acbbe3d96a3da965273a7', 'message': ""WIP: Prometheus: Add selenium tests to helm test pod\n\nThis adds selenium tests to the prometheus helm test pod to help\nverify prometheus's dashboard is functional and accessible\n\nChange-Id: Idade53dd383538ec4ac8ec2b59928a83e538bcbe\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n""}, {'number': 2, 'created': '2019-06-04 19:11:41.000000000', 'files': ['prometheus/templates/configmap-bin.yaml', 'prometheus/templates/bin/_selenium-tests.py.tpl', 'prometheus/templates/pod-helm-tests.yaml', 'prometheus/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f8f01ed243b5ff41e02bb57558b2ef657b51131e', 'message': ""Prometheus: Add selenium tests to helm test pod\n\nThis adds selenium tests to the prometheus helm test pod to help\nverify prometheus's dashboard is functional and accessible\n\nChange-Id: Idade53dd383538ec4ac8ec2b59928a83e538bcbe\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n""}]",0,663120,f8f01ed243b5ff41e02bb57558b2ef657b51131e,8,3,2,17591,,,0,"Prometheus: Add selenium tests to helm test pod

This adds selenium tests to the prometheus helm test pod to help
verify prometheus's dashboard is functional and accessible

Change-Id: Idade53dd383538ec4ac8ec2b59928a83e538bcbe
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/20/663120/2 && git format-patch -1 --stdout FETCH_HEAD,"['prometheus/templates/configmap-bin.yaml', 'prometheus/templates/bin/_selenium-tests.py.tpl', 'prometheus/templates/pod-helm-tests.yaml', 'prometheus/values.yaml']",4,e73f93749a7404b2278acbbe3d96a3da965273a7,prometheus-helm-tests, selenium_tests: docker.io/openstackhelm/osh-selenium:latest-ubuntu_xenial,,45,0
openstack%2Fopenstack-helm-infra~master~Ice56b28c6532538d23c1aa10fec4e72f7ae278dc,openstack/openstack-helm-infra,master,Ice56b28c6532538d23c1aa10fec4e72f7ae278dc,WIP: Update elastic beats to v6.6.0,ABANDONED,2019-02-14 21:26:30.000000000,2020-01-16 13:38:21.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-14 21:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b95b8c35e2fa060c176f95719f214078d18c40bc', 'message': 'WIP: Update elastic beats to v6.6.0\n\nChange-Id: Ice56b28c6532538d23c1aa10fec4e72f7ae278dc\n'}, {'number': 2, 'created': '2019-02-20 19:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/315ec2d870b9d350514ac040d55188a86ecdd5d1', 'message': 'WIP: Update elastic beats to v6.6.0\n\nChange-Id: Ice56b28c6532538d23c1aa10fec4e72f7ae278dc\n'}, {'number': 3, 'created': '2019-02-21 00:14:57.000000000', 'files': ['elastic-packetbeat/templates/daemonset.yaml', 'kibana/templates/deployment.yaml', 'elastic-filebeat/templates/daemonset.yaml', 'elastic-metricbeat/templates/deployment-modules.yaml', 'elastic-packetbeat/values.yaml', 'elastic-metricbeat/templates/daemonset-node-metrics.yaml', 'elastic-metricbeat/values.yaml', 'elastic-filebeat/values.yaml', 'elastic-filebeat/templates/configmap-etc.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3b8abf0d47060c136b9d8bdaf1122bc6c69d1cd8', 'message': 'WIP: Update elastic beats to v6.6.0\n\nChange-Id: Ice56b28c6532538d23c1aa10fec4e72f7ae278dc\n'}]",0,637053,3b8abf0d47060c136b9d8bdaf1122bc6c69d1cd8,7,1,3,17591,,,0,"WIP: Update elastic beats to v6.6.0

Change-Id: Ice56b28c6532538d23c1aa10fec4e72f7ae278dc
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/53/637053/1 && git format-patch -1 --stdout FETCH_HEAD,"['elastic-packetbeat/templates/daemonset.yaml', 'kibana/templates/deployment.yaml', 'elastic-filebeat/templates/daemonset.yaml', 'elastic-metricbeat/templates/deployment-modules.yaml', 'elastic-packetbeat/values.yaml', 'elastic-metricbeat/templates/daemonset-node-metrics.yaml', 'elastic-metricbeat/values.yaml', 'elastic-filebeat/values.yaml']",8,b95b8c35e2fa060c176f95719f214078d18c40bc,update-beats-6," filebeat: docker.elastic.co/beats/filebeat:6.6.0 index: ""filebeat-*"" retry: enabled: true interval: 5 kibana: host: ""${KIBANA_HOST}:${KIBANA_PORT}"" username: ""${ELASTICSEARCH_USERNAME}"" password: ""${ELASTICSEARCH_PASSWORD}"" inputs: - type: log paths: - /var/log/syslog fields: input: syslog - type: log paths: - /var/log/kern.log fields: input: ""kern.log"" - type: kubernetes templates: - condition: equals: kubernetes.namespace: osh-infra config: - type: docker containers.ids: - ""${data.kubernetes.container.id}"" exclude_lines: [""^\\s+[\\-`('.|_]""] kibana: name: kibana namespace: osh-infra hosts: default: kibana-dash public: kibana host_fqdn_override: default: null path: default: null scheme: default: http port: kibana: default: 5601 http: default: 80"," filebeat: docker.elastic.co/beats/filebeat:6.2.3 prospectors: - type: docker containers.ids: - ""*"" multiline: pattern: '^Traceback' match: after negate: true",208,69
openstack%2Fopenstack-helm-infra~master~Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2,openstack/openstack-helm-infra,master,Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2,"WIP/DNM: Armada job update, electric boogaloo",ABANDONED,2019-02-04 19:57:28.000000000,2020-01-16 13:38:14.000000000,,"[{'_account_id': 17591}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 19:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6b15b62034b8f81a55c0b86cf5eea8ecbeb6747f', 'message': 'WIP/DNM: Armada deployment job, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 2, 'created': '2019-02-04 20:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e752952d2f87f60d0b20eb842b88fd4af331b51e', 'message': 'WIP/DNM: Armada deployment job, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 3, 'created': '2019-02-04 20:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3512fd7c461ee208c282cc86f79ed54d2c3305b8', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 4, 'created': '2019-02-04 21:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9f36cbf1dcd5b03d8a17440399d7a181d6490dea', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 5, 'created': '2019-02-04 22:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3f36c9df5984138a6fe8ab980ef838122001717a', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 6, 'created': '2019-02-04 23:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ae0bfe52fbf7894c7818e5619c941ca81db349b5', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 7, 'created': '2019-02-05 14:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5cd35c793a0e5ac53a70bbafc0ed7dcdb9633c54', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 8, 'created': '2019-02-05 14:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/eeb4bbf2802d41252e5fe5d7e3a343eb195117e5', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 9, 'created': '2019-02-05 14:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3bd9d6f6f50a999f9b5bba5b0657f06e8ca13bee', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 10, 'created': '2019-02-05 15:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/dc37b41d422fae8c83af5c8f80e625fa2274a2f8', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 11, 'created': '2019-02-05 16:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f980dfa47e53775cde0059649497812a8f4c1fe5', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 12, 'created': '2019-02-05 17:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/42c8dc43756aac497e6829e2ad0bdc7704f7e570', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 13, 'created': '2019-02-05 18:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2dce1e3324a0b7bb0bfeca379143252d5249135d', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 14, 'created': '2019-02-05 19:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1f27217c4f875c1ea2dd48e59588bb005396ba5c', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 15, 'created': '2019-02-05 21:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cdd665824da301050825bcce961b1211712f1cb4', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 16, 'created': '2019-02-05 21:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7039e8700a3fbca10f655d46e5ca78f4e3c84120', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 17, 'created': '2019-02-05 22:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fc67ce63c37da9cc6495bf849eaf36b026189ac2', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 18, 'created': '2019-02-06 14:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1f60c74b9858415c8ec38f0554bb9b253cfbdedb', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 19, 'created': '2019-02-06 17:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/518e7bb2d62e388d292f411d2c56185633ad014d', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}, {'number': 20, 'created': '2019-02-20 21:08:37.000000000', 'files': ['roles/reboot-all-hosts/main.yaml', 'playbooks/osh-infra-pod-status.yaml', 'zuul.d/project.yaml', 'tools/deployment/armada/manifests/armada-lma.yaml', 'zuul.d/jobs.yaml', 'playbooks/osh-infra-reboot-all-hosts.yaml', 'roles/display-pod-status/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/466f817976221f678ffec7af01494b043d509cb5', 'message': 'WIP/DNM: Armada job update, electric boogaloo\n\nChange-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2\n'}]",0,634792,466f817976221f678ffec7af01494b043d509cb5,65,2,20,17591,,,0,"WIP/DNM: Armada job update, electric boogaloo

Change-Id: Icfbbf50c7e1d6397dac4f3da53cc5458aee467b2
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/92/634792/18 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/osh-infra-reboot-nodes.yaml', 'zuul.d/project.yaml', 'zuul.d/jobs.yaml', 'roles/reboot-nodes/main.yaml']",4,6b15b62034b8f81a55c0b86cf5eea8ecbeb6747f,armada/reboot,"# Copyright 2017 The Openstack-Helm Authors. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Rebooting hosts shell: sleep 2 && reboot sudo: yes async: 30 poll: 0 ignore_errors: true args: executable: /bin/bash - name: Wait for hosts to come up following reboot wait_for: host: '{{ hostvars[item].ansible_host }}' port: 22 state: started delay: 60 timeout: 240 with_items: '{{ play_hosts }}' connection: local - name: Watch pod status for 15 minutes shell: | set -xe; end=$(date +%s) end=$((end + 900)) while true; do kubectl get pods --all-namespaces sleep 30 now=$(date +%s) [ $now -gt $end ] && echo 15 minutes have elapsed. && \ kubectl get pods --all-namespaces && exit -1 done args: executable: /bin/bash ",,98,2
openstack%2Ftripleo-operator-ansible~master~I6aa82fba2d555ea1be831bc672ce79d0e21a296e,openstack/tripleo-operator-ansible,master,I6aa82fba2d555ea1be831bc672ce79d0e21a296e,Add container image show role,MERGED,2020-01-13 20:33:42.000000000,2020-01-16 13:37:48.000000000,2020-01-16 13:37:48.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-13 20:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/05599ffe9433f3b4c264a71b0ac858397b044166', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}, {'number': 2, 'created': '2020-01-14 15:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/704c603f3eaab7a78e57b145f6cf97f0d125c7bd', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}, {'number': 3, 'created': '2020-01-14 15:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9ef478d060d8c89882551ae72cc925908b524725', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}, {'number': 4, 'created': '2020-01-14 23:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/f57f341ee0c87bc1ee1dc64fd2754543c9431613', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}, {'number': 5, 'created': '2020-01-15 18:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/e0c3cc719bbe8f0d8ecbefeac189d98977280732', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}, {'number': 6, 'created': '2020-01-15 18:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/6ce799c6c7f43d712941e08cc25bf38b84e86482', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}, {'number': 7, 'created': '2020-01-15 18:30:53.000000000', 'files': ['roles/tripleo-container-image-show/tests/inventory', 'roles/tripleo-container-image-show/meta/main.yml', 'roles/tripleo-container-image-show/tasks/main.yml', 'roles/tripleo-container-image-show/tests/test.yml', 'roles/tripleo-container-image-show/defaults/main.yml', 'roles/tripleo-container-image-show/README.md'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/212ed4590aeb20a8dd2fadc6a26fc2ef87a43eff', 'message': 'Add container image show role\n\nAdd tripleo-container-image-show that will return the container details.\n\nChange-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e\n'}]",2,702290,212ed4590aeb20a8dd2fadc6a26fc2ef87a43eff,21,4,7,14985,,,0,"Add container image show role

Add tripleo-container-image-show that will return the container details.

Change-Id: I6aa82fba2d555ea1be831bc672ce79d0e21a296e
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/90/702290/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-container-image-show/tests/inventory', 'roles/tripleo-container-image-show/meta/main.yml', 'roles/tripleo-container-image-show/tasks/main.yml', 'roles/tripleo-container-image-show/tests/test.yml', 'roles/tripleo-container-image-show/defaults/main.yml', 'roles/tripleo-container-image-show/README.md']",6,05599ffe9433f3b4c264a71b0ac858397b044166,tripleo-undercloud,"tripleo-container-image-show ============================ A role to perform the container image show against a registry. Requirements ------------ None. Role Variables -------------- * `tripleo_container_image_show_debug`: (Boolean) Flag to print out the show command. Default: False * `tripleo_container_image_show_format`: (String) The format that the output will be in. By default we specify 'json' so that the output will be parsed in ansible. Default: json * `tripleo_container_image_show_image`: (String) Image to fetch the details * `tripleo_container_image_show_password`: (String) Password for the registry * `tripleo_container_image_show_timeout`: (Number) Amount of time to wait for the command to conplete. Default: 180 * `tripleo_container_image_show_username`: (String) Username for the registry Output Variables ---------------- * `tripleo_container_image_show_output`: (Dictionary|String) If tripleo_container_image_show_format is json, the results will automatically be parsed and a dictionary is returned. If another format is used then this will be the response in String format. Dependencies ------------ None. Example Playbook ---------------- Example container show execution playbook - hosts: undercloud gather_facts: true tasks: - name: List containers import_role: name: tripleo-container-image-show vars: tripleo_container_image_show_image: docker.io/library/centos:7 - name: Print containers debug: var: tripleo_container_image_show_output License ------- Apache-2.0 ",,133,0
openstack%2Ftripleo-operator-ansible~master~I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a,openstack/tripleo-operator-ansible,master,I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a,Add container image list role,MERGED,2020-01-13 19:26:17.000000000,2020-01-16 13:37:12.000000000,2020-01-16 13:37:12.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-13 19:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/fc806b00fe89f9648561c990709f983cad3ca0ee', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 2, 'created': '2020-01-13 19:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/f2c607fd3d43324d88e8f7b915bb249a7bd55d46', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 3, 'created': '2020-01-13 20:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9a17350186d6df9c549b83b6943b76187f0736bb', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 4, 'created': '2020-01-14 15:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/f1b81a1adf524a2a887a2e28aa3f6687c6f30150', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 5, 'created': '2020-01-14 15:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/9ed8c2ae4aa10bf60b890646cd321232a5ff1527', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 6, 'created': '2020-01-14 23:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/45bd01703862166765d67c74ae9d4dacc4199776', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 7, 'created': '2020-01-15 18:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/fea4e530fc47af41d2cf70651b36e2006bc1cc55', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 8, 'created': '2020-01-15 18:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/16546ecdb3a4973c991e2897421ac15c2001d16d', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}, {'number': 9, 'created': '2020-01-15 19:30:16.000000000', 'files': ['roles/tripleo-container-image-list/tasks/main.yml', 'roles/tripleo-container-image-list/defaults/main.yml', 'roles/tripleo-container-image-list/tests/test.yml', 'roles/tripleo-container-image-list/tests/inventory', 'roles/tripleo-container-image-list/README.md', 'roles/tripleo-container-image-list/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/6dd959d19f35107fdc3a533a5f49bec0916008a8', 'message': 'Add container image list role\n\nAdding tripleo-container-image-list which can be used to query the\ncontainers in a given registry.\n\nChange-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a\n'}]",10,702284,6dd959d19f35107fdc3a533a5f49bec0916008a8,30,4,9,14985,,,0,"Add container image list role

Adding tripleo-container-image-list which can be used to query the
containers in a given registry.

Change-Id: I08e70fa7802028c1fdfb2b0ce09ea247a0e4847a
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/84/702284/7 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-container-image-list/tasks/main.yml', 'roles/tripleo-container-image-list/defaults/main.yml', 'roles/tripleo-container-image-list/tests/test.yml', 'roles/tripleo-container-image-list/tests/inventory', 'roles/tripleo-container-image-list/README.md', 'roles/tripleo-container-image-list/meta/main.yml']",6,fc806b00fe89f9648561c990709f983cad3ca0ee,tripleo-undercloud,"--- # Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. galaxy_info: author: OpenStack description: TripleO Operator Role -- tripleo-container-image-list company: Red Hat license: Apache-2.0 min_ansible_version: 2.8 # # Provide a list of supported platforms, and for each platform a list of versions. # If you don't wish to enumerate all versions for a particular platform, use 'all'. # To view available platforms and versions (or releases), visit: # https://galaxy.ansible.com/api/v1/platforms/ # platforms: - name: CentOS versions: - 7 - 8 galaxy_tags: - tripleo # List your role dependencies here, one per line. Be sure to remove the '[]' above, # if you add dependencies to this list. dependencies: [] ",,130,0
openstack%2Fneutron~master~I6968da1d0f8dbf0ddb1b5d8b0796f2357a2a505e,openstack/neutron,master,I6968da1d0f8dbf0ddb1b5d8b0796f2357a2a505e,Bump neutron-lib to 2.0.0,MERGED,2020-01-08 09:21:01.000000000,2020-01-16 13:05:59.000000000,2020-01-16 13:03:28.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2020-01-08 09:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/673ebb93dfc854b0c9c9033405941551d07bdade', 'message': 'Bump neutron-lib to 1.31.0\n\nChange-Id: I6968da1d0f8dbf0ddb1b5d8b0796f2357a2a505e\n'}, {'number': 2, 'created': '2020-01-12 17:56:51.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/84658a96b372b25d88db6adc2d941e73a91370fa', 'message': 'Bump neutron-lib to 2.0.0\n\nChange-Id: I6968da1d0f8dbf0ddb1b5d8b0796f2357a2a505e\n'}]",0,701517,84658a96b372b25d88db6adc2d941e73a91370fa,59,7,2,11975,,,0,"Bump neutron-lib to 2.0.0

Change-Id: I6968da1d0f8dbf0ddb1b5d8b0796f2357a2a505e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/701517/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,673ebb93dfc854b0c9c9033405941551d07bdade,bump-neutron-lib-2.0.0,neutron-lib==1.31.0,neutron-lib==1.30.0,2,2
openstack%2Fcinder~master~Ieb55bf4abed5856412576c3e45a5350c463deef2,openstack/cinder,master,Ieb55bf4abed5856412576c3e45a5350c463deef2,Remove the Virtuozzo Storage Driver,MERGED,2019-12-26 23:27:39.000000000,2020-01-16 12:56:22.000000000,2020-01-14 10:08:30.000000000,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-26 23:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65209ebba73234d3c4a545c209a135c244f95b69', 'message': ""Remove the Virtuozzo Storage Driver\n\nThe Virtuozzo Storage driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: Ieb55bf4abed5856412576c3e45a5350c463deef2\n""}, {'number': 2, 'created': '2020-01-02 20:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/63b4c60077a02c886458fb0f77379382af2e898b', 'message': ""Remove the Virtuozzo Storage Driver\n\nThe Virtuozzo Storage driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: Ieb55bf4abed5856412576c3e45a5350c463deef2\n""}, {'number': 3, 'created': '2020-01-13 18:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/971558ac97dc5cb3918d91359b9892a364c90322', 'message': ""Remove the Virtuozzo Storage Driver\n\nThe Virtuozzo Storage driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: Ieb55bf4abed5856412576c3e45a5350c463deef2\n""}, {'number': 4, 'created': '2020-01-13 19:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/231a2d8a55984fe869b84db74201f125dca9c591', 'message': ""Remove the Virtuozzo Storage Driver\n\nThe Virtuozzo Storage driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: Ieb55bf4abed5856412576c3e45a5350c463deef2\n""}, {'number': 5, 'created': '2020-01-14 02:47:16.000000000', 'files': ['cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'doc/source/reference/support-matrix.rst', 'releasenotes/notes/virtuozzo-storage-driver-removal-d53942afce6465d0.yaml', 'cinder/tests/unit/volume/drivers/test_vzstorage.py', 'cinder/volume/drivers/vzstorage.py', 'doc/source/configuration/block-storage/drivers/vzstorage-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3e3153059618a30b7cce816d69b8b6af832262f4', 'message': ""Remove the Virtuozzo Storage Driver\n\nThe Virtuozzo Storage driver was marked\nunsupported during the Train release.  Since\nthen, the 3rd Party CI hasn't been fixed and\nthere has been no sign of activity from the\nvendor.  As a result the driver is being removed.\n\nChange-Id: Ieb55bf4abed5856412576c3e45a5350c463deef2\n""}]",0,700658,3e3153059618a30b7cce816d69b8b6af832262f4,136,30,5,7198,,,0,"Remove the Virtuozzo Storage Driver

The Virtuozzo Storage driver was marked
unsupported during the Train release.  Since
then, the 3rd Party CI hasn't been fixed and
there has been no sign of activity from the
vendor.  As a result the driver is being removed.

Change-Id: Ieb55bf4abed5856412576c3e45a5350c463deef2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/700658/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'doc/source/reference/support-matrix.rst', 'releasenotes/notes/virtuozzo-storage-driver-removal-d53942afce6465d0.yaml', 'cinder/tests/unit/volume/drivers/test_vzstorage.py', 'cinder/volume/drivers/vzstorage.py', 'doc/source/configuration/block-storage/drivers/vzstorage-driver.rst']",7,65209ebba73234d3c4a545c209a135c244f95b69,ci_unsupported,,"======================== Virtuozzo Storage driver ======================== The Virtuozzo Storage driver is a fault-tolerant distributed storage system that is optimized for virtualization workloads. Set the following in your ``cinder.conf`` file, and use the following options to configure it. .. code-block:: ini volume_driver = cinder.volume.drivers.vzstorage.VZStorageDriver .. config-table:: :config-target: Virtuozzo Storage cinder.volume.drivers.vzstorage ",8,1253
openstack%2Fcompute-hyperv~master~Ibce6b062a81200611bcaac3f2cb90b14b559375b,openstack/compute-hyperv,master,Ibce6b062a81200611bcaac3f2cb90b14b559375b,Handle Python 3 transition and fix tests,MERGED,2020-01-15 15:16:53.000000000,2020-01-16 12:46:45.000000000,2020-01-16 12:46:45.000000000,"[{'_account_id': 8543}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 15:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/cd0149e672fcb3fdb2f0f3236b16816c9f26d850', 'message': ""Handle Python 3 transition\n\nWhile dropping Python 2.7 support, the upstream project has been\nupdated, so we'll have to move the templates in-tree.\n\nWhile at it, we're updating the supported Python versions.\n\nChange-Id: Ibce6b062a81200611bcaac3f2cb90b14b559375b\n""}, {'number': 2, 'created': '2020-01-16 09:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/a76a1171d3fcb9a03fae856fdd9c38dd98d8c0f5', 'message': ""Handle Python 3 transition and fix tests\n\nWhile dropping Python 2.7 support, the upstream project has been\nupdated, so we'll have to move the templates in-tree.\n\nWhile at it, we're updating the supported Python versions.\n\nSome Nova fixtures have been moved to oslo.test, so in order to be\nable to unblock the gate, we'll have to squash those fixes as well.\nFor the same reason, we'll have to remove nova-network checks, which\nhas been completely dropped.\n\nChange-Id: Ibce6b062a81200611bcaac3f2cb90b14b559375b\n""}, {'number': 3, 'created': '2020-01-16 10:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/f28d0996d0f24a7e890b42bb812ef8ddd403de86', 'message': ""Handle Python 3 transition and fix tests\n\nWhile dropping Python 2.7 support, the upstream project has been\nupdated, so we'll have to move the templates in-tree.\n\nWhile at it, we're updating the supported Python versions.\n\nSome Nova fixtures have been moved to oslo.test, so in order to be\nable to unblock the gate, we'll have to squash those fixes as well.\nFor the same reason, we'll have to remove nova-network checks, which\nhas been completely dropped.\n\nA few options have been moved to a separate config group, which\nwe'll have to take into account.\n\nChange-Id: Ibce6b062a81200611bcaac3f2cb90b14b559375b\n""}, {'number': 4, 'created': '2020-01-16 11:12:19.000000000', 'files': ['compute_hyperv/nova/imagecache.py', 'compute_hyperv/tests/test.py', 'compute_hyperv/nova/vmops.py', 'compute_hyperv/tests/unit/test_vif.py', '.zuul.yaml', 'compute_hyperv/nova/vif.py', 'compute_hyperv/tests/unit/test_imagecache.py', 'compute_hyperv/tests/unit/test_vmops.py', 'setup.cfg', 'tox.ini', 'compute_hyperv/tests/unit/test_driver.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/bd2aacc14fb33631c4f9fb6b2264d46f2f226800', 'message': ""Handle Python 3 transition and fix tests\n\nWhile dropping Python 2.7 support, the upstream project has been\nupdated, so we'll have to move the templates in-tree.\n\nWhile at it, we're updating the supported Python versions.\n\nSome Nova fixtures have been moved to oslo.test, so in order to be\nable to unblock the gate, we'll have to squash those fixes as well.\nFor the same reason, we'll have to remove nova-network checks, which\nhas been completely dropped.\n\nA few options have been moved to a separate config group, which\nwe'll have to take into account.\n\nChange-Id: Ibce6b062a81200611bcaac3f2cb90b14b559375b\n""}]",0,702681,bd2aacc14fb33631c4f9fb6b2264d46f2f226800,12,2,4,8543,,,0,"Handle Python 3 transition and fix tests

While dropping Python 2.7 support, the upstream project has been
updated, so we'll have to move the templates in-tree.

While at it, we're updating the supported Python versions.

Some Nova fixtures have been moved to oslo.test, so in order to be
able to unblock the gate, we'll have to squash those fixes as well.
For the same reason, we'll have to remove nova-network checks, which
has been completely dropped.

A few options have been moved to a separate config group, which
we'll have to take into account.

Change-Id: Ibce6b062a81200611bcaac3f2cb90b14b559375b
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/81/702681/4 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg', 'tox.ini']",3,cd0149e672fcb3fdb2f0f3236b16816c9f26d850,,"envlist = py37,pep8,pip-missing-reqs","envlist = py35,py36,pep8,pip-missing-reqs",4,1
openstack%2Fopenstack-ansible~stable%2Ftrain~I3533929784b0035cd9a522dc7589f200522486b6,openstack/openstack-ansible,stable/train,I3533929784b0035cd9a522dc7589f200522486b6,Bump SHAs for stable/train,MERGED,2020-01-12 14:03:18.000000000,2020-01-16 12:37:12.000000000,2020-01-16 12:34:51.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27822}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-12 14:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a6638b7a818fedb973e858898be6d5de652ff64d', 'message': 'Bump SHAs for stable/train\n\nChange-Id: I3533929784b0035cd9a522dc7589f200522486b6\n'}, {'number': 2, 'created': '2020-01-15 18:03:02.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/83e1650e56cb8f5fc9049e1a84b5c2ad0e23e9c2', 'message': 'Bump SHAs for stable/train\n\nChange-Id: I3533929784b0035cd9a522dc7589f200522486b6\n'}]",0,702135,83e1650e56cb8f5fc9049e1a84b5c2ad0e23e9c2,19,5,2,28619,,,0,"Bump SHAs for stable/train

Change-Id: I3533929784b0035cd9a522dc7589f200522486b6
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/35/702135/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,a6638b7a818fedb973e858898be6d5de652ff64d,bump_osa, version: 5dc5cf874b9ae5a5f7e20f6e68652af4d4854276 version: fc7212b192f0f75579c0e215c26b38b9e87a273e, version: d8346d845afe53211384b1baeed2a62cd37b6f41 version: 19068659c79e56ddbca0a19c6cf631e8271feac8,49,49
openstack%2Fkolla-ansible~stable%2Fstein~Ide6eb4c2b079cf35e633ad6a04db1587e40e7633,openstack/kolla-ansible,stable/stein,Ide6eb4c2b079cf35e633ad6a04db1587e40e7633,Fix Zun Docker runtime selection,MERGED,2020-01-13 14:26:00.000000000,2020-01-16 12:26:09.000000000,2020-01-16 12:21:43.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-13 14:26:00.000000000', 'files': ['ansible/roles/zun/templates/zun.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2a1e6e1c608f07be18d5aa4406dfb7744892e32e', 'message': 'Fix Zun Docker runtime selection\n\nPer [1] Docker uses API version 1.26 since daemon version 1.13.1.\nKolla Ansible forced a limit on the Docker API version reported\nto Zun of 1.24 which was surprising users and preventing\nusage of Docker runtime selection via Zun.\nThe default of Zun is 1.26 [2] which enables runtime selection.\nZun does not use this parameter for anything else atm.\n\n[1] https://docs.docker.com/engine/api/v1.26/#section/Versioning\n[2] https://review.opendev.org/490794\n\nChange-Id: Ide6eb4c2b079cf35e633ad6a04db1587e40e7633\nCloses-bug: #1859176\n(cherry picked from commit 5e8431e0cc6d1e9f24f482b08e8429db77d21c11)\n(cherry picked from commit c6ff77a9c1187c08f88318b94d78ce1b9a1782f6)\n'}]",0,702226,2a1e6e1c608f07be18d5aa4406dfb7744892e32e,15,4,1,30491,,,0,"Fix Zun Docker runtime selection

Per [1] Docker uses API version 1.26 since daemon version 1.13.1.
Kolla Ansible forced a limit on the Docker API version reported
to Zun of 1.24 which was surprising users and preventing
usage of Docker runtime selection via Zun.
The default of Zun is 1.26 [2] which enables runtime selection.
Zun does not use this parameter for anything else atm.

[1] https://docs.docker.com/engine/api/v1.26/#section/Versioning
[2] https://review.opendev.org/490794

Change-Id: Ide6eb4c2b079cf35e633ad6a04db1587e40e7633
Closes-bug: #1859176
(cherry picked from commit 5e8431e0cc6d1e9f24f482b08e8429db77d21c11)
(cherry picked from commit c6ff77a9c1187c08f88318b94d78ce1b9a1782f6)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/26/702226/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/zun/templates/zun.conf.j2'],1,2a1e6e1c608f07be18d5aa4406dfb7744892e32e,bug/1859176,,docker_remote_api_version = 1.24,0,1
openstack%2Fkolla~master~I8897ede43f11090902fe7c0c096f17f57c1c9c67,openstack/kolla,master,I8897ede43f11090902fe7c0c096f17f57c1c9c67,"Revert ""Add AArch64 publisher for Debian/source""",MERGED,2020-01-15 16:33:04.000000000,2020-01-16 12:26:03.000000000,2020-01-16 12:21:41.000000000,"[{'_account_id': 1}, {'_account_id': 5263}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-15 16:33:04.000000000', 'files': ['tests/test_build.py', '.zuul.d/debian.yaml', 'tools/create-multiarch-images.sh', 'tests/playbooks/publish-multiarch.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/b66f144c42f54690fd23406c770cffd6a2a60bae', 'message': 'Revert ""Add AArch64 publisher for Debian/source""\n\nTurned out that linaro-london network pipe is too thin \nto support this job. Pushing images took 3 hours so job\ntimed out.\n\nWill check it once new nodes arrive.\n\nThis reverts commit f2801fabdd727fc72a28b056d79787af484424a7.\n\nChange-Id: I8897ede43f11090902fe7c0c096f17f57c1c9c67\n'}]",0,702698,b66f144c42f54690fd23406c770cffd6a2a60bae,12,8,1,24072,,,0,"Revert ""Add AArch64 publisher for Debian/source""

Turned out that linaro-london network pipe is too thin 
to support this job. Pushing images took 3 hours so job
timed out.

Will check it once new nodes arrive.

This reverts commit f2801fabdd727fc72a28b056d79787af484424a7.

Change-Id: I8897ede43f11090902fe7c0c096f17f57c1c9c67
",git fetch https://review.opendev.org/openstack/kolla refs/changes/98/702698/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.d/debian.yaml', 'tests/test_build.py', 'tools/create-multiarch-images.sh', 'tests/playbooks/publish-multiarch.yml']",4,b66f144c42f54690fd23406c770cffd6a2a60bae,,,"--- - hosts: all tasks: - name: Login to Dockerhub command: ""docker login -u {{ kolla_dockerhub_creds.user }} -p {{ kolla_dockerhub_creds.password }}"" no_log: true - name: Ensure ~/.docker exists file: path: ~/.docker state: directory mode: 0777 - name: Enable experimental features in Docker so we can use 'docker manifest' copy: content: '{ ""experimental"": ""enabled"" }' dest: ~/.docker/config.json - name: Define image tag set_fact: image_tag: zuul.branch | regex_replace('^stable/', '') - name: Create multiarch images command: ""TAG={{ image_tag }} NAMESPACE=kolla DISTRO={{ base_distro }} TYPE={{ install_type }} tools/create-multiarch-images.sh"" ",3,83
openstack%2Fnetworking-ovn~stable%2Ftrain~I44f6de4c9a2b1c6054417dbb7f647a6af8339660,openstack/networking-ovn,stable/train,I44f6de4c9a2b1c6054417dbb7f647a6af8339660,Don't fail in case subnet or Logical Switch not found,MERGED,2020-01-10 11:08:29.000000000,2020-01-16 12:23:11.000000000,2020-01-16 12:21:38.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2020-01-10 11:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/abbd99a10393208b93a38f315f6d43f30bf1006f', 'message': ""Don't fail in case subnet or Logical Switch not found\n\nIn case of subnet not found all the related actions could\nnot be taken. This patch prevent this situation to happen.\nThis could be possible that LB is going to be deleted after\nthe subnet (for example remove of the LoadBalancer in Error\nstate).\n\nThe same could happend with Logical Switch. Sometimes the\nmember network is delated in meantime and then we tries to\nthe members. It means we would need to remove LB to LS and\nLB to LR associations, but it could not happend because of\nmissing LS. In those terms now we just pass the flow\nand remove the LS to LR counters in external_ids.\n\nChange-Id: I44f6de4c9a2b1c6054417dbb7f647a6af8339660\nCloses-Bug: 1857009\n""}, {'number': 2, 'created': '2020-01-14 17:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/a688ed33ec204dd1923b181fc0577d56bafea893', 'message': ""Don't fail in case subnet or Logical Switch not found\n\nIn case of subnet not found all the related actions could\nnot be taken. This patch prevent this situation to happen.\nThis could be possible that LB is going to be deleted after\nthe subnet (for example remove of the LoadBalancer in Error\nstate).\n\nThe same could happend with Logical Switch. Sometimes the\nmember network is delated in meantime and then we tries to\nthe members. It means we would need to remove LB to LS and\nLB to LR associations, but it could not happend because of\nmissing LS. In those terms now we just pass the flow\nand remove the LS to LR counters in external_ids.\n\nChange-Id: I44f6de4c9a2b1c6054417dbb7f647a6af8339660\nCloses-Bug: 1857009\n""}, {'number': 3, 'created': '2020-01-15 12:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/bf4f8390a6335e67eb38c6c72eaaaca8e13f8472', 'message': ""Don't fail in case subnet or Logical Switch not found\n\nIn case of subnet not found all the related actions could\nnot be taken. This patch prevent this situation to happen.\nThis could be possible that LB is going to be deleted after\nthe subnet (for example remove of the LoadBalancer in Error\nstate).\n\nThe same could happend with Logical Switch. Sometimes the\nmember network is delated in meantime and then we tries to\nthe members. It means we would need to remove LB to LS and\nLB to LR associations, but it could not happend because of\nmissing LS. In those terms now we just pass the flow\nand remove the LS to LR counters in external_ids.\n\nChange-Id: I44f6de4c9a2b1c6054417dbb7f647a6af8339660\nCloses-Bug: 1857009\n""}, {'number': 4, 'created': '2020-01-15 18:15:26.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9aa7edd7852df98fe257d6a3b5c3b524398a1d4b', 'message': ""Don't fail in case subnet or Logical Switch not found\n\nIn case of subnet not found all the related actions could\nnot be taken. This patch prevent this situation to happen.\nThis could be possible that LB is going to be deleted after\nthe subnet (for example remove of the LoadBalancer in Error\nstate).\n\nThe same could happend with Logical Switch. Sometimes the\nmember network is delated in meantime and then we tries to\nthe members. It means we would need to remove LB to LS and\nLB to LR associations, but it could not happend because of\nmissing LS. In those terms now we just pass the flow\nand remove the LS to LR counters in external_ids.\n\nChange-Id: I44f6de4c9a2b1c6054417dbb7f647a6af8339660\nCloses-Bug: 1857009\n""}]",5,701933,9aa7edd7852df98fe257d6a3b5c3b524398a1d4b,22,4,4,24791,,,0,"Don't fail in case subnet or Logical Switch not found

In case of subnet not found all the related actions could
not be taken. This patch prevent this situation to happen.
This could be possible that LB is going to be deleted after
the subnet (for example remove of the LoadBalancer in Error
state).

The same could happend with Logical Switch. Sometimes the
member network is delated in meantime and then we tries to
the members. It means we would need to remove LB to LS and
LB to LR associations, but it could not happend because of
missing LS. In those terms now we just pass the flow
and remove the LS to LR counters in external_ids.

Change-Id: I44f6de4c9a2b1c6054417dbb7f647a6af8339660
Closes-Bug: 1857009
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/33/701933/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py']",2,abbd99a10393208b93a38f315f6d43f30bf1006f,ovn-provider-train," def test__find_ls_for_lr_subnet_not_found(self, net_dr): fake_subnet1 = fakes.FakeSubnet.create_one_subnet() fake_subnet1.network_id = 'foo1' fake_subnet2 = fakes.FakeSubnet.create_one_subnet() fake_subnet2.network_id = 'foo2' net_dr.return_value.get_subnet.side_effect = [ fake_subnet1, n_exc.NotFound] p1 = fakes.FakeOVNPort.create_one_port(attrs={ 'gateway_chassis': [], 'external_ids': { ovn_const.OVN_SUBNET_EXT_IDS_KEY: '%s %s' % (fake_subnet1.id, fake_subnet2.id)}}) self.router.ports.append(p1) res = self.helper._find_ls_for_lr(self.router) self.assertListEqual(['neutron-foo1'], res) @mock.patch('networking_ovn.octavia.ovn_driver.get_network_driver') side_effect) = [idlutils.RowNotFound] def test__update_lb_to_ls_association_network_dis_ls_not_found(self): self._update_lb_to_ls_association.stop() (self.helper.ovn_nbdb_api.ls_get.return_value.execute. side_effect) = [idlutils.RowNotFound] self.helper._update_lb_to_ls_association( self.ref_lb1, network_id=self.network.uuid, associate=False) self.helper.ovn_nbdb_api.ls_get.assert_called_once_with( self.network.name) self.helper.ovn_nbdb_api.db_set.assert_called_once_with( 'Load_Balancer', self.ref_lb1.uuid, ('external_ids', {'ls_refs': '{}'})) self.helper.ovn_nbdb_api.ls_lb_del.assert_not_called() @mock.patch('networking_ovn.octavia.ovn_driver.get_network_driver') def test__update_lb_to_ls_association_network_dis_net_not_found(self, gn): gn.return_value.get_subnet.side_effect = n_exc.NotFound self._update_lb_to_ls_association.stop() (self.helper.ovn_nbdb_api.ls_get.return_value.execute. return_value) = self.network self.helper._update_lb_to_ls_association( self.ref_lb1, subnet_id='foo', associate=False) self.helper.ovn_nbdb_api.ls_get.assert_not_called() self.helper.ovn_nbdb_api.db_set.assert_not_called() self.helper.ovn_nbdb_api.ls_lb_del.assert_not_called() ", return_value) = None,90,24
openstack%2Fkolla~stable%2Frocky~I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e,openstack/kolla,stable/rocky,I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e,CI: Fix symlinks for failed build logs,MERGED,2020-01-13 10:04:22.000000000,2020-01-16 12:23:05.000000000,2020-01-16 12:23:05.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-13 10:04:22.000000000', 'files': ['tests/playbooks/post.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/11f54cfb096aba21d35e9860167e8deaaf623af3', 'message': 'CI: Fix symlinks for failed build logs\n\nFollow up to I5b5f323471676317a2898875cbbf297082328fcc. Logs are no\nlonger gzipped, so we do not need to modify the 000_FAILED_* symlinks.\n\nChange-Id: I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e\n(cherry picked from commit 63f773f569c7601deab40b32bd62ccde513fa46f)\n'}]",0,702180,11f54cfb096aba21d35e9860167e8deaaf623af3,14,4,1,14826,,,0,"CI: Fix symlinks for failed build logs

Follow up to I5b5f323471676317a2898875cbbf297082328fcc. Logs are no
longer gzipped, so we do not need to modify the 000_FAILED_* symlinks.

Change-Id: I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e
(cherry picked from commit 63f773f569c7601deab40b32bd62ccde513fa46f)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/80/702180/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/playbooks/post.yml'],1,11f54cfb096aba21d35e9860167e8deaaf623af3,,," # Update symlinks to new file names for f in $(find logs -name ""*FAILED*""); do sudo mv ${f} ${f}.gz sudo ln -sf ${f#*/000_FAILED_}.gz ${f}.gz done ",0,6
openstack%2Fcharm-neutron-gateway~stable%2F19.10~I5f943941328f8a9cd0701e626e4557e243bf37f0,openstack/charm-neutron-gateway,stable/19.10,I5f943941328f8a9cd0701e626e4557e243bf37f0,Remove deprecated neutron-lbaasv2-agent from NRPE checks,MERGED,2020-01-15 08:27:24.000000000,2020-01-16 11:48:52.000000000,2020-01-16 11:48:52.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 28014}, {'_account_id': 30442}, {'_account_id': 31503}]","[{'number': 1, 'created': '2020-01-15 08:27:24.000000000', 'files': ['hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/neutron_utils.py', 'hooks/neutron_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/b4e5b911c50c8362a537eadd2fea00479784f1ff', 'message': 'Remove deprecated neutron-lbaasv2-agent from NRPE checks\n\nThis patch removes the deprecated neutron-lbaasv2-agent service from\nNRPE checks after an OpenStack upgrade to an OpenStack version greater\nthan Stein.\n\nDepends-On: https://github.com/juju/charm-helpers/pull/409\n\nChange-Id: I5f943941328f8a9cd0701e626e4557e243bf37f0\nSigned-off-by: Aggelos Kolaitis <akolaitis@admin.grnet.gr>\n(cherry picked from commit 7e68feed95eb9489184914cf218265d4a30558e2)\n'}]",0,702593,b4e5b911c50c8362a537eadd2fea00479784f1ff,10,7,1,28014,,,0,"Remove deprecated neutron-lbaasv2-agent from NRPE checks

This patch removes the deprecated neutron-lbaasv2-agent service from
NRPE checks after an OpenStack upgrade to an OpenStack version greater
than Stein.

Depends-On: https://github.com/juju/charm-helpers/pull/409

Change-Id: I5f943941328f8a9cd0701e626e4557e243bf37f0
Signed-off-by: Aggelos Kolaitis <akolaitis@admin.grnet.gr>
(cherry picked from commit 7e68feed95eb9489184914cf218265d4a30558e2)
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/93/702593/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/charmsupport/nrpe.py', 'hooks/neutron_utils.py', 'hooks/neutron_hooks.py']",3,b4e5b911c50c8362a537eadd2fea00479784f1ff,," deprecated_services, nrpe.remove_deprecated_check(nrpe_setup, deprecated_services())",,25,0
openstack%2Ftripleo-ansible~master~I32eeab72bdf6538cea749ebe55a6ae65c0f31442,openstack/tripleo-ansible,master,I32eeab72bdf6538cea749ebe55a6ae65c0f31442,tripleo-container-manage: fix check mode,MERGED,2020-01-15 23:45:17.000000000,2020-01-16 11:39:07.000000000,2020-01-16 11:39:07.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-15 23:45:17.000000000', 'files': ['tripleo_ansible/roles/tripleo-container-manage/tasks/podman/create.yml', 'tripleo_ansible/roles/tripleo-container-manage/tasks/podman/exec.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c7a81f95a254a57d6cfac4be263afc315f1e3fcf', 'message': 'tripleo-container-manage: fix check mode\n\nIf no commands are run, provide an empty default.\n\nChange-Id: I32eeab72bdf6538cea749ebe55a6ae65c0f31442\n'}]",3,702777,c7a81f95a254a57d6cfac4be263afc315f1e3fcf,9,4,1,3153,,,0,"tripleo-container-manage: fix check mode

If no commands are run, provide an empty default.

Change-Id: I32eeab72bdf6538cea749ebe55a6ae65c0f31442
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/77/702777/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo-container-manage/tasks/podman/create.yml', 'tripleo_ansible/roles/tripleo-container-manage/tasks/podman/exec.yml']",2,c7a81f95a254a57d6cfac4be263afc315f1e3fcf,fix," all_containers_commands: ""{{ containers_commands|default([], true) + (all_containers_commands | default([]) | list) }}"""," all_containers_commands: ""{{ containers_commands + (all_containers_commands | default([]) | list) }}""",2,2
openstack%2Ftripleo-ansible~master~I6997af78f6fddac7811de67162a6b673c9897f57,openstack/tripleo-ansible,master,I6997af78f6fddac7811de67162a6b673c9897f57,"Revert ""tripleo-container-image: add |list to containers_commands""",MERGED,2020-01-15 23:45:17.000000000,2020-01-16 11:14:45.000000000,2020-01-16 11:14:45.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-15 23:45:17.000000000', 'files': ['tripleo_ansible/roles/tripleo-container-manage/tasks/podman/create.yml', 'tripleo_ansible/roles/tripleo-container-manage/tasks/podman/exec.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/556fbb8b3adb18454b4aa81c0ab682c100e73308', 'message': 'Revert ""tripleo-container-image: add |list to containers_commands""\n\nIt doesn\'t work as expected, we need to do default([]).\n\nThis reverts commit b2287480a300cf0e115e8e941934cdb9adb797f7.\n\nChange-Id: I6997af78f6fddac7811de67162a6b673c9897f57\n'}]",0,702776,556fbb8b3adb18454b4aa81c0ab682c100e73308,8,4,1,3153,,,0,"Revert ""tripleo-container-image: add |list to containers_commands""

It doesn't work as expected, we need to do default([]).

This reverts commit b2287480a300cf0e115e8e941934cdb9adb797f7.

Change-Id: I6997af78f6fddac7811de67162a6b673c9897f57
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/76/702776/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo-container-manage/tasks/podman/create.yml', 'tripleo_ansible/roles/tripleo-container-manage/tasks/podman/exec.yml']",2,556fbb8b3adb18454b4aa81c0ab682c100e73308,fix," all_containers_commands: ""{{ containers_commands + (all_containers_commands | default([]) | list) }}"""," all_containers_commands: ""{{ containers_commands|list + (all_containers_commands | default([]) | list) }}""",2,2
openstack%2Fdesignate~master~Iaf21ec59755375d3c3bc043b16a1b14aa991475e,openstack/designate,master,Iaf21ec59755375d3c3bc043b16a1b14aa991475e,Improve sink recordset creation,MERGED,2019-12-23 09:49:01.000000000,2020-01-16 10:44:00.000000000,2020-01-16 10:42:08.000000000,"[{'_account_id': 13252}, {'_account_id': 15736}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-12-23 09:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/16b6c77ca6fe6f38f580ff25e10a6a5d6dc4432f', 'message': 'Improved sink record create efficiency\n\nReduced the number of calls we need to make\nwhen creating records using the sink.\n\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 2, 'created': '2019-12-23 10:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d0393b03db952a0c1fd311fe240247e0a8ce6dbc', 'message': 'Improved sink record create efficiency\n\nReduced the number of calls we need to make\nwhen creating records using the sink.\n\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 3, 'created': '2019-12-24 21:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/60ddd05866387fedbde68b1627f52b6c921b4029', 'message': 'Improved sink record create efficiency\n\nReduced the number of calls we need to make\nwhen creating records using the sink.\n\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 4, 'created': '2019-12-24 21:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/1257e23c4d2e8de5ac3b260d1feea7be6785e626', 'message': 'Improved sink record create efficiency\n\nReduced the number of calls we need to make\nwhen creating records using the sink.\n\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 5, 'created': '2019-12-24 23:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4dd8d5034209bf0a696f5fa55e22c4b682733a08', 'message': 'Improve sink recordset creation\n\nReduced the number of calls we need to make\nwhen creating records using the sink.\n\nPartial-Bug: #1768618\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 6, 'created': '2019-12-24 23:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/a474e1b9da133eb654dd51cad2a1c32fac287498', 'message': 'Improve sink recordset creation\n\nReduced the number of calls we need to make when creating records using\nthe sink by better using the create/update recordset api.\n\nThis also fixes a bug where the sink could trigger a race condition in\nthe worker causing it to throw a BadAction exception.\n\nPartial-Bug: #1768618\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 7, 'created': '2019-12-25 00:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/9fa138d4312850915362fb4d0937722d6bfbc9ef', 'message': 'Improve sink recordset creation\n\nReduced the number of calls we need to make when creating records using\nthe sink by better using the create/update recordset api.\n\nThis also fixes a bug where the sink could trigger a race condition in\nthe worker causing it to throw a BadAction exception.\n\nPartial-Bug: #1768618\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}, {'number': 8, 'created': '2019-12-29 02:48:05.000000000', 'files': ['designate/notification_handler/base.py', 'contrib/designate-ext-samplehandler/designate_ext_samplehandler/notification_handler/sample.py', 'designate/tests/test_notification_handler/test_nova.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/4869913519e0b7bb12b4ba1ef6b7ce8aabb53825', 'message': 'Improve sink recordset creation\n\nReduced the number of calls we need to make when creating records using\nthe sink by better using the create/update recordset api.\n\nThis also fixes a bug where the sink could trigger a race condition in\nthe worker causing it to throw a BadAction exception.\n\nPartial-Bug: #1768618\nChange-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e\n'}]",1,700404,4869913519e0b7bb12b4ba1ef6b7ce8aabb53825,27,4,8,22623,,,0,"Improve sink recordset creation

Reduced the number of calls we need to make when creating records using
the sink by better using the create/update recordset api.

This also fixes a bug where the sink could trigger a race condition in
the worker causing it to throw a BadAction exception.

Partial-Bug: #1768618
Change-Id: Iaf21ec59755375d3c3bc043b16a1b14aa991475e
",git fetch https://review.opendev.org/openstack/designate refs/changes/04/700404/8 && git format-patch -1 --stdout FETCH_HEAD,"['designate/notification_handler/base.py', 'contrib/designate-ext-samplehandler/designate_ext_samplehandler/notification_handler/sample.py']",2,16b6c77ca6fe6f38f580ff25e10a6a5d6dc4432f,," self._create_recordset(context, [Record(**record_values)], **recordset_values)"," recordset = self._find_or_create_recordset(context, **recordset_values) self.central_api.create_record(context, zone_id, recordset['id'], Record(**record_values))",23,20
openstack%2Fhorizon~master~I4385ba30561121505d7eca551e57e97a1085ea3c,openstack/horizon,master,I4385ba30561121505d7eca551e57e97a1085ea3c,Imported Translations from Zanata,MERGED,2020-01-16 07:45:54.000000000,2020-01-16 10:28:08.000000000,2020-01-16 10:25:55.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 07:45:54.000000000', 'files': ['openstack_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'doc/source/locale/de/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc-install.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/01440a4cb80ab63524ed49a5b14a062d4840370e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4385ba30561121505d7eca551e57e97a1085ea3c\n'}]",0,702809,01440a4cb80ab63524ed49a5b14a062d4840370e,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4385ba30561121505d7eca551e57e97a1085ea3c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/09/702809/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'doc/source/locale/de/LC_MESSAGES/doc.po', 'doc/source/locale/de/LC_MESSAGES/doc-install.po']",6,01440a4cb80ab63524ed49a5b14a062d4840370e,zanata/translations,"# Andreas Jaeger <jaegerandi@gmail.com>, 2020. #zanata""POT-Creation-Date: 2020-01-10 03:07+0000\n""""PO-Revision-Date: 2020-01-15 03:45+0000\n""msgid ""Django 2.2"" msgstr ""Django 2.2"" msgid ""Python 3.6 or 3.7"" msgstr ""Python 3.6 oder 3.7"" ","""POT-Creation-Date: 2020-01-08 17:20+0000\n""""PO-Revision-Date: 2019-09-16 09:38+0000\n""",124,145
openstack%2Fdesignate~master~I2e9f1485fce401336ab8a4a8b1aa1f971292168f,openstack/designate,master,I2e9f1485fce401336ab8a4a8b1aa1f971292168f,Fixed neutron endpoint override,MERGED,2019-09-28 06:58:24.000000000,2020-01-16 10:18:13.000000000,2020-01-16 10:15:33.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-09-28 06:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bef3ccc41fbeb843408a4450dfd9b19e10c27910', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 2, 'created': '2019-09-28 08:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b971f53674579ef6571939e74fd3fecda03c7617', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 3, 'created': '2019-09-28 08:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5e5076b4abf24a65174ddb3fd9f8b36dde459920', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 4, 'created': '2019-09-28 08:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ed1619ce74996589901593a67f7c2bba7b2f7477', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 5, 'created': '2019-10-18 22:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/0ed33f018f9d88ae8c08c7753ccfb5644880faca', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 6, 'created': '2019-10-23 18:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ba3dfed739c558a8dd9c2ded19698acafb3bdad7', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 7, 'created': '2019-11-15 06:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/dbc0561f6bba17da8b27fdb008b06e3f5a47f36b', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 8, 'created': '2019-11-24 08:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/51b68fed4624695e5b8b3177f82d37cea3e7383d', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 9, 'created': '2019-11-27 19:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b461b529c65d79cdeebc370d12129a76c9942c4a', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 10, 'created': '2019-12-16 18:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/cb61481c2c75d7851caef785333f4d6134fd1e41', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 11, 'created': '2019-12-18 23:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/a36844cde86a4f5b8ebd720978d550c872048b13', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 12, 'created': '2020-01-16 01:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/fc88de22c9c18564827be24b09dd30faaad0f723', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}, {'number': 13, 'created': '2020-01-16 05:30:09.000000000', 'files': ['designate/network_api/base.py', 'designate/tests/unit/network_api/__init__.py', 'designate/tests/unit/network_api/test_base.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/14429136dbc2428f260b26a755f87588ab7d639a', 'message': ""Fixed neutron endpoint override\n\nThe network_api endpoint code would never\nactually use the manually configured endpoints.\n\nThis patch changes that by first checking if\ncustom endpoints were configured, and if that\nisn't the case it will use the service_catalog\ninstead.\n\nIn addition we introduce full testing on\nthis code path to make sure it behaves\nas we expect.\n\nChange-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f\n""}]",1,685518,14429136dbc2428f260b26a755f87588ab7d639a,44,3,13,22623,,,0,"Fixed neutron endpoint override

The network_api endpoint code would never
actually use the manually configured endpoints.

This patch changes that by first checking if
custom endpoints were configured, and if that
isn't the case it will use the service_catalog
instead.

In addition we introduce full testing on
this code path to make sure it behaves
as we expect.

Change-Id: I2e9f1485fce401336ab8a4a8b1aa1f971292168f
",git fetch https://review.opendev.org/openstack/designate refs/changes/18/685518/7 && git format-patch -1 --stdout FETCH_HEAD,"['designate/network_api/base.py', 'designate/tests/unit/network_api/__init__.py', 'designate/tests/unit/network_api/test_base.py', 'designate/network_api/neutron.py']",4,bef3ccc41fbeb843408a4450dfd9b19e10c27910,endpoint_override, endpoints = self.endpoints(, endpoints = self._endpoints(,241,28
openstack%2Fopenstack-ansible-os_octavia~master~Ifc3c550a620da0de47ef6715bb61f00318a06fbc,openstack/openstack-ansible-os_octavia,master,Ifc3c550a620da0de47ef6715bb61f00318a06fbc,The variables exist in ansible_facts,ABANDONED,2020-01-15 11:05:29.000000000,2020-01-16 10:16:31.000000000,,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 25591}]","[{'number': 1, 'created': '2020-01-15 11:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/2c4aece6f87387d91307149734048ceb3f97c9dc', 'message': 'before Ansible 2.9, os_flavor_facts os_networks_facts os_image_facts return ansible_facts.\n\nChange-Id: Ifc3c550a620da0de47ef6715bb61f00318a06fbc\n'}, {'number': 2, 'created': '2020-01-15 15:11:30.000000000', 'files': ['tasks/octavia_amp_image.yml', 'tasks/octavia_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/7f906cd4aeb841e21b3eaa25087db62fa69be8cc', 'message': ""The variables exist in ansible_facts\n\nbefore Ansible 2.9, os_flavor_facts os_networks_facts os_image_facts\nmodules return ansible_facts.\n\nIn order to access the return values, we need to either through\nansible_facts.foobar or registered_var.ansible_facts.foobar\n\nThe variable foobar in the Ansible is populated by *_facts modules with\nthe content which we don't need.\n\nFor example:\n- openstack_flavors has all the flavors' data.\n- get_flavor_facts.ansible_facts.openstack_flavors has only the flavors'\ndata which is already filtered by the module parameters\n\nChange-Id: Ifc3c550a620da0de47ef6715bb61f00318a06fbc\n""}]",0,702645,7f906cd4aeb841e21b3eaa25087db62fa69be8cc,7,3,2,25591,,,0,"The variables exist in ansible_facts

before Ansible 2.9, os_flavor_facts os_networks_facts os_image_facts
modules return ansible_facts.

In order to access the return values, we need to either through
ansible_facts.foobar or registered_var.ansible_facts.foobar

The variable foobar in the Ansible is populated by *_facts modules with
the content which we don't need.

For example:
- openstack_flavors has all the flavors' data.
- get_flavor_facts.ansible_facts.openstack_flavors has only the flavors'
data which is already filtered by the module parameters

Change-Id: Ifc3c550a620da0de47ef6715bb61f00318a06fbc
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_octavia refs/changes/45/702645/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/octavia_amp_image.yml', 'tasks/octavia_post_install.yml']",2,2c4aece6f87387d91307149734048ceb3f97c9dc,use_ansbile_facts," # NOTE(cshen): # before Ansible 2.9, os_flavor_facts returns ansible_facts octavia_nova_flavor_uuid: ""{{ ansible_facts.openstack_flavors[0].id }}"" # NOTE(cshen): # before Ansible 2.9, os_networks_facts returns ansible_facts octavia_neutron_management_network_uuid: ""{{ ansible_facts.openstack_networks[0].id }}"" - Restart uwsgi services "," octavia_nova_flavor_uuid: ""{{ openstack_flavors[0].id }}"" octavia_neutron_management_network_uuid: ""{{ openstack_networks[0].id }}"" - Restart uwsgi services",13,5
openstack%2Foctavia-dashboard~stable%2Ftrain~I90bfeb589475155bc0275e00f44233252ed48562,openstack/octavia-dashboard,stable/train,I90bfeb589475155bc0275e00f44233252ed48562,Imported Translations from Zanata,MERGED,2019-12-12 10:06:06.000000000,2020-01-16 10:09:15.000000000,2020-01-16 10:07:39.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-12 10:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/b29557cc4c7388ab485a055ddbc00b26eb2eba7f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I90bfeb589475155bc0275e00f44233252ed48562\n'}, {'number': 2, 'created': '2020-01-15 08:30:45.000000000', 'files': ['octavia_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/262e822c5bd19411a9641c3854b4097a1d1a69c5', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I90bfeb589475155bc0275e00f44233252ed48562\n'}]",0,698667,262e822c5bd19411a9641c3854b4097a1d1a69c5,19,6,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I90bfeb589475155bc0275e00f44233252ed48562
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/67/698667/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_dashboard/locale/en_GB/LC_MESSAGES/djangojs.po'],1,b29557cc4c7388ab485a055ddbc00b26eb2eba7f,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2019. #zanata""POT-Creation-Date: 2019-10-30 09:50+0000\n""""PO-Revision-Date: 2019-12-11 02:21+0000\n""msgid ""Flavor Description"" msgstr ""Flavour Description"" msgid ""Flavor ID"" msgstr ""Flavour ID"" msgid """" ""The protocol for which this pool and its members listen. A valid value is "" ""HTTP, HTTPS, PROXY, TCP or UDP."" msgstr """" ""The protocol for which this pool and its members listen. A valid value is "" ""HTTP, HTTPS, PROXY, TCP or UDP."" msgid ""Unable to create flavor profile."" msgstr ""Unable to create flavour profile."" msgid ""Unable to create flavor."" msgstr ""Unable to create flavour."" msgid ""Unable to delete flavor profile."" msgstr ""Unable to delete flavour profile."" msgid ""Unable to delete flavor."" msgstr ""Unable to delete flavour."" msgid ""Unable to retrieve flavor profile."" msgstr ""Unable to retrieve flavour profile."" msgid ""Unable to retrieve flavor profiles."" msgstr ""Unable to retrieve flavour profiles."" msgid ""Unable to retrieve flavor."" msgstr ""Unable to retrieve flavour."" msgid ""Unable to retrieve flavors."" msgstr ""Unable to retrieve flavours."" msgid ""Unable to update flavor profile."" msgstr ""Unable to update flavour profile."" msgid ""Unable to update flavor."" msgstr ""Unable to update flavour."" msgid """" ""You have selected \""%s\"". Deleted load balancer is not recoverable and this "" ""deletion will delete all of the sub-resources."" msgid_plural """" ""You have selected \""%s\"". Deleted load balancers are not recoverable and "" ""this deletion will delete all of the sub-resources."" msgstr[0] """" ""You have selected \""%s\"". Deleted load balancer is not recoverable and this "" ""deletion will delete all of the sub-resources."" msgstr[1] """" ""You have selected \""%s\"". Deleted load balancers are not recoverable and "" ""this deletion will delete all of the sub-resources."" #, python-format","""POT-Creation-Date: 2019-08-26 15:40+0000\n""""PO-Revision-Date: 2018-12-18 11:21+0000\n""",60,2
openstack%2Fmistral-tempest-plugin~master~Ia96244290428e374ec22ee250264225d708ddc87,openstack/mistral-tempest-plugin,master,Ia96244290428e374ec22ee250264225d708ddc87,"Fix requirements, tox",MERGED,2020-01-15 14:14:35.000000000,2020-01-16 09:57:56.000000000,2020-01-16 09:57:56.000000000,"[{'_account_id': 8731}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2020-01-15 14:14:35.000000000', 'files': ['test-requirements.txt', 'doc/source/_static/.placeholder', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/mistral-tempest-plugin/commit/67f38b48268039872a7b133d555340412286d74a', 'message': 'Fix requirements, tox\n\nChange-Id: Ia96244290428e374ec22ee250264225d708ddc87\n'}]",0,702668,67f38b48268039872a7b133d555340412286d74a,9,4,1,19134,,,0,"Fix requirements, tox

Change-Id: Ia96244290428e374ec22ee250264225d708ddc87
",git fetch https://review.opendev.org/openstack/mistral-tempest-plugin refs/changes/68/702668/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/_static/.placeholder', 'doc/requirements.txt', 'tox.ini']",4,67f38b48268039872a7b133d555340412286d74a,requirements,"deps = -r{toxinidir}/doc/requirements.txt sphinx-build -E -W --keep-going -b html doc/source doc/build/htmlignore = E123,E125,W504"," sphinx-build -W -d doc/build/doctrees --keep-going -b html doc/source/ doc/build/htmlignore = E123,E125",9,11
openstack%2Fcompute-hyperv~master~I29321ebc93fc8a8b9d29148de7b9cf7f44f5564a,openstack/compute-hyperv,master,I29321ebc93fc8a8b9d29148de7b9cf7f44f5564a,Drop nova-network checks,ABANDONED,2020-01-15 12:46:03.000000000,2020-01-16 09:33:53.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-01-15 12:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/6074e1a79df3083fcbad30c17579506e2f816773', 'message': 'Drop nova-network checks\n\nNova-network as been completely removed, so related checks are\nfailing as the according functions have been dropped.\n\nThis change drops those checks, assuming that neutron is being used.\n\nChange-Id: I29321ebc93fc8a8b9d29148de7b9cf7f44f5564a\n'}, {'number': 2, 'created': '2020-01-15 13:51:11.000000000', 'files': ['compute_hyperv/nova/vmops.py', 'compute_hyperv/tests/unit/test_vif.py', 'compute_hyperv/nova/vif.py', 'compute_hyperv/tests/unit/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/647ac5a07b7e8570658b7db26dafc81df34a946c', 'message': 'Drop nova-network checks\n\nNova-network as been completely removed, so related checks are\nfailing as the according functions have been dropped.\n\nThis change drops those checks, assuming that neutron is being used.\n\nChange-Id: I29321ebc93fc8a8b9d29148de7b9cf7f44f5564a\n'}]",0,702660,647ac5a07b7e8570658b7db26dafc81df34a946c,5,1,2,8543,,,0,"Drop nova-network checks

Nova-network as been completely removed, so related checks are
failing as the according functions have been dropped.

This change drops those checks, assuming that neutron is being used.

Change-Id: I29321ebc93fc8a8b9d29148de7b9cf7f44f5564a
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/60/702660/1 && git format-patch -1 --stdout FETCH_HEAD,"['compute_hyperv/nova/vmops.py', 'compute_hyperv/tests/unit/test_vif.py', 'compute_hyperv/nova/vif.py', 'compute_hyperv/tests/unit/test_vmops.py']",4,6074e1a79df3083fcbad30c17579506e2f816773,, def test_get_neutron_events(self): def test_get_neutron_events_no_timeout(self):," @mock.patch.object(vmops.utils, 'is_neutron') def test_get_neutron_events(self, mock_is_neutron): mock_is_neutron.assert_called_once_with() @mock.patch.object(vmops.utils, 'is_neutron') def test_get_neutron_events_no_timeout(self, mock_is_neutron): mock_is_neutron.assert_called_once_with()",5,28
openstack%2Fmistral-lib~master~I0384a421fca057f66365e6fdb0b1efdb1a1c49f2,openstack/mistral-lib,master,I0384a421fca057f66365e6fdb0b1efdb1a1c49f2,"Fix requirements, doc",MERGED,2020-01-15 15:06:59.000000000,2020-01-16 09:23:44.000000000,2020-01-16 09:23:44.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 15:06:59.000000000', 'files': ['test-requirements.txt', 'doc/source/contributor/creating_custom_actions.rst', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/mistral-lib/commit/a2fed6c34aa30f324b76db29c02485d2178adeb9', 'message': 'Fix requirements, doc\n\nChange-Id: I0384a421fca057f66365e6fdb0b1efdb1a1c49f2\n'}]",0,702678,a2fed6c34aa30f324b76db29c02485d2178adeb9,6,2,1,19134,,,0,"Fix requirements, doc

Change-Id: I0384a421fca057f66365e6fdb0b1efdb1a1c49f2
",git fetch https://review.opendev.org/openstack/mistral-lib refs/changes/78/702678/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/contributor/creating_custom_actions.rst', 'lower-constraints.txt', 'doc/requirements.txt', 'tox.ini']",5,a2fed6c34aa30f324b76db29c02485d2178adeb9,doc," doc8 doc/sourcedeps = -r{toxinidir}/doc/requirements.txt setenv = PYTHONHASHSEED=0 commands = rm -rf doc/build sphinx-build -E -W --keep-going -b html doc/source doc/build/html[doc8] extensions = .rst, .yaml, .mistral # Maximal line length should be 80. max-line-length = 80 ", python setup.py check --restructuredtext --strictcommands = python setup.py build_sphinxwhitelist_externals = rm,22,11
openstack%2Fnetworking-ovn~stable%2Ftrain~I8b7f03a9afb94418ff3f2e9a148f5cfb92b966f1,openstack/networking-ovn,stable/train,I8b7f03a9afb94418ff3f2e9a148f5cfb92b966f1,Fix container images names in migration plugin,MERGED,2019-12-11 15:17:22.000000000,2020-01-16 09:20:16.000000000,2020-01-16 09:18:35.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 19118}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-12-11 15:17:22.000000000', 'files': ['migration/infrared/tripleo-ovn-migration/roles/prepare-migration/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0e12ee1cfff8c6d23f1b465c8d5969b8eaf1a957', 'message': ""Fix container images names in migration plugin\n\nDownstream CI ML2/OVS->ML2/OVN migration job fails on\nprepare-migration : Set image tag (tripleo deployment) task due to\nchange in container images names from 'Docker*' to 'Container*' in\ncontainers-default-parameters.yaml\n\nChange-Id: I8b7f03a9afb94418ff3f2e9a148f5cfb92b966f1\n""}]",0,698503,0e12ee1cfff8c6d23f1b465c8d5969b8eaf1a957,12,10,1,29350,,,0,"Fix container images names in migration plugin

Downstream CI ML2/OVS->ML2/OVN migration job fails on
prepare-migration : Set image tag (tripleo deployment) task due to
change in container images names from 'Docker*' to 'Container*' in
containers-default-parameters.yaml

Change-Id: I8b7f03a9afb94418ff3f2e9a148f5cfb92b966f1
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/03/698503/1 && git format-patch -1 --stdout FETCH_HEAD,['migration/infrared/tripleo-ovn-migration/roles/prepare-migration/tasks/main.yml'],1,0e12ee1cfff8c6d23f1b465c8d5969b8eaf1a957,fix_container_names_for_migration," reg=`cat /tmp/oc_plan/environments/containers-default-parameters.yaml | grep ContainerNeutronApiImage | awk '{ split($2, image , ""/""); print image[1] }'` namespace=`cat /tmp/oc_plan/environments/containers-default-parameters.yaml | grep ContainerNeutronApiImage | awk '{ split($2, image , ""/""); print image[2] }'` - { name: ContainerNeutronApiImage, image_name: neutron-server-ovn} - { name: ContainerNeutronConfigImage, image_name: neutron-server-ovn} - { name: ContainerOvnMetadataImage, image_name: neutron-metadata-agent-ovn} - { name: ContainerOvnControllerImage, image_name: ovn-controller} - { name: ContainerOvnControllerConfigImage, image_name: ovn-controller} - { name: ContainerOvnDbsImage, image_name: ovn-northd} - { name: ContainerOvnDbsConfigImage, image_name: ovn-northd}"," reg=`cat /tmp/oc_plan/environments/containers-default-parameters.yaml | grep DockerNeutronApiImage | awk '{ split($2, image , ""/""); print image[1] }'` namespace=`cat /tmp/oc_plan/environments/containers-default-parameters.yaml | grep DockerNeutronApiImage | awk '{ split($2, image , ""/""); print image[2] }'` - { name: DockerNeutronApiImage, image_name: neutron-server-ovn} - { name: DockerNeutronConfigImage, image_name: neutron-server-ovn} - { name: DockerOvnMetadataImage, image_name: neutron-metadata-agent-ovn} - { name: DockerOvnControllerImage, image_name: ovn-controller} - { name: DockerOvnControllerConfigImage, image_name: ovn-controller} - { name: DockerOvnDbsImage, image_name: ovn-northd} - { name: DockerOvnDbsConfigImage, image_name: ovn-northd}",9,9
openstack%2Fmonasca-api~master~I2e3f08edf1ab6aec526ad93d04effb91ddca600a,openstack/monasca-api,master,I2e3f08edf1ab6aec526ad93d04effb91ddca600a,Fix notification method type DB schema migration,MERGED,2019-12-20 16:37:38.000000000,2020-01-16 09:01:42.000000000,2020-01-16 08:59:48.000000000,"[{'_account_id': 10311}, {'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-12-20 16:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/e4714f71539f9d1a521a5c3a3c2dda448d5e26d5', 'message': 'Fix notification method type DB schema migration\n\nThe Stein release does away with the concept of built in notifications,\nin favour of treating all notification types equally.\n\nThis patch fixes an issue with the DB schema migration associated\nwith this change, which will fail if any notifications using\nbuilt-in notification types are configured at the time of the upgrade.\n\nStory: 2006984\nTask: 37746\nChange-Id: I2e3f08edf1ab6aec526ad93d04effb91ddca600a\n'}, {'number': 2, 'created': '2019-12-20 17:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/ec12fba5c46efb808389011f7545039142898ec3', 'message': 'Fix notification method type DB schema migration\n\nThe Stein release does away with the concept of built in notifications,\nin favour of treating all notification types equally.\n\nThis patch fixes an issue with the DB schema migration associated\nwith this change, which will fail if any notifications using\nbuilt-in notification types are configured at the time of the upgrade.\n\nStory: 2006984\nTask: 37746\nChange-Id: I2e3f08edf1ab6aec526ad93d04effb91ddca600a\n'}, {'number': 3, 'created': '2020-01-14 09:27:52.000000000', 'files': ['releasenotes/notes/fix-db-migration-issue-2006984-6676bd3a8a34c9ae.yaml', 'monasca_api/db/alembic/versions/26083b298bb7_remove_builtin_notification_types.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/712f693a72936e102c58a29344aee37e50f57cab', 'message': 'Fix notification method type DB schema migration\n\nThe Stein release does away with the concept of built in notifications,\nin favour of treating all notification types equally.\n\nThis patch fixes an issue with the DB schema migration associated\nwith this change, which will fail if any notifications using\nbuilt-in notification types are configured at the time of the upgrade.\n\nStory: 2006984\nTask: 37746\nChange-Id: I2e3f08edf1ab6aec526ad93d04effb91ddca600a\n'}]",0,700200,712f693a72936e102c58a29344aee37e50f57cab,20,5,3,17669,,,0,"Fix notification method type DB schema migration

The Stein release does away with the concept of built in notifications,
in favour of treating all notification types equally.

This patch fixes an issue with the DB schema migration associated
with this change, which will fail if any notifications using
built-in notification types are configured at the time of the upgrade.

Story: 2006984
Task: 37746
Change-Id: I2e3f08edf1ab6aec526ad93d04effb91ddca600a
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/00/700200/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_api/db/alembic/versions/26083b298bb7_remove_builtin_notification_types.py'],1,e4714f71539f9d1a521a5c3a3c2dda448d5e26d5,alembic_fix,"_NM_BUILT_IN_TYPES = set(['EMAIL', 'WEBHOOK', 'PAGERDUTY']) _nm = table( 'notification_method', sa.Column('type', sa.String(length=20), nullable=False)) # remove them (where not in use) and rely on Monasca Notification # to re-populate the table according to what is set in its config file. # Start by creating a set of all notification method types currently # configured in the Monasca DB connection = op.get_bind() nm_types_configured = connection.execute(_nm.select()).fetchall() nm_types_configured = set([nm_type[0] for nm_type in nm_types_configured]) # Remove all built in notification types which are currently *not* # configured. nm_types_to_remove = _NM_BUILT_IN_TYPES.difference(nm_types_configured) _nm_types.c.name.in_(nm_types_to_remove)))"," # remove them and rely on monasca_notification to re-populate # the table according to what is set in its config file. _nm_types.c.name.in_(('EMAIL', 'WEBHOOK', 'PAGERDUTY'))))",20,3
openstack%2Fneutron~stable%2Fstein~Ifffdee0d4a3226d4871cfabd0bdbf13d7058a83e,openstack/neutron,stable/stein,Ifffdee0d4a3226d4871cfabd0bdbf13d7058a83e,Fix py3 compatibility,MERGED,2019-11-05 12:48:13.000000000,2020-01-16 08:43:21.000000000,2019-11-06 11:18:35.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27339}]","[{'number': 1, 'created': '2019-11-05 12:48:13.000000000', 'files': ['neutron/agent/l3/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/70391139906a673bde88210757656b35cb4c45bc', 'message': ""Fix py3 compatibility\n\nIn fetch_and_sync_all_routers method is used python's range function.\nRange function accepts integers.\n\nThis patch is fixing divide behaviour in py3 where result number is float,\nby retyping float to int as it is represented in py2.\n\nChange-Id: Ifffdee0d4a3226d4871cfabd0bdbf13d7058a83e\nCloses-Bug: #1824334\n(cherry picked from commit 49a66dba31f23d54972e962beef66c39307904df)\n""}]",0,692998,70391139906a673bde88210757656b35cb4c45bc,12,7,1,30523,,,0,"Fix py3 compatibility

In fetch_and_sync_all_routers method is used python's range function.
Range function accepts integers.

This patch is fixing divide behaviour in py3 where result number is float,
by retyping float to int as it is represented in py2.

Change-Id: Ifffdee0d4a3226d4871cfabd0bdbf13d7058a83e
Closes-Bug: #1824334
(cherry picked from commit 49a66dba31f23d54972e962beef66c39307904df)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/692998/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/agent.py'],1,70391139906a673bde88210757656b35cb4c45bc,bug/1824334-stable/stein," self.sync_routers_chunk_size // 2,"," self.sync_routers_chunk_size / 2,",1,1
openstack%2Frequirements~master~Ia227832e63083aaa00f4b636d5fb415c53fde125,openstack/requirements,master,Ia227832e63083aaa00f4b636d5fb415c53fde125,update constraint for os-traits to new release 2.2.0,MERGED,2020-01-15 21:43:04.000000000,2020-01-16 08:42:58.000000000,2020-01-16 08:41:34.000000000,"[{'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2020-01-15 21:43:04.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b8074d840df5d58252eb67619c6cdc37bd7ecce5', 'message': 'update constraint for os-traits to new release 2.2.0\n\nChange-Id: Ia227832e63083aaa00f4b636d5fb415c53fde125\nmeta:version: 2.2.0\nmeta:diff-start: -\nmeta:series: independent\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Lee Yarwood <lyarwood@redhat.com>\nmeta:release:Commit: Eric Fried <openstack@fried.cc>\nmeta:release:Change-Id: Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,702755,b8074d840df5d58252eb67619c6cdc37bd7ecce5,12,5,1,11131,,,0,"update constraint for os-traits to new release 2.2.0

Change-Id: Ia227832e63083aaa00f4b636d5fb415c53fde125
meta:version: 2.2.0
meta:diff-start: -
meta:series: independent
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Lee Yarwood <lyarwood@redhat.com>
meta:release:Commit: Eric Fried <openstack@fried.cc>
meta:release:Change-Id: Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/55/702755/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,b8074d840df5d58252eb67619c6cdc37bd7ecce5,new-release,os-traits===2.2.0,os-traits===2.1.0,1,1
openstack%2Ffreezer~master~I14ab74f3e82e83ef5c5a49831f68335965e7e101,openstack/freezer,master,I14ab74f3e82e83ef5c5a49831f68335965e7e101,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2019-11-22 01:53:15.000000000,2020-01-16 08:36:39.000000000,2020-01-16 08:34:14.000000000,"[{'_account_id': 8556}, {'_account_id': 21069}, {'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-22 01:53:15.000000000', 'files': ['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-a76d53b7a12bcff2.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer/commit/f04df2caa58717dc1667d02c86f2da8d6a261c08', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nfreezer is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I14ab74f3e82e83ef5c5a49831f68335965e7e101\n'}]",0,695615,f04df2caa58717dc1667d02c86f2da8d6a261c08,11,4,1,8556,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

freezer is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Change-Id: I14ab74f3e82e83ef5c5a49831f68335965e7e101
",git fetch https://review.opendev.org/openstack/freezer refs/changes/15/695615/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-a76d53b7a12bcff2.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",5,f04df2caa58717dc1667d02c86f2da8d6a261c08,drop-py27-support,"envlist = py37,pep8,pylint,docsbasepython = python3","envlist = py27,py37,pep8,pylint,docsbasepython = python3[testenv:py27] basepython = python2.7 basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",8,14
openstack%2Fmonasca-api~master~I2da1b3a60df4781c2e1bb954db3293722414c6b8,openstack/monasca-api,master,I2da1b3a60df4781c2e1bb954db3293722414c6b8,Fix invalid list of notification types in API spec,MERGED,2019-12-19 11:42:04.000000000,2020-01-16 08:25:41.000000000,2020-01-16 08:24:15.000000000,"[{'_account_id': 10311}, {'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-12-19 11:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/8e93dffac031987b125a1b87125f61e4222b4c00', 'message': 'Fix invalid list of notification types in API spec\n\nTrivialFix\nChange-Id: I2da1b3a60df4781c2e1bb954db3293722414c6b8\n'}, {'number': 2, 'created': '2020-01-14 11:39:44.000000000', 'files': ['docs/monasca-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3a405648d37f85b03b9f4db064e717fa419a2661', 'message': 'Fix invalid list of notification types in API spec\n\nTrivialFix\nChange-Id: I2da1b3a60df4781c2e1bb954db3293722414c6b8\n'}]",1,699958,3a405648d37f85b03b9f4db064e717fa419a2661,14,4,2,17669,,,0,"Fix invalid list of notification types in API spec

TrivialFix
Change-Id: I2da1b3a60df4781c2e1bb954db3293722414c6b8
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/58/699958/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/monasca-api-spec.md'],1,8e93dffac031987b125a1b87125f61e4222b4c00,,"Currently, notification method types of email, PagerDuty, webhook, Slack and Jira are supported. In the case of email, the address is the email address. In the case of PagerDuty, the address is the PagerDuty Service API Key. In the case of a webhook, the address is the URL of the webhook. See the Monasca Notification service plugin [documentation](https://opendev.org/openstack/monasca-notification#plugins) for more information.* type (string(100), required) - The type of notification method (See [List supported Notification Method Types](#list-supported-notification-method-types) for supported types).* type (string(100), optional) - The type of notification method (See [List supported Notification Method Types](#list-supported-notification-method-types) for supported types).","Currently, notification method types of email, PagerDuty and webhooks are supported. In the case of email, the address is the email address. In the case of PagerDuty, the address is the PagerDuty Service API Key. In the case of a webhook, the address is the URL of the webhook.* type (string(100), required) - The type of notification method (`EMAIL`, `WEBHOOK`, or `PAGERDUTY` ).* type (string(100), optional) - The type of notification method (`EMAIL`, `WEBHOOK`, or `PAGERDUTY` ).",3,3
openstack%2Fmonasca-agent~master~Id04c34bd9aabd61ccd4ce22b30e515e4ca627561,openstack/monasca-agent,master,Id04c34bd9aabd61ccd4ce22b30e515e4ca627561,Add Infiniband metrics plugin,MERGED,2019-12-20 17:44:34.000000000,2020-01-16 08:25:26.000000000,2020-01-16 08:25:26.000000000,"[{'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-20 17:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6f9dbb2ab6262d4fc8e59704ce56901c3dd0a0d7', 'message': 'Add Infiniband metrics plugin\n\nThis plugin adds initial support for gathering Infiniband counters.\n\nStory: 2007044\nTask: 37859\nChange-Id: Id04c34bd9aabd61ccd4ce22b30e515e4ca627561\n'}, {'number': 2, 'created': '2020-01-14 11:33:44.000000000', 'files': ['tests/checks_d/test_ib_network.py', 'tests/detection/test_ib_network.py', 'monasca_agent/collector/checks_d/ib_network.py', 'docs/Plugins.md', 'monasca_setup/detection/plugins/ib_network.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/e4aba27933e26115b0e66d09ceff707bf85d93e9', 'message': 'Add Infiniband metrics plugin\n\nThis plugin adds initial support for gathering Infiniband counters.\n\nStory: 2007044\nTask: 37859\nChange-Id: Id04c34bd9aabd61ccd4ce22b30e515e4ca627561\n'}]",1,700215,e4aba27933e26115b0e66d09ceff707bf85d93e9,11,3,2,17669,,,0,"Add Infiniband metrics plugin

This plugin adds initial support for gathering Infiniband counters.

Story: 2007044
Task: 37859
Change-Id: Id04c34bd9aabd61ccd4ce22b30e515e4ca627561
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/15/700215/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/checks_d/test_ib_network.py', 'tests/detection/test_ib_network.py', 'monasca_agent/collector/checks_d/ib_network.py', 'docs/Plugins.md', 'monasca_setup/detection/plugins/ib_network.py']",5,6f9dbb2ab6262d4fc8e59704ce56901c3dd0a0d7,,"# Copyright (c) 2018 StackHPC Ltd. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import os import monasca_setup.agent_config import monasca_setup.detection LOG = logging.getLogger(__name__) _IB_DEVICE_PATH = ""/sys/class/infiniband/"" class IBNetworkDetect(monasca_setup.detection.Plugin): """"""Detects and configures Infiniband plugin."""""" def _detect(self): self.available = False if not self._detect_infiniband(): LOG.info('Infiniband hardware was not detected: ib_network plugin' 'will not be loaded.') return self.available = True def build_config(self): config = monasca_setup.agent_config.Plugins() config['ib_network'] = {'init_config': None, 'instances': [{'name': 'ib_network_stats'}]} return config def _detect_infiniband(self): return os.path.isdir(_IB_DEVICE_PATH) ",,288,0
openstack%2Ftripleo-ansible~master~I48b1e749081e2f84cda3687f685f3c392817c89a,openstack/tripleo-ansible,master,I48b1e749081e2f84cda3687f685f3c392817c89a,paunch: allow to override any container config,MERGED,2020-01-09 03:41:51.000000000,2020-01-16 08:14:09.000000000,2020-01-16 05:57:19.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-09 03:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a081d80fe0b8898b2f655e35326efba174bdc56a', 'message': 'paunch: allow to override any container config\n\nThis will enable an operator to override a paunch-managed container config.\n\nExample given:\n\n- name: Start containers for step 1\n  paunch:\n    config: /var/lib/tripleo-config/hashed-container-startup-config-step_1.json\n    config_overrides:\n      haproxy:\n        image: docker.io/tripleomaster/centos-binary-haproxy:current-tripleo-hotfix\n    config_id: tripleo_step1\n    action: apply\n\nDepends-On: I6639ab859b120aa9349dc72b0d6e7d575be20c7a\nChange-Id: I48b1e749081e2f84cda3687f685f3c392817c89a\n'}, {'number': 2, 'created': '2020-01-10 16:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b2d9fa17cc68fe3f18740d538ca4e35998204cb8', 'message': 'paunch: allow to override any container config\n\nThis will enable an operator to override a paunch-managed container config.\n\nExample given:\n\n- name: Start containers for step 1\n  paunch:\n    config: /var/lib/tripleo-config/hashed-container-startup-config-step_1.json\n    config_overrides:\n      haproxy:\n        image: docker.io/tripleomaster/centos-binary-haproxy:current-tripleo-hotfix\n    config_id: tripleo_step1\n    action: apply\n\nDepends-On: I6639ab859b120aa9349dc72b0d6e7d575be20c7a\nChange-Id: I48b1e749081e2f84cda3687f685f3c392817c89a\n'}, {'number': 3, 'created': '2020-01-10 16:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c75d439095d0a4ead9604b95fcbd53921015de6f', 'message': 'paunch: allow to override any container config\n\nThis will enable an operator to override a paunch-managed container config.\n\nExample given:\n\n- name: Start containers for step 1\n  paunch:\n    config: /var/lib/tripleo-config/hashed-container-startup-config-step_1.json\n    config_overrides:\n      haproxy:\n        image: docker.io/tripleomaster/centos-binary-haproxy:current-tripleo-hotfix\n    config_id: tripleo_step1\n    action: apply\n\nDepends-On: I6639ab859b120aa9349dc72b0d6e7d575be20c7a\nChange-Id: I48b1e749081e2f84cda3687f685f3c392817c89a\n'}, {'number': 4, 'created': '2020-01-10 20:08:49.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/paunch.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fac2c679d833f9a071ce453005f050544cf3636a', 'message': 'paunch: allow to override any container config\n\nThis will enable an operator to override a paunch-managed container config.\n\nExample given:\n\n- name: Start containers for step 1\n  paunch:\n    config: /var/lib/tripleo-config/hashed-container-startup-config-step_1.json\n    config_overrides:\n      haproxy:\n        image: docker.io/tripleomaster/centos-binary-haproxy:current-tripleo-hotfix\n    config_id: tripleo_step1\n    action: apply\n\nDepends-On: I6639ab859b120aa9349dc72b0d6e7d575be20c7a\nChange-Id: I48b1e749081e2f84cda3687f685f3c392817c89a\n'}]",0,701661,fac2c679d833f9a071ce453005f050544cf3636a,25,7,4,3153,,,0,"paunch: allow to override any container config

This will enable an operator to override a paunch-managed container config.

Example given:

- name: Start containers for step 1
  paunch:
    config: /var/lib/tripleo-config/hashed-container-startup-config-step_1.json
    config_overrides:
      haproxy:
        image: docker.io/tripleomaster/centos-binary-haproxy:current-tripleo-hotfix
    config_id: tripleo_step1
    action: apply

Depends-On: I6639ab859b120aa9349dc72b0d6e7d575be20c7a
Change-Id: I48b1e749081e2f84cda3687f685f3c392817c89a
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/61/701661/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/paunch.py'],1,a081d80fe0b8898b2f655e35326efba174bdc56a,paunch/merge," config_overrides: description: - Dictionary to override containers configs default: {} config_overrides: haproxy: image: docker.io/tripleomaster/centos-binary-haproxy:current-tripleo-hotfix self.config_overrides = self.module.params['config_overrides'] self.config_yaml = putils_common.load_config( self.config, merge_with=self.config_overrides)", self.config_yaml = putils_common.load_config(self.config),11,1
openstack%2Fhorizon~master~I47f73ff94664d315a2400feb8ce8a25f4e6beced,openstack/horizon,master,I47f73ff94664d315a2400feb8ce8a25f4e6beced,Fixes a series of bugs related to Floating IPs.,MERGED,2019-10-30 08:39:30.000000000,2020-01-16 08:01:27.000000000,2020-01-06 16:14:47.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 26546}]","[{'number': 1, 'created': '2019-10-30 08:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/71c1fe93a907a3d6d22f2806b9915b3e716f2f34', 'message': ""Fixes a series of bugs related to Floating IPs.\n\n- Fixes KeyErrors when accessing 'floatingip' values in usages, which\n\xa0 broke Floating IP allocation.\n- The quota display in the bottom right of the Allocation dialog are\n\xa0 only displayed if 'enabled_quotas' is True\n- Adds security group rule tallying for the usages overview page, which\n\xa0 fixes a KeyError crash for installations where Horizon 'enable_quotas'\n\xa0 is set to true, but the 'quota_details' extension is not installed on\n\xa0 in Neutron\n- Adds a policy check to show and hide The plus/add button in\n\xa0 Instances->Associate Floating IP to match the Allocate IP To Project\n\xa0 button in Floating IPs\n- Fixed the page title not being set for the non-modal version of the\n\xa0 modal allocation dialog/form\n- Added an 'allowed' functionality for network usage overview charts to\n\xa0 allow for them to be dynamically disabled\n- Added tests and mocks for the above\n- Added tests for non-legacy quota tallying for networks\n- Added test for disabled network quotas in overview\n\nChange-Id: I47f73ff94664d315a2400feb8ce8a25f4e6beced\ncloses-bug: #1838522\n""}, {'number': 2, 'created': '2019-11-21 10:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5d4c06e41f24606247f7b8be9eae24ad307ca2c', 'message': ""Fixes a series of bugs related to Floating IPs.\n\n- Fixes KeyErrors when accessing 'floatingip' values in usages, which\n\xa0 broke Floating IP allocation.\n- The quota display in the bottom right of the Allocation dialog are\n\xa0 only displayed if 'enabled_quotas' is True\n- Adds security group rule tallying for the usages overview page, which\n\xa0 fixes a KeyError crash for installations where Horizon 'enable_quotas'\n\xa0 is set to true, but the 'quota_details' extension is not installed on\n\xa0 in Neutron\n- Adds a policy check to show and hide The plus/add button in\n\xa0 Instances->Associate Floating IP to match the Allocate IP To Project\n\xa0 button in Floating IPs\n- Fixed the page title not being set for the non-modal version of the\n\xa0 modal allocation dialog/form\n- Added an 'allowed' functionality for network usage overview charts to\n\xa0 allow for them to be dynamically disabled\n- Added tests and mocks for the above\n- Added tests for non-legacy quota tallying for networks\n- Added test for disabled network quotas in overview\n\nChange-Id: I47f73ff94664d315a2400feb8ce8a25f4e6beced\ncloses-bug: #1838522\n""}, {'number': 3, 'created': '2019-11-21 14:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/570cc0340aa318b342b02fbe42d1b1ecc445ef98', 'message': ""Fixes a series of bugs related to Floating IPs.\n\n- Fixes KeyErrors when accessing 'floatingip' values in usages, which\n\xa0 broke Floating IP allocation.\n- The quota display in the bottom right of the Allocation dialog are\n\xa0 only displayed if 'enabled_quotas' is True\n- Adds security group rule tallying for the usages overview page, which\n\xa0 fixes a KeyError crash for installations where Horizon 'enable_quotas'\n\xa0 is set to true, but the 'quota_details' extension is not installed on\n\xa0 in Neutron\n- Adds a policy check to show and hide The plus/add button in\n\xa0 Instances->Associate Floating IP to match the Allocate IP To Project\n\xa0 button in Floating IPs\n- Fixed the page title not being set for the non-modal version of the\n\xa0 modal allocation dialog/form\n- Added an 'allowed' functionality for network usage overview charts to\n\xa0 allow for them to be dynamically disabled\n- Added tests and mocks for the above\n- Added tests for non-legacy quota tallying for networks\n- Added test for disabled network quotas in overview\n\nChange-Id: I47f73ff94664d315a2400feb8ce8a25f4e6beced\ncloses-bug: #1838522\n""}, {'number': 4, 'created': '2019-12-17 04:30:40.000000000', 'files': ['openstack_dashboard/dashboards/project/floating_ips/templates/floating_ips/_allocate.html', 'openstack_dashboard/usage/views.py', 'openstack_dashboard/dashboards/project/floating_ips/templates/floating_ips/allocate.html', 'openstack_dashboard/dashboards/project/overview/tests.py', 'openstack_dashboard/dashboards/project/floating_ips/views.py', 'openstack_dashboard/dashboards/project/floating_ips/tables.py', 'openstack_dashboard/dashboards/project/floating_ips/forms.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/test/unit/usage/test_quotas.py', 'openstack_dashboard/dashboards/project/floating_ips/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/161b4ae5d4a7a29f9e5c91d9b391dee49e075993', 'message': ""Fixes a series of bugs related to Floating IPs.\n\n- Fixes KeyErrors when accessing 'floatingip' values in usages, which\n  broken Floating IP allocation.\n- The quota display in the bottom right of the Allocation dialog are\n  only displayed if 'enabled_quotas' is True\n- Adds security group rule tallying for the usages overview page, which\n  fixes a KeyError crash for installations where Horizon 'enable_quotas'\n  is set to true, but the 'quota_details' extension is not installed on\n  in Neutron\n- Adds a policy check to show and hide The plus/add button in\n  Instances->Associate Floating IP to match the Allocate IP To Project\n  button in Floating IPs\n- Fixed the page title not being set for the non-modal version of the\n  modal allocation dialog/form\n- Added an 'allowed' functionality for network usage overview charts to\n  allow for them to be dynamically disabled\n- Added tests and mocks for the above\n- Added tests for non-legacy quota tallying for networks\n- Added test for disabled network quotas in overview\n\nChange-Id: I47f73ff94664d315a2400feb8ce8a25f4e6beced\ncloses-bug: #1838522\n""}]",12,692074,161b4ae5d4a7a29f9e5c91d9b391dee49e075993,29,5,4,26546,,,0,"Fixes a series of bugs related to Floating IPs.

- Fixes KeyErrors when accessing 'floatingip' values in usages, which
  broken Floating IP allocation.
- The quota display in the bottom right of the Allocation dialog are
  only displayed if 'enabled_quotas' is True
- Adds security group rule tallying for the usages overview page, which
  fixes a KeyError crash for installations where Horizon 'enable_quotas'
  is set to true, but the 'quota_details' extension is not installed on
  in Neutron
- Adds a policy check to show and hide The plus/add button in
  Instances->Associate Floating IP to match the Allocate IP To Project
  button in Floating IPs
- Fixed the page title not being set for the non-modal version of the
  modal allocation dialog/form
- Added an 'allowed' functionality for network usage overview charts to
  allow for them to be dynamically disabled
- Added tests and mocks for the above
- Added tests for non-legacy quota tallying for networks
- Added test for disabled network quotas in overview

Change-Id: I47f73ff94664d315a2400feb8ce8a25f4e6beced
closes-bug: #1838522
",git fetch https://review.opendev.org/openstack/horizon refs/changes/74/692074/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/floating_ips/templates/floating_ips/_allocate.html', 'openstack_dashboard/dashboards/project/floating_ips/templates/floating_ips/allocate.html', 'openstack_dashboard/usage/views.py', 'openstack_dashboard/dashboards/project/floating_ips/views.py', 'openstack_dashboard/dashboards/project/overview/tests.py', 'openstack_dashboard/dashboards/project/floating_ips/tables.py', 'openstack_dashboard/dashboards/project/floating_ips/forms.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/test/unit/usage/test_quotas.py', 'openstack_dashboard/dashboards/project/floating_ips/workflows.py']",10,71c1fe93a907a3d6d22f2806b9915b3e716f2f34,bug/1838522,"from openstack_dashboard import policy empty_value=None if policy.check(((""network"", ""create_floatingip""),), request=self.request): self.fields['ip_id'].widget.add_item_link = ALLOCATE_URL "," empty_value=None, add_item_link=ALLOCATE_URL",208,56
openstack%2Ffreezer~master~If341ec109bff4daef37347ef65cd3c903f74fba7,openstack/freezer,master,If341ec109bff4daef37347ef65cd3c903f74fba7,Update some tempest jobs to voting job,MERGED,2020-01-16 05:42:01.000000000,2020-01-16 07:48:11.000000000,2020-01-16 07:45:18.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 05:42:01.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer/commit/6d39ec438c2214ac2ea33b0f7e82126f97938a65', 'message': 'Update some tempest jobs to voting job\n\nUpdate some tempest jobs to voting job.\n\nChange-Id: If341ec109bff4daef37347ef65cd3c903f74fba7\n'}]",0,702799,6d39ec438c2214ac2ea33b0f7e82126f97938a65,7,2,1,21069,,,0,"Update some tempest jobs to voting job

Update some tempest jobs to voting job.

Change-Id: If341ec109bff4daef37347ef65cd3c903f74fba7
",git fetch https://review.opendev.org/openstack/freezer refs/changes/99/702799/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,6d39ec438c2214ac2ea33b0f7e82126f97938a65,, - freezer-ubuntu - freezer-tempest-agent - freezer-ubuntu - freezer-tempest-agent, - freezer-ubuntu: voting: false - freezer-tempest-agent: voting: false - freezer-ubuntu: voting: false - freezer-tempest-agent: voting: false,4,8
openstack%2Fproject-config~master~If4fd66c4c08e8b8de1877d1fbcfc6bb2b3d7dea3,openstack/project-config,master,If4fd66c4c08e8b8de1877d1fbcfc6bb2b3d7dea3,Remove legacy-gearman-plugin-mavin-build-ubuntu-trusty,MERGED,2020-01-15 23:04:48.000000000,2020-01-16 07:41:47.000000000,2020-01-16 07:41:47.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 23:04:48.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1c56c2d6bdf47612d11e6b75cfba2073bfaf9964', 'message': 'Remove legacy-gearman-plugin-mavin-build-ubuntu-trusty\n\nThe dependent change introduces a non-trusty based job, switch to that\n\nDepends-On: https://review.opendev.org/702768\nChange-Id: If4fd66c4c08e8b8de1877d1fbcfc6bb2b3d7dea3\n'}]",0,702769,1c56c2d6bdf47612d11e6b75cfba2073bfaf9964,9,3,1,7118,,,0,"Remove legacy-gearman-plugin-mavin-build-ubuntu-trusty

The dependent change introduces a non-trusty based job, switch to that

Depends-On: https://review.opendev.org/702768
Change-Id: If4fd66c4c08e8b8de1877d1fbcfc6bb2b3d7dea3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/702769/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,1c56c2d6bdf47612d11e6b75cfba2073bfaf9964,trusty-removal, - legacy-gearman-plugin-maven-build - legacy-gearman-plugin-maven-build, - legacy-gearman-plugin-maven-build-ubuntu-trusty - legacy-gearman-plugin-maven-build-ubuntu-trusty,2,2
openstack%2Fdevstack~master~I93325cbd26dbc6a30062d9ba83acab248897b18e,openstack/devstack,master,I93325cbd26dbc6a30062d9ba83acab248897b18e,Stop enabling g-reg by default,MERGED,2020-01-15 17:38:11.000000000,2020-01-16 07:41:14.000000000,2020-01-16 07:38:54.000000000,"[{'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 17:38:11.000000000', 'files': ['.zuul.yaml', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d7dfcdb4674daae8a294848b1de6fa87c5d7d4eb', 'message': 'Stop enabling g-reg by default\n\nPer [1] Glance registry should not be required to run since Queens.\n\n[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html\n\nChange-Id: I93325cbd26dbc6a30062d9ba83acab248897b18e\nDepends-on: https://review.opendev.org/702707\nRelated-bug: #1859847\n'}]",0,702709,d7dfcdb4674daae8a294848b1de6fa87c5d7d4eb,8,3,1,30491,,,0,"Stop enabling g-reg by default

Per [1] Glance registry should not be required to run since Queens.

[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html

Change-Id: I93325cbd26dbc6a30062d9ba83acab248897b18e
Depends-on: https://review.opendev.org/702707
Related-bug: #1859847
",git fetch https://review.opendev.org/openstack/devstack refs/changes/09/702709/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'stackrc']",2,d7dfcdb4674daae8a294848b1de6fa87c5d7d4eb,stop-deploying-g-reg," ENABLED_SERVICES+=,g-api"," ENABLED_SERVICES+=,g-api,g-reg",1,2
openstack%2Fopenstack-manuals~master~Id0555d387b848cf206392dfcc79079312ee60e75,openstack/openstack-manuals,master,Id0555d387b848cf206392dfcc79079312ee60e75,Imported Translations from Zanata,MERGED,2020-01-16 06:30:56.000000000,2020-01-16 07:39:56.000000000,2020-01-16 07:15:43.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 06:30:56.000000000', 'files': ['doc/install-guide/source/locale/tr_TR/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/id/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/en_GB/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ru/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/en_GB/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f6ed07f84beb883c5ffb9d8d748db65e787b6cab', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id0555d387b848cf206392dfcc79079312ee60e75\n'}]",0,702802,f6ed07f84beb883c5ffb9d8d748db65e787b6cab,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Id0555d387b848cf206392dfcc79079312ee60e75
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/02/702802/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/locale/tr_TR/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/id/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/en_GB/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ru/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/en_GB/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po']",12,f6ed07f84beb883c5ffb9d8d748db65e787b6cab,zanata/translations,"""POT-Creation-Date: 2020-01-15 15:42+0000\n""","""POT-Creation-Date: 2019-07-24 04:41+0000\n""# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide msgid """" ""Implement a deployment tool such as Ansible, Chef, Puppet, or Salt to "" ""automate deployment and management of the production environment."" msgstr """" ""  Production    Ansible, Chef, Puppet, Salt  "" ""  ."" # auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-mitaka, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide# auto translated by TM merge from project: openstack-manuals, version: stable-liberty, DocId: doc/install-guide/source/locale/install-guide",64,246
openstack%2Fopenstack-zuul-jobs~master~I5c76030077959e76c8c2caf175392c7111c044e6,openstack/openstack-zuul-jobs,master,I5c76030077959e76c8c2caf175392c7111c044e6,Move legacy-gearman-plugin-mavin-build away from Trusty,MERGED,2020-01-15 23:03:10.000000000,2020-01-16 07:32:41.000000000,2020-01-16 07:23:27.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 23:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e18ae81262d7d6296e831866704b971da7a41853', 'message': 'Move legacy-gearman-plugin-mavin-build away from Trusty\n\nMake a non-trusty-dependent duplicate of the\nlegacy-gearman-plugin-mavin-build-ubuntu-trusty job so we can remove\nthe trusty-based job.\n\nChange-Id: I5c76030077959e76c8c2caf175392c7111c044e6\n'}, {'number': 2, 'created': '2020-01-15 23:09:46.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/gearman-plugin-maven-build/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/21046ab54249b5e48596035cf9ded7bc3fac9518', 'message': 'Move legacy-gearman-plugin-mavin-build away from Trusty\n\nMake a non-trusty-dependent duplicate of the\nlegacy-gearman-plugin-mavin-build-ubuntu-trusty job so we can remove\nthe trusty-based job.\n\nChange-Id: I5c76030077959e76c8c2caf175392c7111c044e6\n'}]",0,702768,21046ab54249b5e48596035cf9ded7bc3fac9518,11,3,2,7118,,,0,"Move legacy-gearman-plugin-mavin-build away from Trusty

Make a non-trusty-dependent duplicate of the
legacy-gearman-plugin-mavin-build-ubuntu-trusty job so we can remove
the trusty-based job.

Change-Id: I5c76030077959e76c8c2caf175392c7111c044e6
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/68/702768/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/gearman-plugin-maven-build/run.yaml']",2,e18ae81262d7d6296e831866704b971da7a41853,trusty-removal,"- hosts: all name: Autoconverted job legacy-gearman-plugin-maven-build-ubuntu-trusty from old job gate-gearman-plugin-maven-build-ubuntu-trusty roles: - bindep tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ https://opendev.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x /usr/local/jenkins/slave_scripts/version-properties.sh source version.properties mvn clean package -B -Dproject-version=$PROJECT_VER executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",,68,0
openstack%2Fopenstack-zuul-jobs~master~I1a77ee84448c328714101bc7a4cd76fd4b27d40a,openstack/openstack-zuul-jobs,master,I1a77ee84448c328714101bc7a4cd76fd4b27d40a,Remove legacy-puppet-openstack-infra-spec-helper-unit-ubuntu-trusty,MERGED,2020-01-15 22:52:23.000000000,2020-01-16 07:29:11.000000000,2020-01-16 07:23:26.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 22:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/bbf996e2f47b5c1939f6f5948400b3fdcd6ef1dd', 'message': 'Remove legacy-puppet-openstack-infra-spec-helper-unit-ubuntu-trusty\n\nJob call removed in dependent change as part of Trusty removal\n\nChange-Id: I1a77ee84448c328714101bc7a4cd76fd4b27d40a\nDepends-On: https://review.opendev.org/702764\n'}, {'number': 2, 'created': '2020-01-15 23:09:46.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/puppet-openstack-infra-spec-helper-unit-ubuntu-trusty/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/c7564320c28f769bf7f9188b58ef1ec44e4042b4', 'message': 'Remove legacy-puppet-openstack-infra-spec-helper-unit-ubuntu-trusty\n\nJob call removed in dependent change as part of Trusty removal\n\nChange-Id: I1a77ee84448c328714101bc7a4cd76fd4b27d40a\nDepends-On: https://review.opendev.org/702764\n'}]",0,702765,c7564320c28f769bf7f9188b58ef1ec44e4042b4,11,3,2,7118,,,0,"Remove legacy-puppet-openstack-infra-spec-helper-unit-ubuntu-trusty

Job call removed in dependent change as part of Trusty removal

Change-Id: I1a77ee84448c328714101bc7a4cd76fd4b27d40a
Depends-On: https://review.opendev.org/702764
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/65/702765/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/zuul-legacy-jobs.yaml'],1,bbf996e2f47b5c1939f6f5948400b3fdcd6ef1dd,trusty-removal,, name: legacy-puppet-openstack-infra-spec-helper-unit-ubuntu-trusty parent: legacy-base run: playbooks/legacy/puppet-openstack-infra-spec-helper-unit-ubuntu-trusty/run.yaml timeout: 3600 nodeset: legacy-ubuntu-trusty required-projects: - opendev/puppet-openstackci - job:,0,9
openstack%2Fdevstack~master~I5477c8769ff4ae151d4d6ccb5e5d8dd5788909b0,openstack/devstack,master,I5477c8769ff4ae151d4d6ccb5e5d8dd5788909b0,"Run Glance initialization when Glance is enabled, not just registry",MERGED,2020-01-15 17:35:15.000000000,2020-01-16 07:27:59.000000000,2020-01-16 07:23:32.000000000,"[{'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-15 17:35:15.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a', 'message': 'Run Glance initialization when Glance is enabled, not just registry\n\nPer [1] Glance registry should not be required to run since Queens.\n\n[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html\n\nChange-Id: I5477c8769ff4ae151d4d6ccb5e5d8dd5788909b0\nCloses-bug: #1859847\n'}]",2,702707,d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a,11,4,1,30491,,,0,"Run Glance initialization when Glance is enabled, not just registry

Per [1] Glance registry should not be required to run since Queens.

[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html

Change-Id: I5477c8769ff4ae151d4d6ccb5e5d8dd5788909b0
Closes-bug: #1859847
",git fetch https://review.opendev.org/openstack/devstack refs/changes/07/702707/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,d8dec362baa2bf7f6ffe1c47352fdbe032eaf20a,bug/1859847,if is_glance_enabled; thenif is_glance_enabled; then,if is_service_enabled g-reg; thenif is_service_enabled g-reg; then,2,2
openstack%2Fnetworking-ovn~stable%2Fstein~I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c,openstack/networking-ovn,stable/stein,I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c,Set binding profile directly from OVNTrunkDriver (redo cont.),MERGED,2019-12-13 11:09:33.000000000,2020-01-16 07:18:21.000000000,2020-01-16 07:15:40.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-12-13 11:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4c53eabbb093b1d7df6ee8d39d01abf8943989e4', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 82efc6197a469e963d8a8105efbae0ff5a4dc82d)\n'}, {'number': 2, 'created': '2019-12-18 10:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/511bf23bdbd5e484ed7f8a4730a7fa1ea95346d3', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 82efc6197a469e963d8a8105efbae0ff5a4dc82d)\n'}, {'number': 3, 'created': '2019-12-18 10:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/456737584892ef603462869c39e01a7100b19d63', 'message': 'Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)\n'}, {'number': 4, 'created': '2020-01-14 18:26:02.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/ml2/trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e669382b251b5fec28dba8e40a03c7b8f23f51d3', 'message': ""Set binding profile directly from OVNTrunkDriver (redo cont.)\n\nThis is a tweak to changes done to fix bug 1834637. Specifically,\nthis change addresses scaling. The previous gerrit change had\nmodifications to all OVN sub-ports performed as a single\ntransaction. That did not account for race-condition on neutron\nDB queries, which leads to timeouts under heavy loads.\n\nAnother cleanup done by this change is to fold an additional\nupdate on neutron db into ovn trunk driver. That saves\nupdate from doing another database transaction, thus making\nit faster. The no longer needed function in mech_driver was\ncalled _update_subport_host_if_needed\n\nBy breaking the iteration into multiple transactions, the\nchange in time is marginal:\n\n  Service-level agreement\n  NeutronTrunks :: neutron.create_trunk\n\n  from 34.2 sec to 35.6 for 50%ile\n  from 35.6 sec to 36.1 for 95%ile\n\nThis patch doesn't go to master networking-ovn. It\nhas been  migrated to master Neutron [1].\n\n[1]: https://review.opendev.org/#/c/701646/\n\nChange-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c\nCloses-Bug: #1834637\nCo-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>\n(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)\n""}]",2,698873,e669382b251b5fec28dba8e40a03c7b8f23f51d3,29,6,4,11952,,,0,"Set binding profile directly from OVNTrunkDriver (redo cont.)

This is a tweak to changes done to fix bug 1834637. Specifically,
this change addresses scaling. The previous gerrit change had
modifications to all OVN sub-ports performed as a single
transaction. That did not account for race-condition on neutron
DB queries, which leads to timeouts under heavy loads.

Another cleanup done by this change is to fold an additional
update on neutron db into ovn trunk driver. That saves
update from doing another database transaction, thus making
it faster. The no longer needed function in mech_driver was
called _update_subport_host_if_needed

By breaking the iteration into multiple transactions, the
change in time is marginal:

  Service-level agreement
  NeutronTrunks :: neutron.create_trunk

  from 34.2 sec to 35.6 for 50%ile
  from 35.6 sec to 36.1 for 95%ile

This patch doesn't go to master networking-ovn. It
has been  migrated to master Neutron [1].

[1]: https://review.opendev.org/#/c/701646/

Change-Id: I7de3ac2a7cf8869ead8ab5fbb34a9861a96d3a0c
Closes-Bug: #1834637
Co-authored-by: Maciej Jzefczyk <mjozefcz@redhat.com>
(cherry picked from commit c418dd720b9be9047d779f32407c474e90cb0002)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/73/698873/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py', 'networking_ovn/ml2/trunk_driver.py']",4,4c53eabbb093b1d7df6ee8d39d01abf8943989e4,bug/1834637," for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: LOG.debug(""Setting parent %s for subport %s"", parent_port, subport.port_id) # NOTE(flaviof): We expect binding's host to be set. Otherwise, # sub-port will not transition from DOWN to ACTIVE. db_port.device_owner = trunk_consts.TRUNK_SUBPORT_OWNER for binding in db_port.bindings: binding.profile['parent_name'] = parent_port binding.profile['tag'] = subport.segmentation_id context, {'profile': binding.profile, 'vif_type': portbindings.VIF_TYPE_OVS}, db_port.update() LOG.debug(""Done setting parent %s for subport %s"", parent_port, subport.port_id) LOG.debug(""Unsetting parent for subport %s"", subport.port_id) db_port.device_owner = '' 'vif_type': portbindings.VIF_TYPE_UNBOUND}, db_port.update() LOG.debug(""Done unsetting parent for subport %s"", subport.port_id)"," with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: for binding in db_port.bindings: binding.profile.update({ 'parent_name': parent_port, 'tag': subport.segmentation_id}) context, {'profile': binding.profile}, 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'vif_details': '', 'host': ''},",41,60
openstack%2Fproject-config~master~Id35b717aa66f043ca78cbb83c235cf2fe13940e0,openstack/project-config,master,Id35b717aa66f043ca78cbb83c235cf2fe13940e0,Normalize projects.yaml,MERGED,2020-01-16 06:13:30.000000000,2020-01-16 07:15:50.000000000,2020-01-16 07:15:50.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 06:13:30.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/75d6fcf038980ab753510a15ac0bbf7e5b7c0081', 'message': 'Normalize projects.yaml\n\nChange-Id: Id35b717aa66f043ca78cbb83c235cf2fe13940e0\n'}]",0,702801,75d6fcf038980ab753510a15ac0bbf7e5b7c0081,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: Id35b717aa66f043ca78cbb83c235cf2fe13940e0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/702801/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,75d6fcf038980ab753510a15ac0bbf7e5b7c0081,project-yaml-normalization,, upstream: https://github.com/grnet/charm-watcher.git upstream: https://github.com/evrardjp/ideas.git,0,2
openstack%2Fopenstack-zuul-jobs~master~I21b3a4437432e88a189e5f34748207defdf2adb8,openstack/openstack-zuul-jobs,master,I21b3a4437432e88a189e5f34748207defdf2adb8,Removed OpenstackId Legacy Jobs,MERGED,2020-01-15 02:24:56.000000000,2020-01-16 05:59:24.000000000,2020-01-16 05:57:21.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 9139}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 02:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/1ce480c9454fd4b2eb8019d092e537c51c717a32', 'message': 'Removed OpenstackId Legacy Jobs\n\nDepends-On:  https://review.opendev.org/702572\nChange-Id: I21b3a4437432e88a189e5f34748207defdf2adb8\n'}, {'number': 2, 'created': '2020-01-15 02:35:28.000000000', 'files': ['playbooks/legacy/laravel-openstackid-release-master/run.yaml', 'playbooks/legacy/laravel-openstackid-unittests/post.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/laravel-openstackid-release-branch/post.yaml', 'playbooks/legacy/laravel-openstackid-unittests/run.yaml', 'playbooks/legacy/laravel-openstackid-release-master/post.yaml', 'playbooks/legacy/laravel-openstackid-release-branch/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/64de0027522b955b06140ebcfefe850781ae5505', 'message': 'Removed OpenstackId Legacy Jobs\n\nChange-Id: I21b3a4437432e88a189e5f34748207defdf2adb8\nDepends-On: https://review.opendev.org/702572\n'}]",0,702573,64de0027522b955b06140ebcfefe850781ae5505,15,5,2,9139,,,0,"Removed OpenstackId Legacy Jobs

Change-Id: I21b3a4437432e88a189e5f34748207defdf2adb8
Depends-On: https://review.opendev.org/702572
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/73/702573/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/laravel-openstackid-release-master/run.yaml', 'playbooks/legacy/laravel-openstackid-unittests/post.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/laravel-openstackid-release-branch/post.yaml', 'playbooks/legacy/laravel-openstackid-unittests/run.yaml', 'playbooks/legacy/laravel-openstackid-release-master/post.yaml', 'playbooks/legacy/laravel-openstackid-release-branch/run.yaml']",7,1ce480c9454fd4b2eb8019d092e537c51c717a32,hotfix/remove_openstackid_legacy_jobs,,"- hosts: all name: Autoconverted job legacy-laravel-openstackid-release-branch from old job laravel-openstackid-release-branch tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ https://opendev.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x sudo add-apt-repository ppa:ondrej/php sudo apt-get update executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - include_role: name: bindep - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x /usr/local/jenkins/slave_scripts/version-properties.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x source version.properties /usr/local/jenkins/slave_scripts/php-laravel-build.sh # Clone to dist rm -rf dist mkdir dist rsync -arv --exclude "".git*"" --exclude tarballs --exclude dist . dist # Clean/create a tarball directory rm -rf tarballs mkdir -p tarballs # Create an archive tarball. tar -czf $ZUUL_SHORT_PROJECT_NAME-$PROJECT_VER.tar.gz dist/ cp $ZUUL_SHORT_PROJECT_NAME-$PROJECT_VER.tar.gz tarballs/$ZUUL_SHORT_PROJECT_NAME-latest.tar.gz mv $ZUUL_SHORT_PROJECT_NAME-$PROJECT_VER.tar.gz tarballs/ executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,383
openstack%2Fproject-config~master~I00a6896708581ab9d15f10f41db4b8a988cc8d83,openstack/project-config,master,I00a6896708581ab9d15f10f41db4b8a988cc8d83,Remove infra trusty jobs,MERGED,2020-01-15 22:50:41.000000000,2020-01-16 05:56:25.000000000,2020-01-16 05:56:25.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 22:50:41.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f310e651db84801a7a804e883f65ce30409c8b0f', 'message': 'Remove infra trusty jobs\n\nRemove the Trusty based bindep and puppet jobs in preparation for node\nremoval.\n\nChange-Id: I00a6896708581ab9d15f10f41db4b8a988cc8d83\n'}]",0,702764,f310e651db84801a7a804e883f65ce30409c8b0f,7,3,1,7118,,,0,"Remove infra trusty jobs

Remove the Trusty based bindep and puppet jobs in preparation for node
removal.

Change-Id: I00a6896708581ab9d15f10f41db4b8a988cc8d83
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/702764/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",2,f310e651db84801a7a804e883f65ce30409c8b0f,trusty-removal,, name: project-config-bindep-fallback-ubuntu-trusty parent: project-config-bindep-fallback description: | Check installation of binary packages for file nodepool/elements/bindep-fallback.txt. The testing is done for Ubuntu Trusty. nodeset: ubuntu-trusty - job:,1,14
openstack%2Fproject-config~master~I86a922d59b396a059b255a4d87d8c033b79f7564,openstack/project-config,master,I86a922d59b396a059b255a4d87d8c033b79f7564,copy-wheels: disable PEP503 indexing,MERGED,2020-01-16 01:30:42.000000000,2020-01-16 05:54:36.000000000,2020-01-16 05:54:36.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 01:30:42.000000000', 'files': ['roles/copy-wheels/files/wheel-index.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fec3a46a01f3369a8388286d0c325d4427be7176', 'message': ""copy-wheels: disable PEP503 indexing\n\nCreating the index has turned out to be much more difficult than first\nexpected.  Checksumming the files on AFS to make the index.html takes\ntoo long and times out the jobs.\n\nWe've identified other issues such as the jobs only ever appending\nwheels, making far more data than probably necessary being kept, and\nthe possibility of skipping those wheels already available on PyPi.\n\nDisable this while we reconsider the approach.\n\nChange-Id: I86a922d59b396a059b255a4d87d8c033b79f7564\n""}]",0,702780,fec3a46a01f3369a8388286d0c325d4427be7176,7,3,1,7118,,,0,"copy-wheels: disable PEP503 indexing

Creating the index has turned out to be much more difficult than first
expected.  Checksumming the files on AFS to make the index.html takes
too long and times out the jobs.

We've identified other issues such as the jobs only ever appending
wheels, making far more data than probably necessary being kept, and
the possibility of skipping those wheels already available on PyPi.

Disable this while we reconsider the approach.

Change-Id: I86a922d59b396a059b255a4d87d8c033b79f7564
",git fetch https://review.opendev.org/openstack/project-config refs/changes/80/702780/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/copy-wheels/files/wheel-index.sh'],1,fec3a46a01f3369a8388286d0c325d4427be7176,pep503-indexes," # Create PEP503 style index for this directory # NOTE(ianw) : 2020-01 - this is disabled because it makes the # job very, very slow as it checksums all the files over AFS. # We are currently investigating solutions to this problem. # /usr/local/bin/wheel-indexer.py --debug --output ""index.html"" $f"," # Run the indexer over this directory # NOTE(ianw) : remove temporary ""--output"" when working /usr/local/bin/wheel-indexer.py --debug --output ""index.html.tmp"" $f ",5,4
openstack%2Fmistral~master~If18cd11db29a45f64666172674e1eb55b0a51d73,openstack/mistral,master,If18cd11db29a45f64666172674e1eb55b0a51d73,Fix requirements remove py2,MERGED,2020-01-15 14:17:48.000000000,2020-01-16 05:35:18.000000000,2020-01-16 05:34:00.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}, {'_account_id': 30755}]","[{'number': 1, 'created': '2020-01-15 14:17:48.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/mistral/commit/55f181f8aaf8cdc7d519c1e446d0053cd73368a6', 'message': 'Fix requirements remove py2\n\nChange-Id: If18cd11db29a45f64666172674e1eb55b0a51d73\n'}]",0,702669,55f181f8aaf8cdc7d519c1e446d0053cd73368a6,8,3,1,19134,,,0,"Fix requirements remove py2

Change-Id: If18cd11db29a45f64666172674e1eb55b0a51d73
",git fetch https://review.opendev.org/openstack/mistral refs/changes/69/702669/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,55f181f8aaf8cdc7d519c1e446d0053cd73368a6,doc,,"sphinx>=1.8.0,<2.0.0;python_version=='2.7' # BSD",0,1
openstack%2Ffreezer-tempest-plugin~master~I5621b549fd0c2d7c392a37e45c3404e8adf937a3,openstack/freezer-tempest-plugin,master,I5621b549fd0c2d7c392a37e45c3404e8adf937a3,fix python3 compility issue,MERGED,2020-01-16 02:49:00.000000000,2020-01-16 05:34:09.000000000,2020-01-16 05:34:09.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 02:49:00.000000000', 'files': ['freezer_tempest_plugin/tests/freezer/agent/test_backup_compress.py'], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/f391fe3c09e78ef478ad71056825350bc1ebd977', 'message': 'fix python3 compility issue\n\nChange-Id: I5621b549fd0c2d7c392a37e45c3404e8adf937a3\n'}]",0,702784,f391fe3c09e78ef478ad71056825350bc1ebd977,6,2,1,21069,,,0,"fix python3 compility issue

Change-Id: I5621b549fd0c2d7c392a37e45c3404e8adf937a3
",git fetch https://review.opendev.org/openstack/freezer-tempest-plugin refs/changes/84/702784/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer_tempest_plugin/tests/freezer/agent/test_backup_compress.py'],1,f391fe3c09e78ef478ad71056825350bc1ebd977,," gizp_mimetypes = [b'application/gzip', b'application/x-gzip', 'application/gzip', 'application/x-gzip'] # self.assertEqual(b'application/x-bzip2', mimetype) self.assertIn(mimetype, [b'application/x-bzip2', 'application/x-bzip2']) # self.assertEqual(b'application/x-xz', mimetype) self.assertIn(mimetype, [b'application/x-xz', 'application/x-xz'])"," gizp_mimetypes = [b'application/gzip', b'application/x-gzip'] self.assertEqual(b'application/x-bzip2', mimetype) self.assertEqual(b'application/x-xz', mimetype)",7,3
openstack%2Fproject-config~master~Id34e308509980685ed156fc68fb65975dbd0b780,openstack/project-config,master,Id34e308509980685ed156fc68fb65975dbd0b780,Removed OpenstackId legacy jobs,MERGED,2020-01-15 02:23:58.000000000,2020-01-16 04:44:34.000000000,2020-01-16 04:44:34.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 9139}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 02:23:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8923e244036dde239887eb96f1afba1051b08736', 'message': 'Removed OpenstackId legacy jobs\n\nremoved legacy jobs for openstackid project and pointed\nto new migrated zuul v3 jobs\n\nDepends-On: https://review.opendev.org/702571\nChange-Id: Id34e308509980685ed156fc68fb65975dbd0b780\n'}, {'number': 2, 'created': '2020-01-15 02:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ff3c2157431e43bcf75815144debafbbcce9761b', 'message': 'Removed OpenstackId legacy jobs\n\nremoved legacy jobs for openstackid project and pointed\nto new migrated zuul v3 jobs\n\nDepends-On: https://review.opendev.org/702571\nNeeded-By: https://review.opendev.org/702573\nChange-Id: Id34e308509980685ed156fc68fb65975dbd0b780\n'}, {'number': 3, 'created': '2020-01-15 02:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f959cf4f075d54a28ee9118ef31b9879145d4f67', 'message': 'Removed OpenstackId legacy jobs\n\nremoved legacy jobs for openstackid project and pointed\nto new migrated zuul v3 jobs\n\nChange-Id: Id34e308509980685ed156fc68fb65975dbd0b780\nDepends-On: https://review.opendev.org/702571\nNeeded-By: https://review.opendev.org/702573\n'}, {'number': 4, 'created': '2020-01-15 16:38:18.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3d8c3354749e6f36951b3b38b3c65eebb0b3ca4a', 'message': 'Removed OpenstackId legacy jobs\n\nremoved legacy jobs for openstackid project and pointed\nto new migrated zuul v3 jobs\n\nChange-Id: Id34e308509980685ed156fc68fb65975dbd0b780\nDepends-On: https://review.opendev.org/702571\nNeeded-By: https://review.opendev.org/702573\n'}]",2,702572,3d8c3354749e6f36951b3b38b3c65eebb0b3ca4a,16,6,4,9139,,,0,"Removed OpenstackId legacy jobs

removed legacy jobs for openstackid project and pointed
to new migrated zuul v3 jobs

Change-Id: Id34e308509980685ed156fc68fb65975dbd0b780
Depends-On: https://review.opendev.org/702571
Needed-By: https://review.opendev.org/702573
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/702572/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,8923e244036dde239887eb96f1afba1051b08736,hotfix/remove_openstackid_legacy_jobs, - openstackid-unittests - openstackid-unittests - openstackid-release-branch - openstackid-release-master, - legacy-laravel-openstackid-unittests - legacy-laravel-openstackid-unittests - legacy-laravel-openstackid-release-branch - legacy-laravel-openstackid-release-master,4,4
openstack%2Fbifrost~master~Id66444aa9757f38d40e3da36e4f27f80a707cf95,openstack/bifrost,master,Id66444aa9757f38d40e3da36e4f27f80a707cf95,Fix deprecation warning message from Ansible,MERGED,2020-01-15 15:28:08.000000000,2020-01-16 04:41:09.000000000,2020-01-16 04:39:51.000000000,"[{'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 15:28:08.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/download_ipa_image.yml', 'playbooks/roles/bifrost-ironic-install/tasks/get_ipxe.yml', 'playbooks/roles/bifrost-keystone-install/tasks/pip_install.yml', 'playbooks/roles/bifrost-ironic-install/tasks/pip_install.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/baf8e9b64da790305f34edd86986069481865491', 'message': 'Fix deprecation warning message from Ansible\n\nUsing tests as filters is deprecated. Instead of using\n`result|succeeded` we should use `result is succeeded`.\nThis feature will be removed in Ansible version 2.9.\n\nChange-Id: Id66444aa9757f38d40e3da36e4f27f80a707cf95\n'}]",0,702683,baf8e9b64da790305f34edd86986069481865491,8,3,1,23851,,,0,"Fix deprecation warning message from Ansible

Using tests as filters is deprecated. Instead of using
`result|succeeded` we should use `result is succeeded`.
This feature will be removed in Ansible version 2.9.

Change-Id: Id66444aa9757f38d40e3da36e4f27f80a707cf95
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/83/702683/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/tasks/download_ipa_image.yml', 'playbooks/roles/bifrost-ironic-install/tasks/get_ipxe.yml', 'playbooks/roles/bifrost-keystone-install/tasks/pip_install.yml', 'playbooks/roles/bifrost-ironic-install/tasks/pip_install.yml']",4,baf8e9b64da790305f34edd86986069481865491,fix-depr-msg, until: pip_package_install_done is succeeded until: pip_package_install_done is succeeded until: pip_package_install_done is succeeded, until: pip_package_install_done|succeeded until: pip_package_install_done|succeeded until: pip_package_install_done|succeeded,10,10
openstack%2Fpython-tripleoclient~master~I0ceb90abfd6fcfbb3cbff439f8c348da2a7bfe2f,openstack/python-tripleoclient,master,I0ceb90abfd6fcfbb3cbff439f8c348da2a7bfe2f,Inject ansible-runner logs in the install-undercloud.log file,MERGED,2020-01-13 12:34:10.000000000,2020-01-16 04:33:22.000000000,2020-01-15 16:50:23.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-13 12:34:10.000000000', 'files': ['tripleoclient/v1/tripleo_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/585e41d6b3191accd704f3c750ddf0dca81641e3', 'message': 'Inject ansible-runner logs in the install-undercloud.log file\n\nThe move to ansible-runner lib created a regression where ansible runs\nwere logged in a separated file (ansible.log) instead of being appended\nto the install-undercloud.log.\n\nChange-Id: I0ceb90abfd6fcfbb3cbff439f8c348da2a7bfe2f\nCloses-Bug: #1859183\n'}]",4,702212,585e41d6b3191accd704f3c750ddf0dca81641e3,14,9,1,28223,,,0,"Inject ansible-runner logs in the install-undercloud.log file

The move to ansible-runner lib created a regression where ansible runs
were logged in a separated file (ansible.log) instead of being appended
to the install-undercloud.log.

Change-Id: I0ceb90abfd6fcfbb3cbff439f8c348da2a7bfe2f
Closes-Bug: #1859183
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/12/702212/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/tripleo_deploy.py'],1,585e41d6b3191accd704f3c750ddf0dca81641e3,undercloud-logging," extra_env_var = dict() else: extra_env_var['ANSIBLE_LOG_PATH'] = os.path.join( parsed_args.output_dir, constants.UNDERCLOUD_LOG_FILE) extra_env_variables=extra_env_var,",,5,0
openstack%2Fzun~master~Ibf3f801596c3a768b05fca9ccbef555ddba319af,openstack/zun,master,Ibf3f801596c3a768b05fca9ccbef555ddba319af,Add 'annotations' to capsule API,MERGED,2019-12-21 20:44:30.000000000,2020-01-16 04:31:19.000000000,2020-01-16 04:26:43.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2019-12-21 20:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/4ecb0f52b9f430c7c933f46ca9f2be070e8621b2', 'message': ""[WIP] Add 'annotations' to capsule API\n\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}, {'number': 2, 'created': '2019-12-21 21:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/9cb6e92870c66d87bcaf43cbe43811e6e5f8f669', 'message': ""Add 'annotations' to capsule API\n\nImplements: blueprint add-annotations-to-capsule\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}, {'number': 3, 'created': '2019-12-21 23:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/1042cebaae805c1789699d38d481c3018ca8542e', 'message': ""Add 'annotations' to capsule API\n\nImplements: blueprint add-annotations-to-capsule\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}, {'number': 4, 'created': '2019-12-22 01:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/ff5f1bf183684fd2765a6e0de2bc24df09b45d28', 'message': ""Add 'annotations' to capsule API\n\nImplements: blueprint add-annotations-to-capsule\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}, {'number': 5, 'created': '2019-12-30 17:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/d6635fb869ee95ec1b88ea2339d2fc92171b3be1', 'message': ""Add 'annotations' to capsule API\n\nImplements: blueprint add-annotations-to-capsule\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}, {'number': 6, 'created': '2020-01-06 04:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/baf8781783e6c10bda82cc0a7684ba24939a9f33', 'message': ""Add 'annotations' to capsule API\n\nImplements: blueprint add-annotations-to-capsule\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}, {'number': 7, 'created': '2020-01-12 16:47:31.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/samples/capsule-show-resp.json', 'api-ref/source/samples/capsule-create-req.json', 'api-ref/source/samples/capsule-create-resp.json', '.zuul.yaml', 'zun/api/controllers/v1/schemas/parameter_types.py', 'api-ref/source/capsules.inc', 'zun/api/controllers/v1/views/capsules_view.py', 'zun/api/rest_api_version_history.rst', 'zun/tests/unit/api/base.py', 'api-ref/source/samples/capsule-get-all-resp.json', 'zun/api/controllers/v1/capsules.py', 'zun/tests/unit/api/controllers/test_root.py', 'zun/api/controllers/versions.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/0492c35723925be603b6d218aca4114d0c4ef46f', 'message': ""Add 'annotations' to capsule API\n\nImplements: blueprint add-annotations-to-capsule\nChange-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af\n""}]",0,700284,0492c35723925be603b6d218aca4114d0c4ef46f,26,3,7,11536,,,0,"Add 'annotations' to capsule API

Implements: blueprint add-annotations-to-capsule
Change-Id: Ibf3f801596c3a768b05fca9ccbef555ddba319af
",git fetch https://review.opendev.org/openstack/zun refs/changes/84/700284/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/api/controllers/v1/capsules.py', 'zun/api/controllers/v1/schemas/parameter_types.py', 'zun/objects/container.py', 'zun/api/controllers/v1/views/capsules_view.py']",4,4ecb0f52b9f430c7c933f46ca9f2be070e8621b2,bp/add-annotations-to-capsule," 'annotations',",,11,2
openstack%2Fswift~master~I98ebe15353d675ca00fee387003bf6572ac385e6,openstack/swift,master,I98ebe15353d675ca00fee387003bf6572ac385e6,Clean up container-sync docs,MERGED,2020-01-16 02:32:40.000000000,2020-01-16 04:17:47.000000000,2020-01-16 04:16:19.000000000,"[{'_account_id': 1179}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-16 02:32:40.000000000', 'files': ['doc/source/overview_container_sync.rst', 'doc/source/development_saio.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/0901464513bc371e5fff2c52004de364d56c271f', 'message': 'Clean up container-sync docs\n\nChange-Id: I98ebe15353d675ca00fee387003bf6572ac385e6\n'}]",0,702782,0901464513bc371e5fff2c52004de364d56c271f,7,2,1,15343,,,0,"Clean up container-sync docs

Change-Id: I98ebe15353d675ca00fee387003bf6572ac385e6
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/702782/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/overview_container_sync.rst', 'doc/source/development_saio.rst']",2,0901464513bc371e5fff2c52004de364d56c271f,,.. _saio: SAIO (Swift All In One),SAIO - Swift All In One,72,53
openstack%2Fproject-config~master~I8b61bdaf9a6f253dfa13fb7dd1689440a79f517a,openstack/project-config,master,I8b61bdaf9a6f253dfa13fb7dd1689440a79f517a,Update compute-hyperv test jobs,MERGED,2020-01-15 14:40:09.000000000,2020-01-16 04:05:32.000000000,2020-01-16 04:05:32.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 14:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/689881bf5a5b616e1bb56321492be634cb0e8bcc', 'message': 'Update compute-hyperv test jobs\n\nWe\'re dropping Python 2.7 support, so the ""openstack-python-jobs""\ntemplate should also be dropped. We\'ll do the same for the Py3.5\ntemplate and define it within the project.\n\nChange-Id: I8b61bdaf9a6f253dfa13fb7dd1689440a79f517a\n'}, {'number': 2, 'created': '2020-01-15 14:57:49.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8fd8e90edf5e5447c4145d504f49aeb819a0adfe', 'message': 'Update compute-hyperv test jobs\n\nWe\'re dropping Python 2.7 support, so the ""openstack-python-jobs""\ntemplate should also be removed.\n\nWhile at it, we\'ll move all templates within the project, except for\n""publish-to-pypi"", which is expected to stay here.\n\nChange-Id: I8b61bdaf9a6f253dfa13fb7dd1689440a79f517a\n'}]",1,702673,8fd8e90edf5e5447c4145d504f49aeb819a0adfe,10,3,2,8543,,,0,"Update compute-hyperv test jobs

We're dropping Python 2.7 support, so the ""openstack-python-jobs""
template should also be removed.

While at it, we'll move all templates within the project, except for
""publish-to-pypi"", which is expected to stay here.

Change-Id: I8b61bdaf9a6f253dfa13fb7dd1689440a79f517a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/73/702673/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,689881bf5a5b616e1bb56321492be634cb0e8bcc,,, - openstack-python-jobs - openstack-python35-jobs,0,2
openstack%2Fproject-config~master~I84635af9dbb1bbb9a0766a31df587418f3a81411,openstack/project-config,master,I84635af9dbb1bbb9a0766a31df587418f3a81411,Retire x/zmq-event-publisher,MERGED,2020-01-15 20:38:41.000000000,2020-01-16 04:04:23.000000000,2020-01-16 04:04:23.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 20:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d7190d92b60f15ca6478d5ca743c36287abba0ab', 'message': 'Retire x/zmq-event-publisher\n\nFinish retiring repository and remove it from OpenDev infrastructure.\n\nChange-Id: I84635af9dbb1bbb9a0766a31df587418f3a81411\nDeepends-On: https://review.opendev.org/702748\n'}, {'number': 2, 'created': '2020-01-15 20:42:09.000000000', 'files': ['gerritbot/channels.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml', 'gerrit/acls/x/zmq-event-publisher.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9c94d17428a46c50e707807f8477ca00beba0943', 'message': 'Retire x/zmq-event-publisher\n\nFinish retiring repository and remove it from OpenDev infrastructure.\n\nAnnouncement:\nhttp://lists.openstack.org/pipermail/openstack-discuss/2020-January/012016.html\n\nChange-Id: I84635af9dbb1bbb9a0766a31df587418f3a81411\nDeepends-On: https://review.opendev.org/702748\n'}]",0,702749,9c94d17428a46c50e707807f8477ca00beba0943,10,4,2,6547,,,0,"Retire x/zmq-event-publisher

Finish retiring repository and remove it from OpenDev infrastructure.

Announcement:
http://lists.openstack.org/pipermail/openstack-discuss/2020-January/012016.html

Change-Id: I84635af9dbb1bbb9a0766a31df587418f3a81411
Deepends-On: https://review.opendev.org/702748
",git fetch https://review.opendev.org/openstack/project-config refs/changes/49/702749/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml', 'gerrit/acls/x/zmq-event-publisher.config']",5,d7190d92b60f15ca6478d5ca743c36287abba0ab,zmq-event,,"[access ""refs/heads/*""] abandon = group zmq-event-publisher-core label-Code-Review = -2..+2 group zmq-event-publisher-core label-Workflow = -1..+1 group zmq-event-publisher-core [access ""refs/tags/*""] pushSignedTag = group zmq-event-publisher-release [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = true ",2,27
openstack%2Fdesignate~master~I0c50aaadaabb6e0f054121d8270fcb8e05b6e762,openstack/designate,master,I0c50aaadaabb6e0f054121d8270fcb8e05b6e762,Simplified network api implementation,MERGED,2019-09-22 07:36:13.000000000,2020-01-16 03:44:13.000000000,2020-01-16 03:42:59.000000000,"[{'_account_id': 13252}, {'_account_id': 15736}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-09-22 07:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b2cc7ca0c7b3ae008e217cc864afabb651d20601', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 2, 'created': '2019-09-22 19:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5307b2512083795690e9895f518c37b01b16b69e', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 3, 'created': '2019-09-22 20:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/57d0886385feaa7fb7236e787aaeabd0204b0373', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 4, 'created': '2019-09-22 20:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c66b594a191a1c540b19f4028e3eebee25b6aca8', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 5, 'created': '2019-09-22 20:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e372e14645fd3c592b3da93e27771fca35f4a130', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 6, 'created': '2019-09-22 20:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/e5f85b4d2bb61b35607168cb9e2d405586cb86eb', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 7, 'created': '2019-09-27 16:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/9d684798162690ed9edf6cb09f81e1c5a5ce65cc', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 8, 'created': '2019-10-18 22:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/a8740a7dcecbc99ee7d79f9eed2d613622d3dcac', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 9, 'created': '2019-10-23 18:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c8f8896ab74a21536297a1e454e36c9720d02c24', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 10, 'created': '2019-11-15 06:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f23f00df04846061d87a4867f2c7cc96aea0896c', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 11, 'created': '2019-11-24 08:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b1898bbfd4ca00ed3d41441da24952eda5756337', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 12, 'created': '2019-11-27 19:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d4f1d6cda22ef30a1acef171704d0416fa7b01fb', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 13, 'created': '2019-12-16 18:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/94b597d2da7bb82cb39348d111ed7f32ee1ec21d', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}, {'number': 14, 'created': '2019-12-18 23:09:12.000000000', 'files': ['designate/network_api/neutron.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/ac53cd4df00acde0615f25fd0a990d2eb994a213', 'message': 'Simplified network api implementation\n\nReduced the complexity of the neutron code\nfor looking up ptr records.\n\n* Limit max concurrency to 5.\n* Better error handling.\n\nChange-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762\n'}]",0,683808,ac53cd4df00acde0615f25fd0a990d2eb994a213,35,5,14,22623,,,0,"Simplified network api implementation

Reduced the complexity of the neutron code
for looking up ptr records.

* Limit max concurrency to 5.
* Better error handling.

Change-Id: I0c50aaadaabb6e0f054121d8270fcb8e05b6e762
",git fetch https://review.opendev.org/openstack/designate refs/changes/08/683808/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/network_api/neutron.py'],1,b2cc7ca0c7b3ae008e217cc864afabb651d20601,simplified_neutron_api,"from neutronclient.v2_0 import client as clientv20 region=region ) floating_ips = [] for endpoint, region in endpoints: floating_ips.extend( self._get_floating_ips(context, endpoint, region, project_id=context.project_id) ) return floating_ips @staticmethod def _get_floating_ips(context, endpoint, region, project_id): client = get_client(context, endpoint=endpoint) try: fips = client.list_floatingips(project_id=project_id) for fip in fips['floatingips']: yield { } except neutron_exceptions.Unauthorized as e: # NOTE: 401 might be that the user doesn't have neutron # activated in a particular region, we'll just log the failure # and go on with our lives. LOG.warning(""Calling Neutron resulted in a 401, "" ""please investigate."") LOG.exception(e) except Exception as e: raise exceptions.NeutronCommunicationFailure(e) return","from neutronclient.v2_0 import client as clientv20from oslo_service import threadgroup region=region) tg = threadgroup.ThreadGroup() failed = [] data = [] def _call(endpoint, region, *args, **kw): client = get_client(context, endpoint=endpoint) LOG.debug(""Attempting to fetch FloatingIPs from %s @ %s"", endpoint, region) try: fips = client.list_floatingips(*args, **kw) except neutron_exceptions.Unauthorized as e: # NOTE: 401 might be that the user doesn't have neutron # activated in a particular region, we'll just log the failure # and go on with our lives. LOG.warning(""Calling Neutron resulted in a 401, "" ""please investigate."") LOG.exception(e) return except Exception as e: LOG.error('Failed calling Neutron %(region)s - %(endpoint)s', {'region': region, 'endpoint': endpoint}) LOG.exception(e) failed.append((e, endpoint, region)) return for fip in fips['floatingips']: data.append({ }) LOG.debug(""Added %i FloatingIPs from %s @ %s"", len(data), endpoint, region) for endpoint, region in endpoints: tg.add_thread(_call, endpoint, region, project_id=context.project_id) tg.wait() # NOTE: Sadly tg code doesn't give us a good way to handle failures. if failed: msg = 'Failed retrieving FloatingIPs from Neutron in %s' % \ "", "".join(['%s - %s' % (i[1], i[2]) for i in failed]) raise exceptions.NeutronCommunicationFailure(msg) return data",27,45
openstack%2Ffreezer~master~I975ed171d2b108ad3df7e85bafbe5e971eaf209f,openstack/freezer,master,I975ed171d2b108ad3df7e85bafbe5e971eaf209f,[Trivial]Fix typo of instnace,MERGED,2020-01-03 02:08:08.000000000,2020-01-16 03:43:10.000000000,2020-01-16 03:41:44.000000000,"[{'_account_id': 20190}, {'_account_id': 21387}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-03 02:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/8c7a4b7ca1cdfc222994921feeae7ac9c8e70244', 'message': '[Trivial]Fix typo of instnace\n\nThis is to fix the typo of instnace, which should be instance.\n\nChange-Id: I975ed171d2b108ad3df7e85bafbe5e971eaf209f\n'}, {'number': 2, 'created': '2020-01-16 02:23:51.000000000', 'files': ['freezer/engine/nova/nova.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/c1231d0ebb7909c9b101ec68dcf2bce8c3b7793f', 'message': '[Trivial]Fix typo of instnace\n\nThis is to fix the typo of instnace, which should be instance.\n\nChange-Id: I975ed171d2b108ad3df7e85bafbe5e971eaf209f\n'}]",0,700975,c1231d0ebb7909c9b101ec68dcf2bce8c3b7793f,17,3,2,20190,,,0,"[Trivial]Fix typo of instnace

This is to fix the typo of instnace, which should be instance.

Change-Id: I975ed171d2b108ad3df7e85bafbe5e971eaf209f
",git fetch https://review.opendev.org/openstack/freezer refs/changes/75/700975/1 && git format-patch -1 --stdout FETCH_HEAD,['freezer/engine/nova/nova.py'],1,8c7a4b7ca1cdfc222994921feeae7ac9c8e70244,instnace," message=""Waiting for instance {0} snapshot to become """," message=""Waiting for instnace {0} snapshot to become """,1,1
openstack%2Fneutron~master~I1ddee94bd34182960de8e5261fbc99edc10b6654,openstack/neutron,master,I1ddee94bd34182960de8e5261fbc99edc10b6654,IPv6 accepts first address only for routers,MERGED,2020-01-10 14:03:52.000000000,2020-01-16 03:23:59.000000000,2020-01-16 03:22:14.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2020-01-10 14:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd74b612ef1581ef61c7b501a08ed048447251d5', 'message': 'Interface owner is not relevant to validate an IP address\n\nNeutron accepts first address in an IPv6 subnet as valid unicast\n[1][2]. The interface owner is not relevant anymore to validate\nan IPv6 address in a subnet.\n\n[1] https://tools.ietf.org/html/rfc4291#section-2.6.1\n[2] https://review.opendev.org/#/c/647484/\n\nChange-Id: I1ddee94bd34182960de8e5261fbc99edc10b6654\nCloses-Bug: #1859163\n'}, {'number': 2, 'created': '2020-01-10 14:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a1e234f3f68faa7364c72dcaef2450012651358f', 'message': 'IPv6 accepts first address only for routers\n\nNeutron considers the network address a valid IPv6 address if the\nowner is a router or is not defined yet [1][2]. If not, the IPv6\naddress is discharded.\n\n[1] https://tools.ietf.org/html/rfc4291#section-2.6.1\n[2] https://review.opendev.org/#/c/647484/\n\nChange-Id: I1ddee94bd34182960de8e5261fbc99edc10b6654\nCloses-Bug: #1859163\n'}, {'number': 3, 'created': '2020-01-12 18:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b0467373d3c52919b51a0dfda88507bcca8f23a', 'message': 'IPv6 accepts first address only for routers\n\nNeutron considers the network address a valid IPv6 address if the\nowner is a router or is not defined yet [1][2]. If not, the IPv6\naddress is discharded.\n\n[1] https://tools.ietf.org/html/rfc4291#section-2.6.1\n[2] https://review.opendev.org/#/c/647484/\n\nChange-Id: I1ddee94bd34182960de8e5261fbc99edc10b6654\nCloses-Bug: #1859163\n'}, {'number': 4, 'created': '2020-01-12 20:39:07.000000000', 'files': ['neutron/ipam/utils.py', 'neutron/tests/unit/ipam/test_utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b20669fa6ec88445ccf4b3fa8cb38aa05b5b3efb', 'message': 'IPv6 accepts first address only for routers\n\nNeutron considers the network address a valid IPv6 address if the\nowner is a router or is not defined yet [1][2]. If not, the IPv6\naddress is discharded.\n\n[1] https://tools.ietf.org/html/rfc4291#section-2.6.1\n[2] https://review.opendev.org/#/c/647484/\n\nChange-Id: I1ddee94bd34182960de8e5261fbc99edc10b6654\nCloses-Bug: #1859163\n'}]",0,701965,b20669fa6ec88445ccf4b3fa8cb38aa05b5b3efb,45,10,4,16688,,,0,"IPv6 accepts first address only for routers

Neutron considers the network address a valid IPv6 address if the
owner is a router or is not defined yet [1][2]. If not, the IPv6
address is discharded.

[1] https://tools.ietf.org/html/rfc4291#section-2.6.1
[2] https://review.opendev.org/#/c/647484/

Change-Id: I1ddee94bd34182960de8e5261fbc99edc10b6654
Closes-Bug: #1859163
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/701965/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/ipam_backend_mixin.py', 'neutron/ipam/utils.py']",2,fd74b612ef1581ef61c7b501a08ed048447251d5,bug/1859163,"def check_subnet_ip(cidr, ip_address): return ip in net","def check_subnet_ip(cidr, ip_address, port_owner=''): # NOTE(njohnston): In some cases the code cannot know the owner of the # port. In these cases port_owner should an empty string, and we pass # it through here. return (port_owner in (constants.ROUTER_PORT_OWNERS + ('', )) and ip in net)",4,10
openstack%2Frequirements~stable%2Ftrain~I22e1dc81cb286234db6edf7f8b7d1fd122ab5694,openstack/requirements,stable/train,I22e1dc81cb286234db6edf7f8b7d1fd122ab5694,update constraint for python-magnumclient to new release 2.16.0,MERGED,2020-01-15 13:37:01.000000000,2020-01-16 03:22:17.000000000,2020-01-16 03:22:17.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 13:37:01.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c1edaef87c0b930a7f17b8d30a1e5917cd8db679', 'message': 'update constraint for python-magnumclient to new release 2.16.0\n\nChange-Id: I22e1dc81cb286234db6edf7f8b7d1fd122ab5694\nmeta:version: 2.16.0\nmeta:diff-start: -\nmeta:series: train\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Spyros Trigazis <spyridon.trigazis@cern.ch>\nmeta:release:Commit: Spyros Trigazis <spyridon.trigazis@cern.ch>\nmeta:release:Change-Id: I773387b1802dc7b6243530048e23eff352acb92f\nmeta:release:Code-Review+2: Jean-Philippe Evrard <jean-philippe@evrard.me>\nmeta:release:Workflow+1: Jean-Philippe Evrard <jean-philippe@evrard.me>\n'}]",0,702665,c1edaef87c0b930a7f17b8d30a1e5917cd8db679,7,3,1,11131,,,0,"update constraint for python-magnumclient to new release 2.16.0

Change-Id: I22e1dc81cb286234db6edf7f8b7d1fd122ab5694
meta:version: 2.16.0
meta:diff-start: -
meta:series: train
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Spyros Trigazis <spyridon.trigazis@cern.ch>
meta:release:Commit: Spyros Trigazis <spyridon.trigazis@cern.ch>
meta:release:Change-Id: I773387b1802dc7b6243530048e23eff352acb92f
meta:release:Code-Review+2: Jean-Philippe Evrard <jean-philippe@evrard.me>
meta:release:Workflow+1: Jean-Philippe Evrard <jean-philippe@evrard.me>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/702665/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,c1edaef87c0b930a7f17b8d30a1e5917cd8db679,new-release,python-magnumclient===2.16.0,python-magnumclient===2.15.0,1,1
openstack%2Fcinder~master~I80b4e1378198c93fd390a2b240d5c70a17d7b600,openstack/cinder,master,I80b4e1378198c93fd390a2b240d5c70a17d7b600,Doc: update storwize cinder driver configuration guide,MERGED,2019-12-23 09:01:12.000000000,2020-01-16 03:02:48.000000000,2020-01-16 02:24:50.000000000,"[{'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30428}]","[{'number': 1, 'created': '2019-12-23 09:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b46f4864bb040d909599cef398101d7aebcc569', 'message': 'doc: update storwize cinder driver configuration guide\n\nThere is something wrong in storwize cinder driver configuration guide.\nThis patch deletes 1 unsupported volume type configuration and adds 2\nsupported volume type configurations.\n\nChange-Id: I80b4e1378198c93fd390a2b240d5c70a17d7b600\nCloses-Bugs: #1857327\n'}, {'number': 2, 'created': '2019-12-24 06:25:01.000000000', 'files': ['doc/source/configuration/block-storage/drivers/ibm-storwize-svc-driver.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/371feff100990441bfa0dcf05cc23f4ffbe61ec7', 'message': 'Doc: update storwize cinder driver configuration guide\n\nThere is something wrong in storwize cinder driver configuration guide.\nThis patch remove 1 unsupported volume type configuration and adds 2\nsupported volume type configurations.\n\nChange-Id: I80b4e1378198c93fd390a2b240d5c70a17d7b600\nCloses-Bugs: #1857327\n'}]",2,700396,371feff100990441bfa0dcf05cc23f4ffbe61ec7,48,23,2,30428,,,0,"Doc: update storwize cinder driver configuration guide

There is something wrong in storwize cinder driver configuration guide.
This patch remove 1 unsupported volume type configuration and adds 2
supported volume type configurations.

Change-Id: I80b4e1378198c93fd390a2b240d5c70a17d7b600
Closes-Bugs: #1857327
",git fetch https://review.opendev.org/openstack/cinder refs/changes/96/700396/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/block-storage/drivers/ibm-storwize-svc-driver.rst'],1,1b46f4864bb040d909599cef398101d7aebcc569,bug/1857327,- flashcopy_rate - cycle_period_seconds,- host_site,2,1
openstack%2Fdevstack-plugin-container~stable%2Ftrain~I6e6fee297b0579d385ca7130f0db0f9e3b2a5df8,openstack/devstack-plugin-container,stable/train,I6e6fee297b0579d385ca7130f0db0f9e3b2a5df8,Update .gitreview for stable/train,MERGED,2019-10-24 14:47:20.000000000,2020-01-16 02:43:23.000000000,2020-01-16 02:43:23.000000000,"[{'_account_id': 11536}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-24 14:47:20.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-container/commit/4b70b7584e12b2b09f34b62fda5e1b5e9075348b', 'message': 'Update .gitreview for stable/train\n\nChange-Id: I6e6fee297b0579d385ca7130f0db0f9e3b2a5df8\n'}]",0,690990,4b70b7584e12b2b09f34b62fda5e1b5e9075348b,6,2,1,22816,,,0,"Update .gitreview for stable/train

Change-Id: I6e6fee297b0579d385ca7130f0db0f9e3b2a5df8
",git fetch https://review.opendev.org/openstack/devstack-plugin-container refs/changes/90/690990/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,4b70b7584e12b2b09f34b62fda5e1b5e9075348b,create-train,defaultbranch=stable/train,,1,0
openstack%2Fansible-role-collect-logs~master~I50b78a169a9b5a9969f59d83567ceeed73fbc842,openstack/ansible-role-collect-logs,master,I50b78a169a9b5a9969f59d83567ceeed73fbc842,Fix molecule report,MERGED,2020-01-15 19:25:33.000000000,2020-01-16 02:30:53.000000000,2020-01-16 02:30:53.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-15 19:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/2ab8a591d867e17bbed9a272a62daa44fdfe4e91', 'message': 'WIP: Fix molecule report\n\nChange-Id: I50b78a169a9b5a9969f59d83567ceeed73fbc842\n'}, {'number': 2, 'created': '2020-01-16 00:22:12.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/e8b67c59bab2cda563332a3e57b6a7a131c2ec9b', 'message': 'Fix molecule report\n\nAssures the HTML report is produced and collected by tox-molecule job.\n\nChange-Id: I50b78a169a9b5a9969f59d83567ceeed73fbc842\n'}]",0,702735,e8b67c59bab2cda563332a3e57b6a7a131c2ec9b,9,6,2,24162,,,0,"Fix molecule report

Assures the HTML report is produced and collected by tox-molecule job.

Change-Id: I50b78a169a9b5a9969f59d83567ceeed73fbc842
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/35/702735/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/layout.yaml', 'tox.ini']",2,2ab8a591d867e17bbed9a272a62daa44fdfe4e91,fix/molecule-report, ansible>=2.9 docker>=4.0.1 mock molecule>=3.0a5 pytest-molecule>=1.2.4 # MIT pytest-xdist selinux>=0.2.1 # MIT python -m pytest --color=yes --html={envlogdir}/reports.html --self-contained-html {tty:-s} {posargs}," ansible pytest-molecule # MIT selinux # MIT mock molecule>=2.22rc1,<3 bash -c ""cd {toxinidir}; molecule test -s sova;""",12,10
openstack%2Ftripleo-heat-templates~master~I192c19fdafe051f84be5845eaa665917b81f608a,openstack/tripleo-heat-templates,master,I192c19fdafe051f84be5845eaa665917b81f608a,Open ports for Metrics QDRs,MERGED,2020-01-15 12:21:52.000000000,2020-01-16 02:30:52.000000000,2020-01-16 02:30:52.000000000,"[{'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 7144}, {'_account_id': 9914}, {'_account_id': 14250}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-15 12:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2efcd0f27f5c28c2a6595d8f8b8d313618ca2e60', 'message': 'Open ports for Metrics QDRs\n\nThis patch opens ports for internal communication of QDRs deployed\non controllers.\n\nChange-Id: I192c19fdafe051f84be5845eaa665917b81f608a\n'}, {'number': 2, 'created': '2020-01-15 12:46:54.000000000', 'files': ['deployment/metrics/qdr-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/706d9b398271fc124ef59aafba61341a63332b4a', 'message': 'Open ports for Metrics QDRs\n\nThis patch opens ports for internal communication of QDRs deployed\non controllers.\n\nChange-Id: I192c19fdafe051f84be5845eaa665917b81f608a\n'}]",0,702656,706d9b398271fc124ef59aafba61341a63332b4a,17,10,2,5241,,,0,"Open ports for Metrics QDRs

This patch opens ports for internal communication of QDRs deployed
on controllers.

Change-Id: I192c19fdafe051f84be5845eaa665917b81f608a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/56/702656/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/metrics/qdr-container-puppet.yaml'],1,2efcd0f27f5c28c2a6595d8f8b8d313618ca2e60,open-qdr-ports, - 5667 - 5668,,2,0
openstack%2Fcinder~master~I24bfb313cf28b20037f5f9aea9417bc8371bfd91,openstack/cinder,master,I24bfb313cf28b20037f5f9aea9417bc8371bfd91,Fix tox 'bindep' environment,MERGED,2019-08-28 19:09:51.000000000,2020-01-16 02:28:20.000000000,2020-01-16 02:24:52.000000000,"[{'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 28543}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}, {'_account_id': 30688}]","[{'number': 1, 'created': '2019-08-28 19:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/76e693433b04874236665970b917306f7cecc808', 'message': ""Fix tox 'bindep' environment\n\ntox.ini is hard-coded to always use the 'test' profile for bindep;\ninstead, let tox get the profile from the posargs\n\nChange-Id: I24bfb313cf28b20037f5f9aea9417bc8371bfd91\n""}, {'number': 2, 'created': '2019-08-28 19:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/508d836098b3be101142cecac059725fad337264', 'message': ""Fix tox 'bindep' environment\n\ntox.ini is hard-coded to always use the 'test' profile for bindep;\ninstead, let tox get the profile from the posargs\n\nPartial-bug: #1841836\nChange-Id: I24bfb313cf28b20037f5f9aea9417bc8371bfd91\n""}, {'number': 3, 'created': '2019-11-13 19:51:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0eab57ebfe3ab721462eb288a43d3b90cc23eda9', 'message': ""Fix tox 'bindep' environment\n\ntox.ini is hard-coded to always use the 'test' profile for bindep;\ninstead, let tox get the profile from the posargs\n\nCloses-bug: #1841836\nChange-Id: I24bfb313cf28b20037f5f9aea9417bc8371bfd91\n""}]",0,679119,0eab57ebfe3ab721462eb288a43d3b90cc23eda9,62,31,3,5314,,,0,"Fix tox 'bindep' environment

tox.ini is hard-coded to always use the 'test' profile for bindep;
instead, let tox get the profile from the posargs

Closes-bug: #1841836
Change-Id: I24bfb313cf28b20037f5f9aea9417bc8371bfd91
",git fetch https://review.opendev.org/openstack/cinder refs/changes/19/679119/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,76e693433b04874236665970b917306f7cecc808,bug/1841836,commands = bindep {posargs},commands = bindep test,1,1
openstack%2Fcinder~master~I2d3c0f3f8d2c02ffedc4bf5ddc45e21c2d22c3e2,openstack/cinder,master,I2d3c0f3f8d2c02ffedc4bf5ddc45e21c2d22c3e2,Fix KeyError exception when volume filter file does not exist,MERGED,2019-12-02 01:30:26.000000000,2020-01-16 02:26:41.000000000,2020-01-16 02:24:48.000000000,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 19004}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 26970}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-12-02 01:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/29f6bf84192327f980cb89dd3450d74e9ac84d5d', 'message': 'Fix KeyError exception when volume filter file does not exist\n\nSince current code assume that resource key is existed, exception\nhappens when filter file does not initialized. Return empty list\nto avoid KeyError exception.\n\nChange-Id: I2d3c0f3f8d2c02ffedc4bf5ddc45e21c2d22c3e2\n'}, {'number': 2, 'created': '2019-12-30 09:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f18abca1d1c44f75c627755cd7e9915276214b42', 'message': 'Fix KeyError exception when volume filter file does not exist\n\nSince current code assume that resource key is existed, exception\nhappens when filter file does not initialized. Return empty list\nto avoid KeyError exception.\n\nChange-Id: I2d3c0f3f8d2c02ffedc4bf5ddc45e21c2d22c3e2\n'}, {'number': 3, 'created': '2019-12-31 01:00:07.000000000', 'files': ['cinder/api/v2/volumes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe7cf6be84ca133da31d97beb9593b79fad34e0e', 'message': 'Fix KeyError exception when volume filter file does not exist\n\nSince current code assume that resource key is existed, exception\nhappens when filter file does not initialized. Return empty list\nto avoid KeyError exception.\n\nCloses-Bug: #1857945\nChange-Id: I2d3c0f3f8d2c02ffedc4bf5ddc45e21c2d22c3e2\n'}]",3,696804,fe7cf6be84ca133da31d97beb9593b79fad34e0e,79,28,3,26970,,,0,"Fix KeyError exception when volume filter file does not exist

Since current code assume that resource key is existed, exception
happens when filter file does not initialized. Return empty list
to avoid KeyError exception.

Closes-Bug: #1857945
Change-Id: I2d3c0f3f8d2c02ffedc4bf5ddc45e21c2d22c3e2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/696804/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/common.py'],1,29f6bf84192327f980cb89dd3450d74e9ac84d5d,bug/1857945, return {resource: []}, return {},1,1
openstack%2Fopenstack-helm-infra~master~Icdcc53e3572f611feeb27e1ed8519b7477a820cd,openstack/openstack-helm-infra,master,Icdcc53e3572f611feeb27e1ed8519b7477a820cd,Added default network policy for postgresql,ABANDONED,2019-10-18 20:23:11.000000000,2020-01-16 02:25:52.000000000,,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-10-18 20:23:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/25cfebe2dea84632a951f942067fe00f024f089f', 'message': ""Added default network policy for postgresql\n\nNetwork policy is not applied by default.\nIn values_overrides, network policy is turned on.\nSince we don't have postgresql deployed in osh,\nall the ingress and egress traffic are allowed\nin this override.\n\nChange-Id: Icdcc53e3572f611feeb27e1ed8519b7477a820cd\n""}, {'number': 2, 'created': '2019-11-08 15:29:43.000000000', 'files': ['postgresql/templates/network_policy.yaml', 'postgresql/values_overrides/netpol.yaml', 'postgresql/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8517d0130c657dc5fd6f88390af908af0fc0c6ba', 'message': ""Added default network policy for postgresql\n\nNetwork policy is not applied by default.\nIn values_overrides, network policy is turned on.\nSince we don't have postgresql deployed in osh,\nall the ingress and egress traffic are allowed\nin this override.\n\nChange-Id: Icdcc53e3572f611feeb27e1ed8519b7477a820cd\n""}]",3,689572,8517d0130c657dc5fd6f88390af908af0fc0c6ba,9,5,2,18236,,,0,"Added default network policy for postgresql

Network policy is not applied by default.
In values_overrides, network policy is turned on.
Since we don't have postgresql deployed in osh,
all the ingress and egress traffic are allowed
in this override.

Change-Id: Icdcc53e3572f611feeb27e1ed8519b7477a820cd
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/72/689572/1 && git format-patch -1 --stdout FETCH_HEAD,"['postgresql/templates/network_policy.yaml', 'postgresql/values_overrides/netpol.yaml', 'postgresql/values.yaml']",3,25cfebe2dea84632a951f942067fe00f024f089f,netpol,network_policy: postgresql: ingress: - {} egress: - {} network_policy: false,,29,0
openstack%2Fkeystone-specs~master~Ia4b92e1b34344bf79626058264f35a328d55c6c5,openstack/keystone-specs,master,Ia4b92e1b34344bf79626058264f35a328d55c6c5,Switch to Ussuri jobs,ABANDONED,2019-10-31 11:34:58.000000000,2020-01-16 02:22:46.000000000,,"[{'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-10-31 11:34:58.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/c0f60913607a90400a13e53b4788365ddbbd074f', 'message': 'Switch to Ussuri jobs\n\nChange-Id: Ia4b92e1b34344bf79626058264f35a328d55c6c5\n'}]",0,692345,c0f60913607a90400a13e53b4788365ddbbd074f,7,2,1,30408,,,0,"Switch to Ussuri jobs

Change-Id: Ia4b92e1b34344bf79626058264f35a328d55c6c5
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/45/692345/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c0f60913607a90400a13e53b4788365ddbbd074f,, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Fopenstack-ansible-plugins~master~Id35ec5f114c3e94db76b05fa0cc3513df4cc7399,openstack/openstack-ansible-plugins,master,Id35ec5f114c3e94db76b05fa0cc3513df4cc7399,Update invaild link for Conf,ABANDONED,2019-09-18 11:54:14.000000000,2020-01-16 02:22:19.000000000,,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27383}, {'_account_id': 29865}]","[{'number': 1, 'created': '2019-09-18 11:54:14.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/660ee163706c2ccf32c1eb0b3a66abbb4df30bdc', 'message': 'Update invaild link for Conf\n\nChange-Id: Id35ec5f114c3e94db76b05fa0cc3513df4cc7399\n'}]",1,682877,660ee163706c2ccf32c1eb0b3a66abbb4df30bdc,7,4,1,30408,,,0,"Update invaild link for Conf

Change-Id: Id35ec5f114c3e94db76b05fa0cc3513df4cc7399
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/77/682877/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,660ee163706c2ccf32c1eb0b3a66abbb4df30bdc,, 'https://opendev.org/cgit/openstack/{}'.format(target_name), 'https://git.openstack.org/cgit/openstack/{}'.format(target_name),2,2
openstack%2Fopenstack-ansible-os_swift~master~I531d9fdf424d1d2dfaeb15e01d3e75d3e532505c,openstack/openstack-ansible-os_swift,master,I531d9fdf424d1d2dfaeb15e01d3e75d3e532505c,Update invaild link for Conf,ABANDONED,2019-09-18 11:51:57.000000000,2020-01-16 02:22:11.000000000,,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27383}, {'_account_id': 30455}]","[{'number': 1, 'created': '2019-09-18 11:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/65f20be8e3aad19ae9d375e64a5f696c26809236', 'message': 'Update invaild link for Conf\n\nChange-Id: I531d9fdf424d1d2dfaeb15e01d3e75d3e532505c\n'}, {'number': 2, 'created': '2019-11-05 02:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/16df89d68b6af29572dfca7a539d07231d2fcccf', 'message': 'Update invaild link for Conf\n\nChange-Id: I531d9fdf424d1d2dfaeb15e01d3e75d3e532505c\n'}, {'number': 3, 'created': '2019-11-05 02:19:41.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/d93a5010bebcd92129b8359dd2ecc931ccdd0b9c', 'message': 'Update invaild link for Conf\n\nChange-Id: I531d9fdf424d1d2dfaeb15e01d3e75d3e532505c\n'}]",1,682874,d93a5010bebcd92129b8359dd2ecc931ccdd0b9c,10,4,3,30408,,,0,"Update invaild link for Conf

Change-Id: I531d9fdf424d1d2dfaeb15e01d3e75d3e532505c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/74/682874/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,65f20be8e3aad19ae9d375e64a5f696c26809236,, 'https://opendev.org/cgit/openstack/{}'.format(target_name), 'https://git.openstack.org/cgit/openstack/{}'.format(target_name),2,2
openstack%2Fdesignate~master~Icb5b4a5aa10b33a46c112aa770f6c6ec9ab9c741,openstack/designate,master,Icb5b4a5aa10b33a46c112aa770f6c6ec9ab9c741,Fix misspell word,ABANDONED,2019-09-06 08:43:31.000000000,2020-01-16 02:22:02.000000000,,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2019-09-06 08:43:31.000000000', 'files': ['designate/sqlalchemy/utils.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/7ad768f50aa27ecefa6b058d9c636a6e76922f9c', 'message': 'Fix misspell word\n\nChange-Id: Icb5b4a5aa10b33a46c112aa770f6c6ec9ab9c741\n'}]",0,680620,7ad768f50aa27ecefa6b058d9c636a6e76922f9c,4,2,1,30408,,,0,"Fix misspell word

Change-Id: Icb5b4a5aa10b33a46c112aa770f6c6ec9ab9c741
",git fetch https://review.opendev.org/openstack/designate refs/changes/20/680620/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/sqlalchemy/utils.py'],1,7ad768f50aa27ecefa6b058d9c636a6e76922f9c,,# copy from oslo/db/sqlalchemy/utils.py,# copy from olso/db/sqlalchemy/utils.py,1,1
openstack%2Fshade~master~I1b0d95fd1eae8f0a901c788b2d6f4884c37eeec6,openstack/shade,master,I1b0d95fd1eae8f0a901c788b2d6f4884c37eeec6,Fix code specification with pep8,ABANDONED,2019-09-03 09:51:51.000000000,2020-01-16 02:21:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-09-03 09:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/12f651e8bc6b60846fdfef552d7544d4e99e1db9', 'message': 'Fix code specification with pep8\n\nChange-Id: I1b0d95fd1eae8f0a901c788b2d6f4884c37eeec6\n'}, {'number': 2, 'created': '2019-09-03 09:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/f826ea7b885dc1a440709472bf391e793695139e', 'message': 'Fix code specification with pep8\n\nChange-Id: I1b0d95fd1eae8f0a901c788b2d6f4884c37eeec6\n'}, {'number': 3, 'created': '2019-09-03 09:54:39.000000000', 'files': ['shade/_heat/template_utils.py', 'shade/_heat/template_format.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/a7de691d0dac0dd95022bfdbe22d0d42f5370cc8', 'message': 'Fix code specification with pep8\n\nChange-Id: I1b0d95fd1eae8f0a901c788b2d6f4884c37eeec6\n'}]",0,679736,a7de691d0dac0dd95022bfdbe22d0d42f5370cc8,5,1,3,30408,,,0,"Fix code specification with pep8

Change-Id: I1b0d95fd1eae8f0a901c788b2d6f4884c37eeec6
",git fetch https://review.opendev.org/openstack/shade refs/changes/36/679736/3 && git format-patch -1 --stdout FETCH_HEAD,"['shade/_heat/utils.py', 'shade/_heat/template_utils.py', 'shade/_heat/template_format.py']",3,12f651e8bc6b60846fdfef552d7544d4e99e1db9,, ,,4,1
openstack%2Fmagnum~master~Ibc3e82e5bfb6586b2e965e460f7a1983672fdc48,openstack/magnum,master,Ibc3e82e5bfb6586b2e965e460f7a1983672fdc48,"Unified word spelling of "":returns""",ABANDONED,2019-08-20 07:39:56.000000000,2020-01-16 02:21:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-08-20 07:39:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d013f2747ae8ea733648267ec233317083c43cf6', 'message': 'Unified word spelling of :returns\n\nChange-Id: Ibc3e82e5bfb6586b2e965e460f7a1983672fdc48\n'}, {'number': 2, 'created': '2019-08-20 07:42:56.000000000', 'files': ['magnum/conductor/k8s_api.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6fbdd1a9ee22a469442d12906b65c61d7d9d1ceb', 'message': 'Unified word spelling of "":returns""\n\nChange-Id: Ibc3e82e5bfb6586b2e965e460f7a1983672fdc48\n'}]",0,677420,6fbdd1a9ee22a469442d12906b65c61d7d9d1ceb,6,1,2,30408,,,0,"Unified word spelling of "":returns""

Change-Id: Ibc3e82e5bfb6586b2e965e460f7a1983672fdc48
",git fetch https://review.opendev.org/openstack/magnum refs/changes/20/677420/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/conductor/k8s_api.py'],1,d013f2747ae8ea733648267ec233317083c43cf6,, :returns: The method will return the response directly, :return: The method will return the response directly,1,1
openstack%2Ftricircle~master~I05fb37055698c8745edf88b8b08646b1e56d083e,openstack/tricircle,master,I05fb37055698c8745edf88b8b08646b1e56d083e,Start README.rst with a better title,ABANDONED,2019-11-28 01:22:46.000000000,2020-01-16 02:21:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-11-28 01:22:46.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/eb466b97337e475d5224df3dc925e8995e227212', 'message': 'Start README.rst with a better title\n\nNow that we are using gitea the contents of our README.rst are\nmore prominently displayed. Starting it with a ""Team and repository\ntags"" title is a bit confusing. This change makes it start with the\nname of the project instead.\n\nChange-Id: I05fb37055698c8745edf88b8b08646b1e56d083e\n'}]",0,696423,eb466b97337e475d5224df3dc925e8995e227212,3,1,1,30408,,,0,"Start README.rst with a better title

Now that we are using gitea the contents of our README.rst are
more prominently displayed. Starting it with a ""Team and repository
tags"" title is a bit confusing. This change makes it start with the
name of the project instead.

Change-Id: I05fb37055698c8745edf88b8b08646b1e56d083e
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/23/696423/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,eb466b97337e475d5224df3dc925e8995e227212,dev,========= Tricircle =========,======================== Team and repository tags ================================= Tricircle ========= ,3,7
openstack%2Fmagnum~master~Ic9741497f497eaf39caecd74f77865865c172c48,openstack/magnum,master,Ic9741497f497eaf39caecd74f77865865c172c48,Start README.rst with a better title,ABANDONED,2019-11-28 02:11:08.000000000,2020-01-16 02:20:39.000000000,,"[{'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-11-28 02:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/bf0fe1966c3aa942704b8076b9ce9e72835433a0', 'message': 'Start README.rst with a better title\n\nNow that we are using gitea the contents of our README.rst are\nmore prominently displayed. Starting it with a ""Team and repository\ntags"" title is a bit confusing. This change makes it start with the\nname of the project instead.\n\nChange-Id: Ic9741497f497eaf39caecd74f77865865c172c48\n'}, {'number': 2, 'created': '2019-12-20 01:08:06.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/79591e46167633c6b7753a8060bf65d41c92f500', 'message': 'Start README.rst with a better title\n\nNow that we are using gitea the contents of our README.rst are\nmore prominently displayed. Starting it with a ""Team and repository\ntags"" title is a bit confusing. This change makes it start with the\nname of the project instead.\n\nChange-Id: Ic9741497f497eaf39caecd74f77865865c172c48\n'}]",1,696436,79591e46167633c6b7753a8060bf65d41c92f500,7,2,2,30408,,,0,"Start README.rst with a better title

Now that we are using gitea the contents of our README.rst are
more prominently displayed. Starting it with a ""Team and repository
tags"" title is a bit confusing. This change makes it start with the
name of the project instead.

Change-Id: Ic9741497f497eaf39caecd74f77865865c172c48
",git fetch https://review.opendev.org/openstack/magnum refs/changes/36/696436/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,bf0fe1966c3aa942704b8076b9ce9e72835433a0,,====== Magnum ======,======================== Team and repository tags ============================== Magnum ====== ,3,7
openstack%2Ffreezer-tempest-plugin~master~I8cbcdbc175fbc37e1ebe2c53023abcc2aec9d28f,openstack/freezer-tempest-plugin,master,I8cbcdbc175fbc37e1ebe2c53023abcc2aec9d28f,Fix some python3 compatility,MERGED,2020-01-16 00:32:47.000000000,2020-01-16 02:14:54.000000000,2020-01-16 02:14:54.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}]","[{'number': 1, 'created': '2020-01-16 00:32:47.000000000', 'files': ['freezer_tempest_plugin/tests/freezer/agent/test_backup_compress.py', 'freezer_tempest_plugin/tests/freezer/agent/test_metadata_checksum.py'], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/acd6893d0a6d4788853f51176bf7569ca0e66fce', 'message': 'Fix some python3 compatility\n\nChange-Id: I8cbcdbc175fbc37e1ebe2c53023abcc2aec9d28f\n'}]",0,702778,acd6893d0a6d4788853f51176bf7569ca0e66fce,8,3,1,21069,,,0,"Fix some python3 compatility

Change-Id: I8cbcdbc175fbc37e1ebe2c53023abcc2aec9d28f
",git fetch https://review.opendev.org/openstack/freezer-tempest-plugin refs/changes/78/702778/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_tempest_plugin/tests/freezer/agent/test_backup_compress.py', 'freezer_tempest_plugin/tests/freezer/agent/test_metadata_checksum.py']",2,acd6893d0a6d4788853f51176bf7569ca0e66fce,," self.assertNotEqual(b'', err, message)"," self.assertNotEqual('', err, message)",4,4
openstack%2Ffreezer-tempest-plugin~master~I602061f2d544854df4720fa414afd1c1687bf2d5,openstack/freezer-tempest-plugin,master,I602061f2d544854df4720fa414afd1c1687bf2d5,Fix tempest running under python3,MERGED,2020-01-10 20:18:39.000000000,2020-01-16 02:12:25.000000000,2020-01-16 02:12:25.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}, {'_account_id': 27339}]","[{'number': 1, 'created': '2020-01-10 20:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/91186181c960d96cc107e2d7876731fb514d84b0', 'message': 'Fix tempest running under python3\n\nChange-Id: I602061f2d544854df4720fa414afd1c1687bf2d5\n'}, {'number': 2, 'created': '2020-01-11 10:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/a96100b3c8df5e4d38e40edb99d81e1f8a0c31b4', 'message': 'Fix tempest running under python3\n\nChange-Id: I602061f2d544854df4720fa414afd1c1687bf2d5\n'}, {'number': 3, 'created': '2020-01-11 18:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/86ffd8404f1d625a718f6f3f976b0ee19d279740', 'message': 'Fix tempest running under python3\n\nChange-Id: I602061f2d544854df4720fa414afd1c1687bf2d5\n'}, {'number': 4, 'created': '2020-01-12 14:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/fbe35e68069450699d71009556be086a60260d64', 'message': 'Fix tempest running under python3\n\nChange-Id: I602061f2d544854df4720fa414afd1c1687bf2d5\nDepends-On: https://review.opendev.org/#/c/696606/\n'}, {'number': 5, 'created': '2020-01-12 14:22:08.000000000', 'files': ['freezer_tempest_plugin/common.py', 'freezer_tempest_plugin/tests/freezer/agent/test_backup_compress.py', 'freezer_tempest_plugin/tests/scheduler/base.py', 'freezer_tempest_plugin/tests/freezer/agent/test_metadata_checksum.py', 'freezer_tempest_plugin/tests/freezerclient/base.py', 'freezer_tempest_plugin/tests/freezerclient/test_freezer_cmd_action.py', 'freezer_tempest_plugin/tests/freezerclient/test_freezer_cmd_client.py', 'freezer_tempest_plugin/tests/freezer/agent/base.py'], 'web_link': 'https://opendev.org/openstack/freezer-tempest-plugin/commit/2531984a018d4f5357793e3211b84c7c60bc865d', 'message': 'Fix tempest running under python3\n\nChange-Id: I602061f2d544854df4720fa414afd1c1687bf2d5\n'}]",0,702035,2531984a018d4f5357793e3211b84c7c60bc865d,24,4,5,27339,,,0,"Fix tempest running under python3

Change-Id: I602061f2d544854df4720fa414afd1c1687bf2d5
",git fetch https://review.opendev.org/openstack/freezer-tempest-plugin refs/changes/35/702035/5 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_tempest_plugin/common.py', 'freezer_tempest_plugin/tests/freezer/agent/test_backup_compress.py', 'freezer_tempest_plugin/tests/scheduler/base.py', 'freezer_tempest_plugin/tests/freezer/agent/test_metadata_checksum.py', 'freezer_tempest_plugin/tests/freezerclient/base.py', 'freezer_tempest_plugin/tests/freezer/agent/base.py']",6,91186181c960d96cc107e2d7876731fb514d84b0,fix-tempest-py3," with open(path, 'rb') as f: env=self.environ, shell=False, universal_newlines=True)"," with open(path, 'r') as f: env=self.environ, shell=False)",16,8
openstack%2Fcinder~master~I615e34f2f8df60eaea09e32b15437deb36f441c0,openstack/cinder,master,I615e34f2f8df60eaea09e32b15437deb36f441c0,SPDK drivers: Update RPC calls to match latest SPDK changes,MERGED,2019-11-12 14:55:11.000000000,2020-01-16 01:52:00.000000000,2020-01-16 01:48:54.000000000,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28050}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-11-12 14:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5d0c196689e1d63c3d1cf999dd142e2adca9d7a5', 'message': 'SPDK drivers: Update RPC calls to match latest SPDK changes\n\nWith latest SPDK release most of the old RPC calls has been\ndeprecated and soon will be obsolete. This patch updates\nrelevant calls to the latest version.\n\nSigned-off-by: Maciej Szwed <maciej.szwed@intel.com>\nChange-Id: I615e34f2f8df60eaea09e32b15437deb36f441c0\n\n'}, {'number': 2, 'created': '2020-01-02 12:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4df7003b14a034c11e93645f865986467e546c3e', 'message': 'SPDK drivers: Update RPC calls to match latest SPDK changes\n\nWith latest SPDK release most of the old RPC calls has been\ndeprecated and soon will be obsolete. This patch updates\nrelevant calls to the latest version.\n\nSigned-off-by: Maciej Szwed <maciej.szwed@intel.com>\nChange-Id: I615e34f2f8df60eaea09e32b15437deb36f441c0\n\n'}, {'number': 3, 'created': '2020-01-08 14:24:04.000000000', 'files': ['doc/source/configuration/block-storage/drivers/spdk-volume-driver.rst', 'cinder/volume/targets/spdknvmf.py', 'releasenotes/notes/rpc-update-50bef83f48d4f96f.yaml', 'cinder/tests/unit/targets/test_spdknvmf.py', 'cinder/volume/drivers/spdk.py', 'cinder/tests/unit/volume/drivers/test_spdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/01d8401d14c9a69676c330837e9460e5a63f3063', 'message': 'SPDK drivers: Update RPC calls to match latest SPDK changes\n\nWith latest SPDK release most of the old RPC calls has been\ndeprecated and soon will be obsolete. This patch updates\nrelevant calls to the latest version.\n\nSigned-off-by: Maciej Szwed <maciej.szwed@intel.com>\nChange-Id: I615e34f2f8df60eaea09e32b15437deb36f441c0\n\n'}]",0,693856,01d8401d14c9a69676c330837e9460e5a63f3063,83,31,3,28050,,,0,"SPDK drivers: Update RPC calls to match latest SPDK changes

With latest SPDK release most of the old RPC calls has been
deprecated and soon will be obsolete. This patch updates
relevant calls to the latest version.

Signed-off-by: Maciej Szwed <maciej.szwed@intel.com>
Change-Id: I615e34f2f8df60eaea09e32b15437deb36f441c0

",git fetch https://review.opendev.org/openstack/cinder refs/changes/56/693856/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration/block-storage/drivers/spdk-volume-driver.rst', 'cinder/volume/targets/spdknvmf.py', 'cinder/volume/drivers/spdk.py']",3,5d0c196689e1d63c3d1cf999dd142e2adca9d7a5,," output = self._rpc_call('bdev_lvol_get_lvstores') output = self._rpc_call('bdev_get_bdevs') output = self._rpc_call('bdev_get_bdevs') self._rpc_call('bdev_lvol_delete', params) output = self._rpc_call('bdev_lvol_get_lvstores') output2 = self._rpc_call('bdev_lvol_create', params) output2 = self._rpc_call('bdev_lvol_clone', params) self._rpc_call('bdev_lvol_inflate', params) self._rpc_call('bdev_lvol_resize', params) payload = {'method': 'bdev_get_bdevs', 'jsonrpc': '2.0', 'id': 1} self._rpc_call('bdev_get_bdevs') self._rpc_call('bdev_lvol_snapshot', params) self._rpc_call('bdev_lvol_inflate', params) bdev = self._rpc_call('bdev_get_bdevs', params) self._rpc_call('bdev_lvol_inflate', params) self._rpc_call('bdev_lvol_snapshot', params) self._rpc_call('bdev_lvol_inflate', params) self._rpc_call('bdev_lvol_clone', params) self._rpc_call('bdev_lvol_inflate', params) self._rpc_call('bdev_lvol_resize', params)"," output = self._rpc_call('get_lvol_stores') output = self._rpc_call('get_bdevs') output = self._rpc_call('get_bdevs') self._rpc_call('destroy_lvol_bdev', params) output = self._rpc_call('get_lvol_stores') output2 = self._rpc_call('construct_lvol_bdev', params) output2 = self._rpc_call('clone_lvol_bdev', params) self._rpc_call('inflate_lvol_bdev', params) self._rpc_call('resize_lvol_bdev', params) payload = {'method': 'get_bdevs', 'jsonrpc': '2.0', 'id': 1} self._rpc_call('get_bdevs') self._rpc_call('snapshot_lvol_bdev', params) self._rpc_call('inflate_lvol_bdev', params) bdev = self._rpc_call('get_bdevs', params) self._rpc_call('inflate_lvol_bdev', params) self._rpc_call('snapshot_lvol_bdev', params) self._rpc_call('inflate_lvol_bdev', params) self._rpc_call('clone_lvol_bdev', params) self._rpc_call('inflate_lvol_bdev', params) self._rpc_call('resize_lvol_bdev', params)",27,26
openstack%2Fcinder~stable%2Ftrain~I864c8984109574680032be6f797855a49d835fe3,openstack/cinder,stable/train,I864c8984109574680032be6f797855a49d835fe3,DS8k Cinder Driver support Python3,MERGED,2020-01-06 02:48:21.000000000,2020-01-16 01:50:47.000000000,2020-01-16 01:48:50.000000000,"[{'_account_id': 1736}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 26422}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29716}]","[{'number': 1, 'created': '2020-01-06 02:48:21.000000000', 'files': ['cinder/volume/drivers/ibm/ibm_storage/ds8k_restclient.py', 'cinder/volume/drivers/ibm/ibm_storage/ibm_storage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ee87b3864eaf4ad62bd577af0443e3fb73ccabb9', 'message': 'DS8k Cinder Driver support Python3\n\nChange IBM DS8K Cinder Driver code to support python3\n\nChange-Id: I864c8984109574680032be6f797855a49d835fe3\nCloses-Bug: 1855657\n(cherry picked from commit 77a285b813638e7b8c651df57d3119543ceb685f)\n'}]",3,701126,ee87b3864eaf4ad62bd577af0443e3fb73ccabb9,21,14,1,26422,,,0,"DS8k Cinder Driver support Python3

Change IBM DS8K Cinder Driver code to support python3

Change-Id: I864c8984109574680032be6f797855a49d835fe3
Closes-Bug: 1855657
(cherry picked from commit 77a285b813638e7b8c651df57d3119543ceb685f)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/26/701126/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/ibm_storage/ds8k_restclient.py', 'cinder/volume/drivers/ibm/ibm_storage/ibm_storage.py']",2,ee87b3864eaf4ad62bd577af0443e3fb73ccabb9,Bug1855657-stable/train,, # TODO(jsbryant) Remove driver in the 'U' release if CI is not fixed. SUPPORTED = False ,2,5
openstack%2Fcinder~master~Idb845b318a6f6cc6adca66ca6b578f74d05e17f5,openstack/cinder,master,Idb845b318a6f6cc6adca66ca6b578f74d05e17f5,Update release notes for ibm storage,MERGED,2020-01-06 08:25:52.000000000,2020-01-16 01:50:46.000000000,2020-01-16 01:48:52.000000000,"[{'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 29716}]","[{'number': 1, 'created': '2020-01-06 08:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c52cef1e5bc102a4828bd10014162aa6684955b', 'message': 'Update release notes for ibm storage\n\nIBM DS8k cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We need to mark DS8k cinder driver as supported\nagain. This commit updated release notes and support-matrix.ini\nfor IBM DS8k driver.\n\nChange-Id: Idb845b318a6f6cc6adca66ca6b578f74d05e17f5\n'}, {'number': 2, 'created': '2020-01-06 10:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/71cd35a53cbcf8cb00f44e2e6fba4f012ba325b6', 'message': 'Update release notes for ibm storage\n\nIBM DS8k cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We need to mark DS8k cinder driver as supported\nagain. This commit updated release notes and support-matrix.ini\nfor IBM DS8k driver.\n\nChange-Id: Idb845b318a6f6cc6adca66ca6b578f74d05e17f5\n'}, {'number': 3, 'created': '2020-01-07 01:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/65df1edcde572bb598a06fc72648dbfaea5dd138', 'message': 'Update release notes for ibm storage\n\nIBM DS8k cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We need to mark DS8k cinder driver as supported\nagain. This commit updated release notes and support-matrix.ini\nfor IBM DS8k driver.\n\nChange-Id: Idb845b318a6f6cc6adca66ca6b578f74d05e17f5\n'}, {'number': 4, 'created': '2020-01-07 01:23:16.000000000', 'files': ['doc/source/reference/support-matrix.ini', 'releasenotes/notes/ibm-storage-supported-a373a54777333929.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7a6e457f65812c65c0044a311dc8b6d09bc88625', 'message': 'Update release notes for ibm storage\n\nIBM DS8k cinder driver has been marked as unsupported due to lack\nof external CI running log. Now IBM new external CI system is up\nand running. We need to mark DS8k cinder driver as supported\nagain. This commit updated release notes and support-matrix.ini\nfor IBM DS8k driver.\n\nChange-Id: Idb845b318a6f6cc6adca66ca6b578f74d05e17f5\n'}]",1,701165,7a6e457f65812c65c0044a311dc8b6d09bc88625,66,22,4,26422,,,0,"Update release notes for ibm storage

IBM DS8k cinder driver has been marked as unsupported due to lack
of external CI running log. Now IBM new external CI system is up
and running. We need to mark DS8k cinder driver as supported
again. This commit updated release notes and support-matrix.ini
for IBM DS8k driver.

Change-Id: Idb845b318a6f6cc6adca66ca6b578f74d05e17f5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/65/701165/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/support-matrix.ini', 'releasenotes/notes/ibm-storage-supported-a373a54777333929.yaml']",2,7c52cef1e5bc102a4828bd10014162aa6684955b,ibm_storage_support,"--- upgrade: - | The IBM Storage drivers (XIV) have been marked as unsupported and are now deprecated. ``enable_unsupported_driver`` will need to be set to ``True`` in the driver's section in cinder.conf to continue to use them. deprecations: - | The IBM Storage drivers (XIV) have been marked as unsupported and are now deprecated. ``enable_unsupported_driver`` will need to be set to ``True`` in the driver's section in cinder.conf to continue to use them. If the support status does not change, the drivers will be removed in the 'U' development cycle. ",,15,1
openstack%2Fcinderlib~master~Ifc37f5af9ed1cf94db79402ea453aafc5bdc8741,openstack/cinderlib,master,Ifc37f5af9ed1cf94db79402ea453aafc5bdc8741,Update master for stable/train,MERGED,2019-12-12 10:08:10.000000000,2020-01-16 01:50:20.000000000,2020-01-16 01:48:56.000000000,"[{'_account_id': 9535}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-12 10:08:10.000000000', 'files': ['releasenotes/source/train.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/cinderlib/commit/cafeb6edd23c5fb26d565212ec19a1a72e8d28f0', 'message': 'Update master for stable/train\n\nAdd file to the reno documentation build to show release notes for\nstable/train.\n\nUse pbr instruction to increment the minor version number\nautomatically so that master versions are higher than the versions on\nstable/train.\n\nChange-Id: Ifc37f5af9ed1cf94db79402ea453aafc5bdc8741\nSem-Ver: feature\n'}]",0,698670,cafeb6edd23c5fb26d565212ec19a1a72e8d28f0,12,6,1,22816,,,0,"Update master for stable/train

Add file to the reno documentation build to show release notes for
stable/train.

Use pbr instruction to increment the minor version number
automatically so that master versions are higher than the versions on
stable/train.

Change-Id: Ifc37f5af9ed1cf94db79402ea453aafc5bdc8741
Sem-Ver: feature
",git fetch https://review.opendev.org/openstack/cinderlib refs/changes/70/698670/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/train.rst', 'releasenotes/source/index.rst']",2,cafeb6edd23c5fb26d565212ec19a1a72e8d28f0,reno-train, train,,7,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I32524f85ef6a0ca3e87fa9acc8c9e12776225717,openstack/tripleo-heat-templates,stable/queens,I32524f85ef6a0ca3e87fa9acc8c9e12776225717,Simplify octavia post deploy configs,MERGED,2019-10-29 18:12:13.000000000,2020-01-16 01:46:43.000000000,2020-01-16 01:45:13.000000000,"[{'_account_id': 6469}, {'_account_id': 6681}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-29 18:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eb53ead4bb0113d6f61ecec5bd80712314143595', 'message': 'Simplify octavia post deploy configs\n\nConsolidate post deploy configurations in a single file. Octavia\ncontroller services share many configurations. It is best to consolidate\nthem in the same configuration file. This fixes problems seen like\namphorae not having the controller_ip_port_list config value set on\nfailover triggered by the Health Manager service as that config was only\nbeing loaded for the Worker service.\n\nConflicts:\n    docker/services/octavia-health-manager.yaml\n    docker/services/octavia-housekeeping.yaml\n    docker/services/octavia-worker.yaml\n\nCloses-Bug: #1836074\nDepends-On: https://review.opendev.org/#/c/691935/\n\nChange-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717\n(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)\n(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)\n(cherry picked from commit 158d3319aa7b2e6026e3b39f0bdfa33bbf96ef92)\n(cherry picked from commit 1093f01974d153f8ef58423a9023ce7475ad6fd4)\n'}, {'number': 2, 'created': '2020-01-08 14:45:07.000000000', 'files': ['docker/services/octavia-health-manager.yaml', 'docker/services/octavia-worker.yaml', 'releasenotes/notes/consolidate-octavia-post-deploy-configs-bc251a5446e5615d.yaml', 'docker/services/octavia-housekeeping.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ea86c43b8b6e2da1adc0569e5c963a9decee7f47', 'message': 'Simplify octavia post deploy configs\n\nConsolidate post deploy configurations in a single file. Octavia\ncontroller services share many configurations. It is best to consolidate\nthem in the same configuration file. This fixes problems seen like\namphorae not having the controller_ip_port_list config value set on\nfailover triggered by the Health Manager service as that config was only\nbeing loaded for the Worker service.\n\nBackport note: this backport also includes https://review.opendev.org/696729/\nDepends-On: https://review.opendev.org/#/c/691935/\nCloses-Bug: #1836074\n\nChange-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717\n(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)\n(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)\n(cherry picked from commit 6a45e9b37a9664e753125526211c253dee318368)\n(cherry picked from commit 8e9b155a61151ef52383d42ed4866e0a785a10ca)\n'}]",0,691936,ea86c43b8b6e2da1adc0569e5c963a9decee7f47,18,5,2,6469,,,0,"Simplify octavia post deploy configs

Consolidate post deploy configurations in a single file. Octavia
controller services share many configurations. It is best to consolidate
them in the same configuration file. This fixes problems seen like
amphorae not having the controller_ip_port_list config value set on
failover triggered by the Health Manager service as that config was only
being loaded for the Worker service.

Backport note: this backport also includes https://review.opendev.org/696729/
Depends-On: https://review.opendev.org/#/c/691935/
Closes-Bug: #1836074

Change-Id: I32524f85ef6a0ca3e87fa9acc8c9e12776225717
(cherry picked from commit c2bb9c0937852d1d5488bc727983fce3435ca898)
(cherry picked from commit 25d8177d143d7933f243543ed12cf4b956167fd1)
(cherry picked from commit 6a45e9b37a9664e753125526211c253dee318368)
(cherry picked from commit 8e9b155a61151ef52383d42ed4866e0a785a10ca)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/691936/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/octavia-health-manager.yaml', 'docker/services/octavia-worker.yaml', 'releasenotes/notes/consolidate-octavia-post-deploy-configs-bc251a5446e5615d.yaml', 'docker/services/octavia-housekeeping.yaml']",4,eb53ead4bb0113d6f61ecec5bd80712314143595,," command: /usr/bin/octavia-housekeeping --config-file /usr/share/octavia/octavia-dist.conf --config-file /etc/octavia/octavia.conf --config-file /etc/octavia/post-deploy.conf --log-file /var/log/octavia/housekeeping.log --config-dir /etc/octavia/conf.d/octavia-housekeeping post_upgrade_tasks: - name: remove directory /etc/octavia/conf.d/common when: step|int == 5 file: path: ""/var/lib/config-data/puppet-generated/octavia/etc/octavia/conf.d/common"" state: absent post_update_tasks: - name: remove directory /etc/octavia/conf.d/common when: step|int == 5 file: path: ""/var/lib/config-data/puppet-generated/octavia/etc/octavia/conf.d/common"" state: absent", command: /usr/bin/octavia-housekeeping --config-file /usr/share/octavia/octavia-dist.conf --config-file /etc/octavia/octavia.conf --log-file /var/log/octavia/housekeeping.log --config-dir /etc/octavia/conf.d/common --config-dir /etc/octavia/conf.d/octavia-housekeeping,44,3
openstack%2Fdiskimage-builder~master~If3de6efa6074e059dc9fdd47c7bdc19d26d4d7f2,openstack/diskimage-builder,master,If3de6efa6074e059dc9fdd47c7bdc19d26d4d7f2,Fix Yum repositories and GPG keys for CentOS 8.1,MERGED,2020-01-15 18:39:31.000000000,2020-01-16 01:22:36.000000000,2020-01-16 01:21:15.000000000,"[{'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6469}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-15 18:39:31.000000000', 'files': ['diskimage_builder/elements/yum-minimal/root.d/08-yum-chroot'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ae2be0b464392256df7009f7030281963c06aa81', 'message': 'Fix Yum repositories and GPG keys for CentOS 8.1\n\nCentOS 8.1 split repositories and GPG keys out into subpackages. This\nbroke DIB support for CentOS 8.\n\nhttps://git.centos.org/rpms/centos-release/c/7e41cef418ab8781dab118e81f811221dd83c226?branch=c8\nhttps://git.centos.org/rpms/centos-release/c/26a0d73cedb9a2bfbcc38459344111fea231c577?branch=c8\n\nChange-Id: If3de6efa6074e059dc9fdd47c7bdc19d26d4d7f2\n'}]",4,702721,ae2be0b464392256df7009f7030281963c06aa81,27,8,1,6469,,,0,"Fix Yum repositories and GPG keys for CentOS 8.1

CentOS 8.1 split repositories and GPG keys out into subpackages. This
broke DIB support for CentOS 8.

https://git.centos.org/rpms/centos-release/c/7e41cef418ab8781dab118e81f811221dd83c226?branch=c8
https://git.centos.org/rpms/centos-release/c/26a0d73cedb9a2bfbcc38459344111fea231c577?branch=c8

Change-Id: If3de6efa6074e059dc9fdd47c7bdc19d26d4d7f2
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/21/702721/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/yum-minimal/root.d/08-yum-chroot'],1,ae2be0b464392256df7009f7030281963c06aa81,," # CentOS 8.1 split repositories and GPG keys out into subpackages if [[ ${DISTRO_NAME} = centos && ${DIB_RELEASE} -ge 8 ]]; then packages+=""centos-repos centos-gpg-keys "" fi ",,5,0
openstack%2Fopenstack-chef~master~If780398073eb2b4a8d8fc865c15179a677d2e42e,openstack/openstack-chef,master,If780398073eb2b4a8d8fc865c15179a677d2e42e,Fix typo in openstack-bare-metal databag,MERGED,2020-01-15 21:20:33.000000000,2020-01-16 01:21:10.000000000,2020-01-16 01:20:01.000000000,"[{'_account_id': 21961}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 21:20:33.000000000', 'files': ['data_bags/service_passwords/openstack-bare-metal.json'], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/e536f52ba24c979287d9b70f851a04e9490d8827', 'message': ""Fix typo in openstack-bare-metal databag\n\nIt used 'openstac-bare-metal' instead of 'openstack-bare-metal'.\n\nChange-Id: If780398073eb2b4a8d8fc865c15179a677d2e42e\n""}]",0,702751,e536f52ba24c979287d9b70f851a04e9490d8827,11,2,1,21961,,,0,"Fix typo in openstack-bare-metal databag

It used 'openstac-bare-metal' instead of 'openstack-bare-metal'.

Change-Id: If780398073eb2b4a8d8fc865c15179a677d2e42e
",git fetch https://review.opendev.org/openstack/openstack-chef refs/changes/51/702751/1 && git format-patch -1 --stdout FETCH_HEAD,['data_bags/service_passwords/openstack-bare-metal.json'],1,e536f52ba24c979287d9b70f851a04e9490d8827,bare-metal-databag-typo," ""openstack-bare-metal"": { ""encrypted_data"": ""XungldtBZTJXKXxUezYe45a0dozxLgsXMA==\n"", ""iv"": ""s3SrfIFb7qQv44gA\n"", ""auth_tag"": ""tAIA0ww4wqCDWxpY3otvEQ==\n"",} "," ""openstac-bare-metal"": { ""encrypted_data"": ""V3TjN0VM+M5h0gCFyFRQqQZc8zYFTeWaYg==\n"", ""iv"": ""oDSNcsfcj6Db298Z\n"", ""auth_tag"": ""NSpX3UCs//hoNttc2SCh7g==\n"",}",5,5
openstack%2Fcyborg~master~Icb5281756d77117fb28139b9cc720b055e481290,openstack/cyborg,master,Icb5281756d77117fb28139b9cc720b055e481290,Set ignore_basepython_conflict (fixes confusing pep8 message),MERGED,2019-11-27 19:42:04.000000000,2020-01-16 01:01:02.000000000,2020-01-16 00:59:35.000000000,"[{'_account_id': 14070}, {'_account_id': 14131}, {'_account_id': 21672}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 28748}]","[{'number': 1, 'created': '2019-11-27 19:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/488c5fa769e586dd65d9e088a4ab384bb2f7efd2', 'message': 'WIP: Set ignore_basepython_conflict (and run pep8)\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nThe lack thereof was causing pep8 to be skipped in the gate.\n\nChange-Id: Icb5281756d77117fb28139b9cc720b055e481290\n'}, {'number': 2, 'created': '2019-11-27 20:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f07ce8d51e066af124c8ce94beee82066c614936', 'message': 'WIP: Set ignore_basepython_conflict (and run pep8)\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nThe lack thereof was causing pep8 to be skipped in the gate.\n\nChange-Id: Icb5281756d77117fb28139b9cc720b055e481290\n'}, {'number': 3, 'created': '2019-11-27 21:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/5110b325212d749ec9e59f3a015d2e339a947c43', 'message': ""Set ignore_basepython_conflict (fixes confusing pep8 message)\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nThe lack thereof was causing pep8 jobs in the gate to output lines like:\n\n   pep8: skipped tests\n   congratulations :)\n /usr/local/lib/python3.6/dist-packages/tox/config/__init__.py:582: UserWarning: conflicting basepython version (set 3.6, should be 3.7) for env 'py37';resolve conflict or set ignore_basepython_conflict\n   proposed_version, implied_version, testenv_config.envname\n\n...despite the fact that the job was actually running.\n\nChange-Id: Icb5281756d77117fb28139b9cc720b055e481290\n""}, {'number': 4, 'created': '2019-11-27 21:16:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/d496229f13b256f71e9faa2ce66e1c9d0c104d01', 'message': ""Set ignore_basepython_conflict (fixes confusing pep8 message)\n\nAutomatic envs (pyXX) will only use the python version appropriate to\nthat env and ignore basepython inherited from [testenv] if we set\nignore_basepython_conflict.\n\nThe lack thereof was causing pep8 jobs in the gate to output lines like:\n\n   pep8: skipped tests\n   congratulations :)\n /usr/local/lib/python3.6/dist-packages/tox/config/__init__.py:582: UserWarning: conflicting basepython version (set 3.6, should be 3.7) for env 'py37';resolve conflict or set ignore_basepython_conflict\n   proposed_version, implied_version, testenv_config.envname\n\n...despite the fact that the job was actually running.\n\nChange-Id: Icb5281756d77117fb28139b9cc720b055e481290\n""}]",0,696397,d496229f13b256f71e9faa2ce66e1c9d0c104d01,24,7,4,14070,,,0,"Set ignore_basepython_conflict (fixes confusing pep8 message)

Automatic envs (pyXX) will only use the python version appropriate to
that env and ignore basepython inherited from [testenv] if we set
ignore_basepython_conflict.

The lack thereof was causing pep8 jobs in the gate to output lines like:

   pep8: skipped tests
   congratulations :)
 /usr/local/lib/python3.6/dist-packages/tox/config/__init__.py:582: UserWarning: conflicting basepython version (set 3.6, should be 3.7) for env 'py37';resolve conflict or set ignore_basepython_conflict
   proposed_version, implied_version, testenv_config.envname

...despite the fact that the job was actually running.

Change-Id: Icb5281756d77117fb28139b9cc720b055e481290
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/97/696397/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,488c5fa769e586dd65d9e088a4ab384bb2f7efd2,ignore_basepython_conflict,# Automatic envs (pyXX) will only use the python version appropriate to that # env and ignore basepython inherited from [testenv] if we set # ignore_basepython_conflict. ignore_basepython_conflict = True,,4,0
openstack%2Fnova~master~Id80fd1f68c0bb3b2d3af6e139b3d163acaef081d,openstack/nova,master,Id80fd1f68c0bb3b2d3af6e139b3d163acaef081d,libvirt: Remove MIN_QEMU_FILE_BACKED_DISCARD_VERSION,MERGED,2019-11-25 14:17:16.000000000,2020-01-16 01:00:23.000000000,2020-01-16 00:58:15.000000000,"[{'_account_id': 6962}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-25 14:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa52e421cb5e6592881b1b3466d3277e8580f167', 'message': 'libvirt: Remove MIN_QEMU_FILE_BACKED_DISCARD_VERSION\n\nThe updated minimum required libvirt (5.0.0) and QEMU (4.0.0) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the version constant MIN_QEMU_FILE_BACKED_DISCARD_VERSION and\nnow-needless compatibility code; adjust/remove tests.\n\nChange-Id: Id80fd1f68c0bb3b2d3af6e139b3d163acaef081d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2019-12-06 14:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f65cfa593da9ccf4d7ac0b0045b3ceeea3bcc0f0', 'message': 'libvirt: Remove MIN_QEMU_FILE_BACKED_DISCARD_VERSION\n\nThe updated minimum required libvirt (4.0.0) and QEMU (2.11) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the version constant MIN_QEMU_FILE_BACKED_DISCARD_VERSION and\nnow-needless compatibility code; adjust/remove tests.\n\nChange-Id: Id80fd1f68c0bb3b2d3af6e139b3d163acaef081d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2019-12-10 09:00:06.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e59a5fee47fdfdaaa262d333b3642de4b4caa57d', 'message': 'libvirt: Remove MIN_QEMU_FILE_BACKED_DISCARD_VERSION\n\nThe updated minimum required QEMU (2.11) for ""Ussuri"" satisfy the\nversion requirement; this was done in Change-Id: Ia18e9be4d (22c1916b49\n libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for ""Ussuri"", 2019-11-19).\n\nDrop the version constant MIN_QEMU_FILE_BACKED_DISCARD_VERSION and\nnow-needless compatibility code; adjust/remove tests.\n\nChange-Id: Id80fd1f68c0bb3b2d3af6e139b3d163acaef081d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",3,695915,e59a5fee47fdfdaaa262d333b3642de4b4caa57d,42,11,3,6962,,,0,"libvirt: Remove MIN_QEMU_FILE_BACKED_DISCARD_VERSION

The updated minimum required QEMU (2.11) for ""Ussuri"" satisfy the
version requirement; this was done in Change-Id: Ia18e9be4d (22c1916b49
 libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for ""Ussuri"", 2019-11-19).

Drop the version constant MIN_QEMU_FILE_BACKED_DISCARD_VERSION and
now-needless compatibility code; adjust/remove tests.

Change-Id: Id80fd1f68c0bb3b2d3af6e139b3d163acaef081d
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/695915/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,aa52e421cb5e6592881b1b3466d3277e8580f167,Bump_min_libvirt_and_QEMU_for_Ussuri," mock_lib_version): mock_lib_version): self, libvirt_version, mock_cpu, mock_test_file, mock_lib_version): libvirt_version) libvirt_version)"," @mock.patch.object(fakelibvirt.Connection, 'getVersion') mock_lib_version, mock_version): mock_version.return_value = versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_DISCARD_VERSION) @mock.patch.object(fakelibvirt.Connection, 'getVersion') mock_lib_version, mock_version): mock_version.return_value = versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_DISCARD_VERSION) result = self._test_get_guest_memory_backing_config( None, None, None ) self.assertFalse(result.discard) @mock.patch.object(fakelibvirt.Connection, 'getVersion') @mock.patch.object(fakelibvirt.Connection, 'getLibVersion') def test_get_guest_memory_backing_config_file_backed_discard_qemu(self, mock_lib_version, mock_version): self.flags(file_backed_memory=1024, group='libvirt') mock_lib_version.return_value = versionutils.convert_version_to_int( libvirt_driver.MIN_LIBVIRT_FILE_BACKED_DISCARD_VERSION) mock_version.return_value = versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_DISCARD_VERSION) - 1 @mock.patch.object(fakelibvirt.Connection, 'getVersion') self, libvirt_version, qemu_version, mock_cpu, mock_test_file, mock_lib_version, mock_version): mock_version.return_value = qemu_version qemu_version = versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_DISCARD_VERSION) libvirt_version, qemu_version) qemu_version = versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_DISCARD_VERSION) libvirt_version, qemu_version) self.assertTrue(data.dst_wants_file_backed_memory) self.assertFalse(data.file_backed_memory_discard) def test_check_can_live_migrate_dest_file_backed_discard_bad_qemu(self): libvirt_version = versionutils.convert_version_to_int( libvirt_driver.MIN_LIBVIRT_FILE_BACKED_DISCARD_VERSION) qemu_version = versionutils.convert_version_to_int( libvirt_driver.MIN_QEMU_FILE_BACKED_DISCARD_VERSION) - 1 data = self._test_check_can_live_migrate_dest_file_backed_discard( libvirt_version, qemu_version)",9,51
openstack%2Frequirements~master~I93ddb63ee40c2711419dd56e8828cf631ba6012b,openstack/requirements,master,I93ddb63ee40c2711419dd56e8828cf631ba6012b,update constraint for osc-lib to new release 2.0.0,MERGED,2020-01-14 17:07:44.000000000,2020-01-16 00:59:52.000000000,2020-01-16 00:58:09.000000000,"[{'_account_id': 11628}, {'_account_id': 11904}, {'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 17:07:44.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/457e4784c57a43e4286ed0609921a16ff70fc4e6', 'message': 'update constraint for osc-lib to new release 2.0.0\n\nChange-Id: I93ddb63ee40c2711419dd56e8828cf631ba6012b\nmeta:version: 2.0.0\nmeta:diff-start: -\nmeta:series: ussuri\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Eric Fried <openstack@fried.cc>\nmeta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Change-Id: Ifd777ec06e7fa3e4a3247d66ce3c2f848ca8ba9b\nmeta:release:Code-Review+1: Eric Fried <openstack@fried.cc>\nmeta:release:Code-Review+1: Dean Troyer <dtroyer@gmail.com>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,702483,457e4784c57a43e4286ed0609921a16ff70fc4e6,10,5,1,11131,,,0,"update constraint for osc-lib to new release 2.0.0

Change-Id: I93ddb63ee40c2711419dd56e8828cf631ba6012b
meta:version: 2.0.0
meta:diff-start: -
meta:series: ussuri
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Eric Fried <openstack@fried.cc>
meta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Change-Id: Ifd777ec06e7fa3e4a3247d66ce3c2f848ca8ba9b
meta:release:Code-Review+1: Eric Fried <openstack@fried.cc>
meta:release:Code-Review+1: Dean Troyer <dtroyer@gmail.com>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/83/702483/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,457e4784c57a43e4286ed0609921a16ff70fc4e6,new-release,osc-lib===2.0.0,osc-lib===1.15.0,1,1
openstack%2Fneutron~stable%2Ftrain~I10e3619d5f3600ea97ed695321bb691dece3181f,openstack/neutron,stable/train,I10e3619d5f3600ea97ed695321bb691dece3181f,Add retries to update trunk port,MERGED,2020-01-14 08:06:15.000000000,2020-01-16 00:59:52.000000000,2020-01-16 00:58:05.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-01-14 08:06:15.000000000', 'files': ['neutron/services/trunk/rpc/server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ec0c2d8658acd6fb0aaf80751914514bdb42334', 'message': 'Add retries to update trunk port\n\nIn [1] retry of trunk update was added to avoid StaleDataError\nexceptions to fail to set trunk port or subports to ACTIVE state.\nBut it was only partial fix for the issue descibed in related bug\nand from [2] we know that it still can happen on high load systems\nfrom time to time.\nSo I was checking this issue and reported bug again and I found out\nthat retry was added only in _process_trunk_subport_bindings()\nmethod. But StaleDataError can be raised also in other cases where\nthe same trunk is updated, e.g. in update_trunk_status() method.\n\nSo this commit adds same retry mechanism to all trunk.update() actions\nin services.trunk.rpc.server module.\n\n[1] https://review.opendev.org/#/c/662236/\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1733197\n\nChange-Id: I10e3619d5f3600ea97ed695321bb691dece3181f\nPartial-Bug: #1828375\n(cherry picked from commit ade35a233edb5c9489cc3a68ae00672fb328f63d)\n'}]",0,702363,8ec0c2d8658acd6fb0aaf80751914514bdb42334,16,6,1,11975,,,0,"Add retries to update trunk port

In [1] retry of trunk update was added to avoid StaleDataError
exceptions to fail to set trunk port or subports to ACTIVE state.
But it was only partial fix for the issue descibed in related bug
and from [2] we know that it still can happen on high load systems
from time to time.
So I was checking this issue and reported bug again and I found out
that retry was added only in _process_trunk_subport_bindings()
method. But StaleDataError can be raised also in other cases where
the same trunk is updated, e.g. in update_trunk_status() method.

So this commit adds same retry mechanism to all trunk.update() actions
in services.trunk.rpc.server module.

[1] https://review.opendev.org/#/c/662236/
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1733197

Change-Id: I10e3619d5f3600ea97ed695321bb691dece3181f
Partial-Bug: #1828375
(cherry picked from commit ade35a233edb5c9489cc3a68ae00672fb328f63d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/702363/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/rpc/server.py'],1,8ec0c2d8658acd6fb0aaf80751914514bdb42334,bug/1828375-stable/train," def _safe_update_trunk(self, trunk, **kwargs): trunk.update(**kwargs) def update_trunk_status(self, context, trunk_id, status): """"""Update the trunk status to reflect outcome of data plane wiring."""""" with db_api.CONTEXT_WRITER.using(context): trunk = trunk_objects.Trunk.get_object(context, id=trunk_id) if trunk: self._safe_update_trunk(trunk, status=status) def _process_trunk_subport_bindings(self, context, trunk, port_ids): """"""Process port bindings for subports on the given trunk."""""" updated_ports = [] trunk_port_id = trunk.port_id trunk_port = self.core_plugin.get_port(context, trunk_port_id) trunk_host = trunk_port.get(portbindings.HOST_ID) # NOTE(status_police) Set the trunk in BUILD state before # processing subport bindings. The trunk will stay in BUILD # state until an attempt has been made to bind all subports # passed here and the agent acknowledges the operation was # successful. self._safe_update_trunk( trunk, status=trunk_consts.TRUNK_BUILD_STATUS) self._safe_update_trunk( trunk, status=trunk_consts.TRUNK_ERROR_STATUS) self._safe_update_trunk( trunk, status=trunk_consts.TRUNK_DEGRADED_STATUS)"," def update_trunk_status(self, context, trunk_id, status): """"""Update the trunk status to reflect outcome of data plane wiring."""""" with db_api.CONTEXT_WRITER.using(context): trunk = trunk_objects.Trunk.get_object(context, id=trunk_id) if trunk: trunk.update(status=status) def _process_trunk_subport_bindings(self, context, trunk, port_ids): """"""Process port bindings for subports on the given trunk."""""" updated_ports = [] trunk_port_id = trunk.port_id trunk_port = self.core_plugin.get_port(context, trunk_port_id) trunk_host = trunk_port.get(portbindings.HOST_ID) # NOTE(status_police) Set the trunk in BUILD state before # processing subport bindings. The trunk will stay in BUILD # state until an attempt has been made to bind all subports # passed here and the agent acknowledges the operation was # successful. trunk.update(status=trunk_consts.TRUNK_BUILD_STATUS) trunk.update(status=trunk_consts.TRUNK_ERROR_STATUS) trunk.update(status=trunk_consts.TRUNK_DEGRADED_STATUS)",28,22
openstack%2Fdevstack~master~I9f9160f5a2bf9fd77fb3807e12de219b7a49952d,openstack/devstack,master,I9f9160f5a2bf9fd77fb3807e12de219b7a49952d,Don't install glance default policy,MERGED,2019-11-14 19:04:44.000000000,2020-01-16 00:59:34.000000000,2020-01-16 00:58:07.000000000,"[{'_account_id': 4257}, {'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-11-14 19:04:44.000000000', 'files': ['lib/glance'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0e02e7fd55276678ba839a098896b6142363147c', 'message': ""Don't install glance default policy\n\nWith Glance defining default policies in code, it's no longer necessary\nto install policy.json from the repo.\n\nChange-Id: I9f9160f5a2bf9fd77fb3807e12de219b7a49952d\nDepends-On: https://review.opendev.org/693129\n""}]",0,694386,0e02e7fd55276678ba839a098896b6142363147c,18,6,1,4257,,,0,"Don't install glance default policy

With Glance defining default policies in code, it's no longer necessary
to install policy.json from the repo.

Change-Id: I9f9160f5a2bf9fd77fb3807e12de219b7a49952d
Depends-On: https://review.opendev.org/693129
",git fetch https://review.opendev.org/openstack/devstack refs/changes/86/694386/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/glance'],1,0e02e7fd55276678ba839a098896b6142363147c,,,GLANCE_POLICY_JSON=$GLANCE_CONF_DIR/policy.json cp -p $GLANCE_DIR/etc/policy.json $GLANCE_POLICY_JSON,0,2
openstack%2Fpython-swiftclient~master~Ifdeefeb4a5a3fc6895bd6cda695684de02f8c602,openstack/python-swiftclient,master,Ifdeefeb4a5a3fc6895bd6cda695684de02f8c602,Add test for bulk-delete-attempt-counter fix,MERGED,2019-11-15 22:10:40.000000000,2020-01-16 00:59:28.000000000,2020-01-16 00:58:12.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 31293}]","[{'number': 1, 'created': '2019-11-15 22:10:40.000000000', 'files': ['swiftclient/shell.py', 'test/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e83cd32e2af26ecb9ac9520ac2958f186ba1888c', 'message': 'Add test for bulk-delete-attempt-counter fix\n\nChange-Id: Ifdeefeb4a5a3fc6895bd6cda695684de02f8c602\nRelated-Change: If4af9141fe4f3436a4e9e0e2dfc24c6ec7292996\nRelated-Bug: #1852808\n'}]",3,694635,e83cd32e2af26ecb9ac9520ac2958f186ba1888c,11,3,1,15343,,,0,"Add test for bulk-delete-attempt-counter fix

Change-Id: Ifdeefeb4a5a3fc6895bd6cda695684de02f8c602
Related-Change: If4af9141fe4f3436a4e9e0e2dfc24c6ec7292996
Related-Bug: #1852808
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/35/694635/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'test/unit/test_shell.py']",2,e83cd32e2af26ecb9ac9520ac2958f186ba1888c,bug/1852808," with CaptureOutput() as out: swiftclient.shell.main(argv) self.assertEqual('object\n', out.out) @mock.patch.object(swiftclient.service.SwiftService, '_bulk_delete_page_size', lambda *a: 10) @mock.patch('swiftclient.service.Connection') def test_delete_bulk_object_with_retry(self, connection): argv = ["""", ""delete"", ""container"", ""object""] connection.return_value.post_account.return_value = {}, ( b'{""Number Not Found"": 0, ""Response Status"": ""200 OK"", ' b'""Errors"": [], ""Number Deleted"": 1, ""Response Body"": """"}') connection.return_value.attempts = 3 with CaptureOutput() as out: swiftclient.shell.main(argv) connection.return_value.post_account.assert_called_with( query_string='bulk-delete', data=b'/container/object\n', headers={'Content-Type': 'text/plain', 'Accept': 'application/json'}, response_dict={}) self.assertEqual('object [after 3 attempts]\n', out.out)", swiftclient.shell.main(argv),22,2
openstack%2Frequirements~stable%2Ftrain~Ifb805954ff36420004d552a690046d8ddf3bed5c,openstack/requirements,stable/train,Ifb805954ff36420004d552a690046d8ddf3bed5c,demarcate python-memcached requirements,MERGED,2020-01-14 15:19:12.000000000,2020-01-16 00:58:10.000000000,2020-01-16 00:58:10.000000000,"[{'_account_id': 1916}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 15:19:12.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9d1b803c4c7a7daa7ff64a13832f49a8e40f2b08', 'message': ""demarcate python-memcached requirements\n\nTo support Python3, we need python-memcached 1.58 or above. However,\nprojects such as keystonemiddleware[1] have python-memcached 1.56\nin its lower-constraints.txt. For stable/stein, Python3 is now the\ndefult[2]. However, we generally avoid changing lower constraints in\nthe stable branches so we don't inadvertently break the downstream\nconsumers. Therefore, we need to separate python-memcached requirement\nfor the respective python versions.\n\n[1] https://github.com/openstack/keystonemiddleware/blob/stable/stein/lower-constraints.txt#L61\n[2] https://governance.openstack.org/tc/goals/selected/stein/python3-first.html\n\nChange-Id: Ifb805954ff36420004d552a690046d8ddf3bed5c\n""}]",0,702460,9d1b803c4c7a7daa7ff64a13832f49a8e40f2b08,8,4,1,11904,,,0,"demarcate python-memcached requirements

To support Python3, we need python-memcached 1.58 or above. However,
projects such as keystonemiddleware[1] have python-memcached 1.56
in its lower-constraints.txt. For stable/stein, Python3 is now the
defult[2]. However, we generally avoid changing lower constraints in
the stable branches so we don't inadvertently break the downstream
consumers. Therefore, we need to separate python-memcached requirement
for the respective python versions.

[1] https://github.com/openstack/keystonemiddleware/blob/stable/stein/lower-constraints.txt#L61
[2] https://governance.openstack.org/tc/goals/selected/stein/python3-first.html

Change-Id: Ifb805954ff36420004d552a690046d8ddf3bed5c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/60/702460/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,9d1b803c4c7a7daa7ff64a13832f49a8e40f2b08,constrain_python_memcached,python-memcached>1.55;python_version=='2.7' # PSF python-memcached>1.57;python_version>='3.4' # PSF,python-memcached # PSF,2,1
openstack%2Fopenstack-ansible-os_horizon~stable%2Fstein~I1625cd0140c04ac7bfc45575dffeda22358b4fc7,openstack/openstack-ansible-os_horizon,stable/stein,I1625cd0140c04ac7bfc45575dffeda22358b4fc7,Make use of horizon_git_track_branch,MERGED,2020-01-14 16:10:40.000000000,2020-01-16 00:51:11.000000000,2020-01-16 00:49:54.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-01-14 16:10:40.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/4bcdd2cc089e71ea7e8b8f6826b6136af3b42b73', 'message': 'Make use of horizon_git_track_branch\n\nThis patch aims to make use of horizon_git_track_branch\ninstead of hardcoding branches to repos we eventually use\nfor service dashboards.\n\nChange-Id: I1625cd0140c04ac7bfc45575dffeda22358b4fc7\n'}]",0,702467,4bcdd2cc089e71ea7e8b8f6826b6136af3b42b73,12,4,1,28619,,,0,"Make use of horizon_git_track_branch

This patch aims to make use of horizon_git_track_branch
instead of hardcoding branches to repos we eventually use
for service dashboards.

Change-Id: I1625cd0140c04ac7bfc45575dffeda22358b4fc7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/67/702467/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,4bcdd2cc089e71ea7e8b8f6826b6136af3b42b73,dashboards_branch,"horizon_git_repo: https://opendev.org/openstack/horizon horizon_git_track_branch: master horizon_git_install_branch: ""{{ horizon_git_track_branch }}""blazar_dashboard_git_repo: https://opendev.org/openstack/blazar-dashboard blazar_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""cloudkitty_dashboard_git_repo: https://opendev.org/openstack/cloudkitty-dashboard cloudkitty_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""magnum_dashboard_git_repo: https://opendev.org/openstack/magnum-ui magnum_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""manila_dashboard_git_repo: https://opendev.org/openstack/manila-ui.git manila_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""masakari_dashboard_git_repo: https://opendev.org/openstack/masakari-dashboard masakari_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""mistral_dashboard_git_repo: https://opendev.org/openstack/mistral-dashboard.git mistral_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""octavia_dashboard_git_repo: https://opendev.org/openstack/octavia-dashboard octavia_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""designate_dashboard_git_repo: https://opendev.org/openstack/designate-dashboard designate_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""tacker_dashboard_git_repo: https://opendev.org/openstack/tacker-horizon tacker_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""trove_dashboard_git_repo: https://opendev.org/openstack/trove-dashboard trove_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""heat_dashboard_git_repo: https://opendev.org/openstack/heat-dashboard heat_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""watcher_dashboard_git_repo: https://opendev.org/openstack/watcher-dashboard watcher_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""zun_dashboard_git_repo: https://opendev.org/openstack/zun-ui zun_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""neutron_vpnaas_dashboard_git_repo: https://opendev.org/openstack/neutron-vpnaas-dashboard neutron_vpnaas_dashboard_git_install_branch: ""{{ horizon_git_track_branch }}""",horizon_git_repo: https://git.openstack.org/openstack/horizon horizon_git_install_branch: masterblazar_dashboard_git_repo: https://git.openstack.org/openstack/blazar-dashboard blazar_dashboard_git_install_branch: mastercloudkitty_dashboard_git_repo: https://git.openstack.org/openstack/cloudkitty-dashboard cloudkitty_dashboard_git_install_branch: mastermagnum_dashboard_git_repo: https://git.openstack.org/openstack/magnum-ui magnum_dashboard_git_install_branch: mastermanila_dashboard_git_repo: https://git.openstack.org/openstack/manila-ui.git manila_dashboard_git_install_branch: mastermasakari_dashboard_git_repo: https://git.openstack.org/openstack/masakari-dashboard masakari_dashboard_git_install_branch: mastermistral_dashboard_git_repo: https://git.openstack.org/openstack/mistral-dashboard.git mistral_dashboard_git_install_branch: masteroctavia_dashboard_git_repo: https://git.openstack.org/openstack/octavia-dashboard octavia_dashboard_git_install_branch: masterdesignate_dashboard_git_repo: https://git.openstack.org/openstack/designate-dashboard designate_dashboard_git_install_branch: mastertacker_dashboard_git_repo: https://git.openstack.org/openstack/tacker-horizon tacker_dashboard_git_install_branch: mastertrove_dashboard_git_repo: https://git.openstack.org/openstack/trove-dashboard trove_dashboard_git_install_branch: masterheat_dashboard_git_repo: https://git.openstack.org/openstack/heat-dashboard heat_dashboard_git_install_branch: masterwatcher_dashboard_git_repo: https://git.openstack.org/openstack/watcher-dashboard watcher_dashboard_git_install_branch: masterzun_dashboard_git_repo: https://git.openstack.org/openstack/zun-ui zun_dashboard_git_install_branch: masterneutron_vpnaas_dashboard_git_repo: https://git.openstack.org/openstack/neutron-vpnaas-dashboard neutron_vpnaas_dashboard_git_install_branch: master,31,30
openstack%2Ftripleo-ansible~master~Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c,openstack/tripleo-ansible,master,Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c,Remove dracut-config-generic package,MERGED,2020-01-13 08:16:00.000000000,2020-01-16 00:50:23.000000000,2020-01-15 17:05:25.000000000,"[{'_account_id': 6681}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 17823}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25613}, {'_account_id': 25877}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-01-13 08:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c855f03ae985110100ff163335873b8e68098b24', 'message': ""Remove dracut-config-generic package\n\nIn LP#1830574, we introduce the dracut command to include necessary\nfile into initramfs. However, dracut in RHEL or CentOS doesn't include\nsysctl.conf or other specific module related confs at an installation\nof new kernel if dracut-config-generic package exists on the system.\n\nWe should remove the package to allow creating a host-specific initramfs\nat an installation of new kernel.\n\nCloses-bug: #1857493\n\nChange-Id: Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c\nCo-Authored-By: Keigo Noha <knoha@redhat.com>\n""}, {'number': 2, 'created': '2020-01-13 15:57:32.000000000', 'files': ['tripleo_ansible/roles/tripleo-kernel/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4586da96b4aab1cbbe22bb4619025dcfb03ab899', 'message': ""Remove dracut-config-generic package\n\nIn LP#1830574, we introduce the dracut command to include necessary\nfile into initramfs. However, dracut in RHEL or CentOS doesn't include\nsysctl.conf or other specific module related confs at an installation\nof new kernel if dracut-config-generic package exists on the system.\n\nWe should remove the package to allow creating a host-specific initramfs\nat an installation of new kernel.\n\nCloses-bug: #1857493\n\nChange-Id: Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c\nCo-Authored-By: Keigo Noha <knoha@redhat.com>\n""}]",2,702169,4586da96b4aab1cbbe22bb4619025dcfb03ab899,25,11,2,31245,,,0,"Remove dracut-config-generic package

In LP#1830574, we introduce the dracut command to include necessary
file into initramfs. However, dracut in RHEL or CentOS doesn't include
sysctl.conf or other specific module related confs at an installation
of new kernel if dracut-config-generic package exists on the system.

We should remove the package to allow creating a host-specific initramfs
at an installation of new kernel.

Closes-bug: #1857493

Change-Id: Ib57f9f4c71c0da3b2c28ef17c1c8792711f9973c
Co-Authored-By: Keigo Noha <knoha@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/69/702169/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-kernel/tasks/main.yml'],1,c855f03ae985110100ff163335873b8e68098b24,1857493-remove_dracut_config_generic, - name: Remove dracut-config-generic package: name: 'dracut-config-generic' state: absent ,,5,0
openstack%2Fansible-role-collect-logs~master~Ibe71c1e209490d9b0656524814f750fd99105f69,openstack/ansible-role-collect-logs,master,Ibe71c1e209490d9b0656524814f750fd99105f69,Fix netns listing on network logs collection,MERGED,2020-01-14 13:51:42.000000000,2020-01-16 00:49:05.000000000,2020-01-16 00:49:05.000000000,"[{'_account_id': 3153}, {'_account_id': 5756}, {'_account_id': 9592}, {'_account_id': 11952}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-14 13:51:42.000000000', 'files': ['tasks/collect/network.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/460bfd5268f7600ca73d25598557e4fdf5ab4c90', 'message': 'Fix netns listing on network logs collection\n\nThe output of \'ip netns list\' can include additional information\nsuch as the id (0). This will make the ansible role to\noutput garbage (1). This patch fixes it by parsing just the first\nfield of the command output.\n\n(0):\n$ ip netns list\nqdhcp-8b08833a-20dc-4188-8e65-8a2d47b295e7 (id: 0)\n\n(1):\nCannot open network namespace ""(id:"": No such file or directory\n\nChange-Id: Ibe71c1e209490d9b0656524814f750fd99105f69\nSigned-off-by: Daniel Alvarez <dalvarez@redhat.com>\n'}]",0,702430,460bfd5268f7600ca73d25598557e4fdf5ab4c90,10,7,1,23804,,,0,"Fix netns listing on network logs collection

The output of 'ip netns list' can include additional information
such as the id (0). This will make the ansible role to
output garbage (1). This patch fixes it by parsing just the first
field of the command output.

(0):
$ ip netns list
qdhcp-8b08833a-20dc-4188-8e65-8a2d47b295e7 (id: 0)

(1):
Cannot open network namespace ""(id:"": No such file or directory

Change-Id: Ibe71c1e209490d9b0656524814f750fd99105f69
Signed-off-by: Daniel Alvarez <dalvarez@redhat.com>
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/30/702430/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/collect/network.yml'],1,460bfd5268f7600ca73d25598557e4fdf5ab4c90,," (for NS in $(ip netns list | cut -f 1 -d "" ""); do", (for NS in $(ip netns list); do,1,1
openstack%2Fcharm-neutron-openvswitch~master~I718945e6eeee58e7e9f76c3e88a29e6420da7acd,openstack/charm-neutron-openvswitch,master,I718945e6eeee58e7e9f76c3e88a29e6420da7acd,Migrate neutron-openvswitch tests to Zaza,MERGED,2019-12-26 23:36:00.000000000,2020-01-16 00:26:50.000000000,2020-01-16 00:26:50.000000000,"[{'_account_id': 9247}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-26 23:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/518bec1a8feff44d0b85c20df4eacc50761b8060', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 2, 'created': '2019-12-28 02:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/8b568ad7b0aa30705c1b2367b95885db74813212', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 3, 'created': '2020-01-09 11:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/9358e1c6dc90b608e4a5f7818a54a8c9c84c3eaf', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 4, 'created': '2020-01-10 15:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/51042e22be425f013ae0ed882e8756c357cbe3eb', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 5, 'created': '2020-01-10 16:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/6c5cfd2dfc2df9ebcc0cd9913320852d76afc37c', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 6, 'created': '2020-01-13 07:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/f4689b2501c11cb036b4e0166793bb91d937763a', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 7, 'created': '2020-01-13 08:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/ddc468590d15f2bff49b927a638e0595a99e1ee9', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 8, 'created': '2020-01-14 08:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/2c105c90dafccf5e52f16f95684b29a4c84e8510', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 9, 'created': '2020-01-14 09:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/aa20de27976666db812844020906e1a959427d97', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}, {'number': 10, 'created': '2020-01-14 20:28:31.000000000', 'files': ['tests/gate-basic-xenial-pike', 'tests/bundles/xenial_mitaka.yaml', 'test-requirements.txt', 'Makefile', 'tests/bundles/bionic_queens.yaml', 'tests/gate-basic-trusty-mitaka', 'tests/bundles/bionic_rocky.yaml', 'tests/README.md', 'tests/gate-basic-xenial-mitaka', 'tests/gate-basic-bionic-stein', 'tests/gate-basic-xenial-ocata', 'tests/bundles/disco_stein.yaml', 'tests/gate-basic-disco-stein', 'tests/bundles/xenial_queens.yaml', 'tests/bundles/bionic_train.yaml', 'tests/gate-basic-bionic-train', 'tests/bundles/xenial_ocata.yaml', 'tests/bundles/bionic_stein.yaml', 'tests/tests.yaml', 'tests/basic_deployment.py', 'tests/dev-basic-cosmic-rocky', 'tests/gate-basic-bionic-queens', 'tests/gate-basic-xenial-queens', 'tests/bundles/trusty_mitaka.yaml', 'tests/gate-basic-bionic-rocky', 'tox.ini', 'tests/bundles/xenial_pike.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/b3930738fb002c08b260b7ed95e61849f9432460', 'message': 'Migrate neutron-openvswitch tests to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149\n\nChange-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd\nCloses-Bug: #1828424\n'}]",1,700659,b3930738fb002c08b260b7ed95e61849f9432460,50,4,10,9247,,,0,"Migrate neutron-openvswitch tests to Zaza

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/149

Change-Id: I718945e6eeee58e7e9f76c3e88a29e6420da7acd
Closes-Bug: #1828424
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/59/700659/10 && git format-patch -1 --stdout FETCH_HEAD,"['tests/gate-basic-xenial-pike', 'tests/bundles/xenial_mitaka.yaml', 'test-requirements.txt', 'Makefile', 'tests/bundles/bionic_queens.yaml', 'tests/gate-basic-trusty-mitaka', 'tests/bundles/bionic_rocky.yaml', 'tests/README.md', 'tests/gate-basic-xenial-mitaka', 'tests/gate-basic-bionic-stein', 'tests/gate-basic-xenial-ocata', 'tests/bundles/disco_stein.yaml', 'tests/gate-basic-disco-stein', 'tests/bundles/xenial_queens.yaml', 'tests/bundles/bionic_train.yaml', 'tests/gate-basic-bionic-train', 'tests/bundles/xenial_ocata.yaml', 'tests/bundles/bionic_stein.yaml', 'tests/tests.yaml', 'tests/basic_deployment.py', 'tests/dev-basic-cosmic-rocky', 'tests/gate-basic-bionic-queens', 'tests/gate-basic-xenial-queens', 'tests/bundles/trusty_mitaka.yaml', 'tests/gate-basic-bionic-rocky', 'tox.ini', 'tests/bundles/xenial_pike.yaml']",27,518bec1a8feff44d0b85c20df4eacc50761b8060,bug/1828424,series: xenial machines: '0': constraints: mem=3072M '1': '2': '3': '4': '5': '6': applications: nova-compute: charm: cs:~openstack-charmers-next/nova-compute num_units: 1 to: - '1' nova-cloud-controller: charm: cs:~openstack-charmers-next/nova-cloud-controller num_units: 1 options: network-manager: Neutron openstack-origin: cloud:xenial-pike to: - '2' rabbitmq-server: charm: cs:~openstack-charmers-next/rabbitmq-server num_units: 1 to: - '3' keystone: num_units: 1 charm: cs:~openstack-charmers-next/keystone num_units: 1 options: openstack-origin: cloud:xenial-pike to: - '4' glance: charm: cs:~openstack-charmers-next/glance num_units: 1 options: openstack-origin: cloud:xenial-pike to: - '5' neutron-api: charm: cs:~openstack-charmers-next/neutron-api num_units: 1 options: openstack-origin: cloud:xenial-pike to: - '6' percona-cluster: charm: cs:~openstack-charmers-next/percona-cluster num_units: 1 to: - '0' neutron-openvswitch: charm: ../../../neutron-openvswitch options: enable-sriov: True sriov-device-mappings: physnet42:eth42 relations: - - 'neutron-openvswitch:amqp' - 'rabbitmq-server:amqp' - - 'neutron-openvswitch:neutron-plugin' - 'nova-compute:neutron-plugin' - - 'neutron-openvswitch:neutron-plugin-api' - 'neutron-api:neutron-plugin-api' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'neutron-api:shared-db' - 'percona-cluster:shared-db' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:image-service' - 'glance:image-service' - - 'glance:identity-service' - 'keystone:identity-service' - - 'glance:shared-db' - 'percona-cluster:shared-db' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'keystone:shared-db' - 'percona-cluster:shared-db' - - 'nova-cloud-controller:shared-db' - 'percona-cluster:shared-db' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'nova-cloud-controller:image-service' - 'glance:image-service' ,,1024,760
openstack%2Fcharm-nova-compute~master~Ieb196b337cf03eac798124f4da71d1ebb5707253,openstack/charm-nova-compute,master,Ieb196b337cf03eac798124f4da71d1ebb5707253,Updated AppArmor profile to allow vm migration,MERGED,2020-01-14 20:21:17.000000000,2020-01-16 00:23:33.000000000,2020-01-16 00:23:33.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 27623}, {'_account_id': 29201}]","[{'number': 1, 'created': '2020-01-14 20:21:17.000000000', 'files': ['templates/usr.bin.nova-compute'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/73b0eaa7176939bc385dadc1d62e318cde779060', 'message': 'Updated AppArmor profile to allow vm migration\n\nUpdated AppArmor profile usr.bin.nova-compute to allow access to\nrequired resources for vm migration, resizing, and evacuation.\n\nChange-Id: Ieb196b337cf03eac798124f4da71d1ebb5707253\nCloses-Bug: 1846300\nRelated-Bug: 1859236 # Duplicate Bug\n'}]",0,702510,73b0eaa7176939bc385dadc1d62e318cde779060,15,6,1,29201,,,0,"Updated AppArmor profile to allow vm migration

Updated AppArmor profile usr.bin.nova-compute to allow access to
required resources for vm migration, resizing, and evacuation.

Change-Id: Ieb196b337cf03eac798124f4da71d1ebb5707253
Closes-Bug: 1846300
Related-Bug: 1859236 # Duplicate Bug
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/10/702510/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/usr.bin.nova-compute'],1,73b0eaa7176939bc385dadc1d62e318cde779060,bug/1846300," network netlink dgram, /etc/magic r, /sys/devices/virtual/dmi/** r, /usr/sbin/dmidecode rix,",,4,0
openstack%2Fmagnum-ui~stable%2Ftrain~Id3fd3ee80fb27b08673933800aea6e7ee7ac7cd0,openstack/magnum-ui,stable/train,Id3fd3ee80fb27b08673933800aea6e7ee7ac7cd0,Add rolling upgrade ui,MERGED,2019-12-13 11:23:29.000000000,2020-01-16 00:00:05.000000000,2020-01-15 23:57:11.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 30447}]","[{'number': 1, 'created': '2019-12-13 11:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/5328c4b54685cb3b2f5a2e5794fc859ede3f979d', 'message': 'Add rolling upgrade ui\n\n + Create new row action on clusters panel\n + Create new modal form for upgrading cluster\n + Create REST endpoint for upgrading cluster\n + Bump python-magnumclient lower constraint\n\nRegister the Cluster Upgrade view\n\n + Fixes missing url registraion for upgrade cluster\n   in prior patch (https://review.opendev.org/#/c/697000/4).\n\nChange-Id: Id3fd3ee80fb27b08673933800aea6e7ee7ac7cd0\n(cherry picked from commit cd0817a13b58cbd7cb083e15d3467ce9f845ec32)\n(cherry picked from commit d96f4d16c2b3254b290ff5d257340434a6dd6717)\n'}, {'number': 2, 'created': '2019-12-13 11:24:20.000000000', 'files': ['doc/source/configuration/index.rst', 'magnum_ui/static/dashboard/container-infra/magnum.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/rolling-upgrade/upgrade.service.js', 'magnum_ui/static/dashboard/container-infra/utils.service.js', 'magnum_ui/static/dashboard/container-infra/utils.service.spec.js', 'releasenotes/notes/upgrade-actions-adf2f749ec0cc817.yaml', 'magnum_ui/api/magnum.py', 'magnum_ui/api/rest/magnum.py', 'magnum_ui/static/dashboard/container-infra/clusters/rolling-upgrade/upgrade.service.spec.js', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.js', 'magnum_ui/static/dashboard/container-infra/magnum.service.spec.js'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/b0fdeed6366231990c8784cc68d70ddf6ba0b364', 'message': 'Add rolling upgrade ui\n\n + Create new row action on clusters panel\n + Create new modal form for upgrading cluster\n + Create REST endpoint for upgrading cluster\n + Bump python-magnumclient lower constraint\n\n(cherry picked from commit cd0817a13b58cbd7cb083e15d3467ce9f845ec32)\n\nRegister the Cluster Upgrade view\n\n + Fixes missing url registraion for upgrade cluster\n   in prior patch (https://review.opendev.org/#/c/697000/4).\n\n(cherry picked from commit d96f4d16c2b3254b290ff5d257340434a6dd6717)\n\nChange-Id: Id3fd3ee80fb27b08673933800aea6e7ee7ac7cd0\n'}]",0,698879,b0fdeed6366231990c8784cc68d70ddf6ba0b364,13,5,2,28022,,,0,"Add rolling upgrade ui

 + Create new row action on clusters panel
 + Create new modal form for upgrading cluster
 + Create REST endpoint for upgrading cluster
 + Bump python-magnumclient lower constraint

(cherry picked from commit cd0817a13b58cbd7cb083e15d3467ce9f845ec32)

Register the Cluster Upgrade view

 + Fixes missing url registraion for upgrade cluster
   in prior patch (https://review.opendev.org/#/c/697000/4).

(cherry picked from commit d96f4d16c2b3254b290ff5d257340434a6dd6717)

Change-Id: Id3fd3ee80fb27b08673933800aea6e7ee7ac7cd0
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/79/698879/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration/index.rst', 'magnum_ui/static/dashboard/container-infra/magnum.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/rolling-upgrade/upgrade.service.js', 'magnum_ui/static/dashboard/container-infra/utils.service.js', 'magnum_ui/static/dashboard/container-infra/utils.service.spec.js', 'magnum_ui/api/magnum.py', 'releasenotes/notes/upgrade-actions-adf2f749ec0cc817.yaml', 'magnum_ui/api/rest/magnum.py', 'magnum_ui/static/dashboard/container-infra/clusters/rolling-upgrade/upgrade.service.spec.js', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.js', 'magnum_ui/static/dashboard/container-infra/magnum.service.spec.js']",11,5328c4b54685cb3b2f5a2e5794fc859ede3f979d,train," ""func"": ""upgradeCluster"", ""method"": ""post"", ""path"": ""/api/container_infra/clusters/123/upgrade"", ""data"": { ""cluster_template"": ""ABC"", ""max_batch_size"": 1, ""node_group"": ""production_group"" }, ""error"": ""Unable to perform rolling upgrade."", ""testInput"": [ ""123"", { ""cluster_template"": ""ABC"", ""max_batch_size"": 1, ""node_group"": ""production_group"" } ] }, { ""func"": ""getClusterTemplates"", ""method"": ""get"", ""path"": ""/api/container_infra/cluster_templates/?related_to=123"", ""error"": ""Unable to retrieve the cluster templates."", ""testInput"": [123] }, {",,626,5
openstack%2Fmagnum-ui~stable%2Ftrain~I591d4e6ebe85adac0bcefb3f95b1a7d2abf0ba88,openstack/magnum-ui,stable/train,I591d4e6ebe85adac0bcefb3f95b1a7d2abf0ba88,Add ui for resizing clusters,MERGED,2019-12-13 11:02:19.000000000,2020-01-15 23:58:44.000000000,2020-01-15 23:57:11.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 30447}]","[{'number': 1, 'created': '2019-12-13 11:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/dddee94ca3fcff8cecadb3bbcc63d3f6904eb6f5', 'message': 'Add ui for resizing clusters\n\nCreate new row action on clusters panel\nCreate new modal form for resizing cluster:wq\nCreate REST endpoint for resizing cluster\nBump python-magnumclient lower constraint\nAdd heatclient lower constraint\n\nChange-Id: I591d4e6ebe85adac0bcefb3f95b1a7d2abf0ba88\n(cherry picked from commit 0bfd85d4c132a437dfc20dce54cf0478c479d9db)\n'}, {'number': 2, 'created': '2019-12-13 11:02:42.000000000', 'files': ['magnum_ui/static/dashboard/container-infra/magnum.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/resize/resize.service.js', 'releasenotes/notes/resize-actions-1436a2a0dccbd13b.yaml', 'lower-constraints.txt', 'magnum_ui/static/dashboard/container-infra/clusters/resize/resize.service.spec.js', 'magnum_ui/static/dashboard/container-infra/magnum.service.spec.js', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.spec.js', 'magnum_ui/api/heat.py', 'requirements.txt', 'magnum_ui/api/magnum.py', 'magnum_ui/api/rest/magnum.py', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.js'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/7bc8797bdef9c00724b7452a5311a2e49eab0bfb', 'message': 'Add ui for resizing clusters\n\nCreate new row action on clusters panel\nCreate new modal form for resizing cluster:wq\nCreate REST endpoint for resizing cluster\nBump python-magnumclient lower constraint\nAdd heatclient lower constraint\n\nChange-Id: I591d4e6ebe85adac0bcefb3f95b1a7d2abf0ba88\n(cherry picked from commit 0bfd85d4c132a437dfc20dce54cf0478c479d9db)\n'}]",0,698871,7bc8797bdef9c00724b7452a5311a2e49eab0bfb,21,5,2,28022,,,0,"Add ui for resizing clusters

Create new row action on clusters panel
Create new modal form for resizing cluster:wq
Create REST endpoint for resizing cluster
Bump python-magnumclient lower constraint
Add heatclient lower constraint

Change-Id: I591d4e6ebe85adac0bcefb3f95b1a7d2abf0ba88
(cherry picked from commit 0bfd85d4c132a437dfc20dce54cf0478c479d9db)
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/71/698871/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/static/dashboard/container-infra/magnum.service.js', 'magnum_ui/static/dashboard/container-infra/clusters/resize/resize.service.js', 'releasenotes/notes/resize-actions-1436a2a0dccbd13b.yaml', 'lower-constraints.txt', 'magnum_ui/static/dashboard/container-infra/clusters/resize/resize.service.spec.js', 'magnum_ui/static/dashboard/container-infra/magnum.service.spec.js', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.spec.js', 'magnum_ui/api/heat.py', 'requirements.txt', 'magnum_ui/api/magnum.py', 'magnum_ui/api/rest/magnum.py', 'magnum_ui/static/dashboard/container-infra/clusters/actions.module.js']",12,dddee94ca3fcff8cecadb3bbcc63d3f6904eb6f5,new/cluster-resize-workflow-merge-stable/train," 'horizon.dashboard.container-infra.clusters.resize.service', resizeClusterService, id: 'resizeClusterAction', service: resizeClusterService, template: { text: gettext('Resize Cluster') } }) .append({",,518,4
openstack%2Fopenstack-helm-infra~master~I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa,openstack/openstack-helm-infra,master,I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa,Fix incorrect prometheus alert names in nagios,MERGED,2020-01-02 21:58:54.000000000,2020-01-15 23:44:25.000000000,2020-01-15 23:43:05.000000000,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 27499}, {'_account_id': 30582}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-01-02 21:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf0f873e9d809f05c2e300af6baa1fbdb6aaa4d5', 'message': 'Fix incorrect prometheus alert names in nagios\n\nI noticed a few different nagios service checks were checking the\nsame prometheus alert. This change simply changes the\ncheck_network_receive_errors_high and\ncheck_network_transmit_errors_high service checks to check the alerts\nnode_high_network_errs_rcv and\nnode_high_network_errs_send respectivly.\n\nProm alerts defined on line 141 and 151:\nhttps://opendev.org/openstack/openstack-helm-infra/src/branch/master/prometheus/values_overrides/nodes.yaml#L141\nChange-Id: I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa\n'}, {'number': 2, 'created': '2020-01-02 22:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/94324caee2b5d94d18042138e7331c06e50f5191', 'message': 'Fix incorrect prometheus alert names in nagios\n\nI noticed a few different nagios service checks were checking the\nsame prometheus alert. This change simply changes the\ncheck_network_receive_errors_high and\ncheck_network_transmit_errors_high service checks to check the alerts\nnode_high_network_errs_rcv and\nnode_high_network_errs_send respectivly.\n\nProm alerts defined on line 141 and 151:\nhttps://opendev.org/openstack/openstack-helm-infra/src/branch/master/prometheus/values_overrides/nodes.yaml#L141\nChange-Id: I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa\n'}, {'number': 3, 'created': '2020-01-02 22:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e88b5002cd3d16cf3ff61684572d733761fc5987', 'message': 'Fix incorrect prometheus alert names in nagios\n\nI noticed a few different nagios service checks were checking the\nsame prometheus alert. Prom alerts defined on line 121, 131, 141, 151:\n\nhttps://opendev.org/openstack/openstack-helm-infra/src/branch/master/prometheus/values_overrides/nodes.yaml#L121\n\nChange-Id: I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa\n'}, {'number': 4, 'created': '2020-01-03 16:32:58.000000000', 'files': ['nagios/values.yaml', 'prometheus/values_overrides/kubernetes.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4fdcff593cdddb5edb7229f2319aa2714c0461cc', 'message': 'Fix incorrect prometheus alert names in nagios\n\nI noticed a some nagios service checks were checking prometheus\nalerts which did not exist in our default prometheus configuration.\nIn one case a prometheus alert did not match the naming convention\nof similar alerts.\n\nOne nagios service check, ceph_monitor_clock_skew_high, does not\nhave a corresponding alert  at all, so I\'ve changed it to check the\n\nnode_ntmp_clock_skew_high\n\nalert, where a node has the label ceph-mon=""enabled"".\n\nChange-Id: I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa\n'}]",2,700946,4fdcff593cdddb5edb7229f2319aa2714c0461cc,21,6,4,30777,,,0,"Fix incorrect prometheus alert names in nagios

I noticed a some nagios service checks were checking prometheus
alerts which did not exist in our default prometheus configuration.
In one case a prometheus alert did not match the naming convention
of similar alerts.

One nagios service check, ceph_monitor_clock_skew_high, does not
have a corresponding alert  at all, so I've changed it to check the

node_ntmp_clock_skew_high

alert, where a node has the label ceph-mon=""enabled"".

Change-Id: I2ebf9a4954190b8e2caefc8a61270e28bf24d9fa
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/46/700946/4 && git format-patch -1 --stdout FETCH_HEAD,['nagios/values.yaml'],1,cf0f873e9d809f05c2e300af6baa1fbdb6aaa4d5,misc-nagios-fixes," command_line $USER1$/query_prometheus_alerts.py --prometheus_api $USER2$ --alertname 'node_high_network_errs_rcv' --labels_csv 'instance=~""$HOSTADDRESS$.*""' --msg_format 'CRITICAL- Host system has an unusally high error rate in network reception.' --ok_message 'OK- network reception errors not high.' command_line $USER1$/query_prometheus_alerts.py --prometheus_api $USER2$ --alertname 'node_high_network_errs_send' --labels_csv 'instance=~""$HOSTADDRESS$.*""' --msg_format 'CRITICAL- Host system has an unusally high error rate in network transmission.' --ok_message 'OK- network transmission errors not high.'"," command_line $USER1$/query_prometheus_alerts.py --prometheus_api $USER2$ --alertname 'high_network_drop_send' --labels_csv 'instance=~""$HOSTADDRESS$.*""' --msg_format 'CRITICAL- Host system has an unusally high error rate in network reception.' --ok_message 'OK- network reception errors not high.' command_line $USER1$/query_prometheus_alerts.py --prometheus_api $USER2$ --alertname 'high_network_drop_send' --labels_csv 'instance=~""$HOSTADDRESS$.*""' --msg_format 'CRITICAL- Host system has an unusally high error rate in network transmission.' --ok_message 'OK- network transmission errors not high.'",2,2
openstack%2Fneutron~master~Ia6202610c09811f240af35e2523126447bf02ca5,openstack/neutron,master,Ia6202610c09811f240af35e2523126447bf02ca5,Remove Floating IP DNS record upon associated port deletion,MERGED,2019-10-28 09:26:21.000000000,2020-01-15 22:59:20.000000000,2019-11-11 13:32:33.000000000,"[{'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 13438}, {'_account_id': 16376}, {'_account_id': 20363}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-10-28 09:26:21.000000000', 'files': ['neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4379310846078c45df140071688f740cd900c1d6', 'message': 'Remove Floating IP DNS record upon associated port deletion\n\nPort deletion triggers disassociate_floatingips. This patch ensures\nthat method not only clears the port association for a Floating IP,\nbut also removes any DNS record associated with it.\n\nChange-Id: Ia6202610c09811f240af35e2523126447bf02ca5\nCloses-Bug: #1812168\n'}]",0,691640,4379310846078c45df140071688f740cd900c1d6,51,9,1,261,,,0,"Remove Floating IP DNS record upon associated port deletion

Port deletion triggers disassociate_floatingips. This patch ensures
that method not only clears the port association for a Floating IP,
but also removes any DNS record associated with it.

Change-Id: Ia6202610c09811f240af35e2523126447bf02ca5
Closes-Bug: #1812168
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/691640/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,4379310846078c45df140071688f740cd900c1d6,," # Process DNS record removal after committing the transaction if self._is_dns_integration_supported: self._process_dns_floatingip_delete(context, fip.to_dict())",,3,0
openstack%2Fcinder~master~I3d1a31962f8a6f9a58b9299493b7c58f4cf086d6,openstack/cinder,master,I3d1a31962f8a6f9a58b9299493b7c58f4cf086d6,Add Source links to readme,ABANDONED,2019-10-17 06:25:57.000000000,2020-01-15 22:36:45.000000000,,"[{'_account_id': 1736}, {'_account_id': 9732}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30590}]","[{'number': 1, 'created': '2019-10-17 06:25:57.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e2b64d42ea05bce937bc4ab4e8b8721f9320a41', 'message': 'Add Source links to readme\n\nChange-Id: I3d1a31962f8a6f9a58b9299493b7c58f4cf086d6\n'}]",0,689081,4e2b64d42ea05bce937bc4ab4e8b8721f9320a41,17,15,1,30384,,,0,"Add Source links to readme

Change-Id: I3d1a31962f8a6f9a58b9299493b7c58f4cf086d6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/81/689081/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4e2b64d42ea05bce937bc4ab4e8b8721f9320a41,,* Source: https://opendev.org/openstack/cinder ,,1,0
openstack%2Fkolla-ansible~master~I38da931cdd7ff46cce1994763b5c713652b096cc,openstack/kolla-ansible,master,I38da931cdd7ff46cce1994763b5c713652b096cc,Configure services to use Certificate Authority,MERGED,2019-12-16 23:50:49.000000000,2020-01-15 22:18:13.000000000,2020-01-15 22:16:30.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 29344}, {'_account_id': 29543}, {'_account_id': 30491}, {'_account_id': 30810}]","[{'number': 1, 'created': '2019-12-16 23:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/67e37a2af5e0a002712365455be37236824d6dfc', 'message': 'Include a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint add-ssl-internal-network\nSigned-off-by: James Kirsch <generalfuzz@gmail.com>\n'}, {'number': 2, 'created': '2019-12-17 03:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/51f8a623df2b34f4caa7813b333139234d378213', 'message': 'Include a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint add-ssl-internal-network\n'}, {'number': 3, 'created': '2019-12-17 18:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5eabed9fc234fc71eaca7a506e7abf02ecc8626c', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 4, 'created': '2019-12-17 22:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/092c997ead64d8aab468f32dda7fafc6d6e66760', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 5, 'created': '2019-12-18 19:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3d53a5d2edfd460ff6b5d398c1975ac686f58fec', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 6, 'created': '2019-12-18 21:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/30380aa6cf3455000d96fb605c84407f3ec44c9c', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 7, 'created': '2019-12-30 18:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6338b0e3577fb20e3af076c7769d1183f717ffc0', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 8, 'created': '2020-01-03 19:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/adc3b02aa62503a554339bbdf145cef9ac83bf12', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 9, 'created': '2020-01-03 22:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fe5adb9a6d9e9e5ecc758d513a3a19fb62ec4b4c', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 10, 'created': '2020-01-11 00:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/280086e179b217d3586873c5097bd7de8551bbf5', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 11, 'created': '2020-01-13 18:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c30f962523a3dbbe7ad6239ce17a64cc53954c7a', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}, {'number': 12, 'created': '2020-01-13 19:00:20.000000000', 'files': ['ansible/roles/manila/templates/manila-share.conf.j2', 'ansible/roles/aodh/templates/aodh.conf.j2', 'ansible/roles/monasca/templates/monasca-log-api/log-api.conf.j2', 'ansible/roles/kibana/templates/kibana.yml.j2', 'ansible/roles/masakari/templates/masakari.conf.j2', 'ansible/roles/designate/templates/designate.conf.j2', 'ansible/roles/qinling/templates/qinling.conf.j2', 'ansible/roles/solum/templates/solum.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/ceilometer/templates/ceilometer.conf.j2', 'ansible/roles/senlin/templates/senlin.conf.j2', 'ansible/roles/heat/tasks/bootstrap_service.yml', 'ansible/roles/glance/templates/glance-api.conf.j2', 'ansible/roles/zun/templates/zun.conf.j2', 'ansible/roles/nova-hyperv/templates/nova_hyperv.conf.j2', 'ansible/roles/tempest/templates/tempest.conf.j2', 'ansible/roles/vitrage/templates/vitrage.conf.j2', 'ansible/roles/kuryr/templates/kuryr.conf.j2', 'ansible/roles/magnum/templates/magnum.conf.j2', 'ansible/roles/cyborg/templates/cyborg.conf.j2', 'ansible/roles/ironic/templates/ironic-inspector.conf.j2', 'ansible/roles/nova-cell/templates/nova.conf.j2', 'ansible/roles/trove/templates/trove.conf.j2', 'ansible/roles/octavia/templates/octavia.conf.j2', 'ansible/roles/masakari/templates/masakari-monitors.conf.j2', 'ansible/roles/gnocchi/templates/gnocchi.conf.j2', 'ansible/roles/searchlight/templates/searchlight.conf.j2', 'ansible/roles/swift/templates/proxy-server.conf.j2', 'ansible/roles/tacker/templates/tacker.conf.j2', 'ansible/roles/glance/templates/glance-swift.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/roles/freezer/templates/freezer.conf.j2', 'ansible/roles/sahara/templates/sahara.conf.j2', 'ansible/roles/cinder/templates/cinder.conf.j2', 'ansible/roles/heat/templates/heat.conf.j2', 'ansible/roles/placement/templates/placement.conf.j2', 'ansible/roles/blazar/templates/blazar.conf.j2', 'ansible/roles/congress/templates/congress.conf.j2', 'ansible/roles/mistral/templates/mistral.conf.j2', 'ansible/roles/panko/templates/panko.conf.j2', 'ansible/roles/monasca/templates/monasca-api/api.conf.j2', 'ansible/roles/murano/templates/murano.conf.j2', 'ansible/roles/karbor/templates/karbor.conf.j2', 'ansible/roles/telegraf/templates/telegraf.conf.j2', 'releasenotes/notes/configure-certificate-authority-aa21fa88234b021e.yaml', 'ansible/roles/watcher/templates/watcher.conf.j2', 'ansible/roles/neutron/templates/neutron.conf.j2', 'ansible/roles/cloudkitty/templates/cloudkitty.conf.j2', 'ansible/roles/manila/templates/manila.conf.j2', 'ansible/roles/barbican/templates/barbican.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c15dc20341bc7e9d26f63e677d0d45ef962301dc', 'message': 'Configure services to use Certificate Authority\n\nInclude a reference to the globally configured Certificate Authority to\nall services. Services use the CA to verify HTTPs connections.\n\nChange-Id: I38da931cdd7ff46cce1994763b5c713652b096cc\nPartially-Implements: blueprint support-trusted-ca-certificate-file\n'}]",7,699312,c15dc20341bc7e9d26f63e677d0d45ef962301dc,45,6,12,30810,,,0,"Configure services to use Certificate Authority

Include a reference to the globally configured Certificate Authority to
all services. Services use the CA to verify HTTPs connections.

Change-Id: I38da931cdd7ff46cce1994763b5c713652b096cc
Partially-Implements: blueprint support-trusted-ca-certificate-file
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/12/699312/12 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/swift/templates/proxy-server.conf.j2', 'ansible/roles/tacker/templates/tacker.conf.j2', 'ansible/roles/glance/templates/glance-swift.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/roles/freezer/templates/freezer.conf.j2', 'ansible/roles/manila/templates/manila-share.conf.j2', 'ansible/roles/aodh/templates/aodh.conf.j2', 'ansible/roles/monasca/templates/monasca-log-api/log-api.conf.j2', 'ansible/roles/sahara/templates/sahara.conf.j2', 'ansible/roles/cinder/templates/cinder.conf.j2', 'ansible/roles/heat/templates/heat.conf.j2', 'ansible/roles/masakari/templates/masakari.conf.j2', 'ansible/roles/designate/templates/designate.conf.j2', 'ansible/roles/placement/templates/placement.conf.j2', 'ansible/roles/qinling/templates/qinling.conf.j2', 'ansible/roles/solum/templates/solum.conf.j2', 'ansible/roles/blazar/templates/blazar.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/congress/templates/congress.conf.j2', 'ansible/roles/ceilometer/templates/ceilometer.conf.j2', 'ansible/roles/senlin/templates/senlin.conf.j2', 'ansible/roles/mistral/templates/mistral.conf.j2', 'ansible/roles/glance/templates/glance-api.conf.j2', 'ansible/roles/panko/templates/panko.conf.j2', 'ansible/roles/zun/templates/zun.conf.j2', 'ansible/roles/murano/templates/murano.conf.j2', 'ansible/roles/nova-hyperv/templates/nova_hyperv.conf.j2', 'ansible/roles/karbor/templates/karbor.conf.j2', 'ansible/roles/vitrage/templates/vitrage.conf.j2', 'ansible/roles/watcher/templates/watcher.conf.j2', 'ansible/roles/kuryr/templates/kuryr.conf.j2', 'ansible/roles/magnum/templates/magnum.conf.j2', 'ansible/roles/cyborg/templates/cyborg.conf.j2', 'ansible/roles/ironic/templates/ironic-inspector.conf.j2', 'ansible/roles/neutron/templates/neutron.conf.j2', 'ansible/roles/nova-cell/templates/nova.conf.j2', 'ansible/roles/trove/templates/trove.conf.j2', 'ansible/roles/cloudkitty/templates/cloudkitty.conf.j2', 'ansible/roles/glance/templates/glance-cache.conf.j2', 'ansible/roles/masakari/templates/masakari-monitors.conf.j2', 'ansible/roles/manila/templates/manila.conf.j2', 'ansible/roles/gnocchi/templates/gnocchi.conf.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/searchlight/templates/searchlight.conf.j2']",44,67e37a2af5e0a002712365455be37236824d6dfc,bp/add-internal-network/configure-cacert-verification,cafile = {{ openstack_cacert | default(omit) }}cafile = {{ openstack_cacert | default(omit) }},,86,1
openstack%2Fpuppet-tripleo~master~I91d9f8ffb1e0c8bbdbc90696950aafd797ff380c,openstack/puppet-tripleo,master,I91d9f8ffb1e0c8bbdbc90696950aafd797ff380c,Make rsyslog file_input bulletproof,MERGED,2020-01-13 10:08:32.000000000,2020-01-15 21:49:56.000000000,2020-01-15 21:49:56.000000000,"[{'_account_id': 5241}, {'_account_id': 6681}, {'_account_id': 6926}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-13 10:08:32.000000000', 'files': ['spec/defines/tripleo_profile_base_logging_rsyslog_file_input_spec.rb', 'manifests/profile/base/logging/rsyslog/file_input.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8c813bc8ac6b1541ce32a82bdc0992c16464acf4', 'message': 'Make rsyslog file_input bulletproof\n\nThis patch makes rsyslog::file_input accept also $sources as single hash.\nCurrently when $sources is not array deployment fails.\n\nChange-Id: I91d9f8ffb1e0c8bbdbc90696950aafd797ff380c\n'}]",0,702182,8c813bc8ac6b1541ce32a82bdc0992c16464acf4,25,8,1,5241,,,0,"Make rsyslog file_input bulletproof

This patch makes rsyslog::file_input accept also $sources as single hash.
Currently when $sources is not array deployment fails.

Change-Id: I91d9f8ffb1e0c8bbdbc90696950aafd797ff380c
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/82/702182/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/tripleo_profile_base_logging_rsyslog_file_input_spec.rb', 'manifests/profile/base/logging/rsyslog/file_input.pp']",2,8c813bc8ac6b1541ce32a82bdc0992c16464acf4,," $sources_array = Array($sources, true) $rsyslog_sources = $sources_array.reduce([]) |$memo, $config| {"," $rsyslog_sources = $sources.reduce([]) |$memo, $config| {",26,10
openstack%2Fnova~stable%2Fstein~Ic749c49e227e41732dbe04acea303b303acd264a,openstack/nova,stable/stein,Ic749c49e227e41732dbe04acea303b303acd264a,block_device: Copy original volume_type when missing for snapshot based volumes,MERGED,2019-11-29 11:44:54.000000000,2020-01-15 21:48:32.000000000,2020-01-15 21:46:25.000000000,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-29 11:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f042fe0644442364c16db0f70cf9f39e41bced18', 'message': 'block_device: Copy original volume_type when missing for snapshot based volumes\n\nAttempts to launch an instance from an encrypted volume snapshot would\npreviously fail if a volume_type was not specified in the\nblock_device_mapping of the boot request.\n\nTo avoid such failures DriverVolSnapshotBlockDevice will now attempt to\nlookup and use the volume_type of the original volume that the snapshot\nis based on. This should allow the eventual volume creation request\nbased on the snapshot to succeed in cases where a volume_type is\nrequired but not provided in the boot request.\n\nConflicts:\n        nova/virt/block_device.py\n\nNOTE(lyarwood): Due to I4205c00311f389907dcc390869414687ac03b7f5 not\nbeing present in stable/stein.\n\nCloses-Bug: #1853495\nChange-Id: Ic749c49e227e41732dbe04acea303b303acd264a\n(cherry picked from commit 5679a0bf99c17ff336fa520c9cdfad5156c6c9d2)\n(cherry picked from commit 059dc01ae027f00ffffbaa9ee8a3c958031829ce)\n'}, {'number': 2, 'created': '2019-12-11 20:44:16.000000000', 'files': ['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/95bf4a1e1594611e987f88b470cc02a626373ab4', 'message': ""block_device: Copy original volume_type when missing for snapshot based volumes\n\nAttempts to launch an instance from an encrypted volume snapshot would\npreviously fail if a volume_type was not specified in the\nblock_device_mapping of the boot request.\n\nTo avoid such failures DriverVolSnapshotBlockDevice will now attempt to\nlookup and use the volume_type of the original volume that the snapshot\nis based on. This should allow the eventual volume creation request\nbased on the snapshot to succeed in cases where a volume_type is\nrequired but not provided in the boot request.\n\nConflicts:\n        nova/virt/block_device.py\n        nova/tests/unit/virt/test_block_device.py\n\nNOTE(lyarwood): Due to I4205c00311f389907dcc390869414687ac03b7f5 not\nbeing present in stable/stein. As a result the call to the\nvolume_api.create doesn't proivide the snapshot argument as a keyword.\n\nCloses-Bug: #1853495\nChange-Id: Ic749c49e227e41732dbe04acea303b303acd264a\n(cherry picked from commit 5679a0bf99c17ff336fa520c9cdfad5156c6c9d2)\n(cherry picked from commit 059dc01ae027f00ffffbaa9ee8a3c958031829ce)\n""}]",2,696686,95bf4a1e1594611e987f88b470cc02a626373ab4,18,7,2,10135,,,0,"block_device: Copy original volume_type when missing for snapshot based volumes

Attempts to launch an instance from an encrypted volume snapshot would
previously fail if a volume_type was not specified in the
block_device_mapping of the boot request.

To avoid such failures DriverVolSnapshotBlockDevice will now attempt to
lookup and use the volume_type of the original volume that the snapshot
is based on. This should allow the eventual volume creation request
based on the snapshot to succeed in cases where a volume_type is
required but not provided in the boot request.

Conflicts:
        nova/virt/block_device.py
        nova/tests/unit/virt/test_block_device.py

NOTE(lyarwood): Due to I4205c00311f389907dcc390869414687ac03b7f5 not
being present in stable/stein. As a result the call to the
volume_api.create doesn't proivide the snapshot argument as a keyword.

Closes-Bug: #1853495
Change-Id: Ic749c49e227e41732dbe04acea303b303acd264a
(cherry picked from commit 5679a0bf99c17ff336fa520c9cdfad5156c6c9d2)
(cherry picked from commit 059dc01ae027f00ffffbaa9ee8a3c958031829ce)
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/696686/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/test_block_device.py', 'nova/virt/block_device.py']",2,f042fe0644442364c16db0f70cf9f39e41bced18,," # NOTE(lyarwood): Try to use the original volume type if one isn't # set against the bdm but is on the original volume. if not self.volume_type and snapshot.get('volume_id'): snap_volume_id = snapshot.get('volume_id') orig_volume = volume_api.get(context, snap_volume_id) self.volume_type = orig_volume.get('volume_type_id') ",,38,0
openstack%2Fcinder~master~I926732062dbbd1242cd382e2593e07b4caf4ffec,openstack/cinder,master,I926732062dbbd1242cd382e2593e07b4caf4ffec,Remove hacking check N325,MERGED,2020-01-10 17:14:12.000000000,2020-01-15 21:48:13.000000000,2020-01-15 21:46:28.000000000,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 20284}, {'_account_id': 20813}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22348}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30688}]","[{'number': 1, 'created': '2020-01-10 17:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/81f582eb85e72e027671c1f650d9ca9744c79f06', 'message': ""Remove hacking check N325\n\nThis hacking check was added back when the str()\nfunction couldn't handle unicode characters.  With\nPython3 this is no longer an issue.  As a result we\ncan now remove this check.\n\nChange-Id: I926732062dbbd1242cd382e2593e07b4caf4ffec\n""}, {'number': 2, 'created': '2020-01-10 18:55:52.000000000', 'files': ['cinder/tests/hacking/checks.py', 'cinder/tests/unit/test_hacking.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e387452419e09711ae7efe5b379168acbb928b42', 'message': ""Remove hacking check N325\n\nThis hacking check was added back when the str()\nfunction couldn't handle unicode characters.  With\nPython3 this is no longer an issue.  As a result we\ncan now remove this check.\n\nChange-Id: I926732062dbbd1242cd382e2593e07b4caf4ffec\n""}]",1,702012,e387452419e09711ae7efe5b379168acbb928b42,62,30,2,7198,,,0,"Remove hacking check N325

This hacking check was added back when the str()
function couldn't handle unicode characters.  With
Python3 this is no longer an issue.  As a result we
can now remove this check.

Change-Id: I926732062dbbd1242cd382e2593e07b4caf4ffec
",git fetch https://review.opendev.org/openstack/cinder refs/changes/12/702012/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/hacking/checks.py', 'HACKING.rst']",2,81f582eb85e72e027671c1f650d9ca9744c79f06,remove_N325_hacking_check,,- [N325] str() and unicode() cannot be used on an exception. Remove or use six.text_type().,0,50
openstack%2Ftripleo-quickstart~master~I313dc6233895f37fb7616aee730e5802c9aac3df,openstack/tripleo-quickstart,master,I313dc6233895f37fb7616aee730e5802c9aac3df,fs010/undercloud: disable paunch,MERGED,2019-11-13 13:45:47.000000000,2020-01-15 21:38:27.000000000,2020-01-15 21:36:32.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-11-13 13:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b64541a89277deb40b88ae643b58b38ab34940a6', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 2, 'created': '2019-11-14 09:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/184f4327abdb290064dde74a0dce6991441c77ee', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 3, 'created': '2019-11-15 11:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b11ca3148262480d5f2761b6384dc09dc09482fc', 'message': 'fs010/undercloud: disable paunch\n\nDepends-On: Iab87530e2c0c3952bf46022cf5bee5ad337c78f8\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 4, 'created': '2019-11-15 11:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/33126d6a58f030766f1fbb5b0681f3a79b368859', 'message': 'fs010/undercloud: disable paunch\n\nDepends-On: Iab87530e2c0c3952bf46022cf5bee5ad337c78f8\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 5, 'created': '2019-11-26 13:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7555b8b7aa6a161d19ca33307c2c6ddc4ab21c63', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 6, 'created': '2019-11-26 13:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d5099d2d569126a11e093ec8d8ce89549799762b', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 7, 'created': '2019-12-12 17:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/4c76b365b9778ed49f38e09c4ce0a5df79a16bbf', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 8, 'created': '2020-01-06 22:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8518b46716c98efe5555654c00189d93065eae67', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}, {'number': 9, 'created': '2020-01-11 03:52:47.000000000', 'files': ['config/general_config/featureset010.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/301bb6ddd93a6651d4c5603b82a75e4083b3a372', 'message': 'fs010/undercloud: disable paunch\n\nChange-Id: I313dc6233895f37fb7616aee730e5802c9aac3df\n'}]",0,694075,301bb6ddd93a6651d4c5603b82a75e4083b3a372,49,7,9,3153,,,0,"fs010/undercloud: disable paunch

Change-Id: I313dc6233895f37fb7616aee730e5802c9aac3df
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/75/694075/6 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset010.yml'],1,b64541a89277deb40b88ae643b58b38ab34940a6,fs010, undercloud_enable_paunch: false,,2,0
openstack%2Ftripleo-common~master~I35d73e7eca6f3cc208eda5d4c78a7bdd6cd7b810,openstack/tripleo-common,master,I35d73e7eca6f3cc208eda5d4c78a7bdd6cd7b810,image_uploader (attempt #3): fix images upload with no labels,MERGED,2020-01-15 14:00:24.000000000,2020-01-15 21:38:13.000000000,2020-01-15 21:36:34.000000000,"[{'_account_id': 6926}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-01-15 14:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d8e63e6f5b99024894cc943fdf575bd64d18386e', 'message': ""image_uploader (attenmpt #3): fix images upload with no labels\n\nIf an image has no label, we set labels to {}; so to build tag_label in\nthat case we need to catch the TypeError exception or\ntag_from_label.format(**labels) will raise, since labels would be NoneType.\n\nWe could have remove the default {} for Labels; but it's better to keep\nit for further use in the image uploader; when the parameter is required\nfor certain methods.\n\nChange-Id: I35d73e7eca6f3cc208eda5d4c78a7bdd6cd7b810\n""}, {'number': 2, 'created': '2020-01-15 14:02:18.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1b4f32a28ac93b5a46f36f6aa631f9d26034fb67', 'message': ""image_uploader (attempt #3): fix images upload with no labels\n\nIf an image has no label, we set labels to {}; so to build tag_label in\nthat case we need to catch the TypeError exception or\ntag_from_label.format(**labels) will raise, since labels would be NoneType.\n\nWe could have remove the default {} for Labels; but it's better to keep\nit for further use in the image uploader; when the parameter is required\nfor certain methods.\n\nCloses-Bug: #1857012\nChange-Id: I35d73e7eca6f3cc208eda5d4c78a7bdd6cd7b810\n""}]",0,702667,1b4f32a28ac93b5a46f36f6aa631f9d26034fb67,12,5,2,3153,,,0,"image_uploader (attempt #3): fix images upload with no labels

If an image has no label, we set labels to {}; so to build tag_label in
that case we need to catch the TypeError exception or
tag_from_label.format(**labels) will raise, since labels would be NoneType.

We could have remove the default {} for Labels; but it's better to keep
it for further use in the image uploader; when the parameter is required
for certain methods.

Closes-Bug: #1857012
Change-Id: I35d73e7eca6f3cc208eda5d4c78a7bdd6cd7b810
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/67/702667/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,d8e63e6f5b99024894cc943fdf575bd64d18386e,labels," except (KeyError, TypeError) as e:", except KeyError as e:,1,1
openstack%2Fkolla~master~I9d13ad8a6a610bcf000d3850b77af80d10d66ba7,openstack/kolla,master,I9d13ad8a6a610bcf000d3850b77af80d10d66ba7,Debian: enable backports repo,MERGED,2020-01-13 11:46:42.000000000,2020-01-15 21:37:13.000000000,2020-01-15 21:33:08.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-01-13 11:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/81079b5b7ea55912bfa4cd5c2c454d9d9a2a6579', 'message': ""Debian: switch to 'buster-backports' by default\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}, {'number': 2, 'created': '2020-01-14 09:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fee5705ff7747996d773ad3bd70fd53cf3aedd53', 'message': ""Debian: switch to 'buster-backports' by default\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}, {'number': 3, 'created': '2020-01-14 12:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1ce6eb26c54858675c16096923450476f31dcfa7', 'message': ""Debian: switch to 'buster-backports' by default\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}, {'number': 4, 'created': '2020-01-14 12:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d9bf5017a99a859bd2c0ed5e19ea3cc0eb9c4d03', 'message': ""Debian: enable backports repo\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}, {'number': 5, 'created': '2020-01-14 20:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/31e1f1fea81e0218dbb2f47adb7e63489b437b51', 'message': ""Debian: enable backports repo\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}, {'number': 6, 'created': '2020-01-15 09:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4765eb89615f754ad71152f363f01a4860f24819', 'message': ""Debian: enable backports repo\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}, {'number': 7, 'created': '2020-01-15 12:48:35.000000000', 'files': ['docker/base/apt_preferences.debian', 'releasenotes/notes/debian-ceph-nautilus-83fe26e66874045f.yaml', 'docker/base/sources.list.debian'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f253bc2380c2c9c82f86136b266dc351c100bf02', 'message': ""Debian: enable backports repo\n\nWe get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.\nSo far only ceph is taken from backports repo.\n\nChange-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7\n""}]",3,702201,f253bc2380c2c9c82f86136b266dc351c100bf02,45,7,7,24072,,,0,"Debian: enable backports repo

We get Ceph 'nautilus' that way to be in sync with CentOS and Ubuntu.
So far only ceph is taken from backports repo.

Change-Id: I9d13ad8a6a610bcf000d3850b77af80d10d66ba7
",git fetch https://review.opendev.org/openstack/kolla refs/changes/01/702201/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/apt_preferences.debian', 'docker/base/Dockerfile.j2', 'docker/base/sources.list.debian', 'kolla/common/config.py']",4,81079b5b7ea55912bfa4cd5c2c454d9d9a2a6579,," 'debian': 'buster-backports',"," 'debian': '10',",13,2
openstack%2Fopenstack-zuul-jobs~master~I1c6447f9997e953d3f0a0030b46bd910e8910e0c,openstack/openstack-zuul-jobs,master,I1c6447f9997e953d3f0a0030b46bd910e8910e0c,Remove zmq-event-publisher jobs,MERGED,2020-01-15 20:28:00.000000000,2020-01-15 21:37:01.000000000,2020-01-15 21:33:42.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 20:28:00.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/zmq-event-publisher-jenkinsci-upload/run.yaml', 'playbooks/legacy/zmq-event-publisher-maven-build-ubuntu-trusty/run.yaml', 'playbooks/legacy/zmq-event-publisher-hpi-artifact/post.yaml', 'playbooks/legacy/zmq-event-publisher-hpi-artifact/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/d1e5be8c71da6fc06032e830698fd5a64184e199', 'message': 'Remove zmq-event-publisher jobs\n\nThese jobs are not used anymore, remove them.\n\nDepends-On: https://review.opendev.org/702745\nChange-Id: I1c6447f9997e953d3f0a0030b46bd910e8910e0c\n'}]",0,702747,d1e5be8c71da6fc06032e830698fd5a64184e199,10,3,1,6547,,,0,"Remove zmq-event-publisher jobs

These jobs are not used anymore, remove them.

Depends-On: https://review.opendev.org/702745
Change-Id: I1c6447f9997e953d3f0a0030b46bd910e8910e0c
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/47/702747/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/zmq-event-publisher-jenkinsci-upload/run.yaml', 'playbooks/legacy/zmq-event-publisher-maven-build-ubuntu-trusty/run.yaml', 'playbooks/legacy/zmq-event-publisher-hpi-artifact/post.yaml', 'playbooks/legacy/zmq-event-publisher-hpi-artifact/run.yaml']",5,d1e5be8c71da6fc06032e830698fd5a64184e199,retire-zmq-event-publisher,,"- hosts: all name: Autoconverted job legacy-zmq-event-publisher-hpi-artifact from old job zmq-event-publisher-hpi-artifact roles: - bindep tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ https://opendev.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x /usr/local/jenkins/slave_scripts/version-properties.sh source version.properties mvn clean package -B -Dproject-version=$PROJECT_VER cp ./target/$ZUUL_SHORT_PROJECT_NAME.hpi ./target/$ZUUL_SHORT_PROJECT_NAME-$PROJECT_VER.hpi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,203
openstack%2Fkuryr-kubernetes~master~If7d32023e467d1a63812057e1d151901ce462c7f,openstack/kuryr-kubernetes,master,If7d32023e467d1a63812057e1d151901ce462c7f,Add support for listeners on the same port but different protocol,MERGED,2020-01-13 16:04:02.000000000,2020-01-15 21:36:29.000000000,2020-01-15 21:33:42.000000000,"[{'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-01-13 16:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/7ef385dea9200c30640face5ae209b365fccd432', 'message': ""Add support for listeners on the same port but different protocol\n\nDue to a bug in Octavia this was previously avoided. This is now\nsupported for the amphora provider, so it won't be blocked on the\nkuryr side\n\nChange-Id: If7d32023e467d1a63812057e1d151901ce462c7f\n""}, {'number': 2, 'created': '2020-01-13 16:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/54d61d5a2a5505b7b1e29cbdf87e711ca9df53ce', 'message': ""Add support for listeners on the same port but different protocol\n\nDue to a bug in Octavia this was previously avoided. This is now\nsupported for the amphora provider, so it won't be blocked on the\nkuryr side\n\nChange-Id: If7d32023e467d1a63812057e1d151901ce462c7f\n""}, {'number': 3, 'created': '2020-01-14 13:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/5b85e4a7daa215c8df3ecbc36db587bc053bac73', 'message': ""Add support for listeners on the same port but different protocol\n\nDue to a bug in Octavia this was previously avoided. This is now\nsupported for the amphora provider, so it won't be blocked on the\nkuryr side\n\nChange-Id: If7d32023e467d1a63812057e1d151901ce462c7f\n""}, {'number': 4, 'created': '2020-01-15 17:47:42.000000000', 'files': ['kuryr_kubernetes/controller/handlers/lbaas.py', 'kuryr_kubernetes/controller/drivers/lbaasv2.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/3196021b9ee85276f13c21ad9d47d2d04abe4c79', 'message': ""Add support for listeners on the same port but different protocol\n\nDue to a bug in Octavia this was previously avoided. This is now\nsupported for the amphora provider, so it won't be blocked on the\nkuryr side\n\nChange-Id: If7d32023e467d1a63812057e1d151901ce462c7f\n""}]",2,702251,3196021b9ee85276f13c21ad9d47d2d04abe4c79,21,5,4,23567,,,0,"Add support for listeners on the same port but different protocol

Due to a bug in Octavia this was previously avoided. This is now
supported for the amphora provider, so it won't be blocked on the
kuryr side

Change-Id: If7d32023e467d1a63812057e1d151901ce462c7f
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/51/702251/4 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/handlers/lbaas.py', 'kuryr_kubernetes/controller/drivers/lbaasv2.py']",2,7ef385dea9200c30640face5ae209b365fccd432,octavia-acl,"_OCTAVIA_DL_VERSION = 2, 11 self._octavia_double_listeners = False if v >= _OCTAVIA_DL_VERSION: # FIXME(ltomasbo): ovn-octavia driver does not yet support double # listeners. Remove when it does and consider the right microversion if CONF.kubernetes.endpoints_driver_octavia_provider != 'ovn': self._octavia_double_listeners = True def double_listeners_supported(self): return self._octavia_double_listeners ",,14,2
openstack%2Fnova~stable%2Frocky~I7de14456d04370c842b4c35597dca3a628a826a2,openstack/nova,stable/rocky,I7de14456d04370c842b4c35597dca3a628a826a2,Improve metadata server performance with large security groups,MERGED,2019-12-05 16:40:30.000000000,2020-01-15 21:27:36.000000000,2020-01-15 21:27:36.000000000,"[{'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10980}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-12-05 16:40:30.000000000', 'files': ['nova/tests/unit/network/security_group/test_neutron_driver.py', 'nova/network/security_group/neutron_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/38b2f68a17533e839819e654825613aefd4effd4', 'message': ""Improve metadata server performance with large security groups\n\nDon't include the rules in the SG fetch in the metadata server, since\nwe don't need them there, and with >1000 rules, it starts to get\nreally slow, especially in Pike and later.\n\nCloses-Bug: #1851430\n\nCo-Authored-By: Doug Wiegley <dougwig@parkside.io>\nCo-Authored-By: Matt Riedemann <mriedem.os@gmail.com>\n\nChange-Id: I7de14456d04370c842b4c35597dca3a628a826a2\n(cherry picked from commit eaf16fdde59a14fb38df669b21a911a0c2d2576f)\n(cherry picked from commit 418af2d865809cfa907678f883dae07f4f31baa2)\n(cherry picked from commit fec95a2e4f763e15193504483383f918feb3e636)\n""}]",0,697517,38b2f68a17533e839819e654825613aefd4effd4,40,9,1,6873,,,0,"Improve metadata server performance with large security groups

Don't include the rules in the SG fetch in the metadata server, since
we don't need them there, and with >1000 rules, it starts to get
really slow, especially in Pike and later.

Closes-Bug: #1851430

Co-Authored-By: Doug Wiegley <dougwig@parkside.io>
Co-Authored-By: Matt Riedemann <mriedem.os@gmail.com>

Change-Id: I7de14456d04370c842b4c35597dca3a628a826a2
(cherry picked from commit eaf16fdde59a14fb38df669b21a911a0c2d2576f)
(cherry picked from commit 418af2d865809cfa907678f883dae07f4f31baa2)
(cherry picked from commit fec95a2e4f763e15193504483383f918feb3e636)
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/697517/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/security_group/test_neutron_driver.py', 'nova/network/security_group/neutron_driver.py']",2,38b2f68a17533e839819e654825613aefd4effd4,faster-sg-pull," def _get_secgroups_from_port_list(self, ports, neutron, fields=None): if fields: sg_search_opts['fields'] = fields If detailed is False only the security group name is returned. # If detailed is True, we want all fields from the security groups # including the potentially slow-to-join security_group_rules field. # But if detailed is False, only get the id and name fields since # that's all we'll use below. fields = None if detailed else ['id', 'name'] security_groups = self._get_secgroups_from_port_list( ports, neutron, fields=fields) security groups associated with an instance, otherwise just the security group name."," def _get_secgroups_from_port_list(self, ports, neutron): security_groups = self._get_secgroups_from_port_list(ports, neutron) security groups associated with an instance.",45,11
openstack%2Freleases~master~Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec,openstack/releases,master,Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec,os-traits: release 2.2.0,MERGED,2020-01-15 12:11:33.000000000,2020-01-15 21:24:28.000000000,2020-01-15 21:24:28.000000000,"[{'_account_id': 11904}, {'_account_id': 14070}, {'_account_id': 18081}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 12:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/5ade4efab8524484cd3d84fec01b25825f771628', 'message': 'os-traits: release 2.2.0\n\nThis adds a single trait, COMPUTE_RESCUE_BFV:\n\nc37f67a Add COMPUTE_RESCUE_BFV trait\n\nChange-Id: Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec\n'}, {'number': 2, 'created': '2020-01-15 13:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/52fb2f078296528a2de130c3a025ae376e3de504', 'message': 'os-traits: release 2.2.0\n\nThis adds a single trait, COMPUTE_RESCUE_BFV:\n\nc37f67a Add COMPUTE_RESCUE_BFV trait\n\nChange-Id: Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec\n'}, {'number': 3, 'created': '2020-01-15 20:45:09.000000000', 'files': ['deliverables/_independent/os-traits.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f73474b93e9f2e493a34e4b2a3c45a3b2bf2e359', 'message': 'os-traits: release 2.2.0\n\nThis adds COMPUTE_RESCUE_BFV and COMPUTE_ACCELERATORS:\n\nc37f67a Add COMPUTE_RESCUE_BFV trait\nbdc942a Add a trait that compute manager can handle accelerator requests.\n\nChange-Id: Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec\n'}]",0,702652,f73474b93e9f2e493a34e4b2a3c45a3b2bf2e359,12,4,3,10135,,,0,"os-traits: release 2.2.0

This adds COMPUTE_RESCUE_BFV and COMPUTE_ACCELERATORS:

c37f67a Add COMPUTE_RESCUE_BFV trait
bdc942a Add a trait that compute manager can handle accelerator requests.

Change-Id: Iba9e61c430c6bf31c9761c967dcd52a6d1a7faec
",git fetch https://review.opendev.org/openstack/releases refs/changes/52/702652/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/os-traits.yaml'],1,5ade4efab8524484cd3d84fec01b25825f771628,, - version: 2.2.0 projects: - repo: openstack/os-traits hash: c37f67aea14e35eebed4566718534b393a45f5b4 ,,4,0
openstack%2Fironic-python-agent~master~I4b4d79768c8936c4b9826545498bd6de059d5121,openstack/ironic-python-agent,master,I4b4d79768c8936c4b9826545498bd6de059d5121,"Update hardware to 0.24,0",MERGED,2020-01-15 11:45:43.000000000,2020-01-15 21:18:27.000000000,2020-01-15 21:16:54.000000000,"[{'_account_id': 6618}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-01-15 11:45:43.000000000', 'files': ['plugin-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/74c6fe85f1a1008dd0382194167de2688d3360c8', 'message': 'Update hardware to 0.24,0\n\nThis removes python2 support and adds some bug fixes.\n\nChange-Id: I4b4d79768c8936c4b9826545498bd6de059d5121\n'}]",0,702651,74c6fe85f1a1008dd0382194167de2688d3360c8,12,6,1,12898,,,0,"Update hardware to 0.24,0

This removes python2 support and adds some bug fixes.

Change-Id: I4b4d79768c8936c4b9826545498bd6de059d5121
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/51/702651/1 && git format-patch -1 --stdout FETCH_HEAD,['plugin-requirements.txt'],1,74c6fe85f1a1008dd0382194167de2688d3360c8,no-more-py2,hardware>=0.24.0,hardware>=0.20.1,1,1
openstack%2Fproject-config~master~I67e67a1e98d85e5a8ed31001b26e280e29bc6318,openstack/project-config,master,I67e67a1e98d85e5a8ed31001b26e280e29bc6318,Add noop-jobs for zmq-event-publisher,MERGED,2020-01-15 20:26:05.000000000,2020-01-15 21:13:19.000000000,2020-01-15 21:13:19.000000000,"[{'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 20:26:05.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fc30f930fa28d605e5bfc5ed6c7514a538bf81e2', 'message': ""Add noop-jobs for zmq-event-publisher\n\nThis repo is not used anymore, it's been forked and taken over.\n\nRemove jobs and add noop-jobs so that we can remove jobs and retire repo\nif needed.\n\nChange-Id: I67e67a1e98d85e5a8ed31001b26e280e29bc6318\n""}]",0,702745,fc30f930fa28d605e5bfc5ed6c7514a538bf81e2,8,2,1,6547,,,0,"Add noop-jobs for zmq-event-publisher

This repo is not used anymore, it's been forked and taken over.

Remove jobs and add noop-jobs so that we can remove jobs and retire repo
if needed.

Change-Id: I67e67a1e98d85e5a8ed31001b26e280e29bc6318
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/702745/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,fc30f930fa28d605e5bfc5ed6c7514a538bf81e2,retire-zmq-event-publisher, templates: - noop-jobs, check: jobs: - legacy-zmq-event-publisher-maven-build-ubuntu-trusty gate: jobs: - legacy-zmq-event-publisher-maven-build-ubuntu-trusty post: jobs: - legacy-zmq-event-publisher-hpi-artifact release: jobs: - legacy-zmq-event-publisher-jenkinsci-upload: dependencies: - legacy-zmq-event-publisher-hpi-artifact - legacy-zmq-event-publisher-hpi-artifact,2,15
openstack%2Fironic~master~I8c8b8c707102275a48233fc853acfb65f556946e,openstack/ironic,master,I8c8b8c707102275a48233fc853acfb65f556946e,Fix API docs for target_power_state response,MERGED,2020-01-14 22:02:03.000000000,2020-01-15 21:11:47.000000000,2020-01-15 21:09:41.000000000,"[{'_account_id': 6618}, {'_account_id': 11655}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-14 22:02:03.000000000', 'files': ['api-ref/source/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6da62945bc8fe487c2058a802c26b2d79e1b32af', 'message': 'Fix API docs for target_power_state response\n\nThe API docs stated that the values of target_power_state in a\nNode State Summary are the same as the valid input values in a Change\nNode Power State request (i.e. they include ""rebooting"", ""soft\nrebooting"", and ""soft power off""). However, in actuality these are all\ncompressed to either ""power on"" or ""power off"" by the\n_calculate_target_state() function.\n\nChange-Id: I8c8b8c707102275a48233fc853acfb65f556946e\nStory: #2007089\nTask: 38115\n'}]",0,702542,6da62945bc8fe487c2058a802c26b2d79e1b32af,9,4,1,4257,,,0,"Fix API docs for target_power_state response

The API docs stated that the values of target_power_state in a
Node State Summary are the same as the valid input values in a Change
Node Power State request (i.e. they include ""rebooting"", ""soft
rebooting"", and ""soft power off""). However, in actuality these are all
compressed to either ""power on"" or ""power off"" by the
_calculate_target_state() function.

Change-Id: I8c8b8c707102275a48233fc853acfb65f556946e
Story: #2007089
Task: 38115
",git fetch https://review.opendev.org/openstack/ironic refs/changes/42/702542/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/parameters.yaml'],1,6da62945bc8fe487c2058a802c26b2d79e1b32af,," requested (ie, ""target"") state, either ""power on"" or ""power off""."," requested (ie, ""target"") state either ""power on"", ""power off"", ""rebooting"", ""soft power off"" or ""soft rebooting"".",1,2
openstack%2Fironic-python-agent~master~I2e995ef356075be2a7f5b0a1906d02f90fe98a06,openstack/ironic-python-agent,master,I2e995ef356075be2a7f5b0a1906d02f90fe98a06,Omit configdrive and system_logs from logging,MERGED,2020-01-11 17:28:49.000000000,2020-01-15 21:11:32.000000000,2020-01-15 21:09:45.000000000,"[{'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-11 17:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/07a74e7cb5633540cc53ccc2b11628f63c92803b', 'message': 'Omit configdrive and system_logs from logging\n\nSince they are large and base64-encoded, they bloat ramdisk logs.\n\nChange-Id: I2e995ef356075be2a7f5b0a1906d02f90fe98a06\n'}, {'number': 2, 'created': '2020-01-13 10:53:36.000000000', 'files': ['ironic_python_agent/extensions/base.py', 'ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/d40132ad7105ec1b039d025587a82510ea9698f4', 'message': 'Omit configdrive and system_logs from logging\n\nSince they are large and base64-encoded, they bloat ramdisk logs.\n\nChange-Id: I2e995ef356075be2a7f5b0a1906d02f90fe98a06\n'}]",0,702095,d40132ad7105ec1b039d025587a82510ea9698f4,20,5,2,10239,,,0,"Omit configdrive and system_logs from logging

Since they are large and base64-encoded, they bloat ramdisk logs.

Change-Id: I2e995ef356075be2a7f5b0a1906d02f90fe98a06
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/95/702095/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/extensions/base.py', 'ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py']",3,07a74e7cb5633540cc53ccc2b11628f63c92803b,system-logs,"from collections import abc def remove_keys(var, keys, replace_with=""<removed>""): """"""Remove specific keys from the var, recursing into dicts and lists."""""" if isinstance(var, abc.Mapping): return var.__class__( (key, remove_keys(value, keys, replace_with) if key not in keys else replace_with) for key, value in var.items()) elif isinstance(var, abc.Sequence) and not isinstance(var, str): return var.__class__(remove_keys(item, keys, replace_with) for item in var) else: return var",,38,3
openstack%2Fproject-config~master~Ic526595e4eac0e530eeb7603a88165b9616e0d17,openstack/project-config,master,Ic526595e4eac0e530eeb7603a88165b9616e0d17,New charm for watcher,MERGED,2020-01-11 10:24:59.000000000,2020-01-15 21:07:26.000000000,2020-01-15 15:01:54.000000000,"[{'_account_id': 935}, {'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 13686}, {'_account_id': 22348}, {'_account_id': 30442}]","[{'number': 1, 'created': '2020-01-11 10:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3ed8127854b97cccc232097534237eb75994ece7', 'message': 'New charm for watcher\n\nAdd watcher charm to support charmed OpenStack Watcher\n\nChange-Id: Ic526595e4eac0e530eeb7603a88165b9616e0d17\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}, {'number': 2, 'created': '2020-01-11 10:28:50.000000000', 'files': ['zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a54ab1311697287960ab6cf4ad4b761e83fd216', 'message': 'New charm for watcher\n\nAdd watcher charm to support charmed OpenStack Watcher\n\nNeeded-By: Iba68b49c1eedd29afaca67bc3c2ed2f716da7a57\nChange-Id: Ic526595e4eac0e530eeb7603a88165b9616e0d17\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}]",0,702071,4a54ab1311697287960ab6cf4ad4b761e83fd216,10,6,2,28014,,,0,"New charm for watcher

Add watcher charm to support charmed OpenStack Watcher

Needed-By: Iba68b49c1eedd29afaca67bc3c2ed2f716da7a57
Change-Id: Ic526595e4eac0e530eeb7603a88165b9616e0d17
Signed-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/702071/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul/main.yaml']",2,3ed8127854b97cccc232097534237eb75994ece7,, - openstack/charm-watcher,,7,0
openstack%2Foslotest~master~Ie5f147cff6e92ce64c32b50a01e65c042dbc0b74,openstack/oslotest,master,Ie5f147cff6e92ce64c32b50a01e65c042dbc0b74,trivial: Cleanup of doc config file,MERGED,2019-12-19 09:57:03.000000000,2020-01-15 21:06:19.000000000,2020-01-15 21:03:39.000000000,"[{'_account_id': 6928}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-19 09:57:03.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/0b3c98a34900b49d5efd95b80b417df165536eb1', 'message': 'trivial: Cleanup of doc config file\n\nChange-Id: Ie5f147cff6e92ce64c32b50a01e65c042dbc0b74\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,699941,0b3c98a34900b49d5efd95b80b417df165536eb1,8,3,1,15334,,,0,"trivial: Cleanup of doc config file

Change-Id: Ie5f147cff6e92ce64c32b50a01e65c042dbc0b74
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/41/699941/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,0b3c98a34900b49d5efd95b80b417df165536eb1,trivial,# # -- openstackdocstheme configuration ------------------------------------- ,"# This file is execfile()d with the current directory set to its # containing dir. # # Note that not all possible configuration values are present in this # autogenerated file. # # All configuration values have a default; values that are commented out # serve to show the default. # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. # sys.path.insert(0, os.path.abspath('.')) # If your documentation needs a minimal Sphinx version, state it here. # needs_sphinx = '1.0' # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. # source_encoding = 'utf-8-sig' # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: # today = '' # Else, today_fmt is used as the format for a strftime call. # today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. # default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. # add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). # add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. # show_authors = False # A list of ignored prefixes for module index sorting. # modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. # keep_warnings = False # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. # html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. # html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". # html_title = None # A shorter title for the navigation bar. Default is the same as html_title. # html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. # html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. # html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. # html_extra_path = [] # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. # html_use_smartypants = True # Custom sidebar templates, maps document names to template names. # html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. # html_additional_pages = {} # If false, no module index is generated. # html_domain_indices = True # If false, no index is generated. # html_use_index = True # If true, the index is split into individual pages for each letter. # html_split_index = False # If true, links to the reST sources are added to the pages. # html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. # html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. # html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. # html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). # html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'oslotestReleaseNotesDoc' # openstackdocstheme options # -- Options for LaTeX output --------------------------------------------- latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'oslotestReleaseNotes.tex', u'oslotest Release Notes Documentation', u'oslotest Developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. # latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. # latex_use_parts = False # If true, show page references after internal links. # latex_show_pagerefs = False # If true, show URL addresses after external links. # latex_show_urls = False # Documents to append as an appendix to all manuals. # latex_appendices = [] # If false, no module index is generated. # latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'oslotestReleaseNotes', u'oslotest Release Notes Documentation', [u'oslotest Developers'], 1) ] # If true, show URL addresses after external links. # man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'oslotestReleaseNotes', u'oslotest Release Notes Documentation', u'oslotest Developers', 'oslotestReleaseNotes', 'One line description of project.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. # texinfo_appendices = [] # If false, no module index is generated. # texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. # texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. # texinfo_no_detailmenu = False # -- Options for Internationalization output ------------------------------ locale_dirs = ['locale/']",9,253
openstack%2Foslotest~master~I1a5f9bbcad2ef9e4551739900a7e688bfffa0a6c,openstack/oslotest,master,I1a5f9bbcad2ef9e4551739900a7e688bfffa0a6c,tox: Trivial cleanup,MERGED,2019-12-19 09:57:03.000000000,2020-01-15 21:05:05.000000000,2020-01-15 21:03:38.000000000,"[{'_account_id': 6928}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-12-19 09:57:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/e177e5db2109d56810839020648e67711332519a', 'message': ""tox: Trivial cleanup\n\nRemove some noise and move 'basepython' to the top-level 'testenv'. Also\nuse the new-style URL for upper constraints.\n\nChange-Id: I1a5f9bbcad2ef9e4551739900a7e688bfffa0a6c\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",3,699940,e177e5db2109d56810839020648e67711332519a,11,4,1,15334,,,0,"tox: Trivial cleanup

Remove some noise and move 'basepython' to the top-level 'testenv'. Also
use the new-style URL for upper constraints.

Change-Id: I1a5f9bbcad2ef9e4551739900a7e688bfffa0a6c
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/40/699940/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e177e5db2109d56810839020648e67711332519a,trivial,"minversion = 3.1ignore_basepython_conflict = Truebasepython = python3 -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} PYTHON=coverage run --source oslotest --parallel-mode stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml [flake8] show-source = true exclude = .tox,dist,doc,*.egg,build [hacking] import_exceptions = six.moves.mock","minversion = 2.0 distribute = Falseinstall_command = pip install {opts} {packages} -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt}[testenv:py27] basepython = python2.7 basepython = python3basepython = python3 PYTHON=coverage run --source oslotest --parallel-mode stestr run {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xmlbasepython = python3basepython = python3[flake8] show-source = True exclude = .tox,dist,doc,*.egg,build [hacking] import_exceptions = six.moves.mock basepython = python3basepython = python3",17,26
openstack%2Fnetworking-ovn~stable%2Ftrain~I0b01b764413d178759a43028428c212014d3aa80,openstack/networking-ovn,stable/train,I0b01b764413d178759a43028428c212014d3aa80,Add support for virtual port type,MERGED,2019-12-05 15:33:31.000000000,2020-01-15 20:35:03.000000000,2020-01-15 20:33:06.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-12-05 15:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/de24bb72464ab4bd1b50ef207df0c8ecef9f3224', 'message': 'Add support for virtual port type\n\nThis patch adds support for ""virtual"" port type following the work in\ncore OVN [0].\n\nCurrently there are two main usages for this type of port:\n\n* Octavia: For creating the logical port for the virtual IP.\n* VRRP [1]\n\nUpon adding an IP address to the allowed_address_pairs field of the\nNeutron\'s port, networking-ovn will look if that IP matches with the IP\nof another existing port in the same network. If so, networking-ovn will\nupdating the matching port accordingly setting its type to ""virtual""\nand adding the required options in the OVN database.\n\nThe patch also accounts for other situations such as:\n\n* Creating the VIP port after the parents (the ones with the IP in the\n  allowed_address_pairs field) are created.\n\n* When updating removing/adding allowed_address_pairs\' the virtual\n  ports are also updated.\n\n* When deleting a parent port the virtual ports are also updated.\n\nThe code removes the type ""virtual"" from a virtual port whenever there\'s\nno parents left (in case of deletion or editing allowed_address_pairs)\nmaking it an ordinary port again.\n\nThe patch also keeps the logic introduced by\n33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does\nnot support the virtual port type (> 2.12) making it backward compatible.\n\n[0]\nhttps://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c\n[1]\nhttps://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html\n\nConflicts:\n    networking_ovn/common/utils.py\n    networking_ovn/tests/unit/fakes.py\n\nCloses-Bug: #1840449\nRelated-Bug: #1789686\nChange-Id: I0b01b764413d178759a43028428c212014d3aa80\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)\n'}, {'number': 2, 'created': '2019-12-05 19:11:26.000000000', 'files': ['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/07df2a6bf8acb58608f7bc706556bf3541cc5d4c', 'message': 'Add support for virtual port type\n\nThis patch adds support for ""virtual"" port type following the work in\ncore OVN [0].\n\nCurrently there are two main usages for this type of port:\n\n* Octavia: For creating the logical port for the virtual IP.\n* VRRP [1]\n\nUpon adding an IP address to the allowed_address_pairs field of the\nNeutron\'s port, networking-ovn will look if that IP matches with the IP\nof another existing port in the same network. If so, networking-ovn will\nupdating the matching port accordingly setting its type to ""virtual""\nand adding the required options in the OVN database.\n\nThe patch also accounts for other situations such as:\n\n* Creating the VIP port after the parents (the ones with the IP in the\n  allowed_address_pairs field) are created.\n\n* When updating removing/adding allowed_address_pairs\' the virtual\n  ports are also updated.\n\n* When deleting a parent port the virtual ports are also updated.\n\nThe code removes the type ""virtual"" from a virtual port whenever there\'s\nno parents left (in case of deletion or editing allowed_address_pairs)\nmaking it an ordinary port again.\n\nThe patch also keeps the logic introduced by\n33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does\nnot support the virtual port type (> 2.12) making it backward compatible.\n\n[0]\nhttps://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c\n[1]\nhttps://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html\n\nConflicts:\n    networking_ovn/common/utils.py\n    networking_ovn/tests/unit/fakes.py\n\nCloses-Bug: #1840449\nRelated-Bug: #1789686\nChange-Id: I0b01b764413d178759a43028428c212014d3aa80\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)\n'}]",0,697503,07df2a6bf8acb58608f7bc706556bf3541cc5d4c,14,6,2,6773,,,0,"Add support for virtual port type

This patch adds support for ""virtual"" port type following the work in
core OVN [0].

Currently there are two main usages for this type of port:

* Octavia: For creating the logical port for the virtual IP.
* VRRP [1]

Upon adding an IP address to the allowed_address_pairs field of the
Neutron's port, networking-ovn will look if that IP matches with the IP
of another existing port in the same network. If so, networking-ovn will
updating the matching port accordingly setting its type to ""virtual""
and adding the required options in the OVN database.

The patch also accounts for other situations such as:

* Creating the VIP port after the parents (the ones with the IP in the
  allowed_address_pairs field) are created.

* When updating removing/adding allowed_address_pairs' the virtual
  ports are also updated.

* When deleting a parent port the virtual ports are also updated.

The code removes the type ""virtual"" from a virtual port whenever there's
no parents left (in case of deletion or editing allowed_address_pairs)
making it an ordinary port again.

The patch also keeps the logic introduced by
33fd553158a96b4dc40c66acf050fa7f91227dec for version of OVN which does
not support the virtual port type (> 2.12) making it backward compatible.

[0]
https://github.com/ovn-org/ovn/commit/054f4c85c413e20d893e10ba053ec52ac15db49c
[1]
https://docs.catalystcloud.io/tutorials/deploying-highly-available-instances-with-keepalived.html

Conflicts:
    networking_ovn/common/utils.py
    networking_ovn/tests/unit/fakes.py

Closes-Bug: #1840449
Related-Bug: #1789686
Change-Id: I0b01b764413d178759a43028428c212014d3aa80
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 5e72ea104cba1c30d2de36dbbab6e3d23a075929)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/03/697503/2 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/ovn_client.py', 'networking_ovn/common/utils.py', 'networking_ovn/common/constants.py', 'networking_ovn/ovsdb/ovn_api.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/ovsdb/commands.py', 'releasenotes/notes/virtual-ports-fe725a817ce45e6d.yaml', 'networking_ovn/tests/functional/test_mech_driver.py', 'networking_ovn/tests/unit/fakes.py']",10,de24bb72464ab4bd1b50ef207df0c8ecef9f3224,, self.set_lswitch_port_to_virtual_type = mock.Mock() self.unset_lswitch_port_to_virtual_type = mock.Mock() self.ls_get = mock.Mock() self.is_col_present = mock.Mock() self.is_col_present.return_value = False,,580,23
openstack%2Ftripleo-docs~master~Ie8f48a82f4f2bcf3ef5bdfcf661a7788596e1f4e,openstack/tripleo-docs,master,Ie8f48a82f4f2bcf3ef5bdfcf661a7788596e1f4e,Added missing installation steps to overcloud validation,ABANDONED,2019-03-12 17:13:18.000000000,2020-01-15 20:24:33.000000000,,"[{'_account_id': 10239}, {'_account_id': 10806}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-03-12 17:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/0626815d44e659d6153cdcbe7e17924a6fad756c', 'message': 'Added missing installation steps to overcloud validation\n\nAdded the instructions for installing 2 packages for running tempest for\novercloud validation.\n\nChange-Id: Ie8f48a82f4f2bcf3ef5bdfcf661a7788596e1f4e\nCloses-Bug: 1742136\n'}, {'number': 2, 'created': '2019-03-12 20:31:36.000000000', 'files': ['doc/source/install/basic_deployment/basic_deployment_cli.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/f5e5e37c640fe6ad14bce993460d457ef81e38bc', 'message': 'Added missing installation steps to overcloud validation\n\nAdded the instructions for installing 2 packages for running tempest for\novercloud validation.\n\nChange-Id: Ie8f48a82f4f2bcf3ef5bdfcf661a7788596e1f4e\nCloses-Bug: 1742136\n'}]",6,642828,f5e5e37c640fe6ad14bce993460d457ef81e38bc,13,4,2,10806,,,0,"Added missing installation steps to overcloud validation

Added the instructions for installing 2 packages for running tempest for
overcloud validation.

Change-Id: Ie8f48a82f4f2bcf3ef5bdfcf661a7788596e1f4e
Closes-Bug: 1742136
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/28/642828/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/basic_deployment/basic_deployment_cli.rst'],1,0626815d44e659d6153cdcbe7e17924a6fad756c,bug/1742136,The following additional packages are required for overcloud validation:: sudo yum install -y python-ironic-inspector-tests pip install gabbi ,,7,0
openstack%2Fkolla~stable%2Fstein~I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e,openstack/kolla,stable/stein,I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e,CI: Fix symlinks for failed build logs,MERGED,2020-01-13 10:02:31.000000000,2020-01-15 20:00:46.000000000,2020-01-15 19:58:13.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-01-13 10:02:31.000000000', 'files': ['tests/playbooks/post.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f6ad36b5fe56ec2d80e703751ae641b02d98b99b', 'message': 'CI: Fix symlinks for failed build logs\n\nFollow up to I5b5f323471676317a2898875cbbf297082328fcc. Logs are no\nlonger gzipped, so we do not need to modify the 000_FAILED_* symlinks.\n\nChange-Id: I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e\n(cherry picked from commit 63f773f569c7601deab40b32bd62ccde513fa46f)\n'}]",0,702179,f6ad36b5fe56ec2d80e703751ae641b02d98b99b,13,4,1,14826,,,0,"CI: Fix symlinks for failed build logs

Follow up to I5b5f323471676317a2898875cbbf297082328fcc. Logs are no
longer gzipped, so we do not need to modify the 000_FAILED_* symlinks.

Change-Id: I5df42ac0ff91b1b97537a4fbc33fc7970f29d60e
(cherry picked from commit 63f773f569c7601deab40b32bd62ccde513fa46f)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/79/702179/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/playbooks/post.yml'],1,f6ad36b5fe56ec2d80e703751ae641b02d98b99b,,," # Update symlinks to new file names for f in $(find . -name ""*FAILED*""); do mv ${f} ${f}.gz ln -sf ${f#*/000_FAILED_}.gz ${f}.gz done ",0,6
openstack%2Ftripleo-operator-ansible~master~Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df,openstack/tripleo-operator-ansible,master,Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df,Add undercloud job to cover changes,MERGED,2020-01-09 17:36:58.000000000,2020-01-15 19:56:41.000000000,2020-01-15 19:56:41.000000000,"[{'_account_id': 3153}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-09 17:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/1708d892b4ed86dfd8c68e3ed66851c61baa0034', 'message': 'Add undercloud job to cover changes\n\nOnce we switch quickstart to use this, we should run the undercloud job\nto test changes to the install role.\n\nDepends-On: https://review.opendev.org/#/c/701034/\nChange-Id: Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df\n'}, {'number': 2, 'created': '2020-01-14 14:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/fc3cc52e9ed324baa17d832442d2ebc390fd8c1f', 'message': 'Add undercloud job to cover changes\n\nOnce we switch quickstart to use this, we should run the undercloud job\nto test changes to the install role.\n\nDepends-On: https://review.opendev.org/#/c/701034/\nChange-Id: Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df\n'}, {'number': 3, 'created': '2020-01-14 14:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/914234637570fca9611ea6897e1ae827cbb0fff9', 'message': 'Add undercloud job to cover changes\n\nOnce we switch quickstart to use this, we should run the undercloud job\nto test changes to the install role.\n\nDepends-On: https://review.opendev.org/#/c/701034/\nChange-Id: Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df\n'}, {'number': 4, 'created': '2020-01-14 16:04:59.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-operator-ansible/commit/50aea8d6380d9aaf84ddc327e9ab696833291eeb', 'message': 'Add undercloud job to cover changes\n\nOnce we switch quickstart to use this, we should run the undercloud job\nto test changes to the install role.\n\nDepends-On: https://review.opendev.org/#/c/701034/\nChange-Id: Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df\n'}]",0,701780,50aea8d6380d9aaf84ddc327e9ab696833291eeb,20,4,4,14985,,,0,"Add undercloud job to cover changes

Once we switch quickstart to use this, we should run the undercloud job
to test changes to the install role.

Depends-On: https://review.opendev.org/#/c/701034/
Change-Id: Id4d2f5577b68c4515111fb1dd6cc05aedbfb96df
",git fetch https://review.opendev.org/openstack/tripleo-operator-ansible refs/changes/80/701780/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,1708d892b4ed86dfd8c68e3ed66851c61baa0034,tripleo-undercloud, - tripleo-ci-centos-7-containers-multinode: dependencies: &deps_unit_lint - openstack-tox-pep8 - openstack-tox-py36 - openstack-tox-py37 - openstack-tox-linters files: &continers_multinode_files - ^roles/tripleo-undercloud-install/.*$ - tripleo-ci-centos-7-containers-multinode: files: *continers_multinode_files,,10,0
openstack%2Fkuryr-kubernetes~master~I3f8573e1284e26891e09e6b8e3204f3e02220363,openstack/kuryr-kubernetes,master,I3f8573e1284e26891e09e6b8e3204f3e02220363,Make OpenShift gates to use NPs,MERGED,2020-01-03 12:11:29.000000000,2020-01-15 19:48:37.000000000,2020-01-15 19:44:35.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-01-03 12:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/b1430adb1c85f95c458809137a80515affa4e0d3', 'message': 'Make OpenShift gates to use NPs\n\nIt also make network policy gates voting\n\nChange-Id: I3f8573e1284e26891e09e6b8e3204f3e02220363\n'}, {'number': 2, 'created': '2020-01-08 14:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/83e80ca7e0471ac89fa73c2e23e0d25cfeafefb8', 'message': 'Make OpenShift gates to use NPs\n\nIt also make network policy gates voting\n\nChange-Id: I3f8573e1284e26891e09e6b8e3204f3e02220363\n'}, {'number': 3, 'created': '2020-01-10 16:52:11.000000000', 'files': ['.zuul.d/project.yaml', '.zuul.d/octavia.yaml', 'devstack/lib/kuryr_kubernetes'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/11b7bd4e400be5d7d2130dd1012a6d8523f477e7', 'message': 'Make OpenShift gates to use NPs\n\nIt also make network policy gates voting\n\nChange-Id: I3f8573e1284e26891e09e6b8e3204f3e02220363\n'}]",0,701019,11b7bd4e400be5d7d2130dd1012a6d8523f477e7,34,6,3,23567,,,0,"Make OpenShift gates to use NPs

It also make network policy gates voting

Change-Id: I3f8573e1284e26891e09e6b8e3204f3e02220363
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/19/701019/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.d/project.yaml', '.zuul.d/octavia.yaml']",2,b1430adb1c85f95c458809137a80515affa4e0d3,np-gates," KURYR_ENABLED_HANDLERS: vif,lb,lbaasspec,namespace,pod_label,policy,kuryrnetpolicy KURYR_SG_DRIVER: policy KURYR_ENABLED_HANDLERS: vif,lb,lbaasspec,namespace,pod_label,policy,kuryrnetpolicy,ocproute,ingresslb"," KURYR_SG_DRIVER: namespace KURYR_ENABLED_HANDLERS: vif,lb,lbaasspec,namespace voting: false KURYR_ENABLED_HANDLERS: vif,lb,lbaasspec,namespace,ocproute,ingresslb",8,7
openstack%2Fosc-placement~master~I8280075a020fb4a10b82b710d5e0ca997a3028fd,openstack/osc-placement,master,I8280075a020fb4a10b82b710d5e0ca997a3028fd,Improve tests for warning messages,MERGED,2019-11-25 09:38:45.000000000,2020-01-15 19:47:07.000000000,2020-01-15 19:43:33.000000000,"[{'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2019-11-25 09:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/9233edfb5e5e24a29c524ef177c2c9a0b3ed47af', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}, {'number': 2, 'created': '2019-11-25 11:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/30350a47b93a8397eac29a49aafedac7c2133223', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}, {'number': 3, 'created': '2019-11-26 09:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/6e87646e81865d970ec5414eb0c4c5d9386ca980', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}, {'number': 4, 'created': '2019-12-03 04:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/2a70f069019892984c7fa679c43aedfd37fc506f', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}, {'number': 5, 'created': '2019-12-06 05:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/df07d184ecf8395f2b7f67351b52bf81eb1d4acf', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}, {'number': 6, 'created': '2020-01-14 05:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/0c750f450b3b470494dc53db102082bd987e3bc7', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}, {'number': 7, 'created': '2020-01-15 01:18:08.000000000', 'files': ['osc_placement/tests/functional/base.py', 'osc_placement/tests/functional/test_allocation.py'], 'web_link': 'https://opendev.org/openstack/osc-placement/commit/d80651a389072e59cf2aaf80af3209f5674a077b', 'message': ""Improve tests for warning messages\n\nThe functional test for allocation create did test that it displays\nthe warning message if the microversion is not high enough, but didn't\nvalidate the returned json result.\n\nThis patch changes it to validate the actual result as well as the\nwarning message.\n\nChange-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd\n""}]",8,695864,d80651a389072e59cf2aaf80af3209f5674a077b,24,4,7,25625,,,0,"Improve tests for warning messages

The functional test for allocation create did test that it displays
the warning message if the microversion is not high enough, but didn't
validate the returned json result.

This patch changes it to validate the actual result as well as the
warning message.

Change-Id: I8280075a020fb4a10b82b710d5e0ca997a3028fd
",git fetch https://review.opendev.org/openstack/osc-placement refs/changes/64/695864/1 && git format-patch -1 --stdout FETCH_HEAD,"['osc_placement/tests/functional/base.py', 'osc_placement/tests/functional/test_allocation.py']",2,9233edfb5e5e24a29c524ef177c2c9a0b3ed47af,catch-up-microversion," # 1.8 does not result in an error but display a warning. output, warning = self.resource_allocation_set( project_id='fake-project', user_id='fake-user') expected = [ {'resource_provider': self.rp1['uuid'], 'generation': 3, 'resources': {'VCPU': 2, 'MEMORY_MB': 512}} ] self.assertEqual(expected, output) '--os-placement-api-version less than 1.8', warning)"," # 1.8 does not result in an error (they will be ignored). We have # to specify use_json=False because there will be a warning in the # output which can't be json-decoded. output = self.resource_allocation_set( project_id='fake-project', user_id='fake-user', use_json=False) '--os-placement-api-version less than 1.8', output)",23,10
openstack%2Fdiskimage-builder~master~I461913029049b03f33660b8bd2de0e6229f5ceb2,openstack/diskimage-builder,master,I461913029049b03f33660b8bd2de0e6229f5ceb2,DNM debugging centos 8.1 updates,ABANDONED,2020-01-15 18:42:16.000000000,2020-01-15 19:36:21.000000000,,"[{'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-01-15 18:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/3adaeeca341cfb7a898cb4a94c2e7245285a50f4', 'message': 'DNM debugging centos 8.1 updates\n\nChange-Id: I461913029049b03f33660b8bd2de0e6229f5ceb2\n'}, {'number': 2, 'created': '2020-01-15 18:43:16.000000000', 'files': ['diskimage_builder/elements/yum-minimal/root.d/08-yum-chroot', '.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9285ff2676649293df92211f7d20957859d4c5ed', 'message': 'DNM debugging centos 8.1 updates\n\nChange-Id: I461913029049b03f33660b8bd2de0e6229f5ceb2\n'}]",0,702722,9285ff2676649293df92211f7d20957859d4c5ed,4,2,2,4146,,,0,"DNM debugging centos 8.1 updates

Change-Id: I461913029049b03f33660b8bd2de0e6229f5ceb2
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/22/702722/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/yum-minimal/root.d/08-yum-chroot'],1,3adaeeca341cfb7a898cb4a94c2e7245285a50f4,debug-centos-8.1-builds,set -x ls -al /etc/ ls -al /etc/yum*,,3,0
openstack%2Fnova~master~I20d181d82b4d4dc68ba58a14eeb25d930b859544,openstack/nova,master,I20d181d82b4d4dc68ba58a14eeb25d930b859544,libvirt: Remove MIN_LIBVIRT_KVM_AARCH64_VERSION,MERGED,2019-11-25 13:48:33.000000000,2020-01-15 19:14:57.000000000,2020-01-15 19:11:09.000000000,"[{'_account_id': 6962}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-11-25 13:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/575128b395d013ea78bbfe57fc859b33b49c05af', 'message': 'libvirt: Remove MIN_LIBVIRT_KVM_AARCH64_VERSION\n\nThe updated minimum required libvirt (5.0.0) and QEMU (4.0.0) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nI3d3679705 (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the version constant MIN_LIBVIRT_KVM_AARCH64_VERSION, and\nnow-needless compatibility code.\n\nChange-Id: I20d181d82b4d4dc68ba58a14eeb25d930b859544\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2019-11-25 13:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fd948173659fddd285759441bb73e37ce68cfb6', 'message': 'libvirt: Remove MIN_LIBVIRT_KVM_AARCH64_VERSION\n\nThe updated minimum required libvirt (5.0.0) and QEMU (4.0.0) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the version constant MIN_LIBVIRT_KVM_AARCH64_VERSION, and\nnow-needless compatibility code.\n\nChange-Id: I20d181d82b4d4dc68ba58a14eeb25d930b859544\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2019-12-06 14:47:48.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/86f7893b4731681c64ff30ef3e7c1624c907c287', 'message': 'libvirt: Remove MIN_LIBVIRT_KVM_AARCH64_VERSION\n\nThe updated minimum required libvirt (4.0.0) and QEMU (2.11) for\n""Ussuri"" satisfy the version requirements; this was done in Change-Id:\nIa18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for\n""Ussuri"", 2019-11-19).\n\nDrop the version constant MIN_LIBVIRT_KVM_AARCH64_VERSION, and\nnow-needless compatibility code.\n\nChange-Id: I20d181d82b4d4dc68ba58a14eeb25d930b859544\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",3,695901,86f7893b4731681c64ff30ef3e7c1624c907c287,42,11,3,6962,,,0,"libvirt: Remove MIN_LIBVIRT_KVM_AARCH64_VERSION

The updated minimum required libvirt (4.0.0) and QEMU (2.11) for
""Ussuri"" satisfy the version requirements; this was done in Change-Id:
Ia18e9be4d (22c1916b49  libvirt: Bump MIN_{LIBVIRT,QEMU}_VERSION for
""Ussuri"", 2019-11-19).

Drop the version constant MIN_LIBVIRT_KVM_AARCH64_VERSION, and
now-needless compatibility code.

Change-Id: I20d181d82b4d4dc68ba58a14eeb25d930b859544
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/695901/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,575128b395d013ea78bbfe57fc859b33b49c05af,Bump_min_libvirt_and_QEMU_for_Ussuri,,"# aarch64 architecture with KVM # 'chardev' support got sorted out in 3.6.0 MIN_LIBVIRT_KVM_AARCH64_VERSION = (3, 6, 0)MIN_LIBVIRT_OTHER_ARCH = { fields.Architecture.AARCH64: MIN_LIBVIRT_KVM_AARCH64_VERSION, } kvm_arch = fields.Architecture.from_host() if (CONF.libvirt.virt_type in ('kvm', 'qemu') and kvm_arch in MIN_LIBVIRT_OTHER_ARCH and not self._host.has_min_version( MIN_LIBVIRT_OTHER_ARCH.get(kvm_arch))): raise exception.InternalError( _('Running Nova with qemu/kvm virt_type on %(arch)s ' 'requires libvirt version %(libvirt_ver)s or greater') % {'arch': kvm_arch, 'libvirt_ver': libvirt_utils.version_to_string( MIN_LIBVIRT_OTHER_ARCH.get(kvm_arch))}) ",0,18
openstack%2Ftripleo-quickstart-extras~master~Iaf18f62f268b72148477a5416ac3b75a34344c75,openstack/tripleo-quickstart-extras,master,Iaf18f62f268b72148477a5416ac3b75a34344c75,[Stein] Remove passing tests from skiplist,MERGED,2019-12-16 18:53:29.000000000,2020-01-15 19:13:23.000000000,2020-01-15 19:13:23.000000000,"[{'_account_id': 5689}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 30742}]","[{'number': 1, 'created': '2019-12-16 18:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c3c21570c0e3400984bfa4a380f6a59ca0d44a32', 'message': '[Stein] Remove passing tests from skiplist\n\nTests which are passing are being removed from the skiplist\nwith this patch.\n\nAlong with that, class\nneutron_tempest_plugin.api.test_networks has maximum no. of\ntests passing, so just kept failing test and other all tests\nare removed.\n\nSigned-off by: Soniya Vyas<svyas@redhat.com>\n\nChange-Id: Iaf18f62f268b72148477a5416ac3b75a34344c75\n'}, {'number': 2, 'created': '2020-01-03 10:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/92e655a52b54f16219b06036ee317b1c7489c855', 'message': '[Stein] Remove passing tests from skiplist\n\nTests which are passing are being removed from the skiplist\nwith this patch.\n\nAlong with that, class\nneutron_tempest_plugin.api.test_networks has maximum no. of\ntests passing, so just kept failing test and other all tests\nare removed.\n\nRelated-Bug: #1753209\n\t     #1793482\n\nSigned-off by: Soniya Vyas<svyas@redhat.com>\nChange-Id: Iaf18f62f268b72148477a5416ac3b75a34344c75\n'}, {'number': 3, 'created': '2020-01-10 06:38:33.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_stein.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5d393c80b8d525683f525c9d6d8a8a5a5798dbb5', 'message': '[Stein] Remove passing tests from skiplist\n\nTests which are passing are being removed from the skiplist\nwith this patch.\n\nAlong with that, class\nneutron_tempest_plugin.api.test_networks has maximum no. of\ntests passing, so just kept failing test and other all tests\nare removed.\n\nRelated-Bug: #1753209\nRelated-Bug: #1793482\n\nSigned-off by: Soniya Vyas<svyas@redhat.com>\nChange-Id: Iaf18f62f268b72148477a5416ac3b75a34344c75\n'}]",2,699275,5d393c80b8d525683f525c9d6d8a8a5a5798dbb5,29,11,3,30742,,,0,"[Stein] Remove passing tests from skiplist

Tests which are passing are being removed from the skiplist
with this patch.

Along with that, class
neutron_tempest_plugin.api.test_networks has maximum no. of
tests passing, so just kept failing test and other all tests
are removed.

Related-Bug: #1753209
Related-Bug: #1793482

Signed-off by: Soniya Vyas<svyas@redhat.com>
Change-Id: Iaf18f62f268b72148477a5416ac3b75a34344c75
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/75/699275/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip_stein.yml'],1,c3c21570c0e3400984bfa4a380f6a59ca0d44a32,update_stein, - test: 'neutron_tempest_plugin.api.test_qos.QosDscpMarkingRuleTestJSON' - test: 'neutron_tempest_plugin.api.test_qos.QosMinimumBandwidthRuleTestJSON' - test: 'neutron_tempest_plugin.api.test_ports.PortsTestJSON' - test: 'neutron_tempest_plugin.api.test_networks.NetworksTestJSON.test_create_update_network_dns_domain' - test: 'neutron_tempest_plugin.api.test_floating_ips.FloatingIPPoolTestJSON.test_create_floatingip_from_specific_pool', - test: 'neutron_tempest_plugin.api.admin.test_shared_network_extension.RBACSharedNetworksTest' reason: 'RBAC policy resource conflict' lp: 'https://bugs.launchpad.net/tripleo/+bug/1753209' - test: 'neutron_tempest_plugin.api.test_trunk_negative' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_timestamp' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_subnetpools_negative' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_service_type_management' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_security_groups' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_routers_negative' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_routers' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_qos' - test: 'neutron_tempest_plugin.api.test_ports' - test: 'neutron_tempest_plugin.api.test_networks_negative' - test: 'neutron_tempest_plugin.api.test_networks' - test: 'neutron_tempest_plugin.api.test_floating_ips_negative' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_floating_ips' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_flavors_extensions' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_extension_driver_port_security' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_allowed_address_pair' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_address_scopes_negative' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.test_address_scopes' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.admin.test_shared_network_extension' - test: 'neutron_tempest_plugin.api.admin.test_networks.NetworksTestAdmin' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482' - test: 'neutron_tempest_plugin.api.admin.test_l3_agent_scheduler' reason: 'neutron tempest tests are failing by giving 503 Service Unavailable' lp: 'https://bugs.launchpad.net/tripleo/+bug/1793482',5,56
openstack%2Fsahara~master~I30485a9933d38db76c031c6e760598c4e47123fc,openstack/sahara,master,I30485a9933d38db76c031c6e760598c4e47123fc,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2019-11-17 14:27:46.000000000,2020-01-15 18:54:01.000000000,2020-01-15 18:49:10.000000000,"[{'_account_id': 8556}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2019-11-17 14:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3834b8110f488066ac3edb0a26ee7b68c54f38c0', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I30485a9933d38db76c031c6e760598c4e47123fc\n'}, {'number': 2, 'created': '2019-11-22 09:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/145c761f9b0fd98bcf7cf55f531ab7c061477b03', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nOther required Sahara changes:\n- port the image building job to CentOS 8, and thus Python 3.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I30485a9933d38db76c031c6e760598c4e47123fc\n'}, {'number': 3, 'created': '2019-11-22 15:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1421a9e3806be5f38db4907512b6c3c0858a5d55', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nOther required Sahara changes:\n- port the image building job to CentOS 8, and thus Python 3.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nChange-Id: I30485a9933d38db76c031c6e760598c4e47123fc\n'}, {'number': 4, 'created': '2019-11-29 16:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7ffcc09f67b08625d7791cab83308b392e3d5c2c', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nOther required Sahara changes:\n- port the image building job to CentOS 8, and thus Python 3.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nDepends-On: https://review.opendev.org/#/c/694699/\nChange-Id: I30485a9933d38db76c031c6e760598c4e47123fc\n'}, {'number': 5, 'created': '2020-01-14 17:38:40.000000000', 'files': ['bindep.txt', 'releasenotes/notes/drop-py-2-7-bc282e43b26fbf17.yaml', '.zuul.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara/commit/17c3249a27124408e0e7b4bf82078562dfefacc6', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nOther required Sahara changes:\n- port the image building job to CentOS 8, and thus Python 3.\n\nDepends-On: https://review.opendev.org/#/c/693631/\nDepends-On: https://review.opendev.org/#/c/694699/\nChange-Id: I30485a9933d38db76c031c6e760598c4e47123fc\n'}]",0,694696,17c3249a27124408e0e7b4bf82078562dfefacc6,31,5,5,8556,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

sahara is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Other required Sahara changes:
- port the image building job to CentOS 8, and thus Python 3.

Depends-On: https://review.opendev.org/#/c/693631/
Depends-On: https://review.opendev.org/#/c/694699/
Change-Id: I30485a9933d38db76c031c6e760598c4e47123fc
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/694696/3 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/drop-py-2-7-bc282e43b26fbf17.yaml', '.zuul.yaml', 'playbooks/sahara-grenade/run.yaml', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",6,3834b8110f488066ac3edb0a26ee7b68c54f38c0,drop-py27-support,"envlist = py37,pep8,genpolicybasepython = python3","envlist = py27,py37,pep8,genpolicybasepython = python3[testenv:debug-py27] basepython = python2.7 commands = oslo_debug_helper -t sahara/tests/unit {posargs} basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",12,23
openstack%2Fironic~master~I39fc7c202c1f148e28c22739f3163081bfa7e0a0,openstack/ironic,master,I39fc7c202c1f148e28c22739f3163081bfa7e0a0,Lower RAM for DIB jobs to 2 GiB,MERGED,2020-01-13 23:30:37.000000000,2020-01-15 18:53:30.000000000,2020-01-15 18:47:09.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10379}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-01-13 23:30:37.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8f2ddc0b2101e0c01d307b2fa3f0b386eeb2bd9f', 'message': 'Lower RAM for DIB jobs to 2 GiB\n\nThe CentOS 8 images we use now are much smaller than the previously\nused CentOS 7 images, so hopefully we can require less RAM.\n\nChange-Id: I39fc7c202c1f148e28c22739f3163081bfa7e0a0\n'}]",0,702308,8f2ddc0b2101e0c01d307b2fa3f0b386eeb2bd9f,24,8,1,10239,,,0,"Lower RAM for DIB jobs to 2 GiB

The CentOS 8 images we use now are much smaller than the previously
used CentOS 7 images, so hopefully we can require less RAM.

Change-Id: I39fc7c202c1f148e28c22739f3163081bfa7e0a0
",git fetch https://review.opendev.org/openstack/ironic refs/changes/08/702308/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,8f2ddc0b2101e0c01d307b2fa3f0b386eeb2bd9f,dib-ram, IRONIC_VM_SPECS_RAM: 2048, IRONIC_VM_SPECS_RAM: 3072,1,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Iadef8f3300bb1b5b995052c1a35a1becbfd5730c,openstack/tripleo-heat-templates,stable/queens,Iadef8f3300bb1b5b995052c1a35a1becbfd5730c,Mount /boot from the host within the nova-compute container,MERGED,2020-01-10 16:27:04.000000000,2020-01-15 18:47:16.000000000,2020-01-15 18:47:15.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-10 16:27:04.000000000', 'files': ['docker/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9212c7c07ac39d5cf397598348e89298bcf6f8b2', 'message': 'Mount /boot from the host within the nova-compute container\n\nlibguestfs expects to find /boot/vmlinuz-* for the running version of\nthe kernel. This check is duplicated in nova-compute when libguestfs has\nfailed to launch, providing a useful bread crumb for operators [1].\n\nObviously when this is called from within the nova-compute container in\nthe context of a TripleO deployment this can easily fail after a minor\nupdate that has pulled in a newer container containing a newer kernel.\nThis check could also fail in the opposite case if the host kernel is\nupdated past the version present in the container.\n\nThis change works around this by simply passing /boot as read-only\nthrough to the nova-compute container ensure libguestfs is able to\nalways find the correct version of vmlinuz.\n\nThis should also allow us to eventually drop the kernel RPM from the\nnova-compute container that has been a constant source of maintenance\noverhead in terms of CVEs etc.\n\n[1] https://github.com/openstack/nova/blob/aa096fd18352fb9da94069ec2cab478eed5c6cca/nova/virt/disk/vfs/guestfs.py#L75-L97\n\nConflicts:\n    deployment/nova/nova-compute-container-puppet.yaml\n\nChange-Id: Iadef8f3300bb1b5b995052c1a35a1becbfd5730c\n(cherry picked from commit 9c5c36632d23a693a60e490b3046b07b126b9154)\n(cherry picked from commit 02faf53ea8bb672060c7cfedbc093d5cff809307)\n(cherry picked from commit 1f5c51d5d0f65f4a3da3666813f23b383ec0fd2a)\n(cherry picked from commit bb277211658103484313746d749844a01f1a11e4)\n'}]",0,701996,9212c7c07ac39d5cf397598348e89298bcf6f8b2,7,3,1,10135,,,0,"Mount /boot from the host within the nova-compute container

libguestfs expects to find /boot/vmlinuz-* for the running version of
the kernel. This check is duplicated in nova-compute when libguestfs has
failed to launch, providing a useful bread crumb for operators [1].

Obviously when this is called from within the nova-compute container in
the context of a TripleO deployment this can easily fail after a minor
update that has pulled in a newer container containing a newer kernel.
This check could also fail in the opposite case if the host kernel is
updated past the version present in the container.

This change works around this by simply passing /boot as read-only
through to the nova-compute container ensure libguestfs is able to
always find the correct version of vmlinuz.

This should also allow us to eventually drop the kernel RPM from the
nova-compute container that has been a constant source of maintenance
overhead in terms of CVEs etc.

[1] https://github.com/openstack/nova/blob/aa096fd18352fb9da94069ec2cab478eed5c6cca/nova/virt/disk/vfs/guestfs.py#L75-L97

Conflicts:
    deployment/nova/nova-compute-container-puppet.yaml

Change-Id: Iadef8f3300bb1b5b995052c1a35a1becbfd5730c
(cherry picked from commit 9c5c36632d23a693a60e490b3046b07b126b9154)
(cherry picked from commit 02faf53ea8bb672060c7cfedbc093d5cff809307)
(cherry picked from commit 1f5c51d5d0f65f4a3da3666813f23b383ec0fd2a)
(cherry picked from commit bb277211658103484313746d749844a01f1a11e4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/701996/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/nova-compute.yaml'],1,9212c7c07ac39d5cf397598348e89298bcf6f8b2,, - /boot:/boot:ro,,1,0
openstack%2Fproject-config~master~Ida64b575cedae46dae94c32c1edcba30a0d4a9e8,openstack/project-config,master,Ida64b575cedae46dae94c32c1edcba30a0d4a9e8,"Revert ""Disable compression of files in stage-output role""",MERGED,2020-01-15 18:22:43.000000000,2020-01-15 18:46:53.000000000,2020-01-15 18:46:53.000000000,"[{'_account_id': 1}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-01-15 18:22:43.000000000', 'files': ['zuul/site-variables.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c7d292d803b6d7803a9b4b5c0d49873af9f58430', 'message': 'Revert ""Disable compression of files in stage-output role""\n\nThis reverts commit b025023dd2439dedfca1f6fc095cdf737f481f8f.\n\nThis option is now disabled by default. Stop setting it explicitly.\n\nChange-Id: Ida64b575cedae46dae94c32c1edcba30a0d4a9e8\n'}]",0,702715,c7d292d803b6d7803a9b4b5c0d49873af9f58430,7,3,1,4146,,,0,"Revert ""Disable compression of files in stage-output role""

This reverts commit b025023dd2439dedfca1f6fc095cdf737f481f8f.

This option is now disabled by default. Stop setting it explicitly.

Change-Id: Ida64b575cedae46dae94c32c1edcba30a0d4a9e8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/15/702715/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/site-variables.yaml'],1,c7d292d803b6d7803a9b4b5c0d49873af9f58430,remove-now-default-option,,"# We are planning to change this value in the upstream role, but # are testing that change early via opendev site vars stage_compress_logs: false",0,3
openstack%2Fsahara-tests~master~I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b,openstack/sahara-tests,master,I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b,[ussuri][goal] Drop python 2.7 support and testing,MERGED,2019-11-17 14:52:37.000000000,2020-01-15 18:43:19.000000000,2020-01-15 18:37:48.000000000,"[{'_account_id': 8556}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2019-11-17 14:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/1678724b550cece2599e2d8a0d1f7296192243c4', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}, {'number': 2, 'created': '2019-11-17 14:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/946692d34857f03cc8e05c2971962b8e9bb4b3b6', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}, {'number': 3, 'created': '2019-11-17 14:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/2a5ddbd5023f732ebef999f14edbdbddf12bee73', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}, {'number': 4, 'created': '2019-11-17 14:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/ffaf840b747a6512fad7d5f0baab7ed6e3297fad', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}, {'number': 5, 'created': '2019-11-21 10:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/bf0b4585ba6f28c9855d6c736620749aab0894f8', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nNoteworthy change:\n- run sahara-scenario with Python 3 also against the older releases\n  (up to rocky) which are Xenial-based.\n- on the other hand, make sure that the jobs use a Python 2\n  devstack environment when deploying the pre-Ussuri branches;\n- add the missing scenario-test jobs for stein and train.\n\nCo-Authored-By: Luigi Toscano <ltoscano@redhat.com>\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}, {'number': 6, 'created': '2020-01-09 22:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/6813509f5e976e75185334f8a1b5b8631f370b9e', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nNoteworthy change:\n- run sahara-scenario with Python 3 also against the older releases\n  (up to rocky) which are Xenial-based.\n- on the other hand, make sure that the jobs use a Python 2\n  devstack environment when deploying the pre-Ussuri branches;\n- add the missing scenario-test jobs for stein and train.\n\nCo-Authored-By: Luigi Toscano <ltoscano@redhat.com>\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}, {'number': 7, 'created': '2020-01-14 17:38:10.000000000', 'files': ['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-188a5c85a436ee4f.yaml', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara-tests/commit/752970e295409caed918073f500dfc3926f1ce5a', 'message': '[ussuri][goal] Drop python 2.7 support and testing\n\nOpenStack is dropping the py2.7 support in ussuri cycle.\n\nsahara-tests is ready with python 3 and ok to drop the\npython 2.7 support.\n\nComplete discussion & schedule can be found in\n- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html\n- https://etherpad.openstack.org/p/drop-python2-support\n\nUssuri Communtiy-wide goal:\nhttps://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html\n\nNoteworthy change:\n- run sahara-scenario with Python 3 also against the older releases\n  (up to rocky) which are Xenial-based.\n- on the other hand, make sure that the jobs use a Python 2\n  devstack environment when deploying the pre-Ussuri branches;\n- add the missing scenario-test jobs for stein and train.\n\nCo-Authored-By: Luigi Toscano <ltoscano@redhat.com>\nChange-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b\n'}]",6,694699,752970e295409caed918073f500dfc3926f1ce5a,35,5,7,8556,,,0,"[ussuri][goal] Drop python 2.7 support and testing

OpenStack is dropping the py2.7 support in ussuri cycle.

sahara-tests is ready with python 3 and ok to drop the
python 2.7 support.

Complete discussion & schedule can be found in
- http://lists.openstack.org/pipermail/openstack-discuss/2019-October/010142.html
- https://etherpad.openstack.org/p/drop-python2-support

Ussuri Communtiy-wide goal:
https://governance.openstack.org/tc/goals/selected/ussuri/drop-py27.html

Noteworthy change:
- run sahara-scenario with Python 3 also against the older releases
  (up to rocky) which are Xenial-based.
- on the other hand, make sure that the jobs use a Python 2
  devstack environment when deploying the pre-Ussuri branches;
- add the missing scenario-test jobs for stein and train.

Co-Authored-By: Luigi Toscano <ltoscano@redhat.com>
Change-Id: I3666a9ed9047f7c6a358e40d2f7a1d1103f8563b
",git fetch https://review.opendev.org/openstack/sahara-tests refs/changes/99/694699/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'releasenotes/notes/drop-py-2-7-188a5c85a436ee4f.yaml', 'setup.cfg', 'tox.ini']",4,1678724b550cece2599e2d8a0d1f7296192243c4,drop-py27-support,"envlist = py37,py36,py35,pep8,releasenotesbasepython = python3","envlist = py37,py36,py35,py27,pep8,releasenotesbasepython = python3 commands = {posargs} passenv = OS_* [testenv:venv-py2] basepython = python2basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3",15,34
