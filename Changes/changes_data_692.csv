id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Ffuel-nailgun-extension-iac~master~I8ad995890a91aeba44a8ba091dcfd85a1fc9b3ab,openstack/fuel-nailgun-extension-iac,master,I8ad995890a91aeba44a8ba091dcfd85a1fc9b3ab,Show team and repo badges on README,ABANDONED,2016-11-26 11:12:20.000000000,2017-06-19 19:16:17.000000000,,"[{'_account_id': 3}, {'_account_id': 20656}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-26 11:12:20.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-iac/commit/465e2b544260721ba0616c67a9503058f8fc974e', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/6f2a0742bf39d83e144fa3e4d92ea184\n\nChange-Id: I8ad995890a91aeba44a8ba091dcfd85a1fc9b3ab\n""}]",0,403366,465e2b544260721ba0616c67a9503058f8fc974e,6,3,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/6f2a0742bf39d83e144fa3e4d92ea184

Change-Id: I8ad995890a91aeba44a8ba091dcfd85a1fc9b3ab
",git fetch https://review.opendev.org/openstack/fuel-nailgun-extension-iac refs/changes/66/403366/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,465e2b544260721ba0616c67a9503058f8fc974e,project-badges,Team and repository tags ======================== [![Team and repository tags](http://governance.openstack.org/badges/fuel-nailgun-extension-iac.svg)](http://governance.openstack.org/reference/tags/index.html) <!-- Change things from this point on --> ,,7,0
openstack%2Fkarma-subunit-reporter~master~I7bb3f220fc082b0036ddfc0d7f3b7091233fd65d,openstack/karma-subunit-reporter,master,I7bb3f220fc082b0036ddfc0d7f3b7091233fd65d,Show team and repo badges on README,ABANDONED,2016-11-25 17:43:24.000000000,2017-06-19 19:16:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 17:43:24.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/karma-subunit-reporter/commit/9035aa4cdf2691c245b4dcd2a1d4c349c3a34ba5', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/0ccfdf8ae3112f1801c85eddcea18011\n\nChange-Id: I7bb3f220fc082b0036ddfc0d7f3b7091233fd65d\n""}]",0,403187,9035aa4cdf2691c245b4dcd2a1d4c349c3a34ba5,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/0ccfdf8ae3112f1801c85eddcea18011

Change-Id: I7bb3f220fc082b0036ddfc0d7f3b7091233fd65d
",git fetch https://review.opendev.org/openstack/karma-subunit-reporter refs/changes/87/403187/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,9035aa4cdf2691c245b4dcd2a1d4c349c3a34ba5,project-badges,Team and repository tags ======================== [![Team and repository tags](http://governance.openstack.org/badges/karma-subunit-reporter.svg)](http://governance.openstack.org/reference/tags/index.html) <!-- Change things from this point on --> ,,7,0
openstack%2Feslint-config-openstack~master~Idd5eb5199236cbf9759fd73c5f3cebb226f2bf77,openstack/eslint-config-openstack,master,Idd5eb5199236cbf9759fd73c5f3cebb226f2bf77,Show team and repo badges on README,ABANDONED,2016-11-25 17:40:35.000000000,2017-06-19 19:16:09.000000000,,"[{'_account_id': 3}, {'_account_id': 9725}, {'_account_id': 16628}]","[{'number': 1, 'created': '2016-11-25 17:40:35.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/eslint-config-openstack/commit/039616bb2fe460faff94d8226196b05247bcfc92', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/22c0603d723a7f16adef3d6cdb7517b9\n\nChange-Id: Idd5eb5199236cbf9759fd73c5f3cebb226f2bf77\n""}]",0,403183,039616bb2fe460faff94d8226196b05247bcfc92,5,3,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/22c0603d723a7f16adef3d6cdb7517b9

Change-Id: Idd5eb5199236cbf9759fd73c5f3cebb226f2bf77
",git fetch https://review.opendev.org/openstack/eslint-config-openstack refs/changes/83/403183/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,039616bb2fe460faff94d8226196b05247bcfc92,project-badges,Team and repository tags ======================== [![Team and repository tags](http://governance.openstack.org/badges/eslint-config-openstack.svg)](http://governance.openstack.org/reference/tags/index.html) <!-- Change things from this point on --> ,,7,0
openstack%2Fdevstack-plugin-kafka~master~I1a419a3bbc542ff6a843737b2653107dd3251705,openstack/devstack-plugin-kafka,master,I1a419a3bbc542ff6a843737b2653107dd3251705,Show team and repo badges on README,ABANDONED,2016-11-25 17:37:48.000000000,2017-06-19 19:16:05.000000000,,"[{'_account_id': 3}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-25 17:37:48.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-kafka/commit/dcb0bbcba83ca3ffaa01f52ac60c1250f5361cc4', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/ffae639fecd5f1c3740e70ccdaf854a3\n\nChange-Id: I1a419a3bbc542ff6a843737b2653107dd3251705\n""}]",0,403178,dcb0bbcba83ca3ffaa01f52ac60c1250f5361cc4,6,2,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/ffae639fecd5f1c3740e70ccdaf854a3

Change-Id: I1a419a3bbc542ff6a843737b2653107dd3251705
",git fetch https://review.opendev.org/openstack/devstack-plugin-kafka refs/changes/78/403178/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,dcb0bbcba83ca3ffaa01f52ac60c1250f5361cc4,project-badges,Team and repository tags ======================== [![Team and repository tags](http://governance.openstack.org/badges/devstack-plugin-kafka.svg)](http://governance.openstack.org/reference/tags/index.html) <!-- Change things from this point on --> ,,7,0
openstack%2Ftuning-box~master~Idff761edb2df7b0a7eb5c78d86736457da132c3f,openstack/tuning-box,master,Idff761edb2df7b0a7eb5c78d86736457da132c3f,Show team and repo badges on README,ABANDONED,2016-11-25 16:44:37.000000000,2017-06-19 19:16:00.000000000,,"[{'_account_id': 3}, {'_account_id': 10959}]","[{'number': 1, 'created': '2016-11-25 16:44:37.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tuning-box/commit/a5eeb012f5226774c2e02d1b9fa6469f4843f261', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/0c7c7d882bedaa2cec74b0a01e1ad80a\n\nChange-Id: Idff761edb2df7b0a7eb5c78d86736457da132c3f\n""}]",0,403054,a5eeb012f5226774c2e02d1b9fa6469f4843f261,6,2,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/0c7c7d882bedaa2cec74b0a01e1ad80a

Change-Id: Idff761edb2df7b0a7eb5c78d86736457da132c3f
",git fetch https://review.opendev.org/openstack/tuning-box refs/changes/54/403054/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a5eeb012f5226774c2e02d1b9fa6469f4843f261,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/tuning-box.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Ffuel-nailgun-extension-converted-serializers~master~Ic1a5da4e5e2c24d8f7f3437a83713482892e5a37,openstack/fuel-nailgun-extension-converted-serializers,master,Ic1a5da4e5e2c24d8f7f3437a83713482892e5a37,Show team and repo badges on README,ABANDONED,2016-11-25 16:42:58.000000000,2017-06-19 19:15:56.000000000,,"[{'_account_id': 3}, {'_account_id': 20656}]","[{'number': 1, 'created': '2016-11-25 16:42:58.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-converted-serializers/commit/79b1ddcbed107ed754c7690113c9144d5e3ee1a8', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/2898397381a84fd95a99a25606d6a05d\n\nChange-Id: Ic1a5da4e5e2c24d8f7f3437a83713482892e5a37\n""}]",0,403048,79b1ddcbed107ed754c7690113c9144d5e3ee1a8,5,2,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/2898397381a84fd95a99a25606d6a05d

Change-Id: Ic1a5da4e5e2c24d8f7f3437a83713482892e5a37
",git fetch https://review.opendev.org/openstack/fuel-nailgun-extension-converted-serializers refs/changes/48/403048/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,79b1ddcbed107ed754c7690113c9144d5e3ee1a8,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/fuel-nailgun-extension-converted-serializers.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Ffuel-dev-tools~master~I7d26172e1fa94a2fd276ff3676b5804f8fd76faa,openstack/fuel-dev-tools,master,I7d26172e1fa94a2fd276ff3676b5804f8fd76faa,Show team and repo badges on README,ABANDONED,2016-11-25 16:41:24.000000000,2017-06-19 19:15:53.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 16:41:24.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/fuel-dev-tools/commit/e30c96a207e9dee72cc9ac96eda53a62873de125', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/bf30956f5ce23ace82c587a0bf7ea259\n\nChange-Id: I7d26172e1fa94a2fd276ff3676b5804f8fd76faa\n""}]",0,403042,e30c96a207e9dee72cc9ac96eda53a62873de125,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/bf30956f5ce23ace82c587a0bf7ea259

Change-Id: I7d26172e1fa94a2fd276ff3676b5804f8fd76faa
",git fetch https://review.opendev.org/openstack/fuel-dev-tools refs/changes/42/403042/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e30c96a207e9dee72cc9ac96eda53a62873de125,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/fuel-dev-tools.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fheat-specs~master~Ib5f47e333a565ed20f9c1cc9f4f5a69293bdf866,openstack/heat-specs,master,Ib5f47e333a565ed20f9c1cc9f4f5a69293bdf866,Show team and repo badges on README,ABANDONED,2016-11-25 16:19:31.000000000,2017-06-19 19:15:49.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 16:19:31.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/ce98ecd307612b386bfa4437c7946fdb115857c6', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/6c07cd28bf127e5b83afccf57f535991\n\nChange-Id: Ib5f47e333a565ed20f9c1cc9f4f5a69293bdf866\n""}]",0,402948,ce98ecd307612b386bfa4437c7946fdb115857c6,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/6c07cd28bf127e5b83afccf57f535991

Change-Id: Ib5f47e333a565ed20f9c1cc9f4f5a69293bdf866
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/48/402948/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ce98ecd307612b386bfa4437c7946fdb115857c6,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/heat-specs.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fswift-bench~master~Ibb504032487f56a82d5b0c7e6303a07ede27c471,openstack/swift-bench,master,Ibb504032487f56a82d5b0c7e6303a07ede27c471,Show team and repo badges on README,ABANDONED,2016-11-25 15:38:00.000000000,2017-06-19 19:15:45.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 15:38:00.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/28de0a15df754a44757c52407ac1e20e34d4bc9b', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nhttps://gist.github.com/c48f9b7e555995ff5b5e6b0c6ca2d2e0\n\nChange-Id: Ibb504032487f56a82d5b0c7e6303a07ede27c471\n""}]",0,402850,28de0a15df754a44757c52407ac1e20e34d4bc9b,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

https://gist.github.com/c48f9b7e555995ff5b5e6b0c6ca2d2e0

Change-Id: Ibb504032487f56a82d5b0c7e6303a07ede27c471
",git fetch https://review.opendev.org/openstack/swift-bench refs/changes/50/402850/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,28de0a15df754a44757c52407ac1e20e34d4bc9b,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/swift-bench.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fpython-appcatalogclient~master~Ifef42a9f21a24c094dbf1bdf5a747c15f14b3bdc,openstack/python-appcatalogclient,master,Ifef42a9f21a24c094dbf1bdf5a747c15f14b3bdc,Show team and repo badges on README,ABANDONED,2016-11-25 13:41:11.000000000,2017-06-19 19:15:40.000000000,,"[{'_account_id': 3}, {'_account_id': 16237}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-25 13:41:11.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-appcatalogclient/commit/205cc4dbad355c0d0af150bedcb02416e0af89ac', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/b9dbd918d41ab22b0d684823764f79b1\\n'\n\nChange-Id: Ifef42a9f21a24c094dbf1bdf5a747c15f14b3bdc\n""}]",0,402598,205cc4dbad355c0d0af150bedcb02416e0af89ac,5,3,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/b9dbd918d41ab22b0d684823764f79b1\n'

Change-Id: Ifef42a9f21a24c094dbf1bdf5a747c15f14b3bdc
",git fetch https://review.opendev.org/openstack/python-appcatalogclient refs/changes/98/402598/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,205cc4dbad355c0d0af150bedcb02416e0af89ac,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/python-appcatalogclient.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fos-performance-tools~master~I302e00b8931b39ef1ddf2af66ad6ffb92e174b6c,openstack/os-performance-tools,master,I302e00b8931b39ef1ddf2af66ad6ffb92e174b6c,Show team and repo badges on README,ABANDONED,2016-11-25 12:54:14.000000000,2017-06-19 19:15:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2016-11-25 12:54:14.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/os-performance-tools/commit/58587ee57c7d1660c23d7a3f3ce3bc9f3809d097', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/63c9102d8d13b4ea1918d44361170f9b\\n'\n\nChange-Id: I302e00b8931b39ef1ddf2af66ad6ffb92e174b6c\n""}]",0,402529,58587ee57c7d1660c23d7a3f3ce3bc9f3809d097,4,2,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/63c9102d8d13b4ea1918d44361170f9b\n'

Change-Id: I302e00b8931b39ef1ddf2af66ad6ffb92e174b6c
",git fetch https://review.opendev.org/openstack/os-performance-tools refs/changes/29/402529/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,58587ee57c7d1660c23d7a3f3ce3bc9f3809d097,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/os-performance-tools.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fos-testr~master~Id7bd957180ee6686c7e8f0b6700c1273a13a670c,openstack/os-testr,master,Id7bd957180ee6686c7e8f0b6700c1273a13a670c,Show team and repo badges on README,ABANDONED,2016-11-25 12:48:09.000000000,2017-06-19 19:15:31.000000000,,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 17716}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-25 12:48:09.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/os-testr/commit/4acb25cdf556ecf300bce0301eef1962a94c024e', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/d7e9e3122828de620969bd561def29ac\\n'\n\nChange-Id: Id7bd957180ee6686c7e8f0b6700c1273a13a670c\n""}]",1,402521,4acb25cdf556ecf300bce0301eef1962a94c024e,6,4,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/d7e9e3122828de620969bd561def29ac\n'

Change-Id: Id7bd957180ee6686c7e8f0b6700c1273a13a670c
",git fetch https://review.opendev.org/openstack/os-testr refs/changes/21/402521/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4acb25cdf556ecf300bce0301eef1962a94c024e,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/os-testr.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Ftempest-plugin-cookiecutter~master~I784c124093bc555d8fdaf87413f49db2edb3f221,openstack/tempest-plugin-cookiecutter,master,I784c124093bc555d8fdaf87413f49db2edb3f221,Show team and repo badges on README,ABANDONED,2016-11-25 12:46:50.000000000,2017-06-19 19:15:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 12:46:50.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tempest-plugin-cookiecutter/commit/9a6874ea7f76777d6ca8e8d2a19cc0612f05a02d', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/b98913f43ec6fae33ca67594fd5fd5b8\\n'\n\nChange-Id: I784c124093bc555d8fdaf87413f49db2edb3f221\n""}]",0,402519,9a6874ea7f76777d6ca8e8d2a19cc0612f05a02d,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/b98913f43ec6fae33ca67594fd5fd5b8\n'

Change-Id: I784c124093bc555d8fdaf87413f49db2edb3f221
",git fetch https://review.opendev.org/openstack/tempest-plugin-cookiecutter refs/changes/19/402519/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,9a6874ea7f76777d6ca8e8d2a19cc0612f05a02d,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/tempest-plugin-cookiecutter.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fpylockfile~master~I0e8efa4cf2b85111f57a4e3e259d7db584a0ed15,openstack/pylockfile,master,I0e8efa4cf2b85111f57a4e3e259d7db584a0ed15,Show team and repo badges on README,ABANDONED,2016-11-25 12:21:12.000000000,2017-06-19 19:15:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2016-11-25 12:21:12.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/pylockfile/commit/b473cf61e16a91a9241e89bd3c5bab4a2424ef8d', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/6480fc6aa3c60e2459054f52c36f85a8\\n'\n\nChange-Id: I0e8efa4cf2b85111f57a4e3e259d7db584a0ed15\n""}]",0,402480,b473cf61e16a91a9241e89bd3c5bab4a2424ef8d,5,2,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/6480fc6aa3c60e2459054f52c36f85a8\n'

Change-Id: I0e8efa4cf2b85111f57a4e3e259d7db584a0ed15
",git fetch https://review.opendev.org/openstack/pylockfile refs/changes/80/402480/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b473cf61e16a91a9241e89bd3c5bab4a2424ef8d,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/pylockfile.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fossa~master~I752e5b6df0a8c5fd94bf4384bbd9db8115c01e60,openstack/ossa,master,I752e5b6df0a8c5fd94bf4384bbd9db8115c01e60,Show team and repo badges on README,ABANDONED,2016-11-25 12:03:35.000000000,2017-06-19 19:15:20.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 12:03:35.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ossa/commit/3220667512b00072c5efd90a05267de0f9d9c019', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/042430925fccaaaedfda563966604b21\\n'\n\nChange-Id: I752e5b6df0a8c5fd94bf4384bbd9db8115c01e60\n""}]",0,402454,3220667512b00072c5efd90a05267de0f9d9c019,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/042430925fccaaaedfda563966604b21\n'

Change-Id: I752e5b6df0a8c5fd94bf4384bbd9db8115c01e60
",git fetch https://review.opendev.org/openstack/ossa refs/changes/54/402454/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3220667512b00072c5efd90a05267de0f9d9c019,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/ossa.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fsecurity-analysis~master~Ifc3558fc60afde192640dad4d4df2c339a4d0516,openstack/security-analysis,master,Ifc3558fc60afde192640dad4d4df2c339a4d0516,Show team and repo badges on README,ABANDONED,2016-11-25 12:02:03.000000000,2017-06-19 19:15:17.000000000,,"[{'_account_id': 3}, {'_account_id': 16237}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-25 12:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-analysis/commit/a007294a4551c45fc495df414e442edaec869bd6', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/3efaaa3948229266bd4ad11de0012f2b\\n'\n\nChange-Id: Ifc3558fc60afde192640dad4d4df2c339a4d0516\n""}, {'number': 2, 'created': '2017-02-24 03:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-analysis/commit/acac274cde0d59b42af8acef09bfd4ef98d18b8b', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/3efaaa3948229266bd4ad11de0012f2b\\n'\n\nChange-Id: Ifc3558fc60afde192640dad4d4df2c339a4d0516\n""}, {'number': 3, 'created': '2017-02-24 04:33:16.000000000', 'files': ['test-requirements.txt', 'README.rst'], 'web_link': 'https://opendev.org/openstack/security-analysis/commit/dfcea26e28ac2961d3a531cec6619db2c9efb655', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/3efaaa3948229266bd4ad11de0012f2b\\n'\n\nChange-Id: Ifc3558fc60afde192640dad4d4df2c339a4d0516\n""}]",0,402452,dfcea26e28ac2961d3a531cec6619db2c9efb655,13,3,3,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/3efaaa3948229266bd4ad11de0012f2b\n'

Change-Id: Ifc3558fc60afde192640dad4d4df2c339a4d0516
",git fetch https://review.opendev.org/openstack/security-analysis refs/changes/52/402452/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a007294a4551c45fc495df414e442edaec869bd6,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/security-analysis.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fanchor~master~Ie2b4299ca55b3b9ad66cd6340e81ac810fe95ae8,openstack/anchor,master,Ie2b4299ca55b3b9ad66cd6340e81ac810fe95ae8,Show team and repo badges on README,ABANDONED,2016-11-25 12:01:17.000000000,2017-06-19 19:15:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-25 12:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/bf57e584dd33fa604af6c4887acf5d4a259d4f11', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/eb855d2563be65664cdcc9523a39610e\\n'\n\nChange-Id: Ie2b4299ca55b3b9ad66cd6340e81ac810fe95ae8\n""}, {'number': 2, 'created': '2016-12-01 17:46:52.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/anchor/commit/d32e91f5b79801181687462a9a49000f46dca39c', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/eb855d2563be65664cdcc9523a39610e\\n'\n\nChange-Id: Ie2b4299ca55b3b9ad66cd6340e81ac810fe95ae8\n""}]",0,402450,d32e91f5b79801181687462a9a49000f46dca39c,7,3,2,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/eb855d2563be65664cdcc9523a39610e\n'

Change-Id: Ie2b4299ca55b3b9ad66cd6340e81ac810fe95ae8
",git fetch https://review.opendev.org/openstack/anchor refs/changes/50/402450/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,bf57e584dd33fa604af6c4887acf5d4a259d4f11,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/anchor.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fopenstack-ux~master~Ife9697125b8d376993b18218576c29a9f0d1148b,openstack/openstack-ux,master,Ife9697125b8d376993b18218576c29a9f0d1148b,Show team and repo badges on README,ABANDONED,2016-11-25 11:58:54.000000000,2017-06-19 19:15:06.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-11-25 11:58:54.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ux/commit/502f8762bc5d3f48067c9ced2a3e26916300f4ed', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/41d0ff372a68a1a297bf5528783bf066\\n'\n\nChange-Id: Ife9697125b8d376993b18218576c29a9f0d1148b\n""}]",0,402446,502f8762bc5d3f48067c9ced2a3e26916300f4ed,3,1,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/41d0ff372a68a1a297bf5528783bf066\n'

Change-Id: Ife9697125b8d376993b18218576c29a9f0d1148b
",git fetch https://review.opendev.org/openstack/openstack-ux refs/changes/46/402446/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,502f8762bc5d3f48067c9ced2a3e26916300f4ed,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/openstack-ux.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fsolum-infra-guestagent~master~I603388a2bc04fd3a57c7cb4228dc28d2d00db9b7,openstack/solum-infra-guestagent,master,I603388a2bc04fd3a57c7cb4228dc28d2d00db9b7,Show team and repo badges on README,ABANDONED,2016-11-25 11:37:27.000000000,2017-06-19 19:15:03.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 16237}, {'_account_id': 20835}]","[{'number': 1, 'created': '2016-11-25 11:37:27.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/solum-infra-guestagent/commit/d267266af93db58b625b9f3684ad04476baa0f42', 'message': ""Show team and repo badges on README\n\nThis patch adds the team's and repository's badges to the README file.\nThe motivation behind this is to communicate the project status and\nfeatures at first glance.\n\nFor more information about this effort, please read this email thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html\n\nTo see an example of how this would look like check:\n\nb'https://gist.github.com/aa09a75115b06d7d566337adf265d5a4\\n'\n\nChange-Id: I603388a2bc04fd3a57c7cb4228dc28d2d00db9b7\n""}]",0,402415,d267266af93db58b625b9f3684ad04476baa0f42,9,4,1,6159,,,0,"Show team and repo badges on README

This patch adds the team's and repository's badges to the README file.
The motivation behind this is to communicate the project status and
features at first glance.

For more information about this effort, please read this email thread:

http://lists.openstack.org/pipermail/openstack-dev/2016-October/105562.html

To see an example of how this would look like check:

b'https://gist.github.com/aa09a75115b06d7d566337adf265d5a4\n'

Change-Id: I603388a2bc04fd3a57c7cb4228dc28d2d00db9b7
",git fetch https://review.opendev.org/openstack/solum-infra-guestagent refs/changes/15/402415/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d267266af93db58b625b9f3684ad04476baa0f42,project-badges,======================== Team and repository tags ======================== .. image:: http://governance.openstack.org/badges/solum-infra-guestagent.svg :target: http://governance.openstack.org/reference/tags/index.html .. Change things from this point on ,,9,0
openstack%2Fopenstack-ansible-tests~stable%2Focata~I711aed6daf6391de71d3c2b47fbfc00fe6b66d9f,openstack/openstack-ansible-tests,stable/ocata,I711aed6daf6391de71d3c2b47fbfc00fe6b66d9f,Use ansible-hardening repository,MERGED,2017-06-13 12:58:20.000000000,2017-06-19 19:13:17.000000000,2017-06-19 19:13:17.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-13 12:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/ba847d0cdb7b3030e6e90328d2bfb05a84e86efa', 'message': 'Use ansible-hardening repository\n\nThis patch changes openstack-ansible-security to ansible-hardening.\n\nChange-Id: I711aed6daf6391de71d3c2b47fbfc00fe6b66d9f\n(cherry picked from commit ffe9ae3f7e091351a5ef3644161a69c40e42318c)\n'}, {'number': 2, 'created': '2017-06-19 14:47:33.000000000', 'files': ['common-tasks/test-set-nodepool-vars.yml', 'ansible-role-requirements.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/5b6488987a5f431b91b13bb73380fb1db3692c8e', 'message': 'Use ansible-hardening repository\n\nThis patch changes openstack-ansible-security to ansible-hardening.\n\nChange-Id: I711aed6daf6391de71d3c2b47fbfc00fe6b66d9f\n(cherry picked from commit ffe9ae3f7e091351a5ef3644161a69c40e42318c)\n'}]",0,473825,5b6488987a5f431b91b13bb73380fb1db3692c8e,16,4,2,538,,,0,"Use ansible-hardening repository

This patch changes openstack-ansible-security to ansible-hardening.

Change-Id: I711aed6daf6391de71d3c2b47fbfc00fe6b66d9f
(cherry picked from commit ffe9ae3f7e091351a5ef3644161a69c40e42318c)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/25/473825/2 && git format-patch -1 --stdout FETCH_HEAD,"['common-tasks/test-set-nodepool-vars.yml', 'ansible-role-requirements.yaml']",2,ba847d0cdb7b3030e6e90328d2bfb05a84e86efa,switch-ansible-hardening,"- name: ""ansible-hardening"" src: ""https://git.openstack.org/openstack/ansible-hardening""","- name: ""security"" src: ""https://git.openstack.org/openstack/openstack-ansible-security""",3,3
openstack%2Fpython-glanceclient~master~Icf6423763f2d535b2c85c067d6e4a5676914e2c3,openstack/python-glanceclient,master,Icf6423763f2d535b2c85c067d6e4a5676914e2c3,Remove log translations,MERGED,2017-03-21 05:10:24.000000000,2017-06-19 19:13:08.000000000,2017-06-19 19:13:08.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 11391}, {'_account_id': 11904}, {'_account_id': 23942}, {'_account_id': 24564}, {'_account_id': 24883}, {'_account_id': 25456}]","[{'number': 1, 'created': '2017-03-21 05:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5cf2a94236e0c47dfb3f47279acb954ce5e411f8', 'message': 'Remove log translations\n\nChange-Id: Icf6423763f2d535b2c85c067d6e4a5676914e2c3\n'}, {'number': 2, 'created': '2017-03-21 07:19:51.000000000', 'files': ['glanceclient/_i18n.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/36d2358a9da2738d07f307c51171ce2973efb1c1', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: Icf6423763f2d535b2c85c067d6e4a5676914e2c3\n'}]",0,447808,36d2358a9da2738d07f307c51171ce2973efb1c1,20,8,2,24883,,,0,"Remove log translations

Log messages are no longer being translated. This removes all use of
the _LE, _LI, and _LW translation markers to simplify logging and to
avoid confusion with new contributions.

See:
http://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html
http://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html

Change-Id: Icf6423763f2d535b2c85c067d6e4a5676914e2c3
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/08/447808/1 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/_i18n.py'],1,5cf2a94236e0c47dfb3f47279acb954ce5e411f8,remove_log_translations,," # Translators for log levels. # # The abbreviated names are meant to reflect the usual use of a short # name like '_'. The ""L"" is for ""log"" and the other letter comes from # the level. _LI = _translators.log_info _LW = _translators.log_warning _LE = _translators.log_error _LC = _translators.log_critical",0,10
openstack%2Ftempest~master~I17e6603c588e3efddcf44ca4e7af6e352490e689,openstack/tempest,master,I17e6603c588e3efddcf44ca4e7af6e352490e689,Fix test_volume_migrate_attached to retype as admin,MERGED,2017-06-15 21:51:03.000000000,2017-06-19 19:09:26.000000000,2017-06-19 19:09:26.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6167}]","[{'number': 1, 'created': '2017-06-15 21:51:03.000000000', 'files': ['tempest/scenario/test_volume_migrate_attached.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1df940ebdbf13c6fb80d73be4a6a61c323350f26', 'message': 'Fix test_volume_migrate_attached to retype as admin\n\nBy default, Cinder policy will allow a non-admin owner\nof a volume to retype a volume. That triggers a call from\nCinder to Nova to swap the volume in the guest. The Nova\nswap volume API, however, is admin-only by default. So this\ntest fails with default policy because Cinder gets a 403\nresponse from Nova when trying to swap the volume on the\nNova side.\n\nThis fixes the problem by using the admin client for initiating\nthe retype.\n\nChange-Id: I17e6603c588e3efddcf44ca4e7af6e352490e689\nCloses-Bug: #1698224\n'}]",0,474789,1df940ebdbf13c6fb80d73be4a6a61c323350f26,12,3,1,6873,,,0,"Fix test_volume_migrate_attached to retype as admin

By default, Cinder policy will allow a non-admin owner
of a volume to retype a volume. That triggers a call from
Cinder to Nova to swap the volume in the guest. The Nova
swap volume API, however, is admin-only by default. So this
test fails with default policy because Cinder gets a 403
response from Nova when trying to swap the volume on the
Nova side.

This fixes the problem by using the admin client for initiating
the retype.

Change-Id: I17e6603c588e3efddcf44ca4e7af6e352490e689
Closes-Bug: #1698224
",git fetch https://review.opendev.org/openstack/tempest refs/changes/89/474789/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_volume_migrate_attached.py'],1,1df940ebdbf13c6fb80d73be4a6a61c323350f26,bug/1698224, cls.admin_volumes_client = cls.os_admin.volumes_v2_client self.admin_volumes_client.retype_volume(, self.volumes_client.retype_volume(,2,1
openstack%2Fpatrole~master~Id1f64669860d9527f445398c59593ec16d7c6805,openstack/patrole,master,Id1f64669860d9527f445398c59593ec16d7c6805,RBAC tests for Tempest network agents_client,MERGED,2017-06-10 18:06:35.000000000,2017-06-19 19:08:07.000000000,2017-06-19 19:08:07.000000000,"[{'_account_id': 3}, {'_account_id': 17896}, {'_account_id': 23185}]","[{'number': 1, 'created': '2017-06-10 18:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/be352bc7a10acd18c52bbc7f944c706be80ec91a', 'message': ""RBAC tests for Tempest network agents_client\n\nImplements RBAC tests for Tempest network agents_client, providing\ncoverage for the following policies:\n\n  * update_agent\n  * get_agent\n  * create_dhcp-network\n  * delete_dhcp-network\n  * get_dhcp-networks\n  * create_l3-router\n  * delete_l3-router\n  * get_l3-routers\n\nThis covers all the current endpoints in Tempest's network\nagents_client, except for delete_agent (which is too destructive\nto test in the gate) and list_agents, which doesn't do policy\nenforcement.\n\nChange-Id: Id1f64669860d9527f445398c59593ec16d7c6805\nCloses-Bug: #1697129\n""}, {'number': 2, 'created': '2017-06-10 19:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/604f492858168fa75510751d306811e2eaa4316e', 'message': ""RBAC tests for Tempest network agents_client\n\nImplements RBAC tests for Tempest network agents_client, providing\ncoverage for the following policies:\n\n  * update_agent\n  * get_agent\n  * create_dhcp-network\n  * delete_dhcp-network\n  * get_dhcp-networks\n  * create_l3-router\n  * delete_l3-router\n  * get_l3-routers\n\nThis covers all the current endpoints in Tempest's network\nagents_client, except for delete_agent (which is too destructive\nto test in the gate) and list_agents, which doesn't do policy\nenforcement.\n\nChange-Id: Id1f64669860d9527f445398c59593ec16d7c6805\nCloses-Bug: #1697129\n""}, {'number': 3, 'created': '2017-06-10 20:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/39dda7eb4a8f953971e044fafcd5ab758e509aba', 'message': ""RBAC tests for Tempest network agents_client\n\nImplements RBAC tests for Tempest network agents_client, providing\ncoverage for the following policies:\n\n  * update_agent\n  * get_agent\n  * create_dhcp-network\n  * delete_dhcp-network\n  * get_dhcp-networks\n  * create_l3-router\n  * delete_l3-router\n  * get_l3-routers\n\nThis covers all the current endpoints in Tempest's network\nagents_client, except for delete_agent (which is too destructive\nto test in the gate) and list_agents, which doesn't do policy\nenforcement.\n\nChange-Id: Id1f64669860d9527f445398c59593ec16d7c6805\nCloses-Bug: #1697129\n""}, {'number': 4, 'created': '2017-06-13 15:56:45.000000000', 'files': ['patrole_tempest_plugin/tests/api/network/test_agents_rbac.py', 'releasenotes/notes/rbac-tests-for-network-agents-fbc899925b5948b1.yaml'], 'web_link': 'https://opendev.org/openstack/patrole/commit/1442d57231ccf55e5f4b8ddd0d77f751e7887a8a', 'message': ""RBAC tests for Tempest network agents_client\n\nImplements RBAC tests for Tempest network agents_client, providing\ncoverage for the following policies:\n\n  * update_agent\n  * get_agent\n  * create_dhcp-network\n  * delete_dhcp-network\n  * get_dhcp-networks\n  * create_l3-router\n  * delete_l3-router\n  * get_l3-routers\n\nThis covers all the current endpoints in Tempest's network\nagents_client, except for delete_agent (which is too destructive\nto test in the gate) and list_agents, which doesn't do policy\nenforcement.\n\nChange-Id: Id1f64669860d9527f445398c59593ec16d7c6805\nCloses-Bug: #1697129\n""}]",1,472969,1442d57231ccf55e5f4b8ddd0d77f751e7887a8a,21,3,4,23186,,,0,"RBAC tests for Tempest network agents_client

Implements RBAC tests for Tempest network agents_client, providing
coverage for the following policies:

  * update_agent
  * get_agent
  * create_dhcp-network
  * delete_dhcp-network
  * get_dhcp-networks
  * create_l3-router
  * delete_l3-router
  * get_l3-routers

This covers all the current endpoints in Tempest's network
agents_client, except for delete_agent (which is too destructive
to test in the gate) and list_agents, which doesn't do policy
enforcement.

Change-Id: Id1f64669860d9527f445398c59593ec16d7c6805
Closes-Bug: #1697129
",git fetch https://review.opendev.org/openstack/patrole refs/changes/69/472969/1 && git format-patch -1 --stdout FETCH_HEAD,"['patrole_tempest_plugin/tests/api/network/test_agents_rbac.py', 'releasenotes/notes/rbac-tests-for-network-agents-fbc899925b5948b1.yaml']",2,be352bc7a10acd18c52bbc7f944c706be80ec91a,bug/1697129,"--- features: - | Implements RBAC tests for Tempest network agents_client, providing coverage for the following policies: * update_agent * get_agent * create_dhcp-network * delete_dhcp-network * get_dhcp-networks * create_l3-router * delete_l3-router * get_l3-routers ",,222,0
openstack%2Fopenstack-ansible-repo_server~stable%2Focata~I33f4905363d102f65cda8769d1ff95bbce8f08f8,openstack/openstack-ansible-repo_server,stable/ocata,I33f4905363d102f65cda8769d1ff95bbce8f08f8,Split user create and ssh key generation,MERGED,2017-06-19 14:41:58.000000000,2017-06-19 19:07:06.000000000,2017-06-19 19:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-19 14:41:58.000000000', 'files': ['tasks/repo_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/dcd76405c969666dbb5751c6edc8965b408cf684', 'message': 'Split user create and ssh key generation\n\nIn order to allow an install and config split, but not\nto have ssh keys left inside an pre-installed container,\nthe two tasks are split and tagged appropriately.\n\nChange-Id: I33f4905363d102f65cda8769d1ff95bbce8f08f8\n(cherry picked from commit 891ba5de71ecb6ece264cb0c18716279cbe807c7)\n'}]",0,475413,dcd76405c969666dbb5751c6edc8965b408cf684,7,3,1,6816,,,0,"Split user create and ssh key generation

In order to allow an install and config split, but not
to have ssh keys left inside an pre-installed container,
the two tasks are split and tagged appropriately.

Change-Id: I33f4905363d102f65cda8769d1ff95bbce8f08f8
(cherry picked from commit 891ba5de71ecb6ece264cb0c18716279cbe807c7)
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/13/475413/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/repo_post_install.yml'],1,dcd76405c969666dbb5751c6edc8965b408cf684,artifacts,"- name: Generate the nginx system user ssh key user: name: ""{{ repo_service_user_name }}"" generate_ssh_key: ""yes"" tags: - pkg-repo-user - repo-key - repo-key-create - repo_server-config "," generate_ssh_key: ""yes""",10,1
openstack%2Fhorizon~master~I0e0166af345c53956670bfbc9f70e7df718c164f,openstack/horizon,master,I0e0166af345c53956670bfbc9f70e7df718c164f,Redundant code removed from in 'images/urls.py'.,ABANDONED,2016-12-13 08:46:55.000000000,2017-06-19 19:05:31.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 17172}, {'_account_id': 23302}]","[{'number': 1, 'created': '2016-12-13 08:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2443e32949a1486545753476c85e354e6e814947', 'message': ""Redundant code removed from in 'images/urls.py'.\n\nChange-Id: I0e0166af345c53956670bfbc9f70e7df718c164f\nCloses-Bug: #1626566\n""}, {'number': 2, 'created': '2016-12-16 07:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b08d8a0d0348fc363b79175d76335485edd4881b', 'message': ""Redundant code removed from in 'images/urls.py'.\n\nChange-Id: I0e0166af345c53956670bfbc9f70e7df718c164f\nCloses-Bug: #1626566\n""}, {'number': 3, 'created': '2016-12-19 06:53:30.000000000', 'files': ['openstack_dashboard/dashboards/project/images/urls.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/669f109f9d4c0c28381305f4277e3be6689b269d', 'message': ""Redundant code removed from in 'images/urls.py'.\n\nChange-Id: I0e0166af345c53956670bfbc9f70e7df718c164f\nCloses-Bug: #1626566\n""}]",3,410099,669f109f9d4c0c28381305f4277e3be6689b269d,15,6,3,23719,,,0,"Redundant code removed from in 'images/urls.py'.

Change-Id: I0e0166af345c53956670bfbc9f70e7df718c164f
Closes-Bug: #1626566
",git fetch https://review.opendev.org/openstack/horizon refs/changes/99/410099/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/images/urls.py'],1,2443e32949a1486545753476c85e354e6e814947,bug/1626566," urlpatterns += [ url(r'', include(image_urls, namespace='images')), url(r'', include(snapshot_urls, namespace='snapshots')), ]"," url(r'', include(image_urls, namespace='images')), url(r'', include(snapshot_urls, namespace='snapshots')), url(r'', include(image_urls, namespace='images')), url(r'', include(snapshot_urls, namespace='snapshots')),",5,4
openstack%2Fpython-ironicclient~master~I14160c4275aef7567bc30f80282e8d029bc99b29,openstack/python-ironicclient,master,I14160c4275aef7567bc30f80282e8d029bc99b29,Improve help text for --local-link-connection,MERGED,2017-06-15 19:10:21.000000000,2017-06-19 19:03:58.000000000,2017-06-19 19:03:58.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-06-15 19:10:21.000000000', 'files': ['ironicclient/osc/v1/baremetal_port.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/6425e65d90d27203c54f0901cc7562b042586903', 'message': 'Improve help text for --local-link-connection\n\nImport the help text for the --local-link-connection arguments\n\nChange-Id: I14160c4275aef7567bc30f80282e8d029bc99b29\n'}]",2,474732,6425e65d90d27203c54f0901cc7562b042586903,8,3,1,14760,,,0,"Improve help text for --local-link-connection

Import the help text for the --local-link-connection arguments

Change-Id: I14160c4275aef7567bc30f80282e8d029bc99b29
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/32/474732/1 && git format-patch -1 --stdout FETCH_HEAD,['ironicclient/osc/v1/baremetal_port.py'],1,6425e65d90d27203c54f0901cc7562b042586903,," ""information. Valid keys are 'switch_info', 'switch_id', "" ""and 'port_id'. The keys 'switch_id' and 'port_id' are "" ""required. Can be specified multiple times."") ""information. Valid keys are 'switch_info', 'switch_id', "" ""and 'port_id'. The keys 'switch_id' and 'port_id' are "" ""required. Can be specified multiple times."") ""information. Valid keys are 'switch_info', 'switch_id', "" ""and 'port_id'. The keys 'switch_id' and 'port_id' are "" ""required. Can be specified multiple times."")"," ""information. Valid keys are switch_info, switch_id, "" ""port_id; switch_id and port_id are obligatory. Can be "" ""specified multiple times."") ""information. Valid keys are switch_info, switch_id, "" ""port_id; switch_id and port_id are obligatory. Can be "" ""specified multiple times."") ""information. Valid keys are switch_info, switch_id, "" ""port_id; switch_id and port_id are obligatory (repeat "" ""option to specify multiple keys)."")",9,9
openstack%2Freleases~master~Ic6a60414f95e658fdb96b74596e4f2fc8c3c42d2,openstack/releases,master,Ic6a60414f95e658fdb96b74596e4f2fc8c3c42d2,Add oslo releases for stable/ocata,MERGED,2017-06-16 08:01:23.000000000,2017-06-19 19:01:09.000000000,2017-06-19 19:01:09.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 9796}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-16 08:01:23.000000000', 'files': ['deliverables/ocata/oslo.config.yaml', 'deliverables/ocata/oslo.messaging.yaml', 'deliverables/ocata/oslo.service.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/0adf6d936a7a60e8729bb514cb57e332af5e30ff', 'message': 'Add oslo releases for stable/ocata\n\nChange-Id: Ic6a60414f95e658fdb96b74596e4f2fc8c3c42d2\n'}]",0,474883,0adf6d936a7a60e8729bb514cb57e332af5e30ff,9,4,1,9796,,,0,"Add oslo releases for stable/ocata

Change-Id: Ic6a60414f95e658fdb96b74596e4f2fc8c3c42d2
",git fetch https://review.opendev.org/openstack/releases refs/changes/83/474883/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/ocata/oslo.config.yaml', 'deliverables/ocata/oslo.messaging.yaml', 'deliverables/ocata/oslo.service.yaml']",3,0adf6d936a7a60e8729bb514cb57e332af5e30ff,oslo_ocata,- version: 1.19.1 projects: - repo: openstack/oslo.service hash: 5589677293e3f9aedb510422d51a080f6740dda5,,12,0
openstack%2Fhorizon~master~I8386cc0a81673fdbc56c3c8ef64fb7db44fd3a9c,openstack/horizon,master,I8386cc0a81673fdbc56c3c8ef64fb7db44fd3a9c,[WIP]Add missing links to detail pages in tables.,ABANDONED,2017-01-31 22:14:29.000000000,2017-06-19 19:00:35.000000000,,"[{'_account_id': 3}, {'_account_id': 18332}, {'_account_id': 22779}]","[{'number': 1, 'created': '2017-01-31 22:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/31f98b378802836c007bd69acab883e3058160fb', 'message': 'Add missing links to detail pages in tables.\n\nAdding links to detail pages for columns in various tables.\n\nChange-Id: I8386cc0a81673fdbc56c3c8ef64fb7db44fd3a9c\nCloses-bug: #1605696\n'}, {'number': 2, 'created': '2017-01-31 23:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ebb1ef9c187f7fabb120dae9423e3063e32b3e90', 'message': 'Add missing links to detail pages in tables.\n\nAdding links to detail pages for columns in various tables.\n\nChange-Id: I8386cc0a81673fdbc56c3c8ef64fb7db44fd3a9c\nCloses-bug: #1605696\n'}, {'number': 3, 'created': '2017-02-06 16:57:14.000000000', 'files': ['openstack_dashboard/dashboards/admin/floating_ips/tables.py', 'openstack_dashboard/dashboards/admin/routers/tables.py', 'openstack_dashboard/dashboards/admin/networks/tables.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tables.py', 'openstack_dashboard/dashboards/project/instances/tables.py', 'openstack_dashboard/dashboards/admin/instances/tables.py', 'openstack_dashboard/usage/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1757a935e0afc4239b99092f351f4ab513fbf527', 'message': '[WIP]Add missing links to detail pages in tables.\n\nAdding links to detail pages for columns in various tables.\n\nChange-Id: I8386cc0a81673fdbc56c3c8ef64fb7db44fd3a9c\nCloses-bug: #1605696\n'}]",0,427484,1757a935e0afc4239b99092f351f4ab513fbf527,12,3,3,22779,,,0,"[WIP]Add missing links to detail pages in tables.

Adding links to detail pages for columns in various tables.

Change-Id: I8386cc0a81673fdbc56c3c8ef64fb7db44fd3a9c
Closes-bug: #1605696
",git fetch https://review.opendev.org/openstack/horizon refs/changes/84/427484/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/floating_ips/tables.py', 'openstack_dashboard/dashboards/admin/routers/tables.py', 'openstack_dashboard/dashboards/admin/volumes/volumes/tables.py', 'openstack_dashboard/dashboards/admin/networks/tables.py', 'openstack_dashboard/dashboards/admin/volumes/snapshots/tables.py', 'openstack_dashboard/dashboards/project/instances/tables.py', 'openstack_dashboard/dashboards/admin/instances/tables.py', 'openstack_dashboard/usage/tables.py']",8,31f98b378802836c007bd69acab883e3058160fb,bug/1605696,"from django.core.urlresolvers import reverse def get_tenantLink(instance): if hasattr(instance,""project_name""): return reverse(""horizon:identity:projects:detail"", args=[instance.tenant_id],) else: return None project = tables.Column('project_name', link=get_tenantLink, verbose_name=_(""Project Name""))"," project = tables.Column('project_name', verbose_name=_(""Project Name""))",115,10
openstack%2Freleases~master~I3d02741451684f171611963e7eac5537b91dd6fa,openstack/releases,master,I3d02741451684f171611963e7eac5537b91dd6fa,"Add oslo release(s) for June 19,2017",MERGED,2017-06-19 16:17:18.000000000,2017-06-19 19:00:07.000000000,2017-06-19 19:00:07.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2017-06-19 16:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/70a4f1ea541a068179bc894d8f7493f285e1c689', 'message': 'Add oslo release(s) for June 19,2017\n\nChange-Id: I3d02741451684f171611963e7eac5537b91dd6fa\n'}, {'number': 2, 'created': '2017-06-19 16:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4f5d86516c13b62f2f060173120e9a3cab67099f', 'message': 'Add oslo release(s) for June 19,2017\n\nChange-Id: I3d02741451684f171611963e7eac5537b91dd6fa\n'}, {'number': 3, 'created': '2017-06-19 16:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/c8fb8d54e55377b94341942d49e095fd3672c049', 'message': 'Add oslo release(s) for June 19,2017\n\nChange-Id: I3d02741451684f171611963e7eac5537b91dd6fa\n'}, {'number': 4, 'created': '2017-06-19 16:47:49.000000000', 'files': ['deliverables/pike/castellan.yaml', 'deliverables/pike/oslo.messaging.yaml', 'deliverables/pike/oslo.middleware.yaml', 'deliverables/pike/oslosphinx.yaml', 'deliverables/pike/tooz.yaml', 'deliverables/pike/oslo.config.yaml', 'deliverables/pike/oslo.context.yaml', 'deliverables/pike/automaton.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c603cafaaa8b46d07ca1bf01931202e530924cb7', 'message': 'Add oslo release(s) for June 19,2017\n\nChange-Id: I3d02741451684f171611963e7eac5537b91dd6fa\n'}]",0,475453,c603cafaaa8b46d07ca1bf01931202e530924cb7,11,2,4,9796,,,0,"Add oslo release(s) for June 19,2017

Change-Id: I3d02741451684f171611963e7eac5537b91dd6fa
",git fetch https://review.opendev.org/openstack/releases refs/changes/53/475453/4 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/pike/castellan.yaml', 'deliverables/pike/oslo.messaging.yaml', 'deliverables/pike/oslo.middleware.yaml', 'deliverables/pike/oslosphinx.yaml', 'deliverables/pike/tooz.yaml', 'deliverables/pike/automaton.yaml', 'deliverables/pike/oslo.context.yaml']",7,70a4f1ea541a068179bc894d8f7493f285e1c689,oslo_06_19,- version: 2.15.0 projects: - repo: openstack/oslo.context hash: d0f8de0eb6dc9b88632a6566880e4902f1597560,,28,0
openstack%2Frequirements~master~Iff76f639bcacb5bcc1274fd837e47d34041afa15,openstack/requirements,master,Iff76f639bcacb5bcc1274fd837e47d34041afa15,Add instack-undercloud to requirements,MERGED,2017-02-17 16:37:16.000000000,2017-06-19 18:55:48.000000000,2017-06-19 18:55:48.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6593}, {'_account_id': 6928}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-17 16:37:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/504685a92725fdc9c3330cc838ac4b61b26142b1', 'message': 'Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n'}, {'number': 2, 'created': '2017-03-27 20:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/dbca78bd551de8582ff3521bcf4ab9d1904c104a', 'message': 'Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n'}, {'number': 3, 'created': '2017-04-11 19:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/0375dcd28286e2ff8c7b472f38b12c0fd05bc014', 'message': 'Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n'}, {'number': 4, 'created': '2017-04-11 20:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a4c95ab28ccbdae64bc5accb83eb9ed3562c57a4', 'message': 'Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n'}, {'number': 5, 'created': '2017-06-13 19:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/d8bb16e076affa34ff90c71ba8b109d5104ebdcc', 'message': 'Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n'}, {'number': 6, 'created': '2017-06-13 19:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/737d5b9aca8bc2b20250ab6b27f9566bcd9af808', 'message': 'Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n'}, {'number': 7, 'created': '2017-06-16 16:44:26.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1100ec8a4fc5a90482c5da7389f3f77199a4e20c', 'message': ""Add instack-undercloud to requirements\n\nPreviously this was an indirect requirement for tripleoclient.  We\nnow have a change to make it a direct requirement, which means it\nneeds to be in g-r.\n\n- Is the library actively maintained?\n\nYes, See https://review.openstack.org/#/q/project:openstack/instack-undercloud\n\n- Is the library good code?\n\nYes\n\n- Is the library python 3 compatible?\n\nYes, but it is missing gate jobs for it.  They'll be added by\nIe2752ec1217992e2150f6bdc8131391e2061b331 in project-config.\n\n- Is the library license compatible?\n\nYes, http://git.openstack.org/cgit/openstack/instack-undercloud/plain/LICENSE\n\n- Is the library already packaged in the distros we target (Ubuntu\n  latest / Fedora latest)?\n\nFedora, yes.  TripleO does not support Ubuntu so there are no\npackages there.\n\n- Is the function of this library already covered by other libraries\n  in ``global-requirements.txt``?\n\nNo, it's specific to TripleO.\n\n- Is the library required for OpenStack project or related dev or\n  infrastructure setup? (Answer to this should be Yes, of course)\n  Which?\n\nYes, see the Required-By change.\n\n- If the library release is managed by the Openstack release process does\n  it use the `cycle-with-intermediary` release type?\n\nYes\n\nChange-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15\nRequired-By: If07880e4bc25cffe485704772d64f62288a1a53d\n""}]",1,435521,1100ec8a4fc5a90482c5da7389f3f77199a4e20c,54,7,7,6928,,,0,"Add instack-undercloud to requirements

Previously this was an indirect requirement for tripleoclient.  We
now have a change to make it a direct requirement, which means it
needs to be in g-r.

- Is the library actively maintained?

Yes, See https://review.openstack.org/#/q/project:openstack/instack-undercloud

- Is the library good code?

Yes

- Is the library python 3 compatible?

Yes, but it is missing gate jobs for it.  They'll be added by
Ie2752ec1217992e2150f6bdc8131391e2061b331 in project-config.

- Is the library license compatible?

Yes, http://git.openstack.org/cgit/openstack/instack-undercloud/plain/LICENSE

- Is the library already packaged in the distros we target (Ubuntu
  latest / Fedora latest)?

Fedora, yes.  TripleO does not support Ubuntu so there are no
packages there.

- Is the function of this library already covered by other libraries
  in ``global-requirements.txt``?

No, it's specific to TripleO.

- Is the library required for OpenStack project or related dev or
  infrastructure setup? (Answer to this should be Yes, of course)
  Which?

Yes, see the Required-By change.

- If the library release is managed by the Openstack release process does
  it use the `cycle-with-intermediary` release type?

Yes

Change-Id: Iff76f639bcacb5bcc1274fd837e47d34041afa15
Required-By: If07880e4bc25cffe485704772d64f62288a1a53d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/435521/4 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,504685a92725fdc9c3330cc838ac4b61b26142b1,add-instack-undercloud,instack-undercloud>=6.0.0 # Apache-2.0,,1,0
openstack%2Fopenstack-ansible-plugins~stable%2Fnewton~I684a11f4380f91b1cb0585f38817859dfaa68f80,openstack/openstack-ansible-plugins,stable/newton,I684a11f4380f91b1cb0585f38817859dfaa68f80,connection: ssh: Clear environment when connecting to LXC containers,MERGED,2017-06-17 07:06:56.000000000,2017-06-19 18:52:23.000000000,2017-06-19 18:52:23.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-17 07:06:56.000000000', 'files': ['connection/ssh.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/ea3599ce518d993f53f9472d1f0c7e6405b6c2db', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n(cherry picked from commit 1c7cb99fcc172486f482cfdce4058f8c577f82dc)\n'}]",0,475114,ea3599ce518d993f53f9472d1f0c7e6405b6c2db,8,4,1,6816,,,0,"connection: ssh: Clear environment when connecting to LXC containers

We should clear the environment before connecting to an LXC container to
avoid inheriting host variables that may break container services like
the following failure in rabbitmqctl:

TASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************
fatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node 'rabbit@vagrant-openSUSE-Leap': nodedown\n\nDIAGNOSTICS\n===========\n\nattempted to contact: ['rabbit@vagrant-openSUSE-Leap']\n\nrabbit@vagrant-openSUSE-Leap:\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\n\n\ncurrent node details:\n- node name: 'rabbitmq-cli-82@localhost'\n- home dir: /var/lib/rabbitmq\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node 'rabbit@vagrant-openSUSE-Leap': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: ['rabbit@vagrant-openSUSE-Leap']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: 'rabbitmq-cli-82@localhost'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node 'rabbit@vagrant-openSUSE-Leap' ..."", ""stdout_lines"": [""Status of node 'rabbit@vagrant-openSUSE-Leap' ...""]}
	to retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry

The reason for this failure is that the HOSTNAME variable is being
inherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl
command uses this variable to guess the host it should try to
connect to.

This is similar to what the upstream lxc connection module is doing.

This is an attempt to fix problems introduced in
https://review.openstack.org/#/c/471472/ and subsequently
reverted in https://review.openstack.org/#/c/471713/

The reason for these failures was that 'lxc-attach' executed commands
which assumed that basic variables like HOME are set properly. However,
--clear-env didn't preserve these variables so various operations started
to fail. In order to fix that, it's best if we start a real login shell
using 'su' in order to mimic an expected user environment when executing
commands within the container.

Change-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80
(cherry picked from commit 1c7cb99fcc172486f482cfdce4058f8c577f82dc)
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/14/475114/1 && git format-patch -1 --stdout FETCH_HEAD,['connection/ssh.py'],1,ea3599ce518d993f53f9472d1f0c7e6405b6c2db,lxc-transport-clear-env-login-shell,"from ansible.module_utils._text import to_bytes from ansible.compat.six.moves import shlex_quote # Remote user is normally set, but if it isn't, then default to 'root' container_user = 'root' if self._play_context.remote_user: container_user = to_bytes(self._play_context.remote_user, errors='surrogate_or_strict') # NOTE(hwoarang) It is important to connect to the container # without inheriting the host environment as that would interfere # with running commands and services inside the container. However, # it is also important to create a sensible environment within the # container because certain commands and services expect some # enviromental variables to be set properly. The best way to do # that would be to execute the commands in a login shell lxc_command = 'lxc-attach --clear-env --name %s' % self.container_name # NOTE(hwoarang): the shlex_quote method is necessary here because # we need to properly quote the cmd as it's being passed as argument # to the -c su option. The Ansible ssh class has already # quoted the command of the _executable_ (ie /bin/bash -c ""$cmd""). # However, we also need to quote the executable itself because the # entire command is being passed to the su process. This produces # a somewhat ugly output with too many quotes in a row but we can't # do much since we are effectively passing a command to a command # to a command etc... It's somewhat ugly but maybe it can be # improved somehow... cmd = '%s -- su - %s -c %s' % (lxc_command, container_user, shlex_quote(cmd))"," lxc_command = 'lxc-attach --name %s' % self.container_name cmd = '%s -- %s' % (lxc_command, cmd)",29,2
openstack%2Fopenstack-ansible-plugins~stable%2Focata~I684a11f4380f91b1cb0585f38817859dfaa68f80,openstack/openstack-ansible-plugins,stable/ocata,I684a11f4380f91b1cb0585f38817859dfaa68f80,connection: ssh: Clear environment when connecting to LXC containers,MERGED,2017-06-17 07:06:43.000000000,2017-06-19 18:52:20.000000000,2017-06-19 18:52:20.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-17 07:06:43.000000000', 'files': ['connection/ssh.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/af204e4418988a4bff3664a70f078c8015dc32d2', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n(cherry picked from commit 1c7cb99fcc172486f482cfdce4058f8c577f82dc)\n'}]",0,475113,af204e4418988a4bff3664a70f078c8015dc32d2,8,4,1,6816,,,0,"connection: ssh: Clear environment when connecting to LXC containers

We should clear the environment before connecting to an LXC container to
avoid inheriting host variables that may break container services like
the following failure in rabbitmqctl:

TASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************
fatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node 'rabbit@vagrant-openSUSE-Leap': nodedown\n\nDIAGNOSTICS\n===========\n\nattempted to contact: ['rabbit@vagrant-openSUSE-Leap']\n\nrabbit@vagrant-openSUSE-Leap:\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\n\n\ncurrent node details:\n- node name: 'rabbitmq-cli-82@localhost'\n- home dir: /var/lib/rabbitmq\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node 'rabbit@vagrant-openSUSE-Leap': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: ['rabbit@vagrant-openSUSE-Leap']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: 'rabbitmq-cli-82@localhost'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node 'rabbit@vagrant-openSUSE-Leap' ..."", ""stdout_lines"": [""Status of node 'rabbit@vagrant-openSUSE-Leap' ...""]}
	to retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry

The reason for this failure is that the HOSTNAME variable is being
inherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl
command uses this variable to guess the host it should try to
connect to.

This is similar to what the upstream lxc connection module is doing.

This is an attempt to fix problems introduced in
https://review.openstack.org/#/c/471472/ and subsequently
reverted in https://review.openstack.org/#/c/471713/

The reason for these failures was that 'lxc-attach' executed commands
which assumed that basic variables like HOME are set properly. However,
--clear-env didn't preserve these variables so various operations started
to fail. In order to fix that, it's best if we start a real login shell
using 'su' in order to mimic an expected user environment when executing
commands within the container.

Change-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80
(cherry picked from commit 1c7cb99fcc172486f482cfdce4058f8c577f82dc)
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/13/475113/1 && git format-patch -1 --stdout FETCH_HEAD,['connection/ssh.py'],1,af204e4418988a4bff3664a70f078c8015dc32d2,lxc-transport-clear-env-login-shell,"from ansible.module_utils._text import to_bytes from ansible.compat.six.moves import shlex_quote # Remote user is normally set, but if it isn't, then default to 'root' container_user = 'root' if self._play_context.remote_user: container_user = to_bytes(self._play_context.remote_user, errors='surrogate_or_strict') # NOTE(hwoarang) It is important to connect to the container # without inheriting the host environment as that would interfere # with running commands and services inside the container. However, # it is also important to create a sensible environment within the # container because certain commands and services expect some # enviromental variables to be set properly. The best way to do # that would be to execute the commands in a login shell lxc_command = 'lxc-attach --clear-env --name %s' % self.container_name # NOTE(hwoarang): the shlex_quote method is necessary here because # we need to properly quote the cmd as it's being passed as argument # to the -c su option. The Ansible ssh class has already # quoted the command of the _executable_ (ie /bin/bash -c ""$cmd""). # However, we also need to quote the executable itself because the # entire command is being passed to the su process. This produces # a somewhat ugly output with too many quotes in a row but we can't # do much since we are effectively passing a command to a command # to a command etc... It's somewhat ugly but maybe it can be # improved somehow... cmd = '%s -- su - %s -c %s' % (lxc_command, container_user, shlex_quote(cmd))"," lxc_command = 'lxc-attach --name %s' % self.container_name cmd = '%s -- %s' % (lxc_command, cmd)",29,2
openstack%2Fopenstack-ansible-os_cinder~stable%2Focata~I44fdd82fbb4e2b679832ceca6462472e54177536,openstack/openstack-ansible-os_cinder,stable/ocata,I44fdd82fbb4e2b679832ceca6462472e54177536,Add thinprovisioning tools for Ubuntu,MERGED,2017-06-19 17:16:51.000000000,2017-06-19 18:50:38.000000000,2017-06-19 18:50:38.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-19 17:16:51.000000000', 'files': ['vars/ubuntu-16.04.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/d6ce615963637cfa7489b3d0d94f16308bedb637', 'message': 'Add thinprovisioning tools for Ubuntu\n\nWithout these tools, the thinprovisioning checks and\nattempts to create thinprovisioning volumes fails.\n\nChange-Id: I44fdd82fbb4e2b679832ceca6462472e54177536\nRelated-Bug: 1615134\n(cherry picked from commit f8f7fa0fcaa5d478bf0093bed63735f7b69b4409)\n'}]",0,475464,d6ce615963637cfa7489b3d0d94f16308bedb637,8,3,1,6816,,,0,"Add thinprovisioning tools for Ubuntu

Without these tools, the thinprovisioning checks and
attempts to create thinprovisioning volumes fails.

Change-Id: I44fdd82fbb4e2b679832ceca6462472e54177536
Related-Bug: 1615134
(cherry picked from commit f8f7fa0fcaa5d478bf0093bed63735f7b69b4409)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/64/475464/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/ubuntu-16.04.yml'],1,d6ce615963637cfa7489b3d0d94f16308bedb637,bug/1615134, - libffi-dev - libpq-dev - libssl-dev - nfs-common - open-iscsi - rpcbind - rsync - thin-provisioning-tools, - rpcbind - rsync - nfs-common - libpq-dev - libffi-dev - libssl-dev - open-iscsi,8,7
openstack%2Fopenstack-ansible-os_heat~stable%2Fnewton~Id316760225cce73d77d0ffa91f2241843e6e04a5,openstack/openstack-ansible-os_heat,stable/newton,Id316760225cce73d77d0ffa91f2241843e6e04a5,Add missing functional test script to tox,MERGED,2017-06-19 16:03:18.000000000,2017-06-19 18:49:59.000000000,2017-06-19 18:49:59.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-19 16:03:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/6054607dc1629cface1b2420fdd69f0fe1e18a50', 'message': 'Add missing functional test script to tox\n\nThe tox environment for functional testing is missing the command to\nactually run functional tests.\n\nChange-Id: Id316760225cce73d77d0ffa91f2241843e6e04a5\n'}]",0,475451,6054607dc1629cface1b2420fdd69f0fe1e18a50,7,3,1,14805,,,0,"Add missing functional test script to tox

The tox environment for functional testing is missing the command to
actually run functional tests.

Change-Id: Id316760225cce73d77d0ffa91f2241843e6e04a5
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/51/475451/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6054607dc1629cface1b2420fdd69f0fe1e18a50,run-functional-tests," bash -c ""{toxinidir}/tests/common/test-ansible-functional.sh""",,1,0
openstack%2Fhorizon~master~I64b211baa709608417f0faa0a94112fa4dd91ae1,openstack/horizon,master,I64b211baa709608417f0faa0a94112fa4dd91ae1,Imported Translations from Zanata,MERGED,2017-06-19 10:18:36.000000000,2017-06-19 18:49:03.000000000,2017-06-19 18:49:03.000000000,"[{'_account_id': 3}, {'_account_id': 12826}]","[{'number': 1, 'created': '2017-06-19 10:18:36.000000000', 'files': ['horizon/locale/zh_CN/LC_MESSAGES/django.po', 'releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'horizon/locale/pl_PL/LC_MESSAGES/django.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/77d33333c96a6b253fc8ea431c5f7b676639be21', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I64b211baa709608417f0faa0a94112fa4dd91ae1\n'}]",0,475319,77d33333c96a6b253fc8ea431c5f7b676639be21,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I64b211baa709608417f0faa0a94112fa4dd91ae1
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/475319/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/locale/zh_CN/LC_MESSAGES/django.po', 'releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'horizon/locale/pl_PL/LC_MESSAGES/django.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'releasenotes/source/locale/pt_BR/LC_MESSAGES/releasenotes.po']",12,77d33333c96a6b253fc8ea431c5f7b676639be21,zanata/translations,"# Renato Lipi <renatolipi@gmail.com>, 2016. #zanata # Fernando Pimenta <fernando.c.pimenta@gmail.com>, 2017. #zanata # José Mello <jose.eduardo.jr@gmail.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: Horizon Release Notes 12.0.0\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2017-05-30 17:20+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-06-16 03:29+0000\n"" ""Last-Translator: Fernando Pimenta <fernando.c.pimenta@gmail.com>\n"" ""Language-Team: Portuguese (Brazil)\n"" ""Language: pt-BR\n"" ""X-Generator: Zanata 3.9.6\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" msgid """" ""(optional) Use the common Angular template as the basis of any Angular pages "" ""to minimize boilerplate code and to ensure that we use similar features/"" ""framing."" msgstr """" ""(opcional) Utilize o modelo Angular comum como base para quaisquer páginas "" ""Angular para minimizar código boilerplate e para assegurar que utilizamos "" ""características/enquadramento similares."" msgid ""10.0.0"" msgstr ""10.0.0"" msgid ""10.0.1"" msgstr ""10.0.1"" msgid ""10.0.2"" msgstr ""10.0.2"" msgid ""11.0.0"" msgstr ""11.0.0"" msgid ""12.0.0.0b1-103"" msgstr ""12.0.0.0b1-103"" msgid ""8.0.1"" msgstr ""8.0.1"" msgid ""9.0.0"" msgstr ""9.0.0"" msgid ""9.1.0"" msgstr ""9.1.0"" msgid """" ""A Descriptor concept allows convenient passing of information that can "" ""globally identify an object, for use in generic views and actions."" msgstr """" ""O conceito de Descritor permite uma passagem conveniente de informações que "" ""podem identificar globalmente um objeto, para uso em visualizações genéricas "" ""e ações."" msgid """" ""A Details page for a resource type (e.g. Images) may now use the Angular "" ""application-level registry to register views so developers may easily create "" ""or extend details views. In this implementation these views are presented as "" ""tabs within the Details page."" msgstr """" ""Um página de Detalhes para um recurso (ex: Imagens) pode agora utilizar "" ""registro Angular em nível de aplicação para registrar visualizações, de "" ""forma que os desenvolvedores podem criar ou extender facilmente "" ""visualizações de detalhes. Nessa implementação, essas visualizações são "" ""apresentadas como abas dentro da página de detalhes."" msgid """" ""A directive (hz-details) provides the ability to intelligently display a set "" ""of views (typically for a Details context)."" msgstr """" ""Uma diretiva (hz-details) fornece a capacidade de mostrar inteligentemente "" ""um conjunto de visualizações (tipicamente para um contexto de Detalhes)."" msgid """" ""A generic Details display parses the location to determine the resource "" ""type, and displays relevant details views for that type."" msgstr """" ""Uma exibição genérica de Detalhes analisa a localização para determinar o "" ""tipo de recurso, e exibe visualizações de detalhes relevantes para aquele "" ""tipo."" msgid """" ""A new Profiler panel in the Developer dashboard is introduced. It integrates "" ""`osprofiler library <http://docs.openstack.org/developer/osprofiler/>`_ into "" ""horizon, thus implementing `blueprint openstack-profiler-at-developer-"" ""dashboard <https://blueprints.launchpad.net/horizon/+spec/openstack-profiler-"" ""at-developer-dashboard>`_. Initially profiler is disabled. To enable it the "" ""value ``OPENSTACK_PROFILER['enabled']`` has to be ``True``. This in turn can "" ""be achieved by copying files _9030_profiler_settings.py.example and "" ""_9030_profiler.py to openstack_dashboard/local/local_settings.d/"" ""_9030_profiler_settings.py and openstack_dashboard/local/enabled/"" ""_9030_profiler.py respectively. Also, by default it expects MongoDB cluster "" ""to be present on the same host where Keystone is located (say, in a Devstack "" ""VM). But it also can be configured with params with "" ""``OPENSTACK_PROFILER['notifier_connection_string]'`` and "" ""``OPENSTACK_PROFILER['receiver_connection_string']`` values. MongoDB should "" ""be installed `manually <https://docs.mongodb.com/manual/tutorial/install-"" ""mongodb-on-ubuntu/#install-mongodb-community-edition>`_ and allowed to "" ""receive requests on 0.0.0.0 interface."" msgstr """" ""Um novo painel de Perfil no dashboard do Desenvolvedor é introduzido. Ele "" ""integra `a biblioteca osprofiler <http://docs.openstack.org/developer/"" ""osprofiler/>`_ dentro do horizon, implementando assim o `blueprint openstack-"" ""profiler-at-developer-dashboard <https://blueprints.launchpad.net/horizon/"" ""+spec/openstack-profiler-at-developer-dashboard>`_. Inicialmente o perfil "" ""está desativado. Para ativá-lo o valor ``OPENSTACK_PROFILER['enabled']`` tem "" ""que ser ``True``. Isso, por sua vez, pode ser conseguido copiando arquivos "" ""_9030_profiler_settings.py.example and _9030_profiler.py para "" ""openstack_dashboard/local/local_settings.d/_9030_profiler_settings.py e "" ""openstack_dashboard/local/enabled/_9030_profiler.py respectivamente. Também, "" ""por padrão ele espera que o cluster MongoDB esteja presente no mesmo host "" ""onde o Keystone está localizado (digamos, em uma VM Devstack). Mas ele "" ""também pode ser configurado com parâmetros com valores "" ""``OPENSTACK_PROFILER['notifier_connection_string]'`` e "" ""``OPENSTACK_PROFILER['receiver_connection_string']``. O MongoDB deve ser "" ""instalado `manualmente <https://docs.mongodb.com/manual/tutorial/install-"" ""mongodb-on-ubuntu/#install-mongodb-community-edition>`_ e habilitado a "" ""receber requisições na interface 0.0.0.0."" msgid ""A shared Django template is now available for use by any Angular page."" msgstr """" ""Um modelo Django compartilhado está disponível agora para ser utilizado por "" ""qualquer página Angular."" msgid """" ""ANGULAR_FEATURES now allows for a key 'flavors_panel' to be specified as "" ""True or False indicating whether the Angular version of the panel is enabled."" msgstr """" ""ANGULAR_FEATURES agora permite que uma chave 'flavors_panel' seja "" ""especificada como True ou False indicando se a versão Angular do painel está "" ""ativada."" msgid """" ""Add a new setting OVERVIEW_DAYS_RANGE. It defines the default date range in "" ""the Overview panel meters - either today minus N days (if the value is "" ""integer N), or from the beginning of the current month until today (if set "" ""to None). This setting is be used to limit the amount of data fetched by "" ""default when rendering the Overview panel. The default value is 1, which "" ""differs from the past behaviour, since it caused serious lags on large "" ""deployments (`bug 1508571 <https://bugs.launchpad.net/horizon/"" ""+bug/1508571>`__)."" msgstr """" ""Adicionada uma nova configuração OVERVIEW_DAYS_RANGE. Ela define a faixa "" ""padrão de datas no painel de medição Visão geral - sendo ou hoje menos N "" ""dias (se o valor é um inteiro N), ou a partir do começo do mês corrente até "" ""hoje (se definido para Nenhum). Essa configuração é utilizada para limitrar "" ""a quantidade de dados buscados por padrão ao renderizar o painel de Visão "" ""Geral. O valor padrão é 1, que difere do comportamento passado, uma vez que "" ""causava sérios atrasos em grandes implantações (`bug 1508571 <https://bugs."" ""launchpad.net/horizon/+bug/1508571>`__)."" msgid """" ""Add a new setting OVERVIEW_DAYS_RANGE. It defines the default date range in "" ""the Overview panel meters - either today minus N days (if the value is "" ""integer N), or from the beginning of the current month until today (if set "" ""to None). This setting is be used to limit the amount of data fetched by "" ""default when rendering the Overview panel. The default value is 1, which "" ""differs from the past behaviour, since it caused serious lags on large "" ""deployments."" msgstr """" ""Adicionada uma nova configuração OVERVIEW_DAYS_RANGE. Ela define a faixa "" ""padrão de datas no painel de medição Visão geral - sendo ou hoje menos N "" ""dias (se o valor é um inteiro N), ou a partir do começo do mês corrente até "" ""hoje (se definido para Nenhum). Essa configuração é utilizada para limitrar "" ""a quantidade de dados buscados por padrão ao renderizar o painel de Visão "" ""Geral. O valor padrão é 1, que difere do comportamento passado, uma vez que "" ""causava sérios atrasos em grandes implantações."" msgid """" ""Added ESLint for JavaScript linting, using the eslint-config-openstack "" ""rules. See `this <https://blueprints.launchpad.net/horizon/+spec/jscs-"" ""cleanup>`__ for more details."" msgstr """" ""Adicionado ESLint para Javascript linting, utilizando as regras eslint-"" ""config-openstack. Veja `isto <https://blueprints.launchpad.net/horizon/+spec/"" ""jscs-cleanup>`__ para maiores detalhes."" msgid """" ""Added Karma for JavaScript testing. See `this <https://blueprints.launchpad."" ""net/horizon/+spec/karma>`__ for more details."" msgstr """" ""Adicionado Karma para testes JavaScript. Veja `isto <https://blueprints."" ""launchpad.net/horizon/+spec/karma>`__ para maiores detalhes."" msgid """" ""Added Keystone to Keystone (K2K) federation support in Horizon. If Keystone "" ""is configured with K2K and has service providers, the list of Keystone "" ""providers will appear in a dropdown. In local_settings.py you can optionally "" ""set the identity provider display name with ``KEYSTONE_PROVIDER_IDP_NAME`` "" ""or set the provider id that is used to compare with the other service "" ""providers ``KEYSTONE_PROVIDER_IDP_ID``. [`blueprint k2k-horizon <https://"" ""blueprints.launchpad.net/horizon/+spec/k2k-horizon>`_]."" msgstr """" ""Adicionado suporte à federação Keystone para Keystone (K2K) no Horizon. Se o "" ""Keystone estiver configurado com K2K e tiver provedores de serviço, a lista "" ""dos provedores Keystone irá aparecer em um menu suspenso. Em local_settings."" ""py você pode opcionalmente definir o nome de apresentação do provedor de "" ""identificação com ``KEYSTONE_PROVIDER_IDP_NAME`` ou definir o id do provedor "" ""que é utilizado para comparar com outros provedores "" ""``KEYSTONE_PROVIDER_IDP_ID``. [`blueprint k2k-horizon <https://blueprints."" ""launchpad.net/horizon/+spec/k2k-horizon>`_]."" msgid """" ""Added a new ``ANGULAR FEATURES`` dictionary to the settings. This allows "" ""simple toggling of new AngularJS features."" msgstr """" ""Adicionado um novo dicionário ``ANGULAR FEATURES`` às configurações. Isso "" ""permite trocas simples de novos recursos AngularJS."" msgid """" ""Added ability to render angular row actions with additional details that "" ""explain the purpose of the action. These are rendered as tiles and are meant "" ""to depict the next steps a user might want to take for a given resource."" msgstr """" ""Adicionada a capacidade de renderizar ações em linhas Angular com detalhes "" ""adicionais que explicam o propósito da ação. Elas são renderizadas como "" ""placas e destinam-se a descrever as próximas etapas que um usuário pode "" ""querer tomar para um determinado recurso."" msgid """" ""Added actions to easily associate LBaaS VIP with a floating IP. See `this "" ""<https://blueprints.launchpad.net/horizon/+spec/lbaas-vip-fip-associate>`__ "" ""for more details."" msgstr """" ""Adicionadas ações para associar facilmente LBaaS VIP com IP flutuante. Veja "" ""`isto <https://blueprints.launchpad.net/horizon/+spec/lbaas-vip-fip-"" ""associate>`__ para maiores detalhes."" msgid """" ""Added editing capabilities for data sources. See `this <https://blueprints."" ""launchpad.net/horizon/+spec/allow-editing-of-data-sources>`__ for more "" ""details."" msgstr """" ""Adicionados recursos de edição para fontes de dados. Veja `isto <https://"" ""blueprints.launchpad.net/horizon/+spec/allow-editing-of-data-sources>`__ "" ""para maiores detalhes."" msgid """" ""Added editing capabilities for job binaries. See `this <https://blueprints."" ""launchpad.net/horizon/+spec/allow-editing-of-job-binaries>`__ for more "" ""details."" msgstr """" ""Adicionados recursos de edição para binários de trabalho. Veja `isto "" ""<https://blueprints.launchpad.net/horizon/+spec/allow-editing-of-job-"" ""binaries>`__ para maiores detalhes."" msgid """" ""Added editing capabilities for job templates. See `this <https://blueprints."" ""launchpad.net/horizon/+spec/data-processing-edit-templates>`__ for more "" ""details."" msgstr """" ""Adicionadas recursos de edição para modelos de tarefas. Veja `isto <https://"" ""blueprints.launchpad.net/horizon/+spec/data-processing-edit-templates>`__ "" ""para maiores detalhes."" msgid """" ""Added initial support for database cluster creation and management. Vertica "" ""and MongoDB are currently supported. See `this <https://blueprints.launchpad."" ""net/horizon/+spec/database-clustering-support>`__ for more details."" msgstr """" ""Adicionado suporte inicial para a criação e gerenciamento de clusters. "" ""Vertica e MongoDB são suportados atualmente. Veja `isto <https://blueprints."" ""launchpad.net/horizon/+spec/database-clustering-support>`__ para maiores "" ""detalhes."" msgid ""Added mapping for Identity Provider and Protocol specific WebSSO."" msgstr """" ""Adicionado mapeamento para Provedor de Identidade e Protocolo específico "" ""WebSSO."" msgid ""Added new Trove features."" msgstr ""Adicionado novas funcionalidades do Trove."" msgid """" ""Added new setting INTEGRATION_TESTS_SUPPORT, default value is `False`. This "" ""value is used when running `manage.py compress` command, so by default all "" ""static assets and html classes used by integration tests are removed from "" ""Horizon production build. Integration tests gate job sets this variable to "" ""`True` and recompresses static assets."" msgstr """" ""Adicionada nova configuração INTEGRATION_TESTS_SUPPORT, cujo valor padrão é "" ""`False`. Este valor é utilizado ao se executar o comando `manage.py "" ""compress`, de forma que, por padrão todos os ativos estáticos e classes html "" ""usados ​​por testes de integração são removidos da versão de produção do "" ""Horizon. A porta de tarefas dos testes de integração define essa variável "" ""como `True` e recomprime os recursos estáticos."" msgid """" ""Added policy support to the angular workflow service so each step in a "" ""workflow can specify a policy check that must pass in order for the step to "" ""be displayed."" msgstr """" ""Adicionado suporte à políticas ao serviço de fluxo de trabalho do Angular, "" ""de forma que cada passo em um fluxo de trabalho pode especificar uma "" ""verificação de política que deverá passar afim de que o passo seja mostrado."" msgid """" ""Added settings support to the angular workflow service so each step in a "" ""workflow can specify a boolean setting that must pass in order for the step "" ""to be displayed."" msgstr """" ""Adicionadas configurações de suporte ao serviço de fluxo de trabalho "" ""Angular, de forma que cada passo em um fluxo de trabalho possa especificar "" ""uma configuração booleana que ele deve passar afim de que o passo seja "" ""mostrado."" msgid """" ""Added support for managing domains and projects when using Keystone v3. "" ""Horizon now maintains a domain scoped token for users who have a role on a "" ""domain, a project scoped token for users who have a role on a project, or "" ""both a domain scoped token and project scoped token for users who have roles "" ""on both."" msgstr """" ""Adicionado suporte ao gerenciamento de domínios e projetos ao utilizar "" ""Keystone V3. O Horizon agora mantém um token de escopo de domínio para "" ""usuários que têm uma função em um domínio, um token de escopo de projeto "" ""para usuários que têm uma função em um projeto, ou um token de escopo de "" ""domínio e um token de escopo de projeto para usuários que têm funções em "" ""ambos."" msgid ""Added support for shell job types and multiple Sahara improvements."" msgstr """" ""Adicionado suporte para tipos de trabalhos shell e várias melhorias no "" ""Sahara."" msgid """" ""Added support for shell job types. See `this <https://blueprints.launchpad."" ""net/horizon/+spec/sahara-shell-action-form>`__ for more details."" msgstr """" ""Adicionado suporte para tipos de trablhos shell. Veja `isto <https://"" ""blueprints.launchpad.net/horizon/+spec/sahara-shell-action-form>`__ para "" ""maiores detalhes."" msgid """" ""Added support for subnet allocation via subnet pools. See `this <https://"" ""blueprints.launchpad.net/horizon/+spec/neutron-subnet-allocation>`__ for "" ""more details."" msgstr """" ""Adicionado suporte para alocação de subredes via pools de subredes. Veja "" ""`isto <https://blueprints.launchpad.net/horizon/+spec/neutron-subnet-"" ""allocation>`__ para maiores detalhes."" msgid """" ""Added the Bootstrap Theme Preview panel to the Developer dashboard. This "" ""panel contains a list of Bootstrap components with source code, so that "" ""developers can see examples of how to structure this code and the effects "" ""their theme will have upon it."" msgstr """" ""Adicionado o painel de visualização com tema Bootstrap ao dashboard do "" ""desenvolvedor. Este painel contém uma lista de componentes do Bootstrap com "" ""código fonte, de modo que os desenvolvedores possam ver exemplos de como "" ""estruturar este código e os efeitos que seus temas irão ter após isso."" msgid """" ""Added the Developer dashboard plugin to contrib. This runs when "" ""``DEBUG=True``, and adds tooling to the UI to aid in development."" msgstr """" ""Adicionado o plugin do painel do Desenvolvedor para contrib. Isto executa "" ""quando ``DEBUG=True``, e adiciona ferramental à Interface de Usuário para "" ""ajudar no desenvolvimento."" msgid """" ""Added the Django template cached loader, so templates are stored in memory. "" ""See https://docs.djangoproject.com/en/1.8/ref/templates/api/#django.template."" ""loaders.cached.Loader"" msgstr """" ""Adicionado o carregador em cache do modelo Django, de forma que os modelos "" ""sejam armazenados em memória. Veja https://docs.djangoproject.com/en/1.8/ref/"" ""templates/api/#django.template.loaders.cached.Loader"" msgid """" ""Added the LAUNCH_INSTANCE_DEFAULTS setting which allows specifying default "" ""values for the Launch Instance workflow. Initially only the Configuration "" ""Drive property is supported."" msgstr """" ""Adicionada a configuração LAUNCH_INSTANCE_DEFAULTS que permite que sejam "" ""especificados valores padrão para o fluxo de trabalho de Lançar Instância. "" ""Inicialmente, somente a propriedade Configuration Drive é suportada."" msgid """" ""Added the Metadata tab to the new Launch Instance workflow to allow adding "" ""key-value metadata to an instance at launch. This includes any properties "" ""from the OS::Nova::Server namespace of the glance metadata definitions."" msgstr """" ""Adicionada a aba de Metadados ao fluxo de trabalho Lançar Instância nova "" ""para permitir a adição de chave-valor de metadado à instância no lançamento. "" ""Isto inclui quaisquer propriedades do namespace OS::Nova::Server das "" ""definições de metadados do Glance."" msgid """" ""Added the Scheduler Hints tab to the new Launch Instance workflow to allow "" ""adding scheduler hints to an instance at launch. In addition to adding "" ""custom key-value pairs, the user can also choose from properties in the "" ""glance metadata definitions catalog that have the OS::Nova::Server resource "" ""type and scheduler_hints properties target."" msgstr """" ""Adicionada a guia Dicas do Agendador ao novo fluxo de trabalho Lançar "" ""instância, para permitir a adição de dicas de agendador a uma instância no "" ""lançamento. Além de adicionar pares de valores-chave personalizados, o "" ""usuário pode também escolher a partir das propriedades no catálogo de "" ""definições de metadados do Glance que tem o tipo de recurso OS::Nova::Server "" ""e o alvo de propriedades scheduler_hints. "" msgid ""Added the Update Encryption action for encrypted volume types."" msgstr """" ""Adicionada a ação Atualizar Criptografia para tipos de volumes "" ""criptografados."" msgid """" ""Added the ``TOKEN_DELETE_DISABLED`` setting, so that deployers can customise "" ""the revocation of a users token on log out."" msgstr """" ""Adicionada a configuração ``TOKEN_DELETE_DISABLED``, de modo que os "" ""implementadores possam personalizar a revogação de um token de usuário no "" ""log out."" msgid """" ""Added the angular extensible service which allows angular horizon elements "" ""such as workflows, tables, actions, and forms to be extended dynamically by "" ""adding, removing, or replacing items. The extensible service is applied to "" ""every workflow created using the horizon workflow service. This includes the "" ""angular Launch Instance workflow."" msgstr """" ""Adicionado o serviço extensível Angular que permite elementos Angular do "" ""Horizon como fluxos de trabalho, tabelas, ações, e formulários serem "" ""extendidos dinamicamente através da adição, remoção, ou substituição de "" ""items. O serviço extensível é aplicado a qualquer fluxo de trabalho criado "" ""utilizando o serviço de fluxo de trabalho do Horizon. Isto inclui o fluxo de "" ""trabalho Angular de Lançar Instância."" msgid """" ""Adds a new config value called IMAGES_ALLOW_LOCATION, which allows users to "" ""set locations when creating or updating images. Depending on the Glance "" ""version, the ability to set locations is controlled by policies and/or "" ""configuration values."" msgstr """" ""Adiciona novo valor de configuração chamado IMAGES_ALLOW_LOCATION, que "" ""permite o usuário definir localizações ao criar ou atualizar imagens. "" ""Dependendo da versão do Glance, a capacidade de definir localizações é "" ""controlada por políticas e/ou por valores de configuração."" msgid """" ""Adds complete support for Glance v2 so that Horizon no longer depends on "" ""having a Glance v1 endpoint in the Keystone catalog. Also provides code "" ""compatibility between Glance v1 and v2."" msgstr """" ""Adicionado suporte completo ao Glance v2 de modo que o Horizon não mais "" ""dependa de ter um endpoint Glance v1 no catálogo Keystone.\n"" ""Também fornece compatibilidade de código entre Glance v1 e v2."" msgid """" ""All AngularJS code must use explicit dependency injection. See https://docs."" ""angularjs.org/guide/di#using-strict-dependency-injection"" msgstr """" ""Todos os códigos Angular JS devem utilizar injeção de dependência explícita. "" ""Verifique https://docs.angularjs.org/guide/di#using-strict-dependency-"" ""injection"" msgid """" ""All Volume related panels in Horizon that previously used the term \""GB\"" "" ""and \""gigabyte\"" have been replaced with 'GiB' and 'gibibyte'."" msgstr """" ""Todos os painéis relacionados a Volumes no Horizon que previamente usavam o "" ""termo \""GB\"" e \""gigabyte\"" foram substituídos por 'GiB' e 'gibibyte'."" msgid """" ""All instances of HTML class 'd3_pie_chart_usage' to 'pie-chart-usage' All "" ""instances of HTML class 'd3_pie_chart_distribution' to 'pie-chart-"" ""distribution'"" msgstr """" ""Todas as instâncias de classes HTML 'd3_pie_chart_usage' para 'pie-chart-"" ""usage' Todas as instâncias de classes HTML 'd3_pie_chart_distribution' para "" ""'pie-chart-distribution'"" msgid """" ""All instances of HTML class 'd3_pie_chart_usage' to 'pie-chart-usage'. All "" ""instances of HTML class 'd3_pie_chart_distribution' to 'pie-chart-"" ""distribution'."" msgstr """" ""Todas as instâncias de classes HTML 'd3_pie_chart_usage' to 'pie-chart-"" ""usage'. Todas as instâncias de classes HTML class "" ""'d3_pie_chart_distribution' para 'pie-chart-distribution'."" msgid """" ""All previous instances of horizon.alert(...) used by client-side have been "" ""replaced with horizon.toast. Alert messages via horizon.alert(...) should be "" ""avoided when writing new JavaScript code. horizon.toast.add('error', "" ""gettext(...)) should be used instead."" msgstr """" ""Todas as versões anteriores de horizon.alert(...) utilizadas pelo lado "" ""cliente foram substituídas por horizon.toast. Mensagens de alerta via "" ""horizon.alert(...) devem ser evitadas ao se escrever código novo em "" ""JavaScript. Deve ser utilizado horizon.toast.add('error', gettext(...)) em "" ""seu lugar."" msgid """" ""Allow external plugins to contribute translations to the Javascript message "" ""catalog."" msgstr """" ""Permite plugins externos contribuírem com traduções para o catálogo de "" ""mensagens Javascript."" msgid """" ""Allow to override settings from local_settings.py with file snippets dropped "" ""into local_settings.d/ directory."" msgstr """" ""Permite sobrepor configurações a partir do arquivo local_settings.py com "" ""fragmentos de arquivo colocados dentro do diretório local_settings.d/. "" msgid """" ""Allows to attach ports during instance launch <https://blueprints.launchpad."" ""net/horizon/+spec/allow-launching-ports>"" msgstr """" ""Permite conectar portas durante o lançamento da instância <https://"" ""blueprints.launchpad.net/horizon/+spec/allow-launching-ports>"" msgid """" ""Allows to restrict CIDR range for user private network <https://blueprints."" ""launchpad.net/horizon/+spec/restrict-private-network-input>"" msgstr """" ""Permite restringir faixa CIDR para rede privada do usuário <https://"" ""blueprints.launchpad.net/horizon/+spec/restrict-private-network-input>"" msgid """" ""Although it's not required, it's best to make your actions return promises "" ""with the expected structure."" msgstr """" ""Embora não seja necessário, é melhor fazer com que suas ações retornem "" ""promises com a estrutura esperada."" msgid """" ""An action-result service provides convenience methods for construction of "" ""the result, and for parsing of a resolved object"" msgstr """" ""Um serviço de ação-resultado fornece métodos convenientes para construção de "" ""um resultado, e para a análise de um objeto resolvido."" msgid """" ""Angular actions now should return a promise that resolves with an object "" ""structured in a way to indicate what the action did (or didn't do)."" msgstr """" ""Ações do Angular agora devem retornar uma promise que resolve com um objeto "" ""estruturado de modo a indicar o que a ação fez (ou não fez)."" msgid """" ""Angular components now exist to provide simple-to- configure panels and "" ""tables, based off of registry information about resources (e.g. Instances)."" msgstr """" ""Os componentes Angular agora existem para fornecer painéis e tabelas de "" ""fácil configuração, baseado em informações de registro sobre recursos (Ex: "" ""Instâncias)."" msgid """" ""Any past use of the Django based Swift UI is no longer supported and the "" ""code is being removed. The new angularJS based version should be used "" ""instead."" msgstr """" ""Qualquer uso passado da Swift UI do Django não é mais suportado e o código "" ""está sendo removido. Em vez disso, a nova versão baseada em AngularJS deve "" ""ser utilizada."" msgid ""Bug Fixes"" msgstr ""Correção de Bugs"" msgid """" ""Cinder defines storage size in gibibytes (GiB), which is inconsistent with "" ""Horizon panels that show/request storage size in gigabytes (GB)."" msgstr """" ""O Cinder define o tamanho do armazenamento em (GiB), que é inconsistente com "" ""os painéis do Horizon que mostram armazenamento em gigabytes (GB)."" msgid ""Cloud Admin - View and manage identity resources across domains"" msgstr """" ""Administração da Nuvem - Visualiza e gerencia recursos de identidade entre "" ""domínios"" msgid """" ""Compute images metadata can now be edited from the Project dashboard, using "" ""the new metadata editor. See `this <https://blueprints.launchpad.net/horizon/"" ""+spec/project-images-metadata>`__ for more details."" msgstr """" ""O metadado de imagens de Computação pode ser editado agora através do "" ""dashboard do Projeto, utilizando o novo editor de metadados. Veja `isto "" ""<https://blueprints.launchpad.net/horizon/+spec/project-images-metadata>`__ "" ""para maiores detalhes."" msgid """" ""Configurable token hashing, to disable Horizon from hashing the token passed "" ""to the OpenStack services."" msgstr """" ""Hashing de token configurável, para desativar a capacidade do Horizon fazer "" ""hashing do token que é repassado aos serviços do OpenStack."" msgid """" ""Create from a local file feature is added to both Angular and Django Create "" ""Image workflows. It works either in a 'legacy' mode which proxies an image "" ""upload through Django, or in a new 'direct' mode, which in turn implements "" ""[`blueprint horizon-glance-large-image-upload <https://blueprints.launchpad."" ""net/horizon/+spec/horizon-glance-large-image-upload>`_]. To use the direct "" ""mode HORIZON_IMAGES_UPLOAD_MODE setting should be changed to 'direct' value "" ""along with changing glance-api.conf cors.allowed_origin parameter to the URL "" ""from which Horizon is served."" msgstr """" ""O recurso de criar a partir de um arquivo local foi adicionado aos fluxos de "" ""trabalho Criar Imagem tanto do Angular quanto do Django. Ele funciona mesmo "" ""em modo 'legacy' que faz um proxy do carregamento da imagem para o Django, "" ""ou no novo modo 'direct', que por sua vez implementa [`blueprint horizon-"" ""glance-large-image-upload <https://blueprints.launchpad.net/horizon/+spec/"" ""horizon-glance-large-image-upload>`_]. Para utilizar o modo 'direct' as "" ""configurações de HORIZON_IMAGES_UPLOAD_MODE devem ser alteradas para o valor "" ""'direct' juntamente com a alteração do parâmetro glance-api.conf cors."" ""allowed_origin que deeve apontar para a URL de onde o Horizon é servido."" msgid ""Current limitations on managing identity resources with Keystone v3:"" msgstr """" ""Limitações atuais nos recursos de gerenciamento de identidade com o Keystone "" ""v3:"" msgid """" ""Custom template tags must have a thread-safe Node implementation to work "" ""with the the cached loader. See https://docs.djangoproject.com/en/1.8/howto/"" ""custom-template-tags/#template-tag-thread-safety"" msgstr """" ""Tags de modelo personalizadas devem ter uma implementação de Nodo thread-"" ""safe para funcionar com o carregador de cache. Veja https://docs."" ""djangoproject.com/en/1.8/howto/custom-template-tags/#template-tag-thread-"" ""safety"" msgid """" ""Database-backed sessions will likely not persist across upgrades due to a "" ""change in their structure. See `this <https://github.com/openstack/"" ""django_openstack_auth/commit/8c64de92f4148d85704b10ea1f7bc441db2ddfee>`__ "" ""for more details."" msgstr """" ""Sessões baseadas em bancos de dados provavelmente não irão persistir entre "" ""upgrades devido a uma alteração em sua estrutura. Veja `isto <https://github."" ""com/openstack/django_openstack_auth/"" ""commit/8c64de92f4148d85704b10ea1f7bc441db2ddfee>`__ para maiores detalhes."" msgid ""Deprecation Notes"" msgstr ""Notas de obsolecência"" msgid """" ""Django 1.8 is now supported, and Django 1.7 is our minimum supported version."" msgstr """" ""O Django 1.8 agora é suportado, e o Django 1.7 é nossa versão mínima "" ""suportada."" msgid """" ""Django 1.8 is now supported, and Django 1.7 is our minimum supported "" ""version. See `this <https://blueprints.launchpad.net/horizon/+spec/drop-"" ""django14-support>`__ for more details."" msgstr """" ""Django 1.8 é suportado agora, e Django 1.7 é a nossa versão mínima "" ""suportada. Veja `isto <https://blueprints.launchpad.net/horizon/+spec/drop-"" ""django14-support>`__ for more details."" msgid ""Does not support hierarchical project management."" msgstr ""Não suporta gerenciamento hierárquico de projetos."" msgid ""Does not support project admins managing Keystone projects."" msgstr ""Não suporta administradores de projetos gerenciando projetos Keystone."" msgid """" ""Does not support role assignments across domains, such as giving a user in "" ""domain1 access to domain2."" msgstr """" ""Não suporta atribuição de funções entre projetos, tais como dar a um "" ""usuário do domínio1 acesso ao domínio2."" msgid """" ""Domain Admin - View and manage identity resources in the domain logged in"" msgstr """" ""Administração do Domínio - Visualiza e gerencia recursos de identidade no "" ""domínio em que está logado"" msgid ""Domain management supports the following use cases:"" msgstr ""O gerenciamento de domínios suporta os seguintes casos de uso:"" msgid """" ""Download buttons for OpenStack RC files have been added to the user dropdown "" ""menu in the top right of Horizon."" msgstr """" ""Botões de download para arquivos OpenStack RC foram adicionados ao menu "" ""suspenso no canto superior direito do Horizon."" msgid ""Emit the `hzTable:clearSelected` event to clear table row selections."" msgstr """" ""Emitir o evento `hzTable:clearSelected` para limpar seleções de linha da "" ""tabela."" msgid """" ""Enabled support for migrating volumes. See `this <https://blueprints."" ""launchpad.net/horizon/+spec/volume-migration>`__ for more details."" msgstr """" ""Ativado o suporte à migração de volumes. Veja `isto <https://blueprints."" ""launchpad.net/horizon/+spec/volume-migration>`__ para maiores detalhes."" msgid ""Enhanced plugin support for javasciprt, SCSS and Django template."" msgstr ""Suporte de plugin aprimorado para javascript, SCSS e modelo Django."" msgid """" ""Exposed event log for clusters. See `this <https://blueprints.launchpad.net/"" ""horizon/+spec/sahara-event-log>`__ for more details."" msgstr """" ""Exibir log de eventos para clusters. Veja `isto <https://blueprints."" ""launchpad.net/horizon/+spec/sahara-event-log>`__ para maiores detalhes."" msgid """" ""Full support for translation in AngularJS, along with simpler tooling. See "" ""`this <https://blueprints.launchpad.net/horizon/+spec/angular-translate-"" ""makemessages>`__ for more details."" msgstr """" ""Suporte completo para traduções em AngularJS, juntamente com ferramentas "" ""mais simples. Veja `this <https://blueprints.launchpad.net/horizon/+spec/"" ""angular-translate-makemessages>`__ para maiores detalhes."" msgid """" ""Fullscreen Modals have been deprecated in favor of modal-xl. Currently, it "" ""is set to 95% of the viewable screen width."" msgstr """" ""Modos de tela cheia tornaram-se obsoletos em favor do modal-xl. Atualmente, "" ""ele é definido para 95% da largura da tela visível."" msgid """" ""Glance v2 doesn't support the copy-from feature, so this feature is disabled "" ""in Horizon when using Glance v2."" msgstr """" ""Glance v2 não suporta a funcionalidade copiar-de, assim esse recurso está "" ""desativado no Horizon ao se utilizar Glance v2"" msgid """" ""HORIZON_IMAGES_ALLOW_UPLOAD setting is deprecated and should be gradually "" ""replaced with HORIZON_IMAGES_UPLOAD_MODE setting."" msgstr """" ""A configuração HORIZON_IMAGES_ALLOW_UPLOAD está obsoleta e deve ser "" ""gradualmente substituída pela configuração HORIZON_IMAGES_UPLOAD_MODE."" msgid """" ""Hardcoded admin role is replaced with RBAC policy check in panels. Now users "" ""access to the panels is defined by policies and not user roles. The change "" ""affected the Admin dashboard and its panels (Overview, Hypervisors, "" ""Instances and Metadata Definitions)."" msgstr """" ""A função admin atrelada ao código foi substituída pela política RBAC "" ""selecionável nos painéis. Agora, o acesso de usuários aos painéis é definido "" ""por políticas e não funções de usuários. A mudança afeta o dashboard do "" ""Admin e seus painéis (Visão geral, Hipervisores, Instâncias e Definições de "" ""Metadados)."" msgid ""Heat topology improvements."" msgstr ""Melhorias na topologia do Heat"" msgid """" ""Horizon and Horizon Plugins can access the Keystone Token from JavaScript so "" ""that they can make CORS calls directly to other OpenStack Services. This can "" ""enable much more responsive UI."" msgstr """" ""Horizon e seus plugins podem acessar o Token do Keystone através de "" ""JavaScript de modo que possam fazer chamadas CORS diretamente a outros "" ""serviços OpenStack. Isto pode ativar uma UI muito mais responsiva."" msgid """" ""Horizon can be configured to run with multiple themes available at run "" ""time. A new selection widget is available through the user menu. It uses a "" ""browser cookie to allow users to toggle between the configured themes. By "" ""default, Horizon is configured with the two themes available, 'default' and "" ""'material'."" msgstr """" ""O Horizon pode ser configurado para executar com vários temas disponíveis em "" ""tempo de execução. Um novo widget de seleção está disponível através do menu "" ""de usuário. Ele utiliza um cookie de navegador para permitir aos usuários "" ""alternar entre os temas configurados. Por padrão, o Horizon é configurado "" ""com dois temas disponíveis, 'default' and 'material'."" msgid """" ""Horizon currently supports both Angular 1.3.x and Angular 1.4.x, but will "" ""remove 1.3 support in the future. See `Migrating from 1.3 to 1.4 <https://"" ""docs.angularjs.org/guide/migration#migrating-from-1-3-to-1-4>`_"" msgstr """" ""Horizon suporta atualmente Angular 1.3.x e Angular 1.4.x, mas removerá o "" ""suporte ao 1.3 no futuro. Veja `Migração de 1.3 para 1.4 <https://docs."" ""angularjs.org/guide/migration#migrating-from-1-3-to-1-4>`_"" msgid ""Horizon no longer requires Magic Search as an external dependency."" msgstr ""O Horizon não mais requer o Magic Search como uma dependância externa."" msgid """" ""Horizon no longer requires Nova (or Glance) to function; it will run as long "" ""as keystone is present (for instance, swift-only deployments)."" msgstr """" ""O Horizon não mais requer o Nova (ou o Galnce) para funcionar; ele irá rodar "" ""quando o Keystone estiver presente (por exemplo, implantações swift-only)."" msgid """" ""Horizon no longer uses QUnit in testing, and it has been removed from our "" ""requirements. See `this <https://blueprints.launchpad.net/horizon/+spec/"" ""replace-qunit-tests-with-jasmine>`__ for more details."" msgstr """" ""O Horizon não utiliza mais o QUnit em testes, e ele foi removido de nossos "" ""requisitos. Veja `isto <https://blueprints.launchpad.net/horizon/+spec/"" ""replace-qunit-tests-with-jasmine>`__ para maiores detalhes."" msgid """" ""Horizon now has a (non-navigational) route in Django so generic details "" ""pages are deep-linked."" msgstr """" ""O Horizon agora tem uma rota (não-navegacional) no Django, de modo que as "" ""páginas de detalhes genéricas estão profundamente vinculadas."" msgid """" ""Horizon now has multiple configuration options for the default web URL "" ""(``WEBROOT``), static file location (``STATIC_ROOT``) and static file URL "" ""(``STATIC_URL``) in its settings files."" msgstr """" ""Agora o Horizon tem diversas opções de configuração para a URL web padrão "" ""(``WEBROOT``), localização de arquivo estático (``STATIC_ROOT``) e URL de "" ""arquivo estático (``STATIC_URL``) em seus arquivos de configuração."" msgid """" ""Horizon now supports overriding of existing Django templates. See `this "" ""<https://blueprints.launchpad.net/horizon/+spec/horizon-theme-templates>`__ "" ""for more details."" msgstr """" ""Agora o Horizon suporta a sobreposição de modelos Django existentes. Veja "" ""`isto <https://blueprints.launchpad.net/horizon/+spec/horizon-theme-"" ""templates>`__ para maiores detalhes."" msgid """" ""Horizon requires both a ``volume`` and ``volumev2`` endpoint for Cinder, "" ""even if only using v2."" msgstr """" ""O Horizon requer tanto um endpoint``volume`` como um ``volumev2``para o "" ""Cinder, mesmo que se use apenas v2."" msgid """" ""Horizon support for network IP availability feature. Enable Horizon admin "" ""network dashboard to be able to display IP availability. Enables 2 columns "" ""in the admin network subnets table to display the allocated IPs in a given "" ""subnet and unallocated free IPs for each subnet in the network."" msgstr """" ""Suporte do Horizon ao recurso de disponibilidade de rede IP. Habilita o "" ""dashboard de administração de rede do Horizon a ser capaz de mostrar "" ""disponibilidade de IP.\n"" "" Ativa 2 colunas na tabela de subredes da rede de administração para mostrar "" ""os IPs alocados em uma dada subrede, e IPs livres não alocados para cada "" ""subrede na rede."" msgid """" ""Horizon workflow Step now support allowed() method to determine the step "" ""should be displayed conditionally. The workflow Step class already support "" ""policy check and permission mechanism to decide the step should be "" ""displayed, but allowed() is used to support more complex or dynamic "" ""condition."" msgstr """" ""O fluxo de trabalho Horizon Step agora suporta o método allowed() para "" ""determinar que o passo deve ser mostrado condicionalmente. O fluxo de "" ""trabalho classe Step já suporta checagem de política e mecanismo de "" ""permissões para decidir se o passo deve ser mostrado, mas o allowed() é "" ""usado para suportar condições mais complexas ou dinâmicas."" msgid """" ""If the 'default' theme is still required for legacy overrides to function, "" ""simply copy the styles in the 'default' theme into a pre-existing theme or "" ""create a new custom theme."" msgstr """" ""Se o tema 'default' é ainda requerido por sobreposições legadas para "" ""funcionar, simplesmente copie os estilos no tema 'default' dentro de um tema "" ""pré existente ou crie um novo tema personalizado."" msgid """" ""If you set 'images_panel' to False for the ANGULAR_FEATURES option (which is "" ""not the default) and configure Horizon to use Glance v2, Ramdisk ID and "" ""Kernel ID don't show properly on the \""Edit Image\"" screen."" msgstr """" ""Se você definir 'images_panel' para False para a opção ANGULAR_FEATURES "" ""(que não é o padrão) e configurar o Horizon para utilizar Glance v2, o "" ""Ramdisk ID e o Kernel ID não são mostrados corretamente na tela \""Editar "" ""Imagem\""."" msgid ""Image metadata editor upgraded."" msgstr ""Editor de metadados de imagem atualizado."" msgid """" ""Implements the \""filter first\"" functionality for identity panels such as "" ""projects, users, groups and roles. The filter first functionality is "" ""described in <https://blueprints.launchpad.net/horizon/+spec/admin-views-"" ""filter-first>`"" msgstr """" ""Implementa a funcionalidade \""filtrar primeiro\"" para painéis de identidade "" ""como projetos, usuários, grupos e funções. A fucnionalidade Filtrar Primeiro "" ""é descrita em <https://blueprints.launchpad.net/horizon/+spec/admin-views-"" ""filter-first>`"" msgid ""Improved WebSSO support."" msgstr ""Suporte WebSSO melhorado."" msgid """" ""Improvements to the heat topology, making more resources identifiable where "" ""previously they had no icons and were displayed as unknown resources. See "" ""`this <https://blueprints.launchpad.net/horizon/+spec/heat-topology-display-"" ""improvement>`__ for more details."" msgstr """" ""Melhorias na topologia do Heat, tornando mais recursos identificáveis onde "" ""anteriormente eles não tinham ícones e eram mostrados como recursos "" ""desconhecidos. Veja `isto <https://blueprints.launchpad.net/horizon/+spec/"" ""heat-topology-display-improvement>`__ para maiores detalhes."" msgid """" ""In an effort to establish Angular conventions, use the framework's "" ""toastService rather than the legacy horizon.alert(...) in client-side code. "" ""horizon.alert is still used by the django messaging framework, so horizon."" ""messages.js still exists."" msgstr """" ""Em um esforço em estabelecer convenções do Angular, utilize o framework do "" ""toastService no lugar do antigo horizon.alert(...) no código do lado "" ""cliente. horizon.alert ainda é utilizado pelo framework de mensagens do "" ""Django, assim, horizon.messages.js ainda existe."" msgid """" ""In an effort to standarize our HTML class naming conventions, we will be "" ""updating various class names to use dashes, instead of underscore or "" ""camelcasing, to match with Bootstrap's convention."" msgstr """" ""Em um esforço em padronizar nossas convenções de nomes para classes HTML, "" ""estaremos atualizando vários nomes de classes para utilizar traços, em vez "" ""de underscore ou camelcasing para corresponder à convenção do Bootstrap."" msgid """" ""Inline Edit functionality for Horizon tables is now deprecated and will be "" ""removed in Horizon P (12.0) The functionality was removed from the following "" ""tables. Admin Volume Types table, Admin Metadata Definitions table, Identity "" ""Projects table and Identity Users table"" msgstr """" ""A funcionalidade Edição em Linha para tabelas do Horizon está agora obsoleta "" ""e será removida no Horizon P (12.0). A funcionalidade foi removida das "" ""seguintes tabelas: Admin Volume, tabela Types, tabela Admin Metadata "" ""Definitions, tabela Identify Projects e tabela Indentify Users."" msgid """" ""Instance metadata can be updated (https://blueprints.launchpad.net/horizon/"" ""+spec/edit-server-metadata)"" msgstr """" ""Metadados de Instância podem ser atualizados (https://blueprints.launchpad."" ""net/horizon/+spec/edit-server-metadata)"" msgid ""Instance shelving and unshelving now supported."" msgstr """" ""Emprateleiramento e desemprateleiramento de Instância agora é suportado."" msgid """" ""Integration tests for Flavor features may also be toggled in "" ""openstack_dashboard/test/integration_tests/horizon.conf using the "" ""'panel_type' feature in the 'flavors' setting, either set to 'legacy' or "" ""'angular' to match the enabled panel type."" msgstr """" ""Testes de integração para recursos de Flavor podem também ser intercambiados "" ""em openstack_dashboard/test/integration_tests/horizon.conf utilizando o "" ""recurso 'panel_type' na configuração 'flavors' , seja definindo para "" ""'legacy' ou 'angular' para corresponder ao tipo de painel habilitado."" msgid """" ""Integration tests for Image features may also be toggled in "" ""openstack_dashboard/test/integration_tests/horizon.conf using the "" ""'panel_type' feature, either set to 'legacy' or 'angular' to match the "" ""enabled panel type."" msgstr """" ""Testes de integração para recursos de Imagem também podem ser alternados em "" ""openstack_dashboard/test/integration_tests/horizon.conf utilizando a "" ""característica de 'panel_type' , definida para 'legacy' ou 'angular' para "" ""corresponder ao tipo de painel ativado."" msgid """" ""It is no longer necessary to include the version suffix into "" ""OPENSTACK_KEYSTONE_URL setting. Thanks to a recent update of django-"" ""openstack-auth library as of 2.3.0 release, Horizon will append the proper "" ""version suffix to the URL based on the value stored inside "" ""OPENSTACK_API_VERSIONS['identity'] setting."" msgstr """" ""Não é mais necessário incluir o sufixo de versão na configuração "" ""OPENSTACK_KEYSTONE_URL. Graças a uma atualização recente da biblioteca "" ""django-openstack-auth conforme o release 2.3.0, o Horizon irá acrescentar o "" ""sufixo de versão correspondente à URL baseado no valor armazenado dentro da "" ""configuração OPENSTACK_API_VERSIONS['identity']."" msgid ""JavaScript can now access the Keystone Token."" msgstr ""O JavaScript agora pode acessar o Token do Keystone."" msgid """" ""JavaScript files are now automatically included. See `this <https://"" ""blueprints.launchpad.net/horizon/+spec/auto-js-file-finding>`__ for more "" ""details."" msgstr """" ""Arquivos JavaScript agora são automaticamente incluídos. Veja `isto <https://"" ""blueprints.launchpad.net/horizon/+spec/auto-js-file-finding>`__ para maiores "" ""detalhes."" msgid ""Known Issues"" msgstr ""Problemas Conhecidos"" msgid """" ""LBaaS v1 dashboard has been removed. LBaaS v1 feature was removed from "" ""neutron-lbaas in Newton, but LBaaS v1 dashboard in Horizon has been kept "" ""only for backward compatibility in Newton release so that operators can "" ""upgrade Horizon first. Note that the Dashboard support for LBaaS v2 is "" ""provided as a Horizon plugin via `neutron-lbaas-dashboard project <http://"" ""git.openstack.org/cgit/openstack/neutron-lbaas-dashboard/>`__."" msgstr """" ""O dashboard LBaaS v1 foi removido. O recurso LBaaS v1 foi removido do "" ""neutron-lbaas no Newton, mas o dashboard LBaaS v1 no Horizon foi mantido "" ""apenas para compatibilidade retroativa na versão do Newton, de modo que os "" ""operadores possam atualizar o Horizon primeiro. Observe que o suporte do "" ""Dashboard para LBaaS v2 é fornecido como um plugin do Horizon via `projeto "" ""neutron-lbaas-dashboard <http://git.openstack.org/cgit/openstack/neutron-"" ""lbaas-dashboard/>`__."" msgid """" ""LBaaS v1 dashboard is now deprecated and will be removed in Ocata release. "" ""LBaaS v1 feature was removed from neutron-lbaas in Ocata and this "" ""functionality in Horizon is only for backward compatibility so that "" ""operators can upgrade Horizon first. Note that the Dashboard support for "" ""LBaaS v2 is provided as a Horizon plugin via `neutron-lbaas-dashboard "" ""project <http://git.openstack.org/cgit/openstack/neutron-lbaas-dashboard/"" "">`__."" msgstr """" ""O dashboard LBaaS v1 está agora obsoleto e será removido na edição Ocata. O "" ""recurso LBaaS v1 foi removido do neutron-lbaas no Ocata e esta "" ""funcionalidade no Horizon foi mantida apenas para compatibilidade "" ""retroativa, de modo que os operadores possam atualizar o Horizon primeiro. "" ""Observe que o suporte do Dashboard para LBaaS v2 é fornecido como um plugin "" ""do Horizon via `projeto neutron-lbaas-dashboard Observe que o suporte do "" ""Dashboard para LBaaS v2 é fornecido como um plugin do Horizon via `projeto "" ""neutron-lbaas-dashboard <http://git.openstack.org/cgit/openstack/neutron-"" ""lbaas-dashboard/>`__."" msgid """" ""LP-1585682 is fixed which grants Horizon the ability to properly version "" ""Keystone webpath endpoints (URLs like http://<hostip>/identity instead of "" ""http://<hostip>:5000)."" msgstr """" ""LP-1585682 está corrigido o que concede ao Horizon a capacidade de versionar "" ""corretamente os endpoints web (URLs como http://<hostip>/identity em vez de "" ""http://<hostip>:5000)."" msgid ""Made the Angular Launch Instance workflow the default in Horizon."" msgstr """" ""Tornou o fluxo de trabalho Angular de Lançar Instância o padrão no Horizon."" msgid """" ""Making Keystone Tokens available to JavaScript slightly increases the risk "" ""of a Token being captured. If you don't need this functionality, it can be "" ""disabled by setting the following option in your local_settings: "" ""ENABLE_CLIENT_TOKEN = False"" msgstr """" ""Tornar os Tokens do Keystone disponíveis ao JavaScript aumenta ligeiramente "" ""o risco de um Token ser capturado. Se você não precisa desta funcionalidade, "" ""ela pode ser desativada configurando-se a seguinte opção em seu "" ""local_settings: ENABLE_CLIENT_TOKEN = False"" msgid """" ""Many JavaScript files and most notably the base page template (``horizon/"" ""templates/base.html``) have moved from the framework portion of the repo "" ""(``horizon``) to the application side (``openstack_dashboard``) to better "" ""separate the framework from the application."" msgstr """" ""Muitos arquivos JavaScript e mais notavelmente o modelo da página base "" ""(``horizon/templates/base.html``) foram movidos da porção framework do "" ""repositório (``horizon``) para o lado da aplicação "" ""(``openstack_dashboard``) para melhor separar o framework da aplicação."" msgid """" ""Many Javascript files have moved to new locations in the horizon/lib static "" ""folder. Previously the locations of some files were hard-coded but now the "" ""locations are determined automatically based on the xstatic package name."" msgstr """" ""Muitos arquivos JavaScript foram movidos para novas localizações na pasta "" ""estática horizon/lib. Previamente, as localizações de alguns arquivos eram "" ""atreladas ao código, mas agora as localizações são determinadas "" ""automaticamente, baseadas nome do pacote xstatic."" msgid ""Many of Horizons XStatic packages were updated during this cycle."" msgstr """" ""Muitos do pacotes XStatic do Horizon foram atualizados durante este ciclo."" msgid ""Menu follows the search input position as the user adds more facets"" msgstr """" ""O menu segue a posição de entrada de pesquisa à medida que o usuário "" ""adiciona mais facetas"" msgid ""Modal sizes now inherit from Bootstrap's theme variables."" msgstr ""Os tamanhos modais agora herdam as variáveis ​​do tema Bootstrap."" msgid """" ""Modal sizes now inherit their value from theme variables. Two additional "" ""sizes are available now for use in Horizon, extra to the standard 3 sizes of "" ""Bootstrap Modals, modal-xs and modal-xl."" msgstr """" ""Tamanhos modais agora herdam seus valores das variáveis de temas. Dois "" ""tamanhos adicionais estão disponíveis agora para uso no Horizon, além dos 3 "" ""tamanhos padrão dos Modais Bootstrap, modal-xs e modal-xl."" msgid """" ""Move OpenStack Dashboard Swift panel rendering logic to client-side using "" ""AngularJS for significant usability improvements."" msgstr """" ""Movida a lógica de renderização do painel OpenStack Dashboard Swift para o "" ""lado cliente, utilizando AngularJS para melhorias significativas de "" ""usabilidade."" msgid ""Neutron network type for Geneve tunneling protocol is now supported."" msgstr """" ""Tipo de rede do Neutron para o protocolo de tunelamento Geneve agora é "" ""suportado."" msgid """" ""Neutron provider network configuration now becomes more flexible so that "" ""operators can configure various provider network parameters including new "" ""network type, segmenatiton ID ranges and so on based on neutron network back-"" ""ends they use."" msgstr """" ""O provedor de configuração de rede do Neutron ficou agora mais flexível de "" ""modo que os operadores podem configurar vários parâmetros de provedor de "" ""redes, incluindo tipo de rede, faixas de segmentação de redes e assim por "" ""diante, baseado nos back-ends de rede do Neutron que eles utilizam."" msgid """" ""Neutron provider network configuration now becomes more flexible so that "" ""operators can configure various provider network parameters including new "" ""network type, segmentation ID ranges and so on based on neutron network back-"" ""ends they use."" msgstr """" ""O provedor de configuração de rede do Neutron ficou agora mais flexível de "" ""modo que os operadores podem configurar vários parâmetros de provedor de "" ""redes, incluindo tipo de rede, faixas de segmentação de redes e assim por "" ""diante, baseado nos back-ends de rede do Neutron que eles utilizam."" msgid """" ""Neutron provider network types for Midonet are now supported. To enable "" ""them, specify these network types in ``supported_provider_types`` in the "" ""configuration file."" msgstr """" ""Os tipos de rede do provedor do Neutron para Midonet agora são suportados. "" ""Para ativá-los, especifique esses tipos de rede no arquivo de configuração "" ""``supported_provider_types``."" msgid ""New Features"" msgstr ""Novos Recursos"" msgid ""New network topology panel. Added support for subnet allocation."" msgstr """" ""Novo painel de topologia de rede. Adicionado suporte à alocação de subredes."" msgid """" ""Nova and Glance are no longer required in order to run Horizon. As long as "" ""keystone is present, Horizon will run correctly."" msgstr """" ""Nova e Glance não são mais requeridos para se executar o Horizon. Uma vez "" ""que o Keystone esteja presente, o Horizon funcionará corretamente."" msgid ""Other Notes"" msgstr ""Outras Notas"" msgid """" ""Plugin improvements, Horizon auto discovers JavaScript files for inclusion, "" ""and now has mechanisms for pluggable SCSS and Django template overrides."" msgstr """" ""Melhorias no Plugin, o Horizon descobre automaticamente os arquivos "" ""JavaScript para inclusão e tem agora mecanismos para SCSS plugável e "" ""sobreposições de modelos Django."" msgid """" ""Policies associated with Consistency Groups exist in the Cinder policy file, "" ""and by default, all actions are disabled."" msgstr """" ""Políticas associadas com Grupos de Consistência existem no arquivo de "" ""política do Cinder, e por padrão todas as ações estão destivadas."" msgid ""Properties are now bound to the controller instead of the scope."" msgstr """" ""As propriedades agora estão vinculadas ao controlador em vez de ao escopo."" msgid """" ""Provided the ability for plugins to contribute translations to the "" ""JavaScript message catalog. Previously the horizon and openstack_dahboard "" ""applications were hardcoded."" msgstr """" ""Fornecida a capacidade para os plugins de contribuirem com traduções para o "" ""catálogo de mensagens do JavaScript. Previamente as aplicações do Horizon e "" ""openstack_dahboard eram fixadas no código."" msgid """" ""Removing formerly deprecated Swift UI code that was replaced with an "" ""improved Angular version in Mitaka."" msgstr """" ""Remoção do código de UI Swift anteriormente obsoleto que foi substituído "" ""por uma versão Angular aprimorada em Mitaka."" msgid """" ""Router rules is a horizon extension provided by Big Switch Networks. As part "" ""of the horizon-vendor-split work, we drop the extension from upstream "" ""horizon. It is now available as a separate plugin at https://github.com/"" ""bigswitch/horizon-bsn"" msgstr """" ""Regras de roteador é uma extensão do Horizon fornecida pela Big Switch "" ""Networks. Como parte do trabalho do horizon-vendor-split , retiramos a "" ""extensão do Horizon principal. Ela é disponível agora como um plugin "" ""separado em https://github.com/bigswitch/horizon-bsn"" msgid ""Security Issues"" msgstr ""Problemas de Segurança"" msgid """" ""Selenium tests may now be exercised using the headless PhantomJS driver."" msgstr """" ""Testes do Selenium podem agora ser exercitados utilizando driver PhantomJS "" ""sem cabeçalho."" msgid """" ""Several fixes have been made to the hzTable controller. The list below "" ""outline these changes. See inline documentation for usage details."" msgstr """" ""Várias correções foram feitas no controlador hzTable. A lista abaixo "" ""delineia estas alterações. Veja a documentação em linha para detalhes de uso."" msgid """" ""String attributes ``action_present`` and ``action_past`` were dropped from "" ""``horizon.tables.BatchAction``. ``action_present`` and ``action_past`` "" ""*methods* are the recommended way to define action labels for BatchAction. "" ""The offical way allows us to define more complete strings for action labels "" ""and this also allows translators to translate more flexibily."" msgstr """" ""Atributos de strings ``action_present`` e ``action_past`` foram retirados do "" ""``horizon.tables.BatchAction``. Os *métodos* ``action_present`` and "" ""``action_past`` são a forma recomendada para definir etiquetas de ação para "" ""BatchAction. A forma oficial nos permite definir strings mais complexas para "" ""etiquetas de ação e isto também permite aos tradutores traduzirem mais "" ""flexivelmente."" msgid """" ""Support a parameter to specify subnet or fixed IP address when creating port."" msgstr """" ""Suporta um parâmetro para especificar subrede ou endereço IP fixo durante a "" ""criação de porta."" msgid """" ""Support for shelving and unshelving of instances. See `this <https://"" ""blueprints.launchpad.net/horizon/+spec/horizon-shelving-command>`__ for more "" ""details."" msgstr """" ""Suporte para emprateleiramento e desemprateleiramento de instâncias. Veja "" ""`isto <https://blueprints.launchpad.net/horizon/+spec/horizon-shelving-"" ""command>`__ para maiores detalhes."" msgid """" ""Support for v2 block device mapping, falling back to v1 when unavailable. "" ""See `this <https://blueprints.launchpad.net/horizon/+spec/horizon-block-"" ""device-mapping-v2>`__. for more details."" msgstr """" ""Suporte para mapeamento de dispositivo de bloco v2, voltando para a v1 "" ""quando não estiver disponível. Veja `isto <https://blueprints.launchpad.net/"" ""horizon/+spec/horizon-block-device-mapping-v2>`__. para maiores detalhes."" msgid """" ""The 'default_ipv4_subnet_pool_label' and 'default_ipv6_subnet_pool_label' "" ""options has been deprecated and will be removed in the Newton release. "" ""Starting with Mitaka you can create one default subnet pool per address "" ""family through the Neutron API. These subnet pools will automatically show "" ""up in the subnet pool list using the name of the pool as label."" msgstr """" ""As opções 'default_ipv4_subnet_pool_label' e "" ""'default_ipv6_subnet_pool_label' tornaram-se obsoletas e serão removidas na "" ""versão do Newton. Iniciando a partir do Mitaka você pode criar um pool de "" ""subrede padrão por família de endereços através da API do Neutron. Esses "" ""pools de subredes serão mostrados automaticamente na lista de pool de "" ""subrede, utilizando o nome do pool como etiqueta."" msgid """" ""The 'default_ipv4_subnet_pool_label' and 'default_ipv6_subnet_pool_label' "" ""options were deprecated in the Mitaka release and are no longer valid in the "" ""Newton release. Starting with Mitaka you can create one default subnet pool "" ""per address family through the Neutron API. These subnet pools will "" ""automatically show up in the subnet pool list using the name of the pool as "" ""label."" msgstr """" ""As opções 'default_ipv4_subnet_pool_label' e "" ""'default_ipv6_subnet_pool_label' tornaram-se obsoletas na versão Mitaka e "" ""não são mais válidas na versão Newton. Iniciando a partir do Mitaka você "" ""pode criar um pool de subrede padrão por família de endereços através da API "" ""do Neutron. Esses pools de subredes serão mostrados automaticamente na lista "" ""de pool de subrede, utilizando o nome do pool como etiqueta."" msgid ""The 'webroot' theme has been removed."" msgstr ""O tema 'webroot' foi removido."" msgid """" ""The 'webroot' theme was providing an example of how to set the webroot value "" ""through SCSS for accessing needed static URL prefixes for assets like font "" ""paths. This value is now retrieved directly from the Django settings and is "" ""available directly in the SCSS namespace via $static_url."" msgstr """" ""O tema 'webroot' estava fornecendo um exemplo de como definir o valor do "" ""webroot através do SCSS para acessar prefixos de URL estáticos necessários "" ""para recursos como caminhos de fonte. Este valor é agora recuperado "" ""diretamente das configurações do DJango e está disponível diretamente no "" ""namespace SCSS via $static_url."" msgid """" ""The Access & Security panel's tabs have been moved to their own panels for "" ""clearer navigation and better performance. API Access and Key Pairs now "" ""reside in the Compute panel group. Floating IPs and Security Groups are now "" ""in the Network panel group."" msgstr """" ""As abas do painel Acesso & Segurança foram movidas para o seu próprio painel "" ""para uma navegação mais clara e melhor performance. Acesso à API e Pares de "" ""Chaves agora residem no grupo de painel Computação. IPs flutuantes e Grupos "" ""de Segurança estão agora no grupo de painel de Rede."" msgid """" ""The Angular Bootstrap upgrade contains a breaking change as the directives "" ""and services in this library were renamed. See https://github.com/angular-ui/"" ""bootstrap/wiki/Migration-guide-for-prefixes"" msgstr """" ""A atualização Angular Bootstrap contém uma alteração de ruptura à medida que "" ""as diretivas e serviços desta biblioteca foram renomeados. Veja https://"" ""github.com/angular-ui/bootstrap/wiki/Migration-guide-for-prefixes"" msgid """" ""The Flavor panel now may be configured to use either the legacy or Angular "" ""code."" msgstr """" ""O painel Flavor agora pode ser configurado para utilizar ou o modo legacy ou "" ""código Angular."" msgid """" ""The Images panel now may be configured to use either the legacy or Angular "" ""code."" msgstr """" ""O painel Imagens agora pode ser configurado para utilizar ou o modo legacy "" ""ou código Angular."" msgid """" ""The LAUNCH_INSTANCE_DEFAULTS variable must be added to the "" ""REST_API_REQUIRED_SETTINGS setting in local_settings.py"" msgstr """" ""A variável LAUNCH_INSTANCE_DEFAULTS deve ser adicionada à configuração "" ""REST_API_REQUIRED_SETTINGS em local_settings.py"" msgid """" ""The OPENSTACK_IMAGE_FORMATS variable must be added to the "" ""REST_API_REQUIRED_SETTINGS setting in local_settings.py"" msgstr """" ""A variável OPENSTACK_IMAGE_FORMATS deve ser adicionada à configuração "" ""REST_API_REQUIRED_SETTINGS em local_settings.py"" msgid """" ""The Python Launch Instance workflow has been deprecated and no longer "" ""displays by default."" msgstr """" ""O fluxo de trabalho Python Lançar Instância está obsoleto e não é mais "" ""mostrado por padrão."" msgid """" ""The Python Swift panel has been deprecated and no longer displays by "" ""default. To use the old interface edit ``enabled/"" ""_1920_project_containers_panel.py`` to change ``swift_panel`` to "" ""``'legacy'``."" msgstr """" ""O painel Python Swift está obsoleto e não é mais mostrado por padrão. Para "" ""utilizar a interface antiga edite ``enabled/_1920_project_containers_panel."" ""py`` para mudar ``swift_panel`` para ``'legacy'``."" msgid """" ""The Sahara based content has been removed from the Horizon source tree and "" ""is now a separate plugin. To continue managing Sahara in Horizon, installing "" ""the sahara-dashboard plugin on the Horizon server is required."" msgstr """" ""O conteúdo baseado no Sahara foi removido da árvore de fontes do Horizon e é "" ""agora um plugin separado. Para continuar gerenciando o Sahara no Horizon, a "" ""instalação do plugin sahara-dashboard no servidor Horizon é necessária."" msgid """" ""The Trove based content has been removed from the Horizon source tree and is "" ""now a separate plugin. To continue managing Trove in Horizon, installing the "" ""trove-dashboard plugin on the Horizon server is required."" msgstr """" ""O conteúdo baseado no Trove foi removido da árvore de fontes do Horizon e é "" ""agora um plugin separado. Para continuar gerenciando o Trove no Horizon, a "" ""instalação do plugin trove-dashboard no servidor Horizon é necessária."" msgid """" ""The ``TEMPLATE_*`` settings have been replaced with a ``TEMPLATE`` dict. "" ""This will likely cause issues when porting settings to this version of "" ""Horizon. The TEMPLATE_DEBUG setting has been removed and is tied to the "" ""DEBUG setting now. A detailed explanation of this dict can be found at "" ""https://docs.djangoproject.com/en/1.10/ref/settings/#templates"" msgstr """" ""As configurações ``TEMPLATE_*`` foram substituídas por um dicionário "" ""``TEMPLATE``. Isso provavelmente causará problemas ao portar configurações "" ""para esta versão do Horizon. A configuração TEMPLATE_DEBUG foi removida e "" ""está ligada à configuração DEBUG agora. Uma explicação detalhada deste "" ""dicionário pode ser encontrada em https://docs.djangoproject.com/en/1.10/ref/"" ""settings/#templates"" msgid """" ""The ``is_authenticated()`` and ``is_anonymous()`` functions in Django "" ""OpenStack Auth's ``User`` class are properties when running under Django "" ""1.10, and no longer take a margin parameter."" msgstr """" ""As funções ``is_authenticated()`` e ``is_anonymous()`` na classe ``User`` do "" ""Django OpenStack Auth são propriedades quando estão rodando sob o Django "" ""1.10, e não pegam mais o parâmetro margin."" msgid """" ""The ``status_unknown`` table row class has been replaced with the default "" ""bootstrap ``warning`` class."" msgstr """" ""A classe da linha da tabela ``status_unknown`` foi substituída pela classe "" ""padrão bootstrap ``warning``."" msgid ""The `select` method has been renamed to to `toggleSelect`."" msgstr ""O método `select` foi renomeado para `toggleSelect`."" msgid """" ""The deprecated ``OPENSTACK_QUANTUM_NETWORK`` configuration option has been "" ""removed. If you still use it, you need to replace it with "" ""``OPENSTACK_NEUTRON_NETWORK``."" msgstr """" ""A configuração obsoleta ``OPENSTACK_QUANTUM_NETWORK`` foi removida. Se você "" ""ainda a utiliza, precisa substituí-la por ``OPENSTACK_NEUTRON_NETWORK``."" msgid """" ""The developer enabled files have been moved from ``openstack_dashboard/"" ""enabled`` to ``openstack_dashboard/contrib/developer/enabled``. To enable "" ""them, copy into ``openstack_dashboard/local/enabled`` and set ``DEBUG = "" ""True``."" msgstr """" ""Os arquivos ativados para desenvolvedor foram movidos de "" ""``openstack_dashboard/enabled`` para ``openstack_dashboard/contrib/developer/"" ""enabled``. Para ativá-los, copie dentro de ``openstack_dashboard/local/"" ""enabled`` e defina ``DEBUG = True``."" ",,1829,42
openstack%2Ftripleo-common~stable%2Focata~I8e0818eff079a802e7c2023749ff3824958dbd7d,openstack/tripleo-common,stable/ocata,I8e0818eff079a802e7c2023749ff3824958dbd7d,Bump OS_BAREMETAL_API_VERSION to 1.29,MERGED,2017-05-09 12:21:10.000000000,2017-06-19 18:38:11.000000000,2017-06-19 18:38:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9414}]","[{'number': 1, 'created': '2017-05-09 12:21:10.000000000', 'files': ['tripleo_common/utils/overcloudrc.py', 'tripleo_common/constants.py', 'releasenotes/notes/ironic-api-version-d2b4ec1474918f12.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c4c3499490f496d79c1438b6d3d941e922e2e5b3', 'message': 'Bump OS_BAREMETAL_API_VERSION to 1.29\n\nThis way the CLI and OSC users can use the latest features without specifying\nthe version explicitly. The final Ocata version is 1.31, but 1.29 is the most\nrecent version supported by ironicclient Ocata.\n\nChange-Id: I8e0818eff079a802e7c2023749ff3824958dbd7d\nDepends-On: I285178d0b7384956eb151ca66007d7354566574d\nPartial-Bug: #1663203\n(cherry picked from commit 6180c2cdf66456011d06b9e334baedb816083b54)\n'}]",0,463552,c4c3499490f496d79c1438b6d3d941e922e2e5b3,8,3,1,10239,,,0,"Bump OS_BAREMETAL_API_VERSION to 1.29

This way the CLI and OSC users can use the latest features without specifying
the version explicitly. The final Ocata version is 1.31, but 1.29 is the most
recent version supported by ironicclient Ocata.

Change-Id: I8e0818eff079a802e7c2023749ff3824958dbd7d
Depends-On: I285178d0b7384956eb151ca66007d7354566574d
Partial-Bug: #1663203
(cherry picked from commit 6180c2cdf66456011d06b9e334baedb816083b54)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/52/463552/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/utils/overcloudrc.py', 'releasenotes/notes/ironic-api-version-d2b4ec1474918f12.yaml', 'tripleo_common/constants.py']",3,c4c3499490f496d79c1438b6d3d941e922e2e5b3,bug/1663203, # The default version of the Bare metal API to set in overcloudrc. # 1.29 is the latest API version in Ironic Ocata supported by ironicclient. DEFAULT_BAREMETAL_API_VERSION = '1.29',,14,0
openstack%2Fceilometer~stable%2Fnewton~I937b844cdaf543b128cd00a7916efd829df26ce0,openstack/ceilometer,stable/newton,I937b844cdaf543b128cd00a7916efd829df26ce0,sqlalchemy: use nested transaction when getting/creating event types,MERGED,2017-06-19 14:57:42.000000000,2017-06-19 18:35:02.000000000,2017-06-19 18:35:02.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-06-19 14:57:42.000000000', 'files': ['ceilometer/tests/functional/storage/test_impl_sqlalchemy.py', 'ceilometer/event/storage/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ffc9e56c3c259c21578254d9f7656b9468dc5613', 'message': 'sqlalchemy: use nested transaction when getting/creating event types\n\nIf adding the database fails, not using a nested transaction will make the\nwhole transaction passed from the caller fail. The code does not handle that at\nall.\n\nThis switches to using a nested transaction, so only the insert is rolled-back\nif it fails.\n\n(cherry-picked from e4021dbeac9c3d72497f6de90a748c6b9c8165fc from panko)\n\nChange-Id: I937b844cdaf543b128cd00a7916efd829df26ce0\n'}]",0,475420,ffc9e56c3c259c21578254d9f7656b9468dc5613,6,2,1,1669,,,0,"sqlalchemy: use nested transaction when getting/creating event types

If adding the database fails, not using a nested transaction will make the
whole transaction passed from the caller fail. The code does not handle that at
all.

This switches to using a nested transaction, so only the insert is rolled-back
if it fails.

(cherry-picked from e4021dbeac9c3d72497f6de90a748c6b9c8165fc from panko)

Change-Id: I937b844cdaf543b128cd00a7916efd829df26ce0
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/20/475420/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/functional/storage/test_impl_sqlalchemy.py', 'ceilometer/event/storage/impl_sqlalchemy.py']",2,ffc9e56c3c259c21578254d9f7656b9468dc5613,," def _get_or_create_event_type(self, event_type, session): with session.begin(nested=True):"," def _get_or_create_event_type(self, event_type, session=None): if session is None: session = self._engine_facade.get_session() with session.begin(subtransactions=True):",16,8
openstack%2Fopenstack-ansible-os_glance~stable%2Focata~I827dad684a259f15cdf24a59dfb26e05e1f7826d,openstack/openstack-ansible-os_glance,stable/ocata,I827dad684a259f15cdf24a59dfb26e05e1f7826d,Pass packages to install as a list,MERGED,2017-06-19 15:18:53.000000000,2017-06-19 18:30:47.000000000,2017-06-19 18:30:47.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-19 15:18:53.000000000', 'files': ['tasks/glance_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/13cdc93e92cdb675ac14a32791ade32c024d30b9', 'message': 'Pass packages to install as a list\n\nInstead of using the slower loop, pass the\nlist directly to the install task to do\nthem all at once.\n\nChange-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d\n(cherry picked from commit eea85d2cd54d2d5eca2fdc8cb96230ad65b7d6fe)\n'}]",0,475425,13cdc93e92cdb675ac14a32791ade32c024d30b9,9,3,1,6816,,,0,"Pass packages to install as a list

Instead of using the slower loop, pass the
list directly to the install task to do
them all at once.

Change-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d
(cherry picked from commit eea85d2cd54d2d5eca2fdc8cb96230ad65b7d6fe)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/25/475425/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/glance_install.yml'],1,13cdc93e92cdb675ac14a32791ade32c024d30b9,distro-pkg-optimise," name: ""{{ glance_distro_packages }}"""," name: ""{{ item }}"" with_items: ""{{ glance_distro_packages }}""",1,2
openstack%2Fpuppet-tripleo~master~I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc,openstack/puppet-tripleo,master,I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc,Fix the port for Panko API,MERGED,2017-06-07 03:29:32.000000000,2017-06-19 18:29:47.000000000,2017-06-19 18:29:47.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 6926}, {'_account_id': 9414}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-07 03:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/9b0b6210df434ef55412052f34da5e0598f6fa8a', 'message': 'Fix the default port for Panko API\n\nChange-Id: I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc\nReleated-Bug: #1691283\nDepends-On: I53b286d1d6466b574fdb286cc45f3138f96dff59\n'}, {'number': 2, 'created': '2017-06-07 04:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e882081fdff0da25725a06c8b8f658d3ea53c8c0', 'message': 'Fix the port for Panko API\n\nThe port used for Panko in the puppet module is inconsistent,\nincorrect and conflicts with Trove. According to the official\ndocumentation[0] this should be 8777.\n\n[0]https://docs.openstack.org/developer/panko/install/manual.html#installing-the-api-server\n\nPlease note that port 8779 has been reserved by Trove!\n\nChange-Id: I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc\nReleated-Bug: #1691283\nDepends-On: I53b286d1d6466b574fdb286cc45f3138f96dff59\n'}, {'number': 3, 'created': '2017-06-08 00:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/133eb7541029f0b0cd48936b41cc9a5554bac7da', 'message': 'Fix the port for Panko API\n\nThe port used for Panko is conflicts with Trove[1]. According to the\nofficial documentation[2] this should be 8777. The 8777 port has been\noccupied by ceilometer. So set the panko api port to 8977.\n\n[1]https://github.com/openstack/trove/blob/master/etc/apache2/trove#L20\n[2]https://docs.openstack.org/developer/panko/install/manual.html#installing-the-api-server\n\nChange-Id: I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc\nReleated-Bug: #1691283\nDepends-On: I53b286d1d6466b574fdb286cc45f3138f96dff59\n'}, {'number': 4, 'created': '2017-06-08 00:57:29.000000000', 'files': ['manifests/haproxy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/6b0084c85df7c94465e2d1e9cda42a52947feee4', 'message': 'Fix the port for Panko API\n\nThe port used for Panko is conflicts with Trove[1]. According to the\nofficial documentation[2] this should be 8777. The 8777 port has been\noccupied by ceilometer. So set the panko api port to 8977.\n\n[1]https://github.com/openstack/trove/blob/master/etc/apache2/trove#L20\n[2]https://docs.openstack.org/developer/panko/install/manual.html#installing-the-api-server\n\nChange-Id: I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc\nCloses-Bug: #1691283\nDepends-On: I53b286d1d6466b574fdb286cc45f3138f96dff59\n'}]",0,471567,6b0084c85df7c94465e2d1e9cda42a52947feee4,22,6,4,9414,,,0,"Fix the port for Panko API

The port used for Panko is conflicts with Trove[1]. According to the
official documentation[2] this should be 8777. The 8777 port has been
occupied by ceilometer. So set the panko api port to 8977.

[1]https://github.com/openstack/trove/blob/master/etc/apache2/trove#L20
[2]https://docs.openstack.org/developer/panko/install/manual.html#installing-the-api-server

Change-Id: I5ccfc97765fc8b8bf9686b2451eda9c44c77dffc
Closes-Bug: #1691283
Depends-On: I53b286d1d6466b574fdb286cc45f3138f96dff59
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/67/471567/4 && git format-patch -1 --stdout FETCH_HEAD,['manifests/haproxy.pp'],1,9b0b6210df434ef55412052f34da5e0598f6fa8a,bug/1691283,"# 'panko_api_port' (Defaults to 8777) panko_api_port => 8777,","# 'panko_api_port' (Defaults to 8779) panko_api_port => 8779,",2,2
openstack%2Fopenstack-ansible-os_cinder~master~I5126b059092b1dfad5df1c7f37d84e01fd276c81,openstack/openstack-ansible-os_cinder,master,I5126b059092b1dfad5df1c7f37d84e01fd276c81,Add which in CentOS package list,MERGED,2017-01-11 19:01:22.000000000,2017-06-19 18:29:24.000000000,2017-01-12 00:50:36.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-01-11 19:01:22.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/890f84d31d8059188b749410d5fbeef46c26a728', 'message': 'Add which in CentOS package list\n\nwhich is needed by virtualenv-tools.\n\nChange-Id: I5126b059092b1dfad5df1c7f37d84e01fd276c81\n'}]",0,419093,890f84d31d8059188b749410d5fbeef46c26a728,8,3,1,13095,,,0,"Add which in CentOS package list

which is needed by virtualenv-tools.

Change-Id: I5126b059092b1dfad5df1c7f37d84e01fd276c81
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/93/419093/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,890f84d31d8059188b749410d5fbeef46c26a728,add-CentOS-missing-package, - which,,1,0
openstack%2Fopenstack-ansible~stable%2Focata~I3dce66a5fa94d8a1a27280244622ca68036e6ad1,openstack/openstack-ansible,stable/ocata,I3dce66a5fa94d8a1a27280244622ca68036e6ad1,Set PrivateDevices=false for Galera,MERGED,2017-06-14 18:46:57.000000000,2017-06-19 18:27:52.000000000,2017-06-19 18:27:52.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 13095}]","[{'number': 1, 'created': '2017-06-14 18:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7285f4a456d464f9d0cd62b06aec0928ae86d75d', 'message': ""Set PrivateDevices=false for Galera\n\nThis patch sets the `galera_disable_privatedevices` variable in the\ngalera_server role. If galera is deployed with a container, the\nPrivateDevices configuration will be disabled in MariaDB's systemd\nunit file.\n\nRelated-Bug: 1697531\nChange-Id: I3dce66a5fa94d8a1a27280244622ca68036e6ad1\n""}, {'number': 2, 'created': '2017-06-17 04:19:41.000000000', 'files': ['releasenotes/notes/centos-galera-privatedevices-4958f0be6cffa466.yaml', 'ansible-role-requirements.yml', 'playbooks/inventory/group_vars/galera_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/500c25d530142dde273813e88059e1a9d449c31a', 'message': ""Set PrivateDevices=false for Galera\n\nThis patch sets the `galera_disable_privatedevices` variable in the\ngalera_server role. If galera is deployed with a container, the\nPrivateDevices configuration will be disabled in MariaDB's systemd\nunit file.\n\nRelated-Bug: 1697531\nChange-Id: I3dce66a5fa94d8a1a27280244622ca68036e6ad1\n(cherry picked from commit d10f52bb186b5476e2be8f3b3be7c226a7841c4d)\n""}]",0,474314,500c25d530142dde273813e88059e1a9d449c31a,14,3,2,538,,,0,"Set PrivateDevices=false for Galera

This patch sets the `galera_disable_privatedevices` variable in the
galera_server role. If galera is deployed with a container, the
PrivateDevices configuration will be disabled in MariaDB's systemd
unit file.

Related-Bug: 1697531
Change-Id: I3dce66a5fa94d8a1a27280244622ca68036e6ad1
(cherry picked from commit d10f52bb186b5476e2be8f3b3be7c226a7841c4d)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/14/474314/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/group_vars/galera_all.yml'],1,7285f4a456d464f9d0cd62b06aec0928ae86d75d,bug/1697531," # Disable PrivateDevices for MariaDB on CentOS 7 # See https://bugs.launchpad.net/openstack-ansible/+bug/1697531 for details. galera_disable_privatedevices: ""{{ (properties.is_metal|default(false)) | ternary(false, true) }}""",,4,0
openstack%2Ftripleo-common~master~I1263239bae7dede96191f80ae7932461ce6ea69b,openstack/tripleo-common,master,I1263239bae7dede96191f80ae7932461ce6ea69b,Enable key rotation action and add release note,MERGED,2017-06-15 13:09:20.000000000,2017-06-19 18:17:54.000000000,2017-06-19 18:17:54.000000000,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 9712}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-06-15 13:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4cf6ce9ab10eb26802db2fd6f5020af9efa774dd', 'message': 'Enable key rotation action and add release note\n\nbp keystone-fernet-rotation\nChange-Id: I1263239bae7dede96191f80ae7932461ce6ea69b\n'}, {'number': 2, 'created': '2017-06-19 11:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/187df02052c72a90a249ed02af68b05a0a9dda94', 'message': 'Enable key rotation action and add release note\n\nbp keystone-fernet-rotation\nChange-Id: I1263239bae7dede96191f80ae7932461ce6ea69b\n'}, {'number': 3, 'created': '2017-06-19 12:11:18.000000000', 'files': ['releasenotes/notes/Add-rotate-fernet-keys-action-a1080bf5fb18413f.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6e23d7f8fa70e55600f8bdc392c784a523fca76d', 'message': 'Enable key rotation action and add release note\n\nbp keystone-fernet-rotation\nChange-Id: I1263239bae7dede96191f80ae7932461ce6ea69b\n'}]",2,474574,6e23d7f8fa70e55600f8bdc392c784a523fca76d,17,4,3,10873,,,0,"Enable key rotation action and add release note

bp keystone-fernet-rotation
Change-Id: I1263239bae7dede96191f80ae7932461ce6ea69b
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/74/474574/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/Add-rotate-fernet-keys-action-a1080bf5fb18413f.yaml', 'setup.cfg']",2,4cf6ce9ab10eb26802db2fd6f5020af9efa774dd,bp/keystone-fernet-rotation, tripleo.parameters.rotate_fernet_keys = tripleo_common.actions.parameters:RotateFernetKeysAction,,10,0
openstack%2Fopenstack-ansible-os_keystone~master~I8f16495607abb871390d28c0b3e9b2b856dda097,openstack/openstack-ansible-os_keystone,master,I8f16495607abb871390d28c0b3e9b2b856dda097,Fix rolling upgrade test,MERGED,2017-06-16 17:37:57.000000000,2017-06-19 18:16:03.000000000,2017-06-19 18:16:03.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-16 17:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/803f6af3cecb38f3111648b2a047ea61f4d62bcb', 'message': ""Fix rolling upgrade test\n\nThe rolling upgrade test is currently not setting\nthe endpoint correctly due to 'keystone_upgrade'\nnot being defined.\n\nThis patch removes the requirement to define the\nvar by ensuring that the role always uses haproxy.\nThis prevents having to remember to set the var\nwhen doing development and makes better sense for\ntest purposes anyway.\n\nThis patch also serialises the upgrade and ensures\nthat the backend is set into maintenance mode when\nthe upgrade is actioned.\n\nChange-Id: I8f16495607abb871390d28c0b3e9b2b856dda097\nDepends-On: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n""}, {'number': 2, 'created': '2017-06-17 11:44:21.000000000', 'files': ['tests/inventory', 'tests/test-upgrade-pre.yml', 'tests/test-install-haproxy.yml', 'tests/os_keystone-overrides.yml', 'tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/ed136ef79cc2b3870ceb320b4c3fa4bde8f9c56d', 'message': ""Fix rolling upgrade test\n\nThe rolling upgrade test is currently not setting\nthe endpoint correctly due to 'keystone_upgrade'\nnot being defined.\n\nThis patch removes the requirement to define the\nvar by ensuring that the role always uses haproxy.\nThis prevents having to remember to set the var\nwhen doing development and makes better sense for\ntest purposes anyway.\n\nThis patch also serialises the upgrade and ensures\nthat the backend is set into maintenance mode when\nthe upgrade is actioned.\n\nChange-Id: I8f16495607abb871390d28c0b3e9b2b856dda097\nDepends-On: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n""}]",0,475040,ed136ef79cc2b3870ceb320b4c3fa4bde8f9c56d,18,4,2,6816,,,0,"Fix rolling upgrade test

The rolling upgrade test is currently not setting
the endpoint correctly due to 'keystone_upgrade'
not being defined.

This patch removes the requirement to define the
var by ensuring that the role always uses haproxy.
This prevents having to remember to set the var
when doing development and makes better sense for
test purposes anyway.

This patch also serialises the upgrade and ensures
that the backend is set into maintenance mode when
the upgrade is actioned.

Change-Id: I8f16495607abb871390d28c0b3e9b2b856dda097
Depends-On: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/40/475040/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/inventory', 'tests/test-install-haproxy.yml', 'tests/test-upgrade-pre.yml', 'tests/os_keystone-overrides.yml', 'tests/test.yml']",5,803f6af3cecb38f3111648b2a047ea61f4d62bcb,rolling-upgrades,# Install haproxy - include: common/test-install-haproxy.yml ,,9,26
openstack%2Fopenstack-ansible-os_cinder~stable%2Focata~Idbfb706e88a406a546ae242b10d2a7ada65d1de9,openstack/openstack-ansible-os_cinder,stable/ocata,Idbfb706e88a406a546ae242b10d2a7ada65d1de9,Added open-iscsi package to Cinder container.,MERGED,2017-04-28 19:41:58.000000000,2017-06-19 17:43:44.000000000,2017-06-19 17:43:44.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-04-28 19:41:58.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/4fb0bb48877f579b0d28e6ea18896f949df738e7', 'message': 'Added open-iscsi package to Cinder container.\n\nAllows to properly consume external ISCSI backends.\nThe absense affects the ability to upload the volume from external\nISCSI backend to Glance.\n\nChange-Id: Idbfb706e88a406a546ae242b10d2a7ada65d1de9\n(cherry picked from commit 278cfa177388c91a27da6c3371e5886bb591e535)\n'}]",0,461133,4fb0bb48877f579b0d28e6ea18896f949df738e7,13,3,1,7307,,,0,"Added open-iscsi package to Cinder container.

Allows to properly consume external ISCSI backends.
The absense affects the ability to upload the volume from external
ISCSI backend to Glance.

Change-Id: Idbfb706e88a406a546ae242b10d2a7ada65d1de9
(cherry picked from commit 278cfa177388c91a27da6c3371e5886bb591e535)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/33/461133/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml']",2,4fb0bb48877f579b0d28e6ea18896f949df738e7,iscsi_backend, - open-iscsi,,2,0
openstack%2Fopenstack-ansible-lxc_container_create~stable%2Focata~I79658a261613357b610f481187868a1eed56b5a3,openstack/openstack-ansible-lxc_container_create,stable/ocata,I79658a261613357b610f481187868a1eed56b5a3,Use connection plugin instead of delegating,MERGED,2017-06-19 15:37:28.000000000,2017-06-19 17:41:41.000000000,2017-06-19 17:41:41.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-19 15:37:28.000000000', 'files': ['tasks/container_create.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/05ed7dfa57b7ead13f63edb72918241e8ef1916e', 'message': ""Use connection plugin instead of delegating\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of delegating\nto containers' physical host and writing files to containers through\n/proc, make use of the OSA ssh connection plugin.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n(cherry picked from commit 8ded80fdc960ce9dfd5b56b51afe79743a449930)\n""}]",0,475438,05ed7dfa57b7ead13f63edb72918241e8ef1916e,7,3,1,14805,,,0,"Use connection plugin instead of delegating

As of 2.2.3.0, Ansible now expands and follows the real paths of the
symlinks. Attempting the expand the symlink of /root within a
container's /proc directory becomes unreachable. Instead of delegating
to containers' physical host and writing files to containers through
/proc, make use of the OSA ssh connection plugin.

Closes-Bug: 1696802
Change-Id: I79658a261613357b610f481187868a1eed56b5a3
(cherry picked from commit 8ded80fdc960ce9dfd5b56b51afe79743a449930)
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/38/475438/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/container_create.yml'],1,05ed7dfa57b7ead13f63edb72918241e8ef1916e,bug/1696802," dest: ""{{ lxc_container_interface_target }}"" dest: ""{{ lxc_container_default_route_interfaces }}"" dest: ""/opt/container-setup.sh"" command: /opt/container-setup.sh","- name: Get LXC container PID command: > lxc-info -pHn {{ inventory_hostname }} register: container_pid changed_when: false delegate_to: ""{{ physical_host }}"" tags: - lxc_container_create-setup dest: ""/proc/{{ container_pid.stdout }}/root{{ lxc_container_interface_target }}"" delegate_to: ""{{ physical_host }}"" dest: ""/proc/{{ container_pid.stdout }}/root{{ lxc_container_default_route_interfaces }}"" delegate_to: ""{{ physical_host }}"" dest: ""/proc/{{ container_pid.stdout }}/root/opt/container-setup.sh"" delegate_to: ""{{ physical_host }}"" command: | lxc-attach --name ""{{ inventory_hostname }}"" \ --logfile {{ lxc_container_log_path }}/lxc-{{ inventory_hostname }}.log \ --logpriority {{ (debug | bool) | ternary('DEBUG', 'INFO') }} \ -- /opt/container-setup.sh delegate_to: ""{{ physical_host }}""",4,21
openstack%2Fnova~master~I44bf3fbfc60225dcdb9d3d9c018f66cf49f8cbdc,openstack/nova,master,I44bf3fbfc60225dcdb9d3d9c018f66cf49f8cbdc,api-ref: fix unshelve asynchronous postconditions typo,MERGED,2017-06-19 13:25:45.000000000,2017-06-19 17:41:14.000000000,2017-06-19 17:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 15334}]","[{'number': 1, 'created': '2017-06-19 13:25:45.000000000', 'files': ['api-ref/source/servers-action-shelve.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/f178d0d4b8588075d30ed376ce51aa8d4d3894c4', 'message': 'api-ref: fix unshelve asynchronous postconditions typo\n\nThis section is talking about unshelve, so the asynchronous\npostconditions section should be talking about unshelve.\n\nChange-Id: I44bf3fbfc60225dcdb9d3d9c018f66cf49f8cbdc\n'}]",0,475386,f178d0d4b8588075d30ed376ce51aa8d4d3894c4,14,3,1,6873,,,0,"api-ref: fix unshelve asynchronous postconditions typo

This section is talking about unshelve, so the asynchronous
postconditions section should be talking about unshelve.

Change-Id: I44bf3fbfc60225dcdb9d3d9c018f66cf49f8cbdc
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/475386/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/servers-action-shelve.inc'],1,f178d0d4b8588075d30ed376ce51aa8d4d3894c4,unshelve-api-ref,"After you successfully unshelve a server, its status changes to ``ACTIVE``. The server appears on the compute node.","After you successfully shelve a server, its status changes to ``ACTIVE``. The server appears on the compute node.",2,1
openstack%2Fnova~master~I90fb7beb450100de8f4e542921b99f043c529a0f,openstack/nova,master,I90fb7beb450100de8f4e542921b99f043c529a0f,Add separate instance.create payload type,MERGED,2017-05-05 17:13:47.000000000,2017-06-19 17:40:38.000000000,2017-06-19 17:40:38.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-05-05 17:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e99bb9c85ae8a95cd2426e94de04e544b99148f', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 2, 'created': '2017-05-05 17:50:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1562f06960e617d87a9398577dece6506b51f237', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 3, 'created': '2017-05-08 14:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de57e991f5ce0d642857f30914114ab569f2e271', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 4, 'created': '2017-06-08 09:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7a2115282a43ab13a03ddc0d3e9a9491457b524', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe keypair and tags field are not added directly to the base InstancePayload\nclass because both field need extra db query to fetch. So sending them at\nevery instance action (e.g. reboot) could cause db load.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 5, 'created': '2017-06-12 16:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e38000cfe6875ab13da4bdd2682c018690f4bf8', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe keypair and tags field are not added directly to the base InstancePayload\nclass because both field need extra db query to fetch. So sending them at\nevery instance action (e.g. reboot) could cause db load.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 6, 'created': '2017-06-14 08:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64a72f9b27cf4e453aeb50750d53d12203d660e3', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe keypair and tags field are not added directly to the base InstancePayload\nclass because both field need extra db query to fetch. So sending them at\nevery instance action (e.g. reboot) could cause db load.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 7, 'created': '2017-06-14 08:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5893ba27a6043271ba26f147548a7656a0106256', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe keypair and tags field are not added directly to the base InstancePayload\nclass because both field need extra db query to fetch. So sending them at\nevery instance action (e.g. reboot) could cause db load.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}, {'number': 8, 'created': '2017-06-16 14:30:34.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'doc/notification_samples/instance-create-start.json', 'doc/notification_samples/instance-create-error.json', 'doc/notification_samples/instance-create-end.json', 'nova/notifications/objects/instance.py', 'nova/tests/unit/notifications/objects/test_notification.py', 'nova/compute/manager.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3b72d6058956b238d176d6473c2c538fd60526d5', 'message': 'Add separate instance.create payload type\n\nThere are two parallel efforts to add new fields to the instance.create\nnotification only. Currently instance.create notification uses the generic\nInstanceActionPayload ovo as the payload type. This patch creates a separate\nInstanceCreatePayload ovo so that fields like keypairs and tags can be added\nonly to this specific payload class later in separate patches.\n\nThe keypair and tags field are not added directly to the base InstancePayload\nclass because both field need extra db query to fetch. So sending them at\nevery instance action (e.g. reboot) could cause db load.\n\nThe version of the instance.create payload is not bumped as the content\nof the payload is the same just the name of the type is changed.\n\nChange-Id: I90fb7beb450100de8f4e542921b99f043c529a0f\n'}]",22,463001,3b72d6058956b238d176d6473c2c538fd60526d5,116,17,8,9708,,,0,"Add separate instance.create payload type

There are two parallel efforts to add new fields to the instance.create
notification only. Currently instance.create notification uses the generic
InstanceActionPayload ovo as the payload type. This patch creates a separate
InstanceCreatePayload ovo so that fields like keypairs and tags can be added
only to this specific payload class later in separate patches.

The keypair and tags field are not added directly to the base InstancePayload
class because both field need extra db query to fetch. So sending them at
every instance action (e.g. reboot) could cause db load.

The version of the instance.create payload is not bumped as the content
of the payload is the same just the name of the type is changed.

Change-Id: I90fb7beb450100de8f4e542921b99f043c529a0f
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/463001/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/notification_samples/instance-create-start.json', 'doc/notification_samples/instance-create-error.json', 'doc/notification_samples/instance-create-end.json', 'nova/notifications/objects/instance.py', 'nova/tests/unit/notifications/objects/test_notification.py', 'nova/compute/manager.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/compute/utils.py']",8,3e99bb9c85ae8a95cd2426e94de04e544b99148f,bp/additional-notification-fields-for-searchlight,"def notify_about_instance_create(context, instance, host, phase=None, binary='nova-compute', exception=None): """"""Send versioned notification about instance creation :param instance: the instance which the action performed on :param host: the host emitting the notification :param phase: the phase of the creation :param binary: the binary emitting the notification :param exception: the thrown exception (used in error notifications) """""" fault, priority = _get_fault_and_priority_from_exc(exception) payload = instance_notification.InstanceCreatePayload( instance=instance, fault=fault) notification = instance_notification.InstanceCreateNotification( context=context, priority=priority, publisher=notification_base.NotificationPublisher( context=context, host=host, binary=binary), event_type=notification_base.EventType( object='instance', action=fields.NotificationAction.CREATE, phase=phase), payload=payload) notification.emit(context) ",,109,27
openstack%2Fnova~master~I33350a6fb6ee3d2657e3bf549f51bf4fe78e8a04,openstack/nova,master,I33350a6fb6ee3d2657e3bf549f51bf4fe78e8a04,Fix a wrong comment,MERGED,2017-06-15 01:20:12.000000000,2017-06-19 17:34:10.000000000,2017-06-19 17:34:10.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10118}, {'_account_id': 15334}, {'_account_id': 19741}]","[{'number': 1, 'created': '2017-06-15 01:20:12.000000000', 'files': ['nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4270353a8a5ce19e5f5165be06fc07189c48d095', 'message': 'Fix a wrong comment\n\nTrivialFix\nChange-Id: I33350a6fb6ee3d2657e3bf549f51bf4fe78e8a04\n'}]",0,474400,4270353a8a5ce19e5f5165be06fc07189c48d095,25,6,1,7634,,,0,"Fix a wrong comment

TrivialFix
Change-Id: I33350a6fb6ee3d2657e3bf549f51bf4fe78e8a04
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/474400/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,4270353a8a5ce19e5f5165be06fc07189c48d095,fix_comment," # compute per service but doesn't support live migrations,"," # compute per service but doesn't support evacuations,",1,1
openstack%2Fopenstack-ansible-tests~master~I5cbb3824430dc09b36476f81e0cdfd4f0a15f497,openstack/openstack-ansible-tests,master,I5cbb3824430dc09b36476f81e0cdfd4f0a15f497,Add haproxy install playbook,MERGED,2017-06-07 14:43:27.000000000,2017-06-19 17:28:01.000000000,2017-06-19 17:28:01.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-07 14:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/b9f5cca6d1a1cc693c582ccc5ef5c67ea47e7dd7', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}, {'number': 2, 'created': '2017-06-08 09:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/a0b542db7ecae2b1810aa4eecdb12cdd20917041', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}, {'number': 3, 'created': '2017-06-13 11:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/43d1396065c92951516918f95d2ba5b46c8b98d7', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}, {'number': 4, 'created': '2017-06-16 17:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/ea972fe641a787915aa7069b3f456e24acfb81a4', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nThe common task to manage the backend when doing\nrolling upgrades is included.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}, {'number': 5, 'created': '2017-06-16 17:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/eb99dfadddf7dfab80633c4a0e4c94731afd5bb3', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nThe common task to manage the backend when doing\nrolling upgrades is included.\n\nThe keystone install playbook makes use of them both\nin order to facilitate the rolling upgrades.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}, {'number': 6, 'created': '2017-06-16 18:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/337f0268ed6dc81e7ed096de450319638c8bbb80', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nThe common task to manage the backend when doing\nrolling upgrades is included.\n\nThe keystone install playbook makes use of them both\nin order to facilitate the rolling upgrades.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}, {'number': 7, 'created': '2017-06-19 11:12:22.000000000', 'files': ['common-tasks/haproxy-endpoint-manage.yml', 'test-install-haproxy.yml', 'test-vars.yml', 'test-install-keystone.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/0a500c1abe3a8f878764af44d06813d22c8698d0', 'message': 'Add haproxy install playbook\n\nIn order to effectively test rolling upgrades, haproxy\nwill need to be installed to facilitate the services\nbeing online while the upgrades are happening.\n\nThe common task to manage the backend when doing\nrolling upgrades is included.\n\nThe keystone install playbook makes use of them both\nin order to facilitate the rolling upgrades.\n\nChange-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497\n'}]",0,471805,0a500c1abe3a8f878764af44d06813d22c8698d0,48,5,7,6816,,,0,"Add haproxy install playbook

In order to effectively test rolling upgrades, haproxy
will need to be installed to facilitate the services
being online while the upgrades are happening.

The common task to manage the backend when doing
rolling upgrades is included.

The keystone install playbook makes use of them both
in order to facilitate the rolling upgrades.

Change-Id: I5cbb3824430dc09b36476f81e0cdfd4f0a15f497
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/05/471805/5 && git format-patch -1 --stdout FETCH_HEAD,['test-install-haproxy.yml'],1,b9f5cca6d1a1cc693c582ccc5ef5c67ea47e7dd7,rolling-upgrades,"--- # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Install haproxy hosts: localhost become: true roles: - role: ""haproxy_server"" haproxy_service_configs: ""{{ haproxy_default_services | default([]) }}"" ",,21,0
openstack%2Ftraining-labs~master~I00a8b90d26a6baefe0547a5e692a6a7dcf7b4d87,openstack/training-labs,master,I00a8b90d26a6baefe0547a5e692a6a7dcf7b4d87,Refactor RAM allocation for building basedisk,MERGED,2017-06-18 14:05:49.000000000,2017-06-19 17:25:10.000000000,2017-06-19 17:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 11109}]","[{'number': 1, 'created': '2017-06-18 14:05:49.000000000', 'files': ['labs/stacktrain/kvm/install_base.py', 'labs/osbash/lib/osbash/virtualbox-install_base.sh', 'labs/osbash/lib/osbash/kvm-install_base.sh', 'labs/osbash/lib/osbash/lib.centos-7-x86_64.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/b6029679007465cee0b4995b468e40601772ffde', 'message': 'Refactor RAM allocation for building basedisk\n\nAll methods now get the size of the basedisk from the regular\nVM configuration file, config/config.base.\n\nThere is no need to special case CentOS anymore, all distros get 1024 MB\n(should any distro need more some time in the future, we will increase\nthe RAM allocation for all distros).\n\nChange-Id: I00a8b90d26a6baefe0547a5e692a6a7dcf7b4d87\n'}]",0,475175,b6029679007465cee0b4995b468e40601772ffde,8,2,1,11109,,,0,"Refactor RAM allocation for building basedisk

All methods now get the size of the basedisk from the regular
VM configuration file, config/config.base.

There is no need to special case CentOS anymore, all distros get 1024 MB
(should any distro need more some time in the future, we will increase
the RAM allocation for all distros).

Change-Id: I00a8b90d26a6baefe0547a5e692a6a7dcf7b4d87
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/75/475175/1 && git format-patch -1 --stdout FETCH_HEAD,"['labs/stacktrain/kvm/install_base.py', 'labs/osbash/lib/osbash/virtualbox-install_base.sh', 'labs/osbash/lib/osbash/kvm-install_base.sh', 'labs/osbash/lib/osbash/lib.centos-7-x86_64.sh']",4,b6029679007465cee0b4995b468e40601772ffde,refactor_base_mem,,# Give CentOS 7 installer sufficient RAM VM_BASE_MEM=1024 ,10,8
openstack%2Fzun~master~Ib7b2c6756ba4c3933b0911c1b7d81c03a1b3d1b3,openstack/zun,master,Ib7b2c6756ba4c3933b0911c1b7d81c03a1b3d1b3,Run tempest tests in parallel,MERGED,2017-05-22 00:27:40.000000000,2017-06-19 17:20:55.000000000,2017-06-19 17:20:55.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 16277}]","[{'number': 1, 'created': '2017-05-22 00:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/eac12433aed64111002426c4b41ab5680e6be2ad', 'message': '[WIP] Run tempest tests in parallel\n\nChange-Id: Ib7b2c6756ba4c3933b0911c1b7d81c03a1b3d1b3\n'}, {'number': 2, 'created': '2017-05-23 00:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/ef5e9826d5b7761ded54112177758dc7909def22', 'message': 'Run tempest tests in parallel\n\nChange-Id: Ib7b2c6756ba4c3933b0911c1b7d81c03a1b3d1b3\n'}, {'number': 3, 'created': '2017-06-17 14:53:29.000000000', 'files': ['zun/tests/contrib/post_test_hook.sh', 'doc/source/dev/tempest_tests.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/eb91f4c596346676566ca562d8803130dbbe394a', 'message': 'Run tempest tests in parallel\n\nChange-Id: Ib7b2c6756ba4c3933b0911c1b7d81c03a1b3d1b3\n'}]",0,466558,eb91f4c596346676566ca562d8803130dbbe394a,15,4,3,11536,,,0,"Run tempest tests in parallel

Change-Id: Ib7b2c6756ba4c3933b0911c1b7d81c03a1b3d1b3
",git fetch https://review.opendev.org/openstack/zun refs/changes/58/466558/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/contrib/post_test_hook.sh', 'doc/source/dev/tempest_tests.rst']",2,eac12433aed64111002426c4b41ab5680e6be2ad,, tox -eall-plugin -- zun.tests.tempest.api, tox -eall-plugin -- zun.tests.tempest.api --concurrency=1,2,2
openstack%2Fmonasca-common~master~I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46,openstack/monasca-common,master,I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46,"Add a query language for group, inhibit, and silence rules",MERGED,2017-06-05 21:14:39.000000000,2017-06-19 17:19:03.000000000,2017-06-19 17:19:03.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 7052}, {'_account_id': 11809}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 16168}, {'_account_id': 18179}, {'_account_id': 20033}, {'_account_id': 22157}]","[{'number': 1, 'created': '2017-06-05 21:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/90e74c88a3e3b7134fc1eb6caef5e1ee460ca172', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 2, 'created': '2017-06-05 21:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/60cd4fa93b54cae47011cd5dcee67ca483da0454', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 3, 'created': '2017-06-06 20:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/ac310a60c9daa057702d46a4355b29a5c1aca96a', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 4, 'created': '2017-06-06 20:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/a1eff3743792ebd2ccf76a93cc4fdd632520d9cd', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 5, 'created': '2017-06-06 20:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/cbd755a324380208136b6b544bcc304c975d83ba', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 6, 'created': '2017-06-06 21:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/6bb7a4e3bca7ec7716728be5b19a31c966db64ed', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 7, 'created': '2017-06-12 18:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/eda77cc1c4c400743e01e2f564e52c4bc80ae7da', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 8, 'created': '2017-06-12 18:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/fe9584f7bdecff84d66346628b18094bc2583adc', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 9, 'created': '2017-06-13 17:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/ef7b923309ab6807e350100e8d2ba5eb8a952d7b', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 10, 'created': '2017-06-13 21:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/9f21a7c6aeef7b18ed1b01ac04968eab4626b77c', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 11, 'created': '2017-06-14 16:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/89d20cd5ffb6c1167c771d9823a12525246cd09c', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 12, 'created': '2017-06-14 17:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/17b2eca1492739558aed4e3cf2443bfef9575c97', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 13, 'created': '2017-06-15 17:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/7bf8ea42ffcd93310d0fb07fea45937f21443cc4', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}, {'number': 14, 'created': '2017-06-16 22:42:28.000000000', 'files': ['monasca_common/tests/test_monasca_query_language.py', 'requirements.txt', 'monasca_common/monasca_query_language/exceptions.py', 'monasca_common/monasca_query_language/query_structures.py', 'monasca_common/monasca_query_language/__init__.py', 'monasca_common/monasca_query_language/aql_parser.py'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/41800dd195efaf99119b44a6681ec36ea7bcde38', 'message': 'Add a query language for group, inhibit, and silence rules\n\nThe new alarm rules will each have an expression in their\ndefinition which will need to be parsed by both the Monasca-\nAPI and the Monasca-Notification-Engine. Documentation for\nthis will be included in the API along with descriptions of the\nnew rules.\n\nStory: 2000939\nTask: 4692\n\nChange-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46\n'}]",24,471134,41800dd195efaf99119b44a6681ec36ea7bcde38,52,10,14,22157,,,0,"Add a query language for group, inhibit, and silence rules

The new alarm rules will each have an expression in their
definition which will need to be parsed by both the Monasca-
API and the Monasca-Notification-Engine. Documentation for
this will be included in the API along with descriptions of the
new rules.

Story: 2000939
Task: 4692

Change-Id: I1a98fafae8dfdfa6fdb2eb66f4a4a4f40e518e46
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/34/471134/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_common/monasca_query_language/__init__.py', 'monasca_common/monasca_query_language/query_structures.py', 'monasca_common/monasca_query_language/aql_parser.py']",3,90e74c88a3e3b7134fc1eb6caef5e1ee460ca172,add_query_language_for_rules,"import datetime import sys import time import pyparsing from monasca_common.monasca_query_language.query_structures import (Dimension, MetricSelector, LogicalExpression, SourceExpression, TargetsExpression, ExcludesExpression, GroupByExpression, Rule) COMMA = pyparsing.Suppress(pyparsing.Literal("","")) LPAREN = pyparsing.Suppress(pyparsing.Literal(""("")) RPAREN = pyparsing.Suppress(pyparsing.Literal("")"")) LBRACE = pyparsing.Suppress(pyparsing.Literal(""{"")) RBRACE = pyparsing.Suppress(pyparsing.Literal(""}"")) LBRACKET = pyparsing.Suppress(pyparsing.Literal(""["")) RBRACKET = pyparsing.Suppress(pyparsing.Literal(""]"")) MINUS = pyparsing.Literal(""-"") integer_number = pyparsing.Word(pyparsing.nums) decimal_number = (pyparsing.Optional(MINUS) + integer_number + pyparsing.Optional(""."" + integer_number)) decimal_number.setParseAction(lambda tokens: float("""".join(tokens))) # Initialize non-ascii unicode code points in the Basic Multilingual Plane. unicode_printables = u''.join( unichr(c) for c in range(128, 65536) if not unichr(c).isspace()) # Does not like comma. No Literals from above allowed. valid_identifier_chars = ( (unicode_printables + pyparsing.alphanums + "".-_#$%&'*+/:;?@[\\]^`|"")) metric_name = ( pyparsing.Word(pyparsing.alphas, valid_identifier_chars, min=1, max=255)(""metric_name"")) dimension_name = pyparsing.Word(valid_identifier_chars + ' ', min=1, max=255) dimension_value = pyparsing.Word(valid_identifier_chars + ' ', min=1, max=255) dim_comparison_op = pyparsing.oneOf(""="") dimension = dimension_name + dim_comparison_op + dimension_value dimension.setParseAction(Dimension) dimension_list = pyparsing.Group((LBRACE + pyparsing.Optional( pyparsing.delimitedList(dimension)) + RBRACE)) metric = (metric_name + pyparsing.Optional(dimension_list) | pyparsing.Optional(metric_name) + dimension_list) metric.addParseAction(MetricSelector) source = pyparsing.Keyword(""source"") source_expression = source + metric source_expression.addParseAction(SourceExpression) targets = pyparsing.Keyword(""targets"") targets_expression = targets + metric targets_expression.addParseAction(TargetsExpression) excludes = pyparsing.Keyword(""excluding"") excludes_expression = excludes + metric excludes_expression.addParseAction(ExcludesExpression) group_by = pyparsing.Keyword(""group by"") group_by_expr = group_by + pyparsing.delimitedList(dimension_name) group_by_expr.addParseAction(GroupByExpression) grammar = pyparsing.Optional(source_expression) + pyparsing.Optional(targets_expression) + pyparsing.Optional(excludes_expression) + pyparsing.Optional(group_by_expr) grammar.addParseAction(Rule) class RuleExpressionParser(object): def __init__(self, expr): self._expr = expr def parse(self): parse_result = grammar.parseString(self._expr, parseAll=True) return parse_result ",,267,0
openstack%2Fshade~master~I01a0afef5986b7452fd73e04c48568ebb9817681,openstack/shade,master,I01a0afef5986b7452fd73e04c48568ebb9817681,Remove novaclient from shade's dependencies,MERGED,2017-06-18 18:00:26.000000000,2017-06-19 17:09:10.000000000,2017-06-19 17:09:10.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['requirements.txt', 'shade/_utils.py', 'shade/tests/unit/test_rebuild_server.py', 'shade/tests/unit/test_update_server.py', 'releasenotes/notes/remove-novaclient-3f8d4db20d5f9582.yaml', 'shade/__init__.py', 'shade/_legacy_clients.py', 'extras/install-tips.sh', 'shade/tests/base.py', 'shade/tests/unit/test_create_server.py', 'shade/tests/unit/test_server_set_metadata.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/3aee4f5e6ea3ec4a49442c905a4bd43b1e7b13a9', 'message': ""Remove novaclient from shade's dependencies\n\nAll calls to nova are now done via REST. This means we can remove the\ndependency.\n\nOnly two more to go ...\n\nChange-Id: I01a0afef5986b7452fd73e04c48568ebb9817681\n""}]",0,475192,3aee4f5e6ea3ec4a49442c905a4bd43b1e7b13a9,6,2,1,2,,,0,"Remove novaclient from shade's dependencies

All calls to nova are now done via REST. This means we can remove the
dependency.

Only two more to go ...

Change-Id: I01a0afef5986b7452fd73e04c48568ebb9817681
",git fetch https://review.opendev.org/openstack/shade refs/changes/92/475192/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'shade/_utils.py', 'shade/tests/unit/test_rebuild_server.py', 'shade/tests/unit/test_update_server.py', 'releasenotes/notes/remove-novaclient-3f8d4db20d5f9582.yaml', 'shade/__init__.py', 'shade/_legacy_clients.py', 'extras/install-tips.sh', 'shade/tests/base.py', 'shade/tests/unit/test_create_server.py', 'shade/tests/unit/test_server_set_metadata.py']",11,3aee4f5e6ea3ec4a49442c905a4bd43b1e7b13a9,restification,," """""" Test that a generic exception in the novaclient delete_meta raises an exception in delete_server_metadata. """"""",12,30
openstack%2Fshade~master~I89e0e59ec1ed6a81843da61bd3fce49d57da7c17,openstack/shade,master,I89e0e59ec1ed6a81843da61bd3fce49d57da7c17,Translate final nova calls to REST,MERGED,2017-06-18 18:00:26.000000000,2017-06-19 17:09:04.000000000,2017-06-19 17:09:04.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['shade/operatorcloud.py', 'shade/_tasks.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/56524c16a82f0b75cb9e576eb74982d8b19fb105', 'message': 'Translate final nova calls to REST\n\nChange-Id: I89e0e59ec1ed6a81843da61bd3fce49d57da7c17\n'}]",0,475191,56524c16a82f0b75cb9e576eb74982d8b19fb105,6,2,1,2,,,0,"Translate final nova calls to REST

Change-Id: I89e0e59ec1ed6a81843da61bd3fce49d57da7c17
",git fetch https://review.opendev.org/openstack/shade refs/changes/91/475191/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/operatorcloud.py', 'shade/_tasks.py', 'shade/openstackcloud.py']",3,56524c16a82f0b75cb9e576eb74982d8b19fb105,restification," params = {} params['tenant_id'] = project_id limits = self._compute_client.get('/limits', params=params)"," kwargs = {} kwargs['tenant_id'] = project_id with _utils.shade_exceptions(error_msg): # TODO(mordred) Before we convert this to REST, we need to add # in support for running calls with a different project context limits = self.manager.submit_task(_tasks.NovaLimitsGet(**kwargs))",17,54
openstack%2Fshade~master~Iff4341f2c83493c901f5e18570f82b0b5f7f3ad5,openstack/shade,master,Iff4341f2c83493c901f5e18570f82b0b5f7f3ad5,Convert remaining nova tests to requests_mock,MERGED,2017-06-18 18:00:26.000000000,2017-06-19 17:08:51.000000000,2017-06-19 17:08:51.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['shade/tests/unit/test_usage.py', 'shade/tests/unit/test_quotas.py', 'shade/tests/unit/test_limits.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/56244f54103c076444a1e8793fa78b6753350961', 'message': 'Convert remaining nova tests to requests_mock\n\nChange-Id: Iff4341f2c83493c901f5e18570f82b0b5f7f3ad5\n'}]",0,475190,56244f54103c076444a1e8793fa78b6753350961,14,2,1,2,,,0,"Convert remaining nova tests to requests_mock

Change-Id: Iff4341f2c83493c901f5e18570f82b0b5f7f3ad5
",git fetch https://review.opendev.org/openstack/shade refs/changes/90/475190/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_usage.py', 'shade/tests/unit/test_quotas.py', 'shade/tests/unit/test_limits.py']",3,56244f54103c076444a1e8793fa78b6753350961,restification," def test_get_compute_limits(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['limits']), json={ ""limits"": { ""absolute"": { ""maxImageMeta"": 128, ""maxPersonality"": 5, ""maxPersonalitySize"": 10240, ""maxSecurityGroupRules"": 20, ""maxSecurityGroups"": 10, ""maxServerMeta"": 128, ""maxTotalCores"": 20, ""maxTotalFloatingIps"": 10, ""maxTotalInstances"": 10, ""maxTotalKeypairs"": 100, ""maxTotalRAMSize"": 51200, ""maxServerGroups"": 10, ""maxServerGroupMembers"": 10, ""totalCoresUsed"": 0, ""totalInstancesUsed"": 0, ""totalRAMUsed"": 0, ""totalSecurityGroupsUsed"": 0, ""totalFloatingIpsUsed"": 0, ""totalServerGroupsUsed"": 0 }, ""rate"": [] } }), ]) self.assert_calls() def test_other_get_compute_limits(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['limits'], qs_elements=[ 'tenant_id={id}'.format(id=project.project_id) ]), json={ ""limits"": { ""absolute"": { ""maxImageMeta"": 128, ""maxPersonality"": 5, ""maxPersonalitySize"": 10240, ""maxSecurityGroupRules"": 20, ""maxSecurityGroups"": 10, ""maxServerMeta"": 128, ""maxTotalCores"": 20, ""maxTotalFloatingIps"": 10, ""maxTotalInstances"": 10, ""maxTotalKeypairs"": 100, ""maxTotalRAMSize"": 51200, ""maxServerGroups"": 10, ""maxServerGroupMembers"": 10, ""totalCoresUsed"": 0, ""totalInstancesUsed"": 0, ""totalRAMUsed"": 0, ""totalSecurityGroupsUsed"": 0, ""totalFloatingIpsUsed"": 0, ""totalServerGroupsUsed"": 0 }, ""rate"": [] } }), ]) ","import mock import shade @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_get_compute_limits(self, mock_nova): mock_nova.limits.get.assert_called_once_with() @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_other_get_compute_limits(self, mock_nova): mock_nova.limits.get.assert_called_once_with( tenant_id=project.project_id)",176,46
openstack%2Fdiskimage-builder~master~Ia77a0ffe4c76854b326ed76490479d9c691b49aa,openstack/diskimage-builder,master,Ia77a0ffe4c76854b326ed76490479d9c691b49aa,Sync after writing partition table,MERGED,2017-06-19 00:37:10.000000000,2017-06-19 16:49:31.000000000,2017-06-19 16:49:31.000000000,"[{'_account_id': 3}, {'_account_id': 6133}]","[{'number': 1, 'created': '2017-06-19 00:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4f93564a7377030aecb227baecfb8d40f12eb5d7', 'message': 'Sync after writing partition table\n\nWe introduced the ""settle"" in\nI90103b59357edebbac7a641e8980cb282d37561b thinking that maybe kpartx\nhad not finished writing the partition.  This probably wasn\'t a bad\nfirst assumption, since we used to have this -- but is seems\ninsufficient.\n\nThe other failiure here seems to be if kpartx hasn\'t actually seen the\nupdated partition table in the image, so it has correctly (in it\'s\nmind) not mounted the partition.\n\nLooking at fdisk() run manually on a loopback, it will do a fsync on\nthe raw device after writing and then a global sync as it exits.\n\nThis replicates this; we flush and fsync in mbr.py in the exit handler\nafter writing the partition, before closing the file (i\'ve updated one\nof the unit tests to double-check the call).  In the partitioning.py\ncaller we execute a sync call too.\n\nSince it does seem unlikely the ""-s"" option of kpartx is not working,\nI\'ve removed the udev settle work-around too.\n\nChange-Id: Ia77a0ffe4c76854b326ed76490479d9c691b49aa\nPartial-Bug: #1698337\n'}, {'number': 2, 'created': '2017-06-19 07:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0acd4205a749389437af40ab49dcd29a212aa808', 'message': 'Sync after writing partition table\n\nWe introduced the ""settle"" in\nI90103b59357edebbac7a641e8980cb282d37561b thinking that maybe kpartx\nhad not finished writing the partition.  This probably wasn\'t a bad\nfirst assumption, since we used to have this -- but is seems\ninsufficient.\n\nThe other failiure here seems to be if kpartx hasn\'t actually seen the\nupdated partition table in the image, so it has correctly (in it\'s\nmind) not mounted the partition.\n\nLooking at fdisk() run manually on a loopback, it will do a fsync on\nthe raw device after writing and then a global sync as it exits.\n\nThis replicates this; we flush and fsync in mbr.py in the exit handler\nafter writing the partition, before closing the file (i\'ve updated one\nof the unit tests to double-check the call).  In the partitioning.py\ncaller we execute a sync call too.\n\nSince it does seem unlikely the ""-s"" option of kpartx is not working,\nI\'ve removed the udev settle work-around too.\n\nChange-Id: Ia77a0ffe4c76854b326ed76490479d9c691b49aa\nPartial-Bug: #1698337\n'}, {'number': 3, 'created': '2017-06-19 07:14:21.000000000', 'files': ['diskimage_builder/block_device/tests/test_mbr.py', 'diskimage_builder/block_device/level1/mbr.py', 'diskimage_builder/block_device/level1/partitioning.py'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/5d5fa06e5c53ca8dc857d1700b57c2336ac62db1', 'message': 'Sync after writing partition table\n\nWe introduced the ""settle"" in\nI90103b59357edebbac7a641e8980cb282d37561b thinking that maybe kpartx\nhad not finished writing the partition.  This probably wasn\'t a bad\nfirst assumption, since we used to have this -- but is seems\ninsufficient.\n\nThe other failiure here seems to be if kpartx hasn\'t actually seen the\nupdated partition table in the image, so it has correctly (in it\'s\nmind) not mounted the partition.\n\nLooking at strace of fdisk run manually on a loopback, it will do a\nfsync on the raw device after writing and then a global sync as it\nexits.\n\nThis replicates this; we flush and fsync in mbr.py in the exit handler\nafter writing the partition, before closing the file (i\'ve updated one\nof the unit tests to double-check the call).  In the partitioning.py\ncaller we execute a sync call too.\n\nSince it does seem unlikely the ""-s"" option of kpartx is not working,\nI\'ve removed the udev settle work-around too.\n\nChange-Id: Ia77a0ffe4c76854b326ed76490479d9c691b49aa\nPartial-Bug: #1698337\n'}]",0,475203,5d5fa06e5c53ca8dc857d1700b57c2336ac62db1,34,2,3,7118,,,0,"Sync after writing partition table

We introduced the ""settle"" in
I90103b59357edebbac7a641e8980cb282d37561b thinking that maybe kpartx
had not finished writing the partition.  This probably wasn't a bad
first assumption, since we used to have this -- but is seems
insufficient.

The other failiure here seems to be if kpartx hasn't actually seen the
updated partition table in the image, so it has correctly (in it's
mind) not mounted the partition.

Looking at strace of fdisk run manually on a loopback, it will do a
fsync on the raw device after writing and then a global sync as it
exits.

This replicates this; we flush and fsync in mbr.py in the exit handler
after writing the partition, before closing the file (i've updated one
of the unit tests to double-check the call).  In the partitioning.py
caller we execute a sync call too.

Since it does seem unlikely the ""-s"" option of kpartx is not working,
I've removed the udev settle work-around too.

Change-Id: Ia77a0ffe4c76854b326ed76490479d9c691b49aa
Partial-Bug: #1698337
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/03/475203/1 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage_builder/block_device/tests/test_mbr.py', 'diskimage_builder/block_device/level1/mbr.py', 'diskimage_builder/block_device/level1/partitioning.py']",3,4f93564a7377030aecb227baecfb8d40f12eb5d7,bug/1698337," # ""saftey sync"" to make sure the partitions are written exec_sudo([""sync""]) "," # We need to make sure udev finishes creating the device # before continuting, so ""udevadm settle"". Otherwise later # commands can fail with ""file does not exist"". # XXX: ""-s"" (synchronous) to kpartx should avoid this, # but experience shows it does not. exec_sudo([""udevadm"", ""settle""])",16,9
openstack%2Fcinder~master~I62d86ab4915ab2d7adf0b279db591b1e6e8e293c,openstack/cinder,master,I62d86ab4915ab2d7adf0b279db591b1e6e8e293c,Add several missing policy actions to cinder's policy.json,ABANDONED,2017-03-28 22:18:22.000000000,2017-06-19 16:38:36.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10622}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12778}, {'_account_id': 13628}, {'_account_id': 14384}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16212}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16643}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18883}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22510}, {'_account_id': 23185}, {'_account_id': 23186}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24815}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-03-28 22:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4a00079976fc997ddafe225c4a834bb28dd25815', 'message': 'Add several missing policy actions to cinder\'s policy.json\n\nCurrently, Cinder\'s policy.json does not exhaustively list\nall the policy actions within Cinder.\n\nFor example, volume:attach is enforced in code [0]\nbut is not contained in the policy.json [1].\n\nThe implementation for policy enforcement in [0] is:\n\n    @functools.wraps(func)\n    def wrapped(self, context, target_obj, *args, **kwargs):\n        check_policy(context, func.__name__, target_obj)\n        return func(self, context, target_obj, *args, **kwargs)\n    return wrapped\n\nThis means that each endpoint with @wrap_check_policy decorator\nabove it should be included in the policy.json but this is\nnot the case.\n\nCurrently, the following policy actions are missing:\n\n    ""volume:attach"": ""rule:admin_or_owner"",\n    ""volume:detach"": ""rule:admin_or_owner"",\n    ""volume:reserve_volume"": ""rule:admin_or_owner"",\n    ""volume:unreserve_volume"": ""rule:admin_or_owner"",\n    ""volume:begin_detaching"": ""rule:admin_or_owner"",\n    ""volume:roll_detaching"": ""rule:admin_or_owner"",\n    ""volume:initialize_connection"": ""rule:admin_or_owner"",\n    ""volume:terminate_connection"": ""rule:admin_or_owner"",\n    ""volume:accept_transfer"": ""rule:admin_or_owner"",\n    ""volume:get_volume_image_metadata"": ""rule:admin_or_owner"",\n    ""volume:copy_volume_to_image"": ""rule:admin_or_owner"",\n    ""volume:extend"": ""rule:admin_or_owner"",\n    ""volume:migrate_volume"": ""rule:admin_or_owner"",\n    ""volume:migrate_volume_completion"": ""rule:admin_or_owner"",\n    ""volume:attachment_create"": ""rule:admin_or_owner"",\n    ""volume:attachment_update"": ""rule:admin_or_owner"",\n    ""volume:attachment_delete"": ""rule:admin_or_owner"",\n\n[0] https://github.com/openstack/cinder/blob/master/cinder/volume/api.py\n[1] https://github.com/openstack/cinder/blob/master/etc/cinder/policy.json\n\nChange-Id: I62d86ab4915ab2d7adf0b279db591b1e6e8e293c\nCloses-Bug: #1676672\n'}, {'number': 2, 'created': '2017-04-24 20:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9e2f16cb8d02ddcbbe451d4660ef86ee0410a76a', 'message': 'Add several missing policy actions to cinder\'s policy.json\n\nCurrently, Cinder\'s policy.json does not exhaustively list\nall the policy actions within Cinder.\n\nFor example, volume:attach is enforced in code [0]\nbut is not contained in the policy.json [1].\n\nThe implementation for policy enforcement in [0] is:\n\n    @functools.wraps(func)\n    def wrapped(self, context, target_obj, *args, **kwargs):\n        check_policy(context, func.__name__, target_obj)\n        return func(self, context, target_obj, *args, **kwargs)\n    return wrapped\n\nThis means that each endpoint with @wrap_check_policy decorator\nabove it should be included in the policy.json but this is\nnot the case.\n\nCurrently, the following policy actions are missing:\n\n    ""volume:attach"": ""rule:admin_or_owner"",\n    ""volume:detach"": ""rule:admin_or_owner"",\n    ""volume:reserve_volume"": ""rule:admin_or_owner"",\n    ""volume:unreserve_volume"": ""rule:admin_or_owner"",\n    ""volume:begin_detaching"": ""rule:admin_or_owner"",\n    ""volume:roll_detaching"": ""rule:admin_or_owner"",\n    ""volume:initialize_connection"": ""rule:admin_or_owner"",\n    ""volume:terminate_connection"": ""rule:admin_or_owner"",\n    ""volume:accept_transfer"": ""rule:admin_or_owner"",\n    ""volume:get_volume_image_metadata"": ""rule:admin_or_owner"",\n    ""volume:copy_volume_to_image"": ""rule:admin_or_owner"",\n    ""volume:extend"": ""rule:admin_or_owner"",\n    ""volume:migrate_volume"": ""rule:admin_or_owner"",\n    ""volume:migrate_volume_completion"": ""rule:admin_or_owner"",\n    ""volume:attachment_create"": ""rule:admin_or_owner"",\n    ""volume:attachment_update"": ""rule:admin_or_owner"",\n    ""volume:attachment_delete"": ""rule:admin_or_owner"",\n\n[0] https://github.com/openstack/cinder/blob/master/cinder/volume/api.py\n[1] https://github.com/openstack/cinder/blob/master/etc/cinder/policy.json\n\nChange-Id: I62d86ab4915ab2d7adf0b279db591b1e6e8e293c\nCloses-Bug: #1676672\n'}, {'number': 3, 'created': '2017-04-28 03:35:27.000000000', 'files': ['etc/cinder/policy.json', 'cinder/tests/unit/policy.json'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8aae83e2b0d5f2d9a6201abc1c03a0c1f125efb1', 'message': 'Add several missing policy actions to cinder\'s policy.json\n\nCurrently, Cinder\'s policy.json does not exhaustively list\nall the policy actions within Cinder.\n\nFor example, volume:attach is enforced in code [0]\nbut is not contained in the policy.json [1].\n\nThe implementation for policy enforcement in [0] is:\n\n    @functools.wraps(func)\n    def wrapped(self, context, target_obj, *args, **kwargs):\n        check_policy(context, func.__name__, target_obj)\n        return func(self, context, target_obj, *args, **kwargs)\n    return wrapped\n\nThis means that each endpoint with @wrap_check_policy decorator\nabove it should be included in the policy.json but this is\nnot the case.\n\nCurrently, the following policy actions are missing:\n\n    ""volume:attach"": ""rule:admin_or_owner"",\n    ""volume:detach"": ""rule:admin_or_owner"",\n    ""volume:reserve_volume"": ""rule:admin_or_owner"",\n    ""volume:unreserve_volume"": ""rule:admin_or_owner"",\n    ""volume:begin_detaching"": ""rule:admin_or_owner"",\n    ""volume:roll_detaching"": ""rule:admin_or_owner"",\n    ""volume:initialize_connection"": ""rule:admin_or_owner"",\n    ""volume:terminate_connection"": ""rule:admin_or_owner"",\n    #""volume:accept_transfer"": ""rule:admin_or_owner"",\n    ""volume:get_volume_image_metadata"": ""rule:admin_or_owner"",\n    ""volume:copy_volume_to_image"": ""rule:admin_or_owner"",\n    #""volume:extend"": ""rule:admin_or_owner"",\n    ""volume:migrate_volume"": ""rule:admin_api"",\n    ""volume:migrate_volume_completion"": ""rule:admin_api"",\n    ""volume:attachment_create"": ""rule:admin_or_owner"",\n    ""volume:attachment_update"": ""rule:admin_or_owner"",\n    ""volume:attachment_delete"": ""rule:admin_or_owner"",\n\n[0] https://github.com/openstack/cinder/blob/master/cinder/volume/api.py\n[1] https://github.com/openstack/cinder/blob/master/etc/cinder/policy.json\n\nChange-Id: I62d86ab4915ab2d7adf0b279db591b1e6e8e293c\nCloses-Bug: #1676672\n'}]",23,451095,8aae83e2b0d5f2d9a6201abc1c03a0c1f125efb1,112,46,3,23186,,,0,"Add several missing policy actions to cinder's policy.json

Currently, Cinder's policy.json does not exhaustively list
all the policy actions within Cinder.

For example, volume:attach is enforced in code [0]
but is not contained in the policy.json [1].

The implementation for policy enforcement in [0] is:

    @functools.wraps(func)
    def wrapped(self, context, target_obj, *args, **kwargs):
        check_policy(context, func.__name__, target_obj)
        return func(self, context, target_obj, *args, **kwargs)
    return wrapped

This means that each endpoint with @wrap_check_policy decorator
above it should be included in the policy.json but this is
not the case.

Currently, the following policy actions are missing:

    ""volume:attach"": ""rule:admin_or_owner"",
    ""volume:detach"": ""rule:admin_or_owner"",
    ""volume:reserve_volume"": ""rule:admin_or_owner"",
    ""volume:unreserve_volume"": ""rule:admin_or_owner"",
    ""volume:begin_detaching"": ""rule:admin_or_owner"",
    ""volume:roll_detaching"": ""rule:admin_or_owner"",
    ""volume:initialize_connection"": ""rule:admin_or_owner"",
    ""volume:terminate_connection"": ""rule:admin_or_owner"",
    #""volume:accept_transfer"": ""rule:admin_or_owner"",
    ""volume:get_volume_image_metadata"": ""rule:admin_or_owner"",
    ""volume:copy_volume_to_image"": ""rule:admin_or_owner"",
    #""volume:extend"": ""rule:admin_or_owner"",
    ""volume:migrate_volume"": ""rule:admin_api"",
    ""volume:migrate_volume_completion"": ""rule:admin_api"",
    ""volume:attachment_create"": ""rule:admin_or_owner"",
    ""volume:attachment_update"": ""rule:admin_or_owner"",
    ""volume:attachment_delete"": ""rule:admin_or_owner"",

[0] https://github.com/openstack/cinder/blob/master/cinder/volume/api.py
[1] https://github.com/openstack/cinder/blob/master/etc/cinder/policy.json

Change-Id: I62d86ab4915ab2d7adf0b279db591b1e6e8e293c
Closes-Bug: #1676672
",git fetch https://review.opendev.org/openstack/cinder refs/changes/95/451095/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/policy.json', 'cinder/tests/unit/policy.json']",2,4a00079976fc997ddafe225c4a834bb28dd25815,bug/1676672," ""volume:attach"": """", ""volume:detach"": """", ""volume:reserve_volume"": """", ""volume:unreserve_volume"": """", ""volume:begin_detaching"": """", ""volume:roll_detaching"": """", ""volume:initialize_connection"": """", ""volume:terminate_connection"": """", ""volume:accept_transfer"": """", ""volume:get_volume_image_metadata"": """", ""volume:copy_volume_to_image"": """", ""volume:extend"": """", ""volume:migrate_volume"": """", ""volume:migrate_volume_completion"": """", ""volume:attachment_create"": """", ""volume:attachment_update"": """", ""volume:attachment_delete"": """",",,34,0
openstack%2Freleases~master~Ic74e2c1b5db83cf91cc16c7d859bf2478ba39409,openstack/releases,master,Ic74e2c1b5db83cf91cc16c7d859bf2478ba39409,pbr 3.1.0,MERGED,2017-06-19 11:43:20.000000000,2017-06-19 16:37:41.000000000,2017-06-19 16:37:41.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2017-06-19 11:43:20.000000000', 'files': ['deliverables/_independent/pbr.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c96f71818883448dd47e058b5dcf558e260859b8', 'message': 'pbr 3.1.0\n\nChange-Id: Ic74e2c1b5db83cf91cc16c7d859bf2478ba39409\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,475347,c96f71818883448dd47e058b5dcf558e260859b8,6,2,1,2472,,,0,"pbr 3.1.0

Change-Id: Ic74e2c1b5db83cf91cc16c7d859bf2478ba39409
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/47/475347/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/pbr.yaml'],1,c96f71818883448dd47e058b5dcf558e260859b8,pbr-310, - version: 3.1.0 projects: - repo: openstack-dev/pbr hash: 3c059cb701e55c7c550f2bbe9626c9c063b0d77e,,4,0
openstack%2Fpython-novaclient~master~I52415354f0c7a7483eddaa48f2acafcdecbb26fd,openstack/python-novaclient,master,I52415354f0c7a7483eddaa48f2acafcdecbb26fd,Make --profile load from environment variables,MERGED,2017-06-19 06:17:53.000000000,2017-06-19 16:30:28.000000000,2017-06-19 16:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 9545}, {'_account_id': 19741}]","[{'number': 1, 'created': '2017-06-19 06:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/518461f37134f591fa1840a21dcef8c1799f85ae', 'message': 'Make --profile load from environment variables\n\n--profile argument can be loaded from OS_PROFILE environment variables\nto avoid repeating --profile in client commands.\n\nChange-Id: I52415354f0c7a7483eddaa48f2acafcdecbb26fd\n'}, {'number': 2, 'created': '2017-06-19 06:37:25.000000000', 'files': ['novaclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/c23324ef4806706bef257e711ac6ffaa8a833ea4', 'message': 'Make --profile load from environment variables\n\n--profile argument can be loaded from OS_PROFILE environment variables\nto avoid repeating --profile in client commands.\n\nCo-Authored-By: Hieu LE <hieulq@vn.fujitsu.com>\nChange-Id: I52415354f0c7a7483eddaa48f2acafcdecbb26fd\n'}]",0,475251,c23324ef4806706bef257e711ac6ffaa8a833ea4,10,4,2,23630,,,0,"Make --profile load from environment variables

--profile argument can be loaded from OS_PROFILE environment variables
to avoid repeating --profile in client commands.

Co-Authored-By: Hieu LE <hieulq@vn.fujitsu.com>
Change-Id: I52415354f0c7a7483eddaa48f2acafcdecbb26fd
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/51/475251/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/shell.py'],1,518461f37134f591fa1840a21dcef8c1799f85ae,profile-as-env-var," default=utils.env('OS_PROFILE'),",,1,0
openstack%2Fzun~master~I0211255e49115f7086a6f7dae5dc00f579806275,openstack/zun,master,I0211255e49115f7086a6f7dae5dc00f579806275,Add claim limit in ram filter and cpu filter,MERGED,2017-06-08 08:12:32.000000000,2017-06-19 15:58:50.000000000,2017-06-19 15:58:50.000000000,"[{'_account_id': 3}, {'_account_id': 8264}, {'_account_id': 8871}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 16277}, {'_account_id': 22076}, {'_account_id': 23365}]","[{'number': 1, 'created': '2017-06-08 08:12:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/ceeb60b8b99508c0a20ded9d6408dc982d05d644', 'message': 'Add claim limit in ram filter and cpu filter\n\nAdd resource claim limit in ram filter and cpu filter.\n\nChange-Id: I0211255e49115f7086a6f7dae5dc00f579806275\nPartially-Implements: blueprint import-nova-filter-scheduler\n'}, {'number': 2, 'created': '2017-06-09 02:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8794e57c011fccb4947edf8fa018e6c4bbadbdb5', 'message': 'Add claim limit in ram filter and cpu filter\n\nAdd resource claim limit in ram filter and cpu filter.\n\nChange-Id: I0211255e49115f7086a6f7dae5dc00f579806275\nPartially-Implements: blueprint import-nova-filter-scheduler\n'}, {'number': 3, 'created': '2017-06-12 02:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/c27b1a092098528eb87b78ea81cd493eb1924440', 'message': 'Add claim limit in ram filter and cpu filter\n\nAdd resource claim limit in ram filter and cpu filter.\n\nChange-Id: I0211255e49115f7086a6f7dae5dc00f579806275\nPartially-Implements: blueprint import-nova-filter-scheduler\n'}, {'number': 4, 'created': '2017-06-12 06:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/03357481dbce349b66e70c532445c175cf2f60bb', 'message': 'Add claim limit in ram filter and cpu filter\n\nAdd resource claim limit in ram filter and cpu filter.\n\nChange-Id: I0211255e49115f7086a6f7dae5dc00f579806275\nPartially-Implements: blueprint import-nova-filter-scheduler\n'}, {'number': 5, 'created': '2017-06-19 07:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/7170e3cb4f86420182fa404e14bd28c8667c6423', 'message': 'Add claim limit in ram filter and cpu filter\n\nAdd resource claim limit in ram filter and cpu filter.\n\nChange-Id: I0211255e49115f7086a6f7dae5dc00f579806275\nPartially-Implements: blueprint import-nova-filter-scheduler\n'}, {'number': 6, 'created': '2017-06-19 07:47:01.000000000', 'files': ['zun/scheduler/filters/cpu_filter.py', 'zun/compute/api.py', 'zun/tests/unit/scheduler/filters/test_cpu_filter.py', 'zun/compute/rpcapi.py', 'zun/tests/unit/scheduler/test_filter_scheduler.py', 'zun/compute/claims.py', 'zun/scheduler/filter_scheduler.py', 'zun/scheduler/host_state.py', 'zun/scheduler/filters/ram_filter.py', 'zun/compute/manager.py', 'zun/tests/unit/scheduler/filters/test_ram_filter.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/435d3f86a68672d5166d5c733c2716e3815dd637', 'message': 'Add claim limit in ram filter and cpu filter\n\nAdd resource claim limit in ram filter and cpu filter.\n\nChange-Id: I0211255e49115f7086a6f7dae5dc00f579806275\nPartially-Implements: blueprint import-nova-filter-scheduler\n'}]",2,472136,435d3f86a68672d5166d5c733c2716e3815dd637,30,8,6,8264,,,0,"Add claim limit in ram filter and cpu filter

Add resource claim limit in ram filter and cpu filter.

Change-Id: I0211255e49115f7086a6f7dae5dc00f579806275
Partially-Implements: blueprint import-nova-filter-scheduler
",git fetch https://review.opendev.org/openstack/zun refs/changes/36/472136/5 && git format-patch -1 --stdout FETCH_HEAD,"['zun/scheduler/filters/cpu_filter.py', 'zun/compute/api.py', 'zun/compute/rpcapi.py', 'zun/tests/unit/scheduler/filters/test_cpu_filter.py', 'zun/tests/unit/scheduler/test_filter_scheduler.py', 'zun/compute/claims.py', 'zun/scheduler/filter_scheduler.py', 'zun/scheduler/host_state.py', 'zun/compute/manager.py', 'zun/scheduler/filters/ram_filter.py', 'zun/tests/unit/scheduler/filters/test_ram_filter.py']",11,ceeb60b8b99508c0a20ded9d6408dc982d05d644,bp/import-nova-filter-scheduler,from zun.scheduler.host_state import HostState host = HostState('testhost') host = HostState('testhost'), host = objects.ComputeNode(self.context) host = objects.ComputeNode(self.context),95,32
openstack%2Frst2bash~master~Iccf654359e56c600f491d118a3c020f9a18b6ea6,openstack/rst2bash,master,Iccf654359e56c600f491d118a3c020f9a18b6ea6,WIP: Test CI.,ABANDONED,2016-12-29 04:23:39.000000000,2017-06-19 15:46:17.000000000,,"[{'_account_id': 3}, {'_account_id': 7007}]","[{'number': 1, 'created': '2016-12-29 04:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/232d6f8ea160e18f576e7cb6e4ff754ba246e852', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 2, 'created': '2016-12-29 04:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/01a24430e8067e22ffa2712e1a033b3dd3bc64c0', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 3, 'created': '2016-12-29 04:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/7596e300a44ad029ebe6df882a4aa1e92238d44a', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 4, 'created': '2017-01-09 10:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/4111aa6433fe87a06c194b046666c0f0ee5d20ac', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 5, 'created': '2017-01-09 10:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/a269c2dbc72c3377f59956986925b5ec744c0741', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 6, 'created': '2017-01-09 12:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/e00b2419e04b1b5da29fc26df1f0314b42923092', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 7, 'created': '2017-01-09 17:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/9d748519437dc91b188027939b0f14c8fbf84ce4', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 8, 'created': '2017-01-11 11:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/f9af811d1d199ecee30fdfd086adabf62f190ddb', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 9, 'created': '2017-01-11 12:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/94e96fab3ced892646b2c206f091e2be20d0a806', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 10, 'created': '2017-01-11 15:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/2b0f9f9c9db464498c6ac6a296b6d705100f3003', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 11, 'created': '2017-01-11 16:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/f69a2353edb67ba0d19c25a6cbefebf64851c4e7', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 12, 'created': '2017-01-12 14:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/229b75b19588cae1733e3c8413a719a5bc5c55d1', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 13, 'created': '2017-01-12 14:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/57892490746cd8cbdefb4cfa41dc156a103d093c', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 14, 'created': '2017-01-16 11:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/04245f3d4a7aa5f1207cb9f45b285adbb93fbfc9', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 15, 'created': '2017-01-16 11:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/073e33ddfde963e0471975f273c4474dbfe63b61', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 16, 'created': '2017-01-16 11:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/aec2a59944fd25f8b211cf62f92a011570b28a9d', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 17, 'created': '2017-01-16 11:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/e7cde8dbaed8cb4e1d1de0584a2e2f8241ffc1ba', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 18, 'created': '2017-01-16 11:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/62ca2a8238ba34c1af8cc48b4fd58f05f31a6a5d', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 19, 'created': '2017-01-16 11:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/211018fb332d6cd41c1cd7ce4461ac802a32b32e', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 20, 'created': '2017-01-16 12:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/6a4981d554ad4888faf9bce83ded6192a681b0ca', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 21, 'created': '2017-01-16 14:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/b9de8e3244821ef0ceec71a5da585bf9fb02e8c7', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 22, 'created': '2017-01-17 10:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/977e6dfbc4ed7c8bde2a496b6c2311f6c8c4f2aa', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}, {'number': 23, 'created': '2017-04-11 16:02:29.000000000', 'files': ['bindep.txt', 'tools/cluster', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/335f9ed4716b9b6be1eed4032f2629196c6f2599', 'message': 'WIP: Test CI.\n\nChange-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6\n'}]",0,415594,335f9ed4716b9b6be1eed4032f2629196c6f2599,49,2,23,7007,,,0,"WIP: Test CI.

Change-Id: Iccf654359e56c600f491d118a3c020f9a18b6ea6
",git fetch https://review.opendev.org/openstack/rst2bash refs/changes/94/415594/22 && git format-patch -1 --stdout FETCH_HEAD,['tools/cluster'],1,232d6f8ea160e18f576e7cb6e4ff754ba246e852,ci_cluster_job,echo $@ ./tools/runparser.sh,,3,0
openstack%2Ftripleo-common~master~Ifefe87e35185fd2306d6e8c33c2ae11f0aea1a9b,openstack/tripleo-common,master,Ifefe87e35185fd2306d6e8c33c2ae11f0aea1a9b,Example for fultonj,ABANDONED,2017-06-19 15:43:00.000000000,2017-06-19 15:44:22.000000000,,[],"[{'number': 1, 'created': '2017-06-19 15:43:00.000000000', 'files': ['tripleo_common/actions/ansible.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0b909280231476df86d05721c08d1f5ed51a418d', 'message': 'Example for fultonj\n\nChange-Id: Ifefe87e35185fd2306d6e8c33c2ae11f0aea1a9b\n'}]",0,475444,0b909280231476df86d05721c08d1f5ed51a418d,2,0,1,9712,,,0,"Example for fultonj

Change-Id: Ifefe87e35185fd2306d6e8c33c2ae11f0aea1a9b
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/44/475444/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/actions/ansible.py'],1,0b909280231476df86d05721c08d1f5ed51a418d,," class CephAnsiblePlaybookAction(AnsiblePlaybookAction): def run(self, context): # create tempfile super(CephAnsiblePlaybookAction, self).run(context) # cleanup tempfile",,9,0
openstack%2Fpython-glanceclient~master~I34b0a426bc10749e0b206aee9c8f7bdf3aea002f,openstack/python-glanceclient,master,I34b0a426bc10749e0b206aee9c8f7bdf3aea002f,gitignore: Ignore auto-generated docs,MERGED,2017-04-19 09:43:39.000000000,2017-06-19 15:40:17.000000000,2017-06-19 15:40:17.000000000,"[{'_account_id': 3}, {'_account_id': 5202}, {'_account_id': 5314}]","[{'number': 1, 'created': '2017-04-19 09:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/25c8a1239d8cd592ef6a4815d204489faac4a92c', 'message': 'gitignore: Ignore auto-generated docs\n\nChange-Id: I34b0a426bc10749e0b206aee9c8f7bdf3aea002f\n'}, {'number': 2, 'created': '2017-04-20 08:40:32.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/26a85720399bccc8de33e40c354ed19ca1d3512b', 'message': 'gitignore: Ignore auto-generated docs\n\nChange-Id: I34b0a426bc10749e0b206aee9c8f7bdf3aea002f\n'}]",0,457975,26a85720399bccc8de33e40c354ed19ca1d3512b,15,3,2,15334,,,0,"gitignore: Ignore auto-generated docs

Change-Id: I34b0a426bc10749e0b206aee9c8f7bdf3aea002f
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/75/457975/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,25c8a1239d8cd592ef6a4815d204489faac4a92c,sphinx15,releasenotes/build # File created by docs build process /doc/source/ref ,releasenotes/build,3,1
openstack%2Fopenstack-ansible-lxc_container_create~master~I79658a261613357b610f481187868a1eed56b5a3,openstack/openstack-ansible-lxc_container_create,master,I79658a261613357b610f481187868a1eed56b5a3,Use connection plugin instead of delegating,MERGED,2017-06-18 18:29:50.000000000,2017-06-19 15:38:59.000000000,2017-06-19 15:32:32.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-18 18:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/069978150d1bfdb9f8a69c6dfb17a6172a9a609b', 'message': ""Write to rootfs directory instead of through /proc\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of writing\nfiles directly to containers through /proc, use the rootfs directory.\nWith LVM backed containers, a mount is required.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}, {'number': 2, 'created': '2017-06-18 20:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/10c027d99361a69b058026e07591c8b1f5cb6c26', 'message': ""Write to rootfs directory instead of through /proc\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of writing\nfiles directly to containers through /proc, use the rootfs directory.\nWith LVM backed containers, a mount is required.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}, {'number': 3, 'created': '2017-06-19 03:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/4a549800ff239eb38fe0be4022b5816b7aba5725', 'message': ""Write to rootfs directory instead of through /proc\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of writing\nfiles directly to containers through /proc, use the rootfs directory.\nWith LVM backed containers, a mount is required.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}, {'number': 4, 'created': '2017-06-19 03:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/6c0c6295a11dafdef17332ef4fc6a88657c7fb30', 'message': ""Write to rootfs directory instead of through /proc\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of writing\nfiles directly to containers through /proc, use the rootfs directory.\nWith LVM backed containers, a mount is required.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}, {'number': 5, 'created': '2017-06-19 14:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/4c588f04b5df5dcc2c4f714181faff9362a23933', 'message': ""Use connection plugin instead of delegating\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of delegating\nto containers' physical host and writing files to containers through\n/proc, make use of the OSA ssh connection plugin.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}, {'number': 6, 'created': '2017-06-19 14:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/89364a62b24279f803dc2431bf0d86556cb11892', 'message': ""Use connection plugin instead of delegating\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of delegating\nto containers' physical host and writing files to containers through\n/proc, make use of the OSA ssh connection plugin.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}, {'number': 7, 'created': '2017-06-19 15:02:53.000000000', 'files': ['tasks/container_create.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/8ded80fdc960ce9dfd5b56b51afe79743a449930', 'message': ""Use connection plugin instead of delegating\n\nAs of 2.2.3.0, Ansible now expands and follows the real paths of the\nsymlinks. Attempting the expand the symlink of /root within a\ncontainer's /proc directory becomes unreachable. Instead of delegating\nto containers' physical host and writing files to containers through\n/proc, make use of the OSA ssh connection plugin.\n\nCloses-Bug: 1696802\nChange-Id: I79658a261613357b610f481187868a1eed56b5a3\n""}]",3,475194,8ded80fdc960ce9dfd5b56b51afe79743a449930,24,4,7,14805,,,0,"Use connection plugin instead of delegating

As of 2.2.3.0, Ansible now expands and follows the real paths of the
symlinks. Attempting the expand the symlink of /root within a
container's /proc directory becomes unreachable. Instead of delegating
to containers' physical host and writing files to containers through
/proc, make use of the OSA ssh connection plugin.

Closes-Bug: 1696802
Change-Id: I79658a261613357b610f481187868a1eed56b5a3
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/94/475194/4 && git format-patch -1 --stdout FETCH_HEAD,['tasks/container_create.yml'],1,069978150d1bfdb9f8a69c6dfb17a6172a9a609b,bug/1696802,"- name: Mount container rootfs for LVM backing store mount: path: ""{{ lxc_container_rootfs_directory }}"" src: ""/dev/{{ lxc_container_vg_name }}/{{ inventory_hostname }}"" fstype: ""{{ lxc_container_fs_type }}"" state: mounted when: lxc_container_backing_store == 'lvm' dest: ""{{ lxc_container_rootfs_directory }}{{ lxc_container_interface_target }}"" dest: ""{{ lxc_container_rootfs_directory }}{{ lxc_container_default_route_interfaces }}"" dest: ""{{ lxc_container_rootfs_directory }}/opt/container-setup.sh""- name: Unmount container rootfs for LVM backing store mount: path: ""{{ lxc_container_rootfs_directory }}"" src: ""/dev/{{ lxc_container_vg_name }}/{{ inventory_hostname }}"" state: unmounted when: lxc_container_backing_store == 'lvm' delegate_to: ""{{ physical_host }}"" tags: - lxc_container_create-setup ","- name: Get LXC container PID command: > lxc-info -pHn {{ inventory_hostname }} register: container_pid changed_when: false dest: ""/proc/{{ container_pid.stdout }}/root{{ lxc_container_interface_target }}"" dest: ""/proc/{{ container_pid.stdout }}/root{{ lxc_container_default_route_interfaces }}"" dest: ""/proc/{{ container_pid.stdout }}/root/opt/container-setup.sh""",20,8
openstack%2Ftripleo-validations~master~I6f23de585f4926a98fd8931070e32d313dabb00f,openstack/tripleo-validations,master,I6f23de585f4926a98fd8931070e32d313dabb00f,Updated from global requirements,MERGED,2017-06-10 11:50:07.000000000,2017-06-19 15:38:01.000000000,2017-06-19 15:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9317}, {'_account_id': 17888}]","[{'number': 1, 'created': '2017-06-10 11:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/a2e570ed8dd4f647e13248935043515816943241', 'message': 'Updated from global requirements\n\nChange-Id: I6f23de585f4926a98fd8931070e32d313dabb00f\n'}, {'number': 2, 'created': '2017-06-15 16:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/63f5faf63116fc9bfead41f370bd45230d3babee', 'message': 'Updated from global requirements\n\nChange-Id: I6f23de585f4926a98fd8931070e32d313dabb00f\n'}, {'number': 3, 'created': '2017-06-16 12:24:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/8f45de67ea91be123a150266ca3cdb999a036b6f', 'message': 'Updated from global requirements\n\nChange-Id: I6f23de585f4926a98fd8931070e32d313dabb00f\n'}]",0,472929,8f45de67ea91be123a150266ca3cdb999a036b6f,16,4,3,11131,,,0,"Updated from global requirements

Change-Id: I6f23de585f4926a98fd8931070e32d313dabb00f
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/29/472929/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a2e570ed8dd4f647e13248935043515816943241,openstack/requirements,keystoneauth1>=2.21.0 # Apache-2.0,keystoneauth1>=2.20.0 # Apache-2.0,1,1
openstack%2Ftripleo-validations~master~I592ffe13f224dc5275f6bd89829c98a46d3a7472,openstack/tripleo-validations,master,I592ffe13f224dc5275f6bd89829c98a46d3a7472,Add stack health check validation,MERGED,2017-05-24 12:38:57.000000000,2017-06-19 15:37:39.000000000,2017-06-19 15:37:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4330}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 11166}, {'_account_id': 13039}, {'_account_id': 16515}, {'_account_id': 16628}, {'_account_id': 17888}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-05-24 12:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/303b0bf22b6ed90a9868c90e3f01ceb33d1517b6', 'message': 'Add stack health check validation\n\nThis validation adds a basic health check for the current stack by\nmaking sure all resources are in a *_COMPLETE state. The validation\nshould be run before an upgrade.\n\nChange-Id: I592ffe13f224dc5275f6bd89829c98a46d3a7472\nImplements: blueprint pre-upgrade-validations\n'}, {'number': 2, 'created': '2017-05-29 11:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/7c6a590871ed11971808f1072c4d5e5f9ce14c47', 'message': 'Add stack health check validation\n\nThis validation adds a basic health check for the current stack by\nmaking sure all resources are in a *_COMPLETE state. The validation\nshould be run before an upgrade.\n\nChange-Id: I592ffe13f224dc5275f6bd89829c98a46d3a7472\nImplements: blueprint pre-upgrade-validations\n'}, {'number': 3, 'created': '2017-05-29 13:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/cb10ef2baf23e28633bb3e056d5d0f2f575158e8', 'message': 'Add stack health check validation\n\nThis validation adds a basic health check for the current stack by\nmaking sure all resources are in a *_COMPLETE state. The validation\nshould be run before an upgrade.\n\nChange-Id: I592ffe13f224dc5275f6bd89829c98a46d3a7472\nImplements: blueprint pre-upgrade-validations\n'}, {'number': 4, 'created': '2017-06-09 07:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/68c662c86408598e25c6b42890df03bb6e39b4ab', 'message': 'Add stack health check validation\n\nThis validation adds a basic health check for the current stack by\nmaking sure all resources are in a *_COMPLETE state. The validation\nshould be run before an upgrade.\n\nTo look up the resources, a new lookup plugin is added as well.\n\nChange-Id: I592ffe13f224dc5275f6bd89829c98a46d3a7472\nImplements: blueprint pre-upgrade-validations\n'}, {'number': 5, 'created': '2017-06-15 10:30:53.000000000', 'files': ['validations/stack-health.yaml', 'releasenotes/notes/stack-health-validation-c2174bc5f0bd585e.yaml', 'tripleo_validations/tests/test_inventory.py', 'tripleo_validations/inventory.py', 'validations/lookup_plugins/stack_resources.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/b419de723d2192a9e2842f925f8fec3a857d0c84', 'message': 'Add stack health check validation\n\nThis validation adds a basic health check for the current stack by\nmaking sure all resources are in a *_COMPLETE state. The validation\nshould be run before an upgrade.\n\nTo look up the resources, a new lookup plugin is added as well.\n\nChange-Id: I592ffe13f224dc5275f6bd89829c98a46d3a7472\nImplements: blueprint pre-upgrade-validations\n'}]",5,467607,b419de723d2192a9e2842f925f8fec3a857d0c84,27,11,5,17888,,,0,"Add stack health check validation

This validation adds a basic health check for the current stack by
making sure all resources are in a *_COMPLETE state. The validation
should be run before an upgrade.

To look up the resources, a new lookup plugin is added as well.

Change-Id: I592ffe13f224dc5275f6bd89829c98a46d3a7472
Implements: blueprint pre-upgrade-validations
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/07/467607/4 && git format-patch -1 --stdout FETCH_HEAD,"['validations/stack-health.yaml', 'tripleo_validations/inventory.py', 'validations/lookup_plugins/stack_resources.py']",3,303b0bf22b6ed90a9868c90e3f01ceb33d1517b6,bp/pre-upgrade-validations,"#!/usr/bin/env python # Copyright 2017 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json from ansible.plugins.lookup import LookupBase from heatclient import client as heat_client from tripleo_validations.utils import get_auth_session class LookupModule(LookupBase): def run(self, terms, variables=None, **kwargs): """"""Returns the current plan files. Returns a list of tuples, one for each plan file, containing the template path and the template content. """""" ret = [] session = get_auth_session(variables['auth_url'], variables['username'], variables['project_name'], auth_token=variables['os_auth_token'], cacert=variables['cacert']) hclient = heat_client.Client('1', session=session) resource_list = hclient.resources.list(variables['plan']) for resource in resource_list: ret.append(dict(resource_name=resource.resource_name, resource_status=resource.resource_status, logical_resource_id=resource.logical_resource_id, links=resource.links, creation_time=resource.creation_time, resource_status_reason=resource.resource_status_reason, updated_time=resource.updated_time, required_by=resource.required_by, physical_resource_id=resource.physical_resource_id, resource_type=resource.resource_type )) return ret ",,76,0
openstack%2Fproject-config~master~I760edc8ef5a7950eb8b9a71d0f8ea4bb2cf6219c,openstack/project-config,master,I760edc8ef5a7950eb8b9a71d0f8ea4bb2cf6219c,Move undercloud-containers job to check-tripleo-undercloud-jobs pipeline,MERGED,2017-03-17 10:17:36.000000000,2017-06-19 15:37:35.000000000,2017-05-01 06:51:00.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 13039}, {'_account_id': 13252}]","[{'number': 1, 'created': '2017-03-17 10:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/14194a40f05fc80befa8f416c3731595f0c49812', 'message': 'Move undercloud-containers job to check-tripleo-undercloud-jobs pipeline\n\nAlso move the job out of experimental to check.\n\nChange-Id: I760edc8ef5a7950eb8b9a71d0f8ea4bb2cf6219c\n'}, {'number': 2, 'created': '2017-04-25 08:52:44.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/22b3e830d2f488a26d75d85d13ec2e6644f35fdf', 'message': 'Move undercloud-containers job to check-tripleo-undercloud-jobs pipeline\n\nAlso move the job out of experimental to check.\n\nChange-Id: I760edc8ef5a7950eb8b9a71d0f8ea4bb2cf6219c\n'}]",0,446940,22b3e830d2f488a26d75d85d13ec2e6644f35fdf,13,7,2,13039,,,0,"Move undercloud-containers job to check-tripleo-undercloud-jobs pipeline

Also move the job out of experimental to check.

Change-Id: I760edc8ef5a7950eb8b9a71d0f8ea4bb2cf6219c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/446940/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,14194a40f05fc80befa8f416c3731595f0c49812,undercloud-containers, - gate-tripleo-ci-centos-7-undercloud-containers, - gate-tripleo-ci-centos-7-undercloud-containers,1,1
openstack%2Ftripleo-specs~master~I1a39c645135a1f87b5cb6ebe3f9ac1bec34ae071,openstack/tripleo-specs,master,I1a39c645135a1f87b5cb6ebe3f9ac1bec34ae071,Clean up spec index,MERGED,2017-06-16 22:50:23.000000000,2017-06-19 15:37:30.000000000,2017-06-19 15:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 10239}]","[{'number': 1, 'created': '2017-06-16 22:50:23.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/fdbc5f2304f40603f5aef59a3b0c48bfff2b6284', 'message': 'Clean up spec index\n\nProposed specs will never be published in this doc, so the title\nshould be ""Approved"".  In addition, two Pike entries were added\nat some point so the one that is out of order is removed.\n\nChange-Id: I1a39c645135a1f87b5cb6ebe3f9ac1bec34ae071\n'}]",0,475085,fdbc5f2304f40603f5aef59a3b0c48bfff2b6284,8,4,1,6928,,,0,"Clean up spec index

Proposed specs will never be published in this doc, so the title
should be ""Approved"".  In addition, two Pike entries were added
at some point so the one that is out of order is removed.

Change-Id: I1a39c645135a1f87b5cb6ebe3f9ac1bec34ae071
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/85/475085/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,fdbc5f2304f40603f5aef59a3b0c48bfff2b6284,index-cleanup,Pike Approved Specs:,Pike Proposed Specs:Pike Approved Specs: .. toctree:: :glob: :maxdepth: 1 specs/pike/* ,1,9
openstack%2Fproject-config~master~I786458b9b8bdd239853d24612ef6ee1eec3afee8,openstack/project-config,master,I786458b9b8bdd239853d24612ef6ee1eec3afee8,tripleo: remove experimental quickstart jobs,MERGED,2017-05-22 11:20:05.000000000,2017-06-19 15:35:59.000000000,2017-05-30 08:26:46.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-05-22 11:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/962a3101596913933b1a89653a8287c9331aedbb', 'message': 'tripleo: fix clone destinations for quickstart projects\n\nProjects have to be cloned in different directories, and the custom\nclonemap is blocking the default behaviour for zuul\nSetting different destinations for the two quickstart projects.\n\nChange-Id: I786458b9b8bdd239853d24612ef6ee1eec3afee8\n'}, {'number': 2, 'created': '2017-05-22 12:03:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b11e881e2cedd107607b9c096b241a4412df5e4e', 'message': 'tripleo: remove experimental quickstart jobs\n\nexperimental pipeline in quickstart changes launch an obsolete job that\nuses a broken configuration.\nRemoving those jobs and dependent jjb macros\n\nChange-Id: I786458b9b8bdd239853d24612ef6ee1eec3afee8\n'}, {'number': 3, 'created': '2017-05-22 19:24:23.000000000', 'files': ['jenkins/jobs/tripleo.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f789beffecf750c5eb3b27be5a953ef787b594f6', 'message': 'tripleo: remove experimental quickstart jobs\n\nexperimental pipeline in quickstart changes launch an obsolete job that\nuses a broken configuration.\nRemoving those jobs and dependent jjb macros\n\nChange-Id: I786458b9b8bdd239853d24612ef6ee1eec3afee8\n'}]",2,466686,f789beffecf750c5eb3b27be5a953ef787b594f6,14,4,3,10022,,,0,"tripleo: remove experimental quickstart jobs

experimental pipeline in quickstart changes launch an obsolete job that
uses a broken configuration.
Removing those jobs and dependent jjb macros

Change-Id: I786458b9b8bdd239853d24612ef6ee1eec3afee8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/466686/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/tripleo.yaml'],1,962a3101596913933b1a89653a8287c9331aedbb,fix-experimental-oooq, dest: ./tripleo-quickstart dest: ./tripleo-quickstart-extras, dest: . dest: .,2,2
openstack%2Ftripleo-heat-templates~master~I2d4aeb584eb624178d601cfd6bc0a6473cb5289f,openstack/tripleo-heat-templates,master,I2d4aeb584eb624178d601cfd6bc0a6473cb5289f,Add nested sample environments for inject-trust-anchor,MERGED,2017-05-17 15:48:00.000000000,2017-06-19 15:27:00.000000000,2017-06-19 15:27:00.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-05-17 15:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/76ce3bdab4f18143c0c53f4412b8527ec7717bf3', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 2, 'created': '2017-05-18 20:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/276f2f55c463a78f774b6431e92d06709de3d886', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 3, 'created': '2017-05-18 20:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca5b2412f64bf8d271a6ddcd819e28c8d698ad41', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 4, 'created': '2017-05-19 20:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/284fa78f184beeeda555261482f0e442584b14c0', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 5, 'created': '2017-05-19 21:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b11c700ee6b78849dc2521c83dc829825a4704f6', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 6, 'created': '2017-05-22 16:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ed74bc3e4c2b48e9a05d40bb7e65c3c5f87d9e94', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 7, 'created': '2017-05-22 17:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a7a44a08e585426a457f2a8fc326d4f4d64d050', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 8, 'created': '2017-05-25 17:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a71d24e4473dbb76b0fba0881c527fdf83b10a48', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}, {'number': 9, 'created': '2017-06-12 20:15:06.000000000', 'files': ['sample-env-generator/ssl.yaml', 'tripleo_heat_templates/environment_generator.py', 'sample-env-generator/README.rst', 'environments/inject-trust-anchor-hiera.yaml', 'tripleo_heat_templates/tests/test_environment_generator.py', 'environments/ssl/inject-trust-anchor-hiera.yaml', 'environments/inject-trust-anchor.yaml', 'environments/ssl/inject-trust-anchor.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/204a5820995dd694fcd58d61fc6cf34a8955da92', 'message': 'Add nested sample environments for inject-trust-anchor\n\nFix a bug that prevented these working.  A unit test and\ndocumentation for the nested environment functionality is also\nincluded.\n\nChange-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f\n'}]",0,465648,204a5820995dd694fcd58d61fc6cf34a8955da92,30,6,9,6928,,,0,"Add nested sample environments for inject-trust-anchor

Fix a bug that prevented these working.  A unit test and
documentation for the nested environment functionality is also
included.

Change-Id: I2d4aeb584eb624178d601cfd6bc0a6473cb5289f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/465648/9 && git format-patch -1 --stdout FETCH_HEAD,"['sample-env-generator/ssl.yaml', 'tripleo_heat_templates/environment_generator.py', 'sample-env-generator/README.rst', 'tripleo_heat_templates/tests/test_environment_generator.py', 'environments/ssl/inject-trust-anchor-hiera.yaml', 'environments/ssl/inject-trust-anchor.yaml']",6,76ce3bdab4f18143c0c53f4412b8527ec7717bf3,env-generator,"# ******************************************************************* # This file was created automatically by the sample environment # generator. Developers should use `tox -e genconfig` to update it. # Users are recommended to make changes to a copy of the file instead # of the original, if any customizations are needed. # ******************************************************************* # title: Inject SSL Trust Anchor on Overcloud Nodes # description: | # When using an SSL certificate signed by a CA that is not in the default # list of CAs, this environment allows adding a custom CA certificate to # the overcloud nodes. parameter_defaults: # The content of a CA's SSL certificate file in PEM format. This is evaluated on the client side. # Mandatory. This parameter must be set by the user. # Type: string SSLRootCertificate: | The contents of your certificate go here ",,144,1
openstack%2Ftripleo-heat-templates~master~If11f30c734bfbc17d463a9890c736d7477186fb9,openstack/tripleo-heat-templates,master,If11f30c734bfbc17d463a9890c736d7477186fb9,Add storage sample environments,MERGED,2017-05-18 20:39:23.000000000,2017-06-19 15:26:53.000000000,2017-06-19 15:26:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-05-18 20:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f0b5cc26bb578cd0326db29ecf5fe1a7d757ded6', 'message': 'Add storage sample environments\n\nStarts converting storage-related sample environments to the tool,\nand adds a few new ones for demonstration purposes.\n\nChange-Id: If11f30c734bfbc17d463a9890c736d7477186fb9\n'}, {'number': 2, 'created': '2017-05-19 20:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dd21914d61bd85e89ea529e8dc14d014405bc8f6', 'message': ""Add storage sample environments\n\nStarts converting storage-related sample environments to the tool,\nand adds a few new ones for demonstration purposes.\n\nThis has required the addition of a new category of parameter\noverrides in the tool.  There are some parameters that are part of\nthe public API of roles that should not normally be included in a\nsample environment for that role.  Examples are EndpointMap and\nServiceNetMap.  Those are both passed into most (all?) roles, but\ntheir template defaults are not useful (both default to {}).\nUnless we are explicitly creating a sample environment that\noverrides those defaults we don't want them included.\n\nParameters such as RoleName and RoleParameters are similar.  We\ncan't change them because they are part of the composable roles\ninterface and that would break any existing custom roles, but we\ndon't really want them included normally either.  It's possible\nthese could be made completely private, but there have been some\nvery preliminary discussions about generating role samples that\nmight actually want to set them.\n\nChange-Id: If11f30c734bfbc17d463a9890c736d7477186fb9\n""}, {'number': 3, 'created': '2017-05-19 21:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1aff12380e4a708a740deeaabfdfa6bcaecbca52', 'message': ""Add storage sample environments\n\nStarts converting storage-related sample environments to the tool,\nand adds a few new ones for demonstration purposes.\n\nThis has required the addition of a new category of parameter\noverrides in the tool.  There are some parameters that are part of\nthe public API of roles that should not normally be included in a\nsample environment for that role.  Examples are EndpointMap and\nServiceNetMap.  Those are both passed into most (all?) roles, but\ntheir template defaults are not useful (both default to {}).\nUnless we are explicitly creating a sample environment that\noverrides those defaults we don't want them included.\n\nParameters such as RoleName and RoleParameters are similar.  We\ncan't change them because they are part of the composable roles\ninterface and that would break any existing custom roles, but we\ndon't really want them included normally either.  It's possible\nthese could be made completely private, but there have been some\nvery preliminary discussions about generating role samples that\nmight actually want to set them.\n\nIn order to avoid issues with editing the unit test file in editors\nthat strip trailing whitespace, the minor formatting bug where\nparams like EndpointMap had a trailing space after the name has\nalso been fixed.\n\nChange-Id: If11f30c734bfbc17d463a9890c736d7477186fb9\n""}, {'number': 4, 'created': '2017-05-22 16:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e673b10f8e86f25d03b167d6830237683f00ce94', 'message': ""Add storage sample environments\n\nStarts converting storage-related sample environments to the tool,\nand adds a few new ones for demonstration purposes.\n\nThis has required the addition of a new category of parameter\noverrides in the tool.  There are some parameters that are part of\nthe public API of roles that should not normally be included in a\nsample environment for that role.  Examples are EndpointMap and\nServiceNetMap.  Those are both passed into most (all?) roles, but\ntheir template defaults are not useful (both default to {}).\nUnless we are explicitly creating a sample environment that\noverrides those defaults we don't want them included.\n\nParameters such as RoleName and RoleParameters are similar.  We\ncan't change them because they are part of the composable roles\ninterface and that would break any existing custom roles, but we\ndon't really want them included normally either.  It's possible\nthese could be made completely private, but there have been some\nvery preliminary discussions about generating role samples that\nmight actually want to set them.\n\nIn order to avoid issues with editing the unit test file in editors\nthat strip trailing whitespace, the minor formatting bug where\nparams like EndpointMap had a trailing space after the name has\nalso been fixed.\n\nChange-Id: If11f30c734bfbc17d463a9890c736d7477186fb9\n""}, {'number': 5, 'created': '2017-05-25 17:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6ed7485308bf3705308d4fe1e1a360ebedcd6fdb', 'message': ""Add storage sample environments\n\nStarts converting storage-related sample environments to the tool,\nand adds a few new ones for demonstration purposes.\n\nThis has required the addition of a new category of parameter\noverrides in the tool.  There are some parameters that are part of\nthe public API of roles that should not normally be included in a\nsample environment for that role.  Examples are EndpointMap and\nServiceNetMap.  Those are both passed into most (all?) roles, but\ntheir template defaults are not useful (both default to {}).\nUnless we are explicitly creating a sample environment that\noverrides those defaults we don't want them included.\n\nParameters such as RoleName and RoleParameters are similar.  We\ncan't change them because they are part of the composable roles\ninterface and that would break any existing custom roles, but we\ndon't really want them included normally either.  It's possible\nthese could be made completely private, but there have been some\nvery preliminary discussions about generating role samples that\nmight actually want to set them.\n\nIn order to avoid issues with editing the unit test file in editors\nthat strip trailing whitespace, the minor formatting bug where\nparams like EndpointMap had a trailing space after the name has\nalso been fixed.\n\nChange-Id: If11f30c734bfbc17d463a9890c736d7477186fb9\n""}, {'number': 6, 'created': '2017-06-12 20:15:06.000000000', 'files': ['environments/cinder-netapp-config.yaml', 'tripleo_heat_templates/environment_generator.py', 'environments/ssl/tls-endpoints-public-ip.yaml', 'environments/storage/cinder-nfs.yaml', 'tripleo_heat_templates/tests/test_environment_generator.py', 'environments/puppet-ceph-external.yaml', 'environments/storage/external-ceph.yaml', 'environments/ssl/tls-endpoints-public-dns.yaml', 'sample-env-generator/storage.yaml', 'environments/storage/cinder-netapp-config.yaml', 'environments/ssl/tls-everywhere-endpoints-dns.yaml', 'environments/storage/glance-nfs.yaml', 'environments/storage/enable-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8d086b171099f0a968f1fdd1b39706ec64a52f56', 'message': ""Add storage sample environments\n\nStarts converting storage-related sample environments to the tool,\nand adds a few new ones for demonstration purposes.\n\nThis has required the addition of a new category of parameter\noverrides in the tool.  There are some parameters that are part of\nthe public API of roles that should not normally be included in a\nsample environment for that role.  Examples are EndpointMap and\nServiceNetMap.  Those are both passed into most (all?) roles, but\ntheir template defaults are not useful (both default to {}).\nUnless we are explicitly creating a sample environment that\noverrides those defaults we don't want them included.\n\nParameters such as RoleName and RoleParameters are similar.  We\ncan't change them because they are part of the composable roles\ninterface and that would break any existing custom roles, but we\ndon't really want them included normally either.  It's possible\nthese could be made completely private, but there have been some\nvery preliminary discussions about generating role samples that\nmight actually want to set them.\n\nIn order to avoid issues with editing the unit test file in editors\nthat strip trailing whitespace, the minor formatting bug where\nparams like EndpointMap had a trailing space after the name has\nalso been fixed.\n\nChange-Id: If11f30c734bfbc17d463a9890c736d7477186fb9\n""}]",0,466103,8d086b171099f0a968f1fdd1b39706ec64a52f56,23,4,6,6928,,,0,"Add storage sample environments

Starts converting storage-related sample environments to the tool,
and adds a few new ones for demonstration purposes.

This has required the addition of a new category of parameter
overrides in the tool.  There are some parameters that are part of
the public API of roles that should not normally be included in a
sample environment for that role.  Examples are EndpointMap and
ServiceNetMap.  Those are both passed into most (all?) roles, but
their template defaults are not useful (both default to {}).
Unless we are explicitly creating a sample environment that
overrides those defaults we don't want them included.

Parameters such as RoleName and RoleParameters are similar.  We
can't change them because they are part of the composable roles
interface and that would break any existing custom roles, but we
don't really want them included normally either.  It's possible
these could be made completely private, but there have been some
very preliminary discussions about generating role samples that
might actually want to set them.

In order to avoid issues with editing the unit test file in editors
that strip trailing whitespace, the minor formatting bug where
params like EndpointMap had a trailing space after the name has
also been fixed.

Change-Id: If11f30c734bfbc17d463a9890c736d7477186fb9
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/466103/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/cinder-netapp-config.yaml', 'sample-env-generator/storage.yaml', 'environments/storage/cinder-nfs.yaml', 'environments/puppet-ceph-external.yaml', 'environments/storage/cinder-netapp-config.yaml', 'environments/storage/glance-nfs.yaml', 'environments/storage/enable-ceph.yaml', 'environments/storage/external-ceph.yaml']",8,f0b5cc26bb578cd0326db29ecf5fe1a7d757ded6,env-generator,"# ******************************************************************* # This file was created automatically by the sample environment # generator. Developers should use `tox -e genconfig` to update it. # Users are recommended to make changes to a copy of the file instead # of the original, if any customizations are needed. # ******************************************************************* # title: Deploy Using an External Ceph Cluster # description: | # A Heat environment file which can be used to enable the # use of an externally managed Ceph cluster. parameter_defaults: # The Ceph admin client key. Can be created with ceph-authtool --gen-print-key. # Type: string CephAdminKey: '' # The Ceph client key. Can be created with ceph-authtool --gen-print-key. Currently only used for external Ceph deployments to create the openstack user keyring. # Mandatory. This parameter must be set by the user. # Type: string CephClientKey: <None> # # Type: string CephClientUserName: openstack # The Ceph cluster FSID. Must be a UUID. # Mandatory. This parameter must be set by the user. # Type: string CephClusterFSID: <None> # List of externally managed Ceph Mon Host IPs. Only used for external Ceph deployments. # Type: string CephExternalMonHost: '' # Whether to enable or not the Iscsi backend for Cinder # Type: boolean CinderEnableIscsiBackend: False # Whether to enable or not the Rbd backend for Cinder # Type: boolean CinderEnableRbdBackend: True # # Type: string CinderRbdPoolName: volumes # The short name of the Glance backend to use. Should be one of swift, rbd, or file # Type: string GlanceBackend: rbd # # Type: string GlanceRbdPoolName: images # The short name of the Gnocchi backend to use. Should be one of swift, rbd, or file # Type: string GnocchiBackend: swift # # Type: string GnocchiRbdPoolName: metrics # Whether to enable or not the Rbd backend for Nova # Type: boolean NovaEnableRbdBackend: True # # Type: string NovaRbdPoolName: vms resource_registry: OS::TripleO::Services::CephClient: OS::Heat::None OS::TripleO::Services::CephExternal: ../puppet/services/ceph-external.yaml OS::TripleO::Services::CephMon: OS::Heat::None OS::TripleO::Services::CephOSD: OS::Heat::None ",,444,0
openstack%2Ftripleo-heat-templates~master~I34d3a9356b119d549acd6fe4f0c8713b0bfa5957,openstack/tripleo-heat-templates,master,I34d3a9356b119d549acd6fe4f0c8713b0bfa5957,Add neutron-midonet sample environment,MERGED,2017-05-18 20:39:23.000000000,2017-06-19 15:26:41.000000000,2017-06-19 15:26:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18575}]","[{'number': 1, 'created': '2017-05-18 20:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/918201f9066b37f578d33a02c04e23f1cce8551e', 'message': 'Add neutron-midonet sample environment\n\nChange-Id: I34d3a9356b119d549acd6fe4f0c8713b0bfa5957\n'}, {'number': 2, 'created': '2017-05-19 20:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a881c377aa3574302bd668516b28ed219f33c3a', 'message': 'Add neutron-midonet sample environment\n\nChange-Id: I34d3a9356b119d549acd6fe4f0c8713b0bfa5957\n'}, {'number': 3, 'created': '2017-05-22 16:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4a7a1fc6886c916c20e21ee656df35ad86076cd8', 'message': 'Add neutron-midonet sample environment\n\nChange-Id: I34d3a9356b119d549acd6fe4f0c8713b0bfa5957\n'}, {'number': 4, 'created': '2017-05-25 17:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f491195efefd1bbc34c64d83c4d6beaf42ee59a2', 'message': 'Add neutron-midonet sample environment\n\nChange-Id: I34d3a9356b119d549acd6fe4f0c8713b0bfa5957\n'}, {'number': 5, 'created': '2017-06-12 20:15:06.000000000', 'files': ['environments/neutron-midonet.yaml', 'sample-env-generator/networking.yaml', 'environments/networking/neutron-midonet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7613306b8cb67547cc9f0c56f9ba97a45a9e7f73', 'message': 'Add neutron-midonet sample environment\n\nChange-Id: I34d3a9356b119d549acd6fe4f0c8713b0bfa5957\n'}]",0,466102,7613306b8cb67547cc9f0c56f9ba97a45a9e7f73,23,5,5,6928,,,0,"Add neutron-midonet sample environment

Change-Id: I34d3a9356b119d549acd6fe4f0c8713b0bfa5957
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/466102/5 && git format-patch -1 --stdout FETCH_HEAD,"['environments/neutron-midonet.yaml', 'sample-env-generator/networking.yaml', 'environments/networking/neutron-midonet.yaml']",3,918201f9066b37f578d33a02c04e23f1cce8551e,env-generator,"# ******************************************************************* # This file was created automatically by the sample environment # generator. Developers should use `tox -e genconfig` to update it. # Users are recommended to make changes to a copy of the file instead # of the original, if any customizations are needed. # ******************************************************************* # title: Enable the Neutron MidoNet Services # description: | # A Heat environment that can be used to deploy MidoNet Services parameter_defaults: # Native Transport Port # Type: string CassandraClientPort: 9042 # The port for the Thrift RPC service, which is used for client connections # Type: string CassandraClientPortThrift: 9160 # The SSL port for encrypted communication. Unused unless enabled in encryption_options # Type: string CassandraSslStoragePort: 7001 # The Cassandra port for inter-node communication # Type: string CassandraStoragePort: 7000 # Name of the tunnel zone used to tunnel packages # Type: string TunnelZoneName: tunnelzone_tripleo # Type of the tunnels on the overlay. Choose between `gre` and `vxlan` # Type: string TunnelZoneType: vxlan # ****************************************************** # Static parameters - these are values that must be # included in the environment but should not be changed. # ****************************************************** # Whether enable Cassandra cluster on Controller # Type: boolean EnableCassandraOnController: True # Whether enable Zookeeper cluster on Controller # Type: boolean EnableZookeeperOnController: True # The core plugin for Neutron. The value should be the entrypoint to be loaded # from neutron.core_plugins namespace. # Type: string NeutronCorePlugin: midonet.neutron.plugin_v1.MidonetPluginV2 # If True, DHCP provide metadata route to VM. # Type: boolean NeutronEnableIsolatedMetadata: True # ********************* # End static parameters # ********************* resource_registry: OS::TripleO::AllNodesExtraConfig: ../../puppet/extraconfig/all_nodes/neutron-midonet-all-nodes.yaml OS::TripleO::Controller::Net::SoftwareConfig: ../../net-config-linux-bridge.yaml OS::TripleO::Services::ComputeNeutronCorePlugin: ../../puppet/services/neutron-compute-plugin-midonet.yaml OS::TripleO::Services::ComputeNeutronOvsAgent: OS::Heat::None OS::TripleO::Services::NeutronCorePlugin: OS::TripleO::Services::NeutronCorePluginMidonet OS::TripleO::Services::NeutronL3Agent: OS::Heat::None OS::TripleO::Services::NeutronOvsAgent: OS::Heat::None ",,102,0
openstack%2Ftripleo-heat-templates~master~If2c608f2a61fc5e16784ab594d23f1fa335e1d3c,openstack/tripleo-heat-templates,master,If2c608f2a61fc5e16784ab594d23f1fa335e1d3c,Support config dir for env generator input files,MERGED,2017-05-17 15:48:00.000000000,2017-06-19 15:26:33.000000000,2017-06-19 15:26:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-05-17 15:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d0908735ff3b41f4ad99e0ba15a5d631eb5cbc78', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}, {'number': 2, 'created': '2017-05-18 20:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5e360c9c68bacd04b3e39f04457c0190848302bb', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.  This commit adds support for that as well as\nsome initial environments to demonstrate its use.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}, {'number': 3, 'created': '2017-05-18 20:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0f345b293a305df969700132e2ae77d19dbdf7f', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.  This commit adds support for that as well as\nsome initial environments to demonstrate its use.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}, {'number': 4, 'created': '2017-05-19 20:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d7c4d3adbed482453d3d10d8e97536762e349c1d', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.  This commit adds support for that as well as\nsome initial environments to demonstrate its use.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}, {'number': 5, 'created': '2017-05-22 16:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2ca666fabd6547e6c506c3d7903c4c192c68f4f6', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.  This commit adds support for that as well as\nsome initial environments to demonstrate its use.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}, {'number': 6, 'created': '2017-05-25 17:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1d2be07c3fdd79d617db0a18aa47cfeb955d77c7', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.  This commit adds support for that as well as\nsome initial environments to demonstrate its use.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}, {'number': 7, 'created': '2017-06-12 20:15:06.000000000', 'files': ['sample-env-generator/predictable-placement.yaml', 'tripleo_heat_templates/environment_generator.py', 'environments/ssl/tls-endpoints-public-ip.yaml', 'sample-env-generator/README.rst', 'environments/ssl/enable-tls.yaml', 'environments/enable-tls.yaml', 'sample-env-generator/ssl.yaml', 'environments/ssl/tls-endpoints-public-dns.yaml', 'environments/tls-endpoints-public-ip.yaml', 'environments/tls-endpoints-public-dns.yaml', 'environments/ssl/tls-everywhere-endpoints-dns.yaml', 'tools/yaml-validate.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f503d1b0e7fb9fe77e6fd1e71e08ca2d43427578', 'message': ""Support config dir for env generator input files\n\nWe're not going to want to list every single sample environment in\na single file, so let's also take a directory and just read every\nyaml file in it.  This commit adds support for that as well as\nsome initial environments to demonstrate its use.\n\nChange-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c\n""}]",0,465647,f503d1b0e7fb9fe77e6fd1e71e08ca2d43427578,31,4,7,6928,,,0,"Support config dir for env generator input files

We're not going to want to list every single sample environment in
a single file, so let's also take a directory and just read every
yaml file in it.  This commit adds support for that as well as
some initial environments to demonstrate its use.

Change-Id: If2c608f2a61fc5e16784ab594d23f1fa335e1d3c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/465647/3 && git format-patch -1 --stdout FETCH_HEAD,"['sample-env-generator/ssl.yaml', 'sample-env-generator/predictable-placement.yaml', 'tripleo_heat_templates/environment_generator.py', 'sample-env-generator/README.rst', 'tox.ini', 'environments/storage/external-ceph.yaml']",6,d0908735ff3b41f4ad99e0ba15a5d631eb5cbc78,env-generator, OS::TripleO::Services::CephExternal: ../puppet/services/ceph-external.yaml OS::TripleO::Services::CephMon: OS::Heat::None, OS::TripleO::Services::CephMon: OS::Heat::None OS::TripleO::Services::CephExternal: ../puppet/services/ceph-external.yaml,38,188
openstack%2Ftripleo-heat-templates~master~I002cce176e3430473a29e79efde3464bddb24cc7,openstack/tripleo-heat-templates,master,I002cce176e3430473a29e79efde3464bddb24cc7,Update CloudDomain description,MERGED,2017-06-01 20:08:52.000000000,2017-06-19 15:26:27.000000000,2017-06-19 15:26:26.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-01 20:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bccfb9526ac72e42460f107f4a80802b87d6f4f2', 'message': 'Update CloudDomain description\n\nFirst, this parameter must match what is configured on the\nundercloud, so strengthen that language.\n\nAlso, neutron has deprecated dhcp_domain in favor of dns_domain.\nWe should start pointing people at the new name.  See:\nhttps://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html\n\nChange-Id: I002cce176e3430473a29e79efde3464bddb24cc7\n'}, {'number': 2, 'created': '2017-06-15 16:57:49.000000000', 'files': ['puppet/compute-role.yaml', 'overcloud.j2.yaml', 'puppet/cephstorage-role.yaml', 'puppet/role.role.j2.yaml', 'puppet/objectstorage-role.yaml', 'puppet/blockstorage-role.yaml', 'puppet/controller-role.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4f582439526751f7b12dfcad2a591ea531b6caa1', 'message': ""Update CloudDomain description\n\nFirst, this parameter must match what is configured on the\nundercloud, so strengthen that language.\n\nThere is also now an undercloud.conf parameter that can be used to\nset the requisite options on the undercloud services, so just point\nusers at that rather than trying to explain how to configure the\nservices manually (which is error-prone and doesn't survive\nundercloud updates).\n\nChange-Id: I002cce176e3430473a29e79efde3464bddb24cc7\n""}]",0,469996,4f582439526751f7b12dfcad2a591ea531b6caa1,15,4,2,6928,,,0,"Update CloudDomain description

First, this parameter must match what is configured on the
undercloud, so strengthen that language.

There is also now an undercloud.conf parameter that can be used to
set the requisite options on the undercloud services, so just point
users at that rather than trying to explain how to configure the
services manually (which is error-prone and doesn't survive
undercloud updates).

Change-Id: I002cce176e3430473a29e79efde3464bddb24cc7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/469996/2 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/compute-role.yaml', 'overcloud.j2.yaml', 'puppet/cephstorage-role.yaml', 'puppet/objectstorage-role.yaml', 'puppet/role.role.j2.yaml', 'puppet/blockstorage-role.yaml', 'puppet/controller-role.yaml']",7,bccfb9526ac72e42460f107f4a80802b87d6f4f2,cloud-domain-update, The DNS domain used for the hosts. This must match the dns_domain, The DNS domain used for the hosts. This should match the dhcp_domain,8,8
openstack%2Ftripleo-heat-templates~master~I8dca09372a58b6dacbb8e65602e1b0bdb6c01ae7,openstack/tripleo-heat-templates,master,I8dca09372a58b6dacbb8e65602e1b0bdb6c01ae7,Add an example IronicConductor role,MERGED,2017-06-13 11:22:03.000000000,2017-06-19 15:26:20.000000000,2017-06-19 15:26:19.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-13 11:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03352c07992c244b2f69101f6dba6fa9af3c54f3', 'message': 'Add an example Baremetal role for ironic-conductor nodes\n\nChange-Id: I8dca09372a58b6dacbb8e65602e1b0bdb6c01ae7\nRelated-Blueprint: example-custom-role-environments\n'}, {'number': 2, 'created': '2017-06-15 06:03:25.000000000', 'files': ['releasenotes/notes/baremetal-role-34cb48cc30d7bdb4.yaml', 'roles/IronicConductor.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/977b8ec502a6612e0014a60f1d05ea0b6a550600', 'message': 'Add an example IronicConductor role\n\nChange-Id: I8dca09372a58b6dacbb8e65602e1b0bdb6c01ae7\nRelated-Blueprint: example-custom-role-environments\n'}]",1,473788,977b8ec502a6612e0014a60f1d05ea0b6a550600,12,3,2,10239,,,0,"Add an example IronicConductor role

Change-Id: I8dca09372a58b6dacbb8e65602e1b0bdb6c01ae7
Related-Blueprint: example-custom-role-environments
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/88/473788/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/Baremetal.yaml', 'releasenotes/notes/baremetal-role-34cb48cc30d7bdb4.yaml']",2,03352c07992c244b2f69101f6dba6fa9af3c54f3,bp/example-custom-role-environments,--- features: - | Add an example role ``roles/Baremetal.yaml`` for an ironic-conductor node. ,,25,0
openstack%2Fopenstack-ansible-os_cinder~master~If5729671cb69f928df660ec2d9ba83fe3f567946,openstack/openstack-ansible-os_cinder,master,If5729671cb69f928df660ec2d9ba83fe3f567946,Ensure that services restart in a particular order,MERGED,2017-06-09 13:50:07.000000000,2017-06-19 15:22:12.000000000,2017-06-19 15:20:22.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 13095}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 22405}]","[{'number': 1, 'created': '2017-06-09 13:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/ce5480c7151adfbe24a8604d5ee789e86489a042', 'message': 'Ensure that services restart in a particular order\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 2, 'created': '2017-06-09 13:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/d03dd5e02080967c7f7bd6710b70de53a911731e', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 3, 'created': '2017-06-09 19:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/3d369d938bba462c27134c8678cb320e3fe39c10', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 4, 'created': '2017-06-09 19:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/c4b077429f2880528a24f425c891727eea14567d', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 5, 'created': '2017-06-12 11:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/e5acb2a33d1877d000238074807d5e2bb3d13009', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 6, 'created': '2017-06-12 12:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/b521ca183646cf7e989905487d379b628d92725e', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 7, 'created': '2017-06-12 12:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/5d49887ca26bc2bf6bc964b63784f3198055a44b', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 8, 'created': '2017-06-12 12:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/ee837f5ce9a7c4710df1dd532a6757895619678f', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 9, 'created': '2017-06-12 12:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/c8b0d1d5a04bd75ea59c6e7840f2f523655fab25', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 10, 'created': '2017-06-14 15:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/455bf9c8ee2b83c81b6ba6ee1731bbda4cefc516', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}, {'number': 11, 'created': '2017-06-19 12:25:27.000000000', 'files': ['handlers/main.yml', 'templates/cinder-systemd-init.j2', 'defaults/main.yml', 'templates/cinder-systemd-tmpfiles.j2', 'vars/main.yml', 'tasks/cinder_init_systemd.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/b98100fe0c71d075877f409d71af41d33ca07eda', 'message': 'Ensure that services restart in a particular order\n\nCurrently when multiple services share a host, the\nrestart order is random. This is due to an unordered\ndict being used to facilitate the mapping of services\nto their groups, names and other options.\n\nBased on [1], this patch implements changes to the role\nto ensure that services on the same host are restarted\nin the correct order when the software/config changes.\n\n[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure\n\nChange-Id: If5729671cb69f928df660ec2d9ba83fe3f567946\n'}]",1,472689,b98100fe0c71d075877f409d71af41d33ca07eda,48,6,11,6816,,,0,"Ensure that services restart in a particular order

Currently when multiple services share a host, the
restart order is random. This is due to an unordered
dict being used to facilitate the mapping of services
to their groups, names and other options.

Based on [1], this patch implements changes to the role
to ensure that services on the same host are restarted
in the correct order when the software/config changes.

[1] https://docs.openstack.org/developer/cinder/upgrade.html#minimal-downtime-upgrade-procedure

Change-Id: If5729671cb69f928df660ec2d9ba83fe3f567946
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/89/472689/8 && git format-patch -1 --stdout FETCH_HEAD,"['handlers/main.yml', 'templates/cinder-systemd-init.j2', 'defaults/main.yml', 'templates/cinder-systemd-tmpfiles.j2', 'vars/main.yml', 'tasks/cinder_init_systemd.yml']",6,ce5480c7151adfbe24a8604d5ee789e86489a042,rolling-upgrades," path: ""/var/run/{{ item.service_name }}"" with_items: ""{{ filtered_cinder_services }}"" path: ""/var/lock/{{ item.service_name }}"" with_items: ""{{ filtered_cinder_services }}"" path: ""/etc/tmpfiles.d/{{ item.service_name }}.conf"" with_items: ""{{ filtered_cinder_services }}"" dest: ""/etc/tmpfiles.d/openstack-{{ item.service_name }}.conf"" with_items: ""{{ filtered_cinder_services }}"" dest: ""/etc/systemd/system/{{ item.service_name }}.service"" config_overrides: ""{{ item.init_config_overrides }}"" with_items: ""{{ filtered_cinder_services }}"""," path: ""/var/run/{{ item.value.service_name }}"" with_dict: ""{{ filtered_cinder_services }}"" path: ""/var/lock/{{ item.value.service_name }}"" with_dict: ""{{ filtered_cinder_services }}"" path: ""/etc/tmpfiles.d/{{ item.value.service_name }}.conf"" with_dict: ""{{ filtered_cinder_services }}"" dest: ""/etc/tmpfiles.d/openstack-{{ item.value.service_name }}.conf"" with_dict: ""{{ filtered_cinder_services }}"" dest: ""/etc/systemd/system/{{ item.value.service_name }}.service"" config_overrides: ""{{ item.value.init_config_overrides }}"" with_dict: ""{{ filtered_cinder_services }}""",34,37
openstack%2Fopenstack-ansible-os_glance~master~I827dad684a259f15cdf24a59dfb26e05e1f7826d,openstack/openstack-ansible-os_glance,master,I827dad684a259f15cdf24a59dfb26e05e1f7826d,Pass packages to install as a list,MERGED,2017-06-08 14:11:31.000000000,2017-06-19 15:18:54.000000000,2017-06-19 15:04:59.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-08 14:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/4af6dc688e21646ecbb50668ebe896ad2175807f', 'message': 'Pass packages to install as a list\n\nInstead of using the slower loop, pass the\nlist directly to the install task to do\nthem all at once.\n\nChange-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d\n'}, {'number': 2, 'created': '2017-06-13 18:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/587374df1b48eaa5ad1cfcc063f71e4e788d4f99', 'message': 'Pass packages to install as a list\n\nInstead of using the slower loop, pass the\nlist directly to the install task to do\nthem all at once.\n\nChange-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d\n'}, {'number': 3, 'created': '2017-06-18 15:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/f565176d2d4e23484a15ac3db222542c66fdb5c3', 'message': 'Pass packages to install as a list\n\nInstead of using the slower loop, pass the\nlist directly to the install task to do\nthem all at once.\n\nChange-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d\n'}, {'number': 4, 'created': '2017-06-19 14:15:33.000000000', 'files': ['tasks/glance_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/eea85d2cd54d2d5eca2fdc8cb96230ad65b7d6fe', 'message': 'Pass packages to install as a list\n\nInstead of using the slower loop, pass the\nlist directly to the install task to do\nthem all at once.\n\nChange-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d\n'}]",0,472278,eea85d2cd54d2d5eca2fdc8cb96230ad65b7d6fe,30,4,4,6816,,,0,"Pass packages to install as a list

Instead of using the slower loop, pass the
list directly to the install task to do
them all at once.

Change-Id: I827dad684a259f15cdf24a59dfb26e05e1f7826d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/78/472278/4 && git format-patch -1 --stdout FETCH_HEAD,['tasks/glance_install.yml'],1,4af6dc688e21646ecbb50668ebe896ad2175807f,distro-pkg-optimise," name: ""{{ glance_distro_packages }}"""," name: ""{{ item }}"" with_items: ""{{ glance_distro_packages }}""",1,2
openstack%2Fhorizon~master~I467f5c5bba8c1b197c424d72efe67075ac599ceb,openstack/horizon,master,I467f5c5bba8c1b197c424d72efe67075ac599ceb,Remove unused injected module,MERGED,2017-06-19 14:18:35.000000000,2017-06-19 15:16:11.000000000,2017-06-19 15:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 12826}]","[{'number': 1, 'created': '2017-06-19 14:18:35.000000000', 'files': ['openstack_dashboard/static/app/core/network_qos/qos.module.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d08c6f6085370089f2104796159e040c548f316a', 'message': 'Remove unused injected module\n\nChange-Id: I467f5c5bba8c1b197c424d72efe67075ac599ceb\n'}]",0,475401,d08c6f6085370089f2104796159e040c548f316a,7,2,1,6763,,,0,"Remove unused injected module

Change-Id: I467f5c5bba8c1b197c424d72efe67075ac599ceb
",git fetch https://review.opendev.org/openstack/horizon refs/changes/01/475401/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/app/core/network_qos/qos.module.js'],1,d08c6f6085370089f2104796159e040c548f316a,, 'horizon.app.core.network_qos.resourceType'," 'horizon.app.core.network_qos.resourceType', 'horizon.app.core.openstack-service-api.neutron'",1,2
openstack%2Fopenstack-helm~master~I597889dd9e19ae672926b772d7ae38947ede26bc,openstack/openstack-helm,master,I597889dd9e19ae672926b772d7ae38947ede26bc,Fix cpu and memory limits for glance,MERGED,2017-06-18 06:22:33.000000000,2017-06-19 15:11:44.000000000,2017-06-19 15:11:28.000000000,"[{'_account_id': 3}, {'_account_id': 17591}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-06-18 06:22:33.000000000', 'files': ['glance/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8c4e1c0e2dca70ce9394209329d0087d076fcb03', 'message': 'Fix cpu and memory limits for glance\n\nCurrently, the memory and cpu limits are identical to the requests.\nThis patch set ups the limits to be similar to other services\nsuch as nova and neutron.\n\nChange-Id: I597889dd9e19ae672926b772d7ae38947ede26bc\n'}]",0,475159,8c4e1c0e2dca70ce9394209329d0087d076fcb03,12,5,1,20466,,,0,"Fix cpu and memory limits for glance

Currently, the memory and cpu limits are identical to the requests.
This patch set ups the limits to be similar to other services
such as nova and neutron.

Change-Id: I597889dd9e19ae672926b772d7ae38947ede26bc
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/59/475159/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/values.yaml'],1,8c4e1c0e2dca70ce9394209329d0087d076fcb03,fix-glance-limits," memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"""," memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m""",14,14
openstack%2Fvitrage~master~I3633fffebda984b8840e33ab69090f4cd2f34e71,openstack/vitrage,master,I3633fffebda984b8840e33ab69090f4cd2f34e71,event tempst test changes,MERGED,2017-06-18 12:46:39.000000000,2017-06-19 15:10:03.000000000,2017-06-19 15:10:03.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 19159}, {'_account_id': 19194}]","[{'number': 1, 'created': '2017-06-18 12:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/7712809960d70d4192214e04832101ef9459031d', 'message': 'event tempst test changes\n\nChange-Id: I3633fffebda984b8840e33ab69090f4cd2f34e71\n'}, {'number': 2, 'created': '2017-06-18 14:49:58.000000000', 'files': ['vitrage_tempest_tests/tests/utils.py', 'vitrage_tempest_tests/tests/api/event/test_events.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a9a43fdc1793bda2a16b80f0ce2589c53567d2ac', 'message': 'event tempst test changes\n\nChange-Id: I3633fffebda984b8840e33ab69090f4cd2f34e71\n'}]",5,475171,a9a43fdc1793bda2a16b80f0ce2589c53567d2ac,11,4,2,26095,,,0,"event tempst test changes

Change-Id: I3633fffebda984b8840e33ab69090f4cd2f34e71
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/71/475171/2 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_tests/tests/utils.py', 'vitrage_tempest_tests/tests/api/event/test_events.py']",2,7712809960d70d4192214e04832101ef9459031d,," def test_send_doctor_event_without_resource_id_v2(self): """"""Sending and event in Doctor format should result in an alarm"""""" details2 = { 'hostname': 'host457', 'source': 'sample_monitor', 'cause': 'another alarm', 'severity': 'critical', 'status': 'down', 'monitor_id': 'sample monitor', 'monitor_event_id': '103', } self._test_send_doctor_event(details2) api_alarms = self._wait_for_answer(2, 0.5, self._check_alarms) api_alarms = self._wait_for_answer(2, 0.5, self._check_alarms) self.assertIsNotNone(api_alarms, 'Expected host down alarm') self.assertEqual(0, len(api_alarms), 'Expected host down alarm') def _wait_for_answer(max_waiting, time_between_attempts, func, **kwargs): """"""time_between_attempts should be in range of 0 to 1"""""" time.sleep(time_between_attempts) start_time = time.time() run_time = time.time() - start_time count = count + time_between_attempts + run_time LOG.info(""wait for answer- False"")"," api_alarms = self._wait_for_status(2, self._check_alarms) self._wait_for_status(2, self._check_alarms) # TODO(iaffek) # self.assertIsNotNone(api_alarms, 'Expected host down alarm') # self.assertEqual(0, len(api_alarms), 'Expected host down alarm') def _wait_for_status(max_waiting, func, **kwargs): count += 1 time.sleep(2) LOG.info(""wait_for_status - False"")",43,12
openstack%2Fceilometer~master~Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377,openstack/ceilometer,master,Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377,Add share create/delete/expand/shrink meters,MERGED,2017-06-09 16:33:59.000000000,2017-06-19 15:03:30.000000000,2017-06-19 06:51:15.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6413}, {'_account_id': 6537}, {'_account_id': 8871}, {'_account_id': 15843}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-06-09 16:33:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fcd43c56d8198a5658b46b6fff5c7ce3f47e2571', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nWIP\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 2, 'created': '2017-06-12 22:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6b5056091af8df5b06ab8894fbf73ae33acbd8a0', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nWIP\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 3, 'created': '2017-06-13 21:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e7be1a2167aed0cb33b64ee5540242552e1ef5b4', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nWIP\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 4, 'created': '2017-06-14 19:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1af81d5bfbc4539697424294d5088e3f3f6d81aa', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nWIP\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 5, 'created': '2017-06-15 13:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/04ea28e87bbbe52ff8d13e9ae0823b94b85fd2fd', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 6, 'created': '2017-06-15 17:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a717b12c25bbb7c7ee533b9a50458e09a9107713', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 7, 'created': '2017-06-15 18:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9e0287f7dd797fcd563ea6591c3a9ae163e7eb51', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 8, 'created': '2017-06-16 15:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/97bce5d65448720624cc00b32c40c9af2dc078d8', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}, {'number': 9, 'created': '2017-06-16 15:18:37.000000000', 'files': ['ceilometer/gnocchi_client.py', 'ceilometer/dispatcher/data/gnocchi_resources.yaml', 'ceilometer/data/meters.d/meters.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d89b6c3b4c46ac4a2fb755f38a3faa63d0919d8b', 'message': 'Add share create/delete/expand/shrink meters\n\nPartially-Implements: blueprint manila-meters\n\nChange-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377\n'}]",8,472752,d89b6c3b4c46ac4a2fb755f38a3faa63d0919d8b,40,8,9,6413,,,0,"Add share create/delete/expand/shrink meters

Partially-Implements: blueprint manila-meters

Change-Id: Iaeb1e1ffc2b9c5f6e93f68f8b319066335781377
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/52/472752/8 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/data/meters.d/meters.yaml'],1,fcd43c56d8198a5658b46b6fff5c7ce3f47e2571,bp/manila-meters, # Manila - name: 'share.size' event_type: - 'share.create.*' - 'share.delete.*' - 'share.extend.*' - 'share.shrink.*' type: 'gauge' unit: 'GB' volume: $.payload.size user_id: $.payload.user_id project_id: $.payload.project_id resource_id: $.payload.share_id metadata: name: $.payload.name description: $.payload.description host: $.payload.host availability_zone: $.payload.availability_zone status: $.payload.status,,20,0
openstack%2Fneutron-fwaas~master~Ifb7c6eac155236a154308856e97432b182f0588e,openstack/neutron-fwaas,master,Ifb7c6eac155236a154308856e97432b182f0588e,Updated from global requirements,MERGED,2017-06-15 16:28:07.000000000,2017-06-19 15:00:28.000000000,2017-06-19 15:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 13702}, {'_account_id': 15905}]","[{'number': 1, 'created': '2017-06-15 16:28:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/cc85fe34fc416c34ae077e2a7419ec8b9e2935d2', 'message': 'Updated from global requirements\n\nChange-Id: Ifb7c6eac155236a154308856e97432b182f0588e\n'}]",0,474670,cc85fe34fc416c34ae077e2a7419ec8b9e2935d2,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: Ifb7c6eac155236a154308856e97432b182f0588e
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/70/474670/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cc85fe34fc416c34ae077e2a7419ec8b9e2935d2,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fneutron-fwaas~master~Ieb003a615111738687a17c7d056a536c21c32f6e,openstack/neutron-fwaas,master,Ieb003a615111738687a17c7d056a536c21c32f6e,Refactor find iptables rules,MERGED,2017-06-06 04:02:17.000000000,2017-06-19 14:57:39.000000000,2017-06-19 14:57:38.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7805}, {'_account_id': 10850}, {'_account_id': 12860}, {'_account_id': 13702}, {'_account_id': 15471}, {'_account_id': 15905}, {'_account_id': 17776}]","[{'number': 1, 'created': '2017-06-06 04:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/bbdcdd1184b64e53141cb14e269f58ea9912ea1d', 'message': 'Optimize find iptables rules\n\nUsing list comprehension instead of for loop, it will more efficiency\nwhich have large firewall rules.\n\nChange-Id: Ieb003a615111738687a17c7d056a536c21c32f6e\n'}, {'number': 2, 'created': '2017-06-16 01:52:50.000000000', 'files': ['neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/b360565c49a12e34f89838147fe00bfdf9786b71', 'message': ""Refactor find iptables rules\n\nUsing list comprehension instead of for loop, it's good for readability.\n\nTrivialFix\nChange-Id: Ieb003a615111738687a17c7d056a536c21c32f6e\n""}]",3,471196,b360565c49a12e34f89838147fe00bfdf9786b71,22,9,2,12860,,,0,"Refactor find iptables rules

Using list comprehension instead of for loop, it's good for readability.

TrivialFix
Change-Id: Ieb003a615111738687a17c7d056a536c21c32f6e
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/96/471196/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py'],1,bbdcdd1184b64e53141cb14e269f58ea9912ea1d,optimize_find_rules, fw_rule_ids = [fw_rule.get('id') for fw_rule in fw_rules_list] removed_rules = [pre_fw_rule for pre_fw_rule in pre_fw_rules_list if pre_fw_rule.get('id') not in fw_rule_ids], removed_rules = [] fw_rule_ids = [] for fw_rule in fw_rules_list: fw_rule_ids.append(fw_rule.get('id')) for pre_fw_rule in pre_fw_rules_list: if pre_fw_rule.get('id') not in fw_rule_ids: removed_rules.append(pre_fw_rule),3,7
openstack%2Fmanila~master~I350b9f45c1e2b2d08d8a73a9918cb37428c79653,openstack/manila,master,I350b9f45c1e2b2d08d8a73a9918cb37428c79653,Updated from global requirements,MERGED,2017-06-15 16:25:30.000000000,2017-06-19 14:56:49.000000000,2017-06-19 12:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15100}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 17565}, {'_account_id': 18128}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-06-15 16:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/393f8ce1fe5d08ac6dc09aa44c6c21002060a9bb', 'message': 'Updated from global requirements\n\nChange-Id: I350b9f45c1e2b2d08d8a73a9918cb37428c79653\n'}, {'number': 2, 'created': '2017-06-19 05:39:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/c61460aa85135caafbd7ffaa364e3db7422ca052', 'message': 'Updated from global requirements\n\nChange-Id: I350b9f45c1e2b2d08d8a73a9918cb37428c79653\n'}]",0,474654,c61460aa85135caafbd7ffaa364e3db7422ca052,41,14,2,11131,,,0,"Updated from global requirements

Change-Id: I350b9f45c1e2b2d08d8a73a9918cb37428c79653
",git fetch https://review.opendev.org/openstack/manila refs/changes/54/474654/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,393f8ce1fe5d08ac6dc09aa44c6c21002060a9bb,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Ftripleo-heat-templates~master~I9496de0e5cc670e0a370588a9471594b20fdadf3,openstack/tripleo-heat-templates,master,I9496de0e5cc670e0a370588a9471594b20fdadf3,Updated from global requirements,MERGED,2017-06-15 15:36:02.000000000,2017-06-19 14:49:41.000000000,2017-06-19 14:49:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-15 15:36:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/003dc541efa99b1f9e619f20b573f14cf9d66c73', 'message': 'Updated from global requirements\n\nChange-Id: I9496de0e5cc670e0a370588a9471594b20fdadf3\n'}, {'number': 2, 'created': '2017-06-15 22:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bca8df7f9d80a84dd7b81ecfecf3409e3d20e0a2', 'message': 'Updated from global requirements\n\nChange-Id: I9496de0e5cc670e0a370588a9471594b20fdadf3\n'}, {'number': 3, 'created': '2017-06-16 05:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f3d7ba058399e6936bf4614cd07f31cdaff46ff4', 'message': 'Updated from global requirements\n\nChange-Id: I9496de0e5cc670e0a370588a9471594b20fdadf3\n'}, {'number': 4, 'created': '2017-06-16 12:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/27a316eeecdfd988269abf95afa8fad3fa8ed2ad', 'message': 'Updated from global requirements\n\nChange-Id: I9496de0e5cc670e0a370588a9471594b20fdadf3\n'}, {'number': 5, 'created': '2017-06-19 05:49:23.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9786bf57d2ee41d77bdc7a89d119f2c17abd550e', 'message': 'Updated from global requirements\n\nChange-Id: I9496de0e5cc670e0a370588a9471594b20fdadf3\n'}]",0,474614,9786bf57d2ee41d77bdc7a89d119f2c17abd550e,20,3,5,11131,,,0,"Updated from global requirements

Change-Id: I9496de0e5cc670e0a370588a9471594b20fdadf3
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/474614/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,003dc541efa99b1f9e619f20b573f14cf9d66c73,openstack/requirements,"coverage!=4.4,>=4.0 # Apache-2.0 fixtures>=3.0.0 # Apache-2.0/BSD python-subunit>=0.0.18 # Apache-2.0/BSD testrepository>=0.0.18 # Apache-2.0/BSD testscenarios>=0.4 # Apache-2.0/BSD testtools>=1.4.0 # MIT mock>=2.0 # BSD oslotest>=1.10.0 # Apache-2.0","coverage>=4.0,!=4.4 # Apache-2.0 fixtures>=3.0.0 # Apache-2.0/BSD python-subunit>=0.0.18 # Apache-2.0/BSD testrepository>=0.0.18 # Apache-2.0/BSD testscenarios>=0.4 # Apache-2.0/BSD testtools>=1.4.0 # MIT mock>=2.0 # BSD oslotest>=1.10.0 # Apache-2.0",8,8
openstack%2Ftripleo-quickstart-extras~master~I9e2c6db1461ad5b867e8930cb1f7ef69ae2b8d34,openstack/tripleo-quickstart-extras,master,I9e2c6db1461ad5b867e8930cb1f7ef69ae2b8d34,Define docker mirror only if it's not empty,MERGED,2017-06-11 15:37:49.000000000,2017-06-19 14:49:35.000000000,2017-06-19 14:49:35.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 8652}, {'_account_id': 10022}, {'_account_id': 12715}, {'_account_id': 13039}]","[{'number': 1, 'created': '2017-06-11 15:37:49.000000000', 'files': ['roles/undercloud-deploy/templates/undercloud.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/bec8020e3dcf92b2abd1934604f0ce1a6c87f1d5', 'message': ""Define docker mirror only if it's not empty\n\nDocker mirror could be empty and it means it's not defined.\nUse strict condition check here.\n\nChange-Id: I9e2c6db1461ad5b867e8930cb1f7ef69ae2b8d34\n""}]",0,473098,bec8020e3dcf92b2abd1934604f0ce1a6c87f1d5,12,9,1,10969,,,0,"Define docker mirror only if it's not empty

Docker mirror could be empty and it means it's not defined.
Use strict condition check here.

Change-Id: I9e2c6db1461ad5b867e8930cb1f7ef69ae2b8d34
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/98/473098/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/undercloud-deploy/templates/undercloud.conf.j2'],1,bec8020e3dcf92b2abd1934604f0ce1a6c87f1d5,cont,{% if undercloud_docker_registry_mirror is defined and undercloud_docker_registry_mirror %},{% if undercloud_docker_registry_mirror is defined %},1,1
openstack%2Fkolla-ansible~stable%2Focata~I0af4e315a35c3e43df41b36f54777a056a83ddfe,openstack/kolla-ansible,stable/ocata,I0af4e315a35c3e43df41b36f54777a056a83ddfe,Fix log rotation issue on services,MERGED,2017-06-19 10:59:43.000000000,2017-06-19 14:48:04.000000000,2017-06-19 14:48:04.000000000,"[{'_account_id': 3}, {'_account_id': 8157}, {'_account_id': 10787}]","[{'number': 1, 'created': '2017-06-19 10:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b1072cc3ba4910ac538c65a6565a1ded54589e25', 'message': 'Fix log rotation issue on services\n\nThis patch fix log rotation issue on the following services/program:\n- ceph\n- chrony\n- collectd\n- congress\n- etcd\n- influxdb\n- ironic\n- kibana\n- kuryr\n- mongodb\n- rally\n- tempest\n- trove\n\nNOTE: missed some services in cron.json in previous\ncherry-pick, also fix a typo in mongodb.\n\nChange-Id: I0af4e315a35c3e43df41b36f54777a056a83ddfe\nCloses-Bug: #1688649\n'}, {'number': 2, 'created': '2017-06-19 11:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c307dd18d0c1717fd4fe477af265c30988d15eb1', 'message': 'Fix log rotation issue on services\n\nThis patch fix log rotation issue on the following services/program:\n- ceph\n- chrony\n- collectd\n- congress\n- etcd\n- influxdb\n- ironic\n- kibana\n- kuryr\n- mongodb\n- rally\n- tempest\n- trove\n\nNOTE: missed some services in cron.json in previous\ncherry-pick [0], also fix a typo in mongodb.\n\nPrevious cherry-pick cannot be cherry-picked in this one because\nit is closed.\n\n[0] https://review.openstack.org/#/c/463057/\nChange-Id: I0af4e315a35c3e43df41b36f54777a056a83ddfe\nCloses-Bug: #1688649\n'}, {'number': 3, 'created': '2017-06-19 11:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/667744bacb0bedfa6679565a2c926843aaf84827', 'message': 'Fix log rotation issue on services\n\nThis patch fix log rotation issue on the following services/program:\n- ceph\n- chrony\n- collectd\n- congress\n- etcd\n- influxdb\n- ironic\n- kibana\n- kuryr\n- mongodb\n- rally\n- tempest\n- trove\n\nNOTE: missed some services in cron.json in previous\ncherry-pick [0], also fix a typo in mongodb.\n\nPrevious cherry-pick cannot be cherry-picked in this one because\nit is closed.\n\n[0] https://review.openstack.org/#/c/463057/\nChange-Id: I0af4e315a35c3e43df41b36f54777a056a83ddfe\nCloses-Bug: #1698790\n'}, {'number': 4, 'created': '2017-06-19 11:21:20.000000000', 'files': ['ansible/roles/common/templates/cron.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/66b2ea2c584443608b79303c9e92d6676c933b18', 'message': 'Fix log rotation issue on services\n\nThis patch fix log rotation issue on the following services/program:\n- ceph\n- chrony\n- collectd\n- congress\n- etcd\n- influxdb\n- ironic\n- kibana\n- kuryr\n- mongodb\n- rally\n- tempest\n- trove\n\nNOTE: missed some services in cron.json in previous\ncherry-pick [0], also fix a typo in mongodb.\n\nPrevious cherry-pick cannot be cherry-picked in this one because\nit is closed.\n\n[0] https://review.openstack.org/#/c/463057/\nChange-Id: I0af4e315a35c3e43df41b36f54777a056a83ddfe\nCloses-Bug: #1698790\n'}]",0,475330,66b2ea2c584443608b79303c9e92d6676c933b18,11,3,4,19316,,,0,"Fix log rotation issue on services

This patch fix log rotation issue on the following services/program:
- ceph
- chrony
- collectd
- congress
- etcd
- influxdb
- ironic
- kibana
- kuryr
- mongodb
- rally
- tempest
- trove

NOTE: missed some services in cron.json in previous
cherry-pick [0], also fix a typo in mongodb.

Previous cherry-pick cannot be cherry-picked in this one because
it is closed.

[0] https://review.openstack.org/#/c/463057/
Change-Id: I0af4e315a35c3e43df41b36f54777a056a83ddfe
Closes-Bug: #1698790
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/30/475330/3 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/templates/cron.json.j2'],1,b1072cc3ba4910ac538c65a6565a1ded54589e25,bug/1698790," ( 'ceph', enable_ceph ), ( 'chrony', enable_chrony ), ( 'collectd', enable_collectd ), ( 'congress', enable_congress ), ( 'etcd', enable_etcd ), ( 'influxdb', enable_influxdb ), ( 'ironic', enable_ironic ), ( 'kibana', enable_kibana ), ( 'kuryr', enable_kuryr ), ( 'mongodb', enable_mongodb ), ( 'rally', enable_rally ),"," ( 'watcher', enable_watcher )",11,1
openstack%2Fkolla-ansible~master~I7b542cacb9f21dd84a7e3864c7cd95565dbbf8fb,openstack/kolla-ansible,master,I7b542cacb9f21dd84a7e3864c7cd95565dbbf8fb,Add documetation for kolla-mergepwd tool,MERGED,2017-06-19 13:59:18.000000000,2017-06-19 14:45:49.000000000,2017-06-19 14:45:49.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 10787}, {'_account_id': 13671}, {'_account_id': 19316}]","[{'number': 1, 'created': '2017-06-19 13:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/64121be5103c0e1db1e17e86833887d247125797', 'message': 'Add documetation for kolla-mergepwd tool\n\nChange-Id: I7b542cacb9f21dd84a7e3864c7cd95565dbbf8fb\nImplements: blueprint kolla-merge-passwords\n'}, {'number': 2, 'created': '2017-06-19 14:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/13e0b6c0b5e956ae8d9764ca1b5916d261c82a15', 'message': 'Add documetation for kolla-mergepwd tool\n\nChange-Id: I7b542cacb9f21dd84a7e3864c7cd95565dbbf8fb\nImplements: blueprint kolla-merge-passwords\n'}, {'number': 3, 'created': '2017-06-19 14:11:00.000000000', 'files': ['doc/operating-kolla.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ea5d1a581b1ed3d0f35a5cbc23f28e1e3e5ad9ec', 'message': 'Add documetation for kolla-mergepwd tool\n\nChange-Id: I7b542cacb9f21dd84a7e3864c7cd95565dbbf8fb\nImplements: blueprint kolla-merge-passwords\n'}]",5,475392,ea5d1a581b1ed3d0f35a5cbc23f28e1e3e5ad9ec,14,5,3,13671,,,0,"Add documetation for kolla-mergepwd tool

Change-Id: I7b542cacb9f21dd84a7e3864c7cd95565dbbf8fb
Implements: blueprint kolla-merge-passwords
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/92/475392/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/operating-kolla.rst'],1,64121be5103c0e1db1e17e86833887d247125797,bp/kolla-merge-passwords," ``kolla-mergepwd --old OLD_PASSWORDS --new NEW_PASSWORDS --dest FINAL_PASSWORDS`` is used to merge passwords from old intallation with newly generated passwords during upgrade of Kolla release. The workflow is: - save old passwords from ``/etc/kolla/passwords.yml`` into ``passwords.yml.old`` - generate new passwords via ``kolla-genpwd``, move it to ``passwords.new`` - merge ``passwords.yml.old`` and ``passwords.yml.new`` into ``/etc/kolla/passwords.yml`` For example:: mv /etc/kolla/passwords.yml passwords.yml.old cp kolla-ansible/etc/kolla/passwords.yml passwords.yml.new kolla-genpwd -p passwords.yml.new kolla-mergepwd --old passwords.yml.old --new passwords.yml.new --dest /etc/kolla/passwords.yml",,15,0
openstack%2Fopenstack-ansible-repo_server~master~I33f4905363d102f65cda8769d1ff95bbce8f08f8,openstack/openstack-ansible-repo_server,master,I33f4905363d102f65cda8769d1ff95bbce8f08f8,Split user create and ssh key generation,MERGED,2017-06-15 19:06:46.000000000,2017-06-19 14:42:05.000000000,2017-06-19 14:39:49.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 15993}]","[{'number': 1, 'created': '2017-06-15 19:06:46.000000000', 'files': ['tasks/repo_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/891ba5de71ecb6ece264cb0c18716279cbe807c7', 'message': 'Split user create and ssh key generation\n\nIn order to allow an install and config split, but not\nto have ssh keys left inside an pre-installed container,\nthe two tasks are split and tagged appropriately.\n\nChange-Id: I33f4905363d102f65cda8769d1ff95bbce8f08f8\n'}]",0,474730,891ba5de71ecb6ece264cb0c18716279cbe807c7,13,3,1,6816,,,0,"Split user create and ssh key generation

In order to allow an install and config split, but not
to have ssh keys left inside an pre-installed container,
the two tasks are split and tagged appropriately.

Change-Id: I33f4905363d102f65cda8769d1ff95bbce8f08f8
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/30/474730/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/repo_post_install.yml'],1,891ba5de71ecb6ece264cb0c18716279cbe807c7,artifacts,"- name: Generate the nginx system user ssh key user: name: ""{{ repo_service_user_name }}"" generate_ssh_key: ""yes"" tags: - pkg-repo-user - repo-key - repo-key-create - repo_server-config "," generate_ssh_key: ""yes""",10,1
openstack%2Fheat~master~I33af16bdf4f20a35224bcecb19497960fddf5216,openstack/heat,master,I33af16bdf4f20a35224bcecb19497960fddf5216,Release notes for storing resource attributes,ABANDONED,2017-05-04 22:00:56.000000000,2017-06-19 14:40:59.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}]","[{'number': 1, 'created': '2017-05-04 22:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4abe3769be1726e77a7d140f447956470e79af36', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 2, 'created': '2017-05-25 00:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c80b1c846972905406335e948af0abcc2c5737f0', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 3, 'created': '2017-06-01 00:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e4049a92e8cca79c901aa3ef16b641e127dbc197', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 4, 'created': '2017-06-01 23:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/439ac682038a4628f2eac606e855caae12544ee0', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 5, 'created': '2017-06-02 17:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/12832e6393932834c2953f29e3e766da931b8472', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 6, 'created': '2017-06-06 03:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/59c433b37fb8588548a1c6ee920f21317dc804c8', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 7, 'created': '2017-06-09 02:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e129f909804f99823be6d5e498d61715d1c27c3', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}, {'number': 8, 'created': '2017-06-13 18:41:52.000000000', 'files': ['releasenotes/notes/store-resource-attributes-8bcbedca2f86986e.yaml'], 'web_link': 'https://opendev.org/openstack/heat/commit/6c756c2f92363f1fb00d56e7ac240e0242dcde2c', 'message': 'Release notes for storing resource attributes\n\nChange-Id: I33af16bdf4f20a35224bcecb19497960fddf5216\n'}]",0,462747,6c756c2f92363f1fb00d56e7ac240e0242dcde2c,18,2,8,13564,,,0,"Release notes for storing resource attributes

Change-Id: I33af16bdf4f20a35224bcecb19497960fddf5216
",git fetch https://review.opendev.org/openstack/heat refs/changes/47/462747/5 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/store-resource-attributes-8bcbedca2f86986e.yaml'],1,4abe3769be1726e77a7d140f447956470e79af36,,"--- features: - Resource attributes now are stored in the database when the convergence engine is enabled. Previously, outside of a create or update traversal, attributes always had to be re-resolved. E.g., showing stack outputs that referred to resource attributes required re-resolving those attributes. Now, the attributes are retrieved directly from database avoiding what had been an expensive operation, particularly if it meant resolving through multiple nested stacks. - Stored resource attributes do not persist through resource updates, ensuring that stale attribute data does not get passed along to those that require it. However, they do persist while the resource remains CREATE_COMPLETE or UPDATE_COMPLETE. ",,14,0
openstack%2Fdiskimage-builder~master~Id67c0cf08728407d234976f9807d3bd71d12f758,openstack/diskimage-builder,master,Id67c0cf08728407d234976f9807d3bd71d12f758,Install systemd earlier for Stretch,MERGED,2017-06-19 01:41:49.000000000,2017-06-19 14:37:35.000000000,2017-06-19 13:22:34.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}, {'_account_id': 21741}]","[{'number': 1, 'created': '2017-06-19 01:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c7858dbedd5814376ceffb11074f37788a166774', 'message': 'Install systemd earlier for strech\n\nDebian stretch released as stable recently, and the init system is\nless tightly specified in the base dependencies (for some info, see\n[1]).  It seems, probably unintentionally, that in the previous\nrelease systemd-sysv was brought in by debootstrap, but that is no\nlonger happening.\n\nAdd systemd as an early dependency of debian-minimal.\n\nRemove the package-installs.yaml as that happens too late (other\nthings need to know the init system to write out service files, etc\nand probe for systemd utils before package-installs).  As mentioned, I\ndo not believe the ""only install systemd on testing"" idea was actually\nworking here, because it was being brought in during the initial\ndebootstrap.\n\nUpdate some documentation to explain what\'s going on\n\n[1] https://lists.debian.org/debian-boot/2015/05/msg00156.html\n\nChange-Id: Id67c0cf08728407d234976f9807d3bd71d12f758\n'}, {'number': 2, 'created': '2017-06-19 01:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f119b5dd98f5343e079f68400eb6e7ed3a6eb1be', 'message': 'Install systemd earlier for Stretch\n\nDebian Stretch released as stable recently, and the init system is\nless tightly specified in the base dependencies (for some info, see\n[1]).  It seems, probably unintentionally, that in the previous\nrelease systemd-sysv was brought in by debootstrap, but that is no\nlonger happening.\n\nAdd systemd as an early dependency of debian-minimal.\n\nRemove the package-installs.yaml as that happens too late (other\nthings need to know the init system to write out service files, etc\nand probe for systemd utils before package-installs).  As mentioned, I\ndo not believe the ""only install systemd on testing"" idea was actually\nworking here, because it was being brought in during the initial\ndebootstrap.\n\nUpdate some documentation to explain what\'s going on\n\n[1] https://lists.debian.org/debian-boot/2015/05/msg00156.html\n\nChange-Id: Id67c0cf08728407d234976f9807d3bd71d12f758\n'}, {'number': 3, 'created': '2017-06-19 03:27:50.000000000', 'files': ['diskimage_builder/elements/debian-upstart/README.rst', 'diskimage_builder/elements/debian-systemd/README.rst', 'diskimage_builder/elements/debian-minimal/pkg-map', 'diskimage_builder/elements/debian-minimal/README.rst', 'diskimage_builder/elements/debian-minimal/root.d/75-debian-minimal-baseinstall', 'diskimage_builder/elements/debian-minimal/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a0f747932d0ef321355f62205d2e47b93ddc06dd', 'message': 'Install systemd earlier for Stretch\n\nDebian Stretch released as stable recently, and the init system is\nless tightly specified in the base dependencies (for some info, see\n[1]).  It seems, probably unintentionally, that in the previous\nrelease systemd-sysv was brought in by debootstrap, but that is no\nlonger happening.\n\nAdd systemd as an early dependency of debian-minimal.\n\nRemove the package-installs.yaml as that happens too late (other\nthings need to know the init system to write out service files, etc\nand probe for systemd utils before package-installs).  As mentioned, I\ndo not believe the ""only install systemd on testing"" idea was actually\nworking here, because it was being brought in during the initial\ndebootstrap.\n\nUpdate some documentation to explain what\'s going on\n\n[1] https://lists.debian.org/debian-boot/2015/05/msg00156.html\n\nChange-Id: Id67c0cf08728407d234976f9807d3bd71d12f758\n'}]",2,475206,a0f747932d0ef321355f62205d2e47b93ddc06dd,29,4,3,7118,,,0,"Install systemd earlier for Stretch

Debian Stretch released as stable recently, and the init system is
less tightly specified in the base dependencies (for some info, see
[1]).  It seems, probably unintentionally, that in the previous
release systemd-sysv was brought in by debootstrap, but that is no
longer happening.

Add systemd as an early dependency of debian-minimal.

Remove the package-installs.yaml as that happens too late (other
things need to know the init system to write out service files, etc
and probe for systemd utils before package-installs).  As mentioned, I
do not believe the ""only install systemd on testing"" idea was actually
working here, because it was being brought in during the initial
debootstrap.

Update some documentation to explain what's going on

[1] https://lists.debian.org/debian-boot/2015/05/msg00156.html

Change-Id: Id67c0cf08728407d234976f9807d3bd71d12f758
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/06/475206/3 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage_builder/elements/debian-upstart/README.rst', 'diskimage_builder/elements/debian-systemd/README.rst', 'diskimage_builder/elements/debian-minimal/pkg-map', 'diskimage_builder/elements/debian-minimal/README.rst', 'diskimage_builder/elements/debian-minimal/root.d/75-debian-minimal-baseinstall', 'diskimage_builder/elements/debian-minimal/package-installs.yaml']",6,c7858dbedd5814376ceffb11074f37788a166774,debian-stretch,,systemd: systemd-sysv:,21,19
openstack%2Fpython-tripleoclient~stable%2Fnewton~I8bd16e9753618e4c234440d7a6626e0ce4bd9972,openstack/python-tripleoclient,stable/newton,I8bd16e9753618e4c234440d7a6626e0ce4bd9972,Fix return code when failing before launching the stack,MERGED,2017-06-12 08:22:40.000000000,2017-06-19 14:36:43.000000000,2017-06-19 14:36:43.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}]","[{'number': 1, 'created': '2017-06-12 08:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/50a53159978d4d0eac1773fd13c0b9530e3e88a1', 'message': ""Fix return code when failing before launching the stack\n\nUntil now when a configuration error was detected early during the\npre-deployment verifications, the command would correctly return before\nattempting to create/update the Heat stack, however the return code\nwould still show as '0', preventing scripts from picking up the\nproblem.\n\nConflicts:\n  tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py\n  tripleoclient/v1/overcloud_deploy.py\n\nChange-Id: I8bd16e9753618e4c234440d7a6626e0ce4bd9972\nCloses-Bug: #1672790\n(cherry picked from commit 28051613c9c1c5231140981fca76fa704af55d5d)\n""}, {'number': 2, 'created': '2017-06-19 09:29:15.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'releasenotes/notes/return-code-on-predeploy-failure-bd62025646e25433.yaml', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bb361f47bf9bfad79af0c062fa1107386e769faa', 'message': ""Fix return code when failing before launching the stack\n\nUntil now when a configuration error was detected early during the\npre-deployment verifications, the command would correctly return before\nattempting to create/update the Heat stack, however the return code\nwould still show as '0', preventing scripts from picking up the\nproblem.\n\nConflicts:\n  tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py\n  tripleoclient/v1/overcloud_deploy.py\n\nChange-Id: I8bd16e9753618e4c234440d7a6626e0ce4bd9972\nCloses-Bug: #1672790\n(cherry picked from commit 28051613c9c1c5231140981fca76fa704af55d5d)\n""}]",0,473302,bb361f47bf9bfad79af0c062fa1107386e769faa,13,3,2,4978,,,0,"Fix return code when failing before launching the stack

Until now when a configuration error was detected early during the
pre-deployment verifications, the command would correctly return before
attempting to create/update the Heat stack, however the return code
would still show as '0', preventing scripts from picking up the
problem.

Conflicts:
  tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py
  tripleoclient/v1/overcloud_deploy.py

Change-Id: I8bd16e9753618e4c234440d7a6626e0ce4bd9972
Closes-Bug: #1672790
(cherry picked from commit 28051613c9c1c5231140981fca76fa704af55d5d)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/02/473302/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'releasenotes/notes/return-code-on-predeploy-failure-bd62025646e25433.yaml', 'tripleoclient/v1/overcloud_deploy.py']",3,50a53159978d4d0eac1773fd13c0b9530e3e88a1,bug/1672790, raise exceptions.InvalidConfiguration() raise exceptions.InvalidConfiguration(), return return,34,2
openstack%2Fopenstack-ansible-os_horizon~master~Id5ae1c742511910f033800d6d9dc18cc3b71842e,openstack/openstack-ansible-os_horizon,master,Id5ae1c742511910f033800d6d9dc18cc3b71842e,Install curl for translations update,MERGED,2017-06-19 12:22:34.000000000,2017-06-19 14:31:27.000000000,2017-06-19 14:31:27.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 15993}]","[{'number': 1, 'created': '2017-06-19 12:22:34.000000000', 'files': ['tasks/horizon_translations_update.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/d520752ea87e3d5752693472144092bfb726cfad', 'message': ""Install curl for translations update\n\nWe need curl setup in order to run the pull_catalog command that is\na part of Horizon itself.\n\nThis is only required for our translations update path, and isn't\nrequired usually.\n\nChange-Id: Id5ae1c742511910f033800d6d9dc18cc3b71842e\n""}]",0,475365,d520752ea87e3d5752693472144092bfb726cfad,8,3,1,2799,,,0,"Install curl for translations update

We need curl setup in order to run the pull_catalog command that is
a part of Horizon itself.

This is only required for our translations update path, and isn't
required usually.

Change-Id: Id5ae1c742511910f033800d6d9dc18cc3b71842e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/65/475365/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/horizon_translations_update.yml'],1,d520752ea87e3d5752693472144092bfb726cfad,,"- name: Ensure curl is installed package: name: curl state: ""{{ horizon_package_state }}"" register: install_packages until: install_packages|success retries: 5 delay: 2 ",,9,0
openstack%2Fnova~master~Id134f7745111ccd12695bb041fcce182e833126a,openstack/nova,master,Id134f7745111ccd12695bb041fcce182e833126a,Amend api-ref for multiple networks request,MERGED,2017-06-09 15:17:29.000000000,2017-06-19 14:28:13.000000000,2017-06-19 14:28:13.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5754}, {'_account_id': 8864}, {'_account_id': 15751}, {'_account_id': 16128}]","[{'number': 1, 'created': '2017-06-09 15:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dba76979178fc6326b45b6dba6b13eb25f7e34a5', 'message': ""Amend api-ref for multiple networks request\n\nSince there are chances that the guest OS won't honor the order of networks\nand assign NIC#1 to the second requested network, we say to our users to\nrather use device tagging and metadata querying.\nAmending the api-ref to mention explicitly that Nova doesn't support NIC\nordering although there are codepaths for that which try that.\n\nChange-Id: Id134f7745111ccd12695bb041fcce182e833126a\nRelated-Bug: #1696664\n""}, {'number': 2, 'created': '2017-06-09 15:48:41.000000000', 'files': ['api-ref/source/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/7d7cc942211f0523f970dd6c1268d1d778aed8a7', 'message': ""Amend api-ref for multiple networks request\n\nSince there are chances that the guest OS won't honor the order of networks\nand assign NIC#1 to the second requested network, we say to our users to\nrather use device tagging and metadata querying.\nAmending the api-ref to mention explicitly that Nova doesn't support NIC\nordering although there are codepaths for that which try that.\n\nChange-Id: Id134f7745111ccd12695bb041fcce182e833126a\nRelated-Bug: #1696664\n""}]",1,472733,7d7cc942211f0523f970dd6c1268d1d778aed8a7,20,6,2,7166,,,0,"Amend api-ref for multiple networks request

Since there are chances that the guest OS won't honor the order of networks
and assign NIC#1 to the second requested network, we say to our users to
rather use device tagging and metadata querying.
Amending the api-ref to mention explicitly that Nova doesn't support NIC
ordering although there are codepaths for that which try that.

Change-Id: Id134f7745111ccd12695bb041fcce182e833126a
Related-Bug: #1696664
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/472733/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/parameters.yaml'],1,dba76979178fc6326b45b6dba6b13eb25f7e34a5,bug/1696664," If you pass more than one port or network, the ordering you propose won't necessarly be honored for the guest NICS order.",,2,0
openstack%2Fopenstack-helm~master~I16985e622bdca95d88585d2f1e5bbb09e7dc766b,openstack/openstack-helm,master,I16985e622bdca95d88585d2f1e5bbb09e7dc766b,Fix cpu and memory limits for keystone,MERGED,2017-06-18 06:16:56.000000000,2017-06-19 14:24:14.000000000,2017-06-19 14:24:05.000000000,"[{'_account_id': 3}, {'_account_id': 17591}, {'_account_id': 21420}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-06-18 06:16:56.000000000', 'files': ['keystone/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9b6e57aa6b9d8fb0e1b72d6a893965361e2b07ba', 'message': 'Fix cpu and memory limits for keystone\n\nCurrently, the memory and cpu limits are identical to the requests.\nThis patch set ups the limits to be similar to other services\nsuch as nova and neutron.\n\nChange-Id: I16985e622bdca95d88585d2f1e5bbb09e7dc766b\n'}]",0,475158,9b6e57aa6b9d8fb0e1b72d6a893965361e2b07ba,13,5,1,20466,,,0,"Fix cpu and memory limits for keystone

Currently, the memory and cpu limits are identical to the requests.
This patch set ups the limits to be similar to other services
such as nova and neutron.

Change-Id: I16985e622bdca95d88585d2f1e5bbb09e7dc766b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/58/475158/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/values.yaml'],1,9b6e57aa6b9d8fb0e1b72d6a893965361e2b07ba,fix-limits," memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"" memory: ""1024Mi"" cpu: ""2000m"""," memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m"" memory: ""128Mi"" cpu: ""500m""",10,10
openstack%2Fpython-tripleoclient~stable%2Fnewton~Ie1d4f179492c8018d128332b3fa5c0dd35be0e03,openstack/python-tripleoclient,stable/newton,Ie1d4f179492c8018d128332b3fa5c0dd35be0e03,Add ssl development headers to bindep,MERGED,2017-06-12 11:13:44.000000000,2017-06-19 14:24:11.000000000,2017-06-19 14:24:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9317}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-06-12 11:13:44.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d3e0ca5822c54de5f4d2e81e294cc1e1877e2921', 'message': 'Add ssl development headers to bindep\n\nThis is needed to compile cryptography.\n\nChange-Id: Ie1d4f179492c8018d128332b3fa5c0dd35be0e03\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n(cherry picked from commit e04dcd2d7c29adec587e770c4e7f6c3c7cc79add)\nCloses-Bug: #1697421\n'}]",0,473374,d3e0ca5822c54de5f4d2e81e294cc1e1877e2921,16,4,1,4978,,,0,"Add ssl development headers to bindep

This is needed to compile cryptography.

Change-Id: Ie1d4f179492c8018d128332b3fa5c0dd35be0e03
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
(cherry picked from commit e04dcd2d7c29adec587e770c4e7f6c3c7cc79add)
Closes-Bug: #1697421
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/74/473374/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,d3e0ca5822c54de5f4d2e81e294cc1e1877e2921,,libssl-dev [platform:dpkg test] openssl-devel [platform:rpm test],,2,0
openstack%2Fopenstack-ansible-galera_server~master~If442802f7aff4473cbb573ba1c123cfc46bde9b3,openstack/openstack-ansible-galera_server,master,If442802f7aff4473cbb573ba1c123cfc46bde9b3,tasks: Set Restart option for systemd service file,MERGED,2017-06-05 12:13:07.000000000,2017-06-19 14:20:01.000000000,2017-06-19 14:20:01.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-05 12:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/763538e08a1abfa32bb1c537e0d71278eff43871', 'message': ""tasks: Set Restart option for systemd service file\n\nIn order to have a consistent systemd behavior across distributions, we\ndefine the Restart condition for the galera service file. The 'on-abort'\noption is currently the default in the upstream service file and it's\nalso the most conservative one so we chose that to be the default option\nin the Ansible role as well. We also set a reasonably low RestartSec\nvalue as well.\n\nChange-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3\n""}, {'number': 2, 'created': '2017-06-06 13:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/453828d3158835a43fadf5db49d30e77c45a866d', 'message': ""tasks: Set Restart option for systemd service file\n\nIn order to have a consistent systemd behavior across distributions, we\ndefine the Restart condition for the galera service file. The 'on-abort'\noption is currently the default in the upstream service file and it's\nalso the most conservative one so we chose that to be the default option\nin the Ansible role as well. We also set a reasonably low RestartSec\nvalue as well.\n\nChange-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3\n""}, {'number': 3, 'created': '2017-06-06 15:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/7822f91957b54e64d1cbe0c507d5361444e82e18', 'message': ""tasks: Set Restart option for systemd service file\n\nIn order to have a consistent systemd behavior across distributions, we\ndefine the Restart condition for the galera service file. The 'on-abort'\noption is currently the default in the upstream service file and it's\nalso the most conservative one so we chose that to be the default option\nin the Ansible role as well. We also set a reasonably low RestartSec\nvalue as well.\n\nChange-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3\n""}, {'number': 4, 'created': '2017-06-09 15:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/3bdb2242753664d0107eeb0a0a075de54e2a7311', 'message': ""tasks: Set Restart option for systemd service file\n\nIn order to have a consistent systemd behavior across distributions, we\ndefine the Restart condition for the galera service file. The 'on-abort'\noption is currently the default in the upstream service file and it's\nalso the most conservative one so we chose that to be the default option\nin the Ansible role as well. We also set a reasonably low RestartSec\nvalue as well.\n\nChange-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3\n""}, {'number': 5, 'created': '2017-06-09 19:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/daee85df501f5e7f36508f9121eb9e77938718f1', 'message': ""tasks: Set Restart option for systemd service file\n\nIn order to have a consistent systemd behavior across distributions, we\ndefine the Restart condition for the galera service file. The 'on-abort'\noption is currently the default in the upstream service file and it's\nalso the most conservative one so we chose that to be the default option\nin the Ansible role as well. We also set a reasonably low RestartSec\nvalue as well.\n\nChange-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3\n""}, {'number': 6, 'created': '2017-06-14 15:32:22.000000000', 'files': ['templates/systemd.restart.conf.j2', 'tasks/galera_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/bea68f18cc75138cc1465dd56dbe8d957f8242ad', 'message': ""tasks: Set Restart option for systemd service file\n\nIn order to have a consistent systemd behavior across distributions, we\ndefine the Restart condition for the galera service file. The 'on-abort'\noption is currently the default in the upstream service file and it's\nalso the most conservative one so we chose that to be the default option\nin the Ansible role as well. We also set a reasonably low RestartSec\nvalue as well.\n\nChange-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3\n""}]",0,470947,bea68f18cc75138cc1465dd56dbe8d957f8242ad,22,3,6,23163,,,0,"tasks: Set Restart option for systemd service file

In order to have a consistent systemd behavior across distributions, we
define the Restart condition for the galera service file. The 'on-abort'
option is currently the default in the upstream service file and it's
also the most conservative one so we chose that to be the default option
in the Ansible role as well. We also set a reasonably low RestartSec
value as well.

Change-Id: If442802f7aff4473cbb573ba1c123cfc46bde9b3
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/47/470947/6 && git format-patch -1 --stdout FETCH_HEAD,"['templates/systemd.restart.conf.j2', 'tasks/galera_post_install.yml']",2,763538e08a1abfa32bb1c537e0d71278eff43871,osa-add-suse-support," - { src: ""systemd.restart.conf.j2"", dest: ""restart.conf"" }",,10,0
openstack%2Fopenstack-ansible-galera_server~master~I2244f7cf0de908a10eec244122f8be32c3ade459,openstack/openstack-ansible-galera_server,master,I2244f7cf0de908a10eec244122f8be32c3ade459,Sync test files with the openstack-ansible-tests repository,MERGED,2017-06-05 12:13:07.000000000,2017-06-19 14:19:56.000000000,2017-06-19 14:19:56.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-05 12:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/1682be6d1e5c7c68e98f90bb51ed97ad4a9b372d', 'message': 'Sync test files with the openstack-ansible-tests repository\n\nIn preparation for adding support for SUSE distributions, we sync the\ntest files from the openstack-ansible-tests repository so the upcoming\ncommits can be tested on all supported distributions.\n\nChange-Id: I2244f7cf0de908a10eec244122f8be32c3ade459\n'}, {'number': 2, 'created': '2017-06-06 13:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/de0ced519c7a4e171cf5205669ea36658103db39', 'message': 'Sync test files with the openstack-ansible-tests repository\n\nIn preparation for adding support for SUSE distributions, we sync the\ntest files from the openstack-ansible-tests repository so the upcoming\ncommits can be tested on all supported distributions.\n\nChange-Id: I2244f7cf0de908a10eec244122f8be32c3ade459\n'}, {'number': 3, 'created': '2017-06-06 15:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/a41913aff85fb6d81b40d6e0f4b9a5df0e0cb59e', 'message': 'Sync test files with the openstack-ansible-tests repository\n\nIn preparation for adding support for SUSE distributions, we sync the\ntest files from the openstack-ansible-tests repository so the upcoming\ncommits can be tested on all supported distributions.\n\nChange-Id: I2244f7cf0de908a10eec244122f8be32c3ade459\n'}, {'number': 4, 'created': '2017-06-09 15:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/858355f13fd281efc50134ace18735d18e906412', 'message': 'Sync test files with the openstack-ansible-tests repository\n\nIn preparation for adding support for SUSE distributions, we sync the\ntest files from the openstack-ansible-tests repository so the upcoming\ncommits can be tested on all supported distributions.\n\nChange-Id: I2244f7cf0de908a10eec244122f8be32c3ade459\n'}, {'number': 5, 'created': '2017-06-09 19:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/481ef8fd8fc017554d46697b7cd59d4d0a66b4e5', 'message': 'Sync test files with the openstack-ansible-tests repository\n\nIn preparation for adding support for SUSE distributions, we sync the\ntest files from the openstack-ansible-tests repository so the upcoming\ncommits can be tested on all supported distributions.\n\nChange-Id: I2244f7cf0de908a10eec244122f8be32c3ade459\n'}, {'number': 6, 'created': '2017-06-14 15:32:14.000000000', 'files': ['run_tests.sh', '.gitignore', 'bindep.txt', 'Vagrantfile', 'tests/tests-repo-clone.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/0b06c1658c027158f6048d2ef69e0c3648dbfd39', 'message': 'Sync test files with the openstack-ansible-tests repository\n\nIn preparation for adding support for SUSE distributions, we sync the\ntest files from the openstack-ansible-tests repository so the upcoming\ncommits can be tested on all supported distributions.\n\nChange-Id: I2244f7cf0de908a10eec244122f8be32c3ade459\n'}]",0,470946,0b06c1658c027158f6048d2ef69e0c3648dbfd39,22,3,6,23163,,,0,"Sync test files with the openstack-ansible-tests repository

In preparation for adding support for SUSE distributions, we sync the
test files from the openstack-ansible-tests repository so the upcoming
commits can be tested on all supported distributions.

Change-Id: I2244f7cf0de908a10eec244122f8be32c3ade459
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/46/470946/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', '.gitignore', 'bindep.txt', 'Vagrantfile', 'tests/tests-repo-clone.sh']",5,1682be6d1e5c7c68e98f90bb51ed97ad4a9b372d,osa-add-suse-support,## Functions ----------------------------------------------------------------- function create_tests_clonemap {} ## Main ---------------------------------------------------------------------- # Prepare the clonemap for zuul-cloner to use create_tests_clonemap # Execute the clone # Clean up the clonemap. rm -f ${TESTING_HOME}/tests-clonemap.yaml ,## Main ----------------------------------------------------------------------# This is placed here instead of inside the conditional # to prevent indentation problems.# Clean up the clonemap. rm -f ${TESTING_HOME}/tests-clonemap.yaml ,111,79
openstack%2Fopenstack-ansible~stable%2Fmitaka~I0ba37928e99990691080a41aa685ec65146770f3,openstack/openstack-ansible,stable/mitaka,I0ba37928e99990691080a41aa685ec65146770f3,pin jinja2,MERGED,2017-06-17 05:17:02.000000000,2017-06-19 14:18:37.000000000,2017-06-19 14:18:37.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-17 05:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2a0c8d905a3b20e035936bf2ac62da3441c23d7a', 'message': 'pin jinja2\n\nJinja2 >2.8 breaks ansible 1.9.6+. This makes sure deployers using\nAnsible 1.9.6 are not broken.\n\nChange-Id: I0ba37928e99990691080a41aa685ec65146770f3\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2017-06-17 05:56:38.000000000', 'files': ['global-requirement-pins.txt', 'scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/06777f417a63a8c185fae90eaa41557c60ec6537', 'message': 'pin jinja2\n\nJinja2 >2.8 breaks ansible 1.9.6+. This makes sure deployers using\nAnsible 1.9.6 are not broken.\n\nChange-Id: I0ba37928e99990691080a41aa685ec65146770f3\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,475106,06777f417a63a8c185fae90eaa41557c60ec6537,11,3,2,7353,,,0,"pin jinja2

Jinja2 >2.8 breaks ansible 1.9.6+. This makes sure deployers using
Ansible 1.9.6 are not broken.

Change-Id: I0ba37928e99990691080a41aa685ec65146770f3
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/06/475106/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'global-requirement-pins.txt']",2,2a0c8d905a3b20e035936bf2ac62da3441c23d7a,, ### Pinned for ansible 1.9.6 Jinja2==2.8 # BSD License (3 clause),,4,1
openstack%2Fopenstack-ansible~master~I39ce5c3cf69bcbecea8e940bea2f0a133cfac07a,openstack/openstack-ansible,master,I39ce5c3cf69bcbecea8e940bea2f0a133cfac07a,Move unsetting of group and host env vars,MERGED,2017-06-15 21:39:48.000000000,2017-06-19 14:18:31.000000000,2017-06-19 14:18:31.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-15 21:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/48ccdea8c5112c5540655af4a90eb5cd96b12932', 'message': ""Move unsetting of group and host env vars\n\nThe run-upgrade script sources 'scripts-library.sh' which sources\n'openstack-ansible.rc'. The 'GROUP_VARS_PATH' and 'HOST_VARS_PATH'\nenvironment variables will have to be unset after the new\n'openstack-ansible.rc' file is written so that their changed values from\nthe previous release can take effect.\n\nChange-Id: I39ce5c3cf69bcbecea8e940bea2f0a133cfac07a\n""}, {'number': 2, 'created': '2017-06-18 13:15:47.000000000', 'files': ['scripts/gate-check-commit.sh', 'scripts/run-upgrade.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b9c839fdbbf172a49f4e201494f1ac3854ce040d', 'message': ""Move unsetting of group and host env vars\n\nThe run-upgrade script sources 'scripts-library.sh' which sources\n'openstack-ansible.rc'. The 'GROUP_VARS_PATH' and 'HOST_VARS_PATH'\nenvironment variables will have to be unset after the new\n'openstack-ansible.rc' file is written so that their changed values from\nthe previous release can take effect.\n\nChange-Id: I39ce5c3cf69bcbecea8e940bea2f0a133cfac07a\n""}]",0,474787,b9c839fdbbf172a49f4e201494f1ac3854ce040d,12,3,2,14805,,,0,"Move unsetting of group and host env vars

The run-upgrade script sources 'scripts-library.sh' which sources
'openstack-ansible.rc'. The 'GROUP_VARS_PATH' and 'HOST_VARS_PATH'
environment variables will have to be unset after the new
'openstack-ansible.rc' file is written so that their changed values from
the previous release can take effect.

Change-Id: I39ce5c3cf69bcbecea8e940bea2f0a133cfac07a
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/87/474787/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/gate-check-commit.sh', 'scripts/run-upgrade.sh']",2,48ccdea8c5112c5540655af4a90eb5cd96b12932,periodic_upgrades, # Unset environment variables used by the override_folder # plugin to set paths for group and host vars since the # default locations have changed between Ocata and Pike. unset GROUP_VARS_PATH unset HOST_VARS_PATH ,,6,6
openstack%2Fopenstack-ansible~master~If48ee9cb472de811076d7d3adec8f3c9b476b833,openstack/openstack-ansible,master,If48ee9cb472de811076d7d3adec8f3c9b476b833,scripts: sources-branch-updater-lib.sh: Avoid using 'dirname $0',MERGED,2017-06-15 11:39:41.000000000,2017-06-19 14:18:24.000000000,2017-06-19 14:18:24.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 15362}]","[{'number': 1, 'created': '2017-06-15 11:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0af01a13e8d30e8e53004f98ae5e3dd213088027', 'message': ""scripts: sources-branch-updater-lib.sh: Avoid using 'dirname $0'\n\nSince this library can be sourced by external scripts, 'dirname $0'\ncan't be used reliably to determine where the rest of the OSA helper\nscripts are located since $0 points to the external script.\nIt's best to use the BASH_SOURCE array to determine the file in which\nthe current function is defined.\n\nChange-Id: If48ee9cb472de811076d7d3adec8f3c9b476b833\n""}, {'number': 2, 'created': '2017-06-15 13:12:01.000000000', 'files': ['scripts/sources-branch-updater-lib.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5f301976dc06ffb0b31d72cb4abfe0bf3f8f4899', 'message': ""scripts: sources-branch-updater-lib.sh: Avoid using 'dirname $0'\n\nSince this library can be sourced by external scripts, 'dirname $0'\ncan't be used reliably to determine where the rest of the OSA helper\nscripts are located since $0 points to the external script.\nIt's best to use the BASH_SOURCE array to determine the file in which\nthe current function is defined.\n\nChange-Id: If48ee9cb472de811076d7d3adec8f3c9b476b833\n""}]",0,474551,5f301976dc06ffb0b31d72cb4abfe0bf3f8f4899,10,4,2,23163,,,0,"scripts: sources-branch-updater-lib.sh: Avoid using 'dirname $0'

Since this library can be sourced by external scripts, 'dirname $0'
can't be used reliably to determine where the rest of the OSA helper
scripts are located since $0 points to the external script.
It's best to use the BASH_SOURCE array to determine the file in which
the current function is defined.

Change-Id: If48ee9cb472de811076d7d3adec8f3c9b476b833
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/51/474551/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/sources-branch-updater-lib.sh'],1,0af01a13e8d30e8e53004f98ae5e3dd213088027,scripts/sources-branch-updater-get-dir-context," local current_source_dir=""$(cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd)"" ""$current_source_dir/ansible-role-requirements-editor.py"" -f ansible-role-requirements.yml -n ""${role_name}"" -v ""${role_version}"""," ""$(dirname ""${0}"")/ansible-role-requirements-editor.py"" -f ansible-role-requirements.yml -n ""${role_name}"" -v ""${role_version}""",3,1
openstack%2Fopenstack-ansible-galera_server~master~Ie07468a065af0668db1da1d52b81af3fcee53dca,openstack/openstack-ansible-galera_server,master,Ie07468a065af0668db1da1d52b81af3fcee53dca,tasks: galera_upgrade_post: Retry if starting the MariaDB service failed,MERGED,2017-06-05 12:13:07.000000000,2017-06-19 14:16:11.000000000,2017-06-19 14:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-05 12:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/165d279f820c2e77a5191470469d52672d215f27', 'message': 'tasks: galera_upgrade_post: Retry if starting the MariaDB service failed\n\nSimilar to the galera_running_check play, we should retry a few more\ntimes if the MariaDB service failed to start.\n\nChange-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca\n'}, {'number': 2, 'created': '2017-06-06 13:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/203abf1f7dbf83cc4ccd1e6519061d7e81bfb7d7', 'message': 'tasks: galera_upgrade_post: Retry if starting the MariaDB service failed\n\nSimilar to the galera_running_check play, we should retry a few more\ntimes if the MariaDB service failed to start.\n\nChange-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca\n'}, {'number': 3, 'created': '2017-06-06 15:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/3e3afadf74b1922252c8026b419ef456172c4354', 'message': 'tasks: galera_upgrade_post: Retry if starting the MariaDB service failed\n\nSimilar to the galera_running_check play, we should retry a few more\ntimes if the MariaDB service failed to start.\n\nChange-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca\n'}, {'number': 4, 'created': '2017-06-09 15:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/aebe4c118851acac47f165e0f5311497b70c5c5b', 'message': 'tasks: galera_upgrade_post: Retry if starting the MariaDB service failed\n\nSimilar to the galera_running_check play, we should retry a few more\ntimes if the MariaDB service failed to start.\n\nChange-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca\n'}, {'number': 5, 'created': '2017-06-09 19:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/d96c1fa5f43e8967f634230f44a7c70ebb84126a', 'message': 'tasks: galera_upgrade_post: Retry if starting the MariaDB service failed\n\nSimilar to the galera_running_check play, we should retry a few more\ntimes if the MariaDB service failed to start.\n\nChange-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca\n'}, {'number': 6, 'created': '2017-06-14 15:32:01.000000000', 'files': ['tasks/main.yml', 'tasks/galera_upgrade_post.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/531bf8ed2a3c8a4b4035b10d39c1814274322209', 'message': 'tasks: galera_upgrade_post: Retry if starting the MariaDB service failed\n\nSimilar to the galera_running_check play, we should retry a few more\ntimes if the MariaDB service failed to start.\n\nChange-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca\n'}]",0,470945,531bf8ed2a3c8a4b4035b10d39c1814274322209,22,3,6,23163,,,0,"tasks: galera_upgrade_post: Retry if starting the MariaDB service failed

Similar to the galera_running_check play, we should retry a few more
times if the MariaDB service failed to start.

Change-Id: Ie07468a065af0668db1da1d52b81af3fcee53dca
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/45/470945/4 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/galera_upgrade_post.yml']",2,165d279f820c2e77a5191470469d52672d215f27,osa-add-suse-support," # NOTE (hwoarang) Sometimes the service fails to start on the first attempt # so just try a few more times before giving up. Clearly this needs to be # investigated at some point... register: mysql_service_started until: mysql_service_started | success retries: ""{{ num_retries }}"" delay: ""{{ wait_delay }}""",,10,1
openstack%2Fopenstack-ansible-galera_server~master~Icb65f6c8c1654e24f73e1e5310516cd9b3568aad,openstack/openstack-ansible-galera_server,master,Icb65f6c8c1654e24f73e1e5310516cd9b3568aad,vars: main: Split percona packages from the galera server ones.,MERGED,2017-06-05 12:13:07.000000000,2017-06-19 14:16:05.000000000,2017-06-19 14:16:05.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-05 12:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/c3d1465fa770eb94380b16c66b6e7198e01046a6', 'message': ""vars: main: Only use external percona packages if use_percona_upstream is false\n\nThe role uses the 'use_percona_upstream' variable to determine if\nspecific external packages are going to be used instead of the distro or\nupstream ones. The {qpress,percona}_package_path variables only make sense\nif we are going to use such external packages so we convert their static\ndeclaration into a 'set_fact' task.\n\nChange-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad\n""}, {'number': 2, 'created': '2017-06-06 13:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/3a51366f79c598336aff459116816c64f3dffcfa', 'message': ""vars: main: Split percona packages from the galera server ones.\n\nThe role uses the 'use_percona_upstream' variable to determine if\nspecific external packages are going to be used instead of the distro or\nupstream ones. The {qpress,percona}_package_path variables only make sense\nif we are going to use such external packages so we convert their static\ndeclaration into a 'set_fact' task. This also allows distributions to\noverride the default package list with an empty list if they do not plan\nto use local percona packages.\n\nChange-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad\n""}, {'number': 3, 'created': '2017-06-06 15:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/3c9b72cb2d8e3303fa8622ca768246ad6538ca04', 'message': ""vars: main: Split percona packages from the galera server ones.\n\nThe role uses the 'use_percona_upstream' variable to determine if\nspecific external packages are going to be used instead of the distro or\nupstream ones. The {qpress,percona}_package_path variables only make sense\nif we are going to use such external packages so we convert their static\ndeclaration into a 'set_fact' task. This also allows distributions to\noverride the default package list with an empty list if they do not plan\nto use local percona packages.\n\nChange-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad\n""}, {'number': 4, 'created': '2017-06-09 15:53:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/7d672d33a6aaf15a18479d2d1ebf784e05cb9839', 'message': ""vars: main: Split percona packages from the galera server ones.\n\nThe role uses the 'use_percona_upstream' variable to determine if\nspecific external packages are going to be used instead of the distro or\nupstream ones. The {qpress,percona}_package_path variables only make sense\nif we are going to use such external packages so we convert their static\ndeclaration into a 'set_fact' task. This also allows distributions to\noverride the default package list with an empty list if they do not plan\nto use local percona packages.\n\nChange-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad\n""}, {'number': 5, 'created': '2017-06-09 19:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/f31f5a45cfacd54450b726fd7386991af3332118', 'message': ""vars: main: Split percona packages from the galera server ones.\n\nThe role uses the 'use_percona_upstream' variable to determine if\nspecific external packages are going to be used instead of the distro or\nupstream ones. The {qpress,percona}_package_path variables only make sense\nif we are going to use such external packages so we convert their static\ndeclaration into a 'set_fact' task. This also allows distributions to\noverride the default package list with an empty list if they do not plan\nto use local percona packages.\n\nChange-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad\n""}, {'number': 6, 'created': '2017-06-14 15:31:43.000000000', 'files': ['tasks/galera_install.yml', 'tasks/galera_install_yum.yml', 'vars/main.yml', 'tasks/galera_install_apt.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/22a87ddf74099780a3ed457de1be01947cf93978', 'message': ""vars: main: Split percona packages from the galera server ones.\n\nThe role uses the 'use_percona_upstream' variable to determine if\nspecific external packages are going to be used instead of the distro or\nupstream ones. The {qpress,percona}_package_path variables only make sense\nif we are going to use such external packages so we convert their static\ndeclaration into a 'set_fact' task. This also allows distributions to\noverride the default package list with an empty list if they do not plan\nto use local percona packages.\n\nChange-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad\n""}]",4,470944,22a87ddf74099780a3ed457de1be01947cf93978,32,5,6,23163,,,0,"vars: main: Split percona packages from the galera server ones.

The role uses the 'use_percona_upstream' variable to determine if
specific external packages are going to be used instead of the distro or
upstream ones. The {qpress,percona}_package_path variables only make sense
if we are going to use such external packages so we convert their static
declaration into a 'set_fact' task. This also allows distributions to
override the default package list with an empty list if they do not plan
to use local percona packages.

Change-Id: Icb65f6c8c1654e24f73e1e5310516cd9b3568aad
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/44/470944/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_install.yml', 'vars/main.yml']",2,c3d1465fa770eb94380b16c66b6e7198e01046a6,osa-add-suse-support, percona_packages_list:,,7,0
openstack%2Fopenstack-ansible-os_cinder~master~I44fdd82fbb4e2b679832ceca6462472e54177536,openstack/openstack-ansible-os_cinder,master,I44fdd82fbb4e2b679832ceca6462472e54177536,Add thinprovisioning tools for Ubuntu,MERGED,2017-06-19 11:18:16.000000000,2017-06-19 14:07:29.000000000,2017-06-19 14:07:29.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-06-19 11:18:16.000000000', 'files': ['vars/ubuntu-16.04.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/f8f7fa0fcaa5d478bf0093bed63735f7b69b4409', 'message': 'Add thinprovisioning tools for Ubuntu\n\nWithout these tools, the thinprovisioning checks and\nattempts to create thinprovisioning volumes fails.\n\nChange-Id: I44fdd82fbb4e2b679832ceca6462472e54177536\nRelated-Bug: 1615134\n'}]",0,475339,f8f7fa0fcaa5d478bf0093bed63735f7b69b4409,12,3,1,6816,,,0,"Add thinprovisioning tools for Ubuntu

Without these tools, the thinprovisioning checks and
attempts to create thinprovisioning volumes fails.

Change-Id: I44fdd82fbb4e2b679832ceca6462472e54177536
Related-Bug: 1615134
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/39/475339/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/ubuntu-16.04.yml'],1,f8f7fa0fcaa5d478bf0093bed63735f7b69b4409,bug/1615134, - libffi-dev - libpq-dev - libssl-dev - nfs-common - open-iscsi - rpcbind - rsync - thin-provisioning-tools, - rpcbind - rsync - nfs-common - libpq-dev - libffi-dev - libssl-dev - open-iscsi,8,7
openstack%2Fpython-freezerclient~master~I885319f77edb36fe3de6d1864e81ba73bf12304f,openstack/python-freezerclient,master,I885319f77edb36fe3de6d1864e81ba73bf12304f,Change author in setup.cfg,MERGED,2017-06-16 05:45:34.000000000,2017-06-19 14:04:28.000000000,2017-06-19 14:04:28.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 13940}, {'_account_id': 22405}, {'_account_id': 25695}, {'_account_id': 25720}]","[{'number': 1, 'created': '2017-06-16 05:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/deec7e75665c4be16358ff062d29a683bcd69a9b', 'message': 'Change author in setup.cfg\n\nChanged author to OpenStack in setup.cfg\n\nChange-Id: I885319f77edb36fe3de6d1864e81ba73bf12304f\n'}, {'number': 2, 'created': '2017-06-16 08:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/f56566a3824dba2ad2c3590b58f77d3589b9eb73', 'message': 'Change author in setup.cfg\n\nAs per https://review.openstack.org/#/c/473230/, we need to change\nthe author in setup.cfg from Mistral Team to Openstack.\n\nChange-Id: I885319f77edb36fe3de6d1864e81ba73bf12304f\n'}, {'number': 3, 'created': '2017-06-19 03:03:38.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/0ccf8575d49b48dc215ef4f19434119ebd8bf718', 'message': 'Change author in setup.cfg\n\nAs per https://review.openstack.org/#/c/473230/, we need to change\nthe author in setup.cfg from Freezer Team to Openstack.\n\nChange-Id: I885319f77edb36fe3de6d1864e81ba73bf12304f\n'}]",1,474857,0ccf8575d49b48dc215ef4f19434119ebd8bf718,16,6,3,25695,,,0,"Change author in setup.cfg

As per https://review.openstack.org/#/c/473230/, we need to change
the author in setup.cfg from Freezer Team to Openstack.

Change-Id: I885319f77edb36fe3de6d1864e81ba73bf12304f
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/57/474857/3 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,deec7e75665c4be16358ff062d29a683bcd69a9b,,author = OpenStack,author = Freezer Team,1,1
openstack%2Fpython-tripleoclient~stable%2Focata~I7acd5f5a506df6fc3556ac75af11a9ac8684cdec,openstack/python-tripleoclient,stable/ocata,I7acd5f5a506df6fc3556ac75af11a9ac8684cdec,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-01-27 01:21:38.000000000,2017-06-19 14:02:05.000000000,2017-06-19 14:02:05.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 9317}, {'_account_id': 9712}, {'_account_id': 10239}]","[{'number': 1, 'created': '2017-01-27 01:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f7f16eac9cfded953952518c907d34eb02b06ece', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I7acd5f5a506df6fc3556ac75af11a9ac8684cdec\n'}, {'number': 2, 'created': '2017-01-27 07:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4ec13b29b5e54b62101e6521c33c9d9029d7049f', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I7acd5f5a506df6fc3556ac75af11a9ac8684cdec\n'}, {'number': 3, 'created': '2017-06-14 08:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/cf16964f95f9247aa3d2d224673516fd6a4c087a', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I7acd5f5a506df6fc3556ac75af11a9ac8684cdec\n'}, {'number': 4, 'created': '2017-06-14 08:21:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/53722313902c040e18a298ca17538d77c94f85c8', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I7acd5f5a506df6fc3556ac75af11a9ac8684cdec\n'}]",2,426015,53722313902c040e18a298ca17538d77c94f85c8,24,6,4,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: I7acd5f5a506df6fc3556ac75af11a9ac8684cdec
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/15/426015/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f7f16eac9cfded953952518c907d34eb02b06ece,create-ocata,install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} {opts} {packages},install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fpuppet-tripleo~master~I5d2c89db29ef75aaf371b3c9dd561587d7b6f87b,openstack/puppet-tripleo,master,I5d2c89db29ef75aaf371b3c9dd561587d7b6f87b,Fixes an issue when rebooting with an NFS mount.,MERGED,2017-06-13 19:24:19.000000000,2017-06-19 14:01:59.000000000,2017-06-19 14:01:59.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 14985}, {'_account_id': 24042}, {'_account_id': 26211}]","[{'number': 1, 'created': '2017-06-13 19:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/77db1b424858bedc51befe5531a46056d6ab201f', 'message': 'Fixes an issue when rebooting with an NFS mount.\n\nChange-Id: I5d2c89db29ef75aaf371b3c9dd561587d7b6f87b\nCloses-Bug: #1697752\n'}, {'number': 2, 'created': '2017-06-13 20:01:36.000000000', 'files': ['manifests/glance/nfs_mount.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/96c4adecb2b6ff51d1a3b63a4219e107d0172d1b', 'message': ""Fixes an issue when rebooting with an NFS mount.\n\n_netdev mount option helps fix a timing issue when rebooting.\nThis looks like we're hitting an issue where we're using\nnetwork instead of NetworkManager and that systemd doesn't\nunmount the NFS shares before stopping network.\n\nChange-Id: I5d2c89db29ef75aaf371b3c9dd561587d7b6f87b\nCloses-Bug: #1697752\n""}]",0,473951,96c4adecb2b6ff51d1a3b63a4219e107d0172d1b,13,6,2,25820,,,0,"Fixes an issue when rebooting with an NFS mount.

_netdev mount option helps fix a timing issue when rebooting.
This looks like we're hitting an issue where we're using
network instead of NetworkManager and that systemd doesn't
unmount the NFS shares before stopping network.

Change-Id: I5d2c89db29ef75aaf371b3c9dd561587d7b6f87b
Closes-Bug: #1697752
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/51/473951/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/glance/nfs_mount.pp'],1,77db1b424858bedc51befe5531a46056d6ab201f,bug/1697752," $fstab_prepend_options = '_netdev,bg'", $fstab_prepend_options = 'bg',1,1
openstack%2Fopenstack-helm~master~I97b94fe7cb2ceacdfc3e961c7c1eb8f5ddda26ad,openstack/openstack-helm,master,I97b94fe7cb2ceacdfc3e961c7c1eb8f5ddda26ad,Cinder: Fix dependencies values typo.,MERGED,2017-06-17 13:52:33.000000000,2017-06-19 14:00:58.000000000,2017-06-19 14:00:39.000000000,"[{'_account_id': 3}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-06-17 13:52:33.000000000', 'files': ['cinder/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f1fa268867d6255e386e0d1925e790d3bb0fc3c1', 'message': 'Cinder: Fix dependencies values typo.\n\nThe dependencies for cinder had a typo, so volume was specified twice\nwhile backup was missed. This PS fixes that.\n\nChange-Id: I97b94fe7cb2ceacdfc3e961c7c1eb8f5ddda26ad\n'}]",0,475133,f1fa268867d6255e386e0d1925e790d3bb0fc3c1,11,4,1,23928,,,0,"Cinder: Fix dependencies values typo.

The dependencies for cinder had a typo, so volume was specified twice
while backup was missed. This PS fixes that.

Change-Id: I97b94fe7cb2ceacdfc3e961c7c1eb8f5ddda26ad
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/33/475133/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/values.yaml'],1,f1fa268867d6255e386e0d1925e790d3bb0fc3c1,cinder-deps, backup:, volume:,1,1
openstack%2Fironic-lib~master~Ibda809416c565d57f19179d7f13f4cee8f8145ff,openstack/ironic-lib,master,Ibda809416c565d57f19179d7f13f4cee8f8145ff,Adjust test with option 'backend',MERGED,2017-06-14 05:39:42.000000000,2017-06-19 13:59:52.000000000,2017-06-19 13:59:52.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 9796}, {'_account_id': 10239}]","[{'number': 1, 'created': '2017-06-14 05:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/969d58b5d925a911f976b432f5676e3e77133ebb', 'message': ""Remove invalid test with option 'backend'\n\nConfig option 'backend' with parameter choices =['noop', 'statsd'],\nthat means oslo.config will ensure value is one of them, otherwise\na ValueError will be raised, so don't need handle and test invalid\nvalue for backend.\n\nChange-Id: Ibda809416c565d57f19179d7f13f4cee8f8145ff\n""}, {'number': 2, 'created': '2017-06-16 03:26:21.000000000', 'files': ['ironic_lib/tests/test_metrics_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/f0a2e9791adbce2df17b57126ee5dde553205945', 'message': ""Adjust test with option 'backend'\n\nConfig option 'backend' with parameter choices =['noop', 'statsd'],\nthat means oslo.config will ensure value is one of them, otherwise\na ValueError will be raised, so don't need handle and test config\noption 'backend' with invalid value.\n\nChange-Id: Ibda809416c565d57f19179d7f13f4cee8f8145ff\n""}]",4,474066,f0a2e9791adbce2df17b57126ee5dde553205945,14,4,2,9796,,,0,"Adjust test with option 'backend'

Config option 'backend' with parameter choices =['noop', 'statsd'],
that means oslo.config will ensure value is one of them, otherwise
a ValueError will be raised, so don't need handle and test config
option 'backend' with invalid value.

Change-Id: Ibda809416c565d57f19179d7f13f4cee8f8145ff
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/66/474066/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_lib/metrics_utils.py', 'ironic_lib/tests/test_metrics_utils.py']",2,969d58b5d925a911f976b432f5676e3e77133ebb,enforce_type,," def test_nonexisting_backend(self): CONF.set_override('backend', 'none', group='metrics', enforce_type=False) self.assertRaises(exception.InvalidMetricConfig, metrics_utils.get_metrics_logger, 'foo') CONF.clear_override('backend', group='metrics') ",0,13
openstack%2Fpuppet-tripleo~master~Ib56a7ad8f43fc6274eebc83bd2a62e68c030599d,openstack/puppet-tripleo,master,Ib56a7ad8f43fc6274eebc83bd2a62e68c030599d,Addition of Nuage as mechanism driver for ML2,MERGED,2017-06-14 22:45:06.000000000,2017-06-19 13:57:53.000000000,2017-06-19 13:57:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-14 22:45:06.000000000', 'files': ['manifests/profile/base/neutron/plugins/ml2/nuage.pp', 'manifests/profile/base/neutron/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c70e68e65f806489d9d3f91d406bae82beaa3665', 'message': 'Addition of Nuage as mechanism driver for ML2\n\nAdding Nuage as mechanism driver where ML2 is the neutron\ncore plugin. ML2 base profile includes Nuage when mechanism\ndriver is Nuage. Added Nuage neutron ML2 profile for tripleo.\n\nChange-Id: Ib56a7ad8f43fc6274eebc83bd2a62e68c030599d\n'}]",0,474384,c70e68e65f806489d9d3f91d406bae82beaa3665,8,3,1,18343,,,0,"Addition of Nuage as mechanism driver for ML2

Adding Nuage as mechanism driver where ML2 is the neutron
core plugin. ML2 base profile includes Nuage when mechanism
driver is Nuage. Added Nuage neutron ML2 profile for tripleo.

Change-Id: Ib56a7ad8f43fc6274eebc83bd2a62e68c030599d
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/84/474384/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/neutron/plugins/ml2/nuage.pp', 'manifests/profile/base/neutron/plugins/ml2.pp']",2,c70e68e65f806489d9d3f91d406bae82beaa3665,, if 'nuage' in $mechanism_drivers { include ::tripleo::profile::base::neutron::plugins::ml2::nuage },,35,0
openstack%2Fmistral~stable%2Focata~I18449710ace6276224aaea564588c53a3e2c6adc,openstack/mistral,stable/ocata,I18449710ace6276224aaea564588c53a3e2c6adc,"Make sure that the field ""state_info"" trimmed as expected",MERGED,2017-06-19 10:07:11.000000000,2017-06-19 13:57:47.000000000,2017-06-19 13:57:47.000000000,"[{'_account_id': 3}, {'_account_id': 8731}]","[{'number': 1, 'created': '2017-06-19 10:07:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/977ae75faab4c9a96b737f462b47084662c099a6', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\n* Before this patch, ""state_info"" field of execution objects\n  wasn\'t truncated properly before saving into DB which led to\n  the DB error like:\n    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too\n    long for column \'state_info\' at row 1"")\n  It was happening because the method utils.cut() didn\'t work\n  accurately enough in case if we passed it with a dictionary.\n  This patch doesn\'t fix utils.cut() method but it just saves\n  space for possible method result difference with the expected\n  length so that we make sure that the truncated string\n  representation is always less than 65536 bytes (i.e. the size\n  of MySQL TEXT type). The total difference is not critical\n  anyway.\n\nCloses-Bug: #1698125\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n(cherry picked from commit 5a43d54a058ea4e13924c596b0bee93b727a1f95)\n'}, {'number': 2, 'created': '2017-06-19 11:05:49.000000000', 'files': ['mistral/utils/__init__.py', 'mistral/tests/unit/engine/test_execution_fields_size_limitation.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/db/v2/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/c15c378011702bde2e29922d238ed8b9b9688f39', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\n* Before this patch, ""state_info"" field of execution objects\n  wasn\'t truncated properly before saving into DB which led to\n  the DB error like:\n    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too\n    long for column \'state_info\' at row 1"")\n  It was happening because the method utils.cut() didn\'t work\n  accurately enough in case if we passed it with a dictionary.\n  This patch doesn\'t fix utils.cut() method but it just saves\n  space for possible method result difference with the expected\n  length so that we make sure that the truncated string\n  representation is always less than 65536 bytes (i.e. the size\n  of MySQL TEXT type). The total difference is not critical\n  anyway.\n\nCloses-Bug: #1698125\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n(cherry picked from commit 5a43d54a058ea4e13924c596b0bee93b727a1f95)\n'}]",0,475316,c15c378011702bde2e29922d238ed8b9b9688f39,8,2,2,8731,,,0,"Make sure that the field ""state_info"" trimmed as expected

* Before this patch, ""state_info"" field of execution objects
  wasn't truncated properly before saving into DB which led to
  the DB error like:
    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too
    long for column 'state_info' at row 1"")
  It was happening because the method utils.cut() didn't work
  accurately enough in case if we passed it with a dictionary.
  This patch doesn't fix utils.cut() method but it just saves
  space for possible method result difference with the expected
  length so that we make sure that the truncated string
  representation is always less than 65536 bytes (i.e. the size
  of MySQL TEXT type). The total difference is not critical
  anyway.

Closes-Bug: #1698125
Change-Id: I18449710ace6276224aaea564588c53a3e2c6adc
(cherry picked from commit 5a43d54a058ea4e13924c596b0bee93b727a1f95)
",git fetch https://review.opendev.org/openstack/mistral refs/changes/16/475316/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/utils/__init__.py', 'mistral/tests/unit/engine/test_execution_fields_size_limitation.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/db/v2/sqlalchemy/models.py']",4,977ae75faab4c9a96b737f462b47084662c099a6,bug/1698125," # Note that the limit is 65500 which is less than 65535 (2^16 -1). # The reason is that utils.cut() is not exactly accurate in case if # the value is not a string, but, for example, a dictionary. If we # limit it exactly to 65535 then once in a while it may go slightly # beyond the allowed maximum size. It may depend on the order of # keys in a string representation and other things that are hidden # inside utils.cut_dict() method. lambda t, v, o, i: utils.cut(v, 65500),"," lambda t, v, o, i: utils.cut(v, 65532),",93,13
openstack%2Ftripleo-heat-templates~master~If8df98e1ddd0961ab0c9e5df917fef8200db65e6,openstack/tripleo-heat-templates,master,If8df98e1ddd0961ab0c9e5df917fef8200db65e6,Re-enable docker service in docker.yaml,MERGED,2017-06-19 07:36:03.000000000,2017-06-19 13:46:08.000000000,2017-06-19 13:46:08.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 8042}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-06-19 07:36:03.000000000', 'files': ['environments/docker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/39ee601e77b180bacbf57f8890bb517d3997b331', 'message': 'Re-enable docker service in docker.yaml\n\nIt was removed by mistake from the docker.yaml environment file in\nI76f188438bfc6449b152c2861d99738e6eb3c61b.\n\nChange-Id: If8df98e1ddd0961ab0c9e5df917fef8200db65e6\nCloses-Bug: #1698749\n'}]",0,475274,39ee601e77b180bacbf57f8890bb517d3997b331,10,5,1,13039,,,0,"Re-enable docker service in docker.yaml

It was removed by mistake from the docker.yaml environment file in
I76f188438bfc6449b152c2861d99738e6eb3c61b.

Change-Id: If8df98e1ddd0961ab0c9e5df917fef8200db65e6
Closes-Bug: #1698749
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/475274/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/docker.yaml'],1,39ee601e77b180bacbf57f8890bb517d3997b331,bug/1698749, OS::TripleO::Services::Docker: ../puppet/services/docker.yaml ,,2,0
openstack%2Fdevstack~master~I943b552ca2e36210ac57f36c16db930eb5e58623,openstack/devstack,master,I943b552ca2e36210ac57f36c16db930eb5e58623,"docs: add ""kvm on s390x"" specific configuration in `local.conf`",MERGED,2017-05-29 13:39:53.000000000,2017-06-19 13:41:47.000000000,2017-06-19 13:25:03.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 2874}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 11307}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-05-29 13:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/69470946f74e067fe11bff370c4c79326c9b5fa6', 'message': 'docs: add ""kvm on z"" specific configuration in `loca.conf`\n\nThe upstream CI runs exclusively on nodes with x86 architectures, but\nOpenStack supports even more platforms. One of them is the KVM\non IBM z systems, which is supported since the *Kilo* release.\nThis change describes the additional settings in the ``local.conf`` file\nto enable Devstack on that platform. This is useful for PoCs.\n\nChange-Id: I943b552ca2e36210ac57f36c16db930eb5e58623\n'}, {'number': 2, 'created': '2017-05-30 09:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/85d4d6ef6abbf8938ea90c4d378dba80ff016999', 'message': 'docs: add ""kvm on z"" specific configuration in `loca.conf`\n\nThe upstream CI runs exclusively on nodes with x86 architectures, but\nOpenStack supports even more platforms. One of them is the KVM\non IBM z systems, which is supported since the *Kilo* release.\nThis change describes the additional settings in the ``local.conf`` file\nto enable Devstack on that platform. This is useful for PoCs.\n\nChange-Id: I943b552ca2e36210ac57f36c16db930eb5e58623\n'}, {'number': 3, 'created': '2017-05-30 11:54:03.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/14728c7a51c56141eafbf58617814680887c6690', 'message': 'docs: add ""kvm on s390x"" specific configuration in `local.conf`\n\nThe upstream CI runs exclusively on nodes with x86 architectures, but\nOpenStack supports even more platforms. One of them is the KVM\non s390x (IBM z systems), which is supported since the *Kilo* release.\nThis change describes the additional settings in the ``local.conf`` file\nto enable Devstack on that platform. This is useful for PoCs.\n\nChange-Id: I943b552ca2e36210ac57f36c16db930eb5e58623\n'}]",19,468887,14728c7a51c56141eafbf58617814680887c6690,29,7,3,11303,,,0,"docs: add ""kvm on s390x"" specific configuration in `local.conf`

The upstream CI runs exclusively on nodes with x86 architectures, but
OpenStack supports even more platforms. One of them is the KVM
on s390x (IBM z systems), which is supported since the *Kilo* release.
This change describes the additional settings in the ``local.conf`` file
to enable Devstack on that platform. This is useful for PoCs.

Change-Id: I943b552ca2e36210ac57f36c16db930eb5e58623
",git fetch https://review.opendev.org/openstack/devstack refs/changes/87/468887/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,69470946f74e067fe11bff370c4c79326c9b5fa6,kvm-on-z," Architectures ------------- The upstream CI runs exclusively on nodes with x86 architectures, but OpenStack supports even more architectures. Some of them need to configure Devstack in a certain way. Below is a list of Devstack configurations which differ from the x86 based `minimal-configuration`_. IBM KVM on z Systems ~~~~~~~~~~~~~~~~~~~~ The *KVM on z Systems* platform is supported since the *Kilo* release and needs these additional settings in the ``local.conf`` file:: [[local|localrc]] IMAGE_URLS=""https://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-s390x-disk1.img"" enable_service n-sproxy disable_service etcd3 # https://bugs.launchpad.net/devstack/+bug/1693192 [[post-config|$NOVA_CONF]] [vnc] enabled=False [serial_console] enabled=True base_url=ws://$HOST_IP:6083/ proxyclient_address=$HOST_IP Reasoning: * The default image of Devstack is x86 only. The referenced guest image in the code above (``IMAGE_URLS``) serves as an example. The list of possible s390x guest images is not limited to that. * This platform doesn't support a graphical console like VNC or SPICE. The technical reason is the missing framebuffer on the platform. This means we rely on the substitute feature *serial console* which needs a proxy service and the configuration in section ``[serial_console]``. We also disable VNC for that reason. * The service ``etcd3`` needs to be disabled as long as bug report https://bugs.launchpad.net/devstack/+bug/1693192 is not resolved.",,44,0
openstack%2Foctavia~master~I68541d3e402e1f599285234a847782f37ff29e35,openstack/octavia,master,I68541d3e402e1f599285234a847782f37ff29e35,Implement zero downtime reload with multibinder,ABANDONED,2017-05-19 10:40:00.000000000,2017-06-19 13:40:27.000000000,,"[{'_account_id': 3}, {'_account_id': 2245}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 15309}, {'_account_id': 20279}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-05-19 10:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/49ea2f45259c73d7c659f83c81dd4d398112c8cd', 'message': 'Implement zero downtime reload with multibinder\n\nChange-Id: I68541d3e402e1f599285234a847782f37ff29e35\n'}, {'number': 2, 'created': '2017-06-06 13:58:48.000000000', 'files': ['octavia/tests/unit/common/sample_configs/sample_configs.py', 'elements/multibinder/README.rst', 'diskimage-create/diskimage-create.sh', 'octavia/common/jinja/haproxy/templates/macros.j2', 'elements/multibinder/install.d/80-multibinder', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server.py', 'octavia/amphorae/backends/agent/api_server/listener.py', 'octavia/tests/unit/common/jinja/haproxy/test_jinja_cfg.py', 'elements/multibinder/package-installs.yaml', 'octavia/amphorae/backends/agent/api_server/templates/systemd.conf.j2', 'elements/multibinder/element-deps', 'elements/multibinder/post-install.d/80-multibinder', 'elements/multibinder/svc-map', 'octavia/amphorae/backends/agent/api_server/util.py', 'elements/multibinder/init-scripts/systemd/multibinder.service'], 'web_link': 'https://opendev.org/openstack/octavia/commit/5e6dc3e1a9ad39b01c73fcd23ea9454ac9a5044d', 'message': 'Implement zero downtime reload with multibinder\n\nChange-Id: I68541d3e402e1f599285234a847782f37ff29e35\n'}]",0,466260,5e6dc3e1a9ad39b01c73fcd23ea9454ac9a5044d,17,7,2,2245,,,0,"Implement zero downtime reload with multibinder

Change-Id: I68541d3e402e1f599285234a847782f37ff29e35
",git fetch https://review.opendev.org/openstack/octavia refs/changes/60/466260/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/common/sample_configs/sample_configs.py', 'elements/multibinder/README.rst', 'diskimage-create/diskimage-create.sh', 'octavia/common/jinja/haproxy/templates/macros.j2', 'elements/multibinder/install.d/80-multibinder', 'octavia/tests/functional/amphorae/backend/agent/api_server/test_server.py', 'octavia/amphorae/backends/agent/api_server/listener.py', 'octavia/tests/unit/common/jinja/haproxy/test_jinja_cfg.py', 'elements/multibinder/package-installs.yaml', 'octavia/amphorae/backends/agent/api_server/templates/systemd.conf.j2', 'elements/multibinder/element-deps', 'elements/multibinder/post-install.d/80-multibinder', 'elements/multibinder/svc-map', 'octavia/amphorae/backends/agent/api_server/util.py', 'elements/multibinder/init-scripts/systemd/multibinder.service']",15,49ea2f45259c73d7c659f83c81dd4d398112c8cd,zero-downtime-reload,[Unit] Description=Multibinder After=network.target [Service] ExecStartPre=-/sbin/ip netns add amphora-haproxy ExecStart=/sbin/ip netns exec amphora-haproxy /usr/local/bin/multibinder /run/multibinder.sock Restart=always [Install] WantedBy=multi-user.target ,,78,25
openstack%2Fdevstack~master~I15fe6f25eedf1efebaab81cce26b080577b856cc,openstack/devstack,master,I15fe6f25eedf1efebaab81cce26b080577b856cc,etcd3: Allow for multi-host deployments,MERGED,2017-06-16 14:05:02.000000000,2017-06-19 13:38:21.000000000,2017-06-19 13:38:21.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 10118}]","[{'number': 1, 'created': '2017-06-16 14:05:02.000000000', 'files': ['lib/etcd3'], 'web_link': 'https://opendev.org/openstack/devstack/commit/19279b0f87e2ab1c684d62078df296211d3a60cc', 'message': 'etcd3: Allow for multi-host deployments\n\nIn Multi host deployments, it is possible to run ETCD in a different\nhost than the SERVICE_HOST (where all the controllers run). This patch\nbrings that distinction.\n\nChange-Id: I15fe6f25eedf1efebaab81cce26b080577b856cc\nSigned-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>\n'}]",0,474986,19279b0f87e2ab1c684d62078df296211d3a60cc,11,4,1,14352,,,0,"etcd3: Allow for multi-host deployments

In Multi host deployments, it is possible to run ETCD in a different
host than the SERVICE_HOST (where all the controllers run). This patch
brings that distinction.

Change-Id: I15fe6f25eedf1efebaab81cce26b080577b856cc
Signed-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/86/474986/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/etcd3'],1,19279b0f87e2ab1c684d62078df296211d3a60cc,multi_host_etcd," cmd+="" --advertise-client-urls http://${HOST_IP}:$ETCD_PORT"" cmd+="" --listen-client-urls http://${HOST_IP}:$ETCD_PORT"""," cmd+="" --advertise-client-urls http://$SERVICE_HOST:$ETCD_PORT"" cmd+="" --listen-client-urls http://$SERVICE_HOST:$ETCD_PORT""",2,2
openstack%2Fopenstack-ansible~stable%2Focata~Idc153c45f5da2ee44b49dbd5ef4577f749550556,openstack/openstack-ansible,stable/ocata,Idc153c45f5da2ee44b49dbd5ef4577f749550556,Set PrivateDevices=false for MemcacheD,MERGED,2017-06-17 04:21:04.000000000,2017-06-19 13:37:30.000000000,2017-06-19 13:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 13095}]","[{'number': 1, 'created': '2017-06-17 04:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a4b1fe9dab36c6cccb3a4655dfdda392e371dc5b', 'message': 'Set PrivateDevices=false for MemcacheD\n\nThis patch sets the `memcached_disable_privatedevices` variable in the\nmemcached_server role. If memcached is deployed with a container, the\nPrivateDevices configuration will be disabled in the systemd unit file.\n\nChange-Id: Idc153c45f5da2ee44b49dbd5ef4577f749550556\nRelated-Bug: 1697531\n(cherry picked from commit 14ae2dd53421971a273f7a3213fe1c3726fe12dd)\n'}, {'number': 2, 'created': '2017-06-17 04:22:13.000000000', 'files': ['releasenotes/notes/centos-memcached-privatedevices-d3be3acb19ed71d6.yaml', 'ansible-role-requirements.yml', 'playbooks/inventory/group_vars/memcached.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c66391662cae01fd0ca716164f2adeea1e851ce6', 'message': 'Set PrivateDevices=false for MemcacheD\n\nThis patch sets the `memcached_disable_privatedevices` variable in the\nmemcached_server role. If memcached is deployed with a container, the\nPrivateDevices configuration will be disabled in the systemd unit file.\n\nChange-Id: Idc153c45f5da2ee44b49dbd5ef4577f749550556\nRelated-Bug: 1697531\n(cherry picked from commit 14ae2dd53421971a273f7a3213fe1c3726fe12dd)\n'}]",0,475101,c66391662cae01fd0ca716164f2adeea1e851ce6,8,3,2,6816,,,0,"Set PrivateDevices=false for MemcacheD

This patch sets the `memcached_disable_privatedevices` variable in the
memcached_server role. If memcached is deployed with a container, the
PrivateDevices configuration will be disabled in the systemd unit file.

Change-Id: Idc153c45f5da2ee44b49dbd5ef4577f749550556
Related-Bug: 1697531
(cherry picked from commit 14ae2dd53421971a273f7a3213fe1c3726fe12dd)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/01/475101/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/centos-memcached-privatedevices-d3be3acb19ed71d6.yaml', 'playbooks/inventory/group_vars/memcached.yml']",2,a4b1fe9dab36c6cccb3a4655dfdda392e371dc5b,bug/1697531," # Disable PrivateDevices for MemcacheD on CentOS 7 # See https://bugs.launchpad.net/openstack-ansible/+bug/1697531 for details. memcached_disable_privatedevices: ""{{ ((properties.is_metal | default(false)) | bool) | ternary('false', 'true') }}""",,18,0
openstack%2Fopenstack-ansible-os_cinder~stable%2Focata~I93f302da78bb5e735f961f7f92d92466d317b41c,openstack/openstack-ansible-os_cinder,stable/ocata,I93f302da78bb5e735f961f7f92d92466d317b41c,"Update paste, policy and rootwrap configurations 2017-06-12",MERGED,2017-06-12 10:58:36.000000000,2017-06-19 13:36:02.000000000,2017-06-19 13:36:02.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-12 10:58:36.000000000', 'files': ['files/rootwrap.d/volume.filters'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/501725b333a1bd1eabbc166141f2f625176d653a', 'message': 'Update paste, policy and rootwrap configurations 2017-06-12\n\nChange-Id: I93f302da78bb5e735f961f7f92d92466d317b41c\n'}]",0,473368,501725b333a1bd1eabbc166141f2f625176d653a,16,3,1,17068,,,0,"Update paste, policy and rootwrap configurations 2017-06-12

Change-Id: I93f302da78bb5e735f961f7f92d92466d317b41c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/68/473368/1 && git format-patch -1 --stdout FETCH_HEAD,['files/rootwrap.d/volume.filters'],1,501725b333a1bd1eabbc166141f2f625176d653a,sha-update,"mmlsfileset: CommandFilter, /usr/lpp/mmfs/bin/mmlsfileset, root",,1,0
openstack%2Fdragonflow~master~If6192d79ed9b60b82db5719245e808cae6f92879,openstack/dragonflow,master,If6192d79ed9b60b82db5719245e808cae6f92879,Forward DNAT traffic from table 7,ABANDONED,2016-11-01 09:42:26.000000000,2017-06-19 13:34:02.000000000,,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 18903}, {'_account_id': 20229}, {'_account_id': 22060}, {'_account_id': 23235}, {'_account_id': 23766}]","[{'number': 1, 'created': '2016-11-01 09:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7757b29565930c3bd7144f95b0ef6e8fa7a13df9', 'message': 'Forward DNAT traffic from table 7 when using flat network\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 2, 'created': '2016-11-01 16:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1ae1b8390060c8865c4ad8fa768e186fa46a1d42', 'message': '[WIP] Forward DNAT traffic from table 7 when using flat network\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 3, 'created': '2016-11-02 12:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7ae7080b1a1e1c4d40ea751cd2b4622d79e3240a', 'message': '[WIP] Forward DNAT traffic from table 7 when using flat network\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 4, 'created': '2016-11-02 12:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4578f7260e24ce6102cb15b9384d6cb0f79f1ebe', 'message': '[WIP] Forward DNAT traffic from table 7 when using flat network\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 5, 'created': '2016-11-02 12:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9e358f870f5b2877c488573211b81806a409c390', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller.\nThis patch makes L2 app be aware of floating IPs and makes sure it\ninstalls needed flows (0->7) even when there are no local ports, only\nfloating IPs. Additionally it forwards DNAT traffic from table 7 with\ncorrect metadata field.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 6, 'created': '2016-11-02 13:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/446b38d0559674a0333251a2e1bc029b6dd97a9a', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\n'}, {'number': 7, 'created': '2016-11-02 14:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7cd8146dc5a65b8039cd5679ef751245f886261c', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\n'}, {'number': 8, 'created': '2016-11-02 16:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1c3fcc2f9f5d745992271c4540d2789ed6d33b89', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 9, 'created': '2016-11-03 14:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1d7f4cdc9144302256389b0b0d56b9af62f97970', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 10, 'created': '2016-11-06 06:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/005547d3f2262c6305c40966339c989d59188f2f', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 11, 'created': '2016-11-08 15:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5f9549a11028630a091d789a091595c987826873', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 12, 'created': '2016-11-17 15:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/dbf856b9ae7226d63c05b9cccf0add39fa6347d5', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 13, 'created': '2016-11-20 08:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/82a6337ea877ac3cf39f299f0d1d20cd38c3be27', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 14, 'created': '2016-11-22 09:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/858938e23af2d156593ecbcde9aab8fbf6bda1b7', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 15, 'created': '2016-11-22 16:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/32a23054961066912b302895741c8bae7abb8d38', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 16, 'created': '2016-11-23 10:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/60482b25f973fed9fcc50ba56173ae78e518a98e', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 17, 'created': '2016-11-23 14:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/50fbbcab60ec70b966ea60331a3a9b541bbc9c8a', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 18, 'created': '2016-11-23 20:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e133707cee2cd08abf014f4175412db880b1bb8f', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 19, 'created': '2016-11-27 08:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4401b32c3d367a6796d3112dddbef4b9e4f05926', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 20, 'created': '2016-11-27 10:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/109d847c4a1fb780ca88b9a4d208f584a3df6694', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 21, 'created': '2016-11-29 09:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/cdba3c10d1389d0c0f576573fd16801896cd935d', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 22, 'created': '2016-11-30 04:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d2b888e2eb2214570fdc139862083c165c6c0e7e', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}, {'number': 23, 'created': '2016-12-11 10:23:54.000000000', 'files': ['dragonflow/controller/l2_ml2_app.py', 'dragonflow/tests/fullstack/test_objects.py', 'dragonflow/tests/unit/test_dnat_app.py', 'dragonflow/tests/fullstack/test_apps.py', 'dragonflow/controller/dnat_app.py', 'dragonflow/tests/common/app_testing_objects.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0478fd4fa747bbb499e3dbae6222ef910c74a1b8', 'message': 'Forward DNAT traffic from table 7\n\nUp until now goto DNAT ingress flow was installed in table 0 with lowest\npriority. This meant that and tunnel traffic including flat(vlan=0)\ncould go to table 7 if there were local ports on controller. This patch\nmakes L2 app be aware of floating IPs and makes sure it installs needed\nflows (0->7) even when there are no local ports, only floating IPs.\nAdditionally it forwards DNAT traffic from table 7 with correct metadata\nfield.\n\nCloses-Bug:#1636829\n\nChange-Id: If6192d79ed9b60b82db5719245e808cae6f92879\nSigned-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>\n'}]",53,392086,0478fd4fa747bbb499e3dbae6222ef910c74a1b8,81,8,23,23766,,,0,"Forward DNAT traffic from table 7

Up until now goto DNAT ingress flow was installed in table 0 with lowest
priority. This meant that and tunnel traffic including flat(vlan=0)
could go to table 7 if there were local ports on controller. This patch
makes L2 app be aware of floating IPs and makes sure it installs needed
flows (0->7) even when there are no local ports, only floating IPs.
Additionally it forwards DNAT traffic from table 7 with correct metadata
field.

Closes-Bug:#1636829

Change-Id: If6192d79ed9b60b82db5719245e808cae6f92879
Signed-off-by: Dima Kuznetsov <dima.kuznetsov@toganetworks.com>
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/86/392086/21 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/controller/l2_ml2_app.py', 'dragonflow/controller/dnat_app.py']",2,7757b29565930c3bd7144f95b0ef6e8fa7a13df9,bug/1636829," for table_id in (const.INGRESS_CLASSIFICATION_DISPATCH_TABLE, const.INGRESS_DESTINATION_PORT_LOOKUP_TABLE): match = parser.OFPMatch() match.set_in_port(self.external_ofport) self.add_flow_go_to_table(self.get_datapath(), table_id, const.PRIORITY_DEFAULT, const.INGRESS_NAT_TABLE, match=match) for table_id in (const.INGRESS_CLASSIFICATION_DISPATCH_TABLE, const.INGRESS_DESTINATION_PORT_LOOKUP_TABLE): match = parser.OFPMatch() match.set_in_port(self.external_ofport) self.mod_flow( self.get_datapath(), command=ofproto.OFPFC_DELETE, table_id=table_id, priority=const.PRIORITY_DEFAULT, match=match)"," match = parser.OFPMatch() match.set_in_port(self.external_ofport) self.add_flow_go_to_table(self.get_datapath(), const.INGRESS_CLASSIFICATION_DISPATCH_TABLE, const.PRIORITY_DEFAULT, const.INGRESS_NAT_TABLE, match=match) match = parser.OFPMatch() match.set_in_port(self.external_ofport) self.mod_flow( self.get_datapath(), command=ofproto.OFPFC_DELETE, table_id=const.INGRESS_CLASSIFICATION_DISPATCH_TABLE, priority=const.PRIORITY_DEFAULT, match=match)",26,15
openstack%2Fpuppet-glance~master~Ieeef18a24382ae4ffeb7f3ac63a9a49173ddeb0d,openstack/puppet-glance,master,Ieeef18a24382ae4ffeb7f3ac63a9a49173ddeb0d,Trivial fix style in documents,MERGED,2017-06-19 04:41:29.000000000,2017-06-19 13:19:38.000000000,2017-06-19 13:19:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-06-19 04:41:29.000000000', 'files': ['releasenotes/source/newton.rst', 'releasenotes/source/unreleased.rst', 'releasenotes/source/ocata.rst'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9ee64a0b0713dc401ce11ec4deb77dd6ed1e46f9', 'message': 'Trivial fix style in documents\n\nMake the title match the underline\n\nChange-Id: Ieeef18a24382ae4ffeb7f3ac63a9a49173ddeb0d\n'}]",0,475230,9ee64a0b0713dc401ce11ec4deb77dd6ed1e46f9,7,2,1,26072,,,0,"Trivial fix style in documents

Make the title match the underline

Change-Id: Ieeef18a24382ae4ffeb7f3ac63a9a49173ddeb0d
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/30/475230/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/newton.rst', 'releasenotes/source/unreleased.rst', 'releasenotes/source/ocata.rst']",3,9ee64a0b0713dc401ce11ec4deb77dd6ed1e46f9,fix_style_docs,======================================================,======================================================================,6,6
openstack%2Fpuppet-openstack-integration~master~I978dc40a8bc7f444e7c3697def695a19bf8f4cf0,openstack/puppet-openstack-integration,master,I978dc40a8bc7f444e7c3697def695a19bf8f4cf0,Updated from Puppet OpenStack modules constraints,MERGED,2017-06-17 09:50:43.000000000,2017-06-19 13:19:29.000000000,2017-06-19 13:19:29.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-06-17 09:50:43.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/7a9f6745b99b3523d15b097bfff526376ee32a9e', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: I978dc40a8bc7f444e7c3697def695a19bf8f4cf0\n'}]",0,475121,7a9f6745b99b3523d15b097bfff526376ee32a9e,6,2,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: I978dc40a8bc7f444e7c3697def695a19bf8f4cf0
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/21/475121/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,7a9f6745b99b3523d15b097bfff526376ee32a9e,openstack/puppet/constraints, :ref => '4.17.1', :ref => '4.17.0',1,1
openstack%2Ftripleo-ui~stable%2Focata~I35df26175aa3fe44970420d8e1f0936fc1005337,openstack/tripleo-ui,stable/ocata,I35df26175aa3fe44970420d8e1f0936fc1005337,Fix nodes registration,MERGED,2017-06-19 10:00:28.000000000,2017-06-19 13:19:19.000000000,2017-06-19 13:19:19.000000000,"[{'_account_id': 3}, {'_account_id': 17888}, {'_account_id': 20970}]","[{'number': 1, 'created': '2017-06-19 10:00:28.000000000', 'files': ['src/js/components/nodes/driver_fields/DriverFields.js', 'src/js/components/nodes/driver_fields/PXEAndIPMIToolDriverFields.js', 'releasenotes/notes/nodes-register-port-080747965014e1b3.yaml', 'src/js/immutableRecords/nodes.js', 'src/js/components/nodes/driver_fields/PXEAndDRACDriverFields.js', 'src/js/components/nodes/driver_fields/PXEAndSSHDriverFields.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/e873eb178c1e7489e57cfd87d10f9d9cf1358427', 'message': ""Fix nodes registration\n\n* Don't include uuid in nodes registration\n* Add IPMI port to driver fields\n\nCloses-Bug: 1689507\nCloses-Bug: 1688543\nChange-Id: I35df26175aa3fe44970420d8e1f0936fc1005337\n(cherry picked from commit 2b7419299896eba7aa1238c74c5f4ad09835a9cd)\n""}]",0,475314,e873eb178c1e7489e57cfd87d10f9d9cf1358427,7,3,1,7509,,,0,"Fix nodes registration

* Don't include uuid in nodes registration
* Add IPMI port to driver fields

Closes-Bug: 1689507
Closes-Bug: 1688543
Change-Id: I35df26175aa3fe44970420d8e1f0936fc1005337
(cherry picked from commit 2b7419299896eba7aa1238c74c5f4ad09835a9cd)
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/14/475314/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/nodes-register-port-080747965014e1b3.yaml', 'src/js/components/nodes/driver_fields/DriverFields.js', 'src/js/components/nodes/driver_fields/PXEAndIPMIToolDriverFields.js', 'src/js/immutableRecords/nodes.js', 'src/js/components/nodes/driver_fields/PXEAndDRACDriverFields.js', 'src/js/components/nodes/driver_fields/PXEAndSSHDriverFields.js']",6,e873eb178c1e7489e57cfd87d10f9d9cf1358427,bug/1689507," port_title: { id: 'PXEAndSSHDriverFields.port_title', defaultMessage: 'SSH Port' }, <DriverFields {...this.props} addr_title={this.props.intl.formatMessage(messages.addr_title)} user_title={this.props.intl.formatMessage(messages.user_title)} port_title={this.props.intl.formatMessage(messages.port_title)} pwd_title={this.props.intl.formatMessage(messages.pwd_title)} />", <DriverFields {...this.props} addr_title={this.props.intl.formatMessage(messages.addr_title)} user_title={this.props.intl.formatMessage(messages.user_title)} pwd_title={this.props.intl.formatMessage(messages.pwd_title)} />,93,37
openstack%2Fos-vif~master~I7a68e4ec0469ca5e676f2e7c88c9535d9747ac29,openstack/os-vif,master,I7a68e4ec0469ca5e676f2e7c88c9535d9747ac29,Fix typo VIFVIFHostDeviceDevType to VIFHostDeviceDevType,MERGED,2017-06-17 08:14:53.000000000,2017-06-19 13:09:56.000000000,2017-06-18 20:40:03.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 11604}, {'_account_id': 15334}]","[{'number': 1, 'created': '2017-06-17 08:14:53.000000000', 'files': ['os_vif/objects/vif.py', 'os_vif/objects/fields.py', 'os_vif/tests/test_vif.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/db9ef89ee0e62030eff5ef5a234a4112654194f3', 'message': 'Fix typo VIFVIFHostDeviceDevType to VIFHostDeviceDevType\n\nChange-Id: I7a68e4ec0469ca5e676f2e7c88c9535d9747ac29\n'}]",1,475118,db9ef89ee0e62030eff5ef5a234a4112654194f3,9,4,1,12171,,,0,"Fix typo VIFVIFHostDeviceDevType to VIFHostDeviceDevType

Change-Id: I7a68e4ec0469ca5e676f2e7c88c9535d9747ac29
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/18/475118/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_vif/objects/vif.py', 'os_vif/objects/fields.py', 'os_vif/tests/test_vif.py']",3,db9ef89ee0e62030eff5ef5a234a4112654194f3,," dev_type=objects.fields.VIFHostDeviceDevType.ETHERNET, 'VIFHostDevice': '1.0-bb090f1869c3b4df36efda216ab97a61',"," dev_type=objects.fields.VIFVIFHostDeviceDevType.ETHERNET, 'VIFHostDevice': '1.0-b3516f5af46ecb9432650e4938ac2643',",8,8
openstack%2Fopenstack-ansible-lxc_container_create~master~Icaa1af40b159aaaa2b096c3148356f2d2abb38f5,openstack/openstack-ansible-lxc_container_create,master,Icaa1af40b159aaaa2b096c3148356f2d2abb38f5,Test overridden lxc_container_bind_mounts value,MERGED,2017-06-18 20:11:40.000000000,2017-06-19 13:04:48.000000000,2017-06-19 13:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-18 20:11:40.000000000', 'files': ['tests/test-containers-functional.yml', 'tests/host_vars/container2.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/07f74c7208826d994b3356ecb883412c4867367e', 'message': 'Test overridden lxc_container_bind_mounts value\n\nlxc_container_bind_mounts is overridden within the tests repo with\nchange I774343234a25063eb320cac85ba696d908f0a416.\n\nAdjust the functional test to check for the overridden value.\n\nChange-Id: Icaa1af40b159aaaa2b096c3148356f2d2abb38f5\n'}]",0,475198,07f74c7208826d994b3356ecb883412c4867367e,7,3,1,14805,,,0,"Test overridden lxc_container_bind_mounts value

lxc_container_bind_mounts is overridden within the tests repo with
change I774343234a25063eb320cac85ba696d908f0a416.

Adjust the functional test to check for the overridden value.

Change-Id: Icaa1af40b159aaaa2b096c3148356f2d2abb38f5
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/98/475198/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test-containers-functional.yml', 'tests/host_vars/container2.yml']",2,07f74c7208826d994b3356ecb883412c4867367e,unblock-container-create-gate,,"lxc_container_bind_mounts: - host_directory: ""/openstack/{{ inventory_hostname }}/test2"" container_directory: ""/opt/test2"" ",4,5
openstack%2Ftripleo-docs~master~I8377b17e5557398007ce1b46e39dec26932c0448,openstack/tripleo-docs,master,I8377b17e5557398007ce1b46e39dec26932c0448,Update external Swift configuration doc,MERGED,2017-06-15 13:06:37.000000000,2017-06-19 13:03:33.000000000,2017-06-19 13:03:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9625}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-06-15 13:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/2afd05f7b7c6aaafd61c9e9887d95ac5d88d041b', 'message': 'Update external Swift configuration doc\n\nChange-Id: I8377b17e5557398007ce1b46e39dec26932c0448\n'}, {'number': 2, 'created': '2017-06-15 13:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/48fdcfe618d966d2f3d428e3fd79607890b21d90', 'message': 'Update external Swift configuration doc\n\nChange-Id: I8377b17e5557398007ce1b46e39dec26932c0448\n'}, {'number': 3, 'created': '2017-06-15 13:24:25.000000000', 'files': ['doc/source/advanced_deployment/swift_external.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e91b4f55fea72942889ec5953553fd3814a67b10', 'message': 'Update external Swift configuration doc\n\nChange-Id: I8377b17e5557398007ce1b46e39dec26932c0448\n'}]",0,474571,e91b4f55fea72942889ec5953553fd3814a67b10,12,4,3,6968,,,0,"Update external Swift configuration doc

Change-Id: I8377b17e5557398007ce1b46e39dec26932c0448
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/71/474571/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/advanced_deployment/swift_external.rst'],1,2afd05f7b7c6aaafd61c9e9887d95ac5d88d041b,," ExternalPublicUrl: 'http://<Public Swift endpoint or loadbalancer>:9024/v1/AUTH_%(tenant_id)s' ExternalInternalUrl: 'http://<Internal Swift endpoint>:9024/v1/AUTH_%(tenant_id)s' ExternalAdminUrl: 'http://<Admin Swift endpoint>:9024' SwiftPassword: 'choose_a_random_password'a service user called *swift* that can be used for this purpose. The password for this user is defined by using the *SwiftPassword* parameter, as shown above. The external Swift proxy must use Keystone from the overcloud, otherwise authentication will fail. The public Keystone endpoint must be accessible from the proxy therefore. The following snippet from `/etc/swift/proxy-server.conf` is an example how to configure the Swift proxy to use Keystone from the overcloud:: [pipeline:main] pipeline = [... other middlewares ...] authtoken keystone [... other middlewares ...] [filter:keystone] use = egg:swift#keystoneauth operator_roles = admin, SwiftOperator cache = swift.cache [filter:authtoken] paste.filter_factory = keystonemiddleware.auth_token:filter_factory signing_dir = /tmp/keystone-signing-swift auth_uri = http://<public Keystone endpoint>:5000/ auth_url = http://<admin Keystone endpoint>:35357/ password = <Password as defined in the environment parameters> auth_plugin = password project_domain_id = default user_domain_id = default project_name = service username = swift cache = swift.cache include_service_catalog = False delay_auth_decision = True", ExternalPublicUrl: 'http://swiftproxy:9024/v1/%(tenant_id)s' ExternalInternalUrl: 'http://swiftproxy:9024/v1/%(tenant_id)s' ExternalAdminUrl: 'http://swiftproxy:9024/v1/%(tenant_id)s'a service user called *swift* that can be used for this purpose. ,36,5
openstack%2Fopenstack-ansible-galera_client~master~I248da143d0534a8677a8b4636e021830280a442c,openstack/openstack-ansible-galera_client,master,I248da143d0534a8677a8b4636e021830280a442c,Updated from OpenStack Ansible Tests,MERGED,2017-06-18 14:41:24.000000000,2017-06-19 13:00:34.000000000,2017-06-19 13:00:34.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-18 14:41:24.000000000', 'files': ['run_tests.sh', '.gitignore', 'bindep.txt', 'Vagrantfile', 'tests/tests-repo-clone.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/5c78a67d01661edc28a8a64edac9c7124192b62c', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I248da143d0534a8677a8b4636e021830280a442c\n'}]",0,475176,5c78a67d01661edc28a8a64edac9c7124192b62c,7,3,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I248da143d0534a8677a8b4636e021830280a442c
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/76/475176/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', '.gitignore', 'bindep.txt', 'Vagrantfile', 'tests/tests-repo-clone.sh']",5,5c78a67d01661edc28a8a64edac9c7124192b62c,openstack/openstack-ansible-tests/sync-tests,## Functions ----------------------------------------------------------------- function create_tests_clonemap {} ## Main ---------------------------------------------------------------------- # Prepare the clonemap for zuul-cloner to use create_tests_clonemap # Execute the clone # Clean up the clonemap. rm -f ${TESTING_HOME}/tests-clonemap.yaml ,## Main ----------------------------------------------------------------------# This is placed here instead of inside the conditional # to prevent indentation problems.# Clean up the clonemap. rm -f ${TESTING_HOME}/tests-clonemap.yaml ,107,71
openstack%2Fopenstack-ansible-ceph_client~stable%2Focata~I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2,openstack/openstack-ansible-ceph_client,stable/ocata,I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2,Use the host python interpreter when delegating to localhost,MERGED,2017-06-17 04:28:09.000000000,2017-06-19 13:00:14.000000000,2017-06-19 13:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 13095}]","[{'number': 1, 'created': '2017-06-17 04:28:09.000000000', 'files': ['tasks/ceph_auth_extra_compute.yml', 'tasks/ceph_auth_extra.yml', 'tasks/ceph_config_extra.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/d95066959e13d99d37989c3c3e16ff6e9791c1cb', 'message': 'Use the host python interpreter when delegating to localhost\n\nIn order to ensure that the localhost delegated task uses the host\npython interpreter (to access host-installed libs like\npython-selinux), the interpreter is set on the task.\n\nsee: https://review.openstack.org/#/c/474565/\n\nChange-Id: I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2\n(cherry picked from commit 9c2d22532e5cfd817e2fcacbe7fab8ca28976e61)\n'}]",0,475102,d95066959e13d99d37989c3c3e16ff6e9791c1cb,7,3,1,6816,,,0,"Use the host python interpreter when delegating to localhost

In order to ensure that the localhost delegated task uses the host
python interpreter (to access host-installed libs like
python-selinux), the interpreter is set on the task.

see: https://review.openstack.org/#/c/474565/

Change-Id: I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2
(cherry picked from commit 9c2d22532e5cfd817e2fcacbe7fab8ca28976e61)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/02/475102/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/ceph_auth_extra_compute.yml', 'tasks/ceph_auth_extra.yml', 'tasks/ceph_config_extra.yml']",3,d95066959e13d99d37989c3c3e16ff6e9791c1cb,fix-localhost-delegation," vars: ansible_python_interpreter: ""/usr/bin/python""",,10,0
openstack%2Fopenstack-ansible-os_heat~stable%2Fnewton~I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4,openstack/openstack-ansible-os_heat,stable/newton,I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4,Correct heat developer mode constraint,MERGED,2017-06-17 05:15:41.000000000,2017-06-19 13:00:01.000000000,2017-06-19 13:00:01.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-17 05:15:41.000000000', 'files': ['tasks/heat_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/b554bfe511b6639a39b8bfcd5401abb763f0c5c6', 'message': 'Correct heat developer mode constraint\n\nThe keystone_developer_mode variable is used by mistake.\nThis fixes that.\n\nChange-Id: I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4\n(cherry picked from commit 300f15ee65d2e157a0304caa10fcac279fbd5f18)\n'}]",0,475105,b554bfe511b6639a39b8bfcd5401abb763f0c5c6,9,3,1,6816,,,0,"Correct heat developer mode constraint

The keystone_developer_mode variable is used by mistake.
This fixes that.

Change-Id: I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4
(cherry picked from commit 300f15ee65d2e157a0304caa10fcac279fbd5f18)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/05/475105/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/heat_install.yml'],1,b554bfe511b6639a39b8bfcd5401abb763f0c5c6,," {{ heat_developer_mode | ternary('--constraint /opt/developer-pip-constraints.txt', '') }}"," {{ keystone_developer_mode | ternary('--constraint /opt/developer-pip-constraints.txt', '') }}",1,1
openstack%2Fopenstack-manuals~master~I6e6a5b89c1e9144a9687fc74f4e30f32e7cbbb95,openstack/openstack-manuals,master,I6e6a5b89c1e9144a9687fc74f4e30f32e7cbbb95,Imported Translations from Zanata,MERGED,2017-06-19 11:57:21.000000000,2017-06-19 12:58:05.000000000,2017-06-19 12:58:05.000000000,"[{'_account_id': 3}, {'_account_id': 10607}]","[{'number': 1, 'created': '2017-06-19 11:57:21.000000000', 'files': ['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/arch-design/source/locale/tr_TR/LC_MESSAGES/arch-design.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/82292f74fbcb865bcf43852b3d96b243f8a4dc2a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I6e6a5b89c1e9144a9687fc74f4e30f32e7cbbb95\n'}]",0,475353,82292f74fbcb865bcf43852b3d96b243f8a4dc2a,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I6e6a5b89c1e9144a9687fc74f4e30f32e7cbbb95
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/53/475353/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/arch-design/source/locale/tr_TR/LC_MESSAGES/arch-design.po']",2,82292f74fbcb865bcf43852b3d96b243f8a4dc2a,zanata/translations,"# işbaran akçayır <isbaran@gmail.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: Architecture Design Guide 15.0\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2017-06-18 17:35+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-06-18 05:36+0000\n"" ""Last-Translator: Copied by Zanata <copied-by-zanata@zanata.org>\n"" ""Language-Team: Turkish (Turkey)\n"" ""Language: tr-TR\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" ""X-Generator: Zanata 3.9.6\n"" ""X-POOTLE-MTIME: 1497796838.000000\n"" msgid """" ""**(Optional) External or Public network** - This network is used to "" ""communicate externally from the VMs to the public network space. These "" ""addresses are typically handled by the neutron agent on the controller nodes "" ""and can also be handled by a SDN other than neutron. However, when using "" ""neutron DVR with OVS, this network must be present on the compute node since "" ""north and south traffic will not be handled by the controller nodes, but by "" ""the compute node itself. For more information on DVR with OVS and compute "" ""nodes, see `Open vSwitch: High availability using DVR <https://docs."" ""openstack.org/ocata/networking-guide/deploy-ovs-ha-dvr.html>`_"" msgstr """" ""**(İsteğe bağlı) Harici veya Açık ağ** - Bu ağ sanal makinelerden harici "" ""olarak açık ağ alanına iletişim için kullanılır. Bu adresler genellikle "" ""kontrol düğümündeki neutron aracısı tarafından ele alınır ve başka bir "" ""neutron ya da SDN tarafından da ele alınabilir. Ancak neutron DVR'yi OVS ile "" ""kullanırken bu ağ hesaplama düğümünde olmalıdır, çünkü kuzey ve güney "" ""trafiği kontrol düğümleri tarafından değil, hesaplama düğümü tarafından ele "" ""alınacaktır. OVS'li DVR ve hesaplama düğümleriyle ilgili daha fazla bilgi "" ""için `Open vSwitch: DVR ile yüksek kullanılırlığa <https://docs.openstack."" ""org/ocata/networking-guide/deploy-ovs-ha-dvr.html>`_ göz atın."" msgid """" ""**DRAM SSDs**: Small reads – 4091 IOPs (23x), Small writes – 4184 IOPs (14x)"" msgstr """" ""**DRAM SSD'ler**: Küçük okumalar – 4091 IOPs (23x), Küçük yazmalar – 4184 "" ""IOPs (14x)"" msgid ""**File-level storage for live migration**"" msgstr ""**Canlı göç için dosya-seviyesi depolama** "" msgid """" ""**Flash SSDs**: Small reads – 1075 IOPs (6x), Small writes – 21 IOPs (0.1x)"" msgstr """" ""**Flash SSD'ler**: Küçük okumalar – 1075 IOPs (6x), Küçük yazmalar – 21 IOPs "" ""(0.1x)"" msgid ""**HDDs**: Small reads – 175 IOPs, Small writes – 280 IOPs"" msgstr ""**HDD'ler**: Küçük okumalar – 175 IOPs, Küçük yazmalar – 280 IOPs"" msgid """" ""**Install or OOB network** - Typically used by most distributions and "" ""provisioning tools as the network for deploying base software to the "" ""OpenStack compute nodes. This network should be connected at a minimum of "" ""1Gb and no routing is usually needed."" msgstr """" ""**Yükleme veya OOB ağı** - OpenStack hesaplama düğümlerine temel yazılım "" ""kurulumu için olan ağ olarak çoğu dağıtım ve hazırlık aracı tarafından "" ""kullanılır. Bu ağ en az 1Gb bağlanmalıdır, genellikle yönlendirmeye gerek "" ""yoktur."" msgid """" ""**Internal or Management network** - Used as the internal communication "" ""network between OpenStack compute and control nodes. Can also be used as a "" ""network for iSCSI communication between the compute and iSCSI storage nodes. "" ""Again, this should be a minimum of a 1Gb NIC and should be a non-routed "" ""network. This interface should be redundant for high availability (HA)."" msgstr """" ""**Dahili veya Yönetim ağı** - OpenStack kontrol ve hesaplama düğümleri "" ""arasında dahili iletişim ağı olarak kullanılır. Hesaplama ile iSCSI depolama "" ""düğümleri arasında iSCSI iletişimi için de kullanılabilir. Bu da asgari 1Gb "" ""NIC'e sahip olmalı ve yönlendirilmeyen ağ olmalıdır. Bu arayüz yüksek "" ""kullanılırlık (HA) için yedekli olmalıdır."" msgid ""**Multithread Considerations**"" msgstr ""**Çoklu İş Parçacığı Etmenleri**"" msgid ""**Storage driver support**"" msgstr ""**Depolama sürücüsü desteği**"" msgid """" ""**Storage network** - A private network which could be connected to the Ceph "" ""frontend or other shared storage. For HA purposes this should be a redundant "" ""configuration with suggested 10Gb NICs. This network isolates the storage "" ""for the instances away from other networks. Under load, this storage traffic "" ""could overwhelm other networks and cause outages on other OpenStack services."" msgstr """" ""**Depolama ağı** - Ceph önyüzüne ya da diğer paylaşımlı depolamaya "" ""bağlanabilecek özel bir ağ. Yüksek kullanılırlık amacıyla bu tavsiye edilen "" ""10Gb NIC'lere sahip yedekli yapılandırmada olmalıdır. Bu ağ sunucular için "" ""depolamayı diğer ağlardan yalıtır. Yük altında, bu depolama trafiği diğer "" ""ağları boğabilir ve diğer OpenStack servislerinde kesintilere yol açabilir."" msgid """" ""**Tenant network** - A private network that enables communication between "" ""each tenant's instances. If using flat networking and provider networks, "" ""this network is optional. This network should also be isolated from all "" ""other networks for security compliance. A 1Gb interface should be sufficient "" ""and redundant for HA."" msgstr """" ""**Kiracı ağı** - Her bir kiracının sunucuları arasında iletişimi "" ""etkinleştiren özel bir ağ. Düz ağ ve sağlayıcı ağlar kullanılıyorsa, bu ağ "" ""isteğe bağlıdır. Bu ağ ayrıca güvenlik uyumu için diğer tüm ağlardan "" ""yalıtılmalıdır. Yüksek kullanılırlık ve yedek için 1Gb arayüz yeterli "" ""olmalıdır."" msgid ""1"" msgstr ""1"" msgid ""1 TB disk"" msgstr ""1 TB disk"" msgid ""10"" msgstr ""10"" msgid ""10 GB first disk, 30 GB second disk"" msgstr ""10 GB ilk disk, 30 GB ikinci disk"" msgid """" ""10 GbE horizontally scalable spine leaf back-end storage and front end "" ""network."" msgstr """" ""10 GbE yatay ölçeklenebilir omurga yaprak arka uçlu depolama ve ön yüz ağı."" msgid """" ""10 GbE horizontally scalable spine leaf back-end storage and front-end "" ""network"" msgstr """" ""10 GbE yatay ölçeklenebilir omurga yaprak arka uç depolama ve ön yüz ağı"" msgid """" ""10 storage servers each with 12x4 TB disks equaling 480 TB total space with "" ""approximately 160 TB of usable space after replicas."" msgstr """" ""Yedeklerden sonra yaklaşık 160 TB kullanılabilir alanı olan toplam 480 TB "" ""alana eşit 12x4 TB disklere sahip 10 depolama sunucusu."" msgid """" ""10 storage servers each with 12x4 TB disks which equals 480 TB total space "" ""with about approximately 160 TB of usable space after 3 replicas"" msgstr """" ""3 yedekten sonra 160 TB kullanılır alana sahip olacak 480 TB toplam alana "" ""denk gelen her biri 12x4 TB diske sahip 10 depolama sunucusu"" msgid ""10s of TBs of dataset storage"" msgstr ""10'larca TB verikümesi depolama"" msgid """" ""1U rack-mounted servers have the ability to offer greater server density "" ""than a blade server solution, but are often limited to dual-socket, multi-"" ""core CPU configurations. It is possible to place forty 1U servers in a rack, "" ""providing space for the top of rack (ToR) switches, compared to 32 full "" ""width blade servers."" msgstr """" ""1U kabine-bağlı sunucular blade sunucu çözümüne göre çok daha iyi sunucu "" ""yoğunluğuna sahiptirler, ama çoğunlukla çift-soket çoklu-çekirdek işlemci "" ""yapılandırmalarıyla sınırlıdırlar. Kabine kırk 1U sunucu sığdırarak kabin "" ""üstü (ToR) anahtarlara yer sağlamak mümkündür, blade sunucularla bu rakam "" ""32'dir."" msgid ""2"" msgstr ""2"" msgid """" ""2U rack-mounted servers provide quad-socket, multi-core CPU support, but "" ""with a corresponding decrease in server density (half the density that 1U "" ""rack-mounted servers offer)."" msgstr """" ""2U kabine-bağlı sunucular dört-soket çoklu-çekirdek işlemci desteği sağlar, "" ""ama sunucu yoğunluğunu buna bağlı olarak düşürür (1U kabine-bağlı "" ""sunucuların yarı yoğunluğunu sunarlar)."" msgid ""2x10 GbE back-end bonds"" msgstr ""2x10 GbE arka uç bağları"" msgid ""2x10 GbE bonded front end"" msgstr ""2x10 GbE bağlı ön yüz"" msgid ""3x proxies"" msgstr ""3x vekil"" msgid ""4"" msgstr ""4"" msgid ""5"" msgstr ""5"" msgid ""5 storage servers for caching layer 24x1 TB SSD"" msgstr ""Ön bellekleme katmanı için 5 depolama sunucusu 24x1 TB SSD"" msgid """" "":ref:`logical_architecture` shows one example of the most common integrated "" ""services within OpenStack and how they interact with each other. End users "" ""can interact through the dashboard, CLIs, and APIs. All services "" ""authenticate through a common Identity service, and individual services "" ""interact with each other through public APIs, except where privileged "" ""administrator commands are necessary."" msgstr """" "":ref:`logical_architecture` OpenStack içinde en tümleşik servislerden bir "" ""örnek ve birbirleriyle nasıl iletişim kurduklarını gösterir. Son "" ""kullanıcılar kontrol paneli, CLI'ler, ve API'ler aracılığıyla iletişim "" ""kurabilirler. Tüm servisler genel bir Kimlik servisi aracılığıyla kimlik "" ""doğrulaması yaparlar, ve bağımsız servisler birbirleriyle açık API'ler "" ""aracılığıyla iletişim kurarlar, istisna yetkili yönetici komutlarının "" ""gerekli olduğu durumlardır."" msgid """" "":ref:`table_controller_hardware` contains common considerations to review "" ""when sizing hardware for the cloud controller design."" msgstr """" "":ref:`table_controller_hardware` bulut kontrol birimi tasarımı için donanım "" ""boyutlandırırken gözden geçirilecek etmenleri içerir."" msgid """" "":ref:`table_openstack_storage` explains the differences between Openstack "" ""storage types."" msgstr """" "":ref:`table_openstack_storage` tablosu Openstack depolama türleri arasındaki "" ""farkları açıklar."" msgid """" "":term:`Quality of Service (QoS)` also has a great impact on network "" ""intensive workloads as it provides instant service to packets which have a "" ""higher priority due to the impact of poor network performance. In "" ""applications such as Voice over IP (VoIP), differentiated services code "" ""points are a near requirement for proper operation. You can also use QoS in "" ""the opposite direction for mixed workloads to prevent low priority but high "" ""bandwidth applications, for example backup services, video conferencing, or "" ""file sharing, from blocking bandwidth that is needed for the proper "" ""operation of other workloads. It is possible to tag file storage traffic as "" ""a lower class, such as best effort or scavenger, to allow the higher "" ""priority traffic through. In cases where regions within a cloud might be "" ""geographically distributed it may also be necessary to plan accordingly to "" ""implement WAN optimization to combat latency or packet loss."" msgstr """" ""Zayıf ağ başarımı nedeniyle yüksek önceliğe sahip olan paketlere anında "" ""servis sağladığından :term:`Servis Kalitesi (QoS)`nin de ağ ağırlıklı iş "" ""yükleri üzerinde büyük etkisi vardır. IP üzerinden Ses (VoIP) gibi "" ""uygulamalarda, düzgün işlem için farklı servislerin kod noktaları aynı "" ""ölçüde gereklidir. Karışık iş yüklerinde de düşük öncelikli ama yüksek bant "" ""genişlikli uygulamaları önlemek için QoS'u aksi yönde kullanabilirsiniz, "" ""örneğin yedekleme servisleri, video konferansı, dosya paylaşımı gibi "" ""uygulamaların diğer iş yüklerinin işlemesi için gereken bant genişliğini "" ""engellememesi için. Bulut içindeki bölgelerin coğrafi olarak dağıtık olduğu "" ""durumlarda gecikme ve paket kayıplarıyla savaşmak için de WAN "" ""iyileştirmeleri planlamak gerekli olabilir."" msgid """" ""A RAID 5 array only has 25% of the write IOPS of the read IOPS while a RAID "" ""1 array in this case would produce a maximum of 975 IOPS."" msgstr """" ""Bir RAID 1 dizisi azami 975 IOPS üretecekken RAID 5 dizisi yalnızca okuma "" ""IOPS'unun 25% kadarına sahiptir. "" msgid """" ""A Shared File Systems service share (either manila managed or an external "" ""one registered in manila) that can be partitioned, formatted and mounted "" ""(such as /dev/vdc)"" msgstr """" ""Bölümlenebilir, biçimlendirilmiş, ve bağlı (/dev/vdc gibi) Paylaşımlı Dosya "" ""Sistemleri servisi paylaşımı (manila tarafından yönetilen veya manila'ya "" ""harici olarak kaydedilmiş)"" msgid ""A basic understanding of networking principles and protocols."" msgstr ""Ağ prensipleri ve iletişim kurallarıyla ilgili temel anlayış."" msgid """" ""A block device that can be partitioned, formatted, and mounted (such as, /"" ""dev/vdc)"" msgstr """" ""Bölümlenebilir, biçimlendirilmiş, ve bağlı bir blok aygıt (/dev/vdc gibi)"" msgid """" ""A cloud controller's hardware can be the same as a compute node, though you "" ""may want to further specify based on the size and type of cloud that you run."" msgstr """" ""Bir bulut kontrol biriminin donanımı hesaplama düğümüyle aynı olabilir, yine "" ""de çalıştırdığınız bulut türüne ve boyutuna göre belirleme yapabilirsiniz."" msgid """" ""A cloud environment fundamentally changes the ways that networking is "" ""provided and consumed. Understanding the following concepts and decisions is "" ""imperative when making architectural decisions. For detailed information on "" ""networking concepts, see the `OpenStack Networking Guide <https://docs."" ""openstack.org/ocata/networking-guide/>`_."" msgstr """" ""Bulut ortamı ağın sağlandığı ve tüketildiği yönleri özünde değiştirir. "" ""Mimari kararlar alırken takip eden kavramları ve kararları anlamak faydalı "" ""olacaktır. Ağ kavramlarıyla ilgili ayrıntılı bilgi için `OpenStack Ağ "" ""Kılavuzuna <https://docs.openstack.org/ocata/networking-guide/>`_ göz atın."" msgid ""A disk within a single node"" msgstr ""Tek bir düğümdeki bir disk"" msgid """" ""A distributed shared file system. As of Gluster version 3.3, you can use "" ""Gluster to consolidate your object storage and file storage into one unified "" ""file and object storage solution, which is called Gluster For OpenStack "" ""(GFO). GFO uses a customized version of swift that enables Gluster to be "" ""used as the back-end storage."" msgstr """" ""Dağıtık bir paylaşımlı dosya sistemi. Gluster sürüm 3.3'den itibaren nesne "" ""depolama ve dosya depolamanızı tek bir dosya ve nesne depolama çözümü "" ""şeklinde pekiştirebilirsiniz, buna OpenStack için Gluster (GFO) denir. GFO "" ""Gluster'in arka uç depolama olarak kullanılabilmesini sağlayan "" ""özelleştirilmiş bir swift sürümü kullanır."" msgid ""A file system"" msgstr ""Bir dosya sistemi"" msgid """" ""A firewall, switches and load balancers on the public facing network "" ""connections."" msgstr """" ""Açık taraftaki ağ bağlantıları üzerinde bir güvenlik duvarı, anahtarlar ve "" ""yük dengeleyiciler."" msgid """" ""A general purpose OpenStack cloud has multiple options. The key factors that "" ""will have an influence on selection of storage hardware for a general "" ""purpose OpenStack cloud are as follows:"" msgstr """" ""Genel amaçlı bir OpenStack bulutu birden çok seçeneğe sahiptir. Genel amaçlı "" ""bir OpenStack bulutu için depolama donanımı seçimini etkileyebilecek anahtar "" ""etmenler şunlardır:"" msgid """" ""A hypervisor provides software to manage virtual machine access to the "" ""underlying hardware. The hypervisor creates, manages, and monitors virtual "" ""machines. OpenStack Compute (nova) supports many hypervisors to various "" ""degrees, including:"" msgstr """" ""Hipervizör altta yatan donanıma erişmek için sanal makine erişimini yöneten "" ""yazılımı sağlar. Hipervizör sanal makineleri oluşturur, yönetir ve izler. "" ""OpenStack Hesaplama (nova) bir çok hipervizörü belli derecede destekler:"" msgid """" ""A key consideration in a storage-focused OpenStack cloud is latency. Using "" ""solid-state disks (SSDs) to minimize latency and, to reduce CPU delays "" ""caused by waiting for the storage, increases performance. Use RAID "" ""controller cards in compute hosts to improve the performance of the "" ""underlying disk subsystem."" msgstr """" ""Depolama odaklı bir OpenStack bulutunda anahtar etmenlerden biri gecikmedir. "" ""SSD diskler kullanmak gecikmeyi asgaride tutabilir, ve depolama için "" ""beklenen CPU gecikmelerini azaltarak başarımı artırır. Altta yapan disk alt "" ""sisteminin başarımını iyileştirmek için hesaplama sunucularında RAID kontrol "" ""kartlarını kullanın."" msgid """" ""A measure of how many servers can fit into a given measure of physical "" ""space, such as a rack unit [U]."" msgstr """" ""Fiziksel alana kaç tane sunucu sığacağının ölçümü, örneğin kabin birimi [U]."" msgid ""A scalable, reliable data store for OpenStack virtual machine images."" msgstr """" ""OpenStack sanal makine imajları için ölçeklenebilir, güvenilir veri depolama."" msgid """" ""A storage system presents a LUN backed by a set of SSDs using a traditional "" ""storage array with OpenStack Block Storage integration or a storage platform "" ""such as Ceph or Gluster."" msgstr """" ""Bir depolama sistemi OpenStack Blok Depolama tümleşimi veya Ceph veya "" ""Gluster gibi bir depolama platformu ile geleneksel depolama dizisi "" ""kullanarak bir takım SSD destekli LUN arka ucu sunar."" msgid """" ""A three node MariaDB and Galera cluster, each with 4 vCPUs and 8 GB of RAM"" msgstr """" ""Üç düğümlü MariaDB ve Galera kümesi, her biri 4 vCPU ve 8 GB RAM'e sahip"" msgid """" ""A web service architecture has many options and optional components. Due to "" ""this, it can fit into a large number of other OpenStack designs. A few key "" ""components, however, need to be in place to handle the nature of most web-"" ""scale workloads. You require the following components:"" msgstr """" ""Bir web servisi mimarisi bir çok seçeneğe ve isteğe bağlı bileşenlere "" ""sahiptir. Bu yüzden, yüksek sayıda diğer OpenStack tasarımlarının içine "" ""sığabilir. Yine de çoğu web ölçekli iş yüklerinde bazı anahtar kavramların "" ""yerinde olması gerekir. Şu bileşenlere ihtiyaç duyarsınız:"" msgid """" ""A well-considered auditing plan is essential for quickly finding issues. "" ""Keeping track of changes made to security groups and tenant changes can be "" ""useful in rolling back the changes if they affect production. For example, "" ""if all security group rules for a tenant disappeared, the ability to quickly "" ""track down the issue would be important for operational and legal reasons. "" ""For more details on auditing, see the `Compliance chapter <https://docs."" ""openstack.org/security-guide/compliance.html>`_ in the OpenStack Security "" ""Guide."" msgstr """" ""İyi düşünülmüş bir denetleme planı sorunları bulmak için gereklidir. "" ""Güvenlik gruplarına yapılan değişiklikler ve kiracı değişikliklerini takip "" ""etmek değişiklikleri üretimi etkilemeleri durumunda geri almak için "" ""kullanışlı olabilir. Örneğin, bir kiracı için tüm güvenlik grupları ortadan "" ""kaybolursa, yasal ve işlevsel sebeplerle sorunu çabucak bulabilmek önemli "" ""olur. Denetlemeyle ilgili daha fazla ayrıntı için, OpenStack Güvenlik "" ""Kılavuzundaki `Uyumluluk bölümüne <https://docs.openstack.org/security-guide/"" ""compliance.html>`_ göz atın."" msgid """" ""A wide variety of use case requirements dictate the nature of the storage "" ""back end. Examples of such requirements are as follows:"" msgstr """" ""Geniş kullanım durumu gereksinim çeşitliliği depolama arka ucunun doğasını "" ""belirler. Bu tür gereksinimlere örnek vermek gerekirse:"" msgid """" ""A zone within an Object Storage cluster is a logical division. Any of the "" ""following may represent a zone:"" msgstr """" ""Bir Nesne Depolama kümesindeki bölge mantıksal bir bölümdür. Aşağıdakilerin "" ""her biri bir bölgeyi temsil edebilir:"" msgid """" ""API availability guarantees implying multiple infrastructure services and "" ""highly available load balancers."" msgstr """" ""API kullanılırlığı çeşitli alt yapı servislerini ve yüksek kullanılırlıklı "" ""yük dengeleyicileri kasteder."" msgid ""API differences"" msgstr ""API farkları"" msgid ""API endpoints"" msgstr ""API uç noktaları"" msgid ""Abstract"" msgstr ""Özet"" msgid ""Accessed through…"" msgstr ""Şunun aracılığıyla erişildi..."" msgid ""Accessible from…"" msgstr ""Şuradan erişilebilir..."" msgid ""Add additional persistent storage to a virtual machine"" msgstr ""Bir sanal makineye ek kalıcı depolama ekle"" msgid ""Add additional persistent storage to a virtual machine (VM)"" msgstr ""Bir sanal makineye (VM) ek kalıcı depolama ekle"" msgid """" ""Adding back-end storage capacity to an Object Storage cluster requires "" ""careful planning and forethought. In the design phase, it is important to "" ""determine the maximum partition power required by the Object Storage "" ""service, which determines the maximum number of partitions which can exist. "" ""Object Storage distributes data among all available storage, but a partition "" ""cannot span more than one disk, so the maximum number of partitions can only "" ""be as high as the number of disks."" msgstr """" ""Bir Nesne Depolama kümesine arka uç depolama kapasitesi eklemek dikkatli "" ""planlama ve ileri görüş ister. Tasarım aşamasında, Nesne Depolama servisi "" ""tarafından ihtiyaç duyulan azami bölüm gücüne karar vermek önemlidir, bu var "" ""olabilecek azami bölüm sayısını tanımlar. Nesne Depolama veriyi tüm "" ""kullanılabilir depolamaya dağıtır, ama bir bölüm bir diskten ötesine "" ""geçemez, yani azami bölüm sayısı disklerin sayısı kadar büyük olabilir."" msgid """" ""Adding more layers to the Ethernet frame only slows the networking process "" ""down. This is known as nodal processing delay."" msgstr """" ""Ethernet çerçevesine daha fazla katman eklemek yalnızca ağ sürecini "" ""yavaşlatır. Buna düğümsel işleme gecikmesi denir."" msgid """" ""Additional capabilities can be realized by moving static web content to be "" ""served from OpenStack Object Storage containers, and backing the OpenStack "" ""Image service with OpenStack Object Storage."" msgstr """" ""Statik web içeriğinin OpenStack Nesne Depolama kapsayıcılarından "" ""sunulmasıyla ve OpenStack İmaj servisinin OpenStack Nesne Depolamayla "" ""desteklenmesiyle ek yeteneklerin farkına varılabilir."" msgid ""Additional network design considerations"" msgstr ""Ek ağ tasarım etmenleri"" msgid ""Additional networking services"" msgstr ""Ek ağ servisleri"" msgid """" ""Additionally there are several codecs that can be used to change the data "" ""representation of events such as:"" msgstr """" ""Ek olarak olayların veri sunumunu değiştirmek için kullanılabilecek değişik "" ""kodlayıcılar da bulunmaktadır:"" msgid """" ""Additionally, CPU selection may not be one-size-fits-all across enterprises, "" ""but more of a list of SKUs that are tuned for the enterprise workloads."" msgstr """" ""Ek olarak, işlemci seçimi kurumlar arasında hepsine uygun tek boy şeklinde "" ""değil de, daha çok kurumsal iş yükleri için ayarlanmış SKU'lar listesi "" ""şeklinde olabilir."" msgid """" ""Address network-focused applications when considering certain operational "" ""realities. For example, consider the impending exhaustion of IPv4 addresses, "" ""the migration to IPv6, and the use of private networks to segregate "" ""different types of traffic that an application receives or generates. In the "" ""case of IPv4 to IPv6 migrations, applications should follow best practices "" ""for storing IP addresses. We recommend you avoid relying on IPv4 features "" ""that did not carry over to the IPv6 protocol or have differences in "" ""implementation."" msgstr """" ""Belirli işlevsel gerçekleri göz önüne alırken ağ odaklı uygulamaları da göz "" ""önüne alın. Örneğin yaklaşan IPv4 adreslerinin bitişini, IPv6'ya geçişi, ve "" ""bir uygulamanın aldığı ya da ürettiği değişik türde trafik için özel ağlar "" ""ayırmayı göze alın. IPv4'den IPv6'ya geçiş durumunda, uygulamalar IP "" ""adreslerini depolamak için en iyi yöntemleri takip etmelidirler. IPv6 "" ""iletişim kurallarına taşınmamış ya da uygulanmasında farklılıklar olan IPv4 "" ""özelliklerinden uzak durmanızı öneririz."" msgid """" ""Admin establishing `encrypted volume type <https://docs.openstack.org/admin-"" ""guide/dashboard-manage-volumes.html>`_, then user selecting encrypted volume"" msgstr """" ""Yönetici `şifreli bölüm türü <https://docs.openstack.org/admin-guide/"" ""dashboard-manage-volumes.html>`_ yerleştirir, ardından kullanıcı şifreli "" ""birimi seçer"" msgid ""Administrator configuration of size settings, known as *flavors*"" msgstr """" ""Boyut ayarları için yönetici yapılandırması, *nitelikler* olarak bilinir"" msgid """" ""After an outage, ensure that operations of a site are resumed when it comes "" ""back online. We recommend that you architect the recovery to avoid race "" ""conditions."" msgstr """" ""Bir kesintiden sonra, bölge çevrimiçi olduğunda işlemlerin devam ettiğinden "" ""emin olun. Kurtarmanın yarış koşullarından etkilenmeyecek şekilde "" ""tasarlandığından emin olun."" msgid """" ""After an outage, ensure the method for resuming proper operations of a site "" ""is implemented when it comes back online. We recommend you architect the "" ""recovery to avoid race conditions."" msgstr """" ""Bir kesintiden sonra, konum tekrar çevrimiçi olduğunda yapılması gereken "" ""işlemlerin doğruluğundan emin olun. Kurtarmayı yarış durumlarına sebep "" ""olmayacak şekilde tasarlamanızı öneriyoruz."" msgid """" ""All :term:`Advanced Message Queuing Protocol (AMQP)` messages for services "" ""are received and sent according to the queue broker"" msgstr """" ""Servisler için tüm :term:`Gelişmiş İleti Kuyruklama İletişim Kuralı (AMQP)` "" ""iletileri kuyruk aracısına göre gönderilir ya da alınır"" msgid """" ""All network devices need to be aware of all MACs, even instance MACs, so "" ""there is constant churn in MAC tables and network state changes as instances "" ""start and stop."" msgstr """" ""Tüm ağ aygıtları tüm MAC'lerden, hatta sunucu MAC'lerinden haberdar "" ""olmalıdır, yani sunucular başlatılıp durduruldukça ağ durumu ve MAC "" ""tabloları sürekli değişir."" msgid """" ""All nodes within an OpenStack cloud require network connectivity. In some "" ""cases, nodes require access to more than one network segment. The design "" ""must encompass sufficient network capacity and bandwidth to ensure that all "" ""communications within the cloud, both north-south and east-west traffic, "" ""have sufficient resources available."" msgstr """" ""OpenStack bulutundaki tüm düğümlerin ağ bağlantısına ihtiyacı vardır. Bazı "" ""durumlarda, düğümler birden fazla ağ dilimine ihtiyaç duyabilir. Tasarım "" ""bulut içindeki tüm iletişimin, hem kuzey-güney hem doğu-batı trafiğinde "" ""yeterli kullanılabilir kaynağa sahip olduğuna, ağ kapasitesi ve bant "" ""genişliğinin yeterli olduğuna emin olmalıdır."" msgid """" ""All public access, whether direct, through a command-line client, or through "" ""the web-based dashboard, uses the API service. Find the API reference at "" ""`Development resources for OpenStack clouds <https://developer.openstack.org/"" "">`_."" msgstr """" ""Tüm açık erişim, doğrudan ya da komut satırı istemcisi üzerinden, veya web "" ""tabanlı kontrol panelinden, API servisini kullanır. `OpenStack bulutlar için "" ""geliştirme kaynaklarında <https://developer.openstack.org/>`_ API "" ""kaynaklarını bulabilirsiniz."" msgid """" ""All servers running OpenStack components should be able to access an "" ""appropriate NTP server. You may decide to set up one locally or use the "" ""public pools available from the `Network Time Protocol project <http://www."" ""pool.ntp.org/>`_."" msgstr """" ""OpenStack bileşenleri çalıştıran tüm sunucular uygun bir NTP sunucusuna "" ""erişebilmelidir. Yerel bir tane kurabilir ya da `Ağ Zaman İletişim Kuralı "" ""projesinden <http://www.pool.ntp.org/>`_ açık havuzlardan bir tanesini "" ""kullanabilirsiniz."" msgid ""Allows you to fetch images from Amazon S3."" msgstr ""İmajları Amazon S3'den getirmenizi sağlar."" msgid """" ""Allows you to fetch images from a web server. You cannot write images by "" ""using this mode."" msgstr """" ""İmajları bir web sunucudan getirmenizi sağlar. Bu kipi kullanarak imaj "" ""yazamazsınız."" msgid ""Allows you to store images as objects."" msgstr ""İmajları nesne olarak saklamanızı sağlar."" msgid """" ""Also consider the routing of network traffic. For some applications, develop "" ""a complex policy framework for routing. To create a routing policy that "" ""satisfies business requirements, consider the economic cost of transmitting "" ""traffic over expensive links versus cheaper links, in addition to bandwidth, "" ""latency, and jitter requirements."" msgstr """" ""Ağ trafiğinin yönlendirilmesini de dikkate alın. Bazı uygulamalar için, "" ""yönlendirme için karmaşık ilke çatıları geliştirin. İş gereksinimlerini "" ""karşılayacak bir yönlendirme ilkesi oluşturmak için, ucuz bağlantılarla "" ""pahalı bağlantılar üzerinden trafik aktarım maliyetlerini, ek olarak bant "" ""genişliği, gecikme ve kararsızlık gereksinimlerini dikkate alın."" msgid """" ""Also, you need to decide whether you want to support object storage in your "" ""cloud. The two common use cases for providing object storage in a compute "" ""cloud are to provide:"" msgstr """" ""Ayrıca, bulutunuzda nesne depolamayı destekleyip desteklemeyeceğinize de "" ""karar vermelisiniz. Bir hesaplama bulutunda nesne depolama sunmak için iki "" ""yaygın kullanım sebebi bulunur:"" msgid """" ""Although it is not a substitute for IP networking, networking at layer-2 can "" ""be a powerful adjunct to IP networking."" msgstr """" ""IP ağlarının yerine geçmese de, katman-2 ağları IP ağına ek olarak güçlü bir "" ""seçenektir."" msgid """" ""Among :term:`object`, :term:`container`, and :term:`account servers <account "" ""server>`"" msgstr """" "":term:`nesne`, :term:`kapsayıcı`, and :term:`hesap sunucuları <account "" ""server>` arasında"" msgid ""Amount of available physical storage"" msgstr ""Kullanılabilir fiziksel depolama miktarı"" msgid ""An API driven S3 compatible object store for application use."" msgstr ""Uygulama kullanımı için API güdümlü S3 uyumlu nesne depolama."" msgid """" ""An application that requires additional resources may suit a multiple cloud "" ""architecture. For example, a retailer needs additional resources during the "" ""holiday season, but does not want to add private cloud resources to meet the "" ""peak demand. The user can accommodate the increased load by bursting to a "" ""public cloud for these peak load periods. These bursts could be for long or "" ""short cycles ranging from hourly to yearly."" msgstr """" ""Ek kaynaklar gerektiren bir uygulama çoklu bulut mimarisi için uygun "" ""olabilir. Örneğin, bir satıcı tatil sezonunda ek kaynaklara ihtiyaç duyar, "" ""ama yüksek talebi karşılamak için ek özel bulut kaynakları eklemek istemez. "" ""Kullanıcı bu yük dönemlerinin tepe noktasında artan yükü açık bir buluta "" ""yönlendirerek karşılayabilir. Bu artışlar saatlik ya da yıllık gibi uzun ya "" ""da kısa döngüler halinde olabilir."" msgid """" ""An important consideration in running a cloud over time is projecting growth "" ""and utilization trends in order to plan capital expenditures for the short "" ""and long term. Gather utilization meters for compute, network, and storage, "" ""along with historical records of these meters. While securing major anchor "" ""tenants can lead to rapid jumps in the utilization of resources, the average "" ""rate of adoption of cloud services through normal usage also needs to be "" ""carefully monitored."" msgstr """" ""Bir bulutun zamanla işleyişindeki önemli etmenlerden biri proje büyümesi ve "" ""kullanım trendlerinin kısa ve uzun vadede maddi planlamasının yapılmasıdır. "" ""Hesaplama, ağ ve depolama için kullanım ölçütlerini ve bunların geçmiş "" ""kayıtlarını toplayın. Büyük kiracıların alınması kaynak kullanımının aniden "" ""artmasına sebep olacağı gibi, bulut servislerinin zamanla ortalama artışı da "" ""dikkatlice izlenmelidir."" msgid """" ""An important factor in your choice of hypervisor is your current "" ""organization's hypervisor usage or experience. Also important is the "" ""hypervisor's feature parity, documentation, and the level of community "" ""experience."" msgstr """" ""Hipervizör seçiminizdeki önemli etmen mevcut kurumunuzun hipervizör "" ""kullanımı veya deneyimidir. Hipervizörün özellik eşitliği, belgelendirmesi "" ""ve topluluk deneyimi seviyesi de önemlidir."" msgid ""An object store with a RESTful interface"" msgstr ""RESTful arayüzlü nesne depolama"" msgid """" ""An online classified advertising company wants to run web applications "" ""consisting of Tomcat, Nginx, and MariaDB in a private cloud. To meet the "" ""policy requirements, the cloud infrastructure will run in their own data "" ""center. The company has predictable load requirements but requires scaling "" ""to cope with nightly increases in demand. Their current environment does not "" ""have the flexibility to align with their goal of running an open source API "" ""environment. The current environment consists of the following:"" msgstr """" ""Çevrimiçi gizli bir reklam şirketi Tomcat, Nginx, ve MariaDB'den oluşan web "" ""uygulamalarını özel bir bulutta çalıştırmak istiyor. İlke gereksinimlerini "" ""karşılamak için, bulut alt yapısı kendi veri merkezlerinde çalışacak. "" ""Şirketin ön görülebilen yük gereksinimleri var ama gece yük artışlarını "" ""karşılayabilmek için ölçeklemeye de ihtiyaç duyuyor. Mevcut ortamları açık "" ""kaynak bir API ortamı çalıştırma amaçlarıyla örtüşmüyor. Mevcut ortam "" ""şunlardan oluşuyor:"" msgid """" ""An operations staff supports, manages, and maintains an OpenStack "" ""environment. Their skills may be specialized or varied depending on the size "" ""and purpose of the installation."" msgstr """" ""Bir işletme ekibi OpenStack ortamını destekler, yönetir ve bakım yapar. "" ""Kurulumun amacı ve boyutuna bağlı olarak yetenekleri değişken olabilir."" msgid """" ""An organization designs a large scale cloud-based web application. The "" ""application scales horizontally in a bursting behavior and generates a high "" ""instance count. The application requires an SSL connection to secure data "" ""and must not lose connection state to individual servers."" msgstr """" ""Bir kurum büyük ölçekli bulut tabanlı web uygulaması tasarlar. Uygulama "" ""artan şekilde yatay olarak ölçeklenir ve yüksek sunucu sayısına ulaşır. "" ""Uygulama veriyi güvene almak için SSL bağlantısına ihtiyaç duyar ve bağımsız "" ""sunuculara bağlantı durumunu kaybetmemelidir."" msgid """" ""An organization may have certain legal obligations and regulatory compliance "" ""measures which could require certain workloads or data to not be located in "" ""certain regions."" msgstr """" ""Bir kurumun belirli iş yüklerini veya veriyi belirli bölgelerde tutmamasını "" ""gerektiren yasal sorumluluklar veya hükümlülükleri olabilir."" msgid """" ""An overly complex network design can be difficult to maintain and "" ""troubleshoot. While device-level configuration can ease maintenance concerns "" ""and automated tools can handle overlay networks, avoid or document non-"" ""traditional interconnects between functions and specialized hardware to "" ""prevent outages."" msgstr """" ""Aşırı karmaşık bir ağ tasarımının yönetilmesi ve sorun giderilmesi zor "" ""olabilir. Aygıt seviyesinde yapılandırma yönetim endişelerini azaltabilse, "" ""ve otomatik araçlar üst katman ağları ele alabilse de, özel donanımlarla "" ""işlevler arasındaki geleneksel olmayan bağlantıları belgelendirin ve "" ""kesintileri giderebilmek için özelleşmiş donanımlar kullanın. "" msgid """" ""Analytics of large data sets are dependent on the performance of the storage "" ""system. Clouds using storage systems such as Hadoop Distributed File System "" ""(HDFS) have inefficiencies which can cause performance issues."" msgstr """" ""Büyük veri kümelerinin çözümlenmesi depolama sisteminin başarımına bağlıdır. "" ""Hadoop Dağıtık Dosya Sistemi (HDFS) gibi depolama sistemlerini kullanan "" ""bulutlar başarım sorunları yaratabilecek verimsizliklere sahiptir."" msgid """" ""Another common use case for OpenStack environments is providing a cloud-"" ""based file storage and sharing service. You might consider this a storage-"" ""focused use case, but its network-side requirements make it a network-"" ""focused use case."" msgstr """" ""OpenStack ortamları için yaygın başka bir kullanım alanı da bulut tabanlı "" ""dosya depolama ve paylaşım servisi sağlamaktır. Bunu depolama odaklı "" ""kullanım durumu olarak ele alabilirsiniz, ama ağ taraflı gereksinimleri bir "" ""ağ odaklı kullanım durumu yapar."" msgid """" ""Another consideration is when a new file is being uploaded, the proxy server "" ""must write out as many streams as there are replicas, multiplying network "" ""traffic. For a three-replica cluster, 10 Gbps in means 30 Gbps out. "" ""Combining this with the previous high bandwidth bandwidth private versus "" ""public network recommendations demands of replication is what results in the "" ""recommendation that your private network be of significantly higher "" ""bandwidth than your public network requires. OpenStack Object Storage "" ""communicates internally with unencrypted, unauthenticated rsync for "" ""performance, so the private network is required."" msgstr """" ""Diğer etmen de yeni bir dosyanın yüklendiği durumda oluşur, vekil sunucu "" ""yedek sayısı kadar akışa yazmak durumundadır, bu da ağ trafiğini katlar. Üç "" ""yedekli bir kümede, 10 Gbps içe gelen veri 30 Gbps dışa giden veri demektir. "" ""Bunu daha önceki özel ağlar ile açık ağlar için bant genişliği önerileriyle "" ""birleştirince özel ağınızın açık ağınızdan daha yüksek bant genişliğine "" ""sahip olması gerektiği sonucu ortaya çıkar. OpenStack Nesne Depolama daha "" ""iyi başarım için dahili olarak şifrelenmemiş, yetkilendirilmemiş rsync "" ""kullanır, yani özel bir ağ mecburidir."" msgid """" ""Another option is to assess the average workloads and increase the number of "" ""instances that can run within the compute environment by adjusting the "" ""overcommit ratio. This ratio is configurable for CPU and memory. The default "" ""CPU overcommit ratio is 16:1, and the default memory overcommit ratio is "" ""1.5:1. Determining the tuning of the overcommit ratios during the design "" ""phase is important as it has a direct impact on the hardware layout of your "" ""compute nodes."" msgstr """" ""Başka bir seçenek de ortalama iş yükünü değerlendirmek ve hesaplama "" ""ortamında çalışabilecek sunucu sayısını kaynak aşımı oranına oranlamaktır. "" ""Bu oran CPU ve bellek için yapılandırılabilir. Öntanımlı işlemci kaynak aşım "" ""oranı 16:1 dir, ve öntanımlı hafıza kaynak aşım oranı 1.5:1 dir. Tasarım "" ""aşamasında kaynak aşımı oranlarının ayarlanmasına karar vermek hesaplama "" ""düğümlerinizin donanım düzeni üzerinde doğrudan etkilidir."" msgid """" ""Another option to address the higher host count is to use a quad-socket "" ""platform. Taking this approach decreases host density which also increases "" ""rack count. This configuration affects the number of power connections and "" ""also impacts network and cooling requirements."" msgstr """" ""Yüksek sunucu sayısını ele almak için kullanılacak diğer seçenek dörtlü-"" ""soket platform kullanmaktır. Bu yöntemi takip etmek sunucu yoğunluğunu "" ""azaltır bu da kabin sayısını azaltır. Bu yapılandırma güç bağlantılarının "" ""sayısını ve ağ ve soğutma gereksinimlerini etkiler."" msgid """" ""Any SLA negotiation must also take into account the reliance on third "" ""parties for critical aspects of the design. For example, if there is an "" ""existing SLA on a component such as a storage system, the SLA must take into "" ""account this limitation. If the required SLA for the cloud exceeds the "" ""agreed uptime levels of the cloud components, additional redundancy would be "" ""required. This consideration is critical in a hybrid cloud design, where "" ""there are multiple third parties involved."" msgstr """" ""Tüm SLA el sıkışmaları tasarımın kritik bölgelerinde güven duyulan üçüncü "" ""tarafları da hesaba katmalıdır. Örneğin, bir depolama sistemi gibi bir "" ""bileşen için mevcut bir SLA varsa, SLA bu sınırlandırmayı hesaba katmalıdır. "" ""Bulut için gerekli SLA bulut bileşenleri için anlaşılan hizmet zamanlarını "" ""aşıyorsa, ek yedeklilik gerekecektir. Bu etmen birden fazla üçüncü taraf "" ""bulunan melez bulut tasarımında kritiktir."" msgid ""Anywhere"" msgstr ""Heryerden"" msgid ""Application"" msgstr ""Uygulama"" msgid ""Application Programming Interface (API)"" msgstr ""Uygulama Programlama Arayüzü (API)"" msgid """" ""Application design must also be factored into the capabilities of the "" ""underlying cloud infrastructure. If the compute hosts do not provide a "" ""seamless live migration capability, then it must be expected that if a "" ""compute host fails, that instance and any data local to that instance will "" ""be deleted. However, when providing an expectation to users that instances "" ""have a high-level of uptime guaranteed, the infrastructure must be deployed "" ""in a way that eliminates any single point of failure if a compute host "" ""disappears. This may include utilizing shared file systems on enterprise "" ""storage or OpenStack Block storage to provide a level of guarantee to match "" ""service features."" msgstr """" ""Altta yatan bulut alt yapısının yeteneklerine uygulama tasarımı da dahil "" ""edilmelidir. Eğer hesaplama sunucuları akıcı bir canlı göç yeteneği "" ""sunmuyorsa, bir hesaplama sunucusu bozulduğunda, bu sunucu ve sunucuya özel "" ""tüm verinin silineceği beklenmelidir. Ancak kullanıcılara sunucuların yüksek "" ""seviyede çalışma zamanına sahip olduğu garanti edilirken alt yapı da bir "" ""hesaplama sunucusu ortadan kaybolursa kırılma noktası oluşturmayacak şekilde "" ""kurulmalıdır. Bu servis özellikleriyle eşleşecek seviyede garanti sağlamak "" ""için paylaşımlı dosya sistemleri veya OpenStack Blok depolama kullanmayı da "" ""içerebilir."" msgid ""Application momentum"" msgstr ""Uygulama ivmesi"" msgid ""Application readiness"" msgstr ""Uygulama hazırlığı"" msgid ""Approximately 60 Gb of total bandwidth to the back-end storage cluster"" msgstr ""Arka uç depolama kümesine yaklaşık 60 Gb toplam bant genişliği"" msgid ""Architecture requirements"" msgstr ""Mimari gereksinimleri"" msgid ""Architecture, OpenStack"" msgstr ""Mimari, OpenStack"" msgid ""Are my storage needs mostly read, or write, or mixed?"" msgstr ""Depolama ihtiyacım çoğunlukla okuma ya da yazma mı, yoksa karışık mı?"" msgid ""Are there read, write, or random access performance requirements?"" msgstr ""Okuma, yazma, veya rasgele erişim başarım gereksinimlerim var mı?"" msgid """" ""As a general guideline, increasing the complexity of a cloud architecture "" ""increases the cost of building and maintaining it. For example, a hybrid or "" ""multi-site cloud architecture involving multiple vendors and technical "" ""architectures may require higher setup and operational costs because of the "" ""need for more sophisticated orchestration and brokerage tools than in other "" ""architectures. However, overall operational costs might be lower by virtue "" ""of using a cloud brokerage tool to deploy the workloads to the most cost "" ""effective platform."" msgstr """" ""Genel prensip olarak, bir bulut mimarisinin karmaşıklığı arttıkça inşası ve "" ""yönetiminin maliyeti de artacaktır. Örneğin, birden fazla tedarikçi ve "" ""teknik mimariye ihtiyaç duyan melez ya da birden fazla ikameli bulut "" ""mimarisi diğer mimarilerin aksine sofistike orkestrasyon ve komisyon "" ""araçlarına ihtiyaç duyacağından daha fazla kurulum ve işletim maliyet "" ""çıkarabilir. Ancak, iş yükünü en uygun maliyetli platforma dağıtan komisyon "" ""aracı kullanmanın sonucu olarak genel işlem maliyetleri daha az tutabilir."" msgid """" ""As another example, if you choose to use single-host networking where the "" ""cloud controller is the network gateway for all instances, then the cloud "" ""controller must support the total amount of traffic that travels between "" ""your cloud and the public Internet."" msgstr """" ""Başka bir örnek olarak, bulut kontrol biriminin tüm sunucular için ağ geçidi "" ""olduğu tek sunuculu ağı kullanırsanız, bulut kontrol birimi bulutunuz ve "" ""açık internet arasındaki toplam trafik miktarını da destekleyebilmelidir."" msgid """" ""As another example, you could use pairs of servers for a collective cloud "" ""controller—one active, one standby—for redundant nodes providing a given set "" ""of related services, such as:"" msgstr """" ""Başka bir örnek olarak, verilen ilişkili servisleri sağlayan yedekli "" ""düğümlere sahip olmak için toplu bir bulut kontrol birimi için—biri etkin, "" ""diğeri beklemede—olmak üzere sunucu çiftleri kullanabilirsiniz:"" msgid """" ""As demand for network resources increase, make sure your network design "" ""accommodates expansion and upgrades. Operators add additional IP address "" ""blocks and add additional bandwidth capacity. In addition, consider managing "" ""hardware and software lifecycle events, for example upgrades, "" ""decommissioning, and outages, while avoiding service interruptions for "" ""tenants."" msgstr """" ""Ağ kaynaklarına ihtiyaç arttıkça, ağ tasarımınızın genişlemeyi ve "" ""yükseltmeleri kaldıracağından emin olun. İşetmenler ek IP adresi blokları ve "" ""ek bant genişliği kapasitesi eklerler. Ek olarak, güncellemeler, emekliye "" ""ayrılma ve kesintiler gibi donanım ve yazılım yaşam döngüsü olaylarını da "" ""göz önüne alarak kiracılar için servis kesintilerini engelleyin."" msgid """" ""As more tenants begin to access data within the cluster and their data sets "" ""grow, it is necessary to add front-end bandwidth to service data access "" ""requests. Adding front-end bandwidth to an Object Storage cluster requires "" ""careful planning and design of the Object Storage proxies that tenants use "" ""to gain access to the data, along with the high availability solutions that "" ""enable easy scaling of the proxy layer. We recommend designing a front-end "" ""load balancing layer that tenants and consumers use to gain access to data "" ""stored within the cluster. This load balancing layer may be distributed "" ""across zones, regions or even across geographic boundaries, which may also "" ""require that the design encompass geo-location solutions."" msgstr """" ""Gittikçe daha çok kiracı kümedeki veriye erişmeye başladıkça ve veri "" ""kümeleri büyüdükçe, veri erişim isteklerini karşılamak için ön uç bant "" ""genişliği eklemek gereklidir. Bir Nesne Depolama kümesine ön uç bant "" ""genişliği eklemek dikkatli planlama ve kiracıların veriye erişmek için "" ""kullandığı Nesne Depolama vekillerinin tasarımını gerektirir, bunun yanında "" ""vekil katmanının kolayca ölçeklenmesini sağlayan ön uç yük yüksek "" ""kullanılırlık çözümleri de düşünülmelidir. Kiracıların ve müşterilerin "" ""kümede saklanan veriye erişmek için kullandığı bir ön uç yük dengeleme "" ""katmanı tasarlamanızı öneririz. Bu yük dengeleme katmanı bölgeler arasına, "" ""kullanılırlık bölgelerine, hatta coğrafik sınırlara dağıtılabilir, bu da "" ""tasarımın coğrafik konum çözümlerini kaldırabilmesi demektir."" msgid """" ""As of the Kilo release, key enhancements have been added to the OpenStack "" ""code to improve guest performance. These improvements allow the Compute "" ""service to take advantage of greater insight into a compute host's physical "" ""layout and therefore make smarter decisions regarding workload placement. "" ""Administrators can use this functionality to enable smarter planning choices "" ""for use cases like NFV (Network Function Virtualization) and HPC (High "" ""Performance Computing)."" msgstr """" ""Kilo dağıtımından itibaren, OpenStack koduna misafir başarımını geliştirecek "" ""anahtar iyileştirmeler eklenmiştir. Bu iyileştirmeler Hesaplama servisinin "" ""bir hesaplama sunucusunun fiziksel düzenini hakkında daha fazla bilgi sahibi "" ""olmasını sağlar, böylece iş yükü yerleştirmede daha zekice davranır. "" ""Yöneticiler bu özelliği kullanarak NFV (Ağ İşlevi Sanallaştırma) ve HPC "" ""(Yüksek Başarımlı Hesaplama) gibi kullanım durumları için daha akıllıca "" ""planlama yapabilirler."" msgid """" ""As of the Kilo release, there is no common image format that is usable by "" ""all clouds. Conversion or recreation of images is necessary if migrating "" ""between clouds. To simplify deployment, use the smallest and simplest images "" ""feasible, install only what is necessary, and use a deployment manager such "" ""as Chef or Puppet. Do not use golden images to speed up the process unless "" ""you repeatedly deploy the same images on the same cloud."" msgstr """" ""Kilo dağıtımıyla birlikte, tüm bulutlar tarafından kullanılabilir genel bir "" ""imaj biçimi yok. Bulutlar arasında göç yapılacaksa imajların dönüştürülmesi "" ""ya da yeniden oluşturulması gerekiyor. Kurulumu basitleştirmek için, en "" ""basit ve küçük imajları kullanın, yalnızca ihtiyacınız olan şeyleri kurun, "" ""ve Chef veya Puppet gibi bir kurulum yöneticisi kullanın. Tekrar tekrar aynı "" ""imajları aynı bulutta kurmuyorsanız süreci hızlandırmak için altın imajları "" ""kullanmayın."" msgid """" ""As part of the architecture design for a compute cluster, you must specify "" ""storage for the disk on which the instantiated instance runs. There are "" ""three main approaches to providing temporary storage:"" msgstr """" ""Hesaplama kümesinin mimari tasarımının bir parçası olarak, açılan sunucunun "" ""çalıştığı disk için depolama belirtmelisiniz. Geçici depolama sağlamak için "" ""üç ana yaklaşım vardır."" msgid """" ""As per the recent OpenStack user survey, KVM is the most widely adopted "" ""hypervisor in the OpenStack community. Besides KVM, there are many "" ""deployments that run other hypervisors such as LXC, VMware, Xen, and Hyper-"" ""V. However, these hypervisors are either less used, are niche hypervisors, "" ""or have limited functionality compared to more commonly used hypervisors."" msgstr """" ""Yapılan son araştırmaya göre OpenStack topluluğunda en geniş kullanım "" ""alanına sahip hipervizör KVM. KVM'nin yanında LXC, VMware, Xen, ve Hyper-V "" ""gibi diğer hipervizörleri de çalıştıran bir sürü kurulum var. Ancak bu "" ""hipervizörler ya daha az kullanılıyorlar, niş hipervizörler, veya daha fazla "" ""kullanılan hipervizörlere göre sınırlı işlevselliğe sahipler."" msgid """" ""As the cloud environment grows, the amount of log data increases "" ""exponentially. Enabling debugging on either the OpenStack services or the "" ""operating system further compounds the data issues."" msgstr """" ""Bulut ortamı büyüdükçe, günlük kaydı verisi üssel olarak artar. OpenStack "" ""servislerinde ya da işletim sisteminde hata ayıklamayı etkinleştirmek veri "" ""sorunlarını daha da artırır."" msgid """" ""As with databases and message queues, having more than one :term:`API "" ""server` is a good thing. Traditional HTTP load-balancing techniques can be "" ""used to achieve a highly available ``nova-api`` service."" msgstr """" ""Veritabanları ve ileti kuyruklarında olduğu gibi birden fazla :term:`API "" ""sunucu` olması iyi bir şeydir. Geleneksel HTTP yük dengeleme teknikleri "" ""yüksek kullanılırlıklı bir ``nova-api`` servisi elde etmek için "" ""kullanılabilir."" msgid """" ""As you add back-end storage capacity to the system, the partition maps "" ""redistribute data amongst the storage nodes. In some cases, this involves "" ""replication of extremely large data sets. In these cases, we recommend using "" ""back-end replication links that do not contend with tenants' access to data."" msgstr """" ""Sisteme arka uç depolama kapasitesi ekledikçe, bölüm haritaları veriyi diğer "" ""depolama düğümleri arasında yeniden dağıtır. Bazı durumlarda, bu oldukça "" ""büyük veri kümelerinin çoklanması anlamına gelir. Bu gibi durumlarda, "" ""kiracıların veriye erişimine karışmayacak arka uç çoklama bağlantıları "" ""kullanılmasını öneriyoruz."" msgid ""Auditing"" msgstr ""Denetleme"" msgid ""Authentication"" msgstr ""Kimlik Doğrulama"" msgid ""Authentication and Authorization"" msgstr ""Kimlik doğrulama ve Yetkilendirme"" msgid ""Authentication and authorization for identity management"" msgstr ""Kimlik yönetimi için kimlik doğrulama ve yetkilendirme"" msgid ""Availability"" msgstr ""Kullanılabilirlik"" msgid ""Available user-level quotes"" msgstr ""Kullanılabilir kullanıcı seviyesi kotaları"" msgid """" ""Avoid hardware or software vendor lock-in. The design should not rely on "" ""specific features of a vendor's network router or switch."" msgstr """" ""Donanımsal ya da yazılımsal üretici bağımlılığından uzak durun. Tasarım bir "" ""üreticinin yönlendirici ya da anahtarının belirli özelliklerine bağımlı "" ""olmamalıdır."" msgid """" ""Avoid using a hybrid cloud deployment with more than just OpenStack (or with "" ""different versions of OpenStack) as API changes can cause compatibility "" ""issues."" msgstr """" ""OpenStack (hatta farklı OpenStack sürümleriyle bile) melez bulut "" ""kurulumlarından uzak durun, API değişiklikleri uyumluluk sorunları "" ""çıkarabilir."" msgid """" ""Because sessions persist until closed, the routing and switching "" ""architecture provides high availability. Switches mesh to each hypervisor "" ""and each other, and also provide an MLAG implementation to ensure that "" ""layer-2 connectivity does not fail. Routers use VRRP and fully mesh with "" ""switches to ensure layer-3 connectivity. Since GRE provides an overlay "" ""network, Networking is present and uses the Open vSwitch agent in GRE tunnel "" ""mode. This ensures all devices can reach all other devices and that you can "" ""create tenant networks for private addressing links to the load balancer."" msgstr """" ""Oturumlar kapatılana kadar kaldıklarından, yönlendirme ve anahtarlama "" ""mimarisi yüksek kullanılırlık sağlar. Anahtarlar her bir hipervizör ve "" ""birbirleriyle örgülüdür, ayrıca katman-2 bağlantının başarısız olmadığından "" ""emin olmak için MLAG uygulaması sağlarlar. Yönlendiriciler katman-3 "" ""bağlantısından emin olmak için VRRP sağlarlar ve anahtarlarla tam örgü "" ""halindedirler. GRE bir üst katman ağı sağladığından, Ağ mevcuttur ve GRE "" ""tünel kipinde Open vSwitch aracısı kullanır. Bu, tüm aygıtların birbirine "" ""erişebilmesini ve bağlantıların yük dengeleyiciye özel adreslemesi için "" ""kiracı ağların oluşturulmasını sağlar."" msgid """" ""Because the cloud controller handles so many different services, it must be "" ""able to handle the amount of traffic that hits it. For example, if you "" ""choose to host the OpenStack Image service on the cloud controller, the "" ""cloud controller should be able to support the transferring of the images at "" ""an acceptable speed."" msgstr """" ""Bulut kontrol birimi bir çok servisi ele aldığından, gelen trafiği de "" ""kaldırabilmelidir. Örneğin OpenStack imaj servisini bulut kontrol biriminde "" ""sunmayı seçerseniz, bulut kontrol birimi imajların kabul edilebilir bir "" ""hızda aktarımını sağlayabilmelidir."" msgid ""Before reading this book, we recommend:"" msgstr ""Bu kitabı okumadan önce, şunları öneriyoruz:"" msgid ""Benefits using a Layer-2 network"" msgstr ""Katman-2 ağ kullanmanın faydaları"" msgid ""Benefits using a Layer-3 network"" msgstr ""Katman-3 ağ kullanmanın faydaları"" msgid """" ""Better support for distributed deployments across multiple datacenters "" ""through support for asynchronous eventual consistency replication."" msgstr """" ""Asenkron nihai tutarlılıklı yedekleme desteği ile birden çok veri merkezi "" ""arasında dağıtık kuruluma daha iyi destek."" msgid """" ""Between 120 and 140 installations of Nginx and Tomcat, each with 2 vCPUs and "" ""4 GB of RAM"" msgstr """" ""120 ve 140 arası Nginx ve Tomcat kurulumu, her biri 2 vCPU ve 4 GB RAM'e "" ""sahip"" msgid ""Between servers and the proxies"" msgstr ""Sunucular ve vekiller arasında"" msgid ""Between the proxies and your users"" msgstr ""Vekiller ve kullanıcılarınız arasında"" msgid """" ""Beyond the normal Identity service, Compute service, Image service, and "" ""Object Storage components, we recommend the Orchestration service component "" ""to handle the proper scaling of workloads to adjust to demand. Due to the "" ""requirement for auto-scaling, the design includes the Telemetry service. Web "" ""services tend to be bursty in load, have very defined peak and valley usage "" ""patterns and, as a result, benefit from automatic scaling of instances based "" ""upon traffic. At a network level, a split network configuration works well "" ""with databases residing on private tenant networks since these do not emit a "" ""large quantity of broadcast traffic and may need to interconnect to some "" ""databases for content."" msgstr """" ""Normal Kimlik servisi, Hesaplama servisi, İmaj servisi, ve Nesne Depolama "" ""bileşenlerinin ötesinde Orkestrasyon servis bileşenin iş yüklerinin doğru "" ""ölçeklenmesi isteğini karşılamasını öneriyoruz. Otomatik ölçeklendirme "" ""ihtiyacı yüzünden, tasarım Telemetri servisini içerir. Web servisleri yükte "" ""ani artış göstermeye meyillidir, oldukça belirli uç ve taban noktası "" ""kalıpları bulunur, ve sonuç olarak trafiğe göre sunucuların otomatik "" ""ölçeklenmesinde faydalanırlar. Ağ seviyesinde, ayrık bir ağ yapılandırması "" ""özel kiracı ağlarında duran veritabanları ile iyi çalışır, çünkü bunlar "" ""yüksek miktarda yayın trafiği üretmezler ve içerik için bazı veritabanlarına "" ""dahili olarak bağlanmaları gerekebilir. "" msgid ""Block"" msgstr ""Blok"" msgid ""Block storage"" msgstr ""Blok depolama"" msgid """" ""Block storage is implemented in OpenStack by the Block Storage service "" ""(cinder). Because these volumes are persistent, they can be detached from "" ""one instance and re-attached to another instance and the data remains intact."" msgstr """" ""Blok depolama OpenStack'de Blok Depolama servisi (cinder) tarafından "" ""uygulanır. Bu birimler kalıcı olduklarından, veriyi bozmadan bir sunucudan "" ""ayrılıp başka bir sunucuya tekrar eklenebilirler."" msgid ""Broker between clouds"" msgstr ""Bulutlar arasında aracı"" msgid """" ""Brokering software evaluates relative costs between different cloud "" ""platforms. Cloud Management Platforms (CMP) allow the designer to determine "" ""the right location for the workload based on predetermined criteria."" msgstr """" ""Aracı yazılım farklı bulut platformları arasında masrafları değerlendirir. "" ""Bulut Yönetim Platformları (CMP) tasarımcıya önceden tanımlanmış kriterlere "" ""göre iş yükü için doğru konumu belirleme imkanı verir."" msgid """" ""Business changes can affect provider availability. Likewise, changes in a "" ""provider's service can disrupt a hybrid cloud environment or increase costs."" msgstr """" ""İş değişiklikleri sağlayıcı kullanılırlığını etkileyebilir. Aynı şekilde, "" ""bir sağlayıcının servisindeki değişiklikler melez bulut ortamını bozabilir "" ""veya masrafları artırabilir."" msgid ""Business or technical diversity"" msgstr ""İş veya teknik çeşitlilik"" msgid """" ""Businesses with existing applications may find that it is more cost "" ""effective to integrate applications on multiple cloud platforms than "" ""migrating them to a single platform."" msgstr """" ""Mevcut uygulamalara sahip işler uygulamaları tek bir plaformda toplamak "" ""yerine birden çok bulut platformuna tümleştirmenin daha masrafsız olacağını "" ""bulabilirler."" msgid """" ""By definition, a cloud provides end users with the ability to self-provision "" ""computing power, storage, networks, and software in a simple and flexible "" ""way. The user must be able to scale their resources up to a substantial "" ""level without disrupting the underlying host operations. One of the benefits "" ""of using a general purpose cloud architecture is the ability to start with "" ""limited resources and increase them over time as the user demand grows."" msgstr """" ""Tanım olarak bulut, son kullanıcılara hesaplama gücü, depolama, ağlar, ve "" ""yazılımı esnek bir yolla kendi kendine sağlama olanağı verir. Kullanıcı "" ""kaynaklarını alt katmandaki sunucu işlemlerini rahatsız etmeden kaynaklarını "" ""azımsanmayacak seviyelere ölçekleyebilir olmalıdır. Genel amaçlı bir bulut "" ""mimarisi kullanmanın faydalarından biri sınırlı kaynaklarla başlayıp "" ""kullanıcı gereksinimi arttıkça arttırabilmektir."" msgid """" ""CMPs simplify the migration of application workloads between public, "" ""private, and hybrid cloud platforms."" msgstr """" ""CMP'ler açık, özel, ve melez bulut platformları arasındaki uygulama iş "" ""yüklerinin göçünü basitleştirir."" msgid ""CPU allocation ratio: 16:1"" msgstr ""CPU ayırma oranı: 16:1"" msgid ""CPU overcommit ratio (virtual cores per physical core)"" msgstr ""CPU abonelik aşım oranı (fiziksel çekirdek başına sanal çekirdek)"" msgid ""Capacity"" msgstr ""Kapasite"" msgid ""Capacity and scale"" msgstr ""Kapasite ve ölçek"" msgid """" ""Capacity and the placement of workloads are key design considerations for "" ""clouds. A long-term capacity plan for these designs must incorporate growth "" ""over time to prevent permanent consumption of more expensive external "" ""clouds. To avoid this scenario, account for future applications' capacity "" ""requirements and plan growth appropriately."" msgstr """" ""İş yüklerinin kapasite ve yerleştirmeleri bulutlar için anahtar tasarım "" ""ölçütlerindendir. Bu tasarımlar için uzun soluklu kapasite planı daha pahalı "" ""harici bulutların sürekli tüketimini önlemek için zaman bağlı büyümeyi göz "" ""önüne almalıdır. Bu senaryodan kaçınmak için, gelecekteki uygulamaların "" ""kapasite gereksinimlerini de hesaba katın ve uygun büyüme planını yapın."" msgid ""Capacity planning"" msgstr ""Kapasite planlama"" msgid ""Capacity planning and scalability"" msgstr ""Kapasite planlama ve ölçeklendirme"" msgid """" ""Care must be taken when deciding network functionality. Currently, OpenStack "" ""supports both the legacy networking (nova-network) system and the newer, "" ""extensible OpenStack Networking (neutron). OpenStack Networking and legacy "" ""networking both have their advantages and disadvantages. They are both valid "" ""and supported options that fit different network deployment models described "" ""in the `OpenStack Operations Guide <https://docs.openstack.org/ops-guide/"" ""arch_network_design.html#network-topology>`_."" msgstr """" ""Ağ işlevselliğine karar verilirken dikkat edilmelidir. Şu an OpenStack hem "" ""eski ağ (nova-network) sistemini, hem daha yeni OpenStack Ağını (neutron) "" ""destekler. OpenStack Ağı ve eski ağın kendine göre avantajı ve dezavantajı "" ""vardır. Her ikisi de `OpenStack İşlem Kılavuzunda <https://docs.openstack."" ""org/ops-guide/arch_network_design.html#network-topology>`_ geçerli ve "" ""desteklenen seçeneklerdir."" msgid ""Ceph"" msgstr ""Ceph"" msgid """" ""Ceph is a scalable storage solution that replicates data across commodity "" ""storage nodes."" msgstr """" ""Ceph veriyi ticari depolama düğümleri arasında çoğaltan ölçeklenebilir bir "" ""depolama çözümüdür."" msgid """" ""Ceph provides support for the same Object Storage API as swift and can be "" ""used as a back end for the Block Storage service (cinder) as well as back-"" ""end storage for glance images."" msgstr """" ""Ceph swift ile aynı Nesne Depolama API'si için destek sağlar ve Blok "" ""Depolama servisi (cinder) için arka uç olarak kullanılabileceği gibi glanc "" ""imajları için de arka uç olarak kullanılabilir."" msgid """" ""Ceph supports thin provisioning implemented using copy-on-write. This can be "" ""useful when booting from volume because a new volume can be provisioned very "" ""quickly. Ceph also supports keystone-based authentication (as of version "" ""0.56), so it can be a seamless swap in for the default OpenStack swift "" ""implementation."" msgstr """" ""Ceph yazmada-kopyalama kullanılarak uygulanan ince hazırlamaları destekler. "" ""Bu birimden önyükleme yaparken kullanışlı olabilir çünkü yeni birim çok "" ""hızlı hazırlanabilir. Ceph ayrıca keystone tabanlı kimlik doğrulamayı "" ""destekler (0.56 sürümünden itibaren), böylece öntanımlı OpenStack swift "" ""uygulaması için kolaylıkla takas edilebilir."" msgid """" ""Ceph utilises and object storage mechanism for data storage and exposes the "" ""data via different types of storage interfaces to the end user it supports "" ""interfaces for: - Object storage - Block storage - File-system interfaces"" msgstr """" ""Ceph veri depolama için bir nesne depolama mekanizması kullanır ve veriyi "" ""arayüz sağladığı son kullanıcı için farklı depolama arayüzleri halinde "" ""ortaya çıkarır: - Nesne depolama - Blok depolama - Dosya sistemi arayüzleri"" msgid ""Ceph's advantages include:"" msgstr ""Ceph'in avantajları şunları içerir:"" msgid """" ""Changing the CPU overcommit ratio can have a detrimental effect and cause a "" ""potential increase in a noisy neighbor."" msgstr """" ""İşlemci kaynak aşım oranını değiştirmenin zararlı etkisi vardır ve gürültülü "" ""komşuları artırır."" msgid """" ""Cheaper storage makes the public cloud suitable for maintaining backup "" ""applications."" msgstr """" ""Daha ucuz depolama açık bulutu yedek uygulamalarını sürdürebilmek için uygun "" ""yapar."" msgid ""Choice of file system"" msgstr ""Dosya sistemi seçimi"" msgid ""Choosing a CPU"" msgstr ""Bir işlemci seçmek"" msgid ""Choosing a hypervisor"" msgstr ""Hipervizör seçmek"" msgid ""Choosing network hardware"" msgstr ""Ağ donanımı seçmek"" msgid ""Choosing networking software"" msgstr ""Ağ yazılımı seçmek"" msgid ""Choosing server hardware"" msgstr ""Sunucu donanımı seçmek"" msgid ""Choosing storage back ends"" msgstr ""Depolama arka ucu seçimi"" msgid ""Cloud management platform tools"" msgstr ""Bulut yönetim platformu araçları"" msgid """" ""Cloud networks require management for capacity and growth over time. "" ""Capacity planning includes the purchase of network circuits and hardware "" ""that can potentially have lead times measured in months or years."" msgstr """" ""Bulut ağları zamanla kapasite ve büyüme için yönetim gerektirirler. Kapasite "" ""planlama aylar ya da yıllar sürebilecek tedarik sürelerine sahip ağ "" ""devreleri ve donanımının alınmasını kapsar."" msgid ""Cloud resource deployment"" msgstr ""Bulut kaynak kurulumu"" msgid ""Cloud storage"" msgstr ""Bulut depolama"" msgid """" ""Cloud users expect a fully self-service and on-demand consumption model. "" ""When an OpenStack cloud reaches the massively scalable size, expect "" ""consumption as a service in each and every way."" msgstr """" ""Bulut kullanıcıları tamamen kendine servis ve isteğe bağlı tüketim modeli "" ""beklerler. Bir OpenStack bulutu büyük ölçeklerde boyuta ulaştığında, her "" ""yönüyle servis olarak tüketim bekleyin."" msgid """" ""Combine several shares in groups to keep data consistency inside the groups "" ""for the following safe group operations."" msgstr """" ""Aşağıdaki güvenli grup işlemleri için gruplarda veri tutarlılığını korumak "" ""için bir çok paylaşımo gruplar haline getir. "" msgid ""Command-line interface (CLI)"" msgstr ""Komut Satırı Arayüzü (CLI)"" msgid ""Commodity storage technologies"" msgstr ""Ticari depolama teknolojileri"" msgid """" ""Complex clouds, in particular hybrid clouds, may require tools to facilitate "" ""working across multiple clouds."" msgstr """" ""Karmaşık bulutlar, özellikle melez bulutlar, birden çok bulut arasında "" ""çalışmayı kolaylaştırmak için araçlara ihtiyaç duyabilirler."" msgid ""Complexity"" msgstr ""Karmaşıklık"" msgid ""Compliance and geo-location"" msgstr ""Uyumluluk ve coğrafi konum"" msgid """" ""Compliance considerations are particularly important for multi-site clouds. "" ""Considerations include:"" msgstr """" ""Uyum yükümlülükleri özellikle çoklu konum bulutları için önemlidir. "" ""Yükümlülükler şunları içerir:"" msgid ""Component block diagram"" msgstr ""Bileşen blok şeması"" msgid ""Compute analytics with data processing service"" msgstr ""Veri işleme servisine sahip hesaplama analitikleri"" msgid ""Compute analytics with parallel file systems"" msgstr ""Paralel dosya sistemleri olan hesaplama analitikleri"" msgid """" ""Compute capacity (CPU cores and RAM capacity) is a secondary consideration "" ""for selecting server hardware. The required server hardware must supply "" ""adequate CPU sockets, additional CPU cores, and adequate RA. For more "" ""information, see :ref:`choosing-a-cpu`."" msgstr """" ""Hesaplama kapasitesi (CPU çekirdekleri ve RAM kapasitesi) sunucu donanımı "" ""seçerken ikincil etmenlerdir. Gerekli sunucu donanımı uygun CPU soketlerini, "" ""ek CPU çekirdeklerini ve uygun RA sağlayabilmelidir. Daha fazla bilgi için "" ""bknz :ref:`choosing-a-cpu`."" msgid ""Compute node design"" msgstr ""Hesaplama düğümü tasarımı"" msgid """" ""Compute nodes automatically attach to OpenStack clouds, resulting in a "" ""horizontally scaling process when adding extra compute capacity to an "" ""OpenStack cloud. To further group compute nodes and place nodes into "" ""appropriate availability zones and host aggregates, additional work is "" ""required. It is necessary to plan rack capacity and network switches as "" ""scaling out compute hosts directly affects data center infrastructure "" ""resources as would any other infrastructure expansion."" msgstr """" ""OpenStack bulutuna ek hesaplama kapasitesi eklerken hesaplama düğümleri "" ""otomatik olarak OpenStack bulutuna eklenirler ve yatay ölçeklemeyi "" ""sağlarlar. Hesaplama düğümlerini daha fazla gruplandırmak ve düğümleri uygun "" ""kullanılırlık bölgesine ve istemci takımlarına yerleştirmek için ek iş "" ""gerekir. Hesaplama sunucularının ölçeklenmesi veri merkezi alt yapı "" ""kaynaklarını herhangi bir alt yapı genişletmede olduğu gibi doğrudan "" ""etkileyeceğinden kabin kapasitesi ve ağ anahtarlarını planlamak gereklidir. "" msgid ""Compute resources"" msgstr ""Hesaplama kaynakları"" msgid ""Compute server architecture overview"" msgstr ""Hesaplama sunucusu mimarisi genel görünüşü"" msgid ""Compute server logging"" msgstr ""Hesaplama sunucusu günlük kaydı"" msgid ""Conductor Services"" msgstr ""Orkestra Yönetim Servisleri"" msgid ""Conductor services"" msgstr ""Orkestra yönetim servisleri"" msgid """" ""Configure Block Storage resource nodes with advanced RAID controllers and "" ""high-performance disks to provide fault tolerance at the hardware level."" msgstr """" ""Donanım seviyesinde arızaya dayanıklılık sağlamak için gelişmiş RAID "" ""denetleyicilerine ve yüksek başarımlı disklere sahip kaynak düğümleri olan "" ""Blok Depolama yapılandırın."" msgid """" ""Configure cloud networks to minimize link loss, packet loss, packet storms, "" ""broadcast storms, and loops."" msgstr """" ""Bulut ağlarını bağlantı kaybı, paket kaybı, paket fırtınaları, yayım "" ""fırtınaları, ve döngüleri asgaride tutmak üzere yapılandırın."" msgid ""Configuring ARP can be complicated on a large layer-2 networks."" msgstr ""Büyük bir katman-2 ağda ARP yapılandırması karmaşık olabilir."" msgid """" ""Configuring incorrect IP addresses, VLANs, and routers can cause outages to "" ""areas of the network or, in the worst-case scenario, the entire cloud "" ""infrastructure. Automate network configurations to minimize the opportunity "" ""for operator error as it can cause disruptive problems."" msgstr """" ""Geçersiz IP adresleri, VLAN'lar, ve yönlendiriciler yapılandırmak ağın belli "" ""kısımlarında kesintiye, ya da en kötü durumda tüm bulut alt yapısının "" ""kesintisine neden olabilir. İşletmen hataları yıkıcı sorunlara sebep "" ""olabileceğinden ağ yapılandırmasını otomatikleştirin."" msgid """" ""Connecting more than two sites increases the challenges and adds more "" ""complexity to the design considerations. Multi-site implementations require "" ""planning to address the additional topology used for internal and external "" ""connectivity. Some options include full mesh topology, hub spoke, spine "" ""leaf, and 3D Torus."" msgstr """" ""İkiden çok konumu bağlamak tasarım nazarında daha çok karmaşıklık ekler ve "" ""işleri zorlaştırır. Birden çok konum uygulamaları planlama ve dahili ve "" ""harici bağlantılar için kullanılacak topolojiye ek planlama gerektirir. Tam "" ""örgü topolojisi, hub spoke, spine leaf, ve 3D Torus seçeneklerden "" ""bazılarıdır."" msgid ""Connectivity"" msgstr ""Bağlanabilirlik"" msgid """" ""Consider additional design decisions about monitoring and alarming. If you "" ""are using an external provider, service level agreements (SLAs) are "" ""typically defined in your contract. Operational considerations such as "" ""bandwidth, latency, and jitter can be part of the SLA."" msgstr """" ""İzleme ve alarm hakkında ek tasarım kararlarını göz önüne alın. Harici bir "" ""sağlayıcı kullanıyorsanız, servis seviyesi anlaşmaları (SLA'lar) muhtemelen "" ""anlaşmanızda tanımlanmıştır. Bant genişliği, gecikme ve kararsızlık gibi "" ""işlevsel etkenler SLA'nın bir parçası olabilir."" msgid """" ""Consider configurable networking components related to an OpenStack "" ""architecture design when designing for network intensive workloads that "" ""include MTU and QoS. Some workloads require a larger MTU than normal due to "" ""the transfer of large blocks of data. When providing network service for "" ""applications such as video streaming or storage replication, we recommend "" ""that you configure both OpenStack hardware nodes and the supporting network "" ""equipment for jumbo frames where possible. This allows for better use of "" ""available bandwidth. Configure jumbo frames across the complete path the "" ""packets traverse. If one network component is not capable of handling jumbo "" ""frames then the entire path reverts to the default MTU."" msgstr """" ""MTU ve QoS içeren ağ ağırlıklı iş yükleri için tasarım yaparken OpenStack "" ""ile ilişkili yapılandırılabilir ağ bileşenlerini göz önüne alın. Bazı iş "" ""yükleri büyük veri bloklarının aktarımı yüzünden daha büyük MTU değerine "" ""ihtiyaç duyarlar. Video akışı veya depolama yedekleme gibi uygulamalar için "" ""ağ servisi sağlarken hem OpenStack donanım düğümlerini hem de destekleyen ağ "" ""ekipmanını jumbo çerçeveler için yapılandırmanızı öneriyoruz. Bu "" ""kullanılabilir bant genişliğinin daha iyi kullanılmasını sağlar. Paketlerin "" ""aldıkları tüm yol boyunca jumbo çerçeveleri yapılandırın. Eğer bir ağ "" ""bileşeni jumbo çerçeveleri destekleyemiyorsa tüm yol öntanımlı MTU'ya "" ""dönecektir."" msgid """" ""Consider high availability at the physical and environmental layers. If "" ""there is a single point of failure due to only one upstream link, or only "" ""one power supply, an outage can become unavoidable."" msgstr """" ""Yüksek kullanılırlığı fiziksel ve ortamsal katmanlarda göz önüne alın. "" ""Yukarı tek bağlantınız varsa, veya tek güç kaynağınız varsa, kesinti "" ""kaçınılmazdır."" msgid """" ""Consider the Compute requirements of non-hypervisor nodes (also referred to "" ""as resource nodes). This includes controller, Object Storage nodes, Block "" ""Storage nodes, and networking services."" msgstr """" ""Hipervizör olmayan düğümlerin Hesaplama gereksinimlerine dikkat edin (kaynak "" ""düğümler de denir). Bu kontrol, Nesne Depolama düğümleri, Blok Depolama "" ""düğümleri, ve ağ servislerini içerir."" msgid """" ""Consider the default value of the number of replicas, which is three. This "" ""means that before an object is marked as having been written, at least two "" ""copies exist in case a single server fails to write, the third copy may or "" ""may not yet exist when the write operation initially returns. Altering this "" ""number increases the robustness of your data, but reduces the amount of "" ""storage you have available. Look at the placement of your servers. Consider "" ""spreading them widely throughout your data center's network and power-"" ""failure zones. Is a zone a rack, a server, or a disk?"" msgstr """" ""Kopya yedek sayısını öntanımlı değerini dikkate alın, varsayılan üçtür. "" ""Bunun anlamı bir nesnenin yazıldı olarak işaretlenmeden önce en az iki "" ""kopyasının tek bir sunucunun yazmada başarısız olması ihtimaline karşı var "" ""olduğudur, üçüncü kopya yazma işlemi döndüğünde henüz var olabilir de "" ""olmayabilir de. Bu sayıyla oynamak verinizin dayanıklılığını artırır, ama "" ""kullanılabilir alanınızı azaltır. Sunucularınızn yerleşimine bakın. Veri "" ""merkezinizin ağ ve güç arzıa bölgeleri arasında dağıtın. Bölge bir kabin mi, "" ""sunucu mu yoksa disk mi?"" msgid ""Consider the following costs categories when designing a cloud:"" msgstr ""Bulut tasarlarken şu maliyet kategorilerini göz önünde tutun:"" msgid ""Consider the following factors when selecting compute server hardware:"" msgstr ""Hesaplama sunucusu donanımı seçerken şu etmenlere dikkat edin:"" msgid """" ""Consider the following in selecting server hardware form factor suited for "" ""your OpenStack design architecture:"" msgstr """" ""OpenStack tasarım mimarinize uyumlu donanım biçim katsayısını seçerken "" ""şunlara dikkat edin:"" msgid """" ""Consider the scenario where an entire server fails and 24 TB of data needs "" ""to be transferred \""immediately\"" to remain at three copies — this can put "" ""significant load on the network."" msgstr """" ""Bir sunucunun tamamen arızalandığını ve üç kopyanın sağlanabilmesi için 24 "" ""TB verinin \""anında\"" aktarılması gerektiğini düşünün — bu ağda oldukça "" ""yüksek yüke sebep olabilir."" msgid """" ""Consider the security of data between the client and the endpoint, and of "" ""traffic that traverses the multiple clouds."" msgstr """" ""İstemci ve uç nokta arasındaki verinin güvenliğini ve birden çok bulut "" ""arasında akan trafiğin güvenliğini dikkate alın."" msgid ""Consider these main traffic flows for an Object Storage network:"" msgstr ""Bir Nesne Depolama ağı için şu ana trafik akışlarını göz önüne alın:"" msgid ""Consideration"" msgstr ""Etmen"" msgid """" ""Considerations affecting storage architecture (and corresponding storage "" ""hardware) of a Storage-focused OpenStack cloud include:"" msgstr """" ""Depolama odaklı bir OpenStack bulutunun depolama mimarisini etkileyen "" ""etmenleri (ve ilişkili depolama donanımı) şunları içerir:"" msgid ""Considerations when choosing hardware"" msgstr ""Donanım seçerken göz önüne alınacaklar"" msgid """" ""Considering non-uniform memory access (NUMA) is important when selecting CPU "" ""sizes and types, as there are use cases that use NUMA pinning to reserve "" ""host cores for operating system processes. These reduce the available CPU "" ""for workloads and protects the operating system."" msgstr """" ""İşlemci boyut ve türünü seçerken düzensiz hafıza erişimi (NUMA) önemlidir, "" ""çünkü işletim sistemi süreçleri için sunucu çekirdeklerini ayırmak için NUMA "" ""sabitlemesinin kullanıldığı durumlar bulunur. Bu, iş yükler için "" ""kullanılabilir işlemciyi azaltarak işletim sistemini korur."" msgid ""Considering these requirements, we recommend the following:"" msgstr ""Bu gereksinimleri göz önüne alarak, şunları öneriyoruz:"" msgid ""Consolidation of object storage and block storage."" msgstr ""Nesne depolama ve blok depolamanın pekiştirilmesi."" msgid """" ""Consult the vendor documentation to check for virtualization support. For "" ""Intel CPUs, see `Does my processor support Intel® Virtualization Technology? "" ""<https://www.intel.com/content/www/us/en/support/processors/000005486."" ""html>`_. For AMD CPUs, see `AMD Virtualization <https://www.amd.com/en-us/"" ""innovations/software-technologies/server-solution/virtualization>`_. Your "" ""CPU may support virtualization but it may be disabled. Consult your BIOS "" ""documentation for how to enable CPU features."" msgstr """" ""Sanallaştırma desteği için üretici belgelendirmesine danışın. Intel "" ""işlemciler için, `İşlemcim Intel® Sanallaştırma Teknolojisini destekliyor "" ""mu? <https://www.intel.com/content/www/us/en/support/processors/000005486."" ""html>`_ ve AMD işlemciler için `AMD Sanallaştırma <https://www.amd.com/en-us/"" ""innovations/software-technologies/server-solution/virtualization>`_ "" ""belgelerine göz atın. İşlemciniz sanallaştırmayı desteklemesine rağmen bu "" ""özellik kapalı olabilir. İşlemci özelliklerini etkinleştirmeyle ilgili bilgi "" ""için BIOS belgelendirmenize göz atın."" msgid """" ""Consumers of external clouds rarely have control over provider changes to "" ""APIs, and changes can break compatibility. Using only the most common and "" ""basic APIs can minimize potential conflicts."" msgstr """" ""Harici bulut tüketicilerinin sağlayıcıların API'lere yaptığı değişiklikler "" ""üzerinde kontrolleri çoğunlukla olmaz, ve değişiklikler uyumluluğu "" ""bozabilir. Yalnızca en genel ve temel API'leri kullanmak çakışmaları asgari "" ""düzeye indirebilir."" msgid ""Consumption model"" msgstr ""Tüketim modeli"" msgid ""Contents"" msgstr ""İçindekiler"" msgid ""Control Plane"" msgstr ""Kontrol Düzlemi"" msgid """" ""Control Plane - ancillary services such as API endpoints, and services that "" ""control CRUD operations. The services in this category are usually subject "" ""to a different SLA expectation and may be better suited on separate hardware "" ""or containers from the Data Plane services."" msgstr """" ""Kontrol Düzlemi - API uç noktaları, ve CRUD işlemlerini kontrol eden ikincil "" ""servisler. Bu kategorideki servisler genellikle farklı SLA beklentilerine "" ""sahiptirler ve Veri Düzlemi servislerinden ayrı donanım veya kapsayıcılar "" ""için daha uygundurlar."" msgid ""Controlling traffic with routing metrics is straightforward."" msgstr ""Yönlendirme ölçütleriyle trafiği kontrol etmek kolaydır."" msgid ""Cost"" msgstr ""Maliyet"" msgid """" ""Cost The relative cost of the hardware weighed against the total amount of "" ""capacity available on the hardware based on predetermined requirements."" msgstr """" ""Önceden belirlenmiş gereksinimlere göre donanımın donanım tam "" ""kapasitedeykenki haline göre fiyat oranı."" msgid ""Create a share from a snapshot."" msgstr ""Anlık görüntüden paylaşım oluştur."" msgid """" ""Create a share on either a share server or standalone, depending on the "" ""selected back-end mode, with or without using a share network."" msgstr """" ""Seçili arka uç kipine göre bir paylaşım ağı kullanarak ya da kullanmayarak "" ""bir paylaşım sunucusu ya da tek başına sunucuda paylaşım oluştur."" msgid """" ""Create a share specifying its size, shared file system protocol, visibility "" ""level."" msgstr """" ""Boyutunu, paylaşım dosya sistemi iletişim kuralını, görünürlük seviyesini "" ""belirterek bir paylaşım oluşturun."" msgid """" ""Create a snapshot of a selected share or a share group for storing the "" ""existing shares consistently or creating new shares from that snapshot in a "" ""consistent way."" msgstr """" ""Mevcut paylaşımları tutarlı tutmak ya da bu anlık görüntüden tutarlı bir "" ""yolla yeni paylaşımlar oluşturmak için seçili bir paylaşımın veya paylaşım "" ""grubunun anlık görüntüsünü oluştur."" msgid ""DHCP"" msgstr ""DHCP"" msgid ""DNS"" msgstr ""DNS"" msgid ""Daemon"" msgstr ""Artalan İşlemi"" msgid ""Dashboard"" msgstr ""Kontrol Paneli"" msgid """" ""Data Plane - services that provide virtualization, networking, and storage. "" ""Customers usually require these services to be continuously available."" msgstr """" ""Veri Düzlemi - sanallaştırma, ağ ve deoplama sağlayan servisler. Müşteriler "" ""genellikle bu servislerin sürekli kullanılır olmasını beklerler."" msgid """" ""Data centers have a specified amount of power fed to a given rack or set of "" ""racks. Older data centers may have power densities as low as 20A per rack, "" ""and current data centers can be designed to support power densities as high "" ""as 120A per rack. The selected server hardware must take power density into "" ""account."" msgstr """" ""Veri merkezlerinde bir kabin ya da kabin kümesine belirli miktarda güç "" ""beslemesi yapılır. Eski veri merkezlerinin kabin başına 20A kadar düşük "" ""olabilirken, mevcut veri merkezleri kabin başına 120A yüksekliği "" ""destekleyecek güçle tasarlanabilir. Seçilen donanımda güç yoğunluğu hesaba "" ""katılmalıdır."" msgid """" ""Data in an OpenStack cloud moves between instances across the network (known "" ""as east-west traffic), as well as in and out of the system (known as north-"" ""south traffic). Physical server nodes have network requirements that are "" ""independent of instance network requirements and must be isolated to account "" ""for scalability. We recommend separating the networks for security purposes "" ""and tuning performance through traffic shaping."" msgstr """" ""OpenStack bulutunda veri sunucular arasında ağlar üzerinden (doğu-batı "" ""trafiği olarak bilinir), ve sistemden dışarı (kuzey-güney trafiği olarak "" ""bilinir) hareket eder. Ölçeklenebilirliğin devamı için sunucu ağı "" ""gereksinimlerinden farklı ihtiyaçları olan fiziksel sunucu düğümlerinin ağı "" ""yalıtılmalıdır. Güvenlik amacıyla ve trafik şekillendirme ile başarımın "" ""artırılması için ağların ayrılmasını öneriyoruz."" msgid ""Data plane and control plane"" msgstr ""Veri ve kontrol düzlemi"" msgid ""Data security recommendations:"" msgstr ""Veri güvenliği önerileri:"" msgid ""Database"" msgstr ""Veritabanı"" msgid ""Database and message queue server (such as MySQL, RabbitMQ)"" msgstr ""Veritabanı ve ileti kuyruğu sunucusu (MySQL, RabbitMQ gibi)"" msgid ""Database services, such as ``MySQL`` or ``PostgreSQL``."" msgstr ""``MySQL`` veya ``PostgreSQL`` gibi veritabanı servisleri."" msgid ""Database software"" msgstr ""Veritabanı yazılımı"" msgid ""Databases"" msgstr ""Veritabanları"" msgid """" ""Databases are a common workload that benefit from high performance storage "" ""back ends. Although enterprise storage is not a requirement, many "" ""environments have existing storage that OpenStack cloud can use as back "" ""ends. You can create a storage pool to provide block devices with OpenStack "" ""Block Storage for instances as well as object interfaces. In this example, "" ""the database I-O requirements are high and demand storage presented from a "" ""fast SSD pool."" msgstr """" ""Veritabanları yüksek başarımlı depolama arka uçlarından faydalanan yaygın iş "" ""yükleridir. Kurumsal depolama gereklilik olmasa da, çoğu ortam OpenStack "" ""bulutunun arka uç olarak kullanabileceği mevcut depolamaya sahiptir. "" ""Sunucular ve nesne arayüzleri için OpenStack Blok Depolama ile blok aygıtlar "" ""sunmask için depolama havuzları oluşturabilirsiniz. Bu örnekte veritabanı I/"" ""O gereksinimleri yüksektir ve hızlı SSD havuzundan sunulan depolamaya "" ""ihtiyaç duyulur."" msgid """" ""Decide on a network framework and design minimum functionality tests. This "" ""ensures testing and functionality persists during and after upgrades."" msgstr """" ""Bir ağ çatısında karar kılın ve asgari işlevsellik denemelerini tasarlayın. "" ""Bu yükseltme sürecinde ve sonrasında işlevselliğin kalıcı olduğunu "" ""denemenizi sağlar."" msgid ""Deleted by user"" msgstr ""Kullanıcı tarafından silindi"" msgid """" ""Depending on design, heavy I/O usage from some instances can affect "" ""unrelated instances."" msgstr """" ""Tasarıma bağlı olarak, bazı sunuculardaki ağır I/O kullanımı ilgisiz "" ""sunucuları etkileyebilir."" msgid """" ""Depending on the design, some network service functions may fall into both "" ""the Control and Data Plane categories. For example, the neutron L3 Agent "" ""service may be considered a Control Plane component, but the routers "" ""themselves would be a Data Plane component."" msgstr """" ""Tasarıma bağlı olarak, bazı ağ servisi işlevleri hem Kontrol hem Veri "" ""Düzlemi kategorisine girebilir. Örneğin, neutron L3 Aracı servisi Kontrol "" ""Düzlemi bileşeni sayılabilir, ama yönlendiricilerin kendileri Veri Düzlemi "" ""bileşenidir."" msgid """" ""Depending on the storage architecture, you can adopt a scale-out solution, "" ""or use a highly expandable and scalable centralized storage array. If a "" ""centralized storage array meets your requirements, then the array vendor "" ""determines the hardware selection. It is possible to build a storage array "" ""using commodity hardware with Open Source software, but requires people with "" ""expertise to build such a system."" msgstr """" ""Depolama mimarisine bağlı olarak, bir dışa ölçekleme çözümü edinebilirsiniz, "" ""veya yüksek genişleyebilirlikli ve ölçeklenebilir merkezi depolama dizisi "" ""kullanabilirsiniz. Eğer merkezi depolama dizisi gereksinimlerinizi "" ""karşılıyorsa, dizi üreticisi donanım seçiminizi belirler. Ticari donanımla "" ""ve Açık Kaynaklı yazılımlarla depolama dizisi inşa etmek de mümkündür, ama "" ""böyle bir sistemi inşa edecek deneyimli kişilere ihtiyaç duyulur."" msgid """" ""Depends completely on the size of back-end storage specified when a share "" ""was being created. In case of thin provisioning it can be partial space "" ""reservation (for more details see `Capabilities and Extra-Specs <https://"" ""docs.openstack.org/developer/manila/devref/capabilities_and_extra_specs.html?"" ""highlight=extra%20specs#common-capabilities>`_ specification)"" msgstr """" ""Tamamen bir paylaşım oluşturulduğunda tanımlanan arka uç depolamanın "" ""boyutuna bağlıdır. İnce hazırlık durumunda kısmi alan ayrımı olabilir (daha "" ""fazla ayrıntı için `Kapasite ve Ek Özellikler <https://docs.openstack.org/"" ""developer/manila/devref/capabilities_and_extra_specs.html?highlight=extra"" ""%20specs#common-capabilities>`_ tanımına göz atın)"" msgid ""Deployment considerations"" msgstr ""Kurulum etmenleri"" msgid ""Design"" msgstr ""Tasarım"" msgid """" ""Design a Layer-3 network architecture rather than a layer-2 network "" ""architecture."" msgstr ""Katman-2 ağ mimarisindense katman-2 ağ mimarisi tasarlayın."" msgid """" ""Design a dense multi-path network core to support multi-directional scaling "" ""and flexibility."" msgstr """" ""Çok yönlü ölçeklenebilirlik ve esneklik sağlamak için yoğun çok yollu bir ağ "" ""tasarlayın."" msgid """" ""Design for cost efficient operations to take advantage of massive scale."" msgstr """" ""Büyük ölçekten faydalanabilmek için uygun maliyetli işlemler tasarlayın."" msgid ""Design model"" msgstr ""Tasarım modeli"" msgid """" ""Designing an OpenStack cloud requires a understanding of the cloud user's "" ""requirements and needs to determine the best possible configuration. This "" ""chapter provides guidance on the decisions you need to make during the "" ""design process."" msgstr """" ""OpenStack bulutu tasarlamak bulut kullanıcılarının ihtiyaçlarının "" ""anlaşılmasını ve en iyi uygun yapılandırmayı anlamayı gerektirir. Bu bölüm "" ""tasarım sürecinde almanız gereken kararlar için yönlendirme sağlar."" msgid ""Designing an OpenStack network"" msgstr ""Bir OpenStack ağı tasarlama"" msgid ""Determine if the use case has consistent or highly variable latency."" msgstr """" ""Kullanım durumunun sürekli veya yüksek değişkenlikte gecikmesi olup "" ""olmadığını belirleyin."" msgid ""Determine the most effective configuration for block storage network."" msgstr ""Blok depolama ağı için en etkin yapılandırmaya karar verin."" msgid """" ""Determine the requirements for the cloud prior to constructing the cloud, "" ""and plan for hardware lifecycles, and expansion and new features that may "" ""require different hardware."" msgstr """" ""Bulutu inşa etmeden önce bulut gereksinimlerini göz önüne alın, yeni donanım "" ""gerektirebilecek yeni özellikleri, donanım yaşam döngüleri ve genişleme için "" ""plan yapın."" msgid """" ""Determine the security policy of your organization and understand the data "" ""sovereignty of your cloud geography and plan accordingly."" msgstr """" ""Kurumunuzun güvenlik ilkesine karar verin ve bulut coğrafyanızın veri "" ""hakimiyetini anlayarak buna göre plan yapın."" msgid """" ""Determining the maximum *write* IOPS is a little different because most "" ""administrators configure disk replication using RAID and since the RAID "" ""controller requires IOPS itself, there is a write penalty. The severity of "" ""the write penalty is determined by the type of RAID used."" msgstr """" ""Azami *yazma* IOPS'u biraz farklıdır çünkü çoğu yönetici disk yedeklemeyi "" ""RAID kullanarak yapar ve RAID kontrolcüsü de IOPS'a ihtiyaç duyduğundan, bir "" ""yazma verimsizliği olur. Bu verimsizliğin seviyesi kullanılan RAID türüne "" ""göre belirlenir."" msgid ""Development cloud"" msgstr ""Geliştirici bulutu"" msgid ""Differences between storage types"" msgstr ""Depolama türleri arasındaki farklar"" msgid ""Disaster recovery and business continuity"" msgstr ""Felaktten kurtulma ve işin devamlılığı"" msgid """" ""Disks selected for object storage services do not need to be fast performing "" ""disks. We recommend that object storage nodes take advantage of the best "" ""cost per terabyte available for storage. Contrastingly, disks chosen for "" ""block storage services should take advantage of performance boosting "" ""features that may entail the use of SSDs or flash storage to provide high "" ""performance block storage pools. Storage performance of ephemeral disks used "" ""for instances should also be taken into consideration."" msgstr """" ""Nesne depolama servisleri için seçilen disklerin hızlı başarıma sahip olması "" ""gerekmez. Nesne depolama düğümlerinin terabayt başına en iyi fiyata sahip "" ""disklerden faydalanmalarını öneriyoruz. Buna ters olarak blok depolama "" ""servisleri için seçilen diskler blok depolama havuzları için SSD veya flash "" ""depolama gerektiren başarım artırma özelliklerine sahip disklerden "" ""seçilmelidir. Sunucular için kullanılan geçici disklerin depolama başarımı "" ""da göz önüne alınmalıdır."" msgid ""Do I need block storage?"" msgstr ""Blok depolamaya ihtiyacım var mı?"" msgid ""Do I need file-based storage?"" msgstr ""Dosya tabanlı depolamaya ihtiyacım var mı?"" msgid """" ""Do I need more than one storage choice? Do I need tiered performance storage?"" msgstr """" ""Birden fazla depolama seçimine ihtiyacım var mı? Sıralı başarım depolamaya "" ""ihtiyacım var mı?"" msgid ""Do I need object storage?"" msgstr ""Nesne depolamaya ihtiyacım var mı?"" msgid ""Do I need to support live migration?"" msgstr ""Canlı göçü desteklemem gerekiyor mu?"" msgid ""Do my workloads have IOPS requirements?"" msgstr ""İş yüklerimin IOPS gereksinimi var mı?"" msgid """" ""Does it include tools to help troubleshoot and resolve performance issues?"" msgstr """" ""Başarım sorunlarını gidermek ve çözmek için yardımcı araçlar içeriyor mu?"" msgid ""Does your authentication system also verify externally?"" msgstr ""Kimlik doğrulama sisteminiz harici de çalışıyor mu?"" msgid """" ""Due to the amount of logs being sent from servers in the OpenStack "" ""environment, an optional in-memory data structure store can be used. Common "" ""examples are Redis and Memcached. In newer versions of Elastic Stack, a file "" ""buffer called `Filebeat <https://www.elastic.co/products/beats/filebeat>`_ "" ""is used for a similar purpose but adds a \""backpressure-sensitive\"" protocol "" ""when sending data to Logstash or Elasticsearch."" msgstr """" ""OpenStack ortamında sunuculardan gönderilen günlük kayıtlarının miktarı "" ""sebebiyle isteğe bağlı bir hafızada veri yapısı depolama kullanılabilir. "" ""Redis ve Memcached yaygın örneklerdir. Elastic Stack'in yeni sürümlerinde "" ""`Filebeat <https://www.elastic.co/products/beats/filebeat>`_ isimli dosya "" ""ara belleği benzer amaçlı kullanılır ama veriyi Logstash veya "" ""Elasticsearch'e gönderirken arka basınca duyarlı bir iletişim kuralı ekler."" msgid ""Dynamic resource expansion or bursting"" msgstr ""Dinamik kaynak genişletme ya da patlama"" msgid """" ""Each Object Storage zone should be self-contained within its own "" ""availability zone. Each availability zone should have independent access to "" ""network, power, and cooling infrastructure to ensure uninterrupted access to "" ""data. In addition, a pool of Object Storage proxy servers providing access "" ""to data stored on the object nodes should service each availability zone. "" ""Object proxies in each region should leverage local read and write affinity "" ""so that local storage resources facilitate access to objects wherever "" ""possible. We recommend deploying upstream load balancing to ensure that "" ""proxy services are distributed across the multiple zones and, in some cases, "" ""it may be necessary to make use of third-party solutions to aid with "" ""geographical distribution of services."" msgstr """" ""Her bir Nesne Depolama bölgesi kendi kullanılırlık bölgesinde kullanılabilir "" ""olmalıdır. Veriye kesintisiz erişim için her kullanılabilirlik bölgesinin "" ""ağ, güç ve soğutma alt yapısına bağımsız erişimi olmalıdır. Ek olarak her "" ""bir kullanılırlık bölgesine nesne düğümlerinde saklanan veriye erişim "" ""sağlayan Nesne Depolama vekil sunucuları havuzu servis vermelidir. Her "" ""bölümdeki nesne vekilleri yerel okuma ve yazma benzerliği eğiliminde "" ""olmalıdır böylece yerel depolama kaynakları nesnelere uygun olunan her yerde "" ""erişimi kolaylaştırır. Vekil servislerin birden çok bölgede dağıtıldığından "" ""emin olmak için yukarı akış yük dengeleme kurmanızı öeriyoruz, bazı "" ""durumlarda servislerin coğrafi olarak dağıtımı için üçüncü taraf çözümlere "" ""ihtiyaç duyulabilir."" msgid """" ""Each host can have different storage profiles for hosts aggregation and "" ""availability zones."" msgstr """" ""Her sunucu sunucu takımı ve kullanılırlık bölgeleri için farklı depolama "" ""profillerine sahip olabilir."" msgid """" ""East/West - The internal traffic flow between workload within the cloud as "" ""well as the traffic flow between the compute nodes and storage nodes falls "" ""into the East/West category. Generally this is the heaviest traffic flow and "" ""due to the need to cater for storage access needs to cater for a minimum of "" ""hops and low latency."" msgstr """" ""Doğu/Batı - Bulut içindeki iş yüklerinin dahili trafik akışı ve hesaplama "" ""düğümleri ile depolama düğümleri arasındaki trafik akışı Doğu/Batı "" ""kategorisine girer. Genellikle bu en ağır trafik akışıdır ve depolama "" ""erişimi gereksinimi için temin edilmesi gereken asgari adım ve düşük gecikme "" ""temin edilmelidir."" msgid ""Edge"" msgstr ""Kenar"" msgid """" ""Elastic Stack consists of mainly three components: Elasticsearch (log search "" ""and analysis), Logstash (log intake, processing and output) and Kibana (log "" ""dashboard service)."" msgstr """" ""Elastic Stack temelde üç bileşenden oluşur. Elasticsearch (kayıt arama ve "" ""analiz), Logstash (kayıt alımı, işleme ve çıktı) ev Kibana (kayıt kontrol "" ""paneli servisi)."" msgid ""Eliminating single points of failure in a multi-region design"" msgstr ""Birden çok bölgeli tasarımda tek kırılma noktasını eleme"" msgid ""Eliminating single points of failure within each site"" msgstr ""Tüm konumlarda kırılma noktalarının elenmesi"" msgid """" ""Enables users to submit API calls to OpenStack services through commands."" msgstr """" ""Kullanıcıların komutlar aracılığıyla OpenStack servislerine API çağrıları "" ""göndermelerini etkinleştirir."" msgid ""Encryption configuration"" msgstr ""Şifreleme yapılandırması"" msgid """" ""Ensure that the network structure connects all clouds to form an integrated "" ""system. Also consider the state of handoffs which must be reliable and have "" ""minimal latency for optimal performance of the system."" msgstr """" ""Ağ yapısının tümleşik bir sistem oluşturmak için bağlandığından emin olun. "" ""Ayrıca sistemin başarımı için asgari gecikmeye sahip olması gereken elde "" ""tutulanlara da dikkat edin."" msgid """" ""Ensure that the physical data center provides the necessary power for the "" ""selected network hardware."" msgstr """" ""Fiziksel veri merkezinin seçilen ağ donanımı için gerekli gücü sağladığından "" ""emin olun."" msgid """" ""Ensure that the selected logging, monitoring, or alerting tools support the "" ""proposed OS-hypervisor combination."" msgstr """" ""Seçili günlükleme, izleme, ve uyarı araçlarının teklif edilen OS-hipervizör "" ""katışımını desteklediğinden emin olun."" msgid """" ""Ensure that the storage solution throughput is optimized for your "" ""application requirements."" msgstr """" ""Depolama çözümü işlem hacminin uygulama gereksinimlerinize göre "" ""ayarlandığından emin olun."" msgid ""Ensure that there is no single point of failure in the cloud ecosystem."" msgstr ""Bulut ekosisteminde tek bir kırılma noktası olmadığından emin olun."" msgid """" ""Ensure that your messaging queue handles requests successfully and size "" ""accordingly."" msgstr """" ""İleti kuyruğunuzun istekleri başarıyla aldığından emin olun duruma göre "" ""boyutlandırın."" msgid """" ""Ensure the connectivity matches the storage solution requirements. We "" ""recommend confirming that the network characteristics minimize latency to "" ""boost the overall performance of the design."" msgstr """" ""Bağlantının depolama çözümü gereksinimleriyle eşleştiğinden emin olun. Ağ "" ""karakteristiğinin tasarımın genel başarımını artıracak şekilde gecikmeleri "" ""en aza indirdiğinden emin olmanızı öneriyoruz."" msgid ""Enterprise requirements"" msgstr ""Kurumsal gereksinimler"" msgid ""Ephemeral storage"" msgstr ""Geçici depolama"" msgid """" ""Ephemeral storage - If you only deploy OpenStack :term:`Compute service "" ""(nova)`, by default your users do not have access to any form of persistent "" ""storage. The disks associated with VMs are ephemeral, meaning that from the "" ""user's point of view they disappear when a virtual machine is terminated."" msgstr """" ""Geçici depolama - Yalnızca OpenStack :term:`Hesaplama servisi (nova)` "" ""kurarsanız, öntanımlı olarak kullanıcılarınız herhangi bir kalıcı depolama "" ""biçimine sahip olmaz. Sanal makineler ile ilişkili diskler geçicidir, yani "" ""kullanıcı bakış açısıyla sanal makine kapandığında ortadan kaybolurlar."" msgid """" ""Error reporting has received some attention in Mitaka and Newton but there "" ""are improvements needed."" msgstr """" ""Mitaka ve Newton'da hata raporlama biraz daha ilgi gördü ama iyileştirmelere "" ""hala ihtiyaç var."" msgid """" ""Ethernet frames can carry any kind of packet. Networking at layer-2 is "" ""independent of the layer-3 protocol."" msgstr """" ""Ethernet çerçeveleri her tür paketi taşıyabilir. Katman-2 ağı katman-3 "" ""iletişim kurallarından bağımsızdır."" msgid """" ""Ethernet frames contain all the essentials for networking. These include, "" ""but are not limited to, globally unique source addresses, globally unique "" ""destination addresses, and error control."" msgstr """" ""Ethernet çerçeveleri ağ için tüm esasları içerir. Bunlar benzersiz kaynak "" ""adresleri, benzersiz hedef adresleri ve hata kontrolünü ve fazlasını içerir."" msgid """" ""Every deleted record or file in the system is marked by a tombstone, so that "" ""deletions can be replicated alongside creations. The replication process "" ""cleans up tombstones after a time period known as the consistency window. "" ""The consistency window encompasses replication duration and the length of "" ""time a transient failure can remove a node from the cluster. Tombstone "" ""cleanup must be tied to replication to reach replica convergence."" msgstr """" ""Sistemde silinen her kayıt ya da dosya bir mezar taşıyla işaretlenir, "" ""böylece silmeler de oluştrmalar gibi çoğaltılabilir. Çoğaltma süreci "" ""tutarlılık penceresi denen bir zaman aralığından sonra mezar taşlarını "" ""temizler. Tutarlılık penceresi çoğaltma sürecini ve bir aktarım "" ""başarısızlığının bir düğümü kümeden çıkarma zaman uzunluğunu kapsar. "" ""Yedeklerin bir noktada birleşmesi için mezar taşı temizliği çoğaltmayla "" ""ilişkilendirilmelidir."" msgid """" ""Everything must be capable of automation. For example, everything from "" ""compute hardware, storage hardware, networking hardware, to the installation "" ""and configuration of the supporting software. Manual processes are "" ""impractical in a massively scalable OpenStack design architecture."" msgstr """" ""Herşeyi otomatize edilebilmelidir. Örneğin, hesaplama donanımından, depolama "" ""donanımına, ağ donanımından destekleyen yazılımların kurulumu ve "" ""yapılandırmasana kadar herşey. Büyük ölçekteki OpenStack mimarilerinde elle "" ""yapılan işlemler elverişsizdir."" msgid ""Example of typical usage…"" msgstr ""Genel kullanıma örnek..."" msgid ""Expandability"" msgstr ""Genişleyebilirlik"" msgid """" ""Expandability is a major architecture factor for storage solutions with "" ""general purpose OpenStack cloud. A storage solution that expands to 50 PB is "" ""considered more expandable than a solution that only scales to 10 PB. This "" ""meter is related to scalability, which is the measure of a solution's "" ""performance as it expands."" msgstr """" ""Genişleyebilirlik genel amaçlı OpenStack bulutunda depolama çözümleri için "" ""önemli mimari etmenlerden biridir. 50 PB boyuta genişleyebilir bir depolama "" ""çözümü yalnızca 10 PB boyuta genişleyebilene göre daha genişleyebilir olarak "" ""düşünülür. Bu ölçüt ölçeklenebilirlikle ilişkilidir, bu da bir çözümün "" ""genişledikçe ölçülen başarımını ifade eder."" msgid ""Experimental"" msgstr ""Deneysel"" msgid ""Extensions"" msgstr ""Eklentiler"" msgid ""External"" msgstr ""Harici"" msgid ""External network attachments."" msgstr ""Harici ağ eklentileri."" msgid """" ""External systems such as :term:`LDAP <Lightweight Directory Access Protocol "" ""(LDAP)>` or :term:`Active Directory` require network connectivity between "" ""the cloud controller and an external authentication system. Also ensure that "" ""the cloud controller has the CPU power to keep up with requests."" msgstr """" "":term:`LDAP <Hafif Dizin Erişim İletişim Kuralı (LDAP)>` veya :term:`Active "" ""Directory` gibi harici sistemler bulut kontrol birimi ile harici kimlik "" ""doğrulama sistemi arasında ağ bağlantısı gerektirirler. Bunun yanında bulut "" ""kontrol biriminin isteklerin altından kalkabilecek işlemci gücüne sahip "" ""olduğundan da emin olun."" msgid ""Facilitate orchestration across the clouds"" msgstr ""Bulutlar arasında orkestrasyonu kolaylaştır"" msgid """" ""Factor maintainability into the overall network design. This includes the "" ""ability to manage and maintain IP addresses as well as the use of overlay "" ""identifiers including VLAN tag IDs, GRE tunnel IDs, and MPLS tags. As an "" ""example, if you may need to change all of the IP addresses on a network, a "" ""process known as renumbering, then the design must support this function."" msgstr """" ""Yönetilebilirliği genel ağ tasarımında hesaba katın. Bu IP adreslerini "" ""yönetmek ve ele alma becerisi yanında VLAN etiket kimlikleri, GRE tünel "" ""kimlikleri, ve MPLS etiketleri gibi üst katman tanımlayıcıların kullanımını "" ""da içerir. Örnek olarak, bir ağdaki tüm IP adreslerini değiştirmek "" ""isterseniz, ki buna yeniden numaralandırma denir, mimari bu işlevi "" ""desteklemelidir."" msgid """" ""Fast provisioning of boot-from-volume instances using thin provisioning."" msgstr """" ""İnce hazırlama ile birimden ön yükleme sunucularının hızlı hazırlanması."" msgid ""Fault tolerance"" msgstr ""Hata dayanıklılığı"" msgid ""File system"" msgstr ""Dosya sistemi"" msgid ""File-based storage"" msgstr ""Dosya tabanlı depolama"" msgid ""File-level"" msgstr ""Dosya seviyesi"" msgid """" ""Finally, consider how to respond to network events. How load transfers from "" ""one link to another during a failure scenario could be a factor in the "" ""design. If you do not plan network capacity correctly, failover traffic "" ""could overwhelm other ports or network links and create a cascading failure "" ""scenario. In this case, traffic that fails over to one link overwhelms that "" ""link and then moves to the subsequent links until all network traffic stops."" msgstr """" ""Son olarak, ağ olaylarına nasıl yanıt verileceğini dikkate alın. Bir kesinti "" ""senaryosunda yükün bir bağlantıdan diğerine nasıl aktarılacağı tasarımda bir "" ""etmen olabilir. Ağ kapasitesini doğru planlamazsanız, kesinti trafiği diğer "" ""bağlantı noktaları ya da ağ bağlantılarını boğabilir ve katlanan bir kesinti "" ""senaryosu oluşturabilir. Bu durumda, kesinti olan bağlantı bir sonraki "" ""bağlantıya aktarılır, bu bağlantıyı da boğunca bir diğerine aktarılarak tüm "" ""ağ trafiği durana kadar ilerlenir."" msgid """" ""Financial factors are a primary concern for any organization. Cost "" ""considerations may influence the type of cloud that you build. For example, "" ""a general purpose cloud is unlikely to be the most cost-effective "" ""environment for specialized applications. Unless business needs dictate that "" ""cost is a critical factor, cost should not be the sole consideration when "" ""choosing or designing a cloud."" msgstr """" ""Mali etmenler her kurum işçin birinci önceliktir. Maliyet hesaplamaları inşa "" ""edeceğiniz bulut türünü etkileyebilir. Örneğin, genel amaçlı bir bulut özel "" ""uygulamalar için en hesaplı ortam olmayacaktır. İş ihtiyaçları maliyet "" ""konusunda çok hassas olmadığı sürece bir bulut seçerken ya da tasarlarken "" ""maliyet birinci öncelik olmamalıdır."" msgid ""First and foremost:"" msgstr ""İlk önce:"" msgid """" ""For a compute-focus architecture, we recommend designing the network "" ""architecture using a scalable network model that makes it easy to add "" ""capacity and bandwidth. A good example of such a model is the leaf-spine "" ""model. In this type of network design, you can add additional bandwidth as "" ""well as scale out to additional racks of gear. It is important to select "" ""network hardware that supports port count, port speed, and port density "" ""while allowing for future growth as workload demands increase. In the "" ""network architecture, it is also important to evaluate where to provide "" ""redundancy."" msgstr """" ""Hesaplama odaklı bir mimaride, kapasite ve bant genişliği eklemenin kolay "" ""olacağı ölçeklenebilir bir ağ modeli kullanılmasını öneriyoruz. Bu tarz bir "" ""modele iyi bir örnek yaprak-omurga modelidir. Bu tür ağ tasarımında, ek bant "" ""genişliği ekleyebilir ve ek malzeme kabinlerine ölçeklenebilirsiniz. "" ""Bağlantı noktası sayısı, bağlanı noktası hızı ve bağlantı noktası "" ""yoğunluğunu destekleyen ve istek arttığında genişlemeyi destekleyen ağ "" ""donanımlarını seçmek önemlidir. Ağ mimarisinde, yedekliliği nerde "" ""değerlendireceğinizi bilmek de önemlidir."" msgid """" ""For a general purpose OpenStack cloud, sizing is an important consideration. "" ""The expected or anticipated number of instances that each hypervisor can "" ""host is a common meter used in sizing the deployment. The selected server "" ""hardware needs to support the expected or anticipated instance density."" msgstr """" ""Daha genel amaçlı bir OpenStack bulutu için, boyutlandırma önemli bir "" ""etmendir. Her hipervizörün sunabileceği beklenen ya da tahmin edilen sunucu "" ""sayısı kurulumun ölçeklendirmesinde kullanılan genel ölçüttür. Seçilen "" ""sunucu donanımı beklenen ya da tahmin edilen sunucu yoğunluğunu "" ""desteklemelidir."" msgid """" ""For a general purpose OpenStack cloud, the OpenStack infrastructure "" ""components need to be highly available. If the design does not include "" ""hardware load balancing, networking software packages like HAProxy will need "" ""to be included."" msgstr """" ""Genel amaçlı OpenStack bulutu için, OpenStack alt yapı bileşenlerinin yüksek "" ""kullanılırlıklı olması gerekir. Tasarım donanımsal yük dengeleme "" ""içermiyorsa, HAProxy gibi ağ yazılım paketlerinin dahil edilmesi gerekir."" msgid """" ""For a user of a massively scalable OpenStack public cloud, there are no "" ""expectations for control over security, performance, or availability. Users "" ""expect only SLAs related to uptime of API services, and very basic SLAs for "" ""services offered. It is the user's responsibility to address these issues on "" ""their own. The exception to this expectation is the rare case of a massively "" ""scalable cloud infrastructure built for a private or government organization "" ""that has specific requirements."" msgstr """" ""Büyük ölçekli OpenStack açık bulutunun bir kullanıcısı için, güvenlik, "" ""başarım veya kullanılırlık üzerinde kontrol beklentisi yoktur. Kullanıcılar "" ""yalnızca API servislerinin hizmet süreleriyle ilgili, ve sunulan servislerle "" ""ilgili çok temel SLA'lar beklerler. Bu sorunları ele almak kullanıcının "" ""sorumluluğundadır. Bu beklentiye bir istisna özel bir kuruma veya devlet "" ""kurumuna inşa edilmiş belirli gereksinimleri olan büyük ölçekte bulut alt "" ""yapısıdır."" msgid """" ""For example, CPU, memory or local storage based compute nodes. For NFV or "" ""HPC based clouds, there may even be specific network configurations that "" ""should be reserved for those specific workloads on specific compute nodes. "" ""This method of designing specific resources into groups or zones of compute "" ""can be referred to as bin packing."" msgstr """" ""Örneğin, CPU, hafıza veya yerel deoplama tabanlı hesaplama düğümleri. NFV "" ""veya HPC tabanlı bulutlar için belirli hesaplama düğümlerinde çalışacak "" ""belirli iş yükleri için ayrılmış yapılandırmalar bile olabilir. Belirli "" ""kaynakları gruplara ya da hesaplama bölgelerine göre tasarlamaya kutu "" ""paketleme denir."" msgid """" ""For example, a cloud administrator might be able to list all instances in "" ""the cloud, whereas a user can see only those in his current group. Resources "" ""quotas, such as the number of cores that can be used, disk space, and so on, "" ""are associated with a project."" msgstr """" ""Örneğin bir bulut yöneticisi buluttaki tüm sunucuları listeleyebilir, ancak "" ""bir kullanıcı yalnızca kendi grubundakileri görüntüleyebilir. "" ""Kullanılabilecek çekirdek sayısı, disk alanı, vs gibi kaynak kotaları "" ""projeyle ilişkilidir."" msgid """" ""For example, a system that starts with a single disk and a partition power "" ""of 3 can have 8 (2^3) partitions. Adding a second disk means that each has 4 "" ""partitions. The one-disk-per-partition limit means that this system can "" ""never have more than 8 disks, limiting its scalability. However, a system "" ""that starts with a single disk and a partition power of 10 can have up to "" ""1024 (2^10) disks."" msgstr """" ""Örneğin, 3 bölümleme gücüne sahip tek diskli bir sistem 8 (2^3) bölüme sahip "" ""olabilir. İkinci bir disk eklemek her birinin 4 bölümü olacağı anlamına "" ""gelir. Disk başına bir bölüm kısıtlaması bu sistemin 8 diskten fazlasına "" ""sahip olamayacağı anlamına gelir, bu da ölçeklenebilirliği kısıtlar. Ancak, "" ""tek bir diskle ve bölüm gücü 10 ile başlayan bir sistem 1024 (2^10) diske "" ""sahip olabilir."" msgid """" ""For example, consider a cloud backup application. This workload has two "" ""specific behaviors that impact the network. Because this workload is an "" ""externally-facing service and an internally-replicating application, it has "" ""both :term:`north-south<north-south traffic>` and :term:`east-west<east-west "" ""traffic>` traffic considerations:"" msgstr """" ""Örneğin, bir bulut yedek uygulamasını ele alın. Bu iş yükünün ağı etkileyen "" ""iki özel davranışı bulunur. Bu iş yükü dışa dönük bir servis ve içe dönük "" ""çoğaltma uygulaması olduğundan, hem :term:`kuzey-güney<north-south traffic>` "" ""hem de :term:`doğu-batı<east-west traffic>` trafik sahibidir."" msgid """" ""For example, degraded video streams and low quality VoIP sessions negatively "" ""impact user experience and may lead to productivity and economic loss."" msgstr """" ""Örneğin, düşük kalite video akışları ve VoIP oturumları kullanıcı deneyimini "" ""eksi yönde etkiler ve üretim ve ekonomik kayba sebep olabilir."" msgid """" ""For example, if a physical node has 48 GB of RAM, the scheduler allocates "" ""instances to that node until the sum of the RAM associated with the "" ""instances reaches 72 GB (such as nine instances, in the case where each "" ""instance has 8 GB of RAM)."" msgstr """" ""Örneğin 48 GB RAM'i olan fiziksel düğümde zamanlayıcı sunucularla ilişkili "" ""RAM 72 GB'yi geçene kadar bu düğüme sunucu ayırmaya devam eder (8 GB RAM'e "" ""sahip sunucular olduğunu düşünürsek dokuz sunucu kadar)."" msgid """" ""For example, the EC2 API refers to instances using IDs that contain "" ""hexadecimal, whereas the OpenStack API uses names and digits. Similarly, the "" ""EC2 API tends to rely on DNS aliases for contacting virtual machines, as "" ""opposed to OpenStack, which typically lists IP addresses."" msgstr """" ""Örneğin EC2 API'si sunuculara onaltılık ID'lerle başvurur, OpenStack API ise "" ""isimler ve basamaklarla. Benzer şekilde, EC2 API sanal makineleri yönetirken "" ""DNS takma adlarına güvenir, OpenStack ise genellikle IP adreslerini listeler."" msgid """" ""For example, you must plan the number of IP addresses that you need for both "" ""your guest instances as well as management infrastructure. Additionally, you "" ""must research and discuss cloud network connectivity through proxy servers "" ""and firewalls."" msgstr """" ""Örneğin hem misafir sunucularınız hem de yönetim alt yapınız için IP "" ""adreslerini planlamalısınız. Ek olarak vekil sunucular ve güvenlik duvarları "" ""içinden geçen bulut ağ bağlantınızı araştırmalı ve tartışmalısınız."" msgid """" ""For example, you should consider the time required to run a workload in "" ""different clouds and methods for reducing this time. This may require moving "" ""data closer to applications or applications closer to the data they process, "" ""and grouping functionality so that connections that require low latency take "" ""place over a single cloud rather than spanning clouds."" msgstr """" ""Örneğin, bu zamanı azaltmak için bir iş yükünün farklı bulutlarda ve "" ""yöntemlerde alacağı zamanı göz önüne almalısınız. Bu da veriyi uygulamalara "" ""ya da uygulamaları işledikleri verilere yakın tutmak ve işlevselliği "" ""gruplamak olabilir böylece az gecikme gerektiren bağlantılar birden çok "" ""bulut içinde değil aynı bulut içinde gerçekleşir."" msgid """" ""For information about deploying and operating OpenStack, see the "" ""`Installation Tutorials and Guides <https://docs.openstack.org/project-"" ""install-guide/ocata/>`_, `Deployment Guides <https://docs.openstack.org/"" ""project-deploy-guide/ocata/>`_, and the `OpenStack Operations Guide <https://"" ""docs.openstack.org/ops-guide/>`_."" msgstr """" ""OpenStack kurulum ve işletimiyle ilgili bilgi için, `Kurulum Öğreticileri ve "" ""Kılavuzları <https://docs.openstack.org/project-install-guide/ocata/>`_, "" ""`Kurulum Kılavuzları <https://docs.openstack.org/project-deploy-guide/ocata/"" "">`_, ve `OpenStack İşletim Kılavuzuna <https://docs.openstack.org/ops-guide/"" "">`_ göz atın."" msgid """" ""For instructions on installing Logstash, Elasticsearch and Kibana, see the "" ""`Elasticsearch reference <https://www.elastic.co/guide/en/elasticsearch/"" ""reference/current/getting-started.html>`_."" msgstr """" ""Logstash, Elasticsearch ve Kibana yükleme yönergeleri için bknz "" ""`Elasticsearch kaynağı <https://www.elastic.co/guide/en/elasticsearch/"" ""reference/current/getting-started.html>`_."" msgid """" ""For many deployments, the cloud controller is a single node. However, to "" ""have high availability, you have to take a few considerations into account, "" ""which we'll cover in this chapter."" msgstr """" ""Çoğu kurulum için bulut kontrol birimi tek bir düğümdür. Ancak yüksek "" ""kullanılırlık için bu bölümde kapsayacağımız bazı etmenleri göz önünde "" ""tutmalısınız."" msgid """" ""For many use cases the proximity of the user to their workloads has a direct "" ""influence on the performance of the application and therefore should be "" ""taken into consideration in the design. Certain applications require zero to "" ""minimal latency that can only be achieved by deploying the cloud in multiple "" ""locations. These locations could be in different data centers, cities, "" ""countries or geographical regions, depending on the user requirement and "" ""location of the users."" msgstr """" ""Çoğu kullanım durumunda kullanıcının iş yüklerine yakınlığının uygulama "" ""başarımına doğrudan etkisi vardır, yani tasarımda bu göz önüne alınmalıdır. "" ""Bazı uygulamalar sıfır ya da asgari gecikme gerektirirler, bu da bulutu "" ""birden çok konumda kurmakla elde edilebilir. Bu konumlar kullanıcı "" ""gereksinimi ve kullanıcıların konumuna göre değişik veri merkezleri, "" ""şehirler, ülkeler veya coğrafik bölgeler olabilir."" msgid """" ""For more information about NUMA, see `CPU topologies <https://docs.openstack."" ""org/admin-guide/compute-cpu-topologies.html>`_ in the Administrator Guide."" msgstr """" ""NUMA hakkında daha fazla bilgi için, Yönetici Kılavuzundaki `CPU "" ""topolojileri <https://docs.openstack.org/admin-guide/compute-cpu-topologies."" ""html>`_ kısmına bakın."" msgid """" ""For more information about feature support for hypervisors as well as ironic "" ""and Virtuozzo (formerly Parallels), see `Hypervisor Support Matrix <https://"" ""docs.openstack.org/developer/nova/support-matrix.html>`_ and `Hypervisors "" ""<https://docs.openstack.org/ocata/config-reference/compute/hypervisors."" ""html>`_ in the Configuration Reference."" msgstr """" ""Hipervizörler için özellik desteği ve ironic ve Virtuozzo (eski Parallels) "" ""ile ilgili daha fazla bilgi için Yapılandırma Kaynakçasındaki `Hipervizör "" ""Destek Matrisi <https://docs.openstack.org/developer/nova/support-matrix."" ""html>`_ ve `Hipervizörler <https://docs.openstack.org/ocata/config-reference/"" ""compute/hypervisors.html>`_ bağlantılarına göz atın."" msgid """" ""For more information on configuring Block Storage to use NFS storage, see "" ""`Configure an NFS storage back end <https://docs.openstack.org/admin-guide/"" ""blockstorage-nfs-backend.html>`_ in the OpenStack Administrator Guide."" msgstr """" ""NFS depolama kullanan Blok Depolama yapılandırması hakkında daha fazla bilgi "" ""için OpenStack Yönetici Kılavuzundaki `NFS depolama arka ucu "" ""yapılandırmasına <https://docs.openstack.org/admin-guide/blockstorage-nfs-"" ""backend.html>`_ göz atın."" msgid """" ""For more information on high availability in OpenStack, see the `OpenStack "" ""High Availability Guide <https://docs.openstack.org/ha-guide/>`_."" msgstr """" ""OpenStack'de yüksek kullanılırlıkla ilgili daha fazla bilgi için, `OpenStack "" ""Yüksek Kullanılırlık Kılavuzuna <https://docs.openstack.org/ha-guide/>`_ göz "" ""atın."" msgid """" ""For more information on managing and maintaining your OpenStack environment, "" ""see the `OpenStack Operations Guide <https://docs.openstack.org/ops-guide/"" ""index.html>`_."" msgstr """" ""OpenStack ortamınızı yönetmek ve bakım hakkında daha fazla bilgi için "" ""`OpenStack İşlem Kılavuzuna <https://docs.openstack.org/ops-guide/index."" ""html>`_ göz atın."" msgid """" ""For more information, please see the `Swift replication page <https://docs."" ""openstack.org/developer/swift/overview_replication.html>`_."" msgstr """" ""Daha fazla bilgi için, `Swift çoğaltma sayfasına <https://docs.openstack.org/"" ""developer/swift/overview_replication.html>`_ göz atın."" msgid """" ""For our example, the cloud controller has a collection of ``nova-*`` "" ""components that represent the global state of the cloud; talks to services "" ""such as authentication; maintains information about the cloud in a database; "" ""communicates to all compute nodes and storage :term:`workers <worker>` "" ""through a queue; and provides API access. Each service running on a "" ""designated cloud controller may be broken out into separate nodes for "" ""scalability or availability."" msgstr """" ""Örneğimize göre, bulut kontrol biriminin bulutun genel durumunu temsil eden "" ""``nova-*`` bileşenleri koleksiyonu bulunur; kimlik doğrulama gibi "" ""servislerle konuşur; bulut hakkında bilgiyi bir veritabanında yönetir; tüm "" ""hesaplama düğümleri ve deoplama :term:`işçileriyle <worker>` bir kuyruk "" ""aracılığıyla konuşur; ve API erişimi sağlar. Belirlenmiş bulut kontrol "" ""biriminde çalışan her servis ölçeklenebilirlik ve kullanılabilirlik için "" ""ayrı düğümlere dağıtılmış olabilir."" msgid """" ""Front end web for API requests, the scheduler for choosing which compute "" ""node to boot an instance on, Identity services, and the dashboard"" msgstr """" ""API istekleri için web ön yüzü, bir sunucunun hangi hesaplama düğümünde "" ""önyükleneceğini seçmek için zamanlayıcı, Kimlik servisleri ve kontrol paneli"" msgid """" ""Furthermore, on large layer-2 networks, configuring ARP learning can be "" ""complicated. The setting for the MAC address timer on switches is critical "" ""and, if set incorrectly, can cause significant performance problems. So when "" ""migrating MACs to different physical locations to support instance "" ""migration, problems may arise. As an example, the Cisco default MAC address "" ""timer is extremely long. As such, the network information maintained in the "" ""switches could be out of sync with the new location of the instance."" msgstr """" ""Dahası, büyük katman-2 ağlarda, ARP öğrenmesini yapılandırmak da karmaşık "" ""olabilir. Anahtarlardaki MAC adresi zamanlayıcısı kritiktir ve yanlış "" ""ayarlanırsa büyük başarım sorunlarına yol açar. Yani sunucu göçünü "" ""desteklemek için MAC'leri farklı fiziksel konumlara taşırken sorunlar ortaya "" ""çıkabilir. Örnek olarak Cisco öntanımlı MAC adres zamanlayıcısı çok uzundur. "" ""Yani sunucunun yeni konuma geçmesiyle ağ anahtarında tutulan ağ bilgisi "" ""eşzamanlanmamış olur."" msgid ""General compute cloud"" msgstr ""Genel hesaplama bulutu"" msgid """" ""General examples and configuration guides can be found on the Elastic "" ""`Logstash Configuration page <https://www.elastic.co/guide/en/logstash/"" ""current/configuration-file-structure.html>`_."" msgstr """" ""Genel örnekler ve yapılandırma kılavuzları Elastic `Logstash Yapılandırma "" ""sayfasında <https://www.elastic.co/guide/en/logstash/current/configuration-"" ""file-structure.html>`_ bulunabilir."" msgid """" ""Geographical considerations may also impact the cost of building or leasing "" ""data centers. Considerations include:"" msgstr """" ""Coğrafi etkenler veri merkezi kiralama veya inşa etme masraflarını da "" ""etkileyebilir. Etmenler şunları içerir:"" msgid ""Gluster"" msgstr ""Gluster"" msgid ""GlusterFS"" msgstr ""GlusterFS"" msgid ""HTTP"" msgstr ""HTTP"" msgid ""Hardware Considerations"" msgstr ""Donanım Etmenleri"" msgid ""Hardware must support network redundancy."" msgstr ""Donanım ağ yedekliliğini desteklemeli."" msgid """" ""Hardware resources selected for the resource nodes should be capable of "" ""supporting enough storage for the cloud services. Defining the initial "" ""requirements and ensuring the design can support adding capacity is "" ""important. Hardware nodes selected for object storage should be capable of "" ""support a large number of inexpensive disks with no reliance on RAID "" ""controller cards. Hardware nodes selected for block storage should be "" ""capable of supporting high speed storage solutions and RAID controller cards "" ""to provide performance and redundancy to storage at a hardware level. "" ""Selecting hardware RAID controllers that automatically repair damaged arrays "" ""will assist with the replacement and repair of degraded or deleted storage "" ""devices."" msgstr """" ""Kaynak düğümler için seçilmiş donanım kaynakları bulut servisleri için "" ""yeterli depolamayı destekleme kapasitesine sahip olmalıdır. İlk "" ""gereksinimleri tanımlamak ve tasarımın ek kapasiteyi kaldırabileceğini "" ""bilmek önemlidir. Nesne depolama için seçilen donanım düğümleri RAID kontrol "" ""kartlarına bel bağlamadan yüksek sayıda ucuz diski destekleyebilmelidir. "" ""Blok depolama için seçilen donanım düğümleri yüksek hızlı depolama "" ""çözümlerini ve RAID kontrol kartlarını destekleyerek donanım seviyesinde "" ""başarım ve depolama yedekliliği sağlayabilmelidir. Otomatik olarak hasarlı "" ""dizileri tamir eden donanımsal RAID kontrol kartlarını tercih etmek silinen "" ""ya da eski kalmış depolama aygıtlarının tamirinde yardımcı olacaktır."" msgid """" ""Heavy I/O usage on one compute node does not affect instances on other "" ""compute nodes. Direct I/O access can increase performance."" msgstr """" ""Bir hesaplama düğümündeki ağır I/O kullanımı diğer hesaplama düğümlerindeki "" ""sunucuları etkilemez. Doğrudan I/O erişimi başarımı artırabilir."" msgid """" ""Here are some other factors to consider when selecting hardware for your "" ""compute servers."" msgstr """" ""Hesaplama sunucularınız için donanım seçerken göz önüne almanız gereken "" ""diğer etmenler şöyle."" msgid ""High availability"" msgstr ""Yüksek kullanılırlık"" msgid ""High availability architecture to meet customer SLA requirements."" msgstr """" ""Müşteri SLA gereksinimlerini karşılamak için yüksek kullanılırlıklı mimari."" msgid """" ""High availability implementations vary in functionality and design. Examples "" ""of some common methods are active-hot-standby, active-passive, and active-"" ""active. Development of high availability and test frameworks is necessary to "" ""insure understanding of functionality and limitations."" msgstr """" ""Yüksek kullanılırlık uygulamaları işlevsellik ve tasarımda değişiklik "" ""gösterir. Genelde kullanılan yöntemlerden bazılarına örnek olarak etkin-"" ""sıcak-bekleme, etkin-pasif ve etkin-etkin gösterilebilir. İşlevsellik ve "" ""sınırlamaları iyi anlamak için yüksek kullanılırlık ve deneme çatılarının "" ""geliştirilmesi gereklidir."" msgid ""High performance database"" msgstr ""Yüksek başarımlı veritabanı"" msgid ""High performance database with Database service"" msgstr ""Veritabanı servisiyle yüksek başarımlı veritabanı"" msgid """" ""High performance systems have SLA requirements for a minimum quality of "" ""service with regard to guaranteed uptime, latency, and bandwidth. The level "" ""of the SLA can have a significant impact on the network architecture and "" ""requirements for redundancy in the systems."" msgstr """" ""Yüksek başarım sistemleri garanti edilen hizmet süresi, gecikme ve bant "" ""genişliğiyle ilgili asgari servis kalitesi gereksinimleri için SLA'lara "" ""sahiptirler. SLA seviyesi ağ mimarisi üzerinde ve sistemlerdeki yedeklilik "" ""gereklilikleri üzerinde önemli etki sahibi olabilir."" msgid ""Host density"" msgstr ""Sunucu yoğunluğu"" msgid ""How do I manage the storage operationally?"" msgstr ""Depolama işlemlerini nasıl yöneteceğim?"" msgid ""How long does a single instance run?"" msgstr ""Tek bir sunucu ne kadar çalışıyor?"" msgid ""How many ``nova-api`` services do you run at once for your cloud?"" msgstr ""Bulutunuz için bir kerede kaç ``nova-api`` servisi çalıştırıyorsunuz?"" msgid ""How many compute nodes will run at once?"" msgstr ""Bir kerede kaç hesaplama düğümü çalışacak?"" msgid ""How many instances will run at once?"" msgstr ""Bir kerede kaç sunucu çalışacak?"" msgid ""How many users will access the API?"" msgstr ""Kaç kullanıcı API'ye erişecek?"" msgid ""How many users will access the dashboard versus the REST API directly?"" msgstr ""REST API'nin tersine kaç kullanıcı kontrol paneline doğrudan erişecek?"" msgid """" ""How redundant and distributed is the storage? What happens if a storage node "" ""fails? To what extent can it mitigate my data-loss disaster scenarios?"" msgstr """" ""Depolama ne kadar yedekli ve dağıtık? Bir depolama düğümü arızalanırsa ne "" ""olur? Veri kaybı olan felaket durumu senaryolarımı ne kadar azaltabilir?"" msgid """" ""How the particular storage architecture will be used is critical for "" ""determining the architecture. Some of the configurations that will influence "" ""the architecture include whether it will be used by the hypervisors for "" ""ephemeral instance storage, or if OpenStack Object Storage will use it for "" ""object storage."" msgstr """" ""Belirli depolama mimarisinin nasıl kullanılacağı mimarinin belirlenmesinde "" ""ciddi rol oynar. Hipervizörler tarafından geçici sunucu depolaması olarak "" ""mı, nesne depolama için OpenStack Nesne Depolama tarafından mı kullanılacağı "" ""mimariyi etkileyecek yapılandırmalardan bazılarıdır."" msgid """" ""However, before choosing a storage architecture, a few generic questions "" ""should be answered:"" msgstr """" ""Ancak, bir depolama mimarisi seçerken, bazı genel sorular yanıtlanmalıdır:"" msgid """" ""However, if you are more restricted in the number of physical hosts you have "" ""available for creating your cloud and you want to be able to dedicate as "" ""many of your hosts as possible to running instances, it makes sense to run "" ""compute and storage on the same machines or use an existing storage array "" ""that is available."" msgstr """" ""Bulutunuzu oluşturmak için kullanılabilir fiziksel sunucu sayısında "" ""kısıtlamalarınız varsa ve olabildiğince fazla sunucunuzu sunucu çalıştırmak "" ""için ayırmak istiyorsanız, hesaplama ve depolamayı aynı makinelerde "" ""kullanmak veya mevcut kullanılabilir depolama dizisini kullanmak "" ""isteyebilirsiniz."" msgid ""However, this option has several disadvantages:"" msgstr ""Ancak bu seçeneğin bir çok dezavantajı bulunur:"" msgid """" ""Hybrid cloud architecture enables the migration of applications between "" ""different clouds."" msgstr """" ""Melez bulut mimarisi uygulamaların farklı bulutlar arasında göçünü "" ""etkinleştirir."" msgid """" ""Hybrid cloud designs must accommodate differences in SLAs between providers, "" ""and consider their enforceability."" msgstr """" ""Melez bulut tasarımları sağlayıcılar arasındaki SLA'ların farklılıklarına "" ""uyum sağlamalıdır, uygulanabilirliklerini göz önüne almalıdır."" msgid """" ""Hyper-Threading is Intel's proprietary simultaneous multithreading "" ""implementation used to improve parallelization on their CPUs. You might "" ""consider enabling Hyper-Threading to improve the performance of "" ""multithreaded applications."" msgstr """" ""Hyper-Threading Intel'in işlemcilerinde paralelleştirmeyi iyileştirmek için "" ""kullandıkları tescilli eşzamanlı çoklu iplik uygulamasıdır. Çoklu iş ipliği "" ""ile çalışan uygulamalarda başarımı artırmak için Hyper-Threading desteğini "" ""etkinleştirmeyi düşünmelisiniz."" msgid """" ""IOPS = 1 / (AverageLatency + AverageSeekTime) For example: Average Latency "" ""for Single Disk = 2.99ms or .00299 seconds Average Seek Time for Single Disk "" ""= 4.7ms or .0047 seconds IOPS = 1/(.00299 + .0047) IOPS = 130"" msgstr """" ""IOPS = 1 / (OrtalamaGecikme + OrtalamaAramaSüresi) Örneğin: Tek Disk İçin "" ""Gecikme = 2.99ms veya .00299 saniye Tek Disk için Ortalama Arama Süresi = "" ""4.7ms veya .0047 saniye IOPS = 1/(.00299 + .0047) IOPS = 130"" msgid ""Identity"" msgstr ""Kimlik"" msgid """" ""If OpenStack is not set up in the right way, it is simple to have scenarios "" ""in which users are unable to contact their instances due to having only an "" ""incorrect DNS alias. Despite this, EC2 compatibility can assist users "" ""migrating to your cloud."" msgstr """" ""OpenStack düzgün ayarlanmamışsa, yalnızca yanlış bir DNS takma adı yüzünden "" ""kullanıcılar sunucularına erişemeyebilirler. Buna rağmen EC2 uyumluluğu "" ""kullanıcıların bulutunuza göçüne yardımcı olabilir."" msgid ""If a compute node fails, instances are usually easily recoverable."" msgstr """" ""Bir hesap düğümü arızalanırsa, sunucular genellikle kolaylıkla "" ""kurtarılabilir."" msgid """" ""If a compute node fails, the data associated with the instances running on "" ""that node is lost."" msgstr """" ""Bir hesaplama düğümü başarısız olursa, bu düğümde çalışan sunucularla "" ""ilişkili veri kaybolur."" msgid """" ""If a replicator detects that a remote drive has failed, the replicator uses "" ""the ``get_more_nodes`` interface for the ring to choose an alternative node "" ""with which to synchronize. The replicator can maintain desired levels of "" ""replication in the face of disk failures, though some replicas may not be in "" ""an immediately usable location."" msgstr """" ""Bir çoğaltıcı uzak sürücünün arızalandığını algılarsa, çoğaltıcı halka için "" ""``get_more_nodes`` arayüzünü kullanarak eşzamanlama yapılacak alternatif bir "" ""düğüm seçer. Çoğaltıcı disk arızaları durumunda istenen seviyede yedeklemeyi "" ""devam etirebilir, ama bazı yedekler anında kullanılabilir konumlarda "" ""olmayabilir."" msgid """" ""If a significant portion of the cloud is on externally managed systems, "" ""prepare for situations where it may not be possible to make changes. "" ""Additionally, cloud providers may differ on how infrastructure must be "" ""managed and exposed. This can lead to delays in root cause analysis where a "" ""provider insists the blame lies with the other provider."" msgstr """" ""Bulutun büyük bölümü harici yönetilen sistemlerdeyse, değişiklik "" ""yapamayacağınız durumlar için hazırlıklı olun. Ek olarak, bulut sağlayıcılar "" ""alt yapının nasıl yönetilip ortaya çıkarılacağı konusunda farklılıklar "" ""gösterebilirler. Bu da bir sağlayıcının suçu diğer sağlayıcıya attığı "" ""durumlarda sorunun kökünü anlamada gecikmelere yol açabilir."" msgid ""If additional storage is required, this option does not scale."" msgstr ""Ek depolama gerekirse, bu seçenek ölçeklenmez."" msgid """" ""If applications running in a cloud are not cloud-aware, there should be "" ""clear measures and expectations to define what the infrastructure can and "" ""cannot support. An example would be shared storage between sites. It is "" ""possible, however such a solution is not native to OpenStack and requires a "" ""third-party hardware vendor to fulfill such a requirement. Another example "" ""can be seen in applications that are able to consume resources in object "" ""storage directly."" msgstr """" ""Eğer bulutta çalışan uygulamalar buluttan habersizlerse, alt yapının "" ""sağlayıp sağlayamayacağı şeyler arasında açık ölçütler olmalıdır. Konumlar "" ""arasındaki paylaşımlı depolama bir örnek olabilir. Yapmak mümkündür, ancak "" ""böyle bir çözüm OpenStack'te doğal olarak yoktur ve üçüncü şahıs bir donanım "" ""sağlayıcısının gereksinimi sağlaması gerekir. Başka bir örnek nesne "" ""depolamadan doğrudan kaynak tüketen uygulamalarda görülebilir."" msgid """" ""If many users will make multiple requests, make sure that the CPU load for "" ""the cloud controller can handle it."" msgstr """" ""Bir çok kullanıcı bir çok istek yapacaksa, bulut kontrol biriminin işlemci "" ""yükünün bunu kaldırabileceğinden emin olun."" msgid """" ""If storage protocols other than Ethernet are part of the storage solution, "" ""ensure the appropriate hardware has been selected. If a centralized storage "" ""array is selected, ensure that the hypervisor will be able to connect to "" ""that storage array for image storage."" msgstr """" ""Ethernet dışındaki depolama iletişim kuralları depolama çözümünün "" ""parçasıysa, uygun donanımın seçildiğinden emin olun. Merkezi bir depolama "" ""dizisi seçildiyse, hipervizörün bu depolama dizisine imaj depolama için "" ""erişebildiğinden emin olun."" msgid """" ""If the cloud is initially built with near end of life, but cost effective "" ""hardware, then the performance and capacity demand of new workloads will "" ""drive the purchase of more modern hardware. With individual hardware "" ""components changing over time, you may prefer to manage configurations as "" ""stock keeping units (SKU)s. This method provides an enterprise with a "" ""standard configuration unit of compute (server) that can be placed in any IT "" ""service manager or vendor supplied ordering system that can be triggered "" ""manually or through advanced operational automations. This simplifies "" ""ordering, provisioning, and activating additional compute resources. For "" ""example, there are plug-ins for several commercial service management tools "" ""that enable integration with hardware APIs. These configure and activate new "" ""compute resources from standby hardware based on a standard configurations. "" ""Using this methodology, spare hardware can be ordered for a datacenter and "" ""provisioned based on capacity data derived from OpenStack Telemetry."" msgstr """" ""Bulut kullanım ömrünün sonunda, ama ucuz donanım ile kurulursa, yeni iş "" ""yüklerinin başarım ve kapasitesi daha modern donanımın alınmasını "" ""gerektirir. Bağımsız donanım bileşenlerinin zamanla değişmesiyle "" ""yapılandırmaları stok saklama birimleri (SKU) olarak yönetmeyi tercih "" ""edebilirsiniz. Bu yöntem bir kuruma herhangi bir IT servis yöneticisi veya "" ""üretici tarafından sağlanan sipariş sistemine dahil edilebilecek ve elle "" ""veya işlevsel otomasyonlarla tetiklenebilecek standart hesaplama (sunucu) "" ""yapılandırma birimi sağlar. Bu da sipariş, hazırlama, ve ek hesaplama "" ""kaynaklarının etkinleştirilmesini kolaylaştırır. Örneğin, bir çok ticari "" ""servis yönetim aracı için donanım API'leriyle tümleşimi etkinleştiren "" ""eklentiler bulunur. Bunlar standart yapılandırmalara dayanarak duran "" ""donanımdan yeni hesaplama kaynakları yapılandırır ve etkinleştirirler. Bu "" ""yöntemle, bir veri merkezi için yedek donanım sipariş verilebilir ve "" ""OpenStack Telemetrisinden gelen veriye göre hazırlanabilirler."" msgid """" ""If the data store is highly changeable, the network requirements could have "" ""a significant effect on the operational cost of maintaining the sites."" msgstr """" ""Veri depolama çokça değişebiliyorsa, ağ gereksinimleri konumların "" ""yönetilmesinin işletme maliyetlerini çok etkileyebilir."" msgid """" ""If the design incorporates more than one site, the ability to maintain "" ""object availability in both sites has significant implications on the Object "" ""Storage design and implementation. It also has a significant impact on the "" ""WAN network design between the sites."" msgstr """" ""Tasarım birden çok konum içeriyorsa, nesne kullanılırlığını tüm konumlarda "" ""sürdürmenin Nesne Depolama tasarımı ve kurulumunda büyük etkisi olacaktır. "" ""Ayrıca konumlar arasındaki WAN ağ tasarımında da büyük etki yaratır."" msgid """" ""If the solution is a scale-out storage architecture that includes DAS, it "" ""will affect the server hardware selection. This could ripple into the "" ""decisions that affect host density, instance density, power density, OS-"" ""hypervisor, management tools and others."" msgstr """" ""Çözüm DAS içeren bir dışa ölçekleme depolama mimarisiyse, sunucu donanımı "" ""seçimini etkiler. Bu sunucu yoğunluğu, güç yoğunluğu, OS-hipervizör, yönetim "" ""araçları ve diğerlerini etkileyen kararların dalgalanmasına neden olur."" msgid """" ""If this is the first time you are deploying a cloud infrastructure in your "" ""organization, your first conversations should be with your networking team. "" ""Network usage in a running cloud is vastly different from traditional "" ""network deployments and has the potential to be disruptive at both a "" ""connectivity and a policy level."" msgstr """" ""Kurumunuzda ilk bulut kurulumunuzu yapıyorsanız, yapacağınız ilk konuşma ağ "" ""takımınızla olmalıdır. Çalışan bir bulutta ağ kullanımı geleneksel ağ "" ""kurulumlarından farklıdır ve hem ilkesel hem bağlantısal seviyede yıkıcı "" ""olma potansiyeli vardır."" msgid """" ""If using a storage design that includes shared access to centralized "" ""storage, ensure that this is also designed without single points of failure "" ""and the SLA for the solution matches or exceeds the expected SLA for the "" ""Data Plane."" msgstr """" ""Merkezi depoya paylaşımlı erişim sunan bir depolama tasarımı kullanılıyorsa, "" ""tek bir kırılma noktası olmayacak şekilde tasarlandığından, ve çözüm için "" ""SLA'nın Veri Düzlemi için beklenen SLA ile eşleştiğinden ya da daha iyi "" ""olduğundan emin olun."" msgid """" ""If you are using ``nova-network`` and multi-host networking in your cloud "" ""environment, ``nova-compute`` still requires direct access to the database."" msgstr """" ""Bulut ortamınızda ``nova-network`` ve çoklu sunucu ağı kullanıyorsanız, "" ""``nova-compute`` veritabanına erişim gerektirecektir."" msgid """" ""If you have an OpenStack Object Storage service, we recommend using this as "" ""a scalable place to store your images. You can also use a file system with "" ""sufficient performance or Amazon S3—unless you do not need the ability to "" ""upload new images through OpenStack."" msgstr """" ""Bir OpenStack Nesne Depolama servisiniz varsa, bunu imajlarınızı saklamak "" ""için ölçeklenebilir bir yer olarak kullanmanızı öneririz. Yeterli başarıma "" ""sahip bir dosya sistemi veya Amazon S3'de kullanabilirsiniz—OpenStack "" ""üzerinden yeni imajlar yüklemeniz gerekmiyorsa."" msgid """" ""If you plan to use live migration, we highly recommend a shared storage "" ""configuration. This allows the operating system and application volumes for "" ""instances to reside outside of the compute nodes and adds significant "" ""performance increases when live migrating."" msgstr """" ""Canlı göç kullanmayı planlıyorsanız, paylaşımlı depolama yapılandırmasını "" ""öneriyoruz. Bu işletim sisteminin ve sunucular için uygulama birimlerinin "" ""hesaplama düğümleri dışında durmasını sağlar ve canlı göç yaparken kayda "" ""değer başarım artışı ekler."" msgid """" ""If you use separate compute and storage hosts, you can treat your compute "" ""hosts as \""stateless\"". As long as you do not have any instances currently "" ""running on a compute host, you can take it offline or wipe it completely "" ""without having any effect on the rest of your cloud. This simplifies "" ""maintenance for the compute hosts."" msgstr """" ""Farklı hesaplama ve depolama sunucuları kullanıyorsanız, hesaplama "" ""sunucularınıza \""durumsuz\"" olarak davranabilirsiniz. Bir hesaplama "" ""sunucusunda çalışan sunucularınız olmadığı sürece çevrimdışı hale "" ""getirebilir, bulutunuzu etkilemeyecek şekilde tamamen silebilirsiniz bile. "" ""Bu hesaplama sunucuları için bakım işini basitleştirir."" msgid """" ""If you want to support shared-storage live migration, you need to configure "" ""a distributed file system."" msgstr """" ""Paylaşımlı depolama canlı göçünü desteklemek isterseniz, dağıtık bir dosya "" ""sistemi yapılandırmalısınız."" msgid ""Image disk utilization"" msgstr ""İmaj diski kullanımı"" msgid ""Image portability"" msgstr ""İmaj taşınabilirliği"" msgid ""Image service for the image management"" msgstr ""İmaj yönetimi için imaj servisi"" msgid ""Image-management services"" msgstr ""İmaj-yönetim servisleri"" msgid ""Images"" msgstr ""İmajlar"" msgid ""Implementing Block Storage"" msgstr ""Blok Depolamanın Uygulanması"" msgid ""Implementing Object Storage"" msgstr ""Nesne Depolamanın Uygulanması"" msgid """" ""In OpenStack, the infrastructure is integral to providing services and "" ""should always be available, especially when operating with SLAs. Ensuring "" ""network availability is accomplished by designing the network architecture "" ""so that no single point of failure exists. A consideration of the number of "" ""switches, routes and redundancies of power should be factored into core "" ""infrastructure, as well as the associated bonding of networks to provide "" ""diverse routes to your highly available switch infrastructure."" msgstr """" ""OpenStack'de alt yapı servis sağlamada ayrılmaz bir yere sahiptir ve her "" ""zaman kullanılır olmalıdır, özellikle SLA'larla işlem yapılırken. Ağ "" ""kullanılırlığından emin olmak tek bir kırılma noktasının olmadığı ağ "" ""mimarisi tasarlamakla elde edilir. Çekirdek alt yapıda anahtarların sayısı, "" ""yönlendiriciler ve gücün yedekliliği yanında rotaların yüksek "" ""kullanılırlıklı anahtar alt yapısına yönlendirilmesini sağlayan ağların "" ""bağlanması gibi ilişkiler göz önünde bulundurulmalıdır."" msgid """" ""In a bin packing design, each independent resource pool provides service for "" ""specific flavors. Since instances are scheduled onto compute hypervisors, "" ""each independent node's resources will be allocated to efficiently use the "" ""available hardware. While bin packing can separate workload specific "" ""resources onto individual servers, bin packing also requires a common "" ""hardware design, with all hardware nodes within a compute resource pool "" ""sharing a common processor, memory, and storage layout. This makes it easier "" ""to deploy, support, and maintain nodes throughout their lifecycle."" msgstr """" ""Kutu paketleme tasarımında, her bağımsız kaynak havuzu belirli nitelikler "" ""için servis sağlar. Sunucular hesaplama hipervizörlerine "" ""zamanlandıklarından, her bağımsız düğümün kaynakları kullanılabilir donanımı "" ""etkin kullanmak üzere ayrılır. Kutu paketleme iş yüküne özel kaynakları "" ""bağımsız sunuculara dağıtabilse de, kutu paketleme genel bir donanım "" ""tasarımı gerektirir, bu tasarımda tüm donanım düğümleri genel bir işlemci, "" ""hafıza, ve depolama düzenini paylaşan hesaplama kaynak havuzundadır. Bu "" ""yaşam döngüleri süresince düğümleri kurmayı, desteklemeyi ve yönetmeyi "" ""kolaylaştırır."" msgid """" ""In a cloud with significant demands on Block Storage, the network "" ""architecture should take into account the amount of East-West bandwidth "" ""required for instances to make use of the available storage resources. The "" ""selected network devices should support jumbo frames for transferring large "" ""blocks of data, and utilize a dedicated network for providing connectivity "" ""between instances and Block Storage."" msgstr """" ""Blok Depolamadan çokça talebi olan bir bulutta, ağ mimarisi sunucuların "" ""kullanılabilir depolama kaynaklarının kullanımı için ihtiyaç duyacakları "" ""Doğu-Batı bant genişliği miktarını hesaba katmalıdır. Seçilen ağ aygıtları "" ""büyük veri bloklarını aktarmak için jumbo çerçeveleri desteklemeli ve "" ""sunucular ve Blok Depolama arasındaki bağlantıyı kuran adanmış bir ağ "" ""kullanılmalıdır."" msgid """" ""In a design with multiple regions, the SLA would also need to take into "" ""consideration the use of shared services such as the Identity service and "" ""Dashboard."" msgstr """" ""Birden çok bölgeden oluşan bir tasarımda, SLA Kimlik servisi ve Kontrol "" ""Paneli gibi paylaşımlı servislerin kullanımını da göz önüne almalıdır."" msgid """" ""In a layer-2 network all devices are aware of all MACs, even those that "" ""belong to instances. The network state information in the backbone changes "" ""whenever an instance starts or stops. Because of this, there is far too much "" ""churn in the MAC tables on the backbone switches."" msgstr """" ""Katman-2 ağda tüm aygıtlar tüm MAC'lerden haberdardır, sunuculara ait "" ""olanlardan bile. Bir sunucu başladığında veya durduğunda omurgadaki ağ durum "" ""bilgisi değişir. Bunun yüzünden, omurga anahtarlarındaki MAC tablolarında "" ""çok daha fazla çalkalanma vardır."" msgid """" ""In addition to the Block Storage resource nodes, it is important to design "" ""for high availability and redundancy of the APIs, and related services that "" ""are responsible for provisioning and providing access to storage. We "" ""recommend designing a layer of hardware or software load balancers in order "" ""to achieve high availability of the appropriate REST API services to provide "" ""uninterrupted service. In some cases, it may also be necessary to deploy an "" ""additional layer of load balancing to provide access to back-end database "" ""services responsible for servicing and storing the state of Block Storage "" ""volumes. It is imperative that a highly available database cluster is used "" ""to store the Block Storage metadata."" msgstr """" ""Blok Depolama kaynağı düğümlerine ek olarak, API'lerin yüksek kullanılırlık "" ""ve yedekliliği, ve depolamaya erişim sağlayan ve hazırlıkla görevli "" ""servisler için tasarım yapmak da önemlidir. Kesintisiz servis sağlamak için "" ""uygun REST API servislerine donanımsal veya yazılımsal yük dengeleyeciler "" ""katmanı ile erişim tasarlamanızı öneririz. Bazı durumlarda, Blok Depolama "" ""birimlerinin durumunu saklamak ve servis etmekle görevli arka uç veritabanı "" ""servislerine erişim için de ek bir yük dengeleyici katman kurmak gerekli "" ""olabilir. Blok Depolama metaverisini yüksek kullanılırlıklı bir veritabanı "" ""kümesi ile kullanmak şarttır."" msgid """" ""In addition to the open source technologies, there are a number of "" ""proprietary solutions that are officially supported by OpenStack Block "" ""Storage. You can find a matrix of the functionality provided by all of the "" ""supported Block Storage drivers on the `CinderSupportMatrix wiki <https://"" ""wiki.openstack.org/wiki/CinderSupportMatrix>`_."" msgstr """" ""Açık kaynak teknolojilere ek olarak, OpenStack Blok Depolama tarafından "" ""resmen desteklenen tescilli çözümler de bulunur. Desteklenen tüm Blok "" ""Depolama sürücülerinin işlevsellik matrisini `CinderSupportMatrix wiki'sinde "" ""<https://wiki.openstack.org/wiki/CinderSupportMatrix>`_ bulabilirsiniz."" msgid """" ""In an HDD, data transfer is sequential. The actual read/write head \""seeks\"" "" ""a point in the hard drive to execute the operation. Seek time is "" ""significant. Transfer rate can also be influenced by file system "" ""fragmentation and the layout. Finally, the mechanical nature of hard disks "" ""also has certain performance limitations."" msgstr """" ""Bir HDD'de, veri aktarımı sıralıdır. İşlemi gerçekleştirmek için okuma/yazma "" ""kafası sabit diskte bir noktayı \""arar\"". Arama süresi kayda değerdir. "" ""Aktarım oranı da dosya sistemi parçalanması ve düzeninden etkilenir. Son "" ""olarak sabit disklerin mekanik doğası başarım kısıtlaması oluşturur."" msgid """" ""In an SSD, data transfer is *not* sequential; it is random so it is faster. "" ""There is consistent read performance because the physical location of data "" ""is irrelevant because SSDs have no read/write heads and thus no delays due "" ""to head motion (seeking)."" msgstr """" ""Bİr SSD'de, veri aktarımı sıralı *değildir*; Rasgeledir yani daha hızlıdır. "" ""Verinin fiziksel konumu önemsiz olduğundan tutarlı okuma başarımı bulunur, "" ""SSD'lerin okuma/yazma kafası yoktur yani arama hareketi yüzünden gecikme "" ""oluşmaz."" msgid """" ""In any environment larger than just a few hosts, there are two areas that "" ""might be subject to a SLA:"" msgstr """" ""Bir kaç sunucudan büyük olan her ortamda SLA'ya konu olabilecek iki alan "" ""vardır:"" msgid """" ""In compute server architecture design, you must also consider network and "" ""storage requirements. For more information on network considerations, see :"" ""ref:`network-design`."" msgstr """" ""Hesaplama sunucusu mimarisi tasarımında, ağ ve depolama gereksinimlerini de "" ""hesaba katmalısınız. Ağ etmenleriyle ilgili daha fazla bilgi için bknz :ref:"" ""`network-design`."" msgid """" ""In environments that place substantial demands on Block Storage, we "" ""recommend using multiple storage pools. In this case, each pool of devices "" ""should have a similar hardware design and disk configuration across all "" ""hardware nodes in that pool. This allows for a design that provides "" ""applications with access to a wide variety of Block Storage pools, each with "" ""their own redundancy, availability, and performance characteristics. When "" ""deploying multiple pools of storage, it is also important to consider the "" ""impact on the Block Storage scheduler which is responsible for provisioning "" ""storage across resource nodes. Ideally, ensure that applications can "" ""schedule volumes in multiple regions, each with their own network, power, "" ""and cooling infrastructure. This will give tenants the option of building "" ""fault-tolerant applications that are distributed across multiple "" ""availability zones."" msgstr """" ""Blok Depolamaya yük bindiren ortamlarda, birden fazla depolama havuzu "" ""kullanılmasını öneriyoruz. Bu durumda, her bir aygıt havuzu bu havuzdaki tüm "" ""donanım düğümleri arasında benzer donanım tasarımı ve disk yapılandırmasına "" ""sahip olmalıdır. Bu uygulamalara her biri kendi yedekliliğine, "" ""kullanılırlığına ve başarım karakteristiklerine sahip çeşitli Blok Depolama "" ""havuzlarına erişim sağlayan bir tasarıma izin verir. Birden fazla depolama "" ""havuzu kurarken, düğüm kaynakları arasında depolama hazırlamakla görevli "" ""Blok Depolama zamanlayıcısına olan etkinin de göz önünde tutulması gerekir. "" ""İdeal olarak, uygulamaların birimleri her biri kendi ağ, güç ve soğutma alt "" ""yapısına sahip birden fazla bölgede zamanlayabildiklerinden emin olun. Bu "" ""kiracılara birden çok kullanılırlık bölgesine dağıtılmış hata toleranslı "" ""uygulamalar inşa etme seçeneği verir."" msgid """" ""In general, the questions you should ask when selecting storage are as "" ""follows:"" msgstr ""Genel olarak, depolama seçerken sormanız gereken sorular şunlardır:"" msgid """" ""In layer-3 networking, routing takes instance MAC and IP addresses out of "" ""the network core, reducing state churn. The only time there would be a "" ""routing state change is in the case of a Top of Rack (ToR) switch failure or "" ""a link failure in the backbone itself. Other advantages of using a layer-3 "" ""architecture include:"" msgstr """" ""Katman-3 ağda, yönlendirme sunucu MAC ve IP adreslerini ağ çekirdeğinden "" ""alır, bu da çalkalanmayı azaltır. Yönlendirme durum değişikliği ancak Kabin "" ""Üstü (ToR) anahtar arızasında veya omurgadaki bir bağlantıda sorun olduğunda "" ""olur. Katman-3 mimarisi kullanmanın diğer avantajları şunlardır:"" msgid """" ""In most cases, hyper-threading CPUs can provide a 1.3x to 2.0x performance "" ""benefit over non-hyper-threaded CPUs depending on types of workload."" msgstr """" ""Çoğu durumda, hyper-threading işlemciler iş yükü türüne bağlı olarak 1.3 "" ""kattan 2.0 kata kadar başarım artışı sağlarlar."" msgid """" ""In multi-tenant OpenStack cloud environment, the Shared File Systems service "" ""(manila) provides a set of services for management of shared file systems. "" ""The Shared File Systems service supports multiple back-ends in the form of "" ""drivers, and can be configured to provision shares from one or more back-"" ""ends. Share servers are virtual machines that export file shares using "" ""different file system protocols such as NFS, CIFS, GlusterFS, or HDFS."" msgstr """" ""Çoklu kiracılı OpenStack bulut ortamında, Paylaşımlı Dosya Sistemi servisi "" ""(manila) paylaşımlı dosya sistemlerinin yönetimi için bir servis kümesi "" ""sağlar. Paylaşımlı Dosya Sistemleri servisi sürücüler biçiminde birden çok "" ""arka uç destekler, ve paylaşımları bir ya da daha fazla arka uçtan "" ""hazırlayacak şekilde yapılandırılabilir. Paylaşım sunucuları dosya "" ""paylaşımlarını NFS, CIFS, GlusterFS, veya HDFS gibi farklı dosya sistemi "" ""iletişim kurallarını kullanarak dışa aktarabilen sanal makinelerdir."" msgid """" ""In order to take advantage of these new enhancements in the Compute service, "" ""compute hosts must be using NUMA capable CPUs."" msgstr """" ""Hesaplama servisindeki bu yeni iyileştirmelerden faydalanmak için, hesaplama "" ""sunucuları NUMA kapasiteli işlemciler kullanmalıdır."" msgid """" ""In some cases, the demand on Block Storage may exhaust the available network "" ""bandwidth. As a result, design network infrastructure that services Block "" ""Storage resources in such a way that you can add capacity and bandwidth "" ""easily. This often involves the use of dynamic routing protocols or advanced "" ""networking solutions to add capacity to downstream devices easily. Both the "" ""front-end and back-end storage network designs should encompass the ability "" ""to quickly and easily add capacity and bandwidth."" msgstr """" ""Bazı durumlarda, Blok Depolama talebi kullanılabilir ağ bant genişliğini "" ""yorabilir. Sonuç olarak, Blok Depolama kaynaklarına ihtiyaç halinde kapasite "" ""ya da bant genişliğini kolaylıkla ekleyebileceğiniz ağ alt yapıları "" ""tasarlayın. Bu çoğu zaman dinamik yönlendirme iletişim kurallarının veya "" ""aşağı akış aygıtlarına kolaylıkla kapasite eklemek için gelişmiş ağ "" ""çözümlerinin kullanılmasını içerir. Hem ön uç hem arka uç depolama ağı "" ""tasarımları kolayca kapasite ve bant genişliği ekleme konusunu kapsamalıdır."" msgid """" ""In some cases, you must add bandwidth and capacity to the network resources "" ""servicing requests between proxy servers and storage nodes. For this reason, "" ""the network architecture used for access to storage nodes and proxy servers "" ""should make use of a design which is scalable."" msgstr """" ""Bazı durumlarda, vekil sunucular ve depolama düğümleri arasında istekleri "" ""sunan ağ kaynakları için bant genişliği ve kapasite eklemeniz gerekebilir. "" ""Bu sebeple depolama düğümleri ve vekil sunuculara erişim için kullanılan ağ "" ""mimarisi ölçeklenebilir bir tasarımı kullanmalıdır."" msgid """" ""In the previous version of OpenStack, all ``nova-compute`` services required "" ""direct access to the database hosted on the cloud controller. This was "" ""problematic for two reasons: security and performance. With regard to "" ""security, if a compute node is compromised, the attacker inherently has "" ""access to the database. With regard to performance, ``nova-compute`` calls "" ""to the database are single-threaded and blocking. This creates a performance "" ""bottleneck because database requests are fulfilled serially rather than in "" ""parallel."" msgstr """" ""OpenStack'in önceki sürümünde tüm ``nova-compute`` servisleri bulut kontrol "" ""biriminde sunulan veritabanına doğrudan erişim gerektiriyordu. Bu iki "" ""sebepten sorunludur: güvenlik ve başarım. Güvenliğe nazaran, bir hesaplama "" ""düğümü ele geçirilirse, saldırgan veritabanına erişim sağlayabilir. Başarımı "" ""düşünürsek, veritabanına yapılan ``nova-compute`` çağrıları tek iş "" ""ipliklidir ve engelleyicidir. Bu da veritabanı istekleri paralel yerine seri "" ""işleneceğinden başarım sorunları oluşturur."" msgid """" ""In this example, Ceph presents a swift-compatible REST interface, as well as "" ""a block level storage from a distributed storage cluster. It is highly "" ""flexible and has features that enable reduced cost of operations such as "" ""self healing and auto balancing. Using erasure coded pools are a suitable "" ""way of maximizing the amount of usable space."" msgstr """" ""Bu örnekte, Ceph swift-uyumlu bir REST arayüzü ve dağıtım depolama "" ""kümesinden blok seviyesinde depolama sunar. Oldukça esnektir ve kendini "" ""iyileştirme ve otomatik dengeleme gibi işlemlerin maliyetini azaltan "" ""özelliklere sahiptir. Silinti kodlu havuzlar kullanmak azami kullanılır "" ""alana sahip olmak için uygun bir yöntemdir."" msgid """" ""In this option, each compute node is specified with a significant amount of "" ""disk space, but a distributed file system ties the disks from each compute "" ""node into a single mount."" msgstr """" ""Bu seçenekte, her hesaplama düğümü kayda değer miktarda disk alanıyla "" ""belirtilir, ama dağıtık bir dosya sistemi her bir hesaplama düğümünden "" ""diskleri tek bir bağlama noktasına bağlar."" msgid """" ""In this option, each compute node is specified with enough disks to store "" ""the instances it hosts."" msgstr """" ""Bu seçenekte, her hesaplama düğümü sunduğu sunucuları saklamak için yeterli "" ""diskle belirtilir."" msgid """" ""In this option, the disks storing the running instances are hosted in "" ""servers outside of the compute nodes."" msgstr """" ""Bu seçenekte, çalışan sunucuları saklayan diskler hesaplama düğümleri "" ""dışındaki sunucularda sunulur."" msgid ""In-memory key-value Store (a simplified internal storage structure)"" msgstr """" ""Hafızada anahtar-değer saklama (basitleştirilmiş dahili depolama yapısı)"" msgid """" ""Increasing OpenStack Object Storage means network bandwidth needs to be "" ""taken into consideration. Running OpenStack Object Storage with network "" ""connections offering 10 GbE or better connectivity is advised."" msgstr """" ""OpenStack Nesne Depolamanın artırılması demek ağ genişliğinin hesaba "" ""katılması demektir. OpenStack Nesne Depolamanın 10 GbE veya daha iyi "" ""bağlantı sağlayan ağ bağlantılarıyla çalıştırılması önerilir."" msgid """" ""Increasing the size of the supporting compute environment increases the "" ""network traffic and messages, adding load to the controllers and "" ""administrative services used to support the OpenStack cloud or networking "" ""nodes. When considering hardware for controller nodes, whether using the "" ""monolithic controller design, where all of the controller services live on "" ""one or more physical hardware nodes, or in any of the newer shared nothing "" ""control plane models, adequate resources must be allocated and scaled to "" ""meet scale requirements. Effective monitoring of the environment will help "" ""with capacity decisions on scaling. Proper planning will help avoid "" ""bottlenecks and network oversubscription as the cloud scales."" msgstr """" ""Destekleyen hesaplama ortamının boyutunu artırmak ağ trafiği ve iletileri de "" ""artırır, OpenStack bulutunu veya ağ düğümlerini desteklemek için kullanılan "" ""kontrol birimlerine ve yönetim servislerine ek yük bindirir. Kontrol "" ""düğümlerine donanım eklemeyi düşünürken, tüm kontrol servislerinin bir ya da "" ""daha fazla fiziksel donanım düğümlerinde çalıştığı tek parça kontrol "" ""tasarımı kullanılıyor olsa da, daha yeni hiçbir şeyin paylaşılmadığı kontrol "" ""düzlemi modellerinden birinde olunsa da ölçekleme gereksinimlerini "" ""karşılamak için yeterli kaynak ayrılmalı ve ölçeklenmelidir. Ortamın etkin "" ""şekilde izlenmesi ölçeklemede kapasite seçimine yardımcı olacaktır. Düzgün "" ""planlama bulut ölçeklendikçe ağ abonelik aşımlarını ve darboğazların "" ""olmasını engeller."" msgid """" ""Indicates which resources to use first; for example, spreading out where "" ""instances are launched based on an algorithm"" msgstr """" ""İlk önce hangi kaynakların kullanılacağını belirtir, örneğin bir algoritmaya "" ""göre sunucuların başlatıldığı yayılım"" msgid """" ""Indicates which users can do what actions on certain cloud resources; quota "" ""management is spread out among services, howeverauthentication"" msgstr """" ""Hangi kullanıcıların hangi eylemleri belirli bulut kaynaklarına göre "" ""yapabileceğini gösterir; kota yönetimi servisler arasına dağılmıştır, ancak "" ""yetkilendirme"" msgid """" ""Input-Output performance requirements require researching and modeling "" ""before deciding on a final storage framework. Running benchmarks for Input-"" ""Output performance provides a baseline for expected performance levels. If "" ""these tests include details, then the resulting data can help model behavior "" ""and results during different workloads. Running scripted smaller benchmarks "" ""during the lifecycle of the architecture helps record the system health at "" ""different points in time. The data from these scripted benchmarks assist in "" ""future scoping and gaining a deeper understanding of an organization's needs."" msgstr """" ""Girdi-Çıktı başarım gereksinimleri depolama çatısının son haline karar "" ""verilmeden araştırılmalı ve modellenmelidir. Girdi-Çıktı başarımı için "" ""değerlendirme deneyleri çalıştırmak beklenen başarım seviyeleri için temel "" ""bir çizgi sağlar. Bu deneyler ayrıntıları içerirse, sonuçta alınan veri "" ""farklı iş yükleri için davranış ve sonuç modellemede yardımcı olabilir. "" ""Mimarinin yaşam sürecinde betik halinde daha küçük değerlendirme deneyleri "" ""çalıştırmak sistem sağlığını zamanda farklı noktalarda kaydetmede yardımcı "" ""olur. Bu betik halindeki değerlendirme deneylerinden gelen veri ilerdeki "" ""kapsamın belirlenmesinde ve bir kurumun ihtiyaçlarının daha derinden "" ""anlanabilmesinde yardımcı olur."" msgid ""Input-Output requirements"" msgstr ""Girdi-Çıktı gereksinimleri"" msgid ""Installs a virtual environment and runs tests."" msgstr ""Sanal bir ortam kurar ve denemeler çalıştırır."" msgid ""Instance and image locations"" msgstr ""Sunucu ve imaj konumları"" msgid ""Instance density"" msgstr ""Sunucu yoğunluğu"" msgid ""Instance storage solutions"" msgstr ""Sunucu depolama çözümleri"" msgid """" ""Insufficient disk capacity could also have a negative effect on overall "" ""performance including CPU and memory usage. Depending on the back end "" ""architecture of the OpenStack Block Storage layer, capacity includes adding "" ""disk shelves to enterprise storage systems or installing additional Block "" ""Storage nodes. Upgrading directly attached storage installed in Compute "" ""hosts, and adding capacity to the shared storage for additional ephemeral "" ""storage to instances, may be necessary."" msgstr """" ""Yetersiz disk kapasitesinin de işlemci ve hafıza kullanımıyla birlikte genel "" ""başarımda negatif etkisi vardır. OpenStack Blok Depolama katmanının arka uç "" ""mimarisine bağlı olarak, kapasite kurumsal depolama sistemlerine disk "" ""eklemeyi veya ek Blok Depolama düğümleri eklemeyi içerir. Hesaplama "" ""düğümlerine doğrudan ekli deoplamayı yükseltmek, ve sunuculara ek geçici "" ""depolama için paylaşımlı depolamaya kapasite eklemek gerekli olabilir."" msgid """" ""Integration with OpenStack Identity, and works with the OpenStack Dashboard."" msgstr """" ""OpenStack Kimlik ile tümleşik, ve OpenStack Kontrol Paneli ile birlikte "" ""çalışır."" msgid """" ""Internet Small Computer Systems Interface (iSCSI) is a network protocol that "" ""operates on top of the Transport Control Protocol (TCP) for linking data "" ""storage devices. It transports data between an iSCSI initiator on a server "" ""and iSCSI target on a storage device."" msgstr """" ""İnternet Küçük Bilgisayar Sistemleri Arayüzü (iSCSI) Aktarım Kontrol "" ""İletişim Kuralı (TCP) üzerinde çalışan veri depolama aygıtlarını bağlamak "" ""için kullanılan bir ağ iletişim kuralıdır. Bir sunucu üzerindeki iSCSI "" ""başlatıcı ile depolama aygıtındaki iSCSI hedefi arasında veri aktarır."" msgid """" ""Is it interoperable with all of the projects you are planning on using in "" ""your cloud?"" msgstr """" ""Bulutunuzda kullanmayı düşündüğünüz tüm projelerle birlikte çalışabilir mi?"" msgid ""Is the storage proven with the OpenStack platform?"" msgstr ""Depolama OpenStack platformuyla uyumlu mu?"" msgid ""Isolate virtual networks using encapsulation technologies."" msgstr ""Kapsülleme teknolojilerini kullanarak sanal ağları yalıtın."" msgid ""Issues with live migration"" msgstr ""Canlı göç ile ilgili sorunlar"" msgid """" ""It can be difficult to troubleshoot a network without IP addresses and ICMP."" msgstr ""IP adresleri ve ICMP olmadan bir ağda sorun gidermek zordur."" msgid """" ""It is also important to consider how costs will increase as your cloud "" ""scales. Choices that have a negligible impact in small systems may "" ""considerably increase costs in large systems. In these cases, it is "" ""important to minimize capital expenditure (CapEx) at all layers of the "" ""stack. Operators of massively scalable OpenStack clouds require the use of "" ""dependable commodity hardware and freely available open source software "" ""components to reduce deployment costs and operational expenses. Initiatives "" ""like Open Compute (more information available in the `Open Compute Project "" ""<http://www.opencompute.org>`_) provide additional information."" msgstr """" ""Bulutunuz ölçeklendiğinde masrafların da nasıl artacağını göz önünde tutmak "" ""önemlidir. Küçük sistemlerde önemsiz etkisi olan seçimler sistem büyüdüğünde "" ""masrafları kayda değer ölçüde artırabilir. Bu gibi durumlarda, yığının tüm "" ""katmanlarında sermaye masrafını (CapEx) asgariye düşürmek önemlidir. Büyük "" ""ölçekte OpenStack bulutlarını işletenlerin güvenilir donanım malları ve "" ""özgürce kullanılabilir açık kaynak yazılım bileşenlerini kullanarak kurulum "" ""ve işletme masraflarını düşürmeleri gereklidir. Açık Hesaplama gibi (daha "" ""fazla bilgi için bknz `Açık Hesaplama Projesi <http://www.opencompute."" ""org>`_) girişimler ek bilgi sağlarlar."" msgid """" ""It is also possible to run multiple hypervisors in a single deployment using "" ""host aggregates or cells. However, an individual compute node can run only a "" ""single hypervisor at a time."" msgstr """" ""Tek bir kurulumda sunucu takımları veya hücreler kullanarak birden çok "" ""hipervizör çalıştırmak da mümkün. Ancak, bağımsız bir hesaplama düğümü "" ""yalnızca tek bir hipervizör çalıştırabilir."" msgid """" ""It is difficult to predict the amount of load a particular application might "" ""incur if the number of users fluctuates, or the application experiences an "" ""unexpected increase in use. It is possible to define application "" ""requirements in terms of vCPU, RAM, bandwidth, or other resources and plan "" ""appropriately. However, other clouds might not use the same meter or even "" ""the same oversubscription rates."" msgstr """" ""Belli bir uygulamanın kullanıcı sayısı dalgalandığında veya uygulama "" ""kullanımda beklenmedik artış yaşadığında alacağı yükü tahmin etmek zordur. "" ""Uygulama gereksinimlerini vCPU, RAM, bant genişliği, veeya diğer kaynaklara "" ""göre belirleyip uygun planlama yapmak mümkündür. Ancak, diğer bulutlar aynı "" ""ölçümleri hatta aynı abonelik aşım oranlarını kullanmıyor olabilir."" msgid """" ""It is essentially an object storage system that manages disks and aggregates "" ""the space and performance of disks linearly in hyper scale on commodity "" ""hardware in a smart way. On top of its object store, Sheepdog provides "" ""elastic volume service and http service. Sheepdog does require a specific "" ""kernel version and can work nicely with xattr-supported file systems."" msgstr """" ""Özünde diskleri yöneten ve disklerin alanını ve başarımını doğrusal olarak "" ""büyük ölçekte ticari donanım üzerinde akıllıca bir yolla takımlayan nesne "" ""depolama sistemidir. Nesne depolamasının üstüne, Sheepdog esnek birim "" ""servisi ve http servisi sağlar. Sheepdog belirli bir çekirdek sürümüne "" ""ihtiyaç duyar ve xattr-destekli dosya sistemlerinde güzelce çalışabilir."" msgid """" ""It is important to analyze the applications tolerance for latency and jitter "" ""when designing an environment to support network focused applications. "" ""Certain applications, for example VoIP, are less tolerant of latency and "" ""jitter. When latency and jitter are issues, certain applications may require "" ""tuning of QoS parameters and network device queues to ensure that they "" ""immediately queue for transmitting or guarantee minimum bandwidth. Since "" ""OpenStack currently does not support these functions, consider carefully "" ""your selected network plug-in."" msgstr """" ""Ağ odaklı uygulamaları destekleyen bir ortam tasarlarken uygulamanın gecikme "" ""ve titremeye karşı dayanıklılığını çözümlemek önemlidir. Bazı uygulamalar, "" ""örneğin VoIP gecikmeye pek gelmez. Gecikme ve titreme sorun olduğunda, bazı "" ""uygulamalar QoS parametreleri ve ağ aygıt kuyruklarıyla ayarlanarak iletim "" ""kuyruğuna anında alınmaları ya da asgari bant genişliği atamalarının "" ""yapılması sağlanabilir. OpenStack şu an bu özellikleri desteklemediğinden, "" ""seçtiğiniz ağ eklentisini dikkatle ele alın."" msgid """" ""It is important to consider the functionality, security, scalability, "" ""availability, and testability of the network when choosing a CMP and cloud "" ""provider."" msgstr """" ""Bir CMP ve bulut sağlayıcısı seçerken ağın işlevsellik, güvenlik, "" ""ölçeklenebilirlik, kullanılabilirlik, ve denenebilirliğini göz önüne almak "" ""önemlidir."" msgid """" ""It is important to determine as part of the SLA negotiation which party is "" ""responsible for monitoring and starting up the Compute service instances if "" ""an outage occurs."" msgstr """" ""Bir kesinti durumunda hangi tarafın Hesaplama servisi sunucularını "" ""başlatmaktan ve takip etmekten sorumlu olduğunu SLA el sıkışmalarında "" ""tanımlamak önemlidir."" msgid """" ""It is important to know that layer-2 has a very limited set of network "" ""management tools. It is difficult to control traffic as it does not have "" ""mechanisms to manage the network or shape the traffic. Network "" ""troubleshooting is also troublesome, in part because network devices have no "" ""IP addresses. As a result, there is no reasonable way to check network delay."" msgstr """" ""Katman-2'nin çok kısıtlı ağ yönetim araçları olduğunu bilmek önemlidir. Ağı "" ""yönetmek ve trafiği şekillendirmek için mekanizmaları olmadığından trafiği "" ""kontrol etmek zordur. Kısmen ağ aygıtlarının IP adresi olmadığından, ağda "" ""sorun giderme de sorunludur. Sonuç olarak, ağ gecikmesini kontrol edecek "" ""makul bir yol yoktur."" msgid """" ""It is important to understand what happens to the replication of objects and "" ""data between the sites when a site goes down. If this causes queues to start "" ""building up, consider how long these queues can safely exist until an error "" ""occurs."" msgstr """" ""Bir konum çalışmaz hale geldiğinde nesnelerin kopyalarına ve konumlar "" ""arasındaki veriye ne olduğunu anlamak önemlidir. Eğer bu kuyrukların "" ""oluşmasına sebep oluyorsa, bu kuyrukların bir hata oluşmadan ne kadar uzun "" ""var olabileceklerini düşünün."" msgid """" ""It is possible to gain more performance out of a single storage system by "" ""using specialized network technologies such as RDMA, SRP, iSER and SCST. The "" ""specifics of using these technologies is beyond the scope of this book."" msgstr """" ""RDMA, SRP, iSER ve SCST gibi özelleştirilmiş ağ teknolojilerini kullanarak "" ""tek bir depolama sisteminden daha çok başarım almak mümkündür. Bu "" ""teknolojilerin kullanımı bu kitabın kapsamı dışında kalıyor."" msgid """" ""It is recommended to have a single authentication domain rather than a "" ""separate implementation for each and every site. This requires an "" ""authentication mechanism that is highly available and distributed to ensure "" ""continuous operation. Authentication server locality might be required and "" ""should be planned for."" msgstr """" ""Her konum için ayrı bir uygulama yerine tek bir yetkilendirme alanının "" ""olması tavsiye edilir. Bu yüksek kullanılırlıklı ve dağıtık bir "" ""yetkilendirme mekanizması demektir. Yetkilendirme sunucusunun konumu "" ""planlanmalıdır."" msgid """" ""It may be necessary to implement a third party caching layer for some "" ""applications to achieve suitable performance."" msgstr """" ""Uygun başarımı yakalamak için bazı uygulamalar için üçüncü taraf bir ön "" ""bellekleme katmanı uygulamak gerekebilir."" msgid ""It may be possible to share the external storage for other purposes."" msgstr ""Harici depolamayı diğer amaçlar için paylaşmak mümkün olabilir."" msgid """" ""It's also possible to use virtual machines for all or some of the services "" ""that the cloud controller manages, such as the message queuing. In this "" ""guide, we assume that all services are running directly on the cloud "" ""controller."" msgstr """" ""Bulut kontrol biriminin yönettiği ileti kuyruğu gibi bazı servisler ya da "" ""tüm servisler için sanal makineler kullanmak da mümkündür. Bu kılavuzda, tüm "" ""servislerin bulut kontrol biriminde çalıştığını varsayacağız."" msgid ""Justification"" msgstr ""Gerekçe"" msgid ""LBaaS"" msgstr ""LBaaS"" msgid ""LDAP (such as OpenLDAP or Microsoft's Active Directory)"" msgstr ""LDAP (OpenLDAP veya Microsoft Active Directory gibi)"" msgid ""LVM"" msgstr ""LVM"" msgid """" ""LVM does *not* provide any replication. Typically, administrators configure "" ""RAID on nodes that use LVM as block storage to protect against failures of "" ""individual hard drives. However, RAID does not protect against a failure of "" ""the entire host."" msgstr """" ""LVM herhangi bir yedeklilik *sunmaz*. Genellikle yöneticiler LVM'i blok "" ""depolama olarak kullanan düğümler üzerinde RAID yapılandırarak hard "" ""disklerin arızalanması durumuna karşı koruma sağlarlar. Ancak RAID tüm bir "" ""sunucunun arızalanması durumunda koruma sağlayamaz."" msgid """" ""Larger rack-mounted servers, such as 4U servers, often provide even greater "" ""CPU capacity, commonly supporting four or even eight CPU sockets. These "" ""servers have greater expandability, but such servers have much lower server "" ""density and are often more expensive."" msgstr """" ""4U sunucular gibi daha geniş kabine-bağlı sunucular genellikle daha büyük, "" ""dört ya da sekiz işlemci soketine sahip işlemci kapasitesi sağlarlar. Bu "" ""sunucuların genişleyebilirliği büyük olsa da, sunucu yoğunlukları düşüktür "" ""ve genellikle daha pahalıdırlar."" msgid ""Latency"" msgstr ""Gecikme"" msgid ""Layer networking choices"" msgstr ""Katman ağ seçimleri"" msgid """" ""Layer-2 Ethernet usage has additional benefits over layer-3 IP network usage:"" msgstr """" ""Katman-2 Ethernet kullanımının katman-3 IP ağı kullanımına göre ek faydaları "" ""bulunur:"" msgid ""Layer-2 architecture limitations"" msgstr ""Katman-2 mimari kısıtlamaları"" msgid """" ""Layer-2 network architectures have some limitations that become noticeable "" ""when used outside of traditional data centers."" msgstr """" ""Katman-2 ağ mimarileri geleneksel veri merkezlerinin dışına çıkıldığında "" ""fark edilebilen bazı kısıtlamalara sahiptirler."" msgid ""Layer-3 architecture limitations"" msgstr ""Katman-3 mimari kısıtlamaları"" msgid """" ""Layer-3 architectures enable the use of :term:`quality of service (QoS)` to "" ""manage network performance."" msgstr """" ""Katman-3 mimariler ağ başarımını yönetmek için :term:`servis kalitesi (QoS)` "" ""kullanımını etkinleştirirler."" msgid """" ""Layer-3 networks provide the same level of resiliency and scalability as the "" ""Internet."" msgstr """" ""Katman-3 ağları İnternet'le aynı seviyede esneklik ve ölçeklenebilirlik "" ""sağlar."" msgid """" ""Leveraging Orchestration and Telemetry services is also a potential issue "" ""when providing auto-scaling, orchestrated web application environments. "" ""Defining the web applications in a :term:`Heat Orchestration Template (HOT)` "" ""negates the reliance on the current scripted Puppet solution."" msgstr """" ""Otomatik ölçeklenen, düzenlenen web uygulama ortamları sağlanırken "" ""Orkestrasyon ve Telemetri servislerini yükseltmek de potansiyel bir "" ""sorundur. Web uygulamalarını bir term:`Heat Orkestrasyon Şablonun (HOT)` "" ""içinde tanımlamak mevcut betiklenmiş Puppet çözümünü boşa çıkarır."" msgid """" ""Likely to be fully symmetric. Because replication originates from any node "" ""and might target multiple other nodes algorithmically, it is less likely for "" ""this traffic to have a larger volume in any specific direction. However, "" ""this traffic might interfere with north-south traffic."" msgstr """" ""Tamamen simetrik olacaktır. Çoğaltma herhangi bir düğümden olacağından ve "" ""algoritmik olarak diğer düğümleri hedefleyeceğinden, bu trafiğin herhangi "" ""özel bir yöne daha fazla hacmi olması beklenmez. Ancak bu trafik kuzey-güney "" ""trafiğe karışabilir."" msgid ""Limitations applied by Administrator"" msgstr ""Yönetici tarafından uygulanan sınırlamalar"" msgid ""Linux and virtualization experience."" msgstr ""Linux ve sanallaştırma deneyimi."" msgid ""Live migration and block migration still have some issues:"" msgstr ""Canlı göç ve blok göçün yine de bazı sorunları bulunur:"" msgid """" ""Live migration can also be done with non-shared storage, using a feature "" ""known as *KVM live block migration*. While an earlier implementation of "" ""block-based migration in KVM and QEMU was considered unreliable, there is a "" ""newer, more reliable implementation of block-based live migration as of the "" ""Mitaka release."" msgstr """" ""Canlı göç paylaşımsız depolamayla da yapılabilir, bu *KVM canlı blok göçü* "" ""olarak bilinen bir özelliktir. KVM ve QEMU'da blok tabanlı göçün öcneki "" ""uygulamaları güvenilir değilse de, Mitaka dağıtımıyla birlikte daha "" ""güvenilir ve yeni bir blok tabanlı canlı göç uygulaması gelmiştir."" msgid """" ""Live migration is an integral part of the operations of the cloud. This "" ""feature provides the ability to seamlessly move instances from one physical "" ""host to another, a necessity for performing upgrades that require reboots of "" ""the compute hosts, but only works well with shared storage."" msgstr """" ""Canlı göç bulut işlevlerinin ayrılmaz parçasıdır. Bu özellik sunucuların bir "" ""fiziksel sunucudan diğerine kolaylıkla taşınmasını sağlar, bu da hesaplama "" ""düğümünün yeniden başlatılmasının gerektiği güncellemelerde bir "" ""gereksinimdir, ama yalnızca paylaşımlı depolamada iyi çalışır."" msgid ""Live migration of rescued images."" msgstr ""Kurtarılan imajların canlı göçü."" msgid ""Live migration resource tracking issues."" msgstr ""Canlı göç kaynak izleme sorunları."" msgid ""Load balancing"" msgstr ""Yük dengeleme"" msgid """" ""Load balancing spreads requests across multiple instances. This workload "" ""scales well horizontally across large numbers of instances. This enables "" ""instances to run without publicly routed IP addresses and instead to rely on "" ""the load balancer to provide a globally reachable service. Many of these "" ""services do not require direct server return. This aids in address planning "" ""and utilization at scale since only the virtual IP (VIP) must be public."" msgstr """" ""Yük dengeleme istekleri birden çok sunucu arasına dağıtır. Bu iş yükü yatay "" ""olarak çok sayıda sunucu ile iyi ölçeklenir. Bu sunucuların açıkça "" ""yönlendirilmiş IP adresleri olmadan çalışmasını sağlar ve açıkça "" ""erişilebilir servis sunma işini yük dengeleyiciye bırakır. Bu servislerden "" ""bir çoğu doğrudan sunucu geridönüşü gerektirmez. Bu da büyük ölçekte adres "" ""planlama ve kullanımına yardımcı olur zira yalnızca sanal IP (VIP) dışardan "" ""erişilebilir olmalıdır."" msgid ""Location"" msgstr ""Konum"" msgid """" ""Log analysis often requires disparate logs of differing formats. Elastic "" ""Stack (namely Logstash) was created to take many different log inputs and "" ""transform them into a consistent format that Elasticsearch can catalog and "" ""analyze. As seen in the image above, the process of ingestion starts on the "" ""servers by Logstash, is forwarded to the Elasticsearch server for storage "" ""and searching, and then displayed through Kibana for visual analysis and "" ""interaction."" msgstr """" ""Günlük kaydı analizi çoğunlukla farklı biçimlerde apayrı kayıtlarla yapılır. "" ""Elastic Stack (yani Logstash) olabildiğince farklı kayıt girdisini alıp "" ""Elasticsearch sunucusunun sınıflandırıp analiz edebileceği tutarlı bir "" ""biçime dönüştürmek için oluşturulmuştur. Aşağıdaki imajda görülebildiği "" ""gibi, sunuculardaki içeri alım süreci Logstash ile başlar, depolama ve arama "" ""için Elasticsearch sunucusuna gönderilir, ve görsel analiz ve etkileşim için "" ""Kibana aracılığıyla görüntülenir."" msgid ""Logging and monitoring"" msgstr ""Günlük kayıtları ve izleme"" msgid """" ""Logging and monitoring does not significantly differ for a multi-site "" ""OpenStack cloud. The tools described in the `Logging and monitoring <https://"" ""docs.openstack.org/ops-guide/ops-logging-monitoring.html>`__ in the "" ""Operations Guide remain applicable. Logging and monitoring can be provided "" ""on a per-site basis, and in a common centralized location."" msgstr """" ""Günlük kayıtları ve izleme birden çok konumdaki OpenStack bulutlarında fazla "" ""değişiklik göstermez. İşlemler kılavuzundaki `Günlük kaydı ve izleme "" ""<https://docs.openstack.org/ops-guide/ops-logging-monitoring.html>`__ "" ""araçları uygulanabilir kalırlar. Günlük kayıtları ve izleme konum başına "" ""dağıtılabilir ya da merkezi bir konumda tutulabilir."" msgid """" ""Logging is described in more detail in the `Operations Guide <https://docs."" ""openstack.org/ops-guide/ops-logging-monitoring.html>`_. However, it is an "" ""important design consideration to take into account before commencing "" ""operations of your cloud."" msgstr """" ""Günlük kayıtları `İşlem Kılavuzunda <https://docs.openstack.org/ops-guide/"" ""ops-logging-monitoring.html>`_ daha ayrıntılı tanımlanmıştır. Ancak "" ""bulutunuzu işletmeye başlamadan önce ele almanız gereken önemli tasarım "" ""etmenidir."" msgid """" ""Logs from the web application servers are shipped to OpenStack Object "" ""Storage for processing and archiving."" msgstr """" ""Web uygulama sunucularından gelen günlük kayıtları OpenStack Nesne "" ""Depolamaya işleme ve arşivleme için gönderilir."" msgid ""Loss of compute nodes decreases storage availability for all hosts."" msgstr """" ""Hesaplama düğümlerinin kaybı tüm sunucular için kullanılabilir depolamanın "" ""azalmasına neden olur."" msgid """" ""Loss of the database leads to errors. As a result, we recommend that you "" ""cluster your database to make it failure tolerant. Configuring and "" ""maintaining a database cluster is done outside OpenStack and is determined "" ""by the database software you choose to use in your cloud environment. MySQL/"" ""Galera is a popular option for MySQL-based databases."" msgstr """" ""Veritabanı kaydı hatalara yol açar. Sonuç olarak hataya dayanıklı olması "" ""için veritabanınızı kümelemenizi öneririz. Veritabanı kümesi yapılandırmak "" ""ve yönetmek OpenStack kapsamı dışında kalır ve bulut ortamınız için "" ""seçtiğiniz veritabanı yazılımına bağlıdır. MySQL tabanlı veritabanları için "" ""MySQL/Galera popüler bir seçenektir."" msgid ""Lustre"" msgstr ""Lustre"" msgid """" ""MLAG, often used for switch redundancy, is a proprietary solution that does "" ""not scale beyond two devices and forces vendor lock-in."" msgstr """" ""Çoğunlukla anahtar yedekliliğinde kullanılan MLAG, iki aygıttan fazlasına "" ""ölçeklenemeyen ve üreticiye bağımlılığa zorlayan bir çözümdür."" msgid ""Maintenance considerations"" msgstr ""Bakım etmenleri"" msgid ""Maintenance tasks"" msgstr ""Bakım görevleri"" msgid ""Managed by…"" msgstr ""Yöneten..."" msgid ""Management"" msgstr ""Yönetim"" msgid ""Management software"" msgstr ""Yönetim yazılımı"" msgid """" ""Management software providing clustering, logging, monitoring, and alerting "" ""details for a cloud environment is often used. This impacts and affects the "" ""overall OpenStack cloud design, and must account for the additional resource "" ""consumption such as CPU, RAM, storage, and network bandwidth."" msgstr """" ""Kümeleme, günlük kaydı, izleme, ve uyarı ayrıntıları sağlayan yönetim "" ""yazılımı bulut ortamında sıklıkla kullanılır. Bu genel OpenStack bulut "" ""tasarımını etkiler, ve CPU, RAM, depolama ve ağ bant genişliği gibi ek "" ""kaynakların tüketimi hesaba katılmalıdır."" msgid """" ""Many deployments use the SQL database; however, LDAP is also a popular "" ""choice for those with existing authentication infrastructure that needs to "" ""be integrated."" msgstr """" ""Çoğu kurulum SQL veritabanı kullanır; ancak, tümleştirilecek mevcut kimlik "" ""doğrulama alt yapısı olanlar arasında LDAP popüler seçimdir."" msgid """" ""Many operators use separate compute and storage hosts instead of a "" ""hyperconverged solution. Compute services and storage services have "" ""different requirements, and compute hosts typically require more CPU and RAM "" ""than storage hosts. Therefore, for a fixed budget, it makes sense to have "" ""different configurations for your compute nodes and your storage nodes. "" ""Compute nodes will be invested in CPU and RAM, and storage nodes will be "" ""invested in block storage."" msgstr """" ""Çoğu işletici bir noktada birleşmiş çözüm yerine ayrı hesaplama ve depolama "" ""sunucuları kullanır. Hesaplama servisleri ve depolama servislerinin farklı "" ""gereksinimleri vardır, ve hesaplama sunucularının depolama sunucularına göre "" ""daha fazla CPU ve RAM ihtiyacı vardır. Yani sabit bir bütçe için hesaplama "" ""ve depolama düğümlerinin farklı yapılandırmaya sahip olması mantıklıdır. "" ""Hesaplama düğümleri için CPU ve RAM'e, depolama düğümleri için blok "" ""depolamaya yatırım yapılır."" msgid """" ""MariaDB server instances store their data on shared enterprise storage, such "" ""as NetApp or Solidfire devices. If a MariaDB instance fails, storage would "" ""be expected to be re-attached to another instance and rejoined to the Galera "" ""cluster."" msgstr """" ""MariaDB sunucuları verilerini paylaşımlı kurumsal depolamada tutuyor, "" ""örneğin NetApp veya Solidfire aygıtlarında. Bir MariaDB sunucusu "" ""arızalanırsa, depolamanın başka bir sunucuya eklenmesi ve Galera kümesine "" ""yeniden katılması beklenir."" msgid """" ""Massively scalable OpenStack clouds require extensive metering and "" ""monitoring functionality to maximize the operational efficiency by keeping "" ""the operator informed about the status and state of the infrastructure. This "" ""includes full scale metering of the hardware and software status. A "" ""corresponding framework of logging and alerting is also required to store "" ""and enable operations to act on the meters provided by the metering and "" ""monitoring solutions. The cloud operator also needs a solution that uses the "" ""data provided by the metering and monitoring solution to provide capacity "" ""planning and capacity trending analysis."" msgstr """" ""Büyük ölçekteki OpenStack bulutları işletmeni alt yapının durumuyla ilgili "" ""bilgilendirerek işlem verimliliğini en üst seviyeye çıkarmak için kapsamlı "" ""ölçme ve izleme işlevleri gerektirir. Bu donanım ve yazılım durumuyla ilgili "" ""tüm aralıklarda ölçüm içerir. Ölçme ve izleme çözümlerinin sağladığı "" ""ölçümleri kaydetmek ve bunlar üzerine hareket etmek için ilgili günlük ve "" ""uyarı çatılar da gereklidir. Bulut işletmeni ölçme ve izleme çözümünün "" ""sağladığı veriyi kullanarak kapasite planlama ve kapasite trend analizi "" ""yapan bir çözüme de ihtiyaç duyar."" msgid ""Massively scale the ecosystem to support millions of end users."" msgstr """" ""Milyonlarca son kullanıcıyı destekleyecek şekilde ekosistemi büyük "" ""ölçekleyin."" msgid ""Maximize flexibility to architect future production environments."" msgstr """" ""İlerdeki üretim ortamlarını imar edebilmek için esnekliği azami seviyeye "" ""çıkarın."" msgid """" ""Maximum Read IOPS: In order to accurately calculate maximum read IOPS for a "" ""disk array, multiply the IOPS for each disk by the maximum read or write "" ""IOPS per disk. maxReadIOPS = nDisks * diskMaxIOPS For example, 15 10K "" ""Spinning Disks would be measured the following way: maxReadIOPS = 15 * 130 "" ""maxReadIOPS = 1950"" msgstr """" ""Azami Okuma IOPS'u: Bir disk dizisi için azami okuma IOPS'unu doğru "" ""hesaplamak için, her bir disk için IOPS'u disk başına azami okuma veya yazma "" ""IOPS'uyla çarpın. maxReadIOPS = nDisks * diskMaxIOPS Örneğin, 15 10K Hızında "" ""Disk şöyle ölçülürdü: maxReadIOPS = 15 * 130 maxReadIOPS = 1950"" msgid ""Maximum write IOPS per array:"" msgstr ""Dizi başına azami yazma IOPS'u:"" msgid ""Memcached (a distributed memory object caching system)"" msgstr ""Memcached (dağıtık hafıza nesne ön bellekleme sistemi)"" msgid ""Message Queue"" msgstr ""İleti Kuyruğu"" msgid ""Message queue services"" msgstr ""İleti kuyruğu servisleri"" msgid """" ""Migrating MACs (instance migration) to different physical locations are a "" ""potential problem if you do not set ARP table timeouts properly."" msgstr """" ""ARP tablosu zaman aşımlarını düzgün ayarlamadıysanız MAC'lerin (sunucu göçü) "" ""farklı fiziksel konumlara göçü sorun teşkil eder."" msgid ""Migration scenarios"" msgstr ""Göç senaryoları"" msgid ""Migration, availability, site loss and recovery"" msgstr ""Göç, kullanılırlık, konum kaybı ve kurtarma"" msgid """" ""Migrations of instances from one node to another are more complicated and "" ""rely on features that may not continue to be developed."" msgstr """" ""Sunucuların bir düğümden diğerine göçü daha karmaşıktır ve devam "" ""ettirilmeyen ya da geliştirilmeyen özelliklere bağlı olabilir."" msgid ""MongoDB has its own design considerations for high availability."" msgstr """" ""MongoDB'nin yüksek kullanılırlık için kendi tasarım kısıtlamaları vardır."" msgid ""MooseFS"" msgstr ""MooseFS"" msgid """" ""More hosts are required to support the anticipated scale if the design "" ""architecture uses dual-socket hardware designs."" msgstr """" ""Tasarım mimarisi çift-soket donanım tasarımlarını kullanırsa beklenen ölçeği "" ""desteklemek için daha fazla sunucu gerekir."" msgid """" ""Most OpenStack components require access to back-end database services to "" ""store state and configuration information. Choose an appropriate back-end "" ""database which satisfies the availability and fault tolerance requirements "" ""of the OpenStack services."" msgstr """" ""Çoğu OpenStack bileşenleri durum ve yapılandırma bilgisini kaydetmek için "" ""arka uç veritabanı servislerine erişim gerektirir. OpenStack servislerinin "" ""kullanılırlık ve arıza payı gereksinimlerini tatmin eden bir arka uç "" ""veritabanı seçin."" msgid """" ""Most OpenStack services communicate with each other using the *message "" ""queue*. For example, Compute communicates to block storage services and "" ""networking services through the message queue. Also, you can optionally "" ""enable notifications for any service. RabbitMQ, Qpid, and Zeromq are all "" ""popular choices for a message-queue service. In general, if the message "" ""queue fails or becomes inaccessible, the cluster grinds to a halt and ends "" ""up in a read-only state, with information stuck at the point where the last "" ""message was sent. Accordingly, we recommend that you cluster the message "" ""queue. Be aware that clustered message queues can be a pain point for many "" ""OpenStack deployments. While RabbitMQ has native clustering support, there "" ""have been reports of issues when running it at a large scale. While other "" ""queuing solutions are available, such as Zeromq and Qpid, Zeromq does not "" ""offer stateful queues. Qpid is the messaging system of choice for Red Hat "" ""and its derivatives. Qpid does not have native clustering capabilities and "" ""requires a supplemental service, such as Pacemaker or Corsync. For your "" ""message queue, you need to determine what level of data loss you are "" ""comfortable with and whether to use an OpenStack project's ability to retry "" ""multiple MQ hosts in the event of a failure, such as using Compute's ability "" ""to do so."" msgstr """" ""Çoğu OpenStack servisi birbirleriyle *ileti kuyruğu* ile haberleşir. Örneğin "" ""Hesaplama blok depolama servisleriyle ve ağ servisleriyle ileti kuyruğu "" ""aracılığıyla haberleşir. Ayrıca isteğe bağlı olarak herhangi bir servis için "" ""ileti kuyruğunu etkinleştirebilirsiniz. RabbitMQ, Qpid ve Zeromq ileti-"" ""kuyruğu servisleri arasında popüler seçimlerdir. Genelde ileti kuyruğu arıza "" ""çıkarırsa ya da erişilemez olursa küme durma noktasına gelir ve salt okunur "" ""durumda kalır, bilgi son iletinin gönderildiği noktada kalır. Bu duruma "" ""uygun olarak ileti kuyruğunuzu kümelemenizi öneriyoruz. Kümelenen ileti "" ""kuyruklarının da OpenStack kurulumlarında sorunlar yaşatabildiğini "" ""unutmayın. RabbitMQ doğal kümeleme desteğine sahip olsa da, büyük ölçekte "" ""çalıştırıldığında çıkan sorunlarla ilgili raporlar var. Zeromq ve Qpid gibi "" ""başka kuyruklama çözümleri olsa da, Zeromy durumsal kuyruk sağlamıyor. Qpid "" ""Red Hat ve türevlerinde kullanılan ileti sistemi seçimi. Qpid de doğal "" ""kümeleme yeteneğine sahip değil ve Pacemaker veya Corosync gibi destekleyen "" ""bir servise ihtiyaç duyuyor. İleti kuyruğunuz için ne kadar veri kaybının "" ""sorun olmayacağına ve OpenStack projesinin arıza durumunda birden çok ileti "" ""kuyruğu sunucusuna tekrar deneme yapabilme yeteneğini, örneğin Hesaplamanın "" ""yeteneğini kullanmak isteyip istemeyeceğinize karar vermeniz gerekiyor."" msgid """" ""Most blade servers can support dual-socket multi-core CPUs. To avoid this "" ""CPU limit, select ``full width`` or ``full height`` blades. Be aware, "" ""however, that this also decreases server density. For example, high density "" ""blade servers such as HP BladeSystem or Dell PowerEdge M1000e support up to "" ""16 servers in only ten rack units. Using half-height blades is twice as "" ""dense as using full-height blades, which results in only eight servers per "" ""ten rack units."" msgstr """" ""Çoğu blade sunucu çift soket çoklu çekirdek işlemcileri destekler. Bu "" ""işlemci sınırlamasından kaçınmak için ``tam geniş`` ya da ``tam yüksek`` "" ""blade'leri seçin. Bunun sunucu yoğunluğunu azalttığını da unutmayın. Örneğin "" ""HP BladeSystem veya Dell PowerEdge M1000e gibi yüksek yoğunluklu blade "" ""sunuclar yalnızca on kabin birimi içinde 16 sunucu desteklerler. Yarım "" ""yükseklikte blade'ler kullanmak tam yüksek blade'lerin iki katı yoğunluk "" ""demektir, bu da on kabin birimine yalnızca sekiz sunucunun sığması demektir."" msgid """" ""Most block storage drivers allow the instance to have direct access to the "" ""underlying storage hardware's block device. This helps increase the overall "" ""read/write IO. However, support for utilizing files as volumes is also well "" ""established, with full support for NFS, GlusterFS and others."" msgstr """" ""Çoğu blok depolama sürücüsü sunucunun altta yatan depolama donanımının blok "" ""aygıtına doğrudan erişime izin verir. Bu genel okuma/yazma IO'sunun "" ""artmasına fayda sağlar. Ancak dosyaların birim gibi kullanılmasının desteği "" ""de, NFS, GlusterFS ve diğerlerine tam destekle verilir."" msgid """" ""Most information starts and ends inside Ethernet frames. Today this applies "" ""to data, voice, and video. The concept is that the network will benefit more "" ""from the advantages of Ethernet if the transfer of information from a source "" ""to a destination is in the form of Ethernet frames."" msgstr """" ""Çoğu bilgi Ethernet çerçevelerinin içinde başlar ve biter. Bugün bu veri, "" ""ses ve video için de geçerlidir. Kavram ağın Ethernet avantajlarından "" ""kaynaktan hedefe bilgi aktarımı Ethernet çerçeveleri biçimindeyse daha iyi "" ""yararlanabileceği üzerine kuruludur."" msgid ""Multiple data centers"" msgstr ""Birden çok veri merkezi"" msgid """" ""Multiple network links should be deployed between sites to provide "" ""redundancy for all components. This includes storage replication, which "" ""should be isolated to a dedicated network or VLAN with the ability to assign "" ""QoS to control the replication traffic or provide priority for this traffic."" msgstr """" ""Tüm bileşenler için yedeklilik sağlamak için konumlar arasında birden çok ağ "" ""bağlantısı kurulmalıdır. Bu depolama çoğaltmayı da kapsar, ki bu çoğaltma "" ""trafiğini kontrol edecek QoS atanmış bir VLAN veya adanmış bir ağ ile "" ""yalıtılmış olmalıdır."" msgid ""Multiple racks"" msgstr ""Birden çok kabin"" msgid """" ""MySQL is the default database for OpenStack, but other compatible databases "" ""are available."" msgstr """" ""MySQL OpenStack için öntanımlı veritabanıdır, ama uyumlu diğer veritabanları "" ""da kullanılabilir."" msgid ""NFS"" msgstr ""NFS"" msgid ""NFS (default for Linux)"" msgstr ""NFS (Linux için öntanımlı)"" msgid ""NTP"" msgstr ""NTP"" msgid ""Network"" msgstr ""Ağ"" msgid ""Network Considerations"" msgstr ""Ağ Etmenleri"" msgid """" ""Network File System (NFS) is a file system protocol that allows a user or "" ""administrator to mount a file system on a server. File clients can access "" ""mounted file systems through Remote Procedure Calls (RPC)."" msgstr """" ""Ağ Dosya Sistemi (NFS) bir kullanıcı veya yöneticinin bir sunucu üzerine "" ""dosya sistemi bağlamasını sağlayan sistem iletişim kuralıdır. Dosya "" ""istemcileri bağlı dosya sistemlerine Uzak Yordam Çağrıları (RPC) "" ""aracılığıyla erişebilirler."" msgid ""Network connectivity"" msgstr ""Ağ bağlantısı"" msgid ""Network design"" msgstr ""Ağ tasarımı"" msgid ""Network functions"" msgstr ""Ağ işlevleri"" msgid """" ""Network functions is a broad category but encompasses workloads that support "" ""the rest of a system's network. These workloads tend to consist of large "" ""amounts of small packets that are very short lived, such as DNS queries or "" ""SNMP traps. These messages need to arrive quickly and do not deal with "" ""packet loss as there can be a very large volume of them. There are a few "" ""extra considerations to take into account for this type of workload and this "" ""can change a configuration all the way to the hypervisor level. For an "" ""application that generates 10 TCP sessions per user with an average "" ""bandwidth of 512 kilobytes per second per flow and expected user count of "" ""ten thousand concurrent users, the expected bandwidth plan is approximately "" ""4.88 gigabits per second."" msgstr """" ""Ağ işlevleri geniş bir kategori ama bir sistemin ağının geri kalanını "" ""destekleyen iş yüklerini kapsar. Bu iş yükleri çok sayıda kısa ömürlü küçük "" ""paketten oluşma eğilimindedir, örneğin DNS sorguları ya da SNMP tuzakları "" ""gibi. Bu iletiler çabukça gelmelidir ve paket kaybıyla ilgilenmezler çünkü "" ""çok sayıdadırlar. Bu tür iş yükü için hesaba katılması gereken bir kaç ek "" ""etmen de bulunur ve bu yapılandırmayı hipervizör seviyesine kadar "" ""değiştirebilir. Kullanıcı başına 10 TCP oturumu üreten, saniyede 512 "" ""kilobayt ortalama bant genişliği olan, aynı anda on bin beklenen kullanıcısı "" ""olan bir uygulama için beklenen bant genişliği planı saniyede 4.88 "" ""gigabittir."" msgid ""Network hardware"" msgstr ""Ağ donanımı"" msgid ""Network hardware requirements"" msgstr ""Ağ donanım gereksinimleri"" msgid """" ""Network level tuning for this workload is minimal. :term:`Quality of Service "" ""(QoS)` applies to these workloads for a middle ground Class Selector "" ""depending on existing policies. It is higher than a best effort queue but "" ""lower than an Expedited Forwarding or Assured Forwarding queue. Since this "" ""type of application generates larger packets with longer-lived connections, "" ""you can optimize bandwidth utilization for long duration TCP. Normal "" ""bandwidth planning applies here with regards to benchmarking a session's "" ""usage multiplied by the expected number of concurrent sessions with overhead."" msgstr """" ""Bu iş yükü için Ağ seviyesi ayarlama asgaridir. :term:`Servis Kalitesi "" ""(QoS)` bu iş yüklerine bir orta nokta Sınıf Seçici için mevcut ilkelere göre "" ""uygulanır. En iyi çaba kuyruğundan daha yüksektir ama Hızlandırılmış "" ""Yönlendirme veya Garantili Yönlendirme kuyruğundan düşüktür. Bu tür bir "" ""uygulama uzun zaman alan bağlantıları olan büyük paketler ürettiğinden, bant "" ""genişliğini uzun süreli TCP ile kullanabilirsiniz. Normal bant genişliği "" ""planlama bir oturumun kullanımını değerlendirme deneyi yaparak beklenen aynı "" ""andaki oturum sayısını abonelik aşımını ekleyip çarparak kullanılabilir."" msgid ""Network misconfigurations"" msgstr ""Ağ bozuk yapılandırmaları"" msgid ""Network redundancy protocols"" msgstr ""Ağ yedeklilik iletişim kuralları"" msgid ""Network software requirements"" msgstr ""Ağ yazılım gereksinimleri"" msgid ""Network tuning"" msgstr ""Ağ ayarlama"" msgid """" ""Network uptime guarantees affecting switch design, which might require "" ""redundant switching and power."" msgstr """" ""Ağ çalışma zamanı anahtar tasarımını etkiler, bu da yedekli anahtarlama ve "" ""güç anlamına gelir."" msgid ""Network virtual function cloud"" msgstr ""Ağ sanal işlev bulutu"" msgid ""Network zones"" msgstr ""Ağ bölgeleri"" msgid ""Network-focused cloud examples"" msgstr ""Ağ vurgulu bulut örnekleri"" msgid ""Network:"" msgstr ""Ağ:"" msgid ""Networking"" msgstr ""Ağ"" msgid """" ""Networking at large scales becomes a set of boundary questions. The "" ""determination of how large a layer-2 domain must be is based on the number "" ""of nodes within the domain and the amount of broadcast traffic that passes "" ""between instances. Breaking layer-2 boundaries may require the "" ""implementation of overlay networks and tunnels. This decision is a balancing "" ""act between the need for a smaller overhead or a need for a smaller domain."" msgstr """" ""Büyük ölçekte ağ düşünüldüğünde bu sınırsal sorulara dönüşür. Bir katman-2 "" ""alanın ne kadar geniş olacağını tanımlamak alandaki düğüm sayısı ve "" ""sunucular arasında geçen yayım trafiğinin miktarına bağlıdır. Katman-2 "" ""sınırların aşılması üst katman ağların veya tünellerin uygulanmasını "" ""gerektirebilir. Seçim daha küçük yük veya daha küçük alan arasında dengeleme "" ""hareketidir."" msgid """" ""Networking at the frame level says nothing about the presence or absence of "" ""IP addresses at the packet level. Almost all ports, links, and devices on a "" ""network of LAN switches still have IP addresses, as do all the source and "" ""destination hosts. There are many reasons for the continued need for IP "" ""addressing. The largest one is the need to manage the network. A device or "" ""link without an IP address is usually invisible to most management "" ""applications. Utilities including remote access for diagnostics, file "" ""transfer of configurations and software, and similar applications cannot run "" ""without IP addresses as well as MAC addresses."" msgstr """" ""Çerçeve seviyesinde bir ağ paket seviyesinde IP adreslerinin varlığı "" ""hakkında hiçbir şey söylemez. LAN anahtarlarından oluşan bir ağdaki "" ""neredeyse tüm bağlantı noktaları, bağlantılar, ve aygıtlar ve tüm kaynak ve "" ""hedef sunucular da IP adreslerine sahiptir. IP adreslemeye olan sürekli "" ""ihtiyaç için bir çok sebep bulunur. En büyüğü ağın yönetimidir. IP adresi "" ""olmayan bir bağlantı veya aygıt genellikle çoğu yönetim uygulaması için "" ""görünmezdir. Sorun giderme için uzaktan erişim araçları, yapılandırma ve "" ""yazılımların dosya transferi, ve benzer uygulamalar IP adresleri ve MAC "" ""adresleri olmadan çalışamazlar."" msgid ""Networking concepts"" msgstr ""Ağ kavramları"" msgid ""Networking resources"" msgstr ""Ağ kaynakları"" msgid ""Networking security policy requirements."" msgstr ""Ağ güvenlik ilkesi gereksinimleri."" msgid ""Networking service (neutron)"" msgstr ""Ağ servisi (neutron)"" msgid ""Next answer the following:"" msgstr ""Ardından şunları yanıtlayın:"" msgid ""No need to keep track of address configuration as systems move around."" msgstr """" ""Sistemler hareket ettiklerinden adres yapılandırmalarını takip etmeye gerek "" ""yok."" msgid ""No predefined usage model"" msgstr ""Ön tanımlı kullanım modeli yok"" msgid ""Non-compute node based shared file system"" msgstr ""Hesaplama dışı düğüm tabanlı paylaşımlı dosya sistemi"" msgid ""Non-standard features"" msgstr ""Standart olmayan özellikler"" msgid """" ""North/South - The flow of traffic between the workload and all external "" ""networks, including clients and remote services. This traffic flow is highly "" ""dependant on the workload within the cloud and the type of network services "" ""being offered."" msgstr """" ""Kuzey/Güney - İş yükü ile tüm harici ağlar arasındaki trafik akışıdır, buna "" ""istemciler ve uzak servisler dahildir. Bu trafik akışı bulut içindeki iş "" ""yükü türüne ve teklif edilen ağ servislerinin türüne bağlıdır."" msgid ""Not yet available"" msgstr ""Henüz kullanılabilir değil"" msgid """" ""Now that you see the myriad designs for controlling your cloud, read more "" ""about the further considerations to help with your design decisions."" msgstr """" ""Bulutunuz yapılandırmak için sayısız tasarım gördüğünüze göre, tasarım "" ""kararlarınızda yardımcı olması için diğer etmenler hakkında okuyun."" msgid ""Number of VLANs is limited to 4096."" msgstr ""VLAN sayısı 4096 ile sınırlıdır."" msgid ""Number of physical cores"" msgstr ""Fiziksel çekirdek sayısı"" msgid ""Number of virtual cores per instance"" msgstr ""Sunucu başına sanal çekirdek sayısı"" msgid ""OR"" msgstr ""VEYA"" msgid ""OS-hypervisor combination"" msgstr ""OS-hipervizör katışımı"" msgid ""Object"" msgstr ""Nesne"" msgid """" ""Object Storage frequent communicates among servers hosting data. Even a "" ""small cluster generates megabytes per second of traffic."" msgstr """" ""Nesne Depolama veri sunan sunucular arasında sıklıkla iletişim kurar. Küçük "" ""bir küme bile saniyede megabaytlarca trafik üretir."" msgid ""Object storage"" msgstr ""Nesne depolama"" msgid """" ""Object storage is implemented in OpenStack by the Object Storage service "" ""(swift). Users access binary objects through a REST API. If your intended "" ""users need to archive or manage large datasets, you should provide them with "" ""Object Storage service. Additional benefits include:"" msgstr """" ""OpenStack'de nesne depolama Nesne Depolama servisi (swift) ile uygulanır. "" ""Kullanıcılar ikilik nesnelere REST API ile erişirler. Kullanıcılarınızın "" ""büyük veri kümeleri arşivlemesi veya yönetmesi gerekecekse onlara Nesne "" ""Depolama servisi sunmalısınız. Ek faydaları şunlardır:"" msgid """" ""Object storage resource nodes have no requirements for hardware fault "" ""tolerance or RAID controllers. It is not necessary to plan for fault "" ""tolerance within the object storage hardware because the object storage "" ""service provides replication between zones as a feature of the service. "" ""Block storage nodes, compute nodes, and cloud controllers should all have "" ""fault tolerance built in at the hardware level by making use of hardware "" ""RAID controllers and varying levels of RAID configuration. The level of RAID "" ""chosen should be consistent with the performance and availability "" ""requirements of the cloud."" msgstr """" ""Nesne depolama kaynak düğümlerinin donanım arızası dayanıklılığına veya RAID "" ""kontrolcülerine ihtiyacı yoktur. Nesne depolama donanımı içinde arıza "" ""dayanıklılığı için plan yapmaya gerek yoktur çünkü nesne depolama servisi "" ""bir servis özelliği olarak bölgeler arası yedekleme sağlar. Blok depolama "" ""düğümleri, hesaplama düğümleri, ve bulut kontrolcüleri çeşitli seviyelerde "" ""RAID yapılandırmaları ve donanım seviyesinde RAID kontrolcüleri kullanarak "" ""arıza dayanıklılığına sahip olmak zorundadırlar. Seçilen RAID seviyesi bulut "" ""gereksinimleriyle başarım ve kullanılırlık açısından uyuşmalıdır."" msgid ""Off compute node storage—shared file system"" msgstr ""Hesaplama dışı düğüm deposu—paylaşımlı dosya sistemi"" msgid """" ""Offers each service's REST API access, where the API endpoint catalog is "" ""managed by the Identity service"" msgstr """" ""Her bir servisin REST API erişimini sunar, API uç nokta kataloğu Kimlik "" ""servisi tarafından yönetilir"" msgid ""On compute node storage—nonshared file system"" msgstr ""Hesaplama düğüm depolama—paylaşımsız dosya sistemi"" msgid ""On compute node storage—shared file system"" msgstr ""Hesaplama düğüm depolama-paylaşımlı dosya sistemi"" msgid """" ""On each host that will house block storage, an administrator must initially "" ""create a volume group dedicated to Block Storage volumes. Blocks are created "" ""from LVM logical volumes."" msgstr """" ""Blok depolamayı barındıracak her sunucuda, bir yönetici ilk önce Blok "" ""Depolama birimlerine adanmış bir birim grubu oluşturmalıdır. Bloklar LVM "" ""mantıksal birimlerinden oluşturulur."" msgid """" ""On the other hand, a scale-out storage solution that uses direct-attached "" ""storage (DAS) in the servers may be an appropriate choice. This requires "" ""configuration of the server hardware to support the storage solution."" msgstr """" ""Diğer yandan, sunucularda doğrudan eklemeli depolama (DAS) kullanan bir dışa "" ""ölçek çözümü uygun seçim olabilir. Bu sunucu donanımının depolama çözümünü "" ""destekleyecek şekilde yapılandırılmasını gerektirir."" msgid ""On-demand and self-service application"" msgstr ""İstek halinde ve kendine servis uygulamalar"" msgid """" ""Once a configuration is complete, Kibana can be used as a visualization tool "" ""for OpenStack and system logging. This will allow operators to configure "" ""custom dashboards for performance, monitoring and security."" msgstr """" ""Yapılandırma tamamlandığında Kibana OpenStack ve sistem kayıtları için "" ""görselleştirme aracı olarak kullanılabilir. Bu işletmenlere başarım, izleme "" ""ve güvenlik için özel kontrol panelleri yapılandırma izni verir."" msgid """" ""One choice that always comes up is whether to virtualize. Some services, "" ""such as ``nova-compute``, ``swift-proxy`` and ``swift-object`` servers, "" ""should not be virtualized. However, control servers can often be happily "" ""virtualized—the performance penalty can usually be offset by simply running "" ""more of the service."" msgstr """" ""Hep akla gelen bir seçenek de sanallaştırmanın yapılıp yapılmayacağıdır. "" ""``nova-compute``, ``swift-proxy`` ve ``swift-object`` sunucuları gibi bazı "" ""servisler sanallaştırılmamalıdır. Ancak kontrol sunucuları rahatlıkla "" ""sanallaştırılabilir—başarım düşüklüğü genellikle servisten birden fazla "" ""çalıştırılarak giderilebilir."" msgid """" ""One of the most important networking topics today is the exhaustion of IPv4 "" ""addresses. As of late 2015, ICANN announced that the final IPv4 address "" ""blocks have been fully assigned. Because of this, IPv6 protocol has become "" ""the future of network focused applications. IPv6 increases the address space "" ""significantly, fixes long standing issues in the IPv4 protocol, and will "" ""become essential for network focused applications in the future."" msgstr """" ""Bugünlerde ağ başlıklarından en önemlisi IPv4 adreslerinin bitiyor oluşu. "" ""2015 sonuna doğru, ICANN son IPv4 adres bloklarının da atandığını açıkladı. "" ""Bu sebeple, ağ odaklı uygulamalar için gelecek IPv6 iletişim kuralı. IPv6 "" ""iletişim kuralı adres uzayını kat kat artırır, IPv4 ile uzun zamandır var "" ""olan sorunları düzeltir, ve gelecekte ağ odaklı uygulamalar için gerekli "" ""olacaktır."" msgid """" ""One potential solution to this problem is the implementation of storage "" ""systems designed for performance. Parallel file systems have previously "" ""filled this need in the HPC space and are suitable for large scale "" ""performance-orientated systems."" msgstr """" ""Bu probleme muhtemel bir çözüm başarım için tasarlanmış depolama "" ""sistemlerinin uygulanmasıdır. Paralel dosya sistemleri daha önceleri bu "" ""ihtiyacı HPC alanında doldurdu ve büyük ölçekli başarım eksenli sistemler "" ""için uygundur."" msgid ""One zone per node"" msgstr ""Düğüm başına bir bölge"" msgid """" ""Ongoing maintenance operations are made much simpler if there is logical and "" ""physical separation of Data Plane and Control Plane systems. It then becomes "" ""possible to, for example, reboot a controller without affecting customers. "" ""If one service failure affects the operation of an entire server (``noisy "" ""neighbor``), the separation between Control and Data Planes enables rapid "" ""maintenance with a limited effect on customer operations."" msgstr """" ""Veri Düzlemi ve Kontrol Düzlemi sistemleri arasında mantıksal ve fiziksel "" ""ayrım varsa devam eden bakım işlemleri çok daha basit olur. Ardından örneğin "" ""bir kontrol birimini müşterileri etkilemeden yeniden başlatmak mümkün olur. "" ""Bir servisin bozulması tüm sunucunun işlemini etkilerse (``gürültülü "" ""komşu``), Kontrol ve Veri Düzlemlerinin ayrı olması müşteri işlemleri "" ""üstünden sınırlı bir etki ile hızlıca bakım yapılmasını sağlar."" msgid ""OpenStack Architecture Design Guide"" msgstr ""OpenStack Mimari Tasarım Kılavuzu"" msgid ""OpenStack Block Storage (cinder)"" msgstr ""OpenStack Blok Depolama (cinder)"" msgid """" ""OpenStack Block Storage for use by compute instances, requiring persistent "" ""storage (such as databases for dynamic sites)."" msgstr """" ""Hesaplama sunucuları tarafından kullanılmak üzere kalıcı depolama gerektiren "" ""(dinamik siteler için veritabanları gibi) OpenStack Blok Depolama."" msgid ""OpenStack Compute (nova)"" msgstr ""OpenStack Hesaplama (nova)"" msgid ""OpenStack Compute running KVM hypervisor"" msgstr ""KVM hipervizörünü çalıştıran OpenStack Hesaplama"" msgid """" ""OpenStack Compute uses an SQL database to store and retrieve stateful "" ""information. MySQL is the popular database choice in the OpenStack community."" msgstr """" ""OpenStack Hesaplama durum bilgisini kaydetmek ve almak için bir SQL "" ""veritabanı kullanır. OpenStack topluluğu araında popüler seçim MySQL'dir."" msgid """" ""OpenStack Controller service running Image service, Identity service, "" ""Networking service, combined with support services such as MariaDB and "" ""RabbitMQ, configured for high availability on at least three controller "" ""nodes."" msgstr """" ""En az üç kontrol düğümünde yüksek kullanılırlık için yapılandırılmış, "" ""MariaDB ve RabbitMQ gibi destek servisleri ile İmaj servisi, Kimlik servisi, "" ""Ağ servisi karışımını çalıştıran OpenStack Kontrol servisi."" msgid """" ""OpenStack Controller services (Image service, Identity service, Networking "" ""service, and supporting services such as MariaDB and RabbitMQ)"" msgstr """" ""OpenStack Kontrol sevisleri (İmaj servisi, Kimlik servisi, Ağ servisi, ve "" ""MariaDB ve RabbitMQ gibi destekleyen servisler)"" msgid """" ""OpenStack Identity provides authentication decisions and user attribute "" ""information, which is then used by the other OpenStack services to perform "" ""authorization. The policy is set in the ``policy.json`` file. For "" ""information on how to configure these, see `Managing Projects and Users "" ""<https://docs.openstack.org/ops-guide/ops-projects-users.html>`_ in the "" ""OpenStack Operations Guide."" msgstr """" ""OpenStack Kimlik kimlik doğrulama kararlarını ve kullanıcı özniteliği "" ""bilgisini sağlar, bu da diğer OpenStack servislerinin yetkilendirme "" ""yapmasında kullanılır. İlke ``policy.json`` dosyasında ayarlanır. Bunların "" ""nasıl yapılandırılacağıyla ilgili daha fazla bilgi için OpenStack İşlem "" ""Kılavuzundaki `Proje ve Kullanıcı Yönetimine <https://docs.openstack.org/ops-"" ""guide/ops-projects-users.html>`_ göz atın."" msgid """" ""OpenStack Identity supports different plug-ins for authentication decisions "" ""and identity storage. Examples of these plug-ins include:"" msgstr """" ""OpenStack Kimlik kimlik doğrulama kararları ve kimlik depolama için farklı "" ""eklentileri destekler. Bu eklentilere örnek verecek olursak:"" msgid ""OpenStack Logical Architecture"" msgstr ""OpenStack Mantıksal Mimarisi"" msgid """" ""OpenStack Networking (neutron) is the component of OpenStack that provides "" ""the Networking service API and a reference architecture that implements a "" ""Software Defined Network (SDN) solution."" msgstr """" ""OpenStack Ağı (neutron) Ağ servisi API'si ve bir Yazılımla Tanımlanmış Ağ "" ""(SDN) çözümü uygulayan mimariye başvurudan oluşan OpenStack bileşenidir. "" msgid """" ""OpenStack Networking (neutron) provides a wide variety of networking "" ""services for instances. There are many additional networking software "" ""packages that can be useful when managing OpenStack components. Some "" ""examples include:"" msgstr """" ""OpenStack Ağı (neutron) sunucular için geniş çeşitlilikte ağ servisleri "" ""sunar. OpenStack bileşenlerini yönetirken kullanışlı olabilecek bir çok ek "" ""ağ yazılım paketi bulunur. Bazı örnekler:"" msgid """" ""OpenStack Networking can be used to control hardware load balancers through "" ""the use of plug-ins and the Networking API. This allows users to control "" ""hardware load balance pools and instances as members in these pools, but "" ""their use in production environments must be carefully weighed against "" ""current stability."" msgstr """" ""OpenStack Ağı eklentiler ve Ağ API'si kullanılarak donanımsal yük "" ""dengeleyicileri kontrol etmek için kullanılabilir. Bu kullanıcılara "" ""donanımsal yük dengeleyici havuzlarını ve bu havuzların üyleri olan "" ""sunucuları kontrol etme olasılığı sağlar, ama üretim ortamlarında "" ""kullanımları mevcut kararlılığa göre değerlendirilmelidir."" msgid """" ""OpenStack Networking, when configured for it, supports IPv6. To enable IPv6, "" ""create an IPv6 subnet in Networking and use IPv6 prefixes when creating "" ""security groups."" msgstr """" ""OpenStack Ağı, yapılandırıldığında IPv6 destekler. IPv6'yı etkinleştirmek "" ""için, Ağ kısmında bir IPv6 alt ağı oluşturun ve güvenlik grupları "" ""oluştururken IPv6 ön ekleri kullanın."" msgid ""OpenStack Object Storage"" msgstr ""OpenStack Nesne Depolama"" msgid ""OpenStack Object Storage (swift)"" msgstr ""OpenStack Nesne Depolama (swift)"" msgid ""OpenStack Object Storage for serving static objects (such as images)."" msgstr ""Statik nesneleri sunmak için OpenStack Nesne Depolama (imajlar gibi)."" msgid ""OpenStack Shared File System Storage (manila)"" msgstr ""OpenStack Paylaşımlı Dosya Sistemi Depolama (manila)"" msgid """" ""OpenStack allows you to overcommit CPU and RAM on compute nodes. This allows "" ""you to increase the number of instances running on your cloud at the cost of "" ""reducing the performance of the instances. The Compute service uses the "" ""following ratios by default:"" msgstr """" ""OpenStack hesaplama düğümlerinde CPU ve RAM için abonelik aşımına izin "" ""verir. Bu da sunucuların başarımını düşürmek pahasına bulutunuzda çalışan "" ""sunucu sayısını artırmanızı sağlar. Hesaplama servisi öntanımlı olarak şu "" ""oranları kullanır:"" msgid """" ""OpenStack can store your virtual machine (VM) images inside of an Object "" ""Storage system, as an alternative to storing the images on a file system."" msgstr """" ""İmajlarınızı bir dosya sisteminde saklamak yerine OpenStack sanal makine "" ""(VM) imajlarınızı Nesne Depolama sistemi içinde saklar."" msgid """" ""OpenStack clouds do not present file-level storage to end users. However, it "" ""is important to consider file-level storage for storing instances under ``/"" ""var/lib/nova/instances`` when designing your cloud, since you must have a "" ""shared file system if you want to support live migration."" msgstr """" ""OpenStack bulutlar kullanıcılara dosya seviyesinde depolama sunmazlar. "" ""Ancak, bulutunuzu tasarlarken canlı göçü desteklemek istiyorsanız paylaşımlı "" ""dosya sisteminiz olması gerektiğinden ``/var/lib/nova/instances`` altında "" ""sunucularınız saklamak için dosya seviyesinde depolamayı göz önünde "" ""bulundurun."" msgid """" ""OpenStack clouds explicitly support three types of persistent storage: "" ""*Object Storage*, *Block Storage*, and *File-based storage*."" msgstr """" ""OpenStack bulutları üç tür kalıcı depolamayı açıkça destekler: *Nesne "" ""Depolama*, *Blok Depolama*, ve *Dosya tabanlı depolama*."" msgid """" ""OpenStack clouds require appropriate monitoring platforms to identify and "" ""manage errors."" msgstr """" ""OpenStack bulutları hataları tanımlamak ve yönetmek için uygun izleme "" ""platformları gerektirir."" msgid ""OpenStack compute nodes running the KVM hypervisor."" msgstr ""KVM hipervizörünü çalıştıran OpenStack hesaplama düğümleri."" msgid """" ""OpenStack design, generally, does not include shared storage. However, for "" ""some high availability designs, certain components might require it "" ""depending on the specific implementation."" msgstr """" ""OpenStack tasarımı genel olarak paylaşımlı depolama içermez. Ancak, bazı "" ""yüksek kullanılırlık tasarımları için bazı bileşenlerin duruma özel "" ""uygulamalar üzere ihtiyacı olabilir."" msgid """" ""OpenStack does not currently provide DNS services, aside from the dnsmasq "" ""daemon, which resides on ``nova-network`` hosts. You could consider "" ""providing a dynamic DNS service to allow instances to update a DNS entry "" ""with new IP addresses. You can also consider making a generic forward and "" ""reverse DNS mapping for instances' IP addresses, such as ``vm-203-0-113-123."" ""example.com.``"" msgstr """" ""OpenStack ``nova-network`` sunucularında barınan dnsmasq artalan işi dışında "" ""şu an DNS servisleri sağlamıyor. Sunucuların yeni IP adresleriyle DNS "" ""girdilerini güncellemesini sağlamak için dinamik DNS servisi sağlamayı "" ""düşünebilirsiniz. Ayrıca sunucuların IP adresleri için genel bir ileri ve "" ""geri DNS eşleştirmesi yapmak isteyebilrisiniz, örneğin ``vm-203-0-113-123."" ""ornek.com.``"" msgid """" ""OpenStack has integration with Hadoop to manage the Hadoop cluster within "" ""the cloud. The following diagram shows an OpenStack store with a high "" ""performance requirement:"" msgstr """" ""OpenStack Hadoop kümesini bulutta yönetmeyi sağlamak için Hadoop "" ""tümleştirmesine sahiptir. Aşağıdaki çizim yüksek başarım gereksinimli bir "" ""OpenStack deposunu gösterir:"" msgid """" ""OpenStack input, output and filter examples can be found at https://github."" ""com/sorantis/elkstack/tree/master/elk/logstash."" msgstr """" ""OpenStack girdi, çıktı ve süzme örnekleri https://github.com/sorantis/"" ""elkstack/tree/master/elk/logstash adresinde bulunabilir."" msgid """" ""OpenStack is designed to be massively horizontally scalable, which allows "" ""all services to be distributed widely. However, to simplify this guide, we "" ""have decided to discuss services of a more central nature, using the concept "" ""of a *cloud controller*. A cloud controller is a conceptual simplification. "" ""In the real world, you design an architecture for your cloud controller that "" ""enables high availability so that if any node fails, another can take over "" ""the required tasks. In reality, cloud controller tasks are spread out across "" ""more than a single node."" msgstr """" ""OpenStack ağırlıklı olarak yatay ölçeklenmek için tasarlanmıştır, bu da tüm "" ""servislerin genişçe dağıtılmasına izin verir. Ancak bu kılavuzu "" ""basitleştirmek için bir *bulut kontrol birimi* kavramını kullanarak daha "" ""merkezi doğada olan servisleri tartışmaya karar verdik. Bulut kontrol birimi "" ""kavramsal bir basitleştirmedir. Gerçek dünyada bulut kontrol biriminiz için "" ""yüksek kullanılırlık sağlayan, herhangi bir düğüm arızalandığında gerekli "" ""görevleri bir diğerinin devam ettirebildiği bir mimari tasarlarsınız. "" ""Gerçekte bulut kontrol birimi görevleri tek bir düğümden fazlasına "" ""yayılmıştır."" msgid """" ""OpenStack lends itself to deployment in a highly available manner where it "" ""is expected that at least 2 servers be utilized. These can run all the "" ""services involved from the message queuing service, for example ``RabbitMQ`` "" ""or ``QPID``, and an appropriately deployed database service such as "" ""``MySQL`` or ``MariaDB``. As services in the cloud are scaled out, back-end "" ""services will need to scale too. Monitoring and reporting on server "" ""utilization and response times, as well as load testing your systems, will "" ""help determine scale out decisions."" msgstr """" ""OpenStack en az 2 sunucunun kullanılacağı yüksek kullanılırlık kurulumlarına "" ""katar. Bunlar ihtiyaç olan tüm servisleri çalıştırabilirler, örneğin "" ""``RabbitMQ`` veya ``QPID`` gibi mesaj kuyruğu servisleri, ve uygun kurulmuş "" ""``MySQL`` veya ``MariaDB`` gibi veritabanı servisi. Buluttaki servisler "" ""ölçeklenebildiğinden, arka uç servislerin de ölçeklenmesi gerekir. Sunucu "" ""kullanımını ve yanıt sürelerini izleme ve raporlama, aynı zamanda "" ""sisteminize yük testi yapmak, ölçekleme kararlarının alınmasında yardımcı "" ""olur."" msgid """" ""OpenStack produces a great deal of useful logging information, but for the "" ""information to be useful for operations purposes, you should consider having "" ""a central logging server to send logs to, and a log parsing/analysis system "" ""such as Elastic Stack [formerly known as ELK]."" msgstr """" ""OpenStack yüksek miktarda faydalı günlük kaydı bilgisi üretir, ama bilginin "" ""işlevsel amaçlı faydalı olabilmesi için kayıtların gönderilebileceği merkezi "" ""bir günlük sunucusu ve Elastic Stack [eski ELK] gibi bir günlük işleme/"" ""analiz sistemine ihtiyacınız vardır."" msgid """" ""OpenStack provides a rich networking environment. This chapter details the "" ""requirements and options to consider when designing your cloud. This "" ""includes examples of network implementations to consider, information about "" ""some OpenStack network layouts and networking services that are essential "" ""for stable operation."" msgstr """" ""OpenStack zengin bir ağ ortamı sunar. Bu bölüm bulutunuzu tasarlarken göz "" ""önüne almanız gereken gereksinim ve seçenekleri gösterir. Bu göz önüne "" ""alınacak ağ uygulaması örneklerini, bazı OpenStack ağ yerleşimleri hakkında "" ""bilgi ve kararlı bir işletme için gerekli ağ servislerini içerir."" msgid """" ""OpenStack, like any network application, has a number of standard services "" ""to consider, such as NTP and DNS."" msgstr """" ""OpenStack, herhangi bir ağ uygulaması gibi, dikkate alması gereken standart "" ""servislere sahiptir, NTP ve DNS gibi."" msgid """" ""Operating system patching, hardware/firmware upgrades, and datacenter "" ""related changes, as well as minor and release upgrades to OpenStack "" ""components are all ongoing operational tasks. The six monthly release cycle "" ""of the OpenStack projects needs to be considered as part of the cost of "" ""ongoing maintenance. The solution should take into account storage and "" ""network maintenance and the impact on underlying workloads."" msgstr """" ""İşletim sistemi yamalama, donanım/üretici yazılımı güncellemeleri, ve veri "" ""merkeziyle ilgili değişiklikler, ayrıca OpenStack bileşenlerine yapılan "" ""küçük ve dağıtım yükseltmeleri hep süreklilik arz eden işlevsel görevlerdir. "" ""OpenStack projelerinin altı aylık dağıtım döngüsü bakım masraflarının "" ""parçası olarak ele alınmalıdır. Çözüm depolama ve ağ bakımını ve altta yatan "" ""iş yüklerine etkiyi göz önüne almalıdır."" msgid ""Operational costs"" msgstr ""İşlem maliyetleri"" msgid ""Operational requirements"" msgstr ""İşlevsel gereksinimler"" msgid ""Operator access to systems"" msgstr ""Sistemlere işletmen erişimi"" msgid ""Operator requirements"" msgstr ""İşletmen gereksinimleri"" msgid ""Optimizing network performance"" msgstr ""Ağ başarımının iyileştirilmesi"" msgid """" ""Orchestration requires special client configurations to integrate with "" ""Amazon Web Services. For other types of clouds, use CMP features."" msgstr """" ""Orkestrasyon Amazon Web Servisleriyle tümleşme için özel istemci "" ""yapılandırması gerektirir. Diğer tür bulutlar için, CMP özelliklerini "" ""kullanın."" msgid ""Orchestration service"" msgstr ""Orkestrasyon servisi"" msgid """" ""Organizations leveraging cloud-based services can embrace business diversity "" ""and utilize a hybrid cloud design to spread their workloads across multiple "" ""cloud providers. This ensures that no single cloud provider is the sole host "" ""for an application."" msgstr """" ""Bulut tabanlı servislerden güç alan kurumlar iş çeşitliliği ihtiva edebilir "" ""ve iş yüklerini farklı bulut sağlayıcılar arasında dağıtaran melez bulut "" ""tasarımını kullanabilirler. Bu da uygulamayı tek bir bulut sağlayıcının "" ""sunmamasını sağlar."" msgid """" ""Organizations must find the right balance between data integrity and data "" ""availability. Replication strategy may also influence disaster recovery "" ""methods."" msgstr """" ""Kurumlar veri tutarlılığıyla veri kullanılırlığı arasındaki doğru dengeyi "" ""bulmalıdırlar. Çoğaltma stratejisi afet anında kurtarma yöntemlerini de "" ""etkileyebilir."" msgid """" ""Outages can cause partial or full loss of site functionality. Strategies "" ""should be implemented to understand and plan for recovery scenarios."" msgstr """" ""Kesintiler konum işlevselliğini kısmen ya da tamamen kaybettirebilir. "" ""Kurtarma senaryolarının anlaşılması ve uygulanması için stratejiler "" ""uygulanmalıdır."" msgid ""Overcommitting CPU and RAM"" msgstr ""CPU ve RAM'in abonelik aşımı"" msgid ""Overlay"" msgstr ""Üst Katman"" msgid ""Overlay networks"" msgstr ""Üst katman ağlar"" msgid """" ""Oversubscription is a method to emulate more capacity than may physically be "" ""present. For example, a physical hypervisor node with 32 GB RAM may host 24 "" ""instances, each provisioned with 2 GB RAM. As long as all 24 instances do "" ""not concurrently use 2 full gigabytes, this arrangement works well. However, "" ""some hosts take oversubscription to extremes and, as a result, performance "" ""can be inconsistent. If at all possible, determine what the oversubscription "" ""rates of each host are and plan capacity accordingly."" msgstr """" ""Abonelik aşım fiziksel olarak var olan kapasiteden daha fazlası varmış gibi "" ""yapma yöntemidir. Örneğin, 32 GB RAM'e sahip fiziksel hipervizör düğümü her "" ""birinde 2 GB RAM olan 24 sunucu barındırıyor olabilir. Tüm 24 sunucu 2 "" ""gigabaytın tamamını kullanmadığı sürece, bu ayarlama düzgün çalışacaktır. "" ""Ancak, bazı sunucular abonelik aşımlarını uç noktalara taşırlar, ve sonuç "" ""olarak başarım tutarlı olmayabilir. Eğer mümkünse her sunucunun abonelik "" ""aşım oranlarının ne olduğunu öğrenin ve kapasiteyi buna uygun planlayın."" msgid ""PC"" msgstr ""PC"" msgid ""Parameter in ``nova.conf``"" msgstr ""``nova.conf`` dosyasındaki parametre"" msgid ""Penalty"" msgstr ""Kayıp"" msgid ""Performance"" msgstr ""Başarım"" msgid """" ""Performance is a critical consideration when designing any cloud, and "" ""becomes increasingly important as size and complexity grow. While single-"" ""site, private clouds can be closely controlled, multi-site and hybrid "" ""deployments require more careful planning to reduce problems such as network "" ""latency between sites."" msgstr """" ""Başarım herhangi bir bulut tasarımında büyük öneme sahiptir, ve boyut ve "" ""karmaşıklık büyüdükçe önemi gittikçe artar. Tek konumda, özel bulutlar "" ""yakından kontrol edilebilirken, farklı bölgelerdeki melez kurulumlar "" ""bölgeler arasındaki ağ gecikmesi gibi problemleri azaltmak için çok daha "" ""dikkatli planlanmalıdırlar."" msgid """" ""Performance of block based storage is typically measured in the maximum read "" ""and write operations to non-contiguous storage locations per second. This "" ""measurement typically applies to SAN, hard drives, and solid state drives. "" ""While IOPS can be broadly measured and is not an official benchmark, many "" ""vectors like to be used by vendors to communicate performance levels. Since "" ""there are no real standards for measuring IOPS, vendor test results may "" ""vary, sometimes wildly. However, along with transfer rate which measures the "" ""speed that data can be transferred to contiguous storage locations, IOPS can "" ""be used in a performance evaluation. Typically, transfer rate is represented "" ""by a bytes per second calculation but IOPS is measured by an integer."" msgstr """" ""Blok tabanlı depolamanın başarımı genellikle bitişik olmayan depolama "" ""konumlarına saniyede yapılan okuma ve yazma sınırlarıyla ölçülür. Bu ölçüm "" ""genellikle SAN, hard diskler, ve ssd'lere uygulanır. IOPS ölçmek için bir "" ""çok yöntem olsa da ve resmi bir ölçüm olmasa da, çoğur üretici başarım "" ""seviyesini belirtmek için kullanır. IOPS ölçmek için gerçek standartlar "" ""olmadığından, üretici deneme sonuçları bazen yüksek farklılıklar "" ""gösterebilir. Ancak verinin sıralı depolama konumlarına aktarım hızını ölçen "" ""aktarım oranının yanı sıra, IOPS da başarım değerlendirmede kullanılabilir. "" ""Genel olarak, aktarım oranı saniyede bayt şeklinde sunulurken IOPS bir "" ""tamsayıdır."" msgid ""Performance tuning"" msgstr ""Başarım ayarları"" msgid ""Persistent file-based storage support"" msgstr ""Kalıcı dosya tabanlı depolama desteği"" msgid """" ""Persistent storage - Persistent storage means that the storage resource "" ""outlives any other resource and is always available, regardless of the state "" ""of a running instance."" msgstr """" ""Kalıcı depolama - Kalıcı depolama depolama kaynağının herhangi bir diğer "" ""kaynaktan kalıcı olduğu ve her zaman kullanılabilir olduğu anlamına gelir, "" ""çalışan sunucunun durumundan bağımsızdır."" msgid ""Persists until…"" msgstr ""Kalıcılık süresi..."" msgid ""Physical constraints such as power, rack space, network cabling, etc."" msgstr ""Güç, kabin alanı, ağ kabloları gibi fiziksel kısıtlamalar."" msgid """" ""Physical data centers have limited physical space, power, and cooling. The "" ""number of hosts (or hypervisors) that can be fitted into a given metric "" ""(rack, rack unit, or floor tile) is another important method of sizing. "" ""Floor weight is an often overlooked consideration."" msgstr """" ""Fiziksel veri merkezlerinin sınırlı fiziksel alanı, gücü ve soğutması "" ""vardır. Verilen bir ölçüte (kabin, kabin birimi, döşeme) sığabilecek sunucu "" ""(veya hipervizör) sayısı boyutlandırma için bir diğer önemli yöntemdir. "" ""Zemin ağırlığı genellikle göz önüne alınmayan bir etmendir."" msgid ""Planning and scaling storage capacity"" msgstr ""Depolama kapasitesinin planlanması ve ölçeklenmesi"" msgid ""Port count"" msgstr ""Bağlantı noktası sayısı"" msgid ""Port density"" msgstr ""Bağlantı noktası yoğunluğu"" msgid ""Port speed"" msgstr ""Bağlantı noktası hızı"" msgid ""Possible options include:"" msgstr ""Muhtemel seçenekler:"" msgid ""Power and cooling density"" msgstr ""Güç ve soğutma yoğunluğu"" msgid ""Power requirements"" msgstr ""Güç gereksinimleri"" msgid ""Prior knowledge of cloud architecture and principles."" msgstr ""Bulut mimarisi ve ilkeleri hakkında ön bilgi."" msgid ""Protocol support"" msgstr ""İletişim kuralı desteği"" msgid ""Provider API changes"" msgstr ""Sağlayıcı API değişiklikleri"" msgid ""Provider availability or implementation details"" msgstr ""Sağlayıcı kullanılırlığı veya uygulama ayrıntıları"" msgid """" ""Provides a web-based front end for users to consume OpenStack cloud services"" msgstr """" ""Kullanıcıları OpenStack bulut servislerini tüketebilecekleri web tabanlı ön "" ""yüz sağlar"" msgid ""Providing IPv6 support"" msgstr ""IPv6 desteği sağlamak"" msgid ""Proxy requests to a database"" msgstr ""Veritabanına istekleri vekilden geçir"" msgid ""Proxy:"" msgstr ""Vekil:"" msgid """" ""Public, private, or a hybrid cloud (performance profiles, shared storage, "" ""replication options)"" msgstr """" ""Açık, özel, ya da melez bulut (başarım profilleri, paylaşımlı depolama, "" ""çoğaltma seçenekleri)"" msgid """" ""QoS is desirable for some workloads to ensure delivery. DNS has a major "" ""impact on the load times of other services and needs to be reliable and "" ""provide rapid responses. Configure rules in upstream devices to apply a "" ""higher Class Selector to DNS to ensure faster delivery or a better spot in "" ""queuing algorithms."" msgstr """" ""QoS bazı iş yüklerinde teslimattan emin olmak için gereklidir. DNS'in diğer "" ""servislerin yüklenme zamanı üzerinde büyük önemi bulunur ve güvenilir ve "" ""hızlı yanıt verebilir olması gerekir. Üst akış aygıtlarında DNS için daha "" ""yüksek Sınıf Seçici kuralları yapılandırarak veya kuyruklama "" ""algoritmalarında daha iyi bir yer vererek hızlı aktarım sağlayın."" msgid ""RAM allocation ratio: 1.5:1"" msgstr ""RAM ayırma oranı: 1.5:1"" msgid ""REST proxy:"" msgstr ""REST vekili:"" msgid """" ""Raid 5 has the worst penalty (has the most cross disk writes.) Therefore, "" ""when using the above examples, a 15 disk array using RAID 5 is capable of "" ""1950 read IOPS however, we need to add the penalty when determining the "" ""*write* IOPS:"" msgstr """" ""Raid 5 en büyük kayba sahiptir (diskler arası en çok yazmaya sahip) Bu "" ""yüzden, yukarıdaki örnekleri kullanırken, RAID 5 kullanan 15 diskli bir dizi "" ""1950 okuma IOPS'una sahipken, *yazma* IOPS'una karar verirken kaybı "" ""eklemeliyiz."" msgid ""Raid Type"" msgstr ""Raid Türü"" msgid ""Ramification"" msgstr ""Dallanma"" msgid ""Recovery of instances is complicated by depending on multiple hosts."" msgstr """" ""Sunucuların kurtarılması birden çok sunucuya bağımlılık yüzünden karmaşıktır."" msgid ""Reduced overhead of the IP hierarchy."" msgstr ""IP sıra düzeni giderinin azalması."" msgid ""Redundancy"" msgstr ""Yedeklilik"" msgid ""Redundant networking"" msgstr ""Yedekli ağ"" msgid """" ""Regardless of the overcommit ratio, an instance can not be placed on any "" ""physical node with fewer raw (pre-overcommit) resources than the instance "" ""flavor requires."" msgstr """" ""Abonelik aşım oranından bağımsız olarak, bir sunucu fiziksel bir düğüme "" ""sunucu niteliğinin gerektirdiğinden az ham (abonelik aşım öncesi) kaynak "" ""varsa konulamaz."" msgid ""Reliability and availability"" msgstr ""Güvenilirlik ve kullanılırlık"" msgid """" ""Reliability and availability depend on the many supporting components' "" ""availability and on the level of precautions taken by the service provider. "" ""This includes network, storage systems, datacenter, and operating systems."" msgstr """" ""Güvenilirlik ve kullanılırlık bir çok destekleyen bileşenin "" ""kullanılabilirliğine ve servis sağlayıcı tarafından alınan önlemlerin "" ""seviyesine bağlıdır. Bu ağ, depolama sistemler, veri merkezi ve işletim "" ""sistemlerini içerir."" msgid ""Remove shares."" msgstr ""Paylaşımları kaldır."" msgid """" ""Replicas in Object Storage function independently, and clients only require "" ""a majority of nodes to respond to a request in order for an operation to be "" ""considered successful. Thus, transient failures like network partitions can "" ""quickly cause replicas to diverge. Fix These differences are eventually "" ""reconciled by asynchronous, peer-to-peer replicator processes. The "" ""replicator processes traverse their local filesystems, concurrently "" ""performing operations in a manner that balances load across physical disks."" msgstr """" ""Nesne Depolamadaki yedekler bağımsız işlerler, ve bir işlemin başarılı "" ""olarak sayılması için istemcilerin yalnızca düğümlerin büyük çoğunluğunun "" ""bir isteğe yanıt vermesine ihtiyaçları vardır. Böylece ağ bölümleri gibi "" ""geçici arızalar yedeklerin hızlıca sapmasına sebep olabilir. Bu farklılıklar "" ""bir noktada asenkron, eşten-eşe çoğaltma süreçleri ile yeniden "" ""buluşturulurlar. Çoğaltma süreçleri yükü fiziksel disklere dengeleyecek "" ""şekilde eşzamanlı olarak işleyerek yerel dosya sistemlerinin üstünden "" ""geçerler."" msgid ""Replicating inter-site data"" msgstr ""Konum arası verinin çoğaltılması"" msgid ""Replication"" msgstr ""Çoğaltma"" msgid """" ""Replication across different racks, data centers, and geographical regions "" ""increases focus on determining and ensuring data locality. The ability to "" ""guarantee data is accessed from the nearest or fastest storage can be "" ""necessary for applications to perform well."" msgstr """" ""Farklı kabinler, veri merkezleri, ve coğrafi bölgeler arasında çoğaltma "" ""dikkati veri yerelliğinden emin olma noktasında artırır. Veriye en yakın "" ""veya en hızlı depolamadan erişebilme garantisi uygulamaların iyi çalışması "" ""için zorunlu olabilir."" msgid """" ""Replication is an area of active development, andimplementation details are "" ""likely to change over time."" msgstr """" ""Çoğaltma etkin geliştirme alanındadır, ve uygulama ayrıntıları zamanla "" ""değişmeye müsaittir."" msgid """" ""Replication uses a push model, with records and files generally only being "" ""copied from local to remote replicas. This is important because data on the "" ""node may not belong there (as in the case of handoffs and ring changes), and "" ""a replicator can not know what data exists elsewhere in the cluster that it "" ""should pull in. It is the duty of any node that contains data to ensure that "" ""data gets to where it belongs. Replica placement is handled by the ring."" msgstr """" ""Çoğaltma, itiş modeli kullanır, kayıtlar ve dosyalar genellikle yalnızca "" ""yerelden uzak yedeklere kopyalanır. Bu önemlidir çünkü düğümdeki veri oraya "" ""ait olmayabilir (transfer ve halka değişikliklerinde olduğu gibi) ve "" ""çoğaltıcı kümede başka yerde çekebileceği hangi verinin olduğunu bilemez. "" ""Verinin ait olduğu yere gitmesinden veriyi içeren düğüm sorumludur."" msgid ""Requests for extension"" msgstr ""Eklenti için istekler"" msgid ""Requirements"" msgstr ""Gereksinimler"" msgid """" ""Research indicates the mean time between failures (MTBF) on switches is "" ""between 100,000 and 200,000 hours. This number is dependent on the ambient "" ""temperature of the switch in the data center. When properly cooled and "" ""maintained, this translates to between 11 and 22 years before failure. Even "" ""in the worst case of poor ventilation and high ambient temperatures in the "" ""data center, the MTBF is still 2-3 years."" msgstr """" ""Araştırmaya göre anahtarlar arasında arıza aralığı (MTBF) 100,000 ile "" ""200,000 saat arasında. Bu rakam veri merkezindeki anahtarın çevre "" ""sıcaklığına bağımlı. Düzgün soğutulup bakımı yapıldığında, bu rakam arızadan "" ""önce 11 ve 22 yıl arasına denk gelir. En kötü durumda havalandırmanın "" ""olmadığı ve ortam sıcaklığının yüksek olduğu bir veri merkezinde bile, bu "" ""değer 2-3 senedir."" msgid ""Resource capacity"" msgstr ""Kaynak kapasitesi"" msgid ""Response time to the Compute API"" msgstr ""Hesaplama API'sine yanıt verme zamanı"" msgid """" ""Revenue opportunities vary based on the intent and use case of the cloud. "" ""The requirements of a commercial, customer-facing product are often very "" ""different from an internal, private cloud. You must consider what features "" ""make your design most attractive to your users."" msgstr """" ""Gelir fırsatları bulutun kullanım amacı durumuna göre değişir. Ticari, "" ""müşteriye bakan bir ürünün gereklilikleri dahili, özel bir buluttan oldukça "" ""farklıdır. Hangi özelliklerin tasarımınızı kullanıcılarınıza daha çekici "" ""yapacağını göze almalısınız."" msgid ""Revenue opportunity"" msgstr ""Gelir fırsatı"" msgid ""Routing daemons."" msgstr ""Yönlendirme artalan işlemleri."" msgid ""Run ``glance-*`` servers on the ``swift-proxy`` server."" msgstr ""``glance-*`` sunucularını ``swift-proxy`` sunucusu üzerinde çalıştır."" msgid ""Run a central dedicated database server."" msgstr ""Merkezi adanmış veritabanı sunucusu çalıştır."" msgid ""Run one VM per service."" msgstr ""Servis başına bir sanal makine çalıştır."" msgid ""Run operating system and scratch space"" msgstr ""İşletim sistemi ve sıfırdan alan çalıştır"" msgid ""Running a dedicated storage system can be operationally simpler."" msgstr """" ""Adanmış bir depolama sistemi çalıştırmak işlemsel olarak daha basittir."" msgid """" ""Running a distributed file system can make you lose your data locality "" ""compared with nonshared storage."" msgstr """" ""Dağıtık dosya sistemi çalıştırmak paylaşımsız bir depoalamayla "" ""karşılaştırınca verinizin yerelliğini kaybetmesine sebep olabilir."" msgid """" ""Running a shared file system on a storage system apart from the compute "" ""nodes is ideal for clouds where reliability and scalability are the most "" ""important factors. Running a shared file system on the compute nodes "" ""themselves may be best in a scenario where you have to deploy to pre-"" ""existing servers for which you have little to no control over their "" ""specifications or have specific storage performance needs but do not have a "" ""need for persistent storage."" msgstr """" ""Hesaplama düğümlerinden ayrı bir depolama sistemi üzerinde paylaşımlı dosya "" ""sistemi çalıştırmak güvenilirliğin ve ölçeklenebilirliğin en önemli etmenler "" ""olduğu bulutlar için idealdir. Hesaplama düğümlerinin üzerinde paylaşımlı "" ""dosya sistemi çalıştırmak ise özellikleri üzerinde kontrolünüz olmayan veya "" ""belirli deoplama başarım gereksinimleri olan ama kalıcı depolamaya ihtiyacı "" ""olmayan mevcut sunucular üzerine kurmanız gerektiğinde en iyi senaryo "" ""olabilir."" msgid """" ""Running up to 140 web instances and the small number of MariaDB instances "" ""requires 292 vCPUs available, as well as 584 GB of RAM. On a typical 1U "" ""server using dual-socket hex-core Intel CPUs with Hyperthreading, and "" ""assuming 2:1 CPU overcommit ratio, this would require 8 OpenStack Compute "" ""nodes."" msgstr """" ""140 web sunucu ve az sayıda MariaDB sunucusu çalıştırmak kullanılabilir 292 "" ""vCPU ve 584 GB RAM gerektirir. Hyperthreading destekli onaltı çekirdekli "" ""çift soket Intel CPU'ya sahip sıradan bir 1U sunucu üzerinde 2:1 CPU "" ""abonelik aşım oranı varsayarsak, 8 OpenStack Hesaplama düğümüne ihtiyaç "" ""duyarız."" msgid """" ""Runs as a background process. On Linux platforms, a daemon is usually "" ""installed as a service."" msgstr """" ""Arkaplan süreci olarak çalışır. Linux platformlarda, bir artalan işlemi "" ""genellikle servis olarak kurulur."" msgid ""S3"" msgstr ""S3"" msgid ""SLA considerations"" msgstr ""SLA etmenleri"" msgid ""SLA terms that affect the design include:"" msgstr ""Tasarımı etkileyen SLA etmenleri şunları içerir:"" msgid ""SQL database (such as MySQL or PostgreSQL)"" msgstr ""SQL veritabanı (MySQL veya PostgreSQL gibi)"" msgid ""Scalability"" msgstr ""Ölçeklenebilirlik"" msgid """" ""Scalability across multiple cloud providers may dictate which underlying "" ""network framework you choose in different cloud providers. It is important "" ""to present the network API functions and to verify that functionality "" ""persists across all cloud endpoints chosen."" msgstr """" ""Birden çok bulut sağlayıcı arasında ölçeklendirme farklı bulut "" ""sağlayıcılarda hangi ağ çatısını kullanacağınızı dikte edebilir. Ağ API "" ""işlevlerini sunmak ve işlevselliğin seçili tüm bulut uç noktalarında "" ""varlığını doğrulamak önemlidir."" msgid ""Scalability can be affected by network architecture."" msgstr ""Ölçeklenebilirlik ağ mimarisi tarafından etkilenebilir."" msgid """" ""Scalability, along with expandability, is a major consideration in a general "" ""purpose OpenStack cloud. It might be difficult to predict the final intended "" ""size of the implementation as there are no established usage patterns for a "" ""general purpose cloud. It might become necessary to expand the initial "" ""deployment in order to accommodate growth and user demand."" msgstr """" ""Ölçeklenebilirlik, genişleyebilirlikle beraber genel amaçlı bir OpenStack "" ""bulutu için ana etmendir. Uygulamanın nihai boyutu genel amaçlı bir bulut "" ""için elde edilmiş kullanıcı kalıpları olmadığından tahmin etmesi zor "" ""olabilir. Büyümeyi ve kullanıcı isteklerini karşılamak için ilk kurulumun "" ""genişletilmesi gerekebilir."" msgid ""Scale"" msgstr ""Ölçek"" msgid ""Scale-out solutions"" msgstr ""Dışa ölçekleme çözümleri"" msgid ""Scaling Block Storage"" msgstr ""Blok Depolamanın Ölçeklenmesi"" msgid ""Scaling Object Storage"" msgstr ""Nesne Depolamanın Ölçeklenmesi"" msgid """" ""Scaling storage solutions in a storage-focused OpenStack architecture design "" ""is driven by initial requirements, including :term:`IOPS <Input/output "" ""Operations Per Second (IOPS)>`, capacity, bandwidth, and future needs. "" ""Planning capacity based on projected needs over the course of a budget cycle "" ""is important for a design. The architecture should balance cost and "" ""capacity, while also allowing flexibility to implement new technologies and "" ""methods as they become available."" msgstr """" ""Depolama çözümlerini depolama-odaklı bir OpenStack mimari tasarımında "" ""ölçeklendirmek :term:`IOPS <Input/output Operations Per Second (IOPS)>`, "" ""kapasite, bant genişlği, ve gelecekti ihtiyaçlar gibi bazı gereksinimler "" ""ister. Bir bütçe dönemi boyunca öngörülen ihtiyaçlar doğrultusunda kapasite "" ""planlamak tasarım için önemlidir. Mimari, kapasite ve giderleri dengelemeli, "" ""yeni teknoloji ve yöntemleri kullanılabilir olduklarında uygulayacak "" ""esnekliğe sahip olmalıdır."" msgid ""Scaling your cloud"" msgstr ""Bulutunuzu ölçekleme"" msgid ""Scenario"" msgstr ""Senaryo"" msgid ""Scheduling"" msgstr ""Zamanlama"" msgid ""Scheduling services"" msgstr ""Zamanlama servisleri"" msgid ""Script"" msgstr ""Betik"" msgid ""Security"" msgstr ""Güvenlik"" msgid ""Selecting hardware form factor"" msgstr ""Donanım biçim katsayısı seçimi"" msgid ""Selecting storage hardware"" msgstr ""Depolama donanımı seçmek"" msgid """" ""Selecting the proper zone design is crucial for allowing the Object Storage "" ""cluster to scale while providing an available and redundant storage system. "" ""It may be necessary to configure storage policies that have different "" ""requirements with regards to replicas, retention, and other factors that "" ""could heavily affect the design of storage in a specific zone."" msgstr """" ""Düzgün bölge tasarımını seçmek Nesne Depolama kümesine kullanılabilir ve "" ""yedekli depolama sistemi sunarken ölçekleme imkanı sağlar. Yedekler, koruma "" ""ve belirli bir bölgedeki depolamanın tasarımını derinden etkileyebilecek "" ""diğer etmenlere nazaran farklı gereksinimlere sahip depolama ilkeleri "" ""yapılandırmak gerekli olabilir."" msgid ""Separation of Services"" msgstr ""Servislerin Ayrılması"" msgid ""Server density"" msgstr ""Sunucu yoğunluğu"" msgid ""Server hardware"" msgstr ""Sunucu donanımı"" msgid ""Service level agreements"" msgstr ""Servis seviyesi anlaşmaları"" msgid """" ""Service level agreements (SLA) must be developed in conjunction with "" ""business, technical, and legal input. Small, private clouds may operate "" ""under an informal SLA, but hybrid or public clouds generally require more "" ""formal agreements with their users."" msgstr """" ""Servis seviyesi anlaşmalaro (SLA) iş, teknik, ve yasal girdilerle birlikte "" ""geliştirilmelidir. Küçük, özel bulutlar resmi olmayan bir SLA ile "" ""çalışabilirler, ama melez veya açık bulutlar genellikle kullanıcılarıyla "" ""yasal anlaşmalar gerektirirler."" msgid """" ""Service-level agreements (SLAs) define the levels of availability that will "" ""impact the design of an OpenStack cloud to provide redundancy and high "" ""availability."" msgstr """" ""Servis seviyesi anlaşmaları (SLA'lar) yedeklilik ve yüksek kullanılırlık "" ""sağlamak için bir OpenStack bulutunun tasarımını etkileyen kullanılırlık "" ""seviyelerini tanımlar."" msgid ""Services providing RPC, such as ``RabbitMQ``."" msgstr ""``RabbitMQ`` gibi RPC sağlayan servisler."" msgid ""Set rate limits and quotas for specific shares and snapshots."" msgstr """" ""Belirli paylaşım ve anlık görüntüler için oran sınırları ve kotalar ayarla."" msgid ""Shared File System storage"" msgstr ""Paylaşımlı Dosya Sistemi depolama"" msgid """" ""Shared File Systems service does not apply any additional encryption above "" ""what the share’s back-end storage provides"" msgstr """" ""Paylaşımlı Dosya Sistemleri servisi paylaşımın arka ucunun sağladığının "" ""dışında ek şifreleme uygulamaz"" msgid """" ""Shared storage including SAN based arrays, storage clusters such as "" ""``Ceph``, and/or NFS services."" msgstr """" ""SAN tabanlı diziler dahil paylaşımlı depolama, ``Ceph``, ve/veya NFS "" ""servisleri gibi depolama kümeleri."" msgid ""Sheepdog"" msgstr ""Sheepdog"" msgid """" ""Sheepdog is a userspace distributed storage system. Sheepdog scales to "" ""several hundred nodes, and has powerful virtual disk management features "" ""like snapshot, cloning, rollback and thin provisioning."" msgstr """" ""Sheepdog kullanıcı uzayında çalışan dağıtık depolama sistemidir. Sheepdog "" ""yüzlerce düğüme ölçeklenebilir ve güçlü sanal disk yönetim özelliklerine "" ""sahiptir, örneğin anlık görüntüler, klonlama, geri dönme, ve ince hazırlama."" msgid """" ""Should my persistent storage drives be contained in my compute nodes, or "" ""should I use external storage?"" msgstr """" ""Kalıcı depolama sürücülerim hesaplama düğümlerinde mi olmalı, yoksa harici "" ""depolama mı kullanmalıyım?"" msgid """" ""Similarly, the default RAM allocation ratio of 1.5:1 means that the "" ""scheduler allocates instances to a physical node as long as the total amount "" ""of RAM associated with the instances is less than 1.5 times the amount of "" ""RAM available on the physical node."" msgstr """" ""Benzer şekilde, öntanımlı RAM ayırma oranı olan 1.5:1, zamanlayıcının sunucu "" ""ile ilişkili toplam RAM miktarının fiziksel düğümdeki RAM miktarının 1.5 "" ""katından az olduğu sürece fiziksel düğüme sunucu ayıracağı anlamına gelir."" msgid ""Single Point Of Failure (SPOF)"" msgstr ""Tek Kırılma Noktası (SPOF)"" msgid ""Site loss and recovery"" msgstr ""Konum kaybı ve kurtarma"" msgid """" ""Size your database server accordingly, and scale out beyond one cloud "" ""controller if many instances will report status at the same time and "" ""scheduling where a new instance starts up needs computing power."" msgstr """" ""Veritabanı sunucunuzu uygun şekilde boyutlandırın, ve eğer bir çok sunucu "" ""aynı anda durum raporu verecekse bir bulut kontrol biriminden öteye "" ""ölçekleyin, yeni bir sunucu başlarken hesaplama gücü isteyecektir."" msgid ""Sizing determined by…"" msgstr ""Boyutlandırmaya karar verme kriteri..."" msgid ""Software to provide load balancing"" msgstr ""Yük dengeleme sağlayacak yazılım"" msgid """" ""Solutions that employ Galera/MariaDB require at least three MySQL nodes."" msgstr ""Galera/MariaDB dahil eden çözümler en az üç MySQL düğümü gerektirir."" msgid """" ""Some applications are tolerant of a lack of synchronized object storage, "" ""while others may need those objects to be replicated and available across "" ""regions. Understanding how the cloud implementation impacts new and existing "" ""applications is important for risk mitigation, and the overall success of a "" ""cloud project. Applications may have to be written or rewritten for an "" ""infrastructure with little to no redundancy, or with the cloud in mind."" msgstr """" ""Bazı uygulamalar eşzamanlı nesne depolamanın olmayışına müsamaha "" ""gösterebilirler, diğerleri is bu nesnelerin çoğaltılmış ve bölgeler arasında "" ""kullanılabilir olmasını gerektirebilir. Bulut kurulumunun yeni ve mevcut "" ""uygulamaların risk azaltımını, veya projenin genel başarısını nasıl "" ""etkilediğini anlamak önemlidir. Uygulamaların bulut göz önünde "" ""bulundurularak çok az yedeklilik olan ya da hiç olmayan alt yapılar için "" ""yazılması veya tekrar yazılması gerekebilir."" msgid ""Some basic benchmarks for small read/writes:"" msgstr ""Küçük okuma/yazmalar için bazı değerlendirme deneyleri:"" msgid """" ""Some of the key considerations in the selection of networking hardware "" ""include:"" msgstr """" ""Ağ donanımı seçerken göz önüne alınacak bazı anahtar etmenler şunlardır:"" msgid ""Some other potential design impacts include:"" msgstr ""Diğer bazı tasarım etmenleri şunlardır:"" msgid """" ""Some services are commonly shared between multiple regions, including the "" ""Identity service and the Dashboard. In this case, it is necessary to ensure "" ""that the databases backing the services are replicated, and that access to "" ""multiple workers across each site can be maintained in the event of losing a "" ""single region."" msgstr """" ""Bazı servisler genellikle birden çok bölge arasında paylaşılırlar, örneğin "" ""Kimlik servisi ve Kontrol Paneli. Bu durumda servisleri destekleyen "" ""veritabanlarının çoğaltıldığından, ve bir bölgenin kaybı durumunda her bir "" ""konumdaki birden çok işçiye erişimin sağlandığından emin olunmalıdır."" msgid ""Specific meters that are critically important to capture include:"" msgstr ""Yakalanması önemli belirli ölçütler şunlardır:"" msgid ""Specify access rules and security services for existing shares."" msgstr """" ""Mevcut paylaşımlar için erişim kuralları ve güvenlik servislerini belirt."" msgid ""Speed"" msgstr ""Hız"" msgid """" ""Starting instances and deleting instances is demanding on the compute node "" ""but also demanding on the controller node because of all the API queries and "" ""scheduling needs."" msgstr """" ""API sorguları ve zamanlama gereksinimleri sebebiyle sunucuları başlatmak ve "" ""silmek hesaplama düğümünde olduğu kadar kontrol düğümünde de yük yaratır."" msgid ""Storage"" msgstr ""Depolama"" msgid ""Storage architecture"" msgstr ""Depolama mimarisi"" msgid """" ""Storage can be a significant portion of the overall system cost. For an "" ""organization that is concerned with vendor support, a commercial storage "" ""solution is advisable, although it comes with a higher price tag. If initial "" ""capital expenditure requires minimization, designing a system based on "" ""commodity hardware would apply. The trade-off is potentially higher support "" ""costs and a greater risk of incompatibility and interoperability issues."" msgstr """" ""Depolama genel sistem masrafları arasında önemli bir kısmı tutabilir. "" ""Üretici desteğiyle ilgili endişes olan bir kurum için ticari bir çözüm "" ""tavsiye edilebilir, her ne kadar daha pahalı olacaksa da. Eğer ilk ana para "" ""giderleri asgari olmayı gerektiriyorsa emtia donanım tabanlı bir sistem "" ""tasarlamak tavsiye edilebilir. Verilen ödün muhtemel yüksek destek giderleri "" ""ve uyumsuzluk ve birlikte çalışılabilirlik sorunları olacaktır."" msgid ""Storage cloud"" msgstr ""Depolama bulutu"" msgid ""Storage concepts"" msgstr ""Depolama kavramları"" msgid ""Storage design"" msgstr ""Depolama tasarımı"" msgid """" ""Storage hardware architecture is determined by selecting specific storage "" ""architecture. Determine the selection of storage architecture by evaluating "" ""possible solutions against the critical factors, the user requirements, "" ""technical considerations, and operational considerations. Consider the "" ""following factors when selecting storage hardware:"" msgstr """" ""Depolama donanımı mimarisine belirli depolama mimarisi seçilerek karar "" ""verilir. Ciddi etmenler, kullanıcı gereksinimleri, teknik etmenler ve "" ""işlevsel etmenlere karşı uygun çözümleri değerlendirerek depolama mimarisini "" ""seçin. Depolama donanımı seçerken şu etmenlere dikkat edin:"" msgid ""Storage hardware:"" msgstr ""Depolama donanımı:"" msgid """" ""Storage is found in many parts of the OpenStack cloud environment. It is "" ""important to understand the distinction between :term:`ephemeral <ephemeral "" ""volume>` storage and :term:`persistent <persistent volume>` storage:"" msgstr """" ""Depolama OpenStack bulut ortamının bir çok kısmında bulunur. :term:`geçici "" ""<ephemeral volume>` depolama ve :term:`kalıcı <persistent volume>` depolama: "" ""arasındaki farkı bilmek önemlidir."" msgid """" ""Storage is found in many parts of the OpenStack cloud environment. This "" ""chapter describes storage type, design considerations and options when "" ""selecting persistent storage options for your cloud environment."" msgstr """" ""Depolama OpenStack bulut ortamının çoğu kısmında bulunur. Bu bölüm bulut "" ""ortamınız için kalıcı depolama seçerken kullanacağınız depolama türü, "" ""tasarım etmenleri ve seçeneklerini tanımlar."" msgid ""Storage requirements"" msgstr ""Depolama gereksinimleri"" msgid """" ""Storage-focused OpenStack clouds must address I/O intensive workloads. These "" ""workloads are not CPU intensive, nor are they consistently network "" ""intensive. The network may be heavily utilized to transfer storage, but they "" ""are not otherwise network intensive."" msgstr """" ""Depolama odaklı OpenStack bulutları I/O ağırlıklı iş yüklerini ele "" ""almalıdır. Bu iş yükleri CPU ağırlıklı değildir, ayrıca tutarlı olarak ağ "" ""ağırlıklı da değillerdir. Ağ ağır şekilde depolama aktarımı için "" ""kullanılıyor olabilir, ama aksi halde ağ ağırlıklı değillerdir. "" msgid """" ""Storage-focused architecture depends on specific use cases. This section "" ""discusses three example use cases:"" msgstr """" ""Depolama odaklı mimari belirli kullanım durumlarına bağımlıdır. Bu kısım üç "" ""örnek kullanım durumunu tartışır:"" msgid ""Storage-intensive use cases like HPC and Big Data clouds"" msgstr """" ""HPC ve Büyük Veri bulutları gibi depolama yoğunluklu kullanım durumları"" msgid ""Store data, including VM images"" msgstr ""VM imajları dahil veri sakla"" msgid """" ""Stores and serves images with metadata on each, for launching in the cloud"" msgstr """" ""Herbirinde metaveri ile bulutta çalıştırmak üzere imajları kaydeder ve sunar"" msgid """" ""Sufficient monitoring and data collection should be in-place from the start, "" ""such that timely decisions regarding capacity, input/output metrics (IOPS) "" ""or storage-associated bandwidth can be made."" msgstr """" ""Yeterli izleme ve veri toplama en baştan yerli yerinde çalışmalıdır, "" ""kapasiteyle ilgili, girdi/çıktı ölçümleri (IOPS) veya depolama ilişkili bant "" ""genişliği kararları böylece vaktinde yapılabilir."" msgid ""Support an indeterminate variety of platforms and applications."" msgstr ""Kesin olmayan çeşitlilikte platform ve uygulamayı destekleyin."" msgid ""Support and maintenance"" msgstr ""Destek ve bakım"" msgid """" ""Support for the distributed file-system interface `CephFS <http://ceph.com/"" ""docs/master/cephfs/>`_."" msgstr """" ""Dağıtık dosya sistemi arayüzü `CephFS <http://ceph.com/docs/master/cephfs/"" "">`_ için destek."" msgid ""Supporting asymmetric links"" msgstr ""Asimetrik bağlantıları desteklemek"" msgid ""Swift"" msgstr ""Swift"" msgid ""Table. Cloud controller hardware sizing considerations"" msgstr ""Tablo. Bulut kontrol birimi donanım boyutlandırma etmenleri"" msgid ""Table. Deployment scenarios"" msgstr ""Tablo. Kurulum senaryoları"" msgid ""Table. OpenStack storage"" msgstr ""Tablo. OpenStack depolama"" msgid ""Technical details"" msgstr ""Teknik ayrıntılar"" msgid ""Telemetry service"" msgstr ""Telemetri servisi"" msgid ""Telemetry uses MongoDB."" msgstr ""Telemetri MongoDB kullanır."" msgid """" ""The Architecture Design Guide provides information on planning and designing "" ""an OpenStack cloud. It explains core concepts, cloud architecture design "" ""requirements, and the design criteria of key components and services in an "" ""OpenStack cloud. The guide also describes five common cloud use cases."" msgstr """" ""Mimari Tasarım Kılavuzu bir OpenStack bulutu planlama ve tasarlama üstüne "" ""bilgi sağlar. Çekirdek kavramları, bulut mimari tasarım gereksinimlerini, ve "" ""OpenStack bulutundaki anahtar bileşenlerin ve servislerin tasarım "" ""kriterlerini açıklar. Kılavuz ayrıca beş genel bulut kullanım durumunu "" ""tanımlar."" msgid """" ""The Block Storage service supports multiple back ends in the form of "" ""drivers. Your choice of a storage back end must be supported by a block "" ""storage driver."" msgstr """" ""Blok Depolama servisi sürücüler biçiminde bir çok arka ucu destekler. "" ""Depolama arka ucu seçiminiz blok depolama sürücüsü tarafından "" ""desteklenmelidir."" msgid """" ""The Logical Volume Manager (LVM) is a Linux-based system that provides an "" ""abstraction layer on top of physical disks to expose logical volumes to the "" ""operating system. The LVM back-end implements block storage as LVM logical "" ""partitions."" msgstr """" ""Mantıksal Birim Yöneticisi (LVM) işletim sistemine mantıksal birimler sunmak "" ""için fiziksel diskler üstüne bir soyutlama katmanı ekleyen Linux tabanlı "" ""sistemdir. LVM arka uu blok depolamayı LVM mantıksal bölümleri olarak "" ""uygular."" msgid """" ""The Logstash filter performs intermediary processing on each event. "" ""Conditional filters are applied based on the characteristics of the input "" ""and the event. Some examples of filtering are:"" msgstr """" ""Logstash süzgeci her olayda ara işlemeyi gerçekleştirir. Girdinin ve olayın "" ""ayırıcı niteliğine göre süzgeçler uygulanır. Bazı süzme örnekleri şöyledir:"" msgid """" ""The Networking service provides full control over creation of virtual "" ""network resources to tenants. This is often accomplished in the form of "" ""tunneling protocols that establish encapsulated communication paths over "" ""existing network infrastructure in order to segment tenant traffic. This "" ""method varies depending on the specific implementation, but some of the more "" ""common methods include tunneling over GRE, encapsulating with VXLAN, and "" ""VLAN tags."" msgstr """" ""Ağ servisi kiracılara sanal ağ kaynaklarının oluşturulmasında tam kontrol "" ""sağlar. Bu da genellikle kiracı trafiğini dilimlemek için mevcut ağ alt "" ""yapısı üstünde kapsüllenmiş iletişim yolları sağlayan tünelleme iletişim "" ""kuralları biçiminde başarılır. Bu yöntem belirli uygulamaya göre değişim "" ""gösterir, ama yaygın yöntemlerden bazıları GRE üzerinden tünelleme, VXLAN "" ""ile kapsülleme, ve VLAN etiketleridir."" msgid """" ""The OpenStack Compute API is extensible. An extension adds capabilities to "" ""an API beyond those defined in the core. The introduction of new features, "" ""MIME types, actions, states, headers, parameters, and resources can all be "" ""accomplished by means of extensions to the core API. This allows the "" ""introduction of new features in the API without requiring a version change "" ""and allows the introduction of vendor-specific niche functionality."" msgstr """" ""OpenStack Hesaplama API'si eklentilenebilir. Eklenti API'ye çekirdekte "" ""tanımlanmamış yetenekler ekler. Yeni özelliklerin tanıtımı, MIME türleri, "" ""eylemler, durumlar, başlıklar, parametreler, ve kaynaklar hep çekirdek "" ""API'ye eklenti olarak elde edilebilir. Bu API'ye yeni özelliklerin bir sürüm "" ""değişikliğine gidilmeden getirilebilmesi ve üreticiye özel işlevselliğe izin "" ""verilmesi demektir."" msgid """" ""The OpenStack Image service consists of two parts: ``glance-api`` and "" ""``glance-registry``. The former is responsible for the delivery of images; "" ""the compute node uses it to download images from the back end. The latter "" ""maintains the metadata information associated with virtual machine images "" ""and requires a database."" msgstr """" ""OpenStack imaj servisi iki bölümden oluşur: ``glance-api`` ve ``glance-"" ""registry``. İlki imajların getirilmesinden sorumludur, hesaplama düğümü arka "" ""uçtan imajları indirmek için kullanır. Sonraki sanal makine imajlarıyla "" ""ilişkili metaveri bilgisini yönetir ve bir veritabanına ihtiyaç duyar."" msgid """" ""The OpenStack dashboard (horizon) provides a web-based user interface to the "" ""various OpenStack components. The dashboard includes an end-user area for "" ""users to manage their virtual infrastructure and an admin area for cloud "" ""operators to manage the OpenStack environment as a whole."" msgstr """" ""OpenStack kontrol paneli (horizon) çeşitli OpenStack bileşenleri için web "" ""tabanlı kullanıcı arayüzü sunar. Kontrol paneli kullanıcılar için sanal alt "" ""yapılarını yönetebilecekleri bir son kullanıcı alanı ve bulut "" ""yöneticilerinin OpenStack ortamını yönetebildikleri bir yönetici alanı "" ""içerir."" msgid """" ""The OpenStack services themselves should be deployed across multiple servers "" ""that do not represent a single point of failure. Ensuring availability can "" ""be achieved by placing these services behind highly available load balancers "" ""that have multiple OpenStack servers as members."" msgstr """" ""OpenStack'in kendi servisleri tek bir kırılma noktası olmayan birden çok "" ""sunucuda kurulmalıdır. Kullanılırlıktan emin olmak için bu servisleri birden "" ""çok OpenStack sunucu üyesine sahip yüksek kullanılırlıklı yük "" ""dengeleyicilerin arkasına koyabilirsiniz."" msgid ""The REST API"" msgstr ""REST API"" msgid """" ""The Shared File Systems service is persistent storage and can be mounted to "" ""any number of client machines. It can also be detached from one instance and "" ""attached to another instance without data loss. During this process the data "" ""are safe unless the Shared File Systems service itself is changed or removed."" msgstr """" ""Paylaşımlı Dosya Sistemleri servisi kalıcı depolamadır ve istenen sayıda "" ""istemci makineye bağlanabilir. Ayrıca veri kaybı olmadan bir sunucudan "" ""ayrılıp başka bir sunucuya bağlanabilir. Bu süreçte Paylaşımlı Dosya "" ""Sistemleri servisinin kendisi değiştirilmediği ya da kaldırılmadığı sürece "" ""veri güvendedir."" msgid """" ""The Solaris iSCSI driver for OpenStack Block Storage implements blocks as "" ""ZFS entities. ZFS is a file system that also has the functionality of a "" ""volume manager. This is unlike on a Linux system, where there is a "" ""separation of volume manager (LVM) and file system (such as, ext3, ext4, "" ""xfs, and btrfs). ZFS has a number of advantages over ext4, including "" ""improved data-integrity checking."" msgstr """" ""OpenStack Blok Depolama için Solaris iSCSI sürücüsü blokları ZFS girdileri "" ""olarak uygular. ZFS bir birim yönetici işlevselliğine de sahip olan bir "" ""dosya sistemidir. Bu birim yönetimi (LVM) ile dosya sistemi (ext3, ext3, "" ""xfs, btrfs vs.) ayrımı olan bir Linux sistemi gibi değildir. ZFS'in ext4'e "" ""göre bir takım avantajları vardır, geliştirilmiş veri tutarlılığı kontrolü "" ""de bunlardan biridir."" msgid """" ""The ZFS back end for OpenStack Block Storage supports only Solaris-based "" ""systems, such as Illumos. While there is a Linux port of ZFS, it is not "" ""included in any of the standard Linux distributions, and it has not been "" ""tested with OpenStack Block Storage. As with LVM, ZFS does not provide "" ""replication across hosts on its own, you need to add a replication solution "" ""on top of ZFS if your cloud needs to be able to handle storage-node failures."" msgstr """" ""OpenStack Blok Depolama için ZFS arka ucu yalnızca Illumos gibi Solaris "" ""tabanlı sistemleri destekler. ZFS'in bir Linux portu olsa da standart Linux "" ""dağıtımlarıyla birlikte gelmez, ve OpenStack Blok Depolama ile test "" ""edilmemiştir. LVM ile, ZFS sunucular arasında yedeklemeyi kendi başına "" ""sağlamaz, bulut ihtiyaçlarınız depolama düğümü arızalarına dayanıklı olmak "" ""zorundaysa ZFS üstüne bir yedekleme çözümü koymalısınız."" msgid """" ""The `API Specifications <https://developer.openstack.org/api-guide/quick-"" ""start/index.html>`_ define the core actions, capabilities, and mediatypes of "" ""the OpenStack API. A client can always depend on the availability of this "" ""core API, and implementers are always required to support it in its "" ""entirety. Requiring strict adherence to the core API allows clients to rely "" ""upon a minimal level of functionality when interacting with multiple "" ""implementations of the same API."" msgstr """" ""`API Özellikleri <https://developer.openstack.org/api-guide/quick-start/"" ""index.html>`_ OpenStack API'sinin çekirdek eylemlerini, yeteneklerini ve "" ""ortam türlerini tanımlar. Bir istemci her zaman bu çekirden API'nin "" ""kullanılırlığına güvenebilir, ve bu API'yi uygulayanlar tamamını desteklemek "" ""durumundadır. Çekirdek API'ye sıkı sıkıya bağlılığı gerektirmek aynı API'nin "" ""farklı uygulamalarıyla etkileşime geçen istemcilerin asgari düzeyde "" ""işlevselliğe sahip olması demektir."" msgid """" ""The ``glance-api`` part is an abstraction layer that allows a choice of back "" ""end. Currently, it supports:"" msgstr """" ""``glance-api`` kısmı bir arka uç seçimine izin veren soyutlama katmanıdır. "" ""Şunları destekler:"" msgid """" ""The ``nova-conductor`` service is horizontally scalable. To make ``nova-"" ""conductor`` highly available and fault tolerant, just launch more instances "" ""of the ``nova-conductor`` process, either on the same server or across "" ""multiple servers."" msgstr """" ""``nova-conductor`` servisi yatay ölçeklenebilirdir. Yüksek kullanılırlıklı "" ""ve arızaya dayanıklı bir ``nova-conductor`` için, ``nova-conductor`` "" ""sürecindeki sunuculardan aynı sunucuda ya da birden çok sunucuda daha fazla "" ""başlatın yeter."" msgid """" ""The ability to create pools or availability zones for unpredictable "" ""workloads should be considered. In some cases, the demand for certain "" ""instance types or flavors may not justify individual hardware design. "" ""Allocate hardware designs that are capable of servicing the most common "" ""instance requests. Adding hardware to the overall architecture can be done "" ""later."" msgstr """" ""Beklenmedik iş yükleri için havuzlar veya kullanılırlık bölgeleri oluşturmak "" ""göz önüne alınmalıdır. Bazı durumlarda, belirli sunucu türlerine veya "" ""niteliklerine duyulan ihtiyaç donanım tasarımıyla eşleşmeyebilir. En yaygın "" ""sunucu isteklerini karşılayabilecek donanım tasarımlarını ayırın. Genel "" ""mimariye donanım eklemek daha sonra da yapılabilir."" msgid """" ""The ability to deliver services or products within a flexible time frame is "" ""a common business factor when building a cloud. Allowing users to self-"" ""provision and gain access to compute, network, and storage resources on-"" ""demand may decrease time-to-market for new products and applications."" msgstr """" ""Bulut inşa ederken esnek zaman aralığında servis veya ürünleri "" ""yetiştirebilmek genel bir iş etmenidir. Kullanıcıların kendi hazırlıklarıyla "" ""ve hesaplama, ağ, ve depolama kaynaklarına ihtiyaçları olduğunda erişim "" ""kabiliyetleriyle iş yapmaları yeni ürün ve uygulamaların pazara sürüm "" ""süresini azaltabilir."" msgid """" ""The administrator has more fine-grained control over data distribution and "" ""replication strategies."" msgstr """" ""Yöneticinin veri dağıtımı ve yedekleme stratejileri üzerinde daha ince "" ""ayrıntılı kontrolü bulunur."" msgid """" ""The benefits of NFS is low implementation cost due to shared NICs and "" ""traditional network components, and a simpler configuration and setup "" ""process."" msgstr """" ""NFS'in faydaları paylaşımlı NIC'ler ve geleneksel ağ bileşenleri ile "" ""uygulama masraflarının düşük olması ve daha basit yapılandırma ve kurulum "" ""sürecidir."" msgid """" ""The chassis size of the compute node can limit the number of spindles able "" ""to be used in a compute node."" msgstr """" ""Hesaplama düğümünün şasi boyutu bir hesaplama düğümünde kullanılabilecek mil "" ""sayısını sınırlayabilir."" msgid """" ""The chosen high availability database solution changes according to the "" ""selected database. MySQL, for example, provides several options. Use a "" ""replication technology such as Galera for active-active clustering. For "" ""active-passive use some form of shared storage. Each of these potential "" ""solutions has an impact on the design:"" msgstr """" ""Seçilen yüksek kullanılırlık veritabanı çözümü seçilen veritabanına göre "" ""değişir. MySQL örneğin, bir çok seçenek sunar. Etkin-etkin kümeleme için "" ""Galera gibi bir çoğaltma teknolojisi kullanın. Etkin-pasif kullanım için bir "" ""çeşit paylaşımlı depolama kullanın. Bu çözümlerden her birinin tasarımda "" ""belirli bir etkisi vardır:"" msgid ""The cloud controller manages the following services for the cloud:"" msgstr ""Bulut kontrol birimi bulut için şu servisleri yönetir:"" msgid """" ""The cloud controller provides the central management system for OpenStack "" ""deployments. Typically, the cloud controller manages authentication and "" ""sends messaging to all the systems through a message queue."" msgstr """" ""Bulut kontrol birimi OpenStack kurulumları için merkezi yönetim sistemi "" ""sağlar. Genellikle bulut kontrol birimi yetkilendirmeyi yönetir ve bir mesaj "" ""kuyruğu aracılığıyla tüm sistemlere mesajlaşma gönderir."" msgid """" ""The cloud networks are divided into a number of logical zones that support "" ""the network traffic flow requirements. We recommend defining at the least "" ""four distinct network zones."" msgstr """" ""Bulut ağları ağ trafik akış gereksinimlerini destekleyen bir takım mantıksal "" ""bölgelere bölünür. En az dört ayrı ağ bölgesi oluşturmanızı öneriyoruz."" msgid """" ""The cloud user expects repeatable, dependable, and deterministic processes "" ""for launching and deploying cloud resources. You could deliver this through "" ""a web-based interface or publicly available API endpoints. All appropriate "" ""options for requesting cloud resources must be available through some type "" ""of user interface, a command-line interface (CLI), or API endpoints."" msgstr """" ""Bulut kullanıcısı bulut kaynaklarını başlatmak ve kurmak için "" ""tekrarlanabilir, güvenilir, ve belirleyici süreçler bekler. Bunu web tabanlı "" ""bir arayüz veya genele açık API uç noktaları kullanarak sağlayabilirsiniz. "" ""Bulut kaynakları istemekle ilgili kullanılabilir tüm seçenekler bir tür "" ""kullanıcı arayüzü aracılığıyla, komut satırı arayüzüyle (CLI) veya API uç "" ""noktalarıyla sunulmalıdır."" msgid """" ""The company runs hardware load balancers and multiple web applications "" ""serving their websites and orchestrates environments using combinations of "" ""scripts and Puppet. The website generates large amounts of log data daily "" ""that requires archiving."" msgstr """" ""Şirket web sitelerini sunan donanımsal yük dengeleyiciler ve bir çok web "" ""uygulaması çalıştırır, ortamları betikler ve Puppet karışımı ile orkestre "" ""eder. Web site arşivlemeye ihtiyaç duyan günlük bol miktarda kayıt üretir."" msgid """" ""The concepts supporting OpenStack's authentication and authorization are "" ""derived from well-understood and widely used systems of a similar nature. "" ""Users have credentials they can use to authenticate, and they can be a "" ""member of one or more groups (known as projects or tenants, interchangeably)."" msgstr """" ""OpenStack'in kimlik doğrulama ve yetkilendirmesini destekleyen kavramlar "" ""iyice anlaşılmış ve geniş çapta kullanılan aynı doğadaki sistemlerden gelir. "" ""Kullanıcıların kimlik doğrulamada kullanabilecekleri kimlik bilgileri olur, "" ""ve bir ya da daha fazla grubun üyesi olabilirler (proje veya kiracı diye de "" ""bilinir)."" msgid """" ""The conductor service resolves both of these issues by acting as a proxy for "" ""the ``nova-compute`` service. Now, instead of ``nova-compute`` directly "" ""accessing the database, it contacts the ``nova-conductor`` service, and "" ""``nova-conductor`` accesses the database on ``nova-compute``'s behalf. Since "" ""``nova-compute`` no longer has direct access to the database, the security "" ""issue is resolved. Additionally, ``nova-conductor`` is a nonblocking "" ""service, so requests from all compute nodes are fulfilled in parallel."" msgstr """" ""Orkestra yönetim servisi bu sorunlardan ikisini de ``nova-compute`` servisi "" ""için vekil olarak davranarak çözer. Artık ``nova-compute`` veritabanına "" ""doğrudan erişmek yerine ``nova-conductor`` servisi ile iletişim kurar, ve "" ""``nova-conductor`` veritabanına ``nova-compute``'nin yerine erişir. ``nova-"" ""compute`` artık doğrudan veritabanına erişemediğinden, güvenlik sorunu "" ""çözülmüş olur. Ek olarak, ``nova-conductor`` engelleyici bir servis "" ""olmadığından, tüm hesaplama düğümlerinden gelen istekler paralel olarak "" ""işlenebilir."" msgid """" ""The dashboard is implemented as a Python web application that normally runs "" ""in :term:`Apache` ``httpd``. Therefore, you may treat it the same as any "" ""other web application, provided it can reach the API servers (including "" ""their admin endpoints) over the network."" msgstr """" ""Kontrol paneli normalde :term:`Apache` ``httpd`` çalıştıran bir Python web "" ""uygulaması olarak geliştirildi. Yani API sunucularına (yönetici uç noktaları "" ""da dahil) ağ üzerinden erişebildiği sürece herhangi bir web uygulaması gibi "" ""davranabilirsiniz."" msgid """" ""The dashboard makes many requests, even more than the API access, so add "" ""even more CPU if your dashboard is the main interface for your users."" msgstr """" ""Kontrol paneli birçok istek yapar, API erişiminden bile daha fazla, yani "" ""kullanıcılarınız için ana arayüzünüz kontrol paneliyse daha fazla işlemci "" ""ekleyin."" msgid """" ""The data center floor must be able to support the weight of the proposed "" ""number of hosts within a rack or set of racks. These factors need to be "" ""applied as part of the host density calculation and server hardware "" ""selection."" msgstr """" ""Veri merkezi zemini kabindeki veya kabin kümelerindeki hazırlanan "" ""sunucuların ağırlığını destekleyebilmelidir. Bu etmenler sunucu yoğunluk "" ""hesaplamalarının ve sunuc donanım seçiminin parçası olarak hesaplanmalıdır."" msgid """" ""The default CPU allocation ratio of 16:1 means that the scheduler allocates "" ""up to 16 virtual cores per physical core. For example, if a physical node "" ""has 12 cores, the scheduler sees 192 available virtual cores. With typical "" ""flavor definitions of 4 virtual cores per instance, this ratio would provide "" ""48 instances on a physical node."" msgstr """" ""Öntanımlı CPU ayırma oranı olan 16:1 zamanlayıcının fiziksel çekirdek başına "" ""16 sanal çekirdek ayırdığı anlamına gelir. Örneğin, 12 çekirdekli fiziksel "" ""bir düğümü, zamanlayıcı 192 sanal çekirdek olarak görür. Genel nitelik "" ""tanımlarında olan sunucu başına 4 sanal çekirdek düşünüldüğünde, bu oran "" ""fiziksel düğüm başına 48 sunucu demektir."" msgid """" ""The deployed applications need to continue to function and, more "" ""importantly, you must consider the impact on the performance and reliability "" ""of the application if a site is unavailable."" msgstr """" ""Kurulu uygulamalar çalışmaya devam etmeli, daha da önemlisi, bir konum "" ""kullanılamaz olduğunda uygulamanın başarım ve güvenilirliğine olan etkiyi "" ""göz önünde bulundurmalısınız."" msgid """" ""The deployed applications need to continue to function and, more "" ""importantly, you must consider the impact on the performance and reliability "" ""of the application when a site is unavailable."" msgstr """" ""Kurulan uygulamaların çalışmaya devam etmesi gereklidir, daha önemlisi, bir "" ""konum kullanılamaz olduğunda uygulamanın başarım ve güvenilirliğine etkisini "" ""göz önünde bulundurmalısınız."" msgid """" ""The design will require networking hardware that has the requisite port "" ""count."" msgstr """" ""Tasarım zorunlu bağlantı noktası sayısına sahip ağ donanımı gerektirecektir."" msgid """" ""The edge zone is where network traffic transitions from the cloud overlay or "" ""SDN networks into the traditional network environments."" msgstr """" ""Uç bölge trafiğin bulut üst katmanından ya da SDN ağlarından geleneksel ağ "" ""ortamlarına geçiş yaptığı yere denir."" msgid """" ""The example REST interface, presented as a traditional Object Store running "" ""on traditional spindles, does not require a high performance caching tier."" msgstr """" ""Örnek REST arayüzü, geleneksel miller üzerinde çalışan, yüksek başarımlı ön "" ""bellekleme katmanı gerektirmeyen geleneksel Nesne Depolama sundu."" msgid """" ""The example below shows a REST interface without a high performance "" ""requirement. The following diagram depicts the example architecture:"" msgstr """" ""Aşağıdaki örnek yüksek başarım gereksinimi olmayan bir REST arayüzünü "" ""gösterir. Aşağıdaki çizim örnek mimariyi tasvir eder:"" msgid """" ""The external network is defined as the configuration and components that are "" ""required to provide access to cloud resources and workloads, the external "" ""network is defined as all the components outside of the cloud edge gateways."" msgstr """" ""Harici ağ bulut kaynaklarına ve iş yüklerine erişim sağlamak için gerekli "" ""yapılandırma ve bileşenler olarak tanımlanır, harici ağ bulut kenar "" ""geçitleri dışında kalan tüm bileşenler olarak tanımlanır."" msgid """" ""The figure below depicts an example design for this workload. In this "" ""example, a hardware load balancer provides SSL offload functionality and "" ""connects to tenant networks in order to reduce address consumption. This "" ""load balancer links to the routing architecture as it services the VIP for "" ""the application. The router and load balancer use the GRE tunnel ID of the "" ""application's tenant network and an IP address within the tenant subnet but "" ""outside of the address pool. This is to ensure that the load balancer can "" ""communicate with the application's HTTP servers without requiring the "" ""consumption of a public IP address."" msgstr """" ""Aşağıdaki şekil bu iş yükü için örnek bir tasarım tasvir eder. Bu örnekte, "" ""donanımsal bir yük dengeleyici SSL yükünü alır ve adres tüketimini azaltmak "" ""için kiracı ağlara bağlanır. Bu yük dengeleyici uygulama için VIP servis "" ""ederken yönlendirme mimarisine bağlanır. Yönlendirici ve yük dengeleyici "" ""uygulamanın kiracı ağını GRE tünel kimliğini ve kiracı alt ağındaki IP "" ""adresini adres havuzunun dışından kullanır. Bu yük dengeleyicinin "" ""uygulamanın HTTP sunucularıyla açık IP adreslerinin tüketimine gerek "" ""duymadan iletişim kurabildiğinden emin olmak içindir."" msgid """" ""The following sections describe business, usage, and performance "" ""considerations for customers which will impact cloud architecture design."" msgstr """" ""Aşağıdaki kısımlar müşteriler için bulut mimari tasarımını iş, kullanım, ve "" ""başarım göz önüne alınarak tanımlar."" msgid """" ""The formula for the number of virtual instances on a compute node is "" ""``(OR*PC)/VC``, where:"" msgstr """" ""Hesaplama düğümündeki sanal sunucu sayısının formülü ``(OR*PC)/VC``, "" ""şöyledir:"" msgid """" ""The hardware requirements and configuration are similar to those of the High "" ""Performance Database example below. In this case, the architecture uses "" ""Ceph's Swift-compatible REST interface, features that allow for connecting a "" ""caching pool to allow for acceleration of the presented pool."" msgstr """" ""Donanım gereksinimleri ve yapılandırma aşağıdaki Yüksek Başarımlı Veritabanı "" ""örneği ile aynıdır. Bu durumda, mimari Ceph'in Swift-uyumlu REST arayüzünü, "" ""mevcut havuzun hızlandırılmasına izin veren bir ön bellekleme havuzuna "" ""bağlanmayı sağlayan özellikleri kullanır."" msgid """" ""The importance of security varies based on the type of organization using a "" ""cloud. For example, government and financial institutions often have very "" ""high security requirements. Security should be implemented according to "" ""asset, threat, and vulnerability risk assessment matrices. See `security-"" ""requirements`."" msgstr """" ""Güvenliğin önemi bulutu kullanan kurumun türüne bağlı olarak değişir. "" ""Örneğin, devlet ve finans enstitüleri genellikle yüksek güvenlik "" ""gereksinimlerine ihtiyaç duyar. Güvenlik varlık, tehdit ve kırılganlık risk "" ""matrislerine göre uygulanmalıdır. Bknz `security-requirements`."" msgid """" ""The inclusion of clustering software, such as Corosync or Pacemaker, is "" ""primarily determined by the availability of the cloud infrastructure and the "" ""complexity of supporting the configuration after it is deployed. The "" ""`OpenStack High Availability Guide <https://docs.openstack.org/ha-guide/>`_ "" ""provides more details on the installation and configuration of Corosync and "" ""Pacemaker, should these packages need to be included in the design."" msgstr """" ""Corosync ya da Pacemaker gibi kümeleme yazılımının dahil edilmesine, bulut "" ""alt yapısının kullanılabilirliği ve kurulumundan sonra yapılandırmanın "" ""desteklenme karmaşıklığına bağlı olarak karar verilir. `OpenStack Yüksek "" ""Kullanılırlık Kılavuzu <https://docs.openstack.org/ha-guide/>`_ Corosync ve "" ""Pacemaker yapılandırması ve kurulumu hakkında - eğer tasarıma dahil "" ""edileceklerse - daha fazla ayrıntı verir."" msgid """" ""The lack of a pre-defined usage model enables the user to run a wide variety "" ""of applications without having to know the application requirements in "" ""advance. This provides a degree of independence and flexibility that no "" ""other cloud scenarios are able to provide."" msgstr """" ""Ön tanımlı bir kullanım modelinin olmayışı kullanıcılara önceden uygulama "" ""gereksinimlerini bilmeden çok çeşitli uygulamaları çalıştırma imkanı verir. "" ""Bu diğer bulut senaryolarının sağlayamayacağı bir bağımsızlık ve esneklik "" ""derecesi sunar."" msgid """" ""The location of a service may also impact the application or consumer "" ""experience. If an application serves differing content to different users, "" ""it must properly direct connections to those specific locations. Where "" ""appropriate, use a multi-site installation for these situations."" msgstr """" ""Bir servisin konumu da uygulama veya müşteri deneyimini etkileyebilir. "" ""Uygulama farklı içeriği farklı kullanıcılara sunarsa, bu belirli konumlara "" ""bağlantıları düzgün yönlendirmelidir. Uygun olduğunda, bu gibi durumlar için "" ""çoklu konumlu bir kurulum yapın."" msgid """" ""The logs on the compute nodes, or any server running nova-compute (for "" ""example in a hyperconverged architecture), are the primary points for "" ""troubleshooting issues with the hypervisor and compute services. "" ""Additionally, operating system logs can also provide useful information."" msgstr """" ""Hesaplama düğümlerindeki günlük kayıtları, veya nova-compute çalıştıran "" ""herhangi bir sunucu (aşırı yakınsamalı bir mimarideki gibi) hipervizör ve "" ""hesaplama servisleriyle ilgili sorun gidermede birincil noktalardır. Ek "" ""olarak, işletim sistemi kayıtları da faydalı bilgi sağlayabilir."" msgid """" ""The main advantage of this option is that it scales to external storage when "" ""you require additional storage."" msgstr """" ""Bu seçeneğin temel avantajı ek deoplamaya ihtiyacınız olduğunda harici "" ""depolamaya ölçeklenebilmesidir."" msgid ""The main disadvantages to this approach are:"" msgstr ""Bu yaklaşımın temel dezavantajları şunlardır:"" msgid """" ""The main limitation of layer-3 networking is that there is no built-in "" ""isolation mechanism comparable to the VLANs in layer-2 networks. "" ""Furthermore, the hierarchical nature of IP addresses means that an instance "" ""is on the same subnet as its physical host, making migration out of the "" ""subnet difficult. For these reasons, network virtualization needs to use IP "" ""encapsulation and software at the end hosts. This is for isolation and the "" ""separation of the addressing in the virtual layer from the addressing in the "" ""physical layer. Other potential disadvantages of layer-3 networking include "" ""the need to design an IP addressing scheme rather than relying on the "" ""switches to keep track of the MAC addresses automatically, and to configure "" ""the interior gateway routing protocol in the switches."" msgstr """" ""Katman-3 ağın temel kısıtlaması katman-2 ağlardaki VLAN'larla "" ""karşılaştırılabilecek yerleşik bir yalıtım mekanizması olmamasıdır. Dahası, "" ""IP adreslerin sıra düzenli olması sebebiyle bir sunucunun fiziksel sunucuyla "" ""aynı alt ağda bulunması gerekeceğinden alt ağdan dışarı göç zorlaşır. Bu "" ""sebeplerle, ağ sanallaştırma IP kapsülleme ve uç sunucularda yazılım "" ""kullanmak zorundadır. Bu, sanal katmandaki adreslemeyle fiziksel katmandaki "" ""adreslemeyi yalıtmak içindir. Katman-3 ağın başka bir dezavantajı da "" ""anahtarların MAC adreslerini otomatik takip etmesine bel bağlamak yerine bir "" ""IP adresleme şeması tasarlamak gerekliliğidir, ayrıca anahtarlarda bir "" ""dahili geçit yönlendirme iletişim kuralı yapılandırılmalıdır."" msgid """" ""The main reason to use GFO rather than swift is if you also want to support "" ""a distributed file system, either to support shared storage live migration "" ""or to provide it as a separate service to your end users. If you want to "" ""manage your object and file storage within a single system, you should "" ""consider GFO."" msgstr """" ""Swift yerine GFO kullanmanın temel sebebi dağıtık bir dosya sistemini "" ""paylaşımlı depolama canlı göçünü desteklemek veya son kullanıcılarınıza ayrı "" ""bir servis olarak sunmak istediğiniz durumdur. Nesne ve dosya depolamanızı "" ""tek bir sistem içinde tutmak isterseniz, GFO kullanmayı düşünmelisiniz."" msgid """" ""The maintenance function of an operator should be taken into consideration:"" msgstr ""Bir işletmenin bakım işlevi dikkate alınmalıdır."" msgid """" ""The network architecture determines which network hardware will be used. "" ""Networking software is determined by the selected networking hardware."" msgstr """" ""Ağ mimarisi hangi ağ donanımının kullanılacağını belirler. Ağ yazılımı "" ""seçilen ağ donanımına göre belirlenir."" msgid """" ""The network design for an OpenStack cluster includes decisions regarding the "" ""interconnect needs within the cluster, the need to allow clients to access "" ""their resources, and the access requirements for operators to administrate "" ""the cluster. You should consider the bandwidth, latency, and reliability of "" ""these networks."" msgstr """" ""Bir OpenStack kümesi için ağ tasarımı kümeler arası bağlantı, istemcilerin "" ""kaynaklara erişimini sağlama, ve işletenlerin bulutu yönetmeleri için "" ""gerekli erişim gereksinimleri gibi kararları içerir. Bu ağların ağ "" ""genişliği, gecikme ve güvenilirliklerini göz önüne almalısınız."" msgid """" ""The network design should encompass a physical and logical network design "" ""that can be easily expanded upon. Network hardware should offer the "" ""appropriate types of interfaces and speeds that are required by the hardware "" ""nodes."" msgstr """" ""Ağ tasarımı kolaylıkla genişleyebilir fiziksel ve mantıksal ağ tasarımını "" ""kapsamalıdır. Ağ donanımı donanım düğümleri tarafından ihtiyaç duyulan "" ""arayüz türlerini ve hızları sağlayabilmelidir."" msgid """" ""The network design will be affected by the physical space that is required "" ""to provide the requisite port count. A higher port density is preferred, as "" ""it leaves more rack space for compute or storage components. This can also "" ""lead into considerations about fault domains and power density. Higher "" ""density switches are more expensive, therefore it is important not to over "" ""design the network."" msgstr """" ""Ağ tasarımı gerekli bağlantı noktası sayısını sağlamak için gerekli fiziksel "" ""alan tarafından da etkilenir. Yüksek bağlantı noktası yoğunluğu tercih "" ""edilir, çünkü bu hesaplama ve depolama bileşenlerine daha çok kabin alanı "" ""bırakır. Bu ayrıca arıza alanları ve güç yoğunluğuyla ilgili etmenlere "" ""götürebilir. Yüksek yoğunluklu anahtarlar daha pahalıdır, bu yüzden ağı "" ""gereğinden fazla tasrlamamak önemlidir."" msgid """" ""The network design, in this case, is less dependent on availability and more "" ""dependent on being able to handle high bandwidth. As a direct result, it is "" ""beneficial to forgo redundant links in favor of bonding those connections. "" ""This increases available bandwidth. It is also beneficial to configure all "" ""devices in the path, including OpenStack, to generate and pass jumbo frames."" msgstr """" ""Ağ tasarımı, bu durumda, kullanılırlığa daha az bağımlıdır, daha çok yüksek "" ""bant genişliğini ele almaya bağımlıdır. Bunun doğrudan bir sonucu olarak, bu "" ""bağlantıları bağlamak için yedekli bağlantılara yönelmek faydalıdır. Bu "" ""kullanılabilir bant genişliğini artırır. Ayrıca yoldaki tüm aygıtları, "" ""OpenStack dahil, jumbo çerçeveleri geçirecek ve üretecek şekilde "" ""yapılandırmak faydalı olacaktır."" msgid """" ""The network hardware selection needs to be supported by the logging, "" ""monitoring, and alerting software."" msgstr """" ""Ağ donanımı seçimi günlükleme, izleme ve uyarı yazılımı tarafından "" ""desteklenmelidir."" msgid """" ""The networking hardware must support the proposed network speed, for "" ""example: 1 GbE, 10 GbE, or 40 GbE (or even 100 GbE)."" msgstr """" ""Ağ donanımı teklif edilen ağ hızını desteklemelidir, örneğin: 1 GbE, 10 GbE, "" ""veya 40 GbE (hatta 100 GbE)."" msgid """" ""The number of CPU cores, how much RAM, or how much storage a given server "" ""delivers."" msgstr """" ""Sunucunun işlemci çekirdek sayısı, RAM miktarı veya ne kadar depola sunduğu."" msgid ""The number of MACs stored in switch tables is limited."" msgstr ""Anahtar tablolarında saklanan MAC sayısı sınırlıdır."" msgid """" ""The number of additional resources you can add to a server before it reaches "" ""capacity."" msgstr ""Kapasiteye ulaşmadan önce sunucuya ne kadar ek kaynak eklenebileceği."" msgid """" ""The number of cores that the CPU has also affects your decision. It is "" ""common for current CPUs to have up to 24 cores. Additionally, if an Intel "" ""CPU supports hyper-threading, those 24 cores are doubled to 48 cores. If you "" ""purchase a server that supports multiple CPUs, the number of cores is "" ""further multiplied."" msgstr """" ""İşlemcinin sahip olduğu çekirdek sayısıda kararınızı etkiler. Mevcut "" ""işlemcilerin 24 çekirdeğe kadar çıkması normaldir. Ek olarak, eğer Intel bir "" ""işlemci hyper-threading destekliyorsa, bu 24 çekirdek 48 çekirdeğe katlanır. "" ""Birden çok işlemcili bir sunucu alırsanız, çekirdek sayısı daha da "" ""artacaktır."" msgid """" ""The number of processor cores and threads impacts the number of worker "" ""threads which can be run on a resource node. Design decisions must relate "" ""directly to the service being run on it, as well as provide a balanced "" ""infrastructure for all services."" msgstr """" ""İşlemci çekirdek ve iş ipliği sayısı bir kaynak düğümünde kaç iş ipliği "" ""çalışabileceğini belirler. Tasarım kararı doğrudan üzerinde çalışacak servis "" ""ve tüm servisler için dengeli bir alt yapı sağlayarak ele alınmalıdır."" msgid """" ""The overlay functionality design includes OpenStack Networking in Open "" ""vSwitch GRE tunnel mode. In this case, the layer-3 external routers pair "" ""with VRRP, and switches pair with an implementation of MLAG to ensure that "" ""you do not lose connectivity with the upstream routing infrastructure."" msgstr """" ""Üst katman işlevi mimarisi Open vSwitch GRE tünel kipinde OpenStack Ağını "" ""içerir. Bu durumda, katman-3 harici yönlendiriciler VRRP ile eşleşir, ve "" ""anahtarlar üst alt yapıya yönlendirmede bağlantınızı kaybetmemeniz için MLAG "" ""uygulamasıyla eşleşirler."" msgid """" ""The overlay zone is defined as any L3 connectivity between the cloud "" ""components and could take the form of SDN solutions such as the neutron "" ""overlay solution or 3rd Party SDN solutions."" msgstr """" ""Üst katman bölgesi bulut bileşenleri arasındaki herhangi bir L3 bağlantısı "" ""gibi tanımlanır ve neutron üst katman çözümü veya 3. Kişi SDN çözümleri gibi "" ""SDN çözümleri biçiminde de olabilir."" msgid """" ""The power and cooling density requirements might be lower than with blade, "" ""sled, or 1U server designs due to lower host density (by using 2U, 3U or "" ""even 4U server designs). For data centers with older infrastructure, this "" ""might be a desirable feature."" msgstr """" ""Blade, sled veya 1U tasarımlarda sunucu yoğunluğunun az olmasından dolayı "" ""(2U, 3U hatta 4U sunucu tasarımlarını kullanarak) güç ve soğutma yoğunluğu "" ""gereksinimleri daha az olabilir. Eski alt yapıya sahip veri merkezlerinde bu "" ""istenen bir özellik olabilir."" msgid """" ""The remaining point on bandwidth is the public-facing portion. The ``swift-"" ""proxy`` service is stateless, which means that you can easily add more and "" ""use HTTP load-balancing methods to share bandwidth and availability between "" ""them. More proxies means more bandwidth."" msgstr """" ""Bant genişliği hakkındaki başka bir nokta açık taraftaki yüzle ilgilidir. "" ""``swift-proxy`` servisi durumsuzdur, yani kolaylıkla daha fazla "" ""ekleyebilirsiniz ve HTTP yük dengeleme yöntemlerini kullanarak bant "" ""genişliği ve kullanılabilirliği paylaştırabilirsiniz. Daha fazla vekil daha "" ""fazla bant genişliği demektir."" msgid """" ""The remaining services, responsible for create, read, update and delete "" ""(CRUD) operations, metering, monitoring, and so on, are often referred to as "" ""the Control Plane. The SLA is likely to dictate a lower uptime requirement "" ""for these services."" msgstr """" ""Oluşturma, okuma, güncelleme ve silme (CRUD), ölçme, izleme vs. den sorumlu "" ""geri kalan servislere Kontrol Düzlemi denir. SLA bu servisler için "" ""muhtemelen daha düşük bir hizmet süresi belirleyecektir."" msgid """" ""The replicator does not maintain desired levels of replication when other "" ""failures occur, such as entire node failures, because most failures are "" ""transient."" msgstr """" ""Çoğaltıcı diğer arıza durumlarında istenen yedekleme seviyelerini korumaz, "" ""örneğin tüm düğümün arızası durumunda, çünkü çoğu arıza geçicidir."" msgid """" ""The scheduling services are responsible for determining the compute or "" ""storage node where a virtual machine or block storage volume should be "" ""created. The scheduling services receive creation requests for these "" ""resources from the message queue and then begin the process of determining "" ""the appropriate node where the resource should reside. This process is done "" ""by applying a series of user-configurable filters against the available "" ""collection of nodes."" msgstr """" ""Zamanlama servisleri hesaplama veya depolama düğümünde bir sanal makinenin "" ""veya blok depolama biriminin nerde oluşturulması gerektiğine karar verir. "" ""Zamanlama servisleri ileti kuyruğundan bu kaynaklar için oluşturma istekleri "" ""alırlar ve kaynağın oluşturulması gereken uygun düğüme karar verme sürecini "" ""başlatırlar. Bu süreç kullanılabilir düğüm koleksiyonlarına kullanıcı "" ""tarafından yapılandırılabilen süzgeçlerin uygulanmasıyla yapılır."" msgid """" ""The selected server hardware must have the appropriate number of network "" ""connections, as well as the right type of network connections, in order to "" ""support the proposed architecture. Ensure that, at a minimum, there are at "" ""least two diverse network connections coming into each rack."" msgstr """" ""Seçili sunucu donanımı teklif edilen mimariyi destekleyebilmesi için uygun "" ""ağ bağlantısı sayısına ve doğru ağ bağlantısı türüne sahip olmalıdır. Emin "" ""olmak için her bir kabine en az iki ayrı ağ bağlantısının geldiğinden emin "" ""olun."" msgid """" ""The selection of form factors or architectures affects the selection of "" ""server hardware. Ensure that the selected server hardware is configured to "" ""support enough storage capacity (or storage expandability) to match the "" ""requirements of selected scale-out storage solution. Similarly, the network "" ""architecture impacts the server hardware selection and vice versa."" msgstr """" ""Biçim katsayılarının veya mimarilerin seçimi sunucu donanımı seçimini "" ""etkiler. Seçili sunucu donanımının seçili depolama ölçeklendirme çözümünün "" ""gereksinimleriyle eşleşerek yeterli depolama kapasitesini (veya depolamanın "" ""genişleyebilirliğini) destekleyecek şekilde yapılandırıldığından emin olun. "" ""Benzer şekilde, ağ mimarisi de sunucu donanımı seçimini etkiler, tersi de "" ""doğrudur."" msgid """" ""The selection of storage hardware determines the overall performance and "" ""scalability of a storage-focused OpenStack design architecture. Several "" ""factors impact the design process, including:"" msgstr """" ""Depolama donanımının seçimi depolama odaklı bir OpenStack tasarım "" ""mimarisinin genel başarımını ve ölçeklenebilirliğini etkiler. Tasarım "" ""sürecini bir çok etmen etkiler, bazıları:"" msgid """" ""The services comprising an OpenStack cloud have a number of requirements "" ""that you need to understand in order to be able to meet SLA terms. For "" ""example, in order to provide the Compute service a minimum of storage, "" ""message queueing and database services are necessary as well as the "" ""networking between them."" msgstr """" ""Bir OpenStack bulutundan oluşan servislerin SLA koşullarını karşılamak için "" ""anlamanız gereken bir takım gereksinimleri olabilir. Örneğin, Hesaplama "" ""servisine asgari depolama sağlamak için, mesaj kuyruklama ve veritabanı "" ""servisleri ve aralandaki ağ zorunludur."" msgid ""The solution would consist of the following OpenStack components:"" msgstr ""Çözüm şu OpenStack bileşenlerinden oluşurdu:"" msgid """" ""The supporting network for this type of configuration needs to have a low "" ""latency and evenly distributed availability. This workload benefits from "" ""having services local to the consumers of the service. Use a multi-site "" ""approach as well as deploying many copies of the application to handle load "" ""as close as possible to consumers. Since these applications function "" ""independently, they do not warrant running overlays to interconnect tenant "" ""networks. Overlays also have the drawback of performing poorly with rapid "" ""flow setup and may incur too much overhead with large quantities of small "" ""packets and therefore we do not recommend them."" msgstr """" ""Bu tür bir yapılandırmada destek ağının düşük gecikmeye ve eşit dağıtılmış "" ""kullanılırlığa sahip olması gerekir. Bu iş yükü servislerin servisleri "" ""kullananlara yakın olmasından faydalanır. Yükü kullanıcılara olabildiğince "" ""yakın tutmak için farklı konumlar yaklaşımı yanında uygulamanın "" ""olabildiğince fazla kopyasını dağıtarak muhtemel tüketicilere olabildiğince "" ""yakınlaşın. Bu işlevler bağımsız çalıştıklarından, çalışan üst katmanların "" ""kiracı ağlarla dahili bağ kuracaklarını garantilemezler. Üst katmanlar ani "" ""akış kurulumuyla başarısız çalışabilir ve yüksek sayıda küçük paket olan "" ""durumlarda fazla ek yük bindirebilirler bu yüzden tavsiye etmiyoruz."" msgid """" ""The three main approaches to instance storage are provided in the next few "" ""sections."" msgstr """" ""Sunucu depolamayla ilgili üç ana yaklaşım sonraki kısımlarda anlatılmıştır."" msgid """" ""The type of CPU in your compute node is a very important decision. You must "" ""ensure that the CPU supports virtualization by way of *VT-x* for Intel chips "" ""and *AMD-v* for AMD chips."" msgstr """" ""Hesaplama düğümünüzdeki işlemcinin türü çok önemli bir karardır. İşlemcinin "" ""Intel çipler için *VT-x* ve AMD çipler için *AMD-v* yoluyla sanallaştırmayı "" ""desteklediğinden emin olun."" msgid """" ""The underlay zone is defined as the physical network switching "" ""infrastructure that connects the storage, compute and control platforms. "" ""There are a large number of potential underlay options available."" msgstr """" ""Altkatman bölgesi depolama, hesaplama ve kontrol platformlarını bağlayan "" ""fiziksel ağ anahtarlama alt yapısı olarak tanımlanır. Çok sayıda altkatman "" ""seçeneği kullanılabilirdir."" msgid """" ""The web application instances run from local storage on each of the "" ""OpenStack Compute nodes. The web application instances are stateless, "" ""meaning that any of the instances can fail and the application will continue "" ""to function."" msgstr """" ""Web uygulaması sunucuları her bir OpenStack Hesaplama düğümünde yerel "" ""depolamadan çalışıyor. Web uygulaması sunucuları durumsal değil, yani "" ""sunuculardan herhangi biri arızalanabilir ve uygulama çalışmaya devam "" ""edecektir."" msgid """" ""There are a small number of OpenStack services which are intended to only "" ""run in one place at a time (for example, the ``ceilometer-agent-central`` "" ""service) . In order to prevent these services from becoming a single point "" ""of failure, they can be controlled by clustering software such as "" ""``Pacemaker``."" msgstr """" ""Yalnızca tek bir yerde çalışması gereken küçük sayıda OpenStack servisi "" ""bulunur (örneğin, ``ceilometer-agent-central`` servisi). Bu servislerin "" ""kırılma noktasına dönüşmesini engellemek için, ``Pacemaker`` gibi kümeleme "" ""yazılımı ile kontrol edebilirsiniz."" msgid """" ""There are a variety of well tested tools, such as Internet Control Message "" ""Protocol (ICMP) to monitor and manage traffic."" msgstr """" ""Trafiği izlemek ve yönetmek için İnternet Kontrol İletisi İletişim Kuralı "" ""(ICMP) gibi çok iyi denenmiş araçlar bulunur."" msgid """" ""There are additional risks that arise from configuring the cloud network to "" ""take advantage of vendor specific features. One example is multi-link "" ""aggregation (MLAG) used to provide redundancy at the aggregator switch level "" ""of the network. MLAG is not a standard and, as a result, each vendor has "" ""their own proprietary implementation of the feature. MLAG architectures are "" ""not interoperable across switch vendors, which leads to vendor lock-in, and "" ""can cause delays or inability when upgrading components."" msgstr """" ""Bulut ağını üreticiye özel özellikleri kullanacak şekilde yapılandırmanın ek "" ""riskleri vardır. Bir örnek çoklu bağlantı toplama (MLAG) kullanarak ağın "" ""anahtar seviyesinde toplama yapmaktır. MLAG standart değildir, yani her "" ""üreticinin bu özelliği kendine has uygulaması vardır. MLAG mimariler anahtar "" ""üreticiler arasında eş çalıştırılabilir değildir, bu da belli üreticiye "" ""kitlenmeye sebep olur, ve bileşenler yükseltilirken gecikmelere veya "" ""engellemeye yol açar."" msgid """" ""There are also output filters available that send event data to many "" ""different destinations. Some examples are:"" msgstr """" ""Olay verisini bir çok hedefe gönderek çıktı süzgeçleri de bulunur. Bazı "" ""örnekler:"" msgid """" ""There are currently two schedulers: ``nova-scheduler`` for virtual machines "" ""and ``cinder-scheduler`` for block storage volumes. Both schedulers are able "" ""to scale horizontally, so for high-availability purposes, or for very large "" ""or high-schedule-frequency installations, you should consider running "" ""multiple instances of each scheduler. The schedulers all listen to the "" ""shared message queue, so no special load balancing is required."" msgstr """" ""Mevcut iki zamanlayıcı bulunur: sanal makineler için ``nova-scheduler`` ve "" ""blok depolama birimleri için ``cinder-scheduler``. Her iki zamanlayıcı da "" ""yatay ölçeklenebilirdir, yani yüksek kullanılırlık için, veya çok büyük veya "" ""yüksek zamanlama sıklığındaki kurulumlar için, her bir zamanlayıcıdan birden "" ""fazla çalıştırmayı düşünmelisiniz. Zamanlayıcılar paylaşımlı ileti kuyruğunu "" ""dinlerler, yani özel bir yük dengelemeye gerek yoktur."" msgid """" ""There are many different storage architectures available when designing an "" ""OpenStack cloud. The convergence of orchestration and automation within the "" ""OpenStack platform enables rapid storage provisioning without the hassle of "" ""the traditional manual processes like volume creation and attachment."" msgstr """" ""OpenStack bulutu tasarlarken kullanılabilecek çok sayıda farklı depolama "" ""mimarileri bulunur. OpenStack platformundaki orkestrasyon ve otomasyonun "" ""birleşimi geleneksel elle işletilen birim oluşturma ve ekleme gibi "" ""süreçlerden kurtulmanızı sağlar."" msgid """" ""There are many reasons an OpenStack network has complex requirements. One "" ""main factor is that many components interact at different levels of the "" ""system stack. Data flows are also complex."" msgstr """" ""Bir OpenStack ağının karmaşık gereksinimleri olmasının bir çok sebebi "" ""vardır. Ana etmenlerden biri de bir çok bileşenin sistem yığınıyla farklı "" ""seviyelerde iletişime geçmesidir. Veri akışları da karmaşıktır."" msgid """" ""There are many services outside the realms of pure OpenStack code which "" ""affects the ability of a cloud design to meet SLAs, including:"" msgstr """" ""OpenStack kodu alanı dışında kalan ve bulut tasarımının SLA'ları "" ""karşılamasını etkileyebilecek bir çok servis bulunur, bazıları:"" msgid """" ""There are more subtle design impacts that need to be considered. The "" ""selection of certain networking hardware (and the networking software) "" ""affects the management tools that can be used. There are exceptions to this; "" ""the rise of *open* networking software that supports a range of networking "" ""hardware means there are instances where the relationship between networking "" ""hardware and networking software are not as tightly defined."" msgstr """" ""Ele alınması gereken göze pek çarpmayan tasarım etkenleri bulunur. Belirli "" ""ağ donanımının seçilmesi (ve yazılımının) kullanılabilecek yönetim "" ""araçlarını da etkiler. Buna istisnalar da bulunur; geniş aralıkta ağ "" ""donanımını destekleyen *açık* ağ yazılımının yükselişi ağ donanımı ile ağ "" ""yazılımının sıkı sıkıya tanımlanmadığı durumların da olduğu anlamına geliyor."" msgid ""There are several advantages to this approach:"" msgstr ""Bu yaklaşımın bir çok avantajı bulunur:"" msgid ""There are several disadvantages:"" msgstr ""Bir çok dezavantaj bulunur:"" msgid """" ""There are several factors to take into consideration when deciding on "" ""whether to use Layer 2 networking architecture or a layer 3 networking "" ""architecture. For more information about OpenStack networking concepts, see "" ""the `OpenStack Networking <https://docs.openstack.org/ocata/networking-guide/"" ""intro-os-networking.html#>`_ section in the OpenStack Networking Guide."" msgstr """" ""Katman 2 ağ mimarisi veya katman 3 ağ mimarisi seçerken hesaba katılması "" ""gereken çeşitli etmenler bulunur. OpenStack ağ kavramlarıyla ilgili daha "" ""fazla bilgi için OpenStack Ağ Kılavuzundaki `OpenStack Ağı <https://docs."" ""openstack.org/ocata/networking-guide/intro-os-networking.html#>`_ kısmına "" ""göz atın."" msgid """" ""There are several other considerations when designing a network-focused "" ""OpenStack cloud."" msgstr """" ""Ağ odaklı OpenStack bulutu tasarlarken ele alınacak bir çok etmen bulunur."" msgid """" ""There are several reasons a network designed on layer-2 protocols is "" ""selected over a network designed on layer-3 protocols. In spite of the "" ""difficulties of using a bridge to perform the network role of a router, many "" ""vendors, customers, and service providers choose to use Ethernet in as many "" ""parts of their networks as possible. The benefits of selecting a layer-2 "" ""design are:"" msgstr """" ""Katman-2 iletişim kurallarıyla tasarlanan bir ağın katman-3 ile "" ""tasarlananlara tercih edilmesinin çeşitli sebepleri vardır. Bir "" ""yönlendiricinin ağ rolünü üstlenmesi için köprü kullanmanın zorluklarına "" ""rağmen, çoğu üretici müşteriler ve servis sağlayıcılar ağlarının "" ""olabildiğince çok bölümünde Ethernet kullanmayı terchi ederler. Katman-2 "" ""tasarımını seçmenin faydaları şunlardır:"" msgid """" ""There are some specific configuration parameters that are needed to "" ""configure Logstash for OpenStack. For example, in order to get Logstash to "" ""collect, parse, and send the correct portions of log files to the "" ""Elasticsearch server, you need to format the configuration file properly. "" ""There are input, output and filter configurations. Input configurations tell "" ""Logstash where to recieve data from (log files/forwarders/filebeats/StdIn/"" ""Eventlog), output configurations specify where to put the data, and filter "" ""configurations define the input contents to forward to the output."" msgstr """" ""OpenStack için Logstash yapılandırılması için gereken belirli yapılandırma "" ""parametreleri bulunur. Örneğin Logstash'in günlük kayıtlarının doğru "" ""kısımlarını toplayıp ayrıştırıp Elasticsearch sunucusuna gönderebilmesi "" ""için, yapılandırma dosyasını düzgün biçimlendirmelisiniz. Girdi, çıktı ve "" ""süzgeç yapılandırmaları bulunur. Girdi yapılandırmaları Logstash'e verinin "" ""nerden alınacağını söyler (kayıt dosyası/yönlendiriciler/filebeat/StdIn/Olay "" ""kaydı), çıktı yapılandırmaları verinin nereye konacağını belirtir, süzgeç "" ""yapılandırmaları çıktıya yönlendirilecek girdi içeriğini tanımlar."" msgid """" ""There are special considerations around erasure coded pools. For example, "" ""higher computational requirements and limitations on the operations allowed "" ""on an object; erasure coded pools do not support partial writes."" msgstr """" ""Bunlar silinti kodlu havuzlarla ilgili özel etmenlerdir. Örneğin, yüksek "" ""hesaplama gereksinimleri ve bir nesne üzerinde izin verilen işlemlerin "" ""sınırlandırılması; silinti kodlu havuzlar kısmi yazmaları desteklemez."" msgid ""There are two main advantages:"" msgstr ""İki temel avantaj bulunur:"" msgid """" ""There are two major classes of replicator: the db replicator, which "" ""replicates accounts and containers, and the object replicator, which "" ""replicates object data."" msgstr """" ""İki ana çoğaltıcı sınıfı bulunur; db çoğaltıcı, hesapları ve kapsayıcıları "" ""yedekler, ve nesne çoğaltıcı, nesne verisini yedekler."" msgid """" ""There are two primary types of traffic flow within a cloud infrastructure, "" ""the choice of networking technologies is influenced by the expected loads."" msgstr """" ""Bir bulut altyapısında iki temel trafik akış türü bulunur, ağ "" ""teknolojilerinin seçimi beklenen yüke göre yapılır."" msgid """" ""There are various commodity storage back end technologies available. "" ""Depending on your cloud user's needs, you can implement one or many of these "" ""technologies in different combinations."" msgstr """" ""Çok çeşitli ticari depolama arka uç teknolojileri bulunur. Bulut "" ""kullanıcılarınızın ihtiyaçları doğrultusunda, bu teknolojilerden birini ya "" ""da bir kaçını değişik birleştirmelerle uygulayabilirsiniz."" msgid """" ""There is a trend for cloud operations systems being hosted within the cloud "" ""environment. Operators require access to these systems to resolve a major "" ""incident."" msgstr """" ""Bulut işletme sistemlerinin bulut ortamında tutulması eğilimi bulunmaktadır. "" ""Büyük bir hadise olması durumunda çözüm için işletenlerin bu sistemlere "" ""erişebilmesi gerekir."" msgid """" ""There is no single best practice architecture for the networking hardware "" ""supporting an OpenStack cloud. Some of the key factors that will have a "" ""major influence on selection of networking hardware include:"" msgstr """" ""OpenStack bulutunu destekleyen ağ donanımı için üstün tek bir yöntem yoktur. "" ""Ağ donanımı seçiminde önemli rol oynayacak olan bazı etmenler şunlardır:"" msgid """" ""Therefore, we recommend that host aggregates are used to separate not only "" ""bare metal hosts, but hosts that will provide resources for workloads that "" ""require dedicated resources. This said, when workloads are provisioned to "" ""NUMA host aggregates, NUMA nodes are chosen at random and vCPUs can float "" ""across NUMA nodes on a host. If workloads require SR-IOV or DPDK, they "" ""should be assigned to a NUMA node aggregate with hosts that supply the "" ""functionality. More importantly, the workload or vCPUs that are executing "" ""processes for a workload should be on the same NUMA node due to the limited "" ""amount of cross-node memory bandwidth. In all cases, the "" ""``NUMATopologyFilter`` must be enabled for ``nova-scheduler``."" msgstr """" ""Yani sunucu takımlarının sadece saf metal sunucuları değil, adanmış "" ""kaeynakları gerektiren iş yükleri için kaynak sağlayan sunucuları da ayırmak "" ""için kullanılmasını öneriyoruz. Bununla beraber, iş yükleri NUMA sunucu "" ""takımlarına hazırlandıklarında, NUMA düğümleri rasgele seçilir ve vCPU'lar "" ""sunucu üstündeki NUMA düğümleri arasında kayabilirler. İş yükleri SR-IOV "" ""veya DPDK gerektiriyorsa, özelliği destekleyen sunuclardaki NUMA düğüm "" ""takımına atanmalıdırlar. Daha da önemlisi, iş yükleri ya da iş yükleri için "" ""süreçleri çalıştıran vCPU'lar düğümler arası kısıtlı hafıza bant genişliği "" ""yüzünden aynı NUMA düğümünde olmalıdırlar. Her halükarda, ``nova-scheduler`` "" ""için ``NUMATopologyFilter`` etkin olmalıdır."" msgid """" ""These drivers work a little differently than a traditional block storage "" ""driver. On an NFS or GlusterFS file system, a single file is created and "" ""then mapped as a virtual volume into the instance. This mapping and "" ""translation is similar to how OpenStack utilizes QEMU's file-based virtual "" ""machines stored in ``/var/lib/nova/instances``."" msgstr """" ""Bu sürücüler geleneksel blok depolama sürücülerine göre biraz farklı "" ""çalışırlar. NFS veya GlusterFS dosyas sisteminde, tek bir dosya oluşturulur "" ""ve sanal birim olarak sunucuya eşleştirilir. Bu eşleştirme ve çevrim "" ""OpenStack'in QEMU'nun ``/var/lib/nova/instances`` dizininde tutulan dosya "" ""tabanlı sanal makineleri kullanmasına benzer."" msgid """" ""These input, output and filter configurations are typically stored in :file:"" ""`/etc/logstash/conf.d` but may vary by linux distribution. Separate "" ""configuration files should be created for different logging systems such as "" ""syslog, Apache, and OpenStack."" msgstr """" ""Bu girdi, çıktı ve süzgeç yapılandırmaları genellikle :file:`/etc/logstash/"" ""conf.d` dizininde saklanır ama linux dağıtımına göre bu konum değişebilir. "" ""Syslog, Apache, ve OpenStack gibi farklı kayıt sistemleri için ayrı "" ""yapılandırma dosyaları oluşturulmalıdır."" msgid """" ""This application prioritizes the north-south traffic over east-west traffic: "" ""the north-south traffic involves customer-facing data."" msgstr """" ""Bu uygulama kuzey-güney trafiği doğu-batı trafiğe göre öncelik edinir: kuzey-"" ""güney trafiği müşteriye dönük veriyi içerir."" msgid """" ""This chapter describes the enterprise and operational factors that impacts "" ""the design of an OpenStack cloud."" msgstr """" ""Bu bölüm bir OpenStack bulutun tasarımını etkileyen kurumsal ve işlevsel "" ""etmenleri tanımlar."" msgid """" ""This deployment felt that the spare I/O on the Object Storage proxy server "" ""was sufficient and that the Image Delivery portion of glance benefited from "" ""being on physical hardware and having good connectivity to the Object "" ""Storage back end it was using."" msgstr """" ""Bu kurulum Nesne Depolama vekil sunucusundaki yedek I/O'nun yeterli olduğunu "" ""ve glance'in İmaj Aktarım kısmının fiziksel donanımda olmaktan "" ""faydalandığını ve kullandığı Nesne Depolamayla iyi bağlantısı olduğunu "" ""hissetti."" msgid """" ""This deployment had an expensive hardware load balancer in its organization. "" ""It ran multiple ``nova-api`` and ``swift-proxy`` servers on different "" ""physical servers and used the load balancer to switch between them."" msgstr """" ""Bu kurulum kurumundaki pahalı donanımsal yük dengeleyiciye sahipti. Farklı "" ""fiziksel sunucularda birden çok ``nova-api`` ve ``swift-proxy``sunucusu "" ""çalıştırdı ve yük dengeleyici ile birbirleri arasında geçişi sağladı."" msgid """" ""This deployment ran central services on a set of servers running KVM. A "" ""dedicated VM was created for each service (``nova-scheduler``, rabbitmq, "" ""database, etc). This assisted the deployment with scaling because "" ""administrators could tune the resources given to each virtual machine based "" ""on the load it received (something that was not well understood during "" ""installation)."" msgstr """" ""Bu kurulum KVM çalıştıran sunucu kümesi üzerinde merkezi servisleri "" ""çalıştırdı. Her bir servis için adanmış bir sanal makine oluşturuldu (``nova-"" ""scheduler``, rabbitmq, veritabanı, vs). Bu kurulumun ölçeklenmesinde faydalı "" ""oldu çünkü yöneticiler her bir sanal makineye aldığı yük oranında kaynak "" ""ayarlayabiliyorlardı (kurulum sırasında tam anlaşılmamış bir şeydi)."" msgid """" ""This deployment used a central dedicated server to provide the databases for "" ""all services. This approach simplified operations by isolating database "" ""server updates and allowed for the simple creation of slave database servers "" ""for failover."" msgstr """" ""Bu kurulum tüm servislere veritabanı sağlamak için merkezi adanmış bir "" ""sunucu kullandı. Bu yaklaşım veritabanı sunucu güncellemelerini yalıtarak "" ""işlemleri ve problem halinde kullanılacak köle veritabanı sunucuların "" ""oluşturulmasını basitleştirdi."" msgid ""This example uses the following components:"" msgstr ""Bu örnek aşağıdaki bileşenleri kullanır:"" msgid ""This guide is a work in progress. Contributions are welcome."" msgstr ""Bu kılavuz üstünde hala çalışılıyor. Katkılarınız hoş karşılanır."" msgid ""This guide targets OpenStack Architects for architectural design"" msgstr ""Bu kılavuz OpenStack Mimarlarını mimari tasarım için hedefler"" msgid """" ""This is not an issue for top of rack (ToR) switches. This may be an issue "" ""for spine switches in a leaf and spine fabric, or end of row (EoR) switches."" msgstr """" ""Bu kabin üstü (ToR) anahtarlar için sorun değildir. Bu yaprak ve omurga "" ""iskeletindeki, veya sıra sonundaki (EoR) anahtarlar için sorun olabilir."" msgid """" ""This list expands upon the potential impacts for including a particular "" ""storage architecture (and corresponding storage hardware) into the design "" ""for a general purpose OpenStack cloud:"" msgstr """" ""Bu liste genel amaçlı bir OpenStack bulut tasarımına belirli bir depolama "" ""mimarisini (ve ilişkili depolama donanımını) katmanın potansiyel etkilerini "" ""genişletir."" msgid """" ""This list of open source file-level shared storage solutions is not "" ""exhaustive. Your organization may already have deployed a file-level shared "" ""storage solution that you can use."" msgstr """" ""Bu açık kaynak dosya-seviyesi paylaşım depolama çözümleri kapsamlı değil. "" ""Kurumunuz zaten kullanabileceğiniz dosya seviyesinde paylaşımlı depolama "" ""çözümü kurmuş olabilir."" msgid """" ""This may also require a CMP that can determine which cloud can most "" ""efficiently run which types of workloads."" msgstr """" ""Bu ayrıca hangi bulutun ne tür iş yüklerini etkin çalıştırabildiğini "" ""tanımlayabilen bir CMP gerektirebilir."" msgid """" ""This may cause issues for organizations that have preferred vendor policies "" ""or concerns with support and hardware warranties of non-tier 1 vendors."" msgstr """" ""Bu da belirli üretici ilkeleri olan veya birinci kat olmayan üreticilerle "" ""ilgili donanım garantisi ve desteği endişeleri olan kurumlar için sorun "" ""yaratabilir."" msgid """" ""This section describes operational factors affecting the design of an "" ""OpenStack cloud."" msgstr """" ""Bu kısım bir OpenStack bulutunun tasarımını etkileyen işlevsel etmenleri "" ""tanımlar."" msgid """" ""This section describes some of the choices you need to consider when "" ""designing and building your compute nodes. Compute nodes form the resource "" ""core of the OpenStack Compute cloud, providing the processing, memory, "" ""network and storage resources to run instances."" msgstr """" ""Bu kısım hesaplama düğümlerinizi tasarlarken ve inşa ederken hesaba katmanız "" ""gereken bazı seçimleri tanımlar. Hesaplama düğümleri OpenStack Hesaplama "" ""bulutunun kaynak çekirdeğini biçimlendirir, sunucularınız çalıştırmak için "" ""işleme, hafıza, ağ ve depolama kaynaklarını sağlar."" msgid """" ""This system can provide additional performance. For example, in the database "" ""example below, a portion of the SSD pool can act as a block device to the "" ""Database server. In the high performance analytics example, the inline SSD "" ""cache layer accelerates the REST interface."" msgstr """" ""Bu sistem ek başarım sağlayabilir. Örneğin aşağıdaki veritabanı örneğinde "" ""SSD havuzunun bir kısmı Veritabanı sunucusu için blok aygıtı olarak "" ""davranabilir. Yüksek başarımlı çözümleme örneğinde, SSD önbellek katmanı "" ""REST arayüzünü hızlandırır."" msgid ""Throughput"" msgstr ""İşlem hacmi"" msgid """" ""Time synchronization is a critical element to ensure continued operation of "" ""OpenStack components. Ensuring that all components have the correct time is "" ""necessary to avoid errors in instance scheduling, replication of objects in "" ""the object store, and matching log timestamps for debugging."" msgstr """" ""Zaman eşzamanlama OpenStack bileşenlerinin çalışması için ciddi öneme "" ""sahiptir. Tüm bileşenlerin doğru zamana sahip olduğundan emin olmak sunucu "" ""zamanlamada, nesnelerin nesne deposunda yedeklenmesinde, ve günlük "" ""kayıtlarının hata ayıklama için zaman damgalarının eşleştirilmesinde "" ""önemlidir."" msgid ""Time-to-market"" msgstr ""Pazara sürme süresi"" msgid ""To calculate IOPS for a single drive you could use:"" msgstr ""Tek bir sürücü için IOPS hesaplamak için şunu kullanabilirsiniz:"" msgid ""To calculate maximum IOPS for a disk array:"" msgstr ""Bir disk dizisi için azami IOPS hesaplamak için:"" msgid """" ""To deploy your storage by using only commodity hardware, you can use a "" ""number of open-source packages, as described in :ref:"" ""`table_persistent_file_storage`."" msgstr """" ""Depolamanızı yalnızca ticari donanımla kurmak için, :ref:"" ""`table_persistent_file_storage` tablosunda tanımlandığı gibi bir takım açık "" ""kaynak paketleri kullanabilirsiniz."" msgid """" ""To design, deploy, and configure OpenStack, administrators must understand "" ""the logical architecture. OpenStack modules are one of the following types:"" msgstr """" ""OpenStack tasarlamak, kurmak ve yapılandırmak için yöneticiler mantıksal "" ""mimariyi anlamalıdır. OpenStack modülleri şu türlerden birindedir:"" msgid """" ""To effectively run cloud installations, initial downtime planning includes "" ""creating processes and architectures that support planned maintenance and "" ""unplanned system faults."" msgstr """" ""Bulut kurulumlarını etkin şekilde çalıştırmak için, arıza süresi planlama "" ""planlı bakım ve plansız sistem hatalarını destekleyen mimariler ve süreçler "" ""oluşturmayı içerir."" msgid """" ""To ensure access to nodes within the cloud is not interrupted, we recommend "" ""that the network architecture identifies any single points of failure and "" ""provides some level of redundancy or fault tolerance. The network "" ""infrastructure often involves use of networking protocols such as LACP, VRRP "" ""or others to achieve a highly available network connection. It is also "" ""important to consider the networking implications on API availability. We "" ""recommend a load balancing solution is designed within the network "" ""architecture to ensure that the APIs and potentially other services in the "" ""cloud are highly available."" msgstr """" ""Buluttaki düğümlere erişimin kesilmediğinden emin olmak için, ağ mimarisinin "" ""tüm kırılma noktalarını tanımladığından ve belirli seviyede yedekleme veya "" ""hata toleransı sağladığından emin olunmasını öneriyoruz. Ağ mimarisi "" ""çoğunlukla LACP, VRRP veya diğerleri gibi ağ iletişim kuralları kullanarak "" ""yüksek kullanılırlıklı ağ bağlantıları elde eder. Ağ durumunun API "" ""kullanılırlığına etkisi de göz önünde bulundurulmalıdır. API ve diğer "" ""servislerin yüksek kullanılırlığı için bir yük dengeleme çözümünün de "" ""tasarlanmasını öneriyoruz."" msgid """" ""To obtain greater than dual-socket support in a 1U rack-mount form factor, "" ""customers need to buy their systems from Original Design Manufacturers "" ""(ODMs) or second-tier manufacturers."" msgstr """" ""1U kabine-bağlı biçim katsayısında çift-soket desteğinden fazlasını elde "" ""etmek için, müşteriler sistemlerini Asıl Tasarım Üreticilerinden (ODM'ler) "" ""ya da ikinci katman üreticilerden almalıdırlar."" msgid """" ""To segregate traffic, allow applications to create a private tenant network "" ""for database and storage network traffic. Use a public network for services "" ""that require direct client access from the Internet. Upon segregating the "" ""traffic, consider :term:`quality of service (QoS)` and security to ensure "" ""each network has the required level of service."" msgstr """" ""Trafiği ayırmak için, uygulamaların depolama ve veritabanı trafiği için özel "" ""kiracı ağı oluşturmalarına izin verin. İnternetten doğrudan istemci "" ""erişimine izin gerektiren servisler için açık bir ağ kullanın. Trafiği "" ""ayırdıktan sonra, her ağın gerekli servis seviyesine sahip olduğundan emin "" ""olmak için :term:`servis kalitesini (QoS)` göz önüne alın."" msgid ""Tolerant to rack level failure."" msgstr ""Kabin seviyesinde arızalara dayanıklılık."" msgid """" ""Tracks current information about users and instances, for example, in a "" ""database, typically one database instance managed per service"" msgstr """" ""Kullanıcılar ve sunucularla ilgili mevcut bilgiyi takip eder, örneğin bir "" ""veritabanında, genellikle servis başına bir veritabanı sunucusu yönetilir"" msgid """" ""Traditionally, replication has been the best method of protecting object "" ""store implementations. A variety of replication methods exist in storage "" ""architectures, for example synchronous and asynchronous mirroring. Most "" ""object stores and back-end storage systems implement methods for replication "" ""at the storage subsystem layer. Object stores also tailor replication "" ""techniques to fit a cloud's requirements."" msgstr """" ""Geleneksel olarak, çoğaltma, nesne depolama uygulamalarını korumanın en iyi "" ""yöntemi olmuştur. Depolama mimarilerinde bir takım çoğaltma yöntemi vardr, "" ""örneğin senkron ya da asenkron yansılama. Çoğu nesne depolama ve arka uç "" ""depolama sistemleri deoplama alt sistem katmanında çoğaltma yöntemlerini "" ""uygularlar. Nesne depoları ayrıca çoğaltma tekniklerini bulut "" ""gereksinimlerine uyacak şekilde uydururlar."" msgid ""Traffic flow"" msgstr ""Trafik akışı"" msgid ""Underlay"" msgstr ""Altkatman"" msgid """" ""Upgrading, patching, and changing configuration items may require downtime "" ""for some services. Stopping services that form the Control Plane may not "" ""impact the Data Plane. Live-migration of Compute instances may be required "" ""to perform any actions that require downtime to Data Plane components."" msgstr """" ""Yükseltme, yamalama, ve yapılandırma ögelerinin değiştirilmesi bazı "" ""servisler için kesinti zamanı gerektirebilir. Kontrol Düzlemini oluşturan "" ""servisleri durdurmak Veri Düzlemini etkilemeyebilir. Veri Düzlemi "" ""bileşenlerinin kesintisini gerektiren herhangi bir eylemde Hesaplama "" ""sunucularının canlı göçü gerekli olabilir."" msgid ""Usage"" msgstr ""Kullanım"" msgid """" ""Use External Border Gateway Protocol (eBGP) to connect to the Internet up-"" ""link."" msgstr """" ""İnternet bağlantısına bağlanmak için Harici Sınır Geçit İletişim Kuralı "" ""(eBGP) kullanın."" msgid """" ""Use Internal Border Gateway Protocol (iBGP) to flatten the internal traffic "" ""on the layer-3 mesh."" msgstr """" ""Dahili trafiği katman-3 örgüsünde düzleştirmek için Dahili Sınır Geçit "" ""İletişim Kuralı (iBGP) kullanın."" msgid ""Use an external load balancer."" msgstr ""Harici yük dengeleyici kullan."" msgid ""Use cases"" msgstr ""Kullanım durumları"" msgid """" ""Use hierarchical addressing because it is the only viable option to scale a "" ""network ecosystem."" msgstr """" ""Sıra düzenli adresleme kullanın çünkü bir ağ ekosistemini ölçeklemek için "" ""uygulanabilir tek seçenek odur."" msgid """" ""Use of DAS impacts the server hardware choice and affects host density, "" ""instance density, power density, OS-hypervisor, and management tools."" msgstr """" ""DAS kullanımı sunucu donanımı seçimini ve sunucu yoğunluğu, güç yoğunluğu, "" ""OS-hipervizörü, ve yönetim araçlarını etiler"" msgid ""Use of the network can decrease performance."" msgstr ""Ağın kullanımı başarımı düşürebilir."" msgid ""Use traffic shaping for performance tuning."" msgstr ""Başarım artırma için trafik şekillendirmeyi kullanın."" msgid """" ""Use virtual networking to isolate instance service network traffic from the "" ""management and internal network traffic."" msgstr """" ""Sanal ağ kullanarak sunucu servis ağını yönetim ve dahili ağ trafiğinden "" ""ayırın."" msgid ""User dashboard"" msgstr ""Kullanıcı kontrol paneli"" msgid """" ""User requirements for high availability and cost considerations influence "" ""the level of network hardware redundancy. Network redundancy can be achieved "" ""by adding redundant power supplies or paired switches."" msgstr """" ""Yüksek kullanılırlık ve masraf etmenleri için kullanıcı gereksinimleri ağ "" ""donanımı yedekliliğinin seviyesini etkiler. Ağ yedekliliği eşleşen "" ""anahtarlar veya yedekli güç kaynakları ekleyerek elde edilebilir."" msgid ""User specification in initial request"" msgstr ""İlk istekte kullanıcı tanımı"" msgid """" ""Users interact with the Shared File Systems service by mounting remote file "" ""systems on their instances with the following usage of those systems for "" ""file storing and exchange. The Shared File Systems service provides shares "" ""which is a remote, mountable file system. You can mount a share and access a "" ""share from several hosts by several users at a time. With shares, you can "" ""also:"" msgstr """" ""Kullanıcılar Paylaşımlı Dosya Sistemleri servisi ile uzak dosya sistemlerini "" ""kendi sunucularına bu sistemlerin şu şekilde, dosya depolama ve değişimi "" ""için kullanmak için bağlayarak etkileşirler. Paylaşımlı Dosya Sistemleri "" ""servisi uzak, bağlanabilir dosya sistemi olan paylaşımlar sağlar. Bir "" ""paylaşımı bağlayabilir ve bir çok sunucudan bir çok kullanıcı ile aynı anda "" ""erişebilirsiniz. Paylaşımlarla ayrıca şunları yapabilirsiniz:"" msgid """" ""Users will indicate different needs for their cloud architecture. Some may "" ""need fast access to many objects that do not change often, or want to set a "" ""time-to-live (TTL) value on a file. Others may access only storage that is "" ""mounted with the file system itself, but want it to be replicated instantly "" ""when starting a new instance. For other systems, ephemeral storage is the "" ""preferred choice. When you select :term:`storage back ends <storage back "" ""end>`, consider the following questions from user's perspective:"" msgstr """" ""Kullanıcılar bulut ihtiyaçları için farklı gereksinimler belirteceklerdir. "" ""Bazıları bir sürü pek fazla değişmeyen nesneye hızlı erişim isteyecek, ya da "" ""bir dosyaya yaşam süresi (TTL) değeri ayarlamak isteyecek. Diğerleri "" ""yalnızca dosya sistemine bağlı depolamaya erişim isteyebilir, ama yeni bir "" ""sunucu başlatırken anında kopyalanmasını isteyebilir. Diğer sistemler için "" ""geçici deoplama tercih edilen çözümdür. :term:`Depolama arka uçlarını "" ""<storage back end>` seçerken kullanıcının bakış açısına göre şu soruları "" ""yanıtlayın:"" msgid """" ""Users with a persistent storage mechanism for objects like images and video."" msgstr """" ""Resimler ve videolar gibi nesneler için geçici depolama mekanizması olan "" ""kullanıcılar."" msgid ""Uses any traditional file system to store the images as files."" msgstr """" ""İmajları dosya olarak kaydetmek için herhangi bir geleneksel dosya sistemini "" ""kullanır."" msgid """" ""Using Ceph as an applicable example, a potential architecture would have the "" ""following requirements:"" msgstr """" ""Uygulanabilir bir örnek olarak Ceph kullanılsa, muhtemel bir mimari şu "" ""gereksinimlere sahip olurdu:"" msgid """" ""Using a scale-out storage solution with direct-attached storage (DAS) in the "" ""servers is well suited for a general purpose OpenStack cloud. Cloud services "" ""requirements determine your choice of scale-out solution. You need to "" ""determine if a single, highly expandable and highly vertical, scalable, "" ""centralized storage array is suitable for your design. After determining an "" ""approach, select the storage hardware based on this criteria."" msgstr """" ""Sunucularda doğrudan ekli depolamaya (DAS) sahip bir ölçekleme çözümü "" ""kullanmak genel amaçlı bir OpenStack bulutu için uygundur. Bulut servisi "" ""gereksinimleri ölçekleme çözümünüzü belirler. Tek bir genişleyebilir ve "" ""dikey, ölçeklenebilir, merkezi bir depolama dizisinin tasarımınıza uygun "" ""olup olmadığına karar vermelisiniz. Bir yaklaşım belirledikten sonra, bu "" ""kritere göre bir depolama donanımı seçin."" msgid """" ""Using an SSD cache layer, you can present block devices directly to "" ""hypervisors or instances. The REST interface can also use the SSD cache "" ""systems as an inline cache."" msgstr """" ""Bir SSD önbellek katmanı kullanarak, blok aygıtları doğrudan hipervizörlere "" ""veya sunuculara sunabilirsiniz. REST arayüzü ayrıca SSD önbellek "" ""sistemlerini de satıriçi önbelleği olarak kullanabilir."" msgid """" ""Using native OpenStack tools can help improve performance. For example, you "" ""can use Telemetry to measure performance and the Orchestration service "" ""(heat) to react to changes in demand."" msgstr """" ""Orjinal OpenStack araçlarını kullanmak başarımı artırabilir. Örneğin, "" ""Telemetri ile başarım ölçebilir Orkestrasyon servisi (heat) ile taleplerdeki "" ""değişikliklere tepki verebilirsiniz."" msgid ""Using tunable networking components"" msgstr ""Ayarlanabilir ağ bileşenlerinin kullanılması"" msgid ""VC"" msgstr ""VC"" msgid ""VLANs are an easy mechanism for isolating networks."" msgstr ""VLAN'lar ağları yalıtmak için kolay bir yöntem sunarlar."" msgid ""VM is terminated"" msgstr ""VM sonlandırılınca"" msgid ""View usage of share resources."" msgstr ""Paylaşım kaynaklarının kullanımını görüntüle."" msgid """" ""We recommend deploying high performing storage solutions such as SSD drives "" ""or flash storage systems for applications requiring additional performance "" ""out of Block Storage devices."" msgstr """" ""Blok Depoama aygıtlarından ek başarım bekleyen uygulamalar için SSD aygıtlar "" ""veya flash depolama sistemleri gibi yüksek başarımlı depolama çözümleri "" ""kurmanızı öneriyoruz."" msgid """" ""We recommend leveraging existing monitoring systems to see if they are able "" ""to effectively monitor an OpenStack environment."" msgstr """" ""Mevcut izleme sistemlerini tetikleyerek OpenStack ortamını etkin şekilde "" ""izleyip izlemediklerine bakmanızı öneriyoruz."" msgid """" ""We recommend that data be encrypted both in transit and at-rest. To this "" ""end, carefully select disks, appliances, and software. Do not assume these "" ""features are included with all storage solutions."" msgstr """" ""Verinin hem aktarımda hem de dururken şifreli olmasını öneriyoruz. Diskleri, "" ""gereçleri ve yazılımları dikkatli seçin. Bu özelliklerin tüm depolama "" ""çözümlerinde dahil olduğunu varsaymayın."" msgid """" ""We recommend that you choose the option operators are most familiar with. "" ""NFS is the easiest to set up and there is extensive community knowledge "" ""about it."" msgstr """" ""İşletmenlerin daha aşina oldukları seçenekle devam etmenizi öneriyoruz. NFS "" ""kurulumu en kolay olandır ve geniş topluluk bilgisi sunar."" msgid """" ""We recommend that you use a fast NIC, such as 10 GB. You can also choose to "" ""use two 10 GB NICs and bond them together. While you might not be able to "" ""get a full bonded 20 GB speed, different transmission streams use different "" ""NICs. For example, if the cloud controller transfers two images, each image "" ""uses a different NIC and gets a full 10 GB of bandwidth."" msgstr """" ""Hızlı bir NIC kullanmanızı öneriyoruz, örneğin 10 GB. İki 10 GB NIC kullanıp "" ""bağlamayı da tercih edebilirsiniz. Tam bağlı 20 GB hıza erişemeseniz de, "" ""farklı aktarım akışları farklı NIC'leri kullanacaktır. Örneğin bulut kontrol "" ""birimi iki imajı aktarıyorsa, her bir imaj farklı bir NIC kullanarak tam 10 "" ""GB bant genişliği kullanabilir."" msgid """" ""We recommend using cloud orchestration tools for managing a diverse "" ""portfolio of systems and applications across multiple cloud platforms."" msgstr """" ""Birden çok bulut platformuna yayılan çok çeşitli sistemleri yönetmek için "" ""bulut orkestrasyon araçları kullanmanızı öneriyoruz."" msgid ""Web scale cloud"" msgstr ""Web ölçekli bulut"" msgid """" ""Web-scale or development clouds where storage is typically ephemeral in "" ""nature"" msgstr """" ""Depolamanın doğası gereği geçici olduğu web ölçekli veya geliştirme bulutları"" msgid """" ""Weigh these considerations against each other to determine the best design "" ""for the desired purpose. For example, increasing server density means "" ""sacrificing resource capacity or expandability. It also can decrease "" ""availability and increase the chance of noisy neighbor issues. Increasing "" ""resource capacity and expandability can increase cost but decrease server "" ""density. Decreasing cost often means decreasing supportability, "" ""availability, server density, resource capacity, and expandability."" msgstr """" ""İstenen amaca göre en iyi tasarım için bu etmenleri tartın. Örneğin, sunucu "" ""yoğunluğunu artırmak demek kaynak kapasitesinden veya genişleyebilirlikten "" ""ödün vermek demektir. Ayrıca kullanılırlığı azaltabilir ve daha çok "" ""gürültülü komşu sorunları yaratabilir. Kaynak kapasitesi ve "" ""genişleyebilirliği artırmak masraflı olabilir ama sunucu yoğunluğunu "" ""azaltır. Masrafı azaltmak çoğu zaman desteklenebilirliği, kullanılırlığı, "" ""sunucu yoğunluğunu, kaynak kapasitesini ve genişleyebilirliği azaltmak "" ""demektir."" msgid ""What OpenStack features and enhancements does the cinder driver enable?"" msgstr """" ""Cinder sürücüsü hangi OpenStack özelliklerini ve iyileştirmelerini "" ""etkinleştiriyor?"" msgid ""What about SSD? DRAM SSD?"" msgstr ""Peki ya SSD? DRAM SSD?"" msgid ""What are my workloads?"" msgstr ""İş yüklerim neler?"" msgid ""What is my company currently using and can I use it with OpenStack?"" msgstr ""Şirketim şu an ne kullanıyor ve bunu OpenStack ile kullanabilir miyim?"" msgid ""What is my forecast for the scaling of storage for compute?"" msgstr ""Hesaplama için depolamada ilerisi için ölçekleme öngörüm nedir?"" msgid ""What is the desired attachment method: NFS, iSCSI, FC, or other?"" msgstr """" ""Tercih edilen ekleme yöntemi nedir: NFS, iSCSI, FC, veya başka bir şey?"" msgid """" ""What is the level of support provided by the vendor within the community?"" msgstr ""Üreticinin topluluk içinde sağladığı destek seviyesi nedir?"" msgid ""What storage is my enterprise currently using? Can it be re-purposed?"" msgstr ""Kurumum şu an hangi depolamayı kullanıyor? Yeniden tasarlanabilir mi?"" msgid """" ""What type of performance do I need in regards to IOPS? Total IOPS and IOPS "" ""per instance? Do I have applications with IOPS SLAs?"" msgstr """" ""IOPS bakımından nasıl bir başarıma ihtiyacım var? Toplam IOPS ve sunucu "" ""başına IOPS? IOPS SLA'ları olan uygulamalarım var mı?"" msgid """" ""When CPU pinning is requested for for a guest, it is assumed there is no "" ""overcommit (or, an overcommit ratio of 1.0). When dedicated resourcing is "" ""not requested for a workload, the normal overcommit ratios are applied."" msgstr """" ""Bir misafir için işlemci sabitleme istenildiğinde, kaynak aşımı olmadığı "" ""varsayılır (veyea 1.0 oranında kaynak aşımı denebilir). Bir iş yükü için "" ""adanmış kaynaklama istenmediğinde, normal kaynak aşım oranları uygulanır."" msgid """" ""When a user uploads and stores content, that content moves into the "" ""OpenStack installation. When users download this content, the content moves "" ""out from the OpenStack installation. Because this service operates primarily "" ""as a backup, most of the traffic moves southbound into the environment. In "" ""this situation, it benefits you to configure a network to be asymmetrically "" ""downstream because the traffic that enters the OpenStack installation is "" ""greater than the traffic that leaves the installation."" msgstr """" ""Kullanıcı içerik yüklediğinde ve kaydettiğinde, bu içerik OpenStack "" ""kurulumuna taşınır. Kullanıcılar içeriği indirdiklerinde, içerik OpenStack "" ""kurulumundan dışarı taşınır. Bu servis birincil olarak yedekleme için servis "" ""vereceğinden, çoğu trafik güney taraflı olarak ortama doğru taşınır. Bu "" ""durumda, ağı asimetrik aşağı akışlı yapılandırmak faydalıdır çünkü OpenStack "" ""kurulumuna doğru giren trafik kurulumu terk eden trafikten büyüktür. "" msgid """" ""When architecting an OpenStack cloud, as part of the planning process, you "" ""must not only determine what hardware to utilize but whether compute "" ""resources will be provided in a single pool or in multiple pools or "" ""availability zones. You should consider if the cloud will provide distinctly "" ""different profiles for compute."" msgstr """" ""OpenStack bulutu imar ederken, planlama sürecinin bir parçası olarak hangi "" ""donanımın kullanılacağının yanı sıra hesaplama havuzlarının tek bir havuzda "" ""mı birden çok havuzda ya da kullanılırlık bölgesinde mi olacağına karar "" ""vermeniz gerekir. Bulutun hesaplama için farklı profiller sağlayıp "" ""sağlamayacağına karar vermelisiniz."" msgid """" ""When attempting to deploy logging and monitoring facilities to a centralized "" ""location, care must be taken with the load placed on the inter-site "" ""networking links"" msgstr """" ""Merkezi bir konuma günlükleme ve izleme kurulumuna teşebbüs edilirken, "" ""konumlar arası bağlantıya gelecek yük hesaba katılmalıdır"" msgid """" ""When designing a OpenStack cloud compute server architecture, you must "" ""decide whether you intend to scale up or scale out. Selecting a smaller "" ""number of larger hosts, or a larger number of smaller hosts, depends on a "" ""combination of factors: cost, power, cooling, physical rack and floor space, "" ""support-warranty, and manageability. Typically, the scale out model has been "" ""popular for OpenStack because it reduces the number of possible failure "" ""domains by spreading workloads across more infrastructure. However, the "" ""downside is the cost of additional servers and the datacenter resources "" ""needed to power, network, and cool the servers."" msgstr """" ""Bir OpenStack bulut hesaplama sunucusu mimarisi tasarlarken yapacağınız "" ""ölçeklemenin yönüne karar vermelisiniz. Az sayıda daha büyük sunucu seçmek "" ""veya daha fazla küçük sunucuyla devam etmek, bir çok etmenin birleşimine "" ""bağlıdır: masraf, güç, soğutma, fiziksel kabin ve zemin alanı, destek-"" ""garanti, ve yönetilebilirlik. Genellikle sayıca artırım OpenStack için "" ""popüler olmuştur çünkü iş yükünü daha fazla alt yapıya dağıtarak arıza "" ""alanlarının sayısını azaltır. Eksi tarafı ek sunucuların fiyatı ve güç, ağ "" ""ve soğutma isteyen veri merkezi kaynaklarıdır."" msgid """" ""When designing a network architecture, the traffic patterns of an "" ""application heavily influence the allocation of total bandwidth and the "" ""number of links that you use to send and receive traffic. Applications that "" ""provide file storage for customers allocate bandwidth and links to favor "" ""incoming traffic; whereas video streaming applications allocate bandwidth "" ""and links to favor outgoing traffic."" msgstr """" ""Bir ağ mimarisi tasarlarken bir uygulamanın trafik kalıpları trafik alıp "" ""göndermek için kullandığınız toplam bant genişliği ve bağlantı sayısını "" ""çokça etkiler. Müşterileri için dosya depolama sağlayan uygulamalar yoğun "" ""gelen trafiğe uygun bant genişliği ve bağlantılar ayırır; bunun gibi video "" ""aktarım yapan uygulamalar ise dışarı giden trafiğe uygun bant genişliği ve "" ""bağlantılar ayırır."" msgid """" ""When designing an OpenStack cloud, it is important to consider the needs "" ""dictated by the :term:`Service Level Agreement (SLA)`. This includes the "" ""core services required to maintain availability of running Compute service "" ""instances, networks, storage, and additional services running on top of "" ""those resources. These services are often referred to as the Data Plane "" ""services, and are generally expected to be available all the time."" msgstr """" ""Bir OpenStack bulutu tasarlarken, :term:`Servis Seviyesi Anlaşması (SLA)` "" ""tarafından istenen ihtiyaçlar göz önüne alınmalıdır. Bu çalışan Hesaplama "" ""servisi sunuclarının, depolamanın ve bu servislerin üstüne çalışan ek "" ""servislerin kullanılırlığının sağlayan çekirdek servisleri içerir. Bu "" ""servisler genellikle Veri Düzlemi servisleri olarak adlandırılır, ve "" ""genellikle her zaman kullanılabilir olmaları beklenir."" msgid """" ""When designing compute resource pools, consider the number of processors, "" ""amount of memory, network requirements, the quantity of storage required for "" ""each hypervisor, and any requirements for bare metal hosts provisioned "" ""through ironic."" msgstr """" ""Hesaplama kaynak havuzları tasarlarken, işlemci sayısını, hafıza miktarını, "" ""ağ gereksinimlerini, her bir hipervizör için gereken depolama miktarını, ve "" ""ironic üzerinden hazırlanan metal istemciler için gereksinimleri göz önüne "" ""alın."" msgid """" ""When designing your cluster, you must consider durability and availability "" ""which is dependent on the spread and placement of your data, rather than the "" ""reliability of the hardware."" msgstr """" ""Kümenizi tasarlarken, dayanıklılık ve kullanılırlığı da göz önüne "" ""almalısınız, bu da donanımın güvenilirliğinden ziyade verinizin "" ""yerleştirmesine ve dağıtımına bağlıdır."" msgid """" ""When running embedded object store methods, ensure that you do not instigate "" ""extra data replication as this may cause performance issues."" msgstr """" ""Gömülü nesne depolama yöntemleri kullanılırken, ek veri çoğaltma "" ""başlatmadığınızdan emin olun, bu başarım sorunlarına yol açabilir."" msgid """" ""When selecting a processor, compare features and performance "" ""characteristics. Some processors include features specific to virtualized "" ""compute hosts, such as hardware-assisted virtualization, and technology "" ""related to memory paging (also known as EPT shadowing). These types of "" ""features can have a significant impact on the performance of your virtual "" ""machine."" msgstr """" ""Bir işlemci seçerken, özelliklerini ve başarım karakteristiğini "" ""karşılaştırın. Bazı işlemciler sanallaştırma sunucuları için iyileştirmeler "" ""içerir, örneğin donanım destekli sanallaştırma ve hafıza sayfalandırmayla "" ""ilgili özellikler (EPT gölgelendirme diye de bilinir). Bu tür özelliklerin "" ""sanal makinenizin başarımı üstünde hatrı sayılır etkisi olacaktır."" msgid """" ""When selecting network devices, be aware that making a decision based on the "" ""greatest port density often comes with a drawback. Aggregation switches and "" ""routers have not all kept pace with ToR switches and may induce bottlenecks "" ""on north-south traffic. As a result, it may be possible for massive amounts "" ""of downstream network utilization to impact upstream network devices, "" ""impacting service to the cloud. Since OpenStack does not currently provide a "" ""mechanism for traffic shaping or rate limiting, it is necessary to implement "" ""these features at the network hardware level."" msgstr """" ""Ağ aygıtları seçerken, en yoğun bağlantı noktasını baz alarak yapacağınız "" ""seçimin genellikle sakıncaları olacaktır. Takım anahtarların ve "" ""yönlendiricilerin hepsi ToR anahtarlarıyla tempoyu tuttramadılar, bu da "" ""kuzey-güney trafiğinde dar boğazların oluşabileceği anlamına geliyor. Sonuç "" ""olarak çok büyük miktarda aşağı akış ağı kullanımının yukarı akış ağ "" ""aygıtlarını etkilemesi mümkündür, bu da bulut servisini etkiler. OpenStack "" ""şu an trafik şekillendirme veya oran sınırlandırma için bir mekanizma "" ""desteklemediğinden, bu özellikleri ağ donanımı seviyesinde uygulamak "" ""gereklidir."" msgid """" ""When using the Networking service, the OpenStack controller servers or "" ""separate Networking hosts handle routing unless the dynamic virtual routers "" ""pattern for routing is selected. Running routing directly on the controller "" ""servers mixes the Data and Control Planes and can cause complex issues with "" ""performance and troubleshooting. It is possible to use third party software "" ""and external appliances that help maintain highly available layer three "" ""routes. Doing so allows for common application endpoints to control network "" ""hardware, or to provide complex multi-tier web applications in a secure "" ""manner. It is also possible to completely remove routing from Networking, "" ""and instead rely on hardware routing capabilities. In this case, the "" ""switching infrastructure must support layer three routing."" msgstr """" ""Ağ servisini kullanırken, dinamik sanal yönlendiriciler kalıbı seçilmezse "" ""OpenStack kontrol sunucuları veya ayrı Ağ sunucuları yönlendirmeyi ele "" ""alırlar. Yönlendirmeyi doğrudan kontrol sunucularında çalıştırmak Veri ve "" ""Kontrol Düzlemlerini karıştırır ve başarım ve hata ayıklamada "" ""karmaşıklıklara yol açabilirler. Yüksek kullanılırlıklı katman üç "" ""yönlendiricileri yönetmek için üçüncü taraf yazılımı ve harici uygulamalar "" ""kullanmak da mümkündür. Böyle yapmak genel uygulama uç noktalarının ağ "" ""donanımını kontrol etmesine veya birden çok aşamalı web uygulamalarını "" ""güvenli bir şekilde sağlamasına izin verir. Ağdan yönlendirmeyi tamamen "" ""kaldırmak ve yalnızca donanımla yönlendirmeye bel bağlamak da mümkündür. Bu "" ""durumda, anahtarlama alt yapısı katman üç yönlendirmeyi desteklemelidir."" msgid """" ""Where instances and images will be stored will influence the architecture."" msgstr ""Sunucuların ve imajların nerede saklanacağı mimariyi etkiler."" msgid """" ""Whereas the simplicity of layer-2 protocols might work well in a data center "" ""with hundreds of physical machines, cloud data centers have the additional "" ""burden of needing to keep track of all virtual machine addresses and "" ""networks. In these data centers, it is not uncommon for one physical node to "" ""support 30-40 instances."" msgstr """" ""Katman-2 iletişim kurallarının basitliği yüzlerce fiziksel makinenin olduğu "" ""fiziksel bir veri merkezinde iyi çalışsa da, bulut veri merkezleri bir de "" ""tüm sanal makine adresleri ve ağlarının izini sürmek zorundadır. Bu veri "" ""merkezlerinde bir fiziksel düğümün 30-40 sunucuyu desteklemesi yaygındır."" msgid """" ""Whether you should enable Hyper-Threading on your CPUs depends upon your use "" ""case. For example, disabling Hyper-Threading can be beneficial in intense "" ""computing environments. We recommend performance testing with your local "" ""workload with both Hyper-Threading on and off to determine what is more "" ""appropriate in your case."" msgstr """" ""İşlemcilerinizde Hyper-Threading etkinleştirip etkinleştirmeyeceğiniz "" ""kullanım durumunuza bağlıdır. Örneğin, Hyper-Threading'i kapatmak yoğun "" ""hesaplama ortamlarında faydalı olabilir. Yerel iş yükünüzle Hyper-Threading "" ""açık ve kapalıyken denemeler yapmanızı ve uygun olan hangisiyse onu "" ""seçmenizi öneriyoruz."" msgid """" ""Which storage choices result in the best cost-performance scenario I am "" ""aiming for?"" msgstr """" ""Hedeflediğim masraf-başarım senaryosunda hangi depolama sonuçları en iyileri?"" msgid """" ""While consistency and partition tolerance are both inherent features of the "" ""Object Storage service, it is important to design the overall storage "" ""architecture to ensure that the implemented system meets those goals. The "" ""OpenStack Object Storage service places a specific number of data replicas "" ""as objects on resource nodes. Replicas are distributed throughout the "" ""cluster, based on a consistent hash ring also stored on each node in the "" ""cluster."" msgstr """" ""Tutarlılık ve bölüm tahammülü Nesne Depolama servisinin doğasında olan "" ""özellikler olsa da, genel depolama mimarisini kurulan sistemin hedeflerle "" ""eşleşmesi üzerine tasarlamak önemlidir. OpenStack Nesne Depolama servisi "" ""belirli sayıda veri yedeğini kaynak düğümlerde nesneler olarak saklar. "" ""Yedekler küme içinde yine kümedeki her bir düğümde kaydedilen tutarlı bir "" ""özet halkası baz alınarak dağıtılır."" msgid """" ""While each enterprise install is different, the following networks with "" ""their proposed bandwidth is highly recommended for a basic production "" ""OpenStack install."" msgstr """" ""Her kurumun kurulumu farklı olsa da, temel OpenStack ürün kurulumunda "" ""aşağıdaki bant genişliği teklif edilen ağlar tavsiye edilir."" msgid """" ""While not as common in large enterprises, compute host components can also "" ""be upgraded to account for increases in demand, known as vertical scaling. "" ""Upgrading CPUs with more cores, or increasing the overall server memory, can "" ""add extra needed capacity depending on whether the running applications are "" ""more CPU intensive or memory intensive. Since OpenStack schedules workload "" ""placement based on capacity and technical requirements, removing compute "" ""nodes from availability and upgrading them using a rolling upgrade design."" msgstr """" ""Büyük kurumlarda yaygın olmasa da, hesaplama sunucu bileşenleri istek "" ""halinde dikey ölçeklendirme denilen şekilde de yükseltilebilirler. Daha "" ""fazla çekirdeğe sahip işlemcilere yükseltme veya genel sunucu belleğini "" ""artırma, çalışan uygulamaların işlemci veya hafıza yoğunluklu olmaları "" ""durumunda gerekli ek kapasiteyi sağlayaiblir. OpenStack iş yükü "" ""yerleştirmesini kapasite ve teknik gereksinimlere göre yaptığından, "" ""hesaplama düğümlerini çıkarmak ve yuvarlanan yükseltme tasarımıyla "" ""güncellemek gerekir."" msgid """" ""While our example contains all central services in a single location, it is "" ""possible and indeed often a good idea to separate services onto different "" ""physical servers. :ref:`table_deployment_scenarios` is a list of deployment "" ""scenarios we've seen and their justifications."" msgstr """" ""Örneğimiz tüm merkezi servisleri tek bir konumda içerse de, servisleri "" ""farklı fiziksel sunuculara ayırmak mümkündür ve çoğunlukla iyi bir "" ""fikirdir. :ref:`table_deployment_scenarios` gördüğümüz kurulum "" ""senaryolarının listesi ve gerekçeleridir."" msgid """" ""While this is not a definitive list of all the questions possible, the list "" ""above will hopefully help narrow the list of possible storage choices down."" msgstr """" ""Bu sorulması gereken soruların tam bir listesi değil, ama mümkün depolama "" ""seçeneklerini azalatmanıza yardımcı olacağını umuyoruz."" msgid """" ""Will the storage architecture scale linearly as the cloud grows and what are "" ""its limits?"" msgstr """" ""Depolama mimarisi bulut büyüdükçe doğrusal olarak ölçeklenecek mi ve "" ""sınırları nelerdir?"" msgid """" ""With file-level storage, users access stored data using the operating "" ""system's file system interface. Most users who have used a network storage "" ""solution before have encountered this form of networked storage. The most "" ""common file system protocol for Unix is NFS, and for Windows, CIFS "" ""(previously, SMB)."" msgstr """" ""Dosya-seviyesinde depolamayla, kullanıcılar kaydedilen veriye işletim "" ""sisteminin dosya sistemi arayüzüyle erişirler. Daha önce bir ağ çözümü "" ""kullanmış çoğu kullanıcı bu şekildeki ağ depolamanın bir biçimini "" ""kullanmıştır. Unix için en yaygın sistem iletişim kuralı NFS'dir, ve Windows "" ""için, CIFS'dir (önceden, SMB)."" msgid ""Within a VM"" msgstr ""Bir VM"" msgid """" ""You can add adjunct networking features, for example class of service (CoS) "" ""or multicasting, to Ethernet as readily as IP networks."" msgstr """" ""Ethernete IP ağlarındaki kadar hazır şekilde ek ağ özellikleri "" ""ekleyebilirsiniz, örneğin servis sınıfı (CoS) veya çokluyayın."" msgid """" ""You can configure layer-3 to use Border Gateway Protocol (BGP) confederation "" ""for scalability. This way core routers have state proportional to the number "" ""of racks, not to the number of servers or instances."" msgstr """" ""Katman-3'ü ölçeklenebilirlik için Sınır Geçidi İletişim Kuralı (BGP) birliği "" ""ile yapılandırabilirsiniz. Böylece çekirdek yönlendiriciler sunucu sayısına "" ""göre değil kabin sayısına oranlı durum bilgisine sahip olurlar."" msgid """" ""You can implement networking in two separate ways. Legacy networking (nova-"" ""network) provides a flat DHCP network with a single broadcast domain. This "" ""implementation does not support tenant isolation networks or advanced plug-"" ""ins, but it is currently the only way to implement a distributed layer-3 "" ""(L3) agent using the multi-host configuration. The Networking service "" ""(neutron) is the official networking implementation and provides a pluggable "" ""architecture that supports a large variety of network methods. Some of these "" ""include a layer-2 only provider network model, external device plug-ins, or "" ""even OpenFlow controllers."" msgstr """" ""Ağı iki farklı şekilde uygulayabilirsiniz. Geleneksel ağ (nova-ağı) tek "" ""yayın alanı olan düz bir DHCP ağı sağlar. Bu uygulama kiracı yalıtım "" ""ağlarını veya gelişmiş eklentileri desteklemez, ama şu an çoklu sunucu "" ""yapılandırmasını kullanarak bir dağıtık katman-3 (L3) aracısı uygulamanın "" ""tek yoludur. Ağ servisi (neutron) resmi ağ uygulamasıdır ve çok çeşitli ağ "" ""yöntemlerini destekleyen tak-çıkar mimari sağlar. Bunlardan bazıları "" ""yalnızca katman-2 sağlayıcı ağ modeli, harici aygıt eklentileri, hatta "" ""OpenStack kontrolcüleridir."" msgid ""You can scale to any number of spindles."" msgstr ""İstediğiniz sayıda mile ölçekleyebilirsiniz."" msgid """" ""You can upgrade Block Storage pools to add storage capacity without "" ""interrupting the overall Block Storage service. Add nodes to the pool by "" ""installing and configuring the appropriate hardware and software and then "" ""allowing that node to report in to the proper storage pool through the "" ""message bus. Block Storage nodes generally report into the scheduler service "" ""advertising their availability. As a result, after the node is online and "" ""available, tenants can make use of those storage resources instantly."" msgstr """" ""Blok Depolama havuzlarını genel Blok Depolama servisini kesintiye uğratmadan "" ""güncelleyebilir ve kapasite eklyebilirsiniz. Havuza uygun donanım ve "" ""yazılımı yükleyerek düğümler ekleyin ve düğümün ileti yolu ile uygun "" ""depolama havuzuna raporlama yapmasını sağlayın. Blok Depolama düğümleri "" ""genellikle zamanlayıcı servisine kullanılırlıklarını iletirler. Sonuç "" ""olarak, düğüm çevrimiçi ve kullanılabilir olduğunda, kiracılar bu depolama "" ""kaynaklarını anında kullanabilir duruma gelirler."" msgid """" ""You must accommodate the need to maintain a set of layer-4 devices to handle "" ""traffic control."" msgstr """" ""Trafik kontrolünü ele alması için bir grup katman-4 aygıtı barındırmanız "" ""gerekir."" msgid """" ""You must balance the time required to build a new cloud platform against the "" ""time saved by migrating users away from legacy platforms. In some cases, "" ""existing infrastructure may influence your architecture choices. For "" ""example, using multiple cloud platforms may be a good option when there is "" ""an existing investment in several applications, as it could be faster to tie "" ""the investments together rather than migrating the components and "" ""refactoring them to a single platform."" msgstr """" ""Yeni bir bulu platformu inşa etmek için gerekli zamanı kullanıcıları eski "" ""platformlardan göç ettirmeyle kazanılacak zamanla dengelemelisiniz. Bazı "" ""durumlarda, mevcut alt yapı mimari seçeneklerinizi etkileyebilir. Örneğin, "" ""birden çok bulut platformu kullanmak, bir çok uygulamaya yapılmış mevcut "" ""yatırım varsa iyi biri seçenek olabilir, çünkü bileşenleri göç ettirmek ve "" ""tek bir platform düzenlemektense yatırımları beraber bağlamak daha hızlı "" ""olabilir."" msgid """" ""You must choose whether you want to support the Amazon EC2 compatibility "" ""APIs, or just the OpenStack APIs. One issue you might encounter when running "" ""both APIs is an inconsistent experience when referring to images and "" ""instances."" msgstr """" ""Yalnızca OpenStack API'lerini mi Amazon EC2 uyumluluk API'lerini demi "" ""desteklemek istediğinize karar vermelisiniz. Her iki API'yi de çalıştırırken "" ""yaşayacağınız bir sorun imaj ve sunuculara başvururken yaşanacak tutarsız "" ""deneyimdir."" msgid """" ""You must consider a number of important technical and business requirements "" ""when planning and designing an OpenStack network:"" msgstr """" ""Bir OpenStack ağı tasarlarken bir takım önemli teknik ve iş gereksinimlerini "" ""göz önüne almalısınız:"" msgid """" ""You must select the appropriate CPU and RAM allocation ratio for your "" ""particular use case."" msgstr """" ""Kullanım durumunuza göre uygun CPU ve RAM ayırma oranlarını kendiniz "" ""seçmelisiniz."" msgid ""You need to size the controller with a core per service."" msgstr """" ""Kontrol birimini servis başına bir çekirdek olacak şekilde "" ""boyutlandırmalısınız."" msgid """" ""You should conduct a high availability risk analysis to determine whether to "" ""use redundant switches such as Top of Rack (ToR) switches. In most cases, it "" ""is much more economical to use single switches with a small pool of spare "" ""switches to replace failed units than it is to outfit an entire data center "" ""with redundant switches. Applications should tolerate rack level outages "" ""without affecting normal operations since network and compute resources are "" ""easily provisioned and plentiful."" msgstr """" ""Kabin Üstü (ToR) anahtarlar gibi yedekli anahtarlar kullanıp kullanmamanız "" ""gerektiğine karar vermek için bir yüksek kullanılırlık risk çözümlemesi "" ""yapmalısınız. Çoğu durumda, tüm veri merkezini yedekli anahtarlarla "" ""doldurmak yerine tekli anahtarlar kullanmak ve bir birimin arıza yapması "" ""halinde değiştirmek için yedek anahtarlar tutmak daha ekonomiktir. Ağ ve "" ""hesaplama kaynakları bol olduğundan ve kolayca hazırlandığından uygulamalar "" ""kabin seviyesinde kesintilere dayanıklı olmalı ve normal işlemeye devam "" ""etmelidir."" msgid """" ""You should consider Ceph if you want to manage your object and block storage "" ""within a single system, or if you want to support fast boot-from-volume."" msgstr """" ""Nesne ve blok depolamanızı aynı sistemden yönetmek istiyorsanız, veya "" ""birimden hızlı önyüklemeyi desteklemek istiyorsanız Ceph kullanmayı gözden "" ""geçirmelisiniz."" msgid """" ""You should consider designing the Object Storage system with a sufficient "" ""number of zones to provide quorum for the number of replicas defined. For "" ""example, with three replicas configured in the swift cluster, the "" ""recommended number of zones to configure within the Object Storage cluster "" ""in order to achieve quorum is five. While it is possible to deploy a "" ""solution with fewer zones, the implied risk of doing so is that some data "" ""may not be available and API requests to certain objects stored in the "" ""cluster might fail. For this reason, ensure you properly account for the "" ""number of zones in the Object Storage cluster."" msgstr """" ""Tanımlanan sayıda yedek için gerekli çoğunluğu sağlamak için yeterli sayıda "" ""bölgeye sahip bir Nesne Depolama sistemi tasarlamaya dikkat etmelisiniz. "" ""Örneğin üç yedek ile yapılandırılmış bir swift kümesinde Nesne Depolama "" ""kümesi ile gerekli çoğunluğu sağlamak için yapılandırılması gereken tavsiye "" ""edilen bölge sayısı beştir. Daha az sayıda bölge ile bir çözüm kurmak da "" ""mümkünken, bunu yapmanın riski bazı verilerin kullanılabilir olmamasını ve "" ""bazı nesnelere yapılan API isteklerinin başarısız olmasını beraberinde "" ""getirebilir. Bu sebeple Nesne Depolama kümesinde yeterli bölge olduğundan "" ""emin olmalısınız."" msgid """" ""You should consider using the OpenStack Object Storage service if you "" ""eventually plan on distributing your storage cluster across multiple data "" ""centers, if you need unified accounts for your users for both compute and "" ""object storage, or if you want to control your object storage with the "" ""OpenStack Dashboard. For more information, see the `Swift project page "" ""<https://www.openstack.org/software/releases/ocata/components/swift>`_."" msgstr """" ""Depolama kümenizi birden çok veri merkezi arasında dağıtmayı düşünüyorsanız, "" ""hem hesaplama hem nesne depolama için kullanıcılarınız için tekil hesaplara "" ""ihtiyacınız varsa, veya nesne depolamanızı OpenStack Kontrol Paneli ile "" ""kontrol etmek isterseniz OpenStack Nesne Depolama servisini kullanmayı "" ""düşünmelisiniz."" msgid ""ZFS"" msgstr ""ZFS"" msgid ""Zone per collection of nodes"" msgstr ""Düğüm topluluğu başına bölge"" msgid ""`Docker <https://www.docker.com/>`_"" msgstr ""`Docker <https://www.docker.com/>`_"" msgid ""`Hyper-V <https://technet.microsoft.com/en-us/library/hh831531.aspx>`_"" msgstr ""`Hyper-V <https://technet.microsoft.com/en-us/library/hh831531.aspx>`_"" msgid ""`KVM <https://www.linux-kvm.org/page/Main_Page>`_"" msgstr ""`KVM <https://www.linux-kvm.org/page/Main_Page>`_"" msgid ""`LXC <https://linuxcontainers.org/>`_"" msgstr ""`LXC <https://linuxcontainers.org/>`_"" msgid ""`QEMU <https://wiki.qemu.org/Main_Page>`_"" msgstr ""`QEMU <https://wiki.qemu.org/Main_Page>`_"" msgid ""`VMware ESX/ESXi <https://www.vmware.com/support/vsphere-hypervisor>`_"" msgstr ""`VMware ESX/ESXi <https://www.vmware.com/support/vsphere-hypervisor>`_"" msgid ""`Xen <https://www.xenproject.org/>`_"" msgstr ""`Xen <https://www.xenproject.org/>`_"" msgid """" ""``Sled servers`` are rack-mounted servers that support multiple independent "" ""servers in a single 2U or 3U enclosure. These deliver higher density as "" ""compared to typical 1U or 2U rack-mounted servers. For example, many sled "" ""servers offer four independent dual-socket nodes in 2U for a total of eight "" ""CPU sockets in 2U."" msgstr """" ""``Sled sunucular`` tek bir 2U veya 3U alanında birden çok bağımsız sunucu "" ""destekleyen kabine-bağlı sunuculardır. Bunlar tipik 1U veya 2U kabine-bağlı "" ""sunuculara göre yüksek yoğunluk sunarlar. Örneğin çoğun sled sunucu 2U'da "" ""dört bağımsız çift-soket düğüm, toplam sekiz işlemci soketi sunarlar."" msgid ""authentication, authorization, and auditing (AAA)"" msgstr ""kimlik doğrulama, yetkilendirme, ve denetleme (AAA)"" msgid ""collectd"" msgstr ""collectd"" msgid ""csv"" msgstr ""csv"" msgid ""date"" msgstr ""tarih"" msgid ""east-west traffic"" msgstr ""doğu-batı trafik"" msgid ""elasticsearch"" msgstr ""elasticsearch"" msgid ""environmental considerations"" msgstr ""ortam etmenleri"" msgid ""federal legal requirements"" msgstr ""birleşik yasal gereklilikler"" msgid ""file"" msgstr ""dosya"" msgid ""floor space"" msgstr ""yer boşluğu"" msgid ""floor weight"" msgstr ""yer ağırlığı"" msgid ""graphite"" msgstr ""graphite"" msgid ""grok"" msgstr ""grok"" msgid ""iSCSI"" msgstr ""iSCSI"" msgid """" ""iSCSI is suitable for cloud environments with Block Storage service to "" ""support applications or for file sharing systems. Network connectivity can "" ""be achieved at a lower cost compared to other storage back end technologies "" ""since iSCSI does not require host bus adaptors (HBA) or storage-specific "" ""network devices."" msgstr """" ""iSCSI uygulamaları desteklemek için Blok Depolama servisi olan veya dosya "" ""paylaşım sistemli bulut ortamları için uygundur. Ağ bağlanılırlığı diğer "" ""depolama arka uç teknolojilerine göre düşük masrafla elde edilebilir, çünkü "" ""iSCSI depolamaya özel ağ aygıtları ya da sunucu yolu adaptörlerine (HBA) "" ""ihtiyaç duymaz."" msgid ""image consistency and availability"" msgstr ""imaj tutarlılığı ve kullanılırlığı"" msgid ""jira"" msgstr ""jira"" msgid ""json"" msgstr ""json"" msgid ""local jurisdictional legal and compliance requirements"" msgstr ""yerel yargı yasası ve uyum gereksinimleri"" msgid ""nagios"" msgstr ""nagios"" msgid ""north-south traffic"" msgstr ""kuzey-güney trafik"" msgid ""pagerduty"" msgstr ""pagerduty"" msgid ""physical security"" msgstr ""fiziksel güvenlik"" msgid ""plan"" msgstr ""plan"" msgid ""power usage and power usage efficiency (PUE)"" msgstr ""güç kullanımı ve güç kullanım etkinliği (PUE)"" msgid ""rack height and type"" msgstr ""kabin yüksekliği ve türü"" msgid ""redis"" msgstr ""redis"" msgid ""rubydebug"" msgstr ""rubydebug"" msgid ""stdout"" msgstr ""stdout"" msgid """" ""storage replication and availability (both block and file/object storage)"" msgstr ""depo kopyalama ve kullanılırlığı (hem blok hem dosya/nesne depolama)"" ",,7986,43
openstack%2Ftripleo-ci~master~I36102fd0a52d8342eb2fa1ed8f68d1a6741aaa28,openstack/tripleo-ci,master,I36102fd0a52d8342eb2fa1ed8f68d1a6741aaa28,Removing duplicate set in ovb-settings,ABANDONED,2017-06-19 09:11:09.000000000,2017-06-19 12:47:23.000000000,,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 10969}, {'_account_id': 12715}]","[{'number': 1, 'created': '2017-06-19 09:11:09.000000000', 'files': ['scripts/quickstart/ovb-settings.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/94876d487e7933afca7f53970a20cd6a9fe9f517', 'message': 'Removing duplicate set in ovb-settings\n\nSmall patch to remove duplicate set founded in ovb-settings file\n\nChange-Id: I36102fd0a52d8342eb2fa1ed8f68d1a6741aaa28\n'}]",0,475304,94876d487e7933afca7f53970a20cd6a9fe9f517,4,4,1,8367,,,0,"Removing duplicate set in ovb-settings

Small patch to remove duplicate set founded in ovb-settings file

Change-Id: I36102fd0a52d8342eb2fa1ed8f68d1a6741aaa28
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/04/475304/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/quickstart/ovb-settings.yml'],1,94876d487e7933afca7f53970a20cd6a9fe9f517,delete_duplicate,,overcloud_templates_path: /usr/share/openstack-tripleo-heat-templates,0,1
openstack%2Fptgbot~master~I154e809a3f4155d14eccd3d8063f92821d6965d9,openstack/ptgbot,master,I154e809a3f4155d14eccd3d8063f92821d6965d9,Restore copyright attribution from statusbot,MERGED,2017-06-13 09:33:21.000000000,2017-06-19 12:44:27.000000000,2017-06-19 12:44:27.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2017-06-13 09:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/d08654fca98a77ddd28e061a8d25c8e45cca478c', 'message': ""Restore copyright attribution from statusbot\n\nWhile ptgbot's bot.py didn't start out as a straight statusbot\nfork, it ended up borrowing most of its connection code, so\noriginal attribution should be preserved.\n\nChange-Id: I154e809a3f4155d14eccd3d8063f92821d6965d9\n""}, {'number': 2, 'created': '2017-06-13 09:41:08.000000000', 'files': ['ptgbot/bot.py'], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/a434345db4f3586d2db8cf82b9285fcb249f12a0', 'message': ""Restore copyright attribution from statusbot\n\nWhile ptgbot's bot.py didn't start out as a straight statusbot\nfork, it ended up borrowing most of its connection code, so\noriginal attribution should be preserved.\n\nChange-Id: I154e809a3f4155d14eccd3d8063f92821d6965d9\n""}]",0,473758,a434345db4f3586d2db8cf82b9285fcb249f12a0,8,2,2,308,,,0,"Restore copyright attribution from statusbot

While ptgbot's bot.py didn't start out as a straight statusbot
fork, it ended up borrowing most of its connection code, so
original attribution should be preserved.

Change-Id: I154e809a3f4155d14eccd3d8063f92821d6965d9
",git fetch https://review.opendev.org/openstack/ptgbot refs/changes/58/473758/1 && git format-patch -1 --stdout FETCH_HEAD,['ptgbot/bot.py'],1,d08654fca98a77ddd28e061a8d25c8e45cca478c,rooms-mgmt,"# Copyright 2011, 2013 OpenStack Foundation # Copyright 2012 Hewlett-Packard Development Company, L.P.","# Copyright (c) 2017, Thierry Carrez",2,1
openstack%2Fptgbot~master~I4130c49cc2a3985c440d5b9205f1900daaf46d3d,openstack/ptgbot,master,I4130c49cc2a3985c440d5b9205f1900daaf46d3d,Add room name validation,MERGED,2017-06-13 09:33:21.000000000,2017-06-19 12:44:22.000000000,2017-06-19 12:44:22.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2017-06-13 09:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/19e3019d27192f55ca21f2673caa34cd1412dcc2', 'message': 'Add room name validation\n\nRooms must match a defined set of active rooms.\n\nAdd !add !del !list commands in order to manage the room list.\nAlso add a !clean command to remove session entries from a given\nset of rooms. All commands take a list of rooms as argument.\n\nChange-Id: I4130c49cc2a3985c440d5b9205f1900daaf46d3d\n'}, {'number': 2, 'created': '2017-06-13 09:41:08.000000000', 'files': ['ptgbot/db.py', 'ptgbot/bot.py'], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/cca73956da7781c58bb60156bdb08a0796604547', 'message': 'Add room name validation\n\nRooms must match a defined set of active rooms.\n\nAdd !add !del !list commands in order to manage the room list.\nAlso add a !clean command to remove session entries from a given\nset of rooms. All commands take a list of rooms as argument.\n\nChange-Id: I4130c49cc2a3985c440d5b9205f1900daaf46d3d\n'}]",0,473757,cca73956da7781c58bb60156bdb08a0796604547,8,2,2,308,,,0,"Add room name validation

Rooms must match a defined set of active rooms.

Add !add !del !list commands in order to manage the room list.
Also add a !clean command to remove session entries from a given
set of rooms. All commands take a list of rooms as argument.

Change-Id: I4130c49cc2a3985c440d5b9205f1900daaf46d3d
",git fetch https://review.opendev.org/openstack/ptgbot refs/changes/57/473757/1 && git format-patch -1 --stdout FETCH_HEAD,"['ptgbot/db.py', 'ptgbot/bot.py']",2,19e3019d27192f55ca21f2673caa34cd1412dcc2,rooms-mgmt," def send_room_list(self, channel): rooms = self.data.list_rooms() if rooms: self.send(channel, ""Active rooms: %s"" % str.join(' ', rooms)) else: self.send(channel, ""There are no active rooms defined yet"") if not self.data.is_room_valid(room): self.send(chan, ""%s: unknown room '%s'"" % (nick, room)) self.send_room_list(chan) return elif command == 'list': self.send_room_list(chan) return elif command in ('clean', 'add', 'del'): if len(words) < 2: self.send(chan, ""this command takes one or more arguments"") return getattr(self.data, command + '_rooms')(words[1:])", # TODO: Add test for room/day/person match,52,3
openstack%2Freleases~master~I93ecb2ea14fb9cc7045cc63ed84f8914afef9d12,openstack/releases,master,I93ecb2ea14fb9cc7045cc63ed84f8914afef9d12,Release kolla 4.0.2,MERGED,2017-06-16 15:58:00.000000000,2017-06-19 12:44:16.000000000,2017-06-19 12:44:15.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 10787}]","[{'number': 1, 'created': '2017-06-16 15:58:00.000000000', 'files': ['deliverables/ocata/kolla.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/57d095713763eaa815370c698662347f209aeb8d', 'message': 'Release kolla 4.0.2\n\nChange-Id: I93ecb2ea14fb9cc7045cc63ed84f8914afef9d12\n'}]",0,475014,57d095713763eaa815370c698662347f209aeb8d,7,3,1,7488,,,0,"Release kolla 4.0.2

Change-Id: I93ecb2ea14fb9cc7045cc63ed84f8914afef9d12
",git fetch https://review.opendev.org/openstack/releases refs/changes/14/475014/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/kolla.yaml'],1,57d095713763eaa815370c698662347f209aeb8d,, - version: 4.0.2 projects: - repo: openstack/kolla hash: d33ff04e032dc1b17139194a4409d455cf899c8b,,4,0
openstack%2Freleases~master~Ifad6d6ba6384f86ed0e834e2e1781b484ccb7825,openstack/releases,master,Ifad6d6ba6384f86ed0e834e2e1781b484ccb7825,ocata: release nova 15.0.6,MERGED,2017-06-14 16:01:10.000000000,2017-06-19 12:43:47.000000000,2017-06-19 12:43:47.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7166}, {'_account_id': 10135}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-14 16:01:10.000000000', 'files': ['deliverables/ocata/nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f5241657a041ed5e44bd4e3e09ef1627c970d904', 'message': ""ocata: release nova 15.0.6\n\nThis is a bug fix release:\n\nuser@ubuntu:~/git/nova$ git log --oneline --no-merges 15.0.5..\n2a11315 Calculate stopped instance's disk sizes for disk_available_least\nfb4184f libvirt: handle missing rbd_secret_uuid from old connection info\n87989c5 [BugFix] Release the memory quota for video ram when deleting an instance.\n593e708 Warn the user about orphaned extra records during keypair migration\n94a3ea5 [Trivial] Hyper-V: accept Glance vhdx images\nef853e0 Use VIR_DOMAIN_BLOCK_REBASE_COPY_DEV when rebasing\ne221784 make sure to rebuild claim on recreate\na272023 Add strict option to discover_hosts\n6041572 Fix cell0 naming when QS params on the connection\n1052ad4 Catch neutronclient.NotFound on floating deletion\n2868d52 Avoid lazy-load error when getting instance AZ\ndf58537 Make xenapi driver compatible with assert_can_migrate\n3696a89 Fix MarkerNotFound when paging and marker was found in cell0\n0316f63 Add recreate functional test for regression bug 1689692\n81838f1 Correct _ensure_console_log_for_instance implementation\n893d11b Avoid lazy-loading instance.id when cross_az_attach=False\n74e2a40 Exclude deleted service records when calling hypervisor statistics\nf2c5ee2 fix InvalidSharedStorage exception message\nfbcf8d6 libvirt: Always disconnect_volume after rebase failures\n\nChange-Id: Ifad6d6ba6384f86ed0e834e2e1781b484ccb7825\n""}]",0,474259,f5241657a041ed5e44bd4e3e09ef1627c970d904,11,5,1,6873,,,0,"ocata: release nova 15.0.6

This is a bug fix release:

user@ubuntu:~/git/nova$ git log --oneline --no-merges 15.0.5..
2a11315 Calculate stopped instance's disk sizes for disk_available_least
fb4184f libvirt: handle missing rbd_secret_uuid from old connection info
87989c5 [BugFix] Release the memory quota for video ram when deleting an instance.
593e708 Warn the user about orphaned extra records during keypair migration
94a3ea5 [Trivial] Hyper-V: accept Glance vhdx images
ef853e0 Use VIR_DOMAIN_BLOCK_REBASE_COPY_DEV when rebasing
e221784 make sure to rebuild claim on recreate
a272023 Add strict option to discover_hosts
6041572 Fix cell0 naming when QS params on the connection
1052ad4 Catch neutronclient.NotFound on floating deletion
2868d52 Avoid lazy-load error when getting instance AZ
df58537 Make xenapi driver compatible with assert_can_migrate
3696a89 Fix MarkerNotFound when paging and marker was found in cell0
0316f63 Add recreate functional test for regression bug 1689692
81838f1 Correct _ensure_console_log_for_instance implementation
893d11b Avoid lazy-loading instance.id when cross_az_attach=False
74e2a40 Exclude deleted service records when calling hypervisor statistics
f2c5ee2 fix InvalidSharedStorage exception message
fbcf8d6 libvirt: Always disconnect_volume after rebase failures

Change-Id: Ifad6d6ba6384f86ed0e834e2e1781b484ccb7825
",git fetch https://review.opendev.org/openstack/releases refs/changes/59/474259/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/nova.yaml'],1,f5241657a041ed5e44bd4e3e09ef1627c970d904,bug/1689692," - version: 15.0.6 projects: - repo: openstack/nova hash: fe329029265e10296a550fc9153b7977da4aefe2 highlights: > - High severity bug fixes: * Bug 1687581: When using the libvirt compute driver with attached ceph-backed volumes, fallback to using nova config for rbd_secret_uuid if it was not in the original volume connection information from Cinder when the volume was attached. * Bug 1692982: A --strict option is added to the ``nova-manage cell_v2 discover_hosts`` command to fail if no hosts are discovered. * Bug 1696001: Handle parsing database connection URLs with query string parameters during simple_cell_setup/map_cell0 commands. * Bug 1689692: Fix paging over cells where the marker is found in the cell0 database.",,18,0
openstack%2Fptgbot~master~I6a86f834da94ee094ee5957d7f5d4948bd74dd4f,openstack/ptgbot,master,I6a86f834da94ee094ee5957d7f5d4948bd74dd4f,Fix .gitreview to match code repository,MERGED,2017-06-13 09:33:21.000000000,2017-06-19 12:42:44.000000000,2017-06-19 12:42:44.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2017-06-13 09:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/7f10428e8c53403025ab6b768b10252571c61ebf', 'message': 'Fix .gitreview to match code repository\n\n.gitreview was pointing to an erroneous git repository.\n\nChange-Id: I6a86f834da94ee094ee5957d7f5d4948bd74dd4f\n'}, {'number': 2, 'created': '2017-06-13 09:41:08.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/2668ea8f6e4161d375b28dcb26a8c8485c9c238a', 'message': 'Fix .gitreview to match code repository\n\n.gitreview was pointing to an erroneous git repository.\n\nChange-Id: I6a86f834da94ee094ee5957d7f5d4948bd74dd4f\n'}]",0,473756,2668ea8f6e4161d375b28dcb26a8c8485c9c238a,8,2,2,308,,,0,"Fix .gitreview to match code repository

.gitreview was pointing to an erroneous git repository.

Change-Id: I6a86f834da94ee094ee5957d7f5d4948bd74dd4f
",git fetch https://review.opendev.org/openstack/ptgbot refs/changes/56/473756/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,7f10428e8c53403025ab6b768b10252571c61ebf,rooms-mgmt,project=openstack/ptgbot.git,project=openstack-infra/ptgbot.git,1,1
openstack%2Freleases~master~I9a063817957381322064c14abacfaab85021e648,openstack/releases,master,I9a063817957381322064c14abacfaab85021e648,Release kolla-ansible 4.0.2,MERGED,2017-06-16 15:58:44.000000000,2017-06-19 12:42:16.000000000,2017-06-19 12:42:16.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 10787}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-16 15:58:44.000000000', 'files': ['deliverables/ocata/kolla-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/06f97b5443b58a838404399c35567b1dc970b014', 'message': 'Release kolla-ansible 4.0.2\n\nChange-Id: I9a063817957381322064c14abacfaab85021e648\n'}]",0,475015,06f97b5443b58a838404399c35567b1dc970b014,8,4,1,7488,,,0,"Release kolla-ansible 4.0.2

Change-Id: I9a063817957381322064c14abacfaab85021e648
",git fetch https://review.opendev.org/openstack/releases refs/changes/15/475015/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/kolla-ansible.yaml'],1,06f97b5443b58a838404399c35567b1dc970b014,, - version: 4.0.2 projects: - repo: openstack/kolla-ansible hash: f61d731a48887110592b63baf8c27bd3ac0bac2f,,4,0
openstack%2Fptgbot~master~I8c6d890620e59f2cc3a6bda660d16efdb56ae1f0,openstack/ptgbot,master,I8c6d890620e59f2cc3a6bda660d16efdb56ae1f0,Remove unused variable,MERGED,2017-06-13 09:41:08.000000000,2017-06-19 12:41:31.000000000,2017-06-19 12:41:31.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2017-06-13 09:41:08.000000000', 'files': ['ptgbot/bot.py'], 'web_link': 'https://opendev.org/openstack/ptgbot/commit/cc7c4661844cbd0da9a44599f301c551cb0667c0', 'message': ""Remove unused variable\n\nauth variable is no longer used, which triggers a F841 flake8\nerror. Let's get rid of it.\n\nChange-Id: I8c6d890620e59f2cc3a6bda660d16efdb56ae1f0\n""}]",0,473761,cc7c4661844cbd0da9a44599f301c551cb0667c0,6,2,1,308,,,0,"Remove unused variable

auth variable is no longer used, which triggers a F841 flake8
error. Let's get rid of it.

Change-Id: I8c6d890620e59f2cc3a6bda660d16efdb56ae1f0
",git fetch https://review.opendev.org/openstack/ptgbot refs/changes/61/473761/1 && git format-patch -1 --stdout FETCH_HEAD,['ptgbot/bot.py'],1,cc7c4661844cbd0da9a44599f301c551cb0667c0,rooms-mgmt,, auth = e.arguments[0][0] == '+',0,1
openstack%2Freleases~master~I44be38bfa6fecfe847c652f53ff8a3d76b987615,openstack/releases,master,I44be38bfa6fecfe847c652f53ff8a3d76b987615,Release ironic-lib 2.8.0 for Pike,MERGED,2017-06-15 14:12:46.000000000,2017-06-19 12:40:41.000000000,2017-06-19 12:40:41.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 13294}]","[{'number': 1, 'created': '2017-06-15 14:12:46.000000000', 'files': ['deliverables/pike/ironic-lib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/223228b26d7076bf1d686bde7ab55fc7af4c9724', 'message': 'Release ironic-lib 2.8.0 for Pike\n\nChange-Id: I44be38bfa6fecfe847c652f53ff8a3d76b987615\n'}]",0,474591,223228b26d7076bf1d686bde7ab55fc7af4c9724,7,3,1,10239,,,0,"Release ironic-lib 2.8.0 for Pike

Change-Id: I44be38bfa6fecfe847c652f53ff8a3d76b987615
",git fetch https://review.opendev.org/openstack/releases refs/changes/91/474591/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/ironic-lib.yaml'],1,223228b26d7076bf1d686bde7ab55fc7af4c9724,ironic-lib, - version: 2.8.0 projects: - repo: openstack/ironic-lib hash: 56e761936623fe6c66bccfe946276a27df7a78c8,,4,0
openstack%2Freleases~master~Id2f81c092609f5c5861f4c7063b5c808b439ceba,openstack/releases,master,Id2f81c092609f5c5861f4c7063b5c808b439ceba,Release karbor 0.3.0,MERGED,2017-05-22 08:40:59.000000000,2017-06-19 12:40:35.000000000,2017-06-19 12:40:35.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 20883}]","[{'number': 1, 'created': '2017-05-22 08:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/56fdbe18cdcdbe1ee23d447a36cbfae58eab7315', 'message': 'Release karbor 0.2.1\n\nChange-Id: Id2f81c092609f5c5861f4c7063b5c808b439ceba\n'}, {'number': 2, 'created': '2017-06-18 08:35:48.000000000', 'files': ['deliverables/pike/karbor.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ee041b3764e296112aeab9e05e8e515359d950e7', 'message': 'Release karbor 0.3.0\n\nChange-Id: Id2f81c092609f5c5861f4c7063b5c808b439ceba\n'}]",0,466629,ee041b3764e296112aeab9e05e8e515359d950e7,9,3,2,20883,,,0,"Release karbor 0.3.0

Change-Id: Id2f81c092609f5c5861f4c7063b5c808b439ceba
",git fetch https://review.opendev.org/openstack/releases refs/changes/29/466629/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/karbor.yaml'],1,56fdbe18cdcdbe1ee23d447a36cbfae58eab7315,karbor-0.3.0,releases: - version: 0.2.1 projects: - repo: openstack/karbor hash: a83137c81707738e9ca554d0146783536ffbd227,,5,0
openstack%2Freleases~master~I61bdb075ca506099ef2d9e53878d955efeea1fd0,openstack/releases,master,I61bdb075ca506099ef2d9e53878d955efeea1fd0,Release karbor-dashboard 0.3.0,MERGED,2017-05-22 08:39:06.000000000,2017-06-19 12:40:30.000000000,2017-06-19 12:40:30.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 20883}]","[{'number': 1, 'created': '2017-05-22 08:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4d7310e01ec03e7701151e22c79d1c034b224eb3', 'message': 'Release karbor-dashboard 0.2.0\n\nChange-Id: I61bdb075ca506099ef2d9e53878d955efeea1fd0\n'}, {'number': 2, 'created': '2017-06-18 08:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/7b0efabb5b806aa049b281c2df6ea7946bca0468', 'message': 'Release karbor-dashboard 0.2.0\n\nChange-Id: I61bdb075ca506099ef2d9e53878d955efeea1fd0\n'}, {'number': 3, 'created': '2017-06-18 08:37:25.000000000', 'files': ['deliverables/pike/karbor-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e93bc291637b0ebfbb21bcf3e815df14d71dbfb2', 'message': 'Release karbor-dashboard 0.3.0\n\nChange-Id: I61bdb075ca506099ef2d9e53878d955efeea1fd0\n'}]",0,466628,e93bc291637b0ebfbb21bcf3e815df14d71dbfb2,11,3,3,20883,,,0,"Release karbor-dashboard 0.3.0

Change-Id: I61bdb075ca506099ef2d9e53878d955efeea1fd0
",git fetch https://review.opendev.org/openstack/releases refs/changes/28/466628/3 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/pike/karbor-dashboard.yaml'],1,4d7310e01ec03e7701151e22c79d1c034b224eb3,karbor-dashboard-0.3.0,releases: - version: 0.2.0 projects: - repo: openstack/karbor-dashboard hash: e0b55c296d1373a01674c0bfee2cac848ad7b911,,5,0
openstack%2Fos-vif~master~Ic3c6286728a07e3e68a24d034e4c48e8b2a4f582,openstack/os-vif,master,Ic3c6286728a07e3e68a24d034e4c48e8b2a4f582,Use versionedobjects PCIAddress field,MERGED,2017-06-17 09:05:50.000000000,2017-06-19 12:40:06.000000000,2017-06-19 12:40:06.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 11604}, {'_account_id': 15334}]","[{'number': 1, 'created': '2017-06-17 09:05:50.000000000', 'files': ['os_vif/objects/vif.py', 'os_vif/tests/test_fields.py', 'os_vif/objects/fields.py'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/aa9e1980211cda32b234cc7a86d739175ada4ca8', 'message': 'Use versionedobjects PCIAddress field\n\nChange-Id: Ic3c6286728a07e3e68a24d034e4c48e8b2a4f582\n'}]",0,475120,aa9e1980211cda32b234cc7a86d739175ada4ca8,10,5,1,12171,,,0,"Use versionedobjects PCIAddress field

Change-Id: Ic3c6286728a07e3e68a24d034e4c48e8b2a4f582
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/20/475120/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_vif/objects/vif.py', 'os_vif/tests/test_fields.py', 'os_vif/objects/fields.py']",3,aa9e1980211cda32b234cc7a86d739175ada4ca8,pci_address,,"import re import six class PCIAddress(fields.FieldType): _REGEX = re.compile(r'^[0-9a-f]{4}:[0-9a-f]{2}:[0-1][0-9a-f].[0-7]$') @staticmethod def coerce(obj, attr, value): if isinstance(value, six.string_types): newvalue = value.lower() if PCIAddress._REGEX.match(newvalue): return newvalue raise ValueError(""Malformed PCI address %s"", value) class PCIAddressField(fields.AutoTypedField): AUTO_TYPE = PCIAddress()",2,58
openstack%2Fdevstack~master~Ida1d6d012e1e05f35ba45670436acd6f920c9575,openstack/devstack,master,Ida1d6d012e1e05f35ba45670436acd6f920c9575,Updated from generate-devstack-plugins-list,MERGED,2017-06-19 08:55:47.000000000,2017-06-19 12:31:10.000000000,2017-06-19 11:40:47.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 10385}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-06-19 08:55:47.000000000', 'files': ['doc/source/plugin-registry.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/41da1a9feb397d2536acd2f59daab55937a04513', 'message': 'Updated from generate-devstack-plugins-list\n\nChange-Id: Ida1d6d012e1e05f35ba45670436acd6f920c9575\n'}]",0,475296,41da1a9feb397d2536acd2f59daab55937a04513,8,4,1,11131,,,0,"Updated from generate-devstack-plugins-list

Change-Id: Ida1d6d012e1e05f35ba45670436acd6f920c9575
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/475296/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/plugin-registry.rst'],1,41da1a9feb397d2536acd2f59daab55937a04513,openstack/devstack/plugins,tap-as-a-service-dashboard `git://git.openstack.org/openstack/tap-as-a-service-dashboard <https://git.openstack.org/cgit/openstack/tap-as-a-service-dashboard>`__,,1,0
openstack%2Fos-brick~master~I239cfa5dbaccf5648b732d6c414792b8497acc19,openstack/os-brick,master,I239cfa5dbaccf5648b732d6c414792b8497acc19,Fix slow test_connect_volume_device_not_valid test,MERGED,2017-06-09 12:20:46.000000000,2017-06-19 12:29:33.000000000,2017-06-19 11:14:32.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 22248}]","[{'number': 1, 'created': '2017-06-09 12:20:46.000000000', 'files': ['os_brick/tests/initiator/connectors/test_fibre_channel.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/cf9eeb1a4ef60c224995849ed0d1fad9d8ccf184', 'message': ""Fix slow test_connect_volume_device_not_valid test\n\nThis test unnecessarily takes 6 seconds to execute so this patch reduces\nthis time to 0.0000 seconds.\n\nWe have to mock `eventlet.greenthread.sleep` instead of `time.sleep`\nbecause that's what is directly being used in oslo_service's\nloopingcall.\n\nTrivialFix\n\nChange-Id: I239cfa5dbaccf5648b732d6c414792b8497acc19\n""}]",0,472657,cf9eeb1a4ef60c224995849ed0d1fad9d8ccf184,36,4,1,9535,,,0,"Fix slow test_connect_volume_device_not_valid test

This test unnecessarily takes 6 seconds to execute so this patch reduces
this time to 0.0000 seconds.

We have to mock `eventlet.greenthread.sleep` instead of `time.sleep`
because that's what is directly being used in oslo_service's
loopingcall.

TrivialFix

Change-Id: I239cfa5dbaccf5648b732d6c414792b8497acc19
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/57/472657/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/tests/initiator/connectors/test_fibre_channel.py'],1,cf9eeb1a4ef60c224995849ed0d1fad9d8ccf184,fix/test-mock-time," @mock.patch('eventlet.greenthread.sleep', mock.Mock())",,1,0
openstack%2Ftripleo-heat-templates~master~I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f,openstack/tripleo-heat-templates,master,I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f,DNM - policy.json change test in container CI,ABANDONED,2017-06-14 21:18:05.000000000,2017-06-19 12:25:20.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-06-14 21:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b7bb4637dfb779999fea0294e91cc84be156301c', 'message': 'DNM - policy.json change test in container CI\n\nChange-Id: I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f\n'}, {'number': 2, 'created': '2017-06-14 21:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2faf0a9d0fbb7a8e2096ddc43bf19ac8e34e000e', 'message': 'DNM - policy.json change test in container CI\n\nChange-Id: I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f\n'}, {'number': 3, 'created': '2017-06-15 11:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eccd9d327743eda044eb702396210a434301942c', 'message': 'DNM - policy.json change test in container CI\n\nChange-Id: I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f\n'}, {'number': 4, 'created': '2017-06-16 15:41:29.000000000', 'files': ['ci/environments/multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75d39e2acfeb58e54907f2852d9ed967e5b5844e', 'message': 'DNM - policy.json change test in container CI\n\nChange-Id: I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f\n'}]",0,474360,75d39e2acfeb58e54907f2852d9ed967e5b5844e,15,2,4,3153,,,0,"DNM - policy.json change test in container CI

Change-Id: I4d9ff041db4828a3ed277cf1e5857b7f8a381a3f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/474360/4 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario001-multinode-containers.yaml'],1,b7bb4637dfb779999fea0294e91cc84be156301c,test/cont," NovaApiPolicies: { nova-context_is_admin: { key: 'compute:get_all', value: '' } }",,1,0
openstack%2Fmanila~master~I6049692d9ea4570704bdb3e4171d50c95515ac7d,openstack/manila,master,I6049692d9ea4570704bdb3e4171d50c95515ac7d,Wrong substitution of replica ID in log message,MERGED,2017-06-19 05:23:53.000000000,2017-06-19 12:24:18.000000000,2017-06-19 12:10:33.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 9003}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16643}, {'_account_id': 20099}, {'_account_id': 21884}]","[{'number': 1, 'created': '2017-06-19 05:23:53.000000000', 'files': ['manila/share/api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/ef8bb2e1499140225875a8d78cde5e5358d35f9c', 'message': 'Wrong substitution of replica ID in log message\n\nIts noted that we are using wrong value for substitution\nof share replica ID in delete share replica api code.\n\nFor that, Wrong id is logged in manila-api logs.\nCorrected it.\n\nChange-Id: I6049692d9ea4570704bdb3e4171d50c95515ac7d\nCloses-Bug: #1665635\n'}]",1,475231,ef8bb2e1499140225875a8d78cde5e5358d35f9c,19,13,1,16305,,,0,"Wrong substitution of replica ID in log message

Its noted that we are using wrong value for substitution
of share replica ID in delete share replica api code.

For that, Wrong id is logged in manila-api logs.
Corrected it.

Change-Id: I6049692d9ea4570704bdb3e4171d50c95515ac7d
Closes-Bug: #1665635
",git fetch https://review.opendev.org/openstack/manila refs/changes/31/475231/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/api.py'],1,ef8bb2e1499140225875a8d78cde5e5358d35f9c,bug/1665635," LOG.info(""Deleting replica %s."", share_replica['id'])"," LOG.info(""Deleting replica %s."", id)",1,1
openstack%2Fpanko~master~I57b920f77b8cd489fda13b8dbf8c219b888601d6,openstack/panko,master,I57b920f77b8cd489fda13b8dbf8c219b888601d6,Add url_prefix parameter in Elasticsearch connection,MERGED,2017-06-16 09:28:38.000000000,2017-06-19 12:22:55.000000000,2017-06-19 12:22:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-06-16 09:28:38.000000000', 'files': ['panko/storage/impl_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/panko/commit/fe7549adffb4035f401d5947c41fc4eb6212d5cd', 'message': 'Add url_prefix parameter in Elasticsearch connection\n\nForgot to include it in https://review.openstack.org/#/c/450204/\nwhen I did the second patch\n\nChange-Id: I57b920f77b8cd489fda13b8dbf8c219b888601d6\n'}]",0,474922,fe7549adffb4035f401d5947c41fc4eb6212d5cd,10,4,1,25568,,,0,"Add url_prefix parameter in Elasticsearch connection

Forgot to include it in https://review.openstack.org/#/c/450204/
when I did the second patch

Change-Id: I57b920f77b8cd489fda13b8dbf8c219b888601d6
",git fetch https://review.opendev.org/openstack/panko refs/changes/22/474922/1 && git format-patch -1 --stdout FETCH_HEAD,['panko/storage/impl_elasticsearch.py'],1,fe7549adffb4035f401d5947c41fc4eb6212d5cd,add_url_prefix_to_elasticsearch_conn," self.conn = es.Elasticsearch(hosts=url_split.netloc + url_split.path,"," self.conn = es.Elasticsearch(hosts=url_split.netloc,",1,1
openstack%2Fpython-manilaclient~master~I7b0061c714f42f1bc1f2ee17fa69ea59ce180e3b,openstack/python-manilaclient,master,I7b0061c714f42f1bc1f2ee17fa69ea59ce180e3b,Updated from global requirements,MERGED,2017-06-15 16:34:23.000000000,2017-06-19 12:14:21.000000000,2017-06-19 12:14:21.000000000,"[{'_account_id': 3}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16643}]","[{'number': 1, 'created': '2017-06-15 16:34:23.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/37bf2d9b4be277ece01e9ff782234d264ed4fd56', 'message': 'Updated from global requirements\n\nChange-Id: I7b0061c714f42f1bc1f2ee17fa69ea59ce180e3b\n'}]",0,474691,37bf2d9b4be277ece01e9ff782234d264ed4fd56,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I7b0061c714f42f1bc1f2ee17fa69ea59ce180e3b
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/91/474691/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,37bf2d9b4be277ece01e9ff782234d264ed4fd56,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Ftripleo-docs~master~I4a8e24a5189ceacf08d2aa8478a55ead5e8f117f,openstack/tripleo-docs,master,I4a8e24a5189ceacf08d2aa8478a55ead5e8f117f,Update instack-undercloud URL,MERGED,2017-06-19 06:51:03.000000000,2017-06-19 12:09:06.000000000,2017-06-19 12:09:06.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 10239}]","[{'number': 1, 'created': '2017-06-19 06:51:03.000000000', 'files': ['doc/source/introduction/architecture.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/5dc27e903527eb98217dcf88fac837242151003d', 'message': ""Update instack-undercloud URL\n\nCurrently the docs point to an obselete URL that redirects you to the\ncurrent locations.  Update the link to point to the preferred location.\n\nNOTE: I considered linking directly to git.openstack.org but gitweb\ndoesn't render the MD so the github URL is a little more user friendly.\n\nChange-Id: I4a8e24a5189ceacf08d2aa8478a55ead5e8f117f\n""}]",5,475265,5dc27e903527eb98217dcf88fac837242151003d,10,4,1,12898,,,0,"Update instack-undercloud URL

Currently the docs point to an obselete URL that redirects you to the
current locations.  Update the link to point to the preferred location.

NOTE: I considered linking directly to git.openstack.org but gitweb
doesn't render the MD so the github URL is a little more user friendly.

Change-Id: I4a8e24a5189ceacf08d2aa8478a55ead5e8f117f
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/65/475265/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/introduction/architecture.rst'],1,5dc27e903527eb98217dcf88fac837242151003d,feature/docs-updates,<https://github.com/openstack/instack-undercloud>`_'s script and it calls,<https://github.com/rdo-management/instack-undercloud>`_'s script and it calls,1,1
openstack%2Fnetworking-hyperv~stable%2Focata~I7e463baa1ccc2e4d24d41c8e90a133adc24a1298,openstack/networking-hyperv,stable/ocata,I7e463baa1ccc2e4d24d41c8e90a133adc24a1298,Updated from global requirements,MERGED,2017-05-15 23:32:55.000000000,2017-06-19 12:07:58.000000000,2017-06-19 12:07:58.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-05-15 23:32:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/bb6c5c4632a0b53e731271379f8f362a95c0f675', 'message': 'Updated from global requirements\n\nChange-Id: I7e463baa1ccc2e4d24d41c8e90a133adc24a1298\n'}]",0,464824,bb6c5c4632a0b53e731271379f8f362a95c0f675,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I7e463baa1ccc2e4d24d41c8e90a133adc24a1298
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/24/464824/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bb6c5c4632a0b53e731271379f8f362a95c0f675,openstack/requirements,pbr>=1.8 # Apache-2.0,"pbr<2.0.0,>=1.8 # Apache-2.0",1,1
openstack%2Fcompute-hyperv~master~Ia30942dfcd0a4ab88ce3818020c5476d007a2395,openstack/compute-hyperv,master,Ia30942dfcd0a4ab88ce3818020c5476d007a2395,"Fixes ""always enable nested virt"" issue",MERGED,2017-04-10 08:51:55.000000000,2017-06-19 12:07:53.000000000,2017-06-19 12:07:53.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}]","[{'number': 1, 'created': '2017-04-10 08:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/58b320931cd2fae37c6724dba4925ef7e6c3ac88', 'message': 'Fixes ""always enable nested virt"" issue\n\nWhen creating an instance, the driver doesn\'t check if nested\nvirtualization is required. This fixes this issue.\n\nChange-Id: Ia30942dfcd0a4ab88ce3818020c5476d007a2395\n'}, {'number': 2, 'created': '2017-06-19 09:31:15.000000000', 'files': ['hyperv/nova/vmops.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/5d9b23af9ef083c80f588d899d3ed14ac9f2fb71', 'message': 'Fixes ""always enable nested virt"" issue\n\nWhen creating an instance, the driver doesn\'t check if nested\nvirtualization is required. This fixes this issue.\n\nCloses-Bug: #1698771\n\nChange-Id: Ia30942dfcd0a4ab88ce3818020c5476d007a2395\n'}]",1,455165,5d9b23af9ef083c80f588d899d3ed14ac9f2fb71,12,4,2,8213,,,0,"Fixes ""always enable nested virt"" issue

When creating an instance, the driver doesn't check if nested
virtualization is required. This fixes this issue.

Closes-Bug: #1698771

Change-Id: Ia30942dfcd0a4ab88ce3818020c5476d007a2395
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/65/455165/1 && git format-patch -1 --stdout FETCH_HEAD,['hyperv/nova/vmops.py'],1,58b320931cd2fae37c6724dba4925ef7e6c3ac88,," if nested_virt_enabled: self._vmutils.set_nested_virtualization(instance.name, state=nested_virt_enabled)"," self._vmutils.set_nested_virtualization(instance.name, state=nested_virt_enabled)",3,2
openstack%2Fos-win~stable%2Focata~Id155d7668199a4330e321165071910630f6c6d93,openstack/os-win,stable/ocata,Id155d7668199a4330e321165071910630f6c6d93,Updated from global requirements,MERGED,2017-05-15 23:37:27.000000000,2017-06-19 12:06:59.000000000,2017-06-19 12:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-05-15 23:37:27.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-win/commit/9ee105ff133adb13fa06210193821d79da670a19', 'message': 'Updated from global requirements\n\nChange-Id: Id155d7668199a4330e321165071910630f6c6d93\n'}]",0,464843,9ee105ff133adb13fa06210193821d79da670a19,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: Id155d7668199a4330e321165071910630f6c6d93
",git fetch https://review.opendev.org/openstack/os-win refs/changes/43/464843/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9ee105ff133adb13fa06210193821d79da670a19,openstack/requirements,pbr>=1.8 # Apache-2.0,"pbr<2.0.0,>=1.8 # Apache-2.0",1,1
openstack%2Fcompute-hyperv~stable%2Focata~I6696c3ba158e6357178f41a4f48c54cf9dbe7985,openstack/compute-hyperv,stable/ocata,I6696c3ba158e6357178f41a4f48c54cf9dbe7985,Updated from global requirements,MERGED,2017-05-15 23:29:34.000000000,2017-06-19 12:06:34.000000000,2017-06-19 12:06:34.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}]","[{'number': 1, 'created': '2017-05-15 23:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/28259f016c9a6b799768905c73d0268e9126216c', 'message': 'Updated from global requirements\n\nChange-Id: I6696c3ba158e6357178f41a4f48c54cf9dbe7985\n'}, {'number': 2, 'created': '2017-06-09 17:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/4558a72a17c843ee3f0e96f6c8917adf66b57e56', 'message': 'Updated from global requirements\n\nChange-Id: I6696c3ba158e6357178f41a4f48c54cf9dbe7985\n'}, {'number': 3, 'created': '2017-06-19 06:17:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/08242dba3b2c9dffe8f7411ed71d4f4ecd58ba6a', 'message': 'Updated from global requirements\n\nChange-Id: I6696c3ba158e6357178f41a4f48c54cf9dbe7985\n'}]",0,464786,08242dba3b2c9dffe8f7411ed71d4f4ecd58ba6a,17,3,3,11131,,,0,"Updated from global requirements

Change-Id: I6696c3ba158e6357178f41a4f48c54cf9dbe7985
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/86/464786/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,28259f016c9a6b799768905c73d0268e9126216c,openstack/requirements,pbr>=1.8 # Apache-2.0,"pbr<2.0.0,>=1.8 # Apache-2.0",1,1
openstack%2Fceilometer~master~I6f368332b2cdded523a45fe7df37be005d39ecdf,openstack/ceilometer,master,I6f368332b2cdded523a45fe7df37be005d39ecdf,Fix html_last_updated_fmt for Python3.,ABANDONED,2017-06-09 08:46:33.000000000,2017-06-19 12:04:29.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 15843}]","[{'number': 1, 'created': '2017-06-09 08:46:33.000000000', 'files': ['api-ref/source/conf.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0fc38b61ea21ab44526d644bb30a28fc5694cb50', 'message': 'Fix html_last_updated_fmt for Python3.\n\nhtml_last_updated_fmt option is interpreted as a\nbyte string in python3, causing Sphinx build to break.\nThis patch makes it utf-8 string.\n\nChange-Id: I6f368332b2cdded523a45fe7df37be005d39ecdf\nCloses-Bug:#1693670\n'}]",0,472590,0fc38b61ea21ab44526d644bb30a28fc5694cb50,5,3,1,20184,,,0,"Fix html_last_updated_fmt for Python3.

html_last_updated_fmt option is interpreted as a
byte string in python3, causing Sphinx build to break.
This patch makes it utf-8 string.

Change-Id: I6f368332b2cdded523a45fe7df37be005d39ecdf
Closes-Bug:#1693670
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/90/472590/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/conf.py'],1,0fc38b61ea21ab44526d644bb30a28fc5694cb50,bug/1693670, html_last_updated_fmt = subprocess.check_output(git_cmd).decode('utf-8')," html_last_updated_fmt = subprocess.Popen( git_cmd, stdout=subprocess.PIPE).communicate()[0].decode()",1,2
openstack%2Fapi-sig~master~I22f37e462f2389b4ddc398d3d658c932d1b2e434,openstack/api-sig,master,I22f37e462f2389b4ddc398d3d658c932d1b2e434,Update Liaison Information,MERGED,2017-06-16 17:00:29.000000000,2017-06-19 12:04:25.000000000,2017-06-19 12:04:25.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 10239}, {'_account_id': 16643}]","[{'number': 1, 'created': '2017-06-16 17:00:29.000000000', 'files': ['doc/source/liaisons.json'], 'web_link': 'https://opendev.org/openstack/api-sig/commit/a4e5fcf4fd8c600318f65e1c3f00ce800fae3061', 'message': 'Update Liaison Information\n\nRecent employment changes has resulted in several liasons no longer to\ncontinue in that capacity. This patch updates with the current liaisons,\nand also adds their emails, which will make contacting them about API-WG\nissues simpler.\n\nChange-Id: I22f37e462f2389b4ddc398d3d658c932d1b2e434\n'}]",2,475027,a4e5fcf4fd8c600318f65e1c3f00ce800fae3061,8,4,1,1063,,,0,"Update Liaison Information

Recent employment changes has resulted in several liasons no longer to
continue in that capacity. This patch updates with the current liaisons,
and also adds their emails, which will make contacting them about API-WG
issues simpler.

Change-Id: I22f37e462f2389b4ddc398d3d658c932d1b2e434
",git fetch https://review.opendev.org/openstack/api-sig refs/changes/27/475027/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/liaisons.json'],1,a4e5fcf4fd8c600318f65e1c3f00ce800fae3061,liaison_email," ""email"": ""douglas.mendizabal@rackspace.com"", ""email"": ""cdent+os@anticedent.org"", ""email"": ""scott.dangelo@gmail.com"", ""email"": ""muroi.masahito@lab.ntt.co.jp"", ""email"": """", ""email"": ""nik.komawar@gmail.com"", ""email"": ""rico.lin.guanyu@gmail.com"", ""email"": ""clu@us.ibm.com"", ""email"": ""vdrok@mirantis.com"", ""email"": ""dstanek@dstanek.com"", ""email"": ""sviridov.ilya@gmail.com"", ""email"": ""liyong.qiao@intel.com"", ""email"": ""wanghua.humble@gmail.com"", ""email"": ""Goutham.PachaRavi@netapp.com"", ""email"": ""renat.akhmerov@gmail.com"", ""email"": ""nstarodubstev@mirantis.com"", ""email"": ""amotoki@gmail.com"", ""email"": ""matthew.gilliard@gmail.com"", ""email"": ""soulxu@gmail.com"", ""email"": """", ""email"": ""msm@redhat.com"", ""email"": ""tengqim@linux.vnet.ibm.com"", ""email"": ""me@not.mn"", ""email"": ""peter@tesora.com"", ""email"": ""amrith.kumar@gmail.com"", ""email"": """", ""email"": ""feilong@catalyst.net.nz"","," ""name"": ""Stuart McLaren"", ""nick"": ""mclaren"" }, { ""project"": ""Glance"", ""name"": ""Alex Meade"", ""nick"": ""ameade"" }, { ""project"": ""Manila"",",27,10
openstack%2Fpanko~master~I2a5b8a24a9c8f81a486f6e45661df136f33fa244,openstack/panko,master,I2a5b8a24a9c8f81a486f6e45661df136f33fa244,Fix html_last_updated_fmt for Python3.,ABANDONED,2017-06-09 11:39:20.000000000,2017-06-19 12:03:36.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-06-09 11:39:20.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/panko/commit/372d0dda8958643f353aac7c5db1d80631f622c4', 'message': 'Fix html_last_updated_fmt for Python3.\n\nhtml_last_updated_fmt option is interpreted as a\nbyte string in python3, causing Sphinx build to break.\nThis patch makes it utf-8 string.\n\nChange-Id: I2a5b8a24a9c8f81a486f6e45661df136f33fa244\nCloses-Bug:#1693670\n'}]",0,472648,372d0dda8958643f353aac7c5db1d80631f622c4,4,2,1,20184,,,0,"Fix html_last_updated_fmt for Python3.

html_last_updated_fmt option is interpreted as a
byte string in python3, causing Sphinx build to break.
This patch makes it utf-8 string.

Change-Id: I2a5b8a24a9c8f81a486f6e45661df136f33fa244
Closes-Bug:#1693670
",git fetch https://review.opendev.org/openstack/panko refs/changes/48/472648/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,372d0dda8958643f353aac7c5db1d80631f622c4,bug/1693670, html_last_updated_fmt = subprocess.check_output(git_cmd).decode('utf-8')," html_last_updated_fmt = subprocess.Popen( git_cmd, stdout=subprocess.PIPE).communicate()[0]",1,2
openstack%2Fdocs-specs~master~Id1121be5bc974c6ad04e16912f3289a5d1c324bd,openstack/docs-specs,master,Id1121be5bc974c6ad04e16912f3289a5d1c324bd,Remove support for py34.,ABANDONED,2017-06-15 04:08:26.000000000,2017-06-19 11:59:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 15334}, {'_account_id': 25695}]","[{'number': 1, 'created': '2017-06-15 04:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/74ce33d78ca5068d64b36a241146dfafde969bb7', 'message': 'Remove support for py34.\n\nThe gating on python 3.4 is restricted to <= Mitaka. This is due to\nthe change from Ubuntu Trusty to Xenial, where only python3.5 is\navailable. There is no need to continue to keep these settings.\n\nChange-Id: Id1121be5bc974c6ad04e16912f3289a5d1c324bd\n'}, {'number': 2, 'created': '2017-06-19 03:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/e20c07ea54b48371000d2377a62f09127fe9970f', 'message': 'Remove support for py34.\n\nThe gating on python 3.4 is restricted to <= Mitaka. This is due to\nthe change from Ubuntu Trusty to Xenial, where only python3.5 is\navailable. There is no need to continue to keep these settings.\n\nChange-Id: Id1121be5bc974c6ad04e16912f3289a5d1c324bd\n'}, {'number': 3, 'created': '2017-06-19 03:08:17.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/4bc7c063a2358b14573fe086a2e0d88127b505e7', 'message': 'Remove support for py34.\n\nThe gating on python 3.4 is restricted to <= Mitaka. This is due to\nthe change from Ubuntu Trusty to Xenial, where only python3.5 is\navailable. There is no need to continue to keep these settings.\n\nChange-Id: Id1121be5bc974c6ad04e16912f3289a5d1c324bd\n'}]",0,474443,4bc7c063a2358b14573fe086a2e0d88127b505e7,11,5,3,25695,,,0,"Remove support for py34.

The gating on python 3.4 is restricted to <= Mitaka. This is due to
the change from Ubuntu Trusty to Xenial, where only python3.5 is
available. There is no need to continue to keep these settings.

Change-Id: Id1121be5bc974c6ad04e16912f3289a5d1c324bd
",git fetch https://review.opendev.org/openstack/docs-specs refs/changes/43/474443/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,74ce33d78ca5068d64b36a241146dfafde969bb7,, , Programming Language :: Python :: 3.4,1,1
openstack%2Fmanila~master~I6c2ea07b0bfc5852b28e44989406cc10eb972e39,openstack/manila,master,I6c2ea07b0bfc5852b28e44989406cc10eb972e39,Use parenthesis instead of backslashes in share folder,MERGED,2017-06-15 09:45:16.000000000,2017-06-19 11:58:09.000000000,2017-06-19 11:58:09.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 16643}]","[{'number': 1, 'created': '2017-06-15 09:45:16.000000000', 'files': ['manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_single_svm.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/share/drivers/zfssa/restclient.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/50df32ceec6e3b5c26669d773527ba4ff7a6477e', 'message': 'Use parenthesis instead of backslashes in share folder\n\nUse parenthesis instead of backslashes in share folder\n\nTrivialFix\nChange-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e39\n'}]",0,474523,50df32ceec6e3b5c26669d773527ba4ff7a6477e,19,5,1,15100,,,0,"Use parenthesis instead of backslashes in share folder

Use parenthesis instead of backslashes in share folder

TrivialFix
Change-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e39
",git fetch https://review.opendev.org/openstack/manila refs/changes/23/474523/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_single_svm.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/share/drivers/zfssa/restclient.py']",6,50df32ceec6e3b5c26669d773527ba4ff7a6477e,trivialfix, self.headers['x-auth-session'] = ( result.get_header('x-auth-session')), self.headers['x-auth-session'] = \ result.get_header('x-auth-session'),34,34
openstack%2Freno~master~I545833e4d7ede4435e4f50bed792a60847e9a813,openstack/reno,master,I545833e4d7ede4435e4f50bed792a60847e9a813,Replace http with https,MERGED,2017-06-19 00:59:36.000000000,2017-06-19 11:54:45.000000000,2017-06-19 11:54:45.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 22406}]","[{'number': 1, 'created': '2017-06-19 00:59:36.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst', 'doc/source/usage.rst', 'setup.cfg', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/reno/commit/0d45aee7dceba7e1ddafdfb995d1b6a45e252a6a', 'message': 'Replace http with https\n\nThe use of https and some of them are http.\nUse https instead of http to ensure the safety without containing our\naccount/password information.\ne.g. https://review.openstack.org/#/c/462890/\n\nChange-Id: I545833e4d7ede4435e4f50bed792a60847e9a813\n'}]",0,475204,0d45aee7dceba7e1ddafdfb995d1b6a45e252a6a,10,4,1,25433,,,0,"Replace http with https

The use of https and some of them are http.
Use https instead of http to ensure the safety without containing our
account/password information.
e.g. https://review.openstack.org/#/c/462890/

Change-Id: I545833e4d7ede4435e4f50bed792a60847e9a813
",git fetch https://review.opendev.org/openstack/reno refs/changes/04/475204/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'README.rst', 'doc/source/usage.rst', 'setup.cfg', 'HACKING.rst']",5,0d45aee7dceba7e1ddafdfb995d1b6a45e252a6a,http2https,Read the OpenStack Style Commandments https://docs.openstack.org/developer/hacking/,Read the OpenStack Style Commandments http://docs.openstack.org/developer/hacking/,10,10
openstack%2Fneutron-lib~master~I60e1a99780202de14522f592288d3a9af7a75592,openstack/neutron-lib,master,I60e1a99780202de14522f592288d3a9af7a75592,Make port_range validator accept an integer,MERGED,2017-06-08 08:47:32.000000000,2017-06-19 11:53:50.000000000,2017-06-19 11:53:50.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 9396}, {'_account_id': 10850}, {'_account_id': 17776}]","[{'number': 1, 'created': '2017-06-08 08:47:32.000000000', 'files': ['neutron_lib/tests/unit/api/validators/test_validators.py', 'neutron_lib/api/validators/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/29a31c152caacdb4d73acb534260443fd07801b0', 'message': ""Make port_range validator accept an integer\n\nIt used to accept an integer but it has been changed for\nsome reasons when migrating to neutron-lib.\nFor compatibility, it's better to keep the original behaviour.\nAfter all, the original behaviour seems reasonable to me.\n\nCloses-Bug: #1696682\nRelated-Bug: #1696389\nChange-Id: I60e1a99780202de14522f592288d3a9af7a75592\n""}]",0,472155,29a31c152caacdb4d73acb534260443fd07801b0,13,7,1,6854,,,0,"Make port_range validator accept an integer

It used to accept an integer but it has been changed for
some reasons when migrating to neutron-lib.
For compatibility, it's better to keep the original behaviour.
After all, the original behaviour seems reasonable to me.

Closes-Bug: #1696682
Related-Bug: #1696389
Change-Id: I60e1a99780202de14522f592288d3a9af7a75592
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/55/472155/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/tests/unit/api/validators/test_validators.py', 'neutron_lib/api/validators/__init__.py']",2,29a31c152caacdb4d73acb534260443fd07801b0,bug/1696682, data = str(data)," if validate_string_or_none(data): msg = _(""Port range must be a string."") LOG.debug(msg) return msg",6,5
openstack%2Fmanila~master~I6c2ea07b0bfc5852b28e44989406cc10eb972e28,openstack/manila,master,I6c2ea07b0bfc5852b28e44989406cc10eb972e28,Use parenthesis instead of backslashes in API folder,MERGED,2017-06-15 09:25:37.000000000,2017-06-19 11:48:28.000000000,2017-06-19 11:48:28.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 16643}]","[{'number': 1, 'created': '2017-06-15 09:25:37.000000000', 'files': ['manila/api/v2/share_networks.py', 'manila/api/v1/shares.py', 'manila/api/v2/share_types.py', 'manila/api/v1/router.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/cffbc0d5aca2dc7d2b5305c329783394f98619fb', 'message': 'Use parenthesis instead of backslashes in API folder\n\nUse parenthesis instead of backslashes in API folder\n\nTrivialFix\nChange-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e28\n'}]",0,474510,cffbc0d5aca2dc7d2b5305c329783394f98619fb,20,5,1,15100,,,0,"Use parenthesis instead of backslashes in API folder

Use parenthesis instead of backslashes in API folder

TrivialFix
Change-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e28
",git fetch https://review.opendev.org/openstack/manila refs/changes/10/474510/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/v2/share_networks.py', 'manila/api/v1/shares.py', 'manila/api/v2/share_types.py', 'manila/api/v1/router.py']",4,cffbc0d5aca2dc7d2b5305c329783394f98619fb,TrivialFix," self.resources[""security_services""] = ( security_service.create_resource())"," self.resources[""security_services""] = \ security_service.create_resource()",10,10
openstack%2Fopenstack-manuals~master~I02fdeef4da5be1f07a0f38b82801c331120859ab,openstack/openstack-manuals,master,I02fdeef4da5be1f07a0f38b82801c331120859ab,Add link to congressclient docs,MERGED,2017-01-30 06:39:30.000000000,2017-06-19 11:36:02.000000000,2017-06-19 11:36:02.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10607}]","[{'number': 1, 'created': '2017-01-30 06:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/41f30db8be1b606959bdf3029f2d9900c4cc71ce', 'message': 'Add link to congressclient docs\n\nChange-Id: I02fdeef4da5be1f07a0f38b82801c331120859ab\n'}, {'number': 2, 'created': '2017-02-01 05:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ee5dcc31881de6f9b72cdafdb78771707956d694', 'message': 'Add link to congressclient docs\n\nChange-Id: I02fdeef4da5be1f07a0f38b82801c331120859ab\n'}, {'number': 3, 'created': '2017-06-19 08:39:05.000000000', 'files': ['www/developer/language-bindings.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9eb0f17d4d147a486793700ee804f81432ca0f79', 'message': 'Add link to congressclient docs\n\nChange-Id: I02fdeef4da5be1f07a0f38b82801c331120859ab\n'}]",1,426651,9eb0f17d4d147a486793700ee804f81432ca0f79,20,3,3,11278,,,0,"Add link to congressclient docs

Change-Id: I02fdeef4da5be1f07a0f38b82801c331120859ab
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/426651/1 && git format-patch -1 --stdout FETCH_HEAD,['www/developer/language-bindings.html'],1,41f30db8be1b606959bdf3029f2d9900c4cc71ce,c-docs," <a href=""/developer/python-congressclient/""> Governance service Python Bindings (congress client) </a>",,3,0
openstack%2Fopenstack-manuals~master~I4a556b6a596a28c0350c7411c147459c3f06d084,openstack/openstack-manuals,master,I4a556b6a596a28c0350c7411c147459c3f06d084,[user-guide] Fix bdm incompatibility,MERGED,2017-06-07 02:23:38.000000000,2017-06-19 11:35:47.000000000,2017-06-19 11:35:47.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 8021}, {'_account_id': 10607}, {'_account_id': 19779}]","[{'number': 1, 'created': '2017-06-07 02:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5e260f7a29886cb22d4fc1c4951f70650acfc150', 'message': ""[user-guide] Fix bdm incompatibility\n\nThe 'block-device' option is incompatible\nin launching instance, need to fix it.\n\nChange-Id: I4a556b6a596a28c0350c7411c147459c3f06d084\nCloses-Bug: #1671404\n""}, {'number': 2, 'created': '2017-06-12 01:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3a04dcfa52b75bcd81e882fc826ced393d297b83', 'message': ""[user-guide] Fix bdm incompatibility\n\nThe 'block-device' option is incompatible\nin launching instance, need to fix it.\nAll tables in the section are also updated.\n\nChange-Id: I4a556b6a596a28c0350c7411c147459c3f06d084\nCloses-Bug: #1671404\n""}, {'number': 3, 'created': '2017-06-14 06:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/43a6e0709ed3ec63cb0d22bb7541d47134041762', 'message': ""[user-guide] Fix bdm incompatibility\n\nThe 'block-device' option is incompatible\nin launching instance, need to fix it.\nAll tables in the section are also updated.\n\nChange-Id: I4a556b6a596a28c0350c7411c147459c3f06d084\nCloses-Bug: #1671404\n""}, {'number': 4, 'created': '2017-06-19 01:35:07.000000000', 'files': ['doc/user-guide/source/cli-nova-launch-instance-from-volume.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/359880bf4df0f7a178cf2cce7f9466f508c2a07a', 'message': ""[user-guide] Fix bdm incompatibility\n\nThe 'block-device' option is incompatible\nin launching instance, need to fix it.\nAll tables in the section are also updated.\n\nChange-Id: I4a556b6a596a28c0350c7411c147459c3f06d084\nCloses-Bug: #1671404\n""}]",9,471543,359880bf4df0f7a178cf2cce7f9466f508c2a07a,19,5,4,8021,,,0,"[user-guide] Fix bdm incompatibility

The 'block-device' option is incompatible
in launching instance, need to fix it.
All tables in the section are also updated.

Change-Id: I4a556b6a596a28c0350c7411c147459c3f06d084
Closes-Bug: #1671404
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/471543/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/source/cli-nova-launch-instance-from-volume.rst'],1,5e260f7a29886cb22d4fc1c4951f70650acfc150,bug/1671404," - ``--block-device-mapping`` - ``--volume`` * - Boot from an existing source volume or snapshot. - ``--volume`` instance, use the ``--block-device-mapping`` parameter. For example: .. code-block:: console $ openstack server create --flavor FLAVOR --image IMAGE \ --block-device-mapping DEV-NAME=ID:TYPE:SIZE:DELETE_ON_TERMINATE \ NAME The parameters are: - ``--flavor`` The flavor ID or name. - ``--image`` The image ID or name. - ``--block-device-mapping`` DEV-NAME=ID:TYPE:SIZE:DELETE_ON_TERMINATE **DEV-NAME** The device name to attch the volume when the instance is booted. **ID** The ID of the source object. **TYPE** Which type object to create the volume. ``volume`` chooses volume to create. ``snapshot`` chooses snapshot to create. **SIZE** The size(GB) of the volume that is created. **DELETE_ON_TERMINATE** What to do with the volume when the instance is terminated. ``false`` does not delete the volume. ``true`` deletes the volume. - ``NAME``. The name for the server.#. Create a VM from previously created bootable volume, use the ``--volume`` parameter. The volume is not | updated | 2016-10-19T13:29:54Z | | created | 2016-10-19T13:29:53Z | | os-extended-volumes:volumes_attached | [{""id"": ""c612f739...""}] |"," - ``--block-device`` - ``--block-device`` * - Boot from an existing source image, volume, or snapshot. - ``--block-device`` instance.#. To create a bootable volume from an image and launch an instance from this volume, use the ``--block-device`` parameter. For example: .. code-block:: console $ openstack server create --flavor FLAVOR --block-device \ source=SOURCE,id=ID,dest=DEST,size=SIZE,shutdown=PRESERVE,bootindex=INDEX \ NAME The parameters are: - ``--flavor`` The flavor ID or name. - ``--block-device`` source=SOURCE,id=ID,dest=DEST,size=SIZE,shutdown=PRESERVE,bootindex=INDEX **source=SOURCE** The type of object used to create the block device. Valid values are ``volume``, ``snapshot``, ``image``, and ``blank``. **id=ID** The ID of the source object. **dest=DEST** The type of the target virtual device. Valid values are ``volume`` and ``local``. **size=SIZE** The size of the volume that is created. **shutdown={preserve\|remove}** What to do with the volume when the instance is deleted. ``preserve`` does not delete the volume. ``remove`` deletes the volume. **bootindex=INDEX** Orders the boot disks. Use ``0`` to boot from this volume. - ``NAME``. The name for the server. #. Create a VM from previously created bootable volume. The volume is not --block-device source=volume,id=$VOLUME_ID,dest=volume,size=10,shutdown=preserve,bootindex=0 \ | updated | 2014-02-02T13:29:54Z | | created | 2014-02-02T13:29:53Z | | os-extended-volumes:volumes_attached | [{""id"": ""2fff50ab...""}] |",50,53
openstack%2Frally~master~I16d105f3354a7429cbc4569923da980645292b4d,openstack/rally,master,I16d105f3354a7429cbc4569923da980645292b4d,[docs] include required platforms of plugins,MERGED,2017-04-19 13:56:49.000000000,2017-06-19 11:35:00.000000000,2017-06-19 11:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2017-04-19 13:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c4d78909d0694bef41f91d8e70f76df0d4aaf231', 'message': '[docs] include required platforms of plugins\n\nChange-Id: I16d105f3354a7429cbc4569923da980645292b4d\n'}, {'number': 2, 'created': '2017-06-16 12:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1e1d2a75f0968f2014c245a14ce198eb67977749', 'message': '[docs] include required platforms of plugins\n\nChange-Id: I16d105f3354a7429cbc4569923da980645292b4d\n'}, {'number': 3, 'created': '2017-06-16 12:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3b964704d13ab54efecbf26622efdd7cac8d0894', 'message': '[docs] include required platforms of plugins\n\nChange-Id: I16d105f3354a7429cbc4569923da980645292b4d\n'}, {'number': 4, 'created': '2017-06-16 13:27:37.000000000', 'files': ['doc/ext/plugin_reference.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/4b0dfb4f2ffeb36d29b144c657e4641e6d917f59', 'message': '[docs] include required platforms of plugins\n\nChange-Id: I16d105f3354a7429cbc4569923da980645292b4d\n'}]",0,458084,4b0dfb4f2ffeb36d29b144c657e4641e6d917f59,15,3,4,9545,,,0,"[docs] include required platforms of plugins

Change-Id: I16d105f3354a7429cbc4569923da980645292b4d
",git fetch https://review.opendev.org/openstack/rally refs/changes/84/458084/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ext/plugin_reference.py', 'rally/plugins/openstack/context/cinder/volumes.py', 'rally/plugins/openstack/context/ceilometer/samples.py', 'rally/plugins/openstack/context/cinder/volume_types.py']",4,c4d78909d0694bef41f91d8e70f76df0d4aaf231,required_platform,"from rally.common import validation@validation.add(""required_platform"", platform=""openstack"", admin=True)",,31,0
openstack%2Frally~master~I66e5cff27c043fc07caf9053512b2b3088808e8e,openstack/rally,master,I66e5cff27c043fc07caf9053512b2b3088808e8e,deployment.list() return the serial result,MERGED,2017-06-16 07:46:22.000000000,2017-06-19 11:34:53.000000000,2017-06-19 11:34:53.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 21528}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-06-16 07:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/354d679a79f993d6e903b652a44fa9a3db8f711b', 'message': 'deployment.list() return the serial result\n\nraas need the serial result, So we should fix\nthe result to a serial result.\n\nChange-Id: I66e5cff27c043fc07caf9053512b2b3088808e8e\n'}, {'number': 2, 'created': '2017-06-17 09:20:23.000000000', 'files': ['rally/api.py', 'tests/unit/test_api.py', 'rally/common/objects/deploy.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/8ccea5967e9d1852b371dde42b04a4dc6ffdafd5', 'message': 'deployment.list() return the serial result\n\nraas need the serial result, So we should fix\nthe result to a serial result.\n\nChange-Id: I66e5cff27c043fc07caf9053512b2b3088808e8e\n'}]",0,474880,8ccea5967e9d1852b371dde42b04a4dc6ffdafd5,19,5,2,22960,,,0,"deployment.list() return the serial result

raas need the serial result, So we should fix
the result to a serial result.

Change-Id: I66e5cff27c043fc07caf9053512b2b3088808e8e
",git fetch https://review.opendev.org/openstack/rally refs/changes/80/474880/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/api.py', 'tests/unit/test_api.py']",2,354d679a79f993d6e903b652a44fa9a3db8f711b,serialization," mock_deployment = mock.Mock() mock_deployment.to_dict.return_value = self.deployment mock_deployment_list.return_value = [mock_deployment] self.assertEqual(ret[0][key], self.deployment[key])"," mock_deployment_list.return_value = self.deployment self.assertEqual(ret[key], self.deployment[key])",6,3
openstack%2Fhorizon~stable%2Focata~I134abc8a2a52aa68433765510f69969626f46a6e,openstack/horizon,stable/ocata,I134abc8a2a52aa68433765510f69969626f46a6e,Imported Translations from Zanata,MERGED,2017-06-19 10:28:11.000000000,2017-06-19 11:34:17.000000000,2017-06-19 11:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 12826}]","[{'number': 1, 'created': '2017-06-19 10:28:11.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8eb4ff5d0fc9fed89c4e56f93efb014df177fd12', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I134abc8a2a52aa68433765510f69969626f46a6e\n'}]",0,475320,8eb4ff5d0fc9fed89c4e56f93efb014df177fd12,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I134abc8a2a52aa68433765510f69969626f46a6e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/20/475320/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",14,8eb4ff5d0fc9fed89c4e56f93efb014df177fd12,zanata/translations,"""Project-Id-Version: horizon 11.0.2.dev38\n""""POT-Creation-Date: 2017-05-24 19:32+0000\n""","""Project-Id-Version: horizon 11.0.1.dev4\n""""POT-Creation-Date: 2017-03-02 22:48+0000\n""msgid ""Admin State is UP (True) by default."" msgstr ""Admin State is UP (True) by default."" msgid """" ""The router, subnet and admin state fields are required. All others are "" ""optional."" msgstr """" ""The router, subnet and admin state fields are required. All others are "" ""optional."" msgid """" ""The state of IPSec site connection to start in. If DOWN (False), IPSec site "" ""connection does not forward packets."" msgstr """" ""The state of IPSec site connection to start in. If DOWN (False), IPSec site "" ""connection does not forward packets."" msgid """" ""The state of VPN service to start in. If DOWN (False) VPN service does not "" ""forward packets."" msgstr """" ""The state of VPN service to start in. If DOWN (False) VPN service does not "" ""forward packets."" ",46,296
openstack%2Fhorizon~master~I0c180146e499c9e48425c7eb4b73792baa6cdb0c,openstack/horizon,master,I0c180146e499c9e48425c7eb4b73792baa6cdb0c,Switch render() arguments to the new way,MERGED,2017-06-17 16:55:35.000000000,2017-06-19 11:33:30.000000000,2017-06-19 11:33:30.000000000,"[{'_account_id': 3}, {'_account_id': 12826}, {'_account_id': 15905}, {'_account_id': 25747}]","[{'number': 1, 'created': '2017-06-17 16:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bfbc47af343f3f003fb1cd7b8bb9a0914770e358', 'message': 'Swift render() arguments to the new way\n\nPreviously template.render() takes Context or RequestContext object\nbut after Django 1.8 the method takes a dict and request as separate\narguments. The old way will be dropped in Django 1.10.\nThis commit update the usage based on the Django 1.8 release notes [1].\n\n[1] https://docs.djangoproject.com/en/1.8/ref/templates/upgrading/#get-template-and-select-template\n\nChange-Id: I0c180146e499c9e48425c7eb4b73792baa6cdb0c\n'}, {'number': 2, 'created': '2017-06-17 16:59:26.000000000', 'files': ['horizon/workflows/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/95d78a140fdb6f24dc3bd87d654e9f927ddfbfa4', 'message': 'Switch render() arguments to the new way\n\nPreviously template.render() takes Context or RequestContext object\nbut after Django 1.8 the method takes a dict and request as separate\narguments. The old way will be dropped in Django 1.10.\nThis commit update the usage based on the Django 1.8 release notes [1].\n\n[1] https://docs.djangoproject.com/en/1.8/ref/templates/upgrading/#get-template-and-select-template\n\nChange-Id: I0c180146e499c9e48425c7eb4b73792baa6cdb0c\n'}]",0,475137,95d78a140fdb6f24dc3bd87d654e9f927ddfbfa4,11,4,2,841,,,0,"Switch render() arguments to the new way

Previously template.render() takes Context or RequestContext object
but after Django 1.8 the method takes a dict and request as separate
arguments. The old way will be dropped in Django 1.10.
This commit update the usage based on the Django 1.8 release notes [1].

[1] https://docs.djangoproject.com/en/1.8/ref/templates/upgrading/#get-template-and-select-template

Change-Id: I0c180146e499c9e48425c7eb4b73792baa6cdb0c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/37/475137/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/workflows/base.py'],1,bfbc47af343f3f003fb1cd7b8bb9a0914770e358,render-parameter," return step_template.render(extra_context, self.workflow.request) return workflow_template.render(extra_context, self.request)"," context = template.RequestContext(self.workflow.request, extra_context) return step_template.render(context) context = template.RequestContext(self.request, extra_context) return workflow_template.render(context)",2,4
openstack%2Fpython-searchlightclient~master~Id84731ff04ebad1a5b90adabb6fba4f52a6ea1f7,openstack/python-searchlightclient,master,Id84731ff04ebad1a5b90adabb6fba4f52a6ea1f7,Updated from global requirements,MERGED,2017-06-10 21:49:01.000000000,2017-06-19 11:28:56.000000000,2017-06-19 11:28:56.000000000,"[{'_account_id': 3}, {'_account_id': 10063}]","[{'number': 1, 'created': '2017-06-10 21:49:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-searchlightclient/commit/4dddff44dc6b89da4c298e2984e2099cf579ab91', 'message': 'Updated from global requirements\n\nChange-Id: Id84731ff04ebad1a5b90adabb6fba4f52a6ea1f7\n'}]",0,473040,4dddff44dc6b89da4c298e2984e2099cf579ab91,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Id84731ff04ebad1a5b90adabb6fba4f52a6ea1f7
",git fetch https://review.opendev.org/openstack/python-searchlightclient refs/changes/40/473040/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,4dddff44dc6b89da4c298e2984e2099cf579ab91,openstack/requirements,requests>=2.14.2 # Apache-2.0,"requests!=2.12.2,!=2.13.0,>=2.10.0 # Apache-2.0",1,1
openstack%2Fkolla-ansible~master~I79d41e94ee3361f2b4d831d17b1bb34a1964f580,openstack/kolla-ansible,master,I79d41e94ee3361f2b4d831d17b1bb34a1964f580,Fix mongodb name in cron.json,MERGED,2017-06-06 11:13:26.000000000,2017-06-19 11:22:46.000000000,2017-06-19 11:22:46.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 7488}, {'_account_id': 8157}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-06 11:13:26.000000000', 'files': ['ansible/roles/common/templates/cron.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/483f32edb6aa4dce67e128fea92334d45e5e3d81', 'message': 'Fix mongodb name in cron.json\n\nThere is a typo in cron.json making cron to fail\nwhen mongodb is enabled.\nOnly affect master.\n\n```MissingRequiredSource:\n/var/lib/kolla/config_files/logrotate/mongdb.conf file is not found```\n\nChange-Id: I79d41e94ee3361f2b4d831d17b1bb34a1964f580\n'}]",0,471316,483f32edb6aa4dce67e128fea92334d45e5e3d81,13,5,1,19316,,,0,"Fix mongodb name in cron.json

There is a typo in cron.json making cron to fail
when mongodb is enabled.
Only affect master.

```MissingRequiredSource:
/var/lib/kolla/config_files/logrotate/mongdb.conf file is not found```

Change-Id: I79d41e94ee3361f2b4d831d17b1bb34a1964f580
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/16/471316/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/templates/cron.json.j2'],1,483f32edb6aa4dce67e128fea92334d45e5e3d81,fix-mongodb-name," ( 'mongodb', enable_mongodb ),"," ( 'mongdb', enable_mongodb ),",1,1
openstack%2Fhorizon~stable%2Fnewton~I272f7f1b20cc1276976c464a82d1776de92d17e7,openstack/horizon,stable/newton,I272f7f1b20cc1276976c464a82d1776de92d17e7,Add config for default create volume option,ABANDONED,2017-06-09 20:44:51.000000000,2017-06-19 11:17:25.000000000,,"[{'_account_id': 3}, {'_account_id': 1004}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-09 20:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1e86df329d4de0c7b89ddab93ce54de38c27cb9a', 'message': 'Add config for default create volume option\n\nThis patch adds the ability to configure the default ""create volume""\nvalue when launching an instance with Cinder enabled.\n\nCo-Authored-By: Rob Cresswell <robert.cresswell@outlook.com>\n\nCloses-Bug: 1678109\nChange-Id: I272f7f1b20cc1276976c464a82d1776de92d17e7\n(cherry picked from commit d734f482ece979018801f38242933dd627e8cd2d)\n'}, {'number': 2, 'created': '2017-06-10 08:22:46.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.spec.js', 'doc/source/topics/settings.rst', 'releasenotes/notes/bug-1678109-4440ebe90908647d.yaml', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.js', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c93142acb3e695f9ba6716ab96e7075265834697', 'message': 'Add config for default create volume option\n\nThis patch adds the ability to configure the default ""create volume""\nvalue when launching an instance with Cinder enabled.\n\nCo-Authored-By: Rob Cresswell <robert.cresswell@outlook.com>\n\nCloses-Bug: 1678109\nChange-Id: I272f7f1b20cc1276976c464a82d1776de92d17e7\n(cherry picked from commit d734f482ece979018801f38242933dd627e8cd2d)\n'}]",0,472815,c93142acb3e695f9ba6716ab96e7075265834697,8,5,2,6908,,,0,"Add config for default create volume option

This patch adds the ability to configure the default ""create volume""
value when launching an instance with Cinder enabled.

Co-Authored-By: Rob Cresswell <robert.cresswell@outlook.com>

Closes-Bug: 1678109
Change-Id: I272f7f1b20cc1276976c464a82d1776de92d17e7
(cherry picked from commit d734f482ece979018801f38242933dd627e8cd2d)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/15/472815/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.spec.js', 'doc/source/topics/settings.rst', 'releasenotes/notes/bug-1678109-4440ebe90908647d.yaml', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.controller.js', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.spec.js']",7,1e86df329d4de0c7b89ddab93ce54de38c27cb9a,bug/1678109," create_volume: true, it('should default create_volume to true if setting not provided', function() { delete settings.LAUNCH_INSTANCE_DEFAULTS.create_volume; model.initialize(true); scope.$apply(); expect(model.newInstanceSpec.create_volume_default).toBe(true); }); it('should default create_volume to false based on setting', function() { settings.LAUNCH_INSTANCE_DEFAULTS.create_volume = false; model.initialize(true); scope.$apply(); expect(model.newInstanceSpec.create_volume_default).toBe(false); }); delete settings.LAUNCH_INSTANCE_DEFAULTS.create_volume; expect(model.newInstanceSpec.create_volume_default).toBe(true); it('sets create volume to true', function() { expect(model.newInstanceSpec.create_volume_default).toBe(true); }); ",,42,2
openstack%2Fqinling~master~I92ea36f668073f380a4aef4526a6fad321d8cc95,openstack/qinling,master,I92ea36f668073f380a4aef4526a6fad321d8cc95,Support to sepcify module.function for python function,MERGED,2017-06-19 11:09:19.000000000,2017-06-19 11:16:53.000000000,2017-06-19 11:16:53.000000000,"[{'_account_id': 3}, {'_account_id': 6732}]","[{'number': 1, 'created': '2017-06-19 11:09:19.000000000', 'files': ['qinling/api/controllers/v1/function.py', 'qinling/orchestrator/kubernetes/manager.py', 'qinling/engine/default_engine.py', 'runtimes/python2/server.py'], 'web_link': 'https://opendev.org/openstack/qinling/commit/fa10083c3bb5d65720c26dae752680ddf11c06fb', 'message': ""Support to sepcify module.function for python function\n\nCurrenty, the function entry is hard-coded to be 'main.main' which is\nnot flexible. This patch adds support for specifying module name and\nfunction name in the code package.\n\nChange-Id: I92ea36f668073f380a4aef4526a6fad321d8cc95\n""}]",0,475334,fa10083c3bb5d65720c26dae752680ddf11c06fb,6,2,1,6732,,,0,"Support to sepcify module.function for python function

Currenty, the function entry is hard-coded to be 'main.main' which is
not flexible. This patch adds support for specifying module name and
function name in the code package.

Change-Id: I92ea36f668073f380a4aef4526a6fad321d8cc95
",git fetch https://review.opendev.org/openstack/qinling refs/changes/34/475334/1 && git format-patch -1 --stdout FETCH_HEAD,"['qinling/api/controllers/v1/function.py', 'qinling/orchestrator/kubernetes/manager.py', 'qinling/engine/default_engine.py', 'runtimes/python2/server.py']",4,fa10083c3bb5d65720c26dae752680ddf11c06fb,,"zip_file = '' function_module = 'main' function_method = 'main' entry = request.form['entry'] global zip_file zip_file = '%s.zip' % function_id 'Request received, download_url:%s, headers: %s, entry: %s' % (download_url, headers, entry) with open(zip_file, 'wb') as fd: if not zipfile.is_zipfile(zip_file): app.logger.info('Code package downloaded to %s' % zip_file) global function_module global function_method function_module, function_method = tuple(entry.rsplit('.', 1)) global zip_file global function_module global function_method importer = zipimport.zipimporter(zip_file) module = importer.load_module(function_module) func = getattr(module, function_method) result = func(**input)","file_name = '' global file_name file_name = '%s.zip' % function_id 'Request received, download_url:%s, headers: %s' % (download_url, headers) with open(file_name, 'wb') as fd: if not zipfile.is_zipfile(file_name): app.logger.info('Code package downloaded to %s' % file_name) global file_name importer = zipimport.zipimporter(file_name) module = importer.load_module('main') result = module.main(**input)",31,18
openstack%2Fneutron~master~I3fa2192271aed81fb6da658b8196b365a20fa286,openstack/neutron,master,I3fa2192271aed81fb6da658b8196b365a20fa286,net_helpers: Set process streams to text mode,MERGED,2017-06-15 12:32:20.000000000,2017-06-19 11:06:42.000000000,2017-06-16 04:33:10.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8655}, {'_account_id': 9656}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-15 12:32:20.000000000', 'files': ['neutron/tests/common/net_helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d619e54e2d51e6dafbdb4f9ac58e26dfc7b14a8', 'message': 'net_helpers: Set process streams to text mode\n\nRootHelperProcess extends Popen from subprocess and sets all\nstdin/stdout/stderr descriptors to PIPE. These descriptors use byte\narray by default in Python 3. If universal_newlines [1] is set for Popen\nobject, then those descriptors work in text mode.\n\n[1] https://docs.python.org/3.5/library/subprocess.html#popen-constructor\n\nChange-Id: I3fa2192271aed81fb6da658b8196b365a20fa286\n'}]",3,474563,5d619e54e2d51e6dafbdb4f9ac58e26dfc7b14a8,24,5,1,8655,,,0,"net_helpers: Set process streams to text mode

RootHelperProcess extends Popen from subprocess and sets all
stdin/stdout/stderr descriptors to PIPE. These descriptors use byte
array by default in Python 3. If universal_newlines [1] is set for Popen
object, then those descriptors work in text mode.

[1] https://docs.python.org/3.5/library/subprocess.html#popen-constructor

Change-Id: I3fa2192271aed81fb6da658b8196b365a20fa286
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/474563/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/common/net_helpers.py'],1,5d619e54e2d51e6dafbdb4f9ac58e26dfc7b14a8,func-py3," kwargs.setdefault('universal_newlines', True) return self._read_stream(self.stdout, timeout) self.stdin.write(data + os.linesep)"," return self._read_stream(self.stdout, timeout).decode('utf-8') self.stdin.write((data + os.linesep).encode('utf-8'))",4,2
openstack%2Fproject-config~master~Id93e35b5756226ba0d59d7c9ce7bc5c12ba8b55b,openstack/project-config,master,Id93e35b5756226ba0d59d7c9ce7bc5c12ba8b55b,Normalize projects.yaml,MERGED,2017-06-19 10:29:38.000000000,2017-06-19 11:04:35.000000000,2017-06-19 11:04:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-19 10:29:38.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b9be872bb9c988cf9d4c179452b34f2aea46d066', 'message': 'Normalize projects.yaml\n\nChange-Id: Id93e35b5756226ba0d59d7c9ce7bc5c12ba8b55b\n'}]",0,475321,b9be872bb9c988cf9d4c179452b34f2aea46d066,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: Id93e35b5756226ba0d59d7c9ce7bc5c12ba8b55b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/475321/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,b9be872bb9c988cf9d4c179452b34f2aea46d066,project-yaml-normalization," description: Environment, dependency and bootstrapping utilities for OpenStack and other services"," description: Environment, dependency and bootstrapping utilities for OpenStack and other services upstream: https://github.com/kazsuz/tap-as-a-service-dashboard.git",2,2
openstack%2Fnetworking-ovn~master~I69eabe87f0b236045cadde295ea2fc668f01c24c,openstack/networking-ovn,master,I69eabe87f0b236045cadde295ea2fc668f01c24c,DO NOT REVIEW: Test gate fix in devstack,ABANDONED,2017-06-19 10:16:55.000000000,2017-06-19 11:02:28.000000000,,"[{'_account_id': 3}, {'_account_id': 6773}]","[{'number': 1, 'created': '2017-06-19 10:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/dcb02fec226abe9da93664bfa7a6a0fdd642dd68', 'message': 'DO NOT REVIEW: Test gate fix in devstack\n\nChange-Id: I69eabe87f0b236045cadde295ea2fc668f01c24c\nDepends-On: Ib5a8ffe63eaec15bc29bfdd133db7169507bab82\n'}, {'number': 2, 'created': '2017-06-19 10:40:04.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/bc5bea65607bad0190b9c1f71480ec17744ef1ba', 'message': 'DO NOT REVIEW: Test gate fix in devstack\n\nChange-Id: I69eabe87f0b236045cadde295ea2fc668f01c24c\nDepends-On: Ib5a8ffe63eaec15bc29bfdd133db7169507bab82\n'}]",0,475318,bc5bea65607bad0190b9c1f71480ec17744ef1ba,5,2,2,6773,,,0,"DO NOT REVIEW: Test gate fix in devstack

Change-Id: I69eabe87f0b236045cadde295ea2fc668f01c24c
Depends-On: Ib5a8ffe63eaec15bc29bfdd133db7169507bab82
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/18/475318/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/journal/journal.py'],1,dcb02fec226abe9da93664bfa7a6a0fdd642dd68,test-gate-fix,# no-op,,1,0
openstack%2Fkolla~master~Ifed4bff187eee950ef6966c6540b56e3f1b4dbd9,openstack/kolla,master,Ifed4bff187eee950ef6966c6540b56e3f1b4dbd9,Fix RST syntax issue,ABANDONED,2016-11-10 09:45:07.000000000,2017-06-19 10:57:45.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2874}, {'_account_id': 16233}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 24164}]","[{'number': 1, 'created': '2016-11-10 09:45:07.000000000', 'files': ['doc/kuryr-guide.rst', 'doc/running-tests.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/74fe4a1f2828525483a0ce6394c1cc1944ecbc8d', 'message': 'Fix RST syntax issue\n\nUse `` instead of ```.\n\nChange-Id: Ifed4bff187eee950ef6966c6540b56e3f1b4dbd9\n'}]",0,396046,74fe4a1f2828525483a0ce6394c1cc1944ecbc8d,12,7,1,167,,,0,"Fix RST syntax issue

Use `` instead of ```.

Change-Id: Ifed4bff187eee950ef6966c6540b56e3f1b4dbd9
",git fetch https://review.opendev.org/openstack/kolla refs/changes/46/396046/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/kuryr-guide.rst', 'doc/running-tests.rst']",2,74fe4a1f2828525483a0ce6394c1cc1944ecbc8d,rst-syntax,the ``kolla/tests/test_kolla_docker.py`` file:,the ``kolla/tests/test_kolla_docker.py``` file:,3,3
openstack%2Fnetworking-bagpipe~master~I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f,openstack/networking-bagpipe,master,I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f,bagpipe-bgp: cleanups in dataplane drivers init,MERGED,2017-06-16 13:59:20.000000000,2017-06-19 10:45:28.000000000,2017-06-19 10:45:28.000000000,"[{'_account_id': 3}, {'_account_id': 12021}]","[{'number': 1, 'created': '2017-06-16 13:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/ed389736f99acb3126d7c4fd07ecfd21427ff84f', 'message': ""bagpipe-bgp: cleanups in IPVPN dataplane drivers init\n\n* linux ipvpn driver __init__ hadn't been updated\n  to follow 67a55405882843c8cdf88b6e51f0ca7d07e137fa\n* ovs ipvpn driver had useless calls to looking glass\n  logger init\n\nChange-Id: I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f\n""}, {'number': 2, 'created': '2017-06-16 14:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/96282ce9a1a53153aadcaae078838f4018944401', 'message': ""bagpipe-bgp: cleanups in IPVPN dataplane drivers init\n\n* linux ipvpn driver __init__ hadn't been updated\n  to follow 67a55405882843c8cdf88b6e51f0ca7d07e137fa\n* ovs ipvpn driver had calls to looking glass logger __init__,\n  done to allow a useless log\n* inheritance to LookingGlassLogger was not necessary\n  in many places\n* the code has been updated to use super(..) to for __init__\n\nChange-Id: I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f\n""}, {'number': 3, 'created': '2017-06-16 16:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/80383fc5f3d24b579a78aa45a4a525c800d1eecf', 'message': ""bagpipe-bgp: cleanups in dataplane drivers init\n\n* linux ipvpn driver __init__ hadn't been updated\n  to follow 67a55405882843c8cdf88b6e51f0ca7d07e137fa\n* ovs ipvpn driver had calls to looking glass logger __init__,\n  done to allow a useless log\n* inheritance to LookingGlassLogger was not necessary\n  in many places\n* the code has been updated to use super(..) for __init__\n  inheritance\n\nChange-Id: I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f\n""}, {'number': 4, 'created': '2017-06-19 08:09:16.000000000', 'files': ['networking_bagpipe/bagpipe_bgp/vpn/evpn/linux_vxlan.py', 'networking_bagpipe/bagpipe_bgp/vpn/dataplane_drivers.py', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_ovs_dataplane.py', 'networking_bagpipe/bagpipe_bgp/common/looking_glass.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/8ed4c24855bacf9c8d9233c43038d56dec7b1a77', 'message': ""bagpipe-bgp: cleanups in dataplane drivers init\n\n* linux ipvpn driver __init__ hadn't been updated\n  to follow 67a55405882843c8cdf88b6e51f0ca7d07e137fa\n* ovs ipvpn driver had calls to looking glass logger __init__,\n  done to allow a useless log\n* inheritance to LookingGlassLogger was not necessary\n  in many places\n* the code has been updated to use super(..) for __init__\n  inheritance\n\nChange-Id: I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f\n""}]",0,474984,8ed4c24855bacf9c8d9233c43038d56dec7b1a77,11,2,4,12021,,,0,"bagpipe-bgp: cleanups in dataplane drivers init

* linux ipvpn driver __init__ hadn't been updated
  to follow 67a55405882843c8cdf88b6e51f0ca7d07e137fa
* ovs ipvpn driver had calls to looking glass logger __init__,
  done to allow a useless log
* inheritance to LookingGlassLogger was not necessary
  in many places
* the code has been updated to use super(..) for __init__
  inheritance

Change-Id: I61ca84a590045a1a4ec87d3a1ba1a7c2ee67679f
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/84/474984/4 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_ovs_dataplane.py']",2,ed389736f99acb3126d7c4fd07ecfd21427ff84f,ipvpn_driver_cleanups, def __init__(self):," def __init__(self, init=True): lg.LookingGlassLocalLogger.__init__(self) ",3,9
openstack%2Fkolla-ansible~master~I375b5876ec2f4c4f32b9f6b3f41d209a59a0f615,openstack/kolla-ansible,master,I375b5876ec2f4c4f32b9f6b3f41d209a59a0f615,Use cryptography instead of pycrypto,MERGED,2017-04-24 08:47:07.000000000,2017-06-19 10:44:53.000000000,2017-06-19 10:44:53.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1390}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22959}]","[{'number': 1, 'created': '2017-04-24 08:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2f7e6751ad485083a7d6bf28368528519ce01245', 'message': 'Use cryptography instead of pycrypto\n\npycrypto is no longer maintained [1]. This patch rewrites functions\nusing pycrypto and replaces them with the cryptography equivalent\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2017-March/113568.html\n\nChange-Id: I375b5876ec2f4c4f32b9f6b3f41d209a59a0f615\n'}, {'number': 2, 'created': '2017-04-24 09:31:06.000000000', 'files': ['requirements.txt', 'kolla_ansible/cmd/genpwd.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/43d42d07dfd9faae5822018f800f08707c0b6bbe', 'message': 'Use cryptography instead of pycrypto\n\npycrypto is no longer maintained [1]. This patch rewrites functions\nusing pycrypto and replaces them with the cryptography equivalent\n\n[1] http://lists.openstack.org/pipermail/openstack-dev/2017-March/113568.html\n\nChange-Id: I375b5876ec2f4c4f32b9f6b3f41d209a59a0f615\n'}]",0,459195,43d42d07dfd9faae5822018f800f08707c0b6bbe,15,6,2,25111,,,0,"Use cryptography instead of pycrypto

pycrypto is no longer maintained [1]. This patch rewrites functions
using pycrypto and replaces them with the cryptography equivalent

[1] http://lists.openstack.org/pipermail/openstack-dev/2017-March/113568.html

Change-Id: I375b5876ec2f4c4f32b9f6b3f41d209a59a0f615
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/95/459195/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'kolla_ansible/cmd/genpwd.py']",2,2f7e6751ad485083a7d6bf28368528519ce01245,crypto,"from cryptography.hazmat.backends import default_backend from cryptography.hazmat.primitives import serialization from cryptography.hazmat.primitives.asymmetric import rsa new_key = rsa.generate_private_key( public_exponent=65537, key_size=bits, backend=default_backend() ) private_key = new_key.private_bytes( encoding=serialization.Encoding.PEM, format=serialization.PrivateFormat.TraditionalOpenSSL, encryption_algorithm=serialization.NoEncryption() ) public_key = new_key.public_key().public_bytes( encoding=serialization.Encoding.OpenSSH, format=serialization.PublicFormat.OpenSSH )","from Crypto.PublicKey import RSA new_key = RSA.generate(bits, os.urandom) private_key = new_key.exportKey(""PEM"") public_key = new_key.publickey().exportKey(""OpenSSH"")",18,4
openstack%2Fmonasca-ui~master~I273f06332fa11a81ea8de2c13059dce9d160e90d,openstack/monasca-ui,master,I273f06332fa11a81ea8de2c13059dce9d160e90d,Add monitoring_policy.json,MERGED,2017-06-09 08:20:39.000000000,2017-06-19 10:39:57.000000000,2017-06-19 10:39:57.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 12542}, {'_account_id': 16168}, {'_account_id': 20033}, {'_account_id': 23043}, {'_account_id': 26141}]","[{'number': 1, 'created': '2017-06-09 08:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/c2641a02c6096eb9a7fde68a2929673782ec642f', 'message': 'Add monitoring_policy.json\n\nmonasca-ui misses policies file to control the permissions\nover actions executed from within Horizon plugin.\n\nChange-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d\n'}, {'number': 2, 'created': '2017-06-09 11:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/fda4d6f6406ca9f0f69a770dece5f82e5b79f9c9', 'message': 'Add monitoring_policy.json\n\nmonasca-ui misses policies file to control the permissions\nover actions executed from within Horizon plugin.\n\nChange-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d\n'}, {'number': 3, 'created': '2017-06-09 11:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/4a4a075f8ca4d971ea45799beb5139f72bf484e3', 'message': 'Add monitoring_policy.json\n\nmonasca-ui misses policies file to control the permissions\nover actions executed from within Horizon plugin.\n\nChange-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d\n'}, {'number': 4, 'created': '2017-06-11 17:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/52cdeb98dde7a7a453833014b4a7a7e1ed0f6bbd', 'message': 'Add monitoring_policy.json\n\nmonasca-ui misses policies file to control the permissions\nover actions executed from within Horizon plugin.\n\nChange-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d\n'}, {'number': 5, 'created': '2017-06-12 10:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/4214636b67fbf99e63afa586a7b99551336b2160', 'message': 'Add monitoring_policy.json\n\nmonasca-ui misses policies file to control the permissions\nover actions executed from within Horizon plugin.\n\nExtra:\n* enabled running tests with configured policies\n\nChange-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d\n'}, {'number': 6, 'created': '2017-06-19 05:18:26.000000000', 'files': ['monitoring/conf/monitoring_policy.json', 'test-requirements.txt', 'monitoring/test/helpers.py', 'monasca_policy.json.sample', 'monitoring/config/local_settings.py', 'tox.ini', 'README.md'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/a7e8a14c2d046ee2829f501aea889b6ffb47360c', 'message': 'Add monitoring_policy.json\n\nmonasca-ui misses policies file to control the permissions\nover actions executed from within Horizon plugin.\n\nExtra:\n* enabled running tests with configured policies\n* removed unbounded policy sample file\n\nChange-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d\n'}]",0,472575,a7e8a14c2d046ee2829f501aea889b6ffb47360c,20,8,6,16168,,,0,"Add monitoring_policy.json

monasca-ui misses policies file to control the permissions
over actions executed from within Horizon plugin.

Extra:
* enabled running tests with configured policies
* removed unbounded policy sample file

Change-Id: I273f06332fa11a81ea8de2c13059dce9d160e90d
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/75/472575/2 && git format-patch -1 --stdout FETCH_HEAD,"['monitoring/conf/monitoring_policy.json', 'monitoring/enabled/_50_admin_add_monitoring_panel.py']",2,c2641a02c6096eb9a7fde68a2929673782ec642f,policies," POLICY_FILES.update({'monitoring': 'monitoring_policy.json',})",,7,0
openstack%2Fmonasca-agent~master~I7557dec9044c4d43bd05c57c733d15df5ec1e736,openstack/monasca-agent,master,I7557dec9044c4d43bd05c57c733d15df5ec1e736,Check version using pbr module,MERGED,2017-06-19 08:22:47.000000000,2017-06-19 10:35:24.000000000,2017-06-19 10:35:24.000000000,"[{'_account_id': 3}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-06-19 08:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/3b5513220d597dc180f152d3c60b35aff9c7371a', 'message': 'Check version using pbr module\n\nUse pbr module to check package version.\n\nChange-Id: I7557dec9044c4d43bd05c57c733d15df5ec1e736\n'}, {'number': 2, 'created': '2017-06-19 08:24:55.000000000', 'files': ['monasca_agent/version.py', 'monasca_agent/common/config.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/4e6d7bee76879cd19d70d28a80e0ecbee7ffaa55', 'message': 'Check version using pbr module\n\nUse pbr module to check package version.\n\nChange-Id: I7557dec9044c4d43bd05c57c733d15df5ec1e736\n'}]",0,475287,4e6d7bee76879cd19d70d28a80e0ecbee7ffaa55,7,2,2,20033,,,0,"Check version using pbr module

Use pbr module to check package version.

Change-Id: I7557dec9044c4d43bd05c57c733d15df5ec1e736
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/87/475287/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_agent/version.py', 'monasca_agent/common/config.py']",2,3b5513220d597dc180f152d3c60b35aff9c7371a,version,from monasca_agent import version return version.version_string," return pkg_resources.require(""monasca-agent"")[0].version",22,1
openstack%2Fopenstack-ansible-rabbitmq_server~master~I32960337a233083907d12b0e23ceec6dacb1c0a8,openstack/openstack-ansible-rabbitmq_server,master,I32960337a233083907d12b0e23ceec6dacb1c0a8,DNM - Testing 474150,ABANDONED,2017-06-14 12:13:53.000000000,2017-06-19 10:31:07.000000000,,"[{'_account_id': 3}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-14 12:13:53.000000000', 'files': ['foobar'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/2aab2cdc8245d5e2c84088d5ada3375929f84f25', 'message': 'DNM - Testing 474150\n\nDummy patch to test https://review.openstack.org/#/c/474150/\n\nDepends-On: Id2bce7425e0f44bbe71001e5f2520d00fbc5cf78\nChange-Id: I32960337a233083907d12b0e23ceec6dacb1c0a8\n'}]",0,474181,2aab2cdc8245d5e2c84088d5ada3375929f84f25,5,2,1,23163,,,0,"DNM - Testing 474150

Dummy patch to test https://review.openstack.org/#/c/474150/

Depends-On: Id2bce7425e0f44bbe71001e5f2520d00fbc5cf78
Change-Id: I32960337a233083907d12b0e23ceec6dacb1c0a8
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/81/474181/1 && git format-patch -1 --stdout FETCH_HEAD,['foobar'],1,2aab2cdc8245d5e2c84088d5ada3375929f84f25,do-not-merge-testing-474150,,,0,0
openstack%2Ftrove-dashboard~master~I91cfb8cc0f14166cf3473d39a411cad2035de95d,openstack/trove-dashboard,master,I91cfb8cc0f14166cf3473d39a411cad2035de95d,Optimize the link address,ABANDONED,2017-06-16 04:22:57.000000000,2017-06-19 10:14:12.000000000,,"[{'_account_id': 3}, {'_account_id': 9664}, {'_account_id': 26072}]","[{'number': 1, 'created': '2017-06-16 04:22:57.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst', 'setup.cfg', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/ab903f0044dcf5eb877bc36fced3869ce95ae45c', 'message': 'Optimize the link address\n\nUpdate link address to ensure safety and preciseness\n\nChange-Id: I91cfb8cc0f14166cf3473d39a411cad2035de95d\n'}]",0,474846,ab903f0044dcf5eb877bc36fced3869ce95ae45c,6,3,1,26072,,,0,"Optimize the link address

Update link address to ensure safety and preciseness

Change-Id: I91cfb8cc0f14166cf3473d39a411cad2035de95d
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/46/474846/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'README.rst', 'setup.cfg', 'HACKING.rst']",4,ab903f0044dcf5eb877bc36fced3869ce95ae45c,link_address,======================== https://docs.openstack.org/developer/hacking/---------------------------,========================== http://docs.openstack.org/developer/hacking/-----------------------------,9,9
openstack%2Fkuryr-kubernetes~master~I6fd8545e4888971c50a98b919548d79497a6848c,openstack/kuryr-kubernetes,master,I6fd8545e4888971c50a98b919548d79497a6848c,Removing detected Keystone Port in vagrant kury_rc,MERGED,2017-06-16 10:21:15.000000000,2017-06-19 10:12:51.000000000,2017-06-19 10:12:51.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 14352}, {'_account_id': 15967}, {'_account_id': 23567}]","[{'number': 1, 'created': '2017-06-16 10:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/59740c1ee488d1651413dddcab9145e877c9e29d', 'message': 'Removing Hardcoded Keystone Port in vagrant kury_rc\n\nChange-Id: I6fd8545e4888971c50a98b919548d79497a6848c\n'}, {'number': 2, 'created': '2017-06-16 10:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/7ee8308203b4fec283eaa97b95ee153af708ebdb', 'message': 'Removing detected Keystone Port in vagrant kury_rc\n\nChange-Id: I6fd8545e4888971c50a98b919548d79497a6848c\n'}, {'number': 3, 'created': '2017-06-19 05:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/fb13c973549eee5a85c843d8de789ffb5b6f2b3f', 'message': 'Removing detected Keystone Port in vagrant kury_rc\n\nCloses-bug: #1698731\nChange-Id: I6fd8545e4888971c50a98b919548d79497a6848c\n'}, {'number': 4, 'created': '2017-06-19 05:06:14.000000000', 'files': ['contrib/vagrant/config/kuryr_rc'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/956445a872d3670dd5c821515d33a42ed4b32627', 'message': 'Removing detected Keystone Port in vagrant kury_rc\n\nUpdating Vagrant environment to use correct url\n\nCloses-bug: #1698731\nChange-Id: I6fd8545e4888971c50a98b919548d79497a6848c\n'}]",1,474938,956445a872d3670dd5c821515d33a42ed4b32627,15,5,4,14867,,,0,"Removing detected Keystone Port in vagrant kury_rc

Updating Vagrant environment to use correct url

Closes-bug: #1698731
Change-Id: I6fd8545e4888971c50a98b919548d79497a6848c
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/38/474938/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/vagrant/config/kuryr_rc'],1,59740c1ee488d1651413dddcab9145e877c9e29d,keystone_port,export OS_AUTH_URL=http://127.0.0.1/identity,export OS_AUTH_URL=http://127.0.0.1:5000/v2.0,1,1
openstack%2Freleases~master~I2684fa68ba1bb5ffa56e06fad11b9aabe8da524b,openstack/releases,master,I2684fa68ba1bb5ffa56e06fad11b9aabe8da524b,Release monasca-api 1.7.0,MERGED,2017-06-19 09:06:10.000000000,2017-06-19 10:11:21.000000000,2017-06-19 10:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-06-19 09:06:10.000000000', 'files': ['deliverables/ocata/monasca-api.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f22ae512ab2245f03ac97f517a031690020b4efa', 'message': 'Release monasca-api 1.7.0\n\nChange-Id: I2684fa68ba1bb5ffa56e06fad11b9aabe8da524b\n'}]",0,475301,f22ae512ab2245f03ac97f517a031690020b4efa,6,2,1,16222,,,0,"Release monasca-api 1.7.0

Change-Id: I2684fa68ba1bb5ffa56e06fad11b9aabe8da524b
",git fetch https://review.opendev.org/openstack/releases refs/changes/01/475301/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/monasca-api.yaml'],1,f22ae512ab2245f03ac97f517a031690020b4efa,monasca-api, - version: 1.7.0 projects: - repo: openstack/monasca-api hash: e4177f7e280f1337a8c918b22d92b080c577cdcb,,4,0
openstack%2Fmagnum~stable%2Fnewton~I47da73787456c97f7d84fd4440404b551ff62528,openstack/magnum,stable/newton,I47da73787456c97f7d84fd4440404b551ff62528,Use eventlet executor in rpc_service,ABANDONED,2017-06-06 09:15:35.000000000,2017-06-19 10:07:28.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 6873}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 13861}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-06-06 09:15:35.000000000', 'files': ['magnum/common/rpc_service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7ab3199f825a5121200b5ccf69e30773805d8210', 'message': ""Use eventlet executor in rpc_service\n\nThe default executor of o.m is 'blocking', but after change [1],\no.m with blocking is broken. 'eventlet' and 'non-blocking' work\nfine and most services use 'eventlet', so this is why it was\nnoticed by magnum which used the default one.\n\nUse eventlet to not be affected by bug #1694728 , but more\nimportantly, the oslo team suggests to not use blocking which\nhas 0% test coverage and it is going to be deprecated and unset\nfrom the default configuration.\n\n[1] https://review.openstack.org/#/c/463673/\n\nChange-Id: I47da73787456c97f7d84fd4440404b551ff62528\nCloses-Bug: #1694728\n(cherry picked from commit bd69b3fff6b50048813360627fb02044cf1bcb58)\n""}]",0,471276,7ab3199f825a5121200b5ccf69e30773805d8210,6,7,1,20498,,,0,"Use eventlet executor in rpc_service

The default executor of o.m is 'blocking', but after change [1],
o.m with blocking is broken. 'eventlet' and 'non-blocking' work
fine and most services use 'eventlet', so this is why it was
noticed by magnum which used the default one.

Use eventlet to not be affected by bug #1694728 , but more
importantly, the oslo team suggests to not use blocking which
has 0% test coverage and it is going to be deprecated and unset
from the default configuration.

[1] https://review.openstack.org/#/c/463673/

Change-Id: I47da73787456c97f7d84fd4440404b551ff62528
Closes-Bug: #1694728
(cherry picked from commit bd69b3fff6b50048813360627fb02044cf1bcb58)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/76/471276/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/common/rpc_service.py'],1,7ab3199f825a5121200b5ccf69e30773805d8210,bug/1694728," executor='eventlet',",,1,0
openstack%2Fmistral~master~I18449710ace6276224aaea564588c53a3e2c6adc,openstack/mistral,master,I18449710ace6276224aaea564588c53a3e2c6adc,"Make sure that the field ""state_info"" trimmed as expected",MERGED,2017-06-14 13:10:21.000000000,2017-06-19 10:07:11.000000000,2017-06-19 09:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 9408}, {'_account_id': 9712}]","[{'number': 1, 'created': '2017-06-14 13:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/58fdb98ec4ff81ef495b9c6115827a5afd935bb4', 'message': 'WIP\n\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n'}, {'number': 2, 'created': '2017-06-15 04:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5df0a17179ad29d6b814d9fd851e3ff76ee3fba1', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n'}, {'number': 3, 'created': '2017-06-15 09:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/90ceb2dbd0cb72e4d46eebf20030cf599fb8bccd', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\n* Before this patch, ""state_info"" field of execution objects\n  wasn\'t truncated properly before saving into DB which led to\n  the DB error like:\n    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too\n    long for column \'state_info\' at row 1"")\n  It was happening because the method utils.cut() didn\'t work\n  accurately enough in case if we passed it with a dictionary.\n  This patch doesn\'t fix utils.cut() method but it just saves\n  space for possible method result difference with the expected\n  length so that we make sure that the truncated string\n  representation is always less than 65536 bytes (i.e. the size\n  of MySQL TEXT type). The total difference is not critical\n  anyway.\n\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n'}, {'number': 4, 'created': '2017-06-15 09:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/38e5ad03cbf428048fbbcb72ca16c8b68c4b8eb9', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\n* Before this patch, ""state_info"" field of execution objects\n  wasn\'t truncated properly before saving into DB which led to\n  the DB error like:\n    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too\n    long for column \'state_info\' at row 1"")\n  It was happening because the method utils.cut() didn\'t work\n  accurately enough in case if we passed it with a dictionary.\n  This patch doesn\'t fix utils.cut() method but it just saves\n  space for possible method result difference with the expected\n  length so that we make sure that the truncated string\n  representation is always less than 65536 bytes (i.e. the size\n  of MySQL TEXT type). The total difference is not critical\n  anyway.\n\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n'}, {'number': 5, 'created': '2017-06-15 10:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/943c1dbf79fc081103d99ce6e1f1b9bea128d440', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\n* Before this patch, ""state_info"" field of execution objects\n  wasn\'t truncated properly before saving into DB which led to\n  the DB error like:\n    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too\n    long for column \'state_info\' at row 1"")\n  It was happening because the method utils.cut() didn\'t work\n  accurately enough in case if we passed it with a dictionary.\n  This patch doesn\'t fix utils.cut() method but it just saves\n  space for possible method result difference with the expected\n  length so that we make sure that the truncated string\n  representation is always less than 65536 bytes (i.e. the size\n  of MySQL TEXT type). The total difference is not critical\n  anyway.\n\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n'}, {'number': 6, 'created': '2017-06-15 11:29:46.000000000', 'files': ['mistral/utils/__init__.py', 'mistral/tests/unit/engine/test_execution_fields_size_limitation.py', 'mistral/tests/unit/db/v2/test_sqlalchemy_db_api.py', 'mistral/db/v2/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/5a43d54a058ea4e13924c596b0bee93b727a1f95', 'message': 'Make sure that the field ""state_info"" trimmed as expected\n\n* Before this patch, ""state_info"" field of execution objects\n  wasn\'t truncated properly before saving into DB which led to\n  the DB error like:\n    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too\n    long for column \'state_info\' at row 1"")\n  It was happening because the method utils.cut() didn\'t work\n  accurately enough in case if we passed it with a dictionary.\n  This patch doesn\'t fix utils.cut() method but it just saves\n  space for possible method result difference with the expected\n  length so that we make sure that the truncated string\n  representation is always less than 65536 bytes (i.e. the size\n  of MySQL TEXT type). The total difference is not critical\n  anyway.\n\nCloses-Bug: #1698125\nChange-Id: I18449710ace6276224aaea564588c53a3e2c6adc\n'}]",6,474195,5a43d54a058ea4e13924c596b0bee93b727a1f95,21,5,6,8731,,,0,"Make sure that the field ""state_info"" trimmed as expected

* Before this patch, ""state_info"" field of execution objects
  wasn't truncated properly before saving into DB which led to
  the DB error like:
    DBDataError: (_mysql_exceptions.DataError) (1406, ""Data too
    long for column 'state_info' at row 1"")
  It was happening because the method utils.cut() didn't work
  accurately enough in case if we passed it with a dictionary.
  This patch doesn't fix utils.cut() method but it just saves
  space for possible method result difference with the expected
  length so that we make sure that the truncated string
  representation is always less than 65536 bytes (i.e. the size
  of MySQL TEXT type). The total difference is not critical
  anyway.

Closes-Bug: #1698125
Change-Id: I18449710ace6276224aaea564588c53a3e2c6adc
",git fetch https://review.opendev.org/openstack/mistral refs/changes/95/474195/6 && git format-patch -1 --stdout FETCH_HEAD,['mistral/tests/unit/engine/test_execution_fields_size_limitation.py'],1,58fdb98ec4ff81ef495b9c6115827a5afd935bb4,bug/1698125,"from mistral_lib.actions import base as actions_base - error: false action: my_action error=<% $.error %> def __init__(self, action_input, action_output_length, error=False): self.error = error def run(self, context): long_text = ''.join('A' for _ in range(self.action_output_length)) if not self.error: return wf_utils.Result(data=long_text) else: return wf_utils.Result(error=long_text) def test_task_execution_state_info_trimmed(self): # No limit on output, input and other JSON fields. cfg.CONF.set_default( 'execution_field_size_limit_kb', -1, group='engine' ) wf_service.create_workflows(WF) # Start workflow. wf_ex = self.engine.start_workflow( 'wf', { 'action_output_length': 70000, 'error': True } ) self.await_workflow_error(wf_ex.id) with db_api.transaction(): wf_ex = db_api.get_workflow_execution(wf_ex.id) task_ex = self._assert_single_item( wf_ex.task_executions, state=states.ERROR ) # ""state_info"" must be trimmed to 65535. self.assertEqual(65535, len(task_ex.state_info)) self.assertEqual(65535, len(wf_ex.state_info))","from mistral.actions import base as actions_base action: my_action def __init__(self, action_input, action_output_length): def run(self): return wf_utils.Result( data=''.join('A' for _ in range(self.action_output_length)) )",45,7
openstack%2Fmagnum~stable%2Focata~I47da73787456c97f7d84fd4440404b551ff62528,openstack/magnum,stable/ocata,I47da73787456c97f7d84fd4440404b551ff62528,Use eventlet executor in rpc_service,ABANDONED,2017-06-06 09:13:11.000000000,2017-06-19 10:07:11.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 6873}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 13861}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-06-06 09:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/70352647a7fe7e1aa9311706d513770086d91f5e', 'message': ""Use eventlet executor in rpc_service\n\nThe default executor of o.m is 'blocking', but after change [1],\no.m with blocking is broken. 'eventlet' and 'non-blocking' work\nfine and most services use 'eventlet', so this is why it was\nnoticed by magnum which used the default one.\n\nUse eventlet to not be affected by bug #1694728 , but more\nimportantly, the oslo team suggests to not use blocking which\nhas 0% test coverage and it is going to be deprecated and unset\nfrom the default configuration.\n\n[1] https://review.openstack.org/#/c/463673/\n\nChange-Id: I47da73787456c97f7d84fd4440404b551ff62528\nCloses-Bug: #1694728\n(cherry picked from commit bd69b3fff6b50048813360627fb02044cf1bcb58)\n""}, {'number': 2, 'created': '2017-06-09 04:38:12.000000000', 'files': ['magnum/common/rpc_service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1c8edc9e6336a1301af9a3093d9b1d8b8be8f425', 'message': ""Use eventlet executor in rpc_service\n\nThe default executor of o.m is 'blocking', but after change [1],\no.m with blocking is broken. 'eventlet' and 'non-blocking' work\nfine and most services use 'eventlet', so this is why it was\nnoticed by magnum which used the default one.\n\nUse eventlet to not be affected by bug #1694728 , but more\nimportantly, the oslo team suggests to not use blocking which\nhas 0% test coverage and it is going to be deprecated and unset\nfrom the default configuration.\n\n[1] https://review.openstack.org/#/c/463673/\n\nChange-Id: I47da73787456c97f7d84fd4440404b551ff62528\nCloses-Bug: #1694728\n(cherry picked from commit bd69b3fff6b50048813360627fb02044cf1bcb58)\n""}]",0,471275,1c8edc9e6336a1301af9a3093d9b1d8b8be8f425,17,7,2,20498,,,0,"Use eventlet executor in rpc_service

The default executor of o.m is 'blocking', but after change [1],
o.m with blocking is broken. 'eventlet' and 'non-blocking' work
fine and most services use 'eventlet', so this is why it was
noticed by magnum which used the default one.

Use eventlet to not be affected by bug #1694728 , but more
importantly, the oslo team suggests to not use blocking which
has 0% test coverage and it is going to be deprecated and unset
from the default configuration.

[1] https://review.openstack.org/#/c/463673/

Change-Id: I47da73787456c97f7d84fd4440404b551ff62528
Closes-Bug: #1694728
(cherry picked from commit bd69b3fff6b50048813360627fb02044cf1bcb58)
",git fetch https://review.opendev.org/openstack/magnum refs/changes/75/471275/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/common/rpc_service.py'],1,70352647a7fe7e1aa9311706d513770086d91f5e,bug/1694728," executor='eventlet',",,1,0
openstack%2Fkuryr-kubernetes~master~I621ebf9b721b18fc4cf62131a7f13db739362edd,openstack/kuryr-kubernetes,master,I621ebf9b721b18fc4cf62131a7f13db739362edd,[WIP] Build system to generate cni binary,ABANDONED,2017-06-16 13:42:54.000000000,2017-06-19 10:04:53.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-16 13:42:54.000000000', 'files': ['tools/build_binary', 'build-requirements.txt', 'builder.Dockerfile', 'tools/build_binary_entrypoint'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/dc1ebffe0abeb6da9e5f2b1310f355bf85482b85', 'message': ""[WIP] Build system to generate cni binary\n\nThis is just to show how a generator Container may look like. The\npyinstaller spec is on vikas' patch\n\nChange-Id: I621ebf9b721b18fc4cf62131a7f13db739362edd\nSigned-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>\n""}]",0,474977,dc1ebffe0abeb6da9e5f2b1310f355bf85482b85,3,1,1,14352,,,0,"[WIP] Build system to generate cni binary

This is just to show how a generator Container may look like. The
pyinstaller spec is on vikas' patch

Change-Id: I621ebf9b721b18fc4cf62131a7f13db739362edd
Signed-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/77/474977/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/build_binary', 'build-requirements.txt', 'builder.Dockerfile', 'tools/build_binary_entrypoint']",4,dc1ebffe0abeb6da9e5f2b1310f355bf85482b85,bug/1638892,#!/bin/bash set -ex cd /opt/kuryr-kubernetes pip3 install -r build-requirements.txt /usr/bin/pyinstaller cni.spec ,,42,0
openstack%2Ftrove-dashboard~master~I1768290e85981664d16172232e3b2f2368440aa0,openstack/trove-dashboard,master,I1768290e85981664d16172232e3b2f2368440aa0,Imported Translations from Zanata,MERGED,2017-05-25 06:21:03.000000000,2017-06-19 10:04:32.000000000,2017-06-19 10:04:32.000000000,"[{'_account_id': 3}, {'_account_id': 9664}]","[{'number': 1, 'created': '2017-05-25 06:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/487b590cda75b44206f5f7396f8b8d1e253d030d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I1768290e85981664d16172232e3b2f2368440aa0\n'}, {'number': 2, 'created': '2017-05-26 06:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/6fc4ae45373ad461907021a4017d8e1e69e839a6', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I1768290e85981664d16172232e3b2f2368440aa0\n'}, {'number': 3, 'created': '2017-06-19 06:59:08.000000000', 'files': ['trove_dashboard/locale/id/LC_MESSAGES/django.po', 'trove_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'trove_dashboard/locale/de/LC_MESSAGES/django.po', 'trove_dashboard/locale/tr_TR/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/e1a1fa462191291f121059816df3908ddb791569', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I1768290e85981664d16172232e3b2f2368440aa0\n'}]",0,467903,e1a1fa462191291f121059816df3908ddb791569,12,2,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I1768290e85981664d16172232e3b2f2368440aa0
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/03/467903/3 && git format-patch -1 --stdout FETCH_HEAD,['trove_dashboard/locale/tr_TR/LC_MESSAGES/djangojs.po'],1,487b590cda75b44206f5f7396f8b8d1e253d030d,zanata/translations,"# işbaran akçayır <isbaran@gmail.com>, 2017. #zanata msgid """" msgstr """" ""Project-Id-Version: trove-dashboard 9.0.0.0b2.dev2\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2017-05-12 11:33+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2017-05-24 02:16+0000\n"" ""Last-Translator: Copied by Zanata <copied-by-zanata@zanata.org>\n"" ""Language-Team: Turkish (Turkey)\n"" ""Language: tr-TR\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" ""X-Generator: Zanata 3.9.6\n"" ""X-POOTLE-MTIME: 1495635326.000000\n"" msgid ""Created"" msgstr ""Oluşturuldu"" msgid ""Database"" msgstr ""Veri tabanı"" msgid ""Datastore"" msgstr ""Veri deposu"" msgid ""Datastore Version"" msgstr ""Veri Deposu Sürümü"" msgid ""Incremental"" msgstr ""Artan"" msgid ""Name"" msgstr ""İsim"" msgid ""Unable to retrieve the Backups."" msgstr ""Yedekler alınamıyor."" msgid ""status"" msgstr ""durum"" ",,40,0
openstack%2Fcharms.openstack~master~I0eb50127aac88a8bf7ee431495a6df0c60ef3fce,openstack/charms.openstack,master,I0eb50127aac88a8bf7ee431495a6df0c60ef3fce,Fix default reactive handlers to only run once,ABANDONED,2017-05-23 09:09:45.000000000,2017-06-19 09:59:38.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20870}]","[{'number': 1, 'created': '2017-05-23 09:09:45.000000000', 'files': ['unit_tests/charms_openstack/charm/test_defaults.py', 'charms_openstack/charm/defaults.py', 'charms_openstack/test_utils.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/c553391fa321a3f61037925f87aaf3e23aed35be', 'message': ""Fix default reactive handlers to only run once\n\nReactive has some unexpected 'gotchas' which arise due to the\ndifferent concepts involved.  Non reactive charms rely on 'hooks' that\nindicate exactly which function will run when a hook is invoked.\nReactive, on the other hand, only uses hooks to run the reactive system,\nand, once it is running, ANY handler that has conditions that evaluate\nto true will run.\n\nThis patch modifies the default handlers that charms.openstack provides\nsuch that they only execute ONCE for each associated reactive state as\nset by the associated interface.  They use the 'detaching' state (i.e.\nwhen the state goes away) to reset the 'run_once' guard state.  This\nshould mean that charms that use the default state will have 'quieter'\ndebug-logs and, perhaps, more understandable behaviour.\n\nNote that the charms that use charms.openstack also need to have a\nsimilar guard around their own, non default, handlers.\n\nNote the depends-on is simply because this change is linked to the\ncharm refactor.\n\nChange-Id: I0eb50127aac88a8bf7ee431495a6df0c60ef3fce\nDepends-On: Ifd171b5a47b814cee6c7e53d9a6bae52833caed2\n""}]",0,467090,c553391fa321a3f61037925f87aaf3e23aed35be,5,3,1,20870,,,0,"Fix default reactive handlers to only run once

Reactive has some unexpected 'gotchas' which arise due to the
different concepts involved.  Non reactive charms rely on 'hooks' that
indicate exactly which function will run when a hook is invoked.
Reactive, on the other hand, only uses hooks to run the reactive system,
and, once it is running, ANY handler that has conditions that evaluate
to true will run.

This patch modifies the default handlers that charms.openstack provides
such that they only execute ONCE for each associated reactive state as
set by the associated interface.  They use the 'detaching' state (i.e.
when the state goes away) to reset the 'run_once' guard state.  This
should mean that charms that use the default state will have 'quieter'
debug-logs and, perhaps, more understandable behaviour.

Note that the charms that use charms.openstack also need to have a
similar guard around their own, non default, handlers.

Note the depends-on is simply because this change is linked to the
charm refactor.

Change-Id: I0eb50127aac88a8bf7ee431495a6df0c60ef3fce
Depends-On: Ifd171b5a47b814cee6c7e53d9a6bae52833caed2
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/90/467090/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/charms_openstack/charm/test_defaults.py', 'charms_openstack/charm/defaults.py', 'charms_openstack/test_utils.py']",3,c553391fa321a3f61037925f87aaf3e23aed35be,fix-default-handlers," 'clear_default_amqp_connection': ( 'default_amqp_connection_done', ), 'clear_default_setup_database': ('default_setup_database_done', ), 'clear_default_setup_endpoint_connection': ( 'default_setup_endpoint_connection_done', ), 'clear_default_setup_endpoint_available': ( 'default_setup_endpoint_available_done', ), 'default_config_changed': ('config.changed', ), 'default_amqp_connection': ('default_amqp_connection_done', ), 'clear_default_amqp_connection': ('amqp.connected', ), 'default_setup_database': ('default_setup_database_done', ), 'clear_default_setup_database': ('shared-db.connected', ), 'default_setup_endpoint_connection': ( 'default_setup_endpoint_connection_done', ), 'clear_default_setup_endpoint_connection': ( 'identity-service.connected', ), 'default_setup_endpoint_available': ( 'default_setup_endpoint_available_done', ), 'clear_default_setup_endpoint_available': ( 'identity-service.available', ), 'default_upgrade_charm': ('upgrade-charm', ), DEFAULTS_FLAG_MAP = { 'charm.installed': ('charm.installed', ), 'amqp.connected': ('amqp.connected', 'default_amqp_connection_done', ), 'shared-db.connected': ('shared-db.connected', 'default_setup_database_done', ), 'identity-service.connected': ( 'identity-service.connected', 'default_setup_endpoint_connection_done', ), 'identity-service.available': ( 'identity-service.available', 'default_setup_endpoint_available_done', ), 'config.changed': ('config.changed', ), 'update-charm': ('upgrade-charm', ), 'update-status': ('update-status', ), } # turns default names into a set of flags to look for. set_defaults_flags = set(itertools.chain( *(v for k, v in self.DEFAULTS_FLAG_MAP.items() if k in defaults))) if (set_defaults_flags .intersection(itertools.chain(*spec.values())))) if set_defaults_flags.intersection(state_list):"," 'default_config_changed': ('config.changed', ), if (set(defaults).intersection(itertools.chain(*spec.values())))) set_defaults = set(defaults) if set_defaults.intersection(state_list):",188,31
openstack%2Fkolla~master~I76a84ec008fec5696cadefdbdeb4204a32421c4b,openstack/kolla,master,I76a84ec008fec5696cadefdbdeb4204a32421c4b,Permit changing yum configuration in the base image,MERGED,2017-06-15 13:47:01.000000000,2017-06-19 09:58:24.000000000,2017-06-19 09:58:24.000000000,"[{'_account_id': 3}, {'_account_id': 11869}, {'_account_id': 16282}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22582}, {'_account_id': 23215}, {'_account_id': 23717}, {'_account_id': 24072}, {'_account_id': 25945}]","[{'number': 1, 'created': '2017-06-15 13:47:01.000000000', 'files': ['docker/macros.j2', 'docker/base/Dockerfile.j2', 'docker/base/yum.conf', 'releasenotes/notes/yum_conf-36fef802e8c003f1.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0cba3b2ccdcb556eaf31e520ec97e4e624baa01e', 'message': 'Permit changing yum configuration in the base image\n\nThis commit allows to configure yum settings via a yum.conf file that\nis shipped in the base image and make it overridable with the\nbase_yum_conf jinja2 block.\n\nChange-Id: I76a84ec008fec5696cadefdbdeb4204a32421c4b\nCloses-Bug: #1698134\n'}]",0,474582,0cba3b2ccdcb556eaf31e520ec97e4e624baa01e,15,10,1,13039,,,0,"Permit changing yum configuration in the base image

This commit allows to configure yum settings via a yum.conf file that
is shipped in the base image and make it overridable with the
base_yum_conf jinja2 block.

Change-Id: I76a84ec008fec5696cadefdbdeb4204a32421c4b
Closes-Bug: #1698134
",git fetch https://review.opendev.org/openstack/kolla refs/changes/82/474582/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'docker/macros.j2', 'docker/base/yum.conf', 'releasenotes/notes/yum_conf-36fef802e8c003f1.yaml']",4,0cba3b2ccdcb556eaf31e520ec97e4e624baa01e,bug/1698134,"--- features: - Allow to configure yum settings, and provide a default yum.conf that is overridable via the base_yum_conf jinja2 block. ",,18,1
openstack%2Fkuryr-kubernetes~master~I5bc198c0fc5e1b2d558e9c010c527be36134a9cb,openstack/kuryr-kubernetes,master,I5bc198c0fc5e1b2d558e9c010c527be36134a9cb,VIF Pool,ABANDONED,2017-03-16 11:14:55.000000000,2017-06-19 09:57:58.000000000,,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 15967}, {'_account_id': 17926}, {'_account_id': 21273}, {'_account_id': 23567}]","[{'number': 1, 'created': '2017-03-16 11:14:55.000000000', 'files': ['kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/controller/drivers/base.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/3d3c6d9e4cbcaa46cec1f80d782aaad05545dd8f', 'message': ""VIF Pool\n\nMock implementation of how a handler less implementation of VIF pools\ncould look like.\n\nFor cleaning up vifs for returning to the pool I miss python3 async\nscheduling for later (which would also trash the vif if it was over max.\n\nAnother Pool driver should be written in\nkuryr_kubernetes/controller/drivers/vif_pool.py that used TTLs and in\nthat case we'd schedule a periodic task that goes and takes expired\nvifs out if over the limit in a batch operation with the vif driver.\n\nChange-Id: I5bc198c0fc5e1b2d558e9c010c527be36134a9cb\nSigned-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>\n""}]",4,446462,3d3c6d9e4cbcaa46cec1f80d782aaad05545dd8f,9,6,1,14352,,,0,"VIF Pool

Mock implementation of how a handler less implementation of VIF pools
could look like.

For cleaning up vifs for returning to the pool I miss python3 async
scheduling for later (which would also trash the vif if it was over max.

Another Pool driver should be written in
kuryr_kubernetes/controller/drivers/vif_pool.py that used TTLs and in
that case we'd schedule a periodic task that goes and takes expired
vifs out if over the limit in a batch operation with the vif driver.

Change-Id: I5bc198c0fc5e1b2d558e9c010c527be36134a9cb
Signed-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/62/446462/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/controller/drivers/base.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py', 'setup.cfg']",4,3d3c6d9e4cbcaa46cec1f80d782aaad05545dd8f,mock_pool,kuryr_kubernetes.controller.drivers.vif_pool = noop = kuryr_kubernetes.controller.drivers.vif_pool:NoopVIFPool basic = kuryr_kubernetes.controller.drivers.vif_pool:BasicVIFPool ,,182,9
openstack%2Fmistral~stable%2Focata~Icfbef6ff464649dbc50b78e292576bd112926d4b,openstack/mistral,stable/ocata,Icfbef6ff464649dbc50b78e292576bd112926d4b,Increase the Environment variable column length,MERGED,2017-06-13 12:38:26.000000000,2017-06-19 09:57:25.000000000,2017-06-19 09:57:25.000000000,"[{'_account_id': 3}, {'_account_id': 6732}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 11085}, {'_account_id': 23314}]","[{'number': 1, 'created': '2017-06-13 12:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/860115095d75edbc724d29d18a484cd64bacd0c2', 'message': 'Increase the Environment variable column length\n\nCloses-Bug: #1697689\nChange-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b\n'}, {'number': 2, 'created': '2017-06-13 13:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/cb760cd39fc2717492f0a4036cd8da7e02ba9c78', 'message': 'Increase the Environment variable column length\n\nCloses-Bug: #1697689\nChange-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b\n'}, {'number': 3, 'created': '2017-06-19 07:26:08.000000000', 'files': ['mistral/db/v2/sqlalchemy/models.py', 'mistral/db/sqlalchemy/migration/alembic_migrations/versions/021_increase_env_columns_size.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/58955acef686ae359e3bfe65428532df4f072460', 'message': 'Increase the Environment variable column length\n\nCloses-Bug: #1697689\nChange-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b\n(cherry picked from commit 78f69001d82dc51fa2ac6903bc3a71f86ff189bc)\n'}]",0,473814,58955acef686ae359e3bfe65428532df4f072460,14,6,3,9712,,,0,"Increase the Environment variable column length

Closes-Bug: #1697689
Change-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b
(cherry picked from commit 78f69001d82dc51fa2ac6903bc3a71f86ff189bc)
",git fetch https://review.opendev.org/openstack/mistral refs/changes/14/473814/3 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/db/sqlalchemy/migration/alembic_migrations/versions/021_increase_env_columns_size.py', 'mistral/db/v2/sqlalchemy/models.py']",2,860115095d75edbc724d29d18a484cd64bacd0c2,bug/1697689, variables = sa.Column(st.JsonLongDictType()), variables = sa.Column(st.JsonDictType()),36,1
openstack%2Ftripleo-common~stable%2Fnewton~Ifcedd54da5c74f12c863b8ec63679360673dd8f6,openstack/tripleo-common,stable/newton,Ifcedd54da5c74f12c863b8ec63679360673dd8f6,Ensure Swift Rings backup container and URLs,MERGED,2017-05-30 14:33:31.000000000,2017-06-19 09:54:54.000000000,2017-06-19 09:54:54.000000000,"[{'_account_id': 3}, {'_account_id': 8449}, {'_account_id': 20775}, {'_account_id': 21537}]","[{'number': 1, 'created': '2017-05-30 14:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5dc13bb9470ed6135ce3a09cdd838b32fb9a7b71', 'message': 'WIP: Ensure Swift Rings backup container and URLs\n\nSwift Rings backup container and URLs for it are created only\nduring deploy but there is possibility of minor update or\nchange of deployment when they should be created. Adding them\nin plan_management update_deployment_plan fixes these cases.\n\nResolves: rhbz#1455616\nChange-Id: Ifcedd54da5c74f12c863b8ec63679360673dd8f6\n(cherry picked from commit c430727d45e67142e69469ec74520f1de427d924)\n'}, {'number': 2, 'created': '2017-06-12 09:10:51.000000000', 'files': ['workbooks/deployment.yaml', 'workbooks/plan_management.yaml', 'workbooks/swift_rings_backup.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/935912dd73da4325faaa1d5e47c2555c6d84359d', 'message': 'Ensure Swift Rings backup container and URLs\n\nSwift Rings backup container and URLs for it are created only\nduring deploy but there is possibility of minor update or\nchange of deployment when they should be created. Adding them\nin plan_management update_deployment_plan fixes these cases.\n\nCloses-Bug: #1695778\nResolves: rhbz#1455616\nChange-Id: Ifcedd54da5c74f12c863b8ec63679360673dd8f6\n(cherry picked from commit bfabb3f5755628f707be58b1ead41b2f799ca099)\n'}]",0,469131,935912dd73da4325faaa1d5e47c2555c6d84359d,16,4,2,11166,,,0,"Ensure Swift Rings backup container and URLs

Swift Rings backup container and URLs for it are created only
during deploy but there is possibility of minor update or
change of deployment when they should be created. Adding them
in plan_management update_deployment_plan fixes these cases.

Closes-Bug: #1695778
Resolves: rhbz#1455616
Change-Id: Ifcedd54da5c74f12c863b8ec63679360673dd8f6
(cherry picked from commit bfabb3f5755628f707be58b1ead41b2f799ca099)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/31/469131/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/plan_management.yaml'],1,5dc13bb9470ed6135ce3a09cdd838b32fb9a7b71,bug/1695778," check_container: action: swift.head_container container=<% $.container %> on-success: get_tempurl on-error: create_container create_container: action: tripleo.plan.create_container container=""<% $.container %>-swift-rings"" on-success: get_tempurl get_tempurl: action: tripleo.swift.tempurl on-success: set_get_tempurl input: container: ""<% $.container %>-swift-rings"" obj: ""swift-rings.tar.gz"" set_get_tempurl: action: tripleo.parameters.update input: parameters: SwiftRingGetTempurl: <% task(get_tempurl).result %> container: <% $.container %> on-success: put_tempurl put_tempurl: action: tripleo.swift.tempurl on-success: set_put_tempurl input: container: ""<% $.container %>-swift-rings"" obj: ""swift-rings.tar.gz"" method: ""PUT"" set_put_tempurl: action: tripleo.parameters.update input: parameters: SwiftRingPutTempurl: <% task(put_tempurl).result %> container: <% $.container %> on-success: update_plan ",,40,0
openstack%2Fnova~master~I73aff37aaecf1f3755f0445ab9edb8f6454cf6c3,openstack/nova,master,I73aff37aaecf1f3755f0445ab9edb8f6454cf6c3,[placement] Increase test coverage,MERGED,2017-06-12 14:09:56.000000000,2017-06-19 09:36:32.000000000,2017-06-19 09:36:32.000000000,"[{'_account_id': 3}, {'_account_id': 1063}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 11564}]","[{'number': 1, 'created': '2017-06-12 14:09:56.000000000', 'files': ['nova/tests/functional/api/openstack/placement/gabbits/inventory.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/7ba0b7ad5f4302d4501fcf48760d152e3e5b60d3', 'message': '[placement] Increase test coverage\n\nIncrease test coverage for deleting all inventory for a\nresource provider. These new tests check if the inventory\nwas deleted for both DELETE and PUT methods, and check if\nthe new resource generation has been correctly updated as\nexpected.\n\nThe DELETE method is implemented by the following change:\nI1ecb12c888f873e8330367c8411d5a2ef0458495.\nThese tests have been originally proposed in this change:\nI626ca4a821b5ab0ebcaa79937a31771fbae5b8d9, however, since\nthese tests do not have anything about the client side code,\nI broke it down into a separate change.\n\nChange-Id: I73aff37aaecf1f3755f0445ab9edb8f6454cf6c3\n'}]",0,473479,7ba0b7ad5f4302d4501fcf48760d152e3e5b60d3,15,5,1,8175,,,0,"[placement] Increase test coverage

Increase test coverage for deleting all inventory for a
resource provider. These new tests check if the inventory
was deleted for both DELETE and PUT methods, and check if
the new resource generation has been correctly updated as
expected.

The DELETE method is implemented by the following change:
I1ecb12c888f873e8330367c8411d5a2ef0458495.
These tests have been originally proposed in this change:
I626ca4a821b5ab0ebcaa79937a31771fbae5b8d9, however, since
these tests do not have anything about the client side code,
I broke it down into a separate change.

Change-Id: I73aff37aaecf1f3755f0445ab9edb8f6454cf6c3
",git fetch https://review.opendev.org/openstack/nova refs/changes/79/473479/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/api/openstack/placement/gabbits/inventory.yaml'],1,7ba0b7ad5f4302d4501fcf48760d152e3e5b60d3,test_coverage,- name: get inventories after deletions GET: /resource_providers/$ENVIRON['RP_UUID']/inventories response_json_paths: $.resource_provider_generation: 8 $.inventories: {} - name: post an inventory again POST: /resource_providers/$ENVIRON['RP_UUID']/inventories request_headers: content-type: application/json data: resource_class: DISK_GB total: 2048 reserved: 512 min_unit: 10 max_unit: 1024 step_size: 10 allocation_ratio: 1.0 status: 201 response_headers: location: $SCHEME://$NETLOC/resource_providers/$ENVIRON['RP_UUID']/inventories/DISK_GB response_json_paths: $.resource_provider_generation: 9 $.total: 2048 $.reserved: 512 - name: delete all inventory with put PUT: /resource_providers/$ENVIRON['RP_UUID']/inventories request_headers: content-type: application/json openstack-api-version: placement 1.4 data: resource_provider_generation: 9 inventories: {} response_json_paths: $.resource_provider_generation: 10 $.inventories: {} status: 200 - name: get generation after deletion GET: /resource_providers/$ENVIRON['RP_UUID']/inventories response_json_paths: $.resource_provider_generation: 10 $.inventories: {} ,- name: get inventories after deletion GET: /resource_providers/$ENVIRON['RP_UUID']/inventories response_json_paths: $.resource_provider_generation: 7 $.inventories: {} ,45,6
openstack%2Fkolla~master~Icd8cf5c15c2a7b29c0dd89e177d7a757b86109c3,openstack/kolla,master,Icd8cf5c15c2a7b29c0dd89e177d7a757b86109c3,Install mistral-dashboard in horizon container (type source),ABANDONED,2016-10-11 11:35:13.000000000,2017-06-19 09:36:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 16233}]","[{'number': 1, 'created': '2016-10-11 11:35:13.000000000', 'files': ['docker/horizon/Dockerfile.j2', 'kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5521ee1f30a8cab314d915221d530c33388a456a', 'message': 'Install mistral-dashboard in horizon container (type source)\n\nChange-Id: Icd8cf5c15c2a7b29c0dd89e177d7a757b86109c3\nPartial-bug: #1632267\n'}]",0,384941,5521ee1f30a8cab314d915221d530c33388a456a,6,3,1,167,,,0,"Install mistral-dashboard in horizon container (type source)

Change-Id: Icd8cf5c15c2a7b29c0dd89e177d7a757b86109c3
Partial-bug: #1632267
",git fetch https://review.opendev.org/openstack/kolla refs/changes/41/384941/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/horizon/Dockerfile.j2', 'kolla/common/config.py']",2,5521ee1f30a8cab314d915221d530c33388a456a,bug/1632267," 'horizon-plugin-mistral-dashboard': { 'type': 'url', 'location': ('http://tarballs.openstack.org/mistral-dashboard/' 'mistral-dashboard-3.0.0.tar.gz')},",,6,0
openstack%2Fblazar~master~I4e2c8ef6037317e9ffc4cf811bfa1881e248e174,openstack/blazar,master,I4e2c8ef6037317e9ffc4cf811bfa1881e248e174,Updated from global requirements,MERGED,2017-06-15 16:21:17.000000000,2017-06-19 09:32:29.000000000,2017-06-19 09:32:29.000000000,"[{'_account_id': 3}, {'_account_id': 15197}, {'_account_id': 23840}]","[{'number': 1, 'created': '2017-06-15 16:21:17.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/blazar/commit/a8f71ea3db84eac0547343e0d66538936869e603', 'message': 'Updated from global requirements\n\nChange-Id: I4e2c8ef6037317e9ffc4cf811bfa1881e248e174\n'}]",0,474628,a8f71ea3db84eac0547343e0d66538936869e603,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I4e2c8ef6037317e9ffc4cf811bfa1881e248e174
",git fetch https://review.opendev.org/openstack/blazar refs/changes/28/474628/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a8f71ea3db84eac0547343e0d66538936869e603,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fmistral~stable%2Fnewton~Icfbef6ff464649dbc50b78e292576bd112926d4b,openstack/mistral,stable/newton,Icfbef6ff464649dbc50b78e292576bd112926d4b,Increase the Environment variable column length,MERGED,2017-06-13 12:38:31.000000000,2017-06-19 09:25:47.000000000,2017-06-19 09:25:47.000000000,"[{'_account_id': 3}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 11085}]","[{'number': 1, 'created': '2017-06-13 12:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c022fa7d5a70b9e310da7eeae64a930759ccbd69', 'message': 'Increase the Environment variable column length\n\nCloses-Bug: #1697689\nChange-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b\n'}, {'number': 2, 'created': '2017-06-13 12:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d44d756fdb40c464142a2a257b34133888ff963d', 'message': 'Increase the Environment variable column length\n\nCloses-Bug: #1697689\nChange-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b\n'}, {'number': 3, 'created': '2017-06-19 07:29:05.000000000', 'files': ['mistral/db/sqlalchemy/migration/alembic_migrations/versions/020_increase_env_columns_size.py', 'mistral/db/v2/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/98a6433b9abe9f52055f91225a4d03b6ed73758a', 'message': 'Increase the Environment variable column length\n\nCloses-Bug: #1697689\nChange-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b\n(cherry picked from commit 78f69001d82dc51fa2ac6903bc3a71f86ff189bc)\n'}]",0,473815,98a6433b9abe9f52055f91225a4d03b6ed73758a,13,4,3,9712,,,0,"Increase the Environment variable column length

Closes-Bug: #1697689
Change-Id: Icfbef6ff464649dbc50b78e292576bd112926d4b
(cherry picked from commit 78f69001d82dc51fa2ac6903bc3a71f86ff189bc)
",git fetch https://review.opendev.org/openstack/mistral refs/changes/15/473815/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/db/sqlalchemy/migration/alembic_migrations/versions/021_increase_env_columns_size.py', 'mistral/db/v2/sqlalchemy/models.py']",2,c022fa7d5a70b9e310da7eeae64a930759ccbd69,bug/1697689, variables = sa.Column(st.JsonLongDictType()), variables = sa.Column(st.JsonDictType()),36,1
openstack%2Fproject-config~master~Ibb9fe36db8632e121b32d94a3bb465ff29d8db0f,openstack/project-config,master,Ibb9fe36db8632e121b32d94a3bb465ff29d8db0f,bifrost: Fix node for bifrost jobs,ABANDONED,2017-06-19 08:47:21.000000000,2017-06-19 09:25:27.000000000,,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 7118}, {'_account_id': 11655}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-19 08:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/18a30a48c6dad614140f9ba110b899ae932aafd5', 'message': 'bifrost: Fix node for bifrost jobs\n\nCommit f05d1fbbf215 (""bifrost: Add experimental openSUSE 42.2 and CentOS\n7 jobs"") added support for bifrost jobs but these jobs are not being\ntriggered because there are no centos-7 or opensuse-422 nodes in the CI.\nAs such, we need to use another list to hold the OS we are interested\nin.\n\nFixes: f05d1fbbf215 (""bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs"")\nChange-Id: Ibb9fe36db8632e121b32d94a3bb465ff29d8db0f\n'}, {'number': 2, 'created': '2017-06-19 09:03:40.000000000', 'files': ['jenkins/jobs/bifrost.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e4392c4aabc77e769616457445a14eb71ffb3b7f', 'message': 'bifrost: Fix node for bifrost jobs\n\nCommit f05d1fbbf215 (""bifrost: Add experimental openSUSE 42.2 and CentOS\n7 jobs"") added support for bifrost jobs but these jobs are not being\ntriggered because there are no centos-7 or opensuse-422 nodes in the CI.\nAs such, we need to use another list to hold the OS we are interested\nin.\n\nFixes: f05d1fbbf215 (""bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs"")\nChange-Id: Ibb9fe36db8632e121b32d94a3bb465ff29d8db0f\n'}]",0,475290,e4392c4aabc77e769616457445a14eb71ffb3b7f,6,7,2,23163,,,0,"bifrost: Fix node for bifrost jobs

Commit f05d1fbbf215 (""bifrost: Add experimental openSUSE 42.2 and CentOS
7 jobs"") added support for bifrost jobs but these jobs are not being
triggered because there are no centos-7 or opensuse-422 nodes in the CI.
As such, we need to use another list to hold the OS we are interested
in.

Fixes: f05d1fbbf215 (""bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs"")
Change-Id: Ibb9fe36db8632e121b32d94a3bb465ff29d8db0f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/475290/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/bifrost.yaml'],1,18a30a48c6dad614140f9ba110b899ae932aafd5,jenkins/jobs/bifrost/add-experimental-opensuse-centos, - ubuntu-trusty - ubuntu-xenial ostype: - gate-bifrost-integration-tinyipa-{ostype} - gate-bifrost-integration-dibipa-debian-{ostype}-nv - gate-bifrost-integration-dhcp-{ostype}-nv, - gate-bifrost-integration-tinyipa-{node} - gate-bifrost-integration-dibipa-debian-{node}-nv - gate-bifrost-integration-dhcp-{node}-nv,6,3
openstack%2Ftripleo-quickstart-extras~master~I6c26225e5a04500faeaac9ea7de661bf1b986df0,openstack/tripleo-quickstart-extras,master,I6c26225e5a04500faeaac9ea7de661bf1b986df0,Replace hardcoded tht path by tht_dir variable for update,MERGED,2017-06-02 21:42:21.000000000,2017-06-19 09:25:22.000000000,2017-06-19 09:25:22.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 10022}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-06-02 21:42:21.000000000', 'files': ['roles/overcloud-upgrade/templates/minor-upgrade-overcloud.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5de7da5b3a22e893b0f1d7e645cdaff8f0d7c9e1', 'message': 'Replace hardcoded tht path by tht_dir variable for update\n\nthe tht path for overcloud registry is missing the\ntht_dir variable.\n\nChange-Id: I6c26225e5a04500faeaac9ea7de661bf1b986df0\n'}]",4,470445,5de7da5b3a22e893b0f1d7e645cdaff8f0d7c9e1,15,7,1,16515,,,0,"Replace hardcoded tht path by tht_dir variable for update

the tht path for overcloud registry is missing the
tht_dir variable.

Change-Id: I6c26225e5a04500faeaac9ea7de661bf1b986df0
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/45/470445/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-upgrade/templates/minor-upgrade-overcloud.sh.j2'],1,5de7da5b3a22e893b0f1d7e645cdaff8f0d7c9e1,minor-update-script, -e {{ tht_dir }}/overcloud-resource-registry-puppet.yaml \, -e tripleo-heat-templates/overcloud-resource-registry-puppet.yaml \,1,1
openstack%2Fpython-watcherclient~master~I9c8d53107b1926d6ce4532d7c696dc36c84c6cf8,openstack/python-watcherclient,master,I9c8d53107b1926d6ce4532d7c696dc36c84c6cf8,Add CLI for Action Plan Cancel,MERGED,2017-05-30 09:29:08.000000000,2017-06-19 09:17:59.000000000,2017-06-19 09:17:59.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 13111}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 21692}, {'_account_id': 22775}]","[{'number': 1, 'created': '2017-05-30 09:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/c302b39cd96d75c647f566c81b4d4d26381f1401', 'message': 'Add CLI for Action Plan Cancel\n\nThis patch CLI for for action plan cancel\nwatcher action plan cancel <action-plan-uuid>\n\nChange-Id: I9c8d53107b1926d6ce4532d7c696dc36c84c6cf8\nPartially-Implements: blueprint cancel-action-plan\n'}, {'number': 2, 'created': '2017-06-01 08:33:11.000000000', 'files': ['watcherclient/tests/unit/v1/test_action_plan_shell.py', 'watcherclient/v1/action_plan_shell.py', 'watcherclient/v1/action_plan.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/3f25b6b2237bd2ebe1fe42902d02dd3d0742363c', 'message': 'Add CLI for Action Plan Cancel\n\nThis patch CLI for for action plan cancel\nwatcher action plan cancel <action-plan-uuid>\n\nChange-Id: I9c8d53107b1926d6ce4532d7c696dc36c84c6cf8\nPartially-Implements: blueprint cancel-action-plan\n'}]",5,469025,3f25b6b2237bd2ebe1fe42902d02dd3d0742363c,11,7,2,19457,,,0,"Add CLI for Action Plan Cancel

This patch CLI for for action plan cancel
watcher action plan cancel <action-plan-uuid>

Change-Id: I9c8d53107b1926d6ce4532d7c696dc36c84c6cf8
Partially-Implements: blueprint cancel-action-plan
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/25/469025/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcherclient/v1/action_plan_shell.py', 'watcherclient/v1/action_plan.py', 'setup.cfg']",3,c302b39cd96d75c647f566c81b4d4d26381f1401,bp/cancel-action-plan, optimize_actionplan_cancel = watcherclient.v1.action_plan_shell:CancelActionPlan actionplan_cancel = watcherclient.v1.action_plan_shell:CancelActionPlan,,35,0
openstack%2Frelease-tools~master~Ife608108c22c38fe9913a5ed6095d643832cbd12,openstack/release-tools,master,Ife608108c22c38fe9913a5ed6095d643832cbd12,lp-tag.py: be prepared for empty lines in input,MERGED,2017-06-13 21:55:10.000000000,2017-06-19 09:05:09.000000000,2017-06-19 09:05:09.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-13 21:55:10.000000000', 'files': ['lp-tag.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/d15e2b89018e560e50f89f60f3342667d7f6b441', 'message': 'lp-tag.py: be prepared for empty lines in input\n\nChange-Id: Ife608108c22c38fe9913a5ed6095d643832cbd12\n'}]",2,473992,d15e2b89018e560e50f89f60f3342667d7f6b441,13,3,1,9656,,,0,"lp-tag.py: be prepared for empty lines in input

Change-Id: Ife608108c22c38fe9913a5ed6095d643832cbd12
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/92/473992/1 && git format-patch -1 --stdout FETCH_HEAD,['lp-tag.py'],1,d15e2b89018e560e50f89f60f3342667d7f6b441,, if bugnum: bug = lp.bugs[bugnum] tag = args.tag tags = bug.tags if tag not in tags: tags.append(tag) bug.tags = tags bug.lp_save(), bug = lp.bugs[bugnum] tag = args.tag tags = bug.tags if tag not in tags: tags.append(tag) bug.tags = tags bug.lp_save(),8,7
openstack%2Ffuel-library~stable%2Focata~If319845aa9f2d9b3ca07936350ef374f504679cb,openstack/fuel-library,stable/ocata,If319845aa9f2d9b3ca07936350ef374f504679cb,Correct logical expressions for storage backends,MERGED,2017-05-17 14:11:04.000000000,2017-06-19 09:00:00.000000000,2017-06-19 08:59:12.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}]","[{'number': 1, 'created': '2017-05-17 14:11:04.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_swift.pp', 'deployment/puppet/openstack_tasks/examples/swift/tasks.yaml', 'deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_radosgw.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fd8268b89be861b1e3edd710dcf48e5a2c7fd98f', 'message': ""Correct logical expressions for storage backends\n\nAfter introducing the change Iead5167210c4132badb866afc25d4ef14e27f6b2\nswift isn't installed if ceph used as a backend for images\nand not for object-storage service. In this sutiation we end up\nwith absence of object-storage at all which is wrong.\n\nThe commit introduces changes which makes possible\nto swift been installed if ceph used only for image service.\n\nChange-Id: If319845aa9f2d9b3ca07936350ef374f504679cb\nCloses-Bug: #1604879\n""}]",0,465594,fd8268b89be861b1e3edd710dcf48e5a2c7fd98f,34,4,1,18845,,,0,"Correct logical expressions for storage backends

After introducing the change Iead5167210c4132badb866afc25d4ef14e27f6b2
swift isn't installed if ceph used as a backend for images
and not for object-storage service. In this sutiation we end up
with absence of object-storage at all which is wrong.

The commit introduces changes which makes possible
to swift been installed if ceph used only for image service.

Change-Id: If319845aa9f2d9b3ca07936350ef374f504679cb
Closes-Bug: #1604879
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/94/465594/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_swift.pp', 'deployment/puppet/openstack_tasks/examples/swift/tasks.yaml', 'deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_radosgw.pp']",3,fd8268b89be861b1e3edd710dcf48e5a2c7fd98f,bug/1604879, if !$storage_hash['objects_ceph'] {, if (!$storage_hash['images_ceph'] and !$storage_hash['objects_ceph']) {,5,5
openstack%2Ffuel-library~stable%2Fnewton~If319845aa9f2d9b3ca07936350ef374f504679cb,openstack/fuel-library,stable/newton,If319845aa9f2d9b3ca07936350ef374f504679cb,Correct logical expressions for storage backends,MERGED,2017-05-17 14:08:11.000000000,2017-06-19 08:57:55.000000000,2017-06-19 08:57:07.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}]","[{'number': 1, 'created': '2017-05-17 14:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f196b117680ec86c5a5c0559ed5a84772eaf5012', 'message': ""Correct logical expressions for storage backends\n\nAfter introducing the change Iead5167210c4132badb866afc25d4ef14e27f6b2\nswift isn't installed if ceph used as a backend for images\nand not for object-storage service. In this sutiation we end up\nwith absence of object-storage at all which is wrong.\n\nThe commit introduces changes which makes possible\nto swift been installed if ceph used only for image service.\n\nChange-Id: If319845aa9f2d9b3ca07936350ef374f504679cb\nCloses-Bug: #1604879\n""}, {'number': 2, 'created': '2017-05-17 14:10:05.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_swift.pp', 'deployment/puppet/openstack_tasks/examples/swift/tasks.yaml', 'deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_radosgw.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9e3e2da3053bb5e697bd2cacae4a682512598992', 'message': ""Correct logical expressions for storage backends\n\nAfter introducing the change Iead5167210c4132badb866afc25d4ef14e27f6b2\nswift isn't installed if ceph used as a backend for images\nand not for object-storage service. In this sutiation we end up\nwith absence of object-storage at all which is wrong.\n\nThe commit introduces changes which makes possible\nto swift been installed if ceph used only for image service.\n\nChange-Id: If319845aa9f2d9b3ca07936350ef374f504679cb\nCloses-Bug: #1604879\n""}]",0,465590,9e3e2da3053bb5e697bd2cacae4a682512598992,44,5,2,18845,,,0,"Correct logical expressions for storage backends

After introducing the change Iead5167210c4132badb866afc25d4ef14e27f6b2
swift isn't installed if ceph used as a backend for images
and not for object-storage service. In this sutiation we end up
with absence of object-storage at all which is wrong.

The commit introduces changes which makes possible
to swift been installed if ceph used only for image service.

Change-Id: If319845aa9f2d9b3ca07936350ef374f504679cb
Closes-Bug: #1604879
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/90/465590/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_swift.pp', 'deployment/puppet/openstack_tasks/examples/swift/tasks.yaml', 'deployment/puppet/osnailyfacter/manifests/openstack_haproxy/openstack_haproxy_radosgw.pp']",3,f196b117680ec86c5a5c0559ed5a84772eaf5012,bug/1604879, if !$storage_hash['objects_ceph'] {, if (!$storage_hash['images_ceph'] and !$storage_hash['objects_ceph']) {,11,3
openstack%2Fneutron-lbaas~master~I37785c33422e09eba6bf6ff26598919945dcf061,openstack/neutron-lbaas,master,I37785c33422e09eba6bf6ff26598919945dcf061,Prevent LBaaSv2 agent from filling up logs.,MERGED,2016-04-13 13:46:30.000000000,2017-06-19 08:55:53.000000000,2017-03-14 22:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 6579}, {'_account_id': 6951}, {'_account_id': 7293}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 11685}, {'_account_id': 12040}, {'_account_id': 21369}, {'_account_id': 21583}]","[{'number': 1, 'created': '2016-04-13 13:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/8fbd49e294f120e8a5605da436e22ca7b517a39f', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has a assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP assigned.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 2, 'created': '2016-04-19 07:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/17c6e0a88f19cbe84db6e6e27d16115fe5482e53', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP assigned.\n\nUnit tests also updated to match new code.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 3, 'created': '2016-04-20 08:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/2761f0394b5d1d1d168902e1d12cce1a95253b48', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP\nassigned.\n\nUnit tests also updated to match new code.\n\nI added the changes to lbaasv2.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 4, 'created': '2016-05-03 13:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b8a0636cdd02246378739dc6e32096100d94556c', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP\nassigned.\n\nUnit tests also updated to match new code.\n\nI also added the changes to lbaasv2 and made them match the v2 agent\napi.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 5, 'created': '2016-05-19 05:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/522a3848cccd4cb2f9063d75f368d5b7b3703dcd', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP\nassigned.\n\nUnit tests also updated to match new code.\n\nI also added the changes to lbaasv2 and made them match the v2 agent\napi.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 6, 'created': '2016-06-14 11:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/711e515e0fcbede3d19c138e7e0dbc83e7d37361', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP\nassigned.\n\nUnit tests also updated to match new code.\n\nI also added the changes to lbaasv2 and made them match the v2 agent\napi, but adjusted log messages.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 7, 'created': '2016-07-13 10:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/1c703b9dda04f4bdb7be0819bf540b21a72d3467', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP\nassigned.\n\nUnit tests also updated to match new code.\n\nI also added the changes to lbaasv2 and made them match the v2 agent\napi, but adjusted log messages.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 8, 'created': '2016-07-18 13:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/84affd98f68d5b105168f88e633cdd4bf52f8b75', 'message': 'Prevent LBaaS agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lb-pool is active (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the lb-pool has a VIP\nassigned.\n\nUnit tests also updated to match new code.\n\nI also added the changes to lbaasv2 and made them match the v2 agent\napi, but adjusted log messages.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 9, 'created': '2016-09-12 13:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/215fdea3c1efe196c854f4fe233486e8b483e877', 'message': 'Prevent LBaaSv2 agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lbaas-listener is created (has an assigned VIP) or when in debug level.\n\nThe needed stats sock is only present when the loadbalancer has a VIP\nassigned/the lbaas-listener is created.\n\nUnit tests also updated to match new code.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 10, 'created': '2016-11-09 10:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/d159b7fbfa15b853cc637059550f5c5531987360', 'message': 'Prevent LBaaSv2 agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lbaas-listener is created (has an assigned VIP) or when in\ndebug level.\n\nThe needed stats sock is only present when the loadbalancer has a VIP\nassigned/the lbaas-listener is created.\n\nUnit tests also updated to match new code.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}, {'number': 11, 'created': '2017-02-02 09:31:00.000000000', 'files': ['neutron_lbaas/drivers/haproxy/namespace_driver.py', 'neutron_lbaas/tests/unit/drivers/haproxy/test_namespace_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/39be448f3184094d5f5505c9b074a3e45b5c6c5a', 'message': 'Prevent LBaaSv2 agent from filling up logs.\n\nThe message concerning stats sock not available is now only printed\nwhen the lbaas-listener is created (has an assigned VIP) or when in\ndebug level.\n\nThe needed stats sock is only present when the loadbalancer has a VIP\nassigned/the lbaas-listener is created.\n\nUnit tests also updated to match new code.\n\nChange-Id: I37785c33422e09eba6bf6ff26598919945dcf061\nCloses-Bug: #1569827\n'}]",20,305284,39be448f3184094d5f5505c9b074a3e45b5c6c5a,85,13,11,21369,,,0,"Prevent LBaaSv2 agent from filling up logs.

The message concerning stats sock not available is now only printed
when the lbaas-listener is created (has an assigned VIP) or when in
debug level.

The needed stats sock is only present when the loadbalancer has a VIP
assigned/the lbaas-listener is created.

Unit tests also updated to match new code.

Change-Id: I37785c33422e09eba6bf6ff26598919945dcf061
Closes-Bug: #1569827
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/84/305284/10 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/services/loadbalancer/drivers/haproxy/namespace_driver.py'],1,8fbd49e294f120e8a5605da436e22ca7b517a39f,fix_for_1569827," logical_config = self.plugin_rpc.get_logical_device(pool_id) if self._is_active(logical_config): LOG.warning(_LW('Stats socket not found for pool %s'), pool_id) else: LOG.debug('Stats socket not found for pool %s,' ' but pool is inactive. VIP already assigned?', pool_id)"," LOG.warning(_LW('Stats socket not found for pool %s'), pool_id)",7,1
openstack%2Fkolla~master~If8fdfe2759b639b68908a4c4f40e00dcf99741f0,openstack/kolla,master,If8fdfe2759b639b68908a4c4f40e00dcf99741f0,Unify keystone endpoint descriptions,ABANDONED,2016-08-07 19:31:19.000000000,2017-06-19 08:54:20.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 2834}, {'_account_id': 7488}]","[{'number': 1, 'created': '2016-08-07 19:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f33b993bc479d9c7298fec66a2eaf574252af7da', 'message': 'Unify keystone endpoint descriptions\n\n* Use OpenStack instead of Openstack\n* remove service postfix\n* fix wrong descriptions\n* fix typos in descriptions\n\nTrivialFix\n\nChange-Id: If8fdfe2759b639b68908a4c4f40e00dcf99741f0\n'}, {'number': 2, 'created': '2016-08-07 20:05:12.000000000', 'files': ['ansible/roles/magnum/tasks/register.yml', 'ansible/roles/ceilometer/tasks/register.yml', 'ansible/roles/heat/tasks/register.yml', 'ansible/roles/neutron/tasks/register.yml', 'ansible/roles/mistral/tasks/register.yml', 'ansible/roles/cinder/tasks/register.yml', 'ansible/roles/glance/tasks/register.yml', 'ansible/roles/murano/tasks/register.yml', 'ansible/roles/manila/tasks/register.yml', 'ansible/roles/watcher/tasks/register.yml', 'ansible/roles/ironic/tasks/register.yml', 'ansible/roles/nova/tasks/register.yml', 'ansible/roles/swift/tasks/register.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7e88ee8f7587fbe3ae910a282c123d7d32b3ab93', 'message': 'Unify keystone endpoint descriptions\n\n* Use OpenStack instead of Openstack\n* remove service postfix\n* fix wrong descriptions\n* fix typos in descriptions\n\nTrivialFix\n\nChange-Id: If8fdfe2759b639b68908a4c4f40e00dcf99741f0\nDepends-on: If239a518b0217cfc105388ae5e298a8904ac2af5\n'}]",1,352110,7e88ee8f7587fbe3ae910a282c123d7d32b3ab93,10,4,2,167,,,0,"Unify keystone endpoint descriptions

* Use OpenStack instead of Openstack
* remove service postfix
* fix wrong descriptions
* fix typos in descriptions

TrivialFix

Change-Id: If8fdfe2759b639b68908a4c4f40e00dcf99741f0
Depends-on: If239a518b0217cfc105388ae5e298a8904ac2af5
",git fetch https://review.opendev.org/openstack/kolla refs/changes/10/352110/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/magnum/tasks/register.yml', 'ansible/roles/ceilometer/tasks/register.yml', 'ansible/roles/heat/tasks/register.yml', 'ansible/roles/neutron/tasks/register.yml', 'ansible/roles/mistral/tasks/register.yml', 'ansible/roles/cinder/tasks/register.yml', 'ansible/roles/glance/tasks/register.yml', 'ansible/roles/murano/tasks/register.yml', 'ansible/roles/manila/tasks/register.yml', 'ansible/roles/watcher/tasks/register.yml', 'ansible/roles/ironic/tasks/register.yml', 'ansible/roles/nova/tasks/register.yml', 'ansible/roles/swift/tasks/register.yml']",13,f33b993bc479d9c7298fec66a2eaf574252af7da,unify-endpoint-descriptions, description='OpenStack Object Storage', description='Openstack Object Storage',13,13
openstack%2Ffaafo~master~I864f2063343faad617cee2947851457ebad2bd18,openstack/faafo,master,I864f2063343faad617cee2947851457ebad2bd18,Use user 'faafo' to connect with the MySQL databse,ABANDONED,2016-02-25 18:32:42.000000000,2017-06-19 08:53:26.000000000,,"[{'_account_id': 3}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-02-25 18:32:42.000000000', 'files': ['contrib/install.sh'], 'web_link': 'https://opendev.org/openstack/faafo/commit/d2dfffa67f005c66c8b7c3e86f20f8e421212c4e', 'message': ""Use user 'faafo' to connect with the MySQL databse\n\nChange-Id: I864f2063343faad617cee2947851457ebad2bd18\n""}]",0,284861,d2dfffa67f005c66c8b7c3e86f20f8e421212c4e,4,2,1,167,,,0,"Use user 'faafo' to connect with the MySQL databse

Change-Id: I864f2063343faad617cee2947851457ebad2bd18
",git fetch https://review.opendev.org/openstack/faafo refs/changes/61/284861/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/install.sh'],1,d2dfffa67f005c66c8b7c3e86f20f8e421212c4e,install-script-database-user, URL_DATABASE='mysql://faafo:password@localhost/faafo', URL_DATABASE='mysql://root:password@localhost/faafo',1,1
openstack%2Frally~master~Ibb0fb8b7d4a5460765f9ad4ea9176af60faefdf3,openstack/rally,master,Ibb0fb8b7d4a5460765f9ad4ea9176af60faefdf3,[verification] make dashboard_url configurable,ABANDONED,2016-01-22 12:55:44.000000000,2017-06-19 08:53:18.000000000,,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-01-22 12:55:44.000000000', 'files': ['rally/verification/tempest/config.py', 'tests/unit/verification/test_config.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6aeffe1671e59af792bfd6b1b9a8661d6d80f22a', 'message': '[verification] make dashboard_url configurable\n\nAt the moment the dashboard URL used for the generated tempest\nconfiguration file is hardcoded in the _configure_dashboard method. This\nway it is not possible to generate a valid tempest configuration for a\nSSL secured dashboard or a dashboard using a different URL than the\nauth_url.\n\nThis patch introduces a new section ""dashboard"" in the rally\nconfiguration with a new parameter ""dashboard_url"". If this parameter is\nset the value will be used as dashboard URL in the generated tempest\nconfiguration file. If this parameter is not set the current generated\nurl based on the auth_url will be used.\n\nChange-Id: Ibb0fb8b7d4a5460765f9ad4ea9176af60faefdf3\n'}]",0,271279,6aeffe1671e59af792bfd6b1b9a8661d6d80f22a,6,3,1,167,,,0,"[verification] make dashboard_url configurable

At the moment the dashboard URL used for the generated tempest
configuration file is hardcoded in the _configure_dashboard method. This
way it is not possible to generate a valid tempest configuration for a
SSL secured dashboard or a dashboard using a different URL than the
auth_url.

This patch introduces a new section ""dashboard"" in the rally
configuration with a new parameter ""dashboard_url"". If this parameter is
set the value will be used as dashboard URL in the generated tempest
configuration file. If this parameter is not set the current generated
url based on the auth_url will be used.

Change-Id: Ibb0fb8b7d4a5460765f9ad4ea9176af60faefdf3
",git fetch https://review.opendev.org/openstack/rally refs/changes/79/271279/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/verification/tempest/config.py', 'tests/unit/verification/test_config.py']",2,6aeffe1671e59af792bfd6b1b9a8661d6d80f22a,dashboard_url_configurable," self.tempest_conf._configure_dashboard() expected_horizon_url = ""http://test/"" self.tempest_conf._configure_dashboard() self.tempest_conf._configure_dashboard()"," expected_horizon_url = ""http://test""",16,6
openstack%2Frally~master~I3010051141ce5556b5031463141b2f27c42c68de,openstack/rally,master,I3010051141ce5556b5031463141b2f27c42c68de,Use _rally_filedir for parameters of the 'verify start' command,ABANDONED,2016-01-14 12:59:18.000000000,2017-06-19 08:52:40.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-01-14 12:59:18.000000000', 'files': ['etc/rally.bash_completion'], 'web_link': 'https://opendev.org/openstack/rally/commit/428928c6d31e2585bad0465327832a456b20b229', 'message': ""Use _rally_filedir for parameters of the 'verify start' command\n\nThe parameters --tempest-config, --tests-file, and --xfails-file\nof the command start in the verify module do accept paths,\n_rally_filedir has to be called for them to be able to use\npath autocompletion with those parameters.\n\nChange-Id: I3010051141ce5556b5031463141b2f27c42c68de\n""}]",0,267532,428928c6d31e2585bad0465327832a456b20b229,7,4,1,167,,,0,"Use _rally_filedir for parameters of the 'verify start' command

The parameters --tempest-config, --tests-file, and --xfails-file
of the command start in the verify module do accept paths,
_rally_filedir has to be called for them to be able to use
path autocompletion with those parameters.

Change-Id: I3010051141ce5556b5031463141b2f27c42c68de
",git fetch https://review.opendev.org/openstack/rally refs/changes/32/267532/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/rally.bash_completion'],1,428928c6d31e2585bad0465327832a456b20b229,bash_completion_missing_file_parameters, if [[ $cur =~ ^(\.|\~|\/) ]] || \ [[ $prev =~ ^--out(|put-file)$ ]] || \ [[ $prev =~ ^--.*-file$ ]] || \ [[ $prev == '--tempest-config' ]]; thencomplete -o filenames -F _rally rally , if [[ $cur =~ ^(\.|\~|\/) ]] || [[ $prev =~ ^--out(|put-file)$ ]] ; thencomplete -o filenames -F _rally rally,5,2
openstack%2Frally~master~I68530d280e33c39c1f489cc36d6b76eb0c7057a3,openstack/rally,master,I68530d280e33c39c1f489cc36d6b76eb0c7057a3,Add new subcommand 'verify delete',ABANDONED,2015-10-01 15:01:31.000000000,2017-06-19 08:51:48.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-10-01 15:01:31.000000000', 'files': ['rally/common/db/sqlalchemy/api.py', 'rally/cli/commands/verify.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/ab57f1a7f739417324b714aaf1d385080a5c028c', 'message': ""Add new subcommand 'verify delete'\n\nThis subcommand will delete the results of a verification run from the\ndatabase.\n\nChange-Id: I68530d280e33c39c1f489cc36d6b76eb0c7057a3\n""}]",2,229942,ab57f1a7f739417324b714aaf1d385080a5c028c,7,4,1,167,,,0,"Add new subcommand 'verify delete'

This subcommand will delete the results of a verification run from the
database.

Change-Id: I68530d280e33c39c1f489cc36d6b76eb0c7057a3
",git fetch https://review.opendev.org/openstack/rally refs/changes/42/229942/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/common/db/sqlalchemy/api.py', 'rally/cli/commands/verify.py']",2,ab57f1a7f739417324b714aaf1d385080a5c028c,verify_delete," required=False, help=""UUID of a verification"") @envutils.with_default_verification_id def delete(self, verification_uuid=None): """"""Delete a verification. :param verification_uuid: Verification UUID """""" try: db.verification_delete(verification_uuid) except exceptions.NotFoundException as e: print(six.text_type(e)) return 1 @cliutils.args(""--uuid"", dest=""verification_uuid"", type=str,",,16,1
openstack%2Ffaafo~master~I781166c3a049354f0545fffda7512cc3e5841293,openstack/faafo,master,I781166c3a049354f0545fffda7512cc3e5841293,Export DEBIAN_FRONTEND=noninteractive in installer script,ABANDONED,2015-09-20 17:22:29.000000000,2017-06-19 08:51:37.000000000,,"[{'_account_id': 3}, {'_account_id': 167}]","[{'number': 1, 'created': '2015-09-20 17:22:29.000000000', 'files': ['contrib/install.sh'], 'web_link': 'https://opendev.org/openstack/faafo/commit/4e1ddfbe85f478d1176c9ad4e7e0d1629ba87c37', 'message': 'Export DEBIAN_FRONTEND=noninteractive in installer script\n\nThis will solve the following issue for all apt-get commands.\n\n---snip---\ndpkg-preconfigure: unable to re-open stdin: No such file or directory\n---snap---\n\nChange-Id: I781166c3a049354f0545fffda7512cc3e5841293\n'}]",0,225498,4e1ddfbe85f478d1176c9ad4e7e0d1629ba87c37,5,2,1,167,,,0,"Export DEBIAN_FRONTEND=noninteractive in installer script

This will solve the following issue for all apt-get commands.

---snip---
dpkg-preconfigure: unable to re-open stdin: No such file or directory
---snap---

Change-Id: I781166c3a049354f0545fffda7512cc3e5841293
",git fetch https://review.opendev.org/openstack/faafo refs/changes/98/225498/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/install.sh'],1,4e1ddfbe85f478d1176c9ad4e7e0d1629ba87c37,installer_export_noninteractive, export DEBIAN_FRONTEND=noninteractive sudo apt-get install -y mysql-server, sudo DEBIAN_FRONTEND=noninteractive apt-get install -y mysql-server,2,1
openstack%2Frally~master~I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395,openstack/rally,master,I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395,On keyboard interrupt abort the started task,ABANDONED,2015-09-18 14:04:52.000000000,2017-06-19 08:51:26.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 9545}, {'_account_id': 13340}, {'_account_id': 14749}, {'_account_id': 14764}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-09-18 14:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bf8bbcc8cd471fc63b4f23844a8a25d264caa21e', 'message': 'On keyboard interrupt abort the started task\n\nChange-Id: I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395\n'}, {'number': 2, 'created': '2015-09-21 10:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f7b666765f02768e855884164c86a63c7c725d74', 'message': 'On keyboard interrupt abort the started task\n\nChange-Id: I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395\n'}, {'number': 3, 'created': '2015-09-22 19:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5066011dbf25351617ef1ac9f557203ee3bfc683', 'message': 'On keyboard interrupt abort the started task\n\nChange-Id: I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395\n'}, {'number': 4, 'created': '2015-09-23 12:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ebbf4e5ff29084601e7ea66972f1fba5ed998755', 'message': 'On keyboard interrupt abort the started task\n\nChange-Id: I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395\n'}, {'number': 5, 'created': '2015-09-30 16:22:00.000000000', 'files': ['rally/cli/commands/task.py', 'tests/unit/cli/commands/test_task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b92d3e7239014b71b67b98bae6bf8166027ad383', 'message': 'On keyboard interrupt abort the started task\n\nChange-Id: I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395\n'}]",3,225163,b92d3e7239014b71b67b98bae6bf8166027ad383,29,9,5,167,,,0,"On keyboard interrupt abort the started task

Change-Id: I5c6c584ca86e3c26f0f7671cb3fd4b89967bc395
",git fetch https://review.opendev.org/openstack/rally refs/changes/63/225163/4 && git format-patch -1 --stdout FETCH_HEAD,['rally/cli/commands/task.py'],1,bf8bbcc8cd471fc63b4f23844a8a25d264caa21e,225163," except KeyboardInterrupt: print(""Keyboard interrupt received, aborting task...\n"") api.Task.abort(task[""uuid""])",,3,0
openstack%2Fopenstackdocstheme~master~I8786047307d43c443920d90097ac7e690a1b69ad,openstack/openstackdocstheme,master,I8786047307d43c443920d90097ac7e690a1b69ad,Introduce theme option 'show_search' to make search fields configurable,ABANDONED,2015-02-16 08:12:48.000000000,2017-06-19 08:51:15.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}]","[{'number': 1, 'created': '2015-02-16 08:12:48.000000000', 'files': ['openstackdocstheme/theme/openstackdocs/script_search.html', 'openstackdocstheme/theme/openstackdocs/docsreleases.html', 'openstackdocstheme/theme/openstackdocs/theme.conf', 'openstackdocstheme/theme/openstackdocs/header.html'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/a5884efab8a5838a1452bddb32371ffb765b3f47', 'message': ""Introduce theme option 'show_search' to make search fields configurable\n\nIntroduce a new HTML theme option 'show_search' (True by default)\nto be able to disable the search formular using the html_theme_options.\n\nChange-Id: I8786047307d43c443920d90097ac7e690a1b69ad\n""}]",1,156150,a5884efab8a5838a1452bddb32371ffb765b3f47,7,3,1,167,,,0,"Introduce theme option 'show_search' to make search fields configurable

Introduce a new HTML theme option 'show_search' (True by default)
to be able to disable the search formular using the html_theme_options.

Change-Id: I8786047307d43c443920d90097ac7e690a1b69ad
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/50/156150/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackdocstheme/theme/openstackdocs/script_search.html', 'openstackdocstheme/theme/openstackdocs/docsreleases.html', 'openstackdocstheme/theme/openstackdocs/theme.conf', 'openstackdocstheme/theme/openstackdocs/header.html']",4,a5884efab8a5838a1452bddb32371ffb765b3f47,make_search_configurable,"{% if theme_show_search %}{% endif %} <div class=""collapse navbar-collapse"" id=""bs-example-navbar-collapse-1""> {% if theme_show_search %}{% endif %}{% if theme_show_search %}{% endif %}"," <div class=""collapse navbar-collapse"" id=""bs-example-navbar-collapse-1""> ",13,42
openstack%2Frally~master~Ice48514caba4372ac5205c370d58f6c427888724,openstack/rally,master,Ice48514caba4372ac5205c370d58f6c427888724,Deprecate CinderUtils and CinderWrapper,MERGED,2017-06-12 16:42:06.000000000,2017-06-19 08:51:07.000000000,2017-06-19 08:51:07.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}, {'_account_id': 21528}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-06-12 16:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d41c8ee233e352d0ee62669d196dcb7961029b22', 'message': 'Deprecate CinderUtils and CinderWrapper\n\nBlockStorage class was introduced some time ago. It includes all required\nlatest methods.\n\nChange-Id: Ice48514caba4372ac5205c370d58f6c427888724\n'}, {'number': 2, 'created': '2017-06-13 08:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ef5a29c6d12b891543640351bc56c073e0c94fc8', 'message': 'Deprecate CinderUtils and CinderWrapper\n\nBlockStorage class was introduced some time ago. It includes all required\nlatest methods.\n\nChange-Id: Ice48514caba4372ac5205c370d58f6c427888724\n'}, {'number': 3, 'created': '2017-06-13 09:11:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3c9ee12515e85f61a013afbb64cda4879ab1e329', 'message': 'Deprecate CinderUtils and CinderWrapper\n\nBlockStorage class was introduced some time ago. It includes all required\nlatest methods.\n\nChange-Id: Ice48514caba4372ac5205c370d58f6c427888724\n'}, {'number': 4, 'created': '2017-06-13 13:34:12.000000000', 'files': ['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'rally/plugins/openstack/scenarios/nova/utils.py', 'rally/plugins/openstack/scenarios/nova/servers.py', 'rally/plugins/openstack/services/storage/cinder_v1.py', 'rally/plugins/openstack/wrappers/cinder.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'rally/plugins/openstack/scenarios/vm/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/6d3f2ccae659b27bb8009ba203057432a8736705', 'message': 'Deprecate CinderUtils and CinderWrapper\n\nBlockStorage class was introduced some time ago. It includes all required\nlatest methods.\n\nChange-Id: Ice48514caba4372ac5205c370d58f6c427888724\n'}]",1,473527,6d3f2ccae659b27bb8009ba203057432a8736705,19,5,4,9545,,,0,"Deprecate CinderUtils and CinderWrapper

BlockStorage class was introduced some time ago. It includes all required
latest methods.

Change-Id: Ice48514caba4372ac5205c370d58f6c427888724
",git fetch https://review.opendev.org/openstack/rally refs/changes/27/473527/3 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'rally/plugins/openstack/scenarios/nova/servers.py', 'rally/plugins/openstack/services/storage/cinder_v1.py', 'rally/plugins/openstack/wrappers/cinder.py', 'rally/plugins/openstack/scenarios/cinder/utils.py', 'tests/unit/plugins/openstack/scenarios/nova/test_servers.py', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'rally/plugins/openstack/scenarios/vm/utils.py']",8,d41c8ee233e352d0ee62669d196dcb7961029b22,glance_cinder_services,class VMScenario(nova_utils.NovaScenario):,"from rally.plugins.openstack.scenarios.cinder import utils as cinder_utilsclass VMScenario(nova_utils.NovaScenario, cinder_utils.CinderScenario):",125,92
openstack%2Fkolla-ansible~master~Idb40cbed763382bef9965c6b090e71156b671590,openstack/kolla-ansible,master,Idb40cbed763382bef9965c6b090e71156b671590,Use templates for keystone domain specific configurations,MERGED,2017-06-12 14:42:35.000000000,2017-06-19 08:50:19.000000000,2017-06-19 08:50:19.000000000,"[{'_account_id': 3}, {'_account_id': 894}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22582}]","[{'number': 1, 'created': '2017-06-12 14:42:35.000000000', 'files': ['ansible/roles/keystone/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/20df81452800f3d48a0d665e142bc28ca95a5300', 'message': 'Use templates for keystone domain specific configurations\n\nChange-Id: Idb40cbed763382bef9965c6b090e71156b671590\n'}]",2,473483,20df81452800f3d48a0d665e142bc28ca95a5300,10,5,1,167,,,0,"Use templates for keystone domain specific configurations

Change-Id: Idb40cbed763382bef9965c6b090e71156b671590
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/83/473483/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/keystone/tasks/config.yml'],1,20df81452800f3d48a0d665e142bc28ca95a5300,use_templates_for_domain_specific_configurations, template:, copy:,1,1
openstack%2Fheat~master~Id5df151fdb3d580c285356bf2be6bc10d65df42e,openstack/heat,master,Id5df151fdb3d580c285356bf2be6bc10d65df42e,Updated from global requirements,MERGED,2017-06-15 16:23:13.000000000,2017-06-19 08:40:54.000000000,2017-06-19 08:40:54.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12404}]","[{'number': 1, 'created': '2017-06-15 16:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3f5ea90d447277e5d14389d35e102d040e7fdaa', 'message': 'Updated from global requirements\n\nChange-Id: Id5df151fdb3d580c285356bf2be6bc10d65df42e\n'}, {'number': 2, 'created': '2017-06-19 05:37:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/eed524e77143aee9027c1880707712d9fae66fee', 'message': 'Updated from global requirements\n\nChange-Id: Id5df151fdb3d580c285356bf2be6bc10d65df42e\n'}]",0,474639,eed524e77143aee9027c1880707712d9fae66fee,20,5,2,11131,,,0,"Updated from global requirements

Change-Id: Id5df151fdb3d580c285356bf2be6bc10d65df42e
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/474639/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c3f5ea90d447277e5d14389d35e102d040e7fdaa,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fmanila~master~I6c2ea07b0bfc5852b28e44989406cc10eb972e27,openstack/manila,master,I6c2ea07b0bfc5852b28e44989406cc10eb972e27,Use parenthesis instead of backslashes,ABANDONED,2017-06-06 09:09:50.000000000,2017-06-19 08:30:03.000000000,,"[{'_account_id': 3}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15831}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 17565}, {'_account_id': 18128}, {'_account_id': 18752}, {'_account_id': 20695}, {'_account_id': 22248}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-06-06 09:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b5d713545a4257855b85c545f14d7086c100750b', 'message': 'Use parenthesis instead of backslashes\n\nUse parenthesis instead of backslashes\n\nTrivialFix\nChange-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e27\n'}, {'number': 2, 'created': '2017-06-07 03:24:07.000000000', 'files': ['manila/api/v2/share_networks.py', 'manila/api/v1/shares.py', 'manila/tests/api/v1/test_share_unmanage.py', 'manila/db/migrations/alembic/versions/56cdbe267881_add_share_export_locations_table.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/api/v1/router.py', 'manila/tests/api/v1/test_share_types_extra_specs.py', 'manila/db/migrations/alembic/versions/55761e5f59c5_add_snapshot_support_extra_spec_to_share_types.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/api/v2/share_types.py', 'manila/db/migrations/alembic/versions/59eb64046740_add_required_extra_spec.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/fe8bf3c024fbefb4f6e45424e28d0ce9bc89bd93', 'message': 'Use parenthesis instead of backslashes\n\nUse parenthesis instead of backslashes\n\nTrivialFix\nChange-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e27\n'}]",0,471270,fe8bf3c024fbefb4f6e45424e28d0ce9bc89bd93,27,15,2,15100,,,0,"Use parenthesis instead of backslashes

Use parenthesis instead of backslashes

TrivialFix
Change-Id: I6c2ea07b0bfc5852b28e44989406cc10eb972e27
",git fetch https://review.opendev.org/openstack/manila refs/changes/70/471270/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/v2/share_networks.py', 'manila/api/v1/shares.py', 'manila/tests/api/v1/test_share_unmanage.py', 'manila/db/migrations/alembic/versions/56cdbe267881_add_share_export_locations_table.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/api/v1/router.py', 'manila/tests/api/v1/test_share_types_extra_specs.py', 'manila/db/migrations/alembic/versions/55761e5f59c5_add_snapshot_support_extra_spec_to_share_types.py', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/api/v2/share_types.py', 'manila/db/migrations/alembic/versions/59eb64046740_add_required_extra_spec.py']",12,b5d713545a4257855b85c545f14d7086c100750b,trivialfix," existing_required_extra_specs = (session.query(es_table). filter(es_table.c.spec_key == 'driver_handles_share_servers'). filter(es_table.c.deleted == 0). all()) share_types = (session.query(st_table). filter(st_table.c.deleted.in_(('0', 'False', ))). filter(st_table.c.id.notin_(exclude_st_ids)). all())"," existing_required_extra_specs = session.query(es_table).\ filter(es_table.c.spec_key == 'driver_handles_share_servers').\ filter(es_table.c.deleted == 0).\ all() share_types = session.query(st_table).\ filter(st_table.c.deleted.in_(('0', 'False', ))).\ filter(st_table.c.id.notin_(exclude_st_ids)).\ all()",81,81
openstack%2Ftripleo-docs~master~Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f,openstack/tripleo-docs,master,Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f,"Remove K, L & M release docs",MERGED,2017-06-16 13:49:08.000000000,2017-06-19 08:29:29.000000000,2017-06-19 08:29:29.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 10239}]","[{'number': 1, 'created': '2017-06-16 13:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/4e2d7be7b57214e457b68c061a4ae10d63441890', 'message': ""Remove K, L & M release docs\n\nKilo, Liberty and Mitaka releases are no longer maintained, repo links\ndon't work and the instructions get more complex with each release.\nThis commit removes instructions relating to this release but retains\nMitaka to Newton upgrade information.\n\nChange-Id: Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f\n""}, {'number': 2, 'created': '2017-06-16 13:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/899d142a052c945c25f68ced46a94b65d43c0d3b', 'message': ""Remove K, L & M release docs\n\nKilo, Liberty and Mitaka releases are no longer maintained, repo links\ndon't work and the instructions get more complex with each release.\nThis commit removes instructions relating to this release but retains\nMitaka to Newton upgrade information.\n\nChange-Id: Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f\n""}, {'number': 3, 'created': '2017-06-16 14:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/31ef554fb1e50a5dc2acabeca62b0ba8d08f95b7', 'message': ""Remove K, L & M release docs\n\nKilo, Liberty and Mitaka releases are no longer maintained, repo links\ndon't work and the instructions get more complex with each release.\nThis commit removes instructions relating to this release but retains\nMitaka to Newton upgrade information.\n\nChange-Id: Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f\n""}, {'number': 4, 'created': '2017-06-16 14:14:17.000000000', 'files': ['doc/source/post_deployment/upload_single_image.rst', '_custom/custom.css', 'doc/source/post_deployment/upgrade.rst', 'doc/source/repositories.txt', 'doc/source/advanced_deployment/root_device.rst', 'doc/source/post_deployment/build_single_image.rst', '_templates/layout.html', 'doc/source/advanced_deployment/baremetal_overcloud.rst', 'doc/source/advanced_deployment/ssl.rst', 'doc/source/index.rst', 'doc/source/post_deployment/quiesce_cephstorage.rst', 'doc/source/basic_deployment/basic_deployment_cli.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e47a6006a7637a06a482bcea5a5069f0c902b775', 'message': ""Remove K, L & M release docs\n\nKilo, Liberty and Mitaka releases are no longer maintained, repo links\ndon't work and the instructions get more complex with each release.\nThis commit removes instructions relating to this release but retains\nMitaka to Newton upgrade information.\n\nChange-Id: Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f\n""}]",0,474979,e47a6006a7637a06a482bcea5a5069f0c902b775,13,3,4,19740,,,0,"Remove K, L & M release docs

Kilo, Liberty and Mitaka releases are no longer maintained, repo links
don't work and the instructions get more complex with each release.
This commit removes instructions relating to this release but retains
Mitaka to Newton upgrade information.

Change-Id: Id3ddd7f9e0f2e249a75f07e4c9e6866dc3263b3f
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/79/474979/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/post_deployment/upload_single_image.rst', '_custom/custom.css', 'doc/source/post_deployment/upgrade.rst', 'doc/source/repositories.txt', 'doc/source/advanced_deployment/root_device.rst', 'doc/source/post_deployment/build_single_image.rst', '_templates/layout.html', 'doc/source/advanced_deployment/baremetal_overcloud.rst', 'doc/source/advanced_deployment/ssl.rst', 'doc/source/index.rst', 'doc/source/post_deployment/quiesce_cephstorage.rst', 'doc/source/basic_deployment/basic_deployment_cli.rst']",12,4e2d7be7b57214e457b68c061a4ae10d63441890,remove-mitaka-docs,," .. admonition:: Mitaka :class: mitaka :: export STABLE_RELEASE=""mitaka"" .. admonition:: Ceph :class: ceph :: export DIB_YUM_REPO_CONF=""$DIB_YUM_REPO_CONF /etc/yum.repos.d/CentOS-Ceph-Hammer.repo"" .. admonition:: Mitaka :class: mitaka :: rhel-7-server-rhceph-1.3-mon-rpms rhel-7-server-rhceph-1.3-osd-rpms rhel-7-server-rhceph-1.3-tools-rpms .. admonition:: Mitaka :class: mitaka For TripleO release Mitaka, the import command is:: openstack baremetal import --json instackenv.json The following command must be run after registration to assign the deployment kernel and ramdisk to all nodes:: openstack baremetal configure boot .. admonition:: Stable Branch :class: stable .. admonition:: Mitaka :class: mitaka For TripleO release Mitaka, the introspection command is:: openstack baremetal introspection bulk start ",1,206
openstack%2Fos-win~master~I6fd933b721c0576420b9558915426f6685f5af3f,openstack/os-win,master,I6fd933b721c0576420b9558915426f6685f5af3f,Updated from global requirements,MERGED,2017-06-15 16:32:30.000000000,2017-06-19 08:23:10.000000000,2017-06-19 08:23:10.000000000,"[{'_account_id': 3}, {'_account_id': 8213}, {'_account_id': 24544}]","[{'number': 1, 'created': '2017-06-15 16:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/322f57fe835ef3b1266ae3e11a6488957c19385d', 'message': 'Updated from global requirements\n\nChange-Id: I6fd933b721c0576420b9558915426f6685f5af3f\n'}, {'number': 2, 'created': '2017-06-19 05:45:25.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-win/commit/6cd0d4a6a45dcac2d8340eb143152833369e2fd6', 'message': 'Updated from global requirements\n\nChange-Id: I6fd933b721c0576420b9558915426f6685f5af3f\n'}]",0,474676,6cd0d4a6a45dcac2d8340eb143152833369e2fd6,10,3,2,11131,,,0,"Updated from global requirements

Change-Id: I6fd933b721c0576420b9558915426f6685f5af3f
",git fetch https://review.opendev.org/openstack/os-win refs/changes/76/474676/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,322f57fe835ef3b1266ae3e11a6488957c19385d,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fnetworking-generic-switch~master~If6da4ce8036db391fec0608ef41a94a7aeeab336,openstack/networking-generic-switch,master,If6da4ce8036db391fec0608ef41a94a7aeeab336,Updated from global requirements,MERGED,2017-06-19 05:40:20.000000000,2017-06-19 08:12:15.000000000,2017-06-19 08:12:15.000000000,"[{'_account_id': 3}, {'_account_id': 9542}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-06-19 05:40:20.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/db036ad5276797bbb2c00075aae302977bd8a5f1', 'message': 'Updated from global requirements\n\nChange-Id: If6da4ce8036db391fec0608ef41a94a7aeeab336\n'}]",0,475235,db036ad5276797bbb2c00075aae302977bd8a5f1,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: If6da4ce8036db391fec0608ef41a94a7aeeab336
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/35/475235/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,db036ad5276797bbb2c00075aae302977bd8a5f1,openstack/requirements,"futurist!=0.15.0,>=0.11.0 # Apache-2.0","futurist>=0.11.0,!=0.15.0 # Apache-2.0",3,3
openstack%2Fkarbor~master~Ifadd5d944bbb97e4304e8ac9044cc66327fbedf4,openstack/karbor,master,Ifadd5d944bbb97e4304e8ac9044cc66327fbedf4,Remove Horizon from gate's devstack,MERGED,2017-06-19 06:07:47.000000000,2017-06-19 08:04:43.000000000,2017-06-19 08:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 17151}, {'_account_id': 20883}]","[{'number': 1, 'created': '2017-06-19 06:07:47.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/karbor/commit/a50b4fefb1677134aa8206724342fdff6e3b058b', 'message': ""Remove Horizon from gate's devstack\n\nHorizon was removed from devstack gate by default [0].\nRemove horizon from Karbor fullstack devstack local.conf\n\n  [0] https://review.openstack.org/#/c/474283/\n\nChange-Id: Ifadd5d944bbb97e4304e8ac9044cc66327fbedf4\n""}]",0,475243,a50b4fefb1677134aa8206724342fdff6e3b058b,7,3,1,20883,,,0,"Remove Horizon from gate's devstack

Horizon was removed from devstack gate by default [0].
Remove horizon from Karbor fullstack devstack local.conf

  [0] https://review.openstack.org/#/c/474283/

Change-Id: Ifadd5d944bbb97e4304e8ac9044cc66327fbedf4
",git fetch https://review.opendev.org/openstack/karbor refs/changes/43/475243/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,a50b4fefb1677134aa8206724342fdff6e3b058b,remove-horizon-devstack,"s+=,c-api,c-vol,c-sch,c-bak","s+=,c-api,c-vol,c-sch,c-bak,horizon",1,1
openstack%2Fswift~master~I2d6c1dbded79d009afb7ddd953cb0de6099aa357,openstack/swift,master,I2d6c1dbded79d009afb7ddd953cb0de6099aa357,[Don't Merge]: Automated Tiering Discssion Organization Patch,NEW,2017-04-25 09:28:38.000000000,2017-06-19 08:02:50.000000000,,"[{'_account_id': 3}, {'_account_id': 4608}, {'_account_id': 9625}, {'_account_id': 13052}, {'_account_id': 13852}, {'_account_id': 14766}]","[{'number': 1, 'created': '2017-04-25 09:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/231d296fd20baea47d7f3429a21e4544f4c3868b', 'message': ""[Don't Merge]: Automated Tiering Discssion Organization Patch\n\nThis patch aims at record and organize discussions about automated tiering.\nThis patch will not merged into automated tiering patch.\n\nChange-Id: I2d6c1dbded79d009afb7ddd953cb0de6099aa357\n""}, {'number': 2, 'created': '2017-06-19 07:19:33.000000000', 'files': ['doc/source/automated_tiering_discussion.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/6dd0f40509bd75007f3c9dd9b1606fd75c2b6bc2', 'message': ""[Don't Merge]: Automated Tiering Discssion Organization Patch\n\nThis patch aims at record and organize discussions about automated tiering.\nThis patch will not merged into automated tiering patch.\n\nChange-Id: I2d6c1dbded79d009afb7ddd953cb0de6099aa357\n""}]",0,459611,6dd0f40509bd75007f3c9dd9b1606fd75c2b6bc2,7,6,2,14766,,,0,"[Don't Merge]: Automated Tiering Discssion Organization Patch

This patch aims at record and organize discussions about automated tiering.
This patch will not merged into automated tiering patch.

Change-Id: I2d6c1dbded79d009afb7ddd953cb0de6099aa357
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/459611/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/automated_tiering_discussion.rst'],1,231d296fd20baea47d7f3429a21e4544f4c3868b,automated-tiering-discussion,"============================= Automated Tiering Discussions ============================= This document explains logic and discussions of autoamated tiering, not how to use. Logic and discussions may not be applied to automated tiering implementation <https://review.openstack.org/#/c/287057/> patch yet. But they will be applied to implementation before the patch is merged. -------- Overview -------- Swift supports the optional special storage policies for automated tiering. The special policies are storage policies with some additional settings. Objects made with the special policies by clients are target of automated tiering. An object with a special policy will be moved among the orignal container (with the special policy) and other containers (with different policies) repeatedly. Even if objects are moved to another container by automated tiering daemons, clients can access the object transparently. The transparentness is so perfect that clients CANNOT know which the objects are moved to another container or not. ----------- Definitions ----------- AddressingRule Python classes which have determination method for objects' suitable storage policy. The determination methods' input is only objects' metadata. AddressingRule instances are plug-in program for automated tiering and you can use AddressingRule made by yourself or third parties. An AddressingRule instance has two kinds of storage policies, `original policy` and `derivative policy`. AddressingRule instances determine objects' suitable storage policy from the original policy or the derivative policies. Original Policy A starting point storage policy of an AddressingRule instance. If clients PUT objects with original policies, the assosiated AddressingRule will be applied to the objects. An AddressingRule has only one original policy. Derivative Poilcy Alternative storage policies for objects stored with original policies. An AddressingRule have one or more derivartive policies. Derivative Container A hidden container created by automated tiering daemons to store objects with a derivative policy. Derivative containers are created by daemons automatically. Original Container A container with an original policy. An original container is assosiated with an AddressingRule instance with the original policy. Original containers are created by clients. An original container can have a derivative container for each derivative policies of the associated AddressingRule instance. Different two original containers don't share derivative containers. Derivative Object Path An object path in a derivative container to store objects with a derivative policy. Original Object Path An object path in an original container. An original object path is assosiated with an AddressingRule instance with the container's original policy. An original object path can have a derivative object path for each derivative object path of the assosiated AddressingRule instance. Derivative object paths of an original object path have same object name. ObjectDeliverer A deamon which moves objects among original object paths and derivative object paths. If ObjectDeliverer moves an object to an derivative object path, ObjectDeliverer will PUT special symlink to the original object path. Tiering Link A special symlink made by ObjectDeliverers. EntityObject An object which is moved among an original object path and derivative object paths. Automated Tiering Middleware A middleware which provides perfectly transparent access to entity objects. If tiering links are in original object path, automated tiering middleware provides same response as entity object. ObjectAddresser A daemon which determines a suitable storage policy for each obejcts with original policies and send tasks to ObjectDeliverer to move objects to the suitable storage policies. Determination of suitable storage policies is done by AddressingRule instances. --------------------------------- Basic Behavior of ObjectDeliverer --------------------------------- Background ObjectDeliverer is a daemon which moves objects among original object paths and derivative object paths. Because ObjectAddressers determine source object path and destination object paths for each objects with original policy and send them as tasks (which are called DeliveryTask) to ObjectDeliverers, the only thing ObjectDeliverer have to do is to execute tasks. The cooperation of ObjectAddressers and ObjectDeliverers is discussed in ""Task Queueing"" section. ObjectDeliverers run on object-servers. Behavior ObjectDeilverers have 5 steps on an object move. Step1: GET object from the source object path Step2: PUT the destination container Step3: PUT the object to the destination object path Step4: PUT tiering link to the original object path (If the destination object path is derivative) Step5: DELETE source object (if the source object path is derivative) Details - Step1 is done by GETting the original object path via automated tiering middleware. As disscussed in ""Basic Behavior of Automated Tiering MIddlware"" section, if tiering link is in original object path, the newest metadata is in only tiering link, not entity object. Therefore, ObjectDeliverer need to GET from original object path via Automated Tiering Middleware to get object body with newest metadata. - Step1 is done with ""if-match"", ""if-modified-since"", and ""if-unmodified-since"" headers to ensure that moved objects are same object as ObjectAddressers watched. Etag and last-modified information are included in DeliveryTask by ObjectAddresser. - In step2, ObjectDeliverer should use unique container paths generated with original container paths and derivative policies to avoid PUTting same derivative container paths with different storage policies. - In step3, if the destination object paths are derivative, all metadata will be removed from the entity objects. This is for combination with object-expirer. The detail of the combination is discussed in ""Combination with Other Functions"" section. - In step3, 4, 5, ObjectDeliverer use intentional timestamps. The intentional timestamps are same timestamp of the source object, but only offsets are updated. Because step 3, 4, 5 need to use newer timestamp than old objects or tombstone to update swift state, but the timestamps must be older than clients' new PUT/DELETE requests to avoid overwrite clients' result. - In step3, 4, 5, ObjectDeliverer use timestamp integer of suitable policy determining time as offset to preserve the newest determination. - ObjectDeliverer cannot COPY objects instead of GETting objects (step1) and PUTting objects (step3), because COPY requests will update objects' timestamp with the timestamp of the COPY requests. ------------ Tiering Link ------------ Tiering link is symlink with special metadata made by ObjectDeliverer. Tiering links have the same metadata of referred entity objects except the follwing 5 points. Point1: Tiering links have 'X-Object-Sysmeta-Symlink-Target'. The values are referred entity objects' path. Point2: Etags are MD5 hash of empty strings. Point3: Content-Lengths are zero. Point4: Tiering links have special metadata 'X-Object-Sysmeta-Tierig-Etag'. The values are referred entity objects' etags. Point5: Tiering links have special metadata 'X-Object-Sysmeta-Tierig-Content-Length'. The values are referred entity objects' content-length. Therefore, we can restore referred entity objects' metadata from tiering links' metadata. ---------------------------------------------- Basic Behaviro of Automated Tiering Middleware ---------------------------------------------- Background Automated tiering middleware provides transparent access of clients' POST(fast-POST) and GET and HEAD. This middleware does nothing for clients' PUT and DELETE. Transparency of clients' PUT and DELETE is discussed in ""Consistency Checking"" section. Transparency of clients' COPY and POST-as-COPY are provided as combination of GET transparency and PUT transparency. Transparency of POST - POST requests to tiering links are approved same as POST requests to standard objects for transparency. This is difference between tiering links and symlinks. - .meta files are made in only original object paths, not derivative object paths. - Automated tiering middleware converts POST response to tiering links to same response to entity objects. Transparency of HEAD - If HEAD requests send to tiering links, this middleware restore metadata of entity objects and send response with the restored metadata. - This middleware restore metadata by moving 'X-Object-Sysmteta-Tiering-Etag' and 'X-Object-Sysmeta-Tiering-Content-Length' to 'Etag' and 'Content-Length' and removing 'X-Object-Sysmeta-Symlink-Target' - Even if there are .meta files with tiering links, we can restore metadata by same method to restore metadata with POST results to entity objects. Transparency of GET - If GET requests send to tiering links, expected metadata are same metadata as HEAD and expected body is the referred entity objects. Therefore, this middleware restore metadata and redirect GET request to referred objects. -------------- AddressingRule -------------- AddressingRules are Python classes which have determination method for objects' suitable storage policy. For plug-in use case, AddressingRule class is implemented as abstract class. AddressingRule subclasses must have determine_suitable_policy method implementation which determines suitable poilcy from objects' metadata. To use AddressingRules, classpath of AddressingRule subclasses and arguments for AddressingRule subclass constructors are needed in ObjectAddresser's configure. Arguments for AddressingRule subclass constructors are as follows: - rule name - original policy name - comma separated derivative policies name list - other additional arguments for subclass constructors ObjectAddressers will have AddressringRule instances constructed with arguments above. ObjectAddresser can have more than one AddressingRule instances. Therefore there will be more than one original policies in one Swift cluster. Therea are two limits for uniqueness of determination of suitable policies. Limit1: Two AddressingRule instances cannot share same original policy. Limit2: An AddressingRule instance's original policy cannot included in Another AddressingRule instances derivative policies. ObjectAddressers checks above limits. --------------------------------- Basic Behavior of ObjectAddresser --------------------------------- Background ObjectAddresser is a daemon which determines a suitable storage policy for each obejcts with original policies and send DeliveryTasks to ObjectDeliverer to move objects to the suitable storage policies. Determination of suitable storage policies is done by AddressingRule instances. ObjectAddressers run on object-servers. Behavior ObjectAddressers execute following 3 steps for each objects in LOCAL NODE with original policies. Step1: If the local object is entity object, get the metadata. If the local object is tiering link, restore the metadata of referred entity object. Step2: Determine suitable storage policy for the entity object by an AddressingRule instance associated with the original policy. Step3: If the suitable storage policy is not current storage policy, send a DeilveryTask to ObjectDeliverer. -------------------- Consistency Checking -------------------- Background Consistent state among an original object path and its derivative object paths are defined as following 3 states. - Consistent State 1: An entity object is in the original object path and no objects are in any derivative object paths. +--------------------------+-----------------------------------------+ | | object state | +==========================+=========================================+ | original object path | entity object | +--------------------------+-----------------------------------------+ | derivative object path 1 | nothing or tombstone | +--------------------------+-----------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+-----------------------------------------+ - Consistent State 2: A tiering link is in the original object path, an entity object is in the referred derivative object path and no objects in any other derivative object paths. +--------------------------+-----------------------------------------+ | | object state | +==========================+=========================================+ | original object path | tiering link to derivtive object path 1 | +--------------------------+-----------------------------------------+ | derivative object path 1 | entity object | +--------------------------+-----------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+-----------------------------------------+ - Consistent State 3: No object is in the orignanl object path and no objects are in any derivative object paths. +--------------------------+-----------------------------------------+ | | object state | +==========================+=========================================+ | original object path | nothing or tombstone | +--------------------------+-----------------------------------------+ | derivative object path 1 | nothing or tombstone | +--------------------------+-----------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+-----------------------------------------+ These consistency will be broken in following cases. - Case 1: A client overwrite tiering link in the original object path by PUTting new object when consistent state 2. +--------------------------+-----------------------------------------+ | | object state | +==========================+=========================================+ | original object path | new entity object | +--------------------------+-----------------------------------------+ | derivative object path 1 | old entity object | +--------------------------+-----------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+-----------------------------------------+ - Case 2: A client DELETE tiering link in the original object path when consistent state 2. +--------------------------+-----------------------------------------+ | | object state | +==========================+=========================================+ | original object path | nothing or tombstone | +--------------------------+-----------------------------------------+ | derivative object path 1 | entity object | +--------------------------+-----------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+-----------------------------------------+ - Case 3: ObjectDeliverer fail to execute task in progress. +--------------------------+-----------------------------------------+ | | object state | +==========================+=========================================+ | original object path | tiering link to derivtive object path 1 | +--------------------------+-----------------------------------------+ | derivative object path 1 | entity object | +--------------------------+-----------------------------------------+ | derivative object path 2 | entity object | +--------------------------+-----------------------------------------+ Therefore, consistency checking feature is needed. For consistency checking, ObjectAddressers check consistency among original object paths and derivative object paths. If ObjectAddressers find inconsistent objects, send tasks to ObjectDeliverer to obtain consisteny. In obtaining consistency process, clients' newest PUT/POST/DELETE result must be preserved. To implement this behavior, ObjectAddressers and ObjectDeliverers propagate objects' state among original object paths and derivative object paths in accordance with following rules. ObjectAddressers and ObjectDeliverers can obtain consistency only by propagating object states from newer object to older objects. - Propagation Rule 1: If an entity object is in an original object path, ObjectDeliverer can DELETE its derivative object path with same timestamp of the .data file. +--------------------------+---------------------------------------+ | | object state | +==========================+=======================================+ | original object path | entity object (t1 .data) | | | (t2 .meta) | +--------------------------+---------------------------------------+ | derivative object path 1 | entity object (t0) | +--------------------------+---------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+---------------------------------------+ [ propagate state ] +--------------------------+---------------------------------------+ | | object state | +==========================+=======================================+ | original object path | entity object (t1 .data) | | | (t2 .meta) | +--------------------------+---------------------------------------+ | derivative object path 1 | tombstone (t1) | +--------------------------+---------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+---------------------------------------+ Note: DELETE with timestamp of .meta file can DELETE the newest entity object in split brain case. +--------------------------+---------------------------------------+------------------------------------------------------+ | | object state in brain 1 | object state in brain 2 | +==========================+=======================================+======================================================+ | original object path | entity object (t1 .data) | tiering link to derivtive object path 1 (t1_1 .data) | | | (t2 .meta) | (t2 .meta) | +--------------------------+---------------------------------------+------------------------------------------------------+ | derivative object path 1 | entity object (t0) | entity object (t1_1) | +--------------------------+---------------------------------------+------------------------------------------------------+ | derivative object path 2 | nothing or tombstone | nothing or tombstone | +--------------------------+---------------------------------------+------------------------------------------------------+ [ propagate state in brain 1 ] +--------------------------+---------------------------------------+------------------------------------------------------+ | | object state in brain 1 | object state in brain 2 | +==========================+=======================================+======================================================+ | original object path | entity object (t1 .data) | tiering link to derivtive object path 1 (t1_1 .data) | | | (t2 .meta) | (t2 .meta) | +--------------------------+---------------------------------------+------------------------------------------------------+ | derivative object path 1 | tombstone (t2) | entity object (t1_1) | +--------------------------+---------------------------------------+------------------------------------------------------+ | derivative object path 2 | nothing or tombstone | nothing or tombstone | +--------------------------+---------------------------------------+------------------------------------------------------+ [ split brain is resolved ] +--------------------------+------------------------------------------------------+ | | object state in brain 2 | +==========================+======================================================+ | original object path | tiering link to derivtive object path 1 (t1_1 .data) | | | (t2 .meta) | +--------------------------+------------------------------------------------------+ | derivative object path 1 | tombstone (t2) | +--------------------------+------------------------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+------------------------------------------------------+ - Propagation Rule 2: If an entity object is in a derivative object path, ObjectDeliverer can PUT tiering link to its original object path with same timestamp of the entity object. +--------------------------+------------------------------------------------+ | | object state | +==========================+================================================+ | original object path | tiering link to derivtive object path 1 (t0_1) | | | (t1 .meta) | +--------------------------+------------------------------------------------+ | derivative object path 1 | entity object (t0_1) | +--------------------------+------------------------------------------------+ | derivative object path 2 | entity object (t0_2) | +--------------------------+------------------------------------------------+ [ propagate state ] +--------------------------+------------------------------------------------+ | | object state | +==========================+================================================+ | original object path | tiering link to derivtive object path 2 (t0_2) | | | (t1 .meta) | +--------------------------+------------------------------------------------+ | derivative object path 1 | entity object (t0_1) | +--------------------------+------------------------------------------------+ | derivative object path 2 | entity object (t0_2) | +--------------------------+------------------------------------------------+ - Propagation Rule 3: If an tiering link is in an original object path, ObjectDeliverer can DELETE its derivative object path with same timestamp of the .data file. +--------------------------+------------------------------------------------+ | | object state | +==========================+================================================+ | original object path | tiering link to derivtive object path 2 (t0_2) | | | (t1 .meta) | +--------------------------+------------------------------------------------+ | derivative object path 1 | entity object (t0_1) | +--------------------------+------------------------------------------------+ | derivative object path 2 | entity object (t0_2) | +--------------------------+------------------------------------------------+ [ propagate state ] +--------------------------+------------------------------------------------+ | | object state | +==========================+================================================+ | original object path | tiering link to derivtive object path 2 (t0_2) | | | (t1 .meta) | +--------------------------+------------------------------------------------+ | derivative object path 1 | tombstone (t0_2) | +--------------------------+------------------------------------------------+ | derivative object path 2 | entity object (t0_2) | +--------------------------+------------------------------------------------+ - Propagation Rule4: If an tombstone is in an original object path, ObjectDeliverer can DELETE its derivative object path with same timestamp of the .data file. +--------------------------+---------------------------------------+ | | object state | +==========================+=======================================+ | original object path | tombstone (t1) | +--------------------------+---------------------------------------+ | derivative object path 1 | entity object (t0) | +--------------------------+---------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+---------------------------------------+ [ propagate state ] +--------------------------+---------------------------------------+ | | object state | +==========================+=======================================+ | original object path | tombstone (t1) | +--------------------------+---------------------------------------+ | derivative object path 1 | tombstone (t1) | +--------------------------+---------------------------------------+ | derivative object path 2 | nothing or tombstone | +--------------------------+---------------------------------------+ Consistency should be managed only by ObjectAddresser and ObjectDeliverer. Therefore, following limits are set. Limit1: Only ObjectDeliverers can send request to derivative object paths. Limit2: Only ObjectDeliverers can make tiering links in origian object paths. +------------------+------------------------------------+------------------------------------------+----------------------------------------+ | | Requests to Derivative Object Path | PUT Tiering Link to Original Object Path | Other Requests to Original Object Path | +==================+====================================+==========================================+========================================+ | Object Deliverer | OK | OK | OK | +------------------+------------------------------------+------------------------------------------+----------------------------------------+ | Other Clients | NG | NG | OK | +------------------+------------------------------------+------------------------------------------+----------------------------------------+ Behavior ObjectAddressers search objects which need to be propagated states and send tasks to ObjectDeliverer to propagate states. There are following two kinds of tasks. CleaningTask: A task for DELETE derivative object path for propagation rule 1, 3, 4. LinkUpdateTask: A task for PUT a tiering link for propagation rule 2. ObjectAddressers execute following 3 steps. Step1: GET list of pair of derivative object path and timestamp by GETting derivative containers. Note: For this step, ObjectAddressers make derivative container list in hidden account when ObjectAddressers send DeliveryTasks to ObjectDeliverer in advance. Step2: For each derivative object paths, if the original object path of the derivative path is in local node, execute step3, if not, skip. Step3: Compare timestamp of .data file in the original object path and timestamp of derivative object path and execute following cases. Note: Timestamp of the derivative object path doesn't have offset because it comes from object listing. Therefore, these timestamps are compared without offsets. Case A: Timestamp of a object or a tombstone of the original object path > Timestamp of the derivative object path Send a CleaningTask. Case B: Timestamp of a object or a tombstone of the original object path < Timestamp of the derivative object path Send a LinkUpdateTask. Case C: Timestamp of a object or a tombstone of the original object path == Timestamp of the derivative object path In this case, ObjectAddressers cannot know which timestamp's offset is newer. Therefore, ObjectAddressers check the reference of the original object path and execute following cases. Case C-A: Tiering link is in the original object path and the tiering link refers the derivative object path Do nothing, even though offsets can be different because offset difference doesn't cause any problems. Case C-B: Other cases Send both of a CleaningTask and a LinkUpdateTask. In this case, offsets must be different because same offset means that the object in the original object path made by propagation from the derivative object path. Therefore, execution of the two tasks results in propagation of the newest offset. Case D: There is no objects or no tombstones in the original object path. Send a LinkUpdateTask. In this case, a tombstone in the original object path may have been reclaimed. Ideally ObjectAddresser should send a CleaningTask to DELETE the derivative object path, but ObjectAddresser cannot know timestamp of the tombstone for propagation. Therefore, ObjectAddresser send a LinkUpdateTask for consistency. Clients will observe a object which is DELETEd reviving. Because behavior of case D is strange, case D should be very rare. Therefore, ObjectAddresser should check tombstones in original object paths before they are reclaimed. Expended time for consistency checking depends on count of derivtive object paths. Therefore, ObjectAddresses run a thread for each following two loops. Loop1: Loop for DELETEd original object paths. Loop2: Loop for non-DELETEd original object paths. Because threads for the loop1 will check only DELETEd original object paths, the threads more easily find tombstones before reclaim. For this loop splitting, the following changes are applied to the steps above. Change1: Additionaly GET list of original object paths in step1. Change2: If threads run loop1, derivative object paths whose original object paths are included in the list of change1 are skipped in step2. Change3: If threads run loop2, derivative object paths whose original object paths are NOT included in the list of change1 are skipped in step2. -------------------------------- Combination with Other Functions -------------------------------- Automated tiering functions provides transparent combination with following functions. - All proxy server middlewares - All daemons with internal clients (object-expirer, container-reconciler, container-sync) Transparency for proxy server middleware The only thing automated tiering function have to do is providing transparent accesses of accounts or containers or objects. - Transparency of object requests If automated tiering middleware is to the right of all other middleware in pipeline apart from the final proxy-logging middleware, transparency will be provided to all other middlewares. - Transparency of container/account requests Transpaceny of container/account requests is discusssed in ""Container and Account Access Transparency"" section. Transparency for daemons with internal clients As discussed in ""Consistency Checking"" section, any clients except ObjectDeliverer must not access derivative object paths. Therefore, all daemons with internal clients must access only original object paths via automated tiering middleware in their own internal clients. Avoidance of derivative object paths access are done by following plan. - Object-Expirer When ObjectDeliverers PUT entity objects to derivative object path, 'X-Delete-At' and 'X-Delete-After' are removed from it. For simplicity and future extension, all metadata will be removed from entity objects in derivative object path. - Container-Reconciler Because derivative container paths are depends on their storage policies, there are no cases that a derivative container has more than one storage policy. - Container-Sync 'X-Container-Sync-To' metadata is added by clients to only original containers. ------------------------------------------------- Hidden Account Name Rule (Discussion is on Going) ------------------------------------------------- There are two plans of hidden acount/contaienr name rule. Plan1: There will be one hidden account per account which has hidden derivative container. The following table is example. +-------------------------+-----------------------------------------------------+ | original | derivative (hidden) | +===========+=============+===================+================+================+ | account | container | derivative policy | account | container | +===========+=============+===================+================+================+ | acc1 | con1 | 1 | .tiered_acc1 | con1_1 | +-----------+-------------+-------------------+----------------+----------------+ | acc1 | con1 | 2 | .tiered_acc1 | con1_2 | +-----------+-------------+-------------------+----------------+----------------+ | acc1 | con2 | 2 | .tiered_acc1 | con2_2 | +-----------+-------------+-------------------+----------------+----------------+ | acc2 | con3 | 1 | .tiered_acc2 | con3_1 | +-----------+-------------+-------------------+----------------+----------------+ In this case, tiering daemons need to make derivative containers list, in some account, because tiering daemon need to GET derivative containers as discussed in ""Consistency Checking"" section. PROS: If each original account don't have many containers, counts of each derivative account's containers will not be large. CONS: Tiering daemons must make derivative containers list. Plan2: Only one hidden account will be used, and original account name and original container name will be included in derivative container name. The following table is example. +-------------------------+-----------------------------------------------------+ | original | derivative (hidden) | +===========+=============+===================+============+====================+ | account | container | derivative policy | account | container | +===========+=============+===================+============+====================+ | acc1 | con1 | 1 | .tiered | quote(acc1/con1/1) | +-----------+-------------+-------------------+------------+--------------------+ | acc1 | con1 | 2 | .tiered | quote(acc1/con1/2) | +-----------+-------------+-------------------+------------+--------------------+ | acc1 | con2 | 2 | .tiered | quote(acc1/con2/2) | +-----------+-------------+-------------------+------------+--------------------+ | acc2 | con3 | 1 | .tiered | quote(acc2/con3/1) | +-----------+-------------+-------------------+------------+--------------------+ Note: quote is function of swift.common.utils.quote In this case, tiering daemons don't need to make derivative container list, because result of GET '.tiered' account is derivative containers list. PROS: Derivative containers list is not required. CONS: Count of '.tiered' account's containers can be large, because all derivative containers in Swift is stored in the '.tiered' account. Which plan is better? ------------------------------------------------------------------ Container and Account Access Transparency (Discussion is on Going) ------------------------------------------------------------------ PUTting tiering links to original object paths will cause following problems. Problem 1: Some records of object listings of container GET will have tiering links' etags and bytes. Problem 2: Container-Bytes-Used of response of container GET/HEAD will decrease. Problem 3: Some records of container listings of account GET will have lesser bytes. Problem 4: Account-Bytes-Used of response of account GET/HEAD will decrease. Therefore, feature for container/account transparency is needed. There are following 3 storategies Strategy 1 (Use information in container/account DB): For problem 1 - Tiering links have etags and bytes of referred entity objects in their content-type. - Object listing will be updated with the entity objects' etag and bytes like slo manifests. For problem 2 - Container GET/HEAD's 'Container-Bytes-Used' header will be updated by automated tiering middleware. Automated tiering middleware will get sum of derivative containers' bytes-used by HEADing all related derivative containers. For problem 3 - In this stragegy, problem 3 is not resolved. Because account DBs don't have string column like container DBs' content-type. For problem 4 - Account GET/HEAD's 'Account-Bytes-Used' header will be updated by automated tiering middleware. Automated tiering middleware will get sum of derivative accounts' bytes-used by HEADing all related derivative accounts. PROS - Simple logic. CONS - All GET/HEAD for account/container include overheads to HEAD derivative containers/accounts. - Bytes information of an object can be doubly counted or missed. - Transparency for container listing is not provided. Strategy 2 (Update bytes_used column in container/account DB): For problem 1 (same as strategy 1) - Tiering links have etags and bytes of referred entity objects in their content-type. - Object listing will be updated with the entity objects' etag and bytes like slo manifests. For problem 2 - When container DBs are updated, bytes_used column will be updated with referred entity objects' bytes for tiering links. For problem 3 and 4 - Resolved with nothing special because sums of container DB's byte_used are required values. PROS: - Resolving all of 4 problems. CONS: - Semantics of bytes_used of account/container DB will be ""values expected by clients"", not ""actually stored in the containers/accounts"". Strategy 3 (No update by tiering) For problem 1, 2, 3, 4 - When ObjectDeliverer PUT tiering link, container DB will not be updated. PROS - Resolving all of 4 problems. - Implementation will be very small. - Third party applications using account/container DB directly (e.g. slogging) can get transparency. CONS: - Semantics of all information of account/container DB will be ""values expected by clients"", not ""actually stored in the containers/accounts"". Which strategy is best? - I think strategy 3 is best. (m_kazuhiro) ------------------------------------- Task Queuing (Discussion is on Going) ------------------------------------- In automated tiering, ObjectAddressers make tasks to move objects and ObjectDeliverers execute them. If ObjectDeiverers execute tasks just after ObjectAddressers make them, failure of task execution will delay moving of objects for long because ObjectAddresser7s loop can be long. Therefore, asynchronous task queueing system is required. There are two implementation plan of task queuing. - Task queue specialized for tiering in current automated tiering patch. - General task queue system <https://wiki.openstack.org/wiki/Swift/ideas/task-execution> Eventually, ObjectAddressers and ObjectDeliverers should use the general task queue. There are 3 strategies for merging general task queue in automated tiering. strategy 1 step1: Automated tiering will be merged with specialized task queue. step2: General task queue will be merged. step3: Following patch which fix automated tiering to use the general task queue. PROS: Automated Tiering can use task queue at first release. CONS: General task queue will not be compatible with specialized task queue. strategy 2 step1: General task queue will be merged. step2: Autoamted tiering with general task queue will be merged. PROS: There are no problem of compatibility. CONS: Automated tiering's merge will be delayed, because general task queue will require long discussion. strategy 3 step1: Automated Tiering will be merged without task queue. Note: ObjectDeliverer execute tasks just after ObjectAddressers make them. The two daemons will be merged into one daemon. step2: General task queue merged. step3: Following patch which fix automated tiering to use the general task queue and split daemons. PROS: The first automated tiering patch will be simple. There are no problem of compatibility. CONS: Automated tiering cannot use task queue at first release. Which strategy is best? - I think stragety 3 is best. Review of automated tiering patch will be easier. --------------------------------------------------------------------------- Optimization of Suitable Policy Determination Loop (Discussion is on Going) --------------------------------------------------------------------------- The more objects in original policies, The longer loop required to make DeliveryTasks. But not all objects in original policies need to be checked to determine suitable policies. For example, think about objects in original policy of an AddressingRule instance which determines suitable policies as followings. - Suitable policy of objects whose elapsed time from last modified are lesser than one month are replication. - Suitable policy of objects whose elapsed time from last modified are greater than one month are erasure coding. In this case, objects which are moved to erausre coding don't need to be checked to determine suitable policies. If ObjectAddressers filter loop for making DeliveryTask by the objects need to be checked to determine suitable policies or not, the loop will be shorter. However, filtering methods will depend on AddressingRule implementations. In proposal for this optimization, ObjectAddresser will use filtered object path lists as follows. - AddressingRule subclasses have object path filtering methods optionally. - AddressingRule subclasses have flag about the subclasses have the optional method or not. - If an AddressingRule has the optional method, ObjectAddresser will check only the original object paths which are generated by the optional filtering method. Is this feature is needed? Is this feature is reasonable? ",,673,0
openstack%2Ffuel-library~master~Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83,openstack/fuel-library,master,Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83,Clean up keystone.conf file,MERGED,2017-06-15 09:56:10.000000000,2017-06-19 07:56:23.000000000,2017-06-19 07:55:32.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14200}]","[{'number': 1, 'created': '2017-06-15 09:56:10.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/keystone/keystone.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/245539ea9fa29e5c46e95947e77f64c62bb0daee', 'message': ""Clean up keystone.conf file\n\nAt the end of keystone.conf file there were some options from\nkeystone-paste.ini file. These options don't affect anything\nthat's why they were removed in order to clean up keystone.conf\n\nChange-Id: Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83\nCloses-Bug: #1693188\n""}]",0,474529,245539ea9fa29e5c46e95947e77f64c62bb0daee,27,5,1,18845,,,0,"Clean up keystone.conf file

At the end of keystone.conf file there were some options from
keystone-paste.ini file. These options don't affect anything
that's why they were removed in order to clean up keystone.conf

Change-Id: Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83
Closes-Bug: #1693188
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/29/474529/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack_tasks/manifests/keystone/keystone.pp'],1,245539ea9fa29e5c46e95947e77f64c62bb0daee,bug/1693188,, keystone_config { 'identity/driver': value =>'keystone.identity.backends.sql.Identity'; 'ec2/driver': value =>'keystone.contrib.ec2.backends.sql.Ec2'; 'filter:debug/paste.filter_factory': value =>'keystone.common.wsgi:Debug.factory'; 'filter:token_auth/paste.filter_factory': value =>'keystone.middleware:TokenAuthMiddleware.factory'; 'filter:admin_token_auth/paste.filter_factory': value =>'keystone.middleware:AdminTokenAuthMiddleware.factory'; 'filter:xml_body/paste.filter_factory': value =>'keystone.middleware:XmlBodyMiddleware.factory'; 'filter:json_body/paste.filter_factory': value =>'keystone.middleware:JsonBodyMiddleware.factory'; 'filter:user_crud_extension/paste.filter_factory': value =>'keystone.contrib.user_crud:CrudExtension.factory'; 'filter:crud_extension/paste.filter_factory': value =>'keystone.contrib.admin_crud:CrudExtension.factory'; 'filter:ec2_extension/paste.filter_factory': value =>'keystone.contrib.ec2:Ec2Extension.factory'; 'filter:s3_extension/paste.filter_factory': value =>'keystone.contrib.s3:S3Extension.factory'; 'filter:url_normalize/paste.filter_factory': value =>'keystone.middleware:NormalizingFilter.factory'; 'filter:stats_monitoring/paste.filter_factory': value =>'keystone.contrib.stats:StatsMiddleware.factory'; 'filter:stats_reporting/paste.filter_factory': value =>'keystone.contrib.stats:StatsExtension.factory'; 'app:public_service/paste.app_factory': value =>'keystone.service:public_app_factory'; 'app:admin_service/paste.app_factory': value =>'keystone.service:admin_app_factory'; 'pipeline:public_api/pipeline': value =>'stats_monitoring url_normalize token_auth admin_token_auth xml_body json_body debug ec2_extension user_crud_extension public_service'; 'pipeline:admin_api/pipeline': value =>'stats_monitoring url_normalize token_auth admin_token_auth xml_body json_body debug stats_reporting ec2_extension s3_extension crud_extension admin_service'; 'app:public_version_service/paste.app_factory': value =>'keystone.service:public_version_app_factory'; 'app:admin_version_service/paste.app_factory': value =>'keystone.service:admin_version_app_factory'; 'pipeline:public_version_api/pipeline': value =>'stats_monitoring url_normalize xml_body public_version_service'; 'pipeline:admin_version_api/pipeline': value =>'stats_monitoring url_normalize xml_body admin_version_service'; 'composite:main/use': value =>'egg:Paste#urlmap'; 'composite:main//v2.0': value =>'public_api'; 'composite:main//': value =>'public_version_api'; 'composite:admin/use': value =>'egg:Paste#urlmap'; 'composite:admin//v2.0': value =>'admin_api'; 'composite:admin//': value =>'admin_version_api'; } ,0,31
openstack%2Ffuel-library~stable%2Fnewton~Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83,openstack/fuel-library,stable/newton,Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83,Clean up keystone.conf file,MERGED,2017-06-15 09:55:06.000000000,2017-06-19 07:52:35.000000000,2017-06-19 07:51:48.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2017-06-15 09:55:06.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/keystone/keystone.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/98154bff027073093b7142b22988cfc7d33cd05f', 'message': ""Clean up keystone.conf file\n\nAt the end of keystone.conf file there were some options from\nkeystone-paste.ini file. These options don't affect anything\nthat's why they were removed in order to clean up keystone.conf\n\nChange-Id: Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83\nCloses-Bug: #1693188\n""}]",0,474527,98154bff027073093b7142b22988cfc7d33cd05f,27,3,1,18845,,,0,"Clean up keystone.conf file

At the end of keystone.conf file there were some options from
keystone-paste.ini file. These options don't affect anything
that's why they were removed in order to clean up keystone.conf

Change-Id: Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83
Closes-Bug: #1693188
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/474527/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack_tasks/manifests/keystone/keystone.pp'],1,98154bff027073093b7142b22988cfc7d33cd05f,bug/1693188,, keystone_config { 'identity/driver': value =>'keystone.identity.backends.sql.Identity'; 'ec2/driver': value =>'keystone.contrib.ec2.backends.sql.Ec2'; 'filter:debug/paste.filter_factory': value =>'keystone.common.wsgi:Debug.factory'; 'filter:token_auth/paste.filter_factory': value =>'keystone.middleware:TokenAuthMiddleware.factory'; 'filter:admin_token_auth/paste.filter_factory': value =>'keystone.middleware:AdminTokenAuthMiddleware.factory'; 'filter:xml_body/paste.filter_factory': value =>'keystone.middleware:XmlBodyMiddleware.factory'; 'filter:json_body/paste.filter_factory': value =>'keystone.middleware:JsonBodyMiddleware.factory'; 'filter:user_crud_extension/paste.filter_factory': value =>'keystone.contrib.user_crud:CrudExtension.factory'; 'filter:crud_extension/paste.filter_factory': value =>'keystone.contrib.admin_crud:CrudExtension.factory'; 'filter:ec2_extension/paste.filter_factory': value =>'keystone.contrib.ec2:Ec2Extension.factory'; 'filter:s3_extension/paste.filter_factory': value =>'keystone.contrib.s3:S3Extension.factory'; 'filter:url_normalize/paste.filter_factory': value =>'keystone.middleware:NormalizingFilter.factory'; 'filter:stats_monitoring/paste.filter_factory': value =>'keystone.contrib.stats:StatsMiddleware.factory'; 'filter:stats_reporting/paste.filter_factory': value =>'keystone.contrib.stats:StatsExtension.factory'; 'app:public_service/paste.app_factory': value =>'keystone.service:public_app_factory'; 'app:admin_service/paste.app_factory': value =>'keystone.service:admin_app_factory'; 'pipeline:public_api/pipeline': value =>'stats_monitoring url_normalize token_auth admin_token_auth xml_body json_body debug ec2_extension user_crud_extension public_service'; 'pipeline:admin_api/pipeline': value =>'stats_monitoring url_normalize token_auth admin_token_auth xml_body json_body debug stats_reporting ec2_extension s3_extension crud_extension admin_service'; 'app:public_version_service/paste.app_factory': value =>'keystone.service:public_version_app_factory'; 'app:admin_version_service/paste.app_factory': value =>'keystone.service:admin_version_app_factory'; 'pipeline:public_version_api/pipeline': value =>'stats_monitoring url_normalize xml_body public_version_service'; 'pipeline:admin_version_api/pipeline': value =>'stats_monitoring url_normalize xml_body admin_version_service'; 'composite:main/use': value =>'egg:Paste#urlmap'; 'composite:main//v2.0': value =>'public_api'; 'composite:main//': value =>'public_version_api'; 'composite:admin/use': value =>'egg:Paste#urlmap'; 'composite:admin//v2.0': value =>'admin_api'; 'composite:admin//': value =>'admin_version_api'; } ,0,31
openstack%2Ffuel-library~stable%2Focata~Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83,openstack/fuel-library,stable/ocata,Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83,Clean up keystone.conf file,MERGED,2017-06-15 09:55:56.000000000,2017-06-19 07:51:42.000000000,2017-06-19 07:50:51.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2017-06-15 09:55:56.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/keystone/keystone.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d076b4c6a5ab660caef43ecd7157348ead1956bb', 'message': ""Clean up keystone.conf file\n\nAt the end of keystone.conf file there were some options from\nkeystone-paste.ini file. These options don't affect anything\nthat's why they were removed in order to clean up keystone.conf\n\nChange-Id: Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83\nCloses-Bug: #1693188\n""}]",0,474528,d076b4c6a5ab660caef43ecd7157348ead1956bb,33,3,1,18845,,,0,"Clean up keystone.conf file

At the end of keystone.conf file there were some options from
keystone-paste.ini file. These options don't affect anything
that's why they were removed in order to clean up keystone.conf

Change-Id: Ib388c37ac4f622cabc405a4d83ba71f2f35b7e83
Closes-Bug: #1693188
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/474528/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/openstack_tasks/manifests/keystone/keystone.pp'],1,d076b4c6a5ab660caef43ecd7157348ead1956bb,bug/1693188,, keystone_config { 'identity/driver': value =>'keystone.identity.backends.sql.Identity'; 'ec2/driver': value =>'keystone.contrib.ec2.backends.sql.Ec2'; 'filter:debug/paste.filter_factory': value =>'keystone.common.wsgi:Debug.factory'; 'filter:token_auth/paste.filter_factory': value =>'keystone.middleware:TokenAuthMiddleware.factory'; 'filter:admin_token_auth/paste.filter_factory': value =>'keystone.middleware:AdminTokenAuthMiddleware.factory'; 'filter:xml_body/paste.filter_factory': value =>'keystone.middleware:XmlBodyMiddleware.factory'; 'filter:json_body/paste.filter_factory': value =>'keystone.middleware:JsonBodyMiddleware.factory'; 'filter:user_crud_extension/paste.filter_factory': value =>'keystone.contrib.user_crud:CrudExtension.factory'; 'filter:crud_extension/paste.filter_factory': value =>'keystone.contrib.admin_crud:CrudExtension.factory'; 'filter:ec2_extension/paste.filter_factory': value =>'keystone.contrib.ec2:Ec2Extension.factory'; 'filter:s3_extension/paste.filter_factory': value =>'keystone.contrib.s3:S3Extension.factory'; 'filter:url_normalize/paste.filter_factory': value =>'keystone.middleware:NormalizingFilter.factory'; 'filter:stats_monitoring/paste.filter_factory': value =>'keystone.contrib.stats:StatsMiddleware.factory'; 'filter:stats_reporting/paste.filter_factory': value =>'keystone.contrib.stats:StatsExtension.factory'; 'app:public_service/paste.app_factory': value =>'keystone.service:public_app_factory'; 'app:admin_service/paste.app_factory': value =>'keystone.service:admin_app_factory'; 'pipeline:public_api/pipeline': value =>'stats_monitoring url_normalize token_auth admin_token_auth xml_body json_body debug ec2_extension user_crud_extension public_service'; 'pipeline:admin_api/pipeline': value =>'stats_monitoring url_normalize token_auth admin_token_auth xml_body json_body debug stats_reporting ec2_extension s3_extension crud_extension admin_service'; 'app:public_version_service/paste.app_factory': value =>'keystone.service:public_version_app_factory'; 'app:admin_version_service/paste.app_factory': value =>'keystone.service:admin_version_app_factory'; 'pipeline:public_version_api/pipeline': value =>'stats_monitoring url_normalize xml_body public_version_service'; 'pipeline:admin_version_api/pipeline': value =>'stats_monitoring url_normalize xml_body admin_version_service'; 'composite:main/use': value =>'egg:Paste#urlmap'; 'composite:main//v2.0': value =>'public_api'; 'composite:main//': value =>'public_version_api'; 'composite:admin/use': value =>'egg:Paste#urlmap'; 'composite:admin//v2.0': value =>'admin_api'; 'composite:admin//': value =>'admin_version_api'; } ,0,31
openstack%2Fproject-config~master~I2c3c0f4c3993b3f1b88663ce29d8b01bfb1e173c,openstack/project-config,master,I2c3c0f4c3993b3f1b88663ce29d8b01bfb1e173c,Add log copier to dib jobs,MERGED,2017-06-16 02:29:12.000000000,2017-06-19 07:45:06.000000000,2017-06-19 07:45:06.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-16 02:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/47dc79d5f8f9d1d37baa69dfb2f4843514f4de54', 'message': 'Add log copier to dib jobs\n\nAdd log copier to dib jobs so we can add some other artifacts for\ncopying.\n\nChange-Id: I2c3c0f4c3993b3f1b88663ce29d8b01bfb1e173c\n'}, {'number': 2, 'created': '2017-06-16 02:42:59.000000000', 'files': ['jenkins/jobs/diskimage-builder.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/840dea4f114134a615cb1e12f271a858e671b335', 'message': 'Add log copier to dib jobs\n\nAdd log copier to dib jobs so we can add some other artifacts for\ncopying.\n\nChange-Id: I2c3c0f4c3993b3f1b88663ce29d8b01bfb1e173c\n'}]",0,474828,840dea4f114134a615cb1e12f271a858e671b335,9,3,2,7118,,,0,"Add log copier to dib jobs

Add log copier to dib jobs so we can add some other artifacts for
copying.

Change-Id: I2c3c0f4c3993b3f1b88663ce29d8b01bfb1e173c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/28/474828/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/diskimage-builder.yaml'],1,47dc79d5f8f9d1d37baa69dfb2f4843514f4de54,dib-logs, - devstack-logs,,1,0
openstack%2Fproject-config~master~I46ff170d49adf400a25d252ff0df31ee46fda129,openstack/project-config,master,I46ff170d49adf400a25d252ff0df31ee46fda129,Add neutron-dynamic-routing job with ryu master,MERGED,2017-05-02 01:27:56.000000000,2017-06-19 07:44:38.000000000,2017-06-19 07:44:38.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 8344}, {'_account_id': 9656}]","[{'number': 1, 'created': '2017-05-02 01:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/65b406e5f00e3e2323118b07ce0e087733298845', 'message': 'Add neutron-dynamic-routing job with ryu master\n\nryu is often released(basically every month). And the new release\nmay affect the behavior of dragent and scenario tests.\nThis adds job to check neutron-dynamic-routing with the ryu master\nto avoid a trouble with the new ryu release.\n\nChange-Id: I46ff170d49adf400a25d252ff0df31ee46fda129\n'}, {'number': 2, 'created': '2017-05-30 04:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/16fc7dbf03cb027482093a9c819b96a969b033b2', 'message': 'Add neutron-dynamic-routing job with ryu master\n\nryu is often released(basically every month). And the new release\nmay affect the behavior of dragent and scenario tests.\nThis adds job to check neutron-dynamic-routing with the ryu master\nto avoid a trouble with the new ryu release.\n\nChange-Id: I46ff170d49adf400a25d252ff0df31ee46fda129\n'}, {'number': 3, 'created': '2017-05-31 05:45:04.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/neutron-dynamic-routing.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/28dfe9b98b3d3e1ef96facd0ed7e585ec1cecc5d', 'message': 'Add neutron-dynamic-routing job with ryu master\n\nryu is often released(basically every month). And the new release\nmay affect the behavior of dragent and scenario tests.\nThis adds job to check neutron-dynamic-routing with the ryu master\nto avoid a trouble with the new ryu release.\n\nChange-Id: I46ff170d49adf400a25d252ff0df31ee46fda129\n'}]",2,461584,28dfe9b98b3d3e1ef96facd0ed7e585ec1cecc5d,14,6,3,8344,,,0,"Add neutron-dynamic-routing job with ryu master

ryu is often released(basically every month). And the new release
may affect the behavior of dragent and scenario tests.
This adds job to check neutron-dynamic-routing with the ryu master
to avoid a trouble with the new ryu release.

Change-Id: I46ff170d49adf400a25d252ff0df31ee46fda129
",git fetch https://review.opendev.org/openstack/project-config refs/changes/84/461584/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'jenkins/jobs/neutron-dynamic-routing.yaml', 'zuul/layout.yaml']",3,65b406e5f00e3e2323118b07ce0e087733298845,dr-with-ryu-master, experimental: - gate-neutron-dynamic-routing-dsvm-tempest-with-ryu-master-scenario-ipv4-nv,,60,0
openstack%2Frst2bash~master~I36bba19ac1be5c865d8ab6521b84e3b3011af8c7,openstack/rst2bash,master,I36bba19ac1be5c865d8ab6521b84e3b3011af8c7,"Minor changes, non-functional refactoring.",MERGED,2017-04-11 18:17:11.000000000,2017-06-19 07:40:09.000000000,2017-06-19 07:38:34.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2017-04-11 18:17:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/fa291b935376ed5df4f19472c0b9f93ddf471f94', 'message': 'Minor changes, non-functional refactoring.\n\nChange-Id: I36bba19ac1be5c865d8ab6521b84e3b3011af8c7\n'}, {'number': 2, 'created': '2017-04-25 02:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/db6ccf9da26a19b958ecd44a195b19225e7868ca', 'message': 'Minor changes, non-functional refactoring.\n\nChange-Id: I36bba19ac1be5c865d8ab6521b84e3b3011af8c7\n'}, {'number': 3, 'created': '2017-04-25 02:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/9c6dcb9a808fa635e137c1626b8a5110ba99f037', 'message': 'Minor changes, non-functional refactoring.\n\nChange-Id: I36bba19ac1be5c865d8ab6521b84e3b3011af8c7\n'}, {'number': 4, 'created': '2017-06-19 07:34:52.000000000', 'files': ['rst2bash/parser.py'], 'web_link': 'https://opendev.org/openstack/rst2bash/commit/c9bef5e7b007e570d635e6f48ab8b0fc6f331f3a', 'message': 'Minor changes, non-functional refactoring.\n\nChange-Id: I36bba19ac1be5c865d8ab6521b84e3b3011af8c7\n'}]",0,455800,c9bef5e7b007e570d635e6f48ab8b0fc6f331f3a,23,3,4,7007,,,0,"Minor changes, non-functional refactoring.

Change-Id: I36bba19ac1be5c865d8ab6521b84e3b3011af8c7
",git fetch https://review.opendev.org/openstack/rst2bash refs/changes/00/455800/1 && git format-patch -1 --stdout FETCH_HEAD,['rst2bash/parser.py'],1,fa291b935376ed5df4f19472c0b9f93ddf471f94,minor_fixes,# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------# ------------------------------------------------------------------------------ # ------------------------------------------------------------------------------# ------------------------------------------------------------------------------,# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# -----------------------------------------------------------------------------# ----------------------------------------------------------------------------- return # -----------------------------------------------------------------------------# -----------------------------------------------------------------------------,11,13
openstack%2Fproject-config~master~Ief29695e69e68d2accedf792fb97db745623bf53,openstack/project-config,master,Ief29695e69e68d2accedf792fb97db745623bf53,Create tap-as-a-service-dashboard project,MERGED,2017-05-29 01:38:16.000000000,2017-06-19 07:39:30.000000000,2017-06-19 07:39:30.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-05-29 01:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/48a5970af84ebe0088fe20bc987304516953333e', 'message': 'Create tap-as-a-service-dashboard project\n\nChange-Id: Ief29695e69e68d2accedf792fb97db745623bf53\n'}, {'number': 2, 'created': '2017-06-16 05:19:03.000000000', 'files': ['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/37febd3693376d10a3c8df12311f956b09418c0a', 'message': 'Create tap-as-a-service-dashboard project\n\nChange-Id: Ief29695e69e68d2accedf792fb97db745623bf53\n'}]",0,468747,37febd3693376d10a3c8df12311f956b09418c0a,11,3,2,19350,,,0,"Create tap-as-a-service-dashboard project

Change-Id: Ief29695e69e68d2accedf792fb97db745623bf53
",git fetch https://review.opendev.org/openstack/project-config refs/changes/47/468747/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",3,48a5970af84ebe0088fe20bc987304516953333e,new-project, - name: openstack/tap-as-a-service-dashboard template: - name: merge-check - name: check-requirements - name: python-jobs - name: python35-jobs ,,16,0
openstack%2Fproject-config~master~I3bd814d16625910c94fb41f1414c39d4ca938c22,openstack/project-config,master,I3bd814d16625910c94fb41f1414c39d4ca938c22,Create the requirements stable maintence team,MERGED,2017-06-02 19:49:12.000000000,2017-06-19 07:39:23.000000000,2017-06-19 07:39:22.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-06-02 19:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/596398ece9bc77ae3eec622f65807383f05f5264', 'message': ""Create the requirements stable maintence team\n\nWe've been relying on the stable-maintenance team for a while and while we\nhad tonyb to help that's worked out, with his absence we've started\nfalling behind on reviews of the stable branches, even with the\nstable-maint team's help.  So we wish to take it on ourselves.  In order\nto do so we'd need a new gerrit group to be created, at the moment it'd\nbe dirk, dims and I on that team.\n\nChange-Id: I3bd814d16625910c94fb41f1414c39d4ca938c22\n""}, {'number': 2, 'created': '2017-06-02 19:58:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/dba5242a8c30c761f41d58e43612912e5817e79c', 'message': ""Create the requirements stable maintence team\n\nWe've been relying on the stable-maintenance team for a while and while we\nhad tonyb to help that's worked out, with his absence we've started\nfalling behind on reviews of the stable branches, even with the\nstable-maint team's help.  So we wish to take it on ourselves.  In order\nto do so we'd need a new gerrit group to be created, at the moment it'd\nbe dirk, dims and I on that team.\n\nChange-Id: I3bd814d16625910c94fb41f1414c39d4ca938c22\n""}, {'number': 3, 'created': '2017-06-02 20:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/50de51fd63dce741dac4eb07ea1390ac336acc05', 'message': ""Create the requirements stable maintence team\n\nWe've been relying on the stable-maintenance team for a while and while we\nhad tonyb to help that's worked out, with his absence we've started\nfalling behind on reviews of the stable branches, even with the\nstable-maint team's help.  So we wish to take it on ourselves.  In order\nto do so we'd need a new gerrit group to be created, at the moment it'd\nbe dirk, dims and I on that team.\n\nChange-Id: I3bd814d16625910c94fb41f1414c39d4ca938c22\n""}, {'number': 4, 'created': '2017-06-07 18:38:25.000000000', 'files': ['gerrit/acls/openstack/requirements.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/77abde08cea73ad95edfc0b5c88c19a0e5812692', 'message': ""Create the requirements stable maintence team\n\nWe've been relying on the stable-maintenance team for a while and while we\nhad tonyb to help that's worked out, with his absence we've started\nfalling behind on reviews of the stable branches, even with the\nstable-maint team's help.  So we wish to take it on ourselves.  In order\nto do so we'd need a new gerrit group to be created, at the moment it'd\nbe dirk, dims and I on that team.\n\nChange-Id: I3bd814d16625910c94fb41f1414c39d4ca938c22\n""}]",6,470419,77abde08cea73ad95edfc0b5c88c19a0e5812692,21,7,4,14288,,,0,"Create the requirements stable maintence team

We've been relying on the stable-maintenance team for a while and while we
had tonyb to help that's worked out, with his absence we've started
falling behind on reviews of the stable branches, even with the
stable-maint team's help.  So we wish to take it on ourselves.  In order
to do so we'd need a new gerrit group to be created, at the moment it'd
be dirk, dims and I on that team.

Change-Id: I3bd814d16625910c94fb41f1414c39d4ca938c22
",git fetch https://review.opendev.org/openstack/project-config refs/changes/19/470419/4 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/requirements.config'],1,596398ece9bc77ae3eec622f65807383f05f5264,create-requirements-stable-maint,abandon = group requirements-stable-maintlabel-Code-Review = -2..+2 group requirements-stable-maintlabel-Workflow = -1..+1 group requirements-stable-maint,abandon = group stable-maint-corelabel-Code-Review = -2..+2 group infra-core label-Code-Review = -2..+2 group stable-maint-corelabel-Workflow = -1..+1 group infra-core label-Workflow = -1..+1 group stable-maint-core,3,5
openstack%2Fvitrage~master~Ibc370a49d1d56ebcad834b2d449b4c607b8374e7,openstack/vitrage,master,Ibc370a49d1d56ebcad834b2d449b4c607b8374e7,"Delete the external-actions.rst file, it belongs in the vitrage-specs project",MERGED,2017-06-18 15:29:09.000000000,2017-06-19 07:37:13.000000000,2017-06-19 07:37:13.000000000,"[{'_account_id': 3}, {'_account_id': 19122}, {'_account_id': 19134}]","[{'number': 1, 'created': '2017-06-18 15:29:09.000000000', 'files': ['doc/source/external-actions.rst'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/0894e673e770e6fabab15fcae2d0eb3a9d1bd3e4', 'message': 'Delete the external-actions.rst file, it belongs in the vitrage-specs project\n\nChange-Id: Ibc370a49d1d56ebcad834b2d449b4c607b8374e7\n'}]",0,475180,0894e673e770e6fabab15fcae2d0eb3a9d1bd3e4,7,3,1,19159,,,0,"Delete the external-actions.rst file, it belongs in the vitrage-specs project

Change-Id: Ibc370a49d1d56ebcad834b2d449b4c607b8374e7
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/80/475180/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/external-actions.rst'],1,0894e673e770e6fabab15fcae2d0eb3a9d1bd3e4,remove-external-actions2,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Support External Actions in Vitrage Templates ============================================= launchpad blueprint: https://blueprints.launchpad.net/vitrage/+spec/support-external-actions Currently, the Vitrage templates support the following actions: raise alarm, set state, mark causal relationship and mark-down. The implementation of mark-down is patchy (update a property on the vertex and call the notifier). We need a way to define in the template an external action that should be taken. One example is the mark-down. Another example is to execute a Mistral workflow or a Congress policy. Problem description =================== The following use cases should be supported: 1. **mark-down**. This is an existing use case. If a mark-down action exists, Vitrage will call Nova mark-down API. The behavior should remain the same after the change. 2. **Execute a Mistral workflow**. The user should be able to execute a Mistral workflow based on Vitrage insights. 3. **Execute other external actions**, like a Congress policy. Proposed change =============== Add a new action for each external engine we would like to support. The action will have metadata with parameters to be sent to the engine. Examples -------- .. code-block:: yaml action: action_type: execute_nova metadata: api_call: mark-down host: host1 .. code-block:: yaml action: action_type: execute_mistral metadata: workflow: evacuate_host failed_host: host1 The idea behind adding a new external_* action for each engine is to emphasize that Vitrage supports a predefined set of external actions, and specifically it does not support runinng scripts. The internal implementation will be identical for Nova, Mistral, Congress, etc. During the template loading phase, the execute_* action will be converted to a generic Execute action, with a notifier parameter. The template validator will verify that the wanted notifier is enabled in vitrage.conf, otherwise the template loading will fail. When executing the Execute action, the evaluator will send an event to the message bus of the wanted notifier. This way, only the Mistral notifier will handle the execute_mistral actions. Note that currently only the Vitrage graph sends notification to the notifier. This behavior will be changed, so notifications will be sent both from the graph (for deduced alarms and set state) and from the evaluator. Alternatives ------------ There are two alternatives: Send Message bus notifications ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Vitrage can have a message bus notifier, that will send notifications about raise/delete alarm, set state and mark causal-relationship. Mistral will be configured to execute certain workflows based on the notifications received from Vitrage. Advantages: * No extra configuration needed in Vitrage * Can work with the current notifiers mechanism Disadvantages: * Messgae bus notifications might get lost * Less powerful. In Vitrage template the user can decide to execute a workflow based on a combination of alarms or a specific topology. Once Mistral gets the notifications, the topology context is no longer there. * mark-down use case is not supported by this solution Configuration Done on the specific notifier ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ A Mistral notifier will be written and receive notifications from the graph. It will be configured by a yaml file that will determine which workflow to execute per specific alarm. Advantages: * No extra configuration needed in Vitrage * Can work with the current notifiers mechanism * No lost messages Disadvantages: * Less powerful. In Vitrage template the user can decide to execute a workflow based on a combination of alarms or a specific topology. In Mistral notifier we no longer have this context. * mark-down use case is not supported by this solution Data model impact ----------------- A new Execute action will be added to the evaluator. REST API impact --------------- None Versioning impact ----------------- We should introduce a versioning mechanism to the templates. This will be done when modifying the implementation of mark-down. Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- None Horizon impact -------------- None Implementation ============== Assignee(s) ----------- Primary assignee: ifat-afek Work Items ---------- * Enhance the template language (template loading and validation) * Update the documentation * Execute the external actions from the evaluator Dependencies ============ None Testing ======= The implementation will be covered by unit tests and tempest tests. Documentation Impact ==================== The new action should be documented References ========== None ",0,197
openstack%2Fproject-config~master~I5881c6f6ed37e6810c680db60fee648effc558ff,openstack/project-config,master,I5881c6f6ed37e6810c680db60fee648effc558ff,Gerritbot: track current branches for sahara repositories,MERGED,2017-06-07 17:15:24.000000000,2017-06-19 07:37:07.000000000,2017-06-19 07:37:07.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8932}, {'_account_id': 23078}]","[{'number': 1, 'created': '2017-06-07 17:15:24.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/58255f8f5b50ccdca837f46126aa41d548639ac4', 'message': 'Gerritbot: track current branches for sahara repositories\n\n... and the future-but-not-far-away stable/pike branch.\nThe order of the stable branches defined for other channels is\nnot consistent, but it probably does not matter.\nChange-Id: I5881c6f6ed37e6810c680db60fee648effc558ff\n'}]",0,471860,58255f8f5b50ccdca837f46126aa41d548639ac4,9,5,1,10459,,,0,"Gerritbot: track current branches for sahara repositories

... and the future-but-not-far-away stable/pike branch.
The order of the stable branches defined for other channels is
not consistent, but it probably does not matter.
Change-Id: I5881c6f6ed37e6810c680db60fee648effc558ff
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/471860/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,58255f8f5b50ccdca837f46126aa41d548639ac4,gerritbot-sahara-currentbranches, - stable/newton - stable/ocata - stable/pike,,3,0
openstack%2Fproject-config~master~Ibfe815f98b851e53c61716067e29275bd97fa46f,openstack/project-config,master,Ibfe815f98b851e53c61716067e29275bd97fa46f,Add coverage job to tempest check,MERGED,2017-06-05 06:41:59.000000000,2017-06-19 07:37:00.000000000,2017-06-19 07:37:00.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-05 06:41:59.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/46380a32e2c68b04856b84bea3c758ebd5f8637f', 'message': 'Add coverage job to tempest check\n\nThis commit adds a coverage job to the tempest check queue. We are\nproviding tempest.lib stable interface now, so, we should care about its\nunit tests and coverage.\n\nChange-Id: Ibfe815f98b851e53c61716067e29275bd97fa46f\n'}]",0,470856,46380a32e2c68b04856b84bea3c758ebd5f8637f,8,4,1,5689,,,0,"Add coverage job to tempest check

This commit adds a coverage job to the tempest check queue. We are
providing tempest.lib stable interface now, so, we should care about its
unit tests and coverage.

Change-Id: Ibfe815f98b851e53c61716067e29275bd97fa46f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/470856/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,46380a32e2c68b04856b84bea3c758ebd5f8637f,add-coverage-job-in-check, - tempest-coverage-ubuntu-xenial-nv,,1,0
openstack%2Fproject-config~master~I996279edc3b73d0482b4600c3deaa52e63753a2d,openstack/project-config,master,I996279edc3b73d0482b4600c3deaa52e63753a2d,New project - OpenStack-Spaceport,MERGED,2017-06-09 20:03:36.000000000,2017-06-19 07:36:54.000000000,2017-06-19 07:36:54.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7822}, {'_account_id': 9237}, {'_account_id': 10787}, {'_account_id': 17591}, {'_account_id': 17966}, {'_account_id': 19384}, {'_account_id': 20466}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-06-09 20:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a79c8d557105a9da654182df195a801aed91e743', 'message': 'New project - OpenStack-Spaceport\n\nOpenStack-Spaceport is a project that aims to help deployment tools\nespecially, but not limited to, those focused upon containerised\nenvironments. Building upon lessons learned in the development of\nboth Kolla-Kubernetes and OpenStack-Helm, OpenStack-Spaceport should\nprovide a common point of collaboration for across projects, providing\na suite of environment and dependency checks, that can be run prior to\nlaunching an OpenStack or related service.\n\nChange-Id: I996279edc3b73d0482b4600c3deaa52e63753a2d\n'}, {'number': 2, 'created': '2017-06-09 20:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e35446a4bb979202ac95b41b6dcc409450706c7d', 'message': 'New project - OpenStack-Spaceport\n\nOpenStack-Spaceport is a project that aims to help deployment tools\nespecially, but not limited to, those focused upon containerised\nenvironments. Building upon lessons learned in the development of\nboth Kolla-Kubernetes and OpenStack-Helm, OpenStack-Spaceport should\nprovide a common point of collaboration for across projects, providing\na suite of environment and dependency checks, that can be run prior to\nlaunching an OpenStack or related service.\n\nChange-Id: I996279edc3b73d0482b4600c3deaa52e63753a2d\n'}, {'number': 3, 'created': '2017-06-09 21:12:57.000000000', 'files': ['gerritbot/channels.yaml', 'accessbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/openstack-spaceport.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/49e127cfda05e51ea52f8e77747d3acf039016c2', 'message': 'New project - OpenStack-Spaceport\n\nOpenStack-Spaceport is a project that aims to help deployment tools\nespecially, but not limited to, those focused upon containerised\nenvironments. Building upon lessons learned in the development of\nboth Kolla-Kubernetes and OpenStack-Helm, OpenStack-Spaceport should\nprovide a common point of collaboration for across projects, providing\na suite of environment and dependency checks, that can be run prior to\nlaunching an OpenStack or related service.\n\nChange-Id: I996279edc3b73d0482b4600c3deaa52e63753a2d\n'}]",2,472791,49e127cfda05e51ea52f8e77747d3acf039016c2,26,12,3,23928,,,0,"New project - OpenStack-Spaceport

OpenStack-Spaceport is a project that aims to help deployment tools
especially, but not limited to, those focused upon containerised
environments. Building upon lessons learned in the development of
both Kolla-Kubernetes and OpenStack-Helm, OpenStack-Spaceport should
provide a common point of collaboration for across projects, providing
a suite of environment and dependency checks, that can be run prior to
launching an OpenStack or related service.

Change-Id: I996279edc3b73d0482b4600c3deaa52e63753a2d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/91/472791/2 && git format-patch -1 --stdout FETCH_HEAD,"['accessbot/channels.yaml', 'gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/openstack-spaceport.config']",5,a79c8d557105a9da654182df195a801aed91e743,openstack-entrypoint,"[access ""refs/heads/*""] abandon = group openstack-spaceport-core create = group openstack-spaceport-release label-Code-Review = -2..+2 group openstack-spaceport-core label-Workflow = -1..+1 group openstack-spaceport-core [access ""refs/tags/*""] pushSignedTag = group openstack-spaceport-release [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = true ",,36,0
openstack%2Fproject-config~master~I2798a3c2e4f3a7a749669c7fdd46829de434eb41,openstack/project-config,master,I2798a3c2e4f3a7a749669c7fdd46829de434eb41,Add OSH-AddOns to IRC channel notification,MERGED,2017-06-06 05:21:59.000000000,2017-06-19 07:36:40.000000000,2017-06-19 07:36:40.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 13252}, {'_account_id': 17591}, {'_account_id': 20443}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-06-06 05:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8c3001fe02b6cbe9fd1aec5911550a5cb77f0e37', 'message': 'Add OSH-AddOns to IRC channel notification\n\nChange-Id: I2798a3c2e4f3a7a749669c7fdd46829de434eb41\n'}, {'number': 2, 'created': '2017-06-10 04:58:23.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2cb044521e87bac5347e7fe48438fb546f4ae59b', 'message': 'Add OSH-AddOns to IRC channel notification\n\nChange-Id: I2798a3c2e4f3a7a749669c7fdd46829de434eb41\n'}]",0,471207,2cb044521e87bac5347e7fe48438fb546f4ae59b,12,7,2,20466,,,0,"Add OSH-AddOns to IRC channel notification

Change-Id: I2798a3c2e4f3a7a749669c7fdd46829de434eb41
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/471207/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,8c3001fe02b6cbe9fd1aec5911550a5cb77f0e37,new-project, - openstack/openstack-helm-addons,,1,0
openstack%2Fproject-config~master~I138a9be62946d1dce001a1c34cf9d6e515fd9411,openstack/project-config,master,I138a9be62946d1dce001a1c34cf9d6e515fd9411,[Zun] Turn dsvm job to voting,MERGED,2017-06-07 16:02:10.000000000,2017-06-19 07:36:33.000000000,2017-06-19 07:36:33.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-06-07 16:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/88f7281e4c77ec9f2daf3015beecaafece33d748', 'message': '[Zun] Turn dsvm job to voting\n\nThis job caught issues from time to time but occationally ignored\nby reviewers, so it is better to make it voting.\n\nChange-Id: I138a9be62946d1dce001a1c34cf9d6e515fd9411\n'}, {'number': 2, 'created': '2017-06-18 15:22:23.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9804da94c8fb6772005d056101a9fbe98cf1ae39', 'message': '[Zun] Turn dsvm job to voting\n\nThis job caught issues from time to time but occationally ignored\nby reviewers, so it is better to make it voting.\n\nChange-Id: I138a9be62946d1dce001a1c34cf9d6e515fd9411\n'}]",0,471842,9804da94c8fb6772005d056101a9fbe98cf1ae39,12,4,2,11536,,,0,"[Zun] Turn dsvm job to voting

This job caught issues from time to time but occationally ignored
by reviewers, so it is better to make it voting.

Change-Id: I138a9be62946d1dce001a1c34cf9d6e515fd9411
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/471842/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,88f7281e4c77ec9f2daf3015beecaafece33d748,, - gate-zunclient-devstack-dsvm-docker-sql, - gate-zunclient-devstack-dsvm-docker-sql-nv,2,2
openstack%2Fproject-config~master~Iafeb4567aa0a7d2d5f818d45995c50ffdc0ef028,openstack/project-config,master,Iafeb4567aa0a7d2d5f818d45995c50ffdc0ef028,Place subunit result file in the correct place,MERGED,2017-06-14 18:33:12.000000000,2017-06-19 07:36:25.000000000,2017-06-19 07:36:25.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-14 18:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/811ebe810915f24088302c85da9e346c4be50138', 'message': 'Place subunit result file in the correct place\n\nChange-Id: Iafeb4567aa0a7d2d5f818d45995c50ffdc0ef028\n'}, {'number': 2, 'created': '2017-06-14 21:29:00.000000000', 'files': ['jenkins/jobs/openstack-ansible-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/becef7c76e5a4049d5541ed1f68648bea28bd17e', 'message': 'Place subunit result file in the correct place\n\nPlace the subunit result file for openstack-ansible jobs,\nso that project job statistics can be seen at OpenStack-Health\ndashboard\n\nChange-Id: Iafeb4567aa0a7d2d5f818d45995c50ffdc0ef028\n'}]",0,474312,becef7c76e5a4049d5541ed1f68648bea28bd17e,10,4,2,17716,,,0,"Place subunit result file in the correct place

Place the subunit result file for openstack-ansible jobs,
so that project job statistics can be seen at OpenStack-Health
dashboard

Change-Id: Iafeb4567aa0a7d2d5f818d45995c50ffdc0ef028
",git fetch https://review.opendev.org/openstack/project-config refs/changes/12/474312/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/openstack-ansible-jobs.yaml'],1,811ebe810915f24088302c85da9e346c4be50138,osa_collect_results, - test-results,,1,0
openstack%2Fproject-config~master~Ibd642084be27bfce55e9939a09835c034e41a1bf,openstack/project-config,master,Ibd642084be27bfce55e9939a09835c034e41a1bf,Cleanup lvm-multibackend job usage for nova/cinder,MERGED,2017-06-15 21:34:28.000000000,2017-06-19 07:33:39.000000000,2017-06-19 07:33:39.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 11904}]","[{'number': 1, 'created': '2017-06-15 21:34:28.000000000', 'files': ['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/92370b0475c89e5a90489087af5aceeb643b5713', 'message': ""Cleanup lvm-multibackend job usage for nova/cinder\n\nThere are two lvm-multibackend jobs really:\n\n1. The multinode one runs slow scenario tests which will\n   test volume retype with a volume attached to a server for\n   swap volume operations.\n\n2. The single node one runs only volume API mulitbackend\n   tests, so retype but without the volume attached to an instance.\n\nThis change adds a comment explaining what the multinode lvm\nmultibackend job does and adds it to Cinder's experimental queue.\n\nIt also removes the single-node job from Nova's experimental queue\nsince Nova was running both jobs in the experimental queue but Nova\nis only going to care about the slow scenario test where an instance\nis involved with the volume retype scenario.\n\nChange-Id: Ibd642084be27bfce55e9939a09835c034e41a1bf\n""}]",0,474786,92370b0475c89e5a90489087af5aceeb643b5713,8,4,1,6873,,,0,"Cleanup lvm-multibackend job usage for nova/cinder

There are two lvm-multibackend jobs really:

1. The multinode one runs slow scenario tests which will
   test volume retype with a volume attached to a server for
   swap volume operations.

2. The single node one runs only volume API mulitbackend
   tests, so retype but without the volume attached to an instance.

This change adds a comment explaining what the multinode lvm
multibackend job does and adds it to Cinder's experimental queue.

It also removes the single-node job from Nova's experimental queue
since Nova was running both jobs in the experimental queue but Nova
is only going to care about the slow scenario test where an instance
is involved with the volume retype scenario.

Change-Id: Ibd642084be27bfce55e9939a09835c034e41a1bf
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/474786/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,92370b0475c89e5a90489087af5aceeb643b5713,consolidate-lvm-multibackend-jobs," # This job runs cinder multi-backend (for things like volume retype/migration) # and it runs tempest slow and scenario tests, and compute live migration # tests. Of particular interest is the TestVolumeMigrateRetypeAttached scenario # test which performs a volume retype of a volume attached to a server instance # as it's root disk.",,7,1
openstack%2Frequirements~stable%2Fnewton~I92d219480dd90532f31dc8ac01b80696067a48cd,openstack/requirements,stable/newton,I92d219480dd90532f31dc8ac01b80696067a48cd,update constraint for oslo.rootwrap to new release 5.1.2,MERGED,2017-05-22 17:09:06.000000000,2017-06-19 07:26:25.000000000,2017-06-19 07:26:25.000000000,"[{'_account_id': 3}, {'_account_id': 9656}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-05-22 17:09:06.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5e5553e6823ffe3043d739073b41e7377dff2874', 'message': 'update constraint for oslo.rootwrap to new release 5.1.2\n\nChange-Id: I92d219480dd90532f31dc8ac01b80696067a48cd\nmeta:version: 5.1.2\nmeta:diff-start: -\nmeta:series: newton\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Ihar Hrachyshka <ihrachys@redhat.com>\nmeta:release:Commit: Ihar Hrachyshka <ihrachys@redhat.com>\nmeta:release:Change-Id: Id805932071eb7a7c65d01c1db63e793b663b4389\nmeta:release:Code-Review+2: Alan Pevec <alan.pevec@redhat.com>\nmeta:release:Code-Review+1: ChangBo Guo(gcb) <glongwave@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,466818,5e5553e6823ffe3043d739073b41e7377dff2874,15,3,1,11131,,,0,"update constraint for oslo.rootwrap to new release 5.1.2

Change-Id: I92d219480dd90532f31dc8ac01b80696067a48cd
meta:version: 5.1.2
meta:diff-start: -
meta:series: newton
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Ihar Hrachyshka <ihrachys@redhat.com>
meta:release:Commit: Ihar Hrachyshka <ihrachys@redhat.com>
meta:release:Change-Id: Id805932071eb7a7c65d01c1db63e793b663b4389
meta:release:Code-Review+2: Alan Pevec <alan.pevec@redhat.com>
meta:release:Code-Review+1: ChangBo Guo(gcb) <glongwave@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/18/466818/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5e5553e6823ffe3043d739073b41e7377dff2874,new-release,oslo.rootwrap===5.1.2,oslo.rootwrap===5.1.1,1,1
openstack%2Fproject-config~master~I49b66d6151efab2f1ecea35b0dc72ae02c9c02f8,openstack/project-config,master,I49b66d6151efab2f1ecea35b0dc72ae02c9c02f8,neutron: Pass python version to gate hook,MERGED,2017-06-15 13:59:20.000000000,2017-06-19 07:22:51.000000000,2017-06-19 07:22:51.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 21798}]","[{'number': 1, 'created': '2017-06-15 13:59:20.000000000', 'files': ['jenkins/jobs/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0ce278420b167f58aa234c62e32279325186055a', 'message': ""neutron: Pass python version to gate hook\n\nGate hook sets up configuration for rootwrap which depends on VENV. In\ncase of python3 job flavor, rootwrap is configured to wrong venv and\nrootwrap doesn't work in tests.\n\nChange-Id: I49b66d6151efab2f1ecea35b0dc72ae02c9c02f8\nDepends-On: I7fea6e9aa09550e00edf6ce2d7301312307df5fd\n""}]",0,474585,0ce278420b167f58aa234c62e32279325186055a,10,6,1,8655,,,0,"neutron: Pass python version to gate hook

Gate hook sets up configuration for rootwrap which depends on VENV. In
case of python3 job flavor, rootwrap is configured to wrong venv and
rootwrap doesn't work in tests.

Change-Id: I49b66d6151efab2f1ecea35b0dc72ae02c9c02f8
Depends-On: I7fea6e9aa09550e00edf6ce2d7301312307df5fd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/474585/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/neutron.yaml'],1,0ce278420b167f58aa234c62e32279325186055a,func-py3, bash -xe $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh dsvm-functional{python}, bash -xe $BASE/new/neutron/neutron/tests/contrib/gate_hook.sh dsvm-functional,1,1
openstack%2Fproject-config~master~Ie2752ec1217992e2150f6bdc8131391e2061b331,openstack/project-config,master,Ie2752ec1217992e2150f6bdc8131391e2061b331,Add py35 job to instack-undercloud,MERGED,2017-06-16 16:44:16.000000000,2017-06-19 07:21:46.000000000,2017-06-19 07:21:46.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-16 16:44:16.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/044c05d89f83b73e68786d695927f921a9565c2b', 'message': 'Add py35 job to instack-undercloud\n\nThis project has been passing the py35 unit tests for a while now,\nbut we never added a gate job to ensure it stays that way.\n\nChange-Id: Ie2752ec1217992e2150f6bdc8131391e2061b331\n'}]",0,475026,044c05d89f83b73e68786d695927f921a9565c2b,7,3,1,6928,,,0,"Add py35 job to instack-undercloud

This project has been passing the py35 unit tests for a while now,
but we never added a gate job to ensure it stays that way.

Change-Id: Ie2752ec1217992e2150f6bdc8131391e2061b331
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/475026/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,044c05d89f83b73e68786d695927f921a9565c2b,i-u-py35, - name: python35-jobs,,1,0
openstack%2Fproject-config~master~I7a910b6beec33ad380069b46a70b6c9168a1c113,openstack/project-config,master,I7a910b6beec33ad380069b46a70b6c9168a1c113,Add experimental py35 job to barbican-tempest-plugin,MERGED,2017-06-15 13:09:03.000000000,2017-06-19 07:21:39.000000000,2017-06-19 07:21:39.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-15 13:09:03.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/10255d3a3cd64b7c9dcd8b2fc6b948b26462abea', 'message': ""Add experimental py35 job to barbican-tempest-plugin\n\nThe job already exists in projects.yaml (see [1]), but it\nwasn't added to layout.yaml. This fixes the issue.\n\n1. https://github.com/openstack-infra/project-config/blob/master/jenkins/jobs/projects.yaml#L476-L482\n\nChange-Id: I7a910b6beec33ad380069b46a70b6c9168a1c113\n""}]",0,474572,10255d3a3cd64b7c9dcd8b2fc6b948b26462abea,7,3,1,8623,,,0,"Add experimental py35 job to barbican-tempest-plugin

The job already exists in projects.yaml (see [1]), but it
wasn't added to layout.yaml. This fixes the issue.

1. https://github.com/openstack-infra/project-config/blob/master/jenkins/jobs/projects.yaml#L476-L482

Change-Id: I7a910b6beec33ad380069b46a70b6c9168a1c113
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/474572/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,10255d3a3cd64b7c9dcd8b2fc6b948b26462abea,barbican-tempest-plugin-py35, experimental: - gate-barbican-simple-crypto-dsvm-tempest-py35-ubuntu-xenial-nv,,2,0
openstack%2Fproject-config~master~I3c88f13a1ed8cfed05e52aca3cfaba65522810af,openstack/project-config,master,I3c88f13a1ed8cfed05e52aca3cfaba65522810af,Switch Fedora job to voting,MERGED,2017-06-14 17:41:53.000000000,2017-06-19 07:21:32.000000000,2017-06-19 07:21:32.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 13252}]","[{'number': 1, 'created': '2017-06-14 17:41:53.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1d9d10486684d58d772b2006017f82d14bc9444b', 'message': 'Switch Fedora job to voting\n\nThis patch changes the Fedora CI job to voting status for the\nansible-hardening project.\n\nChange-Id: I3c88f13a1ed8cfed05e52aca3cfaba65522810af\n'}]",0,474301,1d9d10486684d58d772b2006017f82d14bc9444b,8,4,1,538,,,0,"Switch Fedora job to voting

This patch changes the Fedora CI job to voting status for the
ansible-hardening project.

Change-Id: I3c88f13a1ed8cfed05e52aca3cfaba65522810af
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/474301/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,1d9d10486684d58d772b2006017f82d14bc9444b,fedora-voting-job, - gate-ansible-hardening-ansible-func-fedora-25 - gate-ansible-hardening-ansible-func-fedora-25, - gate-ansible-hardening-ansible-func-fedora-25-nv,2,1
openstack%2Fproject-config~master~Ifafcbecb4425949943855a8e385766d7ed40c409,openstack/project-config,master,Ifafcbecb4425949943855a8e385766d7ed40c409,Make the linter job voting,MERGED,2017-06-13 14:33:01.000000000,2017-06-19 07:20:08.000000000,2017-06-19 07:20:08.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 17591}, {'_account_id': 20443}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 23659}, {'_account_id': 23928}]","[{'number': 1, 'created': '2017-06-13 14:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8285025202c6697fc8bfc670315523163f21444a', 'message': 'Make the linter job voting\n\nThis patch set enables the linter to be voting and gating for\nOpenStack-Helm.\n\nChange-Id: Ifafcbecb4425949943855a8e385766d7ed40c409\n'}, {'number': 2, 'created': '2017-06-14 22:15:38.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f76412f0b08e3ed9b79efe8707309d6b1c60791c', 'message': 'Make the linter job voting\n\nThis patch set enables the linter to be voting and gating for\nOpenStack-Helm.\n\nChange-Id: Ifafcbecb4425949943855a8e385766d7ed40c409\n'}]",0,473859,f76412f0b08e3ed9b79efe8707309d6b1c60791c,15,9,2,20466,,,0,"Make the linter job voting

This patch set enables the linter to be voting and gating for
OpenStack-Helm.

Change-Id: Ifafcbecb4425949943855a8e385766d7ed40c409
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/473859/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,8285025202c6697fc8bfc670315523163f21444a,make-linter-voting, - gate-openstack-helm-nocluster-linter-ubuntu-xenial - gate-openstack-helm-nocluster-linter-ubuntu-xenial, - gate-openstack-helm-nocluster-linter-ubuntu-xenial-nv,3,2
openstack%2Fproject-config~master~Ie60be17ed2bbaaf3c6f99e1a4f2474f8c6196257,openstack/project-config,master,Ie60be17ed2bbaaf3c6f99e1a4f2474f8c6196257,Promote manila lvm centos 7 job to voting,MERGED,2017-06-08 15:45:52.000000000,2017-06-19 07:19:59.000000000,2017-06-19 07:19:59.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6133}, {'_account_id': 6413}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 15100}]","[{'number': 1, 'created': '2017-06-08 15:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/740b92458901e9245e88bd7c82823cb89f4fb8ed', 'message': 'Promote manila lvm centos 7 job to voting\n\ngate-manila-tempest-minimal-dsvm-lvm-centos-7-nv was installed\nas non-voting so that we could get a track record of runs before\nmaking a voting job.\n\nIt has been stable, so promote it to voting.\n\nChange-Id: Ie60be17ed2bbaaf3c6f99e1a4f2474f8c6196257\n'}, {'number': 2, 'created': '2017-06-18 15:59:26.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e7a00faa1a8667204827c7bb9e9dfd0616c99c6a', 'message': 'Promote manila lvm centos 7 job to voting\n\ngate-manila-tempest-minimal-dsvm-lvm-centos-7-nv was installed\nas non-voting so that we could get a track record of runs before\nmaking a voting job.\n\nIt has been stable, so promote it to voting.\n\nChange-Id: Ie60be17ed2bbaaf3c6f99e1a4f2474f8c6196257\n'}]",0,472302,e7a00faa1a8667204827c7bb9e9dfd0616c99c6a,13,7,2,9003,,,0,"Promote manila lvm centos 7 job to voting

gate-manila-tempest-minimal-dsvm-lvm-centos-7-nv was installed
as non-voting so that we could get a track record of runs before
making a voting job.

It has been stable, so promote it to voting.

Change-Id: Ie60be17ed2bbaaf3c6f99e1a4f2474f8c6196257
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/472302/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,740b92458901e9245e88bd7c82823cb89f4fb8ed,, - name: gate-manila-tempest-minimal-dsvm-lvm-centos-7 - gate-manila-tempest-minimal-dsvm-lvm-centos-7, - name: gate-manila-tempest-minimal-dsvm-lvm-centos-7-nv - gate-manila-tempest-minimal-dsvm-lvm-centos-7-nv,3,3
openstack%2Fproject-config~master~Ib112b57ca534f9dce78101a147e1a68df24b4c9b,openstack/project-config,master,Ib112b57ca534f9dce78101a147e1a68df24b4c9b,[fuel] Grant permissions to fuel-stable-core,MERGED,2017-06-15 11:06:28.000000000,2017-06-19 07:18:12.000000000,2017-06-19 07:18:12.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 10288}, {'_account_id': 14348}, {'_account_id': 24901}]","[{'number': 1, 'created': '2017-06-15 11:06:28.000000000', 'files': ['gerrit/acls/openstack/fuel-main.config', 'gerrit/acls/openstack/fuel-astute.config', 'gerrit/acls/openstack/python-fuelclient.config', 'gerrit/acls/openstack/fuel-nailgun-agent.config', 'gerrit/acls/openstack/fuel-ui.config', 'gerrit/acls/openstack/fuel-library.config', 'gerrit/acls/openstack/fuel-web.config', 'gerrit/acls/openstack/fuel-virtualbox.config', 'gerrit/acls/openstack/fuel-ostf.config', 'gerrit/acls/openstack/fuel-agent.config', 'gerrit/acls/openstack/fuel-menu.config', 'gerrit/acls/openstack/network-checker.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5eeb838e5c6ae943e4ae8a5793db7f5107a42957', 'message': '[fuel] Grant permissions to fuel-stable-core\n\nThis commit introduces new CR+2 permissions to the fuel-stable-core group\nfor stable branches in a number of fuel-related projects. Also exclusive\nWF+1 is granted in the fuel-ui project.\n\nChange-Id: Ib112b57ca534f9dce78101a147e1a68df24b4c9b\n'}]",2,474541,5eeb838e5c6ae943e4ae8a5793db7f5107a42957,14,8,1,14610,,,0,"[fuel] Grant permissions to fuel-stable-core

This commit introduces new CR+2 permissions to the fuel-stable-core group
for stable branches in a number of fuel-related projects. Also exclusive
WF+1 is granted in the fuel-ui project.

Change-Id: Ib112b57ca534f9dce78101a147e1a68df24b4c9b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/41/474541/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/fuel-main.config', 'gerrit/acls/openstack/fuel-astute.config', 'gerrit/acls/openstack/python-fuelclient.config', 'gerrit/acls/openstack/fuel-nailgun-agent.config', 'gerrit/acls/openstack/fuel-ui.config', 'gerrit/acls/openstack/fuel-library.config', 'gerrit/acls/openstack/fuel-web.config', 'gerrit/acls/openstack/fuel-virtualbox.config', 'gerrit/acls/openstack/fuel-ostf.config', 'gerrit/acls/openstack/fuel-agent.config', 'gerrit/acls/openstack/fuel-menu.config', 'gerrit/acls/openstack/network-checker.config']",12,5eeb838e5c6ae943e4ae8a5793db7f5107a42957,fuel-stable-core,"label-Code-Review = -2..+2 group fuel-stable-corelabel-Code-Review = -2..+2 group fuel-stable-corelabel-Code-Review = -2..+2 group fuel-stable-core label-Workflow = -1..+0 group Change Owner label-Workflow = -1..+1 group Project Bootstrappers label-Workflow = -1..+1 group fuel-stable-core [access ""refs/heads/stable/mitaka""] exclusiveGroupPermissions = label-Workflow label-Code-Review = -2..+2 group fuel-stable-core",,55,0
openstack%2Fzun~master~I8746d68cfb29590ce1649af2d3566603d2481098,openstack/zun,master,I8746d68cfb29590ce1649af2d3566603d2481098,Add return the image ID in container commit,MERGED,2017-06-05 07:26:44.000000000,2017-06-19 07:17:50.000000000,2017-06-19 07:17:50.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 16277}, {'_account_id': 23055}, {'_account_id': 25026}]","[{'number': 1, 'created': '2017-06-05 07:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/a9167d2fd9d42ed0bd9f5b704c4e94443f6e57d7', 'message': 'Add return the image ID in container commit\n\nThis patch adds return the image ID in container commit,\nso that users will know how to find it in glance.\n\nChange-Id: I8746d68cfb29590ce1649af2d3566603d2481098\nCloses-Bug: #1695788\n'}, {'number': 2, 'created': '2017-06-05 08:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/9e107fa7a3370bf38965aef4ae2cfd8152c39f64', 'message': 'Add return the image ID in container commit\n\nThis patch adds return the image ID in container commit,\nso that users will know how to find it in glance.\n\nChange-Id: I8746d68cfb29590ce1649af2d3566603d2481098\nCloses-Bug: #1695788\n'}, {'number': 3, 'created': '2017-06-06 06:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8448af2f693d3583c106c6bca04c2b69a931399e', 'message': 'Add return the image ID in container commit\n\nThis patch adds return the image ID in container commit,\nso that users will know how to find it in glance.\n\nChange-Id: I8746d68cfb29590ce1649af2d3566603d2481098\nCloses-Bug: #1695788\n'}, {'number': 4, 'created': '2017-06-07 01:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/1c69d3c85701da1650b34b4f4586ca0e4a70ac25', 'message': 'Add return the image ID in container commit\n\nThis patch adds return the image ID in container commit,\nso that users will know how to find it in glance.\n\nChange-Id: I8746d68cfb29590ce1649af2d3566603d2481098\nCloses-Bug: #1695788\n'}, {'number': 5, 'created': '2017-06-12 03:36:01.000000000', 'files': ['zun/compute/rpcapi.py', 'zun/tests/unit/compute/test_compute_manager.py', 'zun/image/driver.py', 'zun/compute/manager.py', 'zun/api/controllers/v1/containers.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/dbeb80e13f96aec19ab14348f9a674e45f3aae5a', 'message': 'Add return the image ID in container commit\n\nThis patch adds return the image ID in container commit,\nso that users will know how to find it in glance.\n\nChange-Id: I8746d68cfb29590ce1649af2d3566603d2481098\nCloses-Bug: #1695788\n'}]",6,470864,dbeb80e13f96aec19ab14348f9a674e45f3aae5a,30,6,5,23055,,,0,"Add return the image ID in container commit

This patch adds return the image ID in container commit,
so that users will know how to find it in glance.

Change-Id: I8746d68cfb29590ce1649af2d3566603d2481098
Closes-Bug: #1695788
",git fetch https://review.opendev.org/openstack/zun refs/changes/64/470864/4 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/compute/test_compute_manager.py', 'zun/compute/manager.py', 'zun/tests/unit/api/controllers/v1/test_containers.py', 'zun/api/controllers/v1/containers.py']",4,a9167d2fd9d42ed0bd9f5b704c4e94443f6e57d7,bug/1695788," return compute_api.container_commit(context, container, kw.get('repository', None), kw.get('tag', None))"," compute_api.container_commit(context, container, kw.get('repository', None), kw.get('tag', None)) pecan.response.status = 202",18,13
openstack%2Fnetworking-l2gw~master~I27a9e4572cc7582176534e7e0711024429c98dae,openstack/networking-l2gw,master,I27a9e4572cc7582176534e7e0711024429c98dae,Tempest plugin expects the l2gw section instead of network,MERGED,2017-06-15 03:27:42.000000000,2017-06-19 07:16:33.000000000,2017-06-19 07:16:33.000000000,"[{'_account_id': 3}, {'_account_id': 1653}]","[{'number': 1, 'created': '2017-06-15 03:27:42.000000000', 'files': ['networking_l2gw/tests/tempest/etc/tempest.conf.sample'], 'web_link': 'https://opendev.org/openstack/networking-l2gw/commit/4bb98061ab23e3b9815620d01d9b994915ff8261', 'message': 'Tempest plugin expects the l2gw section instead of network\n\nChange-Id: I27a9e4572cc7582176534e7e0711024429c98dae\nSigned-off-by: Ricardo Noriega <rnoriega@redhat.com>\n'}]",0,474434,4bb98061ab23e3b9815620d01d9b994915ff8261,6,2,1,21626,,,0,"Tempest plugin expects the l2gw section instead of network

Change-Id: I27a9e4572cc7582176534e7e0711024429c98dae
Signed-off-by: Ricardo Noriega <rnoriega@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-l2gw refs/changes/34/474434/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_l2gw/tests/tempest/etc/tempest.conf.sample'],1,4bb98061ab23e3b9815620d01d9b994915ff8261,tempest_sample,[l2gw],[network],1,1
openstack%2Fopenstack-manuals~master~Ic9dea81b7691ab2df524911045e679f538d2644a,openstack/openstack-manuals,master,Ic9dea81b7691ab2df524911045e679f538d2644a,Add the property hypervisor_type to the image creation,MERGED,2017-05-21 15:24:53.000000000,2017-06-19 07:16:26.000000000,2017-05-22 16:30:30.000000000,"[{'_account_id': 3}, {'_account_id': 10607}, {'_account_id': 17130}, {'_account_id': 19779}]","[{'number': 1, 'created': '2017-05-21 15:24:53.000000000', 'files': ['doc/config-reference/source/compute/hypervisor-hyper-v.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/162ca875e4daa7a28fd00f74dcd4ffa76b6d6e16', 'message': 'Add the property hypervisor_type to the image creation\n\n* hypervisor_type = hyperv\n\nChange-Id: Ic9dea81b7691ab2df524911045e679f538d2644a\n'}]",0,466540,162ca875e4daa7a28fd00f74dcd4ffa76b6d6e16,9,4,1,20663,,,0,"Add the property hypervisor_type to the image creation

* hypervisor_type = hyperv

Change-Id: Ic9dea81b7691ab2df524911045e679f538d2644a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/466540/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/compute/hypervisor-hyper-v.rst'],1,162ca875e4daa7a28fd00f74dcd4ffa76b6d6e16,hyperv," PS C:\> openstack image create --name ""VM_IMAGE_NAME"" --property hypervisor_type=hyperv --public \"," PS C:\> openstack image create --name ""VM_IMAGE_NAME"" --public \",1,1
openstack%2Fzun~master~Id095e7b02f6a6f45c15f97f029027dfbc3955b7e,openstack/zun,master,Id095e7b02f6a6f45c15f97f029027dfbc3955b7e,Unset container's host if it failed to create,MERGED,2017-06-10 16:38:34.000000000,2017-06-19 07:15:20.000000000,2017-06-19 07:15:20.000000000,"[{'_account_id': 3}, {'_account_id': 8264}, {'_account_id': 16277}, {'_account_id': 23365}]","[{'number': 1, 'created': '2017-06-10 16:38:34.000000000', 'files': ['zun/tests/unit/compute/test_compute_manager.py', 'zun/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/bc8375bbc2e89c094c6154a6450cff86c1c51494', 'message': ""Unset container's host if it failed to create\n\nThis is for fixing the wrong calculation of available resources\nin compute host. Resource comsuption of a host is calculated by\nlisting all containers that has a 'host' field equal to current\nhost. If a container failed to create, it should has its 'host'\nfield unset so that its resource won't be attributed to the host.\n\nChange-Id: Id095e7b02f6a6f45c15f97f029027dfbc3955b7e\n""}]",0,472965,bc8375bbc2e89c094c6154a6450cff86c1c51494,16,4,1,11536,,,0,"Unset container's host if it failed to create

This is for fixing the wrong calculation of available resources
in compute host. Resource comsuption of a host is calculated by
listing all containers that has a 'host' field equal to current
host. If a container failed to create, it should has its 'host'
field unset so that its resource won't be attributed to the host.

Change-Id: Id095e7b02f6a6f45c15f97f029027dfbc3955b7e
",git fetch https://review.opendev.org/openstack/zun refs/changes/65/472965/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/compute/test_compute_manager.py', 'zun/compute/manager.py']",2,bc8375bbc2e89c094c6154a6450cff86c1c51494,," def _fail_container(self, context, container, error, unset_host=False): if unset_host: container.host = None self._fail_container(context, container, six.text_type(e), unset_host=True) self._fail_container(context, container, six.text_type(e), unset_host=True)"," def _fail_container(self, context, container, error): self._fail_container(context, container, six.text_type(e)) self._fail_container(context, container, six.text_type(e))",11,7
openstack%2Fui-cookiecutter~master~I13512a105609fd2cf050ab455945ce130e5e026f,openstack/ui-cookiecutter,master,I13512a105609fd2cf050ab455945ce130e5e026f,Improve docs build,MERGED,2017-05-26 07:38:13.000000000,2017-06-19 07:11:56.000000000,2017-06-19 07:11:56.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 16352}]","[{'number': 1, 'created': '2017-05-26 07:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ui-cookiecutter/commit/31346d4f41c00b87721c5aefc952f74e3465b813', 'message': 'Improve docs build\n\nStarting in Django 1.7, standalone scripts, such as a sphinx build\nrequire that django.setup() be called first. See:\nhttps://docs.djangoproject.com/en/1.8/releases/1.7/#standalone-scripts\nIt does not always necessary, but it is needed to avoid warnings\nwhen creating autoindex (as the cookiecutter does).\nNote that horizon no longer generates the autoindex to avoid warnings.\n\nDrops setenv DJANGO_SETTINGS_MODULE in docs env in tox.ini.\nDJANGO_SETTINGS_MODULE is configured in doc/source/conf.py,\nso there is no need to pass envvar.\n\nAdd warning-is-error sphinx setting to avoid doc build warnings.\n\nChange-Id: I13512a105609fd2cf050ab455945ce130e5e026f\n'}, {'number': 2, 'created': '2017-05-29 03:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ui-cookiecutter/commit/f9675494fa71af8133ae22c1a171d34cbaf10777', 'message': 'Improve docs build\n\nStarting in Django 1.7, standalone scripts, such as a sphinx build\nrequire that django.setup() be called first. See:\nhttps://docs.djangoproject.com/en/1.8/releases/1.7/#standalone-scripts\nIt does not always necessary, but it is needed to avoid warnings\nwhen creating autoindex (as the cookiecutter does).\nNote that horizon no longer generates the autoindex to avoid warnings.\n\nDrops setenv DJANGO_SETTINGS_MODULE in docs env in tox.ini.\nDJANGO_SETTINGS_MODULE is configured in doc/source/conf.py,\nso there is no need to pass envvar.\n\nAdd warning-is-error sphinx setting to avoid doc build warnings.\n\nChange-Id: I13512a105609fd2cf050ab455945ce130e5e026f\n'}, {'number': 3, 'created': '2017-05-31 12:18:46.000000000', 'files': ['{{cookiecutter.repo_name}}/setup.cfg', '{{cookiecutter.repo_name}}/doc/source/conf.py', '{{cookiecutter.repo_name}}/tox.ini'], 'web_link': 'https://opendev.org/openstack/ui-cookiecutter/commit/9f73a37928e58564002cbdcbd0dc2053e14d641a', 'message': 'Improve docs build\n\nStarting in Django 1.7, standalone scripts, such as a sphinx build\nrequire that django.setup() be called first. See:\nhttps://docs.djangoproject.com/en/1.8/releases/1.7/#standalone-scripts\nIt does not always necessary, but it is needed to avoid warnings\nwhen creating autoindex (as the cookiecutter does).\nNote that horizon no longer generates the autoindex to avoid warnings.\n\nDrops setenv DJANGO_SETTINGS_MODULE in docs env in tox.ini.\nDJANGO_SETTINGS_MODULE is configured in doc/source/conf.py,\nso there is no need to pass envvar.\n\nAdd warning-is-error sphinx setting to avoid doc build warnings.\n\nChange-Id: I13512a105609fd2cf050ab455945ce130e5e026f\n'}]",0,468294,9f73a37928e58564002cbdcbd0dc2053e14d641a,14,3,3,841,,,0,"Improve docs build

Starting in Django 1.7, standalone scripts, such as a sphinx build
require that django.setup() be called first. See:
https://docs.djangoproject.com/en/1.8/releases/1.7/#standalone-scripts
It does not always necessary, but it is needed to avoid warnings
when creating autoindex (as the cookiecutter does).
Note that horizon no longer generates the autoindex to avoid warnings.

Drops setenv DJANGO_SETTINGS_MODULE in docs env in tox.ini.
DJANGO_SETTINGS_MODULE is configured in doc/source/conf.py,
so there is no need to pass envvar.

Add warning-is-error sphinx setting to avoid doc build warnings.

Change-Id: I13512a105609fd2cf050ab455945ce130e5e026f
",git fetch https://review.opendev.org/openstack/ui-cookiecutter refs/changes/94/468294/2 && git format-patch -1 --stdout FETCH_HEAD,"['{{cookiecutter.repo_name}}/doc/source/conf.py', '{{cookiecutter.repo_name}}/setup.cfg', '{{cookiecutter.repo_name}}/tox.ini']",3,31346d4f41c00b87721c5aefc952f74e3465b813,doc-build,,setenv = DJANGO_SETTINGS_MODULE={{cookiecutter.module_name}}.test.settings,9,3
openstack%2Fvitrage-specs~master~I45472d76fccfe5a0efc29a9fc14452d8620ca539,openstack/vitrage-specs,master,I45472d76fccfe5a0efc29a9fc14452d8620ca539,Support external actions in the Vitrage templates.,MERGED,2017-06-18 15:26:41.000000000,2017-06-19 07:10:10.000000000,2017-06-19 07:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 19122}, {'_account_id': 19134}]","[{'number': 1, 'created': '2017-06-18 15:26:41.000000000', 'files': ['specs/pike/external-actions.rst'], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/5bc6f82a9d7ed8cb20cdf3b38007a99541222f7e', 'message': 'Support external actions in the Vitrage templates.\n\nThis is the first step towards a Vitrage->Mistral integration.\nImplements: blueprint support-external-actions\n\nChange-Id: I45472d76fccfe5a0efc29a9fc14452d8620ca539\n'}]",0,475179,5bc6f82a9d7ed8cb20cdf3b38007a99541222f7e,7,3,1,19159,,,0,"Support external actions in the Vitrage templates.

This is the first step towards a Vitrage->Mistral integration.
Implements: blueprint support-external-actions

Change-Id: I45472d76fccfe5a0efc29a9fc14452d8620ca539
",git fetch https://review.opendev.org/openstack/vitrage-specs refs/changes/79/475179/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/external-actions.rst'],1,5bc6f82a9d7ed8cb20cdf3b38007a99541222f7e,bp/support-external-actions,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================= Support External Actions in Vitrage Templates ============================================= launchpad blueprint: https://blueprints.launchpad.net/vitrage/+spec/support-external-actions Currently, the Vitrage templates support the following actions: raise alarm, set state, mark causal relationship and mark-down. The implementation of mark-down is patchy (update a property on the vertex and call the notifier). We need a way to define in the template an external action that should be taken. One example is the mark-down. Another example is to execute a Mistral workflow or a Congress policy. Problem description =================== The following use cases should be supported: 1. **mark-down**. This is an existing use case. If a mark-down action exists, Vitrage will call Nova mark-down API. The behavior should remain the same after the change. 2. **Execute a Mistral workflow**. The user should be able to execute a Mistral workflow based on Vitrage insights. 3. **Execute other external actions**, like a Congress policy. Proposed change =============== Add a new action for each external engine we would like to support. The action will have metadata with parameters to be sent to the engine. Examples -------- .. code-block:: yaml action: action_type: execute_nova metadata: api_call: mark-down host: host1 .. code-block:: yaml action: action_type: execute_mistral metadata: workflow: evacuate_host failed_host: host1 The idea behind adding a new external_* action for each engine is to emphasize that Vitrage supports a predefined set of external actions, and specifically it does not support runinng scripts. The internal implementation will be identical for Nova, Mistral, Congress, etc. During the template loading phase, the execute_* action will be converted to a generic Execute action, with a notifier parameter. The template validator will verify that the wanted notifier is enabled in vitrage.conf, otherwise the template loading will fail. When executing the Execute action, the evaluator will send an event to the message bus of the wanted notifier. This way, only the Mistral notifier will handle the execute_mistral actions. Note that currently only the Vitrage graph sends notification to the notifier. This behavior will be changed, so notifications will be sent both from the graph (for deduced alarms and set state) and from the evaluator. Alternatives ------------ There are two alternatives: Send Message bus notifications ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Vitrage can have a message bus notifier, that will send notifications about raise/delete alarm, set state and mark causal-relationship. Mistral will be configured to execute certain workflows based on the notifications received from Vitrage. Advantages: * No extra configuration needed in Vitrage * Can work with the current notifiers mechanism Disadvantages: * Messgae bus notifications might get lost * Less powerful. In Vitrage template the user can decide to execute a workflow based on a combination of alarms or a specific topology. Once Mistral gets the notifications, the topology context is no longer there. * mark-down use case is not supported by this solution Configuration Done on the specific notifier ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ A Mistral notifier will be written and receive notifications from the graph. It will be configured by a yaml file that will determine which workflow to execute per specific alarm. Advantages: * No extra configuration needed in Vitrage * Can work with the current notifiers mechanism * No lost messages Disadvantages: * Less powerful. In Vitrage template the user can decide to execute a workflow based on a combination of alarms or a specific topology. In Mistral notifier we no longer have this context. * mark-down use case is not supported by this solution Data model impact ----------------- A new Execute action will be added to the evaluator. REST API impact --------------- None Versioning impact ----------------- We should introduce a versioning mechanism to the templates. This will be done when modifying the implementation of mark-down. Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- None Horizon impact -------------- None Implementation ============== Assignee(s) ----------- Primary assignee: ifat-afek Work Items ---------- * Enhance the template language (template loading and validation) * Update the documentation * Execute the external actions from the evaluator Dependencies ============ None Testing ======= The implementation will be covered by unit tests and tempest tests. Documentation Impact ==================== The new action should be documented References ========== None ",,197,0
openstack%2Fzun~master~I87af8a364a89a3232e904f4c8d35184348b3c47a,openstack/zun,master,I87af8a364a89a3232e904f4c8d35184348b3c47a,Do not set container host before resource claimed,MERGED,2017-06-19 03:14:46.000000000,2017-06-19 07:09:11.000000000,2017-06-19 07:09:11.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 16277}]","[{'number': 1, 'created': '2017-06-19 03:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/80dbaf9492f543017cae76b8fce4e97f09db9b8b', 'message': 'Do not set container host before resource claimed\n\nDo not set container host before resource claimed.\n\nSet the container host in compute node when claimed resource.\n\nChange-Id: I87af8a364a89a3232e904f4c8d35184348b3c47a\nClose-Bugs: #1697569\n'}, {'number': 2, 'created': '2017-06-19 03:18:47.000000000', 'files': ['zun/compute/api.py', 'zun/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/8c7a97d85fce8e927f5ed4a4967bc6f1b4590e82', 'message': 'Do not set container host before resource claimed\n\nDo not set container host before resource claimed.\n\nSet the container host in compute node when claimed resource.\n\nChange-Id: I87af8a364a89a3232e904f4c8d35184348b3c47a\nCloses-Bug: #1697569\n'}]",0,475216,8c7a97d85fce8e927f5ed4a4967bc6f1b4590e82,8,3,2,8264,,,0,"Do not set container host before resource claimed

Do not set container host before resource claimed.

Set the container host in compute node when claimed resource.

Change-Id: I87af8a364a89a3232e904f4c8d35184348b3c47a
Closes-Bug: #1697569
",git fetch https://review.opendev.org/openstack/zun refs/changes/16/475216/2 && git format-patch -1 --stdout FETCH_HEAD,"['zun/compute/api.py', 'zun/compute/rpcapi.py']",2,80dbaf9492f543017cae76b8fce4e97f09db9b8b,bug/1697569," def container_create(self, context, host, container): self._cast(host, 'container_create', container=container) def container_run(self, context, host, container): self._cast(host, 'container_run', container=container)"," def container_create(self, context, container): self._cast(container.host, 'container_create', container=container) def container_run(self, context, container): self._cast(container.host, 'container_run', container=container)",13,10
openstack%2Fnova-powervm~master~Idaafd50c63f08a185eed521c00a5dc756c90ac34,openstack/nova-powervm,master,Idaafd50c63f08a185eed521c00a5dc756c90ac34,Remove log translations,ABANDONED,2017-06-12 05:59:09.000000000,2017-06-19 07:09:09.000000000,,"[{'_account_id': 3}, {'_account_id': 16128}, {'_account_id': 24870}]","[{'number': 1, 'created': '2017-06-12 05:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/6efa795cb26d611a132a0bb1e540201196bde1c6', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: Idaafd50c63f08a185eed521c00a5dc756c90ac34\n'}, {'number': 2, 'created': '2017-06-12 06:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0967f858197ffc75885d6367dbaefe0c9404f906', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: Idaafd50c63f08a185eed521c00a5dc756c90ac34\n'}, {'number': 3, 'created': '2017-06-19 06:34:18.000000000', 'files': ['nova_powervm/virt/powervm/volume/volume.py', 'nova_powervm/virt/powervm/driver.py', 'nova_powervm/virt/powervm/nvram/manager.py', 'nova_powervm/virt/powervm/vif.py', 'nova_powervm/virt/powervm/disk/ssp.py', 'nova_powervm/virt/powervm/i18n.py', 'nova_powervm/virt/powervm/tasks/vm.py', 'nova_powervm/virt/powervm/host.py', 'nova_powervm/virt/powervm/media.py', 'nova_powervm/virt/powervm/disk/driver.py', 'nova_powervm/virt/powervm/volume/iscsi.py', 'nova_powervm/virt/powervm/tasks/image.py', 'nova_powervm/virt/powervm/tasks/network.py', 'nova_powervm/virt/powervm/tasks/storage.py', 'nova_powervm/virt/powervm/disk/imagecache.py', 'nova_powervm/virt/powervm/nvram/swift.py', 'nova_powervm/virt/powervm/volume/fileio.py', 'nova_powervm/virt/powervm/volume/vscsi.py', 'nova_powervm/virt/powervm/disk/localdisk.py', 'nova_powervm/virt/powervm/volume/npiv.py', 'nova_powervm/virt/powervm/live_migration.py', 'nova_powervm/virt/powervm/slot.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b2ee966517408e769ccbb9cf8bfad2e957cf7847', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: Idaafd50c63f08a185eed521c00a5dc756c90ac34\n'}]",0,473221,b2ee966517408e769ccbb9cf8bfad2e957cf7847,13,3,3,24870,,,0,"Remove log translations

Log messages are no longer being translated. This removes all use of
the _LE, _LI, and _LW translation markers to simplify logging and to
avoid confusion with new contributions.

See:
http://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html
http://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html

Change-Id: Idaafd50c63f08a185eed521c00a5dc756c90ac34
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/21/473221/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/volume/volume.py', 'nova_powervm/virt/powervm/driver.py', 'nova_powervm/virt/powervm/nvram/manager.py', 'nova_powervm/virt/powervm/vif.py', 'nova_powervm/virt/powervm/disk/ssp.py', 'nova_powervm/virt/powervm/i18n.py', 'nova_powervm/virt/powervm/tasks/vm.py', 'nova_powervm/virt/powervm/host.py', 'nova_powervm/virt/powervm/media.py', 'nova_powervm/virt/powervm/disk/driver.py', 'nova_powervm/virt/powervm/volume/iscsi.py', 'nova_powervm/virt/powervm/tasks/image.py', 'nova_powervm/virt/powervm/tasks/network.py', 'nova_powervm/virt/powervm/tasks/storage.py', 'nova_powervm/virt/powervm/disk/imagecache.py', 'nova_powervm/virt/powervm/nvram/swift.py', 'nova_powervm/virt/powervm/volume/fileio.py', 'nova_powervm/virt/powervm/volume/vscsi.py', 'nova_powervm/virt/powervm/disk/localdisk.py', 'nova_powervm/virt/powervm/volume/npiv.py', 'nova_powervm/virt/powervm/live_migration.py', 'nova_powervm/virt/powervm/slot.py']",22,6efa795cb26d611a132a0bb1e540201196bde1c6,Remove log translations,"from nova_powervm.virt.powervm.i18n import _ LOG.warning(_(""Unable to delete the slot map from Swift backing "" ""store with ID %(key)s. Will require "" ""manual cleanup.""), {'key': key},","from nova_powervm.virt.powervm.i18n import _LW LOG.warning(_LW(""Unable to delete the slot map from Swift backing "" ""store with ID %(key)s. Will require "" ""manual cleanup.""), {'key': key},",236,268
openstack%2Fzun~master~I9b88a68450fe4d9cdb03d78dc05a3ad123fcf15a,openstack/zun,master,I9b88a68450fe4d9cdb03d78dc05a3ad123fcf15a,Set access_policy for messaging's dispatcher,MERGED,2017-06-14 09:21:52.000000000,2017-06-19 07:09:05.000000000,2017-06-19 07:09:05.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 16277}, {'_account_id': 25695}]","[{'number': 1, 'created': '2017-06-14 09:21:52.000000000', 'files': ['zun/tests/unit/common/test_rpc.py', 'zun/common/rpc.py', 'zun/common/rpc_service.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/921dca49497d5cd95b19ab340d8d6ca295b3e53e', 'message': ""Set access_policy for messaging's dispatcher\n\noslo.messaging allow dispatcher to restrict endpoint methods\nsince 5.11.0 in d3a8f280ebd6fd12865fd20c4d772774e39aefa2, set with\nDefaultRPCAccessPolicy to fix FutureWarning like:\n\nFutureWarning: The access_policy argument is changing its default\nvalue to <class 'oslo_messaging.rpc.dispatcher.DefaultRPCAccessPolicy'>\nin version '?', please update the code to explicitly set None as the\nvalue: access_policy defaults to LegacyRPCAccessPolicy which exposes\nprivate methods. Explicitly set access_policy to DefaultRPCAccessPolicy\nor ExplicitRPCAccessPolicy.\n\nChange-Id: I9b88a68450fe4d9cdb03d78dc05a3ad123fcf15a\n""}]",0,474134,921dca49497d5cd95b19ab340d8d6ca295b3e53e,8,4,1,25587,,,0,"Set access_policy for messaging's dispatcher

oslo.messaging allow dispatcher to restrict endpoint methods
since 5.11.0 in d3a8f280ebd6fd12865fd20c4d772774e39aefa2, set with
DefaultRPCAccessPolicy to fix FutureWarning like:

FutureWarning: The access_policy argument is changing its default
value to <class 'oslo_messaging.rpc.dispatcher.DefaultRPCAccessPolicy'>
in version '?', please update the code to explicitly set None as the
value: access_policy defaults to LegacyRPCAccessPolicy which exposes
private methods. Explicitly set access_policy to DefaultRPCAccessPolicy
or ExplicitRPCAccessPolicy.

Change-Id: I9b88a68450fe4d9cdb03d78dc05a3ad123fcf15a
",git fetch https://review.opendev.org/openstack/zun refs/changes/34/474134/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/common/test_rpc.py', 'zun/common/rpc.py', 'zun/common/rpc_service.py']",3,921dca49497d5cd95b19ab340d8d6ca295b3e53e,,"from oslo_messaging.rpc import dispatcher access_policy = dispatcher.DefaultRPCAccessPolicy serializer=serializer, access_policy=access_policy)", serializer=serializer),15,4
openstack%2Fmagnum-ui~master~I0453a8051c7c6738a652cbf309588ce7d9df5879,openstack/magnum-ui,master,I0453a8051c7c6738a652cbf309588ce7d9df5879,Imported Translations from Zanata,MERGED,2017-06-19 06:49:15.000000000,2017-06-19 07:09:02.000000000,2017-06-19 07:09:02.000000000,"[{'_account_id': 3}, {'_account_id': 16352}]","[{'number': 1, 'created': '2017-06-19 06:49:15.000000000', 'files': ['magnum_ui/locale/id/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/de/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/287b2dd9c5216c4aca3b0d1609fc54fecabf5cb1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I0453a8051c7c6738a652cbf309588ce7d9df5879\n'}]",0,475262,287b2dd9c5216c4aca3b0d1609fc54fecabf5cb1,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I0453a8051c7c6738a652cbf309588ce7d9df5879
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/62/475262/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum_ui/locale/id/LC_MESSAGES/djangojs.po', 'magnum_ui/locale/de/LC_MESSAGES/djangojs.po']",2,287b2dd9c5216c4aca3b0d1609fc54fecabf5cb1,zanata/translations,"# Robert Simai <robert.simai@suse.com>, 2017. #zanata""Project-Id-Version: magnum-ui 2.2.1.dev30\n""""POT-Creation-Date: 2017-06-19 04:46+0000\n""""PO-Revision-Date: 2017-06-01 04:31+0000\n"" ""Last-Translator: Robert Simai <robert.simai@suse.com>\n""""X-Generator: Zanata 3.9.6\n""msgid ""DC/OS"" msgstr ""DC/OS"" ","""Project-Id-Version: magnum-ui 2.1.1.dev142\n""""POT-Creation-Date: 2017-02-01 09:46+0000\n""""PO-Revision-Date: 2017-02-01 07:20+0000\n"" ""Last-Translator: Andreas Jaeger <jaegerandi@gmail.com>\n""""X-Generator: Zanata 3.7.3\n""",17,10
openstack%2Frally~master~I8af4a5d8ae212b4101da9d8eb6fa52ca0abd5b00,openstack/rally,master,I8af4a5d8ae212b4101da9d8eb6fa52ca0abd5b00,Add 'rm -f .testrepository/times.dbm' command in testenv,ABANDONED,2017-04-25 12:17:36.000000000,2017-06-19 06:47:07.000000000,,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2017-04-25 12:17:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/rally/commit/140e43b8a88f3abce91e44e5ba591af2fb6e1b72', 'message': ""Add 'rm -f .testrepository/times.dbm' command in testenv\n\nRunning py2* post py3* tests results in error. Add\n'rm -f .testrepository/times.dbm' command in testenv to\nresolve this.\n\nChange-Id: I8af4a5d8ae212b4101da9d8eb6fa52ca0abd5b00\n""}]",0,459657,140e43b8a88f3abce91e44e5ba591af2fb6e1b72,5,3,1,20401,,,0,"Add 'rm -f .testrepository/times.dbm' command in testenv

Running py2* post py3* tests results in error. Add
'rm -f .testrepository/times.dbm' command in testenv to
resolve this.

Change-Id: I8af4a5d8ae212b4101da9d8eb6fa52ca0abd5b00
",git fetch https://review.opendev.org/openstack/rally refs/changes/57/459657/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,140e43b8a88f3abce91e44e5ba591af2fb6e1b72,test_env, rm -f .testrepository/times.dbm,,1,0
openstack%2Ftripleo-common~master~I450c3102813bd5c398f448542b2ed381cbb60c48,openstack/tripleo-common,master,I450c3102813bd5c398f448542b2ed381cbb60c48,Switch to RDO packages for HA support in Kolla images,MERGED,2017-06-16 17:18:49.000000000,2017-06-19 06:43:40.000000000,2017-06-17 13:40:12.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 20778}]","[{'number': 1, 'created': '2017-06-16 17:18:49.000000000', 'files': ['container-images/tripleo_kolla_template_overrides.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/031e5118dd57daf0a140e42a13db466cc21c1125', 'message': 'Switch to RDO packages for HA support in Kolla images\n\nNow that the needed versions of pacemaker, pcs, libqb and resource-agents\nhave landed in RDO, we can get rid of the temporary external yum repo\n\nChange-Id: I450c3102813bd5c398f448542b2ed381cbb60c48\n'}]",2,475035,031e5118dd57daf0a140e42a13db466cc21c1125,13,7,1,20778,,,0,"Switch to RDO packages for HA support in Kolla images

Now that the needed versions of pacemaker, pcs, libqb and resource-agents
have landed in RDO, we can get rid of the temporary external yum repo

Change-Id: I450c3102813bd5c398f448542b2ed381cbb60c48
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/35/475035/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_kolla_template_overrides.j2'],1,031e5118dd57daf0a140e42a13db466cc21c1125,ha-containers,RUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqbRUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqbRUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqbRUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqbRUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqbRUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqbRUN yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb,# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb# temporary pacemaker packages with support for bundles RUN yum-config-manager --add-repo http://people.redhat.com/mbaldess/rpms/container-repo/pacemaker-bundle.repo && yum install -y pacemaker pacemaker-remote pcs libqb resource-agents && mkdir /etc/libqb,7,14
openstack%2Fheat~master~I74dc574a1c73924d07106d9c4a1392a173e67442,openstack/heat,master,I74dc574a1c73924d07106d9c4a1392a173e67442,Replace six.iteritems() with .items(),ABANDONED,2017-03-31 12:01:29.000000000,2017-06-19 06:40:34.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 20401}, {'_account_id': 22056}]","[{'number': 1, 'created': '2017-03-31 12:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/46e448568e8c4a68d1e54adfc9b635d875ffa10d', 'message': 'Replace six.iteritems() with .items()\n\n1.As mentioned in [1], we should avoid using six.iteritems to achieve\niterators. We can use dict.items instead, as it will return iterators\nin PY3 as well. And dict.items/keys will more readable.\n2.In py2, the performance about list should be negligible, see the\nlink [2].\n[1] https://wiki.openstack.org/wiki/Python3\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I74dc574a1c73924d07106d9c4a1392a173e67442\n'}, {'number': 2, 'created': '2017-03-31 13:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d2f97232db652c586707350cbe558d15e05fb5eb', 'message': 'Replace six.iteritems() with .items()\n\n1.As mentioned in [1], we should avoid using six.iteritems to achieve\niterators. We can use dict.items instead, as it will return iterators\nin PY3 as well. And dict.items/keys will more readable.\n2.In py2, the performance about list should be negligible, see the\nlink [2].\n[1] https://wiki.openstack.org/wiki/Python3\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I74dc574a1c73924d07106d9c4a1392a173e67442\n'}, {'number': 3, 'created': '2017-04-05 11:31:10.000000000', 'files': ['heat/engine/update.py', 'heat/tests/convergence/framework/engine_wrapper.py', 'heat/engine/environment.py', 'heat/engine/resources/openstack/neutron/router.py', 'heat/tests/openstack/cinder/test_volume_utils.py', 'heat/engine/properties.py', 'heat/engine/resources/openstack/manila/share.py', 'heat/engine/scheduler.py', 'heat/tests/test_hacking.py', 'heat/engine/resources/openstack/sahara/templates.py', 'heat/engine/resources/openstack/heat/structured_config.py', 'heat/engine/service.py', 'heat_integrationtests/scenario/test_server_software_config.py', 'heat/api/cloudwatch/watch.py', 'heat/engine/resources/openstack/designate/record.py', 'contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'heat/tests/openstack/nova/test_floatingip.py', 'heat/engine/resources/openstack/nova/server.py', 'heat/objects/resource.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/openstack/barbican/container.py', 'heat/engine/plugin_manager.py', 'heat/engine/dependencies.py', 'heat/tests/engine/test_plugin_manager.py', 'heat/engine/parameters.py', 'heat/db/sqlalchemy/filters.py', 'heat/engine/resources/openstack/aodh/alarm.py', 'heat/engine/resources/openstack/mistral/workflow.py', 'heat/engine/resources/openstack/senlin/cluster.py', 'heat/engine/conditions.py', 'heat/tests/engine/service/test_software_config.py', 'heat/common/wsgi.py', 'heat/engine/resources/aws/autoscaling/launch_config.py', 'heat/common/template_format.py', 'heat/engine/cfn/template.py', 'heat/engine/resources/openstack/magnum/bay.py', 'heat/engine/stack.py', 'heat/engine/function.py', 'tools/custom_guidelines.py', 'heat/tests/openstack/neutron/test_neutron_port.py', 'heat/engine/resources/openstack/designate/zone.py', 'heat/scaling/lbutils.py', 'contrib/heat_docker/heat_docker/resources/docker_container.py', 'heat/engine/template.py', 'heat/tests/test_properties.py', 'heat/engine/resources/openstack/cinder/volume.py', 'heat/engine/resources/openstack/designate/recordset.py', 'heat/engine/hot/template.py', 'heat/api/openstack/v1/util.py', 'doc/source/ext/resources.py', 'heat/tests/test_resource.py', 'heat/engine/hot/functions.py', 'heat/engine/resources/openstack/barbican/order.py', 'heat/common/exception.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'heat/tests/openstack/neutron/test_neutron.py', 'heat/tests/generic_resource.py', 'heat/engine/resource.py', 'heat/engine/resources/openstack/designate/domain.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/718523e0095c0b46916d1f628a81cff3718674ea', 'message': 'Replace six.iteritems() with .items()\n\n1.As mentioned in [1], we should avoid using six.iteritems to achieve\niterators. We can use dict.items instead, as it will return iterators\nin PY3 as well. And dict.items/keys will more readable.\n2.In py2, the performance about list should be negligible, see the\nlink [2].\n[1] https://wiki.openstack.org/wiki/Python3\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I74dc574a1c73924d07106d9c4a1392a173e67442\n'}]",0,452171,718523e0095c0b46916d1f628a81cff3718674ea,10,4,3,20401,,,0,"Replace six.iteritems() with .items()

1.As mentioned in [1], we should avoid using six.iteritems to achieve
iterators. We can use dict.items instead, as it will return iterators
in PY3 as well. And dict.items/keys will more readable.
2.In py2, the performance about list should be negligible, see the
link [2].
[1] https://wiki.openstack.org/wiki/Python3
[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html

Change-Id: I74dc574a1c73924d07106d9c4a1392a173e67442
",git fetch https://review.opendev.org/openstack/heat refs/changes/71/452171/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/mistral/workflow.py', 'heat/engine/update.py', 'heat/engine/resources/openstack/senlin/cluster.py', 'heat/engine/resources/openstack/neutron/router.py', 'heat/common/wsgi.py', 'heat/engine/resources/aws/autoscaling/launch_config.py', 'heat/engine/properties.py', 'heat/engine/resources/openstack/manila/share.py', 'heat/engine/resources/openstack/sahara/templates.py', 'heat/engine/resources/openstack/heat/structured_config.py', 'heat/common/template_format.py', 'heat/engine/cfn/template.py', 'heat/engine/resources/openstack/magnum/bay.py', 'heat/engine/function.py', 'heat/engine/resources/openstack/designate/zone.py', 'heat/engine/resources/openstack/designate/record.py', 'contrib/rackspace/rackspace/tests/test_cloud_loadbalancer.py', 'contrib/heat_docker/heat_docker/resources/docker_container.py', 'heat/engine/resources/openstack/nova/server.py', 'heat/engine/resources/openstack/cinder/volume.py', 'heat/engine/resources/openstack/designate/recordset.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/openstack/barbican/container.py', 'doc/source/ext/resources.py', 'heat/engine/dependencies.py', 'heat/engine/resources/openstack/barbican/order.py', 'heat/common/exception.py', 'contrib/rackspace/rackspace/resources/cloud_loadbalancer.py', 'heat/db/sqlalchemy/filters.py', 'heat/engine/resources/openstack/aodh/alarm.py', 'heat/engine/resources/openstack/designate/domain.py']",31,46e448568e8c4a68d1e54adfc9b635d875ffa10d,," args = dict((k, v) for k, v in self.properties.items() if v)"," args = dict((k, v) for k, v in six.iteritems(self.properties) if v)",46,58
openstack%2Ftripleo-heat-templates~master~I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377,openstack/tripleo-heat-templates,master,I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377,Increase default for CinderLVMLoopDeviceSize,ABANDONED,2017-06-04 11:52:13.000000000,2017-06-19 06:21:01.000000000,,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 18142}, {'_account_id': 18575}, {'_account_id': 21129}]","[{'number': 1, 'created': '2017-06-04 11:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bcaf33b81d4495182c39623978610ed21a5b5fe9', 'message': 'Increase default for CinderLVMLoopDeviceSize\n\nCurrently CinderLVMLoopDeviceSize is 10280M [1] which causes failures for\nthe following tempest tests:\n\n- admin.v2.test_volume_type_access.VolumeTypesAccessV2Test.test_volume_type_access_add\n- VolumesV1SnapshotNegativeTestJSON.test_volume_from_snapshot_decreasing_size\n- test_volumes_backup.VolumesBackupsV2Test.test_backup_create_attached_volume\n- test_volumes_get.VolumesV2GetTest.test_volume_create_get_update_delete_from_image\n\nSearch for ""Volume group ""cinder-volumes"" insufficient free space (9 extents): 256\nrequired"" in scheduler.log on controller.\n\nThis patch increases the value of CinderLVMLoopDeviceSize.\n\nChange-Id: I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377\n'}, {'number': 2, 'created': '2017-06-04 11:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b3fec0e5df40d71e690e00913e36b702ef8614c', 'message': 'Increase default for CinderLVMLoopDeviceSize\n\nCurrently CinderLVMLoopDeviceSize is 10280M [1] which causes failures for\nthe following tempest tests:\n\n- admin.v2.test_volume_type_access.VolumeTypesAccessV2Test.test_volume_type_access_add\n- VolumesV1SnapshotNegativeTestJSON.test_volume_from_snapshot_decreasing_size\n- test_volumes_backup.VolumesBackupsV2Test.test_backup_create_attached_volume\n- test_volumes_get.VolumesV2GetTest.test_volume_create_get_update_delete_from_image\n\nSearch for ""Volume group ""cinder-volumes"" insufficient free space (9 extents): 256\nrequired"" in scheduler.log on controller.\n\nThis patch increases the value of CinderLVMLoopDeviceSize.\n\nChange-Id: I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377\n'}, {'number': 3, 'created': '2017-06-04 12:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/96bda48b3169337ae42d52b889c6a2e92017c344', 'message': 'Increase default for CinderLVMLoopDeviceSize\n\nCurrently CinderLVMLoopDeviceSize is 10280M which causes to fail\nthe following tempest tests:\n\n- admin.v2.test_volume_type_access.VolumeTypesAccessV2Test.test_volume_type_access_add\n- VolumesV1SnapshotNegativeTestJSON.test_volume_from_snapshot_decreasing_size\n- test_volumes_backup.VolumesBackupsV2Test.test_backup_create_attached_volume\n- test_volumes_get.VolumesV2GetTest.test_volume_create_get_update_delete_from_image\n\nSearch for ""Volume group ""cinder-volumes"" insufficient free space (9 extents): 256\nrequired"" in scheduler.log on controller.\n\nThis patch increases the value of CinderLVMLoopDeviceSize.\n\nChange-Id: I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377\n'}, {'number': 4, 'created': '2017-06-07 06:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/59f147184aca6dee6561e622ae7b0471d6f77a82', 'message': 'Increase default for CinderLVMLoopDeviceSize\n\nCurrently CinderLVMLoopDeviceSize is 10280M which causes to fail\nthe following tempest tests:\n\n- admin.v2.test_volume_type_access.VolumeTypesAccessV2Test.test_volume_type_access_add\n- VolumesV1SnapshotNegativeTestJSON.test_volume_from_snapshot_decreasing_size\n- test_volumes_backup.VolumesBackupsV2Test.test_backup_create_attached_volume\n- test_volumes_get.VolumesV2GetTest.test_volume_create_get_update_delete_from_image\n\nSearch for ""Volume group ""cinder-volumes"" insufficient free space (9 extents): 256\nrequired"" in scheduler.log on controller.\n\nThis patch increases the value of CinderLVMLoopDeviceSize.\n\nChange-Id: I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377\n'}, {'number': 5, 'created': '2017-06-07 06:08:34.000000000', 'files': ['puppet/services/cinder-volume.yaml', 'releasenotes/notes/increase-default-lvm-loop-device-size-3a9e769076a7943c.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c9a21bc6907a5eea5d0490505330bc17ed1e0cd0', 'message': 'Increase default for CinderLVMLoopDeviceSize\n\nCurrently CinderLVMLoopDeviceSize is 10280M which causes to fail\nthe following tempest tests:\n\n- admin.v2.test_volume_type_access.VolumeTypesAccessV2Test.test_volume_type_access_add\n- VolumesV1SnapshotNegativeTestJSON.test_volume_from_snapshot_decreasing_size\n- test_volumes_backup.VolumesBackupsV2Test.test_backup_create_attached_volume\n- test_volumes_get.VolumesV2GetTest.test_volume_create_get_update_delete_from_image\n\nSearch for ""Volume group ""cinder-volumes"" insufficient free space (9 extents): 256\nrequired"" in scheduler.log on controller.\n\nThis patch increases the value of CinderLVMLoopDeviceSize.\n\nChange-Id: I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377\n'}]",1,470745,c9a21bc6907a5eea5d0490505330bc17ed1e0cd0,17,8,5,18142,,,0,"Increase default for CinderLVMLoopDeviceSize

Currently CinderLVMLoopDeviceSize is 10280M which causes to fail
the following tempest tests:

- admin.v2.test_volume_type_access.VolumeTypesAccessV2Test.test_volume_type_access_add
- VolumesV1SnapshotNegativeTestJSON.test_volume_from_snapshot_decreasing_size
- test_volumes_backup.VolumesBackupsV2Test.test_backup_create_attached_volume
- test_volumes_get.VolumesV2GetTest.test_volume_create_get_update_delete_from_image

Search for ""Volume group ""cinder-volumes"" insufficient free space (9 extents): 256
required"" in scheduler.log on controller.

This patch increases the value of CinderLVMLoopDeviceSize.

Change-Id: I0f5b3b4314fe2bc9857bdb57a04d9943b8ef0377
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/45/470745/5 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/cinder-volume.yaml'],1,bcaf33b81d4495182c39623978610ed21a5b5fe9,, default: 20560 , default: 10280 description: The size of the loopback file used by the cinder LVM driver.,1,2
openstack%2Fos-brick~master~Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7,openstack/os-brick,master,Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7,Refactor iSCSI connect,MERGED,2017-04-10 17:08:40.000000000,2017-06-19 06:20:26.000000000,2017-06-16 18:00:37.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10135}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12112}, {'_account_id': 12369}, {'_account_id': 12924}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16595}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19852}, {'_account_id': 20146}, {'_account_id': 22248}, {'_account_id': 22700}, {'_account_id': 22796}, {'_account_id': 24502}]","[{'number': 1, 'created': '2017-04-10 17:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/1e9af99f68c619ebea46441ec176ab369d8bb586', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 2, 'created': '2017-04-11 12:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/f564aa39c5bf0ef6044325bbe725a10c75ce703c', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 3, 'created': '2017-04-11 17:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/5e849c885c5b371ba36023a3decfc0dface6cb30', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 4, 'created': '2017-04-12 06:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/37aab80dd13993f8c3ac9b72cc90af5b4c5160fe', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 5, 'created': '2017-04-12 07:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/fca64e3b9808425cf16323e1518ecb39a1ab27a3', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 6, 'created': '2017-04-12 18:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/d3e59bd19c6ff366f07bcece2e5a7508a9d38683', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 7, 'created': '2017-04-13 11:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6c4a8c1261cc95bc5ef53436ea84ceb89be3de1a', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 8, 'created': '2017-04-19 11:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/299c3d5c2a7b790a805701328638961dacbd64cc', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 9, 'created': '2017-04-21 09:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/a08ed544e103bc9c61656fc9f3bbf2b6875d29a2', 'message': ""WIP: Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 10, 'created': '2017-05-22 15:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/48ce093e044c42903964b4bae2bd88bb19588b47', 'message': ""Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 11, 'created': '2017-05-31 10:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/da3e706225bdd952c617c4659a6f6148b611da06', 'message': ""Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 12, 'created': '2017-05-31 12:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/ab06a62851e5ea12929786c65fb9b201c45bf9d1', 'message': ""Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 13, 'created': '2017-05-31 14:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/b1fc9fa22a8c099c76ce21522d45f855953a3ce7', 'message': ""Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 14, 'created': '2017-06-15 14:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/56381be50d4011a9fdacfcf9e4890b763f223a4b', 'message': ""Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}, {'number': 15, 'created': '2017-06-16 14:12:14.000000000', 'files': ['os_brick/tests/initiator/connectors/test_iscsi.py', 'os_brick/tests/initiator/test_linuxscsi.py', 'os_brick/initiator/connectors/iscsi.py', 'os_brick/initiator/linuxscsi.py', 'os_brick/privileged/rootwrap.py', 'os_brick/tests/privileged/test_rootwrap.py', 'releasenotes/notes/refactor_iscsi_connect-dfbb24305a954783.yaml', 'os_brick/exception.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/56c8665d3d342ce90f5d9433966c0f244063b4c1', 'message': ""Refactor iSCSI connect\n\nThis patch refactors iSCSI connect code changing the approach to one\nthat relies primarily on sysfs, instead of CLI tools, to retrieve all\nthe required information: devices from the connection, multipath system\ndevice name, multipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Clean all leftovers on exceptions on a connection.\n\n- Parallelize logins on multipath to increase speed on flaky network\n  connections.\n\n- As long as there is at least one good path when working with multipath\n  we will return a multipath device instead of a single path device,\n  which helps with temporary flaky connections.\n\n- Don't use the rescan retry parameter as log in retry on multipath\n  connections so both single and multipath cases are consistent.\n\n- We no longer rely on just one device to get the wwn and look for the\n  multipath.  This would be problematic with flaky connections.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- It's no longer a problem for the mechanism the fact that a device\n  exists but is not accessible.\n\n- We use links in `/dev/disk/by-id` to get the WWID on connect, so we\n  make sure there are no leftovers on disconnect, but we no longer use\n  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`\n  to find devices.\n\n- We no longer need to rely on the WWN to determine the multipath, we\n  have the session and the LUN, so we trace the devices and from those\n  we get if they belong to a multipath.\n\n- Stop polluting the logs with unnecessary exceptions from checking if\n  the node or session exist.\n\n- Action retries will now only log the final exception instead of\n  logging all the exceptions.\n\n- Warn when a multipath could not be formed and a single device is being\n  used, as performance will be degraded.\n\n- We no longer do global rescans on single connections that could be\n  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal\n  --rescan`).\n\n- Fix scan mechanism that would not request all scans when the same iqn\n  was shareed between portals and could send a scan request to the wrong\n  IP if they shared the same iqn.\n\n- When doing single pathed connections we could end with a multipath\n  because we didn't clean up unfruitful connections.\n\nIt's worth mentioning that this patch does not touch the extend\noperation.\n\nChange-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7\n""}]",17,455393,56c8665d3d342ce90f5d9433966c0f244063b4c1,173,25,15,9535,,,0,"Refactor iSCSI connect

This patch refactors iSCSI connect code changing the approach to one
that relies primarily on sysfs, instead of CLI tools, to retrieve all
the required information: devices from the connection, multipath system
device name, multipath name, the WWN for the block devices...

By doing so, not only do we fix a good number of bugs, but we also
improve the reliability and speed of the mechanism.

A good example of improvements and benefits achieved by this patch are:

- Clean all leftovers on exceptions on a connection.

- Parallelize logins on multipath to increase speed on flaky network
  connections.

- As long as there is at least one good path when working with multipath
  we will return a multipath device instead of a single path device,
  which helps with temporary flaky connections.

- Don't use the rescan retry parameter as log in retry on multipath
  connections so both single and multipath cases are consistent.

- We no longer rely on just one device to get the wwn and look for the
  multipath.  This would be problematic with flaky connections.

- No more querying iSCSI devices for their WWN (page 0x83) removing
  delays and issue on flaky connections.

- It's no longer a problem for the mechanism the fact that a device
  exists but is not accessible.

- We use links in `/dev/disk/by-id` to get the WWID on connect, so we
  make sure there are no leftovers on disconnect, but we no longer use
  symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`, or `/dev/mapper`
  to find devices.

- We no longer need to rely on the WWN to determine the multipath, we
  have the session and the LUN, so we trace the devices and from those
  we get if they belong to a multipath.

- Stop polluting the logs with unnecessary exceptions from checking if
  the node or session exist.

- Action retries will now only log the final exception instead of
  logging all the exceptions.

- Warn when a multipath could not be formed and a single device is being
  used, as performance will be degraded.

- We no longer do global rescans on single connections that could be
  bringing in unrelated and unwanted devices (`iscsiadm -T iqn -p portal
  --rescan`).

- Fix scan mechanism that would not request all scans when the same iqn
  was shareed between portals and could send a scan request to the wrong
  IP if they shared the same iqn.

- When doing single pathed connections we could end with a multipath
  because we didn't clean up unfruitful connections.

It's worth mentioning that this patch does not touch the extend
operation.

Change-Id: Ia1c47bfaa7bc3544a5feba6a8a30faf2f132b8d7
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/93/455393/13 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/initiator/connectors/test_iscsi.py', 'os_brick/initiator/connectors/iscsi.py', 'os_brick/initiator/linuxscsi.py', 'releasenotes/notes/refactor_iscsi_connect-dfbb24305a954783.yaml', 'os_brick/exception.py']",5,1e9af99f68c619ebea46441ec176ab369d8bb586,refactor/multipath,,"class HostChannelsTargetsNotFound(BrickException): message = _('Unable to find host, channel, and target for %(iqns)s.') def __init__(self, message=None, iqns=None, found=None): super(HostChannelsTargetsNotFound, self).__init__(message, iqns=iqns) self.found = found ",421,370
openstack%2Fec2-api~master~I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf,openstack/ec2-api,master,I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf,Remove log translations,ABANDONED,2017-03-23 09:45:58.000000000,2017-06-19 06:05:41.000000000,,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}, {'_account_id': 11131}, {'_account_id': 20401}]","[{'number': 1, 'created': '2017-03-23 09:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e7a07bdc9133b48366f01fd06bc6527196cdcfe2', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf\n'}, {'number': 2, 'created': '2017-04-03 08:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/3cfab6a9b041b4d61b6a25d360125d0d29ea844a', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf\n'}, {'number': 3, 'created': '2017-04-03 10:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/5fe72cb9e4e7a644fb1b043b6f8aed591f88488f', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf\n'}, {'number': 4, 'created': '2017-04-20 07:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/cb28b142cbc6dd52c49912f957b4c656b760a48c', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf\n'}, {'number': 5, 'created': '2017-05-12 06:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/83b397d5dd09755bab871e4167407070c7f78cae', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf\n'}, {'number': 6, 'created': '2017-05-12 08:49:04.000000000', 'files': ['ec2api/api/image.py', 'ec2api/metadata/__init__.py', 'requirements.txt', 'ec2api/api/instance.py', 'ec2api/api/common.py', 'ec2api/clients.py', 'ec2api/api/ec2utils.py', 'ec2api/context.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/99b838802d4f6315cb73870026879d17dd381193', 'message': 'Remove log translations\n\nLog messages are no longer being translated. This removes all use of\nthe _LE, _LI, and _LW translation markers to simplify logging and to\navoid confusion with new contributions.\n\nSee:\nhttp://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html\n\nChange-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf\n'}]",8,449026,99b838802d4f6315cb73870026879d17dd381193,22,5,6,20401,,,0,"Remove log translations

Log messages are no longer being translated. This removes all use of
the _LE, _LI, and _LW translation markers to simplify logging and to
avoid confusion with new contributions.

See:
http://lists.openstack.org/pipermail/openstack-i18n/2016-November/002574.html
http://lists.openstack.org/pipermail/openstack-dev/2017-March/113365.html

Change-Id: I46f243edbf6a68801b76e72c5fdbd7fb0413cbaf
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/26/449026/3 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/image.py', 'ec2api/metadata/__init__.py', 'ec2api/api/instance.py', 'ec2api/api/common.py', 'ec2api/clients.py', 'ec2api/api/ec2utils.py', 'ec2api/context.py']",7,e7a07bdc9133b48366f01fd06bc6527196cdcfe2,rm_log_translations, LOG.warning('Arguments dropped when creating context: %s' %,from ec2api.i18n import _LW LOG.warning(_LW('Arguments dropped when creating context: %s') %,99,106
openstack%2Fzun-ui~master~I5927e3a5bdc6d4bd9e3f0649fa86a243d23c3178,openstack/zun-ui,master,I5927e3a5bdc6d4bd9e3f0649fa86a243d23c3178,Exclude node_modules directory from flake8 target,MERGED,2017-06-19 05:49:25.000000000,2017-06-19 06:05:27.000000000,2017-06-19 06:05:27.000000000,"[{'_account_id': 3}, {'_account_id': 16352}]","[{'number': 1, 'created': '2017-06-19 05:49:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/zun-ui/commit/aefbe4e6f6dadf74363107d7d20a150e24a6e0df', 'message': 'Exclude node_modules directory from flake8 target\n\nChange-Id: I5927e3a5bdc6d4bd9e3f0649fa86a243d23c3178\n'}]",0,475237,aefbe4e6f6dadf74363107d7d20a150e24a6e0df,6,2,1,16352,,,0,"Exclude node_modules directory from flake8 target

Change-Id: I5927e3a5bdc6d4bd9e3f0649fa86a243d23c3178
",git fetch https://review.opendev.org/openstack/zun-ui refs/changes/37/475237/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,aefbe4e6f6dadf74363107d7d20a150e24a6e0df,exclude-node-modules,"exclude = .venv,.git,.tox,dist,*lib/python*,*egg,build,panel_template,dash_template,local_settings.py,*/local/*,*/test/test_plugins/*,.ropeproject,node_modules","exclude = .venv,.git,.tox,dist,*lib/python*,*egg,build,panel_template,dash_template,local_settings.py,*/local/*,*/test/test_plugins/*,.ropeproject",1,1
openstack%2Frequirements~stable%2Fnewton~I72a170a0ab44673dd3041fe102d3b910e7db203f,openstack/requirements,stable/newton,I72a170a0ab44673dd3041fe102d3b910e7db203f,Add virtualbmc to requirements and constraints,MERGED,2017-03-22 10:49:12.000000000,2017-06-19 06:01:28.000000000,2017-06-19 06:01:28.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 9656}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}, {'_account_id': 14760}]","[{'number': 1, 'created': '2017-03-22 10:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/c25e88c0d889f064803709355b1fcef6443259e3', 'message': 'Add virtualbmc to requirements and constraints\n\nvirtualbmc is a library/tool that is used throughout projects under\nOpenStack Baremetal program for testing on virtualized hardware.\n\nIt depends on pyghmi library (pure Python IPMI protocol implementation)\nwhich is already in g-r and u-c.\n\nIn order to avoid incompatible versions of virtualbmc and pyghmi\ninstalled or required, which was already seen (ML thread [0]),\nvirtualbmc should also be present in g-r and u-c.\n\nVersions specified in this patch are latest available at the time of\nNewton release and are known to work with pyghmi version present in\nglobal requirements as of stable/newton.\n\n[0] http://lists.openstack.org/pipermail/openstack-dev/2017-March/113152.html\n\nChange-Id: I72a170a0ab44673dd3041fe102d3b910e7db203f\n(cherry picked from commit 86dd6385ff133f7b2762d175098665a8e450a49f)\n'}, {'number': 2, 'created': '2017-03-29 10:48:20.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3246491d1f3e7c01152d53ce4aa9a3bcafdc6286', 'message': 'Add virtualbmc to requirements and constraints\n\nvirtualbmc is a library/tool that is used throughout projects under\nOpenStack Baremetal program for testing on virtualized hardware.\n\nIt depends on pyghmi library (pure Python IPMI protocol implementation)\nwhich is already in g-r and u-c.\n\nIn order to avoid incompatible versions of virtualbmc and pyghmi\ninstalled or required, which was already seen (ML thread [0]),\nvirtualbmc should also be present in g-r and u-c.\n\nVersions specified in this patch are latest available at the time of\nNewton release and are known to work with pyghmi version present in\nglobal requirements as of stable/newton.\n\n[0] http://lists.openstack.org/pipermail/openstack-dev/2017-March/113152.html\n\nChange-Id: I72a170a0ab44673dd3041fe102d3b910e7db203f\n(cherry picked from commit 86dd6385ff133f7b2762d175098665a8e450a49f)\n'}]",0,448501,3246491d1f3e7c01152d53ce4aa9a3bcafdc6286,18,10,2,9542,,,0,"Add virtualbmc to requirements and constraints

virtualbmc is a library/tool that is used throughout projects under
OpenStack Baremetal program for testing on virtualized hardware.

It depends on pyghmi library (pure Python IPMI protocol implementation)
which is already in g-r and u-c.

In order to avoid incompatible versions of virtualbmc and pyghmi
installed or required, which was already seen (ML thread [0]),
virtualbmc should also be present in g-r and u-c.

Versions specified in this patch are latest available at the time of
Newton release and are known to work with pyghmi version present in
global requirements as of stable/newton.

[0] http://lists.openstack.org/pipermail/openstack-dev/2017-March/113152.html

Change-Id: I72a170a0ab44673dd3041fe102d3b910e7db203f
(cherry picked from commit 86dd6385ff133f7b2762d175098665a8e450a49f)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/01/448501/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,c25e88c0d889f064803709355b1fcef6443259e3,virtualbmc,virtualbmc===0.1.0,,2,0
openstack%2Ftricircle~master~I57ac130cb2383f2912fc6c0af646fb84ab2cdd90,openstack/tricircle,master,I57ac130cb2383f2912fc6c0af646fb84ab2cdd90,[Urgent] Fix sec-group unit tests and smoke tests,MERGED,2017-06-16 09:12:34.000000000,2017-06-19 05:58:18.000000000,2017-06-19 05:58:18.000000000,"[{'_account_id': 3}, {'_account_id': 11819}]","[{'number': 1, 'created': '2017-06-16 09:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/7cf35d708f5503c6a9b1e53e6a2c2cb6cdaa6e8a', 'message': '[Urgent] Fix security group unit tests\n\n1. What is the problem\nIn this patch[1] of Neutron project, new object model for security\ngroup is used. As a result, the ""remote_ip_prefix"" field returned\nby ""get_security_group_rule"" is an AuthenticIPNetwork object instead\nof a string, so our ""_compare_rule"" method fails to recognize two\nidentical rules.\n\n2. What is the solution for the problem\nUse str() to transform the AuthenticIPNetwork object to string.\n\n3. What features need to be implemented to the Tricircle to\nrealize the solution\nN/A\n\n[1] https://github.com/openstack/neutron/commit/\naf52d499a53f9dddacd8c9116d1bb0570e8f579c\n\nChange-Id: I57ac130cb2383f2912fc6c0af646fb84ab2cdd90\n'}, {'number': 2, 'created': '2017-06-19 02:18:31.000000000', 'files': ['tricircle/tests/unit/network/test_security_groups.py', 'tricircle/network/security_groups.py', 'tricircle/tempestplugin/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/31c45b33dccdba5b3790281d6da055be73bb15f2', 'message': '[Urgent] Fix sec-group unit tests and smoke tests\n\n1. What is the problem\n(1) In this patch[1] of Neutron project, new object model for security\ngroup is used. As a result, the ""remote_ip_prefix"" field returned\nby ""get_security_group_rule"" is an AuthenticIPNetwork object instead\nof a string, so our ""_compare_rule"" method fails to recognize two\nidentical rules.\n(2) After this patch[2] of devstack-gate project, horizon is no longer\nthe default project to be deployed in gate test, so enable horizon in\nour own local.conf without explicitly enabling horizon in the gate test\nwill cause gate test to fail.\n\n2. What is the solution for the problem\n(1) Use str() to transform the AuthenticIPNetwork object to string.\n(2) Disable horizon in our own local.conf since we don\'t need it.\n\n3. What features need to be implemented to the Tricircle to\nrealize the solution\nN/A\n\n[1] https://github.com/openstack/neutron/commit/\naf52d499a53f9dddacd8c9116d1bb0570e8f579c\n[2] https://github.com/openstack-infra/devstack-gate/commit/\ne1b6e9f1d6532fe87a8947a633e254d14aeb8fc0\n\nChange-Id: I57ac130cb2383f2912fc6c0af646fb84ab2cdd90\n'}]",0,474916,31c45b33dccdba5b3790281d6da055be73bb15f2,8,2,2,12076,,,0,"[Urgent] Fix sec-group unit tests and smoke tests

1. What is the problem
(1) In this patch[1] of Neutron project, new object model for security
group is used. As a result, the ""remote_ip_prefix"" field returned
by ""get_security_group_rule"" is an AuthenticIPNetwork object instead
of a string, so our ""_compare_rule"" method fails to recognize two
identical rules.
(2) After this patch[2] of devstack-gate project, horizon is no longer
the default project to be deployed in gate test, so enable horizon in
our own local.conf without explicitly enabling horizon in the gate test
will cause gate test to fail.

2. What is the solution for the problem
(1) Use str() to transform the AuthenticIPNetwork object to string.
(2) Disable horizon in our own local.conf since we don't need it.

3. What features need to be implemented to the Tricircle to
realize the solution
N/A

[1] https://github.com/openstack/neutron/commit/
af52d499a53f9dddacd8c9116d1bb0570e8f579c
[2] https://github.com/openstack-infra/devstack-gate/commit/
e1b6e9f1d6532fe87a8947a633e254d14aeb8fc0

Change-Id: I57ac130cb2383f2912fc6c0af646fb84ab2cdd90
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/16/474916/1 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle/tests/unit/network/test_security_groups.py', 'tricircle/network/security_groups.py']",2,7cf35d708f5503c6a9b1e53e6a2c2cb6cdaa6e8a,fix-seg-test, if rule1[key] != rule2[key] and str(rule1[key]) != str(rule2[key]):, if rule1[key] != rule2[key]:,2,1
openstack%2Ffreezer~master~I53f8129103cd0fb795fc9c83760c0cd7e20ec217,openstack/freezer,master,I53f8129103cd0fb795fc9c83760c0cd7e20ec217,Updated from global requirements,MERGED,2017-06-15 16:22:33.000000000,2017-06-19 05:53:56.000000000,2017-06-19 05:53:56.000000000,"[{'_account_id': 3}, {'_account_id': 14101}, {'_account_id': 16768}, {'_account_id': 22405}]","[{'number': 1, 'created': '2017-06-15 16:22:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/freezer/commit/2eb19108d453648b96ae287f06e6d3e9cfc0c3b9', 'message': 'Updated from global requirements\n\nChange-Id: I53f8129103cd0fb795fc9c83760c0cd7e20ec217\n'}]",0,474634,2eb19108d453648b96ae287f06e6d3e9cfc0c3b9,9,4,1,11131,,,0,"Updated from global requirements

Change-Id: I53f8129103cd0fb795fc9c83760c0cd7e20ec217
",git fetch https://review.opendev.org/openstack/freezer refs/changes/34/474634/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2eb19108d453648b96ae287f06e6d3e9cfc0c3b9,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Frequirements~stable%2Focata~I202078f5ca4ba6da4ab0ed52d97d41997674c1b4,openstack/requirements,stable/ocata,I202078f5ca4ba6da4ab0ed52d97d41997674c1b4,Fixed wrong regular expression for vcs requirements,MERGED,2017-05-22 02:44:16.000000000,2017-06-19 05:52:21.000000000,2017-06-19 05:52:20.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 9656}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}, {'_account_id': 17130}]","[{'number': 1, 'created': '2017-05-22 02:44:16.000000000', 'files': ['openstack_requirements/tests/test_requirement.py', 'openstack_requirements/requirement.py'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f299a26c0be5615f112f64756f77d7bcdb1c252a', 'message': 'Fixed wrong regular expression for vcs requirements\n\nThe regular expression to parse requirement line is also used for\nconstrains files. However, it will not match those lines which\npoint to VCS, such as git+http or git+https which pypi accept.\n\nThis commit fixes the issue.\n\nDespite that we only need to change the RE to\n^(?P<url>\\s*(?:-e\\s)?\\s*(?:(?:git\\+)?(?:https|http)|file)://[^#]*)#\negg=(?P<name>[-\\.\\w]+)\nto fix the issue for git+http and git+https, pypi accepts more VCS\nURI schemes other than git. This patch also looses the match for\nthese cases to be accepted.\n\nChange-Id: I202078f5ca4ba6da4ab0ed52d97d41997674c1b4\n(cherry picked from commit f562496f7d7b5f2978d8f35cc738122666e45f1e)\n'}]",0,466570,f299a26c0be5615f112f64756f77d7bcdb1c252a,12,8,1,13158,,,0,"Fixed wrong regular expression for vcs requirements

The regular expression to parse requirement line is also used for
constrains files. However, it will not match those lines which
point to VCS, such as git+http or git+https which pypi accept.

This commit fixes the issue.

Despite that we only need to change the RE to
^(?P<url>\s*(?:-e\s)?\s*(?:(?:git\+)?(?:https|http)|file)://[^#]*)#
egg=(?P<name>[-\.\w]+)
to fix the issue for git+http and git+https, pypi accepts more VCS
URI schemes other than git. This patch also looses the match for
these cases to be accepted.

Change-Id: I202078f5ca4ba6da4ab0ed52d97d41997674c1b4
(cherry picked from commit f562496f7d7b5f2978d8f35cc738122666e45f1e)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/70/466570/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_requirements/tests/test_requirement.py', 'openstack_requirements/requirement.py']",2,f299a26c0be5615f112f64756f77d7bcdb1c252a,fix-editable-re, '^(?P<url>\s*(?:-e\s)?\s*(?:(?:[a-z]+\+)?(?:[a-z]+))://[^#]*)', '^(?P<url>\s*(?:-e\s)?\s*(?:(?:git+)?https|http|file)://[^#]*)',15,2
openstack%2Frequirements~stable%2Fnewton~I9870c747ae3c3b94f7e15f8a03f221488eafac13,openstack/requirements,stable/newton,I9870c747ae3c3b94f7e15f8a03f221488eafac13,bump appdirs to 1.4.3 so setuptools don't have to reinstall 1.4.0,MERGED,2017-04-08 01:01:03.000000000,2017-06-19 05:52:15.000000000,2017-06-19 05:52:15.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7102}, {'_account_id': 9656}, {'_account_id': 11904}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}, {'_account_id': 15674}, {'_account_id': 16643}, {'_account_id': 17130}]","[{'number': 1, 'created': '2017-04-08 01:01:03.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/72d180ee74f342368a0e908a6a8afbf249fc99a6', 'message': ""bump appdirs to 1.4.3 so setuptools don't have to reinstall 1.4.0\n\nthis setuptools bug [1] has caused appdirs reinstall to fail and\nthere is no estimate when setuptools is going to fix it. Moreover,\nwe will have to avoid each future setuptools version without the fix.\nAs an alternative we may be able to bump appdirs to 1.4.3 so it will\nnot have to be reinstalled to 1.4.0 and trigger this bug.\n\n[1] https://github.com/pypa/setuptools/issues/951\n\nChange-Id: I9870c747ae3c3b94f7e15f8a03f221488eafac13\n""}]",0,454927,72d180ee74f342368a0e908a6a8afbf249fc99a6,17,11,1,6671,,,0,"bump appdirs to 1.4.3 so setuptools don't have to reinstall 1.4.0

this setuptools bug [1] has caused appdirs reinstall to fail and
there is no estimate when setuptools is going to fix it. Moreover,
we will have to avoid each future setuptools version without the fix.
As an alternative we may be able to bump appdirs to 1.4.3 so it will
not have to be reinstalled to 1.4.0 and trigger this bug.

[1] https://github.com/pypa/setuptools/issues/951

Change-Id: I9870c747ae3c3b94f7e15f8a03f221488eafac13
",git fetch https://review.opendev.org/openstack/requirements refs/changes/27/454927/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,72d180ee74f342368a0e908a6a8afbf249fc99a6,bump_appdirs,appdirs===1.4.3,appdirs===1.4.0,1,1
openstack%2Fzun~master~Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f,openstack/zun,master,Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f,Add api-ref for container create,MERGED,2017-05-31 09:08:25.000000000,2017-06-19 05:48:42.000000000,2017-06-19 05:48:42.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 21785}, {'_account_id': 23055}]","[{'number': 1, 'created': '2017-05-31 09:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/4777f1bd33378d35b6dc551499ba5b9359a79812', 'message': '[WIP] Add api-ref for container create\n\nChange-Id: Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f\nPartial-Implements: bp zun-api-doc\n'}, {'number': 2, 'created': '2017-05-31 09:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/281670dfc5c1e4c8315aa92f9a9a8a8e26273268', 'message': 'Add api-ref for container create\n\nChange-Id: Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f\nPartial-Implements: bp zun-api-doc\n'}, {'number': 3, 'created': '2017-06-09 07:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/2449b22033949e4966781dc6c318e7dfd4a49324', 'message': 'Add api-ref for container create\n\nChange-Id: Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f\nPartial-Implements: bp zun-api-doc\n'}, {'number': 4, 'created': '2017-06-12 06:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/60ac98631945747e77023aff1bc9beac19ab559a', 'message': 'Add api-ref for container create\n\nChange-Id: Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f\nPartial-Implements: bp zun-api-doc\n'}, {'number': 5, 'created': '2017-06-14 08:45:11.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/samples/container-create-resp.json', 'api-ref/source/containers.inc', 'api-ref/source/samples/container-create-req.json', 'api-ref/source/services.inc'], 'web_link': 'https://opendev.org/openstack/zun/commit/4c524572affcded638e018d93681addf6fbac82c', 'message': 'Add api-ref for container create\n\nChange-Id: Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f\nPartial-Implements: bp zun-api-doc\n'}]",24,469386,4c524572affcded638e018d93681addf6fbac82c,24,5,5,10206,,,0,"Add api-ref for container create

Change-Id: Ib6df2694bff69cb18cb37f42e7aa7f4809b6ae6f
Partial-Implements: bp zun-api-doc
",git fetch https://review.opendev.org/openstack/zun refs/changes/86/469386/5 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/samples/container-create-resp.json', 'api-ref/source/containers.inc', 'api-ref/source/samples/container-create-req.json']",4,4777f1bd33378d35b6dc551499ba5b9359a79812,bp/zun-api-doc,"{ ""environment"":{ }, ""labels"":{ }, ""image"": ""cirros"", ""command"": ""ping -c 4 8.8.8.8"", ""name"": ""test"", ""cpu"": 2, ""memory"": 500, ""workdir"": null, ""image_pull_policy"": null, ""restart_policy"": null, ""interactive"": ""False"", ""image_driver"": ""docker"", ""security_groups"": null } ",,207,0
openstack%2Frequirements~master~Idd6c6b3c2f985b1948e9c94eb09ee92d19b1cbb6,openstack/requirements,master,Idd6c6b3c2f985b1948e9c94eb09ee92d19b1cbb6,update constraint for python-novaclient to new release 9.0.1,MERGED,2017-06-16 16:32:33.000000000,2017-06-19 05:46:43.000000000,2017-06-19 05:46:43.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-16 16:32:33.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/62e4ddf111076d2737fa33d9ab9bf6bd9cf34ec6', 'message': 'update constraint for python-novaclient to new release 9.0.1\n\nChange-Id: Idd6c6b3c2f985b1948e9c94eb09ee92d19b1cbb6\nmeta:version: 9.0.1\nmeta:diff-start: -\nmeta:series: pike\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Sean Dague <sean@dague.net>\nmeta:release:Commit: Sean Dague <sean@dague.net>\nmeta:release:Change-Id: Ia57c177377cf03b467003cad23898366c68847ab\nmeta:release:Code-Review+1: Matt Riedemann <mriedem.os@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,475023,62e4ddf111076d2737fa33d9ab9bf6bd9cf34ec6,11,3,1,11131,,,0,"update constraint for python-novaclient to new release 9.0.1

Change-Id: Idd6c6b3c2f985b1948e9c94eb09ee92d19b1cbb6
meta:version: 9.0.1
meta:diff-start: -
meta:series: pike
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Sean Dague <sean@dague.net>
meta:release:Commit: Sean Dague <sean@dague.net>
meta:release:Change-Id: Ia57c177377cf03b467003cad23898366c68847ab
meta:release:Code-Review+1: Matt Riedemann <mriedem.os@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/23/475023/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,62e4ddf111076d2737fa33d9ab9bf6bd9cf34ec6,new-release,python-novaclient===9.0.1,python-novaclient===9.0.0,1,1
openstack%2Fui-cookiecutter~master~I0c593e2369cdfac17f21c5c0a07d9e73246602d8,openstack/ui-cookiecutter,master,I0c593e2369cdfac17f21c5c0a07d9e73246602d8,Use tox_install.sh to handle Depends-On,MERGED,2017-05-26 07:38:13.000000000,2017-06-19 05:35:54.000000000,2017-06-19 05:35:54.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 16352}]","[{'number': 1, 'created': '2017-05-26 07:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ui-cookiecutter/commit/155fd1751c3055a4badaa5e9ddabfc496f79199f', 'message': 'Use tox_install.sh to handle Depends-On\n\nBy using zuul-cloner, developers can use Depends-On directive\nin a commit message to test cross-project dependency.\n\nChange-Id: I0c593e2369cdfac17f21c5c0a07d9e73246602d8\n'}, {'number': 2, 'created': '2017-05-29 03:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ui-cookiecutter/commit/d09185746e45529a7dc48c3ae8339e1c718bf085', 'message': 'Use tox_install.sh to handle Depends-On\n\nBy using zuul-cloner, developers can use Depends-On directive\nin a commit message to test cross-project dependency.\n\nChange-Id: I0c593e2369cdfac17f21c5c0a07d9e73246602d8\n'}, {'number': 3, 'created': '2017-05-31 12:19:08.000000000', 'files': ['{{cookiecutter.repo_name}}/tools/tox_install.sh', '{{cookiecutter.repo_name}}/test-requirements.txt', '{{cookiecutter.repo_name}}/tox.ini'], 'web_link': 'https://opendev.org/openstack/ui-cookiecutter/commit/9a3817576be38706c4c29831278f9941b0f78ee6', 'message': 'Use tox_install.sh to handle Depends-On\n\nBy using zuul-cloner, developers can use Depends-On directive\nin a commit message to test cross-project dependency.\n\nChange-Id: I0c593e2369cdfac17f21c5c0a07d9e73246602d8\n'}]",0,468297,9a3817576be38706c4c29831278f9941b0f78ee6,14,3,3,841,,,0,"Use tox_install.sh to handle Depends-On

By using zuul-cloner, developers can use Depends-On directive
in a commit message to test cross-project dependency.

Change-Id: I0c593e2369cdfac17f21c5c0a07d9e73246602d8
",git fetch https://review.opendev.org/openstack/ui-cookiecutter refs/changes/97/468297/1 && git format-patch -1 --stdout FETCH_HEAD,"['{{cookiecutter.repo_name}}/tools/tox_install.sh', '{{cookiecutter.repo_name}}/test-requirements.txt', '{{cookiecutter.repo_name}}/tox.ini']",3,155fd1751c3055a4badaa5e9ddabfc496f79199f,tox-install, BRANCH_NAME=master CLIENT_NAME={{cookiecutter.repo_name}}install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages} # os:* is handled by tox_install.sh os:openstack/horizon:horizon,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -U {opts} {packages},93,3
openstack%2Frequirements~master~I53d0ad2d3071a339496185efd77014a023cd2fa3,openstack/requirements,master,I53d0ad2d3071a339496185efd77014a023cd2fa3,Updated from generate-constraints,MERGED,2017-06-16 10:41:14.000000000,2017-06-19 05:34:42.000000000,2017-06-19 05:34:42.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 13404}]","[{'number': 1, 'created': '2017-06-16 10:41:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/2221b8397939128316db990887f0ff6f42a02799', 'message': 'Updated from generate-constraints\n\nChange-Id: I53d0ad2d3071a339496185efd77014a023cd2fa3\n'}, {'number': 2, 'created': '2017-06-17 10:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/5ba63a8468198fe1416cf1464f35a0d1d435e232', 'message': 'Updated from generate-constraints\n\nChange-Id: I53d0ad2d3071a339496185efd77014a023cd2fa3\n'}, {'number': 3, 'created': '2017-06-17 14:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/de39374d40838911a80c91fc0a55120f7944f3e6', 'message': 'Updated from generate-constraints\n\nChange-Id: I53d0ad2d3071a339496185efd77014a023cd2fa3\n'}, {'number': 4, 'created': '2017-06-18 10:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3793aef2afe21fbc0ab45ff5c5a0520b254bc31a', 'message': 'Updated from generate-constraints\n\nChange-Id: I53d0ad2d3071a339496185efd77014a023cd2fa3\n'}, {'number': 5, 'created': '2017-06-18 21:26:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6d9f1791f5d63bc5a6845232e30a6efaf9ab7cc1', 'message': 'Updated from generate-constraints\n\nChange-Id: I53d0ad2d3071a339496185efd77014a023cd2fa3\n'}]",2,474941,6d9f1791f5d63bc5a6845232e30a6efaf9ab7cc1,17,4,5,11131,,,0,"Updated from generate-constraints

Change-Id: I53d0ad2d3071a339496185efd77014a023cd2fa3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/41/474941/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,2221b8397939128316db990887f0ff6f42a02799,openstack/requirements/constraints,pysnmp===4.3.8pyroute2===0.4.16 kazoo===2.4.0unicodecsv===0.14.1requests===2.18.1botocore===1.5.69jsonpatch===1.16,pysnmp===4.3.3pyroute2===0.4.15 kazoo===2.3.1unicodecsv===0.14.1;python_version=='2.7'requests===2.17.3botocore===1.5.68jsonpatch===1.15,7,7
openstack%2Ftempest~master~I19bba38e11a3ab9d97a0caa0f73c14772e01c1bf,openstack/tempest,master,I19bba38e11a3ab9d97a0caa0f73c14772e01c1bf,Fix 4 bytes utf8 char test comment for create images,MERGED,2017-05-02 08:56:32.000000000,2017-06-19 05:27:24.000000000,2017-06-19 05:27:23.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-05-02 08:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/44a199988dff0b872a91b37956a33c7c7b76f536', 'message': ""Re-enable 4 bytes utf8 char test for create images\n\nThis commit re-enables the 4 bytes utf8 char test because the bug\n1370954 was already fixed. And the URL[1] in the comment was not correct\ndue to some changes. So let's re-enable the original test and test the 4\nbyte utf8 char.\n\n[1] http://www.fileformat.info/info/unicode/char/1F4A9/index.htm\n\nRelated-Bug: #1370954\nChange-Id: I19bba38e11a3ab9d97a0caa0f73c14772e01c1bf\n""}, {'number': 2, 'created': '2017-06-06 03:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5eb11a3998227187443aea3c4c5bbc350ba627ae', 'message': ""Re-enable 4 bytes utf8 char test for create images\n\nThis commit re-enables the 4 bytes utf8 char test because the bug\n1370954 was already fixed. And the URL[1] in the comment was not correct\ndue to some changes. So let's re-enable the original test and test the 4\nbyte utf8 char.\n\n[1] http://www.fileformat.info/info/unicode/char/1F4A9/index.htm\n\nRelated-Bug: #1370954\nChange-Id: I19bba38e11a3ab9d97a0caa0f73c14772e01c1bf\n""}, {'number': 3, 'created': '2017-06-09 03:29:10.000000000', 'files': ['tempest/api/compute/images/test_images_oneserver.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/00c448720e63d1075cbff2b3f26b810c3cd648af', 'message': ""Fix 4 bytes utf8 char test comment for create images\n\nThis commit fixes the 4 bytes utf8 char test comment. Because the bug\n1370954 was already fixed. However, nova and glance don't accept a 4\nbytes utf8 char, yet. And also, the URL[1] in the comment isn't correct,\neither, anymore. So this commit also fixes the URL, too.\n\n[1] http://www.fileformat.info/info/unicode/char/1F4A9/index.htm\n\nRelated-Bug: #1370954\nChange-Id: I19bba38e11a3ab9d97a0caa0f73c14772e01c1bf\n""}]",0,461684,00c448720e63d1075cbff2b3f26b810c3cd648af,18,5,3,5689,,,0,"Fix 4 bytes utf8 char test comment for create images

This commit fixes the 4 bytes utf8 char test comment. Because the bug
1370954 was already fixed. However, nova and glance don't accept a 4
bytes utf8 char, yet. And also, the URL[1] in the comment isn't correct,
either, anymore. So this commit also fixes the URL, too.

[1] http://www.fileformat.info/info/unicode/char/1F4A9/index.htm

Related-Bug: #1370954
Change-Id: I19bba38e11a3ab9d97a0caa0f73c14772e01c1bf
",git fetch https://review.opendev.org/openstack/tempest refs/changes/84/461684/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/images/test_images_oneserver.py'],1,44a199988dff0b872a91b37956a33c7c7b76f536,bug/1370954, utf8_name = data_utils.rand_name(b'\xf0\x9f\x92\xa9'.decode('utf-8')), # We use a string with 3 byte utf-8 character due to bug # #1370954 in glance which will 500 if mysql is used as the # backend and it attempts to store a 4 byte utf-8 character utf8_name = data_utils.rand_name(b'\xe2\x82\xa1'.decode('utf-8')),1,5
openstack%2Freleases~master~Ia9646b7e6dd8386616c1286c8b613bd40cc8e583,openstack/releases,master,Ia9646b7e6dd8386616c1286c8b613bd40cc8e583,Release Octavia stable/newton and stable/ocata,MERGED,2017-05-13 00:39:44.000000000,2017-06-19 05:17:51.000000000,2017-06-19 05:17:51.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 11628}, {'_account_id': 12898}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-05-13 00:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/8cbd8273a11d355505b12635285d5cbcc05fec4f', 'message': 'Release Octavia stable/newton and stable/ocata\n\nFor stable/newton:\nneutron-lbaas: 9.3.0\noctavia: 0.9.2\n\nFor stable/ocata:\nneutron-lbaas: 10.1.0\noctavia: 0.10.1\n\nChange-Id: Ia9646b7e6dd8386616c1286c8b613bd40cc8e583\n'}, {'number': 2, 'created': '2017-06-07 22:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b3b3303b5c7343fd2679a9744343ccf662b962de', 'message': 'Release Octavia stable/newton and stable/ocata\n\nFor stable/newton:\nneutron-lbaas: 9.2.1\n\nFor stable/ocata:\nneutron-lbaas: 10.0.1\n\nChange-Id: Ia9646b7e6dd8386616c1286c8b613bd40cc8e583\n'}, {'number': 3, 'created': '2017-06-07 22:32:29.000000000', 'files': ['deliverables/ocata/neutron-lbaas.yaml', 'deliverables/newton/neutron-lbaas.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/99e1fa0f562a31bb74d016f5b575ceace1b5d3a7', 'message': 'Release Octavia stable/newton and stable/ocata\n\nFor stable/newton:\nneutron-lbaas: 9.2.1\n\nFor stable/ocata:\nneutron-lbaas: 10.0.1\n\nChange-Id: Ia9646b7e6dd8386616c1286c8b613bd40cc8e583\n'}]",4,464281,99e1fa0f562a31bb74d016f5b575ceace1b5d3a7,16,5,3,11628,,,0,"Release Octavia stable/newton and stable/ocata

For stable/newton:
neutron-lbaas: 9.2.1

For stable/ocata:
neutron-lbaas: 10.0.1

Change-Id: Ia9646b7e6dd8386616c1286c8b613bd40cc8e583
",git fetch https://review.opendev.org/openstack/releases refs/changes/81/464281/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/newton/octavia.yaml', 'deliverables/ocata/neutron-lbaas.yaml', 'deliverables/newton/neutron-lbaas.yaml', 'deliverables/ocata/octavia.yaml']",4,8cbd8273a11d355505b12635285d5cbcc05fec4f,, - version: 0.10.1 projects: - repo: openstack/octavia hash: de9fdf3e553f4bd3006217898b74b8c06ce2c176 highlights: |- * Updates for RHEL based distros * Updates for changes in neutron * Updates for changes in tempest * Fixed failover logic when using anit-affinity,,39,0
openstack%2Fmagnum-ui~master~Ic85b544a5d91f0f820737480fd123cbebdc94894,openstack/magnum-ui,master,Ic85b544a5d91f0f820737480fd123cbebdc94894,Fix html_last_updated_fmt for Python3,MERGED,2017-06-16 07:27:02.000000000,2017-06-19 04:43:18.000000000,2017-06-19 04:43:18.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 16352}]","[{'number': 1, 'created': '2017-06-16 07:27:02.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/65f76051d5bf2783b6825c733f217f03ef537f78', 'message': 'Fix html_last_updated_fmt for Python3\n\nhtml_last_updated_fmt option is interpreted as a\nbyte string in python3, causing Sphinx build to break.\nThis patch makes it utf-8 string.\n\nChange-Id: Ic85b544a5d91f0f820737480fd123cbebdc94894\n'}]",0,474875,65f76051d5bf2783b6825c733f217f03ef537f78,7,3,1,25903,,,0,"Fix html_last_updated_fmt for Python3

html_last_updated_fmt option is interpreted as a
byte string in python3, causing Sphinx build to break.
This patch makes it utf-8 string.

Change-Id: Ic85b544a5d91f0f820737480fd123cbebdc94894
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/75/474875/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,65f76051d5bf2783b6825c733f217f03ef537f78,html_last_updated_fmt,html_last_updated_fmt = subprocess.check_output(git_cmd).decode('utf-8'),"html_last_updated_fmt = subprocess.check_output(git_cmd, stdin=subprocess.PIPE)",1,2
openstack%2Fnetworking-midonet~master~I801f1cd0e09e18d6132df88d041d432485a4c8bb,openstack/networking-midonet,master,I801f1cd0e09e18d6132df88d041d432485a4c8bb,"Revert ""devstack: Switch to MidoNet 5.4""",MERGED,2017-06-05 02:53:59.000000000,2017-06-19 04:24:58.000000000,2017-06-05 09:54:52.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 9925}, {'_account_id': 19307}]","[{'number': 1, 'created': '2017-06-05 02:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/77470e94b99f8f4d6532d375418b5f898b7b72e0', 'message': 'Revert ""devstack: Switch to MidoNet 5.4""\n\nThis reverts commit 7173c86b53578a5c9d4a7af427f931ef12c65d3a.\n\nIt was not intended for merge.\n\nChange-Id: I801f1cd0e09e18d6132df88d041d432485a4c8bb\n'}, {'number': 2, 'created': '2017-06-05 02:59:28.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/48206f2aff5e11b7a7df80cdf839fddc7adee63f', 'message': 'Revert ""devstack: Switch to MidoNet 5.4""\n\nThis reverts commit 7173c86b53578a5c9d4a7af427f931ef12c65d3a.\n\nIt was not intended for merge.\n\nChange-Id: I801f1cd0e09e18d6132df88d041d432485a4c8bb\n'}]",0,470820,48206f2aff5e11b7a7df80cdf839fddc7adee63f,12,4,2,6854,,,0,"Revert ""devstack: Switch to MidoNet 5.4""

This reverts commit 7173c86b53578a5c9d4a7af427f931ef12c65d3a.

It was not intended for merge.

Change-Id: I801f1cd0e09e18d6132df88d041d432485a4c8bb
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/20/470820/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,77470e94b99f8f4d6532d375418b5f898b7b72e0,midonet-5.4,MIDONET_DEB_URI=${MIDONET_DEB_URI:-http://builds.midonet.org/devstack}MIDONET_BRANCH=${MIDONET_BRANCH:-master},MIDONET_DEB_URI=${MIDONET_DEB_URI:-http://builds.midonet.org/midonet-5.4}MIDONET_BRANCH=${MIDONET_BRANCH:-staging/v5.4},2,2
openstack%2Fpuppet-magnum~master~Ibce35dc916bc78394be50e96f008a39eb945a52a,openstack/puppet-magnum,master,Ibce35dc916bc78394be50e96f008a39eb945a52a,Add environment variable,MERGED,2017-06-12 07:55:02.000000000,2017-06-19 04:24:14.000000000,2017-06-19 04:24:14.000000000,"[{'_account_id': 3}, {'_account_id': 9414}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-12 07:55:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/9699bd1b03302cc6e09e9cc3147cd4a7f88c74a5', 'message': 'Add environment variable\n\nAdd environment variable {toxinidir} in tox.ini\n\nChange-Id: Ibce35dc916bc78394be50e96f008a39eb945a52a\n'}]",0,473268,9699bd1b03302cc6e09e9cc3147cd4a7f88c74a5,11,3,1,9414,,,0,"Add environment variable

Add environment variable {toxinidir} in tox.ini

Change-Id: Ibce35dc916bc78394be50e96f008a39eb945a52a
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/68/473268/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9699bd1b03302cc6e09e9cc3147cd4a7f88c74a5,update_tox,deps = -r{toxinidir}/test-requirements.txt,deps = -rtest-requirements.txt,1,1
openstack%2Frequirements~stable%2Fnewton~I8e4a16fd231d1d8077a6e66499c928be60885b7c,openstack/requirements,stable/newton,I8e4a16fd231d1d8077a6e66499c928be60885b7c,block kombu 4.0.2,ABANDONED,2016-12-18 13:54:30.000000000,2017-06-19 04:23:44.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7109}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}, {'_account_id': 22093}]","[{'number': 1, 'created': '2016-12-18 13:54:30.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f159134dba0103e341f1d9e31f058912d9f497f1', 'message': 'block kombu 4.0.2\n\nsame breakage as kombu 4.0.0 and 4.0.1\n\nbackported to stable/newton\n\nChange-Id: I8e4a16fd231d1d8077a6e66499c928be60885b7c\nRelated-Bug: #1638263\n'}]",1,412220,f159134dba0103e341f1d9e31f058912d9f497f1,18,7,1,22093,,,0,"block kombu 4.0.2

same breakage as kombu 4.0.0 and 4.0.1

backported to stable/newton

Change-Id: I8e4a16fd231d1d8077a6e66499c928be60885b7c
Related-Bug: #1638263
",git fetch https://review.opendev.org/openstack/requirements refs/changes/20/412220/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,f159134dba0103e341f1d9e31f058912d9f497f1,bug/1638263,"kombu>=3.0.25,!=4.0.0,!=4.0.1,!=4.0.2 # BSD","kombu>=3.0.25,!=4.0.0,!=4.0.1 # BSD",1,1
openstack%2Frelease-tools~master~Iafd2309e06db4fe28338b68c7a3e147bfa333c0c,openstack/release-tools,master,Iafd2309e06db4fe28338b68c7a3e147bfa333c0c,README: Rename --no_dry_run to --no-dry-run,MERGED,2017-06-16 14:48:16.000000000,2017-06-19 04:09:28.000000000,2017-06-19 04:09:28.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-06-16 14:48:16.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/1adce5bd0a36ce57fc83cbea3416aad1eb408bf3', 'message': ""README: Rename --no_dry_run to --no-dry-run\n\nThe actual argument is --no-dry-run, let's fix it in doc.\n\nChange-Id: Iafd2309e06db4fe28338b68c7a3e147bfa333c0c\n""}]",0,474995,1adce5bd0a36ce57fc83cbea3416aad1eb408bf3,7,3,1,3153,,,0,"README: Rename --no_dry_run to --no-dry-run

The actual argument is --no-dry-run, let's fix it in doc.

Change-Id: Iafd2309e06db4fe28338b68c7a3e147bfa333c0c
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/95/474995/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1adce5bd0a36ce57fc83cbea3416aad1eb408bf3,docfix, ./expire_old_bug_reports.py nova --no-dry-run ./expire_old_bug_reports.py nova --no-dry-run --credentials-file cred.txt ./expire_old_bug_reports.py nova --no-dry-run, ./expire_old_bug_reports.py nova --no_dry_run ./expire_old_bug_reports.py nova --no_dry_run --credentials-file cred.txt ./expire_old_bug_reports.py nova --no_dry_run,3,3
openstack%2Fos-brick~master~I146a74f9f79c68a89677b9b26a324e06a35886f2,openstack/os-brick,master,I146a74f9f79c68a89677b9b26a324e06a35886f2,Add open-iscsi manual scan support,MERGED,2017-04-10 17:08:40.000000000,2017-06-19 04:07:21.000000000,2017-06-16 18:00:48.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12924}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 15941}, {'_account_id': 16595}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17450}, {'_account_id': 19852}, {'_account_id': 22248}, {'_account_id': 22700}, {'_account_id': 22796}, {'_account_id': 24502}, {'_account_id': 25608}]","[{'number': 1, 'created': '2017-04-10 17:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/0d6a4eb2c64ff1f53e82b55a380860e3c02b3d8c', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 2, 'created': '2017-04-11 12:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/1b8698e4f4300162b8ca1f01059536d50d225e07', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 3, 'created': '2017-04-11 17:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/4430fef830fa519b4a93c8f1d3895b8d463cd652', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 4, 'created': '2017-04-12 06:56:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/c9e71d8041c3063bc792a64e0f31ad6c34b61a4e', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 5, 'created': '2017-04-12 07:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6185c0609ffc07b8da88236ccc1c897c907b2d69', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 6, 'created': '2017-04-12 18:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/9caeb810465c3b279d4a6f14e0e648f7d6bc3703', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 7, 'created': '2017-04-13 11:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/89d58ed2f6b158e9803013cb1685cd48145d3ef4', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 8, 'created': '2017-04-19 11:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/3ad34213e49fe88c94927808570e06e5bb940c28', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 9, 'created': '2017-04-21 09:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/21bc5c611f9446f4f15e287d09baedd6800a79cd', 'message': 'WIP: Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 10, 'created': '2017-05-22 15:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/dd671bf973717b6411b706557d7c70dd75311dcd', 'message': 'Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nManual scans are enabled setting `node.session.scan` to `manual`.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 11, 'created': '2017-05-31 10:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/c86e60b70039e10a9e65720cd6f6851012dfc304', 'message': 'Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nManual scans are enabled setting `node.session.scan` to `manual`.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 12, 'created': '2017-05-31 12:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/3a8ef387ae6922f8b0141aa33ccba1c6b2e26dfa', 'message': 'Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nManual scans are enabled setting `node.session.scan` to `manual`.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 13, 'created': '2017-05-31 14:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6c576e4b71ce09523829ad00898e8ae197b0d288', 'message': 'Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nManual scans are enabled setting `node.session.scan` to `manual`.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 14, 'created': '2017-06-15 14:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/2697ed712b0c4702949572c36c3911895e7ba7fb', 'message': 'Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nManual scans are enabled setting `node.session.scan` to `manual`.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}, {'number': 15, 'created': '2017-06-16 14:12:14.000000000', 'files': ['releasenotes/notes/iscsi_manual_scan_support-d64a1c3c8e1986b4.yaml', 'os_brick/tests/initiator/connectors/test_iscsi.py', 'os_brick/initiator/connectors/iscsi.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/f67d46c5383b3c454f365b653a36d3cd043a7814', 'message': 'Add open-iscsi manual scan support\n\nIt was recently added to open-iscsi the functionality to disable\nautomatic LUN scans on iscsid start, on login, and on reception of\nAEN/AER messages reporting LUN data has changed.\n\nThose 3 cases were one of the causes why Nova-CPU and Cinder-Volumes\nnodes would have unexpected devices.  With this new feature we can\nprevent them from appearing unnexpectedly.\n\nThis patch adds the mechanism required to configure our sessions for\nmanual scans in a backward compatible way.\n\nManual scans are enabled setting `node.session.scan` to `manual`.\n\nChange-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2\n'}]",0,455394,f67d46c5383b3c454f365b653a36d3cd043a7814,182,25,15,9535,,,0,"Add open-iscsi manual scan support

It was recently added to open-iscsi the functionality to disable
automatic LUN scans on iscsid start, on login, and on reception of
AEN/AER messages reporting LUN data has changed.

Those 3 cases were one of the causes why Nova-CPU and Cinder-Volumes
nodes would have unexpected devices.  With this new feature we can
prevent them from appearing unnexpectedly.

This patch adds the mechanism required to configure our sessions for
manual scans in a backward compatible way.

Manual scans are enabled setting `node.session.scan` to `manual`.

Change-Id: I146a74f9f79c68a89677b9b26a324e06a35886f2
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/94/455394/11 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/iscsi_manual_scan_support-d64a1c3c8e1986b4.yaml', 'os_brick/initiator/connectors/iscsi.py']",2,0d6a4eb2c64ff1f53e82b55a380860e3c02b3d8c,refactor/multipath," session, manual_scan = self._connect_to_iscsi_portal(props) # but on manual scan mode we have to do it ourselves. if retry > 1 or manual_scan: out, err = self._run_iscsiadm(connection_properties, (), check_exit_code=(0, 21, 255)) # Try to set the scan mode to manual res = self._iscsiadm_update(connection_properties, 'node.session.scan', 'manual', check_exit_code=False) manual_scan = not res[1] else: manual_scan = 'node.session.scan = manual' in out return s[1], manual_scan return None, None"," session = self._connect_to_iscsi_portal(props) if retry > 1: err = self._run_iscsiadm(connection_properties, (), check_exit_code=(0, 21, 255))[1] return s[1] return None",25,6
openstack%2Ftempest~master~I381600fe7f3c1ee00c84033699f6534e9e873ef5,openstack/tempest,master,I381600fe7f3c1ee00c84033699f6534e9e873ef5,Updated from global requirements,MERGED,2017-06-10 21:50:50.000000000,2017-06-19 04:04:20.000000000,2017-06-19 04:04:20.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-06-10 21:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/50bc5b89d22f684bfef7f33981c2b58810b45a57', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 2, 'created': '2017-06-12 12:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8374b6fe2cad718ac281074f5d49b785223e3453', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 3, 'created': '2017-06-13 11:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e93e5f7c64f4359b54141156cc841d7eaaf5cf24', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 4, 'created': '2017-06-13 13:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/871347387fb9cdec53f3905aaffede14fc8f62b1', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 5, 'created': '2017-06-14 00:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fecd2b20e5e029881f734c55a50db7f8717efe27', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 6, 'created': '2017-06-14 13:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e0e1124a9cfce283bef4eabbb0e1fe9584b76cb', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 7, 'created': '2017-06-15 15:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0e133504789446f632fbcf506d88280071fa0abf', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 8, 'created': '2017-06-15 16:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e74112f6c8420b45ab9f0c0aa8de1415f2dba304', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 9, 'created': '2017-06-15 22:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e48f2442f47931838bccf125ab25deb3ff8ba173', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}, {'number': 10, 'created': '2017-06-16 05:35:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d1fb3e82fd413c1f10b386db0f2a162dbf907395', 'message': 'Updated from global requirements\n\nChange-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5\n'}]",0,473047,d1fb3e82fd413c1f10b386db0f2a162dbf907395,36,6,10,11131,,,0,"Updated from global requirements

Change-Id: I381600fe7f3c1ee00c84033699f6534e9e873ef5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/47/473047/7 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,50bc5b89d22f684bfef7f33981c2b58810b45a57,openstack/requirements,urllib3>=1.21.1 # MIT,urllib3>=1.15.1 # MIT,1,1
openstack%2Fsearchlight~master~I54bbd72627faa60f35368ab09585f082e6d02f54,openstack/searchlight,master,I54bbd72627faa60f35368ab09585f082e6d02f54,Updated from global requirements,MERGED,2017-06-08 16:29:15.000000000,2017-06-19 03:27:42.000000000,2017-06-19 03:27:42.000000000,"[{'_account_id': 3}, {'_account_id': 15888}]","[{'number': 1, 'created': '2017-06-08 16:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/c4e9159c9f5dd8425483ad8331da389642f2c164', 'message': 'Updated from global requirements\n\nChange-Id: I54bbd72627faa60f35368ab09585f082e6d02f54\n'}, {'number': 2, 'created': '2017-06-09 20:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/d466670e75ebefb64f69909761873a47b8f951d4', 'message': 'Updated from global requirements\n\nChange-Id: I54bbd72627faa60f35368ab09585f082e6d02f54\n'}, {'number': 3, 'created': '2017-06-10 13:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/8bfc33ee6b45261d75bc13960c80c5a36b44ef56', 'message': 'Updated from global requirements\n\nChange-Id: I54bbd72627faa60f35368ab09585f082e6d02f54\n'}, {'number': 4, 'created': '2017-06-10 21:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/84f59911a6feb7a461b1a5ce74d557d77fe1ca9b', 'message': 'Updated from global requirements\n\nChange-Id: I54bbd72627faa60f35368ab09585f082e6d02f54\n'}, {'number': 5, 'created': '2017-06-15 15:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/searchlight/commit/1a60201527dcad9a32f4bd856319e7acf1730e36', 'message': 'Updated from global requirements\n\nChange-Id: I54bbd72627faa60f35368ab09585f082e6d02f54\n'}, {'number': 6, 'created': '2017-06-15 16:35:53.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/e126d5515193fd0d7457dc55e60a5e731c77edee', 'message': 'Updated from global requirements\n\nChange-Id: I54bbd72627faa60f35368ab09585f082e6d02f54\n'}]",0,472331,e126d5515193fd0d7457dc55e60a5e731c77edee,15,2,6,11131,,,0,"Updated from global requirements

Change-Id: I54bbd72627faa60f35368ab09585f082e6d02f54
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/31/472331/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c4e9159c9f5dd8425483ad8331da389642f2c164,openstack/requirements,python-novaclient>=9.0.0 # Apache-2.0,python-novaclient>=7.1.0 # Apache-2.0,1,1
openstack%2Fcinder~master~I5f469c809dfb16e52d6298c4aa13a30c27ee56f9,openstack/cinder,master,I5f469c809dfb16e52d6298c4aa13a30c27ee56f9,"[BugFix] Add 'all_tenants', 'project_id' in attachment-list",MERGED,2017-03-25 14:51:05.000000000,2017-06-19 03:05:17.000000000,2017-03-29 11:28:09.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9562}, {'_account_id': 12778}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 16422}, {'_account_id': 18444}, {'_account_id': 18883}, {'_account_id': 22248}, {'_account_id': 24230}, {'_account_id': 24815}, {'_account_id': 25243}]","[{'number': 1, 'created': '2017-03-25 14:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9a9dae2233f6d16a583756c26effb9e062d2fbcc', 'message': ""[BugFix] Add 'all_tenants', 'project_id' in attachment-list\n\nThere are some issues around new attach/detach API/CLI,\nfix them step by step. This patch adds 'all_tenants',\n'project_id' support in attachment-list along with these\nmodifications:\n\n1. Don't throw errors when have invalid filters and\n   don't check filters when is admin context.\n2. Don't apply filters again when query already applied\n   limit and offset.\n\nChange-Id: I5f469c809dfb16e52d6298c4aa13a30c27ee56f9\nCloses-Bug: #1675974\n""}, {'number': 2, 'created': '2017-03-25 15:05:56.000000000', 'files': ['releasenotes/notes/support-tenants-project-in-attachment-list-3edd8g138a28s4r8.yaml', 'cinder/api/v3/attachments.py', 'cinder/tests/unit/api/v3/test_attachments.py', 'cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9bb85f24de6075f3fca08705659021d8e1c35fb5', 'message': ""[BugFix] Add 'all_tenants', 'project_id' in attachment-list\n\nThere are some issues around new attach/detach API/CLI,\nfix them step by step. This patch adds 'all_tenants',\n'project_id' support in attachment-list along with these\nmodifications:\n\n1. Don't throw errors when have invalid filters and\n   don't check filters when is admin context.\n2. Don't apply filters again when query already applied\n   limit and offset.\n\nChange-Id: I5f469c809dfb16e52d6298c4aa13a30c27ee56f9\nCloses-Bug: #1675974\n""}]",0,449939,9bb85f24de6075f3fca08705659021d8e1c35fb5,79,15,2,23083,,,0,"[BugFix] Add 'all_tenants', 'project_id' in attachment-list

There are some issues around new attach/detach API/CLI,
fix them step by step. This patch adds 'all_tenants',
'project_id' support in attachment-list along with these
modifications:

1. Don't throw errors when have invalid filters and
   don't check filters when is admin context.
2. Don't apply filters again when query already applied
   limit and offset.

Change-Id: I5f469c809dfb16e52d6298c4aa13a30c27ee56f9
Closes-Bug: #1675974
",git fetch https://review.opendev.org/openstack/cinder refs/changes/39/449939/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v3/attachments.py', 'releasenotes/notes/support-tenants-project-in-attachment-list-3edd8g138a28s4r8.yaml', 'cinder/tests/unit/api/v3/test_attachments.py', 'cinder/db/sqlalchemy/api.py']",4,9a9dae2233f6d16a583756c26effb9e062d2fbcc,bug/1675974," filters, exclude_list=['project_id']): project_id = filters.pop('project_id', None) if project_id: volume = models.Volume query = query.filter(volume.id == models.VolumeAttachment.volume_id, volume.project_id == project_id) "," project_id = filters.pop('project_id', None) if filters else None filters): query = query.options(joinedload('volume')) if project_id: query = query.filter(models.Volume.project_id == project_id) ",62,23
openstack%2Fproject-config~master~I53c839f300f18972e2c7f5ad51953ab1668a1c72,openstack/project-config,master,I53c839f300f18972e2c7f5ad51953ab1668a1c72,Fix unbound logging config syntax,MERGED,2017-06-19 02:19:18.000000000,2017-06-19 03:00:21.000000000,2017-06-19 03:00:21.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2017-06-19 02:19:18.000000000', 'files': ['nodepool/elements/nodepool-base/finalise.d/89-unbound'], 'web_link': 'https://opendev.org/openstack/project-config/commit/25df1d35cd487b67b83b922124bbdb1646754f01', 'message': 'Fix unbound logging config syntax\n\nAs a follow-on to Ib248c02b789cce1bc11fac27940e11b767c33399, this\nneeds to be under the ""server:"" tag else we get syntax errors starting\nunbound.\n\nChange-Id: I53c839f300f18972e2c7f5ad51953ab1668a1c72\n'}]",0,475209,25df1d35cd487b67b83b922124bbdb1646754f01,7,3,1,7118,,,0,"Fix unbound logging config syntax

As a follow-on to Ib248c02b789cce1bc11fac27940e11b767c33399, this
needs to be under the ""server:"" tag else we get syntax errors starting
unbound.

Change-Id: I53c839f300f18972e2c7f5ad51953ab1668a1c72
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/475209/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/elements/nodepool-base/finalise.d/89-unbound'],1,25df1d35cd487b67b83b922124bbdb1646754f01,unbound-syntax,"server: logfile: ""/var/log/unbound.log"" # Log only errors verbosity: 0","logfile: ""/var/log/unbound.log"" # Log only errors verbosity: 0",4,3
openstack%2Fpuppet-magnum~master~I9d3f0c133ea76acb3ff4fdec179f4100bf68cb32,openstack/puppet-magnum,master,I9d3f0c133ea76acb3ff4fdec179f4100bf68cb32,oslo policy: check puppet resource instead of actual config in spec,MERGED,2017-05-23 07:14:14.000000000,2017-06-19 02:59:28.000000000,2017-06-19 02:59:28.000000000,"[{'_account_id': 3}, {'_account_id': 14985}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-05-23 07:14:14.000000000', 'files': ['spec/classes/magnum_policy_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/358a9d43883bca096b8b503e24bec3bf78bc936f', 'message': 'oslo policy: check puppet resource instead of actual config in spec\n\nChange-Id: I9d3f0c133ea76acb3ff4fdec179f4100bf68cb32\n'}]",0,467044,358a9d43883bca096b8b503e24bec3bf78bc936f,35,3,1,9414,,,0,"oslo policy: check puppet resource instead of actual config in spec

Change-Id: I9d3f0c133ea76acb3ff4fdec179f4100bf68cb32
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/44/467044/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/magnum_policy_spec.rb'],1,358a9d43883bca096b8b503e24bec3bf78bc936f,standard-oslo-policy-params," is_expected.to contain_oslo__policy('magnum_config').with( :policy_file => '/etc/magnum/policy.json', )", is_expected.to contain_magnum_config('oslo_policy/policy_file').with_value('/etc/magnum/policy.json'),3,1
openstack%2Ftacker~master~Ife9936ed7c2f9f6d621cd6f1949ec4211eec5b1e,openstack/tacker,master,Ife9936ed7c2f9f6d621cd6f1949ec4211eec5b1e,"Fix ""cannot import name abstract_driver"" error in tox -e docs.",MERGED,2017-06-13 14:52:30.000000000,2017-06-19 02:44:18.000000000,2017-06-19 02:44:18.000000000,"[{'_account_id': 3}, {'_account_id': 2874}]","[{'number': 1, 'created': '2017-06-13 14:52:30.000000000', 'files': ['tacker/nfvo/drivers/vnffg/sfc_drivers/noop.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/63aca9306a3e31f8df99c4caebb889d83c5d4119', 'message': 'Fix ""cannot import name abstract_driver"" error in tox -e docs.\n\nWhen doing tox -v -e docs, we got exception:\n  File ""/opt/stack/tacker/tacker/nfvo/drivers/vnffg/sfc_drivers/noop.py"", line 20, in <module>\n    from tacker.nfvo.drivers.vnffg.sfc_drivers import abstract_driver\nImportError: cannot import name abstract_driver\n\nChange-Id: Ife9936ed7c2f9f6d621cd6f1949ec4211eec5b1e\nCloses-bug: #1697710\n'}]",0,473869,63aca9306a3e31f8df99c4caebb889d83c5d4119,6,2,1,19644,,,0,"Fix ""cannot import name abstract_driver"" error in tox -e docs.

When doing tox -v -e docs, we got exception:
  File ""/opt/stack/tacker/tacker/nfvo/drivers/vnffg/sfc_drivers/noop.py"", line 20, in <module>
    from tacker.nfvo.drivers.vnffg.sfc_drivers import abstract_driver
ImportError: cannot import name abstract_driver

Change-Id: Ife9936ed7c2f9f6d621cd6f1949ec4211eec5b1e
Closes-bug: #1697710
",git fetch https://review.opendev.org/openstack/tacker refs/changes/69/473869/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/nfvo/drivers/vnffg/sfc_drivers/noop.py'],1,63aca9306a3e31f8df99c4caebb889d83c5d4119,bug/1697710,from tacker.nfvo.drivers.vnffg import abstract_vnffg_driverclass VNFFGNoop(abstract_vnffg_driver.VnffgAbstractDriver):,from tacker.nfvo.drivers.vnffg.sfc_drivers import abstract_driverclass VNFFGNoop(abstract_driver.SfcAbstractDriver):,2,2
openstack%2Ftacker~master~I78c33d61ff92ec82f34f0720ed752ffc270d5c52,openstack/tacker,master,I78c33d61ff92ec82f34f0720ed752ffc270d5c52,Updated from global requirements,MERGED,2017-06-08 16:29:49.000000000,2017-06-19 02:43:49.000000000,2017-06-19 02:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 12455}, {'_account_id': 13380}, {'_account_id': 16237}, {'_account_id': 19644}]","[{'number': 1, 'created': '2017-06-08 16:29:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/6d0ef90b3471de8ddd6e2c0c9b5d99222ce1c582', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}, {'number': 2, 'created': '2017-06-09 20:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/4e398f89c5296d510fbdf38d578bab4d40fad0d5', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}, {'number': 3, 'created': '2017-06-10 13:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/153ded109f45ac82b5b2daba4fe3ca67aef73019', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}, {'number': 4, 'created': '2017-06-10 21:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/0828119a5a73daa4a0dd2209a79bb591ab110e4b', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}, {'number': 5, 'created': '2017-06-12 12:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/0ab3ad5a306a2546e510857ff6380709ce034f74', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}, {'number': 6, 'created': '2017-06-15 15:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/8503e481bb46f68573cd68044cd5b873103e161e', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}, {'number': 7, 'created': '2017-06-15 16:36:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tacker/commit/22768a2ab8741b411f9c8b679c71097ca53f79d8', 'message': 'Updated from global requirements\n\nChange-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52\n'}]",0,472332,22768a2ab8741b411f9c8b679c71097ca53f79d8,23,6,7,11131,,,0,"Updated from global requirements

Change-Id: I78c33d61ff92ec82f34f0720ed752ffc270d5c52
",git fetch https://review.opendev.org/openstack/tacker refs/changes/32/472332/7 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6d0ef90b3471de8ddd6e2c0c9b5d99222ce1c582,openstack/requirements,python-novaclient>=9.0.0 # Apache-2.0,python-novaclient>=7.1.0 # Apache-2.0,1,1
openstack%2Fnetworking-generic-switch~master~I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb,openstack/networking-generic-switch,master,I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb,huawei switch don't support command enable.,ABANDONED,2017-06-13 01:52:52.000000000,2017-06-19 02:20:54.000000000,,"[{'_account_id': 3}, {'_account_id': 14525}, {'_account_id': 21114}]","[{'number': 1, 'created': '2017-06-13 01:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/a0cbafae792eaa2bbbb034c4099eaebac68d9c19', 'message': ""huawei switch don't support command enable.\n\ndetail:\n    reconstruct the class Huawei and rewrite the method\n    send_commands_to_device.\n\nChange-Id: I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb\nClose-bug: #1697440\n""}, {'number': 2, 'created': '2017-06-13 02:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/5d075dd2e3b195f35da0a8f4d0dd87841eae3c35', 'message': ""huawei switch don't support command enable.\n\ndetail:\n    reconstruct the class Huawei and rewrite the method\n    send_commands_to_device.\n\nChange-Id: I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb\nClose-bug: #1697440\n""}, {'number': 3, 'created': '2017-06-13 09:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/b89847e1f02d99fb7a85a163fc4992c422d3266d', 'message': ""huawei switch don't support command enable.\n\ndetail:\n    modify the method send_commands_to_device.\n\nChange-Id: I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb\nClose-bug: #1697440\n""}, {'number': 4, 'created': '2017-06-14 01:42:53.000000000', 'files': ['networking_generic_switch/devices/netmiko_devices/huawei.py', 'networking_generic_switch/devices/netmiko_devices/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/665a1eb11e7162f6175a8e735526dfd4a68687aa', 'message': ""huawei switch don't support command enable.\n\ndetail:\n    modify the method send_commands_to_device.\n\nChange-Id: I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb\nClose-bug: #1697440\n""}]",1,473647,665a1eb11e7162f6175a8e735526dfd4a68687aa,12,3,4,21114,,,0,"huawei switch don't support command enable.

detail:
    modify the method send_commands_to_device.

Change-Id: I146b0e1b80033cbc7c80b0c928d4b7d1b05ac1fb
Close-bug: #1697440
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/47/473647/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_generic_switch/devices/netmiko_devices/huawei.py'],1,a0cbafae792eaa2bbbb034c4099eaebac68d9c19,bug/1697440,"from oslo_log import log as logging from networking_generic_switch.devices import netmiko_devices from networking_generic_switch import exceptions as exc LOG = logging.getLogger(__name__) def send_commands_to_device(self, cmd_set): if not cmd_set: LOG.debug(""Nothing to execute"") return with self._get_connection() as net_connect: try: net_connect.enable() output = net_connect.send_config_set(config_commands=cmd_set) # NOTE (vsaienko) always save configuration when configuration # is applied successfully. if self.SAVE_CONFIGURATION: net_connect.send_command(self.SAVE_CONFIGURATION) except Exception as e: raise exc.GenericSwitchNetmikoConnectError(config=self.config, error=e) LOG.debug(output) return output",from networking_generic_switch.devices import netmiko_devices ,24,1
openstack%2Fpython-heatclient~master~I7a310b1998577682136e68a65813fe91c41be881,openstack/python-heatclient,master,I7a310b1998577682136e68a65813fe91c41be881,Print config_id while deleting software config failed,ABANDONED,2015-10-27 09:13:30.000000000,2017-06-19 01:26:01.000000000,,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 8289}, {'_account_id': 16203}]","[{'number': 1, 'created': '2015-10-27 09:13:30.000000000', 'files': ['heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/f0205337da92b55a284adda1e88509d2f92503cf', 'message': 'Print config_id while deleting software config failed\n\nChange-Id: I7a310b1998577682136e68a65813fe91c41be881\nCloses-Bug: #1508769\n'}]",0,239620,f0205337da92b55a284adda1e88509d2f92503cf,9,4,1,16203,,,0,"Print config_id while deleting software config failed

Change-Id: I7a310b1998577682136e68a65813fe91c41be881
Closes-Bug: #1508769
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/20/239620/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/v1/shell.py'],1,f0205337da92b55a284adda1e88509d2f92503cf,bug1508769, '''Delete software configurations.''' except exc.HTTPNotFound: print(_('Config with ID %s not found') % config_id), '''Delete a software configuration.''' except exc.HTTPNotFound as e: print(e),3,3
openstack%2Fmagnum~master~I857b5430d2c55afb42b8058cffc266956e052f6f,openstack/magnum,master,I857b5430d2c55afb42b8058cffc266956e052f6f,Remove unused function is_docker_library_version_atleast,ABANDONED,2017-06-12 04:49:13.000000000,2017-06-19 00:51:22.000000000,,"[{'_account_id': 3}, {'_account_id': 22255}]","[{'number': 1, 'created': '2017-06-12 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7b399066d0510655eac694d15df96914fdfb865b', 'message': 'Remove unused function is_docker_library_version_atleast\n\nThe function is_docker_library_version_atleast is no longer used in magnum.\nThis patch remove the dead code in magnum.\n\nChange-Id: I857b5430d2c55afb42b8058cffc266956e052f6f\n'}, {'number': 2, 'created': '2017-06-12 06:07:30.000000000', 'files': ['magnum/common/docker_utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/c3a84bc255327938773632c8e9e7026c93fa8312', 'message': 'Remove unused function is_docker_library_version_atleast\n\nThe function is_docker_library_version_atleast is no longer used in magnum.\nThis patch remove the dead code in magnum.\n\nChange-Id: I857b5430d2c55afb42b8058cffc266956e052f6f\n'}]",0,473213,c3a84bc255327938773632c8e9e7026c93fa8312,8,2,2,22255,,,0,"Remove unused function is_docker_library_version_atleast

The function is_docker_library_version_atleast is no longer used in magnum.
This patch remove the dead code in magnum.

Change-Id: I857b5430d2c55afb42b8058cffc266956e052f6f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/13/473213/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/common/docker_utils.py'],1,7b399066d0510655eac694d15df96914fdfb865b,remove,,"def is_docker_library_version_atleast(version): if utils.compare_version(docker.version, version) <= 0: return True return False ",0,6
openstack%2Fmanila~master~I2800a206d279ba91761e6c0e4e4ad6ba65f7867d,openstack/manila,master,I2800a206d279ba91761e6c0e4e4ad6ba65f7867d,Add support on extend_share to glusterfs driver,ABANDONED,2017-06-17 11:32:57.000000000,2017-06-18 23:43:46.000000000,,"[{'_account_id': 10068}, {'_account_id': 16643}]","[{'number': 1, 'created': '2017-06-17 11:32:57.000000000', 'files': ['manila/share/drivers/glusterfs/layout_directory.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/f34abc0dcc802c50acef5ceee3f099cf6925db66', 'message': 'Add support on extend_share to glusterfs driver\n\nThis patch adds extend_share support for the share glusterfs driver.\n\nChange-Id: I2800a206d279ba91761e6c0e4e4ad6ba65f7867d\nSigned-off-by: guojiannan <guojiannan@cmss.chinamobile.com>\nSigned-off-by: chenfangxian <chengfangxian@cmss.chinamobile.com>\n'}]",0,475126,f34abc0dcc802c50acef5ceee3f099cf6925db66,3,2,1,26225,,,0,"Add support on extend_share to glusterfs driver

This patch adds extend_share support for the share glusterfs driver.

Change-Id: I2800a206d279ba91761e6c0e4e4ad6ba65f7867d
Signed-off-by: guojiannan <guojiannan@cmss.chinamobile.com>
Signed-off-by: chenfangxian <chengfangxian@cmss.chinamobile.com>
",git fetch https://review.opendev.org/openstack/manila refs/changes/26/475126/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/glusterfs/layout_directory.py'],1,f34abc0dcc802c50acef5ceee3f099cf6925db66,add-extend-share," """"""Extend a sub-directory/share from the GlusterFS volume."""""" sizestr = six.text_type(new_size) + 'GB' share_dir = '/' + share['name'] args = ('volume', 'quota', self.gluster_manager.volume, 'limit-usage', share_dir, sizestr) try: self.gluster_manager.gluster_call(*args) except Exception as exc: if isinstance(exc, exception.ProcessExecutionError): LOG.error(_LE('Unable to extend share %s'), share['name']) exc = exception.GlusterfsException(exc) raise exc", raise NotImplementedError,12,1
openstack%2Fshade~master~Ic250e904e1a51d659c2599591e2b4274ebc5d1c0,openstack/shade,master,Ic250e904e1a51d659c2599591e2b4274ebc5d1c0,Convert host aggregates calls to REST,MERGED,2017-06-18 18:00:26.000000000,2017-06-18 23:13:16.000000000,2017-06-18 23:13:16.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['shade/operatorcloud.py', 'shade/tests/unit/test_aggregate.py', 'shade/_tasks.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/a2ec277bf5f6ee63b7396894975a104401dfd284', 'message': 'Convert host aggregates calls to REST\n\nChange-Id: Ic250e904e1a51d659c2599591e2b4274ebc5d1c0\n'}]",0,475189,a2ec277bf5f6ee63b7396894975a104401dfd284,8,2,1,2,,,0,"Convert host aggregates calls to REST

Change-Id: Ic250e904e1a51d659c2599591e2b4274ebc5d1c0
",git fetch https://review.opendev.org/openstack/shade refs/changes/89/475189/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/operatorcloud.py', 'shade/tests/unit/test_aggregate.py', 'shade/_tasks.py']",3,a2ec277bf5f6ee63b7396894975a104401dfd284,restification,,"class AggregateList(task_manager.Task): def main(self, client): return client.nova_client.aggregates.list(**self.args) class AggregateCreate(task_manager.Task): def main(self, client): return client.nova_client.aggregates.create(**self.args) class AggregateUpdate(task_manager.Task): def main(self, client): return client.nova_client.aggregates.update(**self.args) class AggregateDelete(task_manager.Task): def main(self, client): return client.nova_client.aggregates.delete(**self.args) class AggregateAddHost(task_manager.Task): def main(self, client): return client.nova_client.aggregates.add_host(**self.args) class AggregateRemoveHost(task_manager.Task): def main(self, client): return client.nova_client.aggregates.remove_host(**self.args) class AggregateSetMetadata(task_manager.Task): def main(self, client): return client.nova_client.aggregates.set_metadata(**self.args) ",41,98
openstack%2Fshade~master~Ia2f5ef2798c57c88a0b3735db3381e1fbc20d9fa,openstack/shade,master,Ia2f5ef2798c57c88a0b3735db3381e1fbc20d9fa,Convert host aggregate tests to requests_mock,MERGED,2017-06-18 18:00:26.000000000,2017-06-18 21:48:43.000000000,2017-06-18 21:48:43.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['shade/tests/fakes.py', 'shade/tests/unit/test_aggregate.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/f1778968de1125f48165efb1694be4c1a951aab9', 'message': 'Convert host aggregate tests to requests_mock\n\nChange-Id: Ia2f5ef2798c57c88a0b3735db3381e1fbc20d9fa\n'}]",0,475188,f1778968de1125f48165efb1694be4c1a951aab9,10,2,1,2,,,0,"Convert host aggregate tests to requests_mock

Change-Id: Ia2f5ef2798c57c88a0b3735db3381e1fbc20d9fa
",git fetch https://review.opendev.org/openstack/shade refs/changes/88/475188/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/fakes.py', 'shade/tests/unit/test_aggregate.py']",2,f1778968de1125f48165efb1694be4c1a951aab9,restification,"class TestAggregate(base.RequestsMockTestCase): def setUp(self): super(TestAggregate, self).setUp() self.aggregate_name = self.getUniqueString('aggregate') self.fake_aggregate = fakes.make_fake_aggregate(1, self.aggregate_name) def test_create_aggregate(self): create_aggregate = self.fake_aggregate.copy() del create_aggregate['metadata'] del create_aggregate['hosts'] self.register_uris([ dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregate': create_aggregate}, validate=dict(json={ 'aggregate': { 'name': self.aggregate_name, 'availability_zone': None, }})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}), ]) self.op_cloud.create_aggregate(name=self.aggregate_name) self.assert_calls() def test_create_aggregate_with_az(self): az_aggregate = fakes.make_fake_aggregate( 1, self.aggregate_name, availability_zone=availability_zone) create_aggregate = az_aggregate.copy() del create_aggregate['metadata'] del create_aggregate['hosts'] self.register_uris([ dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregate': create_aggregate}, validate=dict(json={ 'aggregate': { 'name': self.aggregate_name, 'availability_zone': availability_zone, }})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': az_aggregate}), ]) name=self.aggregate_name, availability_zone=availability_zone) self.assert_calls() def test_delete_aggregate(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregates': [self.fake_aggregate]}), dict(method='DELETE', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1'])), ]) self.assertTrue(self.op_cloud.delete_aggregate('1')) self.assert_calls() def test_update_aggregate_set_az(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregates': [self.fake_aggregate]}), dict(method='PUT', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}, validate=dict( json={ 'aggregate': { 'availability_zone': 'az', }})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}), ]) self.op_cloud.update_aggregate(1, availability_zone='az') self.assert_calls() def test_update_aggregate_unset_az(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregates': [self.fake_aggregate]}), dict(method='PUT', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}, validate=dict( json={ 'aggregate': { 'availability_zone': None, }})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}), ]) self.op_cloud.update_aggregate(1, availability_zone=None) self.assert_calls() def test_set_aggregate_metadata(self): metadata = {'key': 'value'} self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregates': [self.fake_aggregate]}), dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1', 'action']), json={'aggregate': self.fake_aggregate}, validate=dict( json={'set_metadata': {'metadata': metadata}})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}), ]) self.op_cloud.set_aggregate_metadata('1', metadata) self.assert_calls() def test_add_host_to_aggregate(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregates': [self.fake_aggregate]}), dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1', 'action']), json={'aggregate': self.fake_aggregate}, validate=dict( json={'add_host': {'host': hostname}})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}), ]) self.op_cloud.add_host_to_aggregate('1', hostname) self.assert_calls() def test_remove_host_from_aggregate(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates']), json={'aggregates': [self.fake_aggregate]}), dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1', 'action']), json={'aggregate': self.fake_aggregate}, validate=dict( json={'remove_host': {'host': hostname}})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-aggregates', '1']), json={'aggregate': self.fake_aggregate}), ]) self.op_cloud.remove_host_from_aggregate('1', hostname) self.assert_calls()"," import mock import shadeclass TestAggregate(base.TestCase): @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_create_aggregate(self, mock_nova): aggregate_name = 'aggr1' self.op_cloud.create_aggregate(name=aggregate_name) mock_nova.aggregates.create.assert_called_once_with( name=aggregate_name, availability_zone=None ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_create_aggregate_with_az(self, mock_nova): aggregate_name = 'aggr1' name=aggregate_name, availability_zone=availability_zone) mock_nova.aggregates.create.assert_called_once_with( name=aggregate_name, availability_zone=availability_zone ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_delete_aggregate(self, mock_nova): mock_nova.aggregates.list.return_value = [ fakes.FakeAggregate('1234', 'name') ] self.assertTrue(self.op_cloud.delete_aggregate('1234')) mock_nova.aggregates.list.assert_called_once_with() mock_nova.aggregates.delete.assert_called_once_with( aggregate='1234' ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_update_aggregate_set_az(self, mock_nova): mock_nova.aggregates.list.return_value = [ fakes.FakeAggregate('1234', 'name') ] self.op_cloud.update_aggregate('1234', availability_zone='az') mock_nova.aggregates.update.assert_called_once_with( aggregate='1234', values={'availability_zone': 'az'}, ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_update_aggregate_unset_az(self, mock_nova): mock_nova.aggregates.list.return_value = [ fakes.FakeAggregate('1234', 'name', availability_zone='az') ] self.op_cloud.update_aggregate('1234', availability_zone=None) mock_nova.aggregates.update.assert_called_once_with( aggregate='1234', values={'availability_zone': None}, ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_set_aggregate_metadata(self, mock_nova): metadata = {'key', 'value'} mock_nova.aggregates.list.return_value = [ fakes.FakeAggregate('1234', 'name') ] self.op_cloud.set_aggregate_metadata('1234', metadata) mock_nova.aggregates.set_metadata.assert_called_once_with( aggregate='1234', metadata=metadata ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_add_host_to_aggregate(self, mock_nova): mock_nova.aggregates.list.return_value = [ fakes.FakeAggregate('1234', 'name') ] self.op_cloud.add_host_to_aggregate('1234', hostname) mock_nova.aggregates.add_host.assert_called_once_with( aggregate='1234', host=hostname ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_remove_host_from_aggregate(self, mock_nova): mock_nova.aggregates.list.return_value = [ fakes.FakeAggregate('1234', 'name', hosts=[hostname]) ] self.op_cloud.remove_host_from_aggregate('1234', hostname) mock_nova.aggregates.remove_host.assert_called_once_with( aggregate='1234', host=hostname )",201,92
openstack%2Ftripleo-heat-templates~master~Ieb46a87cc70be2ff8c40fa9a320644bf15d0edbc,openstack/tripleo-heat-templates,master,Ieb46a87cc70be2ff8c40fa9a320644bf15d0edbc,WIP Use docker diff to capture only changed files,ABANDONED,2017-05-25 03:27:38.000000000,2017-06-18 20:56:33.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 13039}]","[{'number': 1, 'created': '2017-05-25 03:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/316222cce2c699653f1025153b9644872283464f', 'message': ""WIP Use docker diff to capture only changed files\n\nMarked as WIP because the result is sparse directories in config-data\nwhich can't be mounted directly into /etc, instead some copy mechanism\nwill be needed to consume files from config-data.\n\nChange-Id: Ieb46a87cc70be2ff8c40fa9a320644bf15d0edbc\n""}, {'number': 2, 'created': '2017-05-25 03:32:19.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4524161b79989009cace30b2ec3990306af5b29', 'message': ""WIP Use docker diff to capture only changed files\n\nMarked as WIP because the result is sparse directories in config-data\nwhich can't be mounted directly into /etc, instead some copy mechanism\nwill be needed to consume files from config-data.\n\nChange-Id: Ieb46a87cc70be2ff8c40fa9a320644bf15d0edbc\n""}]",0,467847,e4524161b79989009cace30b2ec3990306af5b29,6,3,2,4571,,,0,"WIP Use docker diff to capture only changed files

Marked as WIP because the result is sparse directories in config-data
which can't be mounted directly into /etc, instead some copy mechanism
will be needed to consume files from config-data.

Change-Id: Ieb46a87cc70be2ff8c40fa9a320644bf15d0edbc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/467847/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,316222cce2c699653f1025153b9644872283464f,docker-puppet," docker diff docker-puppet-${NAME} | grep ""^[AC]"" | cut -d"" "" -f 2 > /root/changed.txt rsync -a --delete --exclude=/usr/** --exclude=/run/** --exclude=/tmp/** --include-from=/root/changed.txt --exclude=/** / /var/lib/config-data/${NAME} '--volume', '/usr/bin/docker-current:/usr/bin/docker', '--volume', '/var/run/docker.sock:/var/run/docker.sock',", rsync -a --delete /etc /root /var/lib/ironic/tftpboot /var/lib/ironic/httpboot /var/www /var/lib/config-data/${NAME} || true,4,1
openstack%2Fproject-config~master~Iceb43923104fd5624aab0fc50c9426664e1230cb,openstack/project-config,master,Iceb43923104fd5624aab0fc50c9426664e1230cb,Move ubuntu-trusty image pause to correct section,MERGED,2017-06-18 19:49:34.000000000,2017-06-18 20:43:08.000000000,2017-06-18 19:50:46.000000000,"[{'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2017-06-18 19:49:34.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3621134bc578fae309561abbc00b8829b33e05c8', 'message': 'Move ubuntu-trusty image pause to correct section\n\nThe pause setting for the ubuntu-trusty image builds should be in\nthe diskimages entry for it, not its labels entry. Move it to the\nappropriate section.\n\nChange-Id: Iceb43923104fd5624aab0fc50c9426664e1230cb\n'}]",0,475196,3621134bc578fae309561abbc00b8829b33e05c8,4,2,1,5263,,,0,"Move ubuntu-trusty image pause to correct section

The pause setting for the ubuntu-trusty image builds should be in
the diskimages entry for it, not its labels entry. Move it to the
appropriate section.

Change-Id: Iceb43923104fd5624aab0fc50c9426664e1230cb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/96/475196/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,3621134bc578fae309561abbc00b8829b33e05c8,ubuntu-trusty, pause: True, pause: True,1,1
openstack%2Fproject-config~master~I0c9851beb562f5a94cc26005a5aea6f02a98d502,openstack/project-config,master,I0c9851beb562f5a94cc26005a5aea6f02a98d502,Pause rebuilding ubuntu-trusty images,MERGED,2017-06-18 19:05:35.000000000,2017-06-18 20:40:47.000000000,2017-06-18 19:21:01.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2017-06-18 19:05:35.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/39ee24ccf73c50bdf796e24254638851c49a3cad', 'message': ""Pause rebuilding ubuntu-trusty images\n\nWe need to roll back ubuntu-trusty images while we work out why DNS\nhas suddenly started failing for the ready script. Pause rebuilding\nso we can stick with yesterday's image in the meantime.\n\nChange-Id: I0c9851beb562f5a94cc26005a5aea6f02a98d502\n""}]",0,475195,39ee24ccf73c50bdf796e24254638851c49a3cad,5,3,1,5263,,,0,"Pause rebuilding ubuntu-trusty images

We need to roll back ubuntu-trusty images while we work out why DNS
has suddenly started failing for the ready script. Pause rebuilding
so we can stick with yesterday's image in the meantime.

Change-Id: I0c9851beb562f5a94cc26005a5aea6f02a98d502
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/475195/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,39ee24ccf73c50bdf796e24254638851c49a3cad,ubuntu-trusty, pause: True,,1,0
openstack%2Fproject-config~master~Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c,openstack/project-config,master,Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c,Run gate-tempest-dsvm-neutron-multinode-full in devstack check,MERGED,2017-06-05 15:26:41.000000000,2017-06-18 20:35:31.000000000,2017-06-18 20:35:31.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 6873}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-06-05 15:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/44ccd4069f4288de0a427b554d55ba925c16120e', 'message': ""Run the live migration job in devstack's experimental queue\n\nIt would be nice to be able to test changes to devstack that\nimpact live migration by running the experimental queue on devstack\nrather than needing to push a nova change to depend on a devstack\nchange just to run the live migration job.\n\nChange-Id: Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c\n""}, {'number': 2, 'created': '2017-06-07 16:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ccbb2d773d477264ecb39a75557415248df2667f', 'message': ""Run gate-tempest-dsvm-neutron-multinode-full in devstack check\n\nIt would be nice to be able to test changes to devstack that\nimpact live migration by running the neutron multinode full\nnon-voting job in the check queue. The multinode grenade job\nis already in the list but that job doesn't run the live\nmigration tests since they aren't smoke tests.\n\nChange-Id: Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c\n""}, {'number': 3, 'created': '2017-06-07 16:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b8d9367ea5417e81da62729d4b8fcdd19c2a736e', 'message': ""Run gate-tempest-dsvm-neutron-multinode-full in devstack check\n\nIt would be nice to be able to test changes to devstack that\nimpact live migration by running the neutron multinode full\nnon-voting job in the check queue. The multinode grenade job\nis already in the list but that job doesn't run the live\nmigration tests since they aren't smoke tests.\n\nChange-Id: Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c\n""}, {'number': 4, 'created': '2017-06-10 11:50:55.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/37868ea9caead7a71dcffb77bef3767763b87931', 'message': ""Run gate-tempest-dsvm-neutron-multinode-full in devstack check\n\nIt would be nice to be able to test changes to devstack that\nimpact live migration by running the neutron multinode full\nnon-voting job in the check queue. The multinode grenade job\nis already in the list but that job doesn't run the live\nmigration tests since they aren't smoke tests.\n\nChange-Id: Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c\n""}]",2,471016,37868ea9caead7a71dcffb77bef3767763b87931,17,6,4,6873,,,0,"Run gate-tempest-dsvm-neutron-multinode-full in devstack check

It would be nice to be able to test changes to devstack that
impact live migration by running the neutron multinode full
non-voting job in the check queue. The multinode grenade job
is already in the list but that job doesn't run the live
migration tests since they aren't smoke tests.

Change-Id: Ibbe1f91d85d38ab5e0dea3fa4afa1630d6d57b3c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/16/471016/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,44ccd4069f4288de0a427b554d55ba925c16120e,live-migration-devstack-experimental, - gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial,,1,0
openstack%2Fproject-config~master~I5c07c4990bd3ea68e9763ce531f62f809f1b48e3,openstack/project-config,master,I5c07c4990bd3ea68e9763ce531f62f809f1b48e3,Add tempest OOOQ job to experimental for tripleo,MERGED,2017-06-09 02:33:07.000000000,2017-06-18 20:34:49.000000000,2017-06-18 20:34:49.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 8367}]","[{'number': 1, 'created': '2017-06-09 02:33:07.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4ac117ada8f94c686da038e2c92590f25c9b5ebf', 'message': 'Add tempest OOOQ job to experimental for tripleo\n\nAdd tempest job as experimental for tripleo-ci and quickstart\nrepositories.\n\nChange-Id: I5c07c4990bd3ea68e9763ce531f62f809f1b48e3\n'}]",0,472499,4ac117ada8f94c686da038e2c92590f25c9b5ebf,9,6,1,10969,,,0,"Add tempest OOOQ job to experimental for tripleo

Add tempest job as experimental for tripleo-ci and quickstart
repositories.

Change-Id: I5c07c4990bd3ea68e9763ce531f62f809f1b48e3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/99/472499/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,4ac117ada8f94c686da038e2c92590f25c9b5ebf,, - gate-tripleo-ci-centos-7-ovb-ha-tempest-oooq experimental-tripleo: - gate-tripleo-ci-centos-7-ovb-ha-tempest-oooq experimental-tripleo: - gate-tripleo-ci-centos-7-ovb-ha-tempest-oooq,,5,0
openstack%2Fshade~master~Ie08b2e2e9ef0b27e9faa27d38934e97c74c76305,openstack/shade,master,Ie08b2e2e9ef0b27e9faa27d38934e97c74c76305,Convert hypervisor list to REST,MERGED,2017-06-18 18:00:26.000000000,2017-06-18 19:53:41.000000000,2017-06-18 19:53:41.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['shade/operatorcloud.py', 'shade/_tasks.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/b1faf5bdd12fdd2cb08c0f08e05223f103171dcd', 'message': 'Convert hypervisor list to REST\n\nChange-Id: Ie08b2e2e9ef0b27e9faa27d38934e97c74c76305\n'}]",0,475187,b1faf5bdd12fdd2cb08c0f08e05223f103171dcd,6,2,1,2,,,0,"Convert hypervisor list to REST

Change-Id: Ie08b2e2e9ef0b27e9faa27d38934e97c74c76305
",git fetch https://review.opendev.org/openstack/shade refs/changes/87/475187/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/operatorcloud.py', 'shade/_tasks.py']",2,b1faf5bdd12fdd2cb08c0f08e05223f103171dcd,restification,,"class HypervisorList(task_manager.Task): def main(self, client): return client.nova_client.hypervisors.list(**self.args) ",3,7
openstack%2Fshade~master~Ie9acb8582ab52580c90b3511acf5e28eed2f9abf,openstack/shade,master,Ie9acb8582ab52580c90b3511acf5e28eed2f9abf,Convert hypervisor test to requests_mock,MERGED,2017-06-18 18:00:26.000000000,2017-06-18 19:52:43.000000000,2017-06-18 19:52:43.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 18:00:26.000000000', 'files': ['shade/tests/unit/test_shade_operator.py', 'shade/tests/fakes.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/d69b81fe00627b527a8c999bd9ce7ac9ac689d30', 'message': 'Convert hypervisor test to requests_mock\n\nChange-Id: Ie9acb8582ab52580c90b3511acf5e28eed2f9abf\n'}]",0,475186,d69b81fe00627b527a8c999bd9ce7ac9ac689d30,6,2,1,2,,,0,"Convert hypervisor test to requests_mock

Change-Id: Ie9acb8582ab52580c90b3511acf5e28eed2f9abf
",git fetch https://review.opendev.org/openstack/shade refs/changes/86/475186/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_shade_operator.py', 'shade/tests/fakes.py']",2,d69b81fe00627b527a8c999bd9ce7ac9ac689d30,restification,"def make_fake_hypervisor(id, name): return json.loads(json.dumps({ 'id': id, 'hypervisor_hostname': name, 'state': 'up', 'status': 'enabled', ""cpu_info"": { ""arch"": ""x86_64"", ""model"": ""Nehalem"", ""vendor"": ""Intel"", ""features"": [ ""pge"", ""clflush"" ], ""topology"": { ""cores"": 1, ""threads"": 1, ""sockets"": 4 } }, ""current_workload"": 0, ""status"": ""enabled"", ""state"": ""up"", ""disk_available_least"": 0, ""host_ip"": ""1.1.1.1"", ""free_disk_gb"": 1028, ""free_ram_mb"": 7680, ""hypervisor_type"": ""fake"", ""hypervisor_version"": 1000, ""local_gb"": 1028, ""local_gb_used"": 0, ""memory_mb"": 8192, ""memory_mb_used"": 512, ""running_vms"": 0, ""service"": { ""host"": ""host1"", ""id"": 7, ""disabled_reason"": None }, ""vcpus"": 1, ""vcpus_used"": 0 })) ",,57,7
openstack%2Fshade~master~If779c02521d0cf07d43f19ff9a11666838e4ac3b,openstack/shade,master,If779c02521d0cf07d43f19ff9a11666838e4ac3b,Convert Server Groups to REST,MERGED,2017-06-18 15:41:33.000000000,2017-06-18 19:52:37.000000000,2017-06-18 19:52:37.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 15:41:33.000000000', 'files': ['shade/_tasks.py', 'shade/openstackcloud.py', 'shade/tests/unit/test_server_group.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/0ad08858a543d67f66e6576c49e7988c53038a28', 'message': 'Convert Server Groups to REST\n\nChange-Id: If779c02521d0cf07d43f19ff9a11666838e4ac3b\n'}]",0,475182,0ad08858a543d67f66e6576c49e7988c53038a28,6,2,1,2,,,0,"Convert Server Groups to REST

Change-Id: If779c02521d0cf07d43f19ff9a11666838e4ac3b
",git fetch https://review.opendev.org/openstack/shade refs/changes/82/475182/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/_tasks.py', 'shade/openstackcloud.py', 'shade/tests/unit/test_server_group.py']",3,0ad08858a543d67f66e6576c49e7988c53038a28,restification,," dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-server-groups', self.group_id],), json={'server_group': self.fake_group}),",15,36
openstack%2Fshade~master~Ic4b137073e0c662d26cac254611708b3f31734e0,openstack/shade,master,Ic4b137073e0c662d26cac254611708b3f31734e0,Convert server group tests to requests_mock,MERGED,2017-06-18 15:41:33.000000000,2017-06-18 19:52:32.000000000,2017-06-18 19:52:32.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 15:41:33.000000000', 'files': ['shade/tests/fakes.py', 'shade/tests/unit/test_server_group.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/3aec23cfd2a0477693e6684a97bfb3abbd3cd937', 'message': 'Convert server group tests to requests_mock\n\nChange-Id: Ic4b137073e0c662d26cac254611708b3f31734e0\n'}]",0,475181,3aec23cfd2a0477693e6684a97bfb3abbd3cd937,6,2,1,2,,,0,"Convert server group tests to requests_mock

Change-Id: Ic4b137073e0c662d26cac254611708b3f31734e0
",git fetch https://review.opendev.org/openstack/shade refs/changes/81/475181/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/fakes.py', 'shade/tests/unit/test_server_group.py']",2,3aec23cfd2a0477693e6684a97bfb3abbd3cd937,restification,"import uuid class TestServerGroup(base.RequestsMockTestCase): def setUp(self): super(TestServerGroup, self).setUp() self.group_id = uuid.uuid4().hex self.group_name = self.getUniqueString('server-group') self.policies = ['affinity'] self.fake_group = fakes.make_fake_server_group( self.group_id, self.group_name, self.policies) def test_create_server_group(self): self.register_uris([ dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-server-groups']), json={'server_group': self.fake_group}, validate=dict( json={'server_group': { 'name': self.group_name, 'policies': self.policies, }})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-server-groups', self.group_id],), json={'server_group': self.fake_group}), ]) self.cloud.create_server_group(name=self.group_name, policies=self.policies) self.assert_calls() def test_delete_server_group(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-server-groups']), json={'server_groups': [self.fake_group]}), dict(method='DELETE', uri=self.get_mock_url( 'compute', 'public', append=['os-server-groups', self.group_id]), json={'server_groups': [self.fake_group]}), ]) self.assertTrue(self.cloud.delete_server_group(self.group_name)) self.assert_calls()","import mock import shadeclass TestServerGroup(base.TestCase): @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_create_server_group(self, mock_nova): server_group_name = 'my-server-group' self.cloud.create_server_group(name=server_group_name, policies=['affinity']) mock_nova.server_groups.create.assert_called_once_with( name=server_group_name, policies=['affinity'] ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_delete_server_group(self, mock_nova): mock_nova.server_groups.list.return_value = [ fakes.FakeServerGroup('1234', 'name', ['affinity']) ] self.assertTrue(self.cloud.delete_server_group('1234')) mock_nova.server_groups.list.assert_called_once_with() mock_nova.server_groups.delete.assert_called_once_with( id='1234' )",55,26
openstack%2Fshade~master~I0e0e1b87b0b32e8c015ba1f9944faf3b0e0738c1,openstack/shade,master,I0e0e1b87b0b32e8c015ba1f9944faf3b0e0738c1,Convert FakeSecGroup to dict,MERGED,2017-06-18 15:17:35.000000000,2017-06-18 19:51:51.000000000,2017-06-18 19:51:51.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 15:17:35.000000000', 'files': ['shade/tests/unit/test_security_groups.py', 'shade/tests/fakes.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/611ce3dca1bf7b320ab075b4f05294c1f24fd4e3', 'message': 'Convert FakeSecGroup to dict\n\nChange-Id: I0e0e1b87b0b32e8c015ba1f9944faf3b0e0738c1\n'}]",0,475178,611ce3dca1bf7b320ab075b4f05294c1f24fd4e3,6,2,1,2,,,0,"Convert FakeSecGroup to dict

Change-Id: I0e0e1b87b0b32e8c015ba1f9944faf3b0e0738c1
",git fetch https://review.opendev.org/openstack/shade refs/changes/78/475178/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_security_groups.py', 'shade/tests/fakes.py']",2,611ce3dca1bf7b320ab075b4f05294c1f24fd4e3,restification,"def make_fake_neutron_security_group( id, name, description, rules, project_id=None): if not rules: rules = [] if not project_id: project_id = PROJECT_ID return json.loads(json.dumps({ 'id': id, 'name': name, 'description': description, 'project_id': project_id, 'tenant_id': project_id, 'security_group_rules': rules, })) def make_fake_nova_security_group_rule( id, from_port, to_port, ip_protocol, cidr): return json.loads(json.dumps({ 'id': id, 'from_port': int(from_port), 'to_port': int(to_port), 'ip_protcol': 'tcp', 'ip_range': { 'cidr': cidr } })) def make_fake_nova_security_group(id, name, description, rules): if not rules: rules = [] return json.loads(json.dumps({ 'id': id, 'name': name, 'description': description, 'tenant_id': PROJECT_ID, 'rules': rules, }))","class FakeSecgroup(object): def __init__(self, id, name, description='', project_id=None, rules=None): self.id = id self.name = name self.description = description self.project_id = project_id self.rules = rules",75,58
openstack%2Fshade~master~I45c1136078f604c73c1fea54a9eb52bbbc8c69b5,openstack/shade,master,I45c1136078f604c73c1fea54a9eb52bbbc8c69b5,Remove use of FakeServer from tests,MERGED,2017-06-18 15:17:35.000000000,2017-06-18 19:51:45.000000000,2017-06-18 19:51:45.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 15:17:35.000000000', 'files': ['shade/tests/unit/test_meta.py', 'shade/tests/unit/test_floating_ip_common.py', 'shade/tests/unit/test_floating_ip_neutron.py', 'shade/tests/unit/test_security_groups.py', 'shade/tests/unit/test_delete_server.py', 'shade/tests/fakes.py', 'shade/tests/unit/test_inventory.py', 'shade/tests/unit/test_create_server.py', 'shade/tests/unit/test_floating_ip_nova.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/fb956cce7b528eebc7332377d76c156cddcbd6ed', 'message': ""Remove use of FakeServer from tests\n\nFakeServer is a Fake of a novaclient object. Use actual json instead.\n\nSpeaking of - transform the dict through json dump/load so that it's\nunicode where it's supposed to be. This makes diffs easier to make.\n\nChange-Id: I45c1136078f604c73c1fea54a9eb52bbbc8c69b5\n""}]",0,475177,fb956cce7b528eebc7332377d76c156cddcbd6ed,6,2,1,2,,,0,"Remove use of FakeServer from tests

FakeServer is a Fake of a novaclient object. Use actual json instead.

Speaking of - transform the dict through json dump/load so that it's
unicode where it's supposed to be. This makes diffs easier to make.

Change-Id: I45c1136078f604c73c1fea54a9eb52bbbc8c69b5
",git fetch https://review.opendev.org/openstack/shade refs/changes/77/475177/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_meta.py', 'shade/tests/unit/test_floating_ip_common.py', 'shade/tests/unit/test_floating_ip_neutron.py', 'shade/tests/unit/test_security_groups.py', 'shade/tests/unit/test_delete_server.py', 'shade/tests/fakes.py', 'shade/tests/unit/test_inventory.py', 'shade/tests/unit/test_create_server.py', 'shade/tests/unit/test_floating_ip_nova.py']",9,fb956cce7b528eebc7332377d76c156cddcbd6ed,restification," self.fake_server = fakes.make_fake_server( 'server-id', '', 'ACTIVE', addresses={u'test_pnztt_net': [{ u'OS-EXT-IPS:type': u'fixed', u'addr': '192.0.2.129', u'version': 4, u'OS-EXT-IPS-MAC:mac_addr': u'fa:16:3e:ae:7d:42'}]}) append=['servers', self.fake_server['id'], 'action']), append=['servers', self.fake_server['id'], 'action']), append=['servers', self.fake_server['id'], 'action']),","from shade import meta self.fake_server = meta.obj_to_munch( fakes.FakeServer( 'server-id', '', 'ACTIVE', addresses={u'test_pnztt_net': [{ u'OS-EXT-IPS:type': u'fixed', u'addr': '192.0.2.129', u'version': 4, u'OS-EXT-IPS-MAC:mac_addr': u'fa:16:3e:ae:7d:42'}]})) append=['servers', self.fake_server.id, 'action']), append=['servers', self.fake_server.id, 'action']), append=['servers', self.fake_server.id, 'action']),",226,271
openstack%2Fneutron-lbaas~master~I6b137a606d604a78ab96f43715995e88e674ef52,openstack/neutron-lbaas,master,I6b137a606d604a78ab96f43715995e88e674ef52,Updated from global requirements,MERGED,2017-06-15 16:28:20.000000000,2017-06-18 19:23:09.000000000,2017-06-18 19:23:09.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10850}, {'_account_id': 11628}]","[{'number': 1, 'created': '2017-06-15 16:28:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e37044917c7445ca9c2b5139ac6c8250c25454a2', 'message': 'Updated from global requirements\n\nChange-Id: I6b137a606d604a78ab96f43715995e88e674ef52\n'}]",0,474671,e37044917c7445ca9c2b5139ac6c8250c25454a2,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I6b137a606d604a78ab96f43715995e88e674ef52
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/71/474671/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e37044917c7445ca9c2b5139ac6c8250c25454a2,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fneutron~master~I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8,openstack/neutron,master,I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8,Pass the complete info in sg/rules db into PRECOMMIT_XXX callback,ABANDONED,2016-02-18 08:28:59.000000000,2017-06-18 18:14:27.000000000,,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7244}, {'_account_id': 7249}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10385}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11114}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15309}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17120}, {'_account_id': 17455}, {'_account_id': 19726}, {'_account_id': 20066}, {'_account_id': 20123}, {'_account_id': 20205}, {'_account_id': 20629}, {'_account_id': 21784}, {'_account_id': 22121}, {'_account_id': 22220}, {'_account_id': 23665}]","[{'number': 1, 'created': '2016-02-18 08:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/94f4e2d49654b4f57a56eeb31de664f551191e8e', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info for registed\ndriver.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 2, 'created': '2016-02-19 05:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a2a6915133500cea8a286171987c9bdb9747a035', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info for registed\ndriver.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 3, 'created': '2016-02-19 05:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e770518a9bf8bc3d746f7321941a7554bd2ab95', 'message': ""Pass the complete info of sg db into PRECOMMIT callback\n\nPRECOMMIT_XXX events' callback need completed sg info when creating resource.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 4, 'created': '2016-03-02 13:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/935f29b79c8ff46ea2653cc4735a6351d9a2c9ce', 'message': 'Pass the complete info of sg/rule db into PRECOMMIT callback\n\nWhen SG try to notify the PRECOMMIT_XXX events, kwargs passed should\ninclude the generated id information and for SG rules, some detailed\ninfo should also be included too.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n'}, {'number': 5, 'created': '2016-03-03 02:40:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/482122c058fa72efa07f08dd5e7a2517c378258c', 'message': 'Pass the complete info of sg/rule db into PRECOMMIT callback\n\nWhen SG try to notify the PRECOMMIT_XXX events, kwargs passed should\ninclude the generated id information and for SG rules, some detailed\ninfo should also be included too.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n'}, {'number': 6, 'created': '2016-03-03 02:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb94fb69d5bca82b037d8e5d1bcab772a5529eba', 'message': 'Pass the complete info of sg/rule db into PRECOMMIT callback\n\nWhen SG try to notify the PRECOMMIT_CREATE events, kwargs passed should\ninclude the generated id information and for SG rules, some detailed\ninfo should also be included too.\nThis patch also independently generate PRECOMMIT_CREATE event for the sg\nrules which are created inside the SG creating process.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n'}, {'number': 7, 'created': '2016-03-04 02:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b576d4aef816a499cabe0d500783432770d6c83', 'message': 'Pass the complete info of sg/rule db into PRECOMMIT callback\n\nWhen SG try to notify the PRECOMMIT_CREATE events, kwargs passed should\ninclude the generated id information and for SG rules, some detailed\ninfo should also be included too.\nThis patch also independently generate PRECOMMIT_CREATE event for the sg\nrules which are created inside the SG creating process.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n'}, {'number': 8, 'created': '2016-03-07 02:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af6b9580abbc6f1b4bbbabeb9479d2da65bf5264', 'message': 'Pass the complete info of sg/rule db into PRECOMMIT callback\n\nWhen SG try to notify the PRECOMMIT_CREATE events, kwargs passed should\ninclude the generated id information and for SG rules, some detailed\ninfo should also be included too.\nThis patch also independently generate PRECOMMIT_CREATE event for the sg\nrules which are created inside the SG creating process.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n'}, {'number': 9, 'created': '2016-03-14 10:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9970937ac4e76b63d4fbd35c3cd630d7d8ab73c9', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info for registed\ndriver.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 10, 'created': '2016-03-17 10:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab858c390839c9db9c9413a84bee2a2f00d8e343', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info for registed\ndriver.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 11, 'created': '2016-03-27 03:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aff0183342db5948f256c54d0b274646905ea469', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registed driver.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 12, 'created': '2016-06-01 17:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2e2e2026aae7bb251a5be37a1c0418c77728912', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registed driver.\n\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 13, 'created': '2016-07-27 00:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/442bec5d4e3edf762acb676271cf3ec56bd5294f', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registed driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 14, 'created': '2016-07-29 18:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/324908e384e852fe56836d28007c8d0777d9a5e2', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 15, 'created': '2016-08-17 23:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b2df3b7c94ea1dd40e8c4220be0580371b9826e7', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 16, 'created': '2016-09-02 21:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a08d552b844338d68f5890645dd5804feca00f5', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 17, 'created': '2016-10-11 22:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e69da79dbc7d6b1988008d7d74fc1657f8293fde', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 18, 'created': '2016-10-19 20:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a47a0cf54a31152116ebb4324f32e14649f7474', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 19, 'created': '2016-10-20 16:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2abb791f95ede36b3556e6edd5a067bc349fe18', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 20, 'created': '2016-10-24 17:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f51406b5e9f029526ede4c60f77779c303904d61', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 21, 'created': '2016-11-04 23:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e732609d128531c717fc132b0b88d6338112047e', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 22, 'created': '2016-11-05 00:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e40e15ca72723d677f2090664378087ed8d0a6ef', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 23, 'created': '2016-11-30 12:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e82413352bdae7a906eb9c4df995d11f835fab7b', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 24, 'created': '2016-12-01 02:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f0e34efbd861246a204016b5ef38ed4db7c2ec1', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Rui Wang <starwangrui@gmail.com>\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}, {'number': 25, 'created': '2016-12-02 01:47:13.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/tests/unit/db/test_securitygroups_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e01415ab18e0c45365828a3b3f31472230f87047', 'message': ""Pass the complete info in sg/rules db into PRECOMMIT_XXX callback\n\nPRECOMMIT_XXX events' callback need completed sg info, like the sg id\nand its related rules for registered driver.\n\nCo-Authored-By: Rui Wang <starwangrui@gmail.com>\nCo-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>\nChange-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8\nCloses-bug: #1546910\n""}]",62,281693,e01415ab18e0c45365828a3b3f31472230f87047,301,41,25,11114,,,0,"Pass the complete info in sg/rules db into PRECOMMIT_XXX callback

PRECOMMIT_XXX events' callback need completed sg info, like the sg id
and its related rules for registered driver.

Co-Authored-By: Rui Wang <starwangrui@gmail.com>
Co-Authored-By: Manjeet Singh Bhatia <manjeet.s.bhatia@intel.com>
Change-Id: I451ae5f0c2157e8fcb34095d0745c3057a8fcfe8
Closes-bug: #1546910
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/281693/21 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_db.py'],1,94f4e2d49654b4f57a56eeb31de664f551191e8e,bug/1546910," secgroup_dict = self._make_security_group_dict( security_group_db) kwargs['security_group'] = secgroup_dict res_rule_dict = self._make_security_group_rule_dict(db) kwargs['security_group_rule'] = res_rule_dict try: sg_rule = query.one() kwargs['security_group_rule'] = sg_rule self._registry_notify(resources.SECURITY_GROUP_RULE, context.session.delete(sg_rule)"," secgroup_dict = self._make_security_group_dict(security_group_db) kwargs['security_group'] = secgroup_dict res_rule_dict = self._make_security_group_rule_dict(db) kwargs['security_group_rule'] = res_rule_dict self._registry_notify(resources.SECURITY_GROUP_RULE, try: context.session.delete(query.one())",12,8
openstack%2Fneutron~master~I277290500d1616d60f15e433694afee2946ba617,openstack/neutron,master,I277290500d1616d60f15e433694afee2946ba617,security_group: pass necessary info to callbacks,ABANDONED,2017-06-16 05:38:46.000000000,2017-06-18 18:13:34.000000000,,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 6854}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-16 05:38:46.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/tests/unit/extensions/test_securitygroup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1bae412c27dae6bfedb93d12410b4279b8356d4', 'message': 'security_group: pass necessary info to callbacks\n\nargument to precommit callbacks of security group/security group rule\nis missing necessary info. e.g. id, default rule etc.\nSo far those info can be retrieved from context.session.new.\nHowever, with ovo patch[1], those information is all dropped because\nNeutronDbObject expunges itself when created.\nrefer to _detach_db_obj method in neutron.objects.base\nSo add necessary info to argument to those callbacks.\n\n[1] https://review.openstack.org/#/c/474575/\nThe change set of af52d499a53f9dddacd8c9116d1bb0570e8f579c\nchange id of I2d43ad79eb004e68866050fbd63d166920b9f2b0\n\nPartial-bug: #1698284\nChange-Id: I277290500d1616d60f15e433694afee2946ba617\n'}]",2,474854,f1bae412c27dae6bfedb93d12410b4279b8356d4,11,9,1,333,,,0,"security_group: pass necessary info to callbacks

argument to precommit callbacks of security group/security group rule
is missing necessary info. e.g. id, default rule etc.
So far those info can be retrieved from context.session.new.
However, with ovo patch[1], those information is all dropped because
NeutronDbObject expunges itself when created.
refer to _detach_db_obj method in neutron.objects.base
So add necessary info to argument to those callbacks.

[1] https://review.openstack.org/#/c/474575/
The change set of af52d499a53f9dddacd8c9116d1bb0570e8f579c
change id of I2d43ad79eb004e68866050fbd63d166920b9f2b0

Partial-bug: #1698284
Change-Id: I277290500d1616d60f15e433694afee2946ba617
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/474854/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/tests/unit/extensions/test_securitygroup.py']",2,f1bae412c27dae6bfedb93d12410b4279b8356d4,bug/1698284,"from neutron_lib.callbacks import events from neutron_lib.callbacks import registry from neutron_lib.callbacks import resourcesfrom neutron.common import utilsclass TestSecurityGroupsCallbacks(SecurityGroupDBTestCase): def setUp(self, plugin=None, ext_mgr=None): super(TestSecurityGroupsCallbacks, self).setUp(plugin=plugin, ext_mgr=ext_mgr) self._sg_create_precommit = mock.MagicMock() registry.subscribe( self._sg_create_precommit, resources.SECURITY_GROUP, events.PRECOMMIT_CREATE) self._sgr_create_precommit = mock.MagicMock() registry.subscribe( self._sgr_create_precommit, resources.SECURITY_GROUP_RULE, events.PRECOMMIT_CREATE) self.addCleanup(self._unsubscribe) def _unsubscribe(self): registry.unsubscribe( self._sg_create_precommit, resources.SECURITY_GROUP, events.PRECOMMIT_CREATE) registry.unsubscribe( self._sgr_create_precommit, resources.SECURITY_GROUP_RULE, events.PRECOMMIT_CREATE) def test_create_security_group_rule(self): name = 'webservers' description = 'my webservers' with self.security_group(name, description) as sg: self._sg_create_precommit.assert_called_with( resources.SECURITY_GROUP, events.PRECOMMIT_CREATE, mock.ANY, context=mock.ANY, egress_rule=mock.ANY, is_default=False, security_group={ 'name': name, 'tenant_id': test_db_base_plugin_v2.TEST_TENANT_ID, 'project_id': test_db_base_plugin_v2.TEST_TENANT_ID, 'description': description}) self._sgr_create_precommit.assert_not_called() security_group_id = sg['security_group']['id'] direction = ""ingress"" remote_ip_prefix = ""10.0.0.0/24"" protocol = 'tcp' port_range_min = 22 port_range_max = 22 ethertype = 'IPv4' with self.security_group_rule(security_group_id, direction, protocol, port_range_min, port_range_max, remote_ip_prefix, ethertype=ethertype): self._sgr_create_precommit.assert_called_with( resources.SECURITY_GROUP_RULE, events.PRECOMMIT_CREATE, mock.ANY, context=mock.ANY, security_group_rule={ 'id': mock.ANY, 'remote_ip_prefix': utils.AuthenticIPNetwork(remote_ip_prefix), 'direction': direction, 'remote_group_id': None, 'port_range_max': port_range_max, 'port_range_min': port_range_min, 'description': '', 'protocol': protocol, 'project_id': test_db_base_plugin_v2.TEST_TENANT_ID, 'ethertype': ethertype, 'security_group_id': security_group_id}) ",,84,9
openstack%2Fopenstackdocstheme~master~Ic83f8fd6fba9262ad9c8e9dd42b3ee44b6063b1a,openstack/openstackdocstheme,master,Ic83f8fd6fba9262ad9c8e9dd42b3ee44b6063b1a,Updated from global requirements,MERGED,2017-06-02 22:04:30.000000000,2017-06-18 17:43:27.000000000,2017-06-18 17:43:27.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-02 22:04:30.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/6e110ee7ca469350a941f7cfa8a4e8fc1feb8f22', 'message': 'Updated from global requirements\n\nChange-Id: Ic83f8fd6fba9262ad9c8e9dd42b3ee44b6063b1a\n'}]",0,470520,6e110ee7ca469350a941f7cfa8a4e8fc1feb8f22,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ic83f8fd6fba9262ad9c8e9dd42b3ee44b6063b1a
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/20/470520/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,6e110ee7ca469350a941f7cfa8a4e8fc1feb8f22,openstack/requirements,"reno!=2.3.1,>=1.8.0 # Apache-2.0",reno>=1.8.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~Iff5a1c4bbf27b3ed9a1df8337e6ef3844986a0cd,openstack/openstack-manuals,master,Iff5a1c4bbf27b3ed9a1df8337e6ef3844986a0cd,[cli-ref] Update python-watcherclient to 1.2.0,MERGED,2017-06-09 03:49:41.000000000,2017-06-18 17:27:38.000000000,2017-06-18 17:27:38.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 17130}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 03:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/71876a0eb6c6bac5b7434872aa7aad5c746cf515', 'message': '[cli-ref] Update python-watcherclient to 1.2.0\n\nChange-Id: Iff5a1c4bbf27b3ed9a1df8337e6ef3844986a0cd\n'}, {'number': 2, 'created': '2017-06-09 05:12:53.000000000', 'files': ['doc/cli-reference/source/watcher.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8a338eaa253e1b33ea9815a7299cdba070ae47f4', 'message': '[cli-ref] Update python-watcherclient to 1.2.0\n\nChange-Id: Iff5a1c4bbf27b3ed9a1df8337e6ef3844986a0cd\n'}]",0,472513,8a338eaa253e1b33ea9815a7299cdba070ae47f4,11,5,2,19779,,,0,"[cli-ref] Update python-watcherclient to 1.2.0

Change-Id: Iff5a1c4bbf27b3ed9a1df8337e6ef3844986a0cd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/472513/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/watcher.rst'],1,71876a0eb6c6bac5b7434872aa7aad5c746cf515,cli-reference,This chapter documents :command:`watcher` version ``1.2.0``. ,This chapter documents :command:`watcher` version ``1.1.0``.,2,2
openstack%2Fopenstack-manuals~master~Ia7e03d7fca0a6699bc1e18625b3fdb84b1dcc0ef,openstack/openstack-manuals,master,Ia7e03d7fca0a6699bc1e18625b3fdb84b1dcc0ef,[cli-ref] Update python-manilaclient to 1.16.0,MERGED,2017-06-09 03:57:36.000000000,2017-06-18 17:27:32.000000000,2017-06-18 17:27:31.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 17130}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 03:57:36.000000000', 'files': ['doc/cli-reference/source/manila.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1ba5e64433168cfd3a59be3d3032d12570d65df7', 'message': '[cli-ref] Update python-manilaclient to 1.16.0\n\nChange-Id: Ia7e03d7fca0a6699bc1e18625b3fdb84b1dcc0ef\n'}]",0,472518,1ba5e64433168cfd3a59be3d3032d12570d65df7,9,5,1,19779,,,0,"[cli-ref] Update python-manilaclient to 1.16.0

Change-Id: Ia7e03d7fca0a6699bc1e18625b3fdb84b1dcc0ef
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/472518/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/manila.rst'],1,1ba5e64433168cfd3a59be3d3032d12570d65df7,cli-reference,"This chapter documents :command:`manila` version ``1.16.0``. Comma separated list of columns to be displayed example --columns ""access_type,access_to"". Comma separated list of columns to be displayed example --columns ""id,name"". deprecated. (Default=None) Comma separated list of columns to be displayed example --columns ""id,name"". Default=None. Default=None. 'size', 'host', 'share_proto', 'availability_zone', 'user_id', 'project_id', 'created_at', 'updated_at', 'display_name', 'name', 'share_type_id', 'share_type', 'share_network_id', 'share_network', 'snapshot_id', 'snapshot'). OPTIONAL: Default=None. Comma separated list of columns to be displayed example --columns ""export_location,is public"". manage-share service host: some.host@driver#pool. \\\\10.0.0.1\\example_cifs_share. microversion >= 2.8. Comma separated list of columns to be displayed example --columns ""name,host"". (Default=None)Available only for microversion >= 2.23. Comma separated list of columns to be displayed example --columns ""verb,uri,value"". Name or ID of the security service(s) to delete. Comma separated list of columns to be displayed example --columns ""name,type"". Comma separated list of columns to be displayed example --columns ""id,host"". Comma separated list of columns to be displayed example --columns ""id,host,status"". Comma separated list of columns to be displayed example --columns ""id,name"". Maximum number of share group snapshots to return. (Default=None) Comma separated list of columns to be displayed example --columns ""id,name"". Comma separated list of columns to be displayed example --columns ""id,name"". (Default=None) Comma separated list of columns to be displayed example --columns ""id,name"". Comma separated list of columns to be displayed example --columns ""id,name"". Comma separated list of columns to be displayed example --columns ""id,host,status"". Comma separated list of columns to be displayed example --columns ""id,host,status"". Comma separated list of columns to be displayed example --columns ""id"". Comma separated list of columns to be displayed example --columns ""id,name"". Comma separated list of columns to be displayed example --columns ""replica_state,id"". Comma separated list of columns to be displayed example --columns ""id,host,status"". Comma separated list of columns to be displayed example --columns ""access_type,access_to"". Comma separated list of columns to be displayed example --columns ""id,path"". Comma separated list of columns to be displayed example --columns ""id,path,is_admin_only"". Comma separated list of columns to be displayed example --columns ""id"". Comma separated list of columns to be displayed example --columns ""id,name"". 'true'/'1' and 'false'/'0'. example --extra-specs thin_provisioning='<is> True', Comma separated list of columns to be displayed example --columns ""id,name"".","This chapter documents :command:`manila` version ``1.15.0``. Comma separated list of columns to be displayed e.g. --columns ""access_type,access_to"" Comma separated list of columns to be displayed e.g. --columns ""id,name"" deprecated(Default=None) Comma separated list of columns to be displayed e.g. --columns ""id,name"" Default=None Default=None 'size', 'host', 'share_proto', 'export_location', 'availability_zone', 'user_id', 'project_id', 'created_at', 'updated_at', 'display_name', 'name', 'share_type_id', 'share_type', 'share_network_id', 'share_network', 'snapshot_id', 'snapshot'). OPTIONAL: Default=None. Comma separated list of columns to be displayed e.g. --columns ""export_location,is public"" manage-share service host: some.host@driver#pool \\\\10.0.0.1\\example_cifs_share microversion >= 2.8 Comma separated list of columns to be displayed e.g. --columns ""name,host"" (Default=None)Available only for microversion >= 2.23 Comma separated list of columns to be displayed e.g. --columns ""verb,uri,value"" Name or ID of the security service(s) to delete Comma separated list of columns to be displayed e.g. --columns ""name,type"" Comma separated list of columns to be displayed e.g. --columns ""id,host"" Comma separated list of columns to be displayed e.g. --columns ""id,host,status"" Comma separated list of columns to be displayed e.g. --columns ""id,name"" Maximum number of share group snapshots to return.(Default=None) Comma separated list of columns to be displayed e.g. --columns ""id,name"" Comma separated list of columns to be displayed e.g. --columns ""id,name"" (Default=None Comma separated list of columns to be displayed e.g. --columns ""id,name"" Comma separated list of columns to be displayed e.g. --columns ""id,name"" Comma separated list of columns to be displayed e.g. --columns ""id,host,status"" Comma separated list of columns to be displayed e.g. --columns ""id,host,status"" Comma separated list of columns to be displayed e.g. --columns ""id"" Comma separated list of columns to be displayed e.g. --columns ""id,name"" Comma separated list of columns to be displayed e.g. --columns ""replica_state,id"" Comma separated list of columns to be displayed e.g. --columns ""id,host,status"" Comma separated list of columns to be displayed e.g. --columns ""access_type,access_to"" Comma separated list of columns to be displayed e.g. --columns ""id,path"" Comma separated list of columns to be displayed e.g. --columns ""id,path,is_admin_only"" Comma separated list of columns to be displayed e.g. --columns ""id"" Comma separated list of columns to be displayed e.g. --columns ""id,name"" 'true'/'1' and 'false'/'0' e.g --extra-specs thin_provisioning='<is> True', Comma separated list of columns to be displayed e.g. --columns ""id,name""",71,72
openstack%2Fsecurity-doc~master~I5d0c7c238629e79db9e660c267f2c59b4cd943ff,openstack/security-doc,master,I5d0c7c238629e79db9e660c267f2c59b4cd943ff,Update note to mention Ocata and EOL releases,MERGED,2017-06-01 23:16:30.000000000,2017-06-18 17:21:08.000000000,2017-06-18 17:21:08.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 7063}, {'_account_id': 10607}, {'_account_id': 12686}, {'_account_id': 21797}, {'_account_id': 25323}]","[{'number': 1, 'created': '2017-06-01 23:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/5f278b769a3076562de687bdf3c96f95f48f1045', 'message': 'Update note to mention Ocata and EOL releases\n\nSecurity guide updated to include Ocata as supported release\nand mention that content may not apply for EOL releases.\n\nChange-Id: I5d0c7c238629e79db9e660c267f2c59b4cd943ff\nCloses-Bug:#1694187\nPartial-Bug: #1691058\n'}, {'number': 2, 'created': '2017-06-06 15:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/23f62893938d8a48db8a139315f3fb4d478d2935', 'message': 'Update note to mention Ocata and EOL releases\n\nSecurity guide updated to include Ocata as supported release\nand mention that content may not apply for EOL releases.\n\nChange-Id: I5d0c7c238629e79db9e660c267f2c59b4cd943ff\nCloses-Bug:#1694187\nPartial-Bug: #1691058\n'}, {'number': 3, 'created': '2017-06-06 16:06:33.000000000', 'files': ['security-guide/source/index.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/f8a4a80e21016b0f7395659f44243dd909e0ffff', 'message': 'Update note to mention Ocata and EOL releases\n\nSecurity guide updated to include Ocata as supported release\nand mention that content may not apply for EOL releases.\n\nChange-Id: I5d0c7c238629e79db9e660c267f2c59b4cd943ff\nCloses-Bug:#1694187\nPartial-Bug: #1691058\n'}]",1,470059,f8a4a80e21016b0f7395659f44243dd909e0ffff,21,8,3,25323,,,0,"Update note to mention Ocata and EOL releases

Security guide updated to include Ocata as supported release
and mention that content may not apply for EOL releases.

Change-Id: I5d0c7c238629e79db9e660c267f2c59b4cd943ff
Closes-Bug:#1694187
Partial-Bug: #1691058
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/59/470059/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/source/index.rst'],1,5f278b769a3076562de687bdf3c96f95f48f1045,bug/1694187,".. note:: This guide documents OpenStack Ocata, Newton, and Mitaka releases and may not apply to EOL releases Kilo and Liberty. ",This guide documents OpenStack Newton and Mitaka releases.,4,1
openstack%2Freno~master~I0f36fc6b8d9112752b13028ba5b07f2a05504f5b,openstack/reno,master,I0f36fc6b8d9112752b13028ba5b07f2a05504f5b,Remove Babel from setup.cfg and requirements,MERGED,2017-06-01 07:59:35.000000000,2017-06-18 17:20:40.000000000,2017-06-18 17:20:40.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6547}, {'_account_id': 14070}]","[{'number': 1, 'created': '2017-06-01 07:59:35.000000000', 'files': ['requirements.txt', 'babel.cfg', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/reno/commit/2f5ad2897f36aba724d599941f4fdd05715118f8', 'message': ""Remove Babel from setup.cfg and requirements\n\nIt's not imported by reno at runtime and no translation has been setup at all.\n\nChange-Id: I0f36fc6b8d9112752b13028ba5b07f2a05504f5b\n""}]",0,469801,2f5ad2897f36aba724d599941f4fdd05715118f8,10,4,1,1669,,,0,"Remove Babel from setup.cfg and requirements

It's not imported by reno at runtime and no translation has been setup at all.

Change-Id: I0f36fc6b8d9112752b13028ba5b07f2a05504f5b
",git fetch https://review.opendev.org/openstack/reno refs/changes/01/469801/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'babel.cfg', 'setup.cfg']",3,2f5ad2897f36aba724d599941f4fdd05715118f8,jd/babel,, [extract_messages] keywords = _ gettext ngettext l_ lazy_gettext mapping_file = babel.cfg output_file = reno/locale/reno.pot,0,8
openstack%2Freno~master~I26be8c3027aebbfb1bf4a6f17c6f995dc44aac1a,openstack/reno,master,I26be8c3027aebbfb1bf4a6f17c6f995dc44aac1a,expand examples in documentation,MERGED,2017-06-05 19:52:41.000000000,2017-06-18 17:20:34.000000000,2017-06-18 17:20:34.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 14070}]","[{'number': 1, 'created': '2017-06-05 19:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reno/commit/0f397b6eee20e52f1a6221313d498e5332dde81d', 'message': 'expand examples in documentation\n\nAdd examples showing how sections that take lists of strings can also\ninclude a single string, and expand on why the escaped rst formatting\nworks.\n\nChange-Id: I26be8c3027aebbfb1bf4a6f17c6f995dc44aac1a\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2017-06-06 16:27:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/reno/commit/e6cb42bce4994caa61753bbf4c87f2b11a12b18d', 'message': 'expand examples in documentation\n\nAdd examples showing how sections that take lists of strings can also\ninclude a single string, and expand on why the escaped rst formatting\nworks.\n\nChange-Id: I26be8c3027aebbfb1bf4a6f17c6f995dc44aac1a\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 3, 'created': '2017-06-06 21:07:55.000000000', 'files': ['examples/notes/add-complex-example-6b5927c246456896.yaml', 'doc/source/examples.rst'], 'web_link': 'https://opendev.org/openstack/reno/commit/8666d22065dc0b2d80d3b48b3310c20b3d601f1e', 'message': 'expand examples in documentation\n\nAdd examples showing how sections that take lists of strings can also\ninclude a single string, and expand on why the escaped rst formatting\nworks.\n\nChange-Id: I26be8c3027aebbfb1bf4a6f17c6f995dc44aac1a\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",4,471118,8666d22065dc0b2d80d3b48b3310c20b3d601f1e,19,7,3,2472,,,0,"expand examples in documentation

Add examples showing how sections that take lists of strings can also
include a single string, and expand on why the escaped rst formatting
works.

Change-Id: I26be8c3027aebbfb1bf4a6f17c6f995dc44aac1a
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/reno refs/changes/18/471118/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/notes/add-complex-example-6b5927c246456896.yaml', 'doc/source/examples.rst']",2,0f397b6eee20e52f1a6221313d498e5332dde81d,allow-simple-strings,========== Examples ========== Input file ========== .. literalinclude:: ../../examples/notes/add-complex-example-6b5927c246456896.yaml :caption: examples/notes/add-complex-example-6b5927c246456896.yaml Rendered ======== .. release-notes:: :earliest-version: 1.0.0,.. release-notes:: Examples,24,5
openstack%2Fopenstack-manuals~master~Ic704ebcf8eab8b6a33674c61c6a47f4fb85163a3,openstack/openstack-manuals,master,Ic704ebcf8eab8b6a33674c61c6a47f4fb85163a3,[cli-ref] Update python-magnumclient to 2.6.0,MERGED,2017-06-13 05:46:27.000000000,2017-06-18 17:06:15.000000000,2017-06-18 17:06:15.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 20156}]","[{'number': 1, 'created': '2017-06-13 05:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0a272859bec55fd08ea9a3ea20a95ec69a94c345', 'message': '[cli-ref] Update python-magnumclient to 2.6.0\n\nChange-Id: Ic704ebcf8eab8b6a33674c61c6a47f4fb85163a3\n'}, {'number': 2, 'created': '2017-06-14 03:24:18.000000000', 'files': ['doc/cli-reference/source/magnum.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/276240d1b94398de5027804653c2f86ec74c2b58', 'message': '[cli-ref] Update python-magnumclient to 2.6.0\n\nChange-Id: Ic704ebcf8eab8b6a33674c61c6a47f4fb85163a3\n'}]",0,473688,276240d1b94398de5027804653c2f86ec74c2b58,9,3,2,19779,,,0,"[cli-ref] Update python-magnumclient to 2.6.0

Change-Id: Ic704ebcf8eab8b6a33674c61c6a47f4fb85163a3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/88/473688/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/magnum.rst'],1,0a272859bec55fd08ea9a3ea20a95ec69a94c345,cli-reference,"the Container Infrastructure Management service (magnum) API and its extensions. This chapter documents :command:`magnum` version ``2.6.0``.``ca-rotate`` Rotate the CA certificate for a bay or cluster to revoke access. ``quotas-create`` Create a quota. ``quotas-delete`` Delete specified resource quota. ``quotas-list`` Print a list of available quotas. ``quotas-show`` Show details about the given project resource quota. ``quotas-update`` Update information about the given project resource quota. OSprofiler middleware in magnum; it is specified in the Magnum configuration file at ""/etc/magnum/magnum.conf"". Without the key, profiling will not be triggered even if OSprofiler is enabled on the server side. .. _magnum_ca-rotate: magnum ca-rotate ---------------- .. code-block:: console usage: magnum ca-rotate --cluster <cluster> Rotate the CA certificate for a bay or cluster to revoke access. **Optional arguments:** ``--cluster <cluster>`` ID or name of the cluster. [<name>]**Positional arguments:** ``<name>`` Name of the cluster to create. Name of the keypair to use for this cluster. This parameter is deprecated and will be removed in a Name of the keypair to use for this cluster. Name of the cluster to create. The --name parameter is deprecated and will be removed in a future release. Use the <name> positional parameter instead. [--insecure-registry <insecure-registry>] [<name>]**Positional arguments:** ``<name>`` Name of the cluster template to create. The name of the SSH keypair to load into the Cluster nodes. This parameter is deprecated and will be removed in a future release. Use --keypair instead. The name of the SSH keypair to load into the Cluster nodes. Name of the cluster template to create. The --name parameter is deprecated and will be removed in a future release. Use the <name> positional parameter instead.``--insecure-registry <insecure-registry>`` url of docker registry [--fields <fields>] [--detail]``--detail`` Show detailed information about the cluster templates. .. _magnum_quotas-create: magnum quotas-create -------------------- .. code-block:: console usage: magnum quotas-create --project-id <project-id> --resource <resource> [--hard-limit <hard-limit>] Create a quota. **Optional arguments:** ``--project-id <project-id>`` Project Id. ``--resource <resource>`` Resource name. ``--hard-limit <hard-limit>`` Max resource limit. .. _magnum_quotas-delete: magnum quotas-delete -------------------- .. code-block:: console usage: magnum quotas-delete --project-id <project-id> --resource <resource> Delete specified resource quota. **Optional arguments:** ``--project-id <project-id>`` Project ID. ``--resource <resource>`` Resource name .. _magnum_quotas-list: magnum quotas-list ------------------ .. code-block:: console usage: magnum quotas-list [--marker <marker>] [--limit <limit>] [--sort-key <sort-key>] [--sort-dir <sort-dir>] [--all-tenants] Print a list of available quotas. **Optional arguments:** ``--marker <marker>`` The last quota UUID of the previous page; displays list of quotas after ""marker"". ``--limit <limit>`` Maximum number of quotas to return. ``--sort-key <sort-key>`` Column to sort results by. ``--sort-dir <sort-dir>`` Direction to sort. ""asc"" or ""desc"". ``--all-tenants`` Flag to indicate list all tenant quotas. .. _magnum_quotas-show: magnum quotas-show ------------------ .. code-block:: console usage: magnum quotas-show --project-id <project-id> --resource <resource> Show details about the given project resource quota. **Optional arguments:** ``--project-id <project-id>`` Project ID. ``--resource <resource>`` Resource name .. _magnum_quotas-update: magnum quotas-update -------------------- .. code-block:: console usage: magnum quotas-update --project-id <project-id> --resource <resource> [--hard-limit <hard-limit>] Update information about the given project resource quota. **Optional arguments:** ``--project-id <project-id>`` Project Id. ``--resource <resource>`` Resource name. ``--hard-limit <hard-limit>`` Max resource limit. ","the Container Infrastructure Management service (magnum) API and its extensions. This chapter documents :command:`magnum` version ``2.5.0``. OSprofiler middleware in nova; it is specified in the Nova configuration file at ""/etc/nova/nova.conf"". Without the key, profiling will not be triggered even if OSprofiler is enabled on the server side. UUID or name of the keypair to use for this cluster. This parameter is deprecated and will be removed in a UUID or name of the keypair to use for this cluster. Name of the cluster to create. The name or UUID of the SSH keypair to load into the Cluster nodes. This parameter is deprecated and will be removed in a future release. Use --keypair instead. The name or UUID of the SSH keypair to load into the Cluster nodes. Name of the cluster template to create. [--fields <fields>]",193,18
openstack%2Fopenstack-ansible-os_glance~master~I2f1e8ef4821f865af36b34f4edd98255a12dd55d,openstack/openstack-ansible-os_glance,master,I2f1e8ef4821f865af36b34f4edd98255a12dd55d,Switch to Cryptography over pycrypto,MERGED,2017-06-07 09:21:32.000000000,2017-06-18 17:04:52.000000000,2017-06-18 17:04:52.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-07 09:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/e07ea07ded4ee9ab84b06e8b48a7b1f7ad03aba5', 'message': 'Switch to Cryptography over pycrypto\n\nThe keystonemiddleware library recently switched to using the\ncryptography library over pycrypto, which was unmaintained. See\nIced7f5115e49ccf4f7f5bf6813cb5988b95c248b\n\nChange-Id: I2f1e8ef4821f865af36b34f4edd98255a12dd55d\nCo-Authored-By: Nolan Brubaker <nolan.brubaker@rackspace.com>\n'}, {'number': 2, 'created': '2017-06-07 17:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/9b74f1537c8a168ed468a24cd19e7616ad548112', 'message': 'Switch to Cryptography over pycrypto\n\nThe keystonemiddleware library recently switched to using the\ncryptography library over pycrypto, which was unmaintained. See\nIced7f5115e49ccf4f7f5bf6813cb5988b95c248b\n\nChange-Id: I2f1e8ef4821f865af36b34f4edd98255a12dd55d\nCo-Authored-By: Nolan Brubaker <nolan.brubaker@rackspace.com>\n'}, {'number': 3, 'created': '2017-06-08 08:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/ec64eeab24e58538d6295e8740a3adf0dd3b677b', 'message': 'Switch to Cryptography over pycrypto\n\nThe keystonemiddleware library recently switched to using the\ncryptography library over pycrypto, which was unmaintained. See\nIced7f5115e49ccf4f7f5bf6813cb5988b95c248b\n\nChange-Id: I2f1e8ef4821f865af36b34f4edd98255a12dd55d\nCo-Authored-By: Nolan Brubaker <nolan.brubaker@rackspace.com>\n'}, {'number': 4, 'created': '2017-06-14 15:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/2f15e4ad7287901d92d808c829758ee10bfde848', 'message': 'Switch to Cryptography over pycrypto\n\nThe keystonemiddleware library recently switched to using the\ncryptography library over pycrypto, which was unmaintained. See\nIced7f5115e49ccf4f7f5bf6813cb5988b95c248b\n\nChange-Id: I2f1e8ef4821f865af36b34f4edd98255a12dd55d\nCo-Authored-By: Nolan Brubaker <nolan.brubaker@rackspace.com>\n'}, {'number': 5, 'created': '2017-06-18 15:08:19.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/10fc37d555794ca71d6106ac457e2e6e5f0e2169', 'message': 'Switch to Cryptography over pycrypto\n\nThe keystonemiddleware library recently switched to using the\ncryptography library over pycrypto, which was unmaintained. See\nIced7f5115e49ccf4f7f5bf6813cb5988b95c248b\n\nChange-Id: I2f1e8ef4821f865af36b34f4edd98255a12dd55d\nCo-Authored-By: Nolan Brubaker <nolan.brubaker@rackspace.com>\n'}]",0,471657,10fc37d555794ca71d6106ac457e2e6e5f0e2169,32,5,5,6816,,,0,"Switch to Cryptography over pycrypto

The keystonemiddleware library recently switched to using the
cryptography library over pycrypto, which was unmaintained. See
Iced7f5115e49ccf4f7f5bf6813cb5988b95c248b

Change-Id: I2f1e8ef4821f865af36b34f4edd98255a12dd55d
Co-Authored-By: Nolan Brubaker <nolan.brubaker@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/57/471657/3 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,e07ea07ded4ee9ab84b06e8b48a7b1f7ad03aba5,pycrypto-cryptography, - cryptography, - pycrypto,1,1
openstack%2Fopenstack-manuals~master~I8cada3b45eaf9f34a9182a07e6e747e0161eea9f,openstack/openstack-manuals,master,I8cada3b45eaf9f34a9182a07e6e747e0161eea9f,[cli-ref] Update python-vitrageclient to 1.2.0,MERGED,2017-06-09 03:51:27.000000000,2017-06-18 17:02:57.000000000,2017-06-18 17:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 17130}, {'_account_id': 20156}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 03:51:27.000000000', 'files': ['doc/cli-reference/source/vitrage.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/35399f94e656ff451037b537e521399ab56d8ceb', 'message': '[cli-ref] Update python-vitrageclient to 1.2.0\n\nChange-Id: I8cada3b45eaf9f34a9182a07e6e747e0161eea9f\n'}]",2,472514,35399f94e656ff451037b537e521399ab56d8ceb,11,6,1,19779,,,0,"[cli-ref] Update python-vitrageclient to 1.2.0

Change-Id: I8cada3b45eaf9f34a9182a07e6e747e0161eea9f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/14/472514/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/vitrage.rst'],1,35399f94e656ff451037b537e521399ab56d8ceb,cli-reference,This chapter documents :command:`vitrage` version ``1.2.0``. [--all-tenants]``--all-tenants`` [--noindent] [--prefix PREFIX] [--all-tenants] alarm_vitrage_id``alarm_vitrage_id````--all-tenants`` [--type <resource type>] [--all-tenants]``--all-tenants`` Shows resources of all the tenants vitrage_id``vitrage_id`` vitrage_id of a resource [--all-tenants]``--all-tenants``,This chapter documents :command:`vitrage` version ``1.1.1``. [--all-tenants [<0|1>]]``--all-tenants [<0|1>]`` [--noindent] [--prefix PREFIX] [--all-tenants [<0|1>]] alarm_id``alarm_id````--all-tenants [<0|1>]`` [--type <resource type>] resource_id``resource_id`` ID of a resource [--all-tenants [<0|1>]]``--all-tenants [<0|1>]``,16,13
openstack%2Fopenstack-manuals~master~I141b5addc5ca9b2146619989d844325f05fdbea9,openstack/openstack-manuals,master,I141b5addc5ca9b2146619989d844325f05fdbea9,Update the file format for disable_libvirt_livesnapshot,MERGED,2017-06-09 16:23:31.000000000,2017-06-18 16:33:54.000000000,2017-06-18 16:33:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-09 16:23:31.000000000', 'files': ['doc/ops-guide/source/ops-user-facing-operations.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5037b0bca1854d5325a24ccc0ad5afbad7a3fa9b', 'message': 'Update the file format for disable_libvirt_livesnapshot\n\nChange-Id: I141b5addc5ca9b2146619989d844325f05fdbea9\n'}]",0,472749,5037b0bca1854d5325a24ccc0ad5afbad7a3fa9b,7,2,1,22165,,,0,"Update the file format for disable_libvirt_livesnapshot

Change-Id: I141b5addc5ca9b2146619989d844325f05fdbea9
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/49/472749/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ops-guide/source/ops-user-facing-operations.rst'],1,5037b0bca1854d5325a24ccc0ad5afbad7a3fa9b,, disable_libvirt_livesnapshot = True, disable_libvirt_livesnapshot = True,1,1
openstack%2Fkolla~master~Ie3c73bcebccffcca7d49858cdb2599eaf566670e,openstack/kolla,master,Ie3c73bcebccffcca7d49858cdb2599eaf566670e,Fix zaqar build on Ubuntu/Debian,MERGED,2017-06-18 00:55:16.000000000,2017-06-18 16:19:38.000000000,2017-06-18 16:19:38.000000000,"[{'_account_id': 3}, {'_account_id': 8157}, {'_account_id': 11869}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-18 00:55:16.000000000', 'files': ['docker/zaqar/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/31f2cc5b4fb8221ec76f29b699dd4440802ae3c7', 'message': ""Fix zaqar build on Ubuntu/Debian\n\nAdd missing ',' when building zaqar for Ubuntu/Debian.\n\nChange-Id: Ie3c73bcebccffcca7d49858cdb2599eaf566670e\nSigned-off-by: Chuck Short <zulcss@gmail.com>\n""}]",0,475152,31f2cc5b4fb8221ec76f29b699dd4440802ae3c7,8,4,1,24,,,0,"Fix zaqar build on Ubuntu/Debian

Add missing ',' when building zaqar for Ubuntu/Debian.

Change-Id: Ie3c73bcebccffcca7d49858cdb2599eaf566670e
Signed-off-by: Chuck Short <zulcss@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/52/475152/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/zaqar/Dockerfile.j2'],1,31f2cc5b4fb8221ec76f29b699dd4440802ae3c7,," 'libapache2-mod-wsgi',", 'libapache2-mod-wsgi',1,1
openstack%2Fopenstack-ansible-os_glance~master~I03afeccfd445335cf80c7181066d8df2936a6a6b,openstack/openstack-ansible-os_glance,master,I03afeccfd445335cf80c7181066d8df2936a6a6b,Install openstacksdk for rolling upgrade test,MERGED,2017-06-16 01:01:49.000000000,2017-06-18 15:30:35.000000000,2017-06-18 15:30:35.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-16 01:01:49.000000000', 'files': ['tests/test-glance-resources-upgrade.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/d319fd2bb4bf6c0e3701ba4d16a5a4db68e447a4', 'message': 'Install openstacksdk for rolling upgrade test\n\nbowling_ball requires the openstacksdk be installed.\n\nChange-Id: I03afeccfd445335cf80c7181066d8df2936a6a6b\n'}]",0,474820,d319fd2bb4bf6c0e3701ba4d16a5a4db68e447a4,10,2,1,14805,,,0,"Install openstacksdk for rolling upgrade test

bowling_ball requires the openstacksdk be installed.

Change-Id: I03afeccfd445335cf80c7181066d8df2936a6a6b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/20/474820/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test-glance-resources-upgrade.yml'],1,d319fd2bb4bf6c0e3701ba4d16a5a4db68e447a4,install-sdk, - python-keystoneclient - python-openstacksdk, - python-keystoneclient,2,1
openstack%2Fopenstack-ansible-os_horizon~master~Ib9b527d60226d3133206675b394d83f1185631b2,openstack/openstack-ansible-os_horizon,master,Ib9b527d60226d3133206675b394d83f1185631b2,Add Translations update steps.,MERGED,2017-06-08 15:28:03.000000000,2017-06-18 14:43:30.000000000,2017-06-18 14:43:30.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-06-08 15:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/e8fd2bd0f2b4aff39cb6b26632dc13818ac0cad3', 'message': ""Add Translations update steps.\n\nTo facilitiate a translations check site this patch enables the ability\nto perform a pull_catalog and compilemessages, which will update the\ntranslations site. By default this won't run at all.\n\nChange-Id: Ib9b527d60226d3133206675b394d83f1185631b2\n""}, {'number': 2, 'created': '2017-06-08 16:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/d805bcd5648c3f2e4f5d1c2a5030b3c4c8c8e7f4', 'message': ""Add Translations update steps.\n\nTo facilitiate a translations check site this patch enables the ability\nto perform a pull_catalog and compilemessages, which will update the\ntranslations site. By default this won't run at all.\n\nChange-Id: Ib9b527d60226d3133206675b394d83f1185631b2\n""}, {'number': 3, 'created': '2017-06-18 13:48:30.000000000', 'files': ['tasks/main.yml', 'tasks/horizon_translations_update.yml', 'defaults/main.yml', 'releasenotes/notes/update_translations-f950283d821bba05.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/0fa5b5942826a4d17f18b416f371cbb792606bd9', 'message': ""Add Translations update steps.\n\nTo facilitiate a translations check site this patch enables the ability\nto perform a pull_catalog and compilemessages, which will update the\ntranslations site. By default this won't run at all.\n\nChange-Id: Ib9b527d60226d3133206675b394d83f1185631b2\n""}]",1,472296,0fa5b5942826a4d17f18b416f371cbb792606bd9,17,4,3,2799,,,0,"Add Translations update steps.

To facilitiate a translations check site this patch enables the ability
to perform a pull_catalog and compilemessages, which will update the
translations site. By default this won't run at all.

Change-Id: Ib9b527d60226d3133206675b394d83f1185631b2
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/96/472296/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'tasks/horizon_translations_update.yml', 'defaults/main.yml', 'releasenotes/notes/update_translations-f950283d821bba05.yaml']",4,e8fd2bd0f2b4aff39cb6b26632dc13818ac0cad3,,"--- features: - You can force update the translations direct from Zanata by setting ``horizon_translations_update`` to ``True``. This will call the ``pull_catalog`` option built into ``horizon-manage.py``. You should only use this when testing translations, otherwise this should remain set to the default of ``False``. ",,45,0
openstack%2Fopenstack-ansible-tests~master~I7099fa2418b2633c378c37e83384fc78d7fbe554,openstack/openstack-ansible-tests,master,I7099fa2418b2633c378c37e83384fc78d7fbe554,sync-test-repos.sh: Add Zuul environment support for synchronizing files,MERGED,2017-05-25 13:33:55.000000000,2017-06-18 14:41:03.000000000,2017-06-18 14:41:03.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-05-25 13:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/6a3f08fc019d9e062184d0b6750b6249be311a35', 'message': 'sync-test-repos.sh: Add Zuul environment support for synchronizing files\n\nWe could re-use this script in the OpenStack CI propose job. For this to\nhappen we need to know if we are running in Zuul, and if we do, then we\nneed to consult the first argument which is normally the OSA project\nwe want to synchronize the files to. As such, add a new codepath which\nonly does a simple copy of files.\n\nChange-Id: I7099fa2418b2633c378c37e83384fc78d7fbe554\n'}, {'number': 2, 'created': '2017-06-13 12:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/4db971bc3ca61c05a2211d29af435f67aa2690a1', 'message': 'sync-test-repos.sh: Add Zuul environment support for synchronizing files\n\nWe could re-use this script in the OpenStack CI propose job. For this to\nhappen we need to know if we are running in Zuul, and if we do, then we\nneed to consult the first argument which is normally the OSA project\nwe want to synchronize the files to. As such, add a new codepath which\nonly does a simple copy of files.\n\nChange-Id: I7099fa2418b2633c378c37e83384fc78d7fbe554\n'}, {'number': 3, 'created': '2017-06-16 18:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/bd3c607ff943ffc23cf79033cde7e0016c49fef3', 'message': 'sync-test-repos.sh: Add Zuul environment support for synchronizing files\n\nWe could re-use this script in the OpenStack CI propose job. For this to\nhappen we need to know if we are running in Zuul, and if we do, then we\nneed to consult the first argument which is normally the OSA project\nwe want to synchronize the files to. As such, add a new codepath which\nonly does a simple copy of files.\n\nChange-Id: I7099fa2418b2633c378c37e83384fc78d7fbe554\n'}, {'number': 4, 'created': '2017-06-18 13:45:30.000000000', 'files': ['sync-test-repos.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/48b08010a5ffc57c1ae480fad74f05e17e9ab6d5', 'message': 'sync-test-repos.sh: Add Zuul environment support for synchronizing files\n\nWe could re-use this script in the OpenStack CI propose job. For this to\nhappen we need to know if we are running in Zuul, and if we do, then we\nneed to consult the first argument which is normally the OSA project\nwe want to synchronize the files to. As such, add a new codepath which\nonly does a simple copy of files.\n\nChange-Id: I7099fa2418b2633c378c37e83384fc78d7fbe554\n'}]",0,468034,48b08010a5ffc57c1ae480fad74f05e17e9ab6d5,35,4,4,23163,,,0,"sync-test-repos.sh: Add Zuul environment support for synchronizing files

We could re-use this script in the OpenStack CI propose job. For this to
happen we need to know if we are running in Zuul, and if we do, then we
need to consult the first argument which is normally the OSA project
we want to synchronize the files to. As such, add a new codepath which
only does a simple copy of files.

Change-Id: I7099fa2418b2633c378c37e83384fc78d7fbe554
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/34/468034/3 && git format-patch -1 --stdout FETCH_HEAD,['sync-test-repos.sh'],1,6a3f08fc019d9e062184d0b6750b6249be311a35,sync-files-allow-project-dir,"copy_files() { local osa_project=${1} # Copy files for f in ${files_to_sync[@]}; do [[ ! -e ${osa_project}/$f ]] && continue cp $f ${osa_project}/$f done } -h|--help) usage; exit 1 ;;# Always exclude openstack-ansible-tests repository. This is not # necessary because osa_projects should never include ""openstack-ansible-tests"" # but it can serve as an example for users who may add more # projects in the future. exclude_project ""openstack-ansible-tests"" ############################# ZUUL SYNCING ################################### # If we running in the OpenStack CI then the first argument is going to be the # project directory and all we need to do is to simply copy files. The # environment is already prepared. if env | grep -q ^ZUUL; then # Some debug information. echo ""Running in a Zuul environment"" echo ""Current directory: $(pwd)"" echo ""OSA project: '${1}'"" # Do we need to skip that repo? check_and_ignore ${1} && exit 0 # This should never happen if Zuul is working properly [[ ! -d ${1} ]] && { echo ""${1} does not exit! Refusing to proceed""; exit 1; } copy_files ${1} # Return back to zuul. No furher processing is required. exit 0 else declare -ra osa_projects=($(./gen-projects-list.sh)) fi pushd openstack-ansible-tests &> /dev/null copy_files ${proj_dir} popd &> /dev/null "," -h|--help|*) usage; exit 1 ;;declare -ra osa_projects=($(./gen-projects-list.sh))# Always exclude openstack-ansible-tests repository. This is not # necessary because osa_projects should never include ""openstack-ansible-tests"" # but it can serve as an example for users who may add more # projects in the future. exclude_project ""openstack-ansible-tests"" for f in ${files_to_sync[@]}; do cp openstack-ansible-tests/$f ${proj_dir}/$f done",45,11
openstack%2Fopenstack-ansible-os_ceilometer~master~Iae293bf96e31b04cb89a0f12963602e6030fe697,openstack/openstack-ansible-os_ceilometer,master,Iae293bf96e31b04cb89a0f12963602e6030fe697,Fix for lookup not detecting errors and happening from wrong place,ABANDONED,2017-05-10 15:41:00.000000000,2017-06-18 13:53:12.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-05-10 15:41:00.000000000', 'files': ['tasks/ceilometer_post_install.yml', 'tasks/ceilometer_post_install_config_template.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/8f26ebdf804cca29789bb5332f7e8dd791ca965f', 'message': ""Fix for lookup not detecting errors and happening from wrong place\n\nThe lookup here occurs from the deployment host and not the container\nhost itself this means that if the deployment host doesn't have direct\naccess to the network it fails.\n\nSecondly because lookups don't have any real error checking, in our case\nafter the proxy timeout it simply takes the contents of this failed page\nand templates it out.\n\nThe following fix allows for some error checking and it will occur from\nthe correct host.\n\nChange-Id: Iae293bf96e31b04cb89a0f12963602e6030fe697\n""}]",0,463811,8f26ebdf804cca29789bb5332f7e8dd791ca965f,5,2,1,25022,,,0,"Fix for lookup not detecting errors and happening from wrong place

The lookup here occurs from the deployment host and not the container
host itself this means that if the deployment host doesn't have direct
access to the network it fails.

Secondly because lookups don't have any real error checking, in our case
after the proxy timeout it simply takes the contents of this failed page
and templates it out.

The following fix allows for some error checking and it will occur from
the correct host.

Change-Id: Iae293bf96e31b04cb89a0f12963602e6030fe697
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/11/463811/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/ceilometer_post_install.yml', 'tasks/ceilometer_post_install_config_template.yml']",2,8f26ebdf804cca29789bb5332f7e8dd791ca965f,venv_checksum_fix,"--- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Build up URL and retrieve config_template upstream files uri: url: ""{{ ceilometer_git_config_lookup_location ~ item.path | default('etc/ceilometer/') ~ item.name + '?h=' ~ ceilometer_git_install_branch | string }}"" return_content: yes register: ceilometer_template_config - name: Config_template upstream files config_template: content: ""{{ ceilometer_template_config.content }}"" dest: ""{{ item.dest }}"" owner: ""{{ item.owner | default(ceilometer_system_user_name ) }}"" group: ""{{ item.group | default(ceilometer_system_group_name) }}"" config_overrides: ""{{ item.config_overrides }}"" config_type: ""{{ item.config_type }}"" list_extend: ""{{ item.list_extend | default(omit) }}"" notify: - Restart ceilometer services ",,31,10
openstack%2Fopenstack-ansible~master~I815f349b6baec0f60dc13adbc6e5500c11f7b47f,openstack/openstack-ansible,master,I815f349b6baec0f60dc13adbc6e5500c11f7b47f,[WIP] Relocate group vars out of inventory path,ABANDONED,2017-05-19 18:30:45.000000000,2017-06-18 13:51:49.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-05-19 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a0fa19d2ced4197a77658afcf6961d018793e1fc', 'message': '[WIP] Relocate group vars out of inventory path\n\nUse the vars_plugin to load all group_vars to allow key-based merging\nof deployer overrides from /etc/openstack_deploy.\n\nChange-Id: I815f349b6baec0f60dc13adbc6e5500c11f7b47f\n'}, {'number': 2, 'created': '2017-05-19 18:32:15.000000000', 'files': ['defaults/group_vars/all.yml', 'defaults/group_vars/all_containers.yml', 'defaults/group_vars/ceilometer_all.yml', 'defaults/group_vars/keystone_all.yml', 'defaults/group_vars/utility_all.yml', 'defaults/group_vars/cinder_all.yml', 'defaults/group_vars/neutron_agent.yml', 'defaults/group_vars/neutron_calico_dhcp_agent.yml', 'defaults/group_vars/neutron_all.yml', 'defaults/group_vars/haproxy_all.yml', 'scripts/openstack-ansible.rc', 'defaults/group_vars/cinder_volume.yml', 'defaults/group_vars/hosts.yml', 'defaults/group_vars/ironic_compute.yml', 'defaults/group_vars/magnum_all.yml', 'defaults/group_vars/memcached.yml', 'defaults/group_vars/ironic_all.yml', 'defaults/group_vars/swift_all.yml', 'defaults/group_vars/repo_all.yml', 'defaults/group_vars/trove_all.yml', 'defaults/group_vars/octavia_all.yml', 'defaults/group_vars/designate_all.yml', 'defaults/group_vars/horizon_all.yml', 'defaults/group_vars/glance_all.yml', 'defaults/group_vars/barbican_all.yml', 'defaults/group_vars/ceph_all.yml', 'defaults/group_vars/gnocchi_all.yml', 'defaults/group_vars/nova_all.yml', 'defaults/group_vars/rsyslog.yml', 'defaults/group_vars/rabbitmq_all.yml', 'defaults/group_vars/aodh_all.yml', 'defaults/group_vars/galera_all.yml', 'defaults/group_vars/heat_all.yml', 'defaults/group_vars/sahara_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b2f25ddb4e0fb74f665203ccc1c0d698f896b3fa', 'message': '[WIP] Relocate group vars out of inventory path\n\nUse the vars_plugin to load all group_vars to allow key-based merging\nof deployer overrides from /etc/openstack_deploy.\n\nChange-Id: I815f349b6baec0f60dc13adbc6e5500c11f7b47f\n'}]",1,466378,b2f25ddb4e0fb74f665203ccc1c0d698f896b3fa,6,2,2,17799,,,0,"[WIP] Relocate group vars out of inventory path

Use the vars_plugin to load all group_vars to allow key-based merging
of deployer overrides from /etc/openstack_deploy.

Change-Id: I815f349b6baec0f60dc13adbc6e5500c11f7b47f
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/78/466378/2 && git format-patch -1 --stdout FETCH_HEAD,"['defaults/group_vars/all.yml', 'defaults/group_vars/all_containers.yml', 'defaults/group_vars/ceilometer_all.yml', 'defaults/group_vars/keystone_all.yml', 'defaults/group_vars/utility_all.yml', 'defaults/group_vars/cinder_all.yml', 'defaults/group_vars/neutron_agent.yml', 'defaults/group_vars/neutron_calico_dhcp_agent.yml', 'defaults/group_vars/neutron_all.yml', 'defaults/group_vars/haproxy_all.yml', 'scripts/openstack-ansible.rc', 'defaults/group_vars/cinder_volume.yml', 'defaults/group_vars/hosts.yml', 'defaults/group_vars/ironic_compute.yml', 'defaults/group_vars/magnum_all.yml', 'defaults/group_vars/memcached.yml', 'defaults/group_vars/ironic_all.yml', 'defaults/group_vars/swift_all.yml', 'defaults/group_vars/repo_all.yml', 'defaults/group_vars/trove_all.yml', 'defaults/group_vars/octavia_all.yml', 'defaults/group_vars/designate_all.yml', 'defaults/group_vars/horizon_all.yml', 'defaults/group_vars/glance_all.yml', 'defaults/group_vars/barbican_all.yml', 'defaults/group_vars/ceph_all.yml', 'defaults/group_vars/gnocchi_all.yml', 'defaults/group_vars/nova_all.yml', 'defaults/group_vars/rsyslog.yml', 'defaults/group_vars/rabbitmq_all.yml', 'defaults/group_vars/aodh_all.yml', 'defaults/group_vars/galera_all.yml', 'defaults/group_vars/heat_all.yml', 'defaults/group_vars/sahara_all.yml']",34,a0fa19d2ced4197a77658afcf6961d018793e1fc,relocate-group-vars,,,2,2
openstack%2Fopenstack-ansible~master~Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf,openstack/openstack-ansible,master,Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf,DNM - Testing lxc-attach with clear environments,ABANDONED,2017-06-07 15:02:43.000000000,2017-06-18 13:47:19.000000000,,"[{'_account_id': 3}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-07 15:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5ae9c6a8389454562521e4b8beb4cb32be35b418', 'message': 'DNM - Testing lxc-attach with clear environments\n\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\nDepends-On: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 2, 'created': '2017-06-07 18:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7ebb8b78fc19cf741f2006d78809cc2899a1694a', 'message': 'DNM - Testing lxc-attach with clear environments\n\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\nDepends-On: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 3, 'created': '2017-06-07 19:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/74b4bdc16be983a45713409ae2092d29abceda81', 'message': 'DNM - Testing lxc-attach with clear environments\n\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 4, 'created': '2017-06-07 21:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cacd13562a7ed8c8f63cab1dec7cb3a834c7f294', 'message': 'DNM - Testing lxc-attach with clear environments\n\nDepends-On: I684a11f4380f91b1cb0585f38817859dfaa68f80\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 5, 'created': '2017-06-08 10:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/59ad1b4622ae17de3d5367377452f1b82627c2d0', 'message': 'DNM - Testing lxc-attach with clear environments\n\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 6, 'created': '2017-06-08 14:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0da2809e7c0a6ac8255b08c3a588bbb59cf0755b', 'message': 'DNM - Testing lxc-attach with clear environments\n\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 7, 'created': '2017-06-08 18:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/22a31d59449851421bb4246d3b5c1341551d97a2', 'message': 'DNM - Testing lxc-attach with clear environments\n\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 8, 'created': '2017-06-09 09:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/55d85d99264d5b124e35d1a5c8cdbd48ab1cfc8f', 'message': 'DNM - Testing lxc-attach with clear environments\n\nDepends-On: I684a11f4380f91b1cb0585f38817859dfaa68f80\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 9, 'created': '2017-06-14 11:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/99362a4d6d7aba1e42db408ad740072f26444d98', 'message': 'DNM - Testing lxc-attach with clear environments\n\nDepends-On: Id2bce7425e0f44bbe71001e5f2520d00fbc5cf78\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}, {'number': 10, 'created': '2017-06-14 11:20:43.000000000', 'files': ['scripts/bootstrap-aio.sh', 'scripts/run-playbooks.sh', 'scripts/gate-check-commit.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/040aaa6c09ed278f1c168cc6333f3462413d3388', 'message': 'DNM - Testing lxc-attach with clear environments\n\nDepends-On: Id2bce7425e0f44bbe71001e5f2520d00fbc5cf78\nChange-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf\n'}]",0,471814,040aaa6c09ed278f1c168cc6333f3462413d3388,28,2,10,23163,,,0,"DNM - Testing lxc-attach with clear environments

Depends-On: Id2bce7425e0f44bbe71001e5f2520d00fbc5cf78
Change-Id: Ie88e8c99033c4b3cac84f2e69128fbb7c01dfebf
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/14/471814/1 && git format-patch -1 --stdout FETCH_HEAD,['dummy'],1,5ae9c6a8389454562521e4b8beb4cb32be35b418,do-not-merge-testing-lxc-clear-env,,,0,0
openstack%2Fkeystone~stable%2Fnewton~I133f34c334c5f262cca751b608934bdf2e622fd1,openstack/keystone,stable/newton,I133f34c334c5f262cca751b608934bdf2e622fd1,Enable trusts for federated users,ABANDONED,2017-06-16 14:21:14.000000000,2017-06-18 13:16:36.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-16 14:21:14.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/token/providers/common.py', 'keystone/identity/core.py', 'keystone/tests/unit/test_v3_federation.py', 'keystone/auth/plugins/mapped.py', 'keystone/conf/federation.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2857cd86ca8d5db55f1e7eb28d37d6f4ecd17a2a', 'message': ""Enable trusts for federated users\n\n1. Add federated shadow user to groups on user creation and remove from\nold groups\n2. Do not always check domains because federated user doesn't belong to\na domain\n\nChange-Id: I133f34c334c5f262cca751b608934bdf2e622fd1\n""}]",0,474988,2857cd86ca8d5db55f1e7eb28d37d6f4ecd17a2a,3,1,1,6508,,,0,"Enable trusts for federated users

1. Add federated shadow user to groups on user creation and remove from
old groups
2. Do not always check domains because federated user doesn't belong to
a domain

Change-Id: I133f34c334c5f262cca751b608934bdf2e622fd1
",git fetch https://review.opendev.org/openstack/keystone refs/changes/88/474988/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/token/providers/common.py', 'keystone/identity/core.py', 'keystone/tests/unit/test_v3_federation.py', 'keystone/auth/plugins/mapped.py', 'keystone/conf/federation.py']",6,2857cd86ca8d5db55f1e7eb28d37d6f4ecd17a2a,,"cache_group_membership_in_db = cfg.BoolOpt('cache_group_membership_in_db', default=False, help=utils.fmt("""""" When turned on, Keystone will save in DB group membership for federated users. Enabling this option is the only way so far to make trusts delegated by federated users work. The downside is that a trust could be used even after the delegating user's permissions were changed in IdP, unless that change was propagated to Keystone by some automation script."""""")) cache_group_membership_in_db,",,131,6
openstack%2Fmanila~master~I0062c1bf94490ed4e5d0eb3675226b144f7124c1,openstack/manila,master,I0062c1bf94490ed4e5d0eb3675226b144f7124c1,Clean releasenotes and install-guide build dir,MERGED,2017-06-01 21:20:16.000000000,2017-06-18 13:10:02.000000000,2017-06-18 09:25:14.000000000,"[{'_account_id': 3}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16643}, {'_account_id': 18128}, {'_account_id': 21884}, {'_account_id': 22248}]","[{'number': 1, 'created': '2017-06-01 21:20:16.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/manila/commit/85405dab2943409e76e3abcf1d58dbc0d8727b13', 'message': 'Clean releasenotes and install-guide build dir\n\nto ensure artefacts from previous runs are not\nleft over when running these document builds locally.\n\nTrivialFix\n\nChange-Id: I0062c1bf94490ed4e5d0eb3675226b144f7124c1\n'}]",4,470019,85405dab2943409e76e3abcf1d58dbc0d8727b13,31,9,1,9003,,,0,"Clean releasenotes and install-guide build dir

to ensure artefacts from previous runs are not
left over when running these document builds locally.

TrivialFix

Change-Id: I0062c1bf94490ed4e5d0eb3675226b144f7124c1
",git fetch https://review.opendev.org/openstack/manila refs/changes/19/470019/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,85405dab2943409e76e3abcf1d58dbc0d8727b13,,whitelist_externals = rm commands = rm -rf releasenotes/build sphinx-build -a -E -W -d releasenotes/build/doctrees \whitelist_externals = rm commands = rm -rf install-guide/build sphinx-build -a -E -W -d install-guide/build/doctrees -b html install-guide/source install-guide/build/html,commands = sphinx-build -a -E -W -d releasenotes/build/doctrees \commands = sphinx-build -a -E -W -d install-guide/build/doctrees -b html install-guide/source install-guide/build/html,8,2
openstack%2Fshade~master~Iea7c8267e87c5b5beb83e9315f41a61ae714005f,openstack/shade,master,Iea7c8267e87c5b5beb83e9315f41a61ae714005f,Convert keypairs calls to REST,MERGED,2017-06-16 23:23:26.000000000,2017-06-18 12:52:39.000000000,2017-06-18 12:52:39.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-16 23:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/67b47ccc0257b08f46b8adb62ecac7dfc629f922', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 2, 'created': '2017-06-17 00:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/c0fd3f3a7f2ad07cd65e900a0d398b78d3b5d2c3', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 3, 'created': '2017-06-17 00:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/850875a2b73e63ccb14447a17f8643bda3da0d79', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 4, 'created': '2017-06-17 13:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/20a4063950385876208cbce62985e0e57f6f82ba', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 5, 'created': '2017-06-17 14:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/ef589372059b389deb42ab3038b62b0881d526ba', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 6, 'created': '2017-06-17 16:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/1e548a2509d23e90cce97c1189733638ba4018eb', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 7, 'created': '2017-06-17 17:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/1e83b82a1a3b5940e7dec71a272414399e7af9e8', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 8, 'created': '2017-06-17 20:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/93891d7cd5da8e1ef361bdc9a5fbdee3aa1b1a2a', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}, {'number': 9, 'created': '2017-06-17 22:12:00.000000000', 'files': ['shade/tests/unit/test_keypair.py', 'shade/_tasks.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/b9a2c296e618d6ea07f8e91d995cc29885fe63c0', 'message': 'Convert keypairs calls to REST\n\nChange-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f\n'}]",0,475091,b9a2c296e618d6ea07f8e91d995cc29885fe63c0,21,2,9,2,,,0,"Convert keypairs calls to REST

Change-Id: Iea7c8267e87c5b5beb83e9315f41a61ae714005f
",git fetch https://review.opendev.org/openstack/shade refs/changes/91/475091/8 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_keypair.py', 'shade/_tasks.py', 'shade/openstackcloud.py']",3,67b47ccc0257b08f46b8adb62ecac7dfc629f922,474027," return self._compute_client.get( '/os-keypairs', error_message=""Error fetching keypair list"") return self._compute_client.post( '/os-keypairs', json={ 'keypair': { 'name': name, 'public_key': public_key, }, }, error_message=""Unable to create keypair {name}"".format(name=name)) self._compute_client.delete('/os-keypairs/{name}'.format( name=name)) except OpenStackCloudURINotFound:","import novaclient.exceptions as nova_exceptions with _utils.shade_exceptions(""Error fetching keypair list""): return self.manager.submit_task(_tasks.KeypairList()) with _utils.shade_exceptions(""Unable to create keypair {name}"".format( name=name)): return self.manager.submit_task(_tasks.KeypairCreate( name=name, public_key=public_key)) self.manager.submit_task(_tasks.KeypairDelete(key=name)) except nova_exceptions.NotFound: except OpenStackCloudException: raise except Exception as e: raise OpenStackCloudException( ""Unable to delete keypair %s: %s"" % (name, e))",15,34
openstack%2Fshade~master~Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea,openstack/shade,master,Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea,Add normalization and functional tests for keypairs,MERGED,2017-06-17 13:57:22.000000000,2017-06-18 12:48:40.000000000,2017-06-18 12:48:40.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-17 13:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0e3091110a8593c293eb7bd11cea5fccb08a3950', 'message': ""Add normalization and functional tests for keypairs\n\nKeypairs didn't have functional tests, although they do have ansible\ntests. Also, there was no normalization. Add both.\n\nChange-Id: Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea\n""}, {'number': 2, 'created': '2017-06-17 14:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/8a74216a15be3e4e81560075a34dca5f5156642b', 'message': ""Add normalization and functional tests for keypairs\n\nKeypairs didn't have functional tests, although they do have ansible\ntests. Also, there was no normalization. Add both.\n\nChange-Id: Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea\n""}, {'number': 3, 'created': '2017-06-17 16:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4451459726ab15cfd5f3f7fa11bf492e9f843c61', 'message': ""Add normalization and functional tests for keypairs\n\nKeypairs didn't have functional tests, although they do have ansible\ntests. Also, there was no normalization. Add both.\n\nChange-Id: Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea\n""}, {'number': 4, 'created': '2017-06-17 17:22:29.000000000', 'files': ['doc/source/model.rst', 'shade/tests/functional/test_keypairs.py', 'shade/tests/fakes.py', 'shade/tests/unit/test_keypair.py', 'shade/_normalize.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/caa69b4117ebe5f75d45adc805f67035d1d55855', 'message': ""Add normalization and functional tests for keypairs\n\nKeypairs didn't have functional tests, although they do have ansible\ntests. Also, there was no normalization. Add both.\n\nChange-Id: Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea\n""}]",0,475134,caa69b4117ebe5f75d45adc805f67035d1d55855,12,2,4,2,,,0,"Add normalization and functional tests for keypairs

Keypairs didn't have functional tests, although they do have ansible
tests. Also, there was no normalization. Add both.

Change-Id: Ib6fab25cf4c88e5f9d224e831a8b5f297b263aea
",git fetch https://review.opendev.org/openstack/shade refs/changes/34/475134/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/model.rst', 'shade/tests/functional/test_keypairs.py', 'shade/tests/fakes.py', 'shade/tests/unit/test_keypair.py', 'shade/_normalize.py', 'shade/openstackcloud.py']",6,0e3091110a8593c293eb7bd11cea5fccb08a3950,474027," return self._normalize_keypairs( self.manager.submit_task(_tasks.KeypairList())) return self._normalize_keypair( self.manager.submit_task(_tasks.KeypairCreate( name=name, public_key=public_key)))"," return self.manager.submit_task(_tasks.KeypairList()) return self.manager.submit_task(_tasks.KeypairCreate( name=name, public_key=public_key))",139,5
openstack%2Fshade~master~I85a9d19959e750995fed20a882eb8a9cae9add64,openstack/shade,master,I85a9d19959e750995fed20a882eb8a9cae9add64,Convert keypairs tests to requests_mock,MERGED,2017-06-16 23:23:26.000000000,2017-06-18 12:48:34.000000000,2017-06-18 12:48:34.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-16 23:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/f95af19857bfa34dbe1093b33106397803d015c4', 'message': 'Convert keypairs tests to requests_mock\n\nChange-Id: I85a9d19959e750995fed20a882eb8a9cae9add64\n'}, {'number': 2, 'created': '2017-06-17 00:09:10.000000000', 'files': ['shade/tests/fakes.py', 'shade/tests/unit/test_keypair.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/587b41b0f6612c147fad93966369836b3e953a18', 'message': 'Convert keypairs tests to requests_mock\n\nChange-Id: I85a9d19959e750995fed20a882eb8a9cae9add64\n'}]",0,475090,587b41b0f6612c147fad93966369836b3e953a18,12,2,2,2,,,0,"Convert keypairs tests to requests_mock

Change-Id: I85a9d19959e750995fed20a882eb8a9cae9add64
",git fetch https://review.opendev.org/openstack/shade refs/changes/90/475090/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/fakes.py', 'shade/tests/unit/test_keypair.py']",2,f95af19857bfa34dbe1093b33106397803d015c4,restification,"class TestKeypair(base.RequestsMockTestCase): def setUp(self): super(TestKeypair, self).setUp() self.keyname = self.getUniqueString('key') self.key = fakes.make_fake_keypair(self.keyname) def test_create_keypair(self): self.register_uris([ dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs']), json={'keypair': self.key}, validate=dict(json={ 'keypair': { 'name': self.key['name'], 'public_key': self.key['public_key']}})), dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs', self.keyname]), json={'keypair': self.key}), ]) new_key = self.cloud.create_keypair( self.keyname, self.key['public_key']) self.assertEqual(new_key['name'], self.keyname) self.assert_calls() def test_create_keypair_exception(self): self.register_uris([ dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs']), status_code=400, validate=dict(json={ 'keypair': { 'name': self.key['name'], 'public_key': self.key['public_key']}})), ]) self.assertRaises( exc.OpenStackCloudException, self.cloud.create_keypair, self.keyname, self.key['public_key']) self.assert_calls() def test_delete_keypair(self): self.register_uris([ dict(method='DELETE', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs', self.keyname]), status_code=202), ]) self.assertTrue(self.cloud.delete_keypair(self.keyname)) self.assert_calls() def test_delete_keypair_not_found(self): self.register_uris([ dict(method='DELETE', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs', self.keyname]), status_code=404), ]) self.assertFalse(self.cloud.delete_keypair(self.keyname)) self.assert_calls() def test_list_keypairs(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs']), json={'keypairs': [self.key]}), ]) def test_list_keypairs_exception(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['os-keypairs']), status_code=400), ]) self.assert_calls()","import shade from mock import patch from novaclient import exceptions as nova_exc from shade import metaclass TestKeypair(base.TestCase): @patch.object(shade.OpenStackCloud, 'nova_client') def test_create_keypair(self, mock_nova): keyname = 'my_keyname' pub_key = 'ssh-rsa BLAH' key = fakes.FakeKeypair('keyid', keyname, pub_key) mock_nova.keypairs.create.return_value = key new_key = self.cloud.create_keypair(keyname, pub_key) mock_nova.keypairs.create.assert_called_once_with( name=keyname, public_key=pub_key ) self.assertEqual(meta.obj_to_munch(key), new_key) @patch.object(shade.OpenStackCloud, 'nova_client') def test_create_keypair_exception(self, mock_nova): mock_nova.keypairs.create.side_effect = Exception() self.assertRaises(exc.OpenStackCloudException, self.cloud.create_keypair, '', '') @patch.object(shade.OpenStackCloud, 'nova_client') def test_delete_keypair(self, mock_nova): self.assertTrue(self.cloud.delete_keypair('mykey')) mock_nova.keypairs.delete.assert_called_once_with( key='mykey' ) @patch.object(shade.OpenStackCloud, 'nova_client') def test_delete_keypair_not_found(self, mock_nova): mock_nova.keypairs.delete.side_effect = nova_exc.NotFound('') self.assertFalse(self.cloud.delete_keypair('invalid')) @patch.object(shade.OpenStackCloud, 'nova_client') def test_list_keypairs(self, mock_nova): mock_nova.keypairs.list.assert_called_once_with() @patch.object(shade.OpenStackCloud, 'nova_client') def test_list_keypairs_exception(self, mock_nova): mock_nova.keypairs.list.side_effect = Exception()",95,39
openstack%2Fshade~master~I5d2ca9426f629014069f98ed9521556392c9d71d,openstack/shade,master,I5d2ca9426f629014069f98ed9521556392c9d71d,Don't remove top-container element for user and project REST API calls,MERGED,2017-06-18 00:49:53.000000000,2017-06-18 12:48:19.000000000,2017-06-18 12:48:19.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-18 00:49:53.000000000', 'files': ['shade/_adapter.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/7cd4ef000153c7c4b8b3a43910ccb2bc4439c6c5', 'message': ""Don't remove top-container element for user and project REST API calls\n\nChange-Id: I5d2ca9426f629014069f98ed9521556392c9d71d\nSigned-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>\n""}]",0,475150,7cd4ef000153c7c4b8b3a43910ccb2bc4439c6c5,6,2,1,986,,,0,"Don't remove top-container element for user and project REST API calls

Change-Id: I5d2ca9426f629014069f98ed9521556392c9d71d
Signed-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>
",git fetch https://review.opendev.org/openstack/shade refs/changes/50/475150/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/_adapter.py', 'shade/openstackcloud.py']",2,7cd4ef000153c7c4b8b3a43910ccb2bc4439c6c5,," api_version = self.cloud_config.get_api_version('identity') key = 'projects' if api_version == '3' else 'tenants' data = self._identity_client.get( '/{endpoint}'.format(endpoint=key), params=pushdown) projects = self._normalize_projects( meta.get_and_munchify(key, data)) data = self._identity_client.patch( project = meta.get_and_munchify('project', data) else: data = self._identity_client.post( project = meta.get_and_munchify('tenant', data) endpoint, key = ('tenants', 'tenant') if self.cloud_config.get_api_version('identity') == '3': endpoint, key = ('projects', 'project') data = self._identity_client.post( '/{endpoint}'.format(endpoint=endpoint), json={key: project_ref}) project = self._normalize_project( meta.get_and_munchify(key, data)) data = self._identity_client.get('/users') return _utils.normalize_users( meta.get_and_munchify('users', data)) data = self._identity_client.get( user = meta.get_and_munchify('user', data) if user and normalize: user = _utils.normalize_users(user)"," if self.cloud_config.get_api_version('identity') == '3': projects = self._identity_client.get('/projects', params=pushdown) if isinstance(projects, dict): projects = projects['projects'] else: projects = self._identity_client.get('/tenants', params=pushdown) if isinstance(projects, dict): projects = projects['tenants'] projects = self._normalize_projects(projects) project = self._identity_client.patch( else: project = self._identity_client.post( if self.cloud_config.get_api_version('identity') == '3': project = self._identity_client.post( '/projects', json={'project': project_ref}) else: project = self._identity_client.post( '/tenants', json={'tenant': project_ref}) project = self._normalize_project(project) users = self._identity_client.get('/users') if isinstance(users, dict): users = users['users'] return _utils.normalize_users(users) user = self._identity_client.get( if user and normalize: return _utils.normalize_users([user])[0]",26,27
openstack%2Fopenstack-ansible~master~Ie3f1738436c72eb82d7f6ca45d84024d11f3d923,openstack/openstack-ansible,master,Ie3f1738436c72eb82d7f6ca45d84024d11f3d923,Implement a data plane down time test for upgrades,MERGED,2017-05-24 15:48:35.000000000,2017-06-18 12:29:28.000000000,2017-06-18 12:29:28.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12892}, {'_account_id': 14805}, {'_account_id': 15993}, {'_account_id': 17068}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-05-24 15:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4fd3d77600133d2a2316603826680ca961f02db5', 'message': '[WIP] Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 2, 'created': '2017-05-25 18:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b81c1ca5bf3860fec26cd1c2fe5746ff1812ca3b', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 3, 'created': '2017-05-26 07:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/67954d79f1fc853fa8dcf6a831066cb1d6225d69', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 4, 'created': '2017-05-26 09:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bf29d4bd31cd99fa14e445f577c82ebb8eca00c8', 'message': '[WIP] Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 5, 'created': '2017-05-26 09:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c80e63ccf57d1981c769621798e22280e84043c7', 'message': '[WIP] Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 6, 'created': '2017-05-26 10:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3116e4a5f030c77058e040ebdfd45c72a1ccad30', 'message': '[WIP] Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 7, 'created': '2017-05-26 11:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/56b0ff3a276212e43543a97b133a30d3412d3e43', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3 while\nthe upgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 8, 'created': '2017-05-26 12:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2e7d00284a98c722a71ae8b086a307a9739278c0', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3\nand a disk access test on the test instance while the\nupgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nOnce the upgrade is complete, the testing is stopped\nand if there are any failures, the job will exit as\nfailed.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 9, 'created': '2017-05-30 09:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/96f0eb46dbb173acb3822e5bb811cb04809d046e', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3\nand a disk access test on the test instance while the\nupgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nOnce the upgrade is complete, the testing is stopped\nand if there are any failures, the job will exit as\nfailed.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 10, 'created': '2017-05-30 12:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/627298d882f337ba9b48217581b835a1f297f048', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3\nand a disk access test on the test instance while the\nupgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nOnce the upgrade is complete, the testing is stopped\nand if there are any failures, the job will exit as\nfailed.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 11, 'created': '2017-06-02 11:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1d17d86aecf6630c00b95a83075f930d14876709', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3\nand a disk access test on the test instance while the\nupgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nOnce the upgrade is complete, the testing is stopped\nand if there are any failures, the job will exit as\nfailed.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}, {'number': 12, 'created': '2017-06-15 13:44:04.000000000', 'files': ['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'tests/disk-access-test.sh', 'tests/roles/bootstrap-host/vars/redhat.yml', 'tests/roles/bootstrap-host/vars/ubuntu.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5640b278da52501aec3b58de8dd594f7bf749b77', 'message': 'Implement a data plane down time test for upgrades\n\nThis patch implements a VM using the demo project, then\nconsistently executes a connectivity test through L3\nand a disk access test on the test instance while the\nupgrade script executes.\n\nThe intent is to determine whether any data plane down\ntime is experienced while executing the upgrade.\n\nOnce the upgrade is complete, the testing is stopped\nand if there are any failures, the job will exit as\nfailed.\n\nChange-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923\n'}]",21,467661,5640b278da52501aec3b58de8dd594f7bf749b77,45,7,12,6816,,,0,"Implement a data plane down time test for upgrades

This patch implements a VM using the demo project, then
consistently executes a connectivity test through L3
and a disk access test on the test instance while the
upgrade script executes.

The intent is to determine whether any data plane down
time is experienced while executing the upgrade.

Once the upgrade is complete, the testing is stopped
and if there are any failures, the job will exit as
failed.

Change-Id: Ie3f1738436c72eb82d7f6ca45d84024d11f3d923
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/61/467661/12 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/gate-check-commit.sh', 'playbooks/utility-install.yml', 'tests/test-persistent-resources.sh']",3,4fd3d77600133d2a2316603826680ca961f02db5,rolling-upgrades,"#!/bin/bash # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ## Shell Opts ---------------------------------------------------------------- set -e ## Vars ---------------------------------------------------------------------- # Log file location TEST_LOG_FILE=""/var/log/persistent-resource-test.log"" # The test instance name INSTANCE_NAME=""test1"" # Test script socket file location TEST_SOCKET_FILE=""~/test-persistent-resources.socket"" # Flag to determine whether to continue or not testagain=1 # Setup counters PASS=0 FAIL=0 ## Functions ----------------------------------------------------------------- # Create a demorc file with auth credentials # and other state tracking information. setup_demorc() { cp ~/openrc ~/demorc sed -i 's/OS_PROJECT_NAME=.*/OS_PROJECT_NAME=demo/' ~/demorc sed -i 's/OS_TENANT_NAME=.*/OS_TENANT_NAME=demo/' ~/demorc sed -i 's/OS_USERNAME=.*/OS_USERNAME=demo/' ~/demorc sed -i 's/OS_PASSWORD=.*/OS_PASSWORD=demo/' ~/demorc echo ""INSTANCE_NAME=${TEST_INSTANCE_NAME}"" >> ~/demorc } # Log results result_log() { # We want the output format to be: # YYYY-MM-DD HH:MM:SS <result> STAMP=$(date -u ""+%Y-%m-%d %H:%M:%S"") echo ""${STAMP} ${1}"" >> ${TEST_LOG_FILE} } # Tests to execute tests() { # A simple end-to-end test to verify that we can login via the floating # IP address and can read data from the disk. CMD_CONNECT=""timeout 1s sshpass -p 'cubswin:)' ssh -o StrictHostKeyChecking=no cirros@${INSTANCE_PUBLIC_ADDRESS}"" if ${DMC_CONNECT} cat /etc/issue > /dev/null; then result_log PASS PASS=$((PASS+1)) else result_log FAIL FAIL=$((FAIL+1)) fi } # Steps to execute when finishing finish() { testagain=0 rm -f ${TEST_SOCKET_FILE} echo ""PASS: ${PASS}"" echo ""FAIL: ${FAIL}"" TOTAL=$((${PASS}+${FAIL})) PERCENT_SUCCESS=$(echo ""scale = 2; ${PASS} * 100 / ${TOTAL}"" | bc) echo ""Success Rate: ${PERCENT_SUCCESS}"" } # Setup the trap for the interrupt trap finish SIGINT ## Main ---------------------------------------------------------------------- # Ensure that the required packages are present apt-get update apt-get install -y bc sshpass # Create the demorc file if it doesn't exist if [[ ! -f ~/demorc ]]; then setup_demorc fi # Fetch the environment variables to be used source ~/demorc # If a test instance does not exist, create it if [ -z ${INSTANCE_UUID+x} ]; then INSTANCE_UUID=$(openstack server create --flavor tempest1 --image cirros ${INSTANCE_NAME} --network private | awk '/ id / {print $4}') echo ""INSTANCE_UUID=${INSTANCE_UUID}"" >> ~/demorc fi # If a floating IP address has not been allocated, do so if [ -z ${INSTANCE_PUBLIC_ADDRESS+x} ]; then INSTANCE_PUBLIC_ADDRESS=$(openstack floating ip create public | awk '/floating_ip_address/ {print $4}') echo ""INSTANCE_PUBLIC_ADDRESS=${INSTANCE_PUBLIC_ADDRESS}"" >> ~/demorc fi # If the floating IP is not associated with the test instance, associate it if ! openstack server show test1 | grep ${INSTANCE_PUBLIC_ADDRESS}; then openstack server add floating ip ${INSTANCE_NAME} ${INSTANCE_PUBLIC_ADDRESS} fi # Setup the socket file to allow termination later echo $$ > ${TEST_SOCKET_FILE} # Execute the test loop while (( testagain )); do tests sleep 1 done ",,139,0
openstack%2Fpython-qinlingclient~master~Ied04cd2fb6c3a0f16a37707bb1ba2db21ab7c191,openstack/python-qinlingclient,master,Ied04cd2fb6c3a0f16a37707bb1ba2db21ab7c191,Function/Runtime list,MERGED,2017-06-18 10:34:28.000000000,2017-06-18 10:44:47.000000000,2017-06-18 10:44:47.000000000,"[{'_account_id': 3}, {'_account_id': 6732}]","[{'number': 1, 'created': '2017-06-18 10:34:28.000000000', 'files': ['README.rst', 'qinlingclient/v1/client.py', 'qinlingclient/v1/function.py', 'qinlingclient/osc/v1/base.py', 'setup.cfg', 'qinlingclient/osc/v1/function.py', 'qinlingclient/osc/v1/runtime.py'], 'web_link': 'https://opendev.org/openstack/python-qinlingclient/commit/727b716510a416b31109d7bfa975c19b516f909e', 'message': 'Function/Runtime list\n\nChange-Id: Ied04cd2fb6c3a0f16a37707bb1ba2db21ab7c191\n'}]",0,475168,727b716510a416b31109d7bfa975c19b516f909e,6,2,1,6732,,,0,"Function/Runtime list

Change-Id: Ied04cd2fb6c3a0f16a37707bb1ba2db21ab7c191
",git fetch https://review.opendev.org/openstack/python-qinlingclient refs/changes/68/475168/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'qinlingclient/v1/client.py', 'qinlingclient/v1/function.py', 'qinlingclient/osc/v1/base.py', 'setup.cfg', 'qinlingclient/osc/v1/function.py', 'qinlingclient/osc/v1/runtime.py']",7,727b716510a416b31109d7bfa975c19b516f909e,list_function_runtime," return ('id', 'name', 'image', 'status', 'project_id', 'created_at', 'updated_at')", pass,79,52
openstack%2Fdragonflow~master~Ic0993a84b5a03f508087bbf05a7dcb414edc5906,openstack/dragonflow,master,Ic0993a84b5a03f508087bbf05a7dcb414edc5906,Remove DFDaemon utlity class,MERGED,2017-02-16 10:15:08.000000000,2017-06-18 09:59:06.000000000,2017-06-18 09:59:06.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 16853}, {'_account_id': 20229}, {'_account_id': 23235}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-02-16 10:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a7135748552f7357273ed57eec7266400790de3b', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}, {'number': 2, 'created': '2017-02-24 11:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1626ec34062c5be1944c0bd461c4ed1dabfe0ef7', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}, {'number': 3, 'created': '2017-06-11 14:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f210b29caafb02e9a725ec07cd693353f2d9ec59', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nThis patch also removes some uses of the eventlet library which are\nmonkey_patched, so that the code should work well in non-eventlet\nenvironments.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}, {'number': 4, 'created': '2017-06-14 15:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/21878c01d5d730e697f36f67a335a1f72991454e', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nThis patch also removes some uses of the eventlet library which are\nmonkey_patched, so that the code should work well in non-eventlet\nenvironments.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}, {'number': 5, 'created': '2017-06-14 17:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/005b3ca6e552fce87e36a3aabaca74fd00e45d65', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nThis patch also removes some uses of the eventlet library which are\nmonkey_patched, so that the code should work well in non-eventlet\nenvironments.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}, {'number': 6, 'created': '2017-06-14 19:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0bc0673bf96ab234e87173e9158d06c12109f2c2', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nThis patch also removes some uses of the eventlet library which are\nmonkey_patched, so that the code should work well in non-eventlet\nenvironments.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}, {'number': 7, 'created': '2017-06-18 06:39:28.000000000', 'files': ['dragonflow/db/db_consistent.py', 'dragonflow/common/utils.py', 'dragonflow/db/pubsub_drivers/nb_api_neutron_notifier.py', 'dragonflow/controller/df_publisher_service.py', 'dragonflow/db/pub_sub_api.py', 'dragonflow/tests/fullstack/test_pub_sub.py', 'dragonflow/db/pubsub_drivers/redis_db_pubsub_driver.py', 'dragonflow/db/pubsub_drivers/zmq_pubsub_driver.py', 'dragonflow/db/drivers/redis_mgt.py', 'dragonflow/tests/common/app_testing_objects.py', 'dragonflow/db/api_nb.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b95a605416ad83f24282de91f4026cd87f016d89', 'message': ""Remove DFDaemon utlity class\n\nThe DFDaemon utility class is a thin wrapper around python's\nthreading.Thread and eventlet's greenthread. It has little added value,\nbut increases our code base and requires maintenance.\n\nThis patch suggests to remove this utility class.\n\nThis patch also removes some uses of the eventlet library which are\nmonkey_patched, so that the code should work well in non-eventlet\nenvironments.\n\nChange-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906\n""}]",2,434798,b95a605416ad83f24282de91f4026cd87f016d89,24,7,7,20229,,,0,"Remove DFDaemon utlity class

The DFDaemon utility class is a thin wrapper around python's
threading.Thread and eventlet's greenthread. It has little added value,
but increases our code base and requires maintenance.

This patch suggests to remove this utility class.

This patch also removes some uses of the eventlet library which are
monkey_patched, so that the code should work well in non-eventlet
environments.

Change-Id: Ic0993a84b5a03f508087bbf05a7dcb414edc5906
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/98/434798/4 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/db/db_consistent.py', 'dragonflow/common/utils.py', 'dragonflow/db/pub_sub_api.py', 'dragonflow/tests/fullstack/test_pub_sub.py', 'dragonflow/db/pubsub_drivers/redis_db_pubsub_driver.py', 'dragonflow/db/pubsub_drivers/zmq_pubsub_driver.py', 'dragonflow/db/drivers/redis_mgt.py', 'dragonflow/tests/common/app_testing_objects.py']",8,a7135748552f7357273ed57eec7266400790de3b,remove-dfdaemon,"import eventlet import greenlet def close(self): self.tap.close() rs, ws, xs = select.select((self.tap,), (), ()) def wait(self, timeout): self.daemon = None self.daemon = eventlet.greenthread.spawn(self.run) self.port.tap.close() def wait(self, timeout, exception): with eventlet.Timeout(timeout, exception): try: self.daemon.wait() except greenlet.GreenletExit: return True","from dragonflow.common import utils as d_utils def wait(self, timeout=None): self.daemon = d_utils.DFDaemon(is_not_light=True) self.thread_id = None self.daemon.daemonize(self.run) if self.thread_id != threading.current_thread().ident: self.daemon.stop() def wait(self, timeout=None, exception=None): self.daemon.wait(timeout, exception) self.thread_id = threading.current_thread().ident",62,88
openstack%2Fdragonflow~master~Ia52f3e49b077090fb6d6264628a10bc4af93c664,openstack/dragonflow,master,Ia52f3e49b077090fb6d6264628a10bc4af93c664,Refactor Aging application,MERGED,2017-02-02 09:44:23.000000000,2017-06-18 09:17:27.000000000,2017-06-18 09:17:27.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-02-02 09:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0d84a56679f312f9f568c9fe316b5cf6265ad96a', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 2, 'created': '2017-02-02 09:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fc97af7f137149adda1d82da88d8c3b13465d3f5', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 3, 'created': '2017-02-02 11:14:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8802956ecf50d1588d36f4ec0f5370c51bf1a3a8', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 4, 'created': '2017-02-03 19:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/cdfcac237df4123cb0f0ae26642dec850d175c52', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 5, 'created': '2017-02-04 08:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e09696f2574c9a417b8b32703ba5a7043369b7b4', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 6, 'created': '2017-02-15 11:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fe0de5932a8f499fdcc5654378053e7e77811f79', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 7, 'created': '2017-02-16 10:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7dda05da5e4c77753be73ac5f9a7b8928261995c', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 8, 'created': '2017-02-16 10:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bd2207e5ab5ce1a1cded38bd4b983c8609e3bcb1', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 9, 'created': '2017-02-24 11:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5b4e6619cab0f3e1b66ea7583749134ba181e306', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 10, 'created': '2017-02-24 15:48:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/173a2501236db9bdfa7f6c44d574fbb199359d50', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 11, 'created': '2017-04-27 10:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/85ffc47244dcba965c06126b5f102a1af3979930', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 12, 'created': '2017-06-14 18:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8d026b74347e6f8e3d74a4b404f2d5de34cb3b7f', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 13, 'created': '2017-06-14 19:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/91e460fc1a19aad943f87b74fc1ccaac4aa613d1', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 14, 'created': '2017-06-15 04:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4a986f03ea9ee0358aded3179fff2524de9bceb6', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}, {'number': 15, 'created': '2017-06-18 06:16:01.000000000', 'files': ['dragonflow/controller/ofswitch.py', 'dragonflow/controller/common/cookies.py', 'dragonflow/controller/df_base_app.py', 'dragonflow/tests/unit/test_cookies.py', 'dragonflow/controller/aging_app.py', 'dragonflow/controller/common/constants.py', 'dragonflow/controller/aging.py', 'dragonflow/controller/df_local_controller.py', 'dragonflow/controller/common/utils.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/afc50c8186e59934612c16e437adfc5b6777672b', 'message': ""Refactor Aging application\n\nAs part of the work on cookies throughout Dragonflow, it was decided\nthat this application would benefit from moving cookie information to be\nprivate, rather than sit in an external utility module.\n\nAdditionally, the code used to connect to the OVS was made available to\nall applications via the shared base class.\n\nLastly, ryu's openflow service necessary for synchronous communication\nwas moved to df-local-controller.\n\nChange-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664\nRelated-Bug: #1471552\n""}]",13,428056,afc50c8186e59934612c16e437adfc5b6777672b,54,5,15,20229,,,0,"Refactor Aging application

As part of the work on cookies throughout Dragonflow, it was decided
that this application would benefit from moving cookie information to be
private, rather than sit in an external utility module.

Additionally, the code used to connect to the OVS was made available to
all applications via the shared base class.

Lastly, ryu's openflow service necessary for synchronous communication
was moved to df-local-controller.

Change-Id: Ia52f3e49b077090fb6d6264628a10bc4af93c664
Related-Bug: #1471552
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/56/428056/11 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/controller/ofswitch.py', 'dragonflow/controller/df_base_app.py', 'dragonflow/controller/common/constants.py', 'dragonflow/controller/aging.py', 'dragonflow/controller/common/utils.py']",5,0d84a56679f312f9f568c9fe316b5cf6265ad96a,cookies,,"from dragonflow.controller.common import constants as const_aging_cookie = 0def set_aging_cookie(c): global _aging_cookie _aging_cookie = c def get_aging_cookie(): return _aging_cookie def set_aging_cookie_bits(old_cookie, old_cookie_mask): return cookies.get_cookie(AGING_COOKIE_NAME, _aging_cookie, old_cookie, old_cookie_mask) def get_xor_cookie(cookie): return cookie ^ const.GLOBAL_INIT_AGING_COOKIE ",73,171
openstack%2Fopenstack-manuals~master~Idaf917b6579fcb10d2c25ce90c151165c3d6ac3f,openstack/openstack-manuals,master,Idaf917b6579fcb10d2c25ce90c151165c3d6ac3f,[cli-ref] Update python-novaclient to 9.0.1,MERGED,2017-06-18 04:52:07.000000000,2017-06-18 09:15:20.000000000,2017-06-18 09:15:20.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-18 04:52:07.000000000', 'files': ['doc/cli-reference/source/nova.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/34213fb2a4a943493f1275d1cde411715e207182', 'message': '[cli-ref] Update python-novaclient to 9.0.1\n\nChange-Id: Idaf917b6579fcb10d2c25ce90c151165c3d6ac3f\n'}]",0,475157,34213fb2a4a943493f1275d1cde411715e207182,6,2,1,19779,,,0,"[cli-ref] Update python-novaclient to 9.0.1

Change-Id: Idaf917b6579fcb10d2c25ce90c151165c3d6ac3f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/57/475157/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/nova.rst'],1,34213fb2a4a943493f1275d1cde411715e207182,cli-reference,This chapter documents :command:`nova` version ``9.0.1``.,This chapter documents :command:`nova` version ``9.0.0``.,1,1
openstack%2Fos-brick~master~I13ef77edf31bffaecd671385cbca564931214a7e,openstack/os-brick,master,I13ef77edf31bffaecd671385cbca564931214a7e,Prevent rbd map again if it's already mapped,MERGED,2017-05-04 07:27:31.000000000,2017-06-18 08:28:53.000000000,2017-06-18 07:10:37.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 9732}, {'_account_id': 10842}, {'_account_id': 11904}, {'_account_id': 15941}, {'_account_id': 16898}, {'_account_id': 19852}, {'_account_id': 20403}, {'_account_id': 22248}, {'_account_id': 22796}, {'_account_id': 23083}, {'_account_id': 24502}]","[{'number': 1, 'created': '2017-05-04 07:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6a1c16457de5049127271829f97bcd9b7632aad6', 'message': ""prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}, {'number': 2, 'created': '2017-05-04 07:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/aced71be8951707ba51dd9502f551ea1f36744cc', 'message': ""prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}, {'number': 3, 'created': '2017-05-04 08:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/5da049d5af38e102e6eda8d8f9a2a821bfab27ee', 'message': ""prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}, {'number': 4, 'created': '2017-05-05 02:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/a4ad6ef4d2cd5e7a17af3cb5613eaa162f5952fa', 'message': ""prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}, {'number': 5, 'created': '2017-05-07 01:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/4c43c8b3058d1690237b01dfa4acc7b19cd6a93d', 'message': ""Prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd volume regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}, {'number': 6, 'created': '2017-05-19 03:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/5bdfed7ff86bf89bc2c1f58374f11341a92110fa', 'message': ""Prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd volume regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}, {'number': 7, 'created': '2017-05-19 03:27:43.000000000', 'files': ['os_brick/tests/initiator/connectors/test_rbd.py', 'os_brick/initiator/connectors/rbd.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/a760c549b335b077172f744105ceda9c90cf81e1', 'message': ""Prevent rbd map again if it's already mapped\n\n`rbd map` maps rbd volume regardless if it's already mapped or not.[1]\nThis patch is to prevent duplicated rbd map in connect_volume.\n\n[1]\n```\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd1\nroot@compute-0:~# rbd -p rbd_ssd map foo\n/dev/rbd2\n```\n\nChange-Id: I13ef77edf31bffaecd671385cbca564931214a7e\n""}]",3,462416,a760c549b335b077172f744105ceda9c90cf81e1,72,14,7,20403,,,0,"Prevent rbd map again if it's already mapped

`rbd map` maps rbd volume regardless if it's already mapped or not.[1]
This patch is to prevent duplicated rbd map in connect_volume.

[1]
```
root@compute-0:~# rbd -p rbd_ssd map foo
/dev/rbd1
root@compute-0:~# rbd -p rbd_ssd map foo
/dev/rbd2
```

Change-Id: I13ef77edf31bffaecd671385cbca564931214a7e
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/16/462416/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/initiator/connectors/test_rbd.py', 'os_brick/initiator/connectors/rbd.py']",2,6a1c16457de5049127271829f97bcd9b7632aad6,rbdmap," rbd_dev_path = RBDConnector.get_rbd_device_name(pool, volume) if (not os.path.islink(rbd_dev_path) or not os.path.exists(os.path.realpath(rbd_dev_path))): cmd = ['rbd', 'map', volume, '--pool', pool] cmd += self._get_rbd_args(connection_properties) self._execute(*cmd, root_helper=self._root_helper, run_as_root=True) return {'path': rbd_dev_path,"," cmd = ['rbd', 'map', volume, '--pool', pool] cmd += self._get_rbd_args(connection_properties) self._execute(*cmd, root_helper=self._root_helper, run_as_root=True) return {'path': RBDConnector.get_rbd_device_name(pool, volume),",31,5
openstack%2Fproject-config~master~I37492780e72aea1be9c41c67af95e3d2810791b5,openstack/project-config,master,I37492780e72aea1be9c41c67af95e3d2810791b5,Add etcd3 to networking-generic-switch job,MERGED,2017-06-08 16:48:44.000000000,2017-06-18 08:23:00.000000000,2017-06-18 08:23:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-06-08 16:48:44.000000000', 'files': ['jenkins/jobs/networking-generic-switch.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8258e1c2417430bc30c56ceb54ba474172b3ec9c', 'message': 'Add etcd3 to networking-generic-switch job\n\nwe need this to test the upcoming DLM functionality\n\nChange-Id: I37492780e72aea1be9c41c67af95e3d2810791b5\nRelated-Bug: #1674324\n'}]",0,472343,8258e1c2417430bc30c56ceb54ba474172b3ec9c,9,5,1,9542,,,0,"Add etcd3 to networking-generic-switch job

we need this to test the upcoming DLM functionality

Change-Id: I37492780e72aea1be9c41c67af95e3d2810791b5
Related-Bug: #1674324
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/472343/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/networking-generic-switch.yaml'],1,8258e1c2417430bc30c56ceb54ba474172b3ec9c,bug/1674324," export OVERRIDE_ENABLED_SERVICES=key,mysql,rabbit,q-svc,q-agt,q-dhcp,q-l3,tempest,etcd3"," export OVERRIDE_ENABLED_SERVICES=key,mysql,rabbit,q-svc,q-agt,q-dhcp,q-l3,tempest",1,1
openstack%2Fproject-config~master~Ic64e7984b4ff888fa56b11239477834a0d972dfb,openstack/project-config,master,Ic64e7984b4ff888fa56b11239477834a0d972dfb,jenkins: scripts: propose_update: Pass project directory as first argument,MERGED,2017-06-07 13:59:32.000000000,2017-06-18 08:20:24.000000000,2017-06-18 08:20:24.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-06-07 13:59:32.000000000', 'files': ['jenkins/scripts/propose_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b4f02248e007bc59f4f471719d2c1b84d913a286', 'message': 'jenkins: scripts: propose_update: Pass project directory as first argument\n\nThe sync_openstack_ansible_common_files.sh expects the OSA project to be\nin the first argument. Fixes the following problem:\n\n2017-06-07 12:23:50.415740 | + update openstack-ansible-galera_client\n2017-06-07 12:23:50.415772 | + bash /usr/local/jenkins/slave_scripts/sync_openstack_ansible_common_files.sh\n2017-06-07 12:23:50.418144 | /usr/local/jenkins/slave_scripts/sync_openstack_ansible_common_files.sh: line 20: 1: unbound variable\n\nChange-Id: Ic64e7984b4ff888fa56b11239477834a0d972dfb\n'}]",0,471785,b4f02248e007bc59f4f471719d2c1b84d913a286,7,4,1,23163,,,0,"jenkins: scripts: propose_update: Pass project directory as first argument

The sync_openstack_ansible_common_files.sh expects the OSA project to be
in the first argument. Fixes the following problem:

2017-06-07 12:23:50.415740 | + update openstack-ansible-galera_client
2017-06-07 12:23:50.415772 | + bash /usr/local/jenkins/slave_scripts/sync_openstack_ansible_common_files.sh
2017-06-07 12:23:50.418144 | /usr/local/jenkins/slave_scripts/sync_openstack_ansible_common_files.sh: line 20: 1: unbound variable

Change-Id: Ic64e7984b4ff888fa56b11239477834a0d972dfb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/471785/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/propose_update.sh'],1,b4f02248e007bc59f4f471719d2c1b84d913a286,jenkins/jobs/osa-fix-unbound-variable, bash /usr/local/jenkins/slave_scripts/sync_openstack_ansible_common_files.sh $1, bash /usr/local/jenkins/slave_scripts/sync_openstack_ansible_common_files.sh,1,1
openstack%2Fproject-config~master~I328135db4643a5baa195ba642f30e26ad008c08e,openstack/project-config,master,I328135db4643a5baa195ba642f30e26ad008c08e,[rally]increase timeout value for cli job,ABANDONED,2017-06-07 08:09:00.000000000,2017-06-18 08:19:41.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9545}, {'_account_id': 21528}, {'_account_id': 22960}]","[{'number': 1, 'created': '2017-06-07 08:09:00.000000000', 'files': ['jenkins/jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f0756990ac1f3aca05d963eaa9166c885b674877', 'message': '[rally]increase timeout value for cli job\n\nTemporarily increase timeout value to unblock rally ci\nbefore completely solving this issue.\n\nChange-Id: I328135db4643a5baa195ba642f30e26ad008c08e\n'}]",0,471622,f0756990ac1f3aca05d963eaa9166c885b674877,8,5,1,21528,,,0,"[rally]increase timeout value for cli job

Temporarily increase timeout value to unblock rally ci
before completely solving this issue.

Change-Id: I328135db4643a5baa195ba642f30e26ad008c08e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/471622/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/rally.yaml'],1,f0756990ac1f3aca05d963eaa9166c885b674877,rally.cinder, timeout: 100, timeout: 80,1,1
openstack%2Fproject-config~master~Ibdfe20b618fb35840f7bb6cda7c85074b206230b,openstack/project-config,master,Ibdfe20b618fb35840f7bb6cda7c85074b206230b,Re-enable beaker tests for puppet-midonet,MERGED,2017-06-02 08:53:25.000000000,2017-06-18 08:17:19.000000000,2017-06-18 08:17:19.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22064}]","[{'number': 1, 'created': '2017-06-02 08:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/544b8971d29d31853b9d6462f08801f76ec9342e', 'message': 'WIP: Re-enable beaker tests for puppet-midonet\n\nThis reverts commit 34faea892c0d68451709cd0b181a533a771b5b0c.\n\nChange-Id: Ibdfe20b618fb35840f7bb6cda7c85074b206230b\n'}, {'number': 2, 'created': '2017-06-18 08:01:28.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b982220f5555565f028e98c5542f270319d98d06', 'message': 'Re-enable beaker tests for puppet-midonet\n\nThis reverts commit 34faea892c0d68451709cd0b181a533a771b5b0c.\n\nChange-Id: Ibdfe20b618fb35840f7bb6cda7c85074b206230b\n'}]",0,470210,b982220f5555565f028e98c5542f270319d98d06,11,6,2,22064,,,0,"Re-enable beaker tests for puppet-midonet

This reverts commit 34faea892c0d68451709cd0b181a533a771b5b0c.

Change-Id: Ibdfe20b618fb35840f7bb6cda7c85074b206230b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/10/470210/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,544b8971d29d31853b9d6462f08801f76ec9342e,, - name: puppet-beaker-jobs, #- name: puppet-beaker-jobs,1,1
openstack%2Fproject-config~master~I80d44e391f0e8686a145f74cbc7fedc6ba38c80b,openstack/project-config,master,I80d44e391f0e8686a145f74cbc7fedc6ba38c80b,[magnum] Add experimental dcos job,MERGED,2017-06-07 13:37:11.000000000,2017-06-18 07:58:39.000000000,2017-06-18 07:58:39.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 20498}, {'_account_id': 20933}]","[{'number': 1, 'created': '2017-06-07 13:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/64e6e8c8d416f51a6488acf9dc08884e7f063a2d', 'message': '[magnum] Add experimental dcos job\n\nAfter having the image build on the CI we can add\nan experimental dcos job.\n\nChange-Id: I80d44e391f0e8686a145f74cbc7fedc6ba38c80b\n'}, {'number': 2, 'created': '2017-06-07 13:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4c7f2cba841a62f0b103427b2f92e65f79f318c9', 'message': '[magnum] Add experimental dcos job\n\nAfter having the image build on the CI [1] we can add\nan experimental dcos job.\n\n[1] http://logs.openstack.org/periodic/periodic-magnum-dib-buildimage-centos-dcos-ubuntu-xenial/\n\nChange-Id: I80d44e391f0e8686a145f74cbc7fedc6ba38c80b\n'}, {'number': 3, 'created': '2017-06-09 09:15:10.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1dacd3a454ad366976206169d531b6030ccbacda', 'message': '[magnum] Add experimental dcos job\n\nAfter having the image build on the CI [1] we can add\nan experimental dcos job.\n\n[1] http://logs.openstack.org/periodic/periodic-magnum-dib-buildimage-centos-dcos-ubuntu-xenial/\n\nChange-Id: I80d44e391f0e8686a145f74cbc7fedc6ba38c80b\n'}]",0,471776,1dacd3a454ad366976206169d531b6030ccbacda,12,6,3,20498,,,0,"[magnum] Add experimental dcos job

After having the image build on the CI [1] we can add
an experimental dcos job.

[1] http://logs.openstack.org/periodic/periodic-magnum-dib-buildimage-centos-dcos-ubuntu-xenial/

Change-Id: I80d44e391f0e8686a145f74cbc7fedc6ba38c80b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/76/471776/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,64e6e8c8d416f51a6488acf9dc08884e7f063a2d,bp/mesos-dcos, - gate-functional-dsvm-magnum-dcos-ubuntu-xenial-nv,,4,1
openstack%2Fkolla~master~I627ef2aa02394d1f5e3a9150f23944357e227df9,openstack/kolla,master,I627ef2aa02394d1f5e3a9150f23944357e227df9,Add os-brick to glance container,MERGED,2017-05-27 03:19:33.000000000,2017-06-18 07:14:58.000000000,2017-06-18 07:14:58.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4428}, {'_account_id': 7488}, {'_account_id': 9414}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 23717}, {'_account_id': 24072}, {'_account_id': 25945}]","[{'number': 1, 'created': '2017-05-27 03:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0b60253bfde0cace780e55e21479bf1fd3eb2d6c', 'message': 'Add os-brick to glance container\n\nos-brick is needed [1] for cinder volume backend for glance.\n\n[1]: https://github.com/openstack/glance_store/blob/master/setup.cfg#L63\n\nChange-Id: I627ef2aa02394d1f5e3a9150f23944357e227df9\n'}, {'number': 2, 'created': '2017-05-31 00:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d3aaed576351dd903ad14af6075f73c5cc212579', 'message': 'Add os-brick to glance container\n\nos-brick is needed [1] for cinder volume backend for glance.\n\n[1]: https://github.com/openstack/glance_store/blob/master/setup.cfg#L63\n\nChange-Id: I627ef2aa02394d1f5e3a9150f23944357e227df9\nCloses-bug: #1694569\n'}, {'number': 3, 'created': '2017-06-02 00:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/478b7b503fe26d16dc67e38a7dcb6458f35ec87b', 'message': 'Add os-brick to glance container\n\nos-brick is needed [1] for cinder volume backend for glance.\n\n[1]: https://github.com/openstack/glance_store/blob/master/setup.cfg#L63\n\nChange-Id: I627ef2aa02394d1f5e3a9150f23944357e227df9\nCloses-bug: #1694569\n'}, {'number': 4, 'created': '2017-06-08 00:19:09.000000000', 'files': ['docker/glance/glance-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5032177d92b19ec764f1d50241a38a40f8a289c0', 'message': 'Add os-brick to glance container\n\nos-brick is needed [1] for cinder volume backend for glance.\n\n[1]: https://github.com/openstack/glance_store/blob/master/setup.cfg#L63\n\nChange-Id: I627ef2aa02394d1f5e3a9150f23944357e227df9\nCloses-bug: #1694569\n'}]",8,468604,5032177d92b19ec764f1d50241a38a40f8a289c0,41,11,4,4428,,,0,"Add os-brick to glance container

os-brick is needed [1] for cinder volume backend for glance.

[1]: https://github.com/openstack/glance_store/blob/master/setup.cfg#L63

Change-Id: I627ef2aa02394d1f5e3a9150f23944357e227df9
Closes-bug: #1694569
",git fetch https://review.opendev.org/openstack/kolla refs/changes/04/468604/3 && git format-patch -1 --stdout FETCH_HEAD,['docker/glance/glance-base/Dockerfile.j2'],1,0b60253bfde0cace780e55e21479bf1fd3eb2d6c,bug/1694569, 'python-os-brick',,1,0
openstack%2Fnova~master~I25ba6f7f4e4fab6db223368427d889d6b06a77e8,openstack/nova,master,I25ba6f7f4e4fab6db223368427d889d6b06a77e8,Fix regression preventing reporting negative resources for overcommit,MERGED,2017-06-16 14:39:31.000000000,2017-06-18 05:56:30.000000000,2017-06-16 17:24:20.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15286}]","[{'number': 1, 'created': '2017-06-16 14:39:31.000000000', 'files': ['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d', 'message': ""Fix regression preventing reporting negative resources for overcommit\n\nIn Nova prior to Ocata, the scheduler computes available resources for\na compute node, attempting to mirror the same calculation that happens\nlocally. It does this to determine if a new instance should fit on the\nnode. If overcommit is being used, some of these numbers can be negative.\n\nIn change 016b810f675b20e8ce78f4c82dc9c679c0162b7a we changed the\ncompute side to never report negative resources, which was an ironic-\nspecific fix for nodes that are offline. That, however, has been\ncorrected for ironic nodes in 047da6498dbb3af71bcb9e6d0e2c38aa23b06615.\nSince the base change to the resource tracker has caused the scheduler\nand compute to do different math, we need to revert it to avoid the\nscheduler sending instances to nodes where it believes -NNN is the\nlower limit (with overcommit), but the node is reporting zero.\n\nThis doesn't actually affect Ocata because of our use of the placement\nengine. However, this code is still in master and needs to be backported.\nThis part of the change actually didn't even have a unit test, so\nthis patch adds one to validate that the resource tracker will\ncalculate and report negative resources.\n\nChange-Id: I25ba6f7f4e4fab6db223368427d889d6b06a77e8\nCloses-Bug: #1698383\n""}]",1,474994,0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d,20,8,1,4393,,,0,"Fix regression preventing reporting negative resources for overcommit

In Nova prior to Ocata, the scheduler computes available resources for
a compute node, attempting to mirror the same calculation that happens
locally. It does this to determine if a new instance should fit on the
node. If overcommit is being used, some of these numbers can be negative.

In change 016b810f675b20e8ce78f4c82dc9c679c0162b7a we changed the
compute side to never report negative resources, which was an ironic-
specific fix for nodes that are offline. That, however, has been
corrected for ironic nodes in 047da6498dbb3af71bcb9e6d0e2c38aa23b06615.
Since the base change to the resource tracker has caused the scheduler
and compute to do different math, we need to revert it to avoid the
scheduler sending instances to nodes where it believes -NNN is the
lower limit (with overcommit), but the node is reporting zero.

This doesn't actually affect Ocata because of our use of the placement
engine. However, this code is still in master and needs to be backported.
This part of the change actually didn't even have a unit test, so
this patch adds one to validate that the resource tracker will
calculate and report negative resources.

Change-Id: I25ba6f7f4e4fab6db223368427d889d6b06a77e8
Closes-Bug: #1698383
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/474994/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py']",2,0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d,bug/1698383,," cn.free_ram_mb = max(0, cn.free_ram_mb) cn.free_disk_gb = max(0, cn.free_disk_gb) ",20,3
openstack%2Fironic~master~I7980d8b5f0dc2afee75e5a222bc30efae8cddeb6,openstack/ironic,master,I7980d8b5f0dc2afee75e5a222bc30efae8cddeb6,Updated from global requirements,MERGED,2017-06-15 16:24:09.000000000,2017-06-18 04:49:28.000000000,2017-06-17 01:17:05.000000000,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-06-15 16:24:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ab831428c675bcd961ea58b4f57359d13dd61081', 'message': 'Updated from global requirements\n\nChange-Id: I7980d8b5f0dc2afee75e5a222bc30efae8cddeb6\n'}, {'number': 2, 'created': '2017-06-16 12:12:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6fcf371bb74ea7cbdbd7602e3b1456358dadd432', 'message': 'Updated from global requirements\n\nChange-Id: I7980d8b5f0dc2afee75e5a222bc30efae8cddeb6\n'}]",0,474642,6fcf371bb74ea7cbdbd7602e3b1456358dadd432,29,8,2,11131,,,0,"Updated from global requirements

Change-Id: I7980d8b5f0dc2afee75e5a222bc30efae8cddeb6
",git fetch https://review.opendev.org/openstack/ironic refs/changes/42/474642/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ab831428c675bcd961ea58b4f57359d13dd61081,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fopenstack-helm~master~If00d5576757ba483cefad9acbe6f4a61d942eac2,openstack/openstack-helm,master,If00d5576757ba483cefad9acbe6f4a61d942eac2,Fixed typo in glance registry node port value name,MERGED,2017-06-17 23:40:00.000000000,2017-06-18 02:35:09.000000000,2017-06-18 02:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 20466}, {'_account_id': 23928}, {'_account_id': 26201}]","[{'number': 1, 'created': '2017-06-17 23:40:00.000000000', 'files': ['glance/templates/service-registry.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5a93f0f596cbe9879b94093399ccab5d968e8032', 'message': ""Fixed typo in glance registry node port value name\n\nThe value path should have 'registry', not 'register'.\n\nChange-Id: If00d5576757ba483cefad9acbe6f4a61d942eac2\nCloses-Bug: #1698595\n""}]",0,475149,5a93f0f596cbe9879b94093399ccab5d968e8032,11,4,1,22477,,,0,"Fixed typo in glance registry node port value name

The value path should have 'registry', not 'register'.

Change-Id: If00d5576757ba483cefad9acbe6f4a61d942eac2
Closes-Bug: #1698595
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/49/475149/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/templates/service-registry.yaml'],1,5a93f0f596cbe9879b94093399ccab5d968e8032,bug/1698595, nodePort: {{ .Values.network.registry.node_port.port }}, nodePort: {{ .Values.network.register.node_port.port }},1,1
openstack%2Fopenstack-manuals~master~Ibe36dc8c21d1779e735225286a7c8852019ad2c9,openstack/openstack-manuals,master,Ibe36dc8c21d1779e735225286a7c8852019ad2c9,"Update ""http"" to ""https"" for safer",MERGED,2017-06-09 19:54:34.000000000,2017-06-18 02:04:30.000000000,2017-06-18 02:04:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 17130}, {'_account_id': 17207}, {'_account_id': 19779}, {'_account_id': 19930}, {'_account_id': 20156}, {'_account_id': 25254}]","[{'number': 1, 'created': '2017-06-09 19:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ceaee01ba57d5f72e5f966b7853ff887f06b9f7e', 'message': 'Update ""http"" to ""https"" for safer\n\nChange-Id: Ibe36dc8c21d1779e735225286a7c8852019ad2c9\n'}, {'number': 2, 'created': '2017-06-13 12:59:36.000000000', 'files': ['doc/ha-guide/source/controller-ha-pacemaker.rst', 'doc/ha-guide/source/compute-node-ha.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/08267552f3fb759ed7d2cb576b77021d12546733', 'message': 'Update ""http"" to ""https"" for safer\n\nChange-Id: Ibe36dc8c21d1779e735225286a7c8852019ad2c9\n'}]",1,472787,08267552f3fb759ed7d2cb576b77021d12546733,15,8,2,22165,,,0,"Update ""http"" to ""https"" for safer

Change-Id: Ibe36dc8c21d1779e735225286a7c8852019ad2c9
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/472787/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/controller-ha-pacemaker.rst', 'doc/ha-guide/source/compute-node-ha.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst']",3,ceaee01ba57d5f72e5f966b7853ff887f06b9f7e,,* `Redis <https://redis.io/>`_:* `Memcached <https://memcached.org/>`_:,* `Redis <http://redis.io/>`_:* `Memcached <http://memcached.org/>`_:,5,5
openstack%2Fironic~master~I79faba2206b86288ae636c46468a8b2dc321f979,openstack/ironic,master,I79faba2206b86288ae636c46468a8b2dc321f979,Wait until iDRAC is ready before out-of-band cleaning,MERGED,2017-05-18 19:45:30.000000000,2017-06-18 01:40:55.000000000,2017-06-16 10:11:32.000000000,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10250}, {'_account_id': 10379}, {'_account_id': 11076}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19339}]","[{'number': 1, 'created': '2017-05-18 19:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/42fb8c14d8d11fa748c9ba16bf13343e20525fa9', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the ramdisk\nis loaded.  After in-band cleaning completes, the node is rebooted.  At that\npoint, the iDRAC automatically creates and runs an ""Export Configuration"" job.\nOut-of-band cleaning then starts: either RAID configuration creation or\ndeletion.  If the export job has not finished by the time the RAID deletion or\ncreation job is attempted to be created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait until the\niDRAC declares itself to be ready before proceeding with out-of-band cleaning.\nThis ensures that the export job has completed before creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: Ic318f64c30f24124956c543a8464d0be611f7ebe\n'}, {'number': 2, 'created': '2017-05-18 19:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/19c7321ad02f8188f9022e35b27ae3fdeace5244', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the\nramdisk is loaded.  After in-band cleaning completes, the node is\nrebooted.  At that point, the iDRAC automatically creates and runs an\n""Export Configuration"" job.  Out-of-band cleaning then starts: either\nRAID configuration creation or deletion.  If the export job has not\nfinished by the time the RAID deletion or creation job is attempted to\nbe created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait\nuntil the iDRAC declares itself to be ready before proceeding with\nout-of-band cleaning.  This ensures that the export job has completed\nbefore creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: Ic318f64c30f24124956c543a8464d0be611f7ebe\n'}, {'number': 3, 'created': '2017-05-19 18:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b3d24cb7f955b14d9b628880944c2ccabc9ab842', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the\nramdisk is loaded.  After in-band cleaning completes, the node is\nrebooted.  At that point, the iDRAC automatically creates and runs an\n""Export Configuration"" job.  Out-of-band cleaning then starts: either\nRAID configuration creation or deletion.  If the export job has not\nfinished by the time the RAID deletion or creation job is attempted to\nbe created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait\nuntil the iDRAC declares itself to be ready before proceeding with\nout-of-band cleaning.  This ensures that the export job has completed\nbefore creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: I929deada3dda7b09a6f29033fff89d9b0382aef8\n'}, {'number': 4, 'created': '2017-05-19 18:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a2a1e889909062f8e9f6bee453f4f38cf5fcc7db', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the\nramdisk is loaded.  After in-band cleaning completes, the node is\nrebooted.  At that point, the iDRAC automatically creates and runs an\n""Export Configuration"" job.  Out-of-band cleaning then starts: either\nRAID configuration creation or deletion.  If the export job has not\nfinished by the time the RAID deletion or creation job is attempted to\nbe created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait\nuntil the iDRAC declares itself to be ready before proceeding with\nout-of-band cleaning.  This ensures that the export job has completed\nbefore creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: I929deada3dda7b09a6f29033fff89d9b0382aef8\n'}, {'number': 5, 'created': '2017-06-07 17:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ba88cfc4c2a7bc35403ad6e8ce5c989116666c4e', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the\nramdisk is loaded.  After in-band cleaning completes, the node is\nrebooted.  At that point, the iDRAC automatically creates and runs an\n""Export Configuration"" job.  Out-of-band cleaning then starts: either\nRAID configuration creation or deletion.  If the export job has not\nfinished by the time the RAID deletion or creation job is attempted to\nbe created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait\nuntil the iDRAC declares itself to be ready before proceeding with\nout-of-band cleaning.  This ensures that the export job has completed\nbefore creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: I929deada3dda7b09a6f29033fff89d9b0382aef8\n'}, {'number': 6, 'created': '2017-06-12 14:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/447e16bbcd56de422c82899f2577792c41547f57', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the\nramdisk is loaded.  After in-band cleaning completes, the node is\nrebooted.  At that point, the iDRAC automatically creates and runs an\n""Export Configuration"" job.  Out-of-band cleaning then starts: either\nRAID configuration creation or deletion.  If the export job has not\nfinished by the time the RAID deletion or creation job is attempted to\nbe created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait\nuntil the iDRAC declares itself to be ready before proceeding with\nout-of-band cleaning.  This ensures that the export job has completed\nbefore creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: I929deada3dda7b09a6f29033fff89d9b0382aef8\n'}, {'number': 7, 'created': '2017-06-15 14:07:20.000000000', 'files': ['ironic/tests/unit/drivers/modules/drac/test_raid.py', 'releasenotes/notes/drac-fix-oob-cleaning-b4b717895e243c9b.yaml', 'ironic/drivers/modules/drac/raid.py', 'driver-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/35f222c55deaa13c599de80eb9eaf0e4cbf8165e', 'message': 'Wait until iDRAC is ready before out-of-band cleaning\n\nWhen out-of-band cleaning is initiated, the node is PXE booted and the\nramdisk is loaded.  After in-band cleaning completes, the node is\nrebooted.  At that point, the iDRAC automatically creates and runs an\n""Export Configuration"" job.  Out-of-band cleaning then starts: either\nRAID configuration creation or deletion.  If the export job has not\nfinished by the time the RAID deletion or creation job is attempted to\nbe created, then the RAID job creation fails.\n\nThis patch causes RAID configuration creation and deletion to wait\nuntil the iDRAC declares itself to be ready before proceeding with\nout-of-band cleaning.  This ensures that the export job has completed\nbefore creating another job.\n\nChange-Id: I79faba2206b86288ae636c46468a8b2dc321f979\nCloses-Bug: 1691808\nDepends-On: I929deada3dda7b09a6f29033fff89d9b0382aef8\n'}]",4,466086,35f222c55deaa13c599de80eb9eaf0e4cbf8165e,59,12,7,10250,,,0,"Wait until iDRAC is ready before out-of-band cleaning

When out-of-band cleaning is initiated, the node is PXE booted and the
ramdisk is loaded.  After in-band cleaning completes, the node is
rebooted.  At that point, the iDRAC automatically creates and runs an
""Export Configuration"" job.  Out-of-band cleaning then starts: either
RAID configuration creation or deletion.  If the export job has not
finished by the time the RAID deletion or creation job is attempted to
be created, then the RAID job creation fails.

This patch causes RAID configuration creation and deletion to wait
until the iDRAC declares itself to be ready before proceeding with
out-of-band cleaning.  This ensures that the export job has completed
before creating another job.

Change-Id: I79faba2206b86288ae636c46468a8b2dc321f979
Closes-Bug: 1691808
Depends-On: I929deada3dda7b09a6f29033fff89d9b0382aef8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/86/466086/3 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/drac/raid.py'],1,42fb8c14d8d11fa748c9ba16bf13343e20525fa9,bug/1691808," # The node is rebooting at this point, so wait for the iDRAC to # enter the ready state before proceeding with cleaning client = drac_common.get_drac_client(node) client.wait_until_idrac_is_ready() # The node is rebooting at this point, so wait for the iDRAC to # enter the ready state before proceeding with cleaning client = drac_common.get_drac_client(node) client.wait_until_idrac_is_ready() ",,10,0
openstack%2Fmagnum~stable%2Focata~I9bfe36e5dd956280eaa42d1c3f1620c4ec27bc0c,openstack/magnum,stable/ocata,I9bfe36e5dd956280eaa42d1c3f1620c4ec27bc0c,Use lowercase keys for swarm waitcondition signal,MERGED,2017-06-16 13:29:35.000000000,2017-06-17 21:07:57.000000000,2017-06-17 21:07:57.000000000,"[{'_account_id': 3}, {'_account_id': 13861}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-06-16 13:29:35.000000000', 'files': ['magnum/drivers/common/templates/swarm/fragments/write-swarm-agent-service.sh', 'magnum/drivers/common/templates/swarm/fragments/cfn-signal.sh', 'magnum/drivers/common/templates/swarm/fragments/write-swarm-master-service.sh', 'magnum/drivers/common/templates/swarm/fragments/write-cluster-failure-service.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8d0f25f130ccb645c51ee080c49971b7816b8e80', 'message': 'Use lowercase keys for swarm waitcondition signal\n\nThe heat waitcondition signal API accepts status, reason, data and id\nfields in a JSON object supplied as POST data. Missing fields will be\nfilled with defaults. Previously, the swarm script fragments used a\ncapitalised form of these keys (Status, Reason, Data, Id) which was\nnot being recognised by heat. This caused failures to not be reported.\n\nThis change uses the correct lowercase names for these fields and also\nfixes some quoting and incorrect use of UUIDs provided as the id field.\n\nChange-Id: I9bfe36e5dd956280eaa42d1c3f1620c4ec27bc0c\nCloses-Bug: #1504059\n'}]",0,474972,8d0f25f130ccb645c51ee080c49971b7816b8e80,24,3,1,14826,,,0,"Use lowercase keys for swarm waitcondition signal

The heat waitcondition signal API accepts status, reason, data and id
fields in a JSON object supplied as POST data. Missing fields will be
filled with defaults. Previously, the swarm script fragments used a
capitalised form of these keys (Status, Reason, Data, Id) which was
not being recognised by heat. This caused failures to not be reported.

This change uses the correct lowercase names for these fields and also
fixes some quoting and incorrect use of UUIDs provided as the id field.

Change-Id: I9bfe36e5dd956280eaa42d1c3f1620c4ec27bc0c
Closes-Bug: #1504059
",git fetch https://review.opendev.org/openstack/magnum refs/changes/72/474972/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/swarm/fragments/cfn-signal.sh', 'magnum/drivers/common/templates/swarm/fragments/write-swarm-agent-service.sh', 'magnum/drivers/common/templates/swarm/fragments/write-swarm-master-service.sh', 'magnum/drivers/common/templates/swarm/fragments/write-cluster-failure-service.yaml']",4,8d0f25f130ccb645c51ee080c49971b7816b8e80,bug/1504059," --data-binary '{""status"": ""FAILURE"", ""reason"": ""$SERVICE service failed to start."", ""data"": ""Failure""}' \"," UUID=`uuidgen` --data-binary ""'""'{""Status"": ""FAILURE"", ""Reason"": ""$SERVICE service failed to start."", ""Data"": ""Failure"", ""Id"": ""$UUID""}'""'"" \",6,7
openstack%2Ftripleo-heat-templates~stable%2Focata~I306a8378dc1685132f7ea3ed91d345eaae70046f,openstack/tripleo-heat-templates,stable/ocata,I306a8378dc1685132f7ea3ed91d345eaae70046f,"Add support for Cinder ""NAS secure"" driver params",MERGED,2017-06-16 12:08:12.000000000,2017-06-17 20:59:48.000000000,2017-06-17 20:59:48.000000000,"[{'_account_id': 3}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-16 12:08:12.000000000', 'files': ['puppet/services/cinder-volume.yaml', 'puppet/services/cinder-backend-netapp.yaml', 'releasenotes/notes/add-cinder-nas-secure-parameters-53f9d6a6e9bc129b.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21eb374fa155131081e40bd3ec75c16ef6b454e4', 'message': 'Add support for Cinder ""NAS secure"" driver params\n\nAdd new parameters that control the NAS security settings in Cinder\'s\nNFS and NetApp back end drivers. The settings are disabled by default.\n\nPartial-Bug: #1688332\nDepends-On: I76e2ce10acf7b671be6a2785829ebb3012b79308\nChange-Id: I306a8378dc1685132f7ea3ed91d345eaae70046f\n(cherry picked from commit 4a48ad89a16b79ac57475a3cb4427b9b60dcd3e3)\n'}]",0,474955,21eb374fa155131081e40bd3ec75c16ef6b454e4,12,2,1,21129,,,0,"Add support for Cinder ""NAS secure"" driver params

Add new parameters that control the NAS security settings in Cinder's
NFS and NetApp back end drivers. The settings are disabled by default.

Partial-Bug: #1688332
Depends-On: I76e2ce10acf7b671be6a2785829ebb3012b79308
Change-Id: I306a8378dc1685132f7ea3ed91d345eaae70046f
(cherry picked from commit 4a48ad89a16b79ac57475a3cb4427b9b60dcd3e3)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/55/474955/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/cinder-volume.yaml', 'puppet/services/cinder-backend-netapp.yaml', 'releasenotes/notes/add-cinder-nas-secure-parameters-53f9d6a6e9bc129b.yaml']",3,21eb374fa155131081e40bd3ec75c16ef6b454e4,bug/1688332,--- features: - Add parameters to control the Cinder NAS security settings associated with the NFS and NetApp Cinder back ends. The settings are disabled by default. ,,29,0
openstack%2Fnova~master~I5961a482ed4de1c8d963e23aa638665c436e7ae8,openstack/nova,master,I5961a482ed4de1c8d963e23aa638665c436e7ae8,WIP set ethernet script to /bin/ture,ABANDONED,2017-06-13 23:52:09.000000000,2017-06-17 20:24:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-06-13 23:52:09.000000000', 'files': ['nova/virt/libvirt/designer.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1ad4f48f5630526d7917b22324d09f0cd61fd905', 'message': 'WIP set ethernet script to /bin/ture\n\n- test patch to check if this will resolve\n  intermitent delay in unpulging interface\n  with libvirt interface type ethernet.\n\nChange-Id: I5961a482ed4de1c8d963e23aa638665c436e7ae8\n'}]",1,474006,1ad4f48f5630526d7917b22324d09f0cd61fd905,12,10,1,11604,,,0,"WIP set ethernet script to /bin/ture

- test patch to check if this will resolve
  intermitent delay in unpulging interface
  with libvirt interface type ethernet.

Change-Id: I5961a482ed4de1c8d963e23aa638665c436e7ae8
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/474006/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/designer.py'],1,1ad4f48f5630526d7917b22324d09f0cd61fd905,, #if host.has_min_version(MIN_LIBVIRT_ETHERNET_SCRIPT_PATH_NONE): # conf.script = None #else: conf.script = '/bin/true', if host.has_min_version(MIN_LIBVIRT_ETHERNET_SCRIPT_PATH_NONE): conf.script = None else: conf.script = '',4,4
openstack%2Ftripleo-ci~master~Ic95ae22255df7f7ed7ba347e083ac311cca25095,openstack/tripleo-ci,master,Ic95ae22255df7f7ed7ba347e083ac311cca25095,Fix checking of ZUUL CHANGES,MERGED,2017-06-17 10:19:19.000000000,2017-06-17 19:51:34.000000000,2017-06-17 19:51:34.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8652}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12715}]","[{'number': 1, 'created': '2017-06-17 10:19:19.000000000', 'files': ['scripts/common_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/94a7b804cfe7510366ca76af245a06e723f2a4a9', 'message': 'Fix checking of ZUUL CHANGES\n\nIf ZUUL_CHANGES is not defined like it happens in periodic jobs\nit should have default as empty string.\n\nChange-Id: Ic95ae22255df7f7ed7ba347e083ac311cca25095\n'}]",0,475122,94a7b804cfe7510366ca76af245a06e723f2a4a9,8,6,1,10969,,,0,"Fix checking of ZUUL CHANGES

If ZUUL_CHANGES is not defined like it happens in periodic jobs
it should have default as empty string.

Change-Id: Ic95ae22255df7f7ed7ba347e083ac311cca25095
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/22/475122/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/common_functions.sh'],1,94a7b804cfe7510366ca76af245a06e723f2a4a9,fixprom1, if [[ -z ${ZUUL_CHANGES:-''} ]]; then, if [[ -z $ZUUL_CHANGES ]]; then,1,1
openstack%2Fsahara~master~Ibfcaa0373da62c0fa7c7150213267635f459595c,openstack/sahara,master,Ibfcaa0373da62c0fa7c7150213267635f459595c,Add 'rm -f .testrepository/times.dbm' command in testenv,ABANDONED,2017-06-15 09:44:18.000000000,2017-06-17 19:04:39.000000000,,"[{'_account_id': 3}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 12038}]","[{'number': 1, 'created': '2017-06-15 09:44:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2f9657d1ad8af81afc36b439e6194408cc370ba2', 'message': ""Add 'rm -f .testrepository/times.dbm' command in testenv\n\nRunning py2* post py3* tests results in error. Add\n'rm -f .testrepository/times.dbm' command in testenv to resolve this.\n\nChange-Id: Ibfcaa0373da62c0fa7c7150213267635f459595c\n""}]",0,474522,2f9657d1ad8af81afc36b439e6194408cc370ba2,6,4,1,26072,,,0,"Add 'rm -f .testrepository/times.dbm' command in testenv

Running py2* post py3* tests results in error. Add
'rm -f .testrepository/times.dbm' command in testenv to resolve this.

Change-Id: Ibfcaa0373da62c0fa7c7150213267635f459595c
",git fetch https://review.opendev.org/openstack/sahara refs/changes/22/474522/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2f9657d1ad8af81afc36b439e6194408cc370ba2,testenv,commands = rm -f .testrepository/times.dbm ostestr {posargs},commands = ostestr {posargs},2,1
openstack%2Fproject-config~master~Id6510c454975b5847845f6438c8342d0a9ee0b2e,openstack/project-config,master,Id6510c454975b5847845f6438c8342d0a9ee0b2e,"Multinode gates, dockerhub publisher prework",MERGED,2017-06-06 17:36:16.000000000,2017-06-17 18:51:15.000000000,2017-06-17 18:51:15.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 10787}, {'_account_id': 13252}]","[{'number': 1, 'created': '2017-06-06 17:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/553329dac7276f952299676960a4b62249f78bd7', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 2, 'created': '2017-06-06 17:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2d25f54dc5080d2979bd383d6b088b1321fcf0f5', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 3, 'created': '2017-06-06 17:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2871c17c64fd47e1ec6f97405b0015a131146cd4', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 4, 'created': '2017-06-06 21:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bbb1ff675485dc7ce1d88206461a2823418f9528', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 5, 'created': '2017-06-06 21:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d6f4e039c1324b5cf1e35651e7a1aabde88d5d27', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 6, 'created': '2017-06-06 22:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7ba71e3cb07aa3fcdfc3eee37adc01663fa42494', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 7, 'created': '2017-06-08 21:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a750ee2aa0a8bb00576a432c055aa1bca99e97d6', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 8, 'created': '2017-06-08 21:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/95b9dc8a7e6fd015a14f84822c767ec61a3f9262', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 9, 'created': '2017-06-08 22:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2c7d7af0b99ef92e362378f3b9c8bcdc12b8d192', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 10, 'created': '2017-06-08 22:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/28f6b06d44ec5870c5cdc7035f8d540edb31b795', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 11, 'created': '2017-06-08 23:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bd367fe5a3e84f27b24a57d18e6b121445041908', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 12, 'created': '2017-06-09 15:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/251364017c189db81395360502faf69547821a5f', 'message': 'Make multinode gates regular\n\nAlso prepare groundwork for upgrade gates and dockerhub publisher\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 13, 'created': '2017-06-09 21:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5801fcf658c14031236243910a5fb637376dcc8a', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 14, 'created': '2017-06-09 21:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/31458ef2f08d032b5b6d43e0b4d332c12e368251', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 15, 'created': '2017-06-09 22:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2bfa600bf2d050dac4b0c7130fb8c75e72c447db', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 16, 'created': '2017-06-09 23:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fa7702bd4aca71ffbeeaebd45a889d0d3bf4f39e', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 17, 'created': '2017-06-10 00:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/84c1d835ac68779d81ab979f81a988f4157ce482', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 18, 'created': '2017-06-13 17:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/95d2c02e84b8da5ff4940745e817423cdd212fb3', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 19, 'created': '2017-06-14 18:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/04388528c001944c9f39cc096838bcf0e3c8bf26', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}, {'number': 20, 'created': '2017-06-14 18:45:18.000000000', 'files': ['jenkins/jobs/kolla.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f2128248b776e42b99cef0ce8d62fa5b4916415d', 'message': 'Multinode gates, dockerhub publisher prework\n\nPrepare groundwork for upgrade gates and dockerhub publisher, also move\nmultinode jobs from experimental to regular pipeline\n\nChange-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e\n'}]",12,471428,f2128248b776e42b99cef0ce8d62fa5b4916415d,53,6,20,10787,,,0,"Multinode gates, dockerhub publisher prework

Prepare groundwork for upgrade gates and dockerhub publisher, also move
multinode jobs from experimental to regular pipeline

Change-Id: Id6510c454975b5847845f6438c8342d0a9ee0b2e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/28/471428/13 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/kolla.yaml', 'zuul/layout.yaml']",2,553329dac7276f952299676960a4b62249f78bd7,, - prepublish-gate-kolla-dsvm-build-ubuntu-source-ubuntu-xenial experimental: - prepublish-kolla-ansible-dsvm-deploy-multinode-ubuntu-source-ubuntu-xenial-2-node-nv - gate-kolla-ansible-dsvm-upgrade-multinode-centos-source-centos-7-node-nv, - gate-kolla-dsvm-build-ubuntu-binary-ubuntu-trusty-nv - gate-kolla-dsvm-build-ubuntu-source-ubuntu-trusty-nv - gate-kolla-dsvm-deploy-ubuntu-binary-ubuntu-trusty-nv - gate-kolla-dsvm-deploy-ubuntu-source-ubuntu-trusty-nv - gate-kolla-dsvm-deploy-multinode-ubuntu-source-ubuntu-trusty-2-node-nv experimental:,37,6
openstack%2Fopenstack-helm~master~Iabd80c8c5f6ae1df8cce2330b75629c7b127398e,openstack/openstack-helm,master,Iabd80c8c5f6ae1df8cce2330b75629c7b127398e,Helm Test: Neutron,ABANDONED,2017-06-06 22:23:54.000000000,2017-06-17 18:10:48.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-06 22:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/194525eaf6490957eae16dd7f840ddb75a9c8e16', 'message': ""Helm Test: Neutron\n\nThis PS introduces 'helm test' functionaility to Neutron.\n\nChange-Id: Iabd80c8c5f6ae1df8cce2330b75629c7b127398e\nPartial-Implements: blueprint implement-helm-test-for-charts\n""}, {'number': 2, 'created': '2017-06-06 22:26:03.000000000', 'files': ['neutron/templates/configmap-bin.yaml', 'neutron/templates/pod-rally-test.yaml', 'neutron/templates/etc/_rally_tests.yaml.tpl', 'tools/gate/basic_launch.sh', 'neutron/values.yaml', 'neutron/templates/configmap-etc.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/84d231f4860f15120bfc66c24f0eced3fc392395', 'message': ""Helm Test: Neutron\n\nThis PS introduces 'helm test' functionaility to Neutron.\n\nChange-Id: Iabd80c8c5f6ae1df8cce2330b75629c7b127398e\nPartial-Implements: blueprint implement-helm-test-for-charts\n""}]",0,471504,84d231f4860f15120bfc66c24f0eced3fc392395,5,1,2,23928,,,0,"Helm Test: Neutron

This PS introduces 'helm test' functionaility to Neutron.

Change-Id: Iabd80c8c5f6ae1df8cce2330b75629c7b127398e
Partial-Implements: blueprint implement-helm-test-for-charts
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/04/471504/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/templates/configmap-bin.yaml', 'neutron/templates/pod-rally-test.yaml', 'neutron/templates/etc/_rally_tests.yaml.tpl', 'neutron/values.yaml', 'neutron/templates/configmap-etc.yaml']",5,194525eaf6490957eae16dd7f840ddb75a9c8e16,bp/implement-helm-test-for-charts," rally_tests.yaml: |+ {{ if .Values.conf.rally_tests.override -}} {{ .Values.conf.rally_tests.override | indent 4 }} {{- else -}} {{- if .Values.conf.rally_tests.prefix -}} {{ .Values.conf.rally_tests.prefix | indent 4 }} {{- end }} {{ tuple ""etc/_rally_tests.yaml.tpl"" . | include ""helm-toolkit.utils.template"" | indent 4 }} {{- end }} {{- if .Values.conf.rally_tests.append -}} {{ .Values.conf.rally_tests.append | indent 4 }} {{- end }}",,398,0
openstack%2Freno~master~I7382ee143c7fb19b19e52ac6c37960242fde8628,openstack/reno,master,I7382ee143c7fb19b19e52ac6c37960242fde8628,Move notesdir default to 'defaults' module,MERGED,2017-06-16 17:15:27.000000000,2017-06-17 17:25:06.000000000,2017-06-17 17:25:06.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 14758}]","[{'number': 1, 'created': '2017-06-16 17:15:27.000000000', 'files': ['reno/config.py', 'reno/defaults.py'], 'web_link': 'https://opendev.org/openstack/reno/commit/18df043b5a0d75baf311e4f4bb3c64a6f0de7373', 'message': ""Move notesdir default to 'defaults' module\n\nWe're going to use this shortly.\n\nChange-Id: I7382ee143c7fb19b19e52ac6c37960242fde8628\n""}]",0,475032,18df043b5a0d75baf311e4f4bb3c64a6f0de7373,8,4,1,15334,,,0,"Move notesdir default to 'defaults' module

We're going to use this shortly.

Change-Id: I7382ee143c7fb19b19e52ac6c37960242fde8628
",git fetch https://review.opendev.org/openstack/reno refs/changes/32/475032/1 && git format-patch -1 --stdout FETCH_HEAD,"['reno/config.py', 'reno/defaults.py']",2,18df043b5a0d75baf311e4f4bb3c64a6f0de7373,reno-pbr-integration,NOTES_SUBDIR = 'notes',,2,1
openstack%2Fproject-config~master~I9ba26958ec1364de58df625e249fd74ae0d00a95,openstack/project-config,master,I9ba26958ec1364de58df625e249fd74ae0d00a95,Templatize Laravel jobs,MERGED,2017-06-08 20:22:00.000000000,2017-06-17 16:55:56.000000000,2017-06-17 16:55:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2017-06-08 20:22:00.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/openstackid.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/63c0e5231a97a65a66c1127160418d10165adb04', 'message': ""Templatize Laravel jobs\n\nThe unit test and release jobs for OpenStackID are potentially\nuseful for other Laravel-based projects, so genericize them.\n\nAlso stop redundantly adding the gate-openstackid-docs-ubuntu-xenial\njob to openstack-infra/openstackid's entry in the Zuul layout since\nit's already included in the infra-publish-jobs project-template.\n\nChange-Id: I9ba26958ec1364de58df625e249fd74ae0d00a95\n""}]",0,472402,63c0e5231a97a65a66c1127160418d10165adb04,7,3,1,5263,,,0,"Templatize Laravel jobs

The unit test and release jobs for OpenStackID are potentially
useful for other Laravel-based projects, so genericize them.

Also stop redundantly adding the gate-openstackid-docs-ubuntu-xenial
job to openstack-infra/openstackid's entry in the Zuul layout since
it's already included in the infra-publish-jobs project-template.

Change-Id: I9ba26958ec1364de58df625e249fd74ae0d00a95
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/472402/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'jenkins/jobs/openstackid.yaml', 'zuul/layout.yaml']",3,63c0e5231a97a65a66c1127160418d10165adb04,openstackid-resources, - gate-laravel-openstackid-unittests gate: - gate-laravel-openstackid-unittests post: - laravel-openstackid-release-branch release: - laravel-openstackid-release-master, - gate-openstackid-unittests - gate-openstackid-docs-ubuntu-xenial gate: - gate-openstackid-unittests - gate-openstackid-docs-ubuntu-xenial post: - openstackid-release-branch release: - openstackid-release-master,16,18
openstack%2Fproject-config~master~I88c0c8878cb5bed48b624755c5730e48df858622,openstack/project-config,master,I88c0c8878cb5bed48b624755c5730e48df858622,bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs,MERGED,2017-06-07 08:01:02.000000000,2017-06-17 16:55:44.000000000,2017-06-17 16:55:44.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 7118}, {'_account_id': 11655}]","[{'number': 1, 'created': '2017-06-07 08:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c3f9fa9dc32923206f39746cd2a2c067da409e1f', 'message': ""bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs\n\nRight now, openSUSE and CentOS distributions are only being tested\nvia a 3rd party CI provided by OPNFV. However, that CI is testing\nmore complex scenarios than the existing jobs, so it will be useful\nto add experimental jobs for these two distributions which can be\npromoted to 'gates' in the future to have them properly tested.\n\nChange-Id: I88c0c8878cb5bed48b624755c5730e48df858622\n""}, {'number': 2, 'created': '2017-06-07 08:01:35.000000000', 'files': ['jenkins/jobs/bifrost.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f05d1fbbf215772caecec9739142dc8520c02cb9', 'message': ""bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs\n\nRight now, openSUSE and CentOS distributions are only being tested\nvia a 3rd party CI provided by OPNFV. However, that CI is testing\nmore complex scenarios than the existing jobs, so it will be useful\nto add experimental jobs for these two distributions which can be\npromoted to 'gates' in the future to have them properly tested.\n\nChange-Id: I88c0c8878cb5bed48b624755c5730e48df858622\n""}]",0,471618,f05d1fbbf215772caecec9739142dc8520c02cb9,10,6,2,23163,,,0,"bifrost: Add experimental openSUSE 42.2 and CentOS 7 jobs

Right now, openSUSE and CentOS distributions are only being tested
via a 3rd party CI provided by OPNFV. However, that CI is testing
more complex scenarios than the existing jobs, so it will be useful
to add experimental jobs for these two distributions which can be
promoted to 'gates' in the future to have them properly tested.

Change-Id: I88c0c8878cb5bed48b624755c5730e48df858622
",git fetch https://review.opendev.org/openstack/project-config refs/changes/18/471618/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/bifrost.yaml', 'zuul/layout.yaml']",2,c3f9fa9dc32923206f39746cd2a2c067da409e1f,jenkins/jobs/bifrost/add-experimental-opensuse-centos, - name: ^.*bifrost-(python27|integration-tinyipa|integration-dibipa-debian|integration-dhcp)-(ubuntu-(trusty|xenial)|opensuse-422|centos-7)(-nv)?$ experimental: - gate-bifrost-integration-tinyipa-centos-7 - gate-bifrost-integration-tinyipa-opensuse-422 - gate-bifrost-integration-dibipa-debian-centos-7-nv - gate-bifrost-integration-dibipa-debian-opensuse-422-nv - gate-bifrost-integration-dhcp-centos-7-nv - gate-bifrost-integration-dhcp-opensuse-422-nv, - name: ^.*bifrost-(python27|integration-tinyipa|integration-dibipa-debian|integration-dhcp)-ubuntu-(trusty|xenial)(-nv)?$,10,1
openstack%2Fproject-config~master~Ibe785ee64b167cb5fe2a387836ba2da2dd4e66ef,openstack/project-config,master,Ibe785ee64b167cb5fe2a387836ba2da2dd4e66ef,Define package map for suse build essential,MERGED,2017-06-16 18:26:00.000000000,2017-06-17 16:53:55.000000000,2017-06-17 16:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 6593}]","[{'number': 1, 'created': '2017-06-16 18:26:00.000000000', 'files': ['nodepool/elements/infra-package-needs/pkg-map'], 'web_link': 'https://opendev.org/openstack/project-config/commit/31ebae33ebea6f54b9b73634149681d4a383be83', 'message': ""Define package map for suse build essential\n\nSince suse (like rhel) doesn't have a metapackage called build-essential\nwe need to define what that logical name is in our package map. Just use\nthe same set of items that rhel installs (glibc-devel, gcc, and make).\n\nChange-Id: Ibe785ee64b167cb5fe2a387836ba2da2dd4e66ef\n""}]",0,475050,31ebae33ebea6f54b9b73634149681d4a383be83,12,4,1,4146,,,0,"Define package map for suse build essential

Since suse (like rhel) doesn't have a metapackage called build-essential
we need to define what that logical name is in our package map. Just use
the same set of items that rhel installs (glibc-devel, gcc, and make).

Change-Id: Ibe785ee64b167cb5fe2a387836ba2da2dd4e66ef
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/475050/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/elements/infra-package-needs/pkg-map'],1,31ebae33ebea6f54b9b73634149681d4a383be83,suse-build-essential," ""build-essential"": ""glibc-devel gcc make"",",,1,0
openstack%2Fproject-config~master~I84b109be2f57793ca7e6e9b7fd26540a049b0052,openstack/project-config,master,I84b109be2f57793ca7e6e9b7fd26540a049b0052,Normalize projects.yaml,MERGED,2017-06-14 10:31:21.000000000,2017-06-17 16:52:55.000000000,2017-06-17 16:52:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-14 10:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a5477f83977494bcd6d5d26f1448cb785e1076d', 'message': 'Normalize projects.yaml\n\nChange-Id: I84b109be2f57793ca7e6e9b7fd26540a049b0052\n'}, {'number': 2, 'created': '2017-06-15 10:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/28defb8e88c25ff119b5f62673c2812e07b733cc', 'message': 'Normalize projects.yaml\n\nChange-Id: I84b109be2f57793ca7e6e9b7fd26540a049b0052\n'}, {'number': 3, 'created': '2017-06-16 10:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b976be13b34cda0e21d6ea9cb7ded78290eebb34', 'message': 'Normalize projects.yaml\n\nChange-Id: I84b109be2f57793ca7e6e9b7fd26540a049b0052\n'}, {'number': 4, 'created': '2017-06-17 08:53:11.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0ef6bf0c762072ec027e1e25bb661a80cd36306f', 'message': 'Normalize projects.yaml\n\nChange-Id: I84b109be2f57793ca7e6e9b7fd26540a049b0052\n'}]",0,474147,0ef6bf0c762072ec027e1e25bb661a80cd36306f,12,2,4,11131,,,0,"Normalize projects.yaml

Change-Id: I84b109be2f57793ca7e6e9b7fd26540a049b0052
",git fetch https://review.opendev.org/openstack/project-config refs/changes/47/474147/3 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,4a5477f83977494bcd6d5d26f1448cb785e1076d,project-yaml-normalization,, upstream: https://github.com/danielmellado/kuryr-tempest-plugin,0,1
openstack%2Fopenstack-manuals~master~Ic157622aead343071ddd667f3494eec5f676920b,openstack/openstack-manuals,master,Ic157622aead343071ddd667f3494eec5f676920b,[cli-ref] Update python-solumclient to 2.4.0,MERGED,2017-06-09 03:46:53.000000000,2017-06-17 16:52:48.000000000,2017-06-17 16:52:48.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 17130}, {'_account_id': 19779}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 03:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/da51c182e848f28c9766463deacbef2d4057ac6e', 'message': '[cli-ref] Update python-solumclient to 2.4.0\n\nChange-Id: Ic157622aead343071ddd667f3494eec5f676920b\n'}, {'number': 2, 'created': '2017-06-09 05:10:03.000000000', 'files': ['doc/cli-reference/source/solum.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5903353422ebba7df2db56d49498d0ff77d119e8', 'message': '[cli-ref] Update python-solumclient to 2.4.0\n\nChange-Id: Ic157622aead343071ddd667f3494eec5f676920b\n'}]",0,472512,5903353422ebba7df2db56d49498d0ff77d119e8,11,5,2,19779,,,0,"[cli-ref] Update python-solumclient to 2.4.0

Change-Id: Ic157622aead343071ddd667f3494eec5f676920b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/12/472512/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/solum.rst'],1,da51c182e848f28c9766463deacbef2d4057ac6e,cli-reference,".. ################################################### .. ## WARNING ###################################### .. ############## WARNING ########################## .. ########################## WARNING ############## .. ###################################### WARNING ## .. ################################################### .. ################################################### .. ## .. This file is tool-generated. Do not edit manually. .. http://docs.openstack.org/contributor-guide/ .. doc-tools/cli-reference.html .. ## .. ## WARNING ###################################### .. ############## WARNING ########################## .. ########################## WARNING ############## .. ###################################### WARNING ## .. ###################################################the Software Development Lifecycle Automation service (solum) API and its extensions. This chapter documents :command:`solum` version ``2.4.0``. For help on a specific :command:`solum` command, enter: .. code-block:: console $ solum help COMMAND.. code-block:: console solum help Show this help message. solum info Show Solum endpoint and API release version. solum --version Show current Solum client version and exit. solum lp help Show a help message specific to languagepack commands. solum lp create <NAME> <GIT_REPO_URL> Create a new language pack from a git repo. solum lp list Print and index of all available language packs. solum lp show <NAME|UUID> Print the details of a language pack. solum lp delete <NAME|UUID> Destroy a language pack. solum lp logs <NAME|UUID> Show logs for a language pack. solum app help Show a help message specific to app commands. solum app list Print an index of all deployed applications. solum app show <NAME|UUID> Print detailed information about one application. solum app create [--app-file <AppFile>] [--git-url <GIT_URL>] [--lp <LANGUAGEPACK>] [--param-file <PARAMFILE>] [--setup-trigger] [--trigger-workflow <CUSTOM-WORKFLOW>] <CUSTOM-WORKFLOW>=(unittest | build | unittest+build) Without the --trigger-workflow flag, the workflow unittest+build+deploy is triggered (this is the default workflow) Register a new application with Solum. solum app deploy <NAME|UUID> Deploy an application, building any applicable artifacts first. du-id is optional flag. It can be used to pass in id of a previously created deployment unit. If passed, this command will deploy the du referenced by the provided du-id instead of building one first. solum app delete <NAME|UUID> Delete an application and all related artifacts. solum app logs <NAME|UUID> [--wf-id <wf-id>] Show the logs of an application for all the workflows. wf-id is optional flag which can be used to pass in id of one of the existing workflows. If provided, the logs only for that workflow are displayed. solum app scale <APP_NAME|UUID> <target> solum workflow list <APP_NAME|UUID> List all application workflows. solum workflow show <APP_NAME|UUID> <WORKFLOW_ID|UUID> Print the details of a workflow. solum workflow logs <APP_NAME|UUID> <WORKFLOW_ID|UUID> List all the logs of a given workflow. SOON TO BE DEPRECATED: solum oldapp create [--plan-file <PLANFILE>] [--git-url <GIT_URL>] [--lp <LANGUAGEPACK>] [--run-cmd <RUN_CMD>] [--unittest-cmd <UNITTEST_CMD>] [--name <NAME>] [--port <PORT>] [--param-file <PARAMFILE>] [--desc <DESCRIPTION>] [--setup-trigger] [--private-repo] [--trigger-workflow <WORKFLOW>] Register a new application with Solum. ",".. This file is manually generated, unlike many of the other chapters.the Software Development Lifecycle Automation service (solum) API and its extensions. This chapter documents :command:`solum` version ``2.3.0``.``solum help`` Show this help message. ``solum info`` Show Solum endpoint and API release version. ``solum --version`` Show current Solum client version and exit. ``solum lp help`` Show a help message specific to languagepack commands. ``solum lp create <NAME> <GIT_REPO_URL>`` Create a new language pack from a git repo. ``solum lp list`` Print and index of all available language packs. ``solum lp show <NAME|UUID>`` Print the details of a language pack. ``solum lp delete <NAME|UUID>`` Destroy a language pack. ``solum lp logs <NAME|UUID>`` Show logs for a language pack. ``solum app help`` Show a help message specific to app commands. ``solum app list`` Print an index of all deployed applications. ``solum app show <NAME|UUID>`` Print detailed information about one application. ``solum app create`` Register a new application with Solum. .. code-block:: console solum app create [--app-file <AppFile>] [--git-url <GIT_URL>] [--lp <LANGUAGEPACK>] [--param-file <PARAMFILE>] [--setup-trigger] [--trigger-workflow <CUSTOM-WORKFLOW>] <CUSTOM-WORKFLOW>=(unittest | build | unittest+build) Without the ``--trigger-workflow`` flag, the workflow ``unittest+build+deploy`` is triggered (this is the default workflow). ``solum app deploy <NAME|UUID>`` Deploy an application, building any applicable artifacts first. du-id is optional flag. It can be used to pass in ID of a previously created deployment unit. If passed, this command will deploy the du referenced by the provided ``du-id`` instead of building one first. ``solum app delete <NAME|UUID>`` Delete an application and all related artifacts. ``solum app logs <NAME|UUID> [--wf-id <wf-id>]`` Show the logs of an application for all the workflows. ``wf-id`` is optional flag which can be used to pass in ID of one of the existing workflows. If provided, the logs only for that workflow are displayed. ``solum app scale <APP_NAME|UUID> <target>`` ``solum workflow list <APP_NAME|UUID>`` List all application workflows. ``solum workflow show <APP_NAME|UUID> <WORKFLOW_ID|UUID>`` Print the details of a workflow. ``solum workflow logs <APP_NAME|UUID> <WORKFLOW_ID|UUID>`` List all the logs of a given workflow. **SOON TO BE DEPRECATED:** ``solum oldapp create`` Register a new application with Solum. .. code-block:: console solum oldapp create [--plan-file <PLANFILE>] [--git-url <GIT_URL>] [--lp <LANGUAGEPACK>] [--run-cmd <RUN_CMD>] [--unittest-cmd <UNITTEST_CMD>] [--name <NAME>] [--port <PORT>] [--param-file <PARAMFILE>] [--desc <DESCRIPTION>] [--setup-trigger] [--private-repo] [--trigger-workflow <WORKFLOW>]",92,95
openstack%2Fopenstack-manuals~master~Ie97e24d40462b88215917cc14e0357946ad2ccc3,openstack/openstack-manuals,master,Ie97e24d40462b88215917cc14e0357946ad2ccc3,[cli-ref] Update python-heatclient to 1.10.0,MERGED,2017-06-09 03:53:13.000000000,2017-06-17 16:52:41.000000000,2017-06-17 16:52:41.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 17130}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 03:53:13.000000000', 'files': ['doc/cli-reference/source/heat.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b61051cd5b867482a5ab2e908ebd8aeda7370ffc', 'message': '[cli-ref] Update python-heatclient to 1.10.0\n\nChange-Id: Ie97e24d40462b88215917cc14e0357946ad2ccc3\n'}]",0,472516,b61051cd5b867482a5ab2e908ebd8aeda7370ffc,9,5,1,19779,,,0,"[cli-ref] Update python-heatclient to 1.10.0

Change-Id: Ie97e24d40462b88215917cc14e0357946ad2ccc3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/16/472516/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/heat.rst'],1,b61051cd5b867482a5ab2e908ebd8aeda7370ffc,cli-reference,This chapter documents :command:`heat` version ``1.10.0``.,This chapter documents :command:`heat` version ``1.9.0``.,1,1
openstack%2Fopenstack-manuals~master~Ic1f778ac0cdd18ce4ca5ac4270c8cac738c1dc78,openstack/openstack-manuals,master,Ic1f778ac0cdd18ce4ca5ac4270c8cac738c1dc78,[cli-ref] Update python-cloudkittyclient to 1.1.0,MERGED,2017-06-09 04:03:18.000000000,2017-06-17 16:52:35.000000000,2017-06-17 16:52:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 17130}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 04:03:18.000000000', 'files': ['doc/cli-reference/source/cloudkitty.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3992b9ecf9bb8974fa859e27f1240f132cb9ecca', 'message': '[cli-ref] Update python-cloudkittyclient to 1.1.0\n\nChange-Id: Ic1f778ac0cdd18ce4ca5ac4270c8cac738c1dc78\n'}]",0,472521,3992b9ecf9bb8974fa859e27f1240f132cb9ecca,9,5,1,19779,,,0,"[cli-ref] Update python-cloudkittyclient to 1.1.0

Change-Id: Ic1f778ac0cdd18ce4ca5ac4270c8cac738c1dc78
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/21/472521/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/cloudkitty.rst'],1,3992b9ecf9bb8974fa859e27f1240f132cb9ecca,cli-reference,This chapter documents :command:`cloudkitty` version ``1.1.0``.,This chapter documents :command:`cloudkitty` version ``1.0.0``.,1,1
openstack%2Fopenstack-manuals~master~I447c51cb22c820c312670d132f3de98158cf7c2a,openstack/openstack-manuals,master,I447c51cb22c820c312670d132f3de98158cf7c2a,[cli-ref] Update python-muranoclient to 0.13.0,MERGED,2017-06-08 02:32:58.000000000,2017-06-17 16:52:28.000000000,2017-06-17 16:52:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 10607}, {'_account_id': 17130}, {'_account_id': 20156}]","[{'number': 1, 'created': '2017-06-08 02:32:58.000000000', 'files': ['doc/cli-reference/source/murano.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/60ac7e4b9286101b74beef6059cb11253120a817', 'message': '[cli-ref] Update python-muranoclient to 0.13.0\n\nChange-Id: I447c51cb22c820c312670d132f3de98158cf7c2a\n'}]",0,472007,60ac7e4b9286101b74beef6059cb11253120a817,10,6,1,19779,,,0,"[cli-ref] Update python-muranoclient to 0.13.0

Change-Id: I447c51cb22c820c312670d132f3de98158cf7c2a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/472007/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/murano.rst'],1,60ac7e4b9286101b74beef6059cb11253120a817,cli-reference,"This chapter documents :command:`murano` version ``0.13.0``. List deployments for an environment or multiple environments.``--os-username OS_USERNAME, --os-user-name OS_USERNAME, --os-user_name OS_USERNAME`` usage: murano deployment-list [--all-environments] [<ID>] List deployments for an environment or multiple environments.**Optional arguments:** ``--all-environments`` Lists all deployments for all environments in user's tenant. ","This chapter documents :command:`murano` version ``0.12.0``. List deployments for an environment.``--os-username OS_USERNAME, --os-user_name OS_USERNAME`` usage: murano deployment-list <ID> List deployments for an environment.",12,5
openstack%2Fopenstack-manuals~master~I8f6d17b497effaccca3bf8b21b0d9490581f79a6,openstack/openstack-manuals,master,I8f6d17b497effaccca3bf8b21b0d9490581f79a6,Imported Translations from Zanata,MERGED,2017-06-10 11:16:19.000000000,2017-06-17 16:52:22.000000000,2017-06-17 16:52:22.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-10 11:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6ffe006ac27497a900ba4afda2cda73764ad60f7', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I8f6d17b497effaccca3bf8b21b0d9490581f79a6\n'}, {'number': 2, 'created': '2017-06-13 11:23:55.000000000', 'files': ['doc/ops-guide/source/locale/ja/LC_MESSAGES/ops-guide.po', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/user-guide/source/locale/id/LC_MESSAGES/user-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9ef3e75200aa6ea52cdd9f5f435d83ee049a821c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I8f6d17b497effaccca3bf8b21b0d9490581f79a6\n'}]",0,472896,9ef3e75200aa6ea52cdd9f5f435d83ee049a821c,9,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I8f6d17b497effaccca3bf8b21b0d9490581f79a6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/472896/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ops-guide/source/locale/ja/LC_MESSAGES/ops-guide.po', 'doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/user-guide/source/locale/id/LC_MESSAGES/user-guide.po']",4,6ffe006ac27497a900ba4afda2cda73764ad60f7,zanata/translations,"""POT-Creation-Date: 2017-06-10 03:00+0000\n""""PO-Revision-Date: 2017-06-10 03:50+0000\n""msgid ""**Create the module file and trove module**"" msgstr ""** Buat file modul dan modul trove **"" msgid ""**Show and list modules**"" msgstr ""** Tampilkan dan daftar modul **"" msgid """" ""An image built with a recent version of the cloud-init package can "" ""automatically access metadata passed through the configuration drive. The "" ""following table lists the references for cloud-init versions mapped to a "" ""particular operating system:"" msgstr """" ""Image yang dibuat dengan versi terbaru dari paket cloud-init secara otomatis "" ""dapat mengakses metadata melewati drive konfigurasi. Tabel berikut "" ""mencantumkan referensi untuk versi cloud-init yang dipetakan ke sistem "" ""operasi tertentu:"" msgid ""Compute tab"" msgstr ""Compute tab"" msgid ""Create a subnet of the ``public`` external network:"" msgstr ""Buat subnet dari jaringan eksternal ``public``:"" msgid ""Create an external network"" msgstr ""Buat jaringan eksternal"" msgid ""Create an external network named ``public``:"" msgstr ""Buat jaringan eksternal bernama ``public``:"" msgid ""Create and apply a module to a mysql database"" msgstr ""Buat dan terapkan modul ke database mysql"" msgid ""Create and use modules for a database"" msgstr ""Buat dan gunakan modul untuk database"" msgid ""Fedora (RHEL)"" msgstr ""Fedora (RHEL)"" msgid ""For variety in this example, create one more instance and module:"" msgstr ""Untuk variasi dalam contoh ini, buat satu lagi instance dan modul:"" ""If this list is empty, the cloud administrator must configure a pool of "" ""floating IP addresses. This command is only available in ``nova-network``. "" ""If you use the OpenStack Networking service, run the following command to "" ""list external networks:"" msgstr """" ""Jika daftar ini kosong, administrator awan harus mengkonfigurasi kumpulan "" ""alamat IP terapung. Perintah ini hanya tersedia di ``nova-network``. Jika "" ""Anda menggunakan layanan OpenStack Networking, jalankan perintah berikut "" ""untuk menampilkan jaringan eksternal:"" msgid """"""If you wish to apply a module, you must create the module first and register "" ""it with the trove service. A user can not directly apply a module to a trove "" ""instance."" msgstr """" ""Jika Anda ingin menerapkan modul, Anda harus membuat modul terlebih dahulu "" ""dan mendaftarkannya dengan layanan trove. Seorang pengguna tidak bisa "" ""langsung menerapkan modul ke instance trove."" msgid """"msgid """" ""In addition to these ways of interacting with a cloud, you can access the "" ""OpenStack APIs directly or indirectly through `cURL <http://curl.haxx.se>`__ "" ""commands or open SDKs. You can automate access or build tools to manage "" ""resources and services by using the OpenStack APIs."" msgstr """" ""Selain cara berinteraksi dengan awan ini, Anda dapat mengakses OpenStack API "" ""secara langsung atau tidak langsung melalui perintah `cURL <http://curl.haxx."" ""se>` __ atau buka SDK. Anda dapat mengotomatisasi akses atau membangun alat "" ""untuk mengelola sumber daya dan layanan dengan menggunakan OpenStack API."" msgid ""Network tab"" msgstr ""Network tab"" msgid """" ""Now they are both updated. If the ``--force`` flag is used, it can reapply "" ""to already applied instances. Notice that the only thing that changes is the "" ""minimum and maximum updated date fields."" msgstr """" ""Sekarang keduanya diperbarui. Jika flag ``--force`` digunakan, maka dapat "" ""mengajukan permohonan kembali ke instance yang sudah diterapkan. Perhatikan "" ""bahwa satu-satunya perubahan adalah bidang tanggal minimum dan maksimum yang "" ""diperbarui."" msgid ""Now to show the usage with a redis cluster, create as follows:"" msgstr """" ""Sekarang untuk menunjukkan penggunaan dengan cluster redis, buatlah sebagai "" ""berikut:"" msgid """" ""Now we have 2 single instances, and 3 cluster instances on various versions "" ""of the module, none current."" msgstr """" ""Sekarang kita memiliki 2 instance tunggal, dan 3 instance cluster pada "" ""berbagai versi modul, tidak ada yang ada saat ini."" msgid ""Object Store tab"" msgstr ""Object Store tab"" msgid ""OpenStack dashboard — Admin tab"" msgstr ""OpenStack dashboard — Admin tab"" msgid ""OpenStack dashboard — Identity tab"" msgstr ""OpenStack dashboard — Identity tab"" msgid ""OpenStack dashboard — Project tab"" msgstr ""OpenStack dashboard — Project tab"" msgid ""OpenStack dashboard — Settings tab"" msgstr ""OpenStack dashboard — Settings tab"" msgid ""Operating system"" msgstr ""Sistem operasi"" msgid ""Orchestration tab"" msgstr ""Orchestration tab"" msgid ""Reference for cloud-init version"" msgstr ""Referensi untuk versi cloud-init"" msgid ""System tab"" msgstr ""System tab"" msgid """" ""The module created here is a demo module called ping. It is the basic type "" ""made for testing purposes. To create it, it is as simple as the following :"" ""command: ``echo`` command:"" msgstr """" ""Modul yang dibuat disini adalah modul demo yang disebut ping. Ini adalah "" ""jenis dasar yang dibuat untuk tujuan pengujian. Untuk membuatnya, "" ""sesederhana yang berikut perintah :command: ``echo``:"" msgid """" ""The original :command: ``count`` command will show the first instance, "" ""unless the ``--include_clustered`` option is used. You can see the MD5 from "" ""each applied module, and you know that the single instance one is not "" ""current."" msgstr """" ""Perintah :command: ``count`` asli akan menunjukkan instance pertama, kecuali "" ""opsi ``--include_clustered`` digunakan. Anda dapat melihat MD5 dari masing-"" ""masing modul yang diterapkan, dan Anda tahu bahwa instance tunggal tidak "" ""mutakhir."" msgid """" ""This example shows you how to create and apply modules to a MySQL 5.6 "" ""database and redis 3.2.6 database cluster."" msgstr """" ""Contoh ini menunjukkan cara membuat dan menerapkan modul ke database MySQL "" ""5.6 dan cluster database redis 3.2.6."" ""To bring every instance to the current version, use some of the optional "" ""arguments to control how many instances are updated at the same time. This "" ""is useful to avoid potential network issues, if the module payload is large. "" ""Since we are not using the ``--force`` flag, the minimum updated date will "" ""not change."" msgstr """" ""Untuk membawa setiap instance ke versi saat ini, gunakan beberapa argumen "" ""opsional untuk mengontrol jumlah instal yang diperbarui pada waktu yang "" ""bersamaan. Ini berguna untuk menghindari masalah jaringan potensial, jika "" ""muatan modulnya besar. Karena kita tidak menggunakan flag ``--force``, "" ""tanggal update minimum tidak akan berubah."" msgid """"""To continue with this document, we recommend that you have installed the "" ""Database service and populated your data store with images for the type and "" ""versions of databases that you want, and that you can create and access a "" ""database."" msgstr """" ""Untuk melanjutkan dokumen ini, kami merekomendasikan agar Anda telah "" ""menginstal layanan Database dan menyimpan data store Anda dengan image untuk "" ""jenis dan versi database yang Anda inginkan, dan Anda dapat membuat dan "" ""mengakses database."" msgid """"""To update a module you should have another file ready to update the module "" ""with:"" msgstr """" ""Untuk memperbarui modul Anda harus memiliki file lain yang siap untuk "" ""memperbarui modul dengan:"" msgid """"""To update an instance in a cluster you can use the :command:`trove module-"" ""apply` command:"" msgstr """" ""Untuk mengupdate sebuah instance di cluster Anda bisa menggunakan perintah :"" ""command:`trove module-apply`:"" msgid """"msgid ""Ubuntu"" msgstr ""Ubuntu"" msgid """" ""Update the module again. By doing this, it will cause the instances to "" ""report their module is not current."" msgstr """" ""Perbaharui modul lagi. Dengan melakukan ini, akan menyebabkan instance untuk "" ""melaporkan modul mereka tidak saat ini."" msgid ""Updating and creating a second module for a redis cluster"" msgstr ""Memperbarui dan membuat modul kedua untuk cluster redis"" ""When running QEMU without support for the hardware virtualization, set "" ""``cpu_mode=\""none\""`` alongside ``virt_type=qemu`` in ``/etc/nova/nova-"" ""compute.conf`` to solve the following error:"" msgstr """" ""Saat menjalankan QEMU tanpa dukungan untuk virtualisasi perangkat keras, "" ""atur ``cpu_mode = \""none\"" `` di samping ``virt_type = qemu`` di ``/etc/nova/"" ""nova-compute.conf`` untuk mengatasi kesalahan berikut:"" msgid """"msgid """" ""When the latest module was created, the ``--include_clustered`` was not "" ""used. Use the :command:`trove module-reapply` command:"" msgstr """" ""Saat modul terbaru dibuat, ``--include_clustered`` tidak digunakan. Gunakan "" ""perintah :command:`trove module-reapply`:"" ""You can count the instances each module is applied to by doing the following:"" msgstr """" ""Anda dapat menghitung instance setiap modul yang diterapkan dengan melakukan "" ""hal berikut:"" msgid """"""You can create a test module and mysql database with the module applied by "" ""doing the following:"" msgstr """" ""Anda bisa membuat test module dan database mysql dengan modul yang "" ""diaplikasikan dengan melakukan hal berikut:"" msgid """"""You can list the instances that have a particular module applied by doing "" ""the following:"" msgstr """" ""Anda dapat mencantumkan instance yang memiliki modul tertentu yang "" ""diterapkan dengan melakukan hal berikut:"" msgid """"msgid ""You can view the modules on your instance by doing the following:"" msgstr """" ""Anda dapat melihat modul di instance Anda dengan melakukan hal berikut:"" msgid ""http://packages.ubuntu.com/search?keywords=cloud-init"" msgstr ""http://packages.ubuntu.com/search?keywords=cloud-init"" msgid """" ""http://software.opensuse.org/download.html?project=Cloud"" ""%3ATools&package=cloud-init"" msgstr """" ""http://software.opensuse.org/download.html?project=Cloud"" ""%3ATools&package=cloud-init"" msgid ""https://www.rpmfind.net/linux/rpm2html/search.php?query=cloud-init"" msgstr ""https://www.rpmfind.net/linux/rpm2html/search.php?query=cloud-init"" msgid ""openSUSE (SLE)"" msgstr ""openSUSE (SLE)"" ","""POT-Creation-Date: 2017-06-02 05:46+0000\n""""PO-Revision-Date: 2017-04-17 11:41+0000\n""",432,36
openstack%2Fproject-config~master~I78b8b89e996f4213c63ffba689f5bdfc4a8772ed,openstack/project-config,master,I78b8b89e996f4213c63ffba689f5bdfc4a8772ed,Make the ceph-plugin-src job non-voting for glance-store and os-brick,MERGED,2017-06-17 01:22:52.000000000,2017-06-17 16:52:10.000000000,2017-06-17 16:52:10.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-17 01:22:52.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3579c3bceaad459d8095691c475e55a4c089d076', 'message': 'Make the ceph-plugin-src job non-voting for glance-store and os-brick\n\nThe gate-tempest-dsvm-full-devstack-plugin-ceph-ubuntu-xenial\njob which runs against nova/cinder/glance/devstack/tempest changes\nin the check queue has been non-voting for months now due to\ninstability and lack of resources to stabilize it.\n\nWhen we made that job non-voting we failed to mirror that in the\nceph-plugin-src jobs that gate against os-brick and glance_storage\nchanges.\n\nThis makes the src job that runs against glance-store and os-brick\nalso non-voting.\n\nChange-Id: I78b8b89e996f4213c63ffba689f5bdfc4a8772ed\nRelated-Bug: #1697953\n'}]",0,475095,3579c3bceaad459d8095691c475e55a4c089d076,7,3,1,6873,,,0,"Make the ceph-plugin-src job non-voting for glance-store and os-brick

The gate-tempest-dsvm-full-devstack-plugin-ceph-ubuntu-xenial
job which runs against nova/cinder/glance/devstack/tempest changes
in the check queue has been non-voting for months now due to
instability and lack of resources to stabilize it.

When we made that job non-voting we failed to mirror that in the
ceph-plugin-src jobs that gate against os-brick and glance_storage
changes.

This makes the src job that runs against glance-store and os-brick
also non-voting.

Change-Id: I78b8b89e996f4213c63ffba689f5bdfc4a8772ed
Related-Bug: #1697953
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/475095/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,3579c3bceaad459d8095691c475e55a4c089d076,bug/1697953, # NOTE(mriedem): Non-voting is temporary until the job stabilizes in # master (Pike). - name: ^gate-tempest-dsvm-full-ceph-plugin-src-.*-ubuntu-(trusty|xenial).*$ branch: ^(?!(stable/mitaka|driverfixes/)).*$ voting: false , gate: - gate-tempest-dsvm-full-ceph-plugin-src-glance_store-ubuntu-trusty - gate-tempest-dsvm-full-ceph-plugin-src-glance_store-ubuntu-xenial - gate-tempest-dsvm-full-ceph-plugin-src-os-brick-ubuntu-trusty - gate-tempest-dsvm-full-ceph-plugin-src-os-brick-ubuntu-xenial,6,5
openstack%2Fopenstack-manuals~master~Ia18276f43216d37b54b65a3c95c077f7490e9dd4,openstack/openstack-manuals,master,Ia18276f43216d37b54b65a3c95c077f7490e9dd4,[cli-ref] Update python-barbicanclient to 4.3.0,MERGED,2017-06-13 05:47:58.000000000,2017-06-17 16:50:16.000000000,2017-06-17 16:50:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 17130}, {'_account_id': 20156}]","[{'number': 1, 'created': '2017-06-13 05:47:58.000000000', 'files': ['doc/cli-reference/source/barbican.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/56d741569f80dfabc4625858eefdd14afb35e325', 'message': '[cli-ref] Update python-barbicanclient to 4.3.0\n\nChange-Id: Ia18276f43216d37b54b65a3c95c077f7490e9dd4\n'}]",0,473690,56d741569f80dfabc4625858eefdd14afb35e325,8,4,1,19779,,,0,"[cli-ref] Update python-barbicanclient to 4.3.0

Change-Id: Ia18276f43216d37b54b65a3c95c077f7490e9dd4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/90/473690/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/barbican.rst'],1,56d741569f80dfabc4625858eefdd14afb35e325,cli-reference,"This chapter documents :command:`barbican` version ``4.3.0``.List CAs. the data type can be specified with --payload_content_type. the data type can be specified with --payload_content_type. If the user wishes to only retrieve the value of the payload they must add ""-f value"" to format returning only the value of the payload text/plain).","This chapter documents :command:`barbican` version ``4.2.0``.List cas. the data type can be specified with --payload-content-type. the data type can be specified with --payload-content-type. If the user wishes to only retrieve the value of the payload they must add ""-f value"" to format returning only the value of the payload text/plain.",10,24
openstack%2Fopenstack-manuals~master~Ibee5885155976b6a9d9dc0bf8c842263ad98f505,openstack/openstack-manuals,master,Ibee5885155976b6a9d9dc0bf8c842263ad98f505,[cli-ref] Update python-ceilometerclient to 2.9.0,MERGED,2017-06-13 05:50:58.000000000,2017-06-17 16:50:09.000000000,2017-06-17 16:50:09.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 17130}, {'_account_id': 20156}]","[{'number': 1, 'created': '2017-06-13 05:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5fcc3e7e93a78972a34761e21982604fb4a3d0f2', 'message': '[cli-ref] Update python-ceilometerclient to 2.9.0\n\nChange-Id: Ibee5885155976b6a9d9dc0bf8c842263ad98f505\n'}, {'number': 2, 'created': '2017-06-13 05:51:48.000000000', 'files': ['doc/cli-reference/source/ceilometer.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/39d8346719b4d8ea20aaa1c32ed0a93ad657c8c9', 'message': '[cli-ref] Update python-ceilometerclient to 2.9.0\n\nChange-Id: Ibee5885155976b6a9d9dc0bf8c842263ad98f505\n'}]",0,473691,39d8346719b4d8ea20aaa1c32ed0a93ad657c8c9,9,4,2,19779,,,0,"[cli-ref] Update python-ceilometerclient to 2.9.0

Change-Id: Ibee5885155976b6a9d9dc0bf8c842263ad98f505
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/91/473691/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/ceilometer.rst'],1,5fcc3e7e93a78972a34761e21982604fb4a3d0f2,cli-reference,The ceilometer client is the command-line interface (CLI) for the Telemetry Data Collection service (ceilometer) API and its extensions. This chapter documents :command:`ceilometer` version ``2.9.0``.,The ceilometer client is the command-line interface (CLI) for the Telemetry Data Collection service (ceilometer) API and its extensions. This chapter documents :command:`ceilometer` version ``2.8.1``.,3,4
openstack%2Fopenstack-manuals~master~I82b82b6592a532da7350e409f419ab3b8480af39,openstack/openstack-manuals,master,I82b82b6592a532da7350e409f419ab3b8480af39,[cli-ref] Update python-freezerclient to 1.4.1,MERGED,2017-06-09 03:54:44.000000000,2017-06-17 16:50:04.000000000,2017-06-17 16:50:04.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6804}, {'_account_id': 17130}, {'_account_id': 20156}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 03:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a04ae2ea44f54956cf33e39dbd2e3f0b050ee859', 'message': '[cli-ref] Update python-freezerclient to 1.4.1\n\nChange-Id: I82b82b6592a532da7350e409f419ab3b8480af39\n'}, {'number': 2, 'created': '2017-06-09 05:12:15.000000000', 'files': ['doc/cli-reference/source/freezer.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f3602d9928af434a0a14a21ccb8bf712231b7da6', 'message': '[cli-ref] Update python-freezerclient to 1.4.1\n\nChange-Id: I82b82b6592a532da7350e409f419ab3b8480af39\n'}]",0,472517,f3602d9928af434a0a14a21ccb8bf712231b7da6,12,6,2,19779,,,0,"[cli-ref] Update python-freezerclient to 1.4.1

Change-Id: I82b82b6592a532da7350e409f419ab3b8480af39
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/472517/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/freezer.rst'],1,a04ae2ea44f54956cf33e39dbd2e3f0b050ee859,cli-reference,"the Backup, Restore, and Disaster Recovery service (freezer) API and its extensions. This chapter documents :command:`freezer` version ``1.4.1``.","the Backup, Restore, and Disaster Recovery service (freezer) API and its extensions. This chapter documents :command:`freezer` version ``1.4.0``.",2,3
openstack%2Fopenstack-manuals~stable%2Fnewton~Ifcaf89e4ee3e6cab2066d653ae065f2f3164c0bd,openstack/openstack-manuals,stable/newton,Ifcaf89e4ee3e6cab2066d653ae065f2f3164c0bd,Imported Translations from Zanata,MERGED,2017-06-17 11:13:25.000000000,2017-06-17 16:49:58.000000000,2017-06-17 16:49:58.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-06-17 11:13:25.000000000', 'files': ['doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1238ebe1f5f522fa27070860375b174bc0f8e689', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Ifcaf89e4ee3e6cab2066d653ae065f2f3164c0bd\n'}]",0,475124,1238ebe1f5f522fa27070860375b174bc0f8e689,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Ifcaf89e4ee3e6cab2066d653ae065f2f3164c0bd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/475124/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po']",2,1238ebe1f5f522fa27070860375b174bc0f8e689,zanata/translations,"""POT-Creation-Date: 2017-06-10 02:53+0000\n""""PO-Revision-Date: 2017-06-16 08:56+0000\n""""Installation and configuration is documented in the `Bare Metal installation "" ""guide <http://docs.openstack.org/project-install-guide/baremetal/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation Bare Metal <http://docs.openstack.org/project-install-guide/"" ""baremetal/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Container "" ""Infrastructure Management installation guide <http://docs.openstack.org/"" ""project-install-guide/container-infrastructure-management/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du Gestionnaire d'Infrastructure de Containeur <http://docs."" ""openstack.org/project-install-guide/container-infrastructure-management/"" ""newton/>`_."" msgid """" ""Installation and configuration is documented in the `Database installation "" ""guide <http://docs.openstack.org/project-install-guide/database/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation de la base de données <http://docs.openstack.org/project-"" ""install-guide/database/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Key Manager "" ""installation guide <http://docs.openstack.org/project-install-guide/key-"" ""manager/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du Gestionnaire de Clés <http://docs.openstack.org/project-"" ""install-guide/key-manager/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Messaging installation "" ""guide <http://docs.openstack.org/project-install-guide/messaging/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du service de Messages <http://docs.openstack.org/project-"" ""install-guide/messaging/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Object Storage "" ""installation guide <http://docs.openstack.org/project-install-guide/object-"" ""storage/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du Stockage Objet <http://docs.openstack.org/project-install-"" ""guide/object-storage/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Orchestration "" ""installation guide <http://docs.openstack.org/project-install-guide/"" ""orchestration/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du service d'Orchestration <http://docs.openstack.org/project-"" ""install-guide/orchestration/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Shared File Systems "" ""installation guide <http://docs.openstack.org/project-install-guide/shared-"" ""file-systems/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du service de Systèmes de Fichiers Partagés <http://docs."" ""openstack.org/project-install-guide/shared-file-systems/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Telemetry Alarming "" ""installation guide <http://docs.openstack.org/project-install-guide/"" ""telemetry-alarming/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du service d'Alertes de Télémétrie <http://docs.openstack.org/"" ""project-install-guide/telemetry-alarming/newton/>`_."" msgid """" ""Installation and configuration is documented in the `Telemetry Data "" ""Collection installation guide <http://docs.openstack.org/project-install-"" ""guide/telemetry/newton/>`_."" msgstr """" ""L'installation et la configuration sont documentées dans le `Guide "" ""d'installation du service de Collecte d'informations de Télémétrie <http://"" ""docs.openstack.org/project-install-guide/telemetry/newton/>`_."" msgid """"""The ``--external`` option defines the virtual network to be external. If you "" ""wish to create an internal network, you can use ``--internal`` instead. "" ""Default value is ``internal``."" msgstr """" ""L'option ``--external`` définit le réseau virtuel comme externe. Si vous "" ""souhaitez créer un réseau interne, vous pouvez utiliser ``--internal`` à la "" ""place. La valeur par défaut est ``internal``."" msgid """"""The provider network must include the ``router:external`` option to enable "" ""self-service routers to use it for connectivity to external networks such as "" ""the Internet. The ``admin`` or other privileged user must include this "" ""option during network creation or add it later. In this case, the ``router:"" ""external`` option was set by using the ``--external`` parameter when "" ""creating the ``provider`` network."" msgstr """" ""Le réseau fournisseur doit inclure l'option ``router: external`` pour "" ""permettre aux routeurs libre-service de l'utiliser pour se connecter aux "" ""réseaux externes comme Internet. L'utilisateur ``admin`` ou un autre "" ""utilisateur à privilèges doit inclure cette option lors de la création du "" ""réseau ou l'ajouter plus tard. Dans ce cas, l'option ``router:external`` a "" ""été définie en utilisant le paramètre ``--external`` lors de la création du "" ""réseau ``fournisseur``."" msgid """"","""POT-Creation-Date: 2017-04-13 04:37+0000\n""""PO-Revision-Date: 2017-02-15 09:07+0000\n""",116,12
openstack%2Fopenstack-manuals~stable%2Focata~If281646bea35b7802ade7c63dac44457022701c2,openstack/openstack-manuals,stable/ocata,If281646bea35b7802ade7c63dac44457022701c2,Imported Translations from Zanata,MERGED,2017-06-09 11:20:07.000000000,2017-06-17 16:48:14.000000000,2017-06-17 16:48:14.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-06-09 11:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c97588bf269f93d78268249d62f78df19bbc203d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}, {'number': 2, 'created': '2017-06-10 11:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/027f83824e25f72e343856e0e192ffd231e4c79c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}, {'number': 3, 'created': '2017-06-12 11:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/993f20e0a0dffc84334111fa3029ae6461f86971', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}, {'number': 4, 'created': '2017-06-13 11:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/00e21835769184c87633667703c10a34404fae37', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}, {'number': 5, 'created': '2017-06-14 11:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d9d04953da6463eb30f3478eec4d44d1c486cc51', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}, {'number': 6, 'created': '2017-06-15 12:34:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/98ca78c8e9ab0a64d49b8f04e1ac5463f118422a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}, {'number': 7, 'created': '2017-06-17 11:17:13.000000000', 'files': ['doc/install-guide/source/locale/id/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/networking-guide/source/locale/id/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ru/LC_MESSAGES/install-guide.po', 'doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/cs/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c5a8d1378faeea10804028f593d066d0bccc0c45', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: If281646bea35b7802ade7c63dac44457022701c2\n'}]",0,472643,c5a8d1378faeea10804028f593d066d0bccc0c45,20,3,7,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: If281646bea35b7802ade7c63dac44457022701c2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/472643/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/ko_KR/LC_MESSAGES/install-guide.po'],1,c97588bf269f93d78268249d62f78df19bbc203d,zanata/translations,"# Wonil Choi <wonil0522@gmail.com>, 2017. #zanata""POT-Creation-Date: 2017-06-07 13:33+0000\n""""PO-Revision-Date: 2017-06-09 07:45+0000\n"" ""Last-Translator: Wonil Choi <wonil0522@gmail.com>\n""msgid """" ""As of Ubuntu 16.04, MariaDB was changed to use the \""unix_socket "" ""Authentication Plugin\"". Local authentication is now performed using the "" ""user credentials (UID), and password authentication is no longer used by "" ""default. This means that the root user no longer uses a password for local "" ""access to the server."" msgstr """" ""현재, 우분투 16.04 의 MariaDB 는 \""unix_socket 인증 플러그인\""을 사용하도록 "" ""변경되었습니다. 지금 로컬 인증은 사용자 증명서(UID)를 사용하여 동작하며, 기"" ""본적으로 패스워드 인증은 더 이상 사용되지 않습니다. 즉 루트 사용자는 더 이상 "" ""서버에 로컬 접근을 위해 패스워드를 사용할 수 없습니다."" msgid ""Password of the Placement service user ``placement``"" msgstr ""Placement 서비스 사용자 ``placement`` 암호"" ","""POT-Creation-Date: 2017-05-21 17:57+0000\n""""PO-Revision-Date: 2017-05-21 12:17+0000\n"" ""Last-Translator: Ian Y. Choi <ianyrchoi@gmail.com>\n""",19,3
openstack%2Fproject-config~master~Iae8507666484e6f078ab4173bec457cc7ebecd23,openstack/project-config,master,Iae8507666484e6f078ab4173bec457cc7ebecd23,Add the #networking-sfc channel,MERGED,2017-06-08 14:51:55.000000000,2017-06-17 16:48:00.000000000,2017-06-17 16:48:00.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5367}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 7776}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14605}, {'_account_id': 14611}, {'_account_id': 21798}]","[{'number': 1, 'created': '2017-06-08 14:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f88396bfd4b9545526723a8e953a20d927e65890', 'message': 'Add gerritbot for networking-sfc\n\nChannel #networking-sfc had already been created but not registered\nin channels.yaml. This adds the channel to the list with gerritbot\nlistening to the openstack/networking-sfc gerrit stream.\n\nChange-Id: Iae8507666484e6f078ab4173bec457cc7ebecd23\n'}, {'number': 2, 'created': '2017-06-08 15:16:53.000000000', 'files': ['gerritbot/channels.yaml', 'accessbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/38ff9d69cc5d08e8ff8da14ed62fb1835f9eddb0', 'message': 'Add the #networking-sfc channel\n\nChannel #networking-sfc had already been created and registered in\nFreenode but not added to project-config. This adds the channel to\nthe accessbot and gerritbot lists, with gerritbot listening to the\nopenstack/networking-sfc gerrit stream.\n\nChange-Id: Iae8507666484e6f078ab4173bec457cc7ebecd23\n'}]",0,472282,38ff9d69cc5d08e8ff8da14ed62fb1835f9eddb0,18,15,2,9396,,,0,"Add the #networking-sfc channel

Channel #networking-sfc had already been created and registered in
Freenode but not added to project-config. This adds the channel to
the accessbot and gerritbot lists, with gerritbot listening to the
openstack/networking-sfc gerrit stream.

Change-Id: Iae8507666484e6f078ab4173bec457cc7ebecd23
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/472282/2 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,f88396bfd4b9545526723a8e953a20d927e65890,gerritbot-networking-sfc,networking-sfc: events: - patchset-created - change-merged - x-vrif-minus-2 projects: - openstack/networking-sfc branches: - master ,,10,0
openstack%2Fshade~master~I4377cfb24c468f2333ac470a2a58fa97cf35d4bd,openstack/shade,master,I4377cfb24c468f2333ac470a2a58fa97cf35d4bd,Remove future document,MERGED,2017-04-20 15:54:11.000000000,2017-06-17 16:17:09.000000000,2017-06-17 16:17:09.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 170}, {'_account_id': 17860}]","[{'number': 1, 'created': '2017-04-20 15:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/93d7a74136927c7c140be5353e2b1be3d1191c3f', 'message': 'Remove future document\n\nThis is a write up of an idea from several years ago which is both long\nin the tooth and honestly never going to happen. Go ahead and remove it.\n\nChange-Id: I4377cfb24c468f2333ac470a2a58fa97cf35d4bd\n'}, {'number': 2, 'created': '2017-04-20 16:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/bb0f0e4d22e343a0b39ec54817f768c3d7a897ad', 'message': 'Remove future document\n\nThis is a write up of an idea from several years ago which is both long\nin the tooth and honestly never going to happen. Go ahead and remove it.\n\nChange-Id: I4377cfb24c468f2333ac470a2a58fa97cf35d4bd\n'}, {'number': 3, 'created': '2017-06-17 14:47:33.000000000', 'files': ['doc/source/index.rst', 'doc/source/future.rst'], 'web_link': 'https://opendev.org/openstack/shade/commit/c23611a093290b0f8882a4995cb0ab04de13888b', 'message': 'Remove future document\n\nThis is a write up of an idea from several years ago which is both long\nin the tooth and honestly never going to happen. Go ahead and remove it.\n\nChange-Id: I4377cfb24c468f2333ac470a2a58fa97cf35d4bd\n'}]",0,458567,c23611a093290b0f8882a4995cb0ab04de13888b,11,4,3,2,,,0,"Remove future document

This is a write up of an idea from several years ago which is both long
in the tooth and honestly never going to happen. Go ahead and remove it.

Change-Id: I4377cfb24c468f2333ac470a2a58fa97cf35d4bd
",git fetch https://review.opendev.org/openstack/shade refs/changes/67/458567/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/future.rst']",2,93d7a74136927c7c140be5353e2b1be3d1191c3f,docs,,"************************ Future Design Discussion ************************ This document discusses a new approach to the Shade library and how we might wish for it to operate in a future, not-yet-developed version. It presents a more object oriented approach, and design decisions that we have learned and decided on while working on the current version. Object Design ============= Shade is a library for managing resources, not for operating APIs. As such, it is the resource in question that is the primary object and not the service that may or may not provide that resource, much as we may feel warm and fuzzy to one of the services. Every resource at minimum has CRUD functions. Additionally, every resource action should have a ""do this task blocking"" or ""request that the cloud start this action and give me a way to check its status"" The creation and deletion of Resources will be handled by a ResourceManager that is attached to the Cloud :: class Cloud: ResourceManager<Server> server servers = server ResourceManager<FloatingIp> floating_ip floating_ips = floating_ip ResourceManager<Image> image images = image ResourceManager<Role> role roles = role ResourceManager<Volume> volume volumes = volume getting, listing and searching ------------------------------ In addition to creating a resource, there are different ways of getting your hands on a resource. A `get`, a `list` and a `search`. `list` has the simplest semantics - it takes no parameters and simply returns a list of all of the resources that exist. `search` takes a set of parameters to match against and returns a list of resources that match the parameters given. If no resources match, it returns an empty list. `get` takes the same set of parameters that `search` takes, but will only ever return a single matching resource or None. If multiple resources are matched, an exception will be raised. :: class ResourceManager<Resource>: def get -> Resource def list -> List<Resource> def search -> List<Resource> def create -> Resource Cloud and ResourceManager interface =================================== All ResourceManagers should accept a cache object passed in to their constructor and should additionally pass that cache object to all Resource constructors. The top-level cloud should create the cache object, then pass it to each of the ResourceManagers when it creates them. Client connection objects should exist and be managed at the Cloud level. A backreference to the OpenStack cloud should be passed to every resource manager so that ResourceManagers can get hold of the ones they need. For instance, an Image ResourceManager would potentially need access to both the glance_client and the swift_client. :: class ResourceManager def __init__(self, cache, cloud) class ServerManager(ResourceManager) class OpenStackCloud def __init__(self): self.cache = dogpile.cache() self.server = ServerManager(self.cache, self) self.servers = self.server Any resources that have an association action - such as servers and floating_ips, should carry reciprocal methods on each resource with absolutely no difference in behavior. :: class Server(Resource): def connect_floating_ip: class FloatingIp(Resource): def connect_server: Resource objects should have all of the accessor methods you'd expect, as well as any other interesting rollup methods or actions. For instance, since a keystone User can be enabled or disabled, one should expect that there would be an enable() and a disable() method, and that those methods will immediately operate the necessary REST apis. However, if you need to make 80 changes to a Resource, 80 REST calls may or may not be silly, so there should also be a generic update() method which can be used to request the minimal amount of REST calls needed to update the attributes to the requested values. Resource objects should all have a to_dict method which will return a plain flat dictionary of their attributes. :: class Resource: def update(**new_values) -> Resource def delete -> None, throws on error Readiness --------- `create`, `get`, and `attach` can return resources that are not yet ready. Each method should take a `wait` and a `timeout` parameter, that will cause the request for the resource to block until it is ready. However, the user may want to poll themselves. Each resource should have an `is_ready` method which will return True when the resource is ready. The `wait` method then can actually be implemented in the base Resource class as an iterate timeout loop around calls to `is_ready`. Every Resource should also have an `is_failed` and an `is_deleted` method. Optional Behavior ----------------- Not all clouds expose all features. For instance, some clouds do not have floating ips. Additionally, some clouds may have the feature but the user account does not, which is effectively the same thing. This should be handled in several ways: If the user explicitly requests a resource that they do not have access to, an error should be raised. For instance, if a user tries to create a floating ip on a cloud that does not expose that feature to them, shade should throw a ""Your cloud does not let you do that"" error. If the resource concept can be can be serviced by multiple possible services, shade should transparently try all of them. The discovery method should use the dogpile.cache mechanism so that it can be avoided on subsequent tries. For instance, if the user says ""please upload this image"", shade should figure out which sequence of actions need to be performed and should get the job done. If the resource isn't present on some clouds, but the overall concept the resource represents is, a different resource should present the concept. For instance, while some clouds do not have floating ips, if what the user wants is ""a server with an IP"" - then the fact that one needs to request a floating ip on some clouds is a detail, and the right thing for that to be is a quality of a server and managed by the server resource. A floating ip resource should really only be directly manipulated by the user if they were doing something very floating-ip specific, such as moving a floating ip from one server to another. In short, it should be considered a MASSIVE bug in shade if the shade user ever has to have in their own code ""if cloud.has_capability(""X"") do_thing else do_other_thing"" - since that construct conveys some resource that shade should really be able to model. Functional Interface ==================== shade should also provide a functional mapping to the object interface that does not expose the object interface at all. For instance, for a resource type `server`, one could expect the following. :: class OpenStackCloud: def create_server return self.server.create().to_dict() def get_server return self.server.get().to_dict() def update_server return self.server.get().update().to_dict() ",0,177
openstack%2Fshade~master~Iadd48cd53488240e33db83797a88af689b1497dc,openstack/shade,master,Iadd48cd53488240e33db83797a88af689b1497dc,Add text about microversions,MERGED,2017-04-20 15:54:11.000000000,2017-06-17 16:04:07.000000000,2017-06-17 16:04:07.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 13252}, {'_account_id': 17860}]","[{'number': 1, 'created': '2017-04-20 15:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/de498c063f7cfd505d9e6efd22f417a7efc16c34', 'message': ""Add text about microversions\n\nWe aren't doing anything with microversions yet, but since we just wrote\ndown algorithms for version discovery, let's go ahead and talk about\nhow microversions should work. Also, mention that it's important to\nfetch information about them as part of discovery.\n\nChange-Id: Iadd48cd53488240e33db83797a88af689b1497dc\n""}, {'number': 2, 'created': '2017-04-20 16:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/f96dc414ad95357672b9f2ca47129f40265b7948', 'message': ""Add text about microversions\n\nWe aren't doing anything with microversions yet, but since we just wrote\ndown algorithms for version discovery, let's go ahead and talk about\nhow microversions should work. Also, mention that it's important to\nfetch information about them as part of discovery.\n\nChange-Id: Iadd48cd53488240e33db83797a88af689b1497dc\n""}, {'number': 3, 'created': '2017-06-17 14:47:33.000000000', 'files': ['doc/source/index.rst', 'doc/source/microversions.rst'], 'web_link': 'https://opendev.org/openstack/shade/commit/145a0ab7a3662615a9b5df5cad28b92dfb30884a', 'message': ""Add text about microversions\n\nWe aren't doing anything with microversions yet, but since we just wrote\ndown algorithms for version discovery, let's go ahead and talk about\nhow microversions should work. Also, mention that it's important to\nfetch information about them as part of discovery.\n\nChange-Id: Iadd48cd53488240e33db83797a88af689b1497dc\n""}]",0,458566,145a0ab7a3662615a9b5df5cad28b92dfb30884a,12,4,3,2,,,0,"Add text about microversions

We aren't doing anything with microversions yet, but since we just wrote
down algorithms for version discovery, let's go ahead and talk about
how microversions should work. Also, mention that it's important to
fetch information about them as part of discovery.

Change-Id: Iadd48cd53488240e33db83797a88af689b1497dc
",git fetch https://review.opendev.org/openstack/shade refs/changes/66/458566/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/microversions.rst', 'doc/source/discovery.rst']",3,de498c063f7cfd505d9e6efd22f417a7efc16c34,docs,"Ultimately, for any service, shade needs to know three things: * The endpoint of the service * The API version of the service * The min and max microversion range for that service, if it supports microversions. :ref:`expanding-endpoints`) Also return the API version and any microversion information that may exist.", :ref:`expanding-endpoints`),85,1
openstack%2Ftrove~master~Ie2edd43a18ec547d480940727021e6f7e83e42a4,openstack/trove,master,Ie2edd43a18ec547d480940727021e6f7e83e42a4,Removed instance reset_password from trove,MERGED,2016-12-21 03:22:36.000000000,2017-06-17 15:10:29.000000000,2017-06-17 15:10:29.000000000,"[{'_account_id': 3}, {'_account_id': 9664}, {'_account_id': 10295}, {'_account_id': 14576}, {'_account_id': 22514}, {'_account_id': 22694}]","[{'number': 1, 'created': '2016-12-21 03:22:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/23686bef9f8f177111e739ade2aaea057e89a748', 'message': 'Removed instance reset_password from trove\n\nThe reset_password operation no longer exists and needs to be removed\nfrom trove.\n\nChange-Id: Ie2edd43a18ec547d480940727021e6f7e83e42a4\nCloses-Bug: #1645866\n'}, {'number': 2, 'created': '2016-12-21 07:45:04.000000000', 'files': ['trove/instance/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/ea57f451d7dd8a6b2b3d970c5b696e5901547dd0', 'message': 'Removed instance reset_password from trove\n\nThe reset_password operation no longer exists and needs to be removed\nfrom trove.\n\nChange-Id: Ie2edd43a18ec547d480940727021e6f7e83e42a4\nCloses-Bug: #1645866\n'}]",1,413388,ea57f451d7dd8a6b2b3d970c5b696e5901547dd0,32,6,2,23192,,,0,"Removed instance reset_password from trove

The reset_password operation no longer exists and needs to be removed
from trove.

Change-Id: Ie2edd43a18ec547d480940727021e6f7e83e42a4
Closes-Bug: #1645866
",git fetch https://review.opendev.org/openstack/trove refs/changes/88/413388/2 && git format-patch -1 --stdout FETCH_HEAD,['trove/instance/service.py'],1,23686bef9f8f177111e739ade2aaea057e89a748,bug/1645866," could include 'resize', 'restart'"," could include 'resize', 'restart', 'reset_password' 'reset_password': self._action_reset_password, def _action_reset_password(self, context, instance, body): raise webob.exc.HTTPNotImplemented() ",1,5
openstack%2Fshade~master~Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24,openstack/shade,master,Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24,Convert list_servers to REST,MERGED,2017-06-16 03:41:45.000000000,2017-06-17 14:45:05.000000000,2017-06-17 14:45:05.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-16 03:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/50ae0ba4beb6304e58fae1201d67cbdc91b98d4d', 'message': 'Convert list_servers to REST\n\nChange-Id: Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24\n'}, {'number': 2, 'created': '2017-06-16 22:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/08b1e6a61911ce9aa7d0f10e51ab729ebb9fdd00', 'message': 'Convert list_servers to REST\n\nChange-Id: Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24\n'}, {'number': 3, 'created': '2017-06-16 23:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/8232f0606745ec173ff21b7054849311fe3d699e', 'message': 'Convert list_servers to REST\n\nChange-Id: Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24\n'}, {'number': 4, 'created': '2017-06-17 00:09:10.000000000', 'files': ['shade/_tasks.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/70365c9f65cc04b711f96a418aac3ae23dc2fbec', 'message': 'Convert list_servers to REST\n\nChange-Id: Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24\n'}]",0,474842,70365c9f65cc04b711f96a418aac3ae23dc2fbec,13,2,4,2,,,0,"Convert list_servers to REST

Change-Id: Id3e60a9df87c3ca64fcabcb5c6d30b2b0bcb0b24
",git fetch https://review.opendev.org/openstack/shade refs/changes/42/474842/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/_tasks.py', 'shade/openstackcloud.py']",2,50ae0ba4beb6304e58fae1201d67cbdc91b98d4d,restification," error_msg = ""Error fetching server list on {cloud}:{region}:"".format( cloud=self.name, region=self.region_name) params = {} if all_projects: params['all_tenants'] = True servers = self._normalize_servers( self._compute_client.get( '/servers/detail', params=params, error_message=error_msg)) return [ self._expand_server(server, detailed, bare) for server in servers ]"," with _utils.shade_exceptions( ""Error fetching server list on {cloud}:{region}:"".format( cloud=self.name, region=self.region_name)): kwargs = {} if all_projects: kwargs['search_opts'] = {'all_tenants': True} servers = self._normalize_servers( self.manager.submit_task(_tasks.ServerList(**kwargs))) return [ self._expand_server(server, detailed, bare) for server in servers ]",14,18
openstack%2Fmonasca-api~master~I668d1f7cd257abbdf5d5d6b78552a152bd67aa60,openstack/monasca-api,master,I668d1f7cd257abbdf5d5d6b78552a152bd67aa60,Fixed HTTP error code for alarm-definitions,MERGED,2017-06-16 15:28:24.000000000,2017-06-17 14:38:01.000000000,2017-06-17 14:38:01.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 15027}, {'_account_id': 18179}]","[{'number': 1, 'created': '2017-06-16 15:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/4bb7e7cd223abc9257b93dda11afe5ef86ec6411', 'message': 'Fixed HTTP error code for alarm-definitions\n\n\tProblem: Received HTTP 422 Unprocessible Entity when alarm definition\n\tid is not specified in query instead of HTTP 400 Bad Request.\n\n\tSolution: Modified on_delete(), on_patch(), and on_put() to return\n\tHTTP 400 Bad Request.\n\nChange-Id: I668d1f7cd257abbdf5d5d6b78552a152bd67aa60\n'}, {'number': 2, 'created': '2017-06-16 19:38:19.000000000', 'files': ['monasca_api/v2/common/exceptions.py', 'monasca_api/v2/reference/alarm_definitions.py', 'monasca_api/tests/test_alarms.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/6e81a619009fd1091a04b7e947c00f8552415bf2', 'message': 'Fixed HTTP error code for alarm-definitions\n\n\tProblem: Received HTTP 422 Unprocessible Entity when alarm definition\n\tid is not specified in query instead of HTTP 400 Bad Request.\n\n\tSolution: Modified on_delete(), on_patch(), and on_put() to return\n\tHTTP 400 Bad Request.\n\nChange-Id: I668d1f7cd257abbdf5d5d6b78552a152bd67aa60\n'}]",1,475008,6e81a619009fd1091a04b7e947c00f8552415bf2,15,5,2,26153,,,0,"Fixed HTTP error code for alarm-definitions

	Problem: Received HTTP 422 Unprocessible Entity when alarm definition
	id is not specified in query instead of HTTP 400 Bad Request.

	Solution: Modified on_delete(), on_patch(), and on_put() to return
	HTTP 400 Bad Request.

Change-Id: I668d1f7cd257abbdf5d5d6b78552a152bd67aa60
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/08/475008/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_api/v2/common/exceptions.py', 'monasca_api/v2/reference/alarm_definitions.py', 'monasca_api/tests/test_alarms.py']",3,4bb7e7cd223abc9257b93dda11afe5ef86ec6411,bug/fixhttp," self.assertEqual(self.srmock.status, falcon.HTTP_400) self.assertEqual(self.srmock.status, falcon.HTTP_400) self.assertEqual(self.srmock.status, falcon.HTTP_400)"," self.assertEqual(self.srmock.status, falcon.HTTP_422) self.assertEqual(self.srmock.status, falcon.HTTP_422) self.assertEqual(self.srmock.status, falcon.HTTP_422)",12,9
openstack%2Fshade~master~I9dfbabd2b5318a59b91edf4d8a62ccc0ccb9baa0,openstack/shade,master,I9dfbabd2b5318a59b91edf4d8a62ccc0ccb9baa0,Convert list servers tests to requests_mock,MERGED,2017-06-16 03:41:45.000000000,2017-06-17 14:37:29.000000000,2017-06-17 14:37:29.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-16 03:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/2b7fb47e26a79ae3c2fc989409d2353f37c0ef3a', 'message': 'Convert list servers tests to requests_mock\n\nAlso, found a few others that had been missed before.\n\nChange-Id: I9dfbabd2b5318a59b91edf4d8a62ccc0ccb9baa0\n'}, {'number': 2, 'created': '2017-06-16 22:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/469c7a38779f59ec3f19ee309ef69791b3418a1c', 'message': 'Convert list servers tests to requests_mock\n\nAlso, found a few others that had been missed before.\n\nChange-Id: I9dfbabd2b5318a59b91edf4d8a62ccc0ccb9baa0\n'}, {'number': 3, 'created': '2017-06-17 00:09:10.000000000', 'files': ['shade/tests/unit/test_caching.py', 'shade/tests/unit/test_server_delete_metadata.py', 'shade/tests/unit/test_shade.py', 'shade/tests/unit/test_image_snapshot.py', 'shade/tests/unit/test_server_set_metadata.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/83c8bf5a3439c8bf732604ca0de9098af312d6b0', 'message': 'Convert list servers tests to requests_mock\n\nAlso, found a few others that had been missed before.\n\nChange-Id: I9dfbabd2b5318a59b91edf4d8a62ccc0ccb9baa0\n'}]",0,474841,83c8bf5a3439c8bf732604ca0de9098af312d6b0,15,2,3,2,,,0,"Convert list servers tests to requests_mock

Also, found a few others that had been missed before.

Change-Id: I9dfbabd2b5318a59b91edf4d8a62ccc0ccb9baa0
",git fetch https://review.opendev.org/openstack/shade refs/changes/41/474841/3 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_caching.py', 'shade/tests/unit/test_server_delete_metadata.py', 'shade/tests/unit/test_shade.py', 'shade/tests/unit/test_image_snapshot.py', 'shade/tests/unit/test_server_set_metadata.py']",5,2b7fb47e26a79ae3c2fc989409d2353f37c0ef3a,restification,"import uuid from shade.exc import OpenStackCloudBadRequest from shade.tests import fakesclass TestServerSetMetadata(base.RequestsMockTestCase): def setUp(self): super(TestServerSetMetadata, self).setUp() self.server_id = str(uuid.uuid4()) self.server_name = self.getUniqueString('name') self.fake_server = fakes.make_fake_server( self.server_id, self.server_name) def test_server_set_metadata_with_exception(self): Test that a generic exception in the novaclient delete_meta raises an exception in delete_server_metadata. self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['servers', 'detail']), json={'servers': [self.fake_server]}), dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['servers', self.fake_server['id'], 'metadata']), validate=dict(json={'metadata': {'meta': 'data'}}), json={}, status_code=400), ]) OpenStackCloudBadRequest, self.cloud.set_server_metadata, self.server_name, {'meta': 'data'}) self.assert_calls() def test_server_set_metadata(self): self.register_uris([ dict(method='GET', uri=self.get_mock_url( 'compute', 'public', append=['servers', 'detail']), json={'servers': [self.fake_server]}), dict(method='POST', uri=self.get_mock_url( 'compute', 'public', append=['servers', self.fake_server['id'], 'metadata']), validate=dict(json={'metadata': {'meta': 'data'}}), status_code=200), ]) self.cloud.set_server_metadata(self.server_id, {'meta': 'data'}) self.assert_calls()","import mock from shade import OpenStackCloud from shade.exc import OpenStackCloudExceptionclass TestServerSetMetadata(base.TestCase): @mock.patch.object(OpenStackCloud, 'nova_client') def test_server_set_metadata_with_set_meta_exception(self, mock_nova): Test that a generic exception in the novaclient set_meta raises an exception in set_server_metadata. mock_nova.servers.set_meta.side_effect = Exception(""exception"") OpenStackCloudException, self.cloud.set_server_metadata, {'id': 'server-id'}, {'meta': 'data'}) @mock.patch.object(OpenStackCloud, 'nova_client') def test_server_set_metadata_with_exception_reraise(self, mock_nova): """""" Test that an OpenStackCloudException exception gets re-raised in set_server_metadata. """""" mock_nova.servers.set_meta.side_effect = OpenStackCloudException("""") self.assertRaises( OpenStackCloudException, self.cloud.set_server_metadata, 'server-id', {'meta': 'data'})",164,127
openstack%2Fshade~master~I25c59933cd61eff31d02b3c763f6ebd5551d3231,openstack/shade,master,I25c59933cd61eff31d02b3c763f6ebd5551d3231,Remove some unused mocks,MERGED,2017-06-16 03:41:45.000000000,2017-06-17 14:35:45.000000000,2017-06-17 14:35:45.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-16 03:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/5615c1a3393e32a1c6d52bec4861dc30d68d707a', 'message': 'Remove some unused mocks\n\nChange-Id: I25c59933cd61eff31d02b3c763f6ebd5551d3231\n'}, {'number': 2, 'created': '2017-06-16 22:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/647614d2400f7f1dd01c1cc7f6be2ee28663026f', 'message': 'Remove some unused mocks\n\nChange-Id: I25c59933cd61eff31d02b3c763f6ebd5551d3231\n'}, {'number': 3, 'created': '2017-06-17 00:09:10.000000000', 'files': ['shade/tests/unit/test_floating_ip_common.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/c5245648edcd2041d1df1f94f68c5d612fda6be9', 'message': 'Remove some unused mocks\n\nChange-Id: I25c59933cd61eff31d02b3c763f6ebd5551d3231\n'}]",0,474840,c5245648edcd2041d1df1f94f68c5d612fda6be9,16,2,3,2,,,0,"Remove some unused mocks

Change-Id: I25c59933cd61eff31d02b3c763f6ebd5551d3231
",git fetch https://review.opendev.org/openstack/shade refs/changes/40/474840/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/unit/test_floating_ip_common.py'],1,5615c1a3393e32a1c6d52bec4861dc30d68d707a,restification," def test_add_ips_to_server_pool(self, mock_add_ip_from_pool): def test_add_ips_to_server_ip_list(self, mock_add_ip_list): self, mock_add_auto_ip, mock_needs_floating_ip):"," @patch.object(OpenStackCloud, 'nova_client') def test_add_ips_to_server_pool( self, mock_add_ip_from_pool, mock_nova_client): mock_nova_client.servers.get.return_value = server @patch.object(OpenStackCloud, 'nova_client') def test_add_ips_to_server_ip_list( self, mock_add_ip_list, mock_nova_client): mock_nova_client.servers.get.return_value = server @patch.object(OpenStackCloud, 'nova_client') self, mock_add_auto_ip, mock_nova_client, mock_needs_floating_ip): mock_nova_client.servers.get.return_value = server",3,12
openstack%2Fshade~master~I540c4d860a60810d6ae6838ec558cc48cff67cf8,openstack/shade,master,I540c4d860a60810d6ae6838ec558cc48cff67cf8,Break early from volume cleanup loop,MERGED,2017-06-14 02:35:21.000000000,2017-06-17 14:29:50.000000000,2017-06-17 14:29:50.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-14 02:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/c0a1704d939c057c82b1fd50babccaaf53a9b8b7', 'message': 'Break early from volume cleanup loop\n\nChange-Id: I540c4d860a60810d6ae6838ec558cc48cff67cf8\n'}, {'number': 2, 'created': '2017-06-16 02:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0d6d3a7672344f23f5b6446c764d13bba6bfb6c2', 'message': 'Break early from volume cleanup loop\n\nChange-Id: I540c4d860a60810d6ae6838ec558cc48cff67cf8\n'}, {'number': 3, 'created': '2017-06-16 22:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/7a678320697984f4b4424ff804e7350bfa815dde', 'message': 'Break early from volume cleanup loop\n\nChange-Id: I540c4d860a60810d6ae6838ec558cc48cff67cf8\n'}, {'number': 4, 'created': '2017-06-17 00:09:10.000000000', 'files': ['shade/tests/functional/test_volume.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/35980c1da8977db1cffb66975145ee5532a83fe8', 'message': 'Break early from volume cleanup loop\n\nChange-Id: I540c4d860a60810d6ae6838ec558cc48cff67cf8\n'}]",0,474027,35980c1da8977db1cffb66975145ee5532a83fe8,18,2,4,2,,,0,"Break early from volume cleanup loop

Change-Id: I540c4d860a60810d6ae6838ec558cc48cff67cf8
",git fetch https://review.opendev.org/openstack/shade refs/changes/27/474027/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/functional/test_volume.py'],1,c0a1704d939c057c82b1fd50babccaaf53a9b8b7,restification, break if found: break,,3,0
openstack%2Fmonasca-transform~master~I37b2d3f47abfabeddccf602fb0f120dc71f4a94e,openstack/monasca-transform,master,I37b2d3f47abfabeddccf602fb0f120dc71f4a94e,Updated from global requirements,MERGED,2017-06-02 02:28:40.000000000,2017-06-17 14:19:26.000000000,2017-06-17 14:19:26.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 10311}, {'_account_id': 11580}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-06-02 02:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-transform/commit/08a1d16645b3242d965e8d09e315e167c4d6dfda', 'message': 'Updated from global requirements\n\nChange-Id: I37b2d3f47abfabeddccf602fb0f120dc71f4a94e\n'}, {'number': 2, 'created': '2017-06-09 20:40:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-transform/commit/2a533d8e276f1ee624df531220ae79e58e659697', 'message': 'Updated from global requirements\n\nChange-Id: I37b2d3f47abfabeddccf602fb0f120dc71f4a94e\n'}, {'number': 3, 'created': '2017-06-13 22:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-transform/commit/30b0f1fb43f29e7c889ff70ffe4edac87edbdd1d', 'message': 'Updated from global requirements\n\nChange-Id: I37b2d3f47abfabeddccf602fb0f120dc71f4a94e\n'}, {'number': 4, 'created': '2017-06-15 16:26:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-transform/commit/a887d85db69b3570ab50131f8a07ec2dd370a850', 'message': 'Updated from global requirements\n\nChange-Id: I37b2d3f47abfabeddccf602fb0f120dc71f4a94e\n'}]",0,470109,a887d85db69b3570ab50131f8a07ec2dd370a850,15,5,4,11131,,,0,"Updated from global requirements

Change-Id: I37b2d3f47abfabeddccf602fb0f120dc71f4a94e
",git fetch https://review.opendev.org/openstack/monasca-transform refs/changes/09/470109/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,08a1d16645b3242d965e8d09e315e167c4d6dfda,openstack/requirements,oslo.config>=4.0.0 # Apache-2.0,oslo.config>=3.22.0 # Apache-2.0,1,1
openstack%2Fneutron~stable%2Focata~I6650f1071499ed6cabd936bb0fb36b32a4b60bca,openstack/neutron,stable/ocata,I6650f1071499ed6cabd936bb0fb36b32a4b60bca,Don't add duplicate metadata rules after router update,MERGED,2017-06-15 20:03:23.000000000,2017-06-17 13:58:57.000000000,2017-06-17 13:58:56.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-15 20:03:23.000000000', 'files': ['neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8815e9e86755d2b253642949faec5de39e92f991', 'message': ""Don't add duplicate metadata rules after router update\n\nFor a HA router, when it's updated, the l3 agents which are standby\nalways call the after_router_added method, then duplicate metadata\nrules are added to iptables table. Althrough these rules will not be\napplied to system because of the _weed_out_duplicates method, they will\ngrow linearly with router update operations.\n\nBecause these metadata rules are added once router is added to the agent\nand will not be cleaned until router is removed, calling the add_rule\nmethod in after_router_updated is a waste.\n\nThis patch removes adding metadata rules in after_router_updated.\n\nConflicts:\n    neutron/tests/unit/agent/metadata/test_driver.py\n\nChange-Id: I6650f1071499ed6cabd936bb0fb36b32a4b60bca\nCloses-Bug: #1658460\n""}]",0,474763,8815e9e86755d2b253642949faec5de39e92f991,19,4,1,1131,,,0,"Don't add duplicate metadata rules after router update

For a HA router, when it's updated, the l3 agents which are standby
always call the after_router_added method, then duplicate metadata
rules are added to iptables table. Althrough these rules will not be
applied to system because of the _weed_out_duplicates method, they will
grow linearly with router update operations.

Because these metadata rules are added once router is added to the agent
and will not be cleaned until router is removed, calling the add_rule
method in after_router_updated is a waste.

This patch removes adding metadata rules in after_router_updated.

Conflicts:
    neutron/tests/unit/agent/metadata/test_driver.py

Change-Id: I6650f1071499ed6cabd936bb0fb36b32a4b60bca
Closes-Bug: #1658460
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/474763/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py']",2,8815e9e86755d2b253642949faec5de39e92f991,bug/1658460," if (not proxy.monitors.get(router.router_id) and not isinstance(router, ha_router.HaRouter)): proxy.spawn_monitored_metadata_proxy( l3_agent.process_monitor, router.ns_name, proxy.metadata_port, l3_agent.conf, router_id=router.router_id)"," if not proxy.monitors.get(router.router_id): after_router_added(resource, event, l3_agent, **kwargs)",27,2
openstack%2Fmurano~master~I7acf37c18a9a97c741048fd983848bbb7e8b6e57,openstack/murano,master,I7acf37c18a9a97c741048fd983848bbb7e8b6e57,Clean up sample policy generation,ABANDONED,2017-06-12 19:30:34.000000000,2017-06-17 13:54:38.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 15168}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-06-12 19:30:34.000000000', 'files': ['.gitignore', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/d5ded703819e23b166607325832055840f3891d3', 'message': 'Clean up sample policy generation\n\nThis commit cleans up sample policy generation by preventing\nmurano.policy.yaml.sample to be committed by adding it to\n.gitconfig. This commit also adds genpolicy (as well as other\ntestenv environments) to tox envlist.\n\nChange-Id: I7acf37c18a9a97c741048fd983848bbb7e8b6e57\nDepends-On: I2356ac0b2033bd83caaf2672189670fc300e55fd\n'}]",1,473563,d5ded703819e23b166607325832055840f3891d3,6,4,1,23186,,,0,"Clean up sample policy generation

This commit cleans up sample policy generation by preventing
murano.policy.yaml.sample to be committed by adding it to
.gitconfig. This commit also adds genpolicy (as well as other
testenv environments) to tox envlist.

Change-Id: I7acf37c18a9a97c741048fd983848bbb7e8b6e57
Depends-On: I2356ac0b2033bd83caaf2672189670fc300e55fd
",git fetch https://review.opendev.org/openstack/murano refs/changes/63/473563/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'tox.ini']",2,d5ded703819e23b166607325832055840f3891d3,cleanup_policy_gen,"envlist = py35,py27,pep8,api-ref,docs,genconfig,genpolicy,releasenotes","envlist = py35,py27,pep8",3,2
openstack%2Fcongress~master~Icaebdf181fb7fb12c63f33b0ae3324af54ac736d,openstack/congress,master,Icaebdf181fb7fb12c63f33b0ae3324af54ac736d,designate_driver & test_designate_driver for congress,ABANDONED,2017-06-17 11:31:00.000000000,2017-06-17 13:24:11.000000000,,[],"[{'number': 1, 'created': '2017-06-17 11:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d2ec67afdfd0d2263e697956ed5817c4756ee190', 'message': 'designate_driver & test_designate_driver for congress\n\nChange-Id: Icaebdf181fb7fb12c63f33b0ae3324af54ac736d\n'}, {'number': 2, 'created': '2017-06-17 12:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/fe91b663bb3bcfabea67712ada8be4341a76e128', 'message': 'designate_driver & test_designate_driver for congress\n\nChange-Id: Icaebdf181fb7fb12c63f33b0ae3324af54ac736d\n'}, {'number': 3, 'created': '2017-06-17 12:15:27.000000000', 'files': ['requirements.txt', 'congress/datasources/designate_driver.py', 'congress/tests/datasources/test_designate_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/8be0801c346a699fb38f15debdde0bd237c44ade', 'message': 'designate_driver & test_designate_driver for congress\n\nChange-Id: Icaebdf181fb7fb12c63f33b0ae3324af54ac736d\n'}]",0,475125,8be0801c346a699fb38f15debdde0bd237c44ade,4,0,3,25083,,,0,"designate_driver & test_designate_driver for congress

Change-Id: Icaebdf181fb7fb12c63f33b0ae3324af54ac736d
",git fetch https://review.opendev.org/openstack/congress refs/changes/25/475125/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/datasources/designate_driver.py', 'congress/tests/datasources/test_designate_driver.py']",2,d2ec67afdfd0d2263e697956ed5817c4756ee190,designate_driver_branch,"from __future__ import print_function from __future__ import division from __future__ import absolute_import u'href': u'http://192.168.122.1:9001' + u'/v2/zones/', to_return = self.mock_recordsets['recordsets'] recordsets_list.return_value = to_return #u'-', (u'f7b10e9b-0cae-4a91-b162-562bc6096648', u'2150b1bf-dee2-4221-b162-562bc6096648',"," u'href': u'http://192.168.122.1:9001/v2/' + u'zones/', recordsets_list.return_value = self.mock_recordsets['recordsets'] u'-', (u'2150b1bf-dee2-4221-b162-562bc6096648',",16,8
openstack%2Fkolla-ansible~master~I79c175c592fba9d078cee9b1b948597ec60bc68c,openstack/kolla-ansible,master,I79c175c592fba9d078cee9b1b948597ec60bc68c,Add Skydive startup guide documentation,MERGED,2017-06-13 13:58:55.000000000,2017-06-17 13:23:43.000000000,2017-06-17 13:23:42.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2888}, {'_account_id': 8157}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 20663}]","[{'number': 1, 'created': '2017-06-13 13:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1c69bd7cb4518d76362b7c66f3725c2b53a4f358', 'message': 'Add Skydive startup guide documentation\n\nJust a simple startup guide for Skydive\n\nChange-Id: I79c175c592fba9d078cee9b1b948597ec60bc68c\n'}, {'number': 2, 'created': '2017-06-14 13:07:45.000000000', 'files': ['doc/skydive-guide.rst', 'doc/index.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fdeffed03ed2ec10033b55b87feb76bba793ea13', 'message': 'Add Skydive startup guide documentation\n\nJust a simple startup guide for Skydive\n\nChange-Id: I79c175c592fba9d078cee9b1b948597ec60bc68c\n'}]",5,473853,fdeffed03ed2ec10033b55b87feb76bba793ea13,17,7,2,8157,,,0,"Add Skydive startup guide documentation

Just a simple startup guide for Skydive

Change-Id: I79c175c592fba9d078cee9b1b948597ec60bc68c
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/53/473853/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/skydive-guide.rst', 'doc/index.rst']",2,1c69bd7cb4518d76362b7c66f3725c2b53a4f358,, skydive-guide,,38,0
openstack%2Ftraining-labs~master~I18c0b7ec08c98c6bf8bdd9b28097d3294406fe88,openstack/training-labs,master,I18c0b7ec08c98c6bf8bdd9b28097d3294406fe88,Use redirected repo for apt,MERGED,2017-06-05 18:14:30.000000000,2017-06-17 12:51:12.000000000,2017-06-17 12:51:12.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 20770}]","[{'number': 1, 'created': '2017-06-05 18:14:30.000000000', 'files': ['labs/osbash/scripts/ubuntu/apt_init.sh'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/52f44f30a1c28ca9c58fd6af80e9ef0fde08dd53', 'message': ""Use redirected repo for apt\n\nUse 'archive.archive.ubuntu.com' instead of 'us.archive.ubuntu.com'.\nThis should speed up the downloads.\n\nChange-Id: I18c0b7ec08c98c6bf8bdd9b28097d3294406fe88\n""}]",0,471076,52f44f30a1c28ca9c58fd6af80e9ef0fde08dd53,9,3,1,20770,,,0,"Use redirected repo for apt

Use 'archive.archive.ubuntu.com' instead of 'us.archive.ubuntu.com'.
This should speed up the downloads.

Change-Id: I18c0b7ec08c98c6bf8bdd9b28097d3294406fe88
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/76/471076/1 && git format-patch -1 --stdout FETCH_HEAD,['labs/osbash/scripts/ubuntu/apt_init.sh'],1,52f44f30a1c28ca9c58fd6af80e9ef0fde08dd53,canonical_repo_redirection,# Use repository redirection for faster repository access. # The mirror 'archive.ubuntu.com' points to the closest to your location # instead of the 'us.archive.ubuntu.com' ones in United States sudo sed -i 's/us.archive.ubuntu.com/archive.ubuntu.com/g' /etc/apt/sources.list ,,5,0
openstack%2Fcastellan~master~I331bed146e856023bcbe27cba86b8edfa4146751,openstack/castellan,master,I331bed146e856023bcbe27cba86b8edfa4146751,Updated from global requirements,MERGED,2017-06-15 16:21:22.000000000,2017-06-17 12:45:28.000000000,2017-06-17 12:45:28.000000000,"[{'_account_id': 3}, {'_account_id': 9796}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-06-15 16:21:22.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/castellan/commit/7608bd1fada73ae620714da2b1c60e8b5fbc4725', 'message': 'Updated from global requirements\n\nChange-Id: I331bed146e856023bcbe27cba86b8edfa4146751\n'}]",0,474629,7608bd1fada73ae620714da2b1c60e8b5fbc4725,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I331bed146e856023bcbe27cba86b8edfa4146751
",git fetch https://review.opendev.org/openstack/castellan refs/changes/29/474629/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,7608bd1fada73ae620714da2b1c60e8b5fbc4725,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fdragonflow~master~Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32,openstack/dragonflow,master,Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32,Updated from global requirements,MERGED,2017-06-14 19:47:08.000000000,2017-06-17 12:08:26.000000000,2017-06-17 12:08:26.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}, {'_account_id': 23235}]","[{'number': 1, 'created': '2017-06-14 19:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2be62514477f887bf3b4ab70bc5ac6e9bc717e50', 'message': 'Updated from global requirements\n\nChange-Id: Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32\n'}, {'number': 2, 'created': '2017-06-15 05:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bb1a270dc190deac30af4d6864223e331a5e2718', 'message': 'Updated from global requirements\n\nChange-Id: Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32\n'}, {'number': 3, 'created': '2017-06-15 15:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/28efde8a207c647532f53724594b26e89dc7a5f5', 'message': 'Updated from global requirements\n\nChange-Id: Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32\n'}, {'number': 4, 'created': '2017-06-15 16:22:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/36185644c5114d1e81309848f0160a47211ed1ab', 'message': 'Updated from global requirements\n\nChange-Id: Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32\n'}]",0,474330,36185644c5114d1e81309848f0160a47211ed1ab,14,5,4,11131,,,0,"Updated from global requirements

Change-Id: Iaef5c9a28ad23af9f72e1f1445fcc7d314f3dc32
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/30/474330/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,2be62514477f887bf3b4ab70bc5ac6e9bc717e50,openstack/requirements,ryu>=4.14 # Apache-2.0,ryu>=4.11 # Apache-2.0,1,1
openstack%2Fkeystone-specs~master~I3a79f12a62037e565484cea4b8ff927d85a83394,openstack/keystone-specs,master,I3a79f12a62037e565484cea4b8ff927d85a83394,Fix html_last_updated_fmt for Python3,MERGED,2017-06-09 08:54:48.000000000,2017-06-17 11:46:20.000000000,2017-06-17 11:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 17860}, {'_account_id': 19741}]","[{'number': 1, 'created': '2017-06-09 08:54:48.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/79135121a92a96aae00db8cda363c590d1916b61', 'message': 'Fix html_last_updated_fmt for Python3\n\nFix the Sphinx html_last_updated_fmt for Python3.\nThe html_last_updated_fmt option is interpreted as a\nbyte string in python3, causing Sphinx build to break.\nThis patch makes it utf-8 string.\n\nChange-Id: I3a79f12a62037e565484cea4b8ff927d85a83394\nCloses-Bug: #1693670\n'}]",1,472591,79135121a92a96aae00db8cda363c590d1916b61,11,4,1,24564,,,0,"Fix html_last_updated_fmt for Python3

Fix the Sphinx html_last_updated_fmt for Python3.
The html_last_updated_fmt option is interpreted as a
byte string in python3, causing Sphinx build to break.
This patch makes it utf-8 string.

Change-Id: I3a79f12a62037e565484cea4b8ff927d85a83394
Closes-Bug: #1693670
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/91/472591/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,79135121a92a96aae00db8cda363c590d1916b61,bug/1693670,"try: html_last_updated_fmt = subprocess.check_output(git_cmd).decode('utf-8') except Exception: warnings.warn('Cannot get last updated time from git repository. ' 'Not setting ""html_last_updated_fmt"".')","html_last_updated_fmt = subprocess.Popen( git_cmd, stdout=subprocess.PIPE).communicate()[0] ",5,3
openstack%2Fopenstack-ansible-os_keystone~master~Ia5c8f31470f0f917ee556ca1157b9191da9d0d2c,openstack/openstack-ansible-os_keystone,master,Ia5c8f31470f0f917ee556ca1157b9191da9d0d2c,Optimise the distro package installation,MERGED,2017-06-06 19:42:10.000000000,2017-06-17 11:34:11.000000000,2017-06-17 11:34:11.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 11268}, {'_account_id': 17068}, {'_account_id': 19741}]","[{'number': 1, 'created': '2017-06-06 19:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/688d501753ac63ee0eadcea9f7e3e33639fdf55e', 'message': 'Optimise the distro package installation\n\nIn order to optimise the distro package installation\nprocess the list of packages to install is prepared\nfor the host, then installed by passing the package\ntask the full list instead of using a loop.\n\nChange-Id: Ia5c8f31470f0f917ee556ca1157b9191da9d0d2c\n'}, {'number': 2, 'created': '2017-06-08 13:27:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/fb0cadd2546656b86d87d8060a5668285c92780e', 'message': 'Optimise the distro package installation\n\nIn order to optimise the distro package installation\nprocess the list of packages to install is prepared\nfor the host, then installed by passing the package\ntask the full list instead of using a loop.\n\nChange-Id: Ia5c8f31470f0f917ee556ca1157b9191da9d0d2c\n'}, {'number': 3, 'created': '2017-06-13 14:52:26.000000000', 'files': ['tasks/keystone_install.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/a66bc38593c70c528f31a522b66d80fbfdfc1f28', 'message': 'Optimise the distro package installation\n\nIn order to optimise the distro package installation\nprocess the list of packages to install is prepared\nfor the host, then installed by passing the package\ntask the full list instead of using a loop.\n\nChange-Id: Ia5c8f31470f0f917ee556ca1157b9191da9d0d2c\n'}]",4,471451,a66bc38593c70c528f31a522b66d80fbfdfc1f28,46,7,3,6816,,,0,"Optimise the distro package installation

In order to optimise the distro package installation
process the list of packages to install is prepared
for the host, then installed by passing the package
task the full list instead of using a loop.

Change-Id: Ia5c8f31470f0f917ee556ca1157b9191da9d0d2c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/51/471451/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/keystone_install.yml', 'vars/main.yml']",2,688d501753ac63ee0eadcea9f7e3e33639fdf55e,distro-pkg-optimise,# # Compile a list of the distro packages to install based on # whether the host is in the host group and the service is # enabled. # keystone_package_list: |- {% set packages = keystone_distro_packages %} {% if keystone_apache_enabled | bool %} {% set _ = packages.extend(keystone_apache_distro_packages) %} {% if keystone_idp != {} %} {% set _ = packages.extend(keystone_idp_distro_packages) %} {% endif %} {% if keystone_sp != {} %} {% set _ = packages.extend(keystone_sp_distro_packages) %} {% endif %} {% else %} {% set _ = packages.extend(keystone_nginx_distro_packages) %} {% endif %} {% if keystone_mod_wsgi_enabled | bool %} {% set _ = packages.extend(keystone_mod_wsgi_distro_packages) %} {% else %} {% set _ = packages.extend(keystone_mod_proxy_uwsgi_distro_packages) %} {% endif %} {% if keystone_developer_mode | bool %} {% set _ = packages.extend(keystone_developer_mode_distro_packages) %} {% endif %} {{ packages }} ,,29,81
openstack%2Fneutron~stable%2Focata~I0a7cf13157de256403cfd6196f64fafdfa65f180,openstack/neutron,stable/ocata,I0a7cf13157de256403cfd6196f64fafdfa65f180,Don't iterate updated_rule_sg_ids or updated_sg_members,MERGED,2017-06-12 08:28:22.000000000,2017-06-17 10:12:22.000000000,2017-06-17 10:12:22.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 7715}, {'_account_id': 9656}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-12 08:28:22.000000000', 'files': ['neutron/agent/linux/iptables_firewall.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/96657be885275969a0feadde6255697b43e01590', 'message': ""Don't iterate updated_rule_sg_ids or updated_sg_members\n\nupdated_rule_sg_ids and updated_sg_members can be updated\nconcurrently by an RPC security_group_updated cast from the\nserver which will result in a RuntimeError due to set\nsize changing during iteration.\n\nThis adjusts the logic to just iterate over a copy of the set.\n\nChange-Id: I0a7cf13157de256403cfd6196f64fafdfa65f180\nCloses-Bug: #1696874\n(cherry picked from commit e51ae07aecd14b8270f5e14175f943a5abc8caa6)\n""}]",0,473304,96657be885275969a0feadde6255697b43e01590,26,5,1,7787,,,0,"Don't iterate updated_rule_sg_ids or updated_sg_members

updated_rule_sg_ids and updated_sg_members can be updated
concurrently by an RPC security_group_updated cast from the
server which will result in a RuntimeError due to set
size changing during iteration.

This adjusts the logic to just iterate over a copy of the set.

Change-Id: I0a7cf13157de256403cfd6196f64fafdfa65f180
Closes-Bug: #1696874
(cherry picked from commit e51ae07aecd14b8270f5e14175f943a5abc8caa6)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/473304/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/iptables_firewall.py'],1,96657be885275969a0feadde6255697b43e01590,bug/1696874, for sg_id in set(self.updated_rule_sg_ids): for device in set(self.updated_sg_members):, for sg_id in self.updated_rule_sg_ids: for device in self.updated_sg_members:,2,2
openstack%2Fneutron~stable%2Focata~Ic48d078542492e933f71d24df85c54c53a0b110c,openstack/neutron,stable/ocata,Ic48d078542492e933f71d24df85c54c53a0b110c,"Fix tempest router migration test when HA enabled, v2",MERGED,2017-06-16 18:47:18.000000000,2017-06-17 10:12:08.000000000,2017-06-17 10:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-16 18:47:18.000000000', 'files': ['neutron/tests/tempest/api/test_revisions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5c5a6e1bbadb77197f086e598949283ad9b81fea', 'message': 'Fix tempest router migration test when HA enabled, v2\n\nWhen run in an HA or DVR configured environment,\nthe test_update_router_extra_attributes_bumps_revision\nAPI test can fail if the release does not support\nrouter migration from CVR-HA to DVR.\n\nAlthough Ocata and later releases support any type of\nrouter migration, older ones do not, so the test\nshould be explicit and test a known valid migration.\n\nAdded missing l3-ha extension requirement from v1.\n\nChange-Id: Ic48d078542492e933f71d24df85c54c53a0b110c\nRelated-bug: #1679794\n(cherry picked from commit 52ed8468a4583453951cf584e9bd1f30a212b29e)\n'}]",0,475054,5c5a6e1bbadb77197f086e598949283ad9b81fea,10,4,1,1131,,,0,"Fix tempest router migration test when HA enabled, v2

When run in an HA or DVR configured environment,
the test_update_router_extra_attributes_bumps_revision
API test can fail if the release does not support
router migration from CVR-HA to DVR.

Although Ocata and later releases support any type of
router migration, older ones do not, so the test
should be explicit and test a known valid migration.

Added missing l3-ha extension requirement from v1.

Change-Id: Ic48d078542492e933f71d24df85c54c53a0b110c
Related-bug: #1679794
(cherry picked from commit 52ed8468a4583453951cf584e9bd1f30a212b29e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/475054/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/test_revisions.py'],1,5c5a6e1bbadb77197f086e598949283ad9b81fea,bug/1679794," @test.requires_ext(extension=""l3-ha"", service=""network"") def test_update_router_extra_attributes_bumps_revision(self): # updates from CVR to CVR-HA are supported on every release, # but only the admin can forcibly create a non-HA router router_args = {'tenant_id': self.client.tenant_id, 'ha': False} router = self.admin_client.create_router('r1', True, **router_args)['router'] self.admin_client.update_router(router['id'], ha=True)['router']"," @test.requires_ext(extension=""dvr"", service=""network"") def test_update_router_extra_attributes_bumps_revision(self): router = self.create_router(router_name='r1') self.admin_client.update_router(router['id'], distributed=True)['router']",8,4
openstack%2Fneutron~stable%2Fnewton~Ic48d078542492e933f71d24df85c54c53a0b110c,openstack/neutron,stable/newton,Ic48d078542492e933f71d24df85c54c53a0b110c,"Fix tempest router migration test when HA enabled, v2",MERGED,2017-06-16 18:47:59.000000000,2017-06-17 10:11:51.000000000,2017-06-17 10:11:51.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-16 18:47:59.000000000', 'files': ['neutron/tests/tempest/api/test_revisions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/578ca25ace1009bc7235d714785849d4327bb864', 'message': 'Fix tempest router migration test when HA enabled, v2\n\nWhen run in an HA or DVR configured environment,\nthe test_update_router_extra_attributes_bumps_revision\nAPI test can fail if the release does not support\nrouter migration from CVR-HA to DVR.\n\nAlthough Ocata and later releases support any type of\nrouter migration, older ones do not, so the test\nshould be explicit and test a known valid migration.\n\nAdded missing l3-ha extension requirement from v1.\n\nChange-Id: Ic48d078542492e933f71d24df85c54c53a0b110c\nRelated-bug: #1679794\n(cherry picked from commit 52ed8468a4583453951cf584e9bd1f30a212b29e)\n'}]",0,475055,578ca25ace1009bc7235d714785849d4327bb864,10,4,1,1131,,,0,"Fix tempest router migration test when HA enabled, v2

When run in an HA or DVR configured environment,
the test_update_router_extra_attributes_bumps_revision
API test can fail if the release does not support
router migration from CVR-HA to DVR.

Although Ocata and later releases support any type of
router migration, older ones do not, so the test
should be explicit and test a known valid migration.

Added missing l3-ha extension requirement from v1.

Change-Id: Ic48d078542492e933f71d24df85c54c53a0b110c
Related-bug: #1679794
(cherry picked from commit 52ed8468a4583453951cf584e9bd1f30a212b29e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/475055/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/test_revisions.py'],1,578ca25ace1009bc7235d714785849d4327bb864,bug/1679794," @test.requires_ext(extension=""l3-ha"", service=""network"") def test_update_router_extra_attributes_bumps_revision(self): # updates from CVR to CVR-HA are supported on every release, # but only the admin can forcibly create a non-HA router router_args = {'tenant_id': self.client.tenant_id, 'ha': False} router = self.admin_client.create_router('r1', True, **router_args)['router'] self.admin_client.update_router(router['id'], ha=True)['router']"," @test.requires_ext(extension=""dvr"", service=""network"") def test_update_router_extra_attributes_bumps_revision(self): router = self.create_router(router_name='r1') self.admin_client.update_router(router['id'], distributed=True)['router']",8,4
openstack%2Fneutron~stable%2Focata~I615b60561b3b7f8c950d5f412fb4cdf7877b98f7,openstack/neutron,stable/ocata,I615b60561b3b7f8c950d5f412fb4cdf7877b98f7,Stop arping when interface gets deleted,MERGED,2017-06-14 20:57:09.000000000,2017-06-17 10:11:36.000000000,2017-06-17 10:11:36.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-14 20:57:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/52bbd4014bfc01bd93879d45fc3f7f8960f77979', 'message': 'Stop arping when interface gets deleted\n\nIt is possible for an interface to be added to a\nrouter, have arping get started for it in a thread,\nthen immediately remove the interface, causing\narping errors in the l3-agent log.  This concurrent\ndeletion should be handled more gracefully by\njust logging a warning on the first detection and\nreturning early.\n\nChange-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7\nCloses-bug: #1696893\n(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)\n'}, {'number': 2, 'created': '2017-06-15 18:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/46f7925d10ddaa40ca3518f142e1135003051703', 'message': ""Stop arping when interface gets deleted\n\nIt is possible for an interface to be added to a\nrouter, have arping get started for it in a thread,\nthen immediately remove the interface, causing\narping errors in the l3-agent log.  This concurrent\ndeletion should be handled more gracefully by\njust logging a warning on the first detection and\nreturning early.\n\nOcata changes: added translation marker to a warning message because\nit's enforced in the branch. (In Pike, we reversed the direction, not\nadding those markers to log messages.)\n\nChange-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7\nCloses-bug: #1696893\n(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)\n""}, {'number': 3, 'created': '2017-06-16 02:41:24.000000000', 'files': ['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/be13101ec4ad521556ec890aafa462244de50f7d', 'message': ""Stop arping when interface gets deleted\n\nIt is possible for an interface to be added to a\nrouter, have arping get started for it in a thread,\nthen immediately remove the interface, causing\narping errors in the l3-agent log.  This concurrent\ndeletion should be handled more gracefully by\njust logging a warning on the first detection and\nreturning early.\n\nOcata changes: added translation marker to a warning message because\nit's enforced in the branch. (In Pike, we reversed the direction, not\nadding those markers to log messages.)\n\nChange-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7\nCloses-bug: #1696893\n(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)\n""}]",0,474353,be13101ec4ad521556ec890aafa462244de50f7d,22,7,3,9656,,,0,"Stop arping when interface gets deleted

It is possible for an interface to be added to a
router, have arping get started for it in a thread,
then immediately remove the interface, causing
arping errors in the l3-agent log.  This concurrent
deletion should be handled more gracefully by
just logging a warning on the first detection and
returning early.

Ocata changes: added translation marker to a warning message because
it's enforced in the branch. (In Pike, we reversed the direction, not
adding those markers to log messages.)

Change-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7
Closes-bug: #1696893
(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/53/474353/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py']",2,52bbd4014bfc01bd93879d45fc3f7f8960f77979,bug/1696893," @mock.patch.object(ip_lib, 'IPWrapper') @mock.patch('eventlet.spawn_n') def test_send_ipv4_addr_adv_notif_nodev(self, spawn_n, mIPWrapper): spawn_n.side_effect = lambda f: f() ip_wrapper = mIPWrapper(namespace=mock.sentinel.ns_name) ip_wrapper.netns.execute.side_effect = RuntimeError ARPING_COUNT = 3 address = '20.0.0.1' with mock.patch.object(ip_lib, 'device_exists', return_value=False): ip_lib.send_ip_addr_adv_notif(mock.sentinel.ns_name, mock.sentinel.iface_name, address, ARPING_COUNT) # should return early with a single call when ENODEV mIPWrapper.assert_has_calls([ mock.call(namespace=mock.sentinel.ns_name), mock.call().netns.execute(mock.ANY, extra_ok_codes=mock.ANY) ] * 1) ",,29,1
openstack%2Fneutron~stable%2Fnewton~I615b60561b3b7f8c950d5f412fb4cdf7877b98f7,openstack/neutron,stable/newton,I615b60561b3b7f8c950d5f412fb4cdf7877b98f7,Stop arping when interface gets deleted,MERGED,2017-06-14 20:57:24.000000000,2017-06-17 10:11:21.000000000,2017-06-17 10:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-14 20:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f09928b3d56c3d12bd4f1b6fef09019da74d664', 'message': 'Stop arping when interface gets deleted\n\nIt is possible for an interface to be added to a\nrouter, have arping get started for it in a thread,\nthen immediately remove the interface, causing\narping errors in the l3-agent log.  This concurrent\ndeletion should be handled more gracefully by\njust logging a warning on the first detection and\nreturning early.\n\nChange-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7\nCloses-bug: #1696893\n(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)\n'}, {'number': 2, 'created': '2017-06-15 18:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7174c425e5a57bbb252305c158f2e78b90efb53', 'message': ""Stop arping when interface gets deleted\n\nIt is possible for an interface to be added to a\nrouter, have arping get started for it in a thread,\nthen immediately remove the interface, causing\narping errors in the l3-agent log.  This concurrent\ndeletion should be handled more gracefully by\njust logging a warning on the first detection and\nreturning early.\n\nOcata changes: added translation marker to a warning message because\nit's enforced in the branch. (In Pike, we reversed the direction, not\nadding those markers to log messages.)\n\nNewton changes: ip_lib.send_ip_addr_adv_notif receives a 'config' object\nwith send_arp_for_ha option set to the number of ARP queries to issue,\nand not the number itself. Adopted the test case to this.\n\nChange-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7\nCloses-bug: #1696893\n(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)\n(cherry picked from commit 46f7925d10ddaa40ca3518f142e1135003051703)\n""}, {'number': 3, 'created': '2017-06-15 19:20:32.000000000', 'files': ['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ff7ca21bbeea9028bd8582386d536bee62cf6f0', 'message': ""Stop arping when interface gets deleted\n\nIt is possible for an interface to be added to a\nrouter, have arping get started for it in a thread,\nthen immediately remove the interface, causing\narping errors in the l3-agent log.  This concurrent\ndeletion should be handled more gracefully by\njust logging a warning on the first detection and\nreturning early.\n\nOcata changes: added translation marker to a warning message because\nit's enforced in the branch. (In Pike, we reversed the direction, not\nadding those markers to log messages.)\n\nNewton changes: ip_lib.send_ip_addr_adv_notif receives a 'config' object\nwith send_arp_for_ha option set to the number of ARP queries to issue,\nand not the number itself. Adopted the test case to this.\n\nChange-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7\nCloses-bug: #1696893\n(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)\n(cherry picked from commit 46f7925d10ddaa40ca3518f142e1135003051703)\n""}]",0,474354,7ff7ca21bbeea9028bd8582386d536bee62cf6f0,16,6,3,9656,,,0,"Stop arping when interface gets deleted

It is possible for an interface to be added to a
router, have arping get started for it in a thread,
then immediately remove the interface, causing
arping errors in the l3-agent log.  This concurrent
deletion should be handled more gracefully by
just logging a warning on the first detection and
returning early.

Ocata changes: added translation marker to a warning message because
it's enforced in the branch. (In Pike, we reversed the direction, not
adding those markers to log messages.)

Newton changes: ip_lib.send_ip_addr_adv_notif receives a 'config' object
with send_arp_for_ha option set to the number of ARP queries to issue,
and not the number itself. Adopted the test case to this.

Change-Id: I615b60561b3b7f8c950d5f412fb4cdf7877b98f7
Closes-bug: #1696893
(cherry picked from commit 739daaa9555e734b94bef89f4fe1c5159c8fd435)
(cherry picked from commit 46f7925d10ddaa40ca3518f142e1135003051703)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/474354/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py']",2,2f09928b3d56c3d12bd4f1b6fef09019da74d664,bug/1696893," @mock.patch.object(ip_lib, 'IPWrapper') @mock.patch('eventlet.spawn_n') def test_send_ipv4_addr_adv_notif_nodev(self, spawn_n, mIPWrapper): spawn_n.side_effect = lambda f: f() ip_wrapper = mIPWrapper(namespace=mock.sentinel.ns_name) ip_wrapper.netns.execute.side_effect = RuntimeError ARPING_COUNT = 3 address = '20.0.0.1' with mock.patch.object(ip_lib, 'device_exists', return_value=False): ip_lib.send_ip_addr_adv_notif(mock.sentinel.ns_name, mock.sentinel.iface_name, address, ARPING_COUNT) # should return early with a single call when ENODEV mIPWrapper.assert_has_calls([ mock.call(namespace=mock.sentinel.ns_name), mock.call().netns.execute(mock.ANY, extra_ok_codes=mock.ANY) ] * 1) ",,29,1
openstack%2Fneutron~master~I08c3f077e470aa593076a525de1445bc5d0bdb9a,openstack/neutron,master,I08c3f077e470aa593076a525de1445bc5d0bdb9a,docs: Fix indent level,MERGED,2017-06-15 23:22:46.000000000,2017-06-17 10:11:01.000000000,2017-06-17 10:11:01.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 6854}, {'_account_id': 7715}]","[{'number': 1, 'created': '2017-06-15 23:22:46.000000000', 'files': ['doc/source/stadium/governance.rst', 'TESTING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eee9d2ca8019623a6ab3700a86d01587f6e8db1c', 'message': 'docs: Fix indent level\n\nLeading spaces before item lists leads to vertical line\non the left side. They are completely unnecessary.\n\nChange-Id: I08c3f077e470aa593076a525de1445bc5d0bdb9a\n'}]",0,474806,eee9d2ca8019623a6ab3700a86d01587f6e8db1c,11,4,1,841,,,0,"docs: Fix indent level

Leading spaces before item lists leads to vertical line
on the left side. They are completely unnecessary.

Change-Id: I08c3f077e470aa593076a525de1445bc5d0bdb9a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/474806/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/stadium/governance.rst', 'TESTING.rst']",2,eee9d2ca8019623a6ab3700a86d01587f6e8db1c,doc-migration,"* Unit tests - Should be able to run on your laptop, directly following a 'git clone' of the project. The underlying system must not be mutated, mocks can be used to achieve this. A unit test typically targets a function or class. * Functional tests - Run against a pre-configured environment (tools/configure_for_func_testing.sh). Typically test a component such as an agent using no mocks. * Integration tests - Run against a running cloud, often target the API level, but also 'scenarios' or 'user stories'. You may find such tests under tests/tempest/api, tests/tempest/scenario, tests/fullstack, and in the Tempest and Rally projects.see this wiki page: https://wiki.openstack.org/wiki/Testr* Check out the latest `merge commit <https://review.openstack.org/gitweb?p=openstack/neutron.git;a=search;s=Jenkins;st=author>`_ * Go to: http://logs.openstack.org/<first-2-digits-of-sha1>/<sha1>/post/neutron-coverage/. * `Spec <https://review.openstack.org/#/c/221494/>`_ is a work in progress to provide a better landing page."," * Unit tests - Should be able to run on your laptop, directly following a 'git clone' of the project. The underlying system must not be mutated, mocks can be used to achieve this. A unit test typically targets a function or class. * Functional tests - Run against a pre-configured environment (tools/configure_for_func_testing.sh). Typically test a component such as an agent using no mocks. * Integration tests - Run against a running cloud, often target the API level, but also 'scenarios' or 'user stories'. You may find such tests under tests/tempest/api, tests/tempest/scenario, tests/fullstack, and in the Tempest and Rally projects.see this wiki page: https://wiki.openstack.org/wiki/Testr * Check out the latest `merge commit <https://review.openstack.org/gitweb?p=openstack/neutron.git;a=search;s=Jenkins;st=author>`_ * Go to: http://logs.openstack.org/<first-2-digits-of-sha1>/<sha1>/post/neutron-coverage/. * `Spec <https://review.openstack.org/#/c/221494/>`_ is a work in progress to provide a better landing page.",149,151
openstack%2Fneutron~master~I1412b047efc1c268b34ef97e78073da7bcbb6d7e,openstack/neutron,master,I1412b047efc1c268b34ef97e78073da7bcbb6d7e,docs: reorganize developer reference for new theme,MERGED,2017-06-15 23:22:46.000000000,2017-06-17 10:10:46.000000000,2017-06-17 10:10:45.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7787}]","[{'number': 1, 'created': '2017-06-15 23:22:46.000000000', 'files': ['doc/source/devref/testing_index.rst', 'doc/source/index.rst', 'doc/source/devref/testing.rst', 'doc/source/devref/development.environment.rst', 'doc/source/devref/modules.rst', 'doc/source/devref/index.rst', 'doc/source/feature_classification/index.rst', 'TESTING.rst', 'doc/source/devref/neutron_internals.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a23cd43abe799af1b72b14c786f2fc9dbd8d3ec4', 'message': 'docs: reorganize developer reference for new theme\n\nopenstackdocstheme generates the toc tree in the left sidebar\nbased on the page hierarchy from the top page.\nThe previous developer guide hirarchy is a bit deep, and\nthis commit reorganizes the devref pages for better navigation\nwith openstackdocstheme.\n\nChange-Id: I1412b047efc1c268b34ef97e78073da7bcbb6d7e\n'}]",0,474805,a23cd43abe799af1b72b14c786f2fc9dbd8d3ec4,10,3,1,841,,,0,"docs: reorganize developer reference for new theme

openstackdocstheme generates the toc tree in the left sidebar
based on the page hierarchy from the top page.
The previous developer guide hirarchy is a bit deep, and
this commit reorganizes the devref pages for better navigation
with openstackdocstheme.

Change-Id: I1412b047efc1c268b34ef97e78073da7bcbb6d7e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/05/474805/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/testing_index.rst', 'doc/source/index.rst', 'doc/source/devref/testing.rst', 'doc/source/devref/development.environment.rst', 'doc/source/devref/modules.rst', 'doc/source/devref/index.rst', 'doc/source/feature_classification/index.rst', 'TESTING.rst', 'doc/source/devref/neutron_internals.rst']",9,a23cd43abe799af1b72b14c786f2fc9dbd8d3ec4,doc-migration,".. Copyright 2010-2011 United States Government as represented by the Administrator of the National Aeronautics and Space Administration. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Convention for heading levels in Neutron devref: ======= Heading 0 (reserved for the title in a document) ------- Heading 1 ~~~~~~~ Heading 2 +++++++ Heading 3 ''''''' Heading 4 (Avoid deeper levels because they do not render well.) ================= Neutron Internals ================= .. toctree:: :maxdepth: 1 services_and_agents api_layer ml2_ext_manager calling_ml2_plugin quota api_extensions plugin-api db_layer db_models policy rpc_api rpc_callbacks layer3 l2_agents agent_extensions ovs_vhostuser quality_of_service service_extensions dns_order external_dns_integration upgrade objects_usage i18n address_scopes openvswitch_firewall network_ip_availability tag provisioning_blocks retries l3_agent_extensions live_migration ",,173,81
openstack%2Fneutron~master~I72d55c26401ae9bfd06626d1b1584a368bbd9f86,openstack/neutron,master,I72d55c26401ae9bfd06626d1b1584a368bbd9f86,docs: switch to openstackdocstheme,MERGED,2017-06-15 23:22:46.000000000,2017-06-17 10:10:30.000000000,2017-06-17 10:10:30.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-15 23:22:46.000000000', 'files': ['doc/source/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'doc/source/dashboards/index.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a1b0b05234048fe0f29df459b984b87faea7505', 'message': 'docs: switch to openstackdocstheme\n\nThe docs reorganization proposed in the docs-specs [1],\nwe will migrate our sphinx theme to openstackdocsthems.\nThis commit switches our docs theme to it,\n\nAlso ajust title levels. openstackdocstheme assume one title (first\nlevel) per page.  Second or later first-level titles are not shown.\nThis changes title levels to match openstackdocsthem requirements.\n\nNote that oslosphinx is used by releasenotes build,\nso it is not dropped from test-requirements.txt.\n\n[1] https://review.openstack.org/#/c/472275/\n\nChange-Id: I72d55c26401ae9bfd06626d1b1584a368bbd9f86\n'}]",0,474804,2a1b0b05234048fe0f29df459b984b87faea7505,12,4,1,841,,,0,"docs: switch to openstackdocstheme

The docs reorganization proposed in the docs-specs [1],
we will migrate our sphinx theme to openstackdocsthems.
This commit switches our docs theme to it,

Also ajust title levels. openstackdocstheme assume one title (first
level) per page.  Second or later first-level titles are not shown.
This changes title levels to match openstackdocsthem requirements.

Note that oslosphinx is used by releasenotes build,
so it is not dropped from test-requirements.txt.

[1] https://review.openstack.org/#/c/472275/

Change-Id: I72d55c26401ae9bfd06626d1b1584a368bbd9f86
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/474804/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'test-requirements.txt', 'doc/source/conf.py', 'doc/source/dashboards/index.rst']",4,2a1b0b05234048fe0f29df459b984b87faea7505,doc-migration,CI Status Dashboards ==================== -----------------------------------,===================================,27,12
openstack%2Fneutron-specs~master~I6df22d9e766d8aeabc2f99262cadeec332d809b0,openstack/neutron-specs,master,I6df22d9e766d8aeabc2f99262cadeec332d809b0,Neutron Common Classification Framework,MERGED,2016-06-24 16:52:18.000000000,2017-06-17 10:08:19.000000000,2017-06-17 10:08:19.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 6469}, {'_account_id': 6598}, {'_account_id': 7278}, {'_account_id': 7776}, {'_account_id': 7787}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8976}, {'_account_id': 9375}, {'_account_id': 9396}, {'_account_id': 9656}, {'_account_id': 10850}, {'_account_id': 11313}, {'_account_id': 11604}, {'_account_id': 11907}, {'_account_id': 12021}, {'_account_id': 13702}, {'_account_id': 14037}, {'_account_id': 14605}, {'_account_id': 14744}, {'_account_id': 15326}, {'_account_id': 16688}, {'_account_id': 16707}, {'_account_id': 17776}, {'_account_id': 18051}, {'_account_id': 20229}, {'_account_id': 21798}, {'_account_id': 23766}, {'_account_id': 23858}]","[{'number': 1, 'created': '2016-06-24 16:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1692699e7526d765504599241c9798a506f02466', 'message': 'The Neutron Common Classifier possible approaches\n\nThis patch documents three possible approaches that can be\nconsidered to support the common/flow classifier functionality.\nMultiple Neutron features need traffic classification.\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\n[Igor]\nI\'m avoiding the ""Flow"" word outside Approach 1/3 since the common classifier\neffort is not necessarily related to OpenFlow or even generic traffic flows,\nunlike the related Flow Management effort, and also to prevent confusion with\nnetworking-sfc\'s existing Flow Classifier.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nRelated-Bug: #1476527\n'}, {'number': 2, 'created': '2016-07-01 16:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/95316e6a62599baed61f1913daeb2b37af3c2ef2', 'message': 'The Neutron Common Classifier possible approaches\n\nThis patch documents three possible approaches that can be\nconsidered to support the common/flow classifier functionality.\nMultiple Neutron features need traffic classification.\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\n[Igor]\nI\'m avoiding the ""Flow"" word outside Approach 1/3 since the common classifier\neffort is not necessarily related to OpenFlow or even generic traffic flows,\nunlike the related Flow Management effort, and also to prevent confusion with\nnetworking-sfc\'s existing Flow Classifier.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nRelated-Bug: #1476527\n'}, {'number': 3, 'created': '2016-07-05 16:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6eb846c80d6d82fad4f7ec79ebf70dc39e5901ef', 'message': 'The Neutron Common Classifier possible approaches\n\nThis patch documents three possible approaches that can be\nconsidered to support the common/flow classifier functionality.\nMultiple Neutron features need traffic classification.\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\n[Igor]\nI\'m avoiding the ""Flow"" word outside Approach 1/3 since the common classifier\neffort is not necessarily related to OpenFlow or even generic traffic flows,\nunlike the related Flow Management effort, and also to prevent confusion with\nnetworking-sfc\'s existing Flow Classifier.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nRelated-Bug: #1476527\n'}, {'number': 4, 'created': '2016-07-10 00:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8b069bbe47f59f8e9cd1f28d1d142181cd6e18e2', 'message': 'The Neutron Common Classifier possible approaches\n\nThis patch documents three possible approaches that can be\nconsidered to support the common/flow classifier functionality.\nMultiple Neutron features need traffic classification.\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\n[Igor]\nI\'m avoiding the ""Flow"" word outside Approach 1/3 since the common classifier\neffort is not necessarily related to OpenFlow or even generic traffic flows,\nunlike the related Flow Management effort, and also to prevent confusion with\nnetworking-sfc\'s existing Flow Classifier.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nRelated-Bug: #1476527\n'}, {'number': 5, 'created': '2016-07-12 09:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ad60eb60ea847c49818abdea12e2d3e96ddb6086', 'message': 'The Neutron Common Classifier possible approaches\n\nThis patch documents three possible approaches that can be\nconsidered to support the common/flow classifier functionality.\nMultiple Neutron features need traffic classification.\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\n[Igor]\nI\'m avoiding the ""Flow"" word outside Approach 1/3 since the common classifier\neffort is not necessarily related to OpenFlow or even generic traffic flows,\nunlike the related Flow Management effort, and also to prevent confusion with\nnetworking-sfc\'s existing Flow Classifier.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nRelated-Bug: #1476527\n'}, {'number': 6, 'created': '2016-09-14 16:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d6caa21099389ef83a16b8aef94aa93216521bbb', 'message': 'The Neutron Common Classification Framework\n\nThis patch documents three possible approaches that can be\nconsidered to support a traffic classification framework.\n\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Sean Mooney <sean.k.mooney@intel.com>\nRelated-Bug: #1476527\n'}, {'number': 7, 'created': '2016-09-14 16:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b7e8f2cd9a7d4a0c6159062d3134bedf8e25e93c', 'message': 'The Neutron Common Classification Framework\n\nThis patch documents three possible approaches that can be\nconsidered to support a traffic classification framework.\n\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Sean Mooney <sean.k.mooney@intel.com>\nRelated-Bug: #1476527\n'}, {'number': 8, 'created': '2016-11-22 14:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c11036cfddeef8fab203d37ddcdec5b397748af2', 'message': 'The Neutron Common Classification Framework\n\nThis patch documents three possible approaches that can be\nconsidered to support a traffic classification framework.\n\nInstead of each feature creating its own classification API, we should\nhave one common API that can be used by any of the features/services.\n\nCurrently the features that need classification are:\n - Tap as a Service, SFC, QoS, FW and BGP/VPN.\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/subprojects.\nThe goal is to come up with one consistent way of defining the API and\nclassifications. Through this common API, each Neutron feature can create\nits own classification and then associate it with the feature itself.\n\nAn approach will be chosen, and likely modified/improved, based on design\ncomprehensiveness, usage simplicity, future extensions, implementation,\nupgrade, performance complexities and community feedback.\n\nMore patches may follow up on design internals for the\nadopted implementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nCo-Authored-By: Cathy Zhang <cathy.zhang@huawei.com>\nCo-Authored-By: Henry Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Sean Mooney <sean.k.mooney@intel.com>\nRelated-Bug: #1476527\n'}, {'number': 9, 'created': '2016-12-07 15:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/be8cab0fcf8e59d1774b9a11fc95b459a00541a6', 'message': 'The Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework and 2 possible\nvariants to how it can be applied in Neutron (called approach A and B).\n\nNeutron features/projects that (may) need classification are:\n - openstack/networking-bgpvpn\n - openstack/neutron-fwaas\n - openstack/networking-sfc\n - openstack/tap-as-a-service\n - QoS\n - Security group rules\n - <others in the future or>\n\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/\nsubprojects. The goal is to come up with one consistent way of\ndefining the API and classifications. Through this common API (or\ncommonly-defined APIs), classifications can be created via a common\nendpoint and then associated to any feature (approach A).\nAlternatively, features can have their own endpoints for defining\nclassifications, but doing so in a consistent manner by obtaining\nthe models from the common framework (approach B).\n\nMore patches may follow up on design internals for the adopted\nimplementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n'}, {'number': 10, 'created': '2016-12-20 16:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bf35cbd776ebf6953448b4df451e8f94ee3eb290', 'message': 'The Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework and 2 possible\nvariants to how it can be applied in Neutron (called approach A and B).\n\nNeutron features/projects that (may) need classification are:\n - openstack/networking-bgpvpn\n - openstack/neutron-fwaas\n - openstack/networking-sfc\n - openstack/tap-as-a-service\n - QoS\n - Security group rules\n - <others in the future>\n\nThe Common Classifier API should be a superset of available\ntraffic classification rules used by existing Neutron services/\nsubprojects. The goal is to come up with one consistent way of\ndefining the API and classifications. Through this common API (or\ncommonly-defined APIs), classifications can be created via a common\nendpoint and then associated to any feature (approach A).\nAlternatively, features can have their own endpoints for defining\nclassifications, but doing so in a consistent manner by obtaining\nthe models from the common framework (approach B).\n\nMore patches may follow up on design internals for the adopted\nimplementation approach.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n'}, {'number': 11, 'created': '2017-02-15 21:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7b964dd61421454f2d25894a8973a116eaba8350', 'message': 'The Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that (may) need classification are:\n - openstack/networking-bgpvpn\n - openstack/neutron-fwaas\n - openstack/networking-sfc\n - openstack/tap-as-a-service\n - QoS\n - Security group rules\n - <others in the future>\n\nThe Common Classifications API should be a superset of available\ntraffic classification rules used by existing Neutron services/\nsubprojects. Through this common API, classifications can be created\nvia a common endpoint and then associated to any feature/service.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n'}, {'number': 12, 'created': '2017-03-01 16:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bc6b52733a5199fb6f409aea569b7a0dc2b83f6b', 'message': 'Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/group-based-policy\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nThe Classifications API should be a superset of available\ntraffic classification rules used by existing Neutron services/\nsubprojects. Through this common API, classifications can be created\nvia a common endpoint and then associated to any Consuming Service.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n'}, {'number': 13, 'created': '2017-03-01 16:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/396434658401f8b894a687102fdf8595bfc89cb6', 'message': 'Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/group-based-policy\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nThe Classifications API should be a superset of available\ntraffic classification rules used by existing Neutron services/\nsubprojects. Through this common API, classifications can be created\nvia a common endpoint and then associated to any Consuming Service.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n'}, {'number': 14, 'created': '2017-04-08 16:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2e8031a4f8e7408363b06aa8736a0cd04277ec1e', 'message': ""Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nFurthermore, there are other projects with classication APIs, such as\nopenstack/group-based-policy and it's possible that others will want\nto support classifications in their own APIs, further reinventing the wheel\nand fragmenting the language used in the OpenStack ecosystem when it comes\nto defining traffic classifications.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n""}, {'number': 15, 'created': '2017-04-19 18:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8e1ed2567f965158df05c9a66a4ac3498358881a', 'message': ""Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nFurthermore, there are other projects with classication APIs, such as\nopenstack/group-based-policy and it's possible that others will want\nto support classifications in their own APIs, further reinventing the wheel\nand fragmenting the language used in the OpenStack ecosystem when it comes\nto defining traffic classifications.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n""}, {'number': 16, 'created': '2017-05-30 13:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/126e3b71a85f56a0eaadec456522803d849675fb', 'message': ""Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nFurthermore, there are other projects with classication APIs, such as\nopenstack/group-based-policy and it's possible that others will want\nto support classifications in their own APIs, further reinventing the wheel\nand fragmenting the language used in the OpenStack ecosystem when it comes\nto defining traffic classifications.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n""}, {'number': 17, 'created': '2017-05-30 15:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8b983a90f5ff1838af634b7cde98749e463ec327', 'message': ""Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nFurthermore, there are other projects with classication APIs, such as\nopenstack/group-based-policy and it's possible that others will want\nto support classifications in their own APIs, further reinventing the wheel\nand fragmenting the language used in the OpenStack ecosystem when it comes\nto defining traffic classifications.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n""}, {'number': 18, 'created': '2017-06-15 15:54:30.000000000', 'files': ['specs/pike/common-classification-framework.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ac282399d4bf910f900628522d277d998fed0ce9', 'message': ""Neutron Common Classification Framework\n\nThis patch documents the Common Classification Framework.\n\nNeutron features/projects that may need classification are:\n- Security group rules\n- openstack/neutron-fwaas\n- openstack/networking-sfc\n- openstack/networking-bgpvpn\n- openstack/tap-as-a-service\n- Neutron QoS\n\nFurthermore, there are other projects with classication APIs, such as\nopenstack/group-based-policy and it's possible that others will want\nto support classifications in their own APIs, further reinventing the wheel\nand fragmenting the language used in the OpenStack ecosystem when it comes\nto defining traffic classifications.\n\nChange-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0\nRelated-Bug: #1476527\n""}]",441,333993,ac282399d4bf910f900628522d277d998fed0ce9,164,33,18,9396,,,0,"Neutron Common Classification Framework

This patch documents the Common Classification Framework.

Neutron features/projects that may need classification are:
- Security group rules
- openstack/neutron-fwaas
- openstack/networking-sfc
- openstack/networking-bgpvpn
- openstack/tap-as-a-service
- Neutron QoS

Furthermore, there are other projects with classication APIs, such as
openstack/group-based-policy and it's possible that others will want
to support classifications in their own APIs, further reinventing the wheel
and fragmenting the language used in the OpenStack ecosystem when it comes
to defining traffic classifications.

Change-Id: I6df22d9e766d8aeabc2f99262cadeec332d809b0
Related-Bug: #1476527
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/93/333993/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/newton/common-classifier.rst'],1,1692699e7526d765504599241c9798a506f02466,commmon-classification-framework,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================= Neutron Common Classifier ========================= https://bugs.launchpad.net/neutron/+bug/1476527 Problem Description =================== At the moment, this spec proposes and compares different approaches to define the Neutron Common Classifier. This classifier is to be added to the Neutron API and be leveraged by Neutron services that need traffic classification. Three approaches are herein described in terms of their possible data models and APIs. The previous spec for this RFE is archived at [0]. Proposed Change =============== Neutron will include new DB models and API resources to allow the definition of traffic classifications and possibly related logic, to be used by other Neutron services/subprojects. More detail will be included in this section, in the future. Data Model Impact ----------------- This section describes the 3 different data model approaches: Approach 1 ~~~~~~~~~~ One or more classification types/rules can be combined to form a flow classifier object. ""and"", ""or"", ""not"" operations can be used to combine multiple flow classifier objects into a ""composite"" flow classifier object. Model:: +------------------------------+ | flow_classifier | +------------------------------+ | tenant_id | | id | | name | | description | | priority | | protocol | | source_ip_prefix | | destination_ip_prefix | | source_port_range_max | | source_port_range_min | | destination_port_range_min | | destination_port_range_max | | ethertype | | source_mac | | destination_mac | | vlan_id | | vlan_priority | | dscp | | dscp_mask | | logical_source_port | | logical_destination_port | +------------------------------+ We can extend the classification types to include L7 parameter/type, such as URL. We can also extend the classification types to include user defined types, such as ""finance department"", ""engineering department"", in the future. These named Classifiers may also be grouped together into a Composite Flow Classifier using a Boolean expression. Each operand in the Boolean expression is a named flow classifier. The operands are combined using the Boolean operators: ""and"", ""or"", ""not"". +------------------------------+ | composite_flow_classifier | +------------------------------+ | tenant_id | | id | | name | | description | | expression | +------------------------------+ The ""expression"" refers to the logical â€œandâ€, â€œorâ€, â€œnotâ€ operations on the multiple flow classifier objects, such as flow_classifier1 & (flow_classifier2 or flow_classifier3) Note that the sequence in the ""or"" list implicitly shows the ""high"" to ""low"" priority. Approach 2 ~~~~~~~~~~ The Common Classifier model should be both explicit and extensible. The figure at [1] shows the model proposed (with sample types) and an API being provided to consumers that allows classifications to be defined and referenced. Separating traffic classification in individual types will allow future types to be added and agreed in the future, while keeping the remaining ones intact. Existing types can of course be updated and properly versioned. Thus, this approach follows a modular, rather than a monolithic way of defining classifications. Looking at the existing neutron-classifier project [2], which was decided as the repo to keep the common classifier (during the Tokyo Summit 2015), there are hints of an architecture like the one proposed by this approach, as can be seen in [4]. As such, this approach is partially based on the neutron-classifier with the major difference that it aims at Neutron core and presents a REST API for users to define said classifications. Before delving into further detail in regards to the API and how classifications will be used by interested Neutron subprojects, let's clarify a few points: - This Common Classifier will include a model and a REST API; - This Common Classifier allows the definition and consumption of Classifications as Resources; - 1 Classification is of a single Type, e.g. either Ethernet, IP, HTTP, or another supported one at the time of a specific OpenStack release; - The definition, i.e. fields to match on, depends on the Type specified; - Not all supported fields need to be defined - only the ones required by the consuming service; - To keep this approach simple, the consuming service should contain any additional logic, such as: - AND/ORing many Classification if needed; - Setting directionality constraints on the Classifications, if needed; - Scoping Classifications to local resources (e.g. Neutron ports), if needed: - Creating a Classification Type to match on said local resources is certainly a possibility as well; - Other logic or local constraints; - The exact way a project will deal with these new resources is out of scope of this approach, but the expectaction is that they will support receiving UUIDs of previously defined Classifications, which they will use to acquire the actual resources from the DB, and convert these into whatever mechanism they are intended to fit (e.g. installing some OVS flows); - This approach also allows projects to evolve at their own pace, supporting only the classification types (and even specific fields) that they intend to support, while the Common Classifier can keep evolving in the future, bringing new classification types and/or fields with every OpenStack release without disrupting any dependent consumer project; - The approach intends to keep the solution as simple as possible: define Classification as resources, pass them to other projects and let them execute. As such, there is only a single user-facing resource. Approach 3 ~~~~~~~~~~ Each single classification type/rule is defined as a flow classifier object. Classifiers are expressed in the database as classifier groups, with classifier chains that link back to the classifier_group via a foreign key. The classifier_chain table is a join table that links classifier groups, to the actual classifiers. Classifier chains contain references to the classifier types, via weak references - the classifier_type column will be an enum, that contains all the classifier types. The combination of (classifier_type, classifier_type_id) is used to lookup the actual classifier. For example, a classifier_chain entry for an ethernet classifier would be recorded as ('ethernet','11111111-22222222-333333333-44444'). Classifier chains also contain a sequence, which is used to order the evaluation of classifiers in the chain. The previous database model had two fields ('outer_vlan_priority' and 'inner_vlan_priority') that were used, but the new model would have two entries in the classifier_chain table, with references to two entries in the vlan_classifier where the vlan_priority is set to the apropriate values, and the sequence number being used to determine the inner and outer vlan. Model:: +------------------------------+ | classifier_group | +------------------------------+ | tenant_id | | id | | name | | description | +------------------------------+ +---------------------+ | classifier_chain | +---------------------+ | classifier_group_id | | classifier_type | | classifier_type_id | | sequence | +---------------------+ +----------------------------+ | ip_classifier | +----------------------------+ | id | | protocol | | source_ip_prefix | | destination_ip_prefix | +----------------------------+ +-----------------+ | ipv4_classifier | +-----------------+ | id | | dscp_tag | | dscp_mask | +-----------------+ +----------------------------+ | transport_classifier | +----------------------------+ | id | | source_port_range_max | | source_port_range_min | | destination_port_range_min | | destination_port_range_max | +----------------------------+ +---------------------+ | ethernet_classifier | +---------------------+ | id | | ethertype | | source_mac | | destination_mac | +---------------------+ +-----------------+ | ipv6_classifier | +-----------------+ | id | | traffic_class | | flow_label | +-----------------+ +-----------------+ | vlan_classifier | +-----------------+ | id | | vlan_priority | +-----------------+ +--------------------------+ | encapsulation_classifier | +--------------------------+ | id | | encapsulation_type | | encapsulation_id | +--------------------------+ +--------------------------+ | neutron_port_classifier | +--------------------------+ | id | | logical_source_port | | logical_destination_port | +--------------------------+ REST APIs --------- This section describes the different REST API approaches. Approach 1 ~~~~~~~~~~ A new API extension is going to be introduced. The base URL for the Classifier API is /v2.0/classifiers/ +----------------------+---------+--------+-----------+-------------+-----------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | | Value | Conversion | | +======================+=========+========+===========+=============+=============================+ | id | string | RO, all| generated | N/A | Identity | | | (UUID) | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | tenant_id | string | RO, all| from auth | N/A | Id of tenant | | | (UUID) | | token | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | name | string | RW, all| None | string | Name of classifier | | (Required) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | description | string | RW, all| None | string | Human-readable description | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | protocol | string | RW, all| None | string | IP protocol number | | (Optional) | | | | | (icmp, tcp, udp, and so on) | | | | | | | empty means allow any | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | source_port | string | RW, all| None | string | Source port (integer in | | (Optional) | | | | | [1, 65535] or range in a:b) | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | destination_port | string | RW, all| None | string | Destination port (integer in| | (Optional) | | | | | [1, 65535] or range in a:b) | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | ethertype | string | RW, all| None | string | Ethertype | | (Optional) | | | | | (eg. IPv4, IPv6) | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | source_ip_prefix | string | RW, all| None | string | CIDR of source | | (Optional) | | | | | IP address | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | destination_ip_prefix| string | RW, all| None | string | CIDR of destination | | (Optional) | | | | | IP address | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | source_mac | string | RW, all| None | string | Source MAC address prefix | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | destination_mac | string | RW, all| None | string | Destination MAC address | | (Optional) | | | | | prefix | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | vlan_priority | int | RW, all| None | int | VLAN Priority | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | vlan_id | int | RW, all| None | int | VLAN Id | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | dscp | int | RW, all| None | int | DSCP value | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | dscp_mask | int | RW, all| None | int | DSCP mask | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | logical_source_port | string | RW, all| None | string | Neutron source port | | (Optional) | (UUID) | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | logical_destination | string | RW, all| None | string | Neutron destination port | | _port (Optional) | (UUID) | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ To achieve greater flexibility, these named Classifiers may also be grouped together into a Composite Classifier using a Boolean expression. Each operand in the expression is a named flow classifier. The operands are combined using the Boolean operators: and, or, not. Parentheses may be used in the expression for the purpose of grouping. For example: ""flow-classifier1 and (flow-classifier2 or flow-classifier3)"" The base URL for the Composite Classifier API is /v2.0/composite_classifiers/ +----------------------+---------+--------+-----------+-------------+-----------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | | Value | Conversion | | +======================+=========+========+===========+=============+=============================+ | id | string | RO, all| generated | N/A | Identity | | | (UUID) | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | tenant_id | string | RO, all| from auth | N/A | Id of tenant | | | (UUID) | | token | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | name | string | RW, all| None | string | Name of Composite Classifier| | (Required) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | description | string | RW, all| None | string | Human-readable description | | (Optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | expression | string | RW, all| None | string | Boolean expression of named | | | | | | | classifier operands which | | | | | | | are combined using Boolean | | | | | | | operators: and, or, not. | +----------------------+---------+--------+-----------+-------------+-----------------------------+ Flow Classifier API methods: +----------+----------------------------------+----------------------------------+ |Operation |URL |Description | +==========+==================================+==================================+ |POST |/v2.0/classifiers |Create a Classifier | +----------+----------------------------------+----------------------------------+ |PUT |/v2.0/classifiers/{id} |Update a specific Classifier | +----------+----------------------------------+----------------------------------+ |DEL |/v2.0/classifiers/{id} |Delete a specific Classifier | +----------+----------------------------------+----------------------------------+ |GET |/v2.0/classifiers/ |Get all Classifiers | +----------+----------------------------------+----------------------------------+ |GET |/v2.0/classifiers/{id} |Show information for a Classifier | +----------+----------------------------------+----------------------------------+ Composite Flow Classifier API methods: +----------+----------------------------------+----------------------------------+ |Operation |URL |Description | +==========+==================================+==================================+ |POST |/v2.0/composite_classifiers |Create a Composite Classifier | +----------+----------------------------------+----------------------------------+ |PUT |/v2.0/composite_classifiers/{id} |Update a specific Composite | | | |Classifier | +----------+----------------------------------+----------------------------------+ |DEL |/v2.0/composite_classifiers/{id} |Delete a specific Composite | | | |Classifier | +----------+----------------------------------+----------------------------------+ |GET |/v2.0/composite_classifiers/ |Get all Composite Classifiers | +----------+----------------------------------+----------------------------------+ |GET |/v2.0/composite_classifiers/{id} |Show information for a Composite | | | |Classifier | +----------+----------------------------------+----------------------------------+ Approach 2 ~~~~~~~~~~ A new API extension is going to be introduced. The base URL for the Common Classifier API is /v2.0/classifications/. The following table presents the API fields prior to any serialization into JSON. +----------------------+---------+--------+-----------+-------------+-----------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | | Value | Conversion | | +======================+=========+========+===========+=============+=============================+ | id | string | RO, all| generated | uuid | Identity | | | (UUID) | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | tenant_id | string | RO, all| from auth | uuid | Id of tenant | | | (UUID) | | token | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | name | string | RW, all| None | string | Name of classification | | (required) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | description | string | RW, all| None | string | Human-readable description | | (optional) | | | | | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ | definition | object | RW, all| None | by Type's | Definition of Classification| | (required) | | | | class && | based on specified Type | | | | | | single Type | | +----------------------+---------+--------+-----------+-------------+-----------------------------+ This would be serialized, using oslo.versionedobjects/oslo.serialization, into the following possible sample JSON:: { ""classification"": { ""id"": ""066b1123-da25-44ff-9130-f8ff92c14cd5"", ""tenant_id"": ""3786020b-9b3c-45e1-b5d6-e2f654678b12"", ""name"": ""ipsec_ipv4"", ""description: ""A relevant description"", ""definition"": { ""ip"": { ""version"": ""4"", ""protocol"": ""50"", ""src_addr"": ""1.1.1.0/24"", ""dst_addr"": ""2.2.2.0/24 } } } } Furthermore, projects would be able to consume these classifications by adding support for Classification IDs to be passed via their own APIs. Possible CLI syntax: ``$ neutron classification-create syns --type=tcp --definition=flag_syn=1`` ``$ neutron qos-bandwidth-limit-rule-create --max-kbps 8000 --classification syns myqospolicy`` The classes that define each type would include every possible field to be matched on, but any subset of them can be used when building a new definition through the API. As an example, ideally, the IP class/type could support every header field, and indirect masking fields, presented in RFC 791. Approach 3 (WIP) ~~~~~~~~~~~~~~~~ This has not as yet been defined, however, the API could include: 1. CRUD operations for individual ""type"" rules. 2. CRUD operations combine the individual rules Comparison ---------- Cathy/Louis: The Approach 1 classifier has the advantage that it is simpler, has less levels of hierarchy, and has the ""not"" operation. For example, since Approach 1 classifier combines all the required classification rules in the flow classifier resource, a single REST API request is needed to create a flow-classifier. In Approach 3, it seems separate REST calls would be required to create the rules for a flow classifier. Other APIs are needed to create the classifier group and the classifier chain (Not very sure about this). As to the differences in terms of adding additional parameters for the classifier, in Approach 1, a new attribute would be added to the flow classifier resource in the database while in Approach 3, a new ""type"" rule resource would be added to the database and that rule resource would need to be added to the classifier group. Igor: Regarding Approach 2, some important advantages are described in Approach 2's Data Model Impact. In essence, the major advantages are the fact that the definition of classifications is not monolithic, by scoping the fields to match in different types/protocols; and the fact that Classifications attempt to be as simple as possible and act as small Resources that can be used and reused in an on-demand, cloud-friendly way. A possible use case that can be extracted from this is having the cloud administrator create a set of Classifications that can be available for consumption by tenants, which would count towards their quota. Community: Thoughts? Implementation ============== Assignee(s) ----------- * Cathy Zhang (cathy.h.zhang@huawei.com) * Igor Duarte Cardoso (igor.duarte.cardoso@intel.com) * Louis Fourie (louis.fourie@huawei.com) References ========== .. [0] (spec) Add common classifier resource: https://review.openstack.org/#/c/190463/ .. [1] Approach 2: Model and API view: http://i.imgur.com/4reoOnB.png .. [2] The neutron-classifier project: http://git.openstack.org/cgit/openstack/neutron-classifier .. [3] The original and current RFE to bring a common classifier to Neutron: https://bugs.launchpad.net/neutron/+bug/1476527 .. [4] Approach 2: neutron-classifier inspiration: https://github.com/openstack/neutron-classifier/blob/10b2eb3127f4809e52e3cf1627c34228bca80101/neutron_classifier/common/constants.py#L17 ",,526,0
openstack%2Ftripleo-heat-templates~master~I76f188438bfc6449b152c2861d99738e6eb3c61b,openstack/tripleo-heat-templates,master,I76f188438bfc6449b152c2861d99738e6eb3c61b,Remove duplicate docker/puppet services.yaml,MERGED,2017-06-09 10:03:52.000000000,2017-06-17 09:46:33.000000000,2017-06-17 09:46:33.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 10873}, {'_account_id': 13039}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 19741}]","[{'number': 1, 'created': '2017-06-09 10:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/459d5bd33907ce75dcef82d523f978326c68fe75', 'message': 'Remove duplicate docker/puppet services.yaml\n\nMove to one common services.yaml not only reduces the duplication, but it\nshould improve performance for the docker/services.yaml case, because we were\ncreating two ResourceChains with $many services which we know can be really\nslow (especially since we seem to be missing concurrent: true on one)\n\nChange-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b\n'}, {'number': 2, 'created': '2017-06-09 10:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c9d2e9601cc5013d6442b59007d2f2753fc2c7a1', 'message': 'Remove duplicate docker/puppet services.yaml\n\nMove to one common services.yaml not only reduces the duplication, but it\nshould improve performance for the docker/services.yaml case, because we were\ncreating two ResourceChains with $many services which we know can be really\nslow (especially since we seem to be missing concurrent: true on one)\n\nChange-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b\n'}, {'number': 3, 'created': '2017-06-09 11:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eec8c2977c65db39e15dd2e64e485b97bd596b2f', 'message': 'Remove duplicate docker/puppet services.yaml\n\nMove to one common services.yaml not only reduces the duplication, but it\nshould improve performance for the docker/services.yaml case, because we were\ncreating two ResourceChains with $many services which we know can be really\nslow (especially since we seem to be missing concurrent: true on one)\n\nChange-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b\n'}, {'number': 4, 'created': '2017-06-09 16:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/800a56ce6862d30a90c2675f499aae7d809160ec', 'message': 'Remove duplicate docker/puppet services.yaml\n\nMove to one common services.yaml not only reduces the duplication, but it\nshould improve performance for the docker/services.yaml case, because we were\ncreating two ResourceChains with $many services which we know can be really\nslow (especially since we seem to be missing concurrent: true on one)\n\nChange-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b\n'}, {'number': 5, 'created': '2017-06-09 16:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/37c7feddd53e7332cf77e1089586d5ff2c496d4b', 'message': 'Remove duplicate docker/puppet services.yaml\n\nMove to one common services.yaml not only reduces the duplication, but it\nshould improve performance for the docker/services.yaml case, because we were\ncreating two ResourceChains with $many services which we know can be really\nslow (especially since we seem to be missing concurrent: true on one)\n\nChange-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b\n'}, {'number': 6, 'created': '2017-06-09 16:11:00.000000000', 'files': ['common/README', 'docker/services/services.yaml', 'environments/docker.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'services.yaml', 'environments/docker-services-tls-everywhere.yaml', 'tools/yaml-validate.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/316cc2572d0a255d466fb7f9aa74de3b8ccb6831', 'message': 'Remove duplicate docker/puppet services.yaml\n\nMove to one common services.yaml not only reduces the duplication, but it\nshould improve performance for the docker/services.yaml case, because we were\ncreating two ResourceChains with $many services which we know can be really\nslow (especially since we seem to be missing concurrent: true on one)\n\nChange-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b\n'}]",6,472618,316cc2572d0a255d466fb7f9aa74de3b8ccb6831,47,8,6,4328,,,0,"Remove duplicate docker/puppet services.yaml

Move to one common services.yaml not only reduces the duplication, but it
should improve performance for the docker/services.yaml case, because we were
creating two ResourceChains with $many services which we know can be really
slow (especially since we seem to be missing concurrent: true on one)

Change-Id: I76f188438bfc6449b152c2861d99738e6eb3c61b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/472618/6 && git format-patch -1 --stdout FETCH_HEAD,"['common/services.yaml', 'docker/services/services.yaml', 'environments/docker.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'environments/docker-services-tls-everywhere.yaml', 'tools/yaml-validate.py']",6,459d5bd33907ce75dcef82d523f978326c68fe75,services_test, filename not in ['./puppet/services/qdr.yaml']): if (filename.startswith('./docker/services/'):," filename not in ['./puppet/services/services.yaml', './puppet/services/qdr.yaml']): if (filename.startswith('./docker/services/') and filename != './docker/services/services.yaml'):",17,115
openstack%2Fneutron~stable%2Fnewton~Icf676059a0dd24ad18b8632563c4de81190f0d04,openstack/neutron,stable/newton,Icf676059a0dd24ad18b8632563c4de81190f0d04,Add missing unit test for segment db,MERGED,2017-06-14 16:09:51.000000000,2017-06-17 09:23:08.000000000,2017-06-17 09:23:08.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 12860}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-14 16:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/24272995d3ce282ca42100712e65877cd6ebbf1d', 'message': 'Add missing unit test for segment db\n\nThis patch add test for get_dynamic_segment.\n\nChange-Id: Icf676059a0dd24ad18b8632563c4de81190f0d04\nCloses-Bug: #1684519\n(cherry picked from commit 8595a017028450ba1c5f7cd0da4e6a9bd624666e)\n'}, {'number': 2, 'created': '2017-06-15 18:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/35645a073fd18fe821bc5b2cbca5f4db7e0fbda5', 'message': 'Add missing unit test for segment db\n\nThis patch add test for get_dynamic_segment.\n\nNewton changes: get_dynamic_segments receives session as the first\nargument, not context.\n\nChange-Id: Icf676059a0dd24ad18b8632563c4de81190f0d04\nCloses-Bug: #1684519\n(cherry picked from commit 8595a017028450ba1c5f7cd0da4e6a9bd624666e)\n'}, {'number': 3, 'created': '2017-06-15 19:20:45.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/00ac588968c62c5c47acee558a69142ca94505dc', 'message': 'Add missing unit test for segment db\n\nThis patch add test for get_dynamic_segment.\n\nNewton changes: get_dynamic_segments receives session as the first\nargument, not context.\n\nChange-Id: Icf676059a0dd24ad18b8632563c4de81190f0d04\nCloses-Bug: #1684519\n(cherry picked from commit 8595a017028450ba1c5f7cd0da4e6a9bd624666e)\n'}]",0,474268,00ac588968c62c5c47acee558a69142ca94505dc,16,7,3,9656,,,0,"Add missing unit test for segment db

This patch add test for get_dynamic_segment.

Newton changes: get_dynamic_segments receives session as the first
argument, not context.

Change-Id: Icf676059a0dd24ad18b8632563c4de81190f0d04
Closes-Bug: #1684519
(cherry picked from commit 8595a017028450ba1c5f7cd0da4e6a9bd624666e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/474268/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/plugins/ml2/test_db.py'],1,24272995d3ce282ca42100712e65877cd6ebbf1d,bug/1684519," def test_get_dynamic_segment(self): net_id = uuidutils.generate_uuid() segment1 = {api.NETWORK_TYPE: 'vlan', api.PHYSICAL_NETWORK: 'physnet1', api.SEGMENTATION_ID: 1} self._create_segments( [segment1], is_seg_dynamic=True, network_id=net_id) segs1 = segments_db.get_dynamic_segment( self.ctx, net_id) self.assertEqual('vlan', segs1[api.NETWORK_TYPE]) self.assertEqual('physnet1', segs1[api.PHYSICAL_NETWORK]) self.assertEqual(1, segs1[api.SEGMENTATION_ID]) segs2 = segments_db.get_dynamic_segment( self.ctx, net_id, physical_network='physnet1') self.assertEqual('vlan', segs2[api.NETWORK_TYPE]) self.assertEqual('physnet1', segs2[api.PHYSICAL_NETWORK]) self.assertEqual(1, segs2[api.SEGMENTATION_ID]) segs3 = segments_db.get_dynamic_segment( self.ctx, net_id, segmentation_id=1) self.assertEqual('vlan', segs3[api.NETWORK_TYPE]) self.assertEqual('physnet1', segs3[api.PHYSICAL_NETWORK]) self.assertEqual(1, segs3[api.SEGMENTATION_ID]) ",,27,0
openstack%2Fneutron~master~I1df870258fad2fb0f01c6bd34685efcb89acf4ce,openstack/neutron,master,I1df870258fad2fb0f01c6bd34685efcb89acf4ce,Add a missing _LW(),MERGED,2017-06-15 16:07:47.000000000,2017-06-17 09:22:53.000000000,2017-06-17 09:22:53.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-06-15 16:07:47.000000000', 'files': ['neutron/agent/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b212951e17aa96eaf1c8b2652c7fef528be18cd4', 'message': 'Add a missing _LW()\n\nMissed a _LW() in a recent ip_lib change.\n\nTrivalfix\n\nChange-Id: I1df870258fad2fb0f01c6bd34685efcb89acf4ce\n'}]",0,474624,b212951e17aa96eaf1c8b2652c7fef528be18cd4,14,5,1,1131,,,0,"Add a missing _LW()

Missed a _LW() in a recent ip_lib change.

Trivalfix

Change-Id: I1df870258fad2fb0f01c6bd34685efcb89acf4ce
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/474624/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ip_lib.py'],1,b212951e17aa96eaf1c8b2652c7fef528be18cd4,log-warning-i18n," LOG.warning(_LW(""Interface %s might have been deleted "" ""concurrently""), iface_name)"," LOG.warning(""Interface %s might have been deleted "" ""concurrently"", iface_name)",2,2
openstack%2Fpuppet-nova~master~I19d06e1449f52343a4fbda0fbe2622c397c40720,openstack/puppet-nova,master,I19d06e1449f52343a4fbda0fbe2622c397c40720,Changed author,MERGED,2017-06-12 07:08:33.000000000,2017-06-17 09:20:13.000000000,2017-06-17 09:20:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-12 07:08:33.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ce9a9fe75b25edcae8368b3f90c5b857a21a3da2', 'message': 'Changed author\n\nChanged author to OpenStack\n\nChange-Id: I19d06e1449f52343a4fbda0fbe2622c397c40720\n'}]",0,473238,ce9a9fe75b25edcae8368b3f90c5b857a21a3da2,25,3,1,22255,,,0,"Changed author

Changed author to OpenStack

Change-Id: I19d06e1449f52343a4fbda0fbe2622c397c40720
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/38/473238/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ce9a9fe75b25edcae8368b3f90c5b857a21a3da2,fix_author,author = OpenStack,author = Puppet Labs and OpenStack Contributors,1,1
openstack%2Fneutron~master~I756594d4d2cc6a63e2ecfdf713f18bebdffeb4d2,openstack/neutron,master,I756594d4d2cc6a63e2ecfdf713f18bebdffeb4d2,Remove unreachable code in OVS mech driver,MERGED,2017-06-14 09:13:37.000000000,2017-06-17 09:17:50.000000000,2017-06-17 09:17:50.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 10385}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 18051}, {'_account_id': 20330}, {'_account_id': 22255}]","[{'number': 1, 'created': '2017-06-14 09:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec05197a700d786dfff0118b8133b013e477f6e2', 'message': 'Remove unreachable code in OVS mech driver\n\nRemoved an unreachable section of code in OpenvswitchMechanismDriver.\n\nTrivial-Fix\n\nChange-Id: I756594d4d2cc6a63e2ecfdf713f18bebdffeb4d2\n'}, {'number': 2, 'created': '2017-06-15 14:05:18.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/mech_driver/mech_openvswitch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7064e587dbea0db0e0de25afc4a68d6a05ccc67c', 'message': 'Remove unreachable code in OVS mech driver\n\nRemoved an unreachable section of code in OpenvswitchMechanismDriver.\n\nTrivial-Fix\n\nChange-Id: I756594d4d2cc6a63e2ecfdf713f18bebdffeb4d2\n'}]",0,474127,7064e587dbea0db0e0de25afc4a68d6a05ccc67c,33,11,2,16688,,,0,"Remove unreachable code in OVS mech driver

Removed an unreachable section of code in OpenvswitchMechanismDriver.

Trivial-Fix

Change-Id: I756594d4d2cc6a63e2ecfdf713f18bebdffeb4d2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/474127/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/openvswitch/mech_driver/mech_openvswitch.py'],1,ec05197a700d786dfff0118b8133b013e477f6e2,bug/1632372,, return self.vif_details,0,1
openstack%2Fnova~master~I252f362257f51b2e001bd07ed624a526ac6aaa3b,openstack/nova,master,I252f362257f51b2e001bd07ed624a526ac6aaa3b,Re-worked ram filter and weights to support overcommit,ABANDONED,2016-10-26 22:36:21.000000000,2017-06-17 09:07:42.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 11642}, {'_account_id': 12175}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17292}, {'_account_id': 20040}, {'_account_id': 22623}, {'_account_id': 23214}, {'_account_id': 26049}, {'_account_id': 26220}, {'_account_id': 26221}]","[{'number': 1, 'created': '2016-10-26 22:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9ea43e888a46c695189274aa08c370c04806de3', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: 1635367\n'}, {'number': 2, 'created': '2016-10-27 01:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4071882a5d7ed80f192c5a86c746f868fb6a151', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: 1635367\n'}, {'number': 3, 'created': '2016-10-28 00:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c1761b0219d41e1d3bd9a434ef6bf52ff13d253', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: 1635367\n'}, {'number': 4, 'created': '2016-10-29 01:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/656a84283d5d82444cd144fc0cc649bfccd8045d', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: 1635367\n'}, {'number': 5, 'created': '2016-11-02 21:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48110976aa5427c9cc5c1863e4bccf1e69f3f6a6', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: 1635367\n'}, {'number': 6, 'created': '2017-05-18 05:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d5ee3a1c9a49276686bad6dadde7b8cb9860a36', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 7, 'created': '2017-05-18 06:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/832c9f292644e78a5d676121ccb6c28555153da1', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 8, 'created': '2017-06-07 07:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/943c231223dcf44ec335f73163e757c48d6ce6f1', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 9, 'created': '2017-06-14 22:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6af92fa9d13b52b49305e22322b7badb2fa6aff2', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 10, 'created': '2017-06-15 00:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22749670d695731c5dc31ccb4d0a7757c4154646', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 11, 'created': '2017-06-15 00:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6b3f59607e72829b9a0faa85493845caebb23a17', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 12, 'created': '2017-06-15 01:03:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/469ba27b5d28123fe7974b7eae0ee3ec69635cd3', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 13, 'created': '2017-06-15 07:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/438c9869400f7c4b160c18071dee71a00b86c4ea', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 14, 'created': '2017-06-15 19:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d47a025c093ecd14bc47d92ab68d046e0b377410', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}, {'number': 15, 'created': '2017-06-16 00:12:48.000000000', 'files': ['nova/tests/unit/scheduler/weights/test_weights_ram.py', 'nova/tests/unit/scheduler/test_host_manager.py', 'nova/tests/unit/scheduler/filters/test_ram_filters.py', 'nova/scheduler/weights/ram.py', 'nova/tests/unit/scheduler/fakes.py', 'nova/conductor/tasks/live_migrate.py', 'nova/scheduler/filters/ram_filter.py', 'releasenotes/notes/weights-e054b35b10054886.yaml', 'nova/scheduler/host_manager.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5486daf2c01f6122e531c5114a607538d47ee72c', 'message': 'Re-worked ram filter and weights to support overcommit\n\nThis patch moves the free_ram_mb calculations directly\nto the filter/weights.\n\nChange-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b\nCloses-Bug: #1635367\n'}]",12,390984,5486daf2c01f6122e531c5114a607538d47ee72c,191,30,15,22623,,,0,"Re-worked ram filter and weights to support overcommit

This patch moves the free_ram_mb calculations directly
to the filter/weights.

Change-Id: I252f362257f51b2e001bd07ed624a526ac6aaa3b
Closes-Bug: #1635367
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/390984/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/weights/test_weights_ram.py', 'nova/tests/unit/scheduler/filters/test_ram_filters.py', 'nova/scheduler/weights/ram.py', 'nova/conductor/tasks/live_migrate.py', 'nova/scheduler/filters/ram_filter.py', 'nova/scheduler/host_manager.py']",6,f9ea43e888a46c695189274aa08c370c04806de3,bug/1635367, self.memory_mb_used = 0 self.memory_mb_used = compute.memory_mb_used , # NOTE(jogo) free_ram_mb can be negative,29,24
openstack%2Fnova~master~Ifb14f0d61aaf89bee6c5ba74d09dd936bd318fbc,openstack/nova,master,Ifb14f0d61aaf89bee6c5ba74d09dd936bd318fbc,Updated from global requirements,MERGED,2017-06-15 16:30:01.000000000,2017-06-17 08:26:54.000000000,2017-06-15 21:38:31.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}]","[{'number': 1, 'created': '2017-06-15 16:30:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/b2f23591190daa87a2212bb5b42d66417b6a5877', 'message': 'Updated from global requirements\n\nChange-Id: Ifb14f0d61aaf89bee6c5ba74d09dd936bd318fbc\n'}]",0,474672,b2f23591190daa87a2212bb5b42d66417b6a5877,20,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ifb14f0d61aaf89bee6c5ba74d09dd936bd318fbc
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/474672/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b2f23591190daa87a2212bb5b42d66417b6a5877,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fneutron~master~Ic3b149ec5dfdc732a4b5851237389abaef8992b7,openstack/neutron,master,Ic3b149ec5dfdc732a4b5851237389abaef8992b7,"Add ""default"" behaviour to QoS policies documentation",MERGED,2017-06-15 08:04:56.000000000,2017-06-17 08:03:53.000000000,2017-06-17 08:03:53.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7787}]","[{'number': 1, 'created': '2017-06-15 08:04:56.000000000', 'files': ['doc/source/devref/quality_of_service.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e87e4ab0dfe99bb594142efcb0f85ec8a573ee1', 'message': 'Add ""default"" behaviour to QoS policies documentation\n\nAdded devref documentation related to the ""default"" behaviour\nfor QoS policies.\n\nChange-Id: Ic3b149ec5dfdc732a4b5851237389abaef8992b7\nCloses-Bug: #1694298\n'}]",0,474479,3e87e4ab0dfe99bb594142efcb0f85ec8a573ee1,10,3,1,16688,,,0,"Add ""default"" behaviour to QoS policies documentation

Added devref documentation related to the ""default"" behaviour
for QoS policies.

Change-Id: Ic3b149ec5dfdc732a4b5851237389abaef8992b7
Closes-Bug: #1694298
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/474479/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/quality_of_service.rst'],1,3e87e4ab0dfe99bb594142efcb0f85ec8a573ee1,bug/1694298,"Each project can have at most one default QoS policy, although is not mandatory. If a default QoS policy is defined, all new networks created within this project will have assigned this policy, as long as no other QoS policy is explicitly attached during the creation process. If the default QoS policy is unset, no change to existing networks will be made. * QosPolicyDefault: defines a default QoS policy per project.* QosPolicyDefault: defines a default QoS policy per project.",,8,0
openstack%2Fnetworking-hyperv~master~I9e7f41f9c5989af169fdfa0e014daf6450248f8a,openstack/networking-hyperv,master,I9e7f41f9c5989af169fdfa0e014daf6450248f8a,SecurityGroups: Clears port from device cache,MERGED,2017-05-30 07:44:18.000000000,2017-06-17 07:58:16.000000000,2017-06-17 07:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 17019}]","[{'number': 1, 'created': '2017-05-30 07:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/595cf19ab148559c3317abe44c2d0e419a49252e', 'message': 'WIP: SecurityGroups: Clears port from device cache\n\nChange-Id: I9e7f41f9c5989af169fdfa0e014daf6450248f8a\n'}, {'number': 2, 'created': '2017-05-30 11:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/5b3779b7c32b89482b602296c828f95cd39f271c', 'message': 'WIP: SecurityGroups: Clears port from device cache\n\nChange-Id: I9e7f41f9c5989af169fdfa0e014daf6450248f8a\n'}, {'number': 3, 'created': '2017-05-30 16:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/39b6ab938773a4b4efdc38d06e986c97b45f763b', 'message': 'WIP: SecurityGroups: Clears port from device cache\n\nChange-Id: I9e7f41f9c5989af169fdfa0e014daf6450248f8a\n'}, {'number': 4, 'created': '2017-05-31 09:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/219dd07572f45bdf2dda49cb3fd25edddb267a17', 'message': ""SecurityGroups: Clears port from device cache\n\nWhen an instance is being rebuilt, or shelved and unshelved,\nthe VM gets destroyed and recreated, keeping the same neutron port.\n\nneutron-ovs-agent doesn't tear down the port, and doesn't notify\nthe HyperVSecurityGroupsDriver that the switch port has been recreated\nin any way, which will cause issues when adding the security group rules;\nmost notably, the default reject rules and the previously existing\nsecurity group rules wouldn't be added.\n\nThis patch pops the _sec_group_rules and _security_ports caches before\nreraising the os_win.exceptions.NotFound exception, after which\nneutron-ovs-agent will retry the port binding.\n\nThis issue doesn't affect the neutron-hyperv-agent, which notifies the\nHyperVSecurityGroupsDriver when a port gets removed, updating its\ncaches accordingly.\n\nCloses-Bug: #1694432\n\nChange-Id: I9e7f41f9c5989af169fdfa0e014daf6450248f8a\n""}, {'number': 5, 'created': '2017-06-16 13:40:56.000000000', 'files': ['hyperv/neutron/security_groups_driver.py', 'hyperv/tests/unit/neutron/test_security_groups_driver.py', 'hyperv/neutron/_common_utils.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/d66301dcdd13ee24f5a0240aa57e094cfb8dd5af', 'message': ""SecurityGroups: Clears port from device cache\n\nWhen an instance is being rebuilt, or shelved and unshelved,\nthe VM gets destroyed and recreated, keeping the same neutron port.\n\nneutron-ovs-agent doesn't tear down the port, and doesn't notify\nthe HyperVSecurityGroupsDriver that the switch port has been recreated\nin any way, which will cause issues when adding the security group rules;\nmost notably, the default reject rules and the previously existing\nsecurity group rules wouldn't be added.\n\nThis patch pops the _sec_group_rules and _security_ports caches before\nreraising the os_win.exceptions.NotFound exception, after which\nneutron-ovs-agent will retry the port binding.\n\nThis issue doesn't affect the neutron-hyperv-agent, which notifies the\nHyperVSecurityGroupsDriver when a port gets removed, updating its\ncaches accordingly.\n\nCloses-Bug: #1694432\n\nChange-Id: I9e7f41f9c5989af169fdfa0e014daf6450248f8a\n""}]",2,469010,d66301dcdd13ee24f5a0240aa57e094cfb8dd5af,27,4,5,8213,,,0,"SecurityGroups: Clears port from device cache

When an instance is being rebuilt, or shelved and unshelved,
the VM gets destroyed and recreated, keeping the same neutron port.

neutron-ovs-agent doesn't tear down the port, and doesn't notify
the HyperVSecurityGroupsDriver that the switch port has been recreated
in any way, which will cause issues when adding the security group rules;
most notably, the default reject rules and the previously existing
security group rules wouldn't be added.

This patch pops the _sec_group_rules and _security_ports caches before
reraising the os_win.exceptions.NotFound exception, after which
neutron-ovs-agent will retry the port binding.

This issue doesn't affect the neutron-hyperv-agent, which notifies the
HyperVSecurityGroupsDriver when a port gets removed, updating its
caches accordingly.

Closes-Bug: #1694432

Change-Id: I9e7f41f9c5989af169fdfa0e014daf6450248f8a
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/10/469010/4 && git format-patch -1 --stdout FETCH_HEAD,['hyperv/neutron/security_groups_driver.py'],1,595cf19ab148559c3317abe44c2d0e419a49252e,," # NOTE(claudiub): In the case of a rebuild / shelve, the # neutron port is not deleted, and it can still be in the cache. # we need to pop in, so when the ports needs to be readded, all # the security group rules are reapplied to it. port = self._sec_group_rules.pop(port_id, {}) self._security_ports.pop(port.get('device_id'), None) port = self._sec_group_rules.pop(port_id, {}) self._security_ports.pop(port.get('device_id'), None) self._security_ports.pop(port['device_id'], None)"," self._sec_group_rules.pop(port_id, None) self._sec_group_rules.pop(port_id, None)",9,2
openstack%2Fkolla-ansible~master~Ie5632d0d99b1708deb3063ea473d345f319764ad,openstack/kolla-ansible,master,Ie5632d0d99b1708deb3063ea473d345f319764ad,Insert a blank line.,ABANDONED,2017-05-19 06:10:27.000000000,2017-06-17 07:18:32.000000000,,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 8157}, {'_account_id': 11869}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 23717}]","[{'number': 1, 'created': '2017-05-19 06:10:27.000000000', 'files': ['tools/validate-all-file.py'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2a747881d7d81255d807fb321e4a8102ea2172c0', 'message': 'Insert a blank line.\n\nChange-Id: Ie5632d0d99b1708deb3063ea473d345f319764ad\n'}]",1,466195,2a747881d7d81255d807fb321e4a8102ea2172c0,17,9,1,25376,,,0,"Insert a blank line.

Change-Id: Ie5632d0d99b1708deb3063ea473d345f319764ad
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/95/466195/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/validate-all-file.py'],1,2a747881d7d81255d807fb321e4a8102ea2172c0,Fix,,,1,0
openstack%2Fnova~master~I0583400b546d3cb32f2fe828711df8272c5ab5af,openstack/nova,master,I0583400b546d3cb32f2fe828711df8272c5ab5af,Add PowerVM to nova support matrix,MERGED,2017-06-05 14:58:48.000000000,2017-06-17 07:07:25.000000000,2017-06-15 20:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8190}, {'_account_id': 10608}, {'_account_id': 13883}, {'_account_id': 13915}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16710}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-06-05 14:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef9850bfee23d98deb3cd3e2d774777f990ed257', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/q/topic:bp/powervm-nova-compute-driver+status:merged+project:openstack/nova\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}, {'number': 2, 'created': '2017-06-05 15:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f4e7362c534f7be3f6cd75bb3792aef09589264', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/q/topic:bp/powervm-nova-compute-driver+status:merged+project:openstack/nova\n\nCloses-Bug: #1693083\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}, {'number': 3, 'created': '2017-06-06 13:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/677cde2834e38ee63f84e5073b1e4a05329432f5', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/q/topic:bp/powervm-nova-compute-driver+status:merged+project:openstack/nova\n\nCloses-Bug: #1693083\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}, {'number': 4, 'created': '2017-06-06 15:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0327c8fcce9b4e150d2cab619189476bad9b2290', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/q/topic:bp/powervm-nova-compute-driver+status:merged+project:openstack/nova\n\nCloses-Bug: #1693083\nPartially-Implements: blueprint powervm-nova-compute-driver\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}, {'number': 5, 'created': '2017-06-06 15:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/743a63363c006b7cefa347cac7cd4edf338105b8', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1-7]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/c/438119/\n[2] https://review.openstack.org/#/c/438598/\n[3] https://review.openstack.org/#/c/438729/\n[4] https://review.openstack.org/#/c/427380/\n[5] https://review.openstack.org/#/c/391288/\n[6] https://review.openstack.org/#/c/409402/\n[7] https://review.openstack.org/#/c/443189/\n\nCloses-Bug: #1693083\nPartially-Implements: blueprint powervm-nova-compute-driver\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}, {'number': 6, 'created': '2017-06-07 20:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d722490fbab2464f6f36d038cbeb95e865f2ed3d', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1-7]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/c/438119/\n[2] https://review.openstack.org/#/c/438598/\n[3] https://review.openstack.org/#/c/438729/\n[4] https://review.openstack.org/#/c/427380/\n[5] https://review.openstack.org/#/c/391288/\n[6] https://review.openstack.org/#/c/409402/\n[7] https://review.openstack.org/#/c/443189/\n\nCloses-Bug: #1693083\nPartially-Implements: blueprint powervm-nova-compute-driver\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}, {'number': 7, 'created': '2017-06-15 13:38:52.000000000', 'files': ['doc/source/support-matrix.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/0fbb97f3c3947c4d0f7c4b05db9cb1fd07139b9d', 'message': 'Add PowerVM to nova support matrix\n\nBase PowerVM support has been added to nova [1-7]. This updates the\nsupport matrix to include PowerVM features.\n\n[1] https://review.openstack.org/#/c/438119/\n[2] https://review.openstack.org/#/c/438598/\n[3] https://review.openstack.org/#/c/438729/\n[4] https://review.openstack.org/#/c/427380/\n[5] https://review.openstack.org/#/c/391288/\n[6] https://review.openstack.org/#/c/409402/\n[7] https://review.openstack.org/#/c/443189/\n\nCloses-Bug: #1693083\nPartially-Implements: blueprint powervm-nova-compute-driver\n\nChange-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af\n'}]",37,470999,0fbb97f3c3947c4d0f7c4b05db9cb1fd07139b9d,64,15,7,16710,,,0,"Add PowerVM to nova support matrix

Base PowerVM support has been added to nova [1-7]. This updates the
support matrix to include PowerVM features.

[1] https://review.openstack.org/#/c/438119/
[2] https://review.openstack.org/#/c/438598/
[3] https://review.openstack.org/#/c/438729/
[4] https://review.openstack.org/#/c/427380/
[5] https://review.openstack.org/#/c/391288/
[6] https://review.openstack.org/#/c/409402/
[7] https://review.openstack.org/#/c/443189/

Closes-Bug: #1693083
Partially-Implements: blueprint powervm-nova-compute-driver

Change-Id: I0583400b546d3cb32f2fe828711df8272c5ab5af
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/470999/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/support-matrix.ini'],1,ef9850bfee23d98deb3cd3e2d774777f990ed257,pvm_support_matrix,driver-impl-powervm=PowerVMdriver-impl-powervm=completedriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=completedriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missingdriver-impl-powervm=missing,,47,0
openstack%2Fopenstack-ansible-plugins~master~I684a11f4380f91b1cb0585f38817859dfaa68f80,openstack/openstack-ansible-plugins,master,I684a11f4380f91b1cb0585f38817859dfaa68f80,connection: ssh: Clear environment when connecting to LXC containers,MERGED,2017-06-07 14:58:20.000000000,2017-06-17 07:06:56.000000000,2017-06-13 13:00:45.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-07 14:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/c6d5a1af9cacc15cf726ab36841bf2539efa6ae3', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 2, 'created': '2017-06-07 17:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/16c676c165727bfefd8edb30871985e1439c8372', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 3, 'created': '2017-06-07 18:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/868e7cb66fd0358ee1a97e7d7fa17f5869695a96', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 4, 'created': '2017-06-07 21:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/25de985f7cfdce98b4f8e77723a0448f3538abac', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 5, 'created': '2017-06-08 09:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/6b1a862dc3f4d72f200f871d02eec76170b63696', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}, {'number': 6, 'created': '2017-06-13 12:47:09.000000000', 'files': ['connection/ssh.py'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/1c7cb99fcc172486f482cfdce4058f8c577f82dc', 'message': 'connection: ssh: Clear environment when connecting to LXC containers\n\nWe should clear the environment before connecting to an LXC container to\navoid inheriting host variables that may break container services like\nthe following failure in rabbitmqctl:\n\nTASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************\nfatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown\\n\\nDIAGNOSTICS\\n===========\\n\\nattempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']\\n\\nrabbit@vagrant-openSUSE-Leap:\\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\\n\\n\\ncurrent node details:\\n- node name: \'rabbitmq-cli-82@localhost\'\\n- home dir: /var/lib/rabbitmq\\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node \'rabbit@vagrant-openSUSE-Leap\': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: [\'rabbit@vagrant-openSUSE-Leap\']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: \'rabbitmq-cli-82@localhost\'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node \'rabbit@vagrant-openSUSE-Leap\' ..."", ""stdout_lines"": [""Status of node \'rabbit@vagrant-openSUSE-Leap\' ...""]}\n\tto retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry\n\nThe reason for this failure is that the HOSTNAME variable is being\ninherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl\ncommand uses this variable to guess the host it should try to\nconnect to.\n\nThis is similar to what the upstream lxc connection module is doing.\n\nThis is an attempt to fix problems introduced in\nhttps://review.openstack.org/#/c/471472/ and subsequently\nreverted in https://review.openstack.org/#/c/471713/\n\nThe reason for these failures was that \'lxc-attach\' executed commands\nwhich assumed that basic variables like HOME are set properly. However,\n--clear-env didn\'t preserve these variables so various operations started\nto fail. In order to fix that, it\'s best if we start a real login shell\nusing \'su\' in order to mimic an expected user environment when executing\ncommands within the container.\n\nChange-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80\n'}]",0,471810,1c7cb99fcc172486f482cfdce4058f8c577f82dc,24,9,6,23163,,,0,"connection: ssh: Clear environment when connecting to LXC containers

We should clear the environment before connecting to an LXC container to
avoid inheriting host variables that may break container services like
the following failure in rabbitmqctl:

TASK [Get status of rabbitmq] *************************************************************************************************************************************************************************************
fatal: [container1]: FAILED! => {""changed"": true, ""cmd"": [""rabbitmqctl"", ""status""], ""delta"": ""0:00:00.705116"", ""end"": ""2017-06-06 20:03:13.771796"", ""failed"": true, ""rc"": 69, ""start"": ""2017-06-06 20:03:13.066680"", ""stderr"": ""Error: unable to connect to node 'rabbit@vagrant-openSUSE-Leap': nodedown\n\nDIAGNOSTICS\n===========\n\nattempted to contact: ['rabbit@vagrant-openSUSE-Leap']\n\nrabbit@vagrant-openSUSE-Leap:\n  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)\n\n\ncurrent node details:\n- node name: 'rabbitmq-cli-82@localhost'\n- home dir: /var/lib/rabbitmq\n- cookie hash: NqWRA5RzO5daz4Jb5LJsXg=="", ""stderr_lines"": [""Error: unable to connect to node 'rabbit@vagrant-openSUSE-Leap': nodedown"", """", ""DIAGNOSTICS"", ""==========="", """", ""attempted to contact: ['rabbit@vagrant-openSUSE-Leap']"", """", ""rabbit@vagrant-openSUSE-Leap:"", ""  * unable to connect to epmd (port 4369) on vagrant-openSUSE-Leap: address (cannot connect to host/port)"", """", """", ""current node details:"", ""- node name: 'rabbitmq-cli-82@localhost'"", ""- home dir: /var/lib/rabbitmq"", ""- cookie hash: NqWRA5RzO5daz4Jb5LJsXg==""], ""stdout"": ""Status of node 'rabbit@vagrant-openSUSE-Leap' ..."", ""stdout_lines"": [""Status of node 'rabbit@vagrant-openSUSE-Leap' ...""]}
	to retry, use: --limit @/vagrant/tests/test-rabbitmq-server-functional.retry

The reason for this failure is that the HOSTNAME variable is being
inherited by the host (vagrant-openSUSE-Leap) and the rabbitmqctl
command uses this variable to guess the host it should try to
connect to.

This is similar to what the upstream lxc connection module is doing.

This is an attempt to fix problems introduced in
https://review.openstack.org/#/c/471472/ and subsequently
reverted in https://review.openstack.org/#/c/471713/

The reason for these failures was that 'lxc-attach' executed commands
which assumed that basic variables like HOME are set properly. However,
--clear-env didn't preserve these variables so various operations started
to fail. In order to fix that, it's best if we start a real login shell
using 'su' in order to mimic an expected user environment when executing
commands within the container.

Change-Id: I684a11f4380f91b1cb0585f38817859dfaa68f80
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/10/471810/1 && git format-patch -1 --stdout FETCH_HEAD,['connection/ssh.py'],1,c6d5a1af9cacc15cf726ab36841bf2539efa6ae3,lxc-transport-clear-env-login-shell," # NOTE(hwoarang) It is important to connect to the container # without inheriting the host environment as that would interfere # with running commands and services inside the container. However, # it is also important to create a sensible environment within the # container because certain commands and services expect some # enviromental variables to be set properly. The best way to do # that would be to execute the commands in a login shell lxc_command = 'lxc-attach --clear-env --name %s' % self.container_name cmd = '%s -- su - %s -c %s' % (lxc_command, self._play_context.remote_user, cmd)"," lxc_command = 'lxc-attach --name %s' % self.container_name cmd = '%s -- %s' % (lxc_command, cmd)",10,2
openstack%2Fproject-config~master~Ib72c2298309f78c596a10d96fbb0aa0df2c50614,openstack/project-config,master,Ib72c2298309f78c596a10d96fbb0aa0df2c50614,Use old image build command for stable/newton,MERGED,2017-06-12 11:02:42.000000000,2017-06-17 06:59:26.000000000,2017-06-17 06:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}, {'_account_id': 9317}]","[{'number': 1, 'created': '2017-06-12 11:02:42.000000000', 'files': ['jenkins/jobs/tripleo.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9e68bb3b657bbc48dc1b74b1a592138395cc445d', 'message': 'Use old image build command for stable/newton\n\nAs part of Idd09c515beb6367e6ea3f98231bad31f5c536e6d the image build\ncommand was updated to stop using deprecated options. However it\nappears the old options are still needed when running the job on\nstable/newton, as CI fails on the new one.\n\nChange-Id: Ib72c2298309f78c596a10d96fbb0aa0df2c50614\nCloses-Bug: #1697413\n'}]",0,473371,9e68bb3b657bbc48dc1b74b1a592138395cc445d,8,4,1,4978,,,0,"Use old image build command for stable/newton

As part of Idd09c515beb6367e6ea3f98231bad31f5c536e6d the image build
command was updated to stop using deprecated options. However it
appears the old options are still needed when running the job on
stable/newton, as CI fails on the new one.

Change-Id: Ib72c2298309f78c596a10d96fbb0aa0df2c50614
Closes-Bug: #1697413
",git fetch https://review.opendev.org/openstack/project-config refs/changes/71/473371/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/tripleo.yaml'],1,9e68bb3b657bbc48dc1b74b1a592138395cc445d,bug/1697413," if [ ""$ZUUL_BRANCH"" == ""stable/newton"" ]; then tox -evenv -- openstack overcloud image build --type {image-name} --elements-path=""$ELEMENTS"" else tox -evenv -- openstack overcloud image build --image-name {image-name} $CONFIG_FILES fi", tox -evenv -- openstack overcloud image build --image-name {image-name} $CONFIG_FILES,5,1
openstack%2Fdiskimage-builder~master~I90103b59357edebbac7a641e8980cb282d37561b,openstack/diskimage-builder,master,I90103b59357edebbac7a641e8980cb282d37561b,Fix mkfs failure when loop device is not ready,MERGED,2017-06-16 16:30:25.000000000,2017-06-17 06:43:47.000000000,2017-06-17 06:43:47.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 21741}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-06-16 16:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7cf064e0c1ef0724ddac22c56b974b2691b810c8', 'message': 'Fix mkfs failure when loop device is not ready\n\nThere was a race in diskimage-builder where the mkfs call after a\nkpartx -avs for the loop device would fail because the device was\nnot yet ready.  This adds a udevadm settle call after the kpartx\nto make sure the udev event queue has cleared.\n\nChange-Id: I90103b59357edebbac7a641e8980cb282d37561b\nCloses-Bug: #1698337\n'}, {'number': 2, 'created': '2017-06-16 16:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f45c734b75a339746a1d4e9ce97ca690eace9fb8', 'message': 'Fix mkfs failure when loop device is not ready\n\nThere was a race in diskimage-builder where the mkfs call after a\nkpartx -avs for the loop device would fail because the device was\nnot yet ready.  This adds a udevadm settle call after the kpartx\nto make sure the udev event queue has cleared.\n\nChange-Id: I90103b59357edebbac7a641e8980cb282d37561b\nCloses-Bug: #1698337\n'}, {'number': 3, 'created': '2017-06-16 23:00:30.000000000', 'files': ['diskimage_builder/block_device/level1/partitioning.py'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/250aeb5d219db1a0fc01033168a55f7f61e60c74', 'message': 'Fix mkfs failure when loop device is not ready\n\nThere was a race in diskimage-builder where the mkfs call after a\nkpartx -avs for the loop device would fail because the device was\nnot yet ready.  This adds a udevadm settle call after the kpartx\nto make sure the udev event queue has cleared.\n\nChange-Id: I90103b59357edebbac7a641e8980cb282d37561b\nCloses-Bug: #1698337\n'}]",0,475022,250aeb5d219db1a0fc01033168a55f7f61e60c74,45,8,3,11628,,,0,"Fix mkfs failure when loop device is not ready

There was a race in diskimage-builder where the mkfs call after a
kpartx -avs for the loop device would fail because the device was
not yet ready.  This adds a udevadm settle call after the kpartx
to make sure the udev event queue has cleared.

Change-Id: I90103b59357edebbac7a641e8980cb282d37561b
Closes-Bug: #1698337
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/22/475022/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/block_device/level1/partitioning.py'],1,7cf064e0c1ef0724ddac22c56b974b2691b810c8,bug/1698337," exec_sudo([""udevadm"", ""settle""])",,1,0
openstack%2Fheat~master~I9787a5de5e4272a3ab370f653182aa9283ae01c0,openstack/heat,master,I9787a5de5e4272a3ab370f653182aa9283ae01c0,Fix races in SoftwareDeploymentGroupTest,MERGED,2017-06-13 23:38:58.000000000,2017-06-17 06:35:44.000000000,2017-06-17 06:35:44.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12404}]","[{'number': 1, 'created': '2017-06-13 23:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aaad75175a868ca503fcbf81155bf92377f84d82', 'message': ""Fix race in SoftwareDeploymentGroupTest\n\nDon't assume that we can get the physical IDs of all of the\nSoftwareDeployment resources as soon as the stack becomes\nCREATE_IN_PROGRESS. Read them again once the stack is COMPLETE.\n\nChange-Id: I9787a5de5e4272a3ab370f653182aa9283ae01c0\nCloses-Bug: #1697794\n""}, {'number': 2, 'created': '2017-06-14 14:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/654ad0b8a0f19a9805267de1df1688679aa1e166', 'message': ""Fix race in SoftwareDeploymentGroupTest\n\nDon't assume that we can get the physical IDs of all of the\nSoftwareDeployment resources as soon as the stack becomes\nCREATE_IN_PROGRESS. 4dd67bb1aa2df4f5270f79600ac1f888b0bd9a5f reads them\nagain once the stack is COMPLETE; this patch also uses the same physical\nresource IDs to verify the update.\n\nChange-Id: I9787a5de5e4272a3ab370f653182aa9283ae01c0\nCloses-Bug: #1697794\nCloses-Bug: #1626073\nRelated-Bug: #1625921\n""}, {'number': 3, 'created': '2017-06-14 17:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9d50cceb82835611ba4d7117ffc0d8bfd2b0c2b', 'message': ""Fix races in SoftwareDeploymentGroupTest\n\nDon't assume that we can get the physical IDs of all of the\nSoftwareDeployment resources as soon as the stack becomes\nCREATE_IN_PROGRESS. 4dd67bb1aa2df4f5270f79600ac1f888b0bd9a5f reads them\nagain once the stack is COMPLETE; this patch also uses the same physical\nresource IDs to verify the update.\n\nAlso, make sure all of the resources are IN_PROGRESS before trying to\nsignal them, because the signal_resources() utility method only signals\nresources that are IN_PROGRESS.\n\nChange-Id: I9787a5de5e4272a3ab370f653182aa9283ae01c0\nCloses-Bug: #1697794\nCloses-Bug: #1626073\nCloses-Bug: #1625921\n""}, {'number': 4, 'created': '2017-06-14 20:34:03.000000000', 'files': ['heat_integrationtests/functional/test_software_deployment_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/41b8e44d1e89440dca994bb927ecb35784d94e34', 'message': ""Fix races in SoftwareDeploymentGroupTest\n\nDon't assume that we can get the physical IDs of all of the\nSoftwareDeployment resources as soon as the stack becomes\nCREATE_IN_PROGRESS. 4dd67bb1aa2df4f5270f79600ac1f888b0bd9a5f reads them\nagain once the stack is COMPLETE; this patch also uses the same physical\nresource IDs to verify the update.\n\nAlso, make sure all of the resources are IN_PROGRESS before trying to\nsignal them, because the signal_resources() utility method only signals\nresources that are IN_PROGRESS.\n\nChange-Id: I9787a5de5e4272a3ab370f653182aa9283ae01c0\nCloses-Bug: #1697794\nCloses-Bug: #1626073\nCloses-Bug: #1625921\n""}]",3,474004,41b8e44d1e89440dca994bb927ecb35784d94e34,28,6,4,4257,,,0,"Fix races in SoftwareDeploymentGroupTest

Don't assume that we can get the physical IDs of all of the
SoftwareDeployment resources as soon as the stack becomes
CREATE_IN_PROGRESS. 4dd67bb1aa2df4f5270f79600ac1f888b0bd9a5f reads them
again once the stack is COMPLETE; this patch also uses the same physical
resource IDs to verify the update.

Also, make sure all of the resources are IN_PROGRESS before trying to
signal them, because the signal_resources() utility method only signals
resources that are IN_PROGRESS.

Change-Id: I9787a5de5e4272a3ab370f653182aa9283ae01c0
Closes-Bug: #1697794
Closes-Bug: #1626073
Closes-Bug: #1625921
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/474004/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_software_deployment_group.py'],1,aaad75175a868ca503fcbf81155bf92377f84d82,bug/1697794," group_resources = self.list_group_resources( stack_identifier, 'deployment', minimal=False) self.assertEqual(4, len(group_resources))"," self.assertEqual(4, len(group_resources))",3,1
openstack%2Fopenstack-ansible-os_neutron~master~Iea02dcc6a05f6afd0f872ff9c68a33a8907fab1f,openstack/openstack-ansible-os_neutron,master,Iea02dcc6a05f6afd0f872ff9c68a33a8907fab1f,Normalise distro package installation,MERGED,2017-06-08 13:32:40.000000000,2017-06-17 06:15:46.000000000,2017-06-17 06:15:46.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-08 13:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/e7cebce0784577bff2d10f16fe78587a48fad032', 'message': 'Normalise distro package installation\n\nThis patch normalises the package installation\nselection variable name and jinja composure to\nbe just a little cleaner.\n\nChange-Id: Iea02dcc6a05f6afd0f872ff9c68a33a8907fab1f\n'}, {'number': 2, 'created': '2017-06-14 15:34:59.000000000', 'files': ['vars/main.yml', 'tasks/neutron_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/fa848c609b15c749e1799bee4bc3062fbbb51b1f', 'message': 'Normalise distro package installation\n\nThis patch normalises the package installation\nselection variable name and jinja composure to\nbe just a little cleaner.\n\nChange-Id: Iea02dcc6a05f6afd0f872ff9c68a33a8907fab1f\n'}]",0,472261,fa848c609b15c749e1799bee4bc3062fbbb51b1f,20,4,2,6816,,,0,"Normalise distro package installation

This patch normalises the package installation
selection variable name and jinja composure to
be just a little cleaner.

Change-Id: Iea02dcc6a05f6afd0f872ff9c68a33a8907fab1f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/61/472261/2 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/neutron_install.yml', 'vars/main.yml']",2,e7cebce0784577bff2d10f16fe78587a48fad032,distro-pkg-optimise,# # Compile a list of the distro packages to install based on # whether the host is in the host group and the service is # enabled. # neutron_package_list: |- {% set packages = neutron_distro_packages %} or (neutron_services['dragonflow-l3-agent']['group'] in group_names and neutron_services['dragonflow-l3-agent'].service_en | bool) %} {% set _ = packages.extend(neutron_ovs_distro_packages) %} {% endif %} {% if neutron_services['neutron-linuxbridge-agent']['group'] in group_names and neutron_services['neutron-linuxbridge-agent'].service_en | bool %} {% set _ = packages.extend(neutron_lxb_distro_packages) %} {% endif %} {% if neutron_services['neutron-lbaasv2-agent']['group'] in group_names and neutron_lbaasv2 | bool %} {% set _ = packages.extend(neutron_lbaas_distro_packages) %} {% endif %} {% if neutron_services['neutron-vpnaas-agent']['group'] in group_names and neutron_vpnaas | bool %} {% set _ = packages.extend(neutron_vpnaas_distro_packages) %} {% endif %} {{ packages }},neutron_packages_list: > {% set packages = neutron_distro_packages -%} or (neutron_services['dragonflow-l3-agent']['group'] in group_names and neutron_services['dragonflow-l3-agent'].service_en | bool) -%} {% set _ = packages.extend(neutron_ovs_distro_packages) -%} {% endif -%} {% if neutron_services['neutron-linuxbridge-agent']['group'] in group_names and neutron_services['neutron-linuxbridge-agent'].service_en | bool -%} {% set _ = packages.extend(neutron_lxb_distro_packages) -%} {% endif -%} {% if neutron_services['neutron-lbaasv2-agent']['group'] in group_names and neutron_lbaasv2 | bool -%} {% set _ = packages.extend(neutron_lbaas_distro_packages) -%} {% endif -%} {% if neutron_services['neutron-vpnaas-agent']['group'] in group_names and neutron_vpnaas | bool -%} {% set _ = packages.extend(neutron_vpnaas_distro_packages) -%} {% endif -%} {{ packages -}},21,16
openstack%2Fmagnum~master~Iea2faa79628232816407c81a9fc59697914d37b3,openstack/magnum,master,Iea2faa79628232816407c81a9fc59697914d37b3,Remove deprecated oslo_messaging.transport.get_transport,ABANDONED,2017-06-13 12:33:26.000000000,2017-06-17 06:13:53.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-13 12:33:26.000000000', 'files': ['magnum/common/rpc.py', 'magnum/common/rpc_service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1d0dc6dd00399f8aae7fa22d7affddd2696ea4b6', 'message': ""Remove deprecated oslo_messaging.transport.get_transport\n\nDeprecationWarning:\nUsing function/method 'oslo_messaging.transport.get_transport()'\nis deprecated: use get_rpc_transport or get_notification_transport.\n\nChange-Id: Iea2faa79628232816407c81a9fc59697914d37b3\n""}]",0,473812,1d0dc6dd00399f8aae7fa22d7affddd2696ea4b6,4,1,1,21785,,,0,"Remove deprecated oslo_messaging.transport.get_transport

DeprecationWarning:
Using function/method 'oslo_messaging.transport.get_transport()'
is deprecated: use get_rpc_transport or get_notification_transport.

Change-Id: Iea2faa79628232816407c81a9fc59697914d37b3
",git fetch https://review.opendev.org/openstack/magnum refs/changes/12/473812/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/common/rpc.py', 'magnum/common/rpc_service.py']",2,1d0dc6dd00399f8aae7fa22d7affddd2696ea4b6,," transport = messaging.get_rpc_transport(CONF) transport = messaging.get_rpc_transport( CONF, allowed_remote_exmods=exmods)"," transport = messaging.get_transport(CONF) transport = messaging.get_transport(CONF, allowed_remote_exmods=exmods)",5,5
openstack%2Fopenstack-ansible-os_cinder~stable%2Focata~I8bae6b5a39f78a2ee4fb02e31d91c1dd3eca7cb0,openstack/openstack-ansible-os_cinder,stable/ocata,I8bae6b5a39f78a2ee4fb02e31d91c1dd3eca7cb0,Optimise the distro package installation,MERGED,2017-06-08 08:32:15.000000000,2017-06-17 06:01:05.000000000,2017-06-17 06:01:05.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-08 08:32:15.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml', 'vars/main.yml', 'tasks/cinder_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/7cbcad79de2fc0fac5d383c66ab0dada6ac1500f', 'message': 'Optimise the distro package installation\n\nIn order to optimise the distro package installation\nprocess the list of packages to install is prepared\nfor the host, then installed by passing the package\ntask the full list instead of using a loop.\n\nChange-Id: I8bae6b5a39f78a2ee4fb02e31d91c1dd3eca7cb0\n(cherry picked from commit 6ba2290a5f9d8d2f216f8cc9efba71cd2987ac4a)\n'}]",0,472147,7cbcad79de2fc0fac5d383c66ab0dada6ac1500f,13,3,1,6816,,,0,"Optimise the distro package installation

In order to optimise the distro package installation
process the list of packages to install is prepared
for the host, then installed by passing the package
task the full list instead of using a loop.

Change-Id: I8bae6b5a39f78a2ee4fb02e31d91c1dd3eca7cb0
(cherry picked from commit 6ba2290a5f9d8d2f216f8cc9efba71cd2987ac4a)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/47/472147/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'vars/ubuntu-16.04.yml', 'defaults/main.yml', 'tasks/cinder_install.yml', 'vars/main.yml']",5,7cbcad79de2fc0fac5d383c66ab0dada6ac1500f,distro-pkg-optimise,# # Compile a list of the distro packages to install based on # whether the host is in the host group and the service is # enabled. # cinder_package_list: |- {% set packages = cinder_distro_packages %} {% if cinder_services['cinder-volume']['group'] in group_names %} {% set _ = packages.extend(cinder_volume_distro_packages) %} {% if cinder_backend_lvm_inuse | bool %} {% set _ = packages.extend(cinder_lvm_volume_distro_packages) %} {% endif %} {% endif %} {% if cinder_developer_mode | bool %} {% set _ = packages.extend(cinder_developer_mode_distro_packages) %} {% endif %} {{ packages }} # # Compile a list of the services on a host based on whether # the host is in the host group and the service is enabled. #,,30,47
openstack%2Ftripleo-ci~master~I02e172837d370aa562c548b58df66e6828e6686e,openstack/tripleo-ci,master,I02e172837d370aa562c548b58df66e6828e6686e,PLEASE DON'T REVIEW FOR TESTING ONLY,ABANDONED,2017-06-14 08:34:18.000000000,2017-06-17 05:29:33.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-14 08:34:18.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b64c996bc3d804389e23bf293ac942e1e35c8828', 'message': ""PLEASE DON'T REVIEW FOR TESTING ONLY\n\nThe goal is to test OVS uprade.\n\nI am interested in only running gate-tripleo-ci-centos-7-multinode-upgrades-nv\njob. Wish I could know how to disable or stop other jobs from running.\n\nChange-Id: I02e172837d370aa562c548b58df66e6828e6686e\n""}]",0,474106,b64c996bc3d804389e23bf293ac942e1e35c8828,4,1,1,10237,,,0,"PLEASE DON'T REVIEW FOR TESTING ONLY

The goal is to test OVS uprade.

I am interested in only running gate-tripleo-ci-centos-7-multinode-upgrades-nv
job. Wish I could know how to disable or stop other jobs from running.

Change-Id: I02e172837d370aa562c548b58df66e6828e6686e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/06/474106/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,b64c996bc3d804389e23bf293ac942e1e35c8828,ovs_update_tst, # FOR TESTING ONLY. Add the OVS repo to get the 2.7 version yum-config-manager --add-repo http://cbs.centos.org/repos/cloud7-openstack-pike-candidate/x86_64/os yum update -y --nogpgcheck openvswitch ,,4,0
openstack%2Fopenstack-ansible-os_heat~stable%2Focata~I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4,openstack/openstack-ansible-os_heat,stable/ocata,I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4,Correct heat developer mode constraint,MERGED,2017-06-15 18:14:41.000000000,2017-06-17 05:15:41.000000000,2017-06-17 05:15:25.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-06-15 18:14:41.000000000', 'files': ['tasks/heat_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/300f15ee65d2e157a0304caa10fcac279fbd5f18', 'message': 'Correct heat developer mode constraint\n\nThe keystone_developer_mode variable is used by mistake.\nThis fixes that.\n\nChange-Id: I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4\n'}]",0,474720,300f15ee65d2e157a0304caa10fcac279fbd5f18,13,4,1,6816,,,0,"Correct heat developer mode constraint

The keystone_developer_mode variable is used by mistake.
This fixes that.

Change-Id: I427ff6e09f19087c4e2e4f98f58c9cff8d116bd4
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/20/474720/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/heat_install.yml'],1,300f15ee65d2e157a0304caa10fcac279fbd5f18,," {{ heat_developer_mode | ternary('--constraint /opt/developer-pip-constraints.txt', '') }}"," {{ keystone_developer_mode | ternary('--constraint /opt/developer-pip-constraints.txt', '') }}",1,1
openstack%2Fopenstack-ansible-tests~master~Ie9176fb561d0ef53051d1a39b5fb38dd30fb45bb,openstack/openstack-ansible-tests,master,Ie9176fb561d0ef53051d1a39b5fb38dd30fb45bb,"Make a ""test_branch"" variable set to master",MERGED,2017-06-06 18:46:29.000000000,2017-06-17 05:03:55.000000000,2017-06-17 05:03:55.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-06-06 18:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/2fcfca17c474d2d46d81506652e709882f3f0db1', 'message': 'Make a ""test_branch"" variable set to master\n\nTo avoid having to change each variable per release we can create a\nsingle ""test_branch"" variable.\n\nAdditionally, when creating the ""local-repo-packages.txt"" constraints\nfile, we should use the ""test_branch"" variable to scope the constraints\nfile per release. This way upgrade jobs will continue to upgrade\ncorrectly from the previous release\'s upstream project.\n\nChange-Id: Ie9176fb561d0ef53051d1a39b5fb38dd30fb45bb\n'}, {'number': 2, 'created': '2017-06-15 07:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/64b56d95b1e2fc02866fa079d256f3f9f5274b1a', 'message': 'Make a ""test_branch"" variable set to master\n\nTo avoid having to change each variable per release we can create a\nsingle ""test_branch"" variable.\n\nAdditionally, when creating the ""local-repo-packages.txt"" constraints\nfile, we should use the ""test_branch"" variable to scope the constraints\nfile per release. This way upgrade jobs will continue to upgrade\ncorrectly from the previous release\'s upstream project.\n\nChange-Id: Ie9176fb561d0ef53051d1a39b5fb38dd30fb45bb\n'}, {'number': 3, 'created': '2017-06-16 18:04:50.000000000', 'files': ['test-vars.yml', 'test-repo-setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/e59747e762799bfa7c756a2b775e14b024681570', 'message': 'Make a ""test_branch"" variable set to master\n\nTo avoid having to change each variable per release we can create a\nsingle ""test_branch"" variable.\n\nAdditionally, when creating the ""local-repo-packages.txt"" constraints\nfile, we should use the ""test_branch"" variable to scope the constraints\nfile per release. This way upgrade jobs will continue to upgrade\ncorrectly from the previous release\'s upstream project.\n\nChange-Id: Ie9176fb561d0ef53051d1a39b5fb38dd30fb45bb\n'}]",3,471440,e59747e762799bfa7c756a2b775e14b024681570,24,4,3,2799,,,0,"Make a ""test_branch"" variable set to master

To avoid having to change each variable per release we can create a
single ""test_branch"" variable.

Additionally, when creating the ""local-repo-packages.txt"" constraints
file, we should use the ""test_branch"" variable to scope the constraints
file per release. This way upgrade jobs will continue to upgrade
correctly from the previous release's upstream project.

Change-Id: Ie9176fb561d0ef53051d1a39b5fb38dd30fb45bb
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/40/471440/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-vars.yml', 'test-repo-setup.yml']",2,2fcfca17c474d2d46d81506652e709882f3f0db1,," dest: ""{{ development_repo_directory }}/local-package-constraints-{{ test_branch | replace('/','_') }}.txt"""," dest: ""{{ development_repo_directory }}/local-package-constraints.txt""",14,13
openstack%2Fmurano~master~I1a8581a559e4333a74d56a5bdce7e6d1f117907d,openstack/murano,master,I1a8581a559e4333a74d56a5bdce7e6d1f117907d,Remove murano default policy.json,MERGED,2017-06-14 14:49:29.000000000,2017-06-17 05:02:39.000000000,2017-06-17 05:02:39.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 15168}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-06-14 14:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/36e952326de57525066c67c54727456b7858e296', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 2, 'created': '2017-06-14 15:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/14dda019881008a8660d9ad85b4910474945397c', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 3, 'created': '2017-06-14 15:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c77ea1e0dca7fa495e3846087aabfebf31d7822b', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 4, 'created': '2017-06-15 13:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2753308416050fe9a95c2844914559790c11149a', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 5, 'created': '2017-06-15 18:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8ad1ddbae7be1ae4d841b4cf7734351ceca4a717', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 6, 'created': '2017-06-15 21:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/eef63d7d14fa65bea92b2906270afe3cbab7ca23', 'message': ""WIP Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 7, 'created': '2017-06-15 21:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6ab535f11979a952f236e689080b723f0a3c8271', 'message': ""WIP Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 8, 'created': '2017-06-16 02:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0396df574bd9d7a8742e5a078d883be8b7b35c8d', 'message': ""WIP Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\n\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 9, 'created': '2017-06-16 03:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2a1029bb4ebc4266d37877b2daf021c33fbc83a3', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n  - updates base admin_api rule to is_admin:True from\n    is_admin:1 (because the latter was causing issues)\n  - updates Murano policy documentation\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}, {'number': 10, 'created': '2017-06-16 03:07:50.000000000', 'files': ['murano/common/policy.py', 'murano/common/policies/__init__.py', 'murano/common/policies/base.py', 'etc/murano/policy.json', 'devstack/plugin.sh', 'doc/source/administrator-guide/configuration.rst', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/murano/commit/fb1a2d5bbe8bf4d00267b2927051aed4249b209f', 'message': ""Remove murano default policy.json\n\nThis commit removes the murano default policy.json file from\netc/murano and references to it in murano's devstack plugin.\n(References to the policy.json in muranodashboard remain\nthe same).\n\nThis commit specifically:\n  - removes the default policy.json\n  - removes references to it in devstack plugin\n  - adds base rules to murano.common.policies.__init__ because\n    they are the last rules to be included\n  - updates base admin_api rule to is_admin:True from\n    is_admin:1 (because the latter was causing issues)\n  - updates Murano policy documentation\n\nPartially Implements: blueprint policy-in-code\nDepends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9\nChange-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d\n""}]",1,474239,fb1a2d5bbe8bf4d00267b2927051aed4249b209f,47,6,10,23186,,,0,"Remove murano default policy.json

This commit removes the murano default policy.json file from
etc/murano and references to it in murano's devstack plugin.
(References to the policy.json in muranodashboard remain
the same).

This commit specifically:
  - removes the default policy.json
  - removes references to it in devstack plugin
  - adds base rules to murano.common.policies.__init__ because
    they are the last rules to be included
  - updates base admin_api rule to is_admin:True from
    is_admin:1 (because the latter was causing issues)
  - updates Murano policy documentation

Partially Implements: blueprint policy-in-code
Depends-On: Ia372983d2bd1010cd19f04061f3276ed16e9c1c9
Change-Id: I1a8581a559e4333a74d56a5bdce7e6d1f117907d
",git fetch https://review.opendev.org/openstack/murano refs/changes/39/474239/3 && git format-patch -1 --stdout FETCH_HEAD,"['murano/common/policies/__init__.py', 'etc/murano/policy.json', 'devstack/plugin.sh', 'devstack/settings']",4,36e952326de57525066c67c54727456b7858e296,policy-in-code,,MURANO_POLICY_FILE=${MURANO_CONF_DIR}/policy.json,2,9
openstack%2Ftripleo-ci~master~I89be964528640e2e0c014194e522c33a416bbb39,openstack/tripleo-ci,master,I89be964528640e2e0c014194e522c33a416bbb39,Fix repositories for promotion jobs,MERGED,2017-06-16 22:49:41.000000000,2017-06-17 04:44:11.000000000,2017-06-17 04:44:11.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 12715}]","[{'number': 1, 'created': '2017-06-16 22:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c4f0e70d7124144ace00f866142aeae71fb1cf91', 'message': 'Fix repositories for promotion jobs\n\nRight now periodic promotion jobs run with current repositories,\ninstead of consistent ones. This patch sets release to\n""consistent-master"" for using consistent repos.\n\nChange-Id: I89be964528640e2e0c014194e522c33a416bbb39\n'}, {'number': 2, 'created': '2017-06-16 22:56:11.000000000', 'files': ['toci_gate_test-oooq.sh', 'toci_quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4951bfe87905746d37e2ea0e630e89f8cf2e1079', 'message': 'Fix repositories for promotion jobs\n\nRight now periodic promotion jobs run with current repositories,\ninstead of consistent ones. This patch sets release to\n""consistent-master"" for using consistent repos.\nClose-Bug: #1698474\n\nChange-Id: I89be964528640e2e0c014194e522c33a416bbb39\n'}]",0,475084,4951bfe87905746d37e2ea0e630e89f8cf2e1079,12,8,2,10969,,,0,"Fix repositories for promotion jobs

Right now periodic promotion jobs run with current repositories,
instead of consistent ones. This patch sets release to
""consistent-master"" for using consistent repos.
Close-Bug: #1698474

Change-Id: I89be964528640e2e0c014194e522c33a416bbb39
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/84/475084/1 && git format-patch -1 --stdout FETCH_HEAD,"['toci_gate_test-oooq.sh', 'toci_quickstart.sh']",2,c4f0e70d7124144ace00f866142aeae71fb1cf91,fixprom,# Use consistent repositories for promotion if [[ $CACHEUPLOAD == 1 && $QUICKSTART_RELEASE == 'master' ]]; then QUICKSTART_RELEASE='consistent-master' fi,,5,2
openstack%2Fopenstack-ansible-os_heat~master~I77bb1e7f9513593cecf2ca95b9e2fa91e251b483,openstack/openstack-ansible-os_heat,master,I77bb1e7f9513593cecf2ca95b9e2fa91e251b483,Deprecate rpc_backend option,MERGED,2017-06-01 07:05:57.000000000,2017-06-17 04:40:15.000000000,2017-06-17 04:40:15.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 9414}]","[{'number': 1, 'created': '2017-06-01 07:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/f504f5144b513c450a5922d5aeafc06c02418892', 'message': 'Deprecate rpc_backend option\n\nOption ""rpc_backend"" from group ""DEFAULT"" is deprecated for removal\n(Replaced by [DEFAULT]/transport_url). Its value may be silently\nignored in the future.\n\nChange-Id: I77bb1e7f9513593cecf2ca95b9e2fa91e251b483\nImplements: blueprint deprecate-rpc-backend\n'}, {'number': 2, 'created': '2017-06-09 07:50:17.000000000', 'files': ['templates/heat.conf.j2', 'defaults/main.yml', 'releasenotes/notes/remove_rpc_backend-1163da2fe9418315.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/972e8b515a4a099a34354bbef3d494351f2691b1', 'message': 'Deprecate rpc_backend option\n\nOption ""rpc_backend"" from group ""DEFAULT"" is deprecated for removal\n(Replaced by [DEFAULT]/transport_url). Its value may be silently\nignored in the future.\n\nChange-Id: I77bb1e7f9513593cecf2ca95b9e2fa91e251b483\nImplements: blueprint deprecate-rpc-backend\n'}]",0,469780,972e8b515a4a099a34354bbef3d494351f2691b1,28,4,2,9414,,,0,"Deprecate rpc_backend option

Option ""rpc_backend"" from group ""DEFAULT"" is deprecated for removal
(Replaced by [DEFAULT]/transport_url). Its value may be silently
ignored in the future.

Change-Id: I77bb1e7f9513593cecf2ca95b9e2fa91e251b483
Implements: blueprint deprecate-rpc-backend
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/80/469780/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/heat.conf.j2', 'defaults/main.yml', 'releasenotes/notes/remove_rpc_backend-1163da2fe9418315.yaml']",3,f504f5144b513c450a5922d5aeafc06c02418892,bp/deprecate-rpc-backend,--- deprecations: - | Remove ``heat_rpc_backend`` option due to deprecation of rpc_backend option in oslo.messaging. ,,5,2
openstack%2Fopenstack-ansible-ceph_client~master~I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2,openstack/openstack-ansible-ceph_client,master,I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2,Use the host python interpreter when delegating to localhost,MERGED,2017-06-15 13:27:29.000000000,2017-06-17 04:28:09.000000000,2017-06-15 14:22:19.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-06-15 13:27:29.000000000', 'files': ['tasks/ceph_auth_extra_compute.yml', 'tasks/ceph_auth_extra.yml', 'tasks/ceph_config_extra.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/9c2d22532e5cfd817e2fcacbe7fab8ca28976e61', 'message': 'Use the host python interpreter when delegating to localhost\n\nIn order to ensure that the localhost delegated task uses the host\npython interpreter (to access host-installed libs like\npython-selinux), the interpreter is set on the task.\n\nsee: https://review.openstack.org/#/c/474565/\n\nChange-Id: I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2\n'}]",0,474577,9c2d22532e5cfd817e2fcacbe7fab8ca28976e61,9,4,1,13095,,,0,"Use the host python interpreter when delegating to localhost

In order to ensure that the localhost delegated task uses the host
python interpreter (to access host-installed libs like
python-selinux), the interpreter is set on the task.

see: https://review.openstack.org/#/c/474565/

Change-Id: I7b20dd195a6562981fc5c72cbf7d91f6b45f4fa2
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/77/474577/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/ceph_auth_extra_compute.yml', 'tasks/ceph_auth_extra.yml', 'tasks/ceph_config_extra.yml']",3,9c2d22532e5cfd817e2fcacbe7fab8ca28976e61,fix-localhost-delegation," vars: ansible_python_interpreter: ""/usr/bin/python""",,10,0
openstack%2Fopenstack-ansible-tests~stable%2Focata~I93318a73c43ff7c6ae423271bd8c252ad94b0149,openstack/openstack-ansible-tests,stable/ocata,I93318a73c43ff7c6ae423271bd8c252ad94b0149,Disable PrivateDevices for galera and Memcached,MERGED,2017-06-17 01:08:53.000000000,2017-06-17 04:14:45.000000000,2017-06-17 04:14:45.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-06-17 01:08:53.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/7162f3d86c2f51f5b98275c07d7508e4eaada15f', 'message': 'Disable PrivateDevices for galera and Memcached\n\nChange-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149\nDepends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83\nRelated-Bug: 1697531\n(cherry picked from commit 7938542000caeb20583033b7bed4970488565891)\n'}]",0,475093,7162f3d86c2f51f5b98275c07d7508e4eaada15f,7,2,1,13095,,,0,"Disable PrivateDevices for galera and Memcached

Change-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149
Depends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83
Related-Bug: 1697531
(cherry picked from commit 7938542000caeb20583033b7bed4970488565891)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/93/475093/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,7162f3d86c2f51f5b98275c07d7508e4eaada15f,bug/1697531,"galera_disable_privatedevices: ""{{ ((properties.is_metal | default(false)) | bool) | ternary('false', 'true') }}""memcached_disable_privatedevices: ""{{ ((properties.is_metal | default(false)) | bool) | ternary('false', 'true') }}""",,2,0
openstack%2Foctavia~master~Ie7008d6ec0462bc44912799809b9eb816e9b8718,openstack/octavia,master,Ie7008d6ec0462bc44912799809b9eb816e9b8718,Small refactor for load_balancer v2 vip validation,MERGED,2017-06-15 17:35:43.000000000,2017-06-17 03:28:27.000000000,2017-06-17 03:28:27.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-06-15 17:35:43.000000000', 'files': ['octavia/api/v2/controllers/load_balancer.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/3d4226b98abd1765e558dccb8c0cc240f4c5a50a', 'message': 'Small refactor for load_balancer v2 vip validation\n\nChange-Id: Ie7008d6ec0462bc44912799809b9eb816e9b8718\n'}]",0,474711,3d4226b98abd1765e558dccb8c0cc240f4c5a50a,24,4,1,10273,,,0,"Small refactor for load_balancer v2 vip validation

Change-Id: Ie7008d6ec0462bc44912799809b9eb816e9b8718
",git fetch https://review.opendev.org/openstack/octavia refs/changes/11/474711/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/api/v2/controllers/load_balancer.py'],1,3d4226b98abd1765e558dccb8c0cc240f4c5a50a,," def _validate_vip_request_object(self, load_balancer): @wsme_pecan.wsexpose(lb_types.LoadBalancerFullRootResponse, body=lb_types.LoadBalancerRootPOST, status_code=201) def post(self, load_balancer): """"""Creates a load balancer."""""" load_balancer = load_balancer.loadbalancer context = pecan.request.context.get('octavia_context') project_id = context.project_id if context.is_admin or CONF.auth_strategy == constants.NOAUTH: if load_balancer.project_id: project_id = load_balancer.project_id if not project_id: raise exceptions.ValidationException(detail=_( ""Missing project ID in request where one is required."")) load_balancer.project_id = project_id self._validate_vip_request_object(load_balancer) "," @wsme_pecan.wsexpose(lb_types.LoadBalancerFullRootResponse, body=lb_types.LoadBalancerRootPOST, status_code=201) def post(self, load_balancer): """"""Creates a load balancer."""""" load_balancer = load_balancer.loadbalancer context = pecan.request.context.get('octavia_context') project_id = context.project_id if context.is_admin or CONF.auth_strategy == constants.NOAUTH: if load_balancer.project_id: project_id = load_balancer.project_id if not project_id: raise exceptions.ValidationException(detail=_( ""Missing project ID in request where one is required."")) load_balancer.project_id = project_id ",20,18
openstack%2Fheat~master~Iefba0a53bd30f64e1a830bae8324d82b2e04c589,openstack/heat,master,Iefba0a53bd30f64e1a830bae8324d82b2e04c589,DNM test neutron,ABANDONED,2017-06-16 15:01:58.000000000,2017-06-17 03:27:17.000000000,,"[{'_account_id': 3}, {'_account_id': 7385}]","[{'number': 1, 'created': '2017-06-16 15:01:58.000000000', 'files': ['heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/96f11b0b2c88ba724244ec877f996cde5eb2d3a9', 'message': 'DNM test neutron\n\nChange-Id: Iefba0a53bd30f64e1a830bae8324d82b2e04c589\nDepends-On: I7e391d0ea8daefff72639357c3c9fc7dc38c5b91\n'}]",0,474998,96f11b0b2c88ba724244ec877f996cde5eb2d3a9,4,2,1,7385,,,0,"DNM test neutron

Change-Id: Iefba0a53bd30f64e1a830bae8324d82b2e04c589
Depends-On: I7e391d0ea8daefff72639357c3c9fc7dc38c5b91
",git fetch https://review.opendev.org/openstack/heat refs/changes/98/474998/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,96f11b0b2c88ba724244ec877f996cde5eb2d3a9,test,,,1,0
openstack%2Fheat~master~Ic0d06e4821cd270688608ca1936758d6cc61dac2,openstack/heat,master,Ic0d06e4821cd270688608ca1936758d6cc61dac2,DNM another test,ABANDONED,2017-06-16 15:10:19.000000000,2017-06-17 03:26:57.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8833}]","[{'number': 1, 'created': '2017-06-16 15:10:19.000000000', 'files': ['heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/dd86d5056dc11135b29e9758b63e85009707ae1f', 'message': 'DNM another test\n\nCheck another neutron patch of SG OVO\n\nDepends-On: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\nChange-Id: Ic0d06e4821cd270688608ca1936758d6cc61dac2\n'}]",0,475000,dd86d5056dc11135b29e9758b63e85009707ae1f,10,3,1,841,,,0,"DNM another test

Check another neutron patch of SG OVO

Depends-On: I740da1ea65a0af9451701e3a40fd673fa82f0f5b
Change-Id: Ic0d06e4821cd270688608ca1936758d6cc61dac2
",git fetch https://review.opendev.org/openstack/heat refs/changes/00/475000/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/service.py'],1,dd86d5056dc11135b29e9758b63e85009707ae1f,test,,,1,0
openstack%2Fironic~master~Ic00fc89443da95eb29338a5477f3af19b9d02aaf,openstack/ironic,master,Ic00fc89443da95eb29338a5477f3af19b9d02aaf,Remove unnecessary line in docstring,MERGED,2017-06-16 09:24:03.000000000,2017-06-17 03:10:14.000000000,2017-06-16 10:19:26.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 7711}, {'_account_id': 10239}, {'_account_id': 17998}]","[{'number': 1, 'created': '2017-06-16 09:24:03.000000000', 'files': ['ironic/tests/unit/conductor/test_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/50e1aa1d44532add607fa4b6d2d0b0af725e24f3', 'message': 'Remove unnecessary line in docstring\n\nAccidentally added in https://review.openstack.org/#/c/469932.\n\nChange-Id: Ic00fc89443da95eb29338a5477f3af19b9d02aaf\nRelated-Bug: #1666009\n'}]",0,474921,50e1aa1d44532add607fa4b6d2d0b0af725e24f3,9,5,1,14826,,,0,"Remove unnecessary line in docstring

Accidentally added in https://review.openstack.org/#/c/469932.

Change-Id: Ic00fc89443da95eb29338a5477f3af19b9d02aaf
Related-Bug: #1666009
",git fetch https://review.opendev.org/openstack/ironic refs/changes/21/474921/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/unit/conductor/test_utils.py'],1,50e1aa1d44532add607fa4b6d2d0b0af725e24f3,bug/1666009,, portgroup.,0,1
openstack%2Fopenstack-ansible~master~I2deace236b5a9a78c55692ad6f3326385ef25d35,openstack/openstack-ansible,master,I2deace236b5a9a78c55692ad6f3326385ef25d35,[WIP] DNM: testing verbose output,ABANDONED,2017-06-06 16:13:57.000000000,2017-06-17 03:08:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-06 16:13:57.000000000', 'files': ['scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/240de6078d025d01898eacd391bb49333b5e811a', 'message': '[WIP] DNM: testing verbose output\n\nChange-Id: I2deace236b5a9a78c55692ad6f3326385ef25d35\n'}]",0,471413,240de6078d025d01898eacd391bb49333b5e811a,3,1,1,17799,,,0,"[WIP] DNM: testing verbose output

Change-Id: I2deace236b5a9a78c55692ad6f3326385ef25d35
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/13/471413/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,240de6078d025d01898eacd391bb49333b5e811a,test-connection,ANSIBLE_PARAMETERS=${ANSIBLE_PARAMETERS:--e gather_facts=False -vvvvv},ANSIBLE_PARAMETERS=${ANSIBLE_PARAMETERS:--e gather_facts=False},1,1
openstack%2Fmurano~master~I0a164ea268a4069a7d09c1058008cb97bf9d1275,openstack/murano,master,I0a164ea268a4069a7d09c1058008cb97bf9d1275,Fix html_last_updated_fmt for Python3,MERGED,2017-06-16 07:30:50.000000000,2017-06-17 03:03:25.000000000,2017-06-17 03:03:25.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}, {'_account_id': 19930}]","[{'number': 1, 'created': '2017-06-16 07:30:50.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/a875b36dc007e91075ec08c18128ea5fa050da6f', 'message': 'Fix html_last_updated_fmt for Python3\n\nhtml_last_updated_fmt option is interpreted as a\nbyte string in python3, causing Sphinx build to break.\nThis patch makes it utf-8 string.\n\nChange-Id: I0a164ea268a4069a7d09c1058008cb97bf9d1275\n'}]",0,474877,a875b36dc007e91075ec08c18128ea5fa050da6f,9,5,1,25903,,,0,"Fix html_last_updated_fmt for Python3

html_last_updated_fmt option is interpreted as a
byte string in python3, causing Sphinx build to break.
This patch makes it utf-8 string.

Change-Id: I0a164ea268a4069a7d09c1058008cb97bf9d1275
",git fetch https://review.opendev.org/openstack/murano refs/changes/77/474877/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,a875b36dc007e91075ec08c18128ea5fa050da6f,html_last_updated_fmt, html_last_updated_fmt = subprocess.check_output(git_cmd).decode('utf-8'), html_last_updated_fmt = subprocess.check_output(git_cmd),1,1
openstack%2Ffuxi-kubernetes~master~Id0ed60e653b5a68d540bd7b38ed3b6358f127499,openstack/fuxi-kubernetes,master,Id0ed60e653b5a68d540bd7b38ed3b6358f127499,Initial codes for Fuxi-kubernetes,MERGED,2017-06-05 11:24:00.000000000,2017-06-17 02:38:42.000000000,2017-06-17 02:38:42.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 11536}, {'_account_id': 14352}, {'_account_id': 15168}]","[{'number': 1, 'created': '2017-06-05 11:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi-kubernetes/commit/77852e1ebcf2468f0badd6cc570d4da473f81ea4', 'message': 'Initial codes for Fuxi-kubernetes\n\nChange-Id: Id0ed60e653b5a68d540bd7b38ed3b6358f127499\n'}, {'number': 2, 'created': '2017-06-05 12:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi-kubernetes/commit/dea0f2b50a531ba11db4098f284123ceef9f6ca3', 'message': 'Initial codes for Fuxi-kubernetes\n\nChange-Id: Id0ed60e653b5a68d540bd7b38ed3b6358f127499\n'}, {'number': 3, 'created': '2017-06-05 12:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi-kubernetes/commit/90c26e63a61b212666b83ce8317fd118fc7b17f9', 'message': 'Initial codes for Fuxi-kubernetes\n\nChange-Id: Id0ed60e653b5a68d540bd7b38ed3b6358f127499\n'}, {'number': 4, 'created': '2017-06-12 12:30:58.000000000', 'files': ['doc/source/contributing.rst', '.gitignore', 'test-requirements.txt', 'fuxi_kubernetes/tests/__init__.py', 'README.rst', 'doc/source/usage.rst', 'babel.cfg', 'setup.py', 'doc/source/conf.py', 'doc/source/installation.rst', 'CONTRIBUTING.rst', 'doc/source/index.rst', 'requirements.txt', 'fuxi_kubernetes/tests/unit/base.py', 'fuxi_kubernetes/__init__.py', '.testr.conf', 'fuxi_kubernetes/tests/unit/__init__.py', 'doc/source/readme.rst', 'setup.cfg', 'LICENSE', 'tox.ini', 'HACKING.rst', 'fuxi_kubernetes/tests/unit/test_fuxi_kubernetes.py'], 'web_link': 'https://opendev.org/openstack/fuxi-kubernetes/commit/0678ee4adab87342fd743dd8ecef9c82808a068d', 'message': 'Initial codes for Fuxi-kubernetes\n\nChange-Id: Id0ed60e653b5a68d540bd7b38ed3b6358f127499\n'}]",1,470923,0678ee4adab87342fd743dd8ecef9c82808a068d,16,6,4,18266,,,0,"Initial codes for Fuxi-kubernetes

Change-Id: Id0ed60e653b5a68d540bd7b38ed3b6358f127499
",git fetch https://review.opendev.org/openstack/fuxi-kubernetes refs/changes/23/470923/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributing.rst', '.gitignore', 'test-requirements.txt', 'README.rst', 'doc/source/usage.rst', 'babel.cfg', 'setup.py', 'doc/source/conf.py', 'doc/source/installation.rst', 'CONTRIBUTING.rst', 'doc/source/index.rst', 'fuxi-kubernetes/tests/__init__.py', 'requirements.txt', 'fuxi-kubernetes/__init__.py', '.testr.conf', 'doc/source/readme.rst', 'setup.cfg', 'LICENSE', 'tox.ini', 'HACKING.rst', 'fuxi-kubernetes/tests/unit/__init__.py']",21,77852e1ebcf2468f0badd6cc570d4da473f81ea4,init,,,528,0
openstack%2Fnova~stable%2Fnewton~I25ba6f7f4e4fab6db223368427d889d6b06a77e8,openstack/nova,stable/newton,I25ba6f7f4e4fab6db223368427d889d6b06a77e8,Fix regression preventing reporting negative resources for overcommit,MERGED,2017-06-16 19:05:39.000000000,2017-06-17 02:33:02.000000000,2017-06-16 22:02:30.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-06-16 19:05:39.000000000', 'files': ['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d8b30c3772dae32ac4cbedb659f6d08eb795425a', 'message': ""Fix regression preventing reporting negative resources for overcommit\n\nIn Nova prior to Ocata, the scheduler computes available resources for\na compute node, attempting to mirror the same calculation that happens\nlocally. It does this to determine if a new instance should fit on the\nnode. If overcommit is being used, some of these numbers can be negative.\n\nIn change 016b810f675b20e8ce78f4c82dc9c679c0162b7a we changed the\ncompute side to never report negative resources, which was an ironic-\nspecific fix for nodes that are offline. That, however, has been\ncorrected for ironic nodes in 047da6498dbb3af71bcb9e6d0e2c38aa23b06615.\nSince the base change to the resource tracker has caused the scheduler\nand compute to do different math, we need to revert it to avoid the\nscheduler sending instances to nodes where it believes -NNN is the\nlower limit (with overcommit), but the node is reporting zero.\n\nThis doesn't actually affect Ocata because of our use of the placement\nengine. However, this code is still in master and needs to be backported.\nThis part of the change actually didn't even have a unit test, so\nthis patch adds one to validate that the resource tracker will\ncalculate and report negative resources.\n\nConflicts:\n      nova/compute/resource_tracker.py\n\nNOTE(mriedem): The conflict is due to change\nI6827137f35c0cb4f9fc4c6f753d9a035326ed01b not being in Newton.\n\nChange-Id: I25ba6f7f4e4fab6db223368427d889d6b06a77e8\nCloses-Bug: #1698383\n(cherry picked from commit 0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d)\n(cherry picked from commit 3284851437e24250d46edba20789a2e5f1f435a0)\n""}]",0,475057,d8b30c3772dae32ac4cbedb659f6d08eb795425a,13,6,1,6873,,,0,"Fix regression preventing reporting negative resources for overcommit

In Nova prior to Ocata, the scheduler computes available resources for
a compute node, attempting to mirror the same calculation that happens
locally. It does this to determine if a new instance should fit on the
node. If overcommit is being used, some of these numbers can be negative.

In change 016b810f675b20e8ce78f4c82dc9c679c0162b7a we changed the
compute side to never report negative resources, which was an ironic-
specific fix for nodes that are offline. That, however, has been
corrected for ironic nodes in 047da6498dbb3af71bcb9e6d0e2c38aa23b06615.
Since the base change to the resource tracker has caused the scheduler
and compute to do different math, we need to revert it to avoid the
scheduler sending instances to nodes where it believes -NNN is the
lower limit (with overcommit), but the node is reporting zero.

This doesn't actually affect Ocata because of our use of the placement
engine. However, this code is still in master and needs to be backported.
This part of the change actually didn't even have a unit test, so
this patch adds one to validate that the resource tracker will
calculate and report negative resources.

Conflicts:
      nova/compute/resource_tracker.py

NOTE(mriedem): The conflict is due to change
I6827137f35c0cb4f9fc4c6f753d9a035326ed01b not being in Newton.

Change-Id: I25ba6f7f4e4fab6db223368427d889d6b06a77e8
Closes-Bug: #1698383
(cherry picked from commit 0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d)
(cherry picked from commit 3284851437e24250d46edba20789a2e5f1f435a0)
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/475057/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py']",2,d8b30c3772dae32ac4cbedb659f6d08eb795425a,bug/1698383,," self.compute_node.free_ram_mb = max(0, self.compute_node.free_ram_mb) self.compute_node.free_disk_gb = max(0, self.compute_node.free_disk_gb)",21,2
openstack%2Fnova~stable%2Focata~I25ba6f7f4e4fab6db223368427d889d6b06a77e8,openstack/nova,stable/ocata,I25ba6f7f4e4fab6db223368427d889d6b06a77e8,Fix regression preventing reporting negative resources for overcommit,MERGED,2017-06-16 17:50:19.000000000,2017-06-17 01:44:05.000000000,2017-06-16 20:32:56.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 16376}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-06-16 17:50:19.000000000', 'files': ['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3284851437e24250d46edba20789a2e5f1f435a0', 'message': ""Fix regression preventing reporting negative resources for overcommit\n\nIn Nova prior to Ocata, the scheduler computes available resources for\na compute node, attempting to mirror the same calculation that happens\nlocally. It does this to determine if a new instance should fit on the\nnode. If overcommit is being used, some of these numbers can be negative.\n\nIn change 016b810f675b20e8ce78f4c82dc9c679c0162b7a we changed the\ncompute side to never report negative resources, which was an ironic-\nspecific fix for nodes that are offline. That, however, has been\ncorrected for ironic nodes in 047da6498dbb3af71bcb9e6d0e2c38aa23b06615.\nSince the base change to the resource tracker has caused the scheduler\nand compute to do different math, we need to revert it to avoid the\nscheduler sending instances to nodes where it believes -NNN is the\nlower limit (with overcommit), but the node is reporting zero.\n\nThis doesn't actually affect Ocata because of our use of the placement\nengine. However, this code is still in master and needs to be backported.\nThis part of the change actually didn't even have a unit test, so\nthis patch adds one to validate that the resource tracker will\ncalculate and report negative resources.\n\nConflicts:\n      nova/compute/resource_tracker.py\n      nova/tests/unit/compute/test_resource_tracker.py\n\nNOTE(mriedem): The conflict is due to change\nI80ba844a6e0fcea89f80aa253d57ac73092773ae not being in Ocata.\n\nChange-Id: I25ba6f7f4e4fab6db223368427d889d6b06a77e8\nCloses-Bug: #1698383\n(cherry picked from commit 0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d)\n""}]",0,475044,3284851437e24250d46edba20789a2e5f1f435a0,14,7,1,6873,,,0,"Fix regression preventing reporting negative resources for overcommit

In Nova prior to Ocata, the scheduler computes available resources for
a compute node, attempting to mirror the same calculation that happens
locally. It does this to determine if a new instance should fit on the
node. If overcommit is being used, some of these numbers can be negative.

In change 016b810f675b20e8ce78f4c82dc9c679c0162b7a we changed the
compute side to never report negative resources, which was an ironic-
specific fix for nodes that are offline. That, however, has been
corrected for ironic nodes in 047da6498dbb3af71bcb9e6d0e2c38aa23b06615.
Since the base change to the resource tracker has caused the scheduler
and compute to do different math, we need to revert it to avoid the
scheduler sending instances to nodes where it believes -NNN is the
lower limit (with overcommit), but the node is reporting zero.

This doesn't actually affect Ocata because of our use of the placement
engine. However, this code is still in master and needs to be backported.
This part of the change actually didn't even have a unit test, so
this patch adds one to validate that the resource tracker will
calculate and report negative resources.

Conflicts:
      nova/compute/resource_tracker.py
      nova/tests/unit/compute/test_resource_tracker.py

NOTE(mriedem): The conflict is due to change
I80ba844a6e0fcea89f80aa253d57ac73092773ae not being in Ocata.

Change-Id: I25ba6f7f4e4fab6db223368427d889d6b06a77e8
Closes-Bug: #1698383
(cherry picked from commit 0ddf3ce01149d78ee0cf8f7497f8a9074c6f167d)
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/475044/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_resource_tracker.py', 'nova/compute/resource_tracker.py']",2,3284851437e24250d46edba20789a2e5f1f435a0,bug/1698383,," cn.free_ram_mb = max(0, cn.free_ram_mb) cn.free_disk_gb = max(0, cn.free_disk_gb)",20,2
openstack%2Fopenstack-ansible-tests~master~I93318a73c43ff7c6ae423271bd8c252ad94b0149,openstack/openstack-ansible-tests,master,I93318a73c43ff7c6ae423271bd8c252ad94b0149,Disable PrivateDevices for galera and Memcached,MERGED,2017-06-15 20:04:40.000000000,2017-06-17 01:08:54.000000000,2017-06-16 23:19:37.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-15 20:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/4b6483e6ac065f4e1fe682309a7de3e947733c20', 'message': ""[test] do not merge (it's pointless)\n\nChange-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149\nDepends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83\n""}, {'number': 2, 'created': '2017-06-16 14:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/70bf6a564148a10bfe23d936b7d28215bd233338', 'message': 'Disable PrivateDevices for galera and Memcached\n\nChange-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149\nDepends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83\n'}, {'number': 3, 'created': '2017-06-16 14:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/e4eb1aa502cc822edf6029741b595dda991366e3', 'message': 'Disable PrivateDevices for galera and Memcached\n\nChange-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149\nDepends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83\nRelated-Bug: 1697531\n'}, {'number': 4, 'created': '2017-06-16 14:35:45.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/7938542000caeb20583033b7bed4970488565891', 'message': 'Disable PrivateDevices for galera and Memcached\n\nChange-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149\nDepends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83\nRelated-Bug: 1697531\n'}]",0,474765,7938542000caeb20583033b7bed4970488565891,47,5,4,13095,,,0,"Disable PrivateDevices for galera and Memcached

Change-Id: I93318a73c43ff7c6ae423271bd8c252ad94b0149
Depends-On: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83
Related-Bug: 1697531
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/65/474765/4 && git format-patch -1 --stdout FETCH_HEAD,['test-install-galera.yml'],1,4b6483e6ac065f4e1fe682309a7de3e947733c20,bug/1697531,,,1,0
openstack%2Fnova~master~I09343b863b374d969b8c6d48b7fa21833cd27591,openstack/nova,master,I09343b863b374d969b8c6d48b7fa21833cd27591,Fixing issues with functional server_group tests,ABANDONED,2017-06-15 01:32:44.000000000,2017-06-17 00:50:52.000000000,,"[{'_account_id': 3}, {'_account_id': 4690}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-06-15 01:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c4aca465008c77c21e220b39c08b714c16d1f3e6', 'message': 'Fixing issues with functional server_group tests\n\nWhen working on Change #390984 I encountered a couple of bugs\nwith these tests, and the tests would fail about 50% of the time.\n\nThis patch explicitly names the first host, host1, and adds it\nto the global FAKE_NODES variable from the fake driver.\n\nChange-Id: I09343b863b374d969b8c6d48b7fa21833cd27591\n'}, {'number': 2, 'created': '2017-06-15 06:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15ca24fb4771331307b98a5b54c7204672c52fbd', 'message': 'Fixing issues with functional server_group tests\n\nWhen working on Change #390984 I encountered a couple of bugs\nwith these tests, and the tests would fail about 50% of the time.\n\nThis patch explicitly names the first host, host1, and adds it\nto the global FAKE_NODES variable from the fake driver.\n\nWe also handle all cases where the nodes where not set at all.\n\nChange-Id: I09343b863b374d969b8c6d48b7fa21833cd27591\n'}, {'number': 3, 'created': '2017-06-15 07:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c347456b7ad58baacf525677a68ddf587e330512', 'message': 'Fixing issues with functional server_group tests\n\nWhen working on Change #390984 I encountered a couple of bugs\nwith these tests, and the tests would fail about 50% of the time.\n\nThis patch explicitly names the first host, host1, and adds it\nto the global FAKE_NODES variable from the fake driver.\n\nWe also handle all cases where the nodes where not set at all.\n\nChange-Id: I09343b863b374d969b8c6d48b7fa21833cd27591\n'}, {'number': 4, 'created': '2017-06-15 07:46:20.000000000', 'files': ['nova/tests/functional/test_server_group.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a806623393a6913c7f1c7b7ee40ed0d8714762c', 'message': 'Fixing issues with functional server_group tests\n\nWhen working on Change #390984 I encountered a couple of bugs\nwith these tests, and the tests would fail about 50% of the time.\n\nThis patch explicitly names the first host, host1, and adds it\nto the global FAKE_NODES variable from the fake driver.\n\nWe also handle all cases where the nodes where not set at all.\n\nChange-Id: I09343b863b374d969b8c6d48b7fa21833cd27591\n'}]",8,474404,7a806623393a6913c7f1c7b7ee40ed0d8714762c,34,8,4,22623,,,0,"Fixing issues with functional server_group tests

When working on Change #390984 I encountered a couple of bugs
with these tests, and the tests would fail about 50% of the time.

This patch explicitly names the first host, host1, and adds it
to the global FAKE_NODES variable from the fake driver.

We also handle all cases where the nodes where not set at all.

Change-Id: I09343b863b374d969b8c6d48b7fa21833cd27591
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/474404/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/test_server_group.py'],1,c4aca465008c77c21e220b39c08b714c16d1f3e6,bug/1635367," fake.set_nodes(['host1']) self.addCleanup(fake.restore_nodes) self.compute = self.start_service('compute', host='host1') fake.set_nodes(['host2', 'host3']) self.start_service('compute', host='host3') ", self.compute = self.start_service('compute'),8,1
openstack%2Fpuppet-tripleo~stable%2Focata~I435c95430cd7f3cfe5c25a1b3bc83064e6ca13be,openstack/puppet-tripleo,stable/ocata,I435c95430cd7f3cfe5c25a1b3bc83064e6ca13be,This patch moves Contrail roles to OpenStack API communication from the public external to the internal_api network. It also adds the missing configuration option for dpdk.,ABANDONED,2017-06-16 17:32:52.000000000,2017-06-17 00:50:44.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-16 17:32:52.000000000', 'files': ['manifests/network/contrail/heat.pp', 'manifests/haproxy.pp', 'manifests/network/contrail/webui.pp', 'manifests/network/contrail/database.pp', 'manifests/network/contrail/analytics.pp', 'manifests/network/contrail/config.pp', 'manifests/network/contrail/provision.pp', 'manifests/network/contrail/neutron_plugin.pp', 'manifests/network/contrail/control.pp', 'manifests/network/contrail/analyticsdatabase.pp', 'manifests/network/contrail/vrouter.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/41d1652bba9067bc10c0c29a7c8ab5f3bed6bb4a', 'message': 'This patch moves Contrail roles to OpenStack API\ncommunication from the public external to the internal_api network.\nIt also adds the missing configuration option for dpdk.\n\nChange-Id: I435c95430cd7f3cfe5c25a1b3bc83064e6ca13be\nCloses-Bug: 1698422\n'}]",0,475039,41d1652bba9067bc10c0c29a7c8ab5f3bed6bb4a,4,1,1,22323,,,0,"This patch moves Contrail roles to OpenStack API
communication from the public external to the internal_api network.
It also adds the missing configuration option for dpdk.

Change-Id: I435c95430cd7f3cfe5c25a1b3bc83064e6ca13be
Closes-Bug: 1698422
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/39/475039/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/network/contrail/heat.pp', 'manifests/haproxy.pp', 'manifests/network/contrail/webui.pp', 'manifests/network/contrail/analytics.pp', 'manifests/network/contrail/config.pp', 'manifests/network/contrail/database.pp', 'manifests/network/contrail/provision.pp', 'manifests/network/contrail/neutron_plugin.pp', 'manifests/network/contrail/control.pp', 'manifests/network/contrail/analyticsdatabase.pp', 'manifests/network/contrail/vrouter.pp']",11,41d1652bba9067bc10c0c29a7c8ab5f3bed6bb4a,bug/1698422,"# Defaults to hiera('contrail_config_vip',hiera('internal_api_virtual_ip'))# Defaults to hiera('contrail::disc_server_ip')# [*internal_vip*]# Defaults to hiera('internal_api_virtual_ip')# [*is_dpdk*] # (optional) Turns vrouter into DPDK Compute Node # String value. # Defaults to hiera('contrail::vrouter::is_dpdk',false) # $api_server = hiera('contrail_config_vip',hiera('internal_api_virtual_ip')), $control_server = hiera('contrail::vrouter::control_node_ips'), $disc_server_ip = hiera('contrail_config_vip',hiera('internal_api_virtual_ip')), $internal_vip = hiera('internal_api_virtual_ip'), $is_dpdk = hiera('contrail::vrouter::is_dpdk',false), if size($control_server) == 0 { #$control_server_list = join(hiera('contrail_control_node_ips'), ' ') $control_server_list = '' } else { $control_server_list = join($control_server, ' ') } 'AUTHN_SERVER' => $auth_host, 'AUTHN_SERVER' => $auth_host, $macaddress = inline_template(""<%= scope.lookupvar('::macaddress_${physical_interface}') -%>"") $vrouter_agent_config = { 'DEFAULT' => { 'DNS' => { 'server' => $control_server_list, }, 'NETWORKS' => { 'control_network_ip' => $host_ip, }, 'VIRTUAL-HOST-INTERFACE' => { 'compute_node_address' => $host_ip, 'gateway' => $gateway, 'ip' => ""${host_ip}/${cidr}"", 'name' => 'vhost0', 'physical_interface' => $physical_interface, }, 'METADATA' => { 'metadata_proxy_secret' => $metadata_secret, }, 'DISCOVERY' => { 'server' => $disc_server_ip, 'port' => $disc_server_port, }, } } elsif $is_dpdk { $pciaddress = generate('/bin/cat','/etc/contrail/dpdk_pci') $macaddress = generate('/bin/cat','/etc/contrail/dpdk_mac') $vrouter_agent_config = { 'DEFAULT' => { 'platform' => 'dpdk', 'physical_uio_driver' => 'uio_pci_generic', 'physical_interface_mac' => $macaddress, 'physical_interface_address' => $pciaddress, }, 'DNS' => { 'server' => $control_server_list, }, 'CONTROL-NODE' => { 'server' => $control_server_list, }, 'NETWORKS' => { 'control_network_ip' => $host_ip, }, $macaddress = inline_template(""<%= scope.lookupvar('::macaddress_${physical_interface}') -%>"") $vrouter_agent_config = { 'DNS' => { 'server' => $control_server_list, }, 'NETWORKS' => { 'control_network_ip' => $host_ip, }, is_dpdk => $is_dpdk, is_dpdk => $is_dpdk,","# Defaults to hiera('contrail_config_vip')# Defaults to hiera('contrail_config_vip'),# [*public_vip*]# Defaults to hiera('public_virtual_ip') $api_server = hiera('contrail_config_vip'), $control_server = hiera('contrail_control_node_ips'), $disc_server_ip = hiera('contrail_config_vip'), $public_vip = hiera('public_virtual_ip'), $macaddress = inline_template(""<%= scope.lookupvar('::macaddress_${physical_interface}') -%>"") $control_server_list = join($control_server, ' ') 'AUTHN_SERVER' => $public_vip, 'AUTHN_SERVER' => $public_vip, $vrouter_agent_config = { 'DEBUG' => { $vrouter_agent_config = {",252,116
openstack%2Foctavia~master~Ib48e4e36f41e6c292e687cd765b1ccc0464d6457,openstack/octavia,master,Ib48e4e36f41e6c292e687cd765b1ccc0464d6457,Enable DIB trace logging,MERGED,2017-06-15 22:43:25.000000000,2017-06-17 00:18:13.000000000,2017-06-17 00:18:13.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22623}]","[{'number': 1, 'created': '2017-06-15 22:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/03ed0d63d9aad185f80fd6963fe47720c20aeb75', 'message': 'Enable DIB trace logging\n\nChange-Id: Ib48e4e36f41e6c292e687cd765b1ccc0464d6457\n'}, {'number': 2, 'created': '2017-06-15 22:47:15.000000000', 'files': ['octavia/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/c75908853bc27edc930b7150d8f8ea10ae706ced', 'message': 'Enable DIB trace logging\n\nChange-Id: Ib48e4e36f41e6c292e687cd765b1ccc0464d6457\n'}]",0,474800,c75908853bc27edc930b7150d8f8ea10ae706ced,19,4,2,10273,,,0,"Enable DIB trace logging

Change-Id: Ib48e4e36f41e6c292e687cd765b1ccc0464d6457
",git fetch https://review.opendev.org/openstack/octavia refs/changes/00/474800/2 && git format-patch -1 --stdout FETCH_HEAD,['octavia/tests/contrib/gate_hook.sh'],1,03ed0d63d9aad185f80fd6963fe47720c20aeb75,, export OCTAVIA_DIB_TRACING=1,,1,0
openstack%2Fnova~master~I12b6a29cd0bc355ac9c023c3fa14be9d409bf775,openstack/nova,master,I12b6a29cd0bc355ac9c023c3fa14be9d409bf775,conf: remove console_driver opt,MERGED,2017-03-03 21:31:16.000000000,2017-06-17 00:14:51.000000000,2017-06-15 07:16:26.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19590}, {'_account_id': 19741}, {'_account_id': 20040}, {'_account_id': 20217}]","[{'number': 1, 'created': '2017-03-03 21:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a6bbd445203c1c4b9f42f0723adf612220c71a6', 'message': 'conf: remove console_driver opt\n\nconsole_driver opt has beed deprecated since Ocata and can be\nremoved from nova.\n\nChange-Id: I12b6a29cd0bc355ac9c023c3fa14be9d409bf775\nImplements: blueprint centralize-config-options-pike\n'}, {'number': 2, 'created': '2017-03-03 23:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b52f71ff064bad7395544389d1fa9828e128b359', 'message': 'conf: remove console_driver opt\n\nconsole_driver opt has beed deprecated since Ocata and can be\nremoved from nova.\n\nChange-Id: I12b6a29cd0bc355ac9c023c3fa14be9d409bf775\nImplements: blueprint centralize-config-options-pike\n'}, {'number': 3, 'created': '2017-03-06 19:49:36.000000000', 'files': ['releasenotes/notes/remove-console-driver-opt-07344dbc02badaa4.yaml', 'nova/conf/console.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f71e5687f545a3b3b981b851d719bbab1cf49ddd', 'message': 'conf: remove console_driver opt\n\nconsole_driver opt has beed deprecated since Ocata and can be\nremoved from nova.\n\nChange-Id: I12b6a29cd0bc355ac9c023c3fa14be9d409bf775\nImplements: blueprint centralize-config-options-pike\n'}]",2,441485,f71e5687f545a3b3b981b851d719bbab1cf49ddd,73,19,3,14511,,,0,"conf: remove console_driver opt

console_driver opt has beed deprecated since Ocata and can be
removed from nova.

Change-Id: I12b6a29cd0bc355ac9c023c3fa14be9d409bf775
Implements: blueprint centralize-config-options-pike
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/441485/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/remove-console-driver-opt-07344dbc02badaa4.yaml', 'nova/conf/console.py']",2,9a6bbd445203c1c4b9f42f0723adf612220c71a6,bp/centralize-config-options-pike,," cfg.StrOpt('console_driver', default='nova.console.xvp.XVPConsoleProxy', deprecated_for_removal=True, deprecated_since='15.0.0', deprecated_reason="""""" This option no longer does anything. Previously this option had only two valid, in-tree values: nova.console.xvp.XVPConsoleProxy and nova.console.fake.FakeConsoleProxy. The latter of these was only used in tests and has since been replaced. """""", help="""""" nova-console-proxy is used to set up multi-tenant VM console access. This option allows pluggable driver program for the console session and represents driver to use for the console proxy. Possible values: * A string representing fully classified class name of console driver. """"""),",5,19
openstack%2Fshade~master~I05c31400e6f2e584a656c8ab422875be2d6f6bfe,openstack/shade,master,I05c31400e6f2e584a656c8ab422875be2d6f6bfe,Add some release notes we forgot to add,MERGED,2017-06-14 23:08:37.000000000,2017-06-17 00:06:09.000000000,2017-06-17 00:06:09.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-14 23:08:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/7c894eb4d8d1dc8e2f6df244665b50ca0fc316b0', 'message': 'Add some release notes we forgot to add\n\nChange-Id: I05c31400e6f2e584a656c8ab422875be2d6f6bfe\n'}, {'number': 2, 'created': '2017-06-15 21:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/a24dd65d7c613408ae544a445298147aa7ae8d26', 'message': 'Add some release notes we forgot to add\n\nChange-Id: I05c31400e6f2e584a656c8ab422875be2d6f6bfe\n'}, {'number': 3, 'created': '2017-06-16 02:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/d40865e0dfdda1cb3fccaecb33b5333a0dce4fd9', 'message': 'Add some release notes we forgot to add\n\nChange-Id: I05c31400e6f2e584a656c8ab422875be2d6f6bfe\n'}, {'number': 4, 'created': '2017-06-16 12:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/2ca7521661b82fd28b70a12ccefd9f04f43023e9', 'message': 'Add some release notes we forgot to add\n\nChange-Id: I05c31400e6f2e584a656c8ab422875be2d6f6bfe\n'}, {'number': 5, 'created': '2017-06-16 22:31:57.000000000', 'files': ['releasenotes/notes/multiple-updates-b48cc2f6db2e526d.yaml'], 'web_link': 'https://opendev.org/openstack/shade/commit/c431cc2c4bed6b8b181fd94b6d57098b32c68c83', 'message': 'Add some release notes we forgot to add\n\nChange-Id: I05c31400e6f2e584a656c8ab422875be2d6f6bfe\n'}]",0,474385,c431cc2c4bed6b8b181fd94b6d57098b32c68c83,30,2,5,2,,,0,"Add some release notes we forgot to add

Change-Id: I05c31400e6f2e584a656c8ab422875be2d6f6bfe
",git fetch https://review.opendev.org/openstack/shade refs/changes/85/474385/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/multiple-updates-b48cc2f6db2e526d.yaml'],1,7c894eb4d8d1dc8e2f6df244665b50ca0fc316b0,475049,--- features: - Removed unneeded calls that were made when deleting servers with floating ips. - Added pagination support for volume listing. upgrade: - Removed designateclient as a dependency. All designate operations are now performed with direct REST calls using keystoneauth Adapter. - Server creation calls are now done with direct REST calls. fixes: - Fixed a bug related to neutron endpoints that did not have trailing slashes. - Fixed issue with ports not having a created_at attribute. ,,14,0
openstack%2Fshade~master~Ia88d1d8a6b3558f7d5d364a9c78bbf834836d3f7,openstack/shade,master,Ia88d1d8a6b3558f7d5d364a9c78bbf834836d3f7,Retry to fetch paginated volumes if we get 404 for next link,MERGED,2017-06-16 18:19:26.000000000,2017-06-17 00:03:59.000000000,2017-06-17 00:03:58.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 170}]","[{'number': 1, 'created': '2017-06-16 18:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/fde50d38c8ef2dbfb74441b1e29f26da96af4e60', 'message': ""Retry to fetch paginated volumes if we get 404 for next link\n\nWhen we get a volume list, it's possible for a volume to disappear\ncausing the pagination to bork. When that happens we retry to\nget the list from scratch for 5 times. If all the attempts fail\nwe just return what we found.\n\nChange-Id: Ia88d1d8a6b3558f7d5d364a9c78bbf834836d3f7\nSigned-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>\n""}, {'number': 2, 'created': '2017-06-16 21:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/d5c05a8898027ba70c00d62eb0eb27451915c461', 'message': ""Retry to fetch paginated volumes if we get 404 for next link\n\nWhen we get a volume list, it's possible for a volume to disappear\ncausing the pagination to bork. When that happens we retry to\nget the list from scratch for 5 times. If all the attempts fail\nwe just return what we found.\n\nChange-Id: Ia88d1d8a6b3558f7d5d364a9c78bbf834836d3f7\nSigned-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>\n""}, {'number': 3, 'created': '2017-06-16 22:29:19.000000000', 'files': ['shade/tests/unit/test_volume.py', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/6b325282d3ab2f848de372a80def36b01b6ba6f4', 'message': ""Retry to fetch paginated volumes if we get 404 for next link\n\nWhen we get a volume list, it's possible for a volume to disappear\ncausing the pagination to bork. When that happens we retry to\nget the list from scratch for 5 times. If all the attempts fail\nwe just return what we found.\n\nChange-Id: Ia88d1d8a6b3558f7d5d364a9c78bbf834836d3f7\nSigned-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>\n""}]",0,475049,6b325282d3ab2f848de372a80def36b01b6ba6f4,13,3,3,986,,,0,"Retry to fetch paginated volumes if we get 404 for next link

When we get a volume list, it's possible for a volume to disappear
causing the pagination to bork. When that happens we retry to
get the list from scratch for 5 times. If all the attempts fail
we just return what we found.

Change-Id: Ia88d1d8a6b3558f7d5d364a9c78bbf834836d3f7
Signed-off-by: Rosario Di Somma <rosario.disomma@dreamhost.com>
",git fetch https://review.opendev.org/openstack/shade refs/changes/49/475049/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_volume.py', 'shade/openstackcloud.py']",2,fde50d38c8ef2dbfb74441b1e29f26da96af4e60,," try: _list(self._volume_client.get(endpoint)) except OpenStackCloudURINotFound: # Catch and re-raise here because we are making recursive # calls and we just have context for the log here self.log.debug( ""While listing volumes, could not find next link"" "" {link}."".format(link=data)) raise attempts = 5 for _ in range(attempts): try: volumes = [] _list(self._volume_client.get('/volumes/detail')) return self._normalize_volumes(volumes) except OpenStackCloudURINotFound: pass else: self.log.debug( ""List volumes failed to retrieve all volumes after"" "" {attempts} attempts. Returning what we found."".format( attempts=attempts)) # list volumes didn't complete succesfully so just return what # we found", _list(self._volume_client.get(endpoint)) _list(self._volume_client.get('/volumes/detail')),117,2
openstack%2Fpuppet-keystone~master~I69da4d70fd3720a01ce1e166a5725a9c76d4c126,openstack/puppet-keystone,master,I69da4d70fd3720a01ce1e166a5725a9c76d4c126,include policy class in api.pp,MERGED,2017-06-15 18:16:34.000000000,2017-06-16 23:59:59.000000000,2017-06-16 23:47:04.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22600}]","[{'number': 1, 'created': '2017-06-15 18:16:34.000000000', 'files': ['manifests/init.pp', 'spec/classes/keystone_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a69d3d6018f16344ee6d80c5f723da3f2c579077', 'message': 'include policy class in api.pp\n\nLike we do in other modules, include keystone::policy class in\n::keystone so users can define policies without taking care of the\nclass.\n\nChange-Id: I69da4d70fd3720a01ce1e166a5725a9c76d4c126\n'}]",0,474722,a69d3d6018f16344ee6d80c5f723da3f2c579077,19,5,1,3153,,,0,"include policy class in api.pp

Like we do in other modules, include keystone::policy class in
::keystone so users can define policies without taking care of the
class.

Change-Id: I69da4d70fd3720a01ce1e166a5725a9c76d4c126
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/22/474722/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/keystone_init_spec.rb']",2,a69d3d6018f16344ee6d80c5f723da3f2c579077,policies, it { is_expected.to contain_class('keystone::policy') },,2,0
openstack%2Fproject-config~master~I67574376bf289eb3f1c0236a30fa143fac7ef529,openstack/project-config,master,I67574376bf289eb3f1c0236a30fa143fac7ef529,Add RDO Cloud-related definitions to project-config,ABANDONED,2017-06-07 20:35:30.000000000,2017-06-16 23:53:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 4162}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-06-07 20:35:30.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e049a9370f5a0f4540ce934985a93577e42ae2da', 'message': 'Add RDO Cloud-related definitions to project-config\n\nRDO Cloud is now available to be used as host cloud\nfor CI jobs. This review adds the required node and\nprovider definitions to schedule jobs on RDO Cloud.\n\nChange-Id: I67574376bf289eb3f1c0236a30fa143fac7ef529\n'}]",2,471909,e049a9370f5a0f4540ce934985a93577e42ae2da,10,6,1,9976,,,0,"Add RDO Cloud-related definitions to project-config

RDO Cloud is now available to be used as host cloud
for CI jobs. This review adds the required node and
provider definitions to schedule jobs on RDO Cloud.

Change-Id: I67574376bf289eb3f1c0236a30fa143fac7ef529
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/471909/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,e049a9370f5a0f4540ce934985a93577e42ae2da,rdocloud-definition, - name: rdocloud-centos-7 image: centos-7 ready-script: configure_mirror.sh min-ready: 6 providers: - name: tripleo-test-rdocloud - name: tripleo-test-rdocloud region-name: 'regionOne' cloud: tripleo-test-rdocloud boot-timeout: 120 max-servers: 70 rate: 0.001 clean-floating-ips: true networks: - net-label: private template-hostname: '{image.name}-{timestamp}' images: - name: centos-7 min-ram: 6144 name-filter: undercloud diskimage: centos-7 username: jenkins private-key: /home/nodepool/.ssh/id_rsa config-drive: true key-name: infra-root-keys,,25,0
openstack%2Fpuppet-zaqar~master~I9f549f11bd4e939ad41ff77c51dd2f32338621c8,openstack/puppet-zaqar,master,I9f549f11bd4e939ad41ff77c51dd2f32338621c8,include policy class in api.pp,MERGED,2017-06-15 18:14:30.000000000,2017-06-16 23:47:11.000000000,2017-06-16 23:47:11.000000000,"[{'_account_id': 3}, {'_account_id': 9414}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-15 18:14:30.000000000', 'files': ['spec/classes/zaqar_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-zaqar/commit/03ec6b471152e77ba89f31ff6918cd139497073b', 'message': 'include policy class in api.pp\n\nLike we do in other modules, include zaqar::policy class in\nzaqar::server so users can define policies without taking care of the\nclass.\n\nChange-Id: I9f549f11bd4e939ad41ff77c51dd2f32338621c8\n'}]",0,474719,03ec6b471152e77ba89f31ff6918cd139497073b,11,3,1,3153,,,0,"include policy class in api.pp

Like we do in other modules, include zaqar::policy class in
zaqar::server so users can define policies without taking care of the
class.

Change-Id: I9f549f11bd4e939ad41ff77c51dd2f32338621c8
",git fetch https://review.opendev.org/openstack/puppet-zaqar refs/changes/19/474719/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/zaqar_server_spec.rb', 'manifests/server.pp']",2,03ec6b471152e77ba89f31ff6918cd139497073b,policies, include ::zaqar::policy,,2,0
openstack%2Ftripleo-quickstart-extras~master~If811682c3312c86f0c407e880be24ad71d6ea72b,openstack/tripleo-quickstart-extras,master,If811682c3312c86f0c407e880be24ad71d6ea72b,Limit collection of config-data to puppet-generated files,MERGED,2017-06-16 08:26:58.000000000,2017-06-16 23:36:24.000000000,2017-06-16 23:36:24.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 10969}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-06-16 08:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c460f9cdd3fb12c115338b23dccda917b01cd90a', 'message': 'Limit collection of config-data to puppet-generated files\n\nThis should give us all the information we need to debug CI failures\nwhile keeping the size of collected data relatively small.\n\nChange-Id: If811682c3312c86f0c407e880be24ad71d6ea72b\nDepends-On: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45\n'}, {'number': 2, 'created': '2017-06-16 08:39:57.000000000', 'files': ['roles/collect-logs/tasks/collect.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2cb712c95f9b9b75246c5b0051729989aecb44a0', 'message': 'Limit collection of config-data to puppet-generated files\n\nThis should give us all the information we need to debug CI failures\nwhile keeping the size of collected data relatively small.\n\nChange-Id: If811682c3312c86f0c407e880be24ad71d6ea72b\nRelated-Bug: #1698172\nDepends-On: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45\n'}]",0,474896,2cb712c95f9b9b75246c5b0051729989aecb44a0,21,7,2,13039,,,0,"Limit collection of config-data to puppet-generated files

This should give us all the information we need to debug CI failures
while keeping the size of collected data relatively small.

Change-Id: If811682c3312c86f0c407e880be24ad71d6ea72b
Related-Bug: #1698172
Depends-On: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/96/474896/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/collect-logs/tasks/collect.yml'],1,c460f9cdd3fb12c115338b23dccda917b01cd90a,bug/1698172, shell: cp -r /var/lib/config-data/puppet-generated /var/log/config-data, shell: cp -r /var/lib/config-data /var/log/config-data,1,1
openstack%2Fnova~master~Ic72b47c11b83ce5151bc34b13eb78af4676dc71a,openstack/nova,master,Ic72b47c11b83ce5151bc34b13eb78af4676dc71a,Centralize compute_node_search_by_hypervisor in os-hypervisors,MERGED,2017-06-14 22:37:01.000000000,2017-06-16 23:34:07.000000000,2017-06-15 12:54:11.000000000,"[{'_account_id': 3}, {'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-06-14 22:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f27189026e3511ef4f034ca14bff0b34cfb77212', 'message': ""Centralize compute_node_search_by_hypervisor in os-hypervisors\n\nThe search and servers routes have very similar code that is calling\ncompute_node_search_by_hypervisor and passing the hypervisor\nhostname pattern. There is going to be an upcoming change where\nwe deprecate these APIs and move them into the index() method using\nquery parameters, so we'll need to use similar code. So centralize\nthis now so the later change is simpler and can just re-use it.\n\nPart of blueprint service-hyper-uuid-in-api\n\nChange-Id: Ic72b47c11b83ce5151bc34b13eb78af4676dc71a\n""}, {'number': 2, 'created': '2017-06-15 00:37:21.000000000', 'files': ['nova/api/openstack/compute/hypervisors.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ffeacdaa74840fbb67858303e4c650927a0f47ce', 'message': ""Centralize compute_node_search_by_hypervisor in os-hypervisors\n\nThe search and servers routes have very similar code that is calling\ncompute_node_search_by_hypervisor and passing the hypervisor\nhostname pattern. There is going to be an upcoming change where\nwe deprecate these APIs and move them into the index() method using\nquery parameters, so we'll need to use similar code. So centralize\nthis now so the later change is simpler and can just re-use it.\n\nPart of blueprint service-hyper-uuid-in-api\n\nChange-Id: Ic72b47c11b83ce5151bc34b13eb78af4676dc71a\n""}]",1,474381,ffeacdaa74840fbb67858303e4c650927a0f47ce,25,10,2,6873,,,0,"Centralize compute_node_search_by_hypervisor in os-hypervisors

The search and servers routes have very similar code that is calling
compute_node_search_by_hypervisor and passing the hypervisor
hostname pattern. There is going to be an upcoming change where
we deprecate these APIs and move them into the index() method using
query parameters, so we'll need to use similar code. So centralize
this now so the later change is simpler and can just re-use it.

Part of blueprint service-hyper-uuid-in-api

Change-Id: Ic72b47c11b83ce5151bc34b13eb78af4676dc71a
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/474381/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/hypervisors.py'],1,f27189026e3511ef4f034ca14bff0b34cfb77212,bp/service-hyper-uuid-in-api," def _get_compute_nodes_by_name_pattern(self, context, hostname_match): compute_nodes = self.host_api.compute_node_search_by_hypervisor( context, hostname_match) if not compute_nodes: msg = (_(""No hypervisor matching '%s' could be found."") % hostname_match) raise webob.exc.HTTPNotFound(explanation=msg) return compute_nodes hypervisors = self._get_compute_nodes_by_name_pattern(context, id) try: return dict(hypervisors=[ self._view_hypervisor( hyp, self.host_api.service_get_by_compute_host(context, hyp.host), False, req) for hyp in hypervisors]) except exception.HostMappingNotFound: compute_nodes = self._get_compute_nodes_by_name_pattern(context, id)"," hypervisors = self.host_api.compute_node_search_by_hypervisor( context, id) if hypervisors: try: return dict(hypervisors=[ self._view_hypervisor( hyp, self.host_api.service_get_by_compute_host(context, hyp.host), False, req) for hyp in hypervisors]) except exception.HostMappingNotFound: msg = _(""No hypervisor matching '%s' could be found."") % id raise webob.exc.HTTPNotFound(explanation=msg) else: compute_nodes = self.host_api.compute_node_search_by_hypervisor( context, id) if not compute_nodes: msg = _(""No hypervisor matching '%s' could be found."") % id raise webob.exc.HTTPNotFound(explanation=msg)",20,20
openstack%2Ftripleo-heat-templates~master~Ie2bded39cdb82a72f0c28f1c552403cd11b5af45,openstack/tripleo-heat-templates,master,Ie2bded39cdb82a72f0c28f1c552403cd11b5af45,Make a copy of files touched by puppet in container,MERGED,2017-06-16 08:18:35.000000000,2017-06-16 23:33:19.000000000,2017-06-16 23:33:19.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8042}, {'_account_id': 9592}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-06-16 08:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2e0f211bd1cccdbf34735cdf3406a5ab54e2e060', 'message': 'Make a copy of files touched by puppet in container\n\nThis should help determine what exactly needs to be bind mounted in the\ncontainer and should also help limit the size of collected logs in CI,\nas collecting the entire /etc directory from each container can grow\npretty quickly in size and is not that useful.\n\nChange-Id: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45\n'}, {'number': 2, 'created': '2017-06-16 08:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/102a97613c43dff27a9764fd434e25aac0f24640', 'message': 'Make a copy of files touched by puppet in container\n\nThis should help determine what exactly needs to be bind mounted in the\ncontainer and should also help limit the size of collected logs in CI,\nas collecting the entire /etc directory from each container can grow\npretty quickly in size and is not that useful.\n\nRelated-Bug: #1698172\nChange-Id: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45\n'}, {'number': 3, 'created': '2017-06-16 14:09:46.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/74595a73210bb9cf5e0d688c57e9fa5423422603', 'message': 'Make a copy of files touched by puppet in container\n\nThis should help determine what exactly needs to be bind mounted in the\ncontainer and should also help limit the size of collected logs in CI,\nas collecting the entire /etc directory from each container can grow\npretty quickly in size and is not that useful.\n\nRelated-Bug: #1698172\nChange-Id: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45\n'}]",0,474891,74595a73210bb9cf5e0d688c57e9fa5423422603,16,7,3,13039,,,0,"Make a copy of files touched by puppet in container

This should help determine what exactly needs to be bind mounted in the
container and should also help limit the size of collected logs in CI,
as collecting the entire /etc directory from each container can grow
pretty quickly in size and is not that useful.

Related-Bug: #1698172
Change-Id: Ie2bded39cdb82a72f0c28f1c552403cd11b5af45
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/474891/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,2e0f211bd1cccdbf34735cdf3406a5ab54e2e060,bug/1698172, # Also make a copy of files modified during puppet run # This is useful for debugging mkdir -p /var/lib/config-data/puppet-generated/${NAME} rsync -a -R -0 --delay-updates --delete-after \ --files-from=<(find $rsync_srcs -newer /etc/ssh/ssh_known_hosts -print0) \ / /var/lib/config-data/puppet-generated/${NAME} ,,7,0
openstack%2Ftripleo-heat-templates~master~I9ac74d6717533f59945694b4a43fe56d7ca768c6,openstack/tripleo-heat-templates,master,I9ac74d6717533f59945694b4a43fe56d7ca768c6,Fall back to non-containerized cinder-backup to unblock OVB CI,MERGED,2017-06-16 13:47:46.000000000,2017-06-16 23:33:12.000000000,2017-06-16 23:33:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 13039}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-16 13:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/78746b02531bd0f137a986aa081b990985a08c8f', 'message': ""Fall back to non-containerized cinder-backup to unblock OVB CI\n\nThe previous fix Ib10e4f18d967d356a15b97f58c488f8402a73356 made\nmultinode CI pass, but there was still an error during volume\nscheduling on OVB:\n\nOSError: [Errno 13] Permission denied: '/var/lib/cinder/conversion'\n\nThis was most likely due to cinder-volume was running on host and used\nhost's cinder user, while we still deployed containerized\ncinder-backup and it chowned /var/lib/cinder under kolla's cinder user\nwhose UID doesn't match the baremetal one.\n\nWe didn't hit this issue in the multinode job because it doesn't\npresently deploy cinder-backup service at all.\n\nChange-Id: I9ac74d6717533f59945694b4a43fe56d7ca768c6\nCloses-Bug: #1698136\n""}, {'number': 2, 'created': '2017-06-16 13:48:55.000000000', 'files': ['environments/docker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6e72aa9f8157a57dfe4db7bc0a5defb86d800ea6', 'message': ""Fall back to non-containerized cinder-backup to unblock OVB CI\n\nThe previous fix Ib10e4f18d967d356a15b97f58c488f8402a73356 made\nmultinode CI pass, but there was still an error during volume\nscheduling on OVB:\n\nOSError: [Errno 13] Permission denied: '/var/lib/cinder/conversion'\n\nThis was most likely due to cinder-volume was running on host and used\nhost's cinder user, while we still deployed containerized\ncinder-backup and it chowned /var/lib/cinder under kolla's cinder user\nwhose UID doesn't match the baremetal one.\n\nWe didn't hit this issue in the multinode job because it doesn't\npresently deploy cinder-backup service at all.\n\nCo-Authored-By: Martin André <m.andre@redhat.com>\nChange-Id: I9ac74d6717533f59945694b4a43fe56d7ca768c6\nCloses-Bug: #1698136\n""}]",0,474978,6e72aa9f8157a57dfe4db7bc0a5defb86d800ea6,15,5,2,8042,,,0,"Fall back to non-containerized cinder-backup to unblock OVB CI

The previous fix Ib10e4f18d967d356a15b97f58c488f8402a73356 made
multinode CI pass, but there was still an error during volume
scheduling on OVB:

OSError: [Errno 13] Permission denied: '/var/lib/cinder/conversion'

This was most likely due to cinder-volume was running on host and used
host's cinder user, while we still deployed containerized
cinder-backup and it chowned /var/lib/cinder under kolla's cinder user
whose UID doesn't match the baremetal one.

We didn't hit this issue in the multinode job because it doesn't
presently deploy cinder-backup service at all.

Co-Authored-By: Martin André <m.andre@redhat.com>
Change-Id: I9ac74d6717533f59945694b4a43fe56d7ca768c6
Closes-Bug: #1698136
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/474978/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/docker.yaml'],1,78746b02531bd0f137a986aa081b990985a08c8f,bug/1698136, # FIXME: Had to remove these to unblock containers CI. They should be put back when fixed. # OS::TripleO::Services::CinderBackup: ../docker/services/cinder-backup.yaml, OS::TripleO::Services::CinderBackup: ../docker/services/cinder-backup.yaml # FIXME: Had to remove this to unblock containers CI. Should be put back when fixed.,2,2
openstack%2Fshade~master~I99c293cc6e961a009ae9793f4e4aea37d1de12f7,openstack/shade,master,I99c293cc6e961a009ae9793f4e4aea37d1de12f7,Go back to deleting volumes serially,ABANDONED,2017-06-15 21:14:04.000000000,2017-06-16 23:26:54.000000000,,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2017-06-15 21:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/ac43c12a297419b006ead3e563f01990e43b5bc0', 'message': 'Go back to deleting volumes serially\n\nDeleting while testing a list with pagination is dangerous and not yet\nfixed.\n\nChange-Id: I99c293cc6e961a009ae9793f4e4aea37d1de12f7\n'}, {'number': 2, 'created': '2017-06-16 02:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/702d7fc57a477b096c20256b704b6a0b2d08aa02', 'message': 'Go back to deleting volumes serially\n\nDeleting while testing a list with pagination is dangerous and not yet\nfixed.\n\nChange-Id: I99c293cc6e961a009ae9793f4e4aea37d1de12f7\n'}, {'number': 3, 'created': '2017-06-16 12:29:42.000000000', 'files': ['shade/tests/functional/test_volume.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/d81ee7e49b3666f4cde8447bd938cc0b4d5dbe4d', 'message': 'Go back to deleting volumes serially\n\nDeleting while testing a list with pagination is dangerous and not yet\nfixed.\n\nChange-Id: I99c293cc6e961a009ae9793f4e4aea37d1de12f7\n'}]",0,474783,d81ee7e49b3666f4cde8447bd938cc0b4d5dbe4d,16,2,3,2,,,0,"Go back to deleting volumes serially

Deleting while testing a list with pagination is dangerous and not yet
fixed.

Change-Id: I99c293cc6e961a009ae9793f4e4aea37d1de12f7
",git fetch https://review.opendev.org/openstack/shade refs/changes/83/474783/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/functional/test_volume.py'],1,ac43c12a297419b006ead3e563f01990e43b5bc0,474783," self.addCleanup(self.cleanup, name)"," volumes = [] volumes.append(v) self.addCleanup(self.cleanup, volumes)",1,3
openstack%2Fpuppet-tripleo~master~I8a47ca53a7dea8391103abcb8960a97036a6f5b3,openstack/puppet-tripleo,master,I8a47ca53a7dea8391103abcb8960a97036a6f5b3,Ensure hiera step value is an integer,MERGED,2017-05-21 22:57:08.000000000,2017-06-16 23:25:23.000000000,2017-06-16 23:25:23.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-05-21 22:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/50147d0f2b140a647ec18e697e7a4b99b4f963c2', 'message': 'Ensure hiera step value is an integer\n\nThe step is typically set with the hieradata setting an integer value:\n\n  {""step"": 1}\n\nHowever it would be useful for the value to be a string so that\nsubstitutions are possible, for example:\n\n  {""step"": ""%{::step}""}\n\nThis change ensures the step parameter defaults to an integer by\nadding zero to the hiera step value, as per[1].\n\nThis change was made by manually removing the undef defaults from\nfluentd.pp, uchiwa.pp, and sensu.pp then bulk updating with:\n\n    find ./ -type f -print0 |xargs -0 sed -i ""s/= hiera(\'step\')/= 0 + hiera(\'step\')/""\n\n[1] https://docs.puppet.com/puppet/4.10/lang_data_number.html#converting-strings-to-numbers\n\nChange-Id: I8a47ca53a7dea8391103abcb8960a97036a6f5b3\n'}, {'number': 2, 'created': '2017-05-26 00:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d9aabd5eff12a8d27d67b4958fe8ad14af24d767', 'message': 'Ensure hiera step value is an integer\n\nThe step is typically set with the hieradata setting an integer value:\n\n  {""step"": 1}\n\nHowever it would be useful for the value to be a string so that\nsubstitutions are possible, for example:\n\n  {""step"": ""%{::step}""}\n\nThis change ensures the step parameter defaults to an integer by\nadding zero to the hiera step value, as per[1].\n\nThis change was made by manually removing the undef defaults from\nfluentd.pp, uchiwa.pp, and sensu.pp then bulk updating with:\n\n    find ./ -type f -print0 |xargs -0 sed -i ""s/= hiera(\'step\')/= 0 + hiera(\'step\')/""\n\n[1] https://docs.puppet.com/puppet/4.10/lang_data_number.html#converting-strings-to-numbers\n\nChange-Id: I8a47ca53a7dea8391103abcb8960a97036a6f5b3\n'}, {'number': 3, 'created': '2017-05-30 22:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/845455c68e91085627a096a1bbd12cd3d9dff215', 'message': 'Ensure hiera step value is an integer\n\nThe step is typically set with the hieradata setting an integer value:\n\n  {""step"": 1}\n\nHowever it would be useful for the value to be a string so that\nsubstitutions are possible, for example:\n\n  {""step"": ""%{::step}""}\n\nThis change ensures the step parameter defaults to an integer by\nadding zero to the hiera step value, as per[1].\n\nThis change was made by manually removing the undef defaults from\nfluentd.pp, uchiwa.pp, and sensu.pp then bulk updating with:\n\n    find ./ -type f -print0 |xargs -0 sed -i ""s/= hiera(\'step\')/= 0 + hiera(\'step\')/""\n\n[1] https://docs.puppet.com/puppet/4.10/lang_data_number.html#converting-strings-to-numbers\n\nChange-Id: I8a47ca53a7dea8391103abcb8960a97036a6f5b3\n'}, {'number': 4, 'created': '2017-05-30 22:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/280ede9f7ae4e8cab9b696f6338118ed2c7c245a', 'message': 'Ensure hiera step value is an integer\n\nThe step is typically set with the hieradata setting an integer value:\n\n  {""step"": 1}\n\nHowever it would be useful for the value to be a string so that\nsubstitutions are possible, for example:\n\n  {""step"": ""%{::step}""}\n\nThis change ensures the step parameter defaults to an integer by\nadding zero to the hiera step value, as per[1].\n\nThis change was made by manually removing the undef defaults from\nfluentd.pp, uchiwa.pp, and sensu.pp then bulk updating with:\n\n    find ./ -type f -print0 |xargs -0 sed -i ""s/= hiera(\'step\')/= 0 + hiera(\'step\')/""\n\n[1] https://docs.puppet.com/puppet/4.10/lang_data_number.html#converting-strings-to-numbers\n\nChange-Id: I8a47ca53a7dea8391103abcb8960a97036a6f5b3\n'}, {'number': 5, 'created': '2017-06-14 02:32:09.000000000', 'files': ['manifests/profile/base/nova/compute.pp', 'manifests/profile/base/nova/libvirt.pp', 'manifests/profile/pacemaker/rabbitmq.pp', 'manifests/profile/base/neutron.pp', 'manifests/profile/base/cinder/backup/swift.pp', 'manifests/profile/base/tacker.pp', 'manifests/profile/base/ironic.pp', 'manifests/profile/pacemaker/database/mysql.pp', 'manifests/profile/pacemaker/database/mysql_bundle.pp', 'manifests/profile/base/pacemaker_remote.pp', 'manifests/profile/base/gnocchi.pp', 'manifests/profile/base/mistral.pp', 'manifests/profile/base/nova.pp', 'manifests/profile/base/aodh.pp', 'manifests/profile/base/ceilometer/agent/notification.pp', 'manifests/profile/base/congress.pp', 'manifests/profile/base/neutron/dhcp.pp', 'manifests/profile/pacemaker/haproxy.pp', 'manifests/profile/base/heat/engine.pp', 'manifests/profile/base/gnocchi/api.pp', 'manifests/profile/base/neutron/agents/vpp.pp', 'manifests/profile/pacemaker/database/redis.pp', 'manifests/profile/base/ceph/mon.pp', 'manifests/profile/base/etcd.pp', 'manifests/profile/base/neutron/plugins/ml2.pp', 'manifests/profile/base/cinder/backup.pp', 'manifests/profile/base/neutron/n1k.pp', 'manifests/profile/base/cinder/volume/iscsi.pp', 'manifests/profile/pacemaker/rabbitmq_bundle.pp', 'manifests/profile/base/neutron/linuxbridge.pp', 'manifests/profile/base/neutron/opencontrail/vrouter.pp', 'manifests/profile/base/nova/api.pp', 'manifests/profile/base/nova/authtoken.pp', 'manifests/profile/base/nova/compute/libvirt.pp', 'manifests/profile/base/neutron/ovn_northd.pp', 'manifests/profile/base/neutron/l2gw.pp', 'manifests/profile/base/ceph.pp', 'manifests/profile/base/nova/consoleauth.pp', 'manifests/profile/base/cinder/volume/nfs.pp', 'manifests/profile/base/sahara/engine.pp', 'manifests/profile/base/monitoring/sensu.pp', 'manifests/network/contrail/analytics.pp', 'manifests/profile/base/neutron/opendaylight.pp', 'manifests/profile/base/panko/api.pp', 'manifests/profile/base/ceilometer/agent/central.pp', 'manifests/profile/base/mistral/event_engine.pp', 'manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/auditd.pp', 'manifests/profile/base/mistral/api.pp', 'manifests/profile/base/neutron/agents/l2gw.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/ceilometer.pp', 'manifests/profile/base/neutron/ovs.pp', 'manifests/profile/base/neutron/plumgrid.pp', 'manifests/profile/base/heat/api_cfn.pp', 'manifests/profile/pacemaker/ovn_northd.pp', 'manifests/profile/pacemaker/haproxy_bundle.pp', 'manifests/profile/base/octavia.pp', 'manifests/profile/base/neutron/plugins/ml2/bagpipe.pp', 'manifests/profile/base/nova/ec2api.pp', 'manifests/profile/base/nova/scheduler.pp', 'manifests/profile/base/cinder/api.pp', 'manifests/profile/base/neutron/plugins/ovs/opendaylight.pp', 'manifests/profile/base/nova/compute/ironic.pp', 'manifests/profile/base/neutron/metadata.pp', 'manifests/profile/base/nova/conductor.pp', 'manifests/profile/base/database/redis.pp', 'manifests/profile/base/swift/storage.pp', 'manifests/profile/base/cinder/volume.pp', 'manifests/profile/base/haproxy.pp', 'manifests/profile/base/swift/ringbuilder.pp', 'manifests/profile/base/memcached.pp', 'manifests/profile/base/vpp.pp', 'manifests/profile/base/neutron/agents/bigswitch.pp', 'manifests/profile/base/neutron/agents/midonet.pp', 'manifests/profile/base/ceph/rgw.pp', 'manifests/profile/base/ceilometer/agent/compute.pp', 'manifests/profile/base/docker.pp', 'manifests/profile/base/aodh/evaluator.pp', 'manifests/profile/base/ceph/mds.pp', 'manifests/profile/base/trove/taskmanager.pp', 'manifests/profile/base/keepalived.pp', 'manifests/profile/base/ironic/api.pp', 'manifests/profile/pacemaker/neutron/lbaas.pp', 'manifests/profile/base/cinder/volume/scaleio.pp', 'manifests/profile/base/metrics/collectd.pp', 'manifests/profile/base/ceilometer/expirer.pp', 'manifests/profile/base/cinder/volume/pure.pp', 'manifests/network/contrail/heat.pp', 'manifests/profile/base/neutron/midonet.pp', 'manifests/profile/base/neutron/plugins/ml2/opendaylight.pp', 'manifests/profile/base/ironic_inspector.pp', 'manifests/profile/base/nova/placement.pp', 'manifests/profile/base/cinder/volume/hpelefthand.pp', 'manifests/profile/base/neutron/l3.pp', 'manifests/profile/base/database/mysql.pp', 'manifests/network/contrail/vrouter.pp', 'manifests/profile/base/neutron/sriov.pp', 'manifests/profile/base/cinder/volume/netapp.pp', 'manifests/profile/base/neutron/plugins/nsx_v3.pp', 'manifests/profile/pacemaker/manila.pp', 'manifests/profile/base/database/mysql/client.pp', 'manifests/profile/base/sahara.pp', 'manifests/profile/base/ceilometer/collector.pp', 'manifests/profile/base/cinder/backup/ceph.pp', 'manifests/profile/base/mistral/executor.pp', 'manifests/profile/base/nova/vncproxy.pp', 'manifests/profile/pacemaker/cinder/volume.pp', 'manifests/profile/base/rabbitmq.pp', 'manifests/profile/base/neutron/agents/nuage.pp', 'manifests/profile/base/octavia/health_manager.pp', 'manifests/profile/base/neutron/bgpvpn.pp', 'manifests/profile/base/neutron/plugins/plumgrid.pp', 'manifests/profile/base/pacemaker.pp', 'manifests/network/contrail/config.pp', 'manifests/profile/base/ceilometer/upgrade.pp', 'manifests/profile/base/barbican.pp', 'manifests/profile/base/cinder/scheduler.pp', 'manifests/profile/base/aodh/notifier.pp', 'manifests/profile/base/snmp.pp', 'manifests/profile/pacemaker/clustercheck.pp', 'manifests/profile/base/panko.pp', 'manifests/profile/base/aodh/api.pp', 'manifests/profile/base/swift/proxy.pp', 'manifests/profile/base/neutron/agents/ovn.pp', 'manifests/profile/base/neutron/plugins/opencontrail.pp', 'manifests/profile/base/database/mongodb.pp', 'manifests/profile/base/ironic/conductor.pp', 'manifests/profile/base/neutron/plugins/ml2/vpp.pp', 'manifests/profile/pacemaker/ceph/rbdmirror.pp', 'manifests/profile/base/barbican/api.pp', 'manifests/profile/base/sahara/api.pp', 'manifests/profile/base/cinder/volume/dellps.pp', 'manifests/profile/base/novajoin.pp', 'manifests/profile/base/neutron/plugins/nuage.pp', 'manifests/network/contrail/control.pp', 'manifests/profile/base/neutron/lbaas.pp', 'manifests/profile/base/securetty.pp', 'manifests/profile/pacemaker/cinder/backup_bundle.pp', 'manifests/profile/base/ceilometer/api.pp', 'manifests/profile/base/heat/api.pp', 'manifests/profile/base/aodh/listener.pp', 'manifests/profile/base/ceph/client.pp', 'manifests/profile/base/trove/conductor.pp', 'manifests/profile/base/neutron/server.pp', 'manifests/profile/base/cinder/volume/rbd.pp', 'manifests/profile/base/mistral/engine.pp', 'manifests/profile/base/trove/api.pp', 'manifests/profile/base/gnocchi/metricd.pp', 'manifests/profile/pacemaker/cinder/backup.pp', 'manifests/profile/base/manila.pp', 'manifests/network/contrail/provision.pp', 'manifests/profile/base/manila/api.pp', 'manifests/profile/base/heat.pp', 'manifests/profile/base/manila/scheduler.pp', 'manifests/profile/base/manila/share.pp', 'manifests/profile/pacemaker/database/redis_bundle.pp', 'manifests/profile/base/neutron/plugins/ml2/ovn.pp', 'manifests/network/contrail/database.pp', 'manifests/profile/base/ceph/osd.pp', 'manifests/profile/base/zaqar.pp', 'manifests/profile/base/keystone.pp', 'manifests/profile/base/gnocchi/statsd.pp', 'manifests/profile/base/logging/fluentd.pp', 'manifests/profile/base/octavia/api.pp', 'manifests/network/contrail/analyticsdatabase.pp', 'manifests/profile/base/glance/api.pp', 'manifests/profile/base/heat/api_cloudwatch.pp', 'manifests/profile/base/monitoring/uchiwa.pp', 'manifests/profile/base/ceilometer/agent/polling.pp', 'manifests/profile/base/neutron/agents/bagpipe.pp', 'manifests/profile/pacemaker/cinder/volume_bundle.pp', 'manifests/profile/base/cinder/volume/dellsc.pp', 'manifests/profile/base/horizon.pp', 'manifests/profile/base/cinder.pp', 'manifests/profile/base/qdr.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/94f13e66089cc0b18d5b4b2f6e204160d836ac3e', 'message': 'Ensure hiera step value is an integer\n\nThe step is typically set with the hieradata setting an integer value:\n\n  {""step"": 1}\n\nHowever it would be useful for the value to be a string so that\nsubstitutions are possible, for example:\n\n  {""step"": ""%{::step}""}\n\nThis change ensures the step parameter defaults to an integer by\ncalling Integer(hiera(\'step\'))\n\nThis change was made by manually removing the undef defaults from\nfluentd.pp, uchiwa.pp, and sensu.pp then bulk updating with:\n\n    find ./ -type f -print0 |xargs -0 sed -i ""s/= hiera(\'step\')/= Integer(hiera(\'step\'))/""\n\nChange-Id: I8a47ca53a7dea8391103abcb8960a97036a6f5b3\n'}]",0,466556,94f13e66089cc0b18d5b4b2f6e204160d836ac3e,45,7,5,4571,,,0,"Ensure hiera step value is an integer

The step is typically set with the hieradata setting an integer value:

  {""step"": 1}

However it would be useful for the value to be a string so that
substitutions are possible, for example:

  {""step"": ""%{::step}""}

This change ensures the step parameter defaults to an integer by
calling Integer(hiera('step'))

This change was made by manually removing the undef defaults from
fluentd.pp, uchiwa.pp, and sensu.pp then bulk updating with:

    find ./ -type f -print0 |xargs -0 sed -i ""s/= hiera('step')/= Integer(hiera('step'))/""

Change-Id: I8a47ca53a7dea8391103abcb8960a97036a6f5b3
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/56/466556/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/nova/compute.pp', 'manifests/profile/base/nova/libvirt.pp', 'manifests/profile/pacemaker/rabbitmq.pp', 'manifests/profile/base/neutron.pp', 'manifests/profile/base/cinder/backup/swift.pp', 'manifests/profile/base/tacker.pp', 'manifests/profile/base/ironic.pp', 'manifests/profile/pacemaker/database/mysql.pp', 'manifests/profile/base/pacemaker_remote.pp', 'manifests/profile/base/gnocchi.pp', 'manifests/profile/base/mistral.pp', 'manifests/profile/base/nova.pp', 'manifests/profile/base/aodh.pp', 'manifests/profile/base/ceilometer/agent/notification.pp', 'manifests/profile/base/congress.pp', 'manifests/profile/base/neutron/dhcp.pp', 'manifests/profile/pacemaker/haproxy.pp', 'manifests/profile/base/heat/engine.pp', 'manifests/profile/base/gnocchi/api.pp', 'manifests/profile/base/neutron/agents/vpp.pp', 'manifests/profile/pacemaker/database/redis.pp', 'manifests/profile/base/ceph/mon.pp', 'manifests/profile/base/etcd.pp', 'manifests/profile/base/neutron/plugins/ml2.pp', 'manifests/profile/base/cinder/backup.pp', 'manifests/profile/base/neutron/n1k.pp', 'manifests/profile/base/cinder/volume/iscsi.pp', 'manifests/profile/base/neutron/linuxbridge.pp', 'manifests/profile/base/neutron/opencontrail/vrouter.pp', 'manifests/profile/base/nova/api.pp', 'manifests/profile/base/nova/authtoken.pp', 'manifests/profile/base/nova/compute/libvirt.pp', 'manifests/profile/base/neutron/ovn_northd.pp', 'manifests/profile/base/neutron/l2gw.pp', 'manifests/profile/base/ceph.pp', 'manifests/profile/base/nova/consoleauth.pp', 'manifests/profile/base/cinder/volume/nfs.pp', 'manifests/profile/base/sahara/engine.pp', 'manifests/profile/base/monitoring/sensu.pp', 'manifests/network/contrail/analytics.pp', 'manifests/profile/base/neutron/opendaylight.pp', 'manifests/profile/base/panko/api.pp', 'manifests/profile/base/ceilometer/agent/central.pp', 'manifests/profile/base/octavia/worker.pp', 'manifests/profile/base/auditd.pp', 'manifests/profile/base/mistral/api.pp', 'manifests/profile/base/neutron/agents/l2gw.pp', 'manifests/profile/base/octavia/housekeeping.pp', 'manifests/profile/base/ceilometer.pp', 'manifests/profile/base/neutron/ovs.pp', 'manifests/profile/base/neutron/plumgrid.pp', 'manifests/profile/base/heat/api_cfn.pp', 'manifests/profile/base/octavia.pp', 'manifests/profile/base/neutron/plugins/ml2/bagpipe.pp', 'manifests/profile/base/nova/ec2api.pp', 'manifests/profile/base/nova/scheduler.pp', 'manifests/profile/base/cinder/api.pp', 'manifests/profile/base/neutron/plugins/ovs/opendaylight.pp', 'manifests/profile/base/nova/compute/ironic.pp', 'manifests/profile/base/neutron/metadata.pp', 'manifests/profile/base/nova/conductor.pp', 'manifests/profile/base/database/redis.pp', 'manifests/profile/base/swift/storage.pp', 'manifests/profile/base/cinder/volume.pp', 'manifests/profile/base/haproxy.pp', 'manifests/profile/base/swift/ringbuilder.pp', 'manifests/profile/base/memcached.pp', 'manifests/profile/base/vpp.pp', 'manifests/profile/base/neutron/agents/bigswitch.pp', 'manifests/profile/base/neutron/agents/midonet.pp', 'manifests/profile/base/ceph/rgw.pp', 'manifests/profile/base/ceilometer/agent/compute.pp', 'manifests/profile/base/docker.pp', 'manifests/profile/base/aodh/evaluator.pp', 'manifests/profile/base/ceph/mds.pp', 'manifests/profile/base/trove/taskmanager.pp', 'manifests/profile/base/keepalived.pp', 'manifests/profile/base/ironic/api.pp', 'manifests/profile/base/cinder/volume/scaleio.pp', 'manifests/profile/base/metrics/collectd.pp', 'manifests/profile/base/ceilometer/expirer.pp', 'manifests/profile/base/cinder/volume/pure.pp', 'manifests/network/contrail/heat.pp', 'manifests/profile/base/neutron/midonet.pp', 'manifests/profile/base/neutron/plugins/ml2/opendaylight.pp', 'manifests/profile/base/ironic_inspector.pp', 'manifests/profile/base/nova/placement.pp', 'manifests/profile/base/cinder/volume/hpelefthand.pp', 'manifests/profile/base/neutron/l3.pp', 'manifests/profile/base/database/mysql.pp', 'manifests/network/contrail/vrouter.pp', 'manifests/profile/base/neutron/sriov.pp', 'manifests/profile/base/cinder/volume/netapp.pp', 'manifests/profile/base/neutron/plugins/nsx_v3.pp', 'manifests/profile/pacemaker/manila.pp', 'manifests/profile/base/database/mysql/client.pp', 'manifests/profile/base/sahara.pp', 'manifests/profile/base/ceilometer/collector.pp', 'manifests/profile/base/cinder/backup/ceph.pp', 'manifests/profile/base/mistral/executor.pp', 'manifests/profile/base/nova/vncproxy.pp', 'manifests/profile/pacemaker/cinder/volume.pp', 'manifests/profile/base/rabbitmq.pp', 'manifests/profile/base/neutron/agents/nuage.pp', 'manifests/profile/base/octavia/health_manager.pp', 'manifests/profile/base/neutron/bgpvpn.pp', 'manifests/profile/base/neutron/plugins/plumgrid.pp', 'manifests/profile/base/pacemaker.pp', 'manifests/network/contrail/config.pp', 'manifests/profile/base/barbican.pp', 'manifests/profile/base/cinder/scheduler.pp', 'manifests/profile/base/aodh/notifier.pp', 'manifests/profile/base/snmp.pp', 'manifests/profile/base/panko.pp', 'manifests/profile/base/aodh/api.pp', 'manifests/profile/base/swift/proxy.pp', 'manifests/profile/base/neutron/agents/ovn.pp', 'manifests/profile/base/neutron/plugins/opencontrail.pp', 'manifests/profile/base/database/mongodb.pp', 'manifests/profile/base/ironic/conductor.pp', 'manifests/profile/base/neutron/plugins/ml2/vpp.pp', 'manifests/profile/pacemaker/ceph/rbdmirror.pp', 'manifests/profile/base/barbican/api.pp', 'manifests/profile/base/sahara/api.pp', 'manifests/profile/base/cinder/volume/dellps.pp', 'manifests/profile/base/neutron/plugins/nuage.pp', 'manifests/network/contrail/control.pp', 'manifests/profile/base/securetty.pp', 'manifests/profile/base/ceilometer/api.pp', 'manifests/profile/base/heat/api.pp', 'manifests/profile/base/aodh/listener.pp', 'manifests/profile/base/ceph/client.pp', 'manifests/profile/base/trove/conductor.pp', 'manifests/profile/base/neutron/server.pp', 'manifests/profile/base/cinder/volume/rbd.pp', 'manifests/profile/base/mistral/engine.pp', 'manifests/profile/base/trove/api.pp', 'manifests/profile/base/gnocchi/metricd.pp', 'manifests/profile/pacemaker/cinder/backup.pp', 'manifests/profile/base/manila.pp', 'manifests/network/contrail/provision.pp', 'manifests/profile/base/manila/api.pp', 'manifests/profile/base/heat.pp', 'manifests/profile/base/manila/scheduler.pp', 'manifests/profile/base/manila/share.pp', 'manifests/profile/base/neutron/plugins/ml2/ovn.pp', 'manifests/network/contrail/database.pp', 'manifests/profile/base/ceph/osd.pp', 'manifests/profile/base/zaqar.pp', 'manifests/profile/base/keystone.pp', 'manifests/profile/base/gnocchi/statsd.pp', 'manifests/profile/base/logging/fluentd.pp', 'manifests/profile/base/octavia/api.pp', 'manifests/network/contrail/analyticsdatabase.pp', 'manifests/profile/base/glance/api.pp', 'manifests/profile/base/heat/api_cloudwatch.pp', 'manifests/profile/base/monitoring/uchiwa.pp', 'manifests/profile/base/ceilometer/agent/polling.pp', 'manifests/profile/base/neutron/agents/bagpipe.pp', 'manifests/profile/base/cinder/volume/dellsc.pp', 'manifests/profile/base/horizon.pp', 'manifests/profile/base/cinder.pp', 'manifests/profile/base/qdr.pp']",163,50147d0f2b140a647ec18e697e7a4b99b4f963c2,integer-step," $step = 0 + hiera('step'),"," $step = hiera('step'),",164,164
openstack%2Ftripleo-heat-templates~stable%2Focata~Ibb9c65a83cc909528024c538cf3bcc96390c555e,openstack/tripleo-heat-templates,stable/ocata,Ibb9c65a83cc909528024c538cf3bcc96390c555e,Add support for autofencing to Pacemaker Remote.,MERGED,2017-06-13 08:41:50.000000000,2017-06-16 23:25:16.000000000,2017-06-16 23:25:16.000000000,"[{'_account_id': 3}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-13 08:41:50.000000000', 'files': ['puppet/services/pacemaker_remote.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/adf344a704be8304ab454104b45aa4af1698330f', 'message': 'Add support for autofencing to Pacemaker Remote.\n\nWe now pass configuration for autofencing to Pacemaker Remote nodes.\n\nChange-Id: Ibb9c65a83cc909528024c538cf3bcc96390c555e\nDepends-On: I87c60bd56feac6dedc00a3c458b805aa9b71d9ce\nCloses-Bug: #1686115\n(cherry picked from commit 05953542a6b688ee549671a46cecb5951b6c3fee)\n'}]",0,473736,adf344a704be8304ab454104b45aa4af1698330f,18,2,1,6449,,,0,"Add support for autofencing to Pacemaker Remote.

We now pass configuration for autofencing to Pacemaker Remote nodes.

Change-Id: Ibb9c65a83cc909528024c538cf3bcc96390c555e
Depends-On: I87c60bd56feac6dedc00a3c458b805aa9b71d9ce
Closes-Bug: #1686115
(cherry picked from commit 05953542a6b688ee549671a46cecb5951b6c3fee)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/473736/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/pacemaker_remote.yaml'],1,adf344a704be8304ab454104b45aa4af1698330f,bug/1686115," EnableFencing: default: false description: Whether to enable fencing in Pacemaker or not. type: boolean FencingConfig: default: {} description: | Pacemaker fencing configuration. The JSON should have the following structure: { ""devices"": [ { ""agent"": ""AGENT_NAME"", ""host_mac"": ""HOST_MAC_ADDRESS"", ""params"": {""PARAM_NAME"": ""PARAM_VALUE""} } ] } For instance: { ""devices"": [ { ""agent"": ""fence_xvm"", ""host_mac"": ""52:54:00:aa:bb:cc"", ""params"": { ""multicast_address"": ""225.0.0.12"", ""port"": ""baremetal_0"", ""manage_fw"": true, ""manage_key_file"": true, ""key_file"": ""/etc/fence_xvm.key"", ""key_file_password"": ""abcdef"" } } ] } type: json tripleo::fencing::config: {get_param: FencingConfig} enable_fencing: {get_param: EnableFencing}",,38,0
openstack%2Fneutron~master~Iebd753e9ca433227c9622227ba76a246b4fea2b3,openstack/neutron,master,Iebd753e9ca433227c9622227ba76a246b4fea2b3,Don't log ipam driver on every IP allocation,MERGED,2017-06-14 09:17:30.000000000,2017-06-16 23:04:17.000000000,2017-06-16 23:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}]","[{'number': 1, 'created': '2017-06-14 09:17:30.000000000', 'files': ['neutron/ipam/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec5b75f5434e0abd258818b9c55b7c6e23fe9c5b', 'message': ""Don't log ipam driver on every IP allocation\n\nWe only support one driver right now so there isn't a point\nin logging it for every single IP allocation call.\n\nTrivialFix\n\nChange-Id: Iebd753e9ca433227c9622227ba76a246b4fea2b3\n""}]",0,474130,ec5b75f5434e0abd258818b9c55b7c6e23fe9c5b,19,5,1,7787,,,0,"Don't log ipam driver on every IP allocation

We only support one driver right now so there isn't a point
in logging it for every single IP allocation call.

TrivialFix

Change-Id: Iebd753e9ca433227c9622227ba76a246b4fea2b3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/474130/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/ipam/driver.py'],1,ec5b75f5434e0abd258818b9c55b7c6e23fe9c5b,,," LOG.debug(""Loading ipam driver: %s"", ipam_driver_name)",0,1
openstack%2Fdevstack~master~Ia6b99c5df6614fe9b73b5731cf234e3acbf57496,openstack/devstack,master,Ia6b99c5df6614fe9b73b5731cf234e3acbf57496,Make Cinders lvm_type default to auto,ABANDONED,2017-06-15 20:31:27.000000000,2017-06-16 22:57:39.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11904}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-06-15 20:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/969def03b3083383adfeb7a40ebd617f47512e66', 'message': 'Make Cinders lvm_type default to auto\n\nWe\'ve had an lvm_type=thin for quite some time, and we\'ve wanted to\nmake it Cinders default for a while, but there\'s no clean way to\nmigrate on upgrades.  So, we have a compromise, detect if the\ndeployment has volumes (including the thin pool).  If there are no\nLVs or if the thin pool exists, use thin.  Otherwise, use the old\nthick lvm-default.\n\nYou can of course still set this in your local.conf if you wish\nusing ""CINDER_LVM_TYPE=default"".\n\nChange-Id: Ia6b99c5df6614fe9b73b5731cf234e3acbf57496\n'}, {'number': 2, 'created': '2017-06-15 23:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cdb256ebf0b0810a5ba68be4689144acaf1e1b7f', 'message': 'Make Cinders lvm_type default to auto\n\nWe\'ve had an lvm_type=thin for quite some time, and we\'ve wanted to\nmake it Cinders default for a while, but there\'s no clean way to\nmigrate on upgrades.  So, we have a compromise, detect if the\ndeployment has volumes (including the thin pool).  If there are no\nLVs or if the thin pool exists, use thin.  Otherwise, use the old\nthick lvm-default.\n\nYou can of course still set this in your local.conf if you wish\nusing ""CINDER_LVM_TYPE=default"".\n\nThis change will set the default to ""auto"" in devstack/lib/cinder\nand specify that it be added to the local.conf.\n\nChange-Id: Ia6b99c5df6614fe9b73b5731cf234e3acbf57496\n'}, {'number': 3, 'created': '2017-06-16 00:46:10.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5410e7e6ee271dd3663215703985e9a16d9fcee9', 'message': 'Make Cinders lvm_type default to auto\n\nWe\'ve had an lvm_type=thin for quite some time, and we\'ve wanted to\nmake it Cinders default for a while, but there\'s no clean way to\nmigrate on upgrades.  So, we have a compromise, detect if the\ndeployment has volumes (including the thin pool).  If there are no\nLVs or if the thin pool exists, use thin.  Otherwise, use the old\nthick lvm-default.\n\nYou can of course still set this in your local.conf if you wish\nusing ""CINDER_LVM_TYPE=default"".\n\nThis change will set the default to ""auto"" in devstack/lib/cinder\nand specify that it be added to the local.conf.\n\nChange-Id: Ia6b99c5df6614fe9b73b5731cf234e3acbf57496\n'}]",0,474769,5410e7e6ee271dd3663215703985e9a16d9fcee9,16,7,3,2243,,,0,"Make Cinders lvm_type default to auto

We've had an lvm_type=thin for quite some time, and we've wanted to
make it Cinders default for a while, but there's no clean way to
migrate on upgrades.  So, we have a compromise, detect if the
deployment has volumes (including the thin pool).  If there are no
LVs or if the thin pool exists, use thin.  Otherwise, use the old
thick lvm-default.

You can of course still set this in your local.conf if you wish
using ""CINDER_LVM_TYPE=default"".

This change will set the default to ""auto"" in devstack/lib/cinder
and specify that it be added to the local.conf.

Change-Id: Ia6b99c5df6614fe9b73b5731cf234e3acbf57496
",git fetch https://review.opendev.org/openstack/devstack refs/changes/69/474769/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,969def03b3083383adfeb7a40ebd617f47512e66,make_cinder_lvmtype_default_auto,CINDER_LVM_TYPE=${CINDER_LVM_TYPE:-auto},CINDER_LVM_TYPE=${CINDER_LVM_TYPE:-default},1,1
openstack%2Ftripleo-common~master~Ie5e9a19e8c435935a758c8cce3e01af4c9bbf220,openstack/tripleo-common,master,Ie5e9a19e8c435935a758c8cce3e01af4c9bbf220,Updated from global requirements,MERGED,2017-06-15 16:36:56.000000000,2017-06-16 22:57:01.000000000,2017-06-16 22:57:01.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}]","[{'number': 1, 'created': '2017-06-15 16:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b7ec5b6ea03892861f65b354e0cad5b093fb59b8', 'message': 'Updated from global requirements\n\nChange-Id: Ie5e9a19e8c435935a758c8cce3e01af4c9bbf220\n'}, {'number': 2, 'created': '2017-06-16 12:24:10.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/44b2f90893c1c9f1b454ff83c51ecf8a7845445c', 'message': 'Updated from global requirements\n\nChange-Id: Ie5e9a19e8c435935a758c8cce3e01af4c9bbf220\n'}]",0,474697,44b2f90893c1c9f1b454ff83c51ecf8a7845445c,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ie5e9a19e8c435935a758c8cce3e01af4c9bbf220
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/97/474697/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b7ec5b6ea03892861f65b354e0cad5b093fb59b8,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fpuppet-manila~master~I1bf6ead3b6290ebf927bacb21e57f2897ce34605,openstack/puppet-manila,master,I1bf6ead3b6290ebf927bacb21e57f2897ce34605,Add cephfs class and deprecate cephfsnative class,MERGED,2017-06-06 08:29:47.000000000,2017-06-16 22:56:55.000000000,2017-06-16 22:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7582}, {'_account_id': 8056}, {'_account_id': 9003}, {'_account_id': 14985}, {'_account_id': 15100}]","[{'number': 1, 'created': '2017-06-06 08:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/51908c84ae5af5d9575d6c6303b2ad80f87635ca', 'message': 'Add cephfs class and deprecate cephfsnative class\n\nManila cephfsnative driver was renamed to cephfs driver and\nsupports both direct cephfs access or through ganesha-nfs server.\nThis patch deprecates the older cephfsnative class and adds\ncphfs class which is compatible with current manila cephfs driver.\n\nChange-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605\nRelated-To: bp cephfs-nfs-support\n'}, {'number': 2, 'created': '2017-06-06 08:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/feb6752ce39ae61188fc91ac8ec8dff60ee2b613', 'message': 'Add cephfs class and deprecate cephfsnative class\n\nManila cephfsnative driver was renamed to cephfs driver and\nsupports both direct cephfs access or through ganesha-nfs server.\nThis patch deprecates the older cephfsnative class and adds\ncphfs class which is compatible with current manila cephfs driver.\n\nChange-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605\nRelated-To: bp cephfs-nfs-support\n'}, {'number': 3, 'created': '2017-06-15 09:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/bd329253342eae8ef3f1af5c786cb2e25fa51cc3', 'message': 'Add cephfs class and deprecate cephfsnative class\n\nManila cephfsnative driver was renamed to cephfs driver and\nsupports both direct cephfs access or through ganesha-nfs server.\nThis patch deprecates the older cephfsnative class and adds\ncphfs class which is compatible with current manila cephfs driver.\n\nChange-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605\nRelated-To: bp cephfs-nfs-support\n'}, {'number': 4, 'created': '2017-06-15 12:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/c33f3b06256a9aaf9ea42c127995621ce1ad4f54', 'message': 'Add cephfs class and deprecate cephfsnative class\n\nManila cephfsnative driver was renamed to cephfs driver and\nsupports both direct cephfs access or through ganesha-nfs server.\nThis patch deprecates the older cephfsnative class and adds\ncphfs class which is compatible with current manila cephfs driver.\n\nChange-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605\nRelated-To: bp cephfs-nfs-support\n'}, {'number': 5, 'created': '2017-06-16 07:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/aa867e503852e02c40a827fb3803c099b1562b85', 'message': 'Add cephfs class and deprecate cephfsnative class\n\nManila cephfsnative driver was renamed to cephfs driver and\nsupports both direct cephfs access or through ganesha-nfs server.\nThis patch deprecates the older cephfsnative class and adds\ncphfs class which is compatible with current manila cephfs driver.\n\nChange-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605\nRelated-To: bp cephfs-nfs-support\n'}, {'number': 6, 'created': '2017-06-16 07:42:36.000000000', 'files': ['manifests/backend/cephfs.pp', 'manifests/backend/cephfsnative.pp', 'spec/defines/manila_backend_cephfs_spec.rb', 'releasenotes/notes/deprecate-cephfsnative-add-cephfs-8ea802ec233c7618.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/97e89fc14741f824128ead481024d523018e5277', 'message': 'Add cephfs class and deprecate cephfsnative class\n\nManila cephfsnative driver was renamed to cephfs driver and\nsupports both direct cephfs access or through ganesha-nfs server.\nThis patch deprecates the older cephfsnative class and adds\ncephfs class which is compatible with current manila cephfs driver.\n\nChange-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605\nRelated-To: bp cephfs-nfs-support\n'}]",6,471257,97e89fc14741f824128ead481024d523018e5277,24,7,6,7582,,,0,"Add cephfs class and deprecate cephfsnative class

Manila cephfsnative driver was renamed to cephfs driver and
supports both direct cephfs access or through ganesha-nfs server.
This patch deprecates the older cephfsnative class and adds
cephfs class which is compatible with current manila cephfs driver.

Change-Id: I1bf6ead3b6290ebf927bacb21e57f2897ce34605
Related-To: bp cephfs-nfs-support
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/57/471257/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/backend/cephfs.pp', 'manifests/backend/cephfsnative.pp']",2,51908c84ae5af5d9575d6c6303b2ad80f87635ca,bp/cephfs-nfs-support, warning('manila::cephfsnative class is deprecated and will be removed in next release. You can use cephfs backend.') ,,64,0
openstack%2Fnova~master~I06aacb9d4a8cff8180010c69d3aa32c0492fe2bc,openstack/nova,master,I06aacb9d4a8cff8180010c69d3aa32c0492fe2bc,Stop caching compute nodes in the request,MERGED,2017-06-14 22:37:01.000000000,2017-06-16 22:48:40.000000000,2017-06-15 19:10:15.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-06-14 22:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38ea4c28c6feebe515f70e9c5dbab1b9cdd3a54f', 'message': 'Stop caching compute nodes in the request\n\nCaching compute nodes in the request was added in change\nI73a96db7beb4cc0f017008f81e9f671382ad9105. That was so the\nPciHypervisorController could use them, which was an extension\non the hypervisors API.\n\nThe os-pci API (and the PciHypervisorController) was removed in\nchange I9099744264eeec175672d10d04da69648dec1a9d so nothing needs\nthe compute nodes from the request cache anymore.\n\nChange-Id: I06aacb9d4a8cff8180010c69d3aa32c0492fe2bc\n'}, {'number': 2, 'created': '2017-06-15 00:37:21.000000000', 'files': ['nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/hypervisors.py', 'nova/tests/unit/api/openstack/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c078dc2f2d7fe0986d2198f47e20ee55a4306298', 'message': 'Stop caching compute nodes in the request\n\nCaching compute nodes in the request was added in change\nI73a96db7beb4cc0f017008f81e9f671382ad9105. That was so the\nPciHypervisorController could use them, which was an extension\non the hypervisors API.\n\nThe os-pci API (and the PciHypervisorController) was removed in\nchange I9099744264eeec175672d10d04da69648dec1a9d so nothing needs\nthe compute nodes from the request cache anymore.\n\nChange-Id: I06aacb9d4a8cff8180010c69d3aa32c0492fe2bc\n'}]",0,474382,c078dc2f2d7fe0986d2198f47e20ee55a4306298,25,10,2,6873,,,0,"Stop caching compute nodes in the request

Caching compute nodes in the request was added in change
I73a96db7beb4cc0f017008f81e9f671382ad9105. That was so the
PciHypervisorController could use them, which was an extension
on the hypervisors API.

The os-pci API (and the PciHypervisorController) was removed in
change I9099744264eeec175672d10d04da69648dec1a9d so nothing needs
the compute nodes from the request cache anymore.

Change-Id: I06aacb9d4a8cff8180010c69d3aa32c0492fe2bc
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/474382/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi.py', 'nova/api/openstack/compute/hypervisors.py', 'nova/tests/unit/api/openstack/test_wsgi.py']",3,38ea4c28c6feebe515f70e9c5dbab1b9cdd3a54f,bp/service-hyper-uuid-in-api,," def test_cache_and_retrieve_compute_nodes(self): request = wsgi.Request.blank('/foo') compute_nodes = [] for x in range(3): compute_nodes.append({'id': 'id%s' % x}) # Store 2 request.cache_db_compute_nodes(compute_nodes[:2]) # Store 1 request.cache_db_compute_node(compute_nodes[2]) self.assertEqual(request.get_db_compute_node('id0'), compute_nodes[0]) self.assertEqual(request.get_db_compute_node('id1'), compute_nodes[1]) self.assertEqual(request.get_db_compute_node('id2'), compute_nodes[2]) self.assertIsNone(request.get_db_compute_node('id3')) self.assertEqual(request.get_db_compute_nodes(), {'id0': compute_nodes[0], 'id1': compute_nodes[1], 'id2': compute_nodes[2]}) ",2,37
openstack%2Fpython-cinderclient~master~I65c2596297a386ce95ae4c79269f15ddfff62595,openstack/python-cinderclient,master,I65c2596297a386ce95ae4c79269f15ddfff62595,Fix simple parameter comment error,MERGED,2017-03-27 01:55:15.000000000,2017-06-16 22:43:41.000000000,2017-06-16 22:43:41.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 4523}, {'_account_id': 23083}]","[{'number': 1, 'created': '2017-03-27 01:55:15.000000000', 'files': ['cinderclient/v3/attachments.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2346c309f7f1393220e4a71e38597c0c0f8d062c', 'message': 'Fix simple parameter comment error\n\nChange-Id: I65c2596297a386ce95ae4c79269f15ddfff62595\n'}]",0,450052,2346c309f7f1393220e4a71e38597c0c0f8d062c,12,4,1,18404,,,0,"Fix simple parameter comment error

Change-Id: I65c2596297a386ce95ae4c79269f15ddfff62595
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/52/450052/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/v3/attachments.py'],1,2346c309f7f1393220e4a71e38597c0c0f8d062c,simple_error_in_comment, :param id: Attachment ID., :param name: Attachment ID.,1,1
openstack%2Fneutron~master~I740da1ea65a0af9451701e3a40fd673fa82f0f5b,openstack/neutron,master,I740da1ea65a0af9451701e3a40fd673fa82f0f5b,OVO: ensure decomposed plugin do not break with OVO,MERGED,2017-06-15 13:14:46.000000000,2017-06-16 22:33:01.000000000,2017-06-16 22:33:01.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 5367}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17120}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-15 13:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23361e0e75b029a9e9c54b8cb2c9ce3b83dff92c', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 2, 'created': '2017-06-15 13:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c5a32c148c2ecfde6d83022c1f9ffffe2cf3d71', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 3, 'created': '2017-06-15 13:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/962ed0159784d696a6a4a274768a0a7b9717620c', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 4, 'created': '2017-06-15 13:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7cbb221430b824c2592c2254bb11bd1d580b35e5', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 5, 'created': '2017-06-15 14:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/816ebf72b0f1b5639d652d9c56098f9aeda96bf4', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 6, 'created': '2017-06-15 14:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f779addc155f014e17c21b9decf422f4213eb336', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 7, 'created': '2017-06-15 15:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ebb462661e4311af782b5707bac4ad2e5a12904', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 8, 'created': '2017-06-15 18:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bb2dd990723521be7716156b9098cc380eb8f7d2', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins. The reason is the method for extending security groups\nand rules expects a database reference and not a neutron object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 9, 'created': '2017-06-16 04:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b955b54730a4f14882d7f0060bc9dccae29cc42c', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins.\n\nThis was for a number of reasons:\n1. _make_security_group_dict should always get the object as\n   as parameter. There were some cases where it received the\n   database object\n2. The returned port security groups needed to be a list\n3. A rule create needed to fetch from the DB\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 10, 'created': '2017-06-16 08:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b90b16e34faef6c5213903ce1f0cc991cc5c8a3', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins.\n\nThis was for a number of reasons:\n1. _make_security_group_dict should always get the object as\n   as parameter. There were some cases where it received the\n   database object\n2. The returned port security groups needed to be a list\n3. A rule create needed to fetch from the DB\n\nIn addition to this the methods resource_extend.apply_funcs\nshould receive the database object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 11, 'created': '2017-06-16 18:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/747ca4296ba9c38e32023eaee6fa9e68120fa765', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins.\n\nThis was for a number of reasons:\n1. _make_security_group_dict should always get the object as\n   as parameter. There were some cases where it received the\n   database object\n2. The returned port security groups needed to be a list\n3. A rule create needed to fetch from the DB\n\nIn addition to this the methods resource_extend.apply_funcs\nshould receive the database object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}, {'number': 12, 'created': '2017-06-16 19:43:06.000000000', 'files': ['neutron/db/securitygroups_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/98b9177c3e284f2d188ac52939ebf730ca0c384f', 'message': 'OVO: ensure decomposed plugin do not break with OVO\n\nCommit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed\nplugins.\n\nThis was for a number of reasons:\n1. _make_security_group_dict should always get the object as\n   as parameter. There were some cases where it received the\n   database object\n2. The returned port security groups needed to be a list\n3. A rule create needed to fetch from the DB\n\nIn addition to this the methods resource_extend.apply_funcs\nshould receive the database object.\n\nChange-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b\n'}]",19,474575,98b9177c3e284f2d188ac52939ebf730ca0c384f,86,14,12,1653,,,0,"OVO: ensure decomposed plugin do not break with OVO

Commit af52d499a53f9dddacd8c9116d1bb0570e8f579c broke decomposed
plugins.

This was for a number of reasons:
1. _make_security_group_dict should always get the object as
   as parameter. There were some cases where it received the
   database object
2. The returned port security groups needed to be a list
3. A rule create needed to fetch from the DB

In addition to this the methods resource_extend.apply_funcs
should receive the database object.

Change-Id: I740da1ea65a0af9451701e3a40fd673fa82f0f5b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/474575/8 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/securitygroups_db.py'],1,23361e0e75b029a9e9c54b8cb2c9ce3b83dff92c,ovo," secgroup_dict = self._make_security_group_dict(context, sg.db_obj) return [self._make_security_group_dict(context, obj, fields) for obj in sg_objs] ret = self._make_security_group_dict(context, self._get_security_group( sg_dict = self._make_security_group_dict(context, sg) def _get_security_group_db(self, context, id): try: query = model_query.query_with_hooks( context, sg_models.SecurityGroup) sg = query.filter(sg_models.SecurityGroup.id == id).one() except exc.NoResultFound: raise ext_sg.SecurityGroupNotFound(id=id) return sg def _make_security_group_dict(self, context, security_group, fields=None): res['security_group_rules'] = [self._make_security_group_rule_dict(context, r) self._get_security_group_db(context, security_group['id'])) return self._make_security_group_rule_dict(context, sg_rule.db_obj) def _get_security_group_rule_db(self, context, id): try: query = model_query.query_with_hooks( context, sg_models.SecurityGroupRule) sgr = query.filter(sg_models.SecurityGroupRule.id == id).one() except exc.NoResultFound: raise ext_sg.SecurityGroupRuleNotFound(id=id) return sgr def _make_security_group_rule_dict(self, context, security_group_rule, fields=None): self._get_security_group_rule_db(context, security_group_rule['id']))"," secgroup_dict = self._make_security_group_dict(sg.db_obj) return [self._make_security_group_dict(obj, fields) for obj in sg_objs] ret = self._make_security_group_dict(self._get_security_group( sg_dict = self._make_security_group_dict(sg) def _make_security_group_dict(self, security_group, fields=None): res['security_group_rules'] = [self._make_security_group_rule_dict(r) security_group) return self._make_security_group_rule_dict(sg_rule.db_obj) def _make_security_group_rule_dict(self, security_group_rule, fields=None): security_group_rule)",31,10
openstack%2Fpbr~master~I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb,openstack/pbr,master,I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb,allow user to override the output location of api docs,MERGED,2017-06-13 21:04:50.000000000,2017-06-16 21:58:13.000000000,2017-06-16 21:58:13.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 19298}]","[{'number': 1, 'created': '2017-06-13 21:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/89aa03f8711c8800a794a7ef8b3c0c4d6342d0e3', 'message': ""allow user to override the output location of api docs\n\nAllow the user to specify 'api_doc_dir' in the build_sphinx section of\ntheir setup.cfg to control where the auto-generated API documentation is\nwritten.\n\nChange-Id: I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}, {'number': 2, 'created': '2017-06-14 11:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/4420dadbd25401681723fefb5542eb8d4c82ed46', 'message': ""allow user to override the output location of api docs\n\nAllow the user to specify 'api_doc_dir' in the build_sphinx section of\ntheir setup.cfg to control where the auto-generated API documentation is\nwritten.\n\nChange-Id: I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}, {'number': 3, 'created': '2017-06-15 16:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/3db2b686f737df8f4a98d185f9db374f57211d2b', 'message': ""allow user to override the output location of api docs\n\nAllow the user to specify 'api_doc_dir' in the build_sphinx section of\ntheir setup.cfg to control where the auto-generated API documentation is\nwritten.\n\nChange-Id: I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}, {'number': 4, 'created': '2017-06-15 16:43:15.000000000', 'files': ['pbr/tests/test_setup.py', 'doc/source/index.rst', 'pbr/builddoc.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/3c059cb701e55c7c550f2bbe9626c9c063b0d77e', 'message': ""allow user to override the output location of api docs\n\nAllow the user to specify 'api_doc_dir' in the build_sphinx section of\ntheir setup.cfg to control where the auto-generated API documentation is\nwritten.\n\nChange-Id: I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,473983,3c059cb701e55c7c550f2bbe9626c9c063b0d77e,18,5,4,2472,,,0,"allow user to override the output location of api docs

Allow the user to specify 'api_doc_dir' in the build_sphinx section of
their setup.cfg to control where the auto-generated API documentation is
written.

Change-Id: I2bd5652bb59cbd9c939931ba2e7db1b37d2b30bb
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/pbr refs/changes/83/473983/1 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_setup.py', 'doc/source/index.rst', 'pbr/builddoc.py']",3,89aa03f8711c8800a794a7ef8b3c0c4d6342d0e3,doc-migration," api_doc_dir = option_dict.get('api_doc_dir', 'api') if 'source_dir' in option_dict: source_dir = os.path.join(option_dict['source_dir'][1], api_doc_dir) else: source_dir = 'doc/source/' + api_doc_dir"," if 'source_dir' in option_dict: source_dir = os.path.join(option_dict['source_dir'][1], 'api') else: source_dir = 'doc/source/api'",86,2
openstack%2Fpython-dracclient~master~Idc56e961699702eca734cba1da5e56cac0ad4832,openstack/python-dracclient,master,Idc56e961699702eca734cba1da5e56cac0ad4832,Fix immediate failure on SSL errors,MERGED,2017-05-19 15:07:41.000000000,2017-06-16 21:48:48.000000000,2017-06-16 21:48:48.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 10250}, {'_account_id': 23847}]","[{'number': 1, 'created': '2017-05-19 15:07:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/9013a081ab73f0801fc544a8bb014852d24d38e6', 'message': 'Fix immediate failure on SSL errors\n\nThis patch adds retry logic to communication with the iDRAC so that\nintermittent SSLErrors or ConnectionErrrors will not cause an immediate\nfailure of the operation.\n\nChange-Id: Idc56e961699702eca734cba1da5e56cac0ad4832\nCloses-Bug: 1691272\n'}, {'number': 2, 'created': '2017-05-22 13:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/8f6f9c1d102c4842904cd52231cb4fa8bebe859f', 'message': 'Fix immediate failure on SSL errors\n\nThis patch adds retry logic to communication with the iDRAC so that\nintermittent SSLErrors or ConnectionErrrors will not cause an immediate\nfailure of the operation.\n\nChange-Id: Idc56e961699702eca734cba1da5e56cac0ad4832\nCloses-Bug: 1691272\n'}, {'number': 3, 'created': '2017-05-24 18:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/06c90a0dfd33fe4de60828fc2c5be9c4fa932a24', 'message': 'Fix immediate failure on SSL errors\n\nThis patch adds retry logic to communication with the iDRAC so that\nintermittent SSLErrors or ConnectionErrrors will not cause an immediate\nfailure of the operation.\n\nChange-Id: Idc56e961699702eca734cba1da5e56cac0ad4832\nCloses-Bug: 1691272\n'}, {'number': 4, 'created': '2017-05-30 20:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/9bafbfb1341ee4d2a404fd0f0ca50d73fe29b9d9', 'message': 'Fix immediate failure on SSL errors\n\nThis patch adds retry logic to communication with the iDRAC so that\nintermittent SSLErrors or ConnectionErrrors will not cause an immediate\nfailure of the operation.\n\nChange-Id: Idc56e961699702eca734cba1da5e56cac0ad4832\nCloses-Bug: 1691272\n'}, {'number': 5, 'created': '2017-06-06 20:57:54.000000000', 'files': ['dracclient/wsman.py', 'dracclient/tests/test_wsman.py', 'dracclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/d6edaac2a1fc0fbb3cfc943a3a1845c74fc57c4f', 'message': 'Fix immediate failure on SSL errors\n\nThis patch adds retry logic to communication with the iDRAC so that\nintermittent SSLErrors or ConnectionErrrors will not cause an immediate\nfailure of the operation.\n\nChange-Id: Idc56e961699702eca734cba1da5e56cac0ad4832\nCloses-Bug: 1691272\n'}]",44,466313,d6edaac2a1fc0fbb3cfc943a3a1845c74fc57c4f,28,4,5,10250,,,0,"Fix immediate failure on SSL errors

This patch adds retry logic to communication with the iDRAC so that
intermittent SSLErrors or ConnectionErrrors will not cause an immediate
failure of the operation.

Change-Id: Idc56e961699702eca734cba1da5e56cac0ad4832
Closes-Bug: 1691272
",git fetch https://review.opendev.org/openstack/python-dracclient refs/changes/13/466313/2 && git format-patch -1 --stdout FETCH_HEAD,"['dracclient/wsman.py', 'dracclient/tests/test_wsman.py']",2,9013a081ab73f0801fc544a8bb014852d24d38e6,bug/1691272,"import requests.exceptions @requests_mock.Mocker() def test_invoke_with_ssl_errors(self, mock_requests): mock_requests.post('https://1.2.3.4:443/wsman', exc=requests.exceptions.SSLError) self.assertRaises(exceptions.WSManRequestFailure, self.client.invoke, 'http://resource', 'method', {'selector': 'foo'}, {'property': 'bar'}) @requests_mock.Mocker() def test_invoke_with_ssl_error_success(self, mock_requests): expected_resp = '<result>yay!</result>' mock_requests.post('https://1.2.3.4:443/wsman', [{'exc': requests.exceptions.SSLError}, {'text': expected_resp}]) resp = self.client.invoke('http://resource', 'method', {'selector': 'foo'}, {'property': 'bar'}) self.assertEqual('yay!', resp.text) @requests_mock.Mocker() def test_invoke_with_connection_errors(self, mock_requests): mock_requests.post('https://1.2.3.4:443/wsman', exc=requests.exceptions.ConnectionError) self.assertRaises(exceptions.WSManRequestFailure, self.client.invoke, 'http://resource', 'method', {'selector': 'foo'}, {'property': 'bar'}) @requests_mock.Mocker() def test_invoke_with_connection_error_success(self, mock_requests): expected_resp = '<result>yay!</result>' mock_requests.post('https://1.2.3.4:443/wsman', [{'exc': requests.exceptions.ConnectionError}, {'text': expected_resp}]) resp = self.client.invoke('http://resource', 'method', {'selector': 'foo'}, {'property': 'bar'}) self.assertEqual('yay!', resp.text) ",,75,11
openstack%2Fpbr~master~Iad009ce74301c9ffd49ff2b2bab4afd9b7dd1388,openstack/pbr,master,Iad009ce74301c9ffd49ff2b2bab4afd9b7dd1388,fix tests based on API change in Sphinx,MERGED,2017-06-13 21:04:50.000000000,2017-06-16 21:45:02.000000000,2017-06-16 21:45:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2017-06-13 21:04:50.000000000', 'files': ['pbr/tests/test_setup.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/d3b2b79f23ac9125a296fd7972e9a8c0c29e320e', 'message': 'fix tests based on API change in Sphinx\n\nUpstream Sphinx now has some new expectations that are no longer being\nmet by some of our tests because we mock the constructor for the\napplication class. Fix the test to ensure the application instance has\nthe needed attributes.\n\nChange-Id: Iad009ce74301c9ffd49ff2b2bab4afd9b7dd1388\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,473982,d3b2b79f23ac9125a296fd7972e9a8c0c29e320e,9,3,1,2472,,,0,"fix tests based on API change in Sphinx

Upstream Sphinx now has some new expectations that are no longer being
met by some of our tests because we mock the constructor for the
application class. Fix the test to ensure the application instance has
the needed attributes.

Change-Id: Iad009ce74301c9ffd49ff2b2bab4afd9b7dd1388
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/pbr refs/changes/82/473982/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/tests/test_setup.py'],1,d3b2b79f23ac9125a296fd7972e9a8c0c29e320e,doc-migration, # setup_command requires the Sphinx instance to have some # attributes that aren't set normally with the way we use the # class (because we replace the constructor). Add default # values directly to the class definition. import sphinx.application sphinx.application.Sphinx.messagelog = [] sphinx.application.Sphinx.statuscode = 0 ,,8,0
openstack%2Fpuppet-barbican~master~I5eb4fb17c3ba4a644efdc67ef4b60615c8e6831e,openstack/puppet-barbican,master,I5eb4fb17c3ba4a644efdc67ef4b60615c8e6831e,include policy class in api.pp,MERGED,2017-06-15 18:00:02.000000000,2017-06-16 21:43:41.000000000,2017-06-16 21:43:41.000000000,"[{'_account_id': 3}, {'_account_id': 14985}, {'_account_id': 15519}]","[{'number': 1, 'created': '2017-06-15 18:00:02.000000000', 'files': ['spec/classes/barbican_api_spec.rb', 'manifests/api.pp'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/7da4ea078404a83dc64aba1ea5237ed8eae092d9', 'message': 'include policy class in api.pp\n\nLike we do in other modules, include barbican::policy class in\nbarbican::api so users can define policies without taking care of the\nclass.\n\nChange-Id: I5eb4fb17c3ba4a644efdc67ef4b60615c8e6831e\n'}]",0,474717,7da4ea078404a83dc64aba1ea5237ed8eae092d9,9,3,1,3153,,,0,"include policy class in api.pp

Like we do in other modules, include barbican::policy class in
barbican::api so users can define policies without taking care of the
class.

Change-Id: I5eb4fb17c3ba4a644efdc67ef4b60615c8e6831e
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/17/474717/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/barbican_api_spec.rb', 'manifests/api.pp']",2,7da4ea078404a83dc64aba1ea5237ed8eae092d9,policies, include ::barbican::policy,,2,0
openstack%2Fpuppet-tripleo~master~I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37,openstack/puppet-tripleo,master,I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37,For http service endpoints always redirect to https,MERGED,2017-06-14 08:36:46.000000000,2017-06-16 21:43:26.000000000,2017-06-16 21:43:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-14 08:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/de1cab8333c389fadcfe1e635aed57f92edf5be8', 'message': 'For http service endpoints always redirect to https\n\nIf public TLS is enabled, this sets as default that services should\nalways redirect to https. This happens if the address that was accessed\nis the external FQDN or the public VIP.\n\nChange-Id: I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37\n'}, {'number': 2, 'created': '2017-06-14 09:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8d2a0f9cb5b9040266a89bdb2fe62b3946e9b92b', 'message': 'For http service endpoints always redirect to https\n\nIf public TLS is enabled, this sets as default that services should\nalways redirect to https.\n\nChange-Id: I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37\n'}, {'number': 3, 'created': '2017-06-14 11:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/dfa9be7c34fe4cd1b413ea05516b0c295e4b2835', 'message': 'For http service endpoints always redirect to https\n\nIf public TLS is enabled, this sets as default that services should\nalways redirect to https.\n\nChange-Id: I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37\n'}, {'number': 4, 'created': '2017-06-14 14:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f007ea6415187ebf771280bfa5a9ba2f691e6f2c', 'message': 'For http service endpoints always redirect to https\n\nIf public TLS is enabled, this sets as default that services should\nalways redirect to https.\n\nChange-Id: I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37\n'}, {'number': 5, 'created': '2017-06-16 09:54:09.000000000', 'files': ['manifests/haproxy.pp', 'manifests/haproxy/endpoint.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/192463755bb599b8879c09a97cf731dad0cde6a0', 'message': 'For http service endpoints always redirect to https\n\nIf public TLS is enabled, this sets as default that services should\nalways redirect to https.\n\nChange-Id: I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37\n'}]",1,474108,192463755bb599b8879c09a97cf731dad0cde6a0,18,4,5,10873,,,0,"For http service endpoints always redirect to https

If public TLS is enabled, this sets as default that services should
always redirect to https.

Change-Id: I19b9d07ac8925366ed27fefcaca4fdb9a9ab1b37
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/08/474108/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/haproxy.pp', 'manifests/haproxy/endpoint.pp']",2,de1cab8333c389fadcfe1e635aed57f92edf5be8,haproxy-dynamic-endpoints,"# [*external_fqdn*] # The FQDN for the external VIP. Used to check if we need to redirect to # https. # Defaults to hiera('cloud_name_external'). # $external_fqdn = hiera('cloud_name_external'), if $mode == 'http' { $tls_listen_options = { 'rsprep' => '^Location:\ http://(.*) Location:\ https://\1', 'redirect' => 'scheme https code 301 if hdr(host) -i ${public_virtual_ip} or hdr(host) -i ${$external_fqdn} !{ ssl_fc }', 'option' => 'forwardfor', } $listen_options_real = merge($tls_listen_options, $listen_options) } else { $listen_options_real = $listen_options } $listen_options_real = $listen_options options => $listen_options_real,"," options => $listen_options,",21,13
openstack%2Ftripleo-heat-templates~stable%2Focata~I9a7a80252703e470a69dc10352e7ece45ab23150,openstack/tripleo-heat-templates,stable/ocata,I9a7a80252703e470a69dc10352e7ece45ab23150,Add ignore_projects to filter gnocchi events,MERGED,2017-05-30 18:21:10.000000000,2017-06-16 21:41:57.000000000,2017-06-16 21:41:57.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-05-30 18:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/81e2066961e64669bd98860bb25ffc37b608b383', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}, {'number': 2, 'created': '2017-05-31 11:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/edc0d51366d4e9fe4ab1f18b9a31853df3ea216b', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}, {'number': 3, 'created': '2017-06-04 23:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fac75d99acf0ece1b3f380eb9685db7fe6eec327', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}, {'number': 4, 'created': '2017-06-07 22:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1b42c409a63f75ae3ecf600dfaf756529968b7a9', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}, {'number': 5, 'created': '2017-06-13 11:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4fde41fd3bbf4fc2319b907bf56e536ef598e03', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}, {'number': 6, 'created': '2017-06-14 15:06:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5e3fd028eeac1c6872072d2a9d3dec1bfc36d3f5', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}, {'number': 7, 'created': '2017-06-15 18:31:37.000000000', 'files': ['puppet/services/swift-proxy.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/32e5fe6cee3e8165bf2730c378d6c4804136104c', 'message': 'Add ignore_projects to filter gnocchi events\n\nWithout this, ceilometer db gets hammered with gnocchi swift events.\nKeystone creds are required so middleware can query for id.\n\nRelated change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1\n\nChange-Id: I9a7a80252703e470a69dc10352e7ece45ab23150\n(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)\n'}]",0,469202,32e5fe6cee3e8165bf2730c378d6c4804136104c,46,4,7,6924,,,0,"Add ignore_projects to filter gnocchi events

Without this, ceilometer db gets hammered with gnocchi swift events.
Keystone creds are required so middleware can query for id.

Related change:  I5c0f4f1a2c7fe7eb39ea6441970e9ac0946a4ec1

Change-Id: I9a7a80252703e470a69dc10352e7ece45ab23150
(cherry picked from commit 37447494de7380409f4461835a2b1882ead37985)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/469202/5 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/swift-proxy.yaml'],1,81e2066961e64669bd98860bb25ffc37b608b383,ignore_projects," SwiftCeilometerIgnoreProjects: default: ['services'] description: Comma-seperated list of project names to ignore. type: comma_delimited_list swift::proxy::ceilometer::auth_uri: {get_param: [EndpointMap, KeystoneInternal, uri]} swift::proxy::ceilometer::auth_url: {get_param: [EndpointMap, KeystoneInternal, uri_no_suffix]} swift::proxy::ceilometer::password: {get_param: SwiftPassword} swift::proxy::ceilometer::ignore_projects: {get_param: SwiftCeilometerIgnoreProjects}",,8,0
openstack%2Fpatrole~master~Id4c1e3d8665458cf1ffa44da21c18d62468472fb,openstack/patrole,master,Id4c1e3d8665458cf1ffa44da21c18d62468472fb,Add waiter to test_volume_backup_delete,MERGED,2017-06-13 19:41:47.000000000,2017-06-16 21:31:22.000000000,2017-06-16 20:13:39.000000000,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 17896}, {'_account_id': 23185}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-06-13 19:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/9cc8d6f4a5caa06286538f41b36b78a5dab9721d', 'message': 'Add waiter to test_volume_backup_delete\n\nAdd waiter to test_volume_backup_delete test to prevent badRequest\nerror caused by invalid backup status.\n\nChange-Id: Id4c1e3d8665458cf1ffa44da21c18d62468472fb\n'}, {'number': 2, 'created': '2017-06-14 16:34:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/e381d48c411f71bcce6e2d5d031ffe5ffa33d700', 'message': 'Add waiter to test_volume_backup_delete\n\nAdd waiter to test_volume_backup_delete test to prevent badRequest\nerror caused by invalid backup status.\n\nChange-Id: Id4c1e3d8665458cf1ffa44da21c18d62468472fb\n'}, {'number': 3, 'created': '2017-06-15 19:54:58.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_volumes_backup_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/93dae2a4487e67473d57420ebbde3afd4c142d84', 'message': 'Add waiter to test_volume_backup_delete\n\nAdd waiter to test_volume_backup_delete test to prevent badRequest\nerror caused by invalid backup status.\n\nChange-Id: Id4c1e3d8665458cf1ffa44da21c18d62468472fb\n'}]",3,473956,93dae2a4487e67473d57420ebbde3afd4c142d84,33,5,3,23185,,,0,"Add waiter to test_volume_backup_delete

Add waiter to test_volume_backup_delete test to prevent badRequest
error caused by invalid backup status.

Change-Id: Id4c1e3d8665458cf1ffa44da21c18d62468472fb
",git fetch https://review.opendev.org/openstack/patrole refs/changes/56/473956/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_volumes_backup_rbac.py'],1,9cc8d6f4a5caa06286538f41b36b78a5dab9721d,," waiters.wait_for_volume_resource_status(self.backups_client, backup['id'], 'available')",,2,0
openstack%2Fneutron~master~Iacf1b6dfe318e3e6cfc76e61c65d407cf9ae7b36,openstack/neutron,master,Iacf1b6dfe318e3e6cfc76e61c65d407cf9ae7b36,replace WorkerSupportServiceMixin with neutron-lib's WorkerBase,MERGED,2017-06-01 21:35:01.000000000,2017-06-16 21:28:34.000000000,2017-06-16 15:36:08.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5367}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8871}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-01 21:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b04d67b4302e36b1960a12d90a01c52806e566d', 'message': ""replace WorkerSupportServiceMixin with neutron-lib's WorkerBase\n\nneutron-lib contains the WorkerBase class [1] that is the equivalent of\nneutron's WorkerSupportServiceMixin. This patch switches over to\nneutron-lib's version.\n\nNote: IIUC no consumers are using WorkerSupportServiceMixin so this\npatch can land without waiting for them to sync-up. I've included\nthe lib impact tag just in case.\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/424151/\n[2] http://codesearch.openstack.org/?q=WorkerSupportServiceMixin\n\nChange-Id: Iacf1b6dfe318e3e6cfc76e61c65d407cf9ae7b36\n""}, {'number': 2, 'created': '2017-06-05 13:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc2c8661ef334fb957413466faf2855b47ae0615', 'message': ""replace WorkerSupportServiceMixin with neutron-lib's WorkerBase\n\nneutron-lib contains the WorkerBase class [1] that is the equivalent of\nneutron's WorkerSupportServiceMixin. This patch switches over to\nneutron-lib's version.\n\nNote: IIUC no consumers are using WorkerSupportServiceMixin so this\npatch can land without waiting for them to sync-up. I've included\nthe lib impact tag just in case.\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/424151/\n[2] http://codesearch.openstack.org/?q=WorkerSupportServiceMixin\n\nChange-Id: Iacf1b6dfe318e3e6cfc76e61c65d407cf9ae7b36\n""}, {'number': 3, 'created': '2017-06-14 12:56:54.000000000', 'files': ['neutron/worker.py', 'neutron/db/l3_db.py', 'neutron/neutron_plugin_base_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7cae827b6b18f55fdfb3868c973f92c709df253e', 'message': ""replace WorkerSupportServiceMixin with neutron-lib's WorkerBase\n\nneutron-lib contains the WorkerBase class [1] that is the equivalent of\nneutron's WorkerSupportServiceMixin. This patch switches over to\nneutron-lib's version.\n\nNote: IIUC no consumers are using WorkerSupportServiceMixin so this\npatch can land without waiting for them to sync-up. I've included\nthe lib impact tag just in case.\n\nNeutronLibImpact\n\n[1] https://review.openstack.org/#/c/424151/\n[2] http://codesearch.openstack.org/?q=WorkerSupportServiceMixin\n\nChange-Id: Iacf1b6dfe318e3e6cfc76e61c65d407cf9ae7b36\n""}]",0,470024,7cae827b6b18f55fdfb3868c973f92c709df253e,54,13,3,5367,,,0,"replace WorkerSupportServiceMixin with neutron-lib's WorkerBase

neutron-lib contains the WorkerBase class [1] that is the equivalent of
neutron's WorkerSupportServiceMixin. This patch switches over to
neutron-lib's version.

Note: IIUC no consumers are using WorkerSupportServiceMixin so this
patch can land without waiting for them to sync-up. I've included
the lib impact tag just in case.

NeutronLibImpact

[1] https://review.openstack.org/#/c/424151/
[2] http://codesearch.openstack.org/?q=WorkerSupportServiceMixin

Change-Id: Iacf1b6dfe318e3e6cfc76e61c65d407cf9ae7b36
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/470024/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/worker.py', 'neutron/db/l3_db.py', 'neutron/neutron_plugin_base_v2.py']",3,5b04d67b4302e36b1960a12d90a01c52806e566d,bp/neutron-lib-networking-ovn,from neutron_lib.services import base as base_servicesclass NeutronPluginBaseV2(base_services.WorkerBase):,from neutron import worker as neutron_worker class NeutronPluginBaseV2(neutron_worker.WorkerSupportServiceMixin):,4,37
openstack%2Fneutron~master~I7e391d0ea8daefff72639357c3c9fc7dc38c5b91,openstack/neutron,master,I7e391d0ea8daefff72639357c3c9fc7dc38c5b91,"Revert ""Integrate Security Groups OVO""",ABANDONED,2017-06-16 15:00:43.000000000,2017-06-16 21:13:00.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 9656}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-16 15:00:43.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/tests/unit/objects/test_securitygroup.py', 'neutron/objects/securitygroup.py', 'neutron/tests/unit/db/test_securitygroups_db.py', 'neutron/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/21c590bb42faf80d15fd709f6e46c1a754a40f25', 'message': 'Revert ""Integrate Security Groups OVO""\n\nThis reverts commit af52d499a53f9dddacd8c9116d1bb0570e8f579c.\n\nAfter this patch was merged, heat dsvm job failing\nwith RemoteDisconnected error with 100% rate.\n\nChange-Id: I7e391d0ea8daefff72639357c3c9fc7dc38c5b91\nCloses-Bug: #1698355\n'}]",0,474997,21c590bb42faf80d15fd709f6e46c1a754a40f25,11,8,1,841,,,0,"Revert ""Integrate Security Groups OVO""

This reverts commit af52d499a53f9dddacd8c9116d1bb0570e8f579c.

After this patch was merged, heat dsvm job failing
with RemoteDisconnected error with 100% rate.

Change-Id: I7e391d0ea8daefff72639357c3c9fc7dc38c5b91
Closes-Bug: #1698355
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/474997/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_db.py', 'neutron/tests/unit/objects/test_securitygroup.py', 'neutron/objects/securitygroup.py', 'neutron/tests/unit/db/test_securitygroups_db.py', 'neutron/tests/unit/objects/test_objects.py']",5,21c590bb42faf80d15fd709f6e46c1a754a40f25,bug/1698355," '_DefaultSecurityGroup': '1.0-971520cb2e0ec06d747885a0cf78347f',"," 'DefaultSecurityGroup': '1.0-971520cb2e0ec06d747885a0cf78347f',",114,150
openstack%2Fdevstack~master~I5281b363f2af98a0925f0b087b43815fa8fda2bd,openstack/devstack,master,I5281b363f2af98a0925f0b087b43815fa8fda2bd,Default Cinder iscsi helper to LIO for centos/rhel,ABANDONED,2017-06-16 21:09:04.000000000,2017-06-16 21:11:33.000000000,,[{'_account_id': 1955}],"[{'number': 1, 'created': '2017-06-16 21:09:04.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/1df6d19331ae6de6ac2192de979681aa6d47c156', 'message': 'Default Cinder iscsi helper to LIO for centos/rhel\n\nscsi-target-utils/tgtd is not available on rhel or centos.\nUse LIO by default for these platforms, and Fedora, instead.\n\nChange-Id: I5281b363f2af98a0925f0b087b43815fa8fda2bd\n'}]",0,475074,1df6d19331ae6de6ac2192de979681aa6d47c156,2,1,1,4523,,,0,"Default Cinder iscsi helper to LIO for centos/rhel

scsi-target-utils/tgtd is not available on rhel or centos.
Use LIO by default for these platforms, and Fedora, instead.

Change-Id: I5281b363f2af98a0925f0b087b43815fa8fda2bd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/74/475074/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,1df6d19331ae6de6ac2192de979681aa6d47c156,,"if is_fedora; then # tgtadm/scsi-target-utils is not present on CentOS/RHEL, # and is not preferred for Fedora CINDER_ISCSI_HELPER=${CINDER_ISCSI_HELPER:-lioadm} else CINDER_ISCSI_HELPER=${CINDER_ISCSI_HELPER:-tgtadm} fi",CINDER_ISCSI_HELPER=${CINDER_ISCSI_HELPER:-tgtadm},7,1
openstack%2Fproject-config~master~I7686df5493dd85d980390c9a0524419e19787d79,openstack/project-config,master,I7686df5493dd85d980390c9a0524419e19787d79,Stop running python2 jobs for Zuul v3,MERGED,2017-06-16 15:25:13.000000000,2017-06-16 21:09:38.000000000,2017-06-16 21:09:38.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4162}]","[{'number': 1, 'created': '2017-06-16 15:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cc499994e89af00956ef6a3d9d763bb490a09083', 'message': ""Stop running python2 jobs on zuulv3\n\nWe're adding things that require python3. Doing that in a manner that\nstill works for python2 is prohibitively difficult, given that they\nactually use python2 language/syntax features.\n\nWe're running zuulv3 with python3. There are no legacy installations of\nv3. And the Software Factory folks say that running it with python3 on\ncentos7 is not an issue.\n\nGo ahead and stop supporting it.\n\nChange-Id: I7686df5493dd85d980390c9a0524419e19787d79\n""}, {'number': 2, 'created': '2017-06-16 20:54:10.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fc825fbfde53d065690ae5e256a57605cfc85d63', 'message': ""Stop running python2 jobs for Zuul v3\n\nWe're adding things that require python3. Doing that in a manner that\nstill works for python2 is prohibitively difficult, given that they\nactually use python2 language/syntax features.\n\nWe're running Zuul v3 with python3. There are no legacy installations of\nv3. And the Software Factory folks say that running it with python3 on\ncentos7 is not an issue.\n\nGo ahead and stop supporting it.\n\nChange-Id: I7686df5493dd85d980390c9a0524419e19787d79\n""}]",1,475005,fc825fbfde53d065690ae5e256a57605cfc85d63,11,3,2,2,,,0,"Stop running python2 jobs for Zuul v3

We're adding things that require python3. Doing that in a manner that
still works for python2 is prohibitively difficult, given that they
actually use python2 language/syntax features.

We're running Zuul v3 with python3. There are no legacy installations of
v3. And the Software Factory folks say that running it with python3 on
centos7 is not an issue.

Go ahead and stop supporting it.

Change-Id: I7686df5493dd85d980390c9a0524419e19787d79
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/475005/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,cc499994e89af00956ef6a3d9d763bb490a09083,, # Only run python27 job on the master branch of zuul - name: ^gate-zuul-python27 branch: master # Only run python27 job on the feature/zuulv3 branch of nodepool - name: ^gate-nodepool-python27 branch: master ,,8,0
openstack%2Fneutron-lib~master~Ifaf4657c37791e8e11907c66fb6cab7128c122a6,openstack/neutron-lib,master,Ifaf4657c37791e8e11907c66fb6cab7128c122a6,rehome qos service DriverBase class,MERGED,2017-06-02 20:18:08.000000000,2017-06-16 21:04:39.000000000,2017-06-16 21:04:38.000000000,"[{'_account_id': 3}, {'_account_id': 5367}, {'_account_id': 6854}, {'_account_id': 9656}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 18051}]","[{'number': 1, 'created': '2017-06-02 20:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/8add23af0cd60961d2848a8fca16f35372b01658', 'message': 'rehome qos service DriverBase class\n\nThe neutron.services.qos.drivers.base.DriverBase class is used by a\nnumber of consumers [1]. This patch rehomes it into neutron_lib along\nwith the qos_consts that are also used by consumers [2].\n\nUTs and a release note are also included.\n\n[1] http://codesearch.openstack.org/?q=from%20neutron%5C.services%5C.qos%5C.drivers%20import%20base\n[2] http://codesearch.openstack.org/?q=from%20neutron%5C.services%5C.qos%20import%20qos_consts\n\nChange-Id: Ifaf4657c37791e8e11907c66fb6cab7128c122a6\n'}, {'number': 2, 'created': '2017-06-13 15:06:39.000000000', 'files': ['neutron_lib/services/qos/__init__.py', 'releasenotes/notes/rehome-qos-driverbase-f729875b2ad74ce0.yaml', 'neutron_lib/tests/unit/services/qos/test_base.py', 'neutron_lib/services/qos/constants.py', 'neutron_lib/tests/unit/services/qos/__init__.py', 'neutron_lib/services/qos/base.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/d35f7e17168c1cf95e7559efb1065322c8541ec8', 'message': 'rehome qos service DriverBase class\n\nThe neutron.services.qos.drivers.base.DriverBase class is used by a\nnumber of consumers [1]. This patch rehomes it into neutron_lib along\nwith the qos_consts that are also used by consumers [2].\n\nUTs and a release note are also included.\n\n[1] http://codesearch.openstack.org/?q=from%20neutron%5C.services%5C.qos%5C.drivers%20import%20base\n[2] http://codesearch.openstack.org/?q=from%20neutron%5C.services%5C.qos%20import%20qos_consts\n\nChange-Id: Ifaf4657c37791e8e11907c66fb6cab7128c122a6\n'}]",10,470426,d35f7e17168c1cf95e7559efb1065322c8541ec8,17,7,2,5367,,,0,"rehome qos service DriverBase class

The neutron.services.qos.drivers.base.DriverBase class is used by a
number of consumers [1]. This patch rehomes it into neutron_lib along
with the qos_consts that are also used by consumers [2].

UTs and a release note are also included.

[1] http://codesearch.openstack.org/?q=from%20neutron%5C.services%5C.qos%5C.drivers%20import%20base
[2] http://codesearch.openstack.org/?q=from%20neutron%5C.services%5C.qos%20import%20qos_consts

Change-Id: Ifaf4657c37791e8e11907c66fb6cab7128c122a6
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/26/470426/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/services/qos/__init__.py', 'releasenotes/notes/rehome-qos-driverbase-f729875b2ad74ce0.yaml', 'neutron_lib/services/qos/constants.py', 'neutron_lib/tests/unit/services/qos/test_base.py', 'neutron_lib/tests/unit/services/qos/__init__.py', 'neutron_lib/services/qos/base.py']",6,8add23af0cd60961d2848a8fca16f35372b01658,bp/neutron-lib-networking-ovn,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from neutron_lib.api import validators as lib_validators from neutron_lib.callbacks import events from neutron_lib.callbacks import registry from neutron_lib.services.qos import constants LOG = logging.getLogger(__name__) @registry.has_registry_receivers class DriverBase(object): def __init__(self, name, vif_types, vnic_types, supported_rules, requires_rpc_notifications=False): """"""Instantiate a qos driver. :param name: driver name. :param vif_types: list of interfaces (VIFs) supported. :param vnic_types: list of vnic types supported. :param supported_rules: dict of supported rules. :param requires_rpc_notifications: indicates if this driver expects rpc push notifications to be sent from the driver. """""" self.name = name self.vif_types = vif_types self.vnic_types = vnic_types self.supported_rules = supported_rules self.requires_rpc_notifications = requires_rpc_notifications @registry.receives(constants.QOS_PLUGIN, [events.AFTER_INIT]) def _register(self, resource, event, trigger, **kwargs): if self.is_loaded: # trigger is the QosServiceDriverManager trigger.register_driver(self) def is_loaded(self): """"""True if the driver is active for the Neutron Server. Implement this property to determine if your driver is actively configured for this Neutron Server deployment. """""" return True def is_vif_type_compatible(self, vif_type): """"""True if the driver is compatible with the VIF type."""""" return vif_type in self.vif_types def is_vnic_compatible(self, vnic_type): """"""True if the driver is compatible with the specific VNIC type."""""" return vnic_type in self.vnic_types def is_rule_supported(self, rule): supported_parameters = self.supported_rules.get(rule.rule_type) if not supported_parameters: LOG.debug(""Rule type %(rule_type)s is not supported by "" ""%(driver_name)s"", {'rule_type': rule.rule_type, 'driver_name': self.name}) return False for parameter, validators in supported_parameters.items(): parameter_value = rule.get(parameter) for validator_type, validator_data in validators.items(): validator_function = lib_validators.get_validator( validator_type) validate_result = validator_function(parameter_value, validator_data) # NOTE(slaweq): validator functions returns None if data is # valid or string with reason why data is not valid if validate_result: LOG.debug(""Parameter %(parameter)s=%(value)s in "" ""rule type %(rule_type)s is not "" ""supported by %(driver_name)s. "" ""Validate result: %(validate_result)s"", {'parameter': parameter, 'value': parameter_value, 'rule_type': rule.rule_type, 'driver_name': self.name, 'validate_result': validate_result}) return False return True def create_policy(self, context, policy): """"""Create policy invocation. This method can be implemented by the specific driver subclass to update the backend where necessary with the specific policy information. :param context: current running context information :param policy: a QoSPolicy object being created, which will have no rules. """""" def create_policy_precommit(self, context, policy): """"""Create policy precommit. This method can be implemented by the specific driver subclass to handle the precommit event of a policy that is being created. :param context: current running context information :param policy: a QoSPolicy object being created, which will have no rules. """""" def update_policy(self, context, policy): """"""Update policy invocation. This method can be implemented by the specific driver subclass to update the backend where necessary. :param context: current running context information :param policy: a QoSPolicy object being updated. """""" def update_policy_precommit(self, context, policy): """"""Update policy precommit. This method can be implemented by the specific driver subclass to handle update precommit event of a policy that is being updated. :param context: current running context information :param policy: a QoSPolicy object being updated. """""" def delete_policy(self, context, policy): """"""Delete policy invocation. This method can be implemented by the specific driver subclass to delete the backend policy where necessary. :param context: current running context information :param policy: a QoSPolicy object being deleted """""" def delete_policy_precommit(self, context, policy): """"""Delete policy precommit. This method can be implemented by the specific driver subclass to handle delete precommit event of a policy that is being deleted. :param context: current running context information :param policy: a QoSPolicy object being deleted """""" ",,302,0
openstack%2Fironic~master~I6a6d248155f98109dd36dba5837494f6974846e6,openstack/ironic,master,I6a6d248155f98109dd36dba5837494f6974846e6,Validate portgroup physical network consistency,MERGED,2017-06-01 15:58:46.000000000,2017-06-16 20:52:08.000000000,2017-06-16 07:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 11655}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 14826}, {'_account_id': 17998}, {'_account_id': 19339}, {'_account_id': 19593}, {'_account_id': 23630}, {'_account_id': 24245}]","[{'number': 1, 'created': '2017-06-01 15:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/43023b1b1c6fb4df23165b63097ceab2368852b1', 'message': 'Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nIf the validation fails, we raise exception.Conflict.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n'}, {'number': 2, 'created': '2017-06-02 19:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc31ea22f101c45133c253a76c1abccf9363a1cf', 'message': 'Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nIf the portgroup has ports with different physical networks, we raise\nPortgroupPhysnetInconsistent.\n\nIf the port has a physical network that is inconsistent with other ports\nin the portgroup, we raise exception.Conflict.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n'}, {'number': 3, 'created': '2017-06-06 15:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8535c073a5d6bf3a9171f74cb6045bd2001da65e', 'message': 'Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nIf the portgroup has ports with different physical networks, we raise\nPortgroupPhysnetInconsistent.\n\nIf the port has a physical network that is inconsistent with other ports\nin the portgroup, we raise exception.Conflict.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n'}, {'number': 4, 'created': '2017-06-07 13:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2a45699e2b0d29e74cb9e55aa80f8f3cc4eeaedd', 'message': 'Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nIf the portgroup has ports with different physical networks, we raise\nPortgroupPhysnetInconsistent.\n\nIf the port has a physical network that is inconsistent with other ports\nin the portgroup, we raise exception.Conflict.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n'}, {'number': 5, 'created': '2017-06-12 18:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/45026b83085bff9698af85c25a83760b0d3a18ed', 'message': ""Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nIf the portgroup has ports with different physical networks, we raise\nPortgroupPhysnetInconsistent. This shouldn't ever happen.\n\nIf the port has a physical network that is inconsistent with other ports\nin the portgroup, we raise exception.Conflict.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n""}, {'number': 6, 'created': '2017-06-15 12:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c3c47b6f96c121729a472c1da6051a65d31bcc02', 'message': ""Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nAll ports in a portgroup should have the same value (which may be None)\nfor their physical_network field.\n\nDuring creation or update of a port in a portgroup we apply the\nfollowing validation criteria:\n\n- If the portgroup has existing ports with different physical networks,\n  we raise PortgroupPhysnetInconsistent. This shouldn't ever happen.\n- If the port has a physical network that is inconsistent with other\n  ports in the portgroup, we raise exception.Conflict.\n\nIf a port's physical network is None, this indicates that ironic's VIF\nattachment mapping algorithm should operate in a legacy (physical\nnetwork unaware) mode for this port or portgroup. This allows existing\nironic nodes to continue to function after an upgrade to a release\nincluding physical network support.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n""}, {'number': 7, 'created': '2017-06-15 22:03:27.000000000', 'files': ['ironic/common/exception.py', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_utils.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/conductor/utils.py', 'ironic/common/network.py', 'ironic/tests/unit/common/test_network.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/039225610d220ddb3d9d1edf4a74c8cb2a0de4fd', 'message': ""Validate portgroup physical network consistency\n\nWhen creating or updating a port that is a member of a portgroup, we\nneed to validate the consistency of the physical networks of the ports\nin the portgroup.\n\nThere are 3 cases we are interested in:\n\n- Creating a port which is a member of a portgroup.\n- Updating the physical network of a port which is a member of a\n  portgroup.\n- Updating the portgroup of a port.\n\nAll ports in a portgroup should have the same value (which may be None)\nfor their physical_network field.\n\nDuring creation or update of a port in a portgroup we apply the\nfollowing validation criteria:\n\n- If the portgroup has existing ports with different physical networks,\n  we raise PortgroupPhysnetInconsistent. This shouldn't ever happen.\n- If the port has a physical network that is inconsistent with other\n  ports in the portgroup, we raise exception.Conflict.\n\nIf a port's physical network is None, this indicates that ironic's VIF\nattachment mapping algorithm should operate in a legacy (physical\nnetwork unaware) mode for this port or portgroup. This allows existing\nironic nodes to continue to function after an upgrade to a release\nincluding physical network support.\n\nChange-Id: I6a6d248155f98109dd36dba5837494f6974846e6\nPartial-Bug: #1666009\n""}]",79,469932,039225610d220ddb3d9d1edf4a74c8cb2a0de4fd,87,15,7,14826,,,0,"Validate portgroup physical network consistency

When creating or updating a port that is a member of a portgroup, we
need to validate the consistency of the physical networks of the ports
in the portgroup.

There are 3 cases we are interested in:

- Creating a port which is a member of a portgroup.
- Updating the physical network of a port which is a member of a
  portgroup.
- Updating the portgroup of a port.

All ports in a portgroup should have the same value (which may be None)
for their physical_network field.

During creation or update of a port in a portgroup we apply the
following validation criteria:

- If the portgroup has existing ports with different physical networks,
  we raise PortgroupPhysnetInconsistent. This shouldn't ever happen.
- If the port has a physical network that is inconsistent with other
  ports in the portgroup, we raise exception.Conflict.

If a port's physical network is None, this indicates that ironic's VIF
attachment mapping algorithm should operate in a legacy (physical
network unaware) mode for this port or portgroup. This allows existing
ironic nodes to continue to function after an upgrade to a release
including physical network support.

Change-Id: I6a6d248155f98109dd36dba5837494f6974846e6
Partial-Bug: #1666009
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/469932/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_utils.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/conductor/utils.py']",4,43023b1b1c6fb4df23165b63097ceab2368852b1,bug/1666009," @task_manager.require_exclusive_lock def validate_port_physnet(task, port_obj): """"""Validate the consistency of physical networks of ports in a portgroup. :param task: a TaskManager instance :param port_obj: a port object to be validated. :raises: Conflict if the port is a member of a portgroup which is on a different physical network. """""" if 'portgroup_id' not in port_obj or not port_obj.portgroup_id: return portgroup_uuid = [pg.uuid for pg in task.portgroups if pg.id == port_obj.portgroup_id][0] pg_physnets = {port.physical_network for port in task.ports if (port.portgroup_id == port_obj.portgroup_id and ('id' not in port_obj or port.id != port_obj.id))} # Sanity check that all existing ports in the group have the same # physical network. if len(pg_physnets) > 1: msg = _(""Port group %(portgroup)s has existing member ports with "" ""different physical networks: %(physnets)s. All ports "" ""in a port group must have the same physical network."") raise exception.Conflict( msg % {'portgroup': portgroup_uuid, 'physnets': "", "".join(pg_physnets)}) if not pg_physnets: return # Check that the port has the same physical network as any existing # member ports. pg_physnet = pg_physnets.pop() port_physnet = (port_obj.physical_network if 'physical_network' in port_obj else None) if port_physnet != pg_physnet: msg = _(""Port group %(portgroup)s is in physical network "" ""%(physnet)s. This port cannot be a member of that port "" ""group while it has a different physical network."") raise exception.Conflict( msg % {'portgroup': portgroup_uuid, 'physnet': pg_physnet})",,423,9
openstack%2Frpm-packaging~stable%2Focata~Ifa500b13146e01fb3b61efc1d60f7e6d072efc4c,openstack/rpm-packaging,stable/ocata,Ifa500b13146e01fb3b61efc1d60f7e6d072efc4c,murano-dashboard: fix semantic_version requirement,MERGED,2017-06-16 12:23:53.000000000,2017-06-16 20:49:44.000000000,2017-06-16 20:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-06-16 12:23:53.000000000', 'files': ['openstack/murano-dashboard/murano-dashboard.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fadd00583efca3224d53ae162eafc07090ebe3de', 'message': 'murano-dashboard: fix semantic_version requirement\n\n(cherry picked from commit 10d9e19f8e5884ae9b5d2b5dd29a49845846127e)\n\nChange-Id: Ifa500b13146e01fb3b61efc1d60f7e6d072efc4c\n'}]",0,474957,fadd00583efca3224d53ae162eafc07090ebe3de,8,4,1,13404,,,0,"murano-dashboard: fix semantic_version requirement

(cherry picked from commit 10d9e19f8e5884ae9b5d2b5dd29a49845846127e)

Change-Id: Ifa500b13146e01fb3b61efc1d60f7e6d072efc4c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/57/474957/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/murano-dashboard/murano-dashboard.spec.j2'],1,fadd00583efca3224d53ae162eafc07090ebe3de,,Requires: {{ py2pkg('semantic_version') }},Requires: {{ py2pkg('semantic-version') }},1,1
openstack%2Frpm-packaging~master~I2879e317692e6f8c6f6b85ed19f04e3374029638,openstack/rpm-packaging,master,I2879e317692e6f8c6f6b85ed19f04e3374029638,Update oslo.log to 3.28.1,MERGED,2017-06-15 20:08:02.000000000,2017-06-16 20:49:28.000000000,2017-06-16 20:49:28.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 13404}, {'_account_id': 19648}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-06-15 20:08:02.000000000', 'files': ['openstack/oslo.log/oslo.log.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4b6781918526a4fbd809f42b2b0f70cd600cfacb', 'message': 'Update oslo.log to 3.28.1\n\nChange-Id: I2879e317692e6f8c6f6b85ed19f04e3374029638\nDepends-on: I2dd4f20e629de9542157989430d2f536989a20a1\n'}]",0,474766,4b6781918526a4fbd809f42b2b0f70cd600cfacb,14,6,1,17130,,,0,"Update oslo.log to 3.28.1

Change-Id: I2879e317692e6f8c6f6b85ed19f04e3374029638
Depends-on: I2dd4f20e629de9542157989430d2f536989a20a1
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/66/474766/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.log/oslo.log.spec.j2'],1,4b6781918526a4fbd809f42b2b0f70cd600cfacb,oslo-log,Version: 3.28.1,Version: 3.28.0,1,1
openstack%2Fpuppet-tripleo~master~Ifef08033043a4cc90a6261e962d2fdecdf275650,openstack/puppet-tripleo,master,Ifef08033043a4cc90a6261e962d2fdecdf275650,Only set the stonith property on the pacemaker_master node,MERGED,2017-06-07 08:24:10.000000000,2017-06-16 20:39:12.000000000,2017-06-16 20:39:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 20172}]","[{'number': 1, 'created': '2017-06-07 08:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7b1834b458e5fd3d0b9c9f94ef1c6b9bfd38739d', 'message': 'Only set the stonith property on the pacemaker_master node\n\nIt makes little sense to enforce the stonith property on remote nodes and/or\nall cluster nodes. We can just enforce it once on the pacemaker_master\nnode as it is a cluster-wide property anyway.\n\nWhile this works in general it creates extra CIB changes for nothing and\nslows down the deployment.\n\nChange-Id: Ifef08033043a4cc90a6261e962d2fdecdf275650\nCloses-Bug: #1696336\n'}, {'number': 2, 'created': '2017-06-07 08:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/32d98dd09d3d1823be49d707065416e040742f4e', 'message': 'Only set the stonith property on the pacemaker_master node\n\nIt makes little sense to enforce the stonith property on remote nodes and/or\nall cluster nodes. We can just enforce it once on the pacemaker_master\nnode as it is a cluster-wide property anyway. We can also remove the\ntripleo::fencing -> pacemaker::stonith constraint in the pacemaker\nremote profile now as the fencing stuff happens on step 5 anyway and\nthe property is set at step 1.\n\nWhile this works in general it creates extra CIB changes for nothing and\nslows down the deployment.\n\nChange-Id: Ifef08033043a4cc90a6261e962d2fdecdf275650\nCloses-Bug: #1696336\n'}, {'number': 3, 'created': '2017-06-14 07:02:49.000000000', 'files': ['manifests/profile/base/pacemaker_remote.pp', 'manifests/profile/base/pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/332755c0fd586f0a3085704b3f4bda78ad8a87ad', 'message': 'Only set the stonith property on the pacemaker_master node\n\nIt makes little sense to enforce the stonith property on remote nodes and/or\nall cluster nodes. We can just enforce it once on the pacemaker_master\nnode as it is a cluster-wide property anyway. We can also remove the\ntripleo::fencing -> pacemaker::stonith constraint in the pacemaker\nremote profile now as the fencing stuff happens on step 5 anyway and\nthe property is set at step 1.\n\nWhile this works in general it creates extra CIB changes for nothing and\nslows down the deployment.\n\nChange-Id: Ifef08033043a4cc90a6261e962d2fdecdf275650\nCloses-Bug: #1696336\n'}]",4,471630,332755c0fd586f0a3085704b3f4bda78ad8a87ad,19,5,3,20172,,,0,"Only set the stonith property on the pacemaker_master node

It makes little sense to enforce the stonith property on remote nodes and/or
all cluster nodes. We can just enforce it once on the pacemaker_master
node as it is a cluster-wide property anyway. We can also remove the
tripleo::fencing -> pacemaker::stonith constraint in the pacemaker
remote profile now as the fencing stuff happens on step 5 anyway and
the property is set at step 1.

While this works in general it creates extra CIB changes for nothing and
slows down the deployment.

Change-Id: Ifef08033043a4cc90a6261e962d2fdecdf275650
Closes-Bug: #1696336
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/30/471630/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/pacemaker_remote.pp', 'manifests/profile/base/pacemaker.pp']",2,7b1834b458e5fd3d0b9c9f94ef1c6b9bfd38739d,bug/1696336," if $pacemaker_master { class { '::pacemaker::stonith': disable => !$enable_fencing, tries => $pcs_tries, }"," class { '::pacemaker::stonith': disable => !$enable_fencing, tries => $pcs_tries,",5,8
openstack%2Fpuppet-swift~master~I6c1f953efe5df32160719ea1de2dd718f281cec0,openstack/puppet-swift,master,I6c1f953efe5df32160719ea1de2dd718f281cec0,Enable Swift containersync on Red Hat platform,MERGED,2017-06-16 13:51:02.000000000,2017-06-16 20:39:06.000000000,2017-06-16 20:39:06.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-16 13:51:02.000000000', 'files': ['releasenotes/notes/swift-containersync-service-f188d18796e7affe.yaml', 'manifests/storage/container.pp', 'spec/classes/swift_storage_container_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/dede1d449473f99c4f929e555a3b65b974ebad4b', 'message': 'Enable Swift containersync on Red Hat platform\n\nThe systemd service files have been merged (see [1]), thus we can enable\nthe containersync service now by default without a distribution check.\n\n[1] https://review.rdoproject.org/r/6172/ merged\n\nChange-Id: I6c1f953efe5df32160719ea1de2dd718f281cec0\n'}]",0,474980,dede1d449473f99c4f929e555a3b65b974ebad4b,8,3,1,6968,,,0,"Enable Swift containersync on Red Hat platform

The systemd service files have been merged (see [1]), thus we can enable
the containersync service now by default without a distribution check.

[1] https://review.rdoproject.org/r/6172/ merged

Change-Id: I6c1f953efe5df32160719ea1de2dd718f281cec0
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/80/474980/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/swift-containersync-service-f188d18796e7affe.yaml', 'manifests/storage/container.pp', 'spec/classes/swift_storage_container_spec.rb']",3,dede1d449473f99c4f929e555a3b65b974ebad4b,redhat-containersync, 'swift-container-sync' => 'swift-container-sync',,15,11
openstack%2Fpuppet-tripleo~stable%2Focata~I87c60bd56feac6dedc00a3c458b805aa9b71d9ce,openstack/puppet-tripleo,stable/ocata,I87c60bd56feac6dedc00a3c458b805aa9b71d9ce,Add support for autofencing to Pacemaker Remote.,MERGED,2017-06-13 08:41:26.000000000,2017-06-16 20:36:25.000000000,2017-06-16 20:36:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-13 08:41:26.000000000', 'files': ['manifests/profile/base/pacemaker_remote.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/265cb21748b4dec8dd95430684d08d1addf9e9a0', 'message': 'Add support for autofencing to Pacemaker Remote.\n\nWe now configure stonith devices for Pacemaker Remote nodes.\n\nChange-Id: I87c60bd56feac6dedc00a3c458b805aa9b71d9ce\nDepends-On: Ifb4d19a6b9920b0e340555d6441878c7234eb197\nPartial-Bug: #1686115\n(cherry picked from commit 19d177c182f35a16bf3ddccfcf7fad6bb54c7bb2)\n'}]",1,473735,265cb21748b4dec8dd95430684d08d1addf9e9a0,13,3,1,6449,,,0,"Add support for autofencing to Pacemaker Remote.

We now configure stonith devices for Pacemaker Remote nodes.

Change-Id: I87c60bd56feac6dedc00a3c458b805aa9b71d9ce
Depends-On: Ifb4d19a6b9920b0e340555d6441878c7234eb197
Partial-Bug: #1686115
(cherry picked from commit 19d177c182f35a16bf3ddccfcf7fad6bb54c7bb2)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/35/473735/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/pacemaker_remote.pp'],1,265cb21748b4dec8dd95430684d08d1addf9e9a0,bug/1686115,"# [*pcs_tries*] # (Optional) The number of times pcs commands should be retried. # Defaults to hiera('pcs_tries', 20) # # [*enable_fencing*] # (Optional) Whether or not to manage stonith devices for nodes # Defaults to hiera('enable_fencing', false) # $pcs_tries = hiera('pcs_tries', 20), $enable_fencing = hiera('enable_fencing', false), $enable_fencing_real = str2bool($enable_fencing) and $step >= 5 class { '::pacemaker::stonith': disable => !$enable_fencing_real, tries => $pcs_tries, } if $enable_fencing_real { include ::tripleo::fencing # enable stonith after all Pacemaker resources have been created Pcmk_resource<||> -> Class['tripleo::fencing'] Pcmk_constraint<||> -> Class['tripleo::fencing'] Exec <| tag == 'pacemaker_constraint' |> -> Class['tripleo::fencing'] # enable stonith after all fencing devices have been created Class['tripleo::fencing'] -> Class['pacemaker::stonith'] }",,27,0
openstack%2Fneutron~master~I9e710db6a5103436b0f098e8f73625e3941df492,openstack/neutron,master,I9e710db6a5103436b0f098e8f73625e3941df492,use neutron-lib's callback fixture,MERGED,2017-06-05 21:16:31.000000000,2017-06-16 20:34:38.000000000,2017-06-16 20:34:38.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5367}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8871}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-06-05 21:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/055c67b0fc6c16db5acace002f9ff1ab8bc14f89', 'message': ""use neutron-lib's callback fixture\n\nThere were a few places left in the code (with TODOs) that were still\nmocking out the callback manager. This patch switches them over to\nthe neutron-lib callback fixture.\n\nChange-Id: I9e710db6a5103436b0f098e8f73625e3941df492\n""}, {'number': 2, 'created': '2017-06-14 12:50:30.000000000', 'files': ['neutron/tests/unit/services/trunk/rpc/test_backend.py', 'neutron/tests/unit/plugins/ml2/drivers/agent/test_capabilities.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_capabilities.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/85a44ee3c0840a10b8b33f72a5605e88085750e2', 'message': ""use neutron-lib's callback fixture\n\nThere were a few places left in the code (with TODOs) that were still\nmocking out the callback manager. This patch switches them over to\nthe neutron-lib callback fixture.\n\nChange-Id: I9e710db6a5103436b0f098e8f73625e3941df492\n""}]",0,471135,85a44ee3c0840a10b8b33f72a5605e88085750e2,32,11,2,5367,,,0,"use neutron-lib's callback fixture

There were a few places left in the code (with TODOs) that were still
mocking out the callback manager. This patch switches them over to
the neutron-lib callback fixture.

Change-Id: I9e710db6a5103436b0f098e8f73625e3941df492
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/471135/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/trunk/rpc/test_backend.py', 'neutron/tests/unit/plugins/ml2/drivers/agent/test_capabilities.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_capabilities.py']",3,055c67b0fc6c16db5acace002f9ff1ab8bc14f89,bp/neutron-lib-networking-ovn,"from neutron_lib import fixture def setUp(self): super(CapabilitiesTest, self).setUp() self._mgr = mock.Mock() self.useFixture(fixture.CallbackRegistryFixture( callback_manager=self._mgr)) def test_register(self): self._mgr.subscribe.assert_called_with(driver.init_handler,"," # TODO(boden) replace with neutron_lib fixture once working @mock.patch(""neutron_lib.callbacks.manager.CallbacksManager.subscribe"") def test_register(self, mocked_subscribe): mocked_subscribe.assert_called_with(driver.init_handler,",31,21
openstack%2Ftripleo-heat-templates~master~Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518,openstack/tripleo-heat-templates,master,Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518,Add Ec2Api to container based deployment,MERGED,2017-05-30 17:59:53.000000000,2017-06-16 19:58:19.000000000,2017-06-16 19:58:19.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6924}, {'_account_id': 6926}, {'_account_id': 13039}, {'_account_id': 18575}, {'_account_id': 19173}]","[{'number': 1, 'created': '2017-05-30 17:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d095981899f8be96e10ecacd9f901eb0aaa9ab48', 'message': 'Add Ec2Api to container based deployment\n\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 2, 'created': '2017-05-31 13:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b9e82d5c40980e68b0cf941ab4cc221553098800', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 3, 'created': '2017-05-31 21:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61e56ee346b233e5c220d6355fcdcc11e5386adb', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 4, 'created': '2017-06-06 12:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d6317973a34c060ad467dcacb20bcc0aab0c5e4', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 5, 'created': '2017-06-07 17:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/44d0694ed208013b99d63255a49be696e310dc65', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 6, 'created': '2017-06-09 07:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7586292a7b64121ebfe94cab8d93207cfd37c367', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 7, 'created': '2017-06-13 14:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6db323260a6c30fa57dc525db7b59cfc695ff735', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 8, 'created': '2017-06-13 18:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a0c488a434ea9241f2ecd84718286d686bc7e21a', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 9, 'created': '2017-06-15 13:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6e186a1884e30f307f6357faf6440f3d5cfc4868', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}, {'number': 10, 'created': '2017-06-15 15:40:57.000000000', 'files': ['environments/services-docker/ec2-api.yaml', 'docker/services/ec2-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c4a247d5806aca2990cc9ac8578f264f9b185474', 'message': 'Add Ec2Api to container based deployment\n\nDepends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f\nChange-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518\n'}]",20,469200,c4a247d5806aca2990cc9ac8578f264f9b185474,59,7,10,19173,,,0,"Add Ec2Api to container based deployment

Depends-On: I5dc10ef5cccf6d378c20c68fc4a32d2d3c38233f
Change-Id: Ib96040c2e27ad76b1fa6ecb9468bb9d97b3c4518
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/00/469200/5 && git format-patch -1 --stdout FETCH_HEAD,"['environments/docker.yaml', 'environments/services-docker/ec2-api.yaml', 'docker/services/ec2-api.yaml']",3,d095981899f8be96e10ecacd9f901eb0aaa9ab48,docker-ec2-api,"heat_template_version: pike description: > OpenStack containerized EC2 API service parameters: DockerNamespace: description: namespace default: 'tripleoupstream' type: string DockerEc2ApiImage: description: image default: 'centos-binary-ec2-api:latest' type: string EndpointMap: default: {} description: Mapping of service endpoint -> protocol. Typically set via parameter_defaults in the resource registry. type: json ServiceNetMap: default: {} description: Mapping of service_name -> network name. Typically set via parameter_defaults in the resource registry. This mapping overrides those in ServiceNetMapDefaults. type: json DefaultPasswords: default: {} type: json RoleName: default: '' description: Role name on which the service is applied type: string RoleParameters: default: {} description: Parameters specific to the role type: json EnableInternalTLS: type: boolean default: false conditions: internal_tls_enabled: {equals: [{get_param: EnableInternalTLS}, true]} resources: ContainersCommon: type: ./containers-common.yaml Ec2ApiPuppetBase: type: ../../puppet/services/ec2-api.yaml properties: EndpointMap: {get_param: EndpointMap} ServiceNetMap: {get_param: ServiceNetMap} DefaultPasswords: {get_param: DefaultPasswords} RoleName: {get_param: RoleName} RoleParameters: {get_param: RoleParameters} outputs: role_data: description: Role data for the EC2 API role. value: service_name: {get_attr: [Ec2ApiPuppetBase, role_data, service_name]} config_settings: map_merge: - get_attr: [Ec2ApiPuppetBase, role_data, config_settings] - apache::default_vhost: false step_config: &step_config get_attr: [Ec2ApiPuppetBase, role_data, step_config] service_config_settings: {get_attr: [Ec2ApiPuppetBase, role_data, service_config_settings]} # BEGIN DOCKER SETTINGS puppet_config: config_volume: ec2-api puppet_tags: ec2_api_paste_ini,ec2_api_config step_config: *step_config config_image: &ec2_api_image list_join: - '/' - [ {get_param: DockerNamespace}, {get_param: DockerEc2ApiImage} ] kolla_config: /var/lib/kolla/config_files/ec2-api.json: command: /usr/sbin/httpd -DFOREGROUND permissions: - path: /var/log/ec2-api owner: ec2api:ec2api recurse: true docker_config: # db sync runs before permissions set by kolla_config step_3: ec2_api_init_log: start_order: 0 image: *ec2_api_image user: root volumes: - /var/log/containers/ec2-api:/var/log/ec2-api command: ['/bin/bash', '-c', 'mkdir -p /var/log/httpd; chown -R ec2api:ec2api /var/log/ec2-api'] ec2_api_db_sync: start_order: 1 image: *ec2_api_image net: host detach: false privileged: false user: root volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - - /var/lib/config-data/ec2-api/etc/ec2api/:/etc/ec2api/:ro - /var/log/containers/ec2-api:/var/log/ec2-api command: ""/usr/bin/bootstrap_host_exec ec2_api su ec2api -s /bin/bash -c '/usr/bin/ec2-api-manage db_sync'"" step_4: ec2_api: image: *ec2_api_image net: host privileged: false restart: always volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - - /var/lib/kolla/config_files/ec2-api.json:/var/lib/kolla/config_files/config.json:ro - /var/lib/config-data/ec2-api/etc/ec2api/:/etc/ec2api/:ro - /var/log/containers/ec2-api:/var/log/ec2-api - if: - internal_tls_enabled - /etc/pki/tls/certs/httpd:/etc/pki/tls/certs/httpd:ro - '' - if: - internal_tls_enabled - /etc/pki/tls/private/httpd:/etc/pki/tls/private/httpd:ro - '' environment: - KOLLA_CONFIG_STRATEGY=COPY_ALWAYS host_prep_tasks: - name: create persistent logs directory file: path: /var/log/containers/ec2-api state: directory upgrade_tasks: - name: Stop and disable httpd service tags: step2 service: name=httpd state=stopped enabled=no metadata_settings: get_attr: [Ec2ApiPuppetBase, role_data, metadata_settings] ",,149,0
openstack%2Fnetworking-generic-switch~master~Ib28a4c803fca06bab16c233d98434dc4b3f97a02,openstack/networking-generic-switch,master,Ib28a4c803fca06bab16c233d98434dc4b3f97a02,Add tempest test for DLM functionality,MERGED,2017-04-07 14:44:56.000000000,2017-06-16 19:57:46.000000000,2017-06-16 19:57:46.000000000,"[{'_account_id': 3}, {'_account_id': 9542}, {'_account_id': 12356}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-04-07 14:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/4086565f8c52697e9b286808318b60c831dad483', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 2, 'created': '2017-04-10 15:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/e8ab5838bdbbf14106d018bd193c3c0e8b919b54', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 3, 'created': '2017-04-11 07:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/78644d53a1f9d6de59c0f3bded951e71e0ea032f', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 4, 'created': '2017-04-12 13:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/4a24a50387b71b08744e59f09af562e0b13041fc', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 5, 'created': '2017-04-13 08:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/2410ff81e788c959879d7ee14255d25fd71aaf02', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 6, 'created': '2017-04-13 17:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/de8937f78b156bb933632dc728f2cd181d62b680', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 7, 'created': '2017-04-14 10:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/f7cdc7ae602b69639af8b58af0c362fd41ab9a7f', 'message': 'Simplest tempest test for DLM functionality\n\ntest setup:\n- force max 2 simulteneous logins for the user ngs uses for SSH\n- run test_ngs_swarm_ops.py test module with concurrency 4\n\nWithout DLM it most certainly fail at least one test in 4, most probably\n2.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\n'}, {'number': 8, 'created': '2017-04-19 16:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/ab1bd0c00037be045793bfc06bc43f123725d250', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}, {'number': 9, 'created': '2017-04-20 15:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/1dd1fbbf52084ee6ee6c443dd5a55841a8621ff1', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}, {'number': 10, 'created': '2017-04-21 11:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/1b76c7b46f1d998ff1f78bdf80f3cbf19027f203', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}, {'number': 11, 'created': '2017-05-19 12:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/a22534d64cf64558fe025b285b6739b57471c3be', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}, {'number': 12, 'created': '2017-06-08 15:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/9e2d0ad2f49599f349888bef4b48dd9370b71cb5', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}, {'number': 13, 'created': '2017-06-16 09:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/01c0eeba27e4672cf3778f9e1caf49a98814aa3d', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}, {'number': 14, 'created': '2017-06-16 11:16:57.000000000', 'files': ['test-requirements.txt', 'tempest_plugin/tests/scenario/test_ngs_basic_ops.py', 'devstack/plugin.sh', 'tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/c9b607724f5632c7b9336c89ed4645c69a7833ac', 'message': 'Add tempest test for DLM functionality\n\nIf configured in the devstack plugin, will:\n- setup 2x extra ports as max allowed session for n-g-s user\n- configure tempest plugin to use that number of extra ports to\n  concurrently run the new test below\n- execute a test that cuncurrently run the ngs basic ops test\n  with the same 2x max sessions\n\nTest is using futurist.ThreadPoll in a single test method to not depend\non concurrency of the test runner itself.\n\nIf ngs.port_dlm_concurrency is not set in tempest.conf,\nthis new test is skipped.\n\nChange-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02\nRelated-Bug: #1674324\n'}]",7,454744,c9b607724f5632c7b9336c89ed4645c69a7833ac,39,4,14,9542,,,0,"Add tempest test for DLM functionality

If configured in the devstack plugin, will:
- setup 2x extra ports as max allowed session for n-g-s user
- configure tempest plugin to use that number of extra ports to
  concurrently run the new test below
- execute a test that cuncurrently run the ngs basic ops test
  with the same 2x max sessions

Test is using futurist.ThreadPoll in a single test method to not depend
on concurrency of the test runner itself.

If ngs.port_dlm_concurrency is not set in tempest.conf,
this new test is skipped.

Change-Id: Ib28a4c803fca06bab16c233d98434dc4b3f97a02
Related-Bug: #1674324
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/44/454744/7 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_plugin/tests/scenario/test_ngs_swarm_ops.py', 'tempest_plugin/tests/scenario/test_ngs_basic_ops.py']",2,4086565f8c52697e9b286808318b60c831dad483,bug/1674324,"class NGSBasicOpsBase(net_base.BaseAdminNetworkTest): super(NGSBasicOpsBase, cls).skip_checks() def _test_ngs_basic_ops(self, llc=None): class NGSBasicOps(NGSBasicOpsBase): @decorators.idempotent_id('59cb81a5-3fd5-4ad3-8c4a-c0b27435cb9c') @test.services('network') def test_ngs_basic_ops(self): self._test_ngs_basic_ops() @decorators.idempotent_id('282a513d-cc01-486c-aa12-1c45f7b6e5a8') @test.services('network') def test_ngs_basic_ops_switch_id(self): llc = [{'switch_id': self.get_local_port_mac(CONF.ngs.bridge_name), 'port_id': CONF.ngs.port_name}] self._test_ngs_basic_ops(llc=llc)","class NGSBasicOps(net_base.BaseAdminNetworkTest): super(NGSBasicOps, cls).skip_checks() @decorators.idempotent_id('59cb81a5-3fd5-4ad3-8c4a-c0b27435cb9c') @test.services('network') def test_ngs_basic_ops(self): port = self.create_neutron_port() net_tag = self.admin_networks_client.list_networks( name=CONF.ngs.network_name )['networks'][0]['provider:segmentation_id'] ovs_tag = self.ovs_get_tag() self.assertEqual(net_tag, ovs_tag) # Ensure that tag is removed when port is deleted self.admin_ports_client.delete_port(port['id']) ovs_tag = self.ovs_get_tag() self.assertIsNone(ovs_tag) @decorators.idempotent_id('282a513d-cc01-486c-aa12-1c45f7b6e5a8') @test.services('network') def test_ngs_basic_ops_switch_id(self): llc = [{'switch_id': self.get_local_port_mac(CONF.ngs.bridge_name), 'port_id': CONF.ngs.port_name}]",66,22
openstack%2Fpuppet-tripleo~master~I1e6672bb0219c1cf56ab21dd911c6f33e2436cc3,openstack/puppet-tripleo,master,I1e6672bb0219c1cf56ab21dd911c6f33e2436cc3,Fix redis when hostname has capital letters,MERGED,2017-06-15 19:18:23.000000000,2017-06-16 19:54:49.000000000,2017-06-16 19:54:49.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-06-15 19:18:23.000000000', 'files': ['manifests/profile/base/database/redis.pp', 'spec/fixtures/hieradata/default.yaml', 'spec/classes/tripleo_profile_base_database_redis_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/62dffeb9dad1394e27de4f8c709f6534ecab8ad3', 'message': 'Fix redis when hostname has capital letters\n\nThe bootstrap_nodeid comparison should be case insensitive.\n\nChange-Id: I1e6672bb0219c1cf56ab21dd911c6f33e2436cc3\nCloses-Bug: #1698190\n'}]",2,474737,62dffeb9dad1394e27de4f8c709f6534ecab8ad3,10,4,1,14985,,,0,"Fix redis when hostname has capital letters

The bootstrap_nodeid comparison should be case insensitive.

Change-Id: I1e6672bb0219c1cf56ab21dd911c6f33e2436cc3
Closes-Bug: #1698190
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/37/474737/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/base/database/redis.pp', 'spec/fixtures/hieradata/default.yaml', 'spec/classes/tripleo_profile_base_database_redis_spec.rb']",3,62dffeb9dad1394e27de4f8c709f6534ecab8ad3,bug/1698190,"# # Copyright (C) 2017 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # require 'spec_helper' describe 'tripleo::profile::base::database::redis' do shared_examples_for 'tripleo::profile::base::database::redis' do context 'with step less than 2' do let(:params) { { :step => 1, :bootstrap_nodeid => 'node.example.com', :redis_node_ips => [] } } it 'should do nothing' do is_expected.to contain_class('tripleo::profile::base::database::redis') is_expected.to_not contain_class('redis') is_expected.to_not contain_class('redis::sentinel') is_expected.to_not contain_class('tripleo::redis_notification') end end context 'with step 2 on bootstrap node' do let(:params) { { :step => 2, :bootstrap_nodeid => 'node.example.com', :redis_node_ips => ['10.0.0.1'] } } it 'should configure redis' do is_expected.to contain_class('tripleo::profile::base::database::redis') is_expected.to contain_class('redis') is_expected.to_not contain_class('redis::sentinel') is_expected.to_not contain_class('tripleo::redis_notification') end end context 'with step 2 on bootstrap node with capital letters' do let(:params) { { :step => 2, :bootstrap_nodeid => 'NODE.example.com', :redis_node_ips => ['10.0.0.1'] } } it 'should configure redis' do is_expected.to contain_class('tripleo::profile::base::database::redis') is_expected.to contain_class('redis').with(:slaveof => nil) end end context 'with step 2 not on bootstrap node' do let(:params) { { :step => 2, :bootstrap_nodeid => 'othernode.example.com', :redis_node_ips => ['10.0.0.1'] } } it 'should configure redis' do is_expected.to contain_class('tripleo::profile::base::database::redis') is_expected.to contain_class('redis').with(:slaveof => ""#{params[:bootstrap_nodeid]} 6379"") is_expected.to_not contain_class('redis::sentinel') is_expected.to_not contain_class('tripleo::redis_notification') end end context 'with step 2 with multiple nodes' do let(:params) { { :step => 2, :bootstrap_nodeid => 'othernode.example.com', :redis_node_ips => ['10.0.0.1', '10.0.0.2'] } } it 'should configure redis' do is_expected.to contain_class('tripleo::profile::base::database::redis') is_expected.to contain_class('redis').with(:slaveof => ""#{params[:bootstrap_nodeid]} 6379"") is_expected.to contain_class('redis::sentinel') is_expected.to contain_class('tripleo::redis_notification') end end end on_supported_os.each do |os, facts| context ""on #{os}"" do let(:facts) do facts.merge({ :hostname => 'node.example.com' }) end it_behaves_like 'tripleo::profile::base::database::redis' end end end ",,108,1
openstack%2Fnetworking-generic-switch~master~I53971e613c3804de255dda5fc0fb164f9bc335ff,openstack/networking-generic-switch,master,I53971e613c3804de255dda5fc0fb164f9bc335ff,Setup DLM in devstack plugin,MERGED,2017-04-19 16:22:15.000000000,2017-06-16 19:44:18.000000000,2017-06-16 19:44:18.000000000,"[{'_account_id': 3}, {'_account_id': 9542}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-04-19 16:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/354f6f3ea27e50caa0065cdddabaf852b73bb9cd', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via DB driver (mysql or postgresql)\n  using neutron's DB connection settings, this will be enough for\n  running as part of DevStack.\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 2, 'created': '2017-04-20 09:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/a2e75203a853184653986d0634756b1e9f7c1bf7', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via DB driver (mysql or postgresql)\n  using neutron's DB connection settings, this will be enough for\n  running as part of DevStack.\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 3, 'created': '2017-04-20 13:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/2684f39749fa07dd54bb0fbbc5fe76c02bb9d9c4', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via DB driver (mysql or postgresql)\n  using neutron's DB connection settings, this will be enough for\n  running as part of DevStack.\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 4, 'created': '2017-04-20 15:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/61ddf4ba7871b96b0cbabae6148ece9a393c4bde', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via DB driver (mysql or postgresql)\n  using neutron's DB connection settings, this will be enough for\n  running as part of DevStack.\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 5, 'created': '2017-04-21 11:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/9ed2b14528d1ca098ce280ee42247c611cfcbe90', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via DB driver (mysql or postgresql)\n  using neutron's DB connection settings, this will be enough for\n  running as part of DevStack.\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 6, 'created': '2017-05-19 12:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/82ac0dd2d053a5f5e0253b477e6e80eb4fd921a6', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via DB driver (mysql or postgresql)\n  using neutron's DB connection settings, this will be enough for\n  running as part of DevStack.\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 7, 'created': '2017-06-08 15:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/b4ee0a74d826a008ddf9ebbad459a442bd4e3cdc', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via etcd3 that is now generally\n  installed in DevStack by default (and fail if etcd3 is not enabled)\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}, {'number': 8, 'created': '2017-06-16 09:47:45.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/d9ec0c5bfdd8cb0c360a9b68f7bb8bf2223149b1', 'message': ""Setup DLM in devstack plugin\n\nThis patch allows to set up n-g-s under DevStack to use and enforce DLM\nfor netmiko connections.\n\nA new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added\n(default 0).\n\nIf it is non-zero:\n\n- a new system user 'ngs_ovs_manager' with password-less sudo permissions\n  and appropriate authorized SSH keys will be created by devstack plugin,\n  and maximum number of sessions for this user will be hard-limited to\n  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/\n  to simulate a switch with limited number of allowed SSH connections;\n- n-g-s will be configured to use this user for SSH connections, and\n  netmiko OVS switches will be configured with ngs_netmiko_max_sessions\n  set accordingly.\n- n-g-s will be configured to use DLM via etcd3 that is now generally\n  installed in DevStack by default (and fail if etcd3 is not enabled)\n\nChange-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff\nRelated-Bug: #1674324\n""}]",2,458154,d9ec0c5bfdd8cb0c360a9b68f7bb8bf2223149b1,26,3,8,9542,,,0,"Setup DLM in devstack plugin

This patch allows to set up n-g-s under DevStack to use and enforce DLM
for netmiko connections.

A new devstack variable GENERIC_SWITCH_USER_MAX_SESSIONS is added
(default 0).

If it is non-zero:

- a new system user 'ngs_ovs_manager' with password-less sudo permissions
  and appropriate authorized SSH keys will be created by devstack plugin,
  and maximum number of sessions for this user will be hard-limited to
  the value of GENERIC_SWITCH_USER_MAX_SESSIONS in /etc/security/limits.d/
  to simulate a switch with limited number of allowed SSH connections;
- n-g-s will be configured to use this user for SSH connections, and
  netmiko OVS switches will be configured with ngs_netmiko_max_sessions
  set accordingly.
- n-g-s will be configured to use DLM via etcd3 that is now generally
  installed in DevStack by default (and fail if etcd3 is not enabled)

Change-Id: I53971e613c3804de255dda5fc0fb164f9bc335ff
Related-Bug: #1674324
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/54/458154/8 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,354f6f3ea27e50caa0065cdddabaf852b73bb9cd,bug/1674324,"# NOTE(pas-ha) NEVER SET THIS TO ANY EXISTING USER! # you might get locked out of SSH when limitinig SSH sessions is enabled for this user, # AND THIS USER WILL BE DELETED TOGETHER WITH ITS HOME DIR ON UNSTACK/CLEANUP!!! # this is why it is left unconfigurable GENERIC_SWITCH_USER=""ngs_ovs_manager"" GENERIC_SWITCH_USER_HOME=""$GENERIC_SWITCH_DATA_DIR/$GENERIC_SWITCH_USER"" GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE=""$GENERIC_SWITCH_USER_HOME/.ssh/authorized_keys"" # 0 means unlimited GENERIC_SWITCH_USER_MAX_SESSIONS=${GENERIC_SWITCH_USER_MAX_SESSIONS:-0}# NOTE(pas-ha) almost verbatim copy of devstack/tools/create-stack-user.sh # adapted to be started w/o sudo from the start function create_ovs_manager_user { # Give the non-root user the ability to run as **root** via ``sudo`` is_package_installed sudo || install_package sudo if ! getent group $GENERIC_SWITCH_USER >/dev/null; then echo ""Creating a group called $GENERIC_SWITCH_USER"" sudo groupadd $GENERIC_SWITCH_USER fi if ! getent passwd $GENERIC_SWITCH_USER >/dev/null; then echo ""Creating a user called $GENERIC_SWITCH_USER"" mkdir -p $GENERIC_SWITCH_USER_HOME sudo useradd -g $GENERIC_SWITCH_USER -s /bin/bash -d $GENERIC_SWITCH_USER_HOME -m $GENERIC_SWITCH_USER fi echo ""Giving $GENERIC_SWITCH_USER user passwordless sudo privileges"" # UEC images ``/etc/sudoers`` does not have a ``#includedir``, add one sudo grep -q ""^#includedir.*/etc/sudoers.d"" /etc/sudoers || echo ""#includedir /etc/sudoers.d"" | sudo tee -a /etc/sudoers ( umask 226 && echo ""$GENERIC_SWITCH_USER ALL=(ALL) NOPASSWD:ALL"" | sudo tee /etc/sudoers.d/99_ngs_ovs_manager ) } function configure_for_dlm { local tooz_backend local neutron_db local db_address # limit number of ssh connections for generic-switch user ( umask 226 && echo ""$GENERIC_SWITCH_USER hard maxlogins $GENERIC_SWITCH_USER_MAX_SESSIONS"" | sudo tee /etc/security/limits.d/ngs_ovs_manager.conf ) # set lock acquire timeout populate_ml2_config $GENERIC_SWITCH_INI_FILE ngs_coordination acquire_timeout=120 # parse neutron db url neutron_db=$(database_connection_url neutron) db_address=$(echo $neutron_db | cut -d: -f2-) if [[ ""$neutron_db"" =~ ""mysql"" ]]; then tooz_backend=""mysql:$db_address"" elif [[ ""$neutron_db"" =~ ""postgresql"" ]]; then tooz_backend=""postgresql:$db_address"" else die $LINENO ""devstack plugin for networking-generic-switch only supports setting DLM over MySQL or PostreSQL, neither found as DB backend for Neutron"" fi # set dlm backend url populate_ml2_config $GENERIC_SWITCH_INI_FILE ngs_coordination backend_url=$tooz_backend } function configure_generic_switch_ssh_keypair { if [[ ! -d $GENERIC_SWITCH_USER_HOME/.ssh ]]; then mkdir -p $GENERIC_SWITCH_USER_HOME/.ssh chmod 700 $GENERIC_SWITCH_USER_HOME/.ssh sudo echo """" >> $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE cat $GENERIC_SWITCH_KEY_FILE.pub | sudo tee -a $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE sudo sort -u -o $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE sudo chown $GENERIC_SWITCH_USER:$GENERIC_SWITCH_USER $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE sudo chown -R $GENERIC_SWITCH_USER:$GENERIC_SWITCH_USER $GENERIC_SWITCH_USER_HOME } function configure_generic_switch_user { create_ovs_manager_user configure_generic_switch_ssh_keypair if [[ ""$GENERIC_SWITCH_USER_MAX_SESSIONS"" -gt 0 ]]; then configure_for_dlm fi configure_generic_switch_user add_generic_switch_to_ml2_config $switch $GENERIC_SWITCH_KEY_FILE $GENERIC_SWITCH_USER localhost netmiko_ovs_linux ""$GENERIC_SWITCH_PORT"" ""$bridge_mac"" add_generic_switch_to_ml2_config $section $GENERIC_SWITCH_KEY_FILE $GENERIC_SWITCH_USER $node netmiko_ovs_linux ""$GENERIC_SWITCH_PORT"" if [[ ""$device_type"" =~ ""netmiko"" && ""$GENERIC_SWITCH_USER_MAX_SESSIONS"" -gt 0 ]]; then populate_ml2_config $GENERIC_SWITCH_INI_FILE $switch_name ngs_netmiko_max_sessions=$GENERIC_SWITCH_USER_MAX_SESSIONS fi sudo grep -v ""$key"" $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE > temp && sudo mv -f temp $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE sudo chown $GENERIC_SWITCH_USER:$GENERIC_SWITCH_USER $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE sudo chmod 0600 $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE # remove generic switch user, its permissions and limits sudo rm -f /etc/sudoers.d/99_ngs_ovs_manager sudo rm -f /etc/security/limits.d/ngs_ovs_manager.conf sudo deluser $GENERIC_SWITCH_USER --remove-home --quiet sudo delgroup $GENERIC_SWITCH_USER --quiet sudo rm -rf $GENERIC_SWITCH_DATA_DIR","GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE=""$HOME/.ssh/authorized_keys""function configure_generic_switch_ssh_keypair { if [[ ! -d $HOME/.ssh ]]; then mkdir -p $HOME/.ssh chmod 700 $HOME/.ssh echo """" >> $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE cat $GENERIC_SWITCH_KEY_FILE.pub | tee -a $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE sort -u -o $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE configure_generic_switch_ssh_keypair add_generic_switch_to_ml2_config $switch $GENERIC_SWITCH_KEY_FILE $STACK_USER localhost netmiko_ovs_linux ""$GENERIC_SWITCH_SSH_PORT"" ""$bridge_mac"" add_generic_switch_to_ml2_config $section $GENERIC_SWITCH_KEY_FILE $STACK_USER $node netmiko_ovs_linux ""$GENERIC_SWITCH_SSH_PORT"" grep -v ""$key"" $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE > temp && mv temp $GENERIC_SWITCH_KEY_AUTHORIZED_KEYS_FILE chmod 0600 $IRONIC_AUTHORIZED_KEYS_FILE rm -rf $GENERIC_SWITCH_DATA_DIR",92,13
openstack%2Fnetworking-generic-switch~master~I95b486cfabbef61566a6cd70a6fb89ef9a960afb,openstack/networking-generic-switch,master,I95b486cfabbef61566a6cd70a6fb89ef9a960afb,Add DLM with tooz for netmiko devices,MERGED,2017-04-03 21:22:03.000000000,2017-06-16 19:44:06.000000000,2017-06-16 19:44:06.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 9542}, {'_account_id': 12356}, {'_account_id': 14525}, {'_account_id': 14826}]","[{'number': 1, 'created': '2017-04-03 21:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/5063f9da06a61f05ee914436afa800af636a025c', 'message': 'WiP PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured.\n\nBefore execution of each command on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`max_sessions` config option in the switch config section (default 1).\nThe set of names to grab a lock by is looked over and over infinitely\nuntil a lock is grabbed.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 2, 'created': '2017-04-04 06:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/6b4cc0c99b2498dcff450a587ca8d2e52414c01d', 'message': 'WiP PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured.\n\nBefore execution of each command on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`max_sessions` config option in the switch config section (default 1).\nThe set of names to grab a lock by is looked over and over infinitely\nuntil a lock is grabbed.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 3, 'created': '2017-04-04 07:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/fefbd3feebeeff107b43c82a459f54bd550a3233', 'message': 'WiP PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured.\n\nBefore execution of each command on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`max_sessions` config option in the switch config section (default 1).\nThe set of names to grab a lock by is looked over and over infinitely\nuntil a lock is grabbed.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 4, 'created': '2017-04-06 09:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/fd9974dbe6343584733657f4b609e8f833eff38e', 'message': 'WiP PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured.\n\nBefore execution of each command on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`max_sessions` config option in the switch config section (default 1).\nThe set of names to grab a lock by is looked over and over infinitely\nuntil a lock is grabbed.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 5, 'created': '2017-04-06 14:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/9dc1865336fe750755a0e43dc2a8b9d354ba9c66', 'message': 'PoC Add DLM with tooz for netmiko devices                                                                                                                            [3/254]\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 6, 'created': '2017-04-06 14:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/e1fe0453ef700c25056356e3e8c1cfe0081f494a', 'message': 'PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 7, 'created': '2017-04-06 14:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/43d669ffaa023855c95e0209a894d1445896459f', 'message': 'PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 8, 'created': '2017-04-06 14:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/9c12ba3b183558626bf2861aaeecb3bc292c6b30', 'message': 'PoC Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 9, 'created': '2017-04-07 14:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/664cae37f4bc9e9c4f1d5b8afe1a51d8b0c1fff0', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 10, 'created': '2017-04-10 15:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/c47117ac44908450dd19bbf7ed5244e6c3e3ec94', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 11, 'created': '2017-04-11 07:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/6cc262a8f72bb4121a481774e4e9dc70425c0e1d', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 12, 'created': '2017-04-12 13:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/fdd76ec4237a5abd7f1781123ce75ed8915f9fb3', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 13, 'created': '2017-04-13 08:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/f6a6d91850b90083b18138eb24d145c97bcf7ee0', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 14, 'created': '2017-04-13 17:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/50ac9ef401f3ca16ea7ec7657ffb8f77a11043a2', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 15, 'created': '2017-04-14 10:00:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/e44b1c3f27bd3b4c5f3bfbe6f0a6e3e9e965d472', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 16, 'created': '2017-04-19 16:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/53ef718015f65a36b46bb8a37178aef3bef2bb55', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 17, 'created': '2017-04-20 15:24:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/4d82f6f21c796ceff25547e4d94379d131bab26e', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 18, 'created': '2017-04-21 11:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/98effe2eb236fcf8c99483a1a3e0f7a16a97061d', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to netmiko-based switches.\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only applicable to Netmiko-based switch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_netmiko_max_sessions` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in `[ngs_coordination]acquire_timeout` is reached or\nsome lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 19, 'created': '2017-05-19 12:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/1c78e4e8a21bed5fe37009f8f3eae85b0ad34ed7', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to networking-generic-switch\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only currently handled by Netmiko-based\nswitch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_max_connections` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in global config option `[ngs_coordination]acquire_timeout`\nis reached or some lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 20, 'created': '2017-06-08 15:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/ac455b17e40ccffbf65031478b168535244f0f67', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to networking-generic-switch\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only currently handled by Netmiko-based\nswitch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_max_connections` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in global config option `[ngs_coordination]acquire_timeout`\nis reached or some lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}, {'number': 21, 'created': '2017-06-16 09:47:45.000000000', 'files': ['networking_generic_switch/locking.py', 'requirements.txt', 'networking_generic_switch/tests/unit/test_locking.py', 'networking_generic_switch/tests/unit/netmiko/test_netmiko_base.py', 'networking_generic_switch/config.py', 'networking_generic_switch/devices/netmiko_devices/__init__.py', 'networking_generic_switch/devices/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/55e7ee5d22c07a1fb4ece739b958edc40f237677', 'message': 'Add DLM with tooz for netmiko devices\n\none of biggest issues with Netmiko-based devices and n-g-s is a limited\nmaximum number of concurrent SSH connections a given switch usually allows.\nThis severely limits scalability of n-g-s when controlling such\nswitches, although they are quite often used as ToR switches in real\nlife scenarios.\n\nThis patch attempts to introduce DLM to networking-generic-switch\n\nDLM is only attempted when `[ngs_coordination]backend_url` is configured\n(default is None) and is only currently handled by Netmiko-based\nswitch drivers.\n\nBefore execution of each command(-set) on the switch, n-g-s will attempt to\ngrab a lock from a set of names, with the set size corresponding to the\n`ngs_max_connections` config option in the particular switch\nconfig section (defaults to 1).\nThe set of names to grab a lock by is looked over and over until a\ntimeout specified in global config option `[ngs_coordination]acquire_timeout`\nis reached or some lock is grabbed.\nThe lock is released after the command is executed, freeing it up for\nanother action to grab.\n\nDepending on the tooz backend chosen, this should allow to globally\nlimit the number of concurrent SSH sessions to a given switch across all\nneutron-service hosts and all threads that execute n-g-s methods.\n\nChange-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb\nCloses-Bug: #1674324\n'}]",75,452959,55e7ee5d22c07a1fb4ece739b958edc40f237677,84,7,21,9542,,,0,"Add DLM with tooz for netmiko devices

one of biggest issues with Netmiko-based devices and n-g-s is a limited
maximum number of concurrent SSH connections a given switch usually allows.
This severely limits scalability of n-g-s when controlling such
switches, although they are quite often used as ToR switches in real
life scenarios.

This patch attempts to introduce DLM to networking-generic-switch

DLM is only attempted when `[ngs_coordination]backend_url` is configured
(default is None) and is only currently handled by Netmiko-based
switch drivers.

Before execution of each command(-set) on the switch, n-g-s will attempt to
grab a lock from a set of names, with the set size corresponding to the
`ngs_max_connections` config option in the particular switch
config section (defaults to 1).
The set of names to grab a lock by is looked over and over until a
timeout specified in global config option `[ngs_coordination]acquire_timeout`
is reached or some lock is grabbed.
The lock is released after the command is executed, freeing it up for
another action to grab.

Depending on the tooz backend chosen, this should allow to globally
limit the number of concurrent SSH sessions to a given switch across all
neutron-service hosts and all threads that execute n-g-s methods.

Change-Id: I95b486cfabbef61566a6cd70a6fb89ef9a960afb
Closes-Bug: #1674324
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/59/452959/21 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'networking_generic_switch/config.py', 'networking_generic_switch/devices/netmiko_devices/__init__.py']",3,5063f9da06a61f05ee914436afa800af636a025c,bug/1674324,"import itertoolsfrom oslo_config import cfgfrom tooz import coordinationCONF = cfg.CONF DLM_COORDINATOR = None def get_coordinator(): global DLM_COORDINATOR if not DLM_COORDINATOR and CONF.coordination.backend_url: DLM_COORDINATOR = coordination.get_coordinator( CONF.coordination.backend_url, ('ngs-' + CONF.host).encode('ascii')) DLM_COORDINATOR.start() return DLM_COORDINATOR def _reset_coordinator(): global DLM_COORDINATOR if DLM_COORDINATOR: DLM_COORDINATOR.stop() DLM_COORDINATOR = None class NetmikoLock(object): """"""Netmiko-specific tooz lock wrapper If coordination backend is configured, it will attempt to grab any lock from a predefined set of names, with the set length as configured value. """""" def __init__(self, cycle_length=1, prefix='ngs-'): self.coordinator = get_coordinator() self.lock_names = [""{}{}"".format(prefix, i) for i in range(cycle_length)] def __enter__(self): if not self.coordinator: return self locked = False # NOTE(pas-ha) the number of allowed connections is usually small (~10) # so memory penalty should be negligible # TODO(pas-ha) this will cycle infinitely until a lock is grabbed, # need to introduce some global timeout for that for name in itertools.cycle(self.lock_names): lock = self.coordinator.get_lock(name) try: locked = lock.acquire(blocking=False) except coordination.LockAcquireFailed: locked = False if not locked: LOG.debug(""Failed to acquire lock %s"" % name) else: self.lock = lock break return self.lock def __exit__(self): if self.coordinator: self.lock.release() max_sessions = self.cofig.pop('max_sessions', 1) self.lock = NetmikoLock( cycle_length=max_sessions, prefix=self.config.get('host', '') or self.config.get('ip', '')) with self.lock: try: net_connect = netmiko.ConnectHandler(**self.config) net_connect.enable() output = net_connect.send_config_set(config_commands=cmd_set) except Exception as e: raise exc.GenericSwitchNetmikoConnectError(config=self.config, error=e)"," try: net_connect = netmiko.ConnectHandler(**self.config) net_connect.enable() output = net_connect.send_config_set(config_commands=cmd_set) except Exception as e: raise exc.GenericSwitchNetmikoConnectError(config=self.config, error=e)",86,9
openstack%2Fironic~master~I0e22312e8cebb37b8f025da2baeca8eb635f35b7,openstack/ironic,master,I0e22312e8cebb37b8f025da2baeca8eb635f35b7,Wire in storage interface attach/detach operations,MERGED,2016-12-02 18:45:56.000000000,2017-06-16 19:29:04.000000000,2017-06-16 10:19:16.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10453}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 11878}, {'_account_id': 11929}, {'_account_id': 12356}, {'_account_id': 13295}, {'_account_id': 13689}, {'_account_id': 14525}, {'_account_id': 14614}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 19686}, {'_account_id': 20035}, {'_account_id': 20146}, {'_account_id': 22700}, {'_account_id': 23883}]","[{'number': 1, 'created': '2016-12-02 18:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1f04a5b1a7c2c7bcf974c670aac67f004995503a', 'message': 'Wire in storage interface attach/detach operations\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 2, 'created': '2016-12-08 21:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6dbebf4a73439b3eae898c4fbd6c6abd75c06ad2', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_interal_info\nis now  populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 3, 'created': '2016-12-16 22:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/15a5ea6d19f465a722779eb322f03887daf3fbc3', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_interal_info\nis now  populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 4, 'created': '2016-12-19 14:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/579bd63043eed326296ffab0dabbda4288993c75', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_interal_info\nis now  populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 5, 'created': '2016-12-21 18:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d97599a2e5d5f8266b31239a55602bc29facf913', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_interal_info\nis now  populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 6, 'created': '2016-12-29 14:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d2ae22c448bc4d23b1605fbb55237465fd60da00', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_interal_info\nis now  populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 7, 'created': '2017-01-11 22:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/54d467c97ac69ca8c2b4177cf36e1131b995fd62', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 8, 'created': '2017-01-12 06:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b155e86b1297b1bcefdc95fc3d23ebf4cfdac505', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 9, 'created': '2017-01-12 17:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f5fc10b6fdecc1983e00d3ac91f2dbee1ad786c7', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 10, 'created': '2017-01-13 18:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7ea111ae492a49ed92f392315db7759110b2ffd2', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 11, 'created': '2017-01-22 14:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/01a3307bd401a5dafa46472f713fb695e955eaa3', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 12, 'created': '2017-02-13 23:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/901cda104cba523a757c4901bbec5426b024305d', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 13, 'created': '2017-02-14 21:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/811b1ac07880c4704c9c4031b235e6d9bd9489b3', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 14, 'created': '2017-02-15 18:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9d34d7bf90493ce1c6f2df8944761b5560dff4ed', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 15, 'created': '2017-02-17 13:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9b5a9a7282062d7df2a18dbc01995b8e08b9e78b', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 16, 'created': '2017-03-14 04:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2e19c2e0d48eaa0aac7cbb5f168eb8e631bbd9fc', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 17, 'created': '2017-03-14 05:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9761e2ffb1570d17397bef8c07d90213d5935e9', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 18, 'created': '2017-03-16 22:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/94fae07e49b096856490957d7d87177561c757ec', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 19, 'created': '2017-04-01 00:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/43ed81fb8e8781d1cc5e76d106d3d2f9e2ad40e7', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 20, 'created': '2017-04-03 17:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8041f65721e7ceb5ff72bf04ea779978710d10d6', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 21, 'created': '2017-04-10 22:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/840a1a9aaadf3999c063b6652cdf4e9b46bda6af', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 22, 'created': '2017-05-04 11:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b4044af68687795cf3d851909864a427a9f85b92', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 23, 'created': '2017-05-18 16:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/86843f74a86e883964c210cc7101b28f99d3dcfe', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 24, 'created': '2017-05-22 19:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6a3a07b12c10cd31dcc8a3118103adbb4e233fbc', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 25, 'created': '2017-05-23 20:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b9d27ffcf5d69a51872d32c950d84fc3ce40f919', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nThe cinder interface is also added to the enabled storage\ninterfaces as this patch makes attach/detach usable by\nstorage interfaces.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 26, 'created': '2017-05-31 00:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c07654ab94ac217cc34841dfc63c19c9f8d9305a', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 27, 'created': '2017-05-31 00:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/028c7aa674809dc69f3dc147079fbae0f74593cd', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 28, 'created': '2017-05-31 04:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/620b84b174daa8e7ca363c57b8a3567dd6e7159a', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nThe cinder interface is also added to the enabled storage\ninterfaces as this patch makes attach/detach usable by\nstorage interfaces.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 29, 'created': '2017-05-31 04:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/637c23e43c18e84ef95c849fc5dae27d65cfae1a', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 30, 'created': '2017-06-06 19:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8ea868920466a5c6e0da867a11d9bf9d0f46c829', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@us.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 31, 'created': '2017-06-07 16:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/21d77525a779835d53285170948bccde91dcbb03', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@us.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 32, 'created': '2017-06-08 13:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7ab4e602983fea983e95c04c57a61518f447e339', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 33, 'created': '2017-06-08 13:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52514e6442dbd9b16be3c26e0b3d1f94c9b104e0', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@us.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 34, 'created': '2017-06-08 14:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/adf989017fe17980b8581beb389793b328a1dc0e', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 35, 'created': '2017-06-08 19:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9a370083c34767bf0b21d56366e8dd5471357974', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 36, 'created': '2017-06-13 21:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/751e6becb177913392ca5af1939a9063d4fd2820', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nThe ""cinder"" storage interface has been enabled by default,\nand further details on the storage interface\'s use are in\nlater patchsets for this feature.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 37, 'created': '2017-06-13 21:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/925d14d30abb30d21ff094f9a76ee956e680d7bc', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nThe ""cinder"" storage interface has been enabled by default,\nand further details on the storage interface\'s use are in\nlater patchsets for this feature.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 38, 'created': '2017-06-15 13:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/05855c195be3c5d90eb27c838b022519fea783e8', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nThe ""cinder"" storage interface has been enabled by default,\nand further details on the storage interface\'s use are in\nlater patchsets for this feature.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}, {'number': 39, 'created': '2017-06-15 21:18:28.000000000', 'files': ['ironic/drivers/modules/agent.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/tests/unit/conductor/test_utils.py', 'ironic/conductor/utils.py', 'ironic/tests/unit/drivers/modules/test_iscsi_deploy.py', 'ironic/conf/default.py', 'ironic/tests/unit/drivers/modules/test_agent.py', 'ironic/tests/unit/drivers/modules/test_deploy_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/104000549eb542db25f780279c885c6a55623e98', 'message': 'Wire in storage interface attach/detach operations\n\nAddition of storage interface attachment and detachment\noperations when:\n\n* Node power is turned on/off, with a storage_interface\n  configured, and when the node is in ACTIVE state.\n* Node deployment and node tear_down operations.\n\nIn addition to attachment and detachment, driver_internal_info\nis now populated with a boot from volume target uuid, if a\nvolume is defined for the node.\n\nAdditionally, upon tear_down, the drivers now call a helper\nto remove storage related dictionaries and destroy\nvolume target records.\n\nThe ""cinder"" storage interface has been enabled by default,\nand further details on the storage interface\'s use are in\nlater patchsets for this feature.\n\nAuthored-By: Julia Kreger <juliaashleykreger@gmail.com>\nCo-Authored-By: Joanna Taryma <joanna.taryma@intel.com>\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nChange-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7\nPartial-Bug: #1559691\n'}]",192,406290,104000549eb542db25f780279c885c6a55623e98,283,24,39,11655,,,0,"Wire in storage interface attach/detach operations

Addition of storage interface attachment and detachment
operations when:

* Node power is turned on/off, with a storage_interface
  configured, and when the node is in ACTIVE state.
* Node deployment and node tear_down operations.

In addition to attachment and detachment, driver_internal_info
is now populated with a boot from volume target uuid, if a
volume is defined for the node.

Additionally, upon tear_down, the drivers now call a helper
to remove storage related dictionaries and destroy
volume target records.

The ""cinder"" storage interface has been enabled by default,
and further details on the storage interface's use are in
later patchsets for this feature.

Authored-By: Julia Kreger <juliaashleykreger@gmail.com>
Co-Authored-By: Joanna Taryma <joanna.taryma@intel.com>
Co-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>
Change-Id: I0e22312e8cebb37b8f025da2baeca8eb635f35b7
Partial-Bug: #1559691
",git fetch https://review.opendev.org/openstack/ironic refs/changes/90/406290/38 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/conductor/test_utils.py', 'ironic/conductor/utils.py']",2,1f04a5b1a7c2c7bcf974c670aac67f004995503a,bug/1559691," # NOTE(TheJulia): When we explicitly power-on a node # we should call call for any volumes to be attached. if (new_state == states.POWER_ON and task.node.storage_interface != 'no-storage'): task.driver.storage.attach_volumes(task) # NOTE(TheJulia): Similarlly to power-on, when we power-off # a node, we should detach any volume attachments. if (new_state == states.POWER_OFF and task.node.storage_interface != 'no-storage'): task.driver.storage.detach_volumes(task)",,58,0
openstack%2Fnova~master~I6a2782ce4a83df8d63bc4ef09b57ae8b5cfb7fbb,openstack/nova,master,I6a2782ce4a83df8d63bc4ef09b57ae8b5cfb7fbb,Make compute_node_statistics() work across cells,MERGED,2017-06-13 18:28:48.000000000,2017-06-16 19:28:45.000000000,2017-06-14 22:49:15.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 20040}, {'_account_id': 21813}]","[{'number': 1, 'created': '2017-06-13 18:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/19d36cb0b90915d10284878b021304f5f63f63ea', 'message': 'Make compute_node_statistics() work across cells\n\nThis makes us issue the stats call once per (non-cell0) cell and\nsummarize the results.\n\nRelated to blueprint cells-aware-api\n\nChange-Id: I6a2782ce4a83df8d63bc4ef09b57ae8b5cfb7fbb\n'}, {'number': 2, 'created': '2017-06-13 22:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/567d70f22ae95589b23a25a97b05754889e852f1', 'message': 'Make compute_node_statistics() work across cells\n\nThis makes us issue the stats call once per (non-cell0) cell and\nsummarize the results.\n\nRelated to blueprint cells-aware-api\n\nChange-Id: I6a2782ce4a83df8d63bc4ef09b57ae8b5cfb7fbb\n'}, {'number': 3, 'created': '2017-06-14 17:30:27.000000000', 'files': ['nova/tests/unit/compute/test_host_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5fc1dfc0f468fd24ecbdbe967d422c05e7add1a5', 'message': 'Make compute_node_statistics() work across cells\n\nThis makes us issue the stats call once per (non-cell0) cell and\nsummarize the results.\n\nRelated to blueprint cells-aware-api\n\nChange-Id: I6a2782ce4a83df8d63bc4ef09b57ae8b5cfb7fbb\n'}]",5,473931,5fc1dfc0f468fd24ecbdbe967d422c05e7add1a5,44,16,3,4393,,,0,"Make compute_node_statistics() work across cells

This makes us issue the stats call once per (non-cell0) cell and
summarize the results.

Related to blueprint cells-aware-api

Change-Id: I6a2782ce4a83df8d63bc4ef09b57ae8b5cfb7fbb
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/473931/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_host_api.py', 'nova/compute/api.py']",2,19d36cb0b90915d10284878b021304f5f63f63ea,bp/cells-aware-api," load_cells() cell_stats = [] for cell in CELLS: print cell if cell.uuid == objects.CellMapping.CELL0_UUID: continue with nova_context.target_cell(context, cell) as cctxt: cell_stats.append(self.db.compute_node_statistics(cctxt)) keys = cell_stats[0].keys() print cell_stats return {k: sum(stats[k] for stats in cell_stats) for k in keys}", return self.db.compute_node_statistics(context),25,1
openstack%2Fos-brick~master~I058ff0a0e5ad517507dc3cda39087c913558561d,openstack/os-brick,master,I058ff0a0e5ad517507dc3cda39087c913558561d,Refactor iSCSI disconnect,MERGED,2017-04-10 17:08:40.000000000,2017-06-16 19:22:13.000000000,2017-06-15 23:12:38.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12112}, {'_account_id': 12369}, {'_account_id': 12924}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16595}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19852}, {'_account_id': 20146}, {'_account_id': 22248}, {'_account_id': 22700}, {'_account_id': 22796}, {'_account_id': 24502}]","[{'number': 1, 'created': '2017-04-10 17:08:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/dddc7fbe334cca207b1e96b615484fca4fdcaa3d', 'message': 'WIP: Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 2, 'created': '2017-04-12 18:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/5b9e13285fb06678de07080c3b34aa88f86dfae2', 'message': 'WIP: Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 3, 'created': '2017-04-13 11:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/8b92801a1f7e1ab423df24bf71b4f565f11b50a3', 'message': 'WIP: Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 4, 'created': '2017-04-19 11:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/fca1fa477181ad558447e82f4274b9f6b0af1b23', 'message': 'WIP: Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 5, 'created': '2017-04-21 09:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/ff2ce0b074074bf3003f80bd9ff19ab729e35f05', 'message': 'WIP: Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 6, 'created': '2017-05-22 15:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/37c7c17028900cdd7f1ca39f229c15eccc040271', 'message': 'Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 7, 'created': '2017-05-31 10:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/8cf28810468c5f79f30ca00f437df55009df2cee', 'message': 'Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}, {'number': 8, 'created': '2017-05-31 14:06:25.000000000', 'files': ['os_brick/initiator/connectors/vmware.py', 'os_brick/initiator/windows/iscsi.py', 'os_brick/tests/initiator/connectors/test_iscsi.py', 'os_brick/tests/initiator/test_linuxscsi.py', 'os_brick/initiator/linuxscsi.py', 'os_brick/initiator/connector.py', 'os_brick/initiator/connectors/hgst.py', 'os_brick/initiator/windows/smbfs.py', 'os_brick/initiator/connectors/aoe.py', 'os_brick/initiator/__init__.py', 'os_brick/initiator/connectors/fibre_channel.py', 'os_brick/tests/windows/fake_win_conn.py', 'os_brick/initiator/connectors/scaleio.py', 'os_brick/initiator/connectors/fake.py', 'os_brick/initiator/connectors/sheepdog.py', 'os_brick/privileged/rootwrap.py', 'os_brick/initiator/connectors/local.py', 'releasenotes/notes/refactor_iscsi_disconnect-557f4173bc1ae4ed.yaml', 'os_brick/tests/privileged/test_rootwrap.py', 'os_brick/initiator/windows/fibre_channel.py', 'os_brick/initiator/connectors/huawei.py', 'os_brick/initiator/connectors/vrtshyperscale.py', 'os_brick/initiator/connectors/drbd.py', 'os_brick/initiator/initiator_connector.py', 'os_brick/initiator/connectors/iscsi.py', 'os_brick/initiator/connectors/disco.py', 'os_brick/initiator/connectors/rbd.py', 'os_brick/initiator/connectors/remotefs.py', 'os_brick/exception.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/400ca5d6db818b966065001571e59198c6966e2f', 'message': 'Refactor iSCSI disconnect\n\nThis patch refactors iSCSI disconnect code changing the approach to one\nthat just uses `iscsiadm -m session` and sysfs to get all the required\ninformation: devices from the connection, multipath system device name,\nmultipath name, the WWN for the block devices...\n\nBy doing so, not only do we fix a good number of bugs, but we also\nimprove the reliability and speed of the mechanism.\n\nA good example of improvements and benefits achieved by this patch are:\n\n- Common code for multipath and single path disconnects.\n\n- No more querying iSCSI devices for their WWN (page 0x83) removing\n  delays and issue on flaky connections.\n\n- All devices are properly cleaned even if they are not part of the\n  multipath.\n\n- We wait for device removal and do it in parallel if there are\n  multiple.\n\n- Removed usage of `multipath -l` to find devices which is really slow\n  with flaky connections and didn\'t work when called with a device from\n  a path that is down.\n\n- Prevent losing data when detaching, currently if the multipath flush\n  fails for any other reason than ""in use"" we silently continue with the\n  removal.  That is the case when all paths are momentarily down.\n\n- Adds a new mechanism for the caller of the disconnect to specify that\n  it\'s acceptable to lose data and that it\'s more important to leave a\n  clean system.  That is the case if we are creating a volume from an\n  image, since the volume will just be set to error, but we don\'t want\n  leftovers.  Optionally we can tell os-brick to ignore errors and don\'t\n  raise an exception if the flush fails.\n\n- Add a warning when we could be leaving leftovers behind due to\n  disconnect issues.\n\n- Action retries (like multipath flush) will now only log the final\n  exception instead of logging all the exceptions.\n\n- Flushes of individual paths now use exponential backoff retries\n  instead of random retries between 0.2 and 2 seconds (from oslo\n  library).\n\n- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,\n  or `/dev/mapper` to find devices or multipaths, as they could be\n  leftovers from previous runs.\n\n- With high failure rates (above 30%) some CLI calls will enter into a\n  weird state where they wait forever, so we add a timeout mechanism in\n  our `execute` method and add it to those specific calls.\n\nCloses-Bug: #1502534\nChange-Id: I058ff0a0e5ad517507dc3cda39087c913558561d\n'}]",12,455392,400ca5d6db818b966065001571e59198c6966e2f,146,22,8,9535,,,0,"Refactor iSCSI disconnect

This patch refactors iSCSI disconnect code changing the approach to one
that just uses `iscsiadm -m session` and sysfs to get all the required
information: devices from the connection, multipath system device name,
multipath name, the WWN for the block devices...

By doing so, not only do we fix a good number of bugs, but we also
improve the reliability and speed of the mechanism.

A good example of improvements and benefits achieved by this patch are:

- Common code for multipath and single path disconnects.

- No more querying iSCSI devices for their WWN (page 0x83) removing
  delays and issue on flaky connections.

- All devices are properly cleaned even if they are not part of the
  multipath.

- We wait for device removal and do it in parallel if there are
  multiple.

- Removed usage of `multipath -l` to find devices which is really slow
  with flaky connections and didn't work when called with a device from
  a path that is down.

- Prevent losing data when detaching, currently if the multipath flush
  fails for any other reason than ""in use"" we silently continue with the
  removal.  That is the case when all paths are momentarily down.

- Adds a new mechanism for the caller of the disconnect to specify that
  it's acceptable to lose data and that it's more important to leave a
  clean system.  That is the case if we are creating a volume from an
  image, since the volume will just be set to error, but we don't want
  leftovers.  Optionally we can tell os-brick to ignore errors and don't
  raise an exception if the flush fails.

- Add a warning when we could be leaving leftovers behind due to
  disconnect issues.

- Action retries (like multipath flush) will now only log the final
  exception instead of logging all the exceptions.

- Flushes of individual paths now use exponential backoff retries
  instead of random retries between 0.2 and 2 seconds (from oslo
  library).

- We no longer use symlinks from `/dev/disk/by-path`, `/dev/disk/by-id`,
  or `/dev/mapper` to find devices or multipaths, as they could be
  leftovers from previous runs.

- With high failure rates (above 30%) some CLI calls will enter into a
  weird state where they wait forever, so we add a timeout mechanism in
  our `execute` method and add it to those specific calls.

Closes-Bug: #1502534
Change-Id: I058ff0a0e5ad517507dc3cda39087c913558561d
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/92/455392/8 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/initiator/__init__.py', 'os_brick/tests/initiator/connectors/test_iscsi.py', 'os_brick/tests/initiator/test_linuxscsi.py', 'os_brick/initiator/connectors/iscsi.py', 'os_brick/initiator/linuxscsi.py', 'os_brick/privileged/rootwrap.py', 'releasenotes/notes/refactor_iscsi_disconnect-557f4173bc1ae4ed.yaml', 'os_brick/initiator/connector.py', 'os_brick/tests/privileged/test_rootwrap.py', 'os_brick/exception.py']",10,dddc7fbe334cca207b1e96b615484fca4fdcaa3d,refactor/multipath,"from oslo_concurrency import processutils as putilsimport traceback class ExceptionChainer(BrickException): """"""A Exception that can contain a group of exceptions. This exception is serves as a container for exceptions useful when we want to store all exceptions that happened during a series of steps and then raise them all together as one. The representation of the exception will include all exceptions and their tracebacks. This class also includes a context manager for convenience, one that will support both swallowing the exception as if nothing had happened and raising the exception. In both cases the exception will be stored. If a message is provided to the context manager it will be formatted and logged with warning level. """""" def __init__(self, *args, **kwargs): self._exceptions = [] self._repr = None super(ExceptionChainer, self).__init__(*args, **kwargs) def __repr__(self): # Since generating the representation can be slow we cache it if not self._repr: tracebacks = (''.join(traceback.format_exception(*exc)) for exc in self._exceptions) self._repr = '\n'.join('\nChained Exception #%s\n%s' % (i + 1, tb) for i, tb in enumerate(tracebacks)) return self._repr __str__ = __unicode__ = __repr__ def __nonzero__(self): # We want to be able to do boolean checks on the exception return bool(self._exceptions) def add_exception(self, exc_type, exc_val, exc_tb): # Clear the representation cache self._repr = None self._exceptions.append((exc_type, exc_val, exc_tb)) def context(self, catch_exception, msg='', *msg_args): self._catch_exception = catch_exception self._exc_msg = msg self._exc_msg_args = msg_args return self def __enter__(self): return self def __exit__(self, exc_type, exc_val, exc_tb): if exc_type: self.add_exception(exc_type, exc_val, exc_tb) if self._exc_msg: LOG.warning(self._exc_msg, self._exc_msg_args) if self._catch_exception: return True class ExecutionTimeout(putils.ProcessExecutionError): pass",,554,394
openstack%2Fswift~master~I9a0d86ca72eea1ef6babd67e8f0d95776dc45496,openstack/swift,master,I9a0d86ca72eea1ef6babd67e8f0d95776dc45496,fixup! Replace slowdown option with *_per_second option,ABANDONED,2017-05-24 23:40:34.000000000,2017-06-16 19:18:43.000000000,,"[{'_account_id': 3}, {'_account_id': 13052}]","[{'number': 1, 'created': '2017-05-24 23:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/52fc4a36efc1a3050a4b85a81e32cb010b9919dc', 'message': 'fixup! Replace slowdown option with *_per_second option\n\nChange-Id: I9a0d86ca72eea1ef6babd67e8f0d95776dc45496\n'}, {'number': 2, 'created': '2017-05-25 15:19:55.000000000', 'files': ['swift/obj/updater.py', 'doc/source/deployment_guide.rst', 'swift/container/updater.py', 'etc/container-server.conf-sample', 'test/unit/container/test_updater.py', 'doc/manpages/object-server.conf.5', 'test/unit/obj/test_updater.py', 'doc/manpages/container-server.conf.5', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/93d0da52eb9237526252f0c45b56cd65267b26f2', 'message': 'fixup! Replace slowdown option with *_per_second option\n\nChange-Id: I9a0d86ca72eea1ef6babd67e8f0d95776dc45496\n'}]",0,467801,93d0da52eb9237526252f0c45b56cd65267b26f2,7,2,2,15343,,,0,"fixup! Replace slowdown option with *_per_second option

Change-Id: I9a0d86ca72eea1ef6babd67e8f0d95776dc45496
",git fetch https://review.opendev.org/openstack/swift refs/changes/01/467801/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/updater.py', 'doc/source/deployment_guide.rst', 'swift/container/updater.py', 'etc/container-server.conf-sample', 'test/unit/container/test_updater.py', 'doc/manpages/object-server.conf.5', 'test/unit/obj/test_updater.py', 'doc/manpages/container-server.conf.5', 'etc/object-server.conf-sample']",9,52fc4a36efc1a3050a4b85a81e32cb010b9919dc,448244,# Send at most this many object updates per second# slowdown will sleep that amount between objects. Deprecated; use # objects_per_second instead. # slowdown = 0.01 #,# Update that amount of objects per second at max,108,4
openstack%2Fkeystone~master~I2c4ce84cdf8e3ab336c391824b1843b271791742,openstack/keystone,master,I2c4ce84cdf8e3ab336c391824b1843b271791742,"Revert ""Support new hashing algorithms for securely storing password hashes""",ABANDONED,2017-06-11 16:16:28.000000000,2017-06-16 19:03:13.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6172}, {'_account_id': 8482}, {'_account_id': 9545}, {'_account_id': 13478}]","[{'number': 1, 'created': '2017-06-11 16:16:28.000000000', 'files': ['keystone/common/sql/data_migration_repo/versions/023_migrate_add_second_password_column_for_expanded_hash_sizes.py', 'keystone/conf/default.py', 'keystone/identity/backends/sql_model.py', 'keystone/common/password_hashing.py', 'keystone/common/sql/contract_repo/versions/023_contract_add_second_password_column_for_expanded_hash_sizes.py', 'keystone/tests/unit/core.py', 'keystone/tests/unit/identity/test_backend_sql.py', 'requirements.txt', 'keystone/conf/identity.py', 'keystone/identity/backends/sql.py', 'releasenotes/notes/bug_1543048_and_1668503-7ead4e15faaab778.yaml', 'keystone/common/sql/expand_repo/versions/023_expand_add_second_password_column_for_expanded_hash_sizes.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/common/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8f71dee82b6320643024e1cafc63c37ede121ed0', 'message': 'Revert ""Support new hashing algorithms for securely storing password hashes""\n\nRelated-Bug: #1697263\n\nThis reverts commit 8ad765e0230ceeb5ca7c36ec3ed6d25c57b22c9d.\n\nChange-Id: I2c4ce84cdf8e3ab336c391824b1843b271791742\n'}]",2,473104,8f71dee82b6320643024e1cafc63c37ede121ed0,15,7,1,9545,,,0,"Revert ""Support new hashing algorithms for securely storing password hashes""

Related-Bug: #1697263

This reverts commit 8ad765e0230ceeb5ca7c36ec3ed6d25c57b22c9d.

Change-Id: I2c4ce84cdf8e3ab336c391824b1843b271791742
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/473104/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/data_migration_repo/versions/023_migrate_add_second_password_column_for_expanded_hash_sizes.py', 'keystone/conf/default.py', 'keystone/identity/backends/sql_model.py', 'keystone/common/password_hashing.py', 'keystone/common/sql/contract_repo/versions/023_contract_add_second_password_column_for_expanded_hash_sizes.py', 'keystone/tests/unit/core.py', 'keystone/tests/unit/identity/test_backend_sql.py', 'requirements.txt', 'keystone/conf/identity.py', 'keystone/identity/backends/sql.py', 'releasenotes/notes/bug_1543048_and_1668503-7ead4e15faaab778.yaml', 'keystone/common/sql/expand_repo/versions/023_expand_add_second_password_column_for_expanded_hash_sizes.py', 'keystone/tests/unit/test_backend_sql.py', 'keystone/common/utils.py']",14,8f71dee82b6320643024e1cafc63c37ede121ed0,bug/1697263,"import passlib.hashdef verify_length_and_trunc_password(password): """"""Verify and truncate the provided password to the max_password_length."""""" max_length = CONF.identity.max_password_length try: if len(password) > max_length: if CONF.strict_password_check: raise exception.PasswordVerificationError(size=max_length) else: msg = ""Truncating user password to %d characters."" LOG.warning(msg, max_length) return password[:max_length] else: return password except TypeError: raise exception.ValidationError(attribute='string', target='password') def hash_user_password(user): """"""Hash a user dict's password without modifying the passed-in dict."""""" password = user.get('password') if password is None: return user return dict(user, password=hash_password(password)) def hash_password(password): """"""Hash a password. Hard."""""" password_utf8 = verify_length_and_trunc_password(password).encode('utf-8') return passlib.hash.sha512_crypt.hash( password_utf8, rounds=CONF.crypt_strength) def check_password(password, hashed): """"""Check that a plaintext password matches hashed. hashpw returns the salt value concatenated with the actual hash value. It extracts the actual salt if this value is then passed as the salt. """""" if password is None or hashed is None: return False password_utf8 = verify_length_and_trunc_password(password).encode('utf-8') return passlib.hash.sha512_crypt.verify(password_utf8, hashed) ",from keystone.common import password_hashing# Compatibilty for password hashing functions. verify_length_and_trunc_password = password_hashing.verify_length_and_trunc_password # noqa hash_password = password_hashing.hash_password hash_user_password = password_hashing.hash_user_password check_password = password_hashing.check_password ,71,456
openstack%2Fswift~stable%2Fnewton~Ia72c407247e4525ef071a1728750850807ae8231,openstack/swift,stable/newton,Ia72c407247e4525ef071a1728750850807ae8231,Do not sync suffixes when remote rejects reconstructor revert,ABANDONED,2017-05-16 08:44:06.000000000,2017-06-16 19:02:41.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 13052}]","[{'number': 1, 'created': '2017-05-16 08:44:06.000000000', 'files': ['swift/obj/reconstructor.py', 'test/unit/__init__.py', 'test/unit/obj/test_reconstructor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2d9d858d99b0fbcbcb6b011e005e0da5b01c8e8d', 'message': 'Do not sync suffixes when remote rejects reconstructor revert\n\nSSYNC is designed to limit concurrent incoming connections in order to\nprevent IO contention.  The reconstructor should expect remote\nreplication servers to fail ssync_sender when the remote is too busy.\nWhen the remote rejects SSYNC - it should avoid forcing additional IO\nagainst the remote with a REPLICATE request which causes suffix\nrehashing.\n\nSuffix rehashing via REPLICATE verbs takes two forms:\n\n1) a initial pre-flight call to REPLICATE /dev/part will cause a remote\nprimary to rehash any invalid suffixes and return a map for the local\nsender to compare so that a sync can be performed on any mis-matched\nsuffixes.\n\n2) a final call to REPLICATE /dev/part/suf1-suf2-suf3[-sufX[...]] will\ncause the remote primary to rehash the *given* suffixes even if they are\n*not* invalid.  This is a requirement for rsync replication because\nafter a suffix is synced via rsync the contents of a suffix dir will\nlikely have changed and the remote server needs to update it hashes.pkl\nto reflect the new data.\n\nSSYNC does not *need* to send a post-sync REPLICATE request.  Any\nsuffixes that are modified by the SSYNC protocol will call _finalize_put\nunder the hood as it is syncing.  It is however not harmful and\npotentially useful to go ahead refresh hashes after an SSYNC while the\ninodes of those suffixes are warm in the cache.\n\nHowever, that only makes sense if the SSYNC conversation actually synced\nany suffixes - if SSYNC is rejected for concurrency before it ever got\nstarted there is no value in the remote performing a rehash.  It may be\nthat *another* reconstructor is pushing data into that same partition\nand the suffixes will become immediately invalidated.\n\nIf a ssync_sender does not successful finish a sync the reconstructor\nshould skip the REPLICATE call entirely and move on to the next\npartition without causing any useless remote IO.\n\nCloses-Bug: #1665141\n\nChange-Id: Ia72c407247e4525ef071a1728750850807ae8231\n'}]",2,464982,2d9d858d99b0fbcbcb6b011e005e0da5b01c8e8d,7,4,1,16896,,,0,"Do not sync suffixes when remote rejects reconstructor revert

SSYNC is designed to limit concurrent incoming connections in order to
prevent IO contention.  The reconstructor should expect remote
replication servers to fail ssync_sender when the remote is too busy.
When the remote rejects SSYNC - it should avoid forcing additional IO
against the remote with a REPLICATE request which causes suffix
rehashing.

Suffix rehashing via REPLICATE verbs takes two forms:

1) a initial pre-flight call to REPLICATE /dev/part will cause a remote
primary to rehash any invalid suffixes and return a map for the local
sender to compare so that a sync can be performed on any mis-matched
suffixes.

2) a final call to REPLICATE /dev/part/suf1-suf2-suf3[-sufX[...]] will
cause the remote primary to rehash the *given* suffixes even if they are
*not* invalid.  This is a requirement for rsync replication because
after a suffix is synced via rsync the contents of a suffix dir will
likely have changed and the remote server needs to update it hashes.pkl
to reflect the new data.

SSYNC does not *need* to send a post-sync REPLICATE request.  Any
suffixes that are modified by the SSYNC protocol will call _finalize_put
under the hood as it is syncing.  It is however not harmful and
potentially useful to go ahead refresh hashes after an SSYNC while the
inodes of those suffixes are warm in the cache.

However, that only makes sense if the SSYNC conversation actually synced
any suffixes - if SSYNC is rejected for concurrency before it ever got
started there is no value in the remote performing a rehash.  It may be
that *another* reconstructor is pushing data into that same partition
and the suffixes will become immediately invalidated.

If a ssync_sender does not successful finish a sync the reconstructor
should skip the REPLICATE call entirely and move on to the next
partition without causing any useless remote IO.

Closes-Bug: #1665141

Change-Id: Ia72c407247e4525ef071a1728750850807ae8231
",git fetch https://review.opendev.org/openstack/swift refs/changes/82/464982/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/reconstructor.py', 'test/unit/__init__.py', 'test/unit/obj/test_reconstructor.py']",3,2d9d858d99b0fbcbcb6b011e005e0da5b01c8e8d,bug/1665141," def _make_fake_ssync(self, ssync_calls, fail_jobs=None): """""" Replace SsyncSender with a thin Fake. :param ssync_calls: an empty list, a non_local, all calls to ssync will be captured for assertion in the caller. :param fail_jobs: optional iter of dicts, any job passed into Fake that matches a failure dict will return success == False. """""" self.success = True for failure in (fail_jobs or []): if all(job.get(k) == v for (k, v) in failure.items()): self.success = False break context['success'] = self.success return self.success, self.available_map if self.success else {} def test_no_delete_failed_revert(self): # test will only process revert jobs self.reconstructor.handoffs_only = True captured_ssync = [] # fail all jobs on part 2 on sda1 fail_jobs = [ {'device': 'sda1', 'partition': 2}, ] with mock.patch('swift.obj.reconstructor.ssync_sender', self._make_fake_ssync( captured_ssync, fail_jobs=fail_jobs)), \ mocked_http_conn(*[200, 200], body=pickle.dumps({})) as request_log: self.reconstructor.reconstruct() # global setup has four revert jobs self.assertEqual(len(captured_ssync), 4) expected_ssync_calls = set([ # device, part, frag_index ('sda1', 2, 2), ('sda1', 2, 0), ('sda1', 0, 2), ('sda1', 1, 1), ]) self.assertEqual(expected_ssync_calls, set([ (context['job']['device'], context['job']['partition'], context['job']['frag_index']) for context in captured_ssync ])) self.assertEqual(2, len(request_log.requests)) expected_suffix_calls = [] for context in captured_ssync: if not context['success']: # only successful jobs generate suffix rehash calls continue job = context['job'] expected_suffix_calls.append( (job['sync_to'][0]['replication_ip'], '/%s/%s/%s' % ( job['device'], job['partition'], '-'.join(sorted(job['suffixes'])))) ) self.assertEqual(set(expected_suffix_calls), set((r['ip'], r['path']) for r in request_log.requests)) self.assertFalse( self.reconstructor.logger.get_lines_for_level('error')) self.assertFalse(request_log.unexpected_requests) mocked_http_conn() as request_log: # failed ssync job should not generate a suffix rehash self.assertEqual([], request_log.requests) mocked_http_conn() as request_log: # failed ssync job should not generate a suffix rehash self.assertEqual([], request_log.requests)"," def _make_fake_ssync(self, ssync_calls): return True, self.available_map mock.patch('swift.obj.diskfile.ECDiskFileManager._get_hashes', return_value=(None, stub_hashes)), \ mocked_http_conn(*[200] * len(expected_suffix_calls), body=pickle.dumps({})) as request_log: found_suffix_calls = set((r['ip'], r['path']) for r in request_log.requests) self.assertEqual(expected_suffix_calls, found_suffix_calls) expected_suffix_calls = set([ (sync_to[0]['replication_ip'], '/%s/0/123-abc' % sync_to[0]['device']) ] + [ (node['replication_ip'], '/%s/0/123-abc' % node['device']) for node in handoff_nodes[:-1] ]) mock.patch('swift.obj.diskfile.ECDiskFileManager._get_hashes', return_value=(None, stub_hashes)), \ mocked_http_conn(*[200] * len(expected_suffix_calls), body=pickle.dumps({})) as request_log: found_suffix_calls = set((r['ip'], r['path']) for r in request_log.requests) self.assertEqual(expected_suffix_calls, found_suffix_calls)",85,26
openstack%2Fneutron~master~Ic48d078542492e933f71d24df85c54c53a0b110c,openstack/neutron,master,Ic48d078542492e933f71d24df85c54c53a0b110c,"Fix tempest router migration test when HA enabled, v2",MERGED,2017-05-05 15:36:08.000000000,2017-06-16 18:48:00.000000000,2017-05-15 21:12:38.000000000,"[{'_account_id': 3}, {'_account_id': 4694}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 9732}]","[{'number': 1, 'created': '2017-05-05 15:36:08.000000000', 'files': ['neutron/tests/tempest/api/test_revisions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/52ed8468a4583453951cf584e9bd1f30a212b29e', 'message': 'Fix tempest router migration test when HA enabled, v2\n\nWhen run in an HA or DVR configured environment,\nthe test_update_router_extra_attributes_bumps_revision\nAPI test can fail if the release does not support\nrouter migration from CVR-HA to DVR.\n\nAlthough Ocata and later releases support any type of\nrouter migration, older ones do not, so the test\nshould be explicit and test a known valid migration.\n\nAdded missing l3-ha extension requirement from v1.\n\nChange-Id: Ic48d078542492e933f71d24df85c54c53a0b110c\nRelated-bug: #1679794\n'}]",0,462976,52ed8468a4583453951cf584e9bd1f30a212b29e,15,5,1,1131,,,0,"Fix tempest router migration test when HA enabled, v2

When run in an HA or DVR configured environment,
the test_update_router_extra_attributes_bumps_revision
API test can fail if the release does not support
router migration from CVR-HA to DVR.

Although Ocata and later releases support any type of
router migration, older ones do not, so the test
should be explicit and test a known valid migration.

Added missing l3-ha extension requirement from v1.

Change-Id: Ic48d078542492e933f71d24df85c54c53a0b110c
Related-bug: #1679794
",git fetch https://review.opendev.org/openstack/neutron refs/changes/76/462976/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/tempest/api/test_revisions.py'],1,52ed8468a4583453951cf584e9bd1f30a212b29e,bug/1679794," @test.requires_ext(extension=""l3-ha"", service=""network"") def test_update_router_extra_attributes_bumps_revision(self): # updates from CVR to CVR-HA are supported on every release, # but only the admin can forcibly create a non-HA router router_args = {'tenant_id': self.client.tenant_id, 'ha': False} router = self.admin_client.create_router('r1', True, **router_args)['router'] self.admin_client.update_router(router['id'], ha=True)['router']"," @test.requires_ext(extension=""dvr"", service=""network"") def test_update_router_extra_attributes_bumps_revision(self): router = self.create_router(router_name='r1') self.admin_client.update_router(router['id'], distributed=True)['router']",8,4
openstack%2Fkuryr-kubernetes~master~I88862f28d0bbbd8bf5259209c4fa3c41130479d1,openstack/kuryr-kubernetes,master,I88862f28d0bbbd8bf5259209c4fa3c41130479d1,Update installation documentation,MERGED,2017-06-09 12:05:19.000000000,2017-06-16 18:42:53.000000000,2017-06-16 18:42:53.000000000,"[{'_account_id': 3}, {'_account_id': 14352}, {'_account_id': 23567}]","[{'number': 1, 'created': '2017-06-09 12:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/358f18dc7e4e2a1b632ea32281f50ed3da9df53f', 'message': 'Update installation documentation\n\nThis commit moves installation/configuration documentation from README\nfile to installation section of the actual docs (which has been rather\nshort thus far). This commit splits a single README into multiple\ninstallation sub-docs. It also expands the manual on installation and\nconfiguration of kuryr-k8s-controller and kuryr-cni.\n\nChange-Id: I88862f28d0bbbd8bf5259209c4fa3c41130479d1\n'}, {'number': 2, 'created': '2017-06-13 10:43:53.000000000', 'files': ['doc/source/index.rst', 'doc/source/installation/https_kubernetes.rst', 'doc/source/installation/manual.rst', 'README.rst', 'doc/source/installation/nested-vlan.rst', 'doc/source/conf.py', 'doc/source/installation/index.rst', 'doc/source/installation.rst', 'doc/source/installation/nested-macvlan.rst'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f50e2140f9b1e067d7efd50977ff0e9e7769fdc8', 'message': 'Update installation documentation\n\nThis commit moves installation/configuration documentation from README\nfile to installation section of the actual docs (which has been rather\nshort thus far). This commit splits a single README into multiple\ninstallation sub-docs. It also expands the manual on installation and\nconfiguration of kuryr-k8s-controller and kuryr-cni.\n\nChange-Id: I88862f28d0bbbd8bf5259209c4fa3c41130479d1\n'}]",0,472653,f50e2140f9b1e067d7efd50977ff0e9e7769fdc8,13,3,2,15168,,,0,"Update installation documentation

This commit moves installation/configuration documentation from README
file to installation section of the actual docs (which has been rather
short thus far). This commit splits a single README into multiple
installation sub-docs. It also expands the manual on installation and
configuration of kuryr-k8s-controller and kuryr-cni.

Change-Id: I88862f28d0bbbd8bf5259209c4fa3c41130479d1
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/53/472653/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/installation/nested.rst', 'doc/source/index.rst', 'doc/source/installation/https_kubernetes.rst', 'doc/source/installation/manual.rst', 'README.rst', 'doc/source/conf.py', 'doc/source/installation/index.rst', 'doc/source/installation.rst']",8,358f18dc7e4e2a1b632ea32281f50ed3da9df53f,,,"============ Installation ============ At the command line:: $ pip install kuryr-kubernetes Or, if you have virtualenvwrapper installed:: $ mkvirtualenv kuryr-kubernetes $ pip install kuryr-kubernetes ",235,131
openstack%2Ftripleo-quickstart-extras~master~I13ec4f6bcec0105c1dc01d0409a5b52628623da5,openstack/tripleo-quickstart-extras,master,I13ec4f6bcec0105c1dc01d0409a5b52628623da5,Add ceph args to deployment arguments,ABANDONED,2017-06-14 21:16:06.000000000,2017-06-16 18:40:58.000000000,,"[{'_account_id': 6796}, {'_account_id': 8652}, {'_account_id': 10022}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-06-14 21:16:06.000000000', 'files': ['roles/overcloud-deploy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/390629b34eb18bfeb13433d0dbfbb309019f069c', 'message': 'Add ceph args to deployment arguments\n\nAdd ceph deployments arguments.\n\nChange-Id: I13ec4f6bcec0105c1dc01d0409a5b52628623da5\n'}]",0,474358,390629b34eb18bfeb13433d0dbfbb309019f069c,4,6,1,10969,,,0,"Add ceph args to deployment arguments

Add ceph deployments arguments.

Change-Id: I13ec4f6bcec0105c1dc01d0409a5b52628623da5
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/58/474358/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-deploy/defaults/main.yml'],1,390629b34eb18bfeb13433d0dbfbb309019f069c,upd,"ceph_args: """" {{ ceph_args }}",,2,0
openstack%2Fkeystone~master~I2a133f7ef2e5838499b213603137e5d81cc07b85,openstack/keystone,master,I2a133f7ef2e5838499b213603137e5d81cc07b85,Flag GET APIs that need corresponding HEAD API,ABANDONED,2017-06-07 21:09:58.000000000,2017-06-16 18:35:59.000000000,,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 17860}, {'_account_id': 21420}]","[{'number': 1, 'created': '2017-06-07 21:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5b49617d17aa28ce44cc25b5a15b1ed6d7d736af', 'message': ""Flag GET APIs that need corresponding HEAD API\n\nIt was determined that all GET APIs in keystone that currently do not\nhave a corresponding HEAD API, should. This commit goes through\nkeystone's usage of `get_action` and flags the GET APIs that should\nbe fixed to support HEAD as well.\n\nChange-Id: I2a133f7ef2e5838499b213603137e5d81cc07b85\nRelated-Bug: 1370335\n""}, {'number': 2, 'created': '2017-06-07 21:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9237cc87a452b045354319316fb5fb599c92ca35', 'message': ""Flag GET APIs that need corresponding HEAD API\n\nIt was determined that all GET APIs in keystone that currently do not\nhave a corresponding HEAD API, should. This commit goes through\nkeystone's usage of `get_action` and flags the GET APIs that should\nbe fixed to support HEAD as well.\n\nChange-Id: I2a133f7ef2e5838499b213603137e5d81cc07b85\nRelated-Bug: 1370335\nRelated-Bug: 1696574\n""}, {'number': 3, 'created': '2017-06-09 22:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/486d453162d1d2f1a72b817d12adafee2815c549', 'message': ""Flag GET APIs that need corresponding HEAD API\n\nIt was determined that all GET APIs in keystone that currently do not\nhave a corresponding HEAD API, should. This commit goes through\nkeystone's usage of `get_action` and flags the GET APIs that should\nbe fixed to support HEAD as well.\n\nChange-Id: I2a133f7ef2e5838499b213603137e5d81cc07b85\nRelated-Bug: 1370335\nRelated-Bug: 1696574\n""}, {'number': 4, 'created': '2017-06-10 02:58:49.000000000', 'files': ['keystone/oauth1/routers.py', 'keystone/resource/routers.py', 'keystone/auth/routers.py', 'keystone/assignment/routers.py', 'keystone/endpoint_policy/routers.py', 'keystone/catalog/routers.py', 'keystone/trust/routers.py', 'keystone/contrib/ec2/routers.py', 'keystone/token/_simple_cert.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/863feb14724e24fc8479b764f8489b67611dea59', 'message': ""Flag GET APIs that need corresponding HEAD API\n\nIt was determined that all GET APIs in keystone that currently do not\nhave a corresponding HEAD API, should. This commit goes through\nkeystone's usage of `get_action` and flags the GET APIs that should\nbe fixed to support HEAD as well.\n\nChange-Id: I2a133f7ef2e5838499b213603137e5d81cc07b85\nRelated-Bug: 1370335\nRelated-Bug: 1696574\n""}]",12,471919,863feb14724e24fc8479b764f8489b67611dea59,25,5,4,5046,,,0,"Flag GET APIs that need corresponding HEAD API

It was determined that all GET APIs in keystone that currently do not
have a corresponding HEAD API, should. This commit goes through
keystone's usage of `get_action` and flags the GET APIs that should
be fixed to support HEAD as well.

Change-Id: I2a133f7ef2e5838499b213603137e5d81cc07b85
Related-Bug: 1370335
Related-Bug: 1696574
",git fetch https://review.opendev.org/openstack/keystone refs/changes/19/471919/3 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/oauth1/routers.py', 'keystone/resource/routers.py', 'keystone/auth/routers.py', 'keystone/federation/routers.py', 'keystone/assignment/routers.py', 'keystone/endpoint_policy/routers.py', 'keystone/catalog/routers.py', 'keystone/trust/routers.py', 'keystone/contrib/ec2/routers.py', 'keystone/token/_simple_cert.py']",10,5b49617d17aa28ce44cc25b5a15b1ed6d7d736af,bug/1370335, # FIXME(lbragstad): HEAD requests should be supported for all # existing GET APIs that don't implement HEAD already. This should # be changed to get_head_action. # FIXME(lbragstad): HEAD requests should be supported for all # existing GET APIs that don't implement HEAD already. This should # be changed to get_head_action.,,128,0
openstack%2Fkuryr-kubernetes~master~I306b37630d0088619dcf5ea75662452c4de2eb48,openstack/kuryr-kubernetes,master,I306b37630d0088619dcf5ea75662452c4de2eb48,Switch gate hook to use etcd3 instead of legacy,MERGED,2017-06-16 17:29:01.000000000,2017-06-16 18:16:46.000000000,2017-06-16 18:16:46.000000000,"[{'_account_id': 3}, {'_account_id': 14352}]","[{'number': 1, 'created': '2017-06-16 17:29:01.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/976d7af0a8655850baa1d21336dcf60aad11288b', 'message': 'Switch gate hook to use etcd3 instead of legacy\n\nRelated-Bug: #1638892\nChange-Id: I306b37630d0088619dcf5ea75662452c4de2eb48\n'}]",0,475036,976d7af0a8655850baa1d21336dcf60aad11288b,6,2,1,15168,,,0,"Switch gate hook to use etcd3 instead of legacy

Related-Bug: #1638892
Change-Id: I306b37630d0088619dcf5ea75662452c4de2eb48
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/36/475036/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,976d7af0a8655850baa1d21336dcf60aad11288b,bug/1638892,"export OVERRIDE_ENABLED_SERVICES=neutron,q-svc,key,mysql,rabbit,docker,etcd3,kubernetes-api,kubernetes-controller-manager,kubernetes-scheduler,kubelet,kuryr-kubernetes,q-lbaasv2","export OVERRIDE_ENABLED_SERVICES=neutron,q-svc,key,mysql,rabbit,docker,legacy_etcd,kubernetes-api,kubernetes-controller-manager,kubernetes-scheduler,kubelet,kuryr-kubernetes,q-lbaasv2",1,1
openstack%2Fkuryr-kubernetes~master~Icf7d48b72d0ff6ae34d4752040100997d7892c5e,openstack/kuryr-kubernetes,master,Icf7d48b72d0ff6ae34d4752040100997d7892c5e,devstack: Use devstack's etcd3 service,MERGED,2017-06-14 14:03:14.000000000,2017-06-16 18:16:36.000000000,2017-06-16 18:16:36.000000000,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 14352}, {'_account_id': 14885}, {'_account_id': 15168}, {'_account_id': 23567}]","[{'number': 1, 'created': '2017-06-14 14:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/867efd039ff226946f1901b3c8a364b60e6f81a7', 'message': ""devstack: Use devstack's etcd3 service\n\nThis patch deprecates the containerized etcd that we've been using up\nuntil now for devstack. It moves the default to be the devstack provided\netcd3 service so we do not conflict with other etcd3 consumers and\nbenefit from the upstream devstack improvements.\n\nChange-Id: Icf7d48b72d0ff6ae34d4752040100997d7892c5e\nFixes-Bug: 1638892\nSigned-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>\n""}, {'number': 2, 'created': '2017-06-16 09:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/68c2130aff0bff51e831a73a56112237361668d0', 'message': ""devstack: Use devstack's etcd3 service\n\nThis patch deprecates the containerized etcd that we've been using up\nuntil now for devstack. It moves the default to be the devstack provided\netcd3 service so we do not conflict with other etcd3 consumers and\nbenefit from the upstream devstack improvements.\n\nChange-Id: Icf7d48b72d0ff6ae34d4752040100997d7892c5e\nFixes-Bug: 1638892\nSigned-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>\n""}, {'number': 3, 'created': '2017-06-16 17:29:01.000000000', 'files': ['devstack/devstackgaterc', 'devstack/local.conf.sample', 'devstack/plugin.sh', 'devstack/local.conf.pod-in-vm.overcloud.sample', 'devstack/lib/kuryr_kubernetes', 'devstack/local.conf.df.sample', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9500a81a57383017eec298a55d343faa446d9974', 'message': ""devstack: Use devstack's etcd3 service\n\nThis patch deprecates the containerized etcd that we've been using up\nuntil now for devstack. It moves the default to be the devstack provided\netcd3 service so we do not conflict with other etcd3 consumers and\nbenefit from the upstream devstack improvements.\n\nChange-Id: Icf7d48b72d0ff6ae34d4752040100997d7892c5e\nFixes-Bug: 1638892\nSigned-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>\n""}]",3,474211,9500a81a57383017eec298a55d343faa446d9974,15,6,3,14352,,,0,"devstack: Use devstack's etcd3 service

This patch deprecates the containerized etcd that we've been using up
until now for devstack. It moves the default to be the devstack provided
etcd3 service so we do not conflict with other etcd3 consumers and
benefit from the upstream devstack improvements.

Change-Id: Icf7d48b72d0ff6ae34d4752040100997d7892c5e
Fixes-Bug: 1638892
Signed-off-by: Antoni Segura Puimedon <antonisp@celebdor.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/11/474211/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/local.conf.sample', 'devstack/plugin.sh', 'devstack/lib/kuryr_kubernetes', 'devstack/local.conf.pod-in-vm.overcloud.sample', 'devstack/local.conf.df.sample', 'devstack/settings']",6,867efd039ff226946f1901b3c8a364b60e6f81a7,bug/1638892,KURYR_ETCD_ADVERTISE_CLIENT_URL=${KURYR_ETCD_ADVERTISE_CLIENT_URL:-http://${HOST_IP}:${ETCD_PORT}},KURYR_ETCD_ADVERTISE_CLIENT_URL=${KURYR_ETCD_ADVERTISE_CLIENT_URL:-http://${HOST_IP}:2379},52,39
openstack%2Fcharm-swift-storage~master~I21f23aee34d315ccb4df303527b4d791fc043f58,openstack/charm-swift-storage,master,I21f23aee34d315ccb4df303527b4d791fc043f58,Only change owner/permissions of new devices,MERGED,2017-06-08 23:03:17.000000000,2017-06-16 18:13:19.000000000,2017-06-16 18:13:19.000000000,"[{'_account_id': 3}, {'_account_id': 6737}, {'_account_id': 20648}, {'_account_id': 20812}]","[{'number': 1, 'created': '2017-06-08 23:03:17.000000000', 'files': ['unit_tests/test_swift_storage_utils.py', 'lib/swift_storage_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/d6061caa2cb1ab13ffd476a6d7f39b5b7ff75803', 'message': 'Only change owner/permissions of new devices\n\nDo not change owner and permissions of already existing\ndevices in the setup_storage() function as this runs\nduring every config-changed hook invocation.\n\nChange-Id: I21f23aee34d315ccb4df303527b4d791fc043f58\nCloses-Bug: #1676728\n'}]",0,472471,d6061caa2cb1ab13ffd476a6d7f39b5b7ff75803,11,4,1,8992,,,0,"Only change owner/permissions of new devices

Do not change owner and permissions of already existing
devices in the setup_storage() function as this runs
during every config-changed hook invocation.

Change-Id: I21f23aee34d315ccb4df303527b4d791fc043f58
Closes-Bug: #1676728
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/71/472471/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_swift_storage_utils.py', 'lib/swift_storage_utils.py']",2,d6061caa2cb1ab13ffd476a6d7f39b5b7ff75803,bugs/1676728," check_call(['chown', '-R', 'swift:swift', mountpoint]) check_call(['chmod', '-R', '0755', mountpoint])"," check_call(['chown', '-R', 'swift:swift', '/srv/node/']) check_call(['chmod', '-R', '0755', '/srv/node/'])",22,7
openstack%2Fopenstack-ansible-tests~master~Ifccb6bef2450110244acf68637ca63ea5c41126c,openstack/openstack-ansible-tests,master,Ifccb6bef2450110244acf68637ca63ea5c41126c,Disable private devices,ABANDONED,2017-06-15 09:01:00.000000000,2017-06-16 18:01:20.000000000,,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-06-15 09:01:00.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/9c11ecfc6fc5798d5e79ff23803c9f676d429b93', 'message': 'Disable private devices\n\nThe galera issue (bug [1]) forces us to update all our gates\nfor centos.\n\nThanks to the bug fix [2], we just have to set a variable.\n\n[1]: https://bugs.launchpad.net/openstack-ansible/+bug/1697531\n[2]: https://review.openstack.org/#/c/473879\n\nChange-Id: Ifccb6bef2450110244acf68637ca63ea5c41126c\n'}]",0,474500,9c11ecfc6fc5798d5e79ff23803c9f676d429b93,8,4,1,17068,,,0,"Disable private devices

The galera issue (bug [1]) forces us to update all our gates
for centos.

Thanks to the bug fix [2], we just have to set a variable.

[1]: https://bugs.launchpad.net/openstack-ansible/+bug/1697531
[2]: https://review.openstack.org/#/c/473879

Change-Id: Ifccb6bef2450110244acf68637ca63ea5c41126c
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/00/474500/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,9c11ecfc6fc5798d5e79ff23803c9f676d429b93,,galera_disable_privatedevices: true,,1,0
openstack%2Fopenstack-ansible-galera_server~stable%2Focata~I67ef7ba02ee652e9855b9cf4ba7a44a361844a83,openstack/openstack-ansible-galera_server,stable/ocata,I67ef7ba02ee652e9855b9cf4ba7a44a361844a83,Move PrivateDevices before mysql password set,MERGED,2017-06-16 16:36:53.000000000,2017-06-16 17:51:29.000000000,2017-06-16 17:51:29.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-06-16 16:36:53.000000000', 'files': ['tasks/galera_install_yum.yml', 'tasks/galera_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/c6d36689655586971fbd4be8a6cba2f54b5f44b3', 'message': 'Move PrivateDevices before mysql password set\n\nMove the PrivateDevices before we try to start the service the first time\n\nRelated-Bug: 1697531\nChange-Id: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83\n(cherry picked from commit 588b9cead7637cc73cc8607e2460fea24cc6e2b0)\n'}]",0,475025,c6d36689655586971fbd4be8a6cba2f54b5f44b3,9,5,1,6816,,,0,"Move PrivateDevices before mysql password set

Move the PrivateDevices before we try to start the service the first time

Related-Bug: 1697531
Change-Id: I67ef7ba02ee652e9855b9cf4ba7a44a361844a83
(cherry picked from commit 588b9cead7637cc73cc8607e2460fea24cc6e2b0)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/25/475025/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_install_yum.yml', 'tasks/galera_post_install.yml']",2,c6d36689655586971fbd4be8a6cba2f54b5f44b3,bug/1697531,,"# See comments above 'galera_disable_privatedevices' in defaults/main.yml for # links to relevant bugs and discussion. - name: Remove PrivateDevices systemd options when in container template: src: without-privatedevices.conf.j2 dest: ""/etc/systemd/system/mariadb.service.d/without-privatedevices.conf"" when: - ansible_pkg_mgr == 'yum' - ansible_service_mgr == 'systemd' notify: - Reload the systemd daemon - Restart mysql tags: - galera-config ",32,15
openstack%2Fproject-config~master~I87809d8917fdd5ca7319241934a006480b736bd3,openstack/project-config,master,I87809d8917fdd5ca7319241934a006480b736bd3,Actually use opendns,MERGED,2017-06-16 17:29:06.000000000,2017-06-16 17:49:22.000000000,2017-06-16 17:49:22.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-06-16 17:29:06.000000000', 'files': ['nodepool/elements/nodepool-base/README.rst', 'nodepool/elements/nodepool-base/environment.d/75-nodepool-base-env'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3fe3e40aa7a9100203536c00eb70801c7ec2ea52', 'message': ""Actually use opendns\n\nTurns out that we set these vars via an evironment.d file in the DIB\nelement which was overriding the finalise script's values to continue to\nuse google dns as primary resolver. Update the environment.d file to use\nopendns by default with fallback being google dns.\n\nChange-Id: I87809d8917fdd5ca7319241934a006480b736bd3\n""}]",0,475037,3fe3e40aa7a9100203536c00eb70801c7ec2ea52,9,5,1,4146,,,0,"Actually use opendns

Turns out that we set these vars via an evironment.d file in the DIB
element which was overriding the finalise script's values to continue to
use google dns as primary resolver. Update the environment.d file to use
opendns by default with fallback being google dns.

Change-Id: I87809d8917fdd5ca7319241934a006480b736bd3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/37/475037/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/nodepool-base/README.rst', 'nodepool/elements/nodepool-base/environment.d/75-nodepool-base-env']",2,3fe3e40aa7a9100203536c00eb70801c7ec2ea52,opendns,export NODEPOOL_STATIC_NAMESERVER_V6=${NODEPOOL_STATIC_NAMESERVER_V6:-2620:0:ccc::2} export NODEPOOL_STATIC_NAMESERVER_V4=${NODEPOOL_STATIC_NAMESERVER_V4:-208.67.222.222} export NODEPOOL_STATIC_NAMESERVER_V6_FALLBACK=${NODEPOOL_STATIC_NAMESERVER_V6_FALLBACK:-2001:4860:4860::8888} export NODEPOOL_STATIC_NAMESERVER_V4_FALLBACK=${NODEPOOL_STATIC_NAMESERVER_V4_FALLBACK:-8.8.8.8},export NODEPOOL_STATIC_NAMESERVER_V6=${NODEPOOL_STATIC_NAMESERVER_V6:-2001:4860:4860::8888} export NODEPOOL_STATIC_NAMESERVER_V4=${NODEPOOL_STATIC_NAMESERVER_V4:-8.8.8.8},8,4
openstack%2Fglance~master~I17bb24aafc5567f2e39ff61d1b1f54eb4039a33f,openstack/glance,master,I17bb24aafc5567f2e39ff61d1b1f54eb4039a33f,DNM: Testing new jobs,ABANDONED,2017-06-16 17:39:48.000000000,2017-06-16 17:43:18.000000000,,[],"[{'number': 1, 'created': '2017-06-16 17:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a56fc7ca5f153ee79ae9612323d1061e98f4262a', 'message': 'DNM: Testing new jobs\n\nThis is to test the new functional jobs.\n\nChange-Id: I17bb24aafc5567f2e39ff61d1b1f54eb4039a33f\nDepends-on: I2b9506d8cb3f4e7e7fde25b3a8add84b6f1b143b\n'}, {'number': 2, 'created': '2017-06-16 17:42:19.000000000', 'files': ['glance/location.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/e235b1d68790888c1128972b08b47d67970e891e', 'message': 'DNM: Testing new jobs\n\nThis is to test the new functional jobs.\n\nChange-Id: I17bb24aafc5567f2e39ff61d1b1f54eb4039a33f\nDepends-on: I2b9506d8cb3f4e7e7fde25b3a8add84b6f1b143b\n'}]",0,475042,e235b1d68790888c1128972b08b47d67970e891e,3,0,2,11904,,,0,"DNM: Testing new jobs

This is to test the new functional jobs.

Change-Id: I17bb24aafc5567f2e39ff61d1b1f54eb4039a33f
Depends-on: I2b9506d8cb3f4e7e7fde25b3a8add84b6f1b143b
",git fetch https://review.opendev.org/openstack/glance refs/changes/42/475042/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a56fc7ca5f153ee79ae9612323d1061e98f4262a,wip,,,1,0
openstack%2Fpuppet-gnocchi~master~I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d,openstack/puppet-gnocchi,master,I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d,Deprecate logging options,MERGED,2017-06-07 18:39:11.000000000,2017-06-16 17:34:38.000000000,2017-06-16 17:34:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-06-07 18:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/033a8b6321bf26a16acea08d356dc3126fa2e6c0', 'message': 'Deprecate logging options\n\nGnocchi is moving away from oslo.log to using daiquiri[1]\n\nLets deprecate the options that dont make sense anymore.\n\n[1]  http://github.com/jd/daiquiri\n\nChange-Id: I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d\n'}, {'number': 2, 'created': '2017-06-08 12:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/e42105b22321fb35d858748e8dbc4955baba5f29', 'message': 'Deprecate logging options\n\nGnocchi is moving away from oslo.log to using daiquiri[1]\n\nLets deprecate the options that dont make sense anymore.\n\n[1]  http://github.com/jd/daiquiri\n\nChange-Id: I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d\n'}, {'number': 3, 'created': '2017-06-09 18:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/7a2cf5e5be5eda04bad1740a607b072f31dc8181', 'message': 'Deprecate logging options\n\nGnocchi is moving away from oslo.log to using daiquiri[1]\n\nLets deprecate the options that dont make sense anymore.\n\n[1]  http://github.com/jd/daiquiri\n\nChange-Id: I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d\n'}, {'number': 4, 'created': '2017-06-13 21:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/a46fe1a6086538ca44f0acbd96bef2dac38fe8d0', 'message': 'Deprecate logging options\n\nGnocchi is moving away from oslo.log to using daiquiri[1]\n\nLets deprecate the options that dont make sense anymore.\n\n[1]  http://github.com/jd/daiquiri\n\nChange-Id: I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d\n'}, {'number': 5, 'created': '2017-06-15 14:51:53.000000000', 'files': ['manifests/logging.pp', 'releasenotes/notes/deprecate-oslo-log-params-12ed30a5db0e5baf.yaml', 'spec/classes/gnocchi_logging_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/48ab267d686a9ec5e364df3b8c368fa628afe0b8', 'message': 'Deprecate logging options\n\nGnocchi is moving away from oslo.log to using daiquiri[1]\n\nLets deprecate the options that dont make sense anymore.\n\n[1]  http://github.com/jd/daiquiri\n\nChange-Id: I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d\n'}]",1,471884,48ab267d686a9ec5e364df3b8c368fa628afe0b8,15,3,5,6924,,,0,"Deprecate logging options

Gnocchi is moving away from oslo.log to using daiquiri[1]

Lets deprecate the options that dont make sense anymore.

[1]  http://github.com/jd/daiquiri

Change-Id: I0b8e324f40ac35f2f7f7f1234b8183eb40a8a64d
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/84/471884/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/logging.pp', 'spec/classes/gnocchi_logging_spec.rb']",2,033a8b6321bf26a16acea08d356dc3126fa2e6c0,deprecate-old-logging-params,," :logging_context_format_string => '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s', :logging_default_format_string => '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s', :logging_debug_format_suffix => '%(funcName)s %(pathname)s:%(lineno)d', :logging_exception_prefix => '%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s', :log_config_append => '/etc/gnocchi/logging.conf', :publish_errors => true, :default_log_levels => { 'amqp' => 'WARN', 'amqplib' => 'WARN', 'boto' => 'WARN', 'sqlalchemy' => 'WARN', 'suds' => 'INFO', 'iso8601' => 'WARN', 'requests.packages.urllib3.connectionpool' => 'WARN' }, :fatal_deprecations => true, :instance_format => '[instance: %(uuid)s] ', :instance_uuid_format => '[instance: %(uuid)s] ', :log_date_format => '%Y-%m-%d %H:%M:%S', shared_examples_for 'logging params set' do it 'enables logging params' do is_expected.to contain_oslo__log('gnocchi_config').with( :logging_context_format_string => '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s', :logging_default_format_string => '%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s', :logging_debug_format_suffix => '%(funcName)s %(pathname)s:%(lineno)d', :logging_exception_prefix => '%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s %(instance)s', :log_config_append => '/etc/gnocchi/logging.conf', :publish_errors => true, :default_log_levels => { 'amqp' => 'WARN', 'amqplib' => 'WARN', 'boto' => 'WARN', 'sqlalchemy' => 'WARN', 'suds' => 'INFO', 'iso8601' => 'WARN', 'requests.packages.urllib3.connectionpool' => 'WARN' }, :fatal_deprecations => true, :instance_format => '[instance: %(uuid)s] ', :instance_uuid_format => '[instance: %(uuid)s] ', :log_date_format => '%Y-%m-%d %H:%M:%S', ) end end shared_examples_for 'logging params unset' do [ :logging_context_format_string, :logging_default_format_string, :logging_debug_format_suffix, :logging_exception_prefix, :log_config_append, :publish_errors, :default_log_levels, :fatal_deprecations, :instance_format, :instance_uuid_format, :log_date_format, ].each { |param| it { is_expected.to contain_oslo__log('gnocchi_config').with(""#{param}"" => '<SERVICE DEFAULT>') } } end ",58,58
openstack%2Fos-collect-config~master~I637b2bfe17842ab5fbcbe8369cd04cfbd38b8ecb,openstack/os-collect-config,master,I637b2bfe17842ab5fbcbe8369cd04cfbd38b8ecb,Updated from global requirements,MERGED,2017-06-15 16:32:18.000000000,2017-06-16 17:29:48.000000000,2017-06-16 17:29:48.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-06-15 16:32:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-collect-config/commit/9d7ae9439b83c6a65a1cd34bdad08998f76726fd', 'message': 'Updated from global requirements\n\nChange-Id: I637b2bfe17842ab5fbcbe8369cd04cfbd38b8ecb\n'}]",0,474675,9d7ae9439b83c6a65a1cd34bdad08998f76726fd,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I637b2bfe17842ab5fbcbe8369cd04cfbd38b8ecb
",git fetch https://review.opendev.org/openstack/os-collect-config refs/changes/75/474675/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9d7ae9439b83c6a65a1cd34bdad08998f76726fd,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~Ia0f0fd2940db1d3df2ac92265a7b292f342968e8,openstack/openstack-manuals,master,Ia0f0fd2940db1d3df2ac92265a7b292f342968e8,ScaleIO Config: Adding Extra Spec documentation,ABANDONED,2017-06-16 02:53:13.000000000,2017-06-16 17:01:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-16 02:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/86c30fa82a01058424a444c2264aab180164e4dd', 'message': 'ScaleIO Config: Adding Extra Spec documentation\n\nExtra spec documentation was missing from the\nScaleIO Block Driver Confiuration Reference\n\nChange-Id: Ia0f0fd2940db1d3df2ac92265a7b292f342968e8\n'}, {'number': 2, 'created': '2017-06-16 03:13:35.000000000', 'files': ['doc/config-reference/source/block-storage/drivers/dell-emc-scaleio-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9569297d0868b76bacdccea1b0f1881a5415cb87', 'message': 'ScaleIO Config: Adding Extra Spec documentation\n\nExtra spec documentation was missing from the\nScaleIO Block Driver Confiuration Reference\n\nChange-Id: Ia0f0fd2940db1d3df2ac92265a7b292f342968e8\n'}]",0,474832,9569297d0868b76bacdccea1b0f1881a5415cb87,5,1,2,25033,,,0,"ScaleIO Config: Adding Extra Spec documentation

Extra spec documentation was missing from the
ScaleIO Block Driver Confiuration Reference

Change-Id: Ia0f0fd2940db1d3df2ac92265a7b292f342968e8
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/474832/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/block-storage/drivers/dell-emc-scaleio-driver.rst'],1,86c30fa82a01058424a444c2264aab180164e4dd,, Extra spec options ~~~~~~~~~~~~~~~~~~ Extra specs are used in volume types created in Block Storage as the preferred property of the volume. The Block Storage scheduler will use extra specs to find the suitable back end for the volume and the Block Storage driver will create the volume based on the properties specified by the extra spec. Use the following command to create a volume type: .. code-block:: console $ openstack volume type create demoVolumeType Use the following command to update the extra spec of a volume type: .. code-block:: console $ openstack volume type set --property provisioning:type=thin demoVolumeType The following sections describe the ScaleIO extra keys. Provisioning type ----------------- - Key: ``provisioning:type`` - Possible Values: - ``thick`` Volume is fully provisioned. Run the following commands to create a ``thick`` volume type: .. code-block:: console $ openstack volume type create myVolumeType $ openstack volume type set --property provisioning:type=thick myVolumeType - ``thin`` Volume is virtually provisioned. Run the following commands to create a ``thin`` volume type: .. code-block:: console $ openstack volume type create myVolumeType $ openstack volume type set --property provisioning:type=thin myVolumeType - Default: Controlled by ``san_thin_provision`` in ``cinder.conf`` or ``thin`` if not set Protection Domain ----------------- - Key: ``sio:pd_name`` The name of the ScaleIO Protection Domain. .. code-block:: console $ openstack volume type create myVolumeType $ openstack volume type set --property sio:pd_name=myProtectionDomain myVolumeType - Default: Value of ``sio_protection_domain_name`` in ``cinder.conf`` Storage Pool ----------------- - Key: ``sio:sp_name`` The name of the ScaleIO Storage Pool. .. code-block:: console $ openstack volume type create myVolumeType $ openstack volume type set --property sio:sp_name=myStoragePool myVolumeType - Default: Value of ``sio_storage_pool_name`` in ``cinder.conf``,,83,0
openstack%2Fpbr~master~I6c0cb3c53f2ba9c28c705a1dffa27adf455d198a,openstack/pbr,master,I6c0cb3c53f2ba9c28c705a1dffa27adf455d198a,Add another monkeypatch to sphinx,ABANDONED,2017-06-03 15:10:36.000000000,2017-06-16 17:00:55.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-06-03 15:10:36.000000000', 'files': ['pbr/tests/test_setup.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/31d7acdcb65e44faaebbbc961c1452a894da1ddf', 'message': ""Add another monkeypatch to sphinx\n\nInside of sphinx setup_command, sphinx now does error checking. Our fake\nobject doesn't set up the attribute it looks for, so the tests bomb out.\n\nI love mocking things.\n\nChange-Id: I6c0cb3c53f2ba9c28c705a1dffa27adf455d198a\n""}]",0,470633,31d7acdcb65e44faaebbbc961c1452a894da1ddf,3,1,1,2,,,0,"Add another monkeypatch to sphinx

Inside of sphinx setup_command, sphinx now does error checking. Our fake
object doesn't set up the attribute it looks for, so the tests bomb out.

I love mocking things.

Change-Id: I6c0cb3c53f2ba9c28c705a1dffa27adf455d198a
",git fetch https://review.opendev.org/openstack/pbr refs/changes/33/470633/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/tests/test_setup.py'],1,31d7acdcb65e44faaebbbc961c1452a894da1ddf,," ""sphinx.application.Sphinx.statuscode"", 0)) self.useFixture(fixtures.MonkeyPatch(",,2,0
openstack%2Fironic-python-agent~master~I58e3ad5330714ea2348e8043ea77063a7c965bc8,openstack/ironic-python-agent,master,I58e3ad5330714ea2348e8043ea77063a7c965bc8,Updated from global requirements,MERGED,2017-06-15 16:24:21.000000000,2017-06-16 16:53:00.000000000,2017-06-16 16:53:00.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 14760}]","[{'number': 1, 'created': '2017-06-15 16:24:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5e02d31c74759b3d9d07a94390200bf953402d19', 'message': 'Updated from global requirements\n\nChange-Id: I58e3ad5330714ea2348e8043ea77063a7c965bc8\n'}]",0,474646,5e02d31c74759b3d9d07a94390200bf953402d19,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I58e3ad5330714ea2348e8043ea77063a7c965bc8
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/46/474646/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5e02d31c74759b3d9d07a94390200bf953402d19,openstack/requirements,"oslo.config!=4.3.0,!=4.4.0,>=4.0.0 # Apache-2.0",oslo.config>=4.0.0 # Apache-2.0,1,1
